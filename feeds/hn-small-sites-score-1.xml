<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 08 Jul 2020 16:16:30 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 08 Jul 2020 16:16:30 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Clean up your data science mess]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757810">thread link</a>) | @fabdrnd
<br/>
July 7, 2020 | https://www.deepflow.ai/clean-up-your-data-science-mess/ | <a href="https://web.archive.org/web/*/https://www.deepflow.ai/clean-up-your-data-science-mess/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.deepflow.ai/content/images/size/w300/2020/06/shallow-focus-photo-of-man-holding-floor-brush-ceramic-434163.jpg 300w,
                            https://www.deepflow.ai/content/images/size/w600/2020/06/shallow-focus-photo-of-man-holding-floor-brush-ceramic-434163.jpg 600w,
                            https://www.deepflow.ai/content/images/size/w1000/2020/06/shallow-focus-photo-of-man-holding-floor-brush-ceramic-434163.jpg 1000w,
                            https://www.deepflow.ai/content/images/size/w2000/2020/06/shallow-focus-photo-of-man-holding-floor-brush-ceramic-434163.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.deepflow.ai/content/images/size/w2000/2020/06/shallow-focus-photo-of-man-holding-floor-brush-ceramic-434163.jpg" alt="Clean Up Your Data Science Mess">
            </figure>

            <section>
                <div>
                    <p>From experimentation to production the road ahead is not paved. While trial and error is the essence of the Data Scientist's life, critical AI systems need clarity. For example, if you built a credit scoring AI that automatically grants loans to your customers, you need to understand how it makes decisions about who should or shouldn't receive a loan. This is the data scientist's job to ensure transparency, but it's not self-evident.</p><p>For a data scientist, a typical workflow looks like the this: You find a dataset, explore it in a notebook, try modeling techniques, fail, repeat ... until it works. After hours of adding new elements to a project, it's not uncommon finding oneself with a sprawling monster of data sources, notebooks and CSVs. That's when you start asking yourself, how do I put that in production? The "mess", that is an inherent part of the data exploration and modeling process, now prevents for a smooth transition of the project to production. Progress starts to stall and time to production keeps getting longer. To add to the pressure, your boss wants your solution live before the end of the week. But what took months of iterations and back and forth won't magically turn into production code. It's a problem that engineers know too well: avoiding technical debt by refactoring legacy code. Messy and hard-to-understand systems are not only a technical challenge, they routinely impact &nbsp;the bottom line of companies big and small (<a href="https://www.deepflow.ai/designing-trustworthy-ai/">read our article on Explainable AI</a>). Needless to say, you need to clean up the mess.</p><figure><img src="https://www.deepflow.ai/content/images/2020/06/maneuver-2.jpg" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/06/maneuver-2.jpg 600w, https://www.deepflow.ai/content/images/2020/06/maneuver-2.jpg 800w" sizes="(min-width: 720px) 720px"><figcaption>From Jupyter notebook to production, an allegory.</figcaption></figure><p>The hand-off of projects from "research" scientists to the "production" engineers is more standardized in large companies where R&amp;D is its own entity and processes are in place to facilitate communication. Data teams in small organizations bear the brunt of limited resources and short development cycles which adds even more pressure to avoid "messy" projects.</p><blockquote>(In Enterprise AI) The most exciting problems yet to be solved are in the deployment and serving space. One reason for the lack of serving solutions is the lack of communication between researchers and production engineers. At companies that can afford to pursue AI research (e.g. big companies), the research team is separated from the deployment team, and the two teams only communicate via the p-managers: product managers, program managers, project managers. Small companies, whose employees can see the entire stack, are constrained by their immediate product needs. Only a few startups, usually those founded by accomplished researchers with enough funding to hire accomplished engineers, have managed to bridge the gap. These startups are poised to take a big chunk of the AI tooling market. <strong>Chip Huyen - "<a href="https://huyenchip.com/2020/06/22/mlops.html">What I learned from looking at 200 machine learning tools</a>"</strong></blockquote><figure><img src="https://www.deepflow.ai/content/images/2020/06/stuck-1.gif" alt=""><figcaption>Putting your AI models in production</figcaption></figure><h2 id="moving-ai-in-production">Moving AI in production</h2><p>In the software industry, the practice of managing the communication and hand offs between Developer and IT Operations is called DevOps. In practical terms, DevOps refers to the collection of industry practices that standardize how code is created, delivered, deployed and maintained in a consistent way from start to finish within a same team. It introduces two foundational concepts: Continuous Integration (CI) and Continuous Delivery (CD). While CI automates the building, packaging and testing of applications, CD automates the delivery of the applications to the different environments (e.g. development, testing, production).</p><p>Data Science works in a very similar way. After all, it's another flavor of software engineering. But because of some of the differences we discussed in the previous part DevOps principles cannot be transposed exactly in the same way. That's why DataOps is gaining interest in the industry, it goes beyond DevOps to offer a tailored approach to manage Data Science projects and avoid the "mess" from start to finish.</p><figure><img src="https://www.deepflow.ai/content/images/2020/06/Screenshot-2020-06-24-at-17.26.21.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/06/Screenshot-2020-06-24-at-17.26.21.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/06/Screenshot-2020-06-24-at-17.26.21.png 1000w, https://www.deepflow.ai/content/images/2020/06/Screenshot-2020-06-24-at-17.26.21.png 1192w" sizes="(min-width: 720px) 720px"><figcaption>DevOps vs. DataOps - <a href="https://datakitchen.io/dataops-cookbook-second-edition.html">The DataOps Cookbook 2nd Ed.</a></figcaption></figure><p>The main reason for DataOps as a separate approach is that contrary to traditional engineering teams, Data Science teams are often composed of many non-engineer types, like analysts or research-focused data scientists. Their skill-set is different from engineers. Their goal is not push production-ready code but to find how data can be leveraged to answer specific problems, explore datasets to find answers, and build predictive models. Their focus is only on improving the accuracy of their models and producing actionable visualizations. </p><p>Another differentiating aspect is the range of tools used. The typical mindset of an engineering team is &nbsp;to create a standardized "sandbox" (isolated development environment to qualify code before pushing it to production) for every engineer in the team. When working on the same projects, every engineer sandbox will look exactly the same to make sure individual changes can be merged easily, thus speeding up development time and improving the quality of the overall code-base. In the context of data teams, creating a standardized environment is much more challenging. Data scientists and analysts tend to use their own tools. The exploratory nature of their work makes it almost a necessity. In this context, we prefer to talk about "orchestration" rather than "building" (see previous graph).</p><p>In conclusion, while DevOps deals with managing the complexity of the engineering life-cycle through centralization (aka. one DevOps team per company), DataOps aims to manage the freedom of Data Science through orchestration (aka. data teams are local and are distributed across the oragnization).</p><figure><img src="https://www.deepflow.ai/content/images/2020/06/cd4ml-end-to-end-2.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/06/cd4ml-end-to-end-2.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/06/cd4ml-end-to-end-2.png 1000w, https://www.deepflow.ai/content/images/size/w1600/2020/06/cd4ml-end-to-end-2.png 1600w, https://www.deepflow.ai/content/images/2020/06/cd4ml-end-to-end-2.png 1832w" sizes="(min-width: 720px) 720px"><figcaption>Continuous Delivery for Machine Learning end-to-end process - <a href="https://martinfowler.com/articles/cd4ml.html#cd4ml-end-to-end.png">CD4ML</a></figcaption></figure><h2 id="the-future-of-enterprise-ai-business-leaders-with-ai-skills">The future of Enterprise AI: business leaders with AI skills</h2><p>As highlighted in the graph below, the biggest change in AI is happening behind the curtain. AI researchers, while still <a href="https://www.nytimes.com/2017/10/22/technology/artificial-intelligence-experts-salaries.html">expensive and in scarce numbers</a>, are not the coveted unicorns they once were.</p><figure><img src="https://www.deepflow.ai/content/images/2020/06/Screenshot-2020-06-24-at-14.53.21-2.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/06/Screenshot-2020-06-24-at-14.53.21-2.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/06/Screenshot-2020-06-24-at-14.53.21-2.png 1000w, https://www.deepflow.ai/content/images/size/w1600/2020/06/Screenshot-2020-06-24-at-14.53.21-2.png 1600w, https://www.deepflow.ai/content/images/2020/06/Screenshot-2020-06-24-at-14.53.21-2.png 2294w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www2.deloitte.com/us/en/insights/focus/cognitive-technologies/ai-adoption-in-the-workforce.html">Deloitte Insights - AI in the Enterprise</a></figcaption></figure><p>After years of educating themselves, an increasing number of companies are realizing that AI research is overkill for their business. The already available algorithms and techniques are more than sufficient to tackle existing problems, no need to reinvent the wheel. What is missing is the ability for organizations to understand how to leverage the state of the art into working solutions. Business leaders and managers need to be trained to understand and utilize existing AI solutions.</p><blockquote>Many companies rush into the AI race without clear objectives, hope a brilliant AI researcher and a technology team can create something great without guidance, and end up with little to show for it. Recruiting an AI quarterback to provide the business input, and ensuring success with well-defined metrics, is the most important job that most companies miss. <strong>Beck, Davenport, and Libert - "<a href="https://hbr.org/2019/03/the-ai-roles-some-companies-forget-to-fill">The AI roles some companies forget to fill</a>".</strong></blockquote><hr><h2 id="track-your-data-team-progress-and-reduce-time-to-production-">Track your data team progress and reduce time to production.</h2><p>With workflows that are production-ready by design, Deepflow makes it easy to manage the versioning, CI/CD, testing and monitoring of your models from conception to execution.</p><h3 id="join-the-next-batch-of-early-adopters">&gt;&gt;<a href="https://bit.ly/Deepflow-Early-Adopter">Join the next batch of early adopters</a>&lt;&lt;</h3><figure><img src="https://www.deepflow.ai/content/images/2020/06/Dashboard-6.jpg" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/06/Dashboard-6.jpg 600w, https://www.deepflow.ai/content/images/size/w1000/2020/06/Dashboard-6.jpg 1000w, https://www.deepflow.ai/content/images/2020/06/Dashboard-6.jpg 1440w" sizes="(min-width: 720px) 720px"></figure>
                </div>
            </section>

                <section>
    <h3>Subscribe to Deepflow</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.deepflow.ai/clean-up-your-data-science-mess/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757810</guid>
            <pubDate>Tue, 07 Jul 2020 10:55:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Event-Streaming: An Additional Architectural Style to Supplement API Design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757781">thread link</a>) | @derberg
<br/>
July 7, 2020 | https://www.asyncapi.com/blog/event-streaming-an-additional-architectural-style-to-suplement-api-design/ | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/event-streaming-an-additional-architectural-style-to-suplement-api-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<blockquote>
<p>This post originally appeared on <a href="https://medium.com/capital-one-tech/event-streaming-an-additional-architectural-style-to-supplement-api-design-703c4f801722" target="_blank">Capital One Tech</a></p>
</blockquote>

<p>The growth and adoption of web-based APIs is key to the transformational technology journey of any enterprise. Those APIs, whether they are RESTful or not, remain synchronous. They, like the web, utilize the pattern of HTTP to implement a request-response interaction approach.</p>

<p>To illustrate, assume we have a project management API with the following interactions:</p>

<ol>
<li>Create a project (e.g. POST /projects)</li>
<li>Create a new task (e.g. POST /projects/{projectId}/tasks)</li>
<li>Assign the task to someone on our team (e.g. POST /tasks/{taskId}/assignees)</li>
<li>The assignee marks the task as complete (e.g. PUT /tasks/{taskId})</li>
</ol>

<p>An API following this design works if design of the user interface closely mirrors those endpoints. But suppose an additional application requirement is to ‘automatically’ update a task’s status when marked complete by another user. With a request/response web-API, an option is to incessantly poll a status API on the chance a status might have changed. This is both cumbersome and error-prone.
Instead of polling, we can introduce an <strong>event-driven architecture</strong>.</p>

<h2 id="introduction-to-event-driven-architecture">Introduction to Event-Driven Architecture<a href="#introduction-to-event-driven-architecture" arialabel="Anchor"> #︎</a> </h2>

<p>In an event-driven architecture (or EDA), an application is composed of independent components that react to events published by other components. EDA is popular for distributed applications, as new components may be introduced into a solution to solve emerging problems — without the knowledge of previously developed components. Message brokers are used as an intermediary for communication, producing a loosely coupled design by preventing components from directly communicating with one another.</p>

<p>If you are familiar with service-oriented architecture (SOA), you have experienced EDA. Most service-oriented architectures used an enterprise service bus (ESB) for service communication rather than a message broker. Events were published to the ESB, where they were then routed to other services to integrate two or more software systems. However, ESBs proved problematic as they were used as “integration glue”, causing integration code to become scattered across services, apps, and the ESB; fragile systems were created. This fragility produced a greater need for coordination between teams, slowing software delivery.</p>

<h2 id="the-emergence-of-a-microservice-and-event-driven-architecture">The Emergence of a Microservice and Event-Driven Architecture<a href="#the-emergence-of-a-microservice-and-event-driven-architecture" arialabel="Anchor"> #︎</a> </h2>

<p>To overcome this increased coordination, the microservice architecture was introduced as a replacement for traditional SOA. This newer distributed architecture, built on APIs and microservices, encourages “dumb pipes, smart endpoints.” Integration logic is pushed to the consumers and producers. Message brokers, rather than ESBs, are used for message routing, not integration logic. Services and APIs talk to one another while hiding implementation details. This loose coupling makes software more resilient to evolution as new requirements emerge.</p>

<p>As enterprises shift to APIs backed by a microservice architecture, the number of published events has grown considerably. Message brokers are typically transactional in nature, ensuring once-and-only-once delivery of messages. While useful for traditional software development, the transactional nature of message brokers limits the scalability of service communication.</p>

<p>Distributed streaming data platforms, such as Apache Kafka, now offer enterprises higher throughput than traditional message brokers. Kafka removes the need for transactional messaging found in message brokers, opting instead for turning events into message streams. These streams are accessible by any authorized subscriber and may be accessed real-time or processed sequentially from a predetermined location or at the start of the stream.</p>

<h2 id="api-design-with-event-streaming">API Design with Event Streaming<a href="#api-design-with-event-streaming" arialabel="Anchor"> #︎</a> </h2>

<p>Event streams help software extend beyond the request-response approach common to web API styles such as REST, GraphQL, and gRPC. Software can communicate bi-directionally, removing the need for API consumers to continually poll for state changes. Instead, APIs publish events to an event stream for notification of data changes or important business events to any number of subscribed services for further processing.</p>

<p>Let’s revisit our previous example. We needed to solve two separate requirements:</p>

<ol>
<li>Notification when a task is marked as completed. Our only option without a message-driven architecture is to require interested parties to constantly make API calls to see if the task has been completed (aka polling)</li>
<li>Alerting a project owner when a task has been modified or marked as completed. Our only option is to mix our user interface concerns with our API by making the API send an email. The API is no longer responsible for managing projects and tasks — it is now responsible for the content and look-and-feel for email alerts</li>
</ol>

<p>If we introduce a message-driven architecture to our solution, we can develop an API that delivers project and task resources that offer the necessary capabilities (create, read, update, delete, and mark as complete). Our API doesn’t need to know about how the task completion event notification will be used, including that an email will be sent. All it needs to do is publish event messages when those events occur and allow other services to take action as appropriate. Events this API may publish include:</p>

<p><img src="https://www.asyncapi.com/images/posts/event-streaming-an-additional-architectural-style-to-suplement-api-design/event-examples.webp" alt="Example of API events" title="Example of API events"></p>

<p>Interested parties can then subscribe to the event(s) they are interested in and safely ignore the rest. In our example, we may end up with three components:</p>

<ol>
<li><strong>Projects API</strong> — Manages the Projects and Project Tasks resources via a REST-based API. The API may be comprised of one or more microservices that implement the capabilities offered by the REST API. When any event, from the list in the table above, occurs then the API publishes an event into the appropriate message stream for consumption by event subscribers</li>
<li><strong>Task Completed Email Microservice</strong> — Subscribes to the Task.Completed event, notifying project manager(s) via email when any task has been marked as completed</li>
<li><strong>Task Modified Email Microservice</strong> — Subscribes to the Task.Updated event, notifying all team members via email when any task has been edited</li>
</ol>

<p>The API has no awareness of the two microservices subscribed to the specific events; it just publishes the events to the appropriate message stream. The solution is considered loosely coupled and therefore capable of evolving over time as new requirements emerge, perhaps with new types of notifications (e.g. SMS, web dashboard alerts) or integrations (e.g. synching to JIRA).</p>

<h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor"> #︎</a> </h2>

<p>The demand for more robust methods of software communication is pushing the limits of today’s interface solutions. Request/response-based APIs are essential. However, today’s technical problems are now demanding event-driven support — in addition to request/response — to improve an API’s capability offerings.</p>

<p>As API designers, we must strive to use all available tools to offer a better developer experience. As you enhance your existing APIs and new APIs emerge, ask yourself:</p>

<ol>
<li>How can my solution architecture be improved by moving beyond standard REST APIs and into a loosely-coupled event-driven architecture?</li>
<li>What events should my API publish that would benefit API consumers?</li>
<li>How will my API consumers benefit from the addition of these events and how do they take advantage of them?</li>
</ol>

<p>Let’s shift our approach from strictly request-response to thinking in terms of how our APIs can not only offer endpoints for requests, but events that enable the API to push to other services. The result will be increased innovation and more transformative APIs both within and across our LOBs.</p>
</div></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/event-streaming-an-additional-architectural-style-to-suplement-api-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757781</guid>
            <pubDate>Tue, 07 Jul 2020 10:50:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snapchat Detection on iOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757666">thread link</a>) | @mpweiher
<br/>
July 7, 2020 | https://aeonlucid.com/Snapchat-detection-on-iOS/ | <a href="https://web.archive.org/web/*/https://aeonlucid.com/Snapchat-detection-on-iOS/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Previously we took a look at <a href="https://aeonlucid.com/Snapchat-detection-on-Android/">Snapchat’s root detection methods on Android</a>. This time we are taking a look at how they detect jailbreaks, tweaks and hooks on iOS.</p>



<p>All the research in this post is based on Snapchat 10.65.0.66 (832559634).</p>

<p><img src="https://aeonlucid.com/images/snapchat/ios_login_message.png" alt="Login Message">
</p>

<p>This is the message you see when you try to login with a detected tweak, although not all tweaks trigger this message. Two examples that trigger this message are <a href="http://cydia.saurik.com/package/com.johncoates.flex3/">Flex 3</a> and <a href="https://www.reddit.com/r/jailbreak/comments/9baacc/release_wraith_snapchatphantom_replacement/">Wraith</a>. Some just flag your account and will get you banned later in a ban wave if you are unlucky.</p>

<h2 id="avoiding-bans">Avoiding bans</h2>

<p>So obviously the first thing we want to look at is, what has the community tried so far to stay hidden? If you google around a bit you will most likely end up with these result. For a few of them, I will list the most notable features.</p>

<ul>
  <li>NoSub (or variants)
    <ul>
      <li>Disable Cydia Substrate / Substitute entirely for specific apps.</li>
      <li>Only if you can find an updated version and don’t want to use tweaks on Snapchat.</li>
    </ul>
  </li>
  <li><a href="https://github.com/NepetaDev/UnSub/blob/master/Tweak/Tweak.xm">UnSub</a>
    <ul>
      <li>Hooks and filters libc file system calls.</li>
      <li>Spoofs the libc getenv to remove the <code>DYLD_INSERT_LIBRARIES</code> variable.</li>
      <li>Spoofs <code>_dyld_image_count</code> and <code>_dyld_get_image_name</code> to hide tweak related dylibs.</li>
    </ul>
  </li>
  <li><a href="https://github.com/jjolano/shadow/blob/master/Tweak.xm">Shadow</a>
    <ul>
      <li>Too much to list.. it hooks way too much.</li>
      <li>Still misses lots of stuff for Snapchat specifically.</li>
    </ul>
  </li>
</ul>

<p>Even <a href="https://support.snapchat.com/en-US/a/jailbroken-iphone">Snapchat themselves recommend NoSub</a>..</p>

<p><img src="https://aeonlucid.com/images/snapchat/ios_snapchat_jailbroken_support.png" alt="Login Message">
</p>

<p>But it seems that nobody knows what Snapchat is <strong>exactly</strong> doing to detect everything. Which is why I am writing this post. Only one that I have seen <a href="https://twitter.com/cokepokes/status/1023114963550797824">publicly making efforts</a> to figure this out is the developer of Phantom, CokePokes.</p>

<h2 id="how-are-they-doing-it">How are they doing it?</h2>

<p>I will try my best to explain every check they do in Snapchat 10.65.0.66.</p>

<p>When you launch the app they create a new thread using <a href="http://man7.org/linux/man-pages/man3/pthread_create.3.html">pthread_create</a> that runs all the checks. At the end of these checks an integer is stored with flags of everything that was detected on the device. Some of these checks are then ran every 31 seconds.</p>

<p>All the code executed for these checks is obfuscated with <a href="https://www.crunchbase.com/organization/strong-codes">Snapchats in-house obfuscation tools</a> and thus very annoying to look at using tools such as IDA.</p>

<h3 id="code-signature-checks">Code signature checks</h3>

<p>One of the first things they do is checking and storing stuff from the code signature. This happens using the <code>sys_csops(169)</code> syscall, which is pretty much undocumented but is very similar to the code here.</p>

<ul>
  <li><a href="https://fergofrog.com/code/cbowser/xnu/bsd/kern/kern_proc.c.html#csops">xnu/bsd/kern/kern_proc.c.html#csops</a></li>
  <li><a href="https://fergofrog.com/code/cbowser/xnu/bsd/kern/kern_proc.c.html#csops_internal">xnu/bsd/kern/kern_proc.c.html#csops_internal</a></li>
</ul>

<p>They execute the following operations:</p>

<ul>
  <li><code>CS_OPS_STATUS</code></li>
  <li><code>CS_OPS_CDHASH</code></li>
  <li><code>CS_OPS_ENTITLEMENTS_BLOB</code></li>
</ul>

<p>The most important one of this is the <code>CS_OPS_STATUS</code>, this retrieves the current codesigning status of the process. A jailbroken device can respond with messy status flags. Such as:</p>

<ul>
  <li><code>CS_GET_TASK_ALLOW</code></li>
  <li><code>CS_INSTALLER</code></li>
  <li><code>CS_PLATFORM_BINARY</code></li>
  <li><code>CS_DEBUGGED</code> (Process was debugged / is being debugged)</li>
  <li>Or missing <code>CS_VALID</code>.</li>
</ul>

<p>A normal device would have these flags:</p>

<ul>
  <li><code>CS_VALID</code></li>
  <li><code>CS_HARD</code></li>
  <li><code>CS_KILL</code></li>
  <li><code>CS_ENFORCEMENT</code></li>
  <li><code>CS_REQUIRE_LV</code></li>
  <li><code>CS_DYLD_PLATFORM</code></li>
  <li><code>CS_SIGNED</code></li>
</ul>

<p>For all available flags and their descriptions, see <a href="https://fergofrog.com/code/cbowser/xnu/BUILD/obj/EXPORT_HDRS/osfmk/kern/cs_blobs.h.html#_M/CS_VALID">this page</a>.</p>

<p>The result of <code>CS_OPS_STATUS</code> and <code>CS_OPS_CDHASH</code> are stored and later sent to the Snapchat servers, encrypted.</p>

<h3 id="bundle-check">Bundle check</h3>

<p>This is a simple check but quite effective if not noticed by a tweak developer. Pseudo code looks like this.</p>

<div><div><pre><code>x0 = CFBundleGetMainBundle()
x1 = CFBundleGetIdentifier(x0)
x2 = CFStringGetCStringPtr(x1)
strncmp("com.toyopagroup.picaboo", x2)
</code></pre></div></div>

<h3 id="dyld-check">Dyld check</h3>

<p>Snapchat has two methods to iterate all loaded dylibs.</p>

<h4 id="first-attempt">First attempt</h4>

<p>One way is using <a href="https://github.com/theos/sdks/blob/master/iPhoneOS11.2.sdk/usr/include/mach-o/dyld.h#L48">dyld_get_image_header</a> and <a href="http://man7.org/linux/man-pages/man3/dladdr1.3.html">dladdr</a>. They iterate over <code>dyld_get_image_header</code> until it returns null and checks if it has seen everything with <a href="https://github.com/theos/sdks/blob/master/iPhoneOS11.2.sdk/usr/include/mach-o/dyld.h#L47">dyld_image_count</a>. The <code>dladdr</code> method provides them with the path of the dylib. These are checked against a few unknown strings but removing everything substrate related from the dyld list fixes this check.</p>

<h4 id="second-attempt">Second attempt</h4>

<p>The other method they use is calling <a href="https://developer.apple.com/documentation/kernel/1537934-task_info">task_info</a> with flavor <code>TASK_DYLD_INFO</code>. This also gives them a list of all loaded dylibs and must be fixed separately from the first dyld check.</p>

<h3 id="file-system-checks">File system checks</h3>

<p>There are a couple of file system checks, of which all use the <code>sys_access(33)</code> syscall.</p>

<h4 id="first-list">First list</h4>

<ul>
  <li>/Library/Application Support/PhLite/phlite.bundle/AuthAPI.pem</li>
  <li>/private/var/tmp/cydia.log</li>
  <li>/bin/bash</li>
  <li>/usr/sbin/sshd</li>
  <li>/usr/libexec/ssh-keysign</li>
  <li>/usr/libexec/sftp-server</li>
  <li>/etc/ssh/sshd_config</li>
  <li>/.installed_yaluX</li>
  <li>/Library/LaunchDaemons/dropbear.plist</li>
  <li>/usr/local/bin/dropbear</li>
  <li>/System/Library/Caches/com.apple.dyld/enable-dylibs-to-override-cache</li>
  <li>/.cydia_no_stash</li>
  <li>/var/log/jailbreakd-stdout.log</li>
  <li>/etc/motd</li>
  <li>/usr/lib/libsubstitute.dylib</li>
  <li>/var/tmp/slide.txt</li>
</ul>

<h4 id="second-list">Second list</h4>

<ul>
  <li>/private/var/containers/Bundle/Application/AD659AF8-68C3-4E4B-BF02-236E1F733005/Snapchat.app/Ghay</li>
  <li>/private/var/containers/Bundle/Application/AD659AF8-68C3-4E4B-BF02-236E1F733005/Snapchat.app/Snapchat.crc</li>
  <li>/private/var/containers/Bundle/Application/AD659AF8-68C3-4E4B-BF02-236E1F733005/Snapchat.app/embedded.mobileprovision</li>
</ul>

<h4 id="last-one-and-expected-to-exist">Last one (and expected to exist)</h4>

<ul>
  <li>/private/var/containers/Bundle/Application/AD659AF8-68C3-4E4B-BF02-236E1F733005/Snapchat.app/PlugIns</li>
</ul>

<p>The last one makes it a bit harder to fix, since you can not simply replace the arm instructions with something that makes it always return false. Thus requiring an inline hook as replacement for the syscall so you gain full control over it.</p>

<h3 id="obj-c---class-checks">Obj-C - Class checks</h3>

<p>A lot of classes are checked from a lot of different tweaks. This is done using <a href="https://developer.apple.com/documentation/objectivec/1418952-objc_getclass">objc_getClass</a>.</p>

<ul>
  <li><code>SCOthmanPrefs</code></li>
  <li><code>SCOthmanSnapSaver</code></li>
  <li><code>SCOFiltersOthman</code></li>
  <li><code>SCSnapchPrefs</code></li>
  <li><code>SCSnapchLocation</code></li>
  <li><code>SCOFiltersSnapch</code></li>
  <li><code>PHSnapSaver</code></li>
  <li><code>PHRegisterViewController</code></li>
  <li><code>phlite</code></li>
  <li><code>dfnvrknsv</code></li>
  <li><code>PHSSaver</code></li>
  <li><code>PHMainSettingsVC</code></li>
  <li><code>SCPPrivacySettings</code></li>
  <li><code>SCPSettings</code></li>
  <li><code>SCPSavedMediaSettings</code></li>
  <li><code>SNAPCHAT_SCPSnapUsageSettings</code></li>
  <li><code>SNAPCHAT_SCPSegmentedController</code></li>
  <li><code>SNAPCHAT_CZPickerView</code></li>
  <li><code>CTAdBase</code></li>
  <li><code>CTRequestModel</code></li>
  <li><code>CTBannerView</code></li>
  <li><code>CPAdManager</code></li>
  <li><code>MMNativeAdController</code></li>
  <li><code>TweakBoxStartupManager</code></li>
  <li><code>SNAPCHAT_GPHelper</code></li>
  <li><code>SCKsausaPrefs</code></li>
  <li><code>SCSCGoodSnapSaver</code></li>
  <li><code>SNAPCHAT_XXXXXXX_GPHelper</code></li>
  <li><code>SCOFiltersHelper</code></li>
  <li><code>_xxx</code></li>
  <li><code>PHSSaver</code></li>
  <li><code>SIGMAPOINT_GPHelper</code></li>
  <li><code>SCS     SnapSaver</code></li>
  <li><code>SCW    wSnapSaver</code></li>
  <li><code>CYJSObject</code></li>
  <li><code>P         D</code></li>
  <li><code>R              t</code></li>
  <li><code>AVCameraViewControlIer</code></li>
  <li><code>SCAppDeIegate</code></li>
  <li><code>FLEXManager</code></li>
  <li><code>oJXM</code></li>
  <li><code>fJWs</code></li>
  <li><code>yytp</code></li>
  <li><code>FLManager</code></li>
  <li><code>DecryptScriptAlertView</code></li>
  <li><code>DzAdsManager</code></li>
</ul>

<h3 id="obj-c---method-checks">Obj-C - Method checks</h3>

<p>They also check methods. This happens using <a href="https://developer.apple.com/documentation/objectivec/1418952-objc_getclass">objc_getClass</a> and then <a href="https://developer.apple.com/documentation/objectivec/1418530-class_getinstancemethod">class_getInstanceMethod</a>. If any exists, you get flagged.</p>

<ul>
  <li><code>NSMutableString</code>
    <ul>
      <li><code>a</code></li>
      <li><code>b</code></li>
      <li><code>c</code></li>
    </ul>
  </li>
  <li><code>SCAppDelegate</code>
    <ul>
      <li><code>MZ42SGH98C:</code></li>
    </ul>
  </li>
  <li><code>SCOperaPageViewController</code>
    <ul>
      <li><code>saveButtonPressed</code></li>
    </ul>
  </li>
  <li><code>UIViewController</code>
    <ul>
      <li><code>dzDidTapGalleryButton</code></li>
    </ul>
  </li>
</ul>

<h3 id="obj-c---method-integrity-checks">Obj-C - Method integrity checks</h3>

<p>Next up is Snapchats own methods. For the classes listed below they first call <a href="https://developer.apple.com/documentation/objectivec/1418490-class_copymethodlist">class_copyMethodList</a>. Then for every <a href="https://developer.apple.com/documentation/objectivec/method?language=objc">Method</a> they check if the <code>IMP</code> pointer (address of the function) is within its own <code>__text</code> segment. This is how they detect whether a method has been hooked.</p>

<ul>
  <li><code>SCAppDelegate</code></li>
  <li><code>MainViewController</code></li>
  <li><code>SCChatMainViewController</code></li>
  <li><code>SCChatViewControllerV3</code></li>
  <li><code>SCScreenshotDetector</code></li>
  <li><code>SCBaseMediaOperaPresenter</code></li>
  <li><code>SCOperaPageViewController</code></li>
  <li><code>SCLoginService</code></li>
  <li><code>SCAdsHoldoutExperimentContext</code></li>
  <li><code>SCExperimentManager</code></li>
  <li><code>SCCaptionDefaultTextView</code></li>
  <li><code>SCChatTypingHandler</code></li>
  <li><code>Story</code></li>
  <li><code>SCChatMessageV3</code></li>
  <li><code>SCOperaViewersLayer</code></li>
</ul>

<p>Thanks to <code>dzan</code> for telling me to check the <code>__text</code> segment. :-)</p>

<h3 id="symbol-checks">Symbol checks</h3>

<p>They also check for a couple of symbols using <a href="https://linux.die.net/man/3/dlsym">dlsym</a>. If the result is not null, you get flagged.</p>

<ul>
  <li><code>MSHookMessageEx</code></li>
  <li><code>MSHookFunction</code></li>
  <li><code>_Z17replaced_readlinkPKcPcm</code></li>
  <li><code>hooksArray</code></li>
  <li><code>_OBJC_METACLASS_$__xxx</code></li>
  <li><code>_OBJC_CLASS_$_PHSSaverV2</code></li>
  <li><code>plist</code></li>
  <li><code>flexBreakPoint</code></li>
  <li><code>convert_coordinates_from_device_to_interface</code></li>
  <li><code>OBJC_METACLASS_$_DzSnapHelper</code></li>
  <li><code>ChKey2</code></li>
</ul>

<h3 id="symbol-hook-checks">Symbol hook checks</h3>

<p>A few symbols are resolved using <a href="https://linux.die.net/man/3/dlsym">dlsym</a> to check whether they have been hooked. They first resolve <code>dlsym</code> using <code>dlsym</code>.. yeah.. That result gets used for the <code>dlsym</code> of the symbols below. For every address returned, the first 4 bytes are checked for common hook related instructions.</p>

<ul>
  <li><code>dlsym</code></li>
  <li><code>objc_getClass</code></li>
  <li><code>class_getInstanceMethod</code></li>
  <li><code>sel_registerName</code></li>
  <li><code>class_copyMethodList</code></li>
  <li><code>_dyld_image_count</code></li>
  <li><code>_dyld_get_image_header</code></li>
  <li><code>dladdr</code></li>
</ul>

<h3 id="environment-variables">Environment variables</h3>

<p>I need to be honest, this is a very annoying way how they check for injection because it is annoying to fix. Instead of using <a href="http://man7.org/linux/man-pages/man3/getenv.3.html">getenv</a> they use the <a href="http://sourceware.org/git/?p=glibc.git;a=blob;f=posix/environ.c">environ</a> variable. Since it is a variable, you can not “hook” it.</p>

<p>At least the following variables are detected.</p>

<ul>
  <li><code>DYLD_INSERT_LIBRARIES=/usr/lib/TweakInject.dylib</code></li>
  <li><code>_MSSafeMode=0</code></li>
</ul>

<h3 id="sandbox-check">Sandbox check</h3>

<p>Probably not an issue for anyone.</p>

<p><img src="https://aeonlucid.com/images/snapchat/ios_sandbox.png" alt="iOS sandbox">
</p>

<h3 id="fingerprinting">Fingerprinting</h3>

<p>Not much detection done here but still relevant, using <code>sys_sysctl(202)</code> they request at least the following properties.</p>

<ul>
  <li><code>kern.version</code></li>
  <li><code>kern.osversion</code></li>
  <li><code>kern.proc.pid.&lt;PID&gt;</code></li>
  <li><code>hw.machine</code></li>
</ul>

<h3 id="other">Other</h3>

<p>The syscall <code>sys_proc_info(33)</code> is also called a couple of times, which could reveal stuff that is ptracing the process. They also use <code>sys_open(5)</code>, <a href="http://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a>, <code>sys_close(6)</code> and <code>sys_lstat64(340)</code> on the <code>Snapchat</code> binary. Probably to check for modifications or generating a checksum.</p>

<h2 id="how-all-this-stuff-was-found">How all this stuff was found</h2>

<p>A lot of the work was done using a small iOS emulator build on top of <a href="https://github.com/unicorn-engine/unicorn">Unicorn</a>. Using an emulator you can see everything they do. Building this was also teached me a lot about the CoreFoundation library of iOS.</p>

<p><img src="https://aeonlucid.com/images/snapchat/ios_emulator.png" alt="iOS emulator">
</p>

<p>Later I implemented a counter for all of my discoveries in a tweak called <a href="https://github.com/AeonLucid/SnapHide">SnapHide</a> while carefully keeping track of how my changes modified the detection flags and slowly getting rid of all of them. You can easily find fixes for checks mentioned in this blog post in the “Detections” directory.</p>

<p>You could alternatively trace the syscalls using any of the methods discussed in the WhoYouGonnaSyscall talk by <a href="https://twitter.com/hexploitable">Hexploitable</a>. Slides of the talk can be found <a href="https://github.com/radareorg/r2con2019/blob/master/talks/WhoYouGonnaSyscall/Hex-r2con2019-WhoYouGonnaSyscall.pdf">here</a>.</p>

<h3 id="a-story-on-how-i-wasted-hours-on-fixing-syscalls">A story on how I wasted hours on fixing syscalls</h3>

<p>Let’s take <code>sys_access(33)</code> as an example. It’s implementation looks like <a href="http://man7.org/linux/man-pages/man2/access.2.html">this</a>. In short, when a file exists and permission is granted, return <code>0</code>. Otherwise return <code>-1</code>. First thing I did was force both of the results in my emulator but I saw no changes happening to the detection flags.</p>

<p>Later when implementing a fix for this in the <a href="https://github.com/AeonLucid/SnapHide">SnapHide</a> tweak, I was unable to have it fail. The arm instructions look like this:</p>

<div><div><pre><code>MOV             X0, X27 ; path
MOV             X1, #0  ; mode
MOV             X16, #0x21
SVC             0x80    ; SYS_access
MOV             X0, #0xFFFFFFFFFFFFFFFF
CSEL            X0, X0, XZR, CS
MOV             X27, X0 ; Use result
</code></pre></div></div>

<p>In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aeonlucid.com/Snapchat-detection-on-iOS/">https://aeonlucid.com/Snapchat-detection-on-iOS/</a></em></p>]]>
            </description>
            <link>https://aeonlucid.com/Snapchat-detection-on-iOS/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757666</guid>
            <pubDate>Tue, 07 Jul 2020 10:35:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ANN support announced in Vespa.ai: Vector and filters and text search at scale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757589">thread link</a>) | @RealJon
<br/>
July 7, 2020 | https://blog.vespa.ai/vespa-product-updates-june-2020/ | <a href="https://web.archive.org/web/*/https://blog.vespa.ai/vespa-product-updates-june-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p>In the <a href="https://blog.vespa.ai/vespa-product-updates-may-2020/">May updates</a>,
we mentioned Improved Slow Node Tolerance, Multi-Threaded Rank Profile Compilation, Reduced Peak Memory at Startup, Feed Performance Improvements and Increased Tensor Performance.</p>

<p>This month, we’re excited to share the following updates:</p>

<h4 id="support-for-approximate-nearest-neighbor-vector-search">Support for Approximate Nearest Neighbor Vector Search</h4>
<p>Vespa now supports approximate nearest neighbor search which can be combined with filters and text search.
By using a <a href="https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/">native implementation of the HNSW algorithm</a>,
Vespa provides state of the art performance on vector search:
Typical single digit millisecond response time, searching hundreds of millions of documents per node,
but also uniquely allows vector query operators to be combined efficiently with filters and text search -
which is usually a requirement for real-world applications such as text search and recommendation.
Vectors can be updated in real time with a sustained write rate of a few thousand vectors per node per second.
Read more in the documentation on <a href="https://docs.vespa.ai/documentation/nearest-neighbor-search.html">nearest neighbor search</a>.</p>

<h4 id="streaming-search-speedup">Streaming Search Speedup</h4>
<p>Streaming Search is a feature unique to Vespa.
It is optimized for use cases like personal search and e-mail search -
but is also useful in high-write applications querying a fraction of the total data set.
With <a href="https://github.com/vespa-engine/vespa/pull/13508">#13508</a>,
read throughput from storage increased up to 5x due to better parallelism.</p>

<h4 id="rank-features">Rank Features</h4>
<ul>
  <li>The (Native)fieldMatch rank features are optimized to use less CPU query time, improving query latency for
<a href="https://docs.vespa.ai/documentation/text-matching-ranking.html#ranking">Text Matching and Ranking</a>.</li>
  <li>The new globalSequence rank feature is an inexpensive global ordering of documents in a system with stable system state.
For a system where node indexes change, this is inaccurate.
See <a href="https://docs.vespa.ai/documentation/reference/rank-features.html#globalSequence">globalSequence documentation</a> for alternatives.</li>
</ul>

<h4 id="gke-sample-application">GKE Sample Application</h4>
<p>Thank you to <a href="https://github.com/griseau">Thomas Griseau</a> for contributing a new sample application
for Vespa on <a href="https://cloud.google.com/kubernetes-engine">GKE</a>,
which is a great way to start using Vespa on Kubernetes.</p>

<hr>
<p>About Vespa: Largely developed by Yahoo engineers,
<a href="https://github.com/vespa-engine/vespa">Vespa</a> is an open source big data processing and serving engine.
It’s in use by many products, such as Yahoo News, Yahoo Sports, Yahoo Finance, and the Verizon Media Ad Platform.
Thanks to feedback and contributions from the community, Vespa continues to grow.</p>

<p>We welcome your contributions and feedback (<a href="https://twitter.com/vespaengine">tweet</a>
or <a href="mailto:info@vespa.ai">email</a>) about any of these new features or future improvements you’d like to request.</p>

<p>Subscribe to the <a href="https://vespa.ai/cloud/mailing-list.html">mailing list</a> for more frequent updates!</p>

            </div></div>]]>
            </description>
            <link>https://blog.vespa.ai/vespa-product-updates-june-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757589</guid>
            <pubDate>Tue, 07 Jul 2020 10:23:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Learnt From Reviewing 22 CVs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757585">thread link</a>) | @bryanrasmussen
<br/>
July 7, 2020 | https://youknowfordevs.com/2020/07/04/what-i-learnt-from-reviewing-22-cvs.html | <a href="https://web.archive.org/web/*/https://youknowfordevs.com/2020/07/04/what-i-learnt-from-reviewing-22-cvs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://youknowfordevs.com/2020/07/04/what-i-learnt-from-reviewing-22-cvs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757585</guid>
            <pubDate>Tue, 07 Jul 2020 10:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Spectrum ROM Disassembly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757449">thread link</a>) | @MindGods
<br/>
July 7, 2020 | https://speccy.xyz/rom/ | <a href="https://web.archive.org/web/*/https://speccy.xyz/rom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://speccy.xyz/rom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757449</guid>
            <pubDate>Tue, 07 Jul 2020 10:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Panic Better, fewer, syntax errors for LR parsers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757356">thread link</a>) | @fanf2
<br/>
July 7, 2020 | https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/ | <a href="https://web.archive.org/web/*/https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

<p><strong>Abstract</strong>  
<span>Syntax errors are generally easy to fix for humans, but not for parsers in general nor LR parsers in</span>
<span>particular. Traditional ‘panic mode’ error recovery, though easy to implement and applicable to</span>
<span>any grammar, often leads to a cascading chain of errors that drown out the original. More</span>
<span>advanced error recovery techniques suffer less from this problem but have seen little practical use</span>
<span>because their typical performance was seen as poor, their worst case unbounded, and the</span>
<span>repairs they reported arbitrary. In this paper we introduce the </span><span>CPCT</span><span>+</span>  <span>algorithm, and an</span>
<span>implementation of that algorithm, that address these issues. First, </span><span>CPCT</span><span>+</span> <span>reports the complete set of</span>
<span>minimum cost repair sequences for a given location, allowing programmers to select the one that</span>
<span>best fits their intention. Second, on a corpus of 200,000 real-world syntactically invalid Java</span>
<span>programs, </span><span>CPCT</span><span>+</span>  <span>is able to repair 98.37%</span><span>±</span><span>0.017% </span><span>of files within a timeout of 0.5s. Finally,</span>
<span>CPCT</span><span>+</span> <span>uses the complete set of minimum cost repair sequences to reduce the cascading error</span>
<span>problem, where incorrect error recovery causes further spurious syntax errors to be identified.</span>
<span>Across the test corpus, </span><span>CPCT</span><span>+</span> <span>reports 435,812</span><span>±</span><span>473 </span><span>error locations to the user, reducing the</span>
<span>cascading error problem substantially relative to the 981,628</span><span>±</span><span>0 </span><span>error locations reported by panic</span>
<span>mode.</span>
</p>

<h3><span>1</span> <a id="x1-10001"></a>Introduction</h3>
<!--l. 131--><p>Programming is a humbling job which requires acknowledging that we will make untold errors in
our quest to perfect a program. Most troubling are semantic errors, where we intended the
program to do one thing, but it does another. Less troubling, but often no less irritating, are
syntax errors, which are generally minor deviances from the exacting syntax required by a
compiler. So common are syntax errors that parsers in modern compilers are designed to cope
with us making several: rather than stop on the first syntax error, they attempt to
<span>recover </span>from it. This allows them to report, and us to fix, all our syntax errors in one
go.
</p><!--l. 141--><p>When error recovery works well, it is a useful productivity gain. Unfortunately, most current
error recovery approaches are simplistic. The most common grammar-neutral approach to error
recovery are those algorithms described as ‘panic mode’ (e.g.&nbsp;[<a href="#Xholub90compilerdesign">13</a>, p.&nbsp;348]) which skip input until
the parser finds something it is able to parse. A more grammar-specific variation of this
idea is to skip input until a pre-determined synchronisation token (e.g. ‘;’ in Java) is
reached&nbsp;[<a href="#Xdegano95comparison">8</a> , p.&nbsp;3], or to try inserting a single synchronisation token. Such strategies are
often unsuccessful, leading to a cascade of spurious syntax errors (see Figure&nbsp;<a href="#x1-1018r1">1<!--tex4ht:ref: fig:javaerror --></a> for an
example). Programmers quickly learn that only the location of the first error in a file – not
the reported repair, nor the location of subsequent errors – can be relied upon to be
accurate.
</p>
                                                                            
                                                                            
<hr><div>
                                                                            
                                                                            
                                                                            
                                                                            
<div><div><table id="TBL-1"><colgroup id="TBL-1-1g"><col id="TBL-1-1"><col id="TBL-1-2"></colgroup><tbody><tr id="TBL-1-1-"><td id="TBL-1-1-1"> <!--l. 159--><!--l. 160--><p><span>(a)</span> </p> </td><td id="TBL-1-1-2"> <div><!--l. 166-->
<p><span><a id="x1-1002r1"></a></span><span>class</span><span>&nbsp;</span><span>C</span><span>&nbsp;</span><span>{</span><span>&nbsp;</span><br><span><a id="x1-1003r2"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>int</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>y</span><span>;</span><span>&nbsp;</span><br><span><a id="x1-1004r3"></a></span><span>}</span>
</p>
  </div>                         </td>
</tr><tr id="TBL-1-2-"><td id="TBL-1-2-1"> <!--l. 173--><!--l. 175--><p><span>(c)</span> </p></td><td id="TBL-1-2-2"> <div><!--l. 181-->
<p><span><a id="x1-1006r1"></a></span><span>Parsing</span><span>&nbsp;</span><span>error</span><span>&nbsp;</span><span>at</span><span>&nbsp;</span><span>line</span><span>&nbsp;</span><span>2</span><span>&nbsp;</span><span>col</span><span>&nbsp;</span><span>9.</span><span>&nbsp;</span><span>Repair</span><span>&nbsp;</span><br><span>
<a id="x1-1007r2"></a></span><span>sequences</span><span>&nbsp;</span><span>found</span><span>:</span><span>&nbsp;</span><br><span><a id="x1-1008r3"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>1:</span><span>&nbsp;</span><span>Delete</span><span>&nbsp;</span><span>y</span><span>&nbsp;</span><br><span>
<a id="x1-1009r4"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>2:</span><span>&nbsp;</span><span>Insert</span><span>&nbsp;</span><span>,</span><span>&nbsp;</span><br><span><a id="x1-1010r5"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>3:</span><span>&nbsp;</span><span>Insert</span><span>&nbsp;</span><span>=</span>
</p>
  </div>                         </td>
</tr></tbody></table></div>
</div><div><div><table id="TBL-2"><colgroup id="TBL-2-1g"><col id="TBL-2-1"><col id="TBL-2-2"></colgroup><tbody><tr id="TBL-2-1-"><td id="TBL-2-1-1"> <!--l. 195--><!--l. 197--><p><span>(b)</span> </p> </td><td id="TBL-2-1-2"> <div><!--l. 203-->
<p><span><a id="x1-1012r1"></a></span><span>C</span><span>.</span><span>java</span><span>:2:</span><span>&nbsp;</span><span>error</span><span>:</span><span>&nbsp;</span><span>’;’</span><span>&nbsp;</span><span>expected</span><span>&nbsp;</span><br><span>
<a id="x1-1013r2"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>int</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>y</span><span>;</span><span>&nbsp;</span><br><span><a id="x1-1014r3"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>^</span><span>&nbsp;</span><br><span>
<a id="x1-1015r4"></a></span><span>C</span><span>.</span><span>java</span><span>:2:</span><span>&nbsp;</span><span>error</span><span>:</span><span>&nbsp;</span><span>&lt;</span><span>identifier</span><span>&gt;</span><span>&nbsp;</span><span>expected</span><span>&nbsp;</span><br><span>
<a id="x1-1016r5"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>int</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>y</span><span>;</span><span>&nbsp;</span><br><span><a id="x1-1017r6"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>^</span>
</p>
  </div>                           </td>
</tr></tbody></table></div></div><p><span>
<span>Figure</span><span>&nbsp;1:  </span></span><span><span>An example of a simple, common Java syntax error (</span><a href="#x1-1001r1"><span>a</span></a><span>) and the problems traditional</span>
<span>error recovery has in dealing with it. </span><span>javac </span><span>(</span><a href="#x1-1011r2"><span>b</span></a><span>) spots the error when it encounters ‘</span><span>y</span><span>’. Its error</span>
<span>recovery algorithm then repairs the input by inserting a semicolon before ‘</span><span>y</span><span>’ (i.e.</span><span>&nbsp;making the input</span>
<span>equivalent to ‘</span><span>int x; y;</span><span>’). This then causes a spurious parsing error, since ‘</span><span>y</span><span>’ on its own is not</span>
<span>a valid statement. The </span><span>CPCT</span><span>+</span>  <span>error recovery algorithm we introduce in this paper produces the</span>
<span>output shown in (</span><a href="#x1-1005r3"><span>c</span></a><span>): after spotting an error when parsing encounters ‘</span><span>y</span><span>’, it uses the Java grammar</span>
<span>to find the complete  set  of  minimum  cost  repair  sequences  (unlike  previous  approaches  which</span>
<span>non-deterministically find one minimum cost repair sequence). In this case three repair sequences</span>
<span>are reported to the user: one can delete ‘</span><span>y</span><span>’ entirely (‘</span><span>int x;</span><span>’), or insert a comma (‘</span><span>int x, y;</span><span>’), or</span>
<span>insert an equals sign (</span><span>‘int x = y;’</span><span>).</span>
</span></p><!--tex4ht:label?: x1-1018r1 -->
                                                                            
                                                                            
</div><hr>
<!--l. 233--><p>It is possible to hand-craft error recovery algorithms for a specific language. These
generally allow better recovery from errors, but are challenging to create. For example,
the Java error recovery approach in the Eclipse IDE is 5KLoC long, making it only
slightly smaller than a modern version of Berkeley Yacc — a complete parsing system!
Unsurprisingly, few real-world parsers contain effective hand-written error recovery
algorithms.
</p><!--l. 240--><p>Most of us are so used to these trade-offs (cheap generic algorithms and poor recovery
vs.&nbsp;expensive hand-written algorithms and reasonable recovery) that we assume them to be
inevitable. However, there is a long line of work on more advanced generic error recovery
algorithms. Probably the earliest such algorithm is Aho and Peterson&nbsp;[<a href="#Xaho72minimum">1</a>], which, upon
encountering an error, creates on-the-fly an alternative (possibly ambiguous) grammar which
allows the parser to recover. This algorithm has fallen out of favour in programming
language circles, probably because of its implementation complexity and the difficulty of
explaining to users what recovery has been used. A simpler family of algorithms, which
trace their roots to Fischer <span>et al.</span>&nbsp;[<a href="#Xfischer79locally">11</a>], instead try to find a single minimum cost <span>repair</span>
<span>sequence </span>of token insertions and deletions which allow the parser to recover. Algorithms in
this family are much better at recovering from errors than naive approaches and can
communicate the repairs they find in a way that humans can easily replicate. However, such
algorithms have seen little practical use because their typical performance is seen as
poor and their worst case unbounded [<a href="#Xmckenzie95error">17</a>, p.&nbsp;14]. We add a further complaint: such
approaches only report a single repair sequence to users. In general – and especially in
syntactically rich languages – there are multiple reasonable repair sequences for a given
error location, and the algorithm has no way of knowing which best matches the user’s
intentions.
</p><!--l. 261--><p>In this paper we introduce a new error recovery algorithm in the Fischer <span>et al. </span>family, <span>CPCT</span><span>+</span>.
This takes the approach of Corchuelo <span>et al.</span>&nbsp;[<a href="#Xcorchuelo02repairing">5</a>] as a base, corrects it, expands it, and
optimises its implementation. <span>CPCT</span><span>+</span> is simple to implement (under 500 lines of Rust
code), is able to repair nearly all errors in reasonable time, reports the complete set of
minimum cost repair sequences to users, and does so in less time than Corchuelo <span>et</span>
<span>al.</span>.
</p><!--l. 269--><p>We validate <span>CPCT</span><span>+</span> on a corpus of 200,000 real, syntactically incorrect, Java programs
(Section&nbsp;<a href="#x1-140006">6<!--tex4ht:ref: experiment --></a>). <span>CPCT</span><span>+</span> is able to recover 98.37%<span>±</span><span>0.017% </span>of files within a 0.5s timeout and does so
while reporting fewer than half the error locations as a traditional panic mode algorithm: in other
words, <span>CPCT</span><span>+</span> substantially reduces the cascading error problem. We also show – for, as far as we
know, the first time – that advanced error recovery can be naturally added to a Yacc-esque
system, allowing users to make fine-grained decisions about what to do when error recovery has
been applied to an input (Section&nbsp;<a href="#x1-180007">7<!--tex4ht:ref: sec:api --></a>). We believe that this shows that algorithms such as <span>CPCT</span><span>+</span>
are ready for wider usage, either on their own, or as part of a multi-phase recovery
system.
</p>
<h4><span>1.1</span> <a id="x1-20001.1"></a>Defining the problem</h4>
<!--l. 285--><p>Formally speaking, we first test the following hypothesis:
</p><!--l. 287--><dl><dt>
<span>H1</span></dt><dd>The complete set of minimum cost repair sequences can be found in acceptable time.</dd></dl>
                                                                            
                                                                            
<!--l. 292--><p>The only work we are aware of with a similar concept of ‘acceptable time’ is&nbsp;[<a href="#XdeJonge12natural">6</a>], who define it
as the total time spent in error recovery per file, with a threshold of 1s. We use that
definition with one change: Since many compilers are able to fully execute in less than 1s,
we felt that a tighter threshold is more appropriate: we use 0.5s since we think that
even the most demanding users will tolerate such a delay. We strongly validate this
hypothesis.
</p><!--l. 300--><p>The complete set of minimum cost repair sequences makes it more likely that the programmer
will see a repair sequence that matches their original intention (see Figure&nbsp;<a href="#x1-1018r1">1<!--tex4ht:ref: fig:javaerror --></a> for an example;
Appendix&nbsp;<a href="#x1-28000A">A<!--tex4ht:ref: app:examples --></a> contains further examples in Java, Lua, and PHP). It also opens up a new
opportunity. Previous error recovery algorithms find a single repair sequence, apply that to the
input, and then continue parsing. While that repair sequence may have been a reasonable local
choice, it may cause cascading errors later. Since we have the complete set of minimum
cost repair sequences available, we can select from that set a repair sequence which
causes fewer cascading errors. We thus rank repair sequences by how far they allow
parsing to continue successfully (up to a threshold — parsing the whole file would, in
general, be too costly), and choose from the subset that gets furthest (note that the
time required to do this is included in the 0.5s timeout). We thus also test a second
hypothesis:
</p><!--l. 315--><dl><dt>
<span>H2</span></dt><dd>Ranking the complete set of minimum cost repair sequences by how far they allow
parsing to continue locally reduces the global cascading error problem.</dd></dl>
<!--l. 321--><p>We also strongly validate this hypothesis. We do this by comparing ‘normal’ <span>CPCT</span><span>+</span> with a
simple variant <span>CPCT</span><span>+</span><span>rev</span> which reverses the ranking process, always selecting from amongst the
worst …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/">https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/</a></em></p>]]>
            </description>
            <link>https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757356</guid>
            <pubDate>Tue, 07 Jul 2020 09:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Symbolic execution with SymCC: Don't interpret, compile!]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757353">thread link</a>) | @DyslexicAtheist
<br/>
July 7, 2020 | http://www.s3.eurecom.fr/tools/symbolic_execution/symcc.html | <a href="https://web.archive.org/web/*/http://www.s3.eurecom.fr/tools/symbolic_execution/symcc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <blockquote>
    <p>
      Symbolic execution with SymCC: Don't interpret, compile!
    </p>
    
    <em>Proceedings of the 29th USENIX Security Symposium (USENIX Security 20),
    Boston, MA, USA</em>
    
    
    <p>
      A major impediment to practical symbolic execution is speed, especially
      when compared to near-native speed solutions like fuzz testing. We propose
      a compilation-based approach to symbolic execution that performs better
      than state-of-the-art implementations by orders of magnitude. We present
      SymCC, an LLVM-based C and C++ compiler that builds concolic execution
      right into the binary. It can be used by software developers as a drop-in
      replacement for <tt>clang</tt> and <tt>clang++</tt>, and we show how to
      add support for other languages with little effort. In comparison with
      KLEE, SymCC is faster by up to three orders of magnitude and an average
      factor of 12. It also outperforms QSYM, a system that recently showed
      great performance improvements over other implementations, by up to two
      orders of magnitude and an average factor of 10. Using it on real-world
      software, we found that our approach consistently achieves higher
      coverage, and we discovered two vulnerabilities in the heavily tested
      OpenJPEG project, which have been confirmed by the project maintainers and
      assigned CVE identifiers.
    </p>
  </blockquote>

  <h2 id="intro">Introduction</h2>

  <p>
    SymCC is a fast compiler-based symbolic execution engine. On this page, we
    provide SymCC's source code, the raw results of the experiments described in
    the paper, as well as instructions how you can replicate those experiments
    yourself.
  </p>

  <h2>Code</h2>

  <p>
    SymCC is available
    on <a href="https://github.com/eurecom-s3/symcc">GitHub</a>.
  </p>

  <h2>Experiments</h2>

  <p>
    In the paper, we describe two sets of experiments: we first benchmark SymCC
    on the CGC programs, then we run it on real-world software. This section
    describes how to replicate our experiments, and provides links to our
    results.
  </p>

  <ol>
    <li>
      <p>
        CGC experiments (our results
        for <a href="http://www.s3.eurecom.fr/~seba/symcc_cgc_pure_time.csv">pure
        execution
        time</a>, <a href="http://www.s3.eurecom.fr/~seba/symcc_cgc_concolic_time.csv">concolic
        execution time</a>,
        and <a href="http://www.s3.eurecom.fr/~seba/symcc_cgc_concolic_coverage.tar.gz">coverage</a>)
      </p>

      <p>
        We used the <a href="https://github.com/trailofbits/cb-multios">Linux
          port</a> of the CGC programs by Trail of Bits. SymCC needs to be built
        with support for 32-bit compilation (see <tt>docs/32-bit.txt</tt>;
        this is not part of the Dockerfile because it would double the build
        time of the container while providing value to just a few users). Then
        you can simply export
        <tt>CC=/path/to/symcc</tt>, <tt>CXX=/path/to/sym++</tt> and <tt>SYMCC_NO_SYMBOLIC_INPUT=1</tt>, and
        build the CGC programs as usual (i.e., by invoking their build.sh script).
      </p>

      <p>
        Run the programs on the raw PoV inputs
        with <tt>SYMCC_NO_SYMBOLIC_INPUT=1</tt> to measure pure execution
        time, and unset the environment variable for symbolic execution. To
        assess coverage, we ran <tt>afl-showmap</tt> with the
        AFL-instrumented CGC programs on each generated input and accumulated
        the resulting coverage maps per program, resulting in a set of covered
        map entries for each CGC program. The sizes of those sets can then be
        fed to the scoring formula presented in the paper.
      </p>

      <p>
        For KLEE and QSYM, we used the setup
        described <a href="http://www.s3.eurecom.fr/tools/symbolic_execution/ir_study.html">here</a> but with the regular 32-bit
        binaries built by cb-multios.
      </p>
    </li>

    <li>
      <p>Real-world software</p>

      <p>
        The analysis of real-world software always follows the same procedure.
        Assuming you have exported <tt>CC=symcc</tt>, <tt>CXX=sym++</tt>
        and <tt>SYMCC_NO_SYMBOLIC_INPUT=1</tt>, first download the code,
        then build it using its own build system, finally
        unset <tt>SYMCC_NO_SYMBOLIC_INPUT</tt> and analyze the program in
        concert with AFL (which requires building a second time for AFL,
        see <tt>docs/Fuzzing.txt</tt>). We used AFL 2.56b and built the
        targets with <tt>AFL_USE_ASAN=1</tt>. Note that the fuzzing helper
        is already installed in the Docker container.
      </p>

      <ul>
        <li>
          <a href="https://github.com/uclouvain/openjpeg.git">OpenJPEG</a>
          (<a href="http://www.s3.eurecom.fr/~seba/symcc_afl_openjpeg.tar.gz">our
          results</a>): we used revision <tt>1f1e9682</tt>, built with CMake as
          described in the project's <tt>INSTALL.md</tt>
          (adding <tt>-DBUILD_THIRDPARTY=ON</tt> to make sure that third-party
          libraries are compiled with SymCC as well), and
          analyzed <tt>bin/opj_decompress -i @@ -o /tmp/image.pgm</tt>; the
          corpus consisted of test
          files <a href="https://github.com/uclouvain/openjpeg-data/blob/master/input/conformance/file1.jp2">file1.jp2</a>
          and <a href="https://github.com/uclouvain/openjpeg-data/blob/master/input/conformance/file8.jp2">file8.jp2</a>.
        </li>

        <li>
          <a href="https://github.com/libarchive/libarchive.git">libarchive</a>
          (<a href="http://www.s3.eurecom.fr/~seba/symcc_afl_libarchive.tar.gz">our
          results</a>): we used revision <tt>9ebb2484</tt>, built with CMake as
          described in the poject's <tt>INSTALL</tt> (but
          adding <tt>-DCMAKE_BUILD_TYPE=Release</tt>), and
          analyzed <tt>bin/bsdtar tf @@</tt>; the corpus consisted of just a
          single dummy file containing the character "A".
        </li>

        <li>
          tcpdump
          (<a href="http://www.s3.eurecom.fr/~seba/symcc_afl_tcpdump.tar.gz">our
          results</a>): we built both tcpdump and libpcap; in order to make the
          former find the latter, just place the source directories next to each
          other in the same folder. We used revision <tt>d615abec</tt>
          of <a href="https://github.com/the-tcpdump-group/libpcap.git">libpcap</a>
          and revision <tt>d57927e1</tt>
          of <a href="https://github.com/the-tcpdump-group/tcpdump.git">tcpdump</a>.
          We built first libpcap and then tcpdump with <tt>./configure
          &amp;&amp; make</tt>, and analyzed
          <tt>tcpdump/tcpdump -e -r @@</tt>; the corpus consisted of just a single dummy
          file containing the character "A".</li>
      </ul>

      <p>
        All experiments used one AFL master process, one secondary AFL process,
        and one SymCC process. We let them run for 24 hours and repeated each of
        them 30 times to create the graphs in the paper; AFL map density was
        extracted from the secondary AFL process' <tt>plot_data</tt> file,
        column <tt>map_size</tt>.
      </p>

      <p>
        The QSYM experiments used an analogous setup, replacing SymCC with QSYM
        and running it with AFL according to the QSYM
        authors' <a href="https://github.com/sslab-gatech/qsym#run-hybrid-fuzzing-with-afl">instructions</a>.
      </p>
    </li>
  </ol>

  <h2>Acknowledgements</h2>

  <p>
    This work was supported by the DAPCODS/IOTics ANR 2016 project (ANR-16-CE25-0015).
  </p>

  <h2>Contact</h2>

  <p>
    Feel free to <a href="http://www.s3.eurecom.fr/~seba/">reach out</a> to us
    if anything is unclear or if you need more information.
  </p>
</div></div>]]>
            </description>
            <link>http://www.s3.eurecom.fr/tools/symbolic_execution/symcc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757353</guid>
            <pubDate>Tue, 07 Jul 2020 09:42:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Techniques I use to improve my team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757225">thread link</a>) | @cauliflower99
<br/>
July 7, 2020 | http://www.dcaulfield.com/team-improvement-techniques/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/team-improvement-techniques/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15632">
<small>
    <a href="http://www.dcaulfield.com/2020/07/06/">July 6, 2020</a></small>
    			<small>
				<a href="http://www.dcaulfield.com/author/admin/"></a></small>
		
<p>In the last couple of months since Ireland announced the lockdown, our team has been performing at a high pace and have become self-organised to a large extent. As a team lead, this has allowed me the privilege of stepping back to look at the broader picture of how our team works individually and, more importantly, together. Through some exercises, I have identified some  methods to gather improvement ideas that can be applied to any team. </p>



<p>Anyone who has been a part of a high functioning team understands that continuous improvement is not optional. In order to perform better and to keep performing, the team must identify their weaknesses and plan to strengthen or mitigate those weaknesses. These improvements remedy stress points in the team, technical debt, repetitive tasks and so forth. The mindset of continuous growth is one that must be worked on and nurtured over time. Your team is not a fine wine – it will not improve if left alone in the corner. It will go sour.</p>



<p>It is one thing to be told to improve something. But very often, being told to improve something does not necessarily benefit you or your team.&nbsp;For example, if my manager comes to me and tells me my communication is poor and he wants bi-weekly emails from now on from my team’s status, all he has done is improve one of his problems, not mine. Improvements must come from within the team, and they must be gathered and executed on regularly. So the question is – how do we gather improvements that are worthwhile and specific enough to solve our problems, not someone else’s?</p>



<h2>80/20 Analysis</h2>



<p>The Pareto Principle, most commonly known as the 80/20 rule, states that about 80% of the effects come from 20% of the causes. In layman’s terms, most of the good things your team is known for doing likely comes from a small subset of your total work.</p>



<p>In my case, my team is known for our expertise in the upgrading of our product. How much of our work is related to this each week? I’d estimate less than 10%.</p>



<p>S<em>ide note</em>: This wasn’t always the case. When we first formed as a team, we spent about 90% of our time on this work. </p>



<p>Over time our mindset of continuous improvement led us to automating away most of our problems. Here is how you can utilize the 80/20 rule to find pressure points to improve. I do this regularly by myself, and occasionally with my team.</p>



<h3>Create a chart.</h3>



<p>Drawing on a piece of paper or whiteboard produces far more ideas than typing on a screen. So create a chart!</p>



<h4>What is going poorly?</h4>



<p>Always start with the bad. What makes you stressed on a Monday? Why does your team constantly get called for customer escalations on a Sunday? What makes you cry at night? (If you’re crying at night you really need this). </p>



<p>Copy the following table onto a piece of paper and fill it out now with any ideas you have.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Pain</strong></th><th><strong>Action to Remedy</strong></th></tr></thead><tbody><tr><td>Monday morning team presentation to management.</td><td>Stressful if I’m not prepped.</td><td>Give a practice run to my team on Friday.</td></tr></tbody></table></figure>



<h4>What is going well?</h4>



<p>This is less effective than analyzing what is poor in the team. You should prioritise fixing the bad over improving the good. There is no point in improving what your team is already good at if there are still issues that stress them. </p>



<p>Ask yourself – what are your team doing well? What do you need to keep doing well? What would happen if you improved these items?</p>



<p>Again, copy the following table onto a piece of paper and fill it out.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Reward</strong></th><th><strong>Improvement reward</strong></th><th><strong>Action to improve</strong></th></tr></thead><tbody><tr><td>Quick bug turnaround.</td><td>No weekend work.</td><td>Become the team with the lowest bug turnaround time.</td><td>Make incoming bugs a priority over stories.</td></tr></tbody></table></figure>



<p>You see the action columns? Take those, discuss with the team whether they agree on the actions required, and put them clearly for all to see everyday. You could create a task in your backlog that gets seen everyday on your sprint board, or print them and place them in your team’s area.</p>



<h2>Preventative Actions</h2>



<p>Identifying Preventative Actions is something that I have recently come across. Each team in my project go through this process every 3 weeks (every sprint). Here’s how it works. </p>



<p>A high priority bug has come into your team. You have spent all weekend pouring over it with your team, and finally came up with a solution late Sunday night, allowing your customer to continue their business as usual. Before you close the bug, there are a couple of things you need to consider and you <strong>must</strong> get answers to them. Otherwise, there will be another weekend in the future that will interrupt your team.</p>



<h3>Why did this bug occur?</h3>



<ul><li>We received a bad requirement specification from our business analysts.</li><li>We missed a corner case in our testware.</li><li>There were too many manual steps in the documentation which led to human error.</li><li>We missed a critical part of our study when planning the requirement.</li></ul>



<h3>What correction did you apply?</h3>



<ul><li>We built a patch fix and sent it to the customer.</li><li>We clarified with the customer that the particular use case reported is not supported yet.</li></ul>



<h3>How will you prevent this type of issue from occurring in the future?</h3>



<ul><li>We will call a 1 hour meeting with our business analyst each week to plan and clarify the feature request.</li><li>We will build a new pipeline that will test our customer’s use case each night.</li><li>We will automate steps x,y and z in our documentation so that human error is reduced.</li></ul>



<p>In my team’s case, for each bug we have the following grid which we fill out.</p>



<figure><table><thead><tr><th><strong>Root Cause</strong></th><th><strong>Correction Applied</strong></th><th><strong>Preventative Action</strong></th></tr></thead><tbody><tr><td>A test case to click on the ‘About’ page in Firefox was missing from our GUI test suite.</td><td>Added this test case to the GUI suite.</td><td>Review GUI test cases as part of a feature sign-off in the future.</td></tr></tbody></table></figure>



<h2>Retrospective</h2>



<p>If your team uses the scrum framework for their work, then you will be very familiar with the retrospective. However, you do not need to work in a scrum environment to have a team retrospective. </p>



<p>Team retrospectives, if taken regularly, can be a valuable tool in the team’s work week and is an opportunity for the team to come together and discuss the good and bad things that have happened in the past few weeks. </p>



<p>A retro should be scheduled on a regular basis, and you as the team lead must lead the meeting. Make sure that everyone from the team is present for the retro, and ensure that everyone is taking part and answering the questions.</p>



<h3>What was good that you need to keep doing?</h3>



<ul><li>We closed out 100% of our stories for the sprint.</li><li>There was good communication with our management.</li><li>We trialed pair programming this sprint – we have seen excellent results and should continue to do this.</li></ul>



<h3>What was bad?</h3>



<ul><li>We had poor communication within the team.<ul><li><em>Improvement</em>: We will trial pair programming for a sprint.</li></ul></li><li>The QA team raised tickets with very little detail resulting in a few days of delay in closing.<ul><li><em>Improvement</em>: Create a template that you would find helpful and send it to the QA team lead. Request that they copy this template and fill it out for all future tickets.</li></ul></li><li>We allowed untested code into the production software.<ul><li><em>Improvement</em>: Revise the +2 code review criteria with the team.</li></ul></li></ul>



<p>The most important part of the retro is to make sure that improvements or solutions are attached to each ‘bad’ item that is discussed.<br>At the end of the retro, prioritise the top one or two improvements, and take note of them for the upcoming sprint to execute.</p>



<h2>Improvement Backlog</h2>



<p>To become a top performing team, each individual must be comfortable with raising and discussing improvements as part of the team’s responsibilities. A team that does not have improvement ideas is a team that is not interested in improving which will lead to stagnation and a low performing team.</p>



<p>An improvement backlog is a list of ideas maintained and prioritised by the team. The list can be physical, like stickies on a whiteboard, or digital, like part of your jira backlog. </p>



<p>For example, my team created a Jira sprint and named it ‘Improvement Ideas’. We have list about 50 improvement ideas, most of which are one-liners and some of which have been discussed with details and acceptance criteria attached.</p>



<p>Each sprint planning, we prioritise this list and take the items we feel are most valuable to us. We have a couple of ad-hoc rules for this backlog.</p>



<ul><li>Any ideas that come up in meetings are inserted as a ‘one-liners’ in this backlog.</li><li>The list is regularly prioritised each sprint.</li><li>Each idea is explained by the team member who originally raised it.</li><li>We take 10-20% of our sprint capacity for improvements.</li></ul>



<p>Keeping this backlog up to date and prioritised will ensure that your team has consistent tasks to work on that primarily help the team.</p>



<h2>Stakeholder Feedback</h2>



<p>Working in a team can often be like working in a bubble. It is tempting to fall into confirmation bias. The most valuable improvements you can get for your product will come from your customers and stakeholders. </p>



<p>Leading the team does not only include leading the people on the team. If your team are known for building the wrong thing, or if their customers are not satisfied with their part of the product, then you as the team lead have ultimately failed.</p>



<p>When it comes to feedback, there is nothing more valuable than your own customers’ feedback. Your customers drive your product backlog. If you are in a large company, you may not have direct contact with your customers. In big companies, customers are often separated by layers of business analysts and management. This is not ideal, but it is something you can work around. </p>



<p>All you need is a small list of stakeholders that consistently use your product area to gain feedback from them. Talk to your managers about the customer interface and who could give feedback. In my case, we were 6 months without any contact with stakeholders that could give us valuable feedback. Eventually we were able to make friends with two guys who act as an interface to one of our company’s top …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dcaulfield.com/team-improvement-techniques/">http://www.dcaulfield.com/team-improvement-techniques/</a></em></p>]]>
            </description>
            <link>http://www.dcaulfield.com/team-improvement-techniques/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757225</guid>
            <pubDate>Tue, 07 Jul 2020 09:20:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to reduce subscriber churn? 5 helpful tips to try]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757096">thread link</a>) | @cquijano
<br/>
July 7, 2020 | https://www.firmhouse.com/blog/how-to-reduce-subscriber-churn-5-helpful-tips-to-try | <a href="https://web.archive.org/web/*/https://www.firmhouse.com/blog/how-to-reduce-subscriber-churn-5-helpful-tips-to-try">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Reading time: 4 minutes</p><p><strong>Retain subscribers, increase revenue, and scale your Product-as-a-Service (PaaS) business.&nbsp;</strong><br></p><p>Increasing and retaining your subscriber base is fundamental to your PaaS subscription business; after all, they provide you the growth you need to scale your PaaS business. Payment issues are one of the leading causes for involuntary churn.<br></p><p>Yet, the number one reason for losing customers in the checkout process is due to a failure in the card network infrastructure. Cards weren't designed for recurring payments; typically, credit cards expire every three years, but they can also get canceled, lost, stolen, or hit card limits.&nbsp;<br></p><p><a href="https://www.firmhouse.com/blog/7-marketing-tips-to-grow-your-product-as-a-service-paas-subscription-business">Keeping existing subscribers </a>on board is crucial to increase your customer average lifetime value (CLTV). However, even if you try hard to offer a seamless experience, you can still lose customers due to payment issues or because your customer card details it's out of date.<br></p><p><strong><em>Preventing failing payments allows you to decrease churn and increase subscribers' retention.&nbsp;</em></strong><br></p><p>Within a subscription business, customer churn is the number of customers who stop paying for their subscription or unsubscribe during a given period. Addressing your customer churn challenges becomes more and more critical for your subscription business to succeed.<br></p><p><strong>There are two types of churn: voluntary and involuntary churn.&nbsp;</strong><br></p><p>In a voluntary churn, the customer decides to consciously unsubscribe when they feel they aren't getting the full value of your product or can't continue with the subscription. Voluntary churn is often based on customer experience rather than the operational aspects, and regardless of what you do, they might be already convinced to unsubscribe.&nbsp;<br></p><p>Now, involuntary churn is not so related to your customer experience. Rather is more related to operational issues that could happen due to payment issues, expired credit cards, insufficient funds or card number has been updated.&nbsp;<br></p><p>Involuntary churn isn't limited to the least engaged customers; it affects all of your subscribers, even the happiest customers (remember they can be as forgetful as your lowest-value customers). By tackling involuntary churn, you can prevent customers from leaving while continuing offering a seamless subscriber experience.<br></p><p>Involuntary churn harms your customer lifetime value (CLTV). Let's say your monthly recurring revenue (MRR) is $60, and the expected contract time is 18 months. If you have 100 customers and half of them are lost due to involuntary churn, that's 50% of subscribers leaving you, which is not useful when you are looking to optimize your customer lifetime value.&nbsp;<br></p><p>Involuntary churn is somehow easier to prevent than voluntary churn. You can avoid these involuntary challenges without changing your proposition or business model. Involuntary and voluntary churn can be prevented by taking the right measurements and having the proper process at hand.&nbsp;<br></p><p><strong>Implement solutions to reduce churn and prevent customers from leaving you again in the future with these 5 strategies:&nbsp;</strong><br></p><p><strong>1. Understand the root cause</strong></p><p>Billing systems or credit cards don't work perfectly. Understand what happens when a payment fails; try to get the why does this keep happening. You can use data for this or ask your customers directly.<br></p><p>If you still have some payment issues this could be due to:&nbsp;<br></p><ul role="list"><li>Insufficient funds from your customer</li><li>Customer bank account was closed</li><li>Credits over the limit to make payments</li><li>The card has expired or is no longer valid&nbsp;</li><li>Other payments issues (like temporary down-time)<br></li></ul><p>These are crucial questions to determine how to prevent failed payments and to retarget customers that are about to leave. If you set your payment schedule around your customer's lifestyle, you can ensure that the funds are ready and available for the payment.&nbsp;<br></p><p><strong>2. Ensure member data is up to date</strong></p><p>Expired cards are the most significant contributors to involuntary churn. Most credit cards expire after three years, meaning customers need to update their card number or expiration date (probably during the same time they are your subscribers). The longer the <a href="https://www.firmhouse.com/blog/the-product-as-a-service-business-case-calculator">lifetime value (LTV)</a>, the more involuntary churn there will be.<br></p><p><strong><em>Run automated updates, so customer data stays up to date.</em></strong> Communicate with your customers if any changes are done to the billing systems.&nbsp;<br></p><p>Also, keep customers up to date if there's any change in your pricing or logistics. Besides, understand if they are having problems receiving the products, or not enough customer experience and address these issues with a seamless payment process with a proactive customer-oriented billing and payment service.<br></p><p><strong>3. Keep customers that don't want to leave from leaving with a seamless experience</strong><br></p><p><a href="https://www.firmhouse.com/blog/what-is-product-as-a-service-paas">Product-as-a-Service (PaaS)</a> subscription services often lack reminders that communicate with their customers about changing their payment options. Friendly reminders are always a great way to include a link that enables customers to update their billing information with an urgent tone.&nbsp;</p><p>Avoid the spam folder. Regularly engage with subscribers, ask them in a non-spammy way what they think about the product, if they are happy or dissatisfied with your product, and why. Make sure to send your emails from return email so customers can get in touch with you if needed. By educating customers about special offers, price increases, and product updates, you stay connected with subscribers and increase your customer experience (CX). Make sure to have constant contact with customers to re-engage with them in the future.&nbsp;<br></p><p><strong>4. Subscriber management&nbsp;</strong><br></p><p>Provide a seamless branded personalized billing and payment experience across all channels—update subscribers' information with a software that can update information more easily. Use a single solution that manages your subscribers through their life cycle, including payment updates and add-ons.&nbsp;&nbsp;<br></p><p>Offer customers flexible and customized payment schedules with constant support. Accept payments through various channels with integration with secure payment gateways that accept multiple currencies and safeguard your customer data.&nbsp;<br></p><p>Subscriber management is also essential once your company starts scaling, and extra support is needed, especially with your customized promotions, customer satisfaction, inventory management, and logistics.&nbsp;<br></p><p><strong>5. Built-in dunning management</strong></p><p>Know when subscribers' credit card expires and take further steps to prevent this from happening. One way to remind your subscribers when their payment method needs to be updated is by sending a series of email (app) messages encouraging customers to update their payment method soon.&nbsp;<br></p><p>Pre-dunning messages come in handy when you don't have another payment system to catch card updates.&nbsp;<br></p><p>Keep in mind that it is crucial to dedicate most of your efforts while they are still actively using your product (considering that it would be harder to capture them once they are gone).&nbsp;<br></p><p>Irregular billing can happen throughout your customer lifecycle, so having subscribers engaged can severely impact your customer subscription status. Prompt users to update their billing information while you make sure to have all the systems in place to prevent involuntary churn. In Firmhouse, we try at least 3 times to collect the payment from the customer. If this is not successful, the customer gets flagged and customer support will take over. Having a well trained customer support team can help you with this.&nbsp;&nbsp;</p><p>‍<br>What to learn how to automate your payment process? You can use a single platform to run your Product-as-a-Service (PaaS) subscription from end-to-end instead of having different systems. <a href="https://www.firmhouse.com/contact">Contact us</a> Firmhouse to get started with your PaaS subscription today.</p></div></div></div>]]>
            </description>
            <link>https://www.firmhouse.com/blog/how-to-reduce-subscriber-churn-5-helpful-tips-to-try</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757096</guid>
            <pubDate>Tue, 07 Jul 2020 08:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stack the bricks with “OK Moments” rather than bet on “Aha moments”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757087">thread link</a>) | @ravivyas
<br/>
July 7, 2020 | https://ravivyas.com/2020/07/07/stack-the-bricks-with-ok-moments-rather-than-bet-on-aha-moments/ | <a href="https://web.archive.org/web/*/https://ravivyas.com/2020/07/07/stack-the-bricks-with-ok-moments-rather-than-bet-on-aha-moments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-514">
		<!-- .entry-header -->

	
	<div>
		
<p>There is a lot of fluff in Entrepreneurship and Product Management which is passed around as magical silver bullets. One of which I dislike is the “Aha Moment.”</p>



<p>A friend added me into a Twitter thread, which trigged a long time rant I had on it.</p>



<figure><div>
<div><blockquote data-width="525" data-dnt="true"><p lang="en" dir="ltr">Frankly "Ah ha" Moments are overrated, Only at launch do products do just one thing for all their users. In most cases selection of a product is a series of "Ok" moments. &lt;cont&gt;</p>— Ravi Vyas ⊾ (@ravivyas84) <a href="https://twitter.com/ravivyas84/status/1280370903042252801?ref_src=twsrc%5Etfw">July 7, 2020</a></blockquote></div>
</div></figure>



<h2>A product is a Stack of things.</h2>



<p>The Aha Moment is supposed to be the moment when a user realizes the value of your product. The problem lies in the fact that rarely does a product just do one thing. Products are a “Stack” of features, ideologies, business, and growth plans and services. Users may ignore deficiencies in multiple parts of the stack for surfeits in the other parts. How many times have you heard someone say, I use the product because the support is great?</p>



<p>Sometimes it is not a “feature”, rather those that don’t exist in the product like great pricing, a just ideology, or simply the location of the team running the product that plays into whether the product will be used. For example, I decided to pay for <a rel="noreferrer noopener" href="https://hey.com/" target="_blank">Hey</a> because of their ideology, I paid for <a rel="noreferrer noopener" href="https://threadreaderapp.com/" target="_blank">Thread Reader</a> to support indie devs and great service. I am playing around with <a href="https://hostomy.com/" target="_blank" rel="noreferrer noopener">Hostomy</a> because it is a service recommended by a friend and is insanely cheap.</p>



<p>Aha moments do exist, but they are hard to achieve and harder to retain as the “Aha Moment” becomes the new normal. Stories for Snapchat might have been one, but today, it is the new Normal, or for some, a passing fad.</p>



<h2>OK Moments</h2>



<p>A better way to think of Great Products is using “OK Moments”. OK moments are basically moments where the users agree with some part of your product, and the best part is they compound.</p>



<p>Here are examples of OK moments</p>



<ul><li>OK, A friend Referred Product X to me</li><li>OK, Product X can do this</li><li>OK, I an afford product X</li><li>OK, Even my good friend uses product X</li><li>OK, Product X will handle Migration</li><li>OK, Product Y is being forced into the organization</li><li>OK, Product Y has this blocker for me, which Product X does not.</li><li>OK, Product X has a free trial, let me use it.</li><li>OK, Product X is a lifetime purchase rather than a monthly subscription</li><li>OK, Product X won an award from Apple, might be good.</li><li>OK, Product X supports the same causes as I do</li></ul>



<p>Each OK moment is either a problem being solved or a spotlight being cast on the product. The Aha moment at the end of the day is a threshold of OK moments, a threshold that is different for different people.</p>



<h2>Start Stacking</h2>



<p>If you are building a product, it is time to stack the OK Product bricks, after all, each innovation we know stands on a stack of others. A point Matt Ridley makes in his book, How Innovation Works.</p>



<figure><img data-attachment-id="517" data-permalink="https://ravivyas.com/image-16/" data-orig-file="https://ravivyascom.files.wordpress.com/2020/07/image.png" data-orig-size="1200,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://ravivyascom.files.wordpress.com/2020/07/image.png?w=300" data-large-file="https://ravivyascom.files.wordpress.com/2020/07/image.png?w=525" src="https://ravivyascom.files.wordpress.com/2020/07/image.png?w=1024" alt="" srcset="https://ravivyascom.files.wordpress.com/2020/07/image.png?w=1024 1024w, https://ravivyascom.files.wordpress.com/2020/07/image.png?w=150 150w, https://ravivyascom.files.wordpress.com/2020/07/image.png?w=300 300w, https://ravivyascom.files.wordpress.com/2020/07/image.png?w=768 768w, https://ravivyascom.files.wordpress.com/2020/07/image.png 1200w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>



<p>OK Moments are no different, so start stacking OK moments across each point of interaction you have with your users to get to the point where everyone else thinks you have figured out your Aha Moment.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://ravivyas.com/2020/07/07/stack-the-bricks-with-ok-moments-rather-than-bet-on-aha-moments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757087</guid>
            <pubDate>Tue, 07 Jul 2020 08:57:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wi-Fi overview]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23757008">thread link</a>) | @arazy
<br/>
July 7, 2020 | https://www.cnrood.com/en/media/solutions/Wi-Fi_Overview_of_the_802.11_Physical_Layer.pdf | <a href="https://web.archive.org/web/*/https://www.cnrood.com/en/media/solutions/Wi-Fi_Overview_of_the_802.11_Physical_Layer.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>�Â~n£ï¹ø?4?¡à¸Þ¶{ÑÍbŸòNØ˜™QÌ+6!´“1ã.&nbsp;¦šÒ”+ï}&lt;=‡ý�/xéÑì'æè™°X·<iîr8Ï{€:îˆ6;mõ­ÑxÕd!œ( eìo«sjpyÞ¶ã”i}b¶�|ºxéáì'æè³‡ši„‘2­à’#š÷È!…�Øea0¸Åž9y›2\€wl�ä="" »="" ¶”¡_x+è1Ë{_šÿ�gho�˜àhÿ�³¢a‚ÅÙl#xóŽ!`xx\émjìl*h’È%Ï#8"âÙ˜±:m="">¯OE)B~ð'ÓÃØOÍÒ÷‚ÖÞ·µíÁkn¾]bbi&nbsp;x‘²9FÛfê}B+{›$Dä˜…&amp;Ú
”!n
ú¯JP×¼	ÙáÂÿHÿ³§÷€oOa?7Dc�Í�±œ(RÙ�I¦ËtÛmvÖ¨`ÄG1’IÌ‘�@OWCëmñÒ”%ï}&lt;=„üÝ7¼æòì¿5þÎ��s#/¢R=qjå�ÊÄÇa%¬R5pÄÜ„V[^ÇMtÝ)C¾ð'ÓÃØOÍÓûÀ7§‡°Ÿ›¢¬˜‰ß2ƒ•bÚlltZÀzºÖÚR‚=àÓÃØOÍÒ÷€&gt;žÂ~n�éR”ï}&lt;=„üÝ/xéáì'æèÞ•)AðÓÃØOÍÒ÷€&gt;žÂ~n�éR”ï}&lt;=„üÝ/xéáì'æèÞ•)AðÓÃØOÍÒ÷€&gt;žÂ~n�éR”ï}&lt;=„üÝ/xéáì'æèÞ•)AðÓÃØOÍÒ÷€&gt;žÂ~n�éR”ï}&lt;=„üÝ/xôðöótoJ”&nbsp;�xôðöót½àÓÃØOÍÑ½*R‚=àÓÃØOÍÒ÷€oOa?7Fô©J÷€oOa?7KÞúx{	ùº7§¥(Þ½&lt;=„üÝ/xôðöótqJ”&nbsp;ÿÐÛ¼é{ˆ¡@%±íñ¢Heá
Š€|Fÿ PîòÑdÜ@A¶"K_Æ‰0œ…ä­x_|Åˆ`ÙÐçmã©Jáˆám®0ÝÑy	ENt”Ðöô[-í×dH2«`ÈXúÀÖQ¹áPÆ²È#kñn„jnF«zÓÁqBô+·&nbsp;‹Vö*tG,tËUjPÃNÁÞë‰&gt;îbÐ³G‡ó»ñâ”„�,+º�™T�d
î|ºÈw=ÙBIˆ–HÅ®�Áe!H66ŒiZò·WEª$Î&nbsp;HÒI®|[­øŒ‘£p|P3#£±kY”0�}zm®Ê·ŽðgH#^Y-eu6RO€�ÁÐ»•L‰�óå]4Ù²£�ÜôÇ*‰!Kåd MºÁê¢Äç¢²xª;Ÿº�YFP$�²²�¢ãhé7©.98S‡9^qð°mzA½­nšž	8sï�‹6bIsäªÓsÄx£‹1f&amp;ëhìA½…ÂßKé¯–¢à–!²#±™š	ËGÏaf',OÅ�0bälP¸¹ñ
–%!Í”Ø°R›�=]=U6‹9V7/b
¶èiÕ2.UØ/´ßi¿É¬÷4Ò¹Ølv.lœ2Gpü`¥�fP3]NBv{¢º`ÞÛ
Ö÷:+
îdk‚ç‘¡$œŽÁõ,Z÷ �§®¶…"Þ!nŠVL@Û®±¶éáã/Ã�EkˆùGExµ;m¶¤»§ƒc`Xqsc`1±#hésaâqg�Xq¶�ðz·¯ÓT¶æáË˜”Ý2ø.¿Œe¥b¢»«�mU˜Œá.#k\Û[Û`¾§&nbsp;Õ«�Ã½€Ív#(àÚälÀ[“¦Ý•!„�o–$Ú,-¥º=AQ\+'h¶UÓ(»g$²@õ©Jy&amp;ŠŽ�²ÊÒÜ„»N’ú+,›¡ÁÈ°ï•œ¢H”gÌT×~�–;m[š�Ä’FÀ*ØØµXÀà×AÚÌ-¦ÆÛëÒ•ž=Ð†Nñ¸ÉqÇ&amp;öl„mãiíÒóBÌ®��YTª3¸»HP‹Øj-ÓêVÅÃÀ™²Ä£:…m&nbsp;|V¨®‘˜–ÖºØXØÜ_Õ4¥&lt;
"%™ª¶ÀùÑ¶ÛcXÕ¼øþ¤~]F(ÒÄQ&amp;D]Š6
žcÕíŠR«b"Ú�ªZ×¾Ëõ×8îÞpë+FÙÜ‘¨-{0]¹Eµ=#&nbsp;×I�kÜhEˆ5K`ðìC4HHÙ§“å
R«;¥†E‹…º´ÙŠ¨Rä6$Øh*ÆÄÄ`yÀb‘æ'B¤åÒö¸={)MÖ%ìoãnW¯V,(«‘PØTZÖË–ÖòR•‰·F$�d15¸ü Îx¥‚°ë»{ZÔŸp$Ì�™Ü¦@Y¬Uø6%†€ÒvÖ�„ÂŒ¤@œQa&nbsp;ÐZÞá§l.•¡R±r…‡’”¬qn¦¢Y$Iœ\"‰$6°#`ñü«�k&nbsp;‚)dBJº†S™µ\µZapÑ(XáU`uÞ®PB"åU,@)Jƒ8Œ�y*¬Ç¤éjÌ7B%XÌêc3.dòqtã1Qa´)ÛZŠ’Ù¼D[Ëo•TZÐ&nbsp;ÊK
…´4¥Wæ®*³3*µõhÝ@°'[�/m/¶¢Û­†*ÈâB&nbsp;FbF–Q´
kAÂÀEŒHFš:…GÀpÚyÊh×’n=jR&nbsp;wO±Ï`@¸�È:H6Ôž‹UÒÎ#ÂÉ‰
HHÙÂ�Tœ&nbsp;›j.6S$5¢AŸ•&nbsp;×K{†¦bS„¨1²•+Ñc´PñVV˜‘#Š°nVëÒiÅÁpAO+5ó_Ä:«§Y°ø,61ÃD±5¯­¶m5}š°²fMNñ¶ÎM¥(™@:tg¬ë©R¨Ù©Y«5®¥J£f¥f¥*Tª6jVjR¥J£f¥f¥*Tª6jVjR¥J£f¥f¥*Tª6jVjR¥J£f¥f¥*Tª6jVjR¥J£f¥f¥(ÿÑ·{ŠmÄ‹Á‹¸©šL‡[º[¤õ¡®¼˜ÝÕ{Â°…•’S`¦ê5
C·�ØßÅ\-êcq1nw
£+±/›KØ|’»Çtq`Øð�óËû•�¤èÓb­ÍÐ¹�‚B_ e9²&nbsp;6PÂ÷Ø,F¶­¸§�`¶1•Ø(*Ë}KÄ
é®w‡cvÚŽ|ªqº8á°AñÏ•L'a¬bENmÔÅC“6¯Êáïl…‰º©ä[ÅÓRŸ‹‹+Ä@«qKÇ—ƒÁo|úhN—Òª;¡�`U†‚,A}ª^hãº&nbsp;õ¤ùTÂvSÚ*ø1Ø×–4–«$ŒÆEÈ¬.H±76èõë¥\o4qÝPzÒ|ª^hãº&nbsp;õ¤ùTÂvSÛ]šÌ­ˆàd8€ŠÀ¶N
™†[hMÀ±ñ{uÏóGÕ­'Ê¦;¡�"ÖƒÖ“åS	Øiˆm­¸–Äð‘Œ0ãäå_ƒ¿×·«j–	§8eð�D·lÁ¶ò�È¬�êƒã¿*—‡ãz&nbsp;øïÊ©g„.ã=}½@¾#˜Ñ9g¶åZÕ±¾hZP&lt;ƒl…/–÷¯ð
Žê&gt;-bS„Úœá9^-šÖoÆõAñß•KÃñ½P|wåVA!•°ƒ„hŒ�a‘Y1°ÆfAÌsŽÊèáþ
…i6^&gt;Í¾;tÛmS†liÄMÂ€0áÛ&amp;nY×£Ååõ+'‡ãz&nbsp;øïÊ¥áøÞ¨&gt;;ò«ð¸#…Å£9Ê³�Â&lt;=9F{kf5±y¡1v.sfäo‚þÕØf�ÆÜ-Ãp’m¾ÌÆÖ¿GWŠ¹¾�êƒã¿*—‡ãz&nbsp;øïÊ¡’¡pè×Ö@‹â9êœµh
XWÝƒ4bE&lt;—bäònt |ðèâ¥H�3æÈZÍ”u¨‹Ó\ïÆõAñß•KÃñ½P|wåVX–`p�”EEP"•Zu±šÛ…�ºÊT±„7�3^äeµõµöU’&gt;XTøÐzäW;Ãñ½P|wåRðüoTùU	3SR‰®¤-šÛ­úàVe“á!H~9¾œ[kmmY<!--?ÕÇ-->U/ÆõAñß•XÂvÎ!¶º×ãžÈ÷Mr]Ô,Q#’Å¯#œ�ã]tPGAÓ«¢ŸÃñ½P|såRðüoTùTÂvSÚ*RbwY¡9#àåÔé}Ž4Õ€äÞÇàº-RÆ&gt;ép²x:?U
•Ú
±kv\U~�êƒã¿*—‡ãz&nbsp;øïÊ¦²˜†Ñ]Ì¾¡Éð#1°,.¦Ýw¬Íº|XÌ,ªª¬‰,ç6·'`=G[T|?ÕÇ~U/ÆõAñß•L'a¦!´T—ºŽ´|Š´LÅ†k8Õ†RG«zéG/	{£¥­Ëm¿Q5ËðüoTùT¼?ÕÇ~U0�”Ä6Ö,LøîÌ¤x!Ö¥ì-§WUvðo;a0í‰f(€í)Ûã¬Œ&amp;å`$x¤ùTþ�êƒãŸ*¶1,Ã¯¡È’Xt�uïX1ÍˆáU`XFK´|’	ÕGÐ­¨&gt;@6ÖÆõAñß•KÃñ½P|wåV¼'a©âEtðæo�Â9î
xKlÍmvxêË×#Ãñ½P|wåRðüoTùTÂvSÛ]{Ò½r<!--?ÕÇ~U/ÆõAñß•L'a¦!¶µcÛ„%’Pr€P£)$ôßeP[8l©4jË`X¡$±}:��7¨x~7ªŽüª^�êƒã¿*˜NÊbE:Éº �%á¤6Œ‚Nw²X¯B‹øíjQ-->9&amp;S/Ñ—!¸&nbsp;Üäk›
Bòmã½7‡ãz&nbsp;øïÊ¥áøÞ¨&gt;;ò©„ì¦!¶¤Íº†€Ä%36„º«ðyÉÔXÚ××®™[ÁB¬&amp;%^ìÀ0bºß5Ù…Èèõµµ7‡ãz&nbsp;øïÊ¥áøÞ¨&gt;;ò©„ì¦!´SÝ@pÁ¼÷\…ì
6R×¹66·O]êyñbQ—¯™‰t³�š�­¦¦Ö�Ž£áøÞ¨&gt;;ò©xv;ªZ_•L'a¦!´WG
îØhŒ¡„œç,×ÆãËW^¹�D:ø¥ùT¼;èaúŒß*˜NÊHÛ]{Ò½qÎ?¢ì!¬‰@öÅ7šX¿¢=i¾U Òk³zW®1Ý,P&lt;ò‰GÈ¥èã¥,Â83•É/`Ö
/}&gt;­ Òk³zW®HÆãd
†-Õy/Sð�ÐêƒãŸ*…HÒ¤�µÓ½+×3ÂwCªŽ|ª^ºP|såR
$WNô¯\Ï	Ý¨&gt;9ò©xNèuAñÏ•H4‘@ÿÒÏ½{øÄj@ú‘­âY$ÆGWNbŽT’uË¥¬*�ä€ÑH­¨É{|Y¢þ
?CîÖÄ¹„Äœ¶‘LM;(x®2<axÐ”‘ÉÌÖmŸ`££aè±µéÂî‹fÂe Ä6sa¨"ÃŒÇb6^ÔaÁeèe.="" b)ŒqÓ="" â®="" ðå¹`2„-pmn›vÚÖèÛsu£n“Å�Ý¸Á•vËn‘{Üÿ�Ú"à£ô"—¡ŒcŽ˜oq¡lncÃØ‹i`¼^¯)õªü•Òàbô"¨i0ˆüÁkr#0rÛ="" jÎ1ÇlŠ²d¥’µ™p#àÓn£~›[×¤²à›(Ì ½€s£\Ûkz¢›àã¬`5“%,•®i°q„fÕd�«(,,hpiØtf'pþ9¬Ùs[§È="" 7ÁÇlŠ³d¥’·Æ0ó="" ’0nÃ¨©ð1zlca¦Å\Ü”²wk�‹ÐŠ\="" ^„s|tÀx«›’–jép1zulpÐ.y€*,3q�†‹s­7ÁÇl±d¥’¶="" 0&ÜxõËn8±uéé*qŒ< ˜òµ´="`Úö#&nbsp;ØÓ|tÀx«JY+¥ÀÅèE./B)¾:`<UÍÉK%t¸½¥ÀÅèE7ÁÇLŠ¹¹)d®—¡¸½¦ø8é€ñW7%,•Òàbô&quot;—¡ß0*æä¥’º\" ^„ràbô"›àã¦Å\Ü”²wk�‹ÐŠ\="" ^„s|tÀx«›’–jép1zk�‹ÐŠoƒŽ˜srrÉ].="" b)p1zmðqÓâ®njy+¥ÀÅèe.="" b)¾:`<uÍÉk%t¸½¥ÀÅèe7ÁÇlŠ¹¹)d®—¡¸½¦ø8é€ñw7%,•Òàbô"—¡ß0*æä¥’º\="" ^„ràbô"›àã¦Å\Ëe`e†‡n�u’q{x›ñy9o”çÚ®§¡¸½¡pvÖb‘²¹rukŽ+{è5j¹%�É|ÊËÅø="" e†lÂÜ"Ø›�k±ÀÅèe.="" @+ÁÛ@¤l®4¯#á="" lÁŽc lÍ ="DÞ°¦:Bêft1­îìN–ùÅ¼½Fˆ¤HÕ˜’#D@ÄØE}·êªU°�§" ë£¢ÆÚ="" Çgpt†*s{›km¶(@8¸àˆÙ•p_)á="">`n5ˆµ­�«ly•1EA$bÀÐt…:�®˜vRÐÈ’¬6„éÉ×Z«s@á÷@ucHÅ�$gœçÑ¬]cs
ÀXR6ìÓ�®f¥—tttTWUÌŽYvæ+nšÜ£¬cDÐ+2–±¹ÖÙŽc¯ˆyt®µ…,«ÕSgÅràkXH\&nbsp;1¥e³‹(@†àÝ�OV–ñÓÛ|¡@²ò¬¶&amp;××ë®žUê¥•zª8«8k$K&amp;_=¶kô[äTòVŒ«ÕK*õS0ÐÿÓ}äsrv;æŒ²)b
”\€P“AûÉŠQ{^;_âÍáÑ°°|è‘NK’Úª;LÇ£[šR¢›¡ƒuÂª%â$�)"­ðˆ	°‘XæU°!�ß’4¾ÚÊ˜\æ]JÅlYH92ÛMI"¡…ÜÜ;IðˆK
f�l¶c¥)ZãÆae$G*¶[Üƒ¦‡)×§]*àCÊA\¨ ôÖ(÷*äYK;:�nÙz6×·¬+jŒª÷°æÂöò)JzæÉ&gt;ãÈìÒbâ³_2pè¶\™­}¶þÔ—ºglBÙÆV@¾+ÞÄu×”23ÎQfg ’oReÁäjœŽÌê*Å¦T¬q˜Û•z’&gt;áÆáÓ‘—A4{VÀÞýúÔc;�LlvåN"2ªEÉ7°*+Í|ÎÆXyÞÒÚf[ñIâþ#n»iIp¦× 3®feU¼vÍ© X_mF¥^Ÿ.#qæ‰qp¿AÏ$‹I½ö‹ôR\Nã¬rFqp¿Å¤fž2ÄØíµÀÚW™&gt;æc£6hõ³›fR@@I&amp;Çe�·_Eê
€Å,‚&lt;—c”Y•†@	-pmÐiJõ1[‘†ÏÁb&nbsp;FÌAž3âë«¼ÓÜßMÁìÑüÕyQÜÜ`�ÄP^Ù—`¶Ý¾-´Çsñ�òpw&lt;“B¬2�˜›ƒm”¥z·š{›é¸=š?š¥æžæúnf�æ«ÊŽæã¼	AŸ!p3§A¶º›‚,5¸5/2±ÀÈ%Ð
&nbsp;mÍÐH¨èu¥+ÔüÓÜßMÁìÑüÕc˜nò´Òb¢Ìå[9
Æ™ô¿‹å×œ6åc�Ñ€Y�4lNÞ½�uŠ”¯Px÷¤y6$á
’«&lt;`Y~k³M•«‹Ü¬2ãÆBT±`Ñ›ÔØß¤ëþµy-*R½ƒÍ=ÍôÜÍÍRóOs}7³GóUãô©Jö4÷7Óp{45KÍ=ÍôÜÍÍW�Ò¥+Ø&lt;ÓÜßMÁìÑüÕ/4÷7Óp{45^?J”¯`óOs}7³GóT¼ÓÜßMÁìÑüÕxý*R½ƒÍ=ÍôÜÍÍRóOs}7³GóUäÊQVb4�í§Ôðp
ÉÐÀG&lt;=…bsŽ*õ¿4÷7Óp{45KÍ=ÍôÜÍÍW�Ò¨VkØ&lt;ÓÜßMÁìÑüÕ/4÷7Óp{45^?J”¯`óOs}7³GóT¼ÓÜßMÁìÑüÕxý*R½ƒÍ=ÍôÜÍÍRóOs}7³GóUãô©Jö4÷7Óp{45KÍ=ÍôÜÍÍW�Ò¥+Ø&lt;ÓÜßMÁìÑüÕ/4÷7Óp{45^?J”¯`óOs}7³GóT¼ÓÜßMÁìÑüÕxý*R½ƒÍ=ÍôÜÍÍRóOs}7³GóUãô©Jö4÷7Óp{45KÍ=ÍôÜÍÍW�Ò¥+Ø&lt;ÓÜßMÁìÑüÕ/4÷7Óp{45^?J”¯VÄã·:RÊqP•xÂ’³G}§è^:gÜÕ–Q‰w‘¤ËËÒÀ€tòªöh}÷‹é(þª)JÅ…ÀøF(ƒ°k\µ¯Õ{éO¹¾ün�Óãý5m�‡Ï'“&amp;o:ËrÖ¶¹¯¥ïÕ\ì¼mºoÌÃl,[áQô
O©YÔzƒ¤s�i]ZU“4ã%@ÑÈNÌ™˜
mÅ í y/TÉ‰ÆfLŠAà.ËÁ’™[0¹@·]úkšèÒ®{â1K„FN3»²ð�¾P[)Ê&nbsp;X°Ý�•Tx�Ò*ÖPÇ…°Î�`°ÈeïÓ&nbsp;Úz®­*®w‰A•Êñ€¸éÛ­YJPÿÔ}äsrv;æ‹g�†…ââœêEœ]zÀ ‘êÐŽòoÁKmOl<yÍ2b1x9"”pnã($�m¦¤ Ã¯äÒ•[ît®�)›ß~i="" ×åsÞâÜ[ÞÃmêÄÁiÄ²�áÑ‘²›p ŒÚèºê="JÌ77¯Â+&amp;dO;7°,¹J’‚×QrìiÃa×'2Ž*ñ›D�‘qmNf">Õ)OƒÁ¶¤-&amp;pùl2Û’,I$“¯¬:+]*T¥!¶¼^CiXõ9÷kÚÚñyy×ív”­º8™#11[7(å�˜¸ñjkºØÐ‚2Êè®\+"°¶cÑ²ý†•)[ébN]Te”^ÌlI½ìÛËQ8üAt�eSM&nbsp;®&gt;(üŠËJ”­­º˜¦•fl†DRŠ‚EÉ'Û'ÜÙ¥A±ø†e~*”‰¢[(+†.5–•)[[tñ,s6Rx&gt;
IªÞö÷Ÿà&amp;ÝlkfQ¨:(†Ï³g+_-`¥JVôÝ|rD!2m@$ôýw¬©R”©R¥JR¥J•)J•*T¥*T©R”©R¥JS®ŒŒU˜ƒšw=ljµÕ€ñŠ·ª“º¦ÀÆ¶‰Þfú¿Ij�46á=˜ªiR¥ZªT©R¥JR¥J•)J•*T¥*T©R”©R¥JR¥J•)J•*T¥*T©R”©R¥JR¯f‡ßx¾’�ê¢¼f½š}âúJ?ªŠR­®næsû¡ôôÿMG]*å`c¾éFMƒcN¶áQ�†³¨Ö‘Î=¥tf™0ñ4Ò*Ž�IÓ`³Çº8yAÉ˜•(Xf'Rom,Iñì©É)†Îä"žY9ZìHÚ:óZ©�¹èòd&lt;Ò°‘K!�¿‹S¯^—Ò±Y«“…{žÖØN—²‚&lt;¤éZƒ(e7ÄvVƒsã�1%¸ˆx®Îvê&nbsp;kmEôon‘Z¡–)ˆŸ?e$Þúu“·fÞšR­¥J•)@ÿÕ}äsrv;æ‹ä¿Ö½ò›eÑ¯n‹ôÐvòØ¬°Ú°’=F4R’b8Œäevg])UJ1’,
ŠêP!c™G�©³j�öÞý5‹pŒ�™&amp;3FC3f:.vž) éÕ¥º*XŒt�³Æ¨¬èËðG’åÀ_RÇO¨Gºm PcUfÃ=ÅÜ)Œlø+ŸZšiTð[®—lÌá^ùTŒÍÎòK5€¹]êê®¤9Ä)Â_(ÌXI¶·¥J6Î�ÈËq²á­ê©"¥YšSÛŠ.z6½�xÄ¼ãö�»^Ð6×‹ËÎ¿hûµŠT)R¥JR¥J•)J•*T¥*T©R”©R¥JR¥J•)J•*T¥*T©R”©R¥JR¥J•)N¼¡n±Vb	3¹;s­M˜¢*ÌA&amp;w'nc[‡tØÕúKTy¡×Of*ªT©Vš•*T©R”©R¥JR¥J•)J•*T¥*T©R”©R¥JR¥J•)J•*T¥*T©R”«Ù¡÷Þ/¤£ú¨¯¯f‡ßx¾’�ê¢”«k›¹œþè}&gt;?ÓQ×J¹X&gt;6éð&lt;ç†º�¯]Ç¯YÔkHçÒº…G…‘ÜD­`\Øtƒn6šÚ¨ðhJDÜ°ÊàÐ1g#Å«“þµ&lt;Øi1xeŠc‘ÉÌÖã[Fè¾ÚËä0$³%‰Ê¦Ù	lë©¾ªä
½f±¶³Z›‘,eÉÈîå¬¦æK“qkV�U&lt;.&lt; q'„lÆöëÕå¨á°¦Ìr±ÊAa˜Vš^Ú(eýM+U)J•*T¥ÿÖ[É¢•N&nbsp;Çb&lt;®h´A�@<sqvb ä&„÷‘ÍÉØïš1¥*-o|ê­˜�n Ü="" @7¥‘6å[‹t�Ùëtt©r”Àp��ô©r”†Úñyy×ív½œ² .ÆÊ¢äž€+Æ$Ögív”¨r¥j”¥j•*r•*t©jt©r¥)r¥j”¥j•*r•*t©jt©r¥)r¥j”¥j•*rœmzœà‰œ6ÜÆ ¼¡åf#yÞÚñ�mÐocwé-qæ‡8öbª¥j•j©r¥j•)j•*t¥*t©r”©r¥jr¥j•)j•*t¥*t©r”©r¥jr¥j•)j½š}âúj?ªŠñšöh}÷‹é(þª)j¶¹»™ïÆè}="">?ÓQ×J¹[æÝ|ïàÛjEÓYÔkÇ8ö•¿’aÙ"RÏ™
ŒüÆo©³¦¨Åañ3ÏÂ%�plŠsòtmlÁfKUÐ¢¤‹gÏpn3ÕÑzÅˆ›tŒ…ø’˜Í£¾}•®´7QÐ/{‘¶±Y«[‰x ��1É#0X*°`K^Á­âÛÑT¦ta‰BI˜€T |¥AÉrí6S¶­Y±ü# Îd¿7vÍeÔ‡¸ui©®ˆ7ž�:-íqÓŠž•*T¥ÿ×Žón0Ø‚6ð-õf¢t@¦&amp;v.‰Ó^‹ÐÞò9¹;óF4¥bi1#*ÄEòXdUm-””Ó¨›ôÚ§�yže.ÚŒ¦EÈü‘˜ZË&nbsp;kÛJÕJ”¥J•*R�Û^//:ý£î×´
µâòó¯Ú&gt;í)P¥J•)J•*T¥*T©R”©R¥JR¥J•)J•*T¥*T©R”©R¥JR¥J•)J•*T¥:ò‡”U˜ž}í§ÔùÅ¶ÜZ¬Å[Â$·£5¸wAý�_¤µG›töb©¥J•i©R¥J•)J•*T¥*T©R”©R¥JR¥J•)J•*T¥*T©R”©R¥JR¥J•)J½š}âúJ?ªŠñšöh}÷‹é(þª)J¶¹»™Ïî‡Óãý5t«›¹œþè}&gt;?ÓQÖuÆ±Î=¥t©R¥X¬Ò¥J•)J•*T¥ÿÐ}äsrv;æŒh;yÜ�Žù£R•*T©JT©R¥)
µâòó¯Ú&gt;í{9PÀ©¸Zà•&gt;¡Šñ‰9Çív”¨R¥J”¥J•Mc‘Í‘Y‰èšÈèó¨LiÊ¡J´.Î#¾r.R4:ÔŸs±Èë@áŸ`ËlVp0Ô{ÕC|MÖbt�–•t&lt;ÅÝK_€o]~]1Ü}Òo]OÉ¨ŒòMcµèbwÐíë*Ñ.
¸H]o³ŠO¹SMÍÇºp‹•ëµ½£YÂÛz¬ï¶àk^!’•n‡rwG¹â�ˆñÙ}Ò*gq7Pm€ýI~]`�ØHžõX7­
.ƒ¼‡o\êU¯ÌÌ~bœÜZúuøé—s±ÎHXØØñMH£
*Ã&nbsp;uÖwÛ}];èvõ–•j]ÎÇ3ðbÍkØ©ÙÒ¯óu?©/Ë¨žOtN]�
ëcK&nbsp;ï!Û×:•m}ÉÝùP7©f÷	¨�ÌÝ@0?f• Œ@ ‚YV7ë]];èvõ’•i|5
š	þ‚O¹W&amp;ãn›ŒËXõ�6ùM`‚œ†Ó�¬ï¶ÆxÓ&gt;´+
èÂÝb¬ÄÓ¹;K×æ.é‚/Ûè—åÕX¬-%fh\æÇ) ëâ­ŠfË€dïŠ`g”6uvÛ8‡B`èaÅÇY)V¸÷7*p‘ÀåzímžZxw+t'£�ˆ¹ÙvmÚEk €I’j[í±&lt;4ÈÁá
5Ž•tâî˜Ûõ×åÕm¹[¢·¼§P¿¹XŽ;&gt;Ê±¿Zô1;èvõŽ•^˜&lt;[¿°¹kÚÙMXÛ™�Y&amp;�Ã6Áo“²³…¶õY7d]A‰Ò4VJUÒóu-~�Š_—U¾än”bí[Åf÷	¬c
C€‚{Ð¬oÖ½Nú½a¥ZÎæcÔ`pÍ:é›sqè¹š	ì“îVJ°ÒèVwÛg›Nú½e¥[£Ü}Ò•C$
c×e÷H©ÄÝ1ðƒõ%ùu‰Á ’'½V7ëC›Nú½séVÏ2·FöðwÓÅMæfèXžì6éR(ÃJ‘Ð:é¿ZêéßC·¬”«T{�Ž•²¤HÛu+í›Uþbn§ãõ%ùuÁÈåÏË³¬›ÖÆ—AÞC·®u*ÜÛ“º)¶ÛÑf÷	¬ï…ÄÇË‰×Ê¤T‚;	
Äm‘AvÛhu&lt;æ©¥J•F§J½š}âúJ?ªŠñšöh}÷‹é(þª)J¶¹»™Ïî‡Óãý5t«›¹œþè}&gt;?ÓQÖuÆ±Î=¥t©R¥X¬Ò¥J•)J•*T¥ÿÑ}äsrv;æŒh;yÜ�Žù£R•*T©JT©R¥)
µâòó¯Ú&gt;í{@Û^//:ý£îÒ•
T©R”à‘²ºû‡Šœî„P¼rXz~Eqë£¸&gt;¸~Ñú©©ŽÐ3*Ò²`äuV«ê­jä€aH�TjMšášàéÄy/m”ìÌxÄë�t°*6è
¶SÜë&amp;Þ�-Ly#«:ö:y5æ×2'e\Ý»ÍÈU�ua±FÏRH$,
Ù…Š“dCjÉºØÉ°¸�BWAbs%«F�!-ÔÜß©\íÞ·™2[ óØù6šÝ¹UZý&nbsp;B‘:d­Ý6Õ¬´‰å^ŒJ#NÌ»Z×„™¥ÁÁ+�$aŽD¸×Ô5¡dc•s¹Æ¹@c³B:µ¬›�3°¶ÏÌ¯'ei[ç«æ?èåxªÀßnˆ�„teRÜˆ›Õ¾
äƒPçlžöM&lt;¥¸0—*·½ÔÙî	èU«&lt;ÌÊ¬Ä€l×=[-T¿G'aÕum­íRŽÜ*XEÊƒÆÛP`äf³eG‡{BJG&lt;¨ÏOsfÞNäâ¦Äãqœ)ÒÊ�F€ap:ë¬®Ên¬Ìln-í¶¸[ƒïîèmÚvmåµw
í©s¯Ã4_SÇÕVù!Ô†‚¨Ž  
«Nà¶‚ÛŒ+Ë�C]´âžÄU±±2ñ˜)±q”ò­­4RJŠB�À›’ícsÐ/ÑL9:ëÅøfŸ6ÔÔF~”Ûêxªœ9
ÝeDß ÝièÙx»nNîî†'4&amp;P&amp;�ŽmsË#B-]—°r32Û@[ÈmC{ã÷ï	³›èÙÎ”J×ÎÖ2mø-WwN[Ÿq¨€¹È™Á:³šÑbÚ×Ž’Í9¡Ìi
¢"åƒ:åÙ`WhÖýu&amp;‘Ä€‹¥‚¨6B/ÓÕ²&nbsp;9-¶Ùz9G·×I¹MÉåú
§•ãªP6mí+r¢‹÷ Ò6õm7ïcúõÕxìTÐà§—Š
 #\ãVÅ×Tà1†i‰iÝFEÌl&nbsp;uÓn–››‰·&lt;ìrœµÛUn5Æ	µ`|&amp;^FÞŠ¼–ÓÄ6íÌ+Œnµ£8)19å5]­§‡ÛR£%"‘Xè3®·ç`¤k_n\­äÛ*r‘x¡™®WFM•Y¿Ð¯o‚åúž*œ›~)»}ŸQ«ª/X€b"ËƒÄÏµÄÓee°°¹n7­\˜wBiwr\*ŒËb¼UÓiµtl:¢½úyõ×	÷Tb?kýTÕÍÆŠWuªbÃÄ€c#˜™ƒÇZ·e¤/fTrÄôC.y“´×qd`À«¹=�*ú¦Õ(Ý¬\’ì3œh
¯aâ¨ÛS!R'«â§NlÞü–åläôxª¡îw"·ßDÀ&nbsp;*€nÚ˜ÐÕØÚtšTwe³3s5”x—¬V
ÛÇbpø%•
‡iŠÊ;•¨Û¤!êÏÉy&gt;*åo†ÞgGl£çOÀry&amp;¬î0&lt;&lt;Ù0$lRGz¨îäSk12ÈÎŒK–žÒº¡üî&gt;3/œÆl©œ\¨7¹¾µ`‘ÉPÌl€µómÕ´ÐÕk˜G²�9�Dr·RN_OŽÝ;y~:×|
öï·fx«*Š72B¯t¡Õ#ªñí=¨›È÷A{ ¨×6«lÕ¢išáò�”ìlÝVª•ð;í³`å}¥ØD8§‘ÊÙP
(�†­¦±u@Ü¤Æka£NG	;vóë—¸ØÙ±‘O$§++ª‚‹°jt×Q]€9X�F¹”%¼`[S\=í_€Ä[7:¼žVÃ]³s·1úS•ÑÉñÕžHçº\emå‘uECr[Eµ„*€£!ÛN­µ5v\Åuº®¬�†äi¶¤’Ê¨H`6k1ò‹¨í7¶Åår¶7·ÕOaÒŸ£9~­U`'@ÐººÈ©YE6˜@ƒzïaqÀÐF�\]ÝÝlV"ˆ%ŒJ×"ææþ?q¤Ý½Ñ•J´š€&nbsp;|ŠÕ¾ŸÙÌ&amp;ÏV¸•ßÜ¬mÙ³‚¤�Ê€•™fjˆ±i™œ¢³lÈòÇm;1cv74Ô©TÉ,KI:IÌÖêUìÐûïÒQýTWŒ×³Cï¼_IGõQX¥[\ÝÌç÷CéñþšŽºUÍÜÎt&gt;Ÿé¨ë:�cXçÒºT©R¬ViR¥J”¥J•*R€ÿÒ}äsrv;æŒh;yÜ�Žù£R•*T©JT©R¥)›&gt;SÁÛ=Ž\×Ë~‹ÛZñ‰9Ç¿¢&gt;í{@Û^//:ý£îÒ•
T©R”«£¸&gt;¸~Ñú©®ut·ç×ÚoªšÁÐÝtöU®÷t®uÆì�:ñ_êZ{µÉ&nbsp;ºê9=;E9]OíÛŸä^˜ê¹¶Ý×�°½ç—Hîv¦®n’7›™ƒ˜Ö5×�sVÈÜ
Ô}N©ê×7wˆ;“%ŠŸ=�’,6×JöãfµïÇµÁøžŠçnó_rdãfóØö.^“[÷uísÏdxª[&nbsp;t‹uäÕÖ×¬ö£œ4V�ÍîvÁÏœ¯%­òEhQÇÍpA ž8Ù©="³îrßs°¼RÞr»/É­
8árì å½ÈÙ®nŸ%Bÿuo{ÿJ<u�Èfôœj5�Çvƒ·wÚ—Êt>Öé¾Êh™L©fˆñ†Š¶;iIÐ»t&lt;^�­®o‘J7¼¨8@Üa§—§®&nbsp;tžyîh¬Ø7·ìJêë=töœó«‡¸&gt;þãü§f‡–ÕÛ`@¹ºí‘³/O·Õ\=Á÷÷t:u&gt;/ƒjîÊ/�¦»KgëÒÕk’In…</u�èfôœj5�çvƒ·wú—êt></sqvb></yí2b1x9"”pnã($�m¦¤></axð”‘éìömÿ`££aè±µéâî‹fâe></iîr8ï{€:îˆ6;mõ­ñxõd!œ(></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cnrood.com/en/media/solutions/Wi-Fi_Overview_of_the_802.11_Physical_Layer.pdf">https://www.cnrood.com/en/media/solutions/Wi-Fi_Overview_of_the_802.11_Physical_Layer.pdf</a></em></p>]]>
            </description>
            <link>https://www.cnrood.com/en/media/solutions/Wi-Fi_Overview_of_the_802.11_Physical_Layer.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23757008</guid>
            <pubDate>Tue, 07 Jul 2020 08:42:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a desktop radiation monitor with Raspberry Pi, brass and wood]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23756964">thread link</a>) | @chrisys
<br/>
July 7, 2020 | https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/ | <a href="https://web.archive.org/web/*/https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <p>I was always a fan of the steampunk style, and having also had experience building steam engines in the past, there was only one real direction this project could go. Once I had my radiation detector kit hooked up to my Raspberry Pi running InfluxDB and Grafana, I found myself woodworking, machining, and fabricobbling an enclosure out of mahogany, brass, copper, toggle switches and, because it just had to be done, nixie tubes.</p>

<p>Read the story of the almost year-long journey (<em>cough</em> some other stuff cropped up…) I went on to make my steampunk vision a reality below, and if you want to get up and running quickly, find out how to <a href="https://www.balena.io/blog/build-a-simple-radiation-monitor-using-a-raspberry-pi-influxdb-and-grafana/">build your own simple version right here</a>!</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/geiger-main.jpg" onclick="openModal();currentSlide(56)">  
</p>

<iframe width="100%" height="500" src="https://www.youtube.com/embed/lEL_XkN69n8" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<hr>

<h2 id="contents">Contents</h2>

<ul>
<li><a href="#intro">Introduction</a></li>
<li><a href="#inspiration">Inspiration &amp; Design</a></li>
<li><a href="#build">The build</a>
<ul><li><a href="#panel">The front panel</a></li>
<li><a href="#wood">Working with wood</a></li>
<li><a href="#brass">Top brass</a></li>
<li><a href="#dekatrons">Imitation Dekatrons</a></li>
<li><a href="#fasteners">Fussy about fasteners</a></li>
<li><a href="#pi">Plumbing in a Pi project</a></li>
<li><a href="#nixie">Nixie tubes</a></li>
<li><a href="#counter">Electrifying a mechanical counter</a></li>
<li><a href="#electronics">Electronics</a></li>
<li><a href="#geiger">Relocating the Geiger tube</a></li></ul></li>
<li><a href="#final">Final assembly</a></li>
<li><a href="#software">Programming and software</a></li>
<li><a href="#end">You have come to the end of your journey</a></li>
</ul>

<hr>

<h2 id="introductionspanidintrospan">Introduction <span id="intro"></span></h2>

<p>Low cost radiation monitors and Geiger counter kits have been available online for around $30-50US/£25-45 for a while, but standing alone they don’t do much other than make the recognizable “clicking” sound we all know from movies and TV. I decided to up the ante by connecting one to a Raspberry Pi, storing the data with InfluxDB, and showing the readings with a Grafana dashboard.</p>



<p>I updated the tech, gave it a web interface, added remote management, and built a custom mahogany housing with brass and copper fittings to show everything off, because it’s important to look suitably <em>hip</em> when sitting on the desk next to your <a href="https://www.balena.io/blog/build-a-raspberry-pi-powered-train-station-oled-sign-for-your-desk/">train sign</a>… right?</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/header.jpg" onclick="openModal();currentSlide(58)">  
</p>

<p>Anyway, I’m gonna show what I built to hopefully provide some inspiration, then show you how to get up and running with a simpler version of the project that anyone can build at home without any special tools. Let’s hit this.</p>

<hr>

<h2 id="inspirationdesignspanidinspirationspan">Inspiration &amp; design <span id="inspiration"></span></h2>

<p>I’ve always found the idea of radiation fascinating; how there are invisible particles moving around at incredibly high speeds, crashing into things and flipping bits all around us. Due to my fascination, it doesn’t take a lot to capture my interest when it comes to this field.</p>

<p>One day last year I was reminiscing over the <a href="https://www.bbc.co.uk/news/business-44606771">now defunct</a> UK-based electronics retailer Maplin, and how they sold all sorts of interesting kits for the aspiring engineer. This led me to <a href="https://www.richardmudhar.com/blog/2019/09/maplin-geiger-counter/">Richard Mudhar’s blog</a> where he tells the story of the <em>Maplin Geiger Counter</em>.</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/mudhar-example.png" alt="An excerpt and image from Richard Mudhar's post"></p>

<figure>  
The original Maplin Geiger Counter. Perhaps some of the design cues are visible here?! (Credit: <a href="https://www.richardmudhar.com/blog/2019/09/maplin-geiger-counter/">Richard Mudhar</a>)  
</figure>

<p>The kit that Richard has built above features both an electromechanical counter on the left, and two rings of LEDs reminiscent of <a href="https://en.wikipedia.org/wiki/Dekatron">dekatron tubes</a> on the right. This display has the neat design feature that as the rate of count increases, the display becomes more noticeable.</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/dekatron.gif" alt=""></p>

<figure>  
The spinning light effect of the Dekatron is something I wanted to replicate. By Hellbus - Own work, CC BY-SA 3.0, <a href="https://commons.wikimedia.org/w/index.php?curid=4741470">https://commons.wikimedia.org/w/index.php?curid=4741470</a>.  
</figure>

<p>I liked the idea of combining the modern technology on the inside (Raspberry Pi, Grafana, etc.) with the timeless look of brass, copper, toggle switches, dark hardwood, and glass on the outside. The idea was now to build something that looked old and had that distinctive steampunk style, but was up to date and Internet-connected.</p>

<p>In addition to the total absolute count like the old Maplin counter, I wanted to offer a live display of the counts per minute (CPM) reading, and what better way to do this than with <a href="https://en.wikipedia.org/wiki/Nixie_tube">Nixie tubes</a>, to get that nice warm orange glow and keep things looking cosy.</p>

<p>I started scribbling down ideas and thoughts of materials I wanted to use alongside shopping lists for parts, and possible designs for the case.</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/notes.jpg" alt="Original shop notes!"></p>

<figure>  
Notes don’t survive well in a machine shop, but these are what’s left of my original sketches.  
</figure>

<p>This process was very much led by an image I had in my mind about how the thing should look and feel and so I just had to make it real… somehow.</p>

<hr>

<h2 id="thebuildspanidbuildspan">The build <span id="build"></span></h2>

<p>With some thoughts and ideas scribbled down it was time to get started. As this is for the most part going to be a bespoke, hand-built item, and made up as I go along, it’s not necessary to put everything in CAD. There are of course some core items that exist already and cannot change size; the Raspberry Pi and radiation detector board, for example. These are off-the-shelf parts that have to fit in the box no matter what, and start to dictate the size of the final unit.</p>

<p>Almost all other parts are completely hand made, machined and fabricated. This was necessitated by the desire to make everything authentic; I didn’t want to build things just for looks, I wanted any design choices made for aesthetic reasons to also be functional; by this I mean when I put 18 screws in something to make it look good, they are going to be 18 <em>real</em> screws that you have to take out to gain access!</p>

<p><strong>NOTE:</strong> Each of the build log images link to a separate gallery when clicked. You can look through the images that way if you prefer, or read on in full detail.</p>

<h3 id="thefrontpanelspanidpanelspan">The front panel <span id="panel"></span></h3>

<p>I started with the front panel of the housing, I knew I wanted two toggle switches; one for power and one for sound (to disable the clicking noise), along with 3 nixie tubes to display the CPM up to 999. Normal background radiation is in the range of about 25-75 CPM, so I figured if background radiation is above 999 CPM, we have bigger problems than worrying about enough digits on the counter.</p>



<p>The two front panel pieces are made from 6mm thick mild steel plate, cut to size with an angle grinder and then milled to dimension with the help of Bridget, the Bridgeport. Holes are then cut for the nixies and the toggle switches.</p>



<p>I manufactured labels for each by hand-punching lettering into 0.5mm thick brass sheet, polishing and fixing with M2 screws. The steel pieces are coated with a clear lacquer to prevent corrosion.</p>

<h3 id="workingwithwoodspanidwoodspan">Working with wood <span id="wood"></span></h3>

<p>Wood isn’t my favourite material to work with, I mean it just changes shape of its own accord! Who can work with that?! Anyhow, it’s very pretty, and so it was decided that the outer box should be made of hardwood. I started with a scrap piece of mahogany, cut it to halve the thickness on the bandsaw, and then set about planing and shaping the sides of the box to fit the dimensions of the Raspberry Pi (3A+) and the radiation detector.</p>



<p>The dimensions of the front panel along with the steel faceplates were planned out in Fusion 360 so that I could print a cutting and drilling template. This was taped onto the planed piece of mahogany, the holes for screws were drilled, and the openings for components cut out.</p>



<p>The pieces were cut at 45 degree angles to enable a mitre joint in each corner. The joints were reinforced with biscuits (mmm biscuits), and then the 4 sides were glued and clamped and allowed to cure overnight.</p>



<p>The top and bottom of the case are made from the same scrap mahogany, but planed a lot thinner - approximately 6mm, the same as the steel plate.</p>

<h3 id="topbrassspanidbrassspan">Top brass <span id="brass"></span></h3>

<p>I had the idea that it would look good to hold the box together with a totally unnecessary amount of screws, 36 to be exact; 18 on top and 18 on the bottom. To prevent the screws damaging the wood surface and to add some extra detail to the top of the case I decided to make a brass plate that the screws all go through to clamp the top cover down.</p>



<p>Some pieces of 2mm brass strip were cut, mitred on the corners and soldered together. Once soldered, sanded and polished, the joints are barely visible.</p>



<p>Holes for screws were then drilled, and the brass plate used to secure the oversize lid to the box whilst it was sanded to size on a drum sander. I later learned that using a drum sander for this was a mistake as it marked the sides of the box, but you live and learn!</p>

<div>  
    <p><img src="https://www.balena.io/blog/content/images/2020/07/top-brass-7.jpg" onclick="openModal();currentSlide(22)"></p><figure>  
Finished case and lid woodwork with brass frame temporarily fitted  
</figure>

</div>

<h3 id="imitationdekatronsspaniddekatronsspan">Imitation Dekatrons <span id="dekatrons"></span></h3>

<p>My attempt at imitating the Dekatron tube effect starts with a piece of 50mm stainless steel (or aluminium) bar. The bar is turned on a lathe down to 40mm, and to have a cavity for the electronics. The work is removed from the lathe and parted off on a bandsaw before being returned to the lathe to have a hole drilled in the rear for cabling to drive the LEDs.</p>



<p>The part is then put on the milling machine to have 10 holes drilled and M2 <del>taps snapped off in the holes</del> threaded ready to fasten the faceplate.</p>



<p>The brass faceplate is made from the same 0.5mm thick brass sheet as the labels from the faceplates. Each piece is drilled with 20 holes (10 for LEDs, 10 for fasteners), and then hand stamped with the numbering for each LED.</p>

<div>  
    <p><img src="https://www.balena.io/blog/content/images/2020/07/dekatrons-7.jpg" onclick="openModal();currentSlide(29)"></p><figure>  
The wired LED faceplate ready to be screwed into the housing.  
</figure>  
</div>

<p>The LEDs are wired with a common ground and connected using a piece of recycled floppy disk drive ribbon cable. All the work is then carried out a second time for the ‘X10’ display. The eagle-eyed readers will notice that the second display is made from a different material than the first - this is due to the fact I snapped both a drill bit and a tap off in the M2 holes - working with stainless steel with these small tools is very difficult! I ended up making the second from aluminium, which machines like butter, in comparison.</p>



<p>Throughout the development of this project I found myself continually swapping fasteners and trying different combinations to see what looks best. The end result is a mix of M2 and M3 metric machine screws in both brass and stainless steel, cheese head and countersunk head, all slotted. You may notice that in earlier photos some of the parts were assembled with Allen-head cap screws but these were later swapped out. Ebay is usually a great place to get small quantities of fasteners of all different shapes and sizes.</p>

<div>  
    <p><img src="https://www.balena.io/blog/content/images/2020/07/screws.jpg" onclick="openModal();currentSlide(30)"></p><figure>  
A mix of fastener types used for this project - various M3 and M2 machine screws.  
</figure>  
</div>

<p>The wood screws used for the top and …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/">https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/</a></em></p>]]>
            </description>
            <link>https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23756964</guid>
            <pubDate>Tue, 07 Jul 2020 08:33:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Want to start a business? Try not to do it alone]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23756790">thread link</a>) | @root993
<br/>
July 7, 2020 | https://www.sankalpjonna.com/posts/want-to-start-a-business-try-not-to-do-it-alone | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/want-to-start-a-business-try-not-to-do-it-alone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It is no secret that building and running a business is not easy no matter how small or big it may be. There are a huge number of obstacles that one has to overcome, but while building<a href="http://superlemon.xyz/"> </a>this <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">Shopify WhatsApp app</a> with my co-founder Preetam, I realised that all the obstacles become significantly easier to overcome when you are not in it alone.&nbsp;</p><p>‍</p><p>To be clear, I have tremendous respect for solo founders. These guys undertake a very lonely journey where nobody else can relate to their problems or achievements for that matter. When you have a bad day, you can't really explain it to someone because the feeling is unique to your situation and when you reach a milestone, you can probably celebrate it with your friends and loved ones but they would never truly understand how big a deal it is for you to have achieved that milestone.&nbsp; So I just want to give a shout out to all the solo founders out there and encourage them to keep crushing it in life.</p><p>‍</p><div><p>Having said this, I would now like to highlight some advantages of starting a business with at least one other person.&nbsp;</p><p><strong>‍</strong></p></div><p><strong>Accountability</strong>‍</p><p>‍</p><p>It is safe to assume that a person who quits their job and lives off of their savings in order to take on the challenge of building a business is dedicated and driven but this does not make them immune from laziness. In fact if your business starts showing some amount of success, it is even more likely that you might slack off because you no longer have to worry about paying the bills or making rent because you have revenue coming in to take care of that. So that fire that kept you on your toes is gone.&nbsp;<br>‍</p><p>Even if you don’t slack off for a single day of your life, you are still human and are capable of making mistakes. Mistakes that don’t have any redemption because only you get affected by the mistake.</p><p>‍</p><p>Having a partner who is just as vested into the venture as you are changes this. You are now accountable to each other and have somebody to answer to when you slack off or make a mistake. This might sound very counterintuitive because the reason why people start businesses is to not have anyone to answer to. But I have found during my journey that this is not always a bad thing and it is actually essential sometimes.<strong>‍</strong></p><p>‍</p><p><strong>Productivity</strong>‍</p><p>‍</p><p>When you start a business there are many skills that you may have to learn based on what domain your business is in. For instance when we started<a href="http://superlemon.xyz/"> </a>our <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">Shopify application</a>, we needed to know Product design, Front-end tech, back-end tech, marketing and distribution, landing page design and customer support. Now obviously if you are a solo founder you could argue that you could hire people for doing all of this but the truth of the matter is that even if you hire people to delegate a job, you still need to have some amount of understanding about that job so that you can hire the right people for the job and gauge whether your employee is performing well or not. In other words you have to learn many skills from scratch.</p><p>‍</p><p>If one person were to learn all of these skills, it would take a lot more time and mental bandwidth than dividing those skills amongst two people who will then nail all the aspects of the business that they are responsible for. It is therefore very important to choose a business partner who has an affinity to the skills that complement your own. This is easier said than done but I would say it is worth spending time just to find a partner that compliments your skills instead of being of the mindset that it would be a waste of time to do so.<strong>‍</strong></p><p>‍</p><p><strong>Moral support</strong>‍</p><p>‍</p><p>Oftentimes founders might find themselves in a situation where they face a problem that only they can solve and they aren’t sure how to do it yet. During such times it is very easy to go down a spiral of thoughts which might convince you that nobody is coming to help you and you are on your own so you are pretty much screwed. During such times it greatly helps if somebody that stands to lose the same thing that you do if you don’t solve the problem tells you that it is going to be okay.&nbsp;</p><p>‍</p><p>This is what my dynamic is like with my co-founder. If he screws up or feels down due to some factor that we had no control over, I tell him that we will live through this and if I screw up, he tells me it is going to be okay. This simple aspect can actually help a lot with maintaining the morale and moving forward despite facing something that might seem like the end of the world at that point of time.<strong>‍</strong></p><p>‍</p><p><strong>Happiness multiplies when you achieve a milestone</strong>‍</p><p>‍</p><p>When you build a business the only way for the outside world to gauge whether you achieved a milestone or not is based on how much money you are making, but for the people involved in building the business, there are a ton of non monetary achievements that give you happiness.&nbsp;</p><p>‍</p><p>For instance when we started out, our product was free for a while but we were gaining a lot of users every day and collecting feedback on what features they would be willing to pay for. This process was a magical time for us and we were the only ones who were capable of deriving happiness out of it. This happiness cannot really be shared with someone not involved in the business because they would not be able to relate to the feeling of talking to a customer from another country using google translate and understanding what their needs were and how we can solve them.<strong>‍</strong></p><p>‍</p><p><strong>Closing notes</strong>‍</p><p>‍</p><p>Someone once said to me that life is all about the people you meet and the things you build together. I genuinely believe this to be true and I would urge aspiring Entrepreneurs to make a full hearted attempt to find a business partner that aligns with your vision. I would also strongly suggest not to be hasty while finding a partner because working with a bad business partner is way worse than working alone and this is something that I experienced with my previous failed venture.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/want-to-start-a-business-try-not-to-do-it-alone</link>
            <guid isPermaLink="false">hacker-news-small-sites-23756790</guid>
            <pubDate>Tue, 07 Jul 2020 08:03:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unitaskers: Introduction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23756664">thread link</a>) | @nonoesp
<br/>
July 7, 2020 | https://sketch.nono.ma/unitaskers-intro | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/unitaskers-intro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <div>

     

    <p><img src="https://nono.imgix.net/img/u/sketch-nono-ma.svg?ixlib=php-3.3.0">

            <img src="https://nono.imgix.net/img/u/sketch-200707-panaderos-sapiens-book-spanish-color.jpg?auto=format%2Ccompress&amp;ixlib=php-3.3.0&amp;w=2500"></p>

    <p>This piece is an introduction a new series—called <em>Unitaskers</em>—that will feature single-purpose artifacts that let you do one thing.</p>
<p>Think, for instance, of a graphite pencil. It's useful to write or draw. You can sharpen it to get thin lines or tilt it to get thicker, faded strokes. You can write a letter or draw a house. You can trace continuous lines or do pointillism. But there isn't much more you can do with it.</p>
<p>In the opposite spectrum are your computer or your smartphone—they can virtually do anything, from drawing and writing to setting an alarm, sending emails, but they make doing something with focus harder than ever before.</p>
<p>How does your thought process change when you write with pencil and paper instead of typing on your laptop? When you read a book on Kindle instead of reading on your tablet? When you capture audio notes with a hand-recorder instead of using your phone?</p>
<p>Let’s find out.</p>
<p>Each essay of the series will use an object (or family of objects) as a source of inspirations to share stories and facts around finding focus in our age of distraction.</p>


  </div>



  </div><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<!-- <p class="u-font-size--g u-opacity--high u-text-align--center">
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p> -->
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Martínez Alonso.">
</p>


      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/unitaskers-intro</link>
            <guid isPermaLink="false">hacker-news-small-sites-23756664</guid>
            <pubDate>Tue, 07 Jul 2020 07:40:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is the Best Monitor Size for Gaming?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23756614">thread link</a>) | @amryoussif
<br/>
July 7, 2020 | https://thegamingexperts.com/what-is-the-best-monitor-size-for-gaming/ | <a href="https://web.archive.org/web/*/https://thegamingexperts.com/what-is-the-best-monitor-size-for-gaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div super-socializer-data-href="https://thegamingexperts.com/what-is-the-best-monitor-size-for-gaming/"><p>Share and Spread the love</p><ul><li><i alt="Facebook" title="Facebook" onclick="theChampPopup(&quot;https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fthegamingexperts.com%2Fwhat-is-the-best-monitor-size-for-gaming%2F&quot;)"><ss></ss></i></li><li><i alt="Twitter" title="Twitter" onclick="theChampPopup(&quot;http://twitter.com/intent/tweet?text=What%20is%20the%20Best%20Monitor%20Size%20for%20Gaming%3F&amp;url=https%3A%2F%2Fthegamingexperts.com%2Fwhat-is-the-best-monitor-size-for-gaming%2F&quot;)"><ss></ss></i></li><li><i alt="Instagram" title="Instagram"><a href="https://www.instagram.com/" target="_blank"><ss></ss></a></i></li><li><i alt="Pinterest" title="Pinterest" onclick="javascript:void((function() {var e=document.createElement('script' );e.setAttribute('type','text/javascript' );e.setAttribute('charset','UTF-8' );e.setAttribute('src','//assets.pinterest.com/js/pinmarklet.js?r='+Math.random()*99999999);document.body.appendChild(e)})());"><ss></ss></i></li><li><i alt="Reddit" title="Reddit" onclick="theChampPopup(&quot;http://reddit.com/submit?url=https%3A%2F%2Fthegamingexperts.com%2Fwhat-is-the-best-monitor-size-for-gaming%2F&amp;title=What%20is%20the%20Best%20Monitor%20Size%20for%20Gaming%3F&quot;)"><ss></ss></i></li></ul></div><hr><p>When you’re shopping for a TV, choosing the screen’s size is quite simple: the larger, the better.&nbsp;</p><p>However, choosing your monitor’s size can be challenging. Gamers need to be following up with the entire picture, so they must sit up close to the screen.&nbsp;</p><p>If the screen is too wide, gamers would lose focus and suffer through eye fatigue. On the other hand, if the screen is too small, they might miss some crucial details, causing them to lose their game.</p><p>In this article, you’ll know how to choose the best screen size based on your viewing distance and preferred resolution. Make sure you don’t miss it!</p><h2>Short Answer</h2><p>If you have a short viewing distance, a 24-inch monitor with a 1080p display is your go-to option. If you enjoy a bit longer viewing distance, you can opt for a 27-inch screen with a 1440p resolution.</p><h2>Aspects to Consider</h2><p>You should consider two things when picking the best screen size: viewing distance and screen’s resolution.</p><h3>Viewing Distance</h3><p>You may ask: “how can the viewing distance affect your gaming experience?”</p><p>It’d be best if you adjust the screen size to your home-gaming setup.&nbsp;</p><p>If you’re a competitive gamer, you need to be about 3-feet away from your screen to enjoy an excellent gaming experience. With such a short distance, your best option is a 24-inch screen. Otherwise, choosing larger options will put a lot of strain on your eyes.</p><h3>Resolution</h3><p>Resolution is one of the essential aspects for pro gamers because if it weren’t good enough, they wouldn’t have that mind-blowing gaming experience, which makes them feel like the main characters of the game.</p><p>Another rule of choosing a monitor’s size is that large screens should have high resolution.</p><p>For instance, if you had a suitable viewing distance and decided to buy a 34-inch screen, the resolution shouldn’t be less than 4k (full HD).</p><p>Also, if you choose a 24-inch display, it’s not recommended that you go for a 4k resolution because the high resolution will slow down the game, as it’ll be too heavy on the graphic card.</p><h2>The Best Monitor Size for Gaming</h2><h3>21-inch Monitors</h3><div><figure><img src="https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors.png" alt="" srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors.png 284w, https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors-24x15.png 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors-36x22.png 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors-48x30.png 48w" sizes="(max-width: 284px) 100vw, 284px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors.png 284w, https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors-24x15.png 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors-36x22.png 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors-48x30.png 48w" data-lazy-src="https://thegamingexperts.com/wp-content/uploads/2020/07/21-inch-Monitors.png"></figure></div><p>As a beginner, you won’t mind settling for such a small screen, but when things get heated, you’ll want more.&nbsp;</p><p>If you possess a 21-inch screen, you should sit less than 3-feet away. Most of these screens come with a 1080p resolution, which will give you a good display, yet it might bring down the refresh rate and responsiveness, leading to your loss.</p><p>The best thing about 21-inch monitors is that you can get them at $100, like the BenQ GW2280 and the HP 22ER monitors.</p><h3>24-inch Monitors</h3><div><figure><img src="https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch.jpg" alt="" width="435" height="246" srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch.jpg 693w, https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch-300x169.jpg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch-24x14.jpg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch-36x20.jpg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch-48x27.jpg 48w" sizes="(max-width: 435px) 100vw, 435px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20435%20246'%3E%3C/svg%3E" data-lazy-srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch.jpg 693w, https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch-300x169.jpg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch-24x14.jpg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch-36x20.jpg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch-48x27.jpg 48w" data-lazy-src="https://thegamingexperts.com/wp-content/uploads/2020/07/24-25-Inch.jpg"></figure></div><p>If you’re a desk-gamer and 3-feet away from your screen, a 24-inch gaming monitor will go perfectly with your home setup. It comes with 1080p-resolution and sometimes 1440p.&nbsp;</p><p>The ideal resolution for the 24-inch screen is 1080p, as a higher resolution might slow down the game. Also, most gamers describe this screen size as the most comfortable because they can visualize the entire screen.</p><p>The 24-inch screen is suitable for viewing the on-screen mini-maps, which don’t require much productivity.</p><p>You might find 24-inch screens that support 4k full HD, but at that moment, you need to remember our golden rule: “when the resolution is too high, the responsiveness is too low.”</p><h3>27-inch Monitors</h3><div><figure><img src="https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1.jpg" alt="" width="409" height="270" srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1.jpg 1024w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-300x199.jpg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-768x509.jpg 768w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-24x16.jpg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-36x24.jpg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-48x32.jpg 48w" sizes="(max-width: 409px) 100vw, 409px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20409%20270'%3E%3C/svg%3E" data-lazy-srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1.jpg 1024w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-300x199.jpg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-768x509.jpg 768w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-24x16.jpg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-36x24.jpg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1-48x32.jpg 48w" data-lazy-src="https://thegamingexperts.com/wp-content/uploads/2020/07/best-27-inch-monitor-1.jpg"></figure></div><p>The QHD screen of the 27-inch gaming monitors is the sweet spot for many pro gamers. If you get one, try to sit about 3 to 4-feet away from the screen to visualize the entire image. If you sat closer than 3-feet, you wouldn’t be able to follow up with the game events.</p><p>Many monitors supporting the 1440p resolution come with a 144-Hz refresh rate, which is good enough to play games like The Witcher 3 without causing any latency.&nbsp;</p><p>27-inch screens can support 4k, but it’s too heavy on the graphics card, causing lower refresh rates.&nbsp;&nbsp;</p><h3>32-inch Monitors</h3><div><figure><img src="https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor.jpg" alt="" width="433" height="243" srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor.jpg 390w, https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor-300x168.jpg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor-24x13.jpg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor-36x20.jpg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor-48x27.jpg 48w" sizes="(max-width: 433px) 100vw, 433px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20433%20243'%3E%3C/svg%3E" data-lazy-srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor.jpg 390w, https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor-300x168.jpg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor-24x13.jpg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor-36x20.jpg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor-48x27.jpg 48w" data-lazy-src="https://thegamingexperts.com/wp-content/uploads/2020/07/28-32-Inch-Gaming-Monitor.jpg"></figure></div><p>If you plan to go for a 32-inch screen, you should know that you might need to hang it up, as you can’t be closer than 5-feet to this screen.&nbsp;</p><p>32-inch screens have 4k resolution with relatively high refresh rates, offering you high-quality gaming experience. Moreover, the screen is big enough to allow multiplayer games.</p><p>Professional gamers do not recommend buying a 32-inch display with a 1080p resolution because the pixelated image is a bit distracting to human eyes.</p><p>Nevertheless, sitting too close to the display drives the players to move their heads and eyes a lot, contributing to their fatigue.</p><h3>Ultra-Wide Monitors</h3><div><figure><img src="https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5.jpg" alt="" width="456" height="256" srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5.jpg 650w, https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5-300x169.jpg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5-24x14.jpg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5-36x20.jpg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5-48x27.jpg 48w" sizes="(max-width: 456px) 100vw, 456px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20456%20256'%3E%3C/svg%3E" data-lazy-srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5.jpg 650w, https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5-300x169.jpg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5-24x14.jpg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5-36x20.jpg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5-48x27.jpg 48w" data-lazy-src="https://thegamingexperts.com/wp-content/uploads/2020/07/Ultrawide-Screen-5.jpg"></figure></div><p>Ultra-wide monitors usually revolve around 34-inch displays, which are the best for high-productivity titles like racing games. With such a big screen, you can open several windows and play multiplayer games.</p><p>As the screen is large, try to sit a little further than usual. Furthermore, 34-inch monitors are large enough to allow some curvature in their display. The previous feature makes the players feel like they’re the hero of the game.</p><p>The screen resolution is as good as a 1080p 24-inch screen, which is about 109 PPI.</p><h3>Dual Monitors</h3><div><figure><img src="https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors.jpeg" alt="" width="420" height="313" srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors.jpeg 1000w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-300x224.jpeg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-768x574.jpeg 768w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-24x18.jpeg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-36x27.jpeg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-48x36.jpeg 48w" sizes="(max-width: 420px) 100vw, 420px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20420%20313'%3E%3C/svg%3E" data-lazy-srcset="https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors.jpeg 1000w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-300x224.jpeg 300w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-768x574.jpeg 768w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-24x18.jpeg 24w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-36x27.jpeg 36w, https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors-48x36.jpeg 48w" data-lazy-src="https://thegamingexperts.com/wp-content/uploads/2020/07/Dual-Monitors.jpeg"></figure></div><p>Having dual monitors makes a lot of sense if you want to open a lot of tabs at the same time. It best suits designers and programmers, but I’m not sure if it’s a viable option for professional gamers.</p><div><p>Gamers need to be focused at all times and picture the entire game, but multiple screens will be a distraction, as they will need to move their eyes and heads to keep all monitors within their sight range.</p><p>If you want to open several windows while playing, consider a large screen with a reliable processor, not dual monitors.</p></div><h2>Final Thoughts</h2><p>There’s no such thing as a perfect screen size because there’s a lot of variables in this equation.</p><p>Firstly, you need to match your options with your budget.&nbsp;</p><p>Secondly, if you’ll be placing the screen on a desk, then a 24-inch display with 1080p resolution is your best option because of the short viewing distance. As your viewing distance gets longer, you can opt for a larger screen.</p><p>Finally, you’ve to choose a better resolution if you want to buy a large screen without negatively impacting your response times and refresh rates.</p></div></div>]]>
            </description>
            <link>https://thegamingexperts.com/what-is-the-best-monitor-size-for-gaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23756614</guid>
            <pubDate>Tue, 07 Jul 2020 07:31:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Qubit and Bloch Sphere]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23756377">thread link</a>) | @keyboardman
<br/>
July 6, 2020 | https://leimao.github.io/blog/Qubit-Bloch-Sphere/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Qubit-Bloch-Sphere/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>A quantum bit or a qubit is a unit of information describing a two-dimensional quantum system. It is also a key basic unit to the quantum computer. Usually it could be visualized using a Bloch sphere.</p>



<p>In this blog post, I would like to derive the connections between qubit and Bloch sphere.</p>

<h3 id="classical-bit">Classical Bit</h3>

<p>A classical bit is a unit of information describing a two-dimensional classical system. A classical bit could only be in one state, either $| 0 \rangle$ or $| 1 \rangle$. $| 0 \rangle$ and $| 1 \rangle$ are orthogonal basis. Usually $| 0 \rangle = [1, 0]^{\top}$ and $| 1 \rangle = [0, 1]^{\top}$.</p>

<h3 id="quantum-bit-qubit">Quantum Bit (Qubit)</h3>

<p>A quantum bit or a qubit is a unit of information describing a two-dimensional quantum system. A qubit is a superposition of two basic states, $| 0 \rangle$ and $| 1 \rangle$.</p>



<p>A generic (normalized) qubit is of the form</p>



<p>where $c_0$ and $c_1$ are complex numbers, and $|c_0|^2 + |c_1|^2 = 1$. After taking the measurement for $| \psi \rangle$, the system would be collapsed to $| 0 \rangle$ with probability $|c_0|^2$ or $| 1 \rangle$ with probability $|c_1|^2$.</p>



<p>A complex number could be described using <a href="https://leimao.github.io/blog/Complex-Number-Representations/">exponential form</a>.</p>



<p>Where $\rho_0$ and $\rho_1$ are real numbers. Therefore,</p>



<p>We could rewrite $\rho_0$ and $\rho_1$ using a new parameter $\frac{\theta}{2}$. We would see why we used $\frac{\theta}{2}$ instead of $\theta$ shortly.</p>



<p>We multiple a complex number $e^{-i\theta_0}$ to $| \psi \rangle$.</p>



<p>We define $\varphi = \theta_1 - \theta_0$, we have</p>



<p>As we have discussed early in <a href="https://leimao.github.io/blog/Quantum-System-States/">quantum system states</a>, quantum system state $| \psi \rangle$ and $c | \psi \rangle$, where $c$ is any non-zero complex number, represent the same quantum system state. Since $e^{-i\theta_0}$ is a non-zero complex number, $| \psi \rangle$ and $e^{-i\theta_0} | \psi \rangle$ represent the same quantum system state. So we have</p>



<p>This means that, with two parameters $\theta$ and $\varphi$, we could determine a qubit state.</p>



<p>The next question is what is the minimum range of $\theta$ and $\varphi$ so that all the possible qubit states, $| \psi \rangle \in \mathbb{C}^2$s, are included? After taking the measurement of the qubit, the probability of observing $| 0 \rangle$ is $\cos^2 \frac{\theta}{2}$ and the probability of observing $| 1 \rangle$ is $\sin^2 \frac{\theta}{2}$. For different $\theta$s, if $\cos^2 \frac{\theta}{2}$s are the same, the qubit states, $| \psi \rangle$s, are also the same. Apparently, $0 \leq \frac{\theta}{2} \leq \frac{\pi}{2}$, i.e., $0 \leq \theta \leq \pi$. If $\theta$ is out of this range, there is always a way to convert the $\theta$ into the range of $[0, \pi]$ while keeping $\cos^2 \frac{\theta}{2}$ the same. For $\varphi$, there is not too much to say, $0 \leq \varphi &lt; 2\pi$.</p>



<p>To summarize, a qubit could be described using two independent variables.</p>



<p>Where $\theta \in [0, \pi]$ and $\varphi \in [0, 2\pi)$.</p>

<h3 id="bloch-sphere">Bloch Sphere</h3>

<p>In quantum mechanics and computing, the Bloch sphere is a geometrical representation of the pure state space of a two-level quantum mechanical system (qubit), named after the physicist Felix Bloch.</p>



<p>Given the two-variable qubit formulation we derived above, it could perfectly fit into the Bloch sphere.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-14-Qubit-Bloch-Sphere/Bloch_sphere.svg.png">
    <figcaption>Bloch Sphere</figcaption>
</figure>
</div>

<p>The north and south poles of the Bloch sphere are typically chosen to correspond to the standard basis vectors $ |0\rangle $ and $ |1\rangle $, respectively. Any coordinate, which could be uniquely described using $\theta$ and $\varphi$, on the sphere, represents a unique qubit.</p>



<p>It is also non-trivial to see that all the qubits on the equator, where $\theta = \frac{\pi}{2}$, have equal probability of collapsing to $ |0\rangle $ and $ |1\rangle $, because $p(|0\rangle) = \cos^2 \frac{\pi}{4} = \frac{1}{2}$ and $p(|1\rangle) = \sin^2 \frac{\pi}{4} = \frac{1}{2}$.</p>



<p>In addition, if the qubit is more closer to the north pole, there is larger chance to collapse to $ |0\rangle $ after taking the measurement. Similarly, if the qubit is more closer to the south pole, there is larger chance to collapse to $ |1\rangle $ after taking the measurement.</p>



<p>Moreover, an arbitrary pair of orthogonal qubits is mapped to antipodal (opposite) points of the Bloch sphere. This is because, any antipodal qubits have the following representations.</p>



<p>We would like to show that $\langle \psi , \psi^{\prime} \rangle = 0$ so that $| \psi \rangle $ and $| \psi^{\prime} \rangle$ are orthogonal.</p>



<p>This concludes the proof.</p>



<p>Last but not least, to answer why we had used $\frac{\theta}{2}$ instead of $\theta$ in the qubit representation, it is because we want to make the qubit representation compatible with the Bloch sphere. If using $\frac{\theta}{2}$, $\theta \in [0, \pi]$ in the Bloch sphere matches $\theta \in [0, \pi]$ in the qubit representation.</p>

<h3 id="manipulate-qubit-on-bloch-sphere">Manipulate Qubit on Bloch Sphere</h3>

<p>As we have partially shown in <a href="https://leimao.github.io/blog/Kronecker-Product-In-Circuits/">one of my previous posts</a>, all the classical logical gates could be considered as matrices, and all the classical bit manipulations are matrix multiplications. This also applies to quantum logical gates and qubits. Actually, all the quantum logical gates are unitary matrices. We would take this fact for now and I would probably explain this in my future blog posts.</p>



<p>Matrix $U$ is unitary if and only if</p>



<p>Unitary matrix preserves inner products. If $U$ is unitary, then for any $v, v^{\prime} \in \mathbb{C}^{n}$, we have $\langle Uv, Uv^{\prime} \rangle = \langle v, v^{\prime} \rangle$.</p>



<p>This could be easily proved by using the <a href="https://leimao.github.io/blog/Inner-Product/">inner product properties</a>.</p>



<p>This means that unitary matrix $U$ also preserves the norm of any vector $v \in \mathbb{C}^{n}$.</p>



<p>Suppose we have a qubit $| \psi \rangle$ and unitary matrix $U$. Because $| \psi | = 1$, so $| U\psi | = 1$. In addition, given the orthogonal basis $|0\rangle$ and $|1\rangle$, because $\langle |0\rangle, |1\rangle \rangle = 1$, so $ \langle U|0\rangle, U |1\rangle \rangle = 1$. This means that $U|0\rangle$ and $U|1\rangle$ are a new pair of orthogonal basis.</p>



<p>On the Bloch sphere, applying a unitary matrix $U$ to qubit $| \psi \rangle$ is equivalent to moving the coordinate of the qubit on the Block sphere, since unitary matrix preserves the norm of vector. Apply a unitary matrix $U$ to both $|0\rangle$ and $|1\rangle$ is equivalent to rotate the north and south poles, i.e. the coordinate system, accordingly.</p>



<p>If we look into $| U \psi \rangle$ more closely.</p>



<p>Since $U|0\rangle$ and $U|1\rangle$ are also orthogonal basis, manipulating qubit is also equivalent to manipulating the entire coordinate system. The coordinates of $| U \psi \rangle$ in the new coordinate system ($U|0\rangle$, $U|1\rangle$) is the same to the coordinates of $| \psi \rangle$ in the old coordinate system ($|0\rangle$, $|1\rangle$).</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://leimao.github.io/blog/Complex-Number-Representations/">Complex Number Representations</a></li>
  <li><a href="https://leimao.github.io/blog/Quantum-System-States/">Quantum System States</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Bloch_sphere">Bloch Sphere - Wikipedia</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Qubit-Bloch-Sphere/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23756377</guid>
            <pubDate>Tue, 07 Jul 2020 06:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Zed Shaw Phenomenon: A Look at Bullies in Tech]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23756105">thread link</a>) | @pcr910303
<br/>
July 6, 2020 | https://wilkie.how/posts/the-zed-shaw-phenomenon | <a href="https://web.archive.org/web/*/https://wilkie.how/posts/the-zed-shaw-phenomenon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://wilkie.how/posts/the-zed-shaw-phenomenon</link>
            <guid isPermaLink="false">hacker-news-small-sites-23756105</guid>
            <pubDate>Tue, 07 Jul 2020 05:49:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2019: The year when (as CEO) I crashed, burned and cried]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23756074">thread link</a>) | @boffinism
<br/>
July 6, 2020 | http://www.pavelsima.cz/blog/2019-the-year-when-as-ceo-i-crashed-burned-and-cried | <a href="https://web.archive.org/web/*/http://www.pavelsima.cz/blog/2019-the-year-when-as-ceo-i-crashed-burned-and-cried">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-6140b52a4b13c5c4e1be"><div><div><p>In 2016, I voluntarily quit a very well paying job and set out to build a start-up. I cut all other activities - stopped producing my podcasts, promoting my book and doing other freelance work - and threw myself fully into <strong>a new mission: to build a billion crown (CZK) company</strong>.&nbsp;</p></div><div><p>Not only did I burn all of my bridges and put all my eggs into one basket, I also went into personal debt well over a million to finance the young and fragile company, at the time it all seemed worth it.</p></div><p>There was excitement, there was novelty, there was challenge. During the first years, the number of clients, colleagues, and revenue kept rising, the world started noticing us, we signed big brands, won awards and even raised a bunch of money.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594048680923_30945"><div><p>It was all sunshine and unicorns.<br></p><p>Until it wasn't.<br></p><p>Feeling that there was no time to waste, I pushed for rapid international expansion immediately after our September 2018 fundraise.&nbsp;<br></p><p>In the blink of an eye, the team doubled in size: we hired senior (expensive) managers and a local sales team in London (even more expensive) in order to take the UK market by storm.<br></p><p>In support of the sales effort, I was frequently flying to London. I would even do round trips - fly to London in the morning, attend two client pitches and be back in Prague by night. Using low budget airlines that had frequent delays, I found myself leaving the house before 6 AM and coming back at 1 the next morning. I would work the whole time on the train, at the airport and sometimes even on the cab ride back home. Consequently, my mind was rushing with thoughts and I couldn't fall asleep despite the exhaustion.</p><p>Sometimes, I'd miss my return flight. I'd be forced to stay the night in an airport hotel and show up to work the next day in Prague wearing day old clothes.</p><p>At the same time, we were trying to enter Polish and Romanian markets. Once in a four day span I managed to cover Prague --&gt; London --&gt; Warsaw --&gt; Manchester --&gt; Bucharest --&gt; Prague. Frequent flyer miles aside, I began to question whether it was still fun arriving at my hotel in Bucharest at 2AM only to find a colleague waiting for me to rehearse the next day's presentation.<br></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594048680923_15646"><div><div><p><em>Life of a start-up CEO  -  pitching, traveling and more pitching… managing the company in between whenever you steal the moment<br></em></p></div><h2><strong>Cracks begin to show</strong></h2><p>I love sleeping and hate early starts, so I was beginning to run on reserves.&nbsp;<br></p><p>Six months into our UK adventure we still had not closed any clients.</p><div><p>We were burning cash like crazy. Some months we were spending 3-4 times the revenue we were bringing in and serious worries started to emerge that we would not hit the targets we needed to hit to acquire another tranche of investment. The fear of running out of cash and going bust grew larger as weeks flew by.</p></div><div><p>What was worse there were underlying tensions between co-founders with totally opposite views of what the product should do and to whom should we sell to. Some pushed for enterprise, others for mid-sized e-commerce clientele with a wildly different customer and feature sets in mind. As we couldn't convince each other rival camps started to emerge within the company.</p></div><p>In spring 2019, when we received definite word that our seed-round investors would not chip in any more funds we needed to scramble to close another round of funding elsewhere. We managed to find two funds who loved our tech and team and could theoretically extend our runway by another year. "Just enough time to break into the UK market and turn things around" I thought.</p><p>It was April when even these new investors pulled out of the deal. I was left with only two choices: either cut costs by two-thirds or go out of business.&nbsp;</p><p>Just eight months after an incredible rush of positivity, great publicity and lots of enthusiasm and new energy to build business, I found myself:<br></p><ol data-rte-list="default"><li><p>Exhausted from all the travelling, stress and hours needed to put in when you are trying to quickly scale up a company.</p></li><li><p>Deep in personal debt on a start-up salary that didn't even cover lease payments and my basic living expenses.</p></li><li><p>Weeks away from corporate bankruptcy.</p></li><li><p>Facing an internal mutiny with the opposing faction attempting to replace me as CEO.</p></li></ol><p>Basically, I was on the brink of losing everything - my business, my reputation, and all my money.</p><div><p>The same thing - our company - that I had already sacrificed so much for was now pushing me against the wall, making it all the more difficult to see a clear way out of the situation.</p></div><h2><strong>The night I cried</strong><br></h2><p>In May 2019, I finally had to face the inevitable. I needed to dump all expansion plans, cut the marketing budget to zero, and most regrettably reduce the team by half.&nbsp;</p><p>One morning, we flew the whole team to Prague for an all hands meeting. I had to come ou and break the dire news in front of everybody.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594048680923_34310"><div><p>The rest of the day I spent in one on one meetings telling colleagues who could stay and who had to go and how promptly.</p><p>I tried to help where I could, recommending my colleagues to other companies, even lending personal money to some who couldn't find new roles quickly enough.&nbsp;</p><p>Overall, the reaction of most of the team was better than I expected, but regardless, by the end of the meeting marathon I was drained to the bone marrow.</p><p>That night - for the first time in my life - I cried because of work.&nbsp;</p><p>I felt like a failure; a bad manager and CEO. I felt like I let a bunch of very good people down. I went through what was probably the lowest low I experienced in my whole life.</p><p>Thankfully, I have the best GF in the world. When I came home I found post-it notes all over our place with each stating one of my positive characters and skills.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594048680923_37476"><div><p>Through time, with her support and the support of our investors I was able to pull myself together, regroup and lead again.</p><h2><strong>All Bad Leads To Something Good In The End</strong></h2><p>During the year of 2019 I must have aged 5 years.&nbsp;</p><p>However, looking back, I now know it was one of the best things to happen to our company and one of the best managerial/entrepreneurial lessons I have ever received and things turned back to good pretty quickly:&nbsp;<br></p><ul data-rte-list="default"><li><p>In the end, our investors backed us with a bridge round of financing so that we wouldn't go bust.&nbsp;</p></li><li><p>We let go of the people who weren't bringing real value to the company.&nbsp;</p></li><li><p>We got rid of all the mutineers who were creating a toxic working environment and restored a positive team spirit.&nbsp;</p></li><li><p>We have learned that we could make the same revenue with half of the staff!</p></li><li><p>In September 2019 we - for the first time in the history of the company - broke even (turned to black numbers).&nbsp;</p></li><li><p>And we've been profitable ever since.&nbsp;</p></li></ul><h2>Never forget, it’s just a job</h2><p>We entered 2020 in great shape. We had record breaking revenue and profits, big strong prospects for future growth... only for COVID to throw us right back into the fire.<br></p><div><p>But that's fine and part of the fun. Most of all it is a different story I am not ready to tell just yet. We march on knowing that the deepest shit - seen from just a slightly different angle - is usually the biggest opportunity to come back stronger than before.</p></div><p>So why did I write this?</p><div><p>Why am I coming clean about my relatively fresh failures?</p></div><p>We all go out to the world every morning attempting to exorcise internal demons and navigate through and against external - and often adverse - forces.</p><p>In start-ups especially, we live in a highly pretentious and deformed version of reality filled with over-hyped expectations, fear of failure and goals we are trying to reach.</p><p>Last year, a Czech start-up founder, supposedly after failing to raise a decisive round of financing and having to face the terror of coming clean, made the tragic decision to take his own life.&nbsp;<br></p><p>A big human tragedy. And probably not an isolated case.</p><p>It gives one a pause. It's not just the death - that already had me at a loss for words, but just that I could empathize with what it's like. I was just in this same situation around the same time this person was and if I wasn't lucky enough to have the support system that I had... I can see how slippery this slope is.</p><p>To all start-up founders and anyone else who might be standing at the edge of the abyss I want to say this:<strong> You are not alone. I've been through this and so have many more people before us than we could ever imagine. Don't succumb to the PR of the (allegedly) successful few. And know that even when you fail, it can be the best thing to ever happen to you.</strong></p><p>To end this with a quote from my friend and a fellow founder/CEO know this:&nbsp;</p><p><em>In the end it's just a job. If the company goes away, the world won't shit its pants. In fact, it will be barely noticed. Things will go on. And so will your life.</em></p></div></div></div>]]>
            </description>
            <link>http://www.pavelsima.cz/blog/2019-the-year-when-as-ceo-i-crashed-burned-and-cried</link>
            <guid isPermaLink="false">hacker-news-small-sites-23756074</guid>
            <pubDate>Tue, 07 Jul 2020 05:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[War Story – hunting down a memory leak in a C++ application]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23755727">thread link</a>) | @wheresvic3
<br/>
July 6, 2020 | https://smalldata.tech/blog/2020/07/01/war-story-hunting-down-a-memory-leak-in-a-c++-application | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2020/07/01/war-story-hunting-down-a-memory-leak-in-a-c++-application">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://smalldata.tech/blog/2020/07/01/war-story-hunting-down-a-memory-leak-in-a-c++-application</link>
            <guid isPermaLink="false">hacker-news-small-sites-23755727</guid>
            <pubDate>Tue, 07 Jul 2020 04:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google offers free fabbing for 130nm open-source chips]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 104 (<a href="https://news.ycombinator.com/item?id=23755693">thread link</a>) | @tomcam
<br/>
July 6, 2020 | https://fossi-foundation.org/2020/06/30/skywater-pdk | <a href="https://web.archive.org/web/*/https://fossi-foundation.org/2020/06/30/skywater-pdk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Did you ever dream about creating your own chip?
I mean, a physical chip.
One which you can hold in your hand, and which does exactly what you’ve designed it to do?</p>

<p>Until today, there were two major road blocks: you had to get access to a process design kit (PDK) from a chip manufacturing house (a foundry), and you had to have enough money to actually pay for the manufacturing.
These times are over.
Today.</p>

<p>Today, in a FOSSi Dial-Up talk, Tim Ansell of Google announced <a href="https://github.com/google/skywater-pdk">SkyWater PDK</a>, the first manufacturable, open source <a href="https://en.wikipedia.org/wiki/Process_design_kit">process design kit</a>.
What differentiates this PDK from previous attempts is the fact that it is manufacturable: with this PDK, you can actually produce chips with the <a href="https://www.skywatertechnology.com/">SkyWater foundry</a> in the 130nm node.</p>

<p>That leaves you as chip designer only with one road block: money.
Manufacturing chips is expensive – even for more than a decade old nodes like the 130nm node, you need to spend at least a couple thousand dollars.</p>

<p>You know what?
Don’t worry – Google and efabless have got you covered!
They are providing <strong>completely free of cost</strong> chip manufacturing runs: one in November this year, and multiple more in 2021.
All open source chip designs qualify, no further strings attached!</p>

<p>Learn more about all of that by re-watching <a href="https://www.youtube.com/watch?v=EczW2IWdnOM">Tim’s Dial-Up talk</a> or click through the <a href="https://docs.google.com/presentation/d/e/2PACX-1vRtwZPc8ykkkgtUkHkoJZrP9jKOo3FYdKqbg-So0ic6_kx7ha1vHnxrWmuxWkTc9GfC8xl0TfEpMLwK/pub?start=false&amp;loop=false&amp;delayms=3000">slides</a>.</p>

<p>This is certainly a dream come true for us at the FOSSi Foundation.
We helped the Free and Open Source Silicon community, our community, grow and tackle huge challenges over the years.
An open, manufacturable PDK was the main blocker in a fully open flow between RTL and a physical chip, and we’re extremely excited to see that blocker removed.</p>

<p>As always, removing one roadblock only highlights more challenges:
RAM, ROM and flash compilers, analog blocks, optimizations to various tools, and much, much more.
Now is the perfect time to get involved in the Free and Open Source Silicon ecosystem – or learn more about the accomplishments and challenges ahead of us.
A good starting point are the next Dial-Up talks.</p>

<p>Head over to the <a href="https://fossi-foundation.org/dial-up/">Dial-Up web site</a> for a listing of the upcoming talks on OpenROAD, cell design, OpenRAM, and Magic, an old, but surprisingly up-to-date tool!
To stay up-to-date with the latest developments in the FOSSi ecosystem <a href="https://librecores.us17.list-manage.com/subscribe?u=5d525b453672149a60c198960&amp;id=1241c8638b">subscribe to El Correo Libre</a>, our monthly newsletter bringing all the important news bits directly to your inbox (or <a href="https://medium.com/librecores">read it online</a>).</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/EczW2IWdnOM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

  </div>

</article>

	</div></div>]]>
            </description>
            <link>https://fossi-foundation.org/2020/06/30/skywater-pdk</link>
            <guid isPermaLink="false">hacker-news-small-sites-23755693</guid>
            <pubDate>Tue, 07 Jul 2020 04:26:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Hire a CTO for a Startup?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23755623">thread link</a>) | @Headqq
<br/>
July 6, 2020 | https://www.purrweb.com/blog/how-to-hire-a-cto-for-a-startup/ | <a href="https://web.archive.org/web/*/https://www.purrweb.com/blog/how-to-hire-a-cto-for-a-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        

                          <p><i><span>I have a great idea for a startup. The only thing I’m still hesitating about is hiring a CTO. It’s particularly important for me because I don’t know the tech side. Outsourcing the technical part to an </span></i><a href="https://www.purrweb.com/"><i><span>MVP development agency</span></i></a><i><span> is one of the ways to check your idea, let’s look at the other.</span></i></p>
<p><span>Well, this article will answer the question.</span></p>
<h2>CTO as a part of MVP development team</h2>
<p>CTO (also known as Head of Engineering) is a person who is involved in making the most important technical decisions.&nbsp; They play a significant role in your project triumph since they decide on the tech stack used for the future product (suitable frameworks and technologies), plan the app infrastructure, and control the whole process of MVP development.</p>
<p>In general, a good CTO is a skilled developer with knowledge in programming that is just enough to create and launch MVP. If you find out how to hire a CTO for a startup, you won’t have to seek any other developers (at least at the very beginning).</p>
<h2>What exactly does CTO do at the MVP stage?</h2>
<p>We say, ‘a CTO is one of the most important parts of the MVP team’.&nbsp; Don’t you believe it? Let us justify this statement (and disclose to you how to hire a CTO for a startup).</p>
<p>To do this, we will touch on the steps of MVP development.</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-26-01.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-26-01.png" alt="How to hire a CTO for a startup?" width="3084" height="1417" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-26-01.png 3084w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-26-01-300x138.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-26-01-768x353.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-26-01-1024x470.png 1024w" sizes="(max-width: 3084px) 100vw, 3084px"></a></p>
<p>We’ll start by assembling a minimum MVP team. Based on the objectives given in the preceding paragraph, we need programmer and designer.</p>
<ul>
<li>Time to create a design concept</li>
</ul>
<p>Yet active sketching and wireframing is not really up to CTOs and it is the found designer who is responsible for generating a design concept, they still have control over the process. The CTO not only introduces the concept requirements to the designer and helps them understand the product vision but also makes sure the concept is technically feasible.</p>
<p>Yes, sometimes designers develop a beautiful concept that is not easy to accomplish because some aspects require sophisticated technologies. And you surely won’t be happy with the situation when you have to google something like ‘we’ve got a not technically feasible design concept. what to do with that?’, so let the CTO check it first.</p>
<ul>
<li>Go on with a prototype</li>
</ul>
<p>Even though prototype designs often don’t look anything like the final product, they require skilled and knowledgeable overwatching too. To consider all additional features and changes that the start-up plans to introduce over time (so that designers could think through the prototype, and developers could later include everything without changing the layout significantly) is part of the CTO’s duties too.</p>
<ul>
<li>Proceed with UI/UX design</li>
</ul>
<p>UI/UX design demands a forward-thinking approach. Here the head of engineering serves as the central point for technical decisions: they validate the complexity of the design realization and choose technologies.&nbsp; But prior to deciding on the tech stack, they conduct TFS (Technical Feasibility Scan): draw up a potential architecture, estimate the amount of work, and identify technical risks (such as scalability, complexity, or need for rare skills.</p>
<ul>
<li>Deep down in coding</li>
</ul>

<p>When the tech stack is chosen, the developer comes into play. Or not.&nbsp; If your CTO and your developer are the same person (which is more likely), it will still be the CTO.&nbsp; However, in case the CTO does not have all the skills or time for realization, they will enlist the help of a third party company or a freelancer. Tip for you: make sure you know how to hire a CTO for a startup before hiring an ineffective one.</p>
<ul>
<li>Make QA testing run in parallel</li>
</ul>
<p>Testing and coding come together. While the code is being written, the CTO begins checking the result. They are involved in so-called alpha testing conducted at the development stage and fixing bugs.</p>
<h2>How to hire a CTO for a startup?</h2>
<p>Let’s consider five common scenarios:</p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-4-eng-.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-4-eng-.png" alt="How to hire a CTO for a startup?" width="1400" height="680" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-4-eng-.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-4-eng--300x146.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-4-eng--768x373.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-4-eng--1024x497.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a></p>
<h3>I will do it all by myself</h3>
<p>On the one hand, you won’t need to hire a tech specialist, which will save you money. On the other hand: You won’t learn any programming language fast. According to the statistics, it takes about 3 months only to learn the BASICS of coding. You certainly can learn it faster (or slower) but it’s still a highly questionable matter since coding takes ‘a moment to learn, a lifetime to master’.</p>
<p>Besides, the average time for creating a complete MVP version including all the activities is 3 months. Is it really worth spending so much time on learning just one skill?</p>
<p>If you are an enthusiast who has an interest in learning coding and has no fear of facing difficulties, then it will be okay. However, if you are not, then you should think twice before setting about buying books and software development courses and downloading Visual Studio Code.</p>
<p>Let’s imagine you tried to learn a programming language.&nbsp; After several months of struggling you realize you don’t want it anymore. By ‘it’ we mean not only coding but also your project.</p>
<p>And, yes, there is no way competitors will wait for you. Time to market matters a lot, and if you don’t seize the occasion, it’ll be seized by someone else.</p>
<h3>Got a techie friend!&nbsp; He is ready to work for free and gonna take care of coding</h3>
<p>What can be better than working with your friend who you’ve known for many years?&nbsp; ‘Nothing’, some of you would say — well, this is a common misconception.</p>
<p>Do you think you can trust each other?&nbsp; It’s not going to be like this in business.&nbsp; Why? &nbsp; For everything is bound to get personal.</p>
<p>Once you trip over something relating to the project, you may have different points of view on it You would probably have to go through hours of disputes before coming to a mutual agreement.</p>
<p>There is always another thing: you would have quarrels about money and equity sharing. Matter of money is where the hell starts because your CTO may start thinking he/she does more than you. ‘It’d be better if I found out how to hire a CTO for a startup’, you are likely to yell.</p>

<p>Have you ever heard of Eduardo Saverin who was the Facebook co-founder? He no longer works there. Almost right after the website was launched, the relationship between co-founders began to fray: they couldn’t come to an understanding, and Zuckenberg cut his friend out of the company.</p>
<p>If you are sure your friend and you won’t get in a situation very similar to this, you can offer them to join your project.</p>
<h3>I will hire a first-class PRO CTO</h3>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-5-eng-.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-5-eng-.png" alt="How to hire a CTO for a startup?" width="1400" height="680" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-5-eng-.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-5-eng--300x146.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-5-eng--768x373.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-5-eng--1024x497.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a><span>How to hire a CTO for a startup? Lure in a pro, of course! (spoiler: no way)</span></p>
<p>In most cases, a first-time startup owner wants to hire an ‘all-in-one, best in the entire industry’ CTO: the person with strong programming and management skills, with a wealth of experience in commercially successful projects.</p>
<p>In fact, you can find such CTOs. Except that it’s likely that true pros already work in well-established companies, of course. Now let’s think a little bit: will a real pro be willing to barter away their position with a good salary in exchange for working with you and waiting for the day when a startup will become profitable? Hardly possible. If such CTOs are ready to leave their previous work behind, then it’s a question of competence.</p>
<p>Non-tech founders are especially susceptible to the idea of having an in-house associate due to a lack of experience in this sphere. But there’s actually no need to hire an in-house CTO for your startup at this stage. It’s much easier to get a professional who will run the technical side of your future product than to get them into your office.</p>
<h3>I heard something about freelancers</h3>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-9.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-9.png" alt="How to hire a CTO for a startup?" width="1400" height="680" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-9.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-9-300x146.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-9-768x373.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/Cover-9-1024x497.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a><span>There is always someone ready to do it cheaper</span></p>
<p>When hiring a freelancer, it is essential that you are not struck blind only with the price. It may be pretty attractive to get a good CTO for less but you can never be dead certain you’ll get a proper product.</p>
<p>Working with a freelancer is full of tricky points ‘cause freelance itself is unsteady. First, it’s a complicated task to find a needed person for non-techies.&nbsp; Yeah, you can see the portfolio which is obviously awesome but there is no way you may be one hundred percent sure this person knows all the technologies you need. With freelancers, it’s easy to underestimate the scope of work. Would you like to find out that you need to find one or even more programmers to hire in the middle of the MVP development process and go beyond the budget?</p>
<p>It’s okay for this market that a freelancer may leave you without even saying goodbye. They can easily drop working with your project if they win something more gainful for them. ☺</p>
<h3>Nah, I’m gonna outsource the technical part to an agency</h3>
<p>If you are still hesitating about finding a CTO for your startup, we find outsourcing to be the best solution for startups.</p>

<p>As you may know, there are companies focused on MVP development. And what will you get when outsourcing your project to such a company?</p>
<ul>
<li>Access to portfolios. That’s where studying ‘done’ projects makes sense.</li>
</ul>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/cover-6.png"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/cover-6.png" alt="How to hire a CTO for a startup?" width="1400" height="988" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/cover-6.png 1400w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/cover-6-300x212.png 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/cover-6-768x542.png 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/cover-6-1024x723.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></a><span>Check out projects relevant to the industry you plan to jump into</span></p>
<p>While developing a similar product outsourcers gained a lot of knowledge: found the biggest pain points, discovered possibilities and limitations on a particular market. These learnings allow them to deliver a truly working product satisfying customers’ needs, which makes outsourcing the best answer to ‘how to hire a CTO for a startup’.</p>
<ul>
<li>You receive competent advice on the tech-stack: if you don’t know which technology to choose — a company will tell you what’s on trend.</li>
<li>You get a team with deep expertise in smooth product implementation. Try to find guys who work in accordance with Agile principles and have time-proven tactics of design, development, and execution.</li>
<li>You have a project manager who will be the ‘nanny’ of the whole project.&nbsp; This person will not only take care of solving pop-up-problems but also bring together those who work with code and those who create a design.&nbsp; You won’t have to be in Zoom 24/7 and settle problems.</li>
<li>Your budget will be understood and the whole product backlog will be prioritized.&nbsp; As a result, the ‘done’ app will have thoroughly picked up features just …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.purrweb.com/blog/how-to-hire-a-cto-for-a-startup/">https://www.purrweb.com/blog/how-to-hire-a-cto-for-a-startup/</a></em></p>]]>
            </description>
            <link>https://www.purrweb.com/blog/how-to-hire-a-cto-for-a-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23755623</guid>
            <pubDate>Tue, 07 Jul 2020 04:15:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Faces of Microsoft (2017)]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23755238">thread link</a>) | @beefhash
<br/>
July 6, 2020 | https://www.typemag.org/post/the-faces-of-microsoft | <a href="https://web.archive.org/web/*/https://www.typemag.org/post/the-faces-of-microsoft">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

		
			<figure data-blockname="pull_quote">
				<p>‘Why do we need more fonts?’ asked Bill Gates. ‘We’ve got a	serif, a sans, and a monospace font. Why do we need more?’...</p>
				
			</figure>
			
			<header data-blockname="article_title">

				
				<h2><a href="https://www.typemag.org/category/3">History of type</a></h2>
				

				

				<p>The people and the rich story of type at the first big tech company.</p>

			</header>
			
			
			
			<figure data-blockname="single_image">
				<a data-lightbox="type-mag-slideshow" data-title="Steven Shaiman, the first program manager for type at Microsoft. He’s been on his own since 2010, living in the Pacific Northwest and working on family enterprises with his wife and five children." href="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-05-Shaiman-Steve-47.jpg"><img data-src="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-05-Shaiman-Steve-47.jpg" alt="" src="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-05-Shaiman-Steve-47.jpg"></a>
				
				<figcaption>Steven Shaiman, the first program manager for type at Microsoft. He’s been on his own since 2010, living in the Pacific Northwest and working on family enterprises with his wife and five children.</figcaption>
			</figure>
			
			<section data-blockname="body_copy">
				<p><span><img src="https://www.typemag.org/images/uploads/win31-datetime.png" alt="" height="300" width="300"></span>Gates was having an informal meeting with Steve Shaiman, a cheerful gnome of a man with a head of frizzy hair who was general manager of Microsoft’s hardware division, and with Raleigh Roark one of the two people who had started the division. They were talking about fonts and applications, especially Word.</p>

<p>Roark gave Gates his answer: For printers, basically. This was the era of desktop publishing and proliferating office applications, and users needed more than just the bitmapped system fonts on their computers to get their work done. Courier, Tms Rmn, and Helv were not going to be enough. </p>

<p>Bill Gates is known for asking hard questions, but also for accepting hard answers and acting on them. As soon as he got his answer, he pointed at Steve and told him: “Now you run type!”</p>

<p>That’s the way things worked at Microsoft in those days, says Shaiman: whoever knew the most about a subject tended to end up in charge of it. So he ended up starting Microsoft’s first fonts group. It was Spring, 1989.</p>
			</section>
			

			





			
			<section data-blockname="sub_heading_1">
				<h2>The conquest of TrueType</h2>
			</section>
			
			<section data-blockname="body_copy">
				<p><span><img src="https://www.typemag.org/images/uploads/win31-phone.png" alt="" height="300" width="300"></span>STEVE SHAIMAN was on a business trip to Atlanta with Nathan Myhrvold, Microsoft’s celebrated head of advanced technology, when they got an unexpected phone call. Myhrvold had with him a satellite phone—an early mobile phone, “which in those days,” as Shaiman put it, “meant something you’d carry in a suitcase.” The unexpected call was from Apple.</p>

<p>At that time, Adobe Systems dominated the digital font market, with its PostScript technology built into Apple’s LaserWriter printers, and with PostScript firmly established as the preferred format for high-quality fonts. Microsoft needed to find its own format and its own fonts if it didn’t want to be dependent on Adobe.</p>

<p>Like Microsoft, Apple was trying to find ways to license the PostScript language from Adobe, or to find an alternative. The Apple call was about font technology: Apple was developing its own font format, TrueType, as an alternative to PostScript, while Microsoft acquired a program called TrueImage, a potential PostScript clone, which Apple was interested in. How about a trade?</p>

<p>Shaiman says that his and Nathan Myhrvold’s reaction was immediate: “Sure!”</p>

<p>Ironically, once Microsoft got hold of TrueType, they loved the concept but didn’t like the way it was implemented. Although they ended up only making slight modifications to the version that shipped with Windows 3.1, when it came time for the next version of Windows, they ended up “throwing out Apple’s code and rewriting it from scratch.”</p>

<p>When Microsoft and Apple publicly announced their collaboration on TrueType at the Seybold conference in September 1989, the announcement was handled in a contentious and aggressive manner that antagonized Adobe and famously brought Adobe’s John Warnock to tears of frustration. Steve Shaiman feels now that it was a poor way to do it: “We couldn’t have done worse.” Although they were demonstrating what they felt was better technology, they made the mistake of shoving it in Adobe’s face. “What we really needed,” he says, “was a good PR person who could have helped us come up with a less aggressive approach.” But the deed was done. The “font wars” were in full swing.</p>

<p>The key developer of Microsoft’s new code was Eliyezer Kohen, whom Myhrvold met at a conference in Switzerland. Eliyezer was, as Steve Shaiman put it, “really, really smart.” He had a PhD from ETH Zurich, where he studied with Hans Eduard Meyer, the designer of the font Syntax, and Niklaus Wirth, designer of the Pascal language; and he developed his own technology for creating scalable fonts. Eliyezer, according to Shaiman, was “a Turkish Jew with a German wife, who wanted to move to the United States, as one or the other of them wasn’t welcome in any country in Europe where they might find decent working conditions.” Microsoft happily brought him in.</p>
			</section>
			
			<figure data-blockname="single_image">
				<img data-src="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-03-Hitchcock-Greg-135.jpg" alt="" src="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-03-Hitchcock-Greg-135.jpg">
				<figcaption>Greg Hitchcock’s journey to Microsoft was a bit circuitous —he studied geography with a focus on computer cartography, and immersed himself in computer science.</figcaption>
			</figure>
			
			<section data-blockname="sub_heading_1">
				<h2>Even a DOS screen needs a font</h2>
			</section>
			
			<section data-blockname="body_copy">
				<p><span><img src="https://www.typemag.org/images/uploads/win31-dosscreen.png" alt="" height="300" width="300"></span>GREG HITCHCOCK was one of the early members of what he calls the “virtual team” that Shaiman and Dennis Adler put together in early 1990 to deal with fonts. Hitchcock is tall, blond, and slow-spoken; he doesn’t fit the image of the high-energy Microsoft employee, and he may seem unassertive, almost tentative, if you see him only in a neutral context. But when you see his attention snap to the subjects he knows and cares about, he is forceful and precise, and very, very knowledgeable. His memory is encyclopedic, and he has been at the heart of Microsoft’s typographic development for more than a quarter century. Today he manages Microsoft’s Advanced Reading Technologies (ART) team.</p>

<p>Although Microsoft had been dealing with fonts in one way or another from the very beginning (even a DOS screen needs a font to display its text), Hitchcock feels that the story of typography at Microsoft really begins here: When the first outline fonts were created for Windows 3.1, in 1990.</p>

<p>It was all brand-new technology. All fonts up until then had been bitmap fonts, crude forms made up of coarse screen pixels in a vague approximation of what real letters looked like. Although Microsoft’s new effort was driven by purely practical needs—mapping the screen fonts on a computer system to the fonts available on a printer—Hitchcock feels that it was also the beginning of thinking about screen fonts as something useful and readable in themselves.</p>

<p>The members of the virtual team came from all over Microsoft: Dennis Adler (Fonts), Jean-François Peyroux (OS/2, and later Windows), Michel Suignard (Windows International), Greg Hitchcock (OS/2), Eliyezer Kohen (Fonts), David Weise (Windows), Tim McCaffery (Windows), Raleigh Roark (Hardware), Gabe Newell (Printing), and later Ben Bauermeister, an outside consultant, whose “PANOSE system” for classifying typefaces by their visual characteristics (rather than their historical roots) might provide a roadmap between screen and print.</p>
			</section>
			
			<section data-blockname="sub_heading_1">
				<h2>Monotype send out S.O.S.</h2>
			</section>
			
			<section data-blockname="body_copy">
				<p><span><img src="https://www.typemag.org/images/uploads/win31-shake.png" alt="" height="300" width="300"></span>STEVE SHAIMAN hired Dennis Adler to manage the fonts groups.&nbsp; Together, they talked with several potential sources of font libraries and font technologies, including most of the big guns in the field. Linotype, the venerable manufacturer of hot-metal typesetting equipment, which owned the rights to, among others, the very popular typeface Helvetica, was being hard-nosed. “Fonts were seen as incredibly valuable at the time,” says Shaiman, “and Linotype’s attitude was, ‘What’s Microsoft going to do for us?’” So they were asking an enormous price for licensing the fonts. And Microsoft didn’t want to license the fonts; it wanted to own the rights. (When Shaiman told me this, he laughed and proclaimed: “Microsoft doesn’t rent things!”)</p>

<p>Monotype, on the other hand, was much more receptive. Monotype was Linotype’s great rival; between them, the two companies had essentially created the business of mechanical typesetting in the late 19th century, with their competing hot-metal composition machines. But the Monotype Corporation had fallen on hard times. The typography division, the only part of the company working on digital fonts, was making money, but the larger machinery business was hemorrhaging cash, and the parent company was about to declare bankruptcy.</p>

<p>Out of that debacle rose a new type-only company, Monotype Typography Ltd, which was essentially the old typography division reconstituted as an independent business.</p>

<p>The new company, with its focus on digital fonts and information technology, was headed by a German, Rene Kerfante, who had joined Monotype in 1987 to head up the typography division, and an American, Ira Mirochnik, who had been Monotype’s chief financial officer. They were both quite ready to negotiate a deal with Microsoft.</p>

<p>So it was Monotype that began developing a set of “core fonts” for Microsoft: Scalable TrueType fonts that could be shipped with Windows and used freely by every Windows customer. The new fonts had to mimic the established core set of PostScript fonts, which included Times Roman and Helvetica. Since Monotype had originally developed the Times fonts back in the hot-metal days, that part was easy. To compete with Helvetica, though, they chose to adapt an earlier Monotype design with similar characteristics, called Arial.</p>

<p>Designing the outlines for these typefaces was the kind of task that the Monotype drawing office excelled at. The hard part was the hinting, the software instructions that control the rendering on various devices. That was what would make the fonts look good on screen.</p>

<p>Monotype had a team in the UK working on font hinting, but they were running into trouble. Although they had an auto-hinting program, called TypeMan, developed by Apple’s principal TrueType developer, Sampo Kaasila, the process was proving to be long, slow, and laborious. As Greg Hitchcock describes it, Monotype in desperation Monotype “sent out the bat signal.” In response, in September 1990, he and Eliyezer made the first of many trips to the UK to provide hands-on help and supervision. This was the start of a back-and-forth pattern for Greg—three weeks in the UK, one week in Redmond—that lasted for the next nine months. Their main job was hinting type, working in little rooms in archaic buildings at the old Monotype works. …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.typemag.org/post/the-faces-of-microsoft">https://www.typemag.org/post/the-faces-of-microsoft</a></em></p>]]>
            </description>
            <link>https://www.typemag.org/post/the-faces-of-microsoft</link>
            <guid isPermaLink="false">hacker-news-small-sites-23755238</guid>
            <pubDate>Tue, 07 Jul 2020 02:53:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games, Strategies, Heuristics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23755072">thread link</a>) | @memexy
<br/>
July 6, 2020 | https://commoncog.com/blog/heuristics-are-ok/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/heuristics-are-ok/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
      <p>In the <em><a href="https://www.goodreads.com/book/show/461104.The_Ascent_of_Man">Ascent of Man</a></em>, mathematician Jacob Bronowski describes a conversation in London with the legendary John von Neumann, some time after von Neumann published his <em>Theory of Games and Economic Behaviour</em> with Oskar Morgenstern in 1944.</p><p>“You mean, the theory of games like chess?” Bronowski asked, after they had settled into their London cab.</p><p>“No, no,” von Neumann replied, “Chess is not a game. Chess is a well-defined form of computation. You may not be able to work out the answers, but in theory there must be a solution, a right procedure in any position.”</p><p>“Now, real games,” he said, “are not like that at all. Real life is not like that. Real life consists of bluffing, of little tactics of deception, of asking yourself what is the other man going to think I mean to do. And that is what games are about in my theory.”</p><p>Bronowki was a chess player; von Neumann a poker player. His book on game theory included a chapter called ‘Poker and Bluffing’ — by all accounts, von Neumann played poker only occasionally, and not very well at that. But he recognised that poker was a fundamentally richer game than chess, and he built his theory around a stripped-down version of the game.</p><p>Decades later, professional poker player Annie Duke retells this story in her book <em><a href="https://www.goodreads.com/book/show/35957157-thinking-in-bets">Thinking in Bets</a></em>, and argues:</p><blockquote>The decisions we make in our lives—in business, saving and spending, health and lifestyle choices, raising our children, and relationships—easily fit von Neumann’s definition of “real games.” They involve uncertainty, risk, and occasional deception, prominent elements in poker. (…)<p>Chess, for all its strategic complexity, isn’t a great model for decision-making in life, where most of our decisions involve hidden information and a much greater influence of luck. This creates a challenge that doesn’t exist in chess: identifying the relative contributions of the decisions we make versus luck in how things turn out.</p><p>Poker, in contrast, is a game of incomplete information. It is a game of decision-making under conditions of uncertainty over time. (Not coincidentally, that is close to the definition of game theory.) Valuable information remains hidden. There is also an element of luck in any outcome. You could make the best possible decision at every point and still lose the hand, because you don’t know what new cards will be dealt and revealed. Once the game is finished and you try to learn from the results, separating the quality of your decisions from the influence of luck is difficult.</p></blockquote><p>Duke gets it mostly right. In her book, she argues that we have more to learn from poker than we do from chess. In chess, whenever we make a mistake, it is possible to pinpoint what the mistake was, and when during the game it was made. But in poker, as in life, mistakes and outcomes may sometimes be unrelated — for instance, it is possible to blunder in poker and yet still win against a world champion; conversely, it is possible to ‘play perfectly’ and lose the entire game.</p><p>Learning in poker is also more reflective of the real world: at the highest levels of chess, making a mistake leads to an observable, predictable outcome that you may study; in poker, you may play a hand but have your opponents fold; this means you walk away with no idea if you played well or badly.</p><p>Duke’s solution, of course, is to focus on explicit decision analysis. Poker demands that we learn probabilistic thinking, and it requires us to separate the evaluation of our outcomes from the quality of our decision making. <em>Thinking in Bets</em> covers many of these techniques, and Duke now teaches her methods to business executives beyond the world of poker.</p><p>Duke’s book is very much in line with mainstream decision theory. The book argues that our brains are evolved for less complex environments, and that we rely on heuristics — mental shortcuts! — that cause us to have cognitive biases. In turn, these biases lead to errors in judgment that prevent us from achieving our goals.</p><p>This might not be surprising to you, especially if you’ve spent any time reading up on decision making — if you have, in addition to Duke’s book, read Daniel Kahneman’s <em><a href="https://www.goodreads.com/book/show/11468377-thinking-fast-and-slow?from_search=true&amp;from_srp=true&amp;qid=pOsNtVC7Nm&amp;rank=1">Thinking: Fast and Slow</a></em>, if you’ve gone through Phillip Tetlock’s <a href="https://commoncog.com/blog/how-do-you-evaluate-your-own-predictions/"><em>Superforecasting</em></a>, or if you are familiar with Richard Thaler’s <a href="https://www.goodreads.com/book/show/3450744-nudge"><em>Nudge</em></a>. These authors argue that the best response to this quandary is to find ways to work around our brain's deficiencies, in order to make ever more rational judgments and decisions.</p><p>In simple terms, if you have read only these books, you would likely conclude that &nbsp;<em>heuristics should be frowned upon.</em> Heuristics lead us to cognitive biases, which in turn prevent us from making good decisions; good decisions are necessary to achieve our goals; therefore, we should be suspicious of the heuristics we lean on if we want to succeed in life.</p><h2 id="but-heuristics-are-how-we-think">But Heuristics Are How We Think</h2><p>Over the past four weeks, we’ve gone through a <a href="https://commoncog.com/blog/the-tacit-knowledge-series/">series of posts</a> on the nature of tacit knowledge, and how this is related to the pursuit of expertise. In <a href="https://commoncog.com/blog/how-to-learn-tacit-knowledge/">Part 2</a>, for instance, I described the recognition-primed decision making (RPD) model as a model for tacit expertise, and gave several examples of using it to extract the tacit knowledge of experts. In <a href="https://commoncog.com/blog/youtube-learn-tacit-knowledge/">last week’s post</a>, I talked about how an understanding of RPD might help us extract tacit knowledge from YouTube — YouTube! — in fields as diverse as Judo, computer programming, and music.</p><p>But sharp readers might have noticed that RPD <em>is completely dependent on heuristics</em>. As Gary Klein writes in <em>Sources of Power</em>:</p><blockquote>The core of the RPD model is a set of heuristics previously described by Amos Tversky and Daniel Kahneman: the simulation heuristic (<a href="https://science.sciencemag.org/content/185/4157/1124">1974</a>), used for diagnosis and for evaluation, and the availability and representativeness heuristics (<a href="https://books.google.com.my/books?id=_0H8gwj4a1MC&amp;lpg=PA117&amp;ots=YEjd4PX1WN&amp;dq=Causal%20schemas%20in%20judgments%20under%20uncertainty%20fosjbeom&amp;pg=PA117#v=onepage&amp;q&amp;f=false">1980</a>), for recognizing situations as typical.</blockquote><p>In fact, the only explicit analysis that occurs during the recognition-primed decision cycle is when you’ve pattern matched the situation against a prototype in your head, and you’ve moved on to the evaluation and generation of an action script.</p><figure><img src="https://commoncog.com/blog/content/images/2020/07/Paper.Commonplace.41.png"></figure><p>This view of decision making is quite different from the previous one. In the previous view, heuristics are suspicious. In this view, <em>heuristics are simply how our brains work.</em> In fact, when someone tells you to acquire expertise, what they’re really saying is “go lean into your heuristics”! And when an expert tells you “it just felt right”, what they’re really saying is that they pattern matched against what is available to them (<a href="https://en.wikipedia.org/wiki/Availability_heuristic">availability bias</a>); they made sense of the developing situation by generating a narrative (<a href="https://www.psychologytoday.com/us/blog/science-choice/201612/what-is-narrative-bias">narrative bias</a>), and then they executed a solution they had simulated in their heads (<a href="https://en.wikipedia.org/wiki/Simulation_heuristic">simulation heuristic</a>).</p><p>For all the attention that Duke spends on explicit decision analysis in poker, <em>actual</em> poker performance seems to be as dependent on prototype recognition and expert intuition as chess is. As <a href="https://www.researchgate.net/publication/340342482_Poker_as_a_Domain_of_Expertise">Palomaki et al, 2020</a> notes:</p><blockquote>A corpus of anecdotal evidence suggests that since the poker environment is complex and fast paced, players need to trust their intuitions or “gut feelings” when making a decision (e.g., Brunson, 2005; Tendler, 2011). These feelings can also be called affective heuristics (Finucane et al., 2000) —that is, “unconscious” processing of task-relevant information experienced phenomenologically as good or bad “feelings” about a situation. It has been empirically established that chess masters, too, often rely on an intuitive “feel” for different moves and assessment of the “board as a whole,” especially in the mid-game where options for various moves are astronomical (e.g., Chassy &amp; Gobet, 2011; Gobet &amp; Chassy, 2009) and it is futile to attempt to work through the alternatives step- by-step in working memory.</blockquote><p>And then they quote World Series of Poker champion Doyle Brunson, who says:</p><blockquote>Whenever I . . . “feel” . . . I recall something that happened previously. Even though I might not consciously do it, I can often recall if this same play . . . came up in the past, and what the player did or what somebody else did. So, many times I get a feeling that he’s bluffing or that I can make a play and get the pot. [My] subconscious mind is reasoning it all out.</blockquote><p>Which is similar to the kinds of things that experts say whenever you ask them about their tacit knowledge.</p><h2 id="putting-the-two-together">Putting The Two Together</h2><p>So how do we square these two views together? The unsatisfactory answer here is that I don't yet know.</p><p>In 2009, Daniel Kahneman and Gary Klein published a paper titled <em><a href="https://www.semanticscholar.org/paper/Conditions-for-intuitive-expertise%3A-a-failure-to-Kahneman-Klein/fe7716fa80fcf7cea3ac71666754360c77197f42">Conditions for intuitive expertise: a failure to disagree</a>.</em> In it, they outlined the history of their respective approaches, and then argued that expert intuition may <em>only</em> be trusted when:</p><ol><li>The environment has high <em>validity</em> — that is, when there are adequate valid cues that may be learnt in the environment, and</li><li>There are sufficient opportunities to learn those relevant cues.</li></ol><p>In giving these two requirements, Kahneman and Klein argue that domains like political forecasting and stock picking fail requirements 1 and 2, while domains like chess, medicine and firefighting, do not.</p><p>(As an interesting aside, they <em>also</em> argue that domains with high levels of uncertainty or information hiding may still be considered high validity — and here they give the examples of poker and warfare. <a href="https://www.researchgate.net/publication/340342482_Poker_as_a_Domain_of_Expertise">Palomaki et al</a>, on the other hand, argue that poker is ‘medium validity’, because poker's short-term outcomes are highly dependent on luck.)</p><p>Kahneman and Klein’s paper is probably one of the most important papers to have come out of the naturalistic decision-making and heuristics+biases academic traditions — but it is only useful up to a certain point. What we <em>really</em> want to know is how Annie Duke — and others like her — are able to blend the analytical rigour of decision analysis with the rapidity of recognition-primed expertise. Can we generalise their methods to other skills? And if so, how do we adapt them to our careers?</p><p>I don’t yet know the answers to these questions, or what they imply for successful stock pickers and hedge fund managers — two roles …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/heuristics-are-ok/">https://commoncog.com/blog/heuristics-are-ok/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/heuristics-are-ok/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23755072</guid>
            <pubDate>Tue, 07 Jul 2020 02:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keeping up with Google Cloud news (list)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23755028">thread link</a>) | @gw5815
<br/>
July 6, 2020 | https://gregsramblings.com/blog/keeping-up-with-google-cloud-news/ | <a href="https://web.archive.org/web/*/https://gregsramblings.com/blog/keeping-up-with-google-cloud-news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        
        <div>
            <h4>Keeping up with Google Cloud news</h4>
            <p>July 01, 2020 </p>
        </div>
        <p>A lot is happening in Google Cloud and the pace of progress is accelerating rapidly. Below are the best ways to keep up to date!</p>
<ul>
<li><a href="https://cloud.google.com/blog/">Google Cloud Blog</a> - The official Google Cloud Blog</li>
<li><a href="https://www.youtube.com/playlist?list=PLIivdWyY5sqIxUCyOq0-FPNn5GZ2-XR45">This Week in Cloud Video Series</a> - ~2 minute weekly summary of Google Cloud news</li>
<li><a href="https://medium.com/@alexismp">TWiGCP blog series</a> - Recap of the week’s Google Cloud announcements</li>
<li><a href="https://medium.com/google-cloud">Google Cloud Medium publication</a> - Content from Googlers and various community experts</li>
<li><a href="https://www.gcppodcast.com/">Google Cloud Weekly Podcast</a> - Over 200 episodes - platform news recaps, guest interviews, etc.</li>
<li><a href="https://cloud.google.com/newsletter">The Google Cloud Newsletter</a> - Email subscription</li>
</ul>
<figure>
    <img src="https://gregsramblings.com/images/google-cloud-news.png" alt="Screenshots of Google Cloud news sources"> 
</figure>


        <hr>
        <p><b>Tags:</b></p><div><p><a href="https://gregsramblings.com/tags/google/">google</a></p></div>
        
            <div><p><a href="https://gregsramblings.com/tags/gcp/">gcp</a></p></div>
        

        <hr>

        


<p><a href="https://disqus.com/">comments powered by <span>Disqus</span></a>

    </p></div>

            </div></div>]]>
            </description>
            <link>https://gregsramblings.com/blog/keeping-up-with-google-cloud-news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23755028</guid>
            <pubDate>Tue, 07 Jul 2020 02:23:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Don't Read Email in the Morning (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23754694">thread link</a>) | @stepstop
<br/>
July 6, 2020 | https://www.paperplanes.de/2015/5/13/why-i-dont-read-email-in-the-morning.html | <a href="https://web.archive.org/web/*/https://www.paperplanes.de/2015/5/13/why-i-dont-read-email-in-the-morning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Early mornings are pristine, they're my favorite time of the day. As the sun
keeps coming up earlier and earlier, I find myself waking up at 6. Rather than
do anything else, I either go for a run or skate, or I grab a book and a cup of
coffee and read.</p>

<p>Mornings are usually my most creative time. I have a clear head that allows me
to think freely and focus on the kind of work that requires attention and
creative thinking. That means I write, or work on strategic topics relevant to
the company, or I read the occasional article, book or paper too. In different
times, I'd write code during these hours.</p>

<p>This time usually stretches beyond breakfast, until around noon. After that,
there's meetings (I only schedule meetings after noon), one on ones, and
increasing chatter and activity around the office.</p>

<p>In other words, <strong>the number of distractions increases as the day goes by.</strong></p>

<p>These kinds of distractions aren't necessarily a bad thing. Meetings, one on
ones, office chatter, they all have their place, and they're all important. All
of them are at least half of what my job entails these days.</p>

<p><strong>But how does email fit into all of this?</strong></p>

<p>As soon as you open email, your attention gets sucked away from everything else.
As you go through your inbox, you're faced with all kinds of problems,
questions, feedback, vendor requests, meeting notes and invites. Your attention
span shortens with every email you process, deciding on whether it warrants a
response, being careful about your own responses along the way.</p>

<p>Usually, after I plow through my inbox, afterwards I have little attention span
left to focus on a single task. Instead I now have dozens of other topics in my
head that drain my focus pool, commanding my creative resources away from work
that requires my full focus.</p>

<p>The same is true about Twitter. You're immediately sucked into other people's
bad days (or good days) and cat pictures, luring your focus away from yourself
and your day. </p>

<p>The temptation of email is great and hard to resist. When you're done working
through your inbox, you have that great feeling of accomplishment. Only then do
you realize that you still have other work to do and that your meetings for the
day aren't too far off.</p>

<p>Time slips, and so does your focus work.</p>

<p><strong>But I'm the CEO, and people need to communicate with me!</strong></p>

<p>They do, and everyone's welcome to step up to my desk or ping me online (if I'm
in chat). Most things that come up in those first hours of the day, though, are
things that I can follow up on later. That's the important part. It's the
following up that matters rather than wanting or getting an immediate response.
Especially in remote and distributed teams, communication is asynchronous.</p>

<p><strong>So when do I read my emails?</strong></p>

<p>I schedule blocks every day, when I focus only on email. This doesn't always
work, but having this explicit schedule does magic beyond having a specific
time. It gives me the mental freedom to focus on important work. I know that I
have my slot for email later, and I have it every day. Instead of worrying about
an ever-growing inbox, I know that every day I'll have a slot in my calendar
that allows me to focus on email and email only.</p>

<p>Try this out for a week. Instead of opening email in the morning, open your
notebook and write down two or three tasks that you want to get done before
lunch. Then work through them. What you can get done in just two hours and by
focusing only on work is pure magic.</p>

    </div></div>]]>
            </description>
            <link>https://www.paperplanes.de/2015/5/13/why-i-dont-read-email-in-the-morning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23754694</guid>
            <pubDate>Tue, 07 Jul 2020 01:34:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing how different devices handle invalid UTF8 characters as SSIDs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23754546">thread link</a>) | @herohamp
<br/>
July 6, 2020 | https://hamptonmoore.com/posts/weird-wifi-names-cont/ | <a href="https://web.archive.org/web/*/https://hamptonmoore.com/posts/weird-wifi-names-cont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>This is a continuation of my previous post <a href="https://hamptonmoore.com/posts/weird-wifi-name-display/">Comparing how different devices display the SSID “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”</a>. After posting it on HackerNews I got lots of feedback. The key one was something that I had sadly missed when I originally started this project. When the WiFi name of “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa” got shortened down to a one byte before the second “a” due to the 32 byte/octet limit of SSIDs. The issue was this character is actually two bytes wide, so the first part of the character stayed, with the second byte of it missing. The character in question was ◌̈́, with the hex codepoint cd84. Looking at the raw hex of the SSID you can see it ends in cd, <code>61ccb6cc81cc93ccbfcc88cc9bcc9bcd90cd98cd86cc90cd9dcc87cc92cc91cd</code>. For those curious about how that would be rendered on your device here it is “á̶̛̛̓̿̈͐͆̐̇̒̑͘͝�”. After realizing this I decided my previous comparisons of how devices reacted to my weird unicode SSID was unfair. The SSID this time is “á̶̛̛̓̿̈͐͆̐̇̒̑͘͝a” which is almost the exact same but that last two byte long character was replaced with an “a”. This was to keep the SSID at 32 octets long. Looking at the new hex of the SSID <code>61ccb6cc81cc93ccbfcc88cc9bcc9bcd90cd98cd86cc90cd9dcc87cc92cc9161</code> you can see that is is identical baring the <code>61</code> instead of a <code>cd</code> at the end.</p> <p>Below are the previous photos of the previous SSID “á̶̛̛̓̿̈͐͆̐̇̒̑͘͝�” with the new SSID “á̶̛̛̓̿̈͐͆̐̇̒̑͘͝a” under it. They are also grouped the same as previously to keep continuity.</p> <p>Galaxy S8 running Android 9 with Kernel 4.4.153 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/android.jpg" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/android.jpg" alt=""></p> <p>Amazon Firestick <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/firestick.jpg" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/firestick.jpg" alt=""></p> <p>As before the Galaxy S8 and the Firestick both handled it perfectly with there being no issues with how it rendered besides vertical cutoff which makes sense.</p> <p>iPhone running iOS 13.5.1 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/iphone-ios1351.jpg" alt=""> <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/iphone-ios1351.jpg" alt=""></p> <p>Apple TV Second Generation <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/appletvgen2.jpg" alt=""> <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/appletvgen2.jpg" alt=""></p> <p>These results were interesting. It showed that if the UTF-8 character in an SSID is invalid then IOS falls back to the <a href="https://en.wikipedia.org/wiki/Mac_OS_Roman">Mac OS Roman</a> character set, but since the new SSID is valid UTF-8 iOS properly renderers the SSID.</p> <p>2012 Macbook running High Sierra 10.13.6 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/macos.jpg" alt=""></p> <p>Unlike last time the Macbook actually showed the network. I believe last time instead of falling back to Mac OS Roman like iOS the Macbook just treated the SSID as spam or noise and dropped it</p> <p>Windows 10 Pro 10.0.19041 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/windows10.png" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/windows10.jpg" alt=""></p> <p>Windows was able to properly handle this SSID as opposed to falling back to <a href="https://en.wikipedia.org/wiki/Windows-1252">Windows-1252</a> like it did previously.</p> <p>Chromebook running ChromeOS 83.0.4103.97 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/chromeos.jpg" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/chromeos.jpg" alt=""></p> <p>Unlike last time the Chromebook was able to render this perfectly with no question marks.</p> <p>Kindle Paperwhite running Firmware 5.10.2 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/kindlepaperwhite.jpg" alt=""></p> <p><img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/kindlepaperwhite.jpg?" alt=""></p> <p>Vizio M55-C2 TV <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/viziom55-c2.jpg" alt=""> <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/d2/viziom55-c2.jpg" alt=""></p> <p>Unlike last time the kindle was able to show the SSID without escape any of the characters. Sadly the Vizio was not able to show the SSID and just fell back to escaped hex.</p> <p>The results from changing the SSID showed a couple things, namely devices really do not like it when they are given invalid or incomplete UTF-8 codes and lots of devices handle UTF-8 text much better than I thought they would. It also showed that some devices fallback to their native 8 bit encoding formats when they see an invalid UTF-8 codepoint, there is probably some room for exploitation here like inserting escape keys. I originally was not expecting the kindle to work at all, nor the chromebook after seeing the slew of question marks originally. Android was also found to be at handling text with invalid UTF-8 characters it just removed them as opposed to switching up formatting, falling back to hex, or erroring out with all question marks.</p> <p>Thank you to everyone who provided valuable feedback on the previous post. I have more research I plan ond doing with this in the future.</p> <p>Lastly if anyone would like to run this test themselves and send me the comparison results to be added my email is <code>me (at) hampton (This key &gt; not shifted) pw</code>.</p> <hr> <p> Hello reader. I do not normally like to put advertisements or promotions on my website, but recently a good friend of my Jaden Ann Scrivener died in a car crash. She was known in the community as the most caring and energetic person around. She was a beam of sunshine and happiness brightening up the day of anyone who interacted with her. If you could <a href="https://www.aplos.com/aws/give/RayofHopeMedicalMissionsInc/Jaden">please donate to her memorial fund</a>. All the proceeds will go to the <a href="https://www.rohmm.org/">Ray of Hope Medical Missions</a> which facilitates life-changing surgeries, reduces infant mortality, and provides mission opportunities locally. </p> </article></div>]]>
            </description>
            <link>https://hamptonmoore.com/posts/weird-wifi-names-cont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23754546</guid>
            <pubDate>Tue, 07 Jul 2020 01:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's Talos all the way down]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23754536">thread link</a>) | @classichasclass
<br/>
July 6, 2020 | https://www.talospace.com/2020/06/its-talos-all-way-down.html | <a href="https://web.archive.org/web/*/https://www.talospace.com/2020/06/its-talos-all-way-down.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-6179143665681918893"><p>
Still can't bear the sticker shock of your very own Talos II, or even a itty bitty Blackbird? Why not do what we all do for the machines we can't own and emulate one instead? (And then decide you like it a lot, and save your pennies?)
</p><p>
QEMU 5.0.0 offers a machine model for the bare-metal PowerNV profile, to which the Raptor systems and other OpenPOWER POWER8 and POWER9 designs intended for Linux (i.e., not PowerVM machines) belong. Using the Talos II firmware image (mostly: one snag to be mentioned), you can boot the machine in QEMU and from there bring up an operating system in emulation. In this article we'll prove it works by bringing up <a href="https://voidlinux-ppc.org/">Void Linux for Power</a> (hi, Daniel!) in a variety of configurations. A set-up like this might be enough to test that your software or open-source package builds and runs on OpenPOWER, even if you don't own one yet. In a future article we'll talk about how you can boot your own code on the metal so you can port your favourite OS or build a unikernel.
</p><p>
(For the purposes of this article I'll assume an audience that isn't as familiar with OpenPOWER terminology as our usual readership. Kindly humour me.)
</p><p>
The emulation is imperfect, both if you're emulating it on a real Raptor family system or on an icky PC. While QEMU can emulate an AST2500 (i.e., the ARM-based Baseboard Management Controller, which acts as the service processor and provides the video framebuffer), and QEMU can also emulate a PowerNV system, it doesn't do both at the same time. That means the very lowest levels are actually being simulated here -- you can't watch Raptor's pretty Hostboot display, for example, and only the barest functions of the BMC are simulated enough to allow bring-up, not including the framebuffer. In fact, the hardware profiles we will use here do not in general match a real Raptor system either: we're just virtually plugging in PCI devices that give us necessary functionality, though of course none of the peripheral devices in a Raptor system is Raptor-proprietary. Finally, even though I have tagged this entry with KVM, KVM currently doesn't work right with the QEMU PowerNV machine model even though I'm pretty sure it should be technically possible. Sadly, I tried in vain to do so, could never get KVM-HV to be happy, and ended up kernel panicking the machine with KVM-PR. <a href="https://gist.github.com/classilla/0b95d7bea3e9a270385a2360fbcf7f40">See if you can triumph where I have failed</a>. In the meantime, naturally you can do everything here on a T2 or Blackbird as well because that's how I did it writing this article, but there is no special acceleration for those systems right now.
</p><p>
The first order of business is the first order of business with any emulator: get the ROMs. Fortunately, no one is going to bust you for pirating a set of these because we're an open platform, remember?
</p><p>
The two pieces required are Skiboot and Petitboot, both of which live in the system's PNOR flash. <a href="https://github.com/open-power/skiboot">Skiboot</a> contains OPAL, the OpenPOWER Abstraction Layer. It comes in after the BMC has turned on main power and started the Power CPUs' self-boot engines, which then IPL ("initial program load") Hostboot for the second-stage power-on sequence. When Hostboot completes, it chains into Skiboot, which initializes the PCIe host bus controllers (PHBs) and provides all the basic hardware calls needed by a guest kernel to support the platform. You can think of it as something like an overgrown BIOS. This is the lowest firmware level of an OpenPOWER system that QEMU currently supports emulating.
</p><p>
Skiboot lives only to service a kernel, so it immediately starts one. This initial payload is the bootloader for <a href="https://github.com/open-power/petitboot">Petitboot</a>, which is also stored in firmware. Petitboot has a small Linux root (Skiroot) and acts as a boot menu, finding bootable volumes on attached devices or over the network. Having found one (or you select one), it chains into it to start the main OS, and from then on Skiboot will provide platform services via OPAL for this final guest until the system is shut down or restarted. Because it's in firmware, Petitboot is always available, which can come in really handy when you're trying to do system recovery.
</p><p>
The first, best and most dedicated way is to <a href="https://github.com/open-power/op-build">build Skiboot and Petitboot yourself</a>. They are open-source and the process is relatively well documented and automated, and you should know how to do this if you own an OpenPOWER machine anyhow. If you aren't doing this on a real OpenPOWER machine you'll need a cross-compiler, but most Linux distros offer such a package nowadays. Do keep in mind that if it looks like you're building a tiny Linux distro, well, that's because that's exactly what you're doing. The advantage here is you can fool around with the firmware at your leisure, but it requires a bit of an investment in disk space and time.
</p><p>
The second way assumes you have a more casual interest and would prefer to go with something prefab. It's possible if you (or, you know, your "friend") has a Raptor-family system to extract the necessary components right from the BMC prompt. Log into the BMC over SSH (or via <a href="https://www.talospace.com/2020/04/what-to-do-when-bmc-wont-talk-to-you.html">direct serial connection</a>) and type <tt>pflash -i</tt>. You'll see a list of all the partitions stored in the PNOR flash. The ones we want are <tt>PAYLOAD</tt> (which contains Skiboot) and <tt>BOOTKERNEL</tt> (which contains Skiroot and Petitboot). The exact addresses may vary from system to system and firmware to firmware.
</p><p>
<tt>root@bmc:~# pflash -P PAYLOAD -r /tmp/pnor.PAYLOAD --skip=4096<br>
Reading to "/tmp/pnor.PAYLOAD" from 0x021a1000..0x022a1000 !<br>
[==================================================] 100%<br>
root@bmc:~# pflash -P BOOTKERNEL -r /tmp/pnor.BOOTKERNEL --skip=4096<br>
Reading to "/tmp/pnor.BOOTKERNEL" from 0x022a1000..0x03821000 !<br>
[==================================================] 100%
</tt></p><p>
We skip the first 4K page to avoid the wrapping around each partition. <tt>pnor.PAYLOAD</tt> is actually compressed and needs to be uncompressed prior to use, so:
</p><p>
<tt>root@bmc:~# cd /tmp<br>
root@bmc:/tmp# xz -d &lt; pnor.PAYLOAD &gt; skiboot.lid</tt>
</p><p>
Finally, <tt>scp</tt> both <tt>skiboot.lid</tt> and <tt>pnor.BOOTKERNEL</tt> to your desired system from the BMC.
</p><p>
Admittedly we just talked at length about the two ways most of you <em>won't</em> get the firmware, so let's talk about the third method and the way most of you will, i.e., you'll just download it. Currently there is an irregularity about Raptor's present Skiboot build for this purpose: it only boots if you are emulating a single <em>POWER8</em>. That's not a typo. If you use it to boot an emulated POWER9, the guest will simply panic, and the guest will go into a bootloop if you are emulating multiple POWER8 CPUs (necessary if you need a larger number of PCIe devices). This is undoubtedly a QEMU deficiency which will be corrected in future releases. In the meantime, if you just care about playing around using a single POWER8 on a terminal, then Raptor's builds (either from BMC flash or downloaded) will suffice. However, if you intend to emulate a POWER9 or SMP POWER8 system, <a href="https://github.com/qemu/qemu/blob/master/pc-bios/skiboot.lid">download QEMU's own pre-built <tt>skiboot.lid</tt></a> and use that instead.
</p><p>
For Petitboot, we will extract that directly from Raptor's PNOR images. Assuming you didn't get it using the process above, <a href="https://wiki.raptorcs.com/wiki/Talos_II/Firmware">download the current Talos II PNOR image</a> and decompress it. In the <tt>shell_upgrade</tt> directory you will see the <tt>bzip2</tt>-compressed PNOR image. Uncompress that, leaving you with a filename like <tt>talos-ii-v2.00.pnor</tt>. <a href="https://gist.github.com/classilla/4a2c907d0acec5b537cd4992a00801c3">Download my <tt>pnorex</tt> extractor tool</a> (it's in Perl, because I'm one of <em>those</em> people) and run it on the PNOR image:
</p><p>
<tt>% pnorex talos-ii-v2.00.pnor<br>
Version 1 PNOR archive with 33 entries.<br>
Extracting PAYLOAD at offset 8601.<br>
This is a xz format image.<br>
Wrote 1020K successfully.<br>
Extracting BOOTKERNEL at offset 8857.<br>
This is an ELF executable image.<br>
Wrote 22012K successfully.<br>
Extracted 2 partitions successfully.
</tt>
</p><p>
If you will be using Raptor's Skiroot, then uncompress <tt>pnor.PAYLOAD</tt> to <tt>skiroot.lid</tt> as above: <tt>xz -d &lt; pnor.PAYLOAD &gt; skiboot.lid</tt>
</p><p>
Now, with <tt>skiroot.lid</tt> (for this first example, either Raptor's or QEMU's) and <tt>pnor.BOOTKERNEL</tt> in the same folder, grab an ISO you want to boot. I used the prefab one Daniel offers on the <a href="https://voidlinux-ppc.org/">Void Linux for Power site</a> since I know it boots fine on OpenPOWER hardware. For our first example let's do a simple example of booting Void from a CD image on a POWER8 using the serial port. Our QEMU command line:
</p><p>
<tt>
qemu-system-ppc64 -M powernv8 -m 4G -cpu power8 \<br>
        -nographic \<br>
        -bios ./skiboot.lid \<br>
        -kernel ./pnor.BOOTKERNEL \<br>
        -device ich9-ahci,id=ahci0 \<br>
        -drive id=cd0,media=cdrom,file=void-live-ppc64le-musl-20200411.iso,if=none \<br>
        -device ide-cd,bus=ahci0.0,drive=cd0
</tt>
</p><p>
This configures a single-processor POWER8 system with 4GB of RAM, no graphics, and an Intel AHCI host controller with a single CD-ROM drive attached. The serial output should go to your terminal. It goes a little like this:
</p><p><a href="https://3.bp.blogspot.com/-3VII_RkIwcE/XvFb7tRycOI/AAAAAAAABs0/yyvLDu_1liEFaU2wpoZWtrf-au1P1YiDACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2020-06-22%2B16-44-48.png" imageanchor="1"><img data-original-height="645" data-original-width="578" height="320" src="https://3.bp.blogspot.com/-3VII_RkIwcE/XvFb7tRycOI/AAAAAAAABs0/yyvLDu_1liEFaU2wpoZWtrf-au1P1YiDACLcBGAsYHQ/s320/Screenshot%2Bfrom%2B2020-06-22%2B16-44-48.png" width="287"></a></p>
<p>
Here we are with Skiboot chaining into Petitboot. You can ignore the errors; there will be a lot of them since the platform is still incomplete. It will take a little bit of time to decompress the kernel (much slower than it would be on a regular system). You will notice a single device attached to the three available PCIe host bridges on the single POWER8 CPU, i.e., the host controller itself. Don't you just love that the vendor code for Intel is <tt>8086</tt>?
</p><p><a href="https://4.bp.blogspot.com/-3IKOOE6kD80/XvFb7uxi8sI/AAAAAAAABss/yKU2WHvBCbgDmXPvyFdSvsCu7yLHnnGuACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2020-06-22%2B16-45-08.png" imageanchor="1"><img data-original-height="645" data-original-width="578" height="320" src="https://4.bp.blogspot.com/-3IKOOE6kD80/XvFb7uxi8sI/AAAAAAAABss/yKU2WHvBCbgDmXPvyFdSvsCu7yLHnnGuACLcBGAsYHQ/s320/Screenshot%2Bfrom%2B2020-06-22%2B16-45-08.png" width="287"></a></p>
<p>
This is Petitboot. When the bootable choices appear, cursor up to the starred option and press E before it autoboots, because we need to tell Void its console is the on-board serial port (otherwise it uses a VGA console: not sure whose bug that is).
</p><p><a href="https://2.bp.blogspot.com/--dDE00hPAsk/XvFb7k5ug4I/AAAAAAAABsw/KD1kofJkAdIusk9rtl8WyjlknApxQRouQCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2020-06-22%2B16-45-43.png" imageanchor="1"><img data-original-height="645" data-original-width="578" height="320" src="https://2.bp.blogspot.com/--dDE00hPAsk/XvFb7k5ug4I/AAAAAAAABsw/KD1kofJkAdIusk9rtl8WyjlknApxQRouQCLcBGAsYHQ/s320/Screenshot%2Bfrom%2B2020-06-22%2B16-45-43.png" width="287"></a></p>
<p>
Add <tt>console=hvc0</tt> at the end, cursor down to <tt>OK</tt> and hit RETURN/ENTER a couple times to boot.
</p><p><a href="https://2.bp.blogspot.com/-h6UHepGrXLo/XvFb8GHW5jI/AAAAAAAABs4/STBtGNaljU4-3EvsmhlstoBbIpU0aLaKgCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2020-06-22%2B16-47-38.png" imageanchor="1"><img data-original-height="645" data-original-width="578" height="320" src="https://2.bp.blogspot.com/-h6UHepGrXLo/XvFb8GHW5jI/AAAAAAAABs4/STBtGNaljU4-3EvsmhlstoBbIpU0aLaKgCLcBGAsYHQ/s320/Screenshot%2Bfrom%2B2020-06-22%2B16-47-38.png" width="287"></a></p>
<p>
A successful login on your emulated baby POWER8. Ta-daa! To rudely pull the plug on the QEMU session, press Ctrl-A, and then X (<tt>QEMU: Terminated</tt>).
</p><p>
Let's now load out the POWER8. We would like to add a video card, an Ethernet card and a USB controller to our existing system, but POWER8 Turismo chips only offer enough PHBs for three PCI endpoints. How do we solve this problem? Easy: we'll add another processor!
</p><p>
At this point …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.talospace.com/2020/06/its-talos-all-way-down.html">https://www.talospace.com/2020/06/its-talos-all-way-down.html</a></em></p>]]>
            </description>
            <link>https://www.talospace.com/2020/06/its-talos-all-way-down.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23754536</guid>
            <pubDate>Tue, 07 Jul 2020 01:03:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google and federated analytics: an effective tool in privacy signalling]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23754410">thread link</a>) | @exanimo_sai
<br/>
July 6, 2020 | https://4thquadrant.io/articles/business-models/google-and-federated-analytics-an-effective-tool-in-privacy-signalling/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/articles/business-models/google-and-federated-analytics-an-effective-tool-in-privacy-signalling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_29_030">

<div>
<p>Last month, the Google AI blog released an article called “Federated Analytics: Collaborative Data Science without Data Collection”, delving into a mode of data science that doesn’t depend on centralised data collection. What I noticed as I was reading it was a heavy handed subtext around privacy. A ctrl+f for ‘privacy’ brought the word up thirteen times – the subtext was very much ‘at Google, we think about privacy’. But what makes this particularly interesting is that decentralised data analysis isn’t a new concept and didn’t find its origins in privacy, where Google had introduced systems for distributed analysis as early as 2014. While it’s not unusual for Google to put out content expounding some of its technical methods and processes, this article is an intentional signalling of the company’s evolved baseline perspective. Basically that privacy is a forefront concern and consideration in all its avenues of pursuit, this being just one of the many bricks in its united front against user-data related backlash.</p>



<h3>Federated Analytics: origin and intended purpose</h3>



<p>Having learnt from past blunders, It’s not surprising that big tech wants to put its best foot forward in an increasingly critical climate. But to understand why federated analytics is a convenient venn of privacy concerns and data science efficiency for Google, we need to understand its intended purpose and how it works. Federated analytics began as an efficiency tool, it was created to solve the problem of growing data sets in disparate locations at the edge, in the fog, and in cloud or enterprise data centers. The difficulty of porting data to one central database for analysis was a cumbersome process, both for the cost of moving and analysing data as well as the associated security concerns of doing so.&nbsp;</p>



<p>Under a federated analytics model, most data is analyzed close to where it is generated. Rather than storing and analyzing all data in a centralized and possibly insecure space, data is analysed locally on the user’s device or as an encrypted data point as part of a large cluster of devices. Only the learning outcomes of the analytics moves up through the hierarchy iteratively collecting information from the edges, to the points of centralised analysis.&nbsp;</p>



<h3>Federated analytics: a role in more private data science&nbsp;</h3>



<p>The main attraction of federated analytics is that it has properties that can preserve privacy while still allowing big tech, or anybody deploying it, to make meaningful inferences from the data.The privacy preserving environment used for federated analytics (a combination of data science tools and privacy mechanisms) ensures that neither collection nor the observed logic are traceable back to the individual’s data, habits or characteristics – tackling one of the main reasons users are concerned about privacy. Privacy for an individual&nbsp; is typically of concern in two scenarios, here we’re discussing the first:</p>



<ol><li>The user’s personal details are accessed by entities beyond the user’s immediate circle.&nbsp;</li><li>the user’s private data is able to be exploited for monetary gain without any of that value flowing back to the user</li></ol>



<p>Let’s say for example that “I like the colour blue” is a particularly important piece of information to the user’s identity. Sharing this within the user’s immediate circle isn’t necessarily beyond the user’s comfort zone or perceived to be an invasion of privacy.</p>



<p>However, handing this piece of information to “everyone else”is a cognitive burden because the user doesn’t have visibility on how the information is being used. What federated analytics represents then, is a shift from “user X likes the colour blue” to “33% of 10 000 users” like the colour blue. The&nbsp; cognitive burden of how information is being used is reduced because it is obfuscated within a large cluster of other data points. This would imply value is not tied to the user’s singular data point, but rather the observation as a whole. It’s important to bear in mind though, that even federated analytics alone is insufficient as it requires working with other privacy methods, differential privacy and secure multi-party computations with the implementation of best practices to ensure privacy. Although the privacy provided by federated analytics may not be appropriate for all types of analysis, its maturity does indicate a large surface area of utility.&nbsp;&nbsp;</p>



<p>Federated analytics doesn’t do a lot in the way of the second concern, but its indirect effect is less privacy-related cognitive burden for the user and greater user experience – somewhat balancing out the user’s negative perception of the process.&nbsp;</p>



<h3>Big tech’s future: why action and signalling go hand in hand</h3>



<p>Now that we’ve understood the context of federated analytics, it offers a clearer picture of how it becomes a useful tool for privacy signalling – an increasingly important component of the big tech narrative. Big tech through their several touchpoints with users and as gatekeepers of user information have been under constant scrutiny for the exploitation of data. This reputation follows them as they continue optimising their existing offerings but also as they attempt to expand their value chains. This means that the privacy signalling that takes place has to cover a range of intensity and reach. For example when Google and Amazon collect data from IoT devices to improve their AI/ML capabilities, they often push disclaimers in the vein of&nbsp; “All data is utilised preserving the individual’s anonymity”. These are baseline measures implemented so that they can continue leveraging data to optimise and expand their service offerings.&nbsp;</p>



<p>Louder signalling takes the form of sweeping changes, process restructuring or just outright vocalisation. Recently Google announced that it would roll out a host of privacy features and new tools in Chrome including “a safety check tool, 3rd party cookie controls in Incognito mode, Enhanced Safe Browsing, Secure DNS &amp; more”. Apple has centred its branding around user centric privacy, a shift from its earlier methods of data collection that made flagship products like Siri possible; it only implemented differential privacy in 2017 and federated analytics in 2019. Facebook, often under fire for being an arbiter of privacy invasion, has taken a more vocal route. CEO Mark Zuckerberg’s blog post in 2019 was a lengthy narrative on the company’s&nbsp; “privacy-focused” future. His address at the company’s 2019 developer conference was candid stating ““the future is private…I know we don’t exactly have the strongest reputation on privacy right now… [but] I am committed to doing this well.”</p>



<p>All of this reflects one thing surely, privacy is a high stakes arena for big tech. To avoid over-regulation and excessive scrutiny it is imperative that these companies are accepted as privacy preserving entities, one of the most important focal points for strategy. It’s then, not overstating the importance of this to say that the player that is best able to signal privacy whilst increasing their data moat over the next decade, will stand to capture the most value – or at least stay standing the longest.&nbsp;</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>





<p>
<h3><span>Down the Rabbit Hole</span></h3>
</p>



<h3>1. Data gravity skews data crunching towards the centre, but crunching data at the edge is gaining more traction</h3>



<p><em>“Data attracts more data, because different sets are most profitably mined together—a phenomenon known as ‘data gravity’.”</em></p>



<p>This phenomenon has seen cloud giants transform into veritable digital oceans with centralised data processing.&nbsp;&nbsp;</p>



<p><em>“Historically, most digital information stayed home, on the device where it was created. Now, more and more data flows into the big computing factories operated by AWS, but also its main competitors, Microsoft Azure, Alibaba Cloud and Google Cloud.”</em></p>



<p>But as our devices become ubiquitously wireless and connected to the internet, the landscape for the data economy is changing. Where centralised processing reinforced the strength of cloud providers and their data based advantages, edge computing represents an argument for bringing data crunching powers closer to the devices and clusters performing the work. This has given rise to a whole spectrum of localised data service providers and software start-ups servicing this requirement and assisting to move compute power to the edge.</p>



<p><em>“AWS represents a centralised model where all the data are collected and crunched in a few places, namely big data centres. Swim.ai (edge start-up), on the other hand, is an example of what is being called “edge computing”: the data are processed in real time as close as possible to where they are collected. It is between these two poles that the infrastructure of the data economy will stretch.”</em></p>



<p>Cloud services concede the edge is important, but continue to assert that the advantages of centralised processing are both numerous and more importantly necessary. This is true particularly for advancing machine learning and AI training algorithms. However, while it is not certain how much traction edge computing and processing data at the edge will gain, it raises important questions of whether there is another way to do things. And perhaps break the hegemony of power cloud providers hold over the data economy.&nbsp;</p>



<p>Source: Should data be crunched at the centre or at the edge? – <a href="https://www.economist.com/special-report/2020/02/20/should-data-be-crunched-at-the-centre-or-at-the-edge" target="_blank" rel="noreferrer noopener">The Economist</a></p>



<h3>2. The economic characteristics of data are unique and fall outside the scope of standard economic theories</h3>



<p>The United Nations report on the data economy posits that it is fundamentally necessary to understand the idiosyncrasies of ‘data’ if we are to understand the data economy and its impacts. The report observes that standard economic theories fail to appropriately contextualise the data economy because of the unique nature …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://4thquadrant.io/articles/business-models/google-and-federated-analytics-an-effective-tool-in-privacy-signalling/">https://4thquadrant.io/articles/business-models/google-and-federated-analytics-an-effective-tool-in-privacy-signalling/</a></em></p>]]>
            </description>
            <link>https://4thquadrant.io/articles/business-models/google-and-federated-analytics-an-effective-tool-in-privacy-signalling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23754410</guid>
            <pubDate>Tue, 07 Jul 2020 00:40:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resealing and Upgrading Trim on a '78-'90 Volvo 240 Windshield]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23754371">thread link</a>) | @luu
<br/>
July 6, 2020 | http://fewstreet.com/2018/06/13/volvo-240-windshield.html | <a href="https://web.archive.org/web/*/http://fewstreet.com/2018/06/13/volvo-240-windshield.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  <div>
    <h3>Resealing and Upgrading Trim on a '78-'90 Volvo 240 Windshield</h3>
    <h4>13 Jun 2018</h4>
    <p>The 1990 and earlier Volvo 240 windshields are known for their frustrating trim design which was held on 
by <a href="https://www.volvopartswebstore.com/products/Volvo/240/Clip-kit-Genuine-Classic-Part/1113962/270148.html">22 plastic clips</a>, 
set into the butyl rubber used to mount the windshield. My 1989 240 developed a leak near the top right of the 
windshield due to a combination of rust and shoddy resealing done by the previous owner.</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-01-07%2016.30.16.jpg" alt="1989 Volvo 240"></p>

<p>Rather than try to bodge some silicon sealant into the leaky areas and buy myself another couple of years, I chose to fully remove the windshield and 
re-glue it with urethane, replacing the chrome trim strip and clips with more modern rubber trim at the same time.</p>

<p>Using a piece of braided steel wire and two dowels as handles, I sawed through the existing urethane after poking a hole with a exacto knife to feed the wire through.
What was waiting for me underneath was not pretty.</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-04-28%2013.08.22.jpg" alt="Rusty Pinchweld"></p>

<p>The pinchweld had rusted enough that there was no choice but to cut it out in several places and weld in new sheet metal:</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-03%2016.47.01.jpg" alt="Grinding out pinchweld"></p>

<p>I used a dremel with a cutting disk to remove the old metal and TIG welded in a patch with my <a href="https://amzn.to/2ya1l1F">AHP AlphaTIG 200X</a> (this job is what finally pushed me to buy it).</p>

<p>As I welded small sections, I used an air gun to cool the back side of the pinch seam to avoid setting the dashboard on fire. I kept a fire
extinguisher close by at all times regardless.</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-03%2019.21.18.jpg" alt="New windshield corner"></p>

<p>I masked off the entire area and painted it with <a href="https://amzn.to/2JH2C1r">Rust-Oleum professional primer</a> and <a href="https://www.walmart.com/ip/Rust-Oleum-Professional-High-Performance-Enamel-Spray/35031494">high performance enamel</a>. 
The silver Rust-Oleum just happens to be a very close color match to the silver on the 240.</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-04%2019.47.02.jpg" alt="Masking"></p>

<p>Considering the horrific condition of the windshield seam before the job, the result isn’t half bad:</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-05%2020.55.08.jpg" alt="After painting"></p>

<p>Next, I had to answer a question that I couldn’t find clear information on anywhere on the internet. Is it possible to re-use a pre-‘90 style windshield 
but replace the trim with the more modern glued rubber? The answer is <strong>yes</strong>. 
You do not need to buy a whole new ‘91+ windshield if you already have an older pane of glass in good condition.</p>

<p>I bought some <a href="http://www.gggcorp.com/Universal_Mouldings.html#OriginalT">Gold Glass Group Universal Moulding T107B</a> 
on Ebay in a 15ft. roll and applied it to the edge of the old style windshield instead of the clips and chrome trim.</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-13%2018.07.48.jpg" alt="Applying Trim"></p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-13%2018.08.02.jpg" alt="Applying Trim Closeup"></p>

<p>A test fit confirmed it fit into the windshield opening perfectly. I think moving from the 0.75” T107B to the 1” T109B trim would have been a good move, to better
cover some of the nasty surface where the old trim sat. During the test fit I made some marks around the perimeter to help locate the 
windshield later when I installed the urethane.</p>

<p>I bought two tubes of <a href="https://amzn.to/2HLgUfO">DOW U-428 Plus Primerless Windshield Adhesive</a> and a <a href="https://amzn.to/2JJCxii">air powered caulk gun</a> and 
laid down a bead about 9mm tall on the seam. The air powered caulk gun was absolutely essential; the U-428 is so thick that you could never
extrude it from a hand powered gun. I had the regulator on my compressor at nearly 60 PSI to get it to flow. I only ended up using one tube, but this isn’t the kind of job you can afford to run out of adhesive 90% of the way through!</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-13%2018.49.28.jpg" alt="Applying Urethane"></p>

<p>With a helper, I lifted the windshield in and set it in place. We made final position adjustments and taped it in place with some blue tape. 
For the temperature and humidity of my location, Dow calls for at least 5 hours of cure time before drive-off.</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-13%2019.06.36.jpg" alt="Blue tape"></p>

<p>Overall, a pretty long process but nothing an experienced garage fabricator couldn’t do on their own. The final result doesn’t look too bad:</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-14%2012.44.17.jpg" alt="Finished image"></p>

<p>I’m sure it’s a horrible misuse of the urethane, but I had a few grams left over, so I used it to glue the perpetually falling off glovebox back together:</p>

<p><img src="http://fewstreet.com/images/volvo_windshield/2018-06-13%2021.28.39.jpg" alt="Blue tape"></p>

  </div>
</div>


    


    

  </div></div>]]>
            </description>
            <link>http://fewstreet.com/2018/06/13/volvo-240-windshield.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23754371</guid>
            <pubDate>Tue, 07 Jul 2020 00:31:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You need domain name insurance]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23754056">thread link</a>) | @bhartzer
<br/>
July 6, 2020 | https://dnprotect.com/legal/how-it-works | <a href="https://web.archive.org/web/*/https://dnprotect.com/legal/how-it-works">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="routerOutlet" fxflex=""><router-outlet></router-outlet><app-how-it-works _nghost-sc269=""><h2 _ngcontent-sc269="">How It Works</h2><h3 _ngcontent-sc269="">DNProtect Score</h3><p _ngcontent-sc269=""> DNProtect wants to help you make sure that your domain name, especially if it is used for a website and email, is set up properly and protected to minimize risk. We have created our proprietary DNP Score to help visualize the risk involved with owning and operating a website on a particular domain name. DNP Score is similar to an individual's credit score or a company's business rating.
</p><p _ngcontent-sc269=""> Many different risk factors are involved when you own an internet domain name. Risk factors can impede or literally halt the ability to use a particular domain name for commerce. Certain factors can potentially lead to theft of the domain name, loss of the domain name to another party, or cause a significant loss of internet traffic to the website on that domain name. Other issues such as domain ownership disputes, being put on email blacklists, malware, or being de-listed or banned in internet search engines can cause problems and loss of revenue.
</p><p _ngcontent-sc269=""> DNProtect's DNP Score takes many different risk potential risk factors into account. Our proprietary DNP Scoring system collects the necessary risk data, processes that data, and assigns a value (positive or negative) to each risk factor. The scoring system then calculates the resulting DNP Score for each domain name. The DNP Score is based on a scale of up to 750 points. Every domain name begins with a median score of 400. Then, positive risk factors and negative risk factors are applied to the score. A higher DNP Score means that the domain name has less risk overall. A lower DNP Score means that the domain name has more risk.
</p><p _ngcontent-sc269=""> It's important to own an internet domain name that has a higher DNP Score because the higher the score the less risk is involved. If you are using that domain name for your website and/or email, then a higher DNP Score means that you minimize the risk of having your website go down, having your email stop working, and your website traffic and sales go down.
</p><p _ngcontent-sc269=""> Learn more about how the <a _ngcontent-sc269="" routerlink="/legal/about-dnp-score" href="https://dnprotect.com/legal/about-dnp-score">DNP Score</a> is calculated.
</p><h3 _ngcontent-sc269="">DNProtect Domain Name Insurance</h3><p _ngcontent-sc269=""> DNProtect provides protection for your domain name. By insuring your domain name with Domain Name Ownership Coverage, DNProtect helps protect your domain name from loss of ownership of the domain name due to:
</p><ul _ngcontent-sc269=""><li _ngcontent-sc269="">Theft of the domain name.</li><li _ngcontent-sc269="">Loss due to a domain name dispute.</li><li _ngcontent-sc269="">Other issues, such as trademark issues with the domain name.</li></ul><p _ngcontent-sc269=""> The premium of the insurance is based partly on the DNP Score of the domain name, as well as the amount of coverage we provide. Our DNProtect wizard will help you determine the amount of coverage you should have on your domain name. For example, if you lost ownership of the domain name tomorrow, what would it cost you to replace the domain name?
</p><p _ngcontent-sc269=""> Do you have any of the following that contains your domain name? If you lost ownership of the domain name, what would it cost to replace the following?
</p><ul _ngcontent-sc269=""><li _ngcontent-sc269="">Print, Radio, or Television Advertising</li><li _ngcontent-sc269="">Trade Show Marketing</li><li _ngcontent-sc269="">Billboard or Outdoor Advertising</li><li _ngcontent-sc269="">Social Media Account(s)</li><li _ngcontent-sc269="">Vehicle Wraps</li><li _ngcontent-sc269="">Letterhead, Business Cards, Brochures, Sales Literature</li><li _ngcontent-sc269="">Email Addresses</li></ul><p _ngcontent-sc269=""> Use the DNProtect wizard to help you realize the true cost of replacing a domain name. We will then be in touch with you with a no-obligation quote for DNProtect domain name protection.
</p></app-how-it-works><!----></div></div>]]>
            </description>
            <link>https://dnprotect.com/legal/how-it-works</link>
            <guid isPermaLink="false">hacker-news-small-sites-23754056</guid>
            <pubDate>Mon, 06 Jul 2020 23:44:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[REST – Idempotency and Safety]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23754015">thread link</a>) | @pradeepl
<br/>
July 6, 2020 | https://pradeeploganathan.com/rest/rest-idempotency-safety/ | <a href="https://web.archive.org/web/*/https://pradeeploganathan.com/rest/rest-idempotency-safety/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-148">
														
							
														
							
														
							<div>
															<div>
									
<p>Implementing HTTP’s uniform interface&nbsp;as discussed in the previous <a rel="noopener noreferrer" href="https://pradeeploganathan.com/2016/09/20/rest-communicating-with-verbs-and-status-codes/" target="_blank">posts</a> has a surprisingly good architectural side effect. If it is Implemented as specified in the REST specifications (HTTP specification – RFC 2616), you get two useful properties namely Idempotency and Safety.</p>



<h3>Safety</h3>



<p>Safety is the ability to invoke an operation without&nbsp;any side effects arising out of the client invoking&nbsp;that operation. It means that the client can invoke an operation&nbsp;with the explicit knowledge that it is not going to change the state of the resource on the server. However, it does not mean that the server should return the same response every time. The server can also perform additional actions when these methods are invoked such as logging calls or incrementing counters etc. but these should not change the state of the resource being acted upon. Generally, read only methods are safe methods. GET, HEAD and OPTIONS are safe methods.</p>



<h3>Idempotency</h3>



<p>Idempotency means that the effect of doing something multiple times&nbsp;will be the same as the effect of doing it only once. A simple example from Math’s&nbsp;would be the effect of multiplying any number by One. In math the number 1 is an idempotent of multiplication. e.g. 5 x 1 = 5 which is the same as 5 x 1 x 1 = 5. Similarly, an API operation that sets a user’s name is a typically idempotent operation. Whether it is called once&nbsp;or multiple&nbsp;times, the effect of the operation is that the user’s name will be set to the target value. Deleting a resource is an example of this distinction; the first time you invoke the delete, the object is deleted. The second time you attempt to delete it, there is no change in the state of the system, but the object remains deleted as requested. An idempotent operation generates no side effects.</p>



<p>Idempotency results in improved reliability, concurrency, prevents data loss and provides the ability to automatically retry /recover from failures. It improves reliability by providing the&nbsp;ability to safely retry requests that may or may not have been processed. This helps tide over network glitches and load spikes by replaying requests. Load balancers like HAProxy can retry requests when the server disconnects abruptly providing automatic recovery from failures. Since API calls are idempotent multiple API calls can be run concurrently without locks and mutexes to synchronize operations on data. This increases concurrency and system throughput resulting in better performance.</p>



<p>Safety and Idempotency let a client make reliable HTTP requests over an unreliable network. If you make a GET request and never get a response, just make another one. It’s safe even if your earlier request was fulfilled since&nbsp;it didn’t have any real effect on the state of the resource server. If you make a PUT request and never get a response, just make another one. If&nbsp;your earlier request got through, your second request will have no additional effect since PUT is&nbsp;idempotent and the operation can be repeated.</p>



<p>The following table lists shows you which HTTP method is safe, and which is&nbsp;idempotent</p>



<figure><table><thead><tr><th>HTTP Method</th><th>Safe</th><th>Idempotent</th></tr></thead><tbody><tr><td>&nbsp;GET</td><td>&nbsp;Yes</td><td>&nbsp;Yes</td></tr><tr><td>&nbsp;POST</td><td>&nbsp;No</td><td>&nbsp;No</td></tr><tr><td>&nbsp;PUT</td><td>No</td><td>&nbsp;Yes</td></tr><tr><td>&nbsp;DELETE</td><td>No</td><td>&nbsp;Yes</td></tr><tr><td>&nbsp;HEAD</td><td>Yes</td><td>&nbsp;Yes</td></tr><tr><td>&nbsp;OPTIONS</td><td>Yes</td><td>&nbsp;Yes</td></tr></tbody></table></figure>



<p>GET, HEAD, OPTIONS, PUT&nbsp;and DELETE requests are idempotent. If you DELETE a resource, it’s gone. If&nbsp;you DELETE it again, it’s still gone. The response codes in the above two requests can differ to indicate that the resource representation being deleted is gone. Two simultaneous Delete requests may result in the first request getting a 200 (OK) and the second request&nbsp;getting a 204&nbsp;(NO CONTENT).If you create a new resource with PUT, and then&nbsp;resend the PUT request, the resource is still there and it has the same properties you&nbsp;gave it when you created it. Making an absolute&nbsp;update to a resource’s state or deleting it outright has the same outcome whether&nbsp;the operation is attempted once or many times. Again, a PUT request can have differing return codes based on the validation done. It can be a 200 (OK) for a successful PUT or a 409 (Conflict) for a PUT where the server resource state is different from the one referenced by the client. A GET or HEAD request should be safe: a client that makes a GET or HEAD request&nbsp;is not requesting any changes to server state. Making any number of GET requests&nbsp;to a certain URI should have the same practical effect as making no requests at all. The safe methods, GET and HEAD, are automatically idempotent as well. POST is neither safe nor idempotent. Making two identical POST requests&nbsp;will result in two subordinate resources containing the same&nbsp;information.</p>



<p>Developing API’s requires us to adhere to the REST semantics which specifies the safety and idempotency requirements for the various verbs as shown in the table above. API consumers will and should expect GET to be safe and idempotent. Similarly, API consumers will incorporate logic to manage additional factors since POST is neither safe nor idempotent.</p>
<div id="snippet-box"><p>Summary</p><div itemscope="" itemtype="https://schema.org/Article"><div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject"><p><img width="180" src="https://pradeeploganathan.com/wp-content/uploads/2016/09/pop-zebra-wp81DxKUd1E-unsplash-scaled.jpg" alt="REST - Idempotency and Safety" data-lazy-src="https://pradeeploganathan.com/wp-content/uploads/2016/09/pop-zebra-wp81DxKUd1E-unsplash-scaled.jpg?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><meta itemprop="url" content="https://pradeeploganathan.com/wp-content/uploads/2016/09/pop-zebra-wp81DxKUd1E-unsplash-scaled.jpg"></div><div><p>Article Name</p><p><span itemprop="headline">REST - Idempotency and Safety</span></p><p>Description</p><p><span itemprop="description">Implementing HTTP’s uniform interface as discussed in the previous posts has a surprisingly good architectural side effect. If it is Implemented as specified in the REST specifications (HTTP specification - RFC 2616), you get two useful properties namely Idempotency and Safety.</span></p><p>Author</p>
							<div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><p>Publisher Name</p><p><span itemprop="name">https://pradeeploganathan.com</span>
							</p>
							

							<p>Publisher Logo</p><div itemprop="logo" itemscope="" itemtype="https://schema.org/ImageObject"><p><img width="180" src="https://pradeeploganathan.com/wp-content/uploads/2020/02/AllSeeingEye.jpg" alt="https://pradeeploganathan.com" data-lazy-src="https://pradeeploganathan.com/wp-content/uploads/2020/02/AllSeeingEye.jpg?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><meta itemprop="url" content="https://pradeeploganathan.com/wp-content/uploads/2020/02/AllSeeingEye.jpg"></div></div><meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://pradeeploganathan.com/rest/rest-idempotency-safety/"><meta itemprop="datePublished" content="2016-09-24T05:59:36+10:00"><meta itemprop="dateModified" content="2020-07-07T09:37:13+10:00"></div>
					</div></div></div>
														</div>
														

																				</article></div>]]>
            </description>
            <link>https://pradeeploganathan.com/rest/rest-idempotency-safety/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23754015</guid>
            <pubDate>Mon, 06 Jul 2020 23:37:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rhetoric of Disagreement (1989) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23753914">thread link</a>) | @claudiawerner
<br/>
July 6, 2020 | http://www.deirdremccloskey.org/docs/pdf/Article_128.pdf | <a href="https://web.archive.org/web/*/http://www.deirdremccloskey.org/docs/pdf/Article_128.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.deirdremccloskey.org/docs/pdf/Article_128.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23753914</guid>
            <pubDate>Mon, 06 Jul 2020 23:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23753769">thread link</a>) | @lacker
<br/>
July 6, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve been playing around with OpenAI’s new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I’m generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn’t
specific to a conversational format, and it isn’t trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a “prompt”. I’m using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I’m not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we’re doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at “common sense”. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to “common sense” questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of “debug output” to answer that question. I don’t know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It’s only 4/5. We’re closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn’t any web page that compares
toasters and pencils by weight. It’s only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we’re getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn’t quite know how to say “Wait a
moment… your question is nonsense.” It also doesn’t know how to say
“I don’t know.”</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you’re a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don’t want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn’t know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn’t exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We’ll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn’t
just the generic model, though, it’s also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It’s funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn’t quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23753769</guid>
            <pubDate>Mon, 06 Jul 2020 23:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Achaemenid Shields Are a Puzzle]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23753604">thread link</a>) | @diodorus
<br/>
July 6, 2020 | https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/ | <a href="https://web.archive.org/web/*/https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- end .post-extras -->

		<div>
			<div data-shortcode="caption" id="attachment_7331"><p><a href="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg"><img aria-describedby="caption-attachment-7331" data-attachment-id="7331" data-permalink="https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/fig_6_2_six_shields/" data-orig-file="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg" data-orig-size="1600,2400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fig_6_2_six_shields" data-image-description="" data-medium-file="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=200" data-large-file="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=529" src="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=529&amp;h=794" alt="" width="529" height="794" srcset="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=529&amp;h=794 529w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=1058&amp;h=1588 1058w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=100&amp;h=150 100w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=200&amp;h=300 200w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=768&amp;h=1152 768w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=683&amp;h=1024 683w" sizes="(max-width: 529px) 100vw, 529px"></a></p><p id="caption-attachment-7331">Figure 6-2 from my forthcoming book from Franz Steiner Verlag.  Some types of <em>gerron</em> (wicker shield) used in the Achaemenid empire in the time of Darius I and Xerxes.  Top: <em>peltē</em> and wooden imitation of a sticks-and-leather shield from Tuekta in the Altai (different sections of ‘sticks’ are painted red, white, and black; similar shields appear in Neo-Assyrian art). Middle: rectangular wicker shields.  Bottom: violin-shaped or figure-eight shields.  Note that they are worn on the arm like a <em>peltē</em> or an Argive shield, not held in the fist like the Tuekta shield.  Source: The J. Paul Getty Museum, Malibu CA, no. 83.AE.247 (digital image courtesy of the Getty’s Open Content Program), State Hermitage Museum, St. Petersburg, no. 2179/96 (photo by author); Gerhard 1847: Taf. CLXVI; western entrance of the Tachara of Darius (sketch by author), Persepolis; two reliefs on the Apadana, Persepolis (photo by author)</p></div>
<p>  If you look at modern paintings and miniatures, you would think we have a good idea of the type of shield used by Achaemenid infantry in the time of Darius and Xerxes.  They cite <a href="http://www.perseus.tufts.edu/hopper/text?doc=Hdt.+7.61&amp;fromdoc=Perseus%3Atext%3A1999.01.0126">Herodotus book 7 chapter 61</a> and show the large rectangular kind on the middle row of the picture above.  But as I argue in chapter 6.5.2 of my forthcoming book from Franz Steiner Verlag, things are more complicated.  These large rectangular shields appear on the doorposts of two buildings at Persepolis and on two or three vases from Athens (out of thousands of soldiers at Persepolis and Susa and thousands of Red Figure vases). The person who published the sketch on the middle left thought it showed a battle against the Phrygian allies of the Amazons.  And this type of shield does not agree with Herodotus’ words that quivers were hanging beneath the shields, unless we understand ‘beneath’ quite loosely.<br>
<span id="more-7332"></span></p>
<p>  The type in the top row is also popular with artists, but it seems specific to the Aegean/Sea of Marmara/Black Sea region.  Warriors of all the different nations in this region used small round, rectangular, or crescent-shaped shields, often made of wicker or covered with goatskin, but we do not see these shields in artwork from the heart of the empire.  Its also hard to imagine these forming a barrier which needed to be knocked over after a long struggle, like Herodotus describes.  But they are the type of shield which artists from Athens most often put in the hands of foreigners, probably because the Athenians were a bit provincial and Thracians and Scythians were the most exotic warriors they were familiar with.</p>
<p>  The type in the bottom row is the most common type at Persepolis, but it does not show up in Greek art at all.  This might be because it was too similar to the Boeotian or dipylon or figure-eight shield and Greek artists felt that it did not say ‘barbarian.’  A bronze boss for such a shield was found at Samos.  It is easy to imagine quivers hanging beneath such a shield, but hard to imagine them forming a solid barrier which needed to be pushed over.  </p>
<p>  We see even more types of shield in art from the empire, such as the small round center-grip shield on the Çan sarcophagus or the big deep round wicker shields carried by ?Thracians? at Persepolis.  But these three types in the three rows are the ones people today are most interested in.</p>
<p>  Diodorus describes the Persian shields at Thermopylae a bit differently than Herodotus describes them at Plataia (11.7.3, my translation) “For the barbarians used small <em>aspides</em> and <em>peltai</em> which were advantageous in broad open spaces, being easy to move, so because of the narrow space they were not able to harm their enemies very well because they were packed close together with their whole bodies covered with the great <em>aspides</em>, while being at a disadvantage because of the lightness of their defensive arms, they suffered wound after wound.”  He seems to imagine Persian warriors using <em>peltai</em> like the barbarians in paintings (Xen. Cyr. 1.2.13)</p>
<p>  People in my lifetime have written a lot of nonsense about wicker shields supposedly being ‘light’ or ‘weak.’  I don’t know of any tests of this, and traditional wooden shields tend to be thinner and lighter than people expect (like 8 mm thick wood plus a layer of linen or parchment in the centre, and 3-5 mm thick wood plus a layer of linen or parchment at the edge).  Modern wooden shields often use heavy plywood and rawhide so the shield can stand up to pounding with blunt weapons: the fact that these shields are unnecessarily heavy is not important because the owners don’t have to march 20 miles with them on their backs, camp, cook dinner, and march 20 miles again.  Tough warriors like the Ottoman Turks used wicker shields and I don’t know of any of their opponents who said that these were poor protection.  Also, until about the time of Xerxes’ punitive expedition against the Ionians-beyond-the-sea, Greek art often shows spearmen with a light figure-eight shields (Dipylon shields, Boeotian shields) which may well have been made of leather or wicker.  Neither art not archaeology shows that all Greek “bearers of spear and shield” in 480 BCE carried a heavy Argive shield and a single long thrusting lance.</p>
<p>  The type of shield in the middle row is the best fit for Herodotus’ descriptions of combat, but not the most common type in art, and it does not match his description of how Persian soldiers were armed.  And as we saw, <a href="https://bookandsword.com/2019/07/06/provisions-loin-girdling-and-battle-gear-in-the-long-sixth-century/">lists of equipment for soldiers in Babylonia</a> do not seem to mention shields at all.  So like a lot of things in ancient history, the idea that Xerxes’ men carried large rectangular wicker shields is our best guess based on pretty thin evidence, not something certain.</p>
<p><em>Further Reading:</em> There are tests of arrows against reproductions of sticks-through-rawhide shields based on artefacts from Dura Europos and Pazyrzk in Barry Molloy’s <em>The Cutting Edge</em> (Tempus: Stroud, 2007) [ISBN 9780752441696 on <a href="https://www.bookfinder.com/search/?isbn=9780752441696&amp;st=xl&amp;ac=qr">Bookfinder</a>]</p>
<p><strong>Don’t leave my sites naked against a hail of financial arrows!  Support them on <a href="https://www.patreon.com/bookandswordblog">Patreon</a> or <a href="https://www.paypal.me/bookandswordblog">paypal.me</a> or even <a href="https://liberapay.com/bookandswordblog/">liberapay</a></strong></p>
<p><em>Edit 2020-07-08:</em> Hi Hacker News!  <a href="https://news.ycombinator.com/item?id=23753604" rel="nofollow">https://news.ycombinator.com/item?id=23753604</a><br>
<a href="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png"><img data-attachment-id="7751" data-permalink="https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/2020-07-08_traffic_cropped/" data-orig-file="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png" data-orig-size="989,236" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-07-08_traffic_cropped" data-image-description="" data-medium-file="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=300" data-large-file="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=529" src="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=529&amp;h=126" alt="a bar chart of one month's traffic where half of all hits are on one day towards the end" width="529" height="126" srcset="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=529&amp;h=126 529w, https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=150&amp;h=36 150w, https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=300&amp;h=72 300w, https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=768&amp;h=183 768w, https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png 989w" sizes="(max-width: 529px) 100vw, 529px"></a></p>
					</div><!-- end .post-entry -->
	</div></div>]]>
            </description>
            <link>https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23753604</guid>
            <pubDate>Mon, 06 Jul 2020 22:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great Year for a Gap Year]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23753511">thread link</a>) | @webcerfer2020
<br/>
July 6, 2020 | https://blogofjake.com/2020/07/06/great-year-for-a-gap-year/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/07/06/great-year-for-a-gap-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1070">
			<!-- .entry-header -->		<!-- .entry-meta -->
	
	<div>
		
<p>I became a better version of myself by taking a gap year after my freshman year of college. 6 years later, I am in the middle of a second gap year. I am convinced taking a gap year is one of the best things a person can do. Here is basically why:</p>



<p>A gap year is an opportunity to do what you like. When you can do what you like, you learn what you like to do. It is good to know what you like to do. It feels great to do what you like.</p>



<p>You can do anything in a gap year. You can start a business. You can start a blog. You can travel the world. You can live somewhere new. You can run a marathon. You can lose 30 pounds. I know you can do these things and more because I did.</p>



<p>I am happier, healthier, and wealthier than I would have been without a gap year. I am smarter and wiser. I am more positive and grateful. I have a better sense of purpose. I have a better set of habits. I make better decisions. They make me a better person.</p>



<p>Of course, if you are not convinced on the greatness of the gap year, you can always pay full tuition for the opportunity to volunteer in your college’s upcoming online experiment.</p>



<p>If you are past college like I am, I have one more thing to tell you. It is never too late.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]>
            </description>
            <link>https://blogofjake.com/2020/07/06/great-year-for-a-gap-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23753511</guid>
            <pubDate>Mon, 06 Jul 2020 22:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you should share your salary]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23753402">thread link</a>) | @miraantabrez
<br/>
July 6, 2020 | https://miraan.co.uk/posts/why-you-should-share-your-salary/ | <a href="https://web.archive.org/web/*/https://miraan.co.uk/posts/why-you-should-share-your-salary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h2 id="eliminating-one-of-the-darker-sides-of-capitalism">Eliminating one of the darker sides of capitalism</h2>

<p>There’s no reason companies should keep salaries a secret.</p>

<p>If salaries are determined rationally, according to principles that everyone in the company would agree to, then there’s nothing to hide.</p>

<p>When salaries are hidden, employees can be paid much less than they’re worth. The underpaid employees won’t know they’re underpaid. So they won’t ask for a raise, and they won’t go looking for another job.</p>

<p>If salaries are public, employees will know their true market worth. More importantly, they’ll know their <em>potential future</em> market worth which lets them make informed life choices.</p>

<p>Your salary can have a huge impact on your life trajectory. It’s most people’s only source of income. It determines where you can live, what house you can buy, how often you can travel, when you can retire and how much time you get to spend on hobbies, personal projects or with family and friends. If you have kids, it determines how much you can spend on them too.</p>

<p>But salary information is still so opaque that people can’t effectively plan their financial future.</p>

<p>When I was a fresh computer science grad, I had no idea what salary to expect when applying for software engineering jobs. I got a couple of offers and accepted one from a London tech startup.</p>

<p>But after a year at the startup, I wanted to see what else was out there. I applied to Facebook and got an offer that was double my current compensation. I was blown away and counted myself lucky to stumble onto this information early in my career.</p>

<p>An old colleague also had no idea what he could be making if he switched jobs. He recently joined Facebook too and tripled his salary. It’s significantly changed his life trajectory. But here’s the crazy thing — if I hadn’t told him what he could be making at Facebook, he still might not have known. He still might be making 3x less than he is now.</p>

<p>It’s sad to think that many will be in this situation for years. They’ll spend a significant part of their life working for a company that is underpaying them. And this is mainly due to keeping salaries secret.</p>

<p>In most other parts of our life, we know what’s out there and how it compares to what we have. When we buy a car, we can compare the options objectively and make an informed decision. When we buy a house, we can do the same thing. The market is mostly fair and efficient because information is readily available.</p>

<p>But the choice that impacts people the most — the job that determines their financial future and what they spend most of their prime waking hours on — is not given the same treatment.</p>

<p>Companies have intentionally hidden salaries to make the labour market unfair and inefficient. They exploit this inefficiency by underpaying their employees so they can make more money. This is a darker side of capitalism which should be eliminated. Consider that we already send people to jail when they exploit nonpublic information in the stock market.</p>

<p>Sharing your own salary makes the labour market fairer and more efficient. It opens people’s eyes to their true market worth, but more importantly, their <em>potential future</em> market worth.</p>

<p>For a student, having the right information can alter their life trajectory. Knowing the market value of different skills can inform what they choose to study and specialize in. The same is true for working professionals.</p>

<p>Compensation at Facebook is mostly formulaic and everyone is pretty open internally about how much they’re paid. But not much is shared externally. If you want to explore tech salaries for yourself, <a href="https://www.levels.fyi/">levels.fyi</a> is a great resource.</p>

<p>In the next post I’ll break down my own software engineering salary at Facebook.</p>


<p><a href="https://twitter.com/miraan_tabrez" data-show-count="false">Follow @miraan_tabrez</a></p>




</div></div>]]>
            </description>
            <link>https://miraan.co.uk/posts/why-you-should-share-your-salary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23753402</guid>
            <pubDate>Mon, 06 Jul 2020 22:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Guarantee Success at Work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23753084">thread link</a>) | @joebalcom
<br/>
July 6, 2020 | https://joebalcom.blog/2020/07/06/success-at-work/ | <a href="https://web.archive.org/web/*/https://joebalcom.blog/2020/07/06/success-at-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1452">
		<!-- .entry-header -->

	
	<div>
		
<figure><img data-attachment-id="1454" data-permalink="https://joebalcom.blog/2020/07/06/stand-out-at-work/photo-1516659257916-7be846591235/" data-orig-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?fit=1350%2C900&amp;ssl=1" data-orig-size="1350,900" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="photo-1516659257916-7be846591235" data-image-description="" data-medium-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?fit=525%2C350&amp;ssl=1" src="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?fit=525%2C350&amp;ssl=1" alt="The one thing you can do to stand out at work." width="644" height="429" srcset="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?w=1350&amp;ssl=1 1350w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=350%2C233&amp;ssl=1 350w" sizes="(max-width: 525px) 100vw, 525px" data-lazy-srcset="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?w=1350&amp;ssl=1 1350w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?resize=350%2C233&amp;ssl=1 350w" data-lazy-src="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/07/photo-1516659257916-7be846591235.jpg?fit=525%2C350&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>If you’re looking for a hack that will put you on the fast track to success at work, I have something for you.</p>



<p>You might not like it.</p>



<p>You might hate it.</p>



<p>You might even despise it so much that you do the opposite.</p>



<p>But sometimes we all must take our medicine and do what it takes to move onward and upward.</p>



<h3><strong>Going Against the Grain of Going Against the Grain</strong></h3>



<p>I know, I know. Since I started this blog, I’ve been doing a lot of railing against the idea of working for someone else. While I do not back down from my stance one bit, I do realize that not everyone <em>wants</em> to work for themselves. I’ve been doing a lot of thinking and a lot of studying on the topic of work, and I feel confident enough to divide the workforce into three camps:</p>



<p><strong>Group A: The small percentage of people who love their jobs</strong>. People in this camp find meaning and enjoyment in the work they do, and their salary is comfortable enough to support their preferred lifestyle. Kudos to these people! They have found the nexus between their version of meaningful work and financial freedom. To achieve this outcome is the ultimate purpose of why I write about <em>work</em>.</p>



<p><strong>Group B: People who hate their jobs and are looking for an alternate path</strong> to meaningful work and financial freedom. Finding suitable answers for these folks is my primary objective, and I find myself in the unique position of creating my own answer to this problem in the process.</p>



<p>There is a third and under-represented camp: <strong>Group C, the silent majority</strong>. These are people who don’t like one or more aspects of their job, but simply don’t feel the need or the urge to venture out on their own. If you find yourself in this camp, this article is for you.</p>







<h3><strong>The Status Quo Is Unacceptable</strong></h3>



<p>If you read <a href="https://joebalcom.blog/2020/06/05/ordinary/">How to be Extraordinarily Ordinary</a>, you’ll see my disdain for the status quo on full display. That post was a bit tongue in cheek, but I will not mince words in this post.</p>



<p>There are a million and one reasons for someone not to like their job. Ranging from pay rates to petty office politics. From specific job functions to Pam from three cubicles way receiving preferential treatment. From not enough hours to too many hours. The list never ends. But one thing is for certain: <em>very few grievances are ever made known to those with the power to change it.</em></p>



<p>The rest are suppressed, hidden from sight, slowly growing into intense misery. This intense misery subsides after a while into dull indifference and acceptance. Selfishness and the “what’s in it for me” mindset sets in, and newer employees are quickly influenced to follow the same path. This is the life cycle of status quo acceptance.</p>



<p>What I learned as an employee is that arranging a work environment conducive to happiness and success is not as hard as you would think. If you simply take the time to sit down with management to lay out your grievances, most of the time you can work something out. And in the rare instance they are not willing to work with you, then it’s a clear sign that you probably should move on.</p>



<p>What I learned from <em>leading</em> 80+ restaurant employees is that disgruntled employees are an inevitable part of managing such a complex system. There are so many moving parts in a large organization that you won’t be able to please everyone all the time. But the astonishing part is that most grievances will go undiscussed, no matter how open the door is. Employees who do not speak up will be condemned to their displeasure, and will inevitably poison the well. For those employees, this becomes a self-fulfilling prophecy.</p>



<p>In order to give success and happiness at work a fighting chance, you cannot accept a status quo that does not work for you. But <a href="https://joebalcom.blog/2020/06/08/12-lessons/">if you find that you cannot extract yourself from the situation</a>, your only choice is to lean into your work.</p>



<h3><strong>How to Get Ahead at </strong><strong>Work</strong></h3>



<p>I’ve been on both sides of the fence and have experienced both perspectives of what is called the <a href="https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem#:~:text=The%20principal%E2%80%93agent%20problem%2C%20in,entity%3A%20the%20%22principal%22.">Principal-Agent Problem</a>. To put it simply, the principal (the owner or boss) has the incentives to do what is best for the good of the firm. The agent (the employee) often only has incentives to do what is best for themselves.</p>



<p>The norms of mediocrity have made this dichotomy an unfortunate reality. Most agents just don’t care enough about what the principal cares about. Different incentives, different goals.</p>



<p>As an agent who is committed to the firm, your best path forward is to <strong>think like the owner</strong>. It is the one thing you can do to guarantee getting ahead. When your aspirations are aligned with those of the owner, you instantly put yourself on the fast track to success.</p>



<h3><strong>Think Like an Owner and You Will Become the Owner</strong></h3>



<p>On the spectrum of happiness, those people closest to maximal happiness tend to be the ones in control of their own destiny. This simple fact is why I have repeatedly advocated for you to take an alternate path, take ownership of every aspect of your life, and leave the crowd behind.</p>



<p>If working for yourself is not an option in your mind, then your only option for true success and happiness at work is to lean into your work and <em>be excellent</em>. To be excellent in your workplace:</p>



<ul><li>Never say “that’s not my job.”</li><li>“How can I help” needs to become an instinct.</li><li>Become a leader within the organization, regardless of your title.</li><li>Don’t wait for someone to tell you to do the work that needs to be done.</li><li>Avoid petty workplace politics.</li><li>Take ownership of everything you do. No excuses.</li><li>Be consistent. The principal has to show up every day, and so should you.</li></ul>



<p>To illustrate this, I’ll tell you about an employee, who worked for me at the restaurant I managed, named Mike. Mike personified every single item on the above list. He was a college student and a busser, but he was so meticulous, so consistent, and so reliable that he earned the nickname “Cap,” as in Captain America.</p>



<p>I was so impressed by his work ethic and attitude, that I offered to promote him on more than one occasion. He turned down my offer every time because he believed what he was doing was the most effective way for him to help the restaurant.</p>



<p>The job wasn’t glamorous, but he leaned into his responsibilities in a way that earned him freedom, trust, and a sense of meaning in his work.</p>



<p>I’m confident that because he thinks like an owner, Mike will one day become an owner.</p>



<h3><strong>The Clear Path Ahead</strong></h3>



<p>There is a clear path to controlling your destiny within the confines of working for someone else. This path is not easy, you might not like it initially, but it will yield the most satisfying results over the long run.</p>



<p>By operating from a position of abundance, by going the extra mile to help others look good, by inspiring and lifting others around you, you will stand out above the rest over time.</p>



<p>I’ll finish with a quote from Naval Ravikant, who sums it up nicely: “If you think like the owner, and you act like the owner, it’s only a matter of time until you become the owner.”</p>



<p>###</p>



<p>Thank you so much for reading. If you enjoyed this post, please share it with someone who needs it! </p>









	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://joebalcom.blog/2020/07/06/success-at-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23753084</guid>
            <pubDate>Mon, 06 Jul 2020 21:37:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Data Science Is Past]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752931">thread link</a>) | @srean
<br/>
July 6, 2020 | https://koaning.io/posts/the-future-is-past/ | <a href="https://web.archive.org/web/*/https://koaning.io/posts/the-future-is-past/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/future-past-draw.png"></p>
<p>After some reflection with friends and colleagues I can’t help but observe an odd fact:</p>
<p><strong>the Future of Data Science is Past</strong></p>
<p>This isn’t because data scientists try to predict the past (which granted, is pretty funny and ironic). It is also because hype and other circumstances have turned data science into a field of inflated expectations. It feels more like a certain type of dream got pushed (even sold) that didn’t solve all the problems that people were hoping for.</p>
<p>After I started hearing that a lot of data projects fail (here’s a nice example on <a href="https://www.reddit.com/r/MachineLearning/comments/beoxx8/discussion_when_ml_and_data_science_are_the_death/">reddit</a>) I started thinking about what was going on. Five years ago the future was so bright that some of us may have been blinded by it. In short, the hype around algorithms forgot to mention that:</p>
<ul>
<li>algorithms are merely cogs in a system</li>
<li>algorithms don’t understand problems</li>
<li>algorithms aren’t creative solutions</li>
<li>algorithms live in a mess</li>
</ul>
<p>In this document I’d like to address these points one by one so that I have something to refer to. I realise that I sound a bit cynical but I’ll end the blog with some hope.</p>
<h2 id="algorithms-are-merely-cogs-in-a-system">Algorithms are Merely Cogs in a System</h2>
<p>I was once put in a team to design a recommendation service for the Dutch BBC. One of the first things we did was make a drawing of what the service should look like. It looked something like this.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/main_setup_numbers.png"></p>
<p>There were different parts of this design:</p>
<ol type="1">
<li>The UI layer</li>
<li>The AB splitting mechanism - we need this is we ever want to compare two algorithms.</li>
<li>The database that caches recommendations - we need this because at scale we cannot calculate these in real time</li>
<li>The scheduler that triggers a cluster to make calculations - we want to incorporate new data on a daily/hourly basis</li>
<li>An algorithm that calculates new recommendations - this is the data science code that takes log files and produces recommendations</li>
<li>The fallback/checker mechanism that ensures we only recommend things we’re allowed to recommend.</li>
</ol>
<p>Out of all these parts the final part (#6) is the most important in this system. It is the part that guarantees that we always have something to recommend even if any part before breaks. It is also the part that ensures that we always adhere to some very important business rules. Business rules like;</p>
<ul>
<li>make sure that we don’t violate a license (some content may only shown during certain parts of the day)</li>
<li>make sure that we don’t show mature content before 22:00</li>
<li>make sure we don’t recommend violent shows after a kids show</li>
</ul>
<p>It is unrealistic that a self learning algorithm is able to pick up these rules as hard constraints so it makes sense to handle this elsewhere in the system. With that in mind; notice how the algorithm is only a small cog in the entire system. The jupyter notebook that contains the recommender algorithm is <strong>not</strong> the investment that needs to be made by the team but rather it is all the stuff around the algorithm that requires practically <em>all</em> the work. Note that step 5 also requires communication with a big data cluster which also demonstrates that a recommender is more of an engineering investment than an algorithmic one. You don’t want a pure scientist team here, you need solid engineers and developers.</p>
<p>This is besides the fact that a lot of good algorithms can be created with simple heuristics that don’t require a maths degree. One could:</p>
<ul>
<li>recommend content that is often watched together</li>
<li>recommend content that is often watched together unless it is too popular</li>
<li>recommend the next episode</li>
</ul>
<p>These are all fair options to at least benchmark. I would also like to point out that the latter idea is a great idea even it isn’t technically machine learning. It should compete with any deep learning algorithm, any day.</p>
<h2 id="algorithms-dont-understand-problems">Algorithms don’t Understand Problems</h2>
<p>It takes a team a lot of time to realise what problem it is actually solving. Getting this right is hard. It’s even harder when the majority of the team consists of the same people. Worse; these people are trained in machine learning and prefer to keep themselves to the algorithmic part of their work.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/circle-half.png"></p>
<p>Thing can go wrong in this situation. The team might not be great at translating the actual problem into an algorithm that represents the business. At the same time, the business might not be able to adapt to a recommendation that comes out of the algorithm. Even worse, it is also possible that the algorithmic solution brings in new problems. If you’re unlucky these new problems can get translated into new algorithmic problems. Before you know it you’re stuck in a loop.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/circle-full.png"></p>
<p>People with an algorithmic background usually tackle a problem in isolation of the system that it is in. A better approach is not to focus on the isolated part but to focus on the communication between two parts of the system. If this is not part of the problem design from the get-go then you’re bound to waste resources until you realise it has to.</p>
<p>Let’s remember the recommender usecase. It is a bad idea to expect the algorithm to magically understand that it cannot recommend mature content before 22:00. When you realise this you know that you need a checking system between the algorithm and the serving layer. It is good to realise this early in the project and not when a large chunk of the code needs to get rewritten.</p>
<p>One potential cure against this “isolation” way of thinking is to not have a team with data people. Instead you want to have teams that are interdisciplinary and maybe have a data person in it. A team with many backgrounds causes more discussion and a more holistic view of things that “might go wrong”. It makes sense to have a UI specialist, a backend engineer, an algorithm person <strong>and</strong> a content expert in a team that is making a recommender.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/better-worse.png"></p>
<p>It is really hard to think outside the box if your in it. By having multiple disciplines you ensure that there is always somebody who can cause a pivot. There’s always somebody who thinks outside of the box that you’re in.</p>
<h2 id="algorithms-arent-creative-solutions">Algorithms aren’t Creative Solutions</h2>
<p>Creative solutions to problems are usually not found by hyper-parameter search. The goal should not be to be the most efficient algorithm but the most effective. Do data teams ever consider that maybe the solution to the problem <strong>isn’t</strong> a machine learning model? Why would the algorithm ever be a good starting point to solving a problem?</p>
<p>To drive this point I’m reminded of a story in the eighties about a condom brand. The business was doing well but it was having some trouble planning production. It turned out to be very hard to predict demand. Both the factory and the warehouse are expensive so people were wondering what to do about it.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/timeseries-1.png"></p>
<p>Then a strategic consultancy firm came in and suggested that this was indeed a <strong>StatisticsProblem[tm]</strong>. The consultancy firm advised getting another third party involved to try to predict the demand curve. A small army of econometricians was brought in to tackle the business case.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/timeseries-2.png"></p>
<p>After two months (and many billed hours) the econometricians reported that no progress was made. The timeseries turned out to not show any predictable patterns that could help with the planning of either the factory or the warehouse. The original consultants and econometricians left (pockets filled) while they reminded their client of the NDA they all signed.</p>
<p>After a few weeks an alternative way of thinking made it’s way to management and it came from a factory worker. The problem turned out to be formulated incorrectly. The factory did not need to be turned off if the company had products to produce. It merely needed to look for a product that it could produce when demand for condoms was low. If it could find a product that correlates negatively with the original product then the factory might produce all year round.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/timeseries-yes.png"></p>
<p>Supposedly, this is how latex pacifiers got invented.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/baby-pacifier.png"></p>
<p>The issue with this fable is that it is very hard to verify it’s truth. Still, one might wonder what would happen if we allow ourselves to solve problems without algorithms for a change.</p>
<h2 id="algorithms-live-in-a-mess">Algorithms Live in a Mess</h2>
<p>From the perspective of a data scientist life is pretty easy. One gets to play in an isolated environment of historical data. One get’s to do this from a jupyter environment that somebody else set up. One even gets to use very complex algorithms by calling <code>model.fit()</code> followed by <code>model.predict()</code>. Lot’s of charts are made, metrics are compared and maybe a model is pushed to production.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/rockstar.png"></p>
<p>This is in stark contrast with businesses. Businesses are not confronted with problems that are in isolation. Businesses instead have dynamic situations that consist of complex systems of changing problems that interact with each other. To repeat what is said <a href="https://ackoffcenter.blogs.com/files/the-future-of-operational-research-is-past.pdf">here</a>; I call such situations messes. Problems are abstractions extracted from messes by analysis; they are to messes ’as atoms are to tables and chairs. We experience messes, tables, and chairs; not problems and atoms.</p>
<p>This is especially true when we consider that the world is a moving target. Optimality is usually of short duration and this is especially true if the consequences of the algorithm aren’t too well understood (who knows what happens when we call <code>.fit()</code> or <code>.predict()</code> given enough columns) or if the algorithm can’t be changed easily.</p>
<p>It get’s worse. The type of model deployed in our field implies a particular paradigm of problem solving. It consists of two parts: predicting the future and making a decision based on this. The effectiveness here depends on how well we can predict the future as well as our ability to act on it. The fact that you can predict something (churn, the weather) does not mean that you can act on it. The fact that you can act on it does not mean that it is predictable.</p>
<p>If we can make good decisions based on predictions then we have another problem: we will cause a shift in the world. This might be great for the short run but it will render our future predictions futile. If we don’t see a backlash in predictive power then our algorithm might cause a way worse problem: self fulfilling prophecies.</p>
<p><img src="https://koaning.io/posts/the-future-is-past/the-future-is-past_files/rockstar-not.png"></p>
<p>This algorithmic attitude towards problem solving often leaves …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://koaning.io/posts/the-future-is-past/">https://koaning.io/posts/the-future-is-past/</a></em></p>]]>
            </description>
            <link>https://koaning.io/posts/the-future-is-past/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752931</guid>
            <pubDate>Mon, 06 Jul 2020 21:23:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Bananas with Naming Microservices?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752813">thread link</a>) | @hjacobs
<br/>
July 6, 2020 | https://srcco.de/posts/naming-applications-components-microservices.html | <a href="https://web.archive.org/web/*/https://srcco.de/posts/naming-applications-components-microservices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><img alt="../galleries/naming-applications-components/magic-baby.jpg" src="https://srcco.de/galleries/naming-applications-components/magic-baby.jpg"></p><p>Naming is hard.
Naming is communication.
Going bananas with naming microservices?
Probably something you will regret!
This post proposes a few guidelines to follow when naming internal applications and components.</p>
<!-- TEASER_END -->
<p>Developers seem to enjoy using clever, cute, funny names for their applications <a href="https://srcco.de/posts/naming-applications-components-microservices.html#id3" id="id1">[1]</a>.
I see many tech companies using codenames for internal applications and microservices.
For example, Airbnb goes bananas with "Banana":</p>
<p><a href="https://twitter.com/spikebrehm/status/1100566261191258114"><img alt="Years ago there started a trend at @AirbnbEng to come up with clever cheeky names for services. Now it's gotten out of control. Exhibit A: the internal web app for viewing microservice docs is called &quot;Banana&quot;. 🍌  What does it mean??" src="https://srcco.de/galleries/naming-applications-components/twitter-airbnb-banana.png"></a></p><p>Twitter engineers seem to like bird names (no surprise):</p>
<p><a href="https://twitter.com/mjackson/status/1100624311872679938"><img alt="We did this at Twitter. It got to the point where I had no idea what people were talking about anymore. Hummingbird, dodo, snowflake, Parrott, we're all real system names" src="https://srcco.de/galleries/naming-applications-components/twitter-twitter-names.png"></a></p><p>Spotify seems to have a mixture of codenames ("Bieber", "horus", "hotdog") and meaningful system names ("charts-api", "userdata").
Slide from a <a href="https://www.slideshare.net/kevingoldsmith/how-spotify-builds-products-organization-architecture-autonomy-accountability/112">talk given by the CTO in 2016</a>:</p>
<p><a href="https://srcco.de/galleries/naming-applications-components/spotify-system-names.jpg"><img alt="Spotify system names" src="https://srcco.de/galleries/naming-applications-components/spotify-system-names.jpg"></a></p><p>The Rockefeller Archive Center <a href="https://blog.rockarch.org/project-electron-update-building-microservices-for-integration">uses constellation-themed names for microservices</a> ("aquarius", "fornax", "gemini"):</p>
<p><a href="https://srcco.de/galleries/naming-applications-components/rockarch-microservices-overhead.png"><img alt="Rockefeller Archive Center microservices" src="https://srcco.de/galleries/naming-applications-components/rockarch-microservices-overhead.png"></a></p><p>Zalando also started to use "fun" team and application IDs when introducing microservices in 2015.
Teams started to have naming schemes for their applications, e.g. "coastal shapes" or "characters from Agatha Christie's Poirot".
Some Georgian names turned out to be successful Open Source projects:</p>
<p><a href="https://twitter.com/try_except_/status/1266108151646035969"><img alt="Twitter: Our Georgian heritage at @ZalandoTech" src="https://srcco.de/galleries/naming-applications-components/twitter-zalando-georgian-names.png"></a></p><p>The <a href="https://news.ycombinator.com/item?id=1942384">orange site has more suggestions for ridiculous names</a>
and <a href="https://namingschemes.com/">namingschemes.com</a> can be your inspiration, too.
So if you want to go crazy with naming, by all means do, but please consider the consequences.
<a href="https://theiconic.tech/naming-your-microservices-needs-to-be-trivial-not-cryptic-288902e800e1">Naming your microservices needs to be trivial, not cryptic</a>:</p>
<blockquote>
How does this sound? I deployed “Leonardo” and it broke “Ernest”</blockquote>
<p>VS</p>
<blockquote>
I deployed “shipments” and that caused the outage on “pick and pack” too.</blockquote>
<p>Or do you want your meetings to <a href="https://www.youtube.com/watch?v=y8OnoxKotPQ">sound like this</a>?</p>
<div id="guidelines">
<h2>Guidelines</h2>
<p>If random "fun" names are not the way to go, how to name internal applications, components, and microservices?
Here some proposed guidelines.</p>
<p>Application names…</p>
<ul>
<li>… MUST NOT contain offensive terms</li>
<li>… MUST NOT include organization/team identifiers</li>
<li>… SHOULD describe the application's purpose</li>
<li>… SHOULD NOT consist solely of acronyms</li>
<li>… SHOULD NOT use broad/general names for local purposes</li>
<li>… SHOULD NOT be clever or rely on temporary concepts</li>
<li>… CAN represent a product branding (if established)</li>
</ul>
<div id="names-must-not-contain-offensive-terms">
<h3>Names MUST NOT contain offensive terms</h3>
<p>Avoid offensive words like "blacklist", "master", and "slave". Avoid violent names like "kill", "killer", and "war".
Also avoid political terms like "brexit" and "putin". Avoid names which can sound offensive for your colleagues,
e.g. "Den Den Mushi" are <a href="https://onepiece.fandom.com/wiki/Den_Den_Mushi">fictional snails</a>, but "Mushi" sounds a lot like "Muschi" (pussy) in German.
Other terminology can also be problematic. For example, imagine you work in a telecommunication company and name one of your services "big brother"
— guess what happens if this name is leaked to the press?</p>
</div>
<div id="names-must-not-include-organization-team-identifiers">
<h3>Names MUST NOT include organization/team identifiers</h3>
<p>Applications typically outlive their organization structure.
Adding department/team identifiers to your application names will cause confusion and unnecessary renaming.
This is especially problematic if your org/team names are codenames.
For example, team "kingpins" has created an application "kingpins-user-frontend", what happens if the application is handed over to team "gravity"?</p>
<p>Microservices should be owned by exactly one engineering team, but they should not reflect the team's identity.</p>
</div>
<div id="names-should-describe-the-application-s-purpose">
<h3>Names SHOULD describe the application's purpose</h3>
<p>The application's name should describe its business purpose, i.e. why it exists in the first place.
The application's purpose should not change, otherwise we need to introduce a new application with a different name.
A microservice should have one responsibility. This should be reflected in its name.</p>
<p>Don't assume that others will have the same context as you and understand the name's meaning.
Make sure to ask colleagues who are not familiar with your business domain to review your names.</p>
</div>
<div id="names-should-not-consist-solely-of-acronyms">
<h3>Names SHOULD NOT consist solely of acronyms</h3>
<p>Acronyms are sometimes a necessary evil, but avoid acronyms unless they are well established in your company.
"CMS" (Content Management System) is a well established acronym. CLOTS, BUGR, and NIPL are probably not well-known.
Avoid cryptic acronyms.</p>
</div>
<div id="names-should-not-use-broad-general-names-for-local-purposes">
<h3>Names SHOULD NOT use broad/general names for local purposes</h3>
<p>Large organizations tend to use similar entities in different domains, e.g. there is probably more than one "item", "order", and "user" entity in your company.
Avoid using too general names like "item processor" or "user service" unless you are absolutely sure that your organization only has exactly one definition for "item" and "user".</p>
</div>
<div id="names-should-not-be-clever-or-rely-on-temporary-concepts">
<h3>Names SHOULD NOT be clever or rely on temporary concepts</h3>
<p>I wholeheartedly agree with <a href="https://www.namingthings.co/naming-things-principles">Austerity as a naming principle</a>:</p>
<blockquote>
It can be tempting to use a bit of humor or a cultural reference in code to lighten the mood a bit, but doing this can violate many principles. For example, a joke name can reduce understandability of the underlying concept and reduce the name’s consistency and searchability. Colloquialisms (which are only understandable to certain audiences) and puns can cause similar issues. They may seem fun initially, but after dealing with them for years, that fun will turn into apathy and (more likely!) antipathy. When in doubt, choose names that are literal and dry.</blockquote>
</div>
<div id="names-can-represent-a-product-branding">
<h3>Names CAN represent a product branding</h3>
<p>Internal application names should not be cryptic codenames, but establishing a brand sometimes makes sense.
Don't introduce a codename unless you are willing to invest into establishing a (product) brand, e.g. a well-recognized codename within the company or for promoting an Open Source project.
Spotify released their developer portal "Backstage" which is now a <a href="https://github.com/spotify/backstage">recognized OSS project</a>.
Zalando has well-established codenames for central infrastructure components like <a href="https://nakadi.io/">Nakadi</a> and <a href="https://github.com/zalando/skipper">Skipper</a>.
Almost every Zalando engineer knows what Nakadi and Skipper are.</p>
<p>Your local "raccoon" and "wingman" microservices don't need branding, their codenames <a href="https://www.youtube.com/watch?v=y8OnoxKotPQ">just lead to confusion</a>.</p>
</div>
</div>
<div id="summary">
<h2>Summary</h2>
<p>Naming is hard, but there is no shortcut for finding a good name.
Selecting or inventing a naming scheme
and assigning a random name to each application sounds like fun.
Please don't prioritize this fun over the struggle of all your colleagues having to deal with these "fun" names.
Involve colleagues from other departments to find a "good" name which expresses the application's purpose.</p>
<p>Stop proliferating meaningless "fun" codenames for software systems.</p>
</div>

</div>
    </div></div>]]>
            </description>
            <link>https://srcco.de/posts/naming-applications-components-microservices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752813</guid>
            <pubDate>Mon, 06 Jul 2020 21:12:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why marketing is eating the world]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23752747">thread link</a>) | @gmays
<br/>
July 6, 2020 | https://elizabethyin.com/2020/06/30/why-marketing-is-eating-the-world/ | <a href="https://web.archive.org/web/*/https://elizabethyin.com/2020/06/30/why-marketing-is-eating-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I was born and raised in the San Francisco Bay Area and grew up during the dot com boom in the late 1990s. One of the most interesting things in looking back are the stark differences in what it took to be successful back then with a software company and what it takes to be successful in building a software startup today in the US. </p>



	<div data-blog-id="155286968">
		<div>
			
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	


<p>When I was a teenager, if you wanted to get into internet startups, you needed to find information on how to build websites. Although there were some no-code website builders, they were largely terrible. Building websites from scratch was the way to go. Moreover, developer knowledge was not really available online, because content on the internet was still being written. You had to hop over to your local Barnes &amp; Noble bookstore to buy books on HTML, Javascript, Perl and whatnot. Lastly and most importantly, you needed access to servers. It was not uncommon for internet companies to spend boatloads of money setting up their infrastructure in a closet at their office. Back then, technical knowledge was a really valuable and a limited skill. If you could assemble the best technical teams and keep them happy, that was a really strong moat for you because you could prevent other would-be competitors from being able to build a competing offer.</p>



<figure><img data-attachment-id="4191" data-permalink="https://elizabethyin.com/pexels-photo-261821/" data-orig-file="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?fit=1880%2C1059&amp;ssl=1" data-orig-size="1880,1059" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="book bookstore close up college" data-image-description="" data-medium-file="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?fit=660%2C372&amp;ssl=1" src="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?resize=660%2C372&amp;ssl=1" alt="" srcset="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?resize=1024%2C577&amp;ssl=1 1024w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?resize=768%2C433&amp;ssl=1 768w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?resize=1536%2C865&amp;ssl=1 1536w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?resize=483%2C272&amp;ssl=1 483w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-261821.jpeg?w=1320&amp;ssl=1 1320w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>Photo by Pixabay on <a href="https://www.pexels.com/photo/book-bookstore-close-up-college-261821/" rel="nofollow">Pexels.com</a></figcaption></figure>



<p>And as a result, for many years, there were not that many websites in the US market (or anywhere). If you had a website, it was relatively easy to capture attention and web traffic. One such website, Craigslist, a simple peer-to-peer marketplace site that we are all familiar with, was started in 1995 and continues to reign to this day despite so many upstarts trying to compete with it on better design and usability. Why? Craigslist gets the job done and more importantly, people know about its existence. Distribution is king.</p>



<p>Although it often took months to build out a website in the 90s, today you can often get a fairly straightforward site out the door even with no-code tools in less than a day. And if you do need to write code, you can search for code examples on just about every possible topic in a variety of discussion forums and on YouTube. Even more advanced computer science topics such as in machine learning now have so many open source resources and infrastructure.  You can often use a variety of specialty libraries without having specialized knowledge. For the most part, in software, technical information has largely become commoditized. This isn’t to say that you can’t make good money being a software engineer — and in fact, if you are a top engineer, you can now make a boatload of money! But it’s to say that most “run-of-the-mill” software development is not a unique skillset and most software businesses developed today don’t require specialized software development skills.</p>



<p>This has led to a flurry of many applications being built online – often with multiple teams building the same thing. It is not uncommon to run into 50 different founding teams all trying to build a marketplace for gym trainers. Or 300 founding teams trying re-invent marketing automation.</p>



<figure><img data-attachment-id="4169" data-permalink="https://elizabethyin.com/2020/06/30/why-marketing-is-eating-the-world/numofsites/" data-orig-file="https://i2.wp.com/elizabethyin.com/wp-content/uploads/2020/06/numofsites.jpeg?fit=960%2C684&amp;ssl=1" data-orig-size="960,684" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="numofsites" data-image-description="" data-medium-file="https://i2.wp.com/elizabethyin.com/wp-content/uploads/2020/06/numofsites.jpeg?fit=300%2C214&amp;ssl=1" data-large-file="https://i2.wp.com/elizabethyin.com/wp-content/uploads/2020/06/numofsites.jpeg?fit=660%2C470&amp;ssl=1" src="https://i2.wp.com/elizabethyin.com/wp-content/uploads/2020/06/numofsites.jpeg?w=660&amp;ssl=1" alt="" srcset="https://i2.wp.com/elizabethyin.com/wp-content/uploads/2020/06/numofsites.jpeg?w=960&amp;ssl=1 960w, https://i2.wp.com/elizabethyin.com/wp-content/uploads/2020/06/numofsites.jpeg?resize=300%2C214&amp;ssl=1 300w, https://i2.wp.com/elizabethyin.com/wp-content/uploads/2020/06/numofsites.jpeg?resize=768%2C547&amp;ssl=1 768w, https://i2.wp.com/elizabethyin.com/wp-content/uploads/2020/06/numofsites.jpeg?resize=382%2C272&amp;ssl=1 382w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"></figure>



<p>According to <a href="https://www.statista.com/chart/19058/how-many-websites-are-there/">Statista</a>, the number of websites has ballooned to nearly 2B!</p>



<p>For most software businesses in the US, the problem isn’t technical knowledge anymore. The problem is getting a wedge into distribution — also known as marketing. </p>



<p>Furthermore, incumbents who generally do a good job, often manage to continue reigning. According to Brad Gerstner, CEO of Altimeter Capital, who recently did a podcast on <em><a href="http://investorfieldguide.com/podcast/">Invest Like The Best</a></em>, large tech companies have managed to take even more market share than 10 years ago. Some people may argue this is because the large tech companies have improved their products over time to stay ahead due to their increased collection of data and better algorithms that feed on that data over time. That may be true for some companies but not all. This also applies to other products that have not made significant strides in their technology — Craigslist, Salesforce CRM, Turbotax, Quickbooks to name a few. Even Google Search which arguably had a better product in the 1990s compared to its peers is about on par with alternative search engines today, but 90% of people worldwide still use Google. Old habits die hard, and distribution matters more than ever if you are just starting a business. It’s hard to topple incumbents who have strong distribution and already large audiences — even if you can build a much better product. </p>



<p>So where are the opportunities in software? Is it even possible to build a company that takes an entire market?  I took to Twitter to find out. </p>



<figure><img data-attachment-id="4187" data-permalink="https://elizabethyin.com/2020/06/30/why-marketing-is-eating-the-world/screen-shot-2020-06-30-at-1-41-57-pm/" data-orig-file="https://i1.wp.com/elizabethyin.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-1.41.57-PM.png?fit=590%2C391&amp;ssl=1" data-orig-size="590,391" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen-Shot-2020-06-30-at-1.41.57-PM" data-image-description="" data-medium-file="https://i1.wp.com/elizabethyin.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-1.41.57-PM.png?fit=300%2C199&amp;ssl=1" data-large-file="https://i1.wp.com/elizabethyin.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-1.41.57-PM.png?fit=590%2C391&amp;ssl=1" src="https://i1.wp.com/elizabethyin.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-1.41.57-PM.png?w=660&amp;ssl=1" alt="" srcset="https://i1.wp.com/elizabethyin.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-1.41.57-PM.png?w=590&amp;ssl=1 590w, https://i1.wp.com/elizabethyin.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-1.41.57-PM.png?resize=300%2C199&amp;ssl=1 300w, https://i1.wp.com/elizabethyin.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-1.41.57-PM.png?resize=410%2C272&amp;ssl=1 410w" sizes="(max-width: 590px) 100vw, 590px" data-recalc-dims="1"></figure>



<p>A big warm thanks to everyone who participated. A number of people came up with some great suggestions of winner-take-all companies within a variety of developer tools / API markets, but in large part, this was an incredibly difficult challenge. No one could think of a company that has started in the last decade and has clearly dominated above all other competitors. On the flipside, we’ve already rattled off a number of older software companies that continue to dominate market share TO THIS DAY in a variety of areas: Google Search, Amazon Books, Turbotax, etc. This isn’t to say that you cannot build a big business if you don’t own a market, but it’s to say that the old way of thinking about market domination is just not applicable anymore.</p>



<p>Put another way, a lot of the “low hanging fruit” in the US software market is now gone. Software in the US generally works. And new opportunities get swept up with would-be competitors immediately. If the 90s was about thinking through your build, the 2020s is about thinking through marketing &amp; distribution. </p>



<p>As such, while many VCs are still fixated on finding unique technology in software and chasing companies that will ultimately be the sole winner, I’d contend that these two strategies — while successful in the 90s and early 00s — largely no longer work. There are certainly exceptions but if we are talking strictly about software, (not hardware, not drug discovery, not synthetic bio, etc) you’d be hard pressed to find a company where winning does not require a solid marketing and/or sales game. This is very different from the 1990s. Having a marketing skillset and mindset is what you need to win in 2020 in the US software market. </p>



<p>Although the low hanging fruit opportunities in the US are gone, it’s not to say that you can’t build a Salesforce competitor or a Craigslist competitor and be successful. The software market in the US has gotten so big — you can still build a billion dollar business if you are the 15th email service provider. We are seeing more and more unicorns ($1b valuation businesses) and many in the same market. However, we are also seeing many more startups than in the 1990s being built. This means that while there are more unicorns as an aggregate number, there are also many more companies that will not become unicorns. And with increased competition, even if there are more winners, the cost of customer acquisition becomes more expensive for all. </p>



<figure><img data-attachment-id="4193" data-permalink="https://elizabethyin.com/pexels-photo-1564506-3/" data-orig-file="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?fit=1880%2C1208&amp;ssl=1" data-orig-size="1880,1208" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="boston terrier wearing unicorn pet costume" data-image-description="" data-medium-file="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?fit=300%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?fit=660%2C424&amp;ssl=1" src="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?resize=660%2C424&amp;ssl=1" alt="" srcset="https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?resize=1024%2C658&amp;ssl=1 1024w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?resize=300%2C193&amp;ssl=1 300w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?resize=768%2C493&amp;ssl=1 768w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?resize=1536%2C987&amp;ssl=1 1536w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?resize=423%2C272&amp;ssl=1 423w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/elizabethyin.com/wp-content/uploads/2020/06/pexels-photo-1564506.jpeg?w=1320&amp;ssl=1 1320w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>Photo by mark glancy on <a href="https://www.pexels.com/photo/boston-terrier-wearing-unicorn-pet-costume-1564506/" rel="nofollow">Pexels.com</a></figcaption></figure>



<p>In fact, there are economic schools of thought around where we are in the tech-economic landscape. As economist Carlotta Perez describes, we are now in the <a href="http://www.carlotaperez.org/downloads/media/PEREZTechnologyandbubblesforEngelsbergseminar.pdf">Deployment Phase</a> of the internet in the US — meaning, we are in-process of exhausting all use cases for internet technologies in the US. What has traditionally happened at the end of a technology phase is oversaturation of investment dollars chasing smaller returns. Valuations go up, returns go down, and investors lose their money. (Sound familiar?) On a company level, what this means is, if not careful, a lot of companies will end up wasting marketing dollars in this type of landscape. Companies in the 2020s, unlike in the 1990s, need to really be performance-marketing driven in order to compete. The end of last year certainly showed us many examples of well-funded companies that could not make the unit economics work. The software industry has become a marketing game. </p>



<p>Even if you aren’t running a strictly software business but use software platforms to operate a business, marketing is still key. If you run your company off  Yelp, Shopify, Patreon, Stripe, Recurly, ConvertKit, Substack, or any of the others, you need to stand out, and that’s marketing. And the people who do the best at marketing make a LOT of money, and those who don’t, just can’t catch a break, even if they are good at their craft. Marketing is necessary.</p>



<p>There are, of course, exceptions to this — there are still emerging markets (both in the geographical sense and technology sense) where marketing doesn’t matter as much. </p>



<p>In developing geographical markets, it’s largely greenfield. We have a portfolio company in Indonesia that was able to get 250k signups almost immediately from brick and mortar small businesses and no budget. In the US, without a large marketing budget, this would be challenging to do now. Why? Because every Square and Opentable is knocking on their door and has been for years. There’s just so much noise small businesses tend to ignore. But in Indonesia, that isn’t the case…yet. The software landscape there is similar to the 1990s in the US. It’s harder to piggyback off of existing software infrastructure — whether it’s payments or platforms — but there’s also a lot of obvious opportunity in software that no one is going after. The same could be said about investing elsewhere in Southeast Asia or in LatAm or Africa. There are fewer startups to compete with for attention, and it’s less of a marketing game than building a software company in the US. </p>



<p>In addition, for companies pursuing developing …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elizabethyin.com/2020/06/30/why-marketing-is-eating-the-world/">https://elizabethyin.com/2020/06/30/why-marketing-is-eating-the-world/</a></em></p>]]>
            </description>
            <link>https://elizabethyin.com/2020/06/30/why-marketing-is-eating-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752747</guid>
            <pubDate>Mon, 06 Jul 2020 21:05:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips to Write Landing Page Text Without Sounding Like a Salesman]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752746">thread link</a>) | @mratiebatie
<br/>
July 6, 2020 | https://targetaudience.app/articles/7-tips-to-write-landing-page-text-without-sounding-like-a-salesman | <a href="https://web.archive.org/web/*/https://targetaudience.app/articles/7-tips-to-write-landing-page-text-without-sounding-like-a-salesman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://targetaudience.app/articles/7-tips-to-write-landing-page-text-without-sounding-like-a-salesman</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752746</guid>
            <pubDate>Mon, 06 Jul 2020 21:05:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Printed perovskite LEDs – technique towards a new standard process]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752693">thread link</a>) | @WaitWaitWha
<br/>
July 6, 2020 | https://www.helmholtz-berlin.de/pubbin/news_seite?nid=21460;sprache=en | <a href="https://web.archive.org/web/*/https://www.helmholtz-berlin.de/pubbin/news_seite?nid=21460;sprache=en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><span>Microelectronics utilise various functional materials whose properties make them suitable for specific applications.</span><span> </span><span>For example, transistors and data storage devices are made of silicon, and most photovoltaic cells used for generating electricity from sunlight are also currently made of this semiconductor material. In contrast, compound semiconductors such as gallium nitride are used to generate light in optoelectronic elements such as light-emitting diodes (LEDs). The manufacturing processes also different for the various classes of materials.</span></p> <p><strong><span>Transcending the materials and methods maze</span></strong><strong><span></span></strong></p> <p><span>Hybrid perovskite materials promise simplification – by arranging the organic and inorganic components of semiconducting crystal in a specific structure.</span><span> </span><span>“They can be used to manufacture all kinds of microelectronic components by modifying their composition“, says Prof. Emil List-Kratochvil, head of a Joint Research Group at HZB and Humboldt-Universität.</span><span> </span><span></span></p> <p><span>What's more, processing perovskite crystals is comparatively simple.</span><span> </span><span>“They can be produced from a liquid solution, so you can build the desired component one layer at a time directly on the substrate“, the physicist explains.</span><span></span></p> <p><strong><span>First solar cells from an inkjet printer, now light-emitting diodes too</span></strong><strong><span></span></strong></p> <p><span>Scientists at HZB have already shown in recent years that solar cells can be printed from a solution of semiconductor compounds – and are worldwide leaders in this technology today.</span><span> </span><span>Now for the first time, the joint team of HZB and HU Berlin has succeeded in producing functional light-emitting diodes in this manner.</span><span> </span><span>The research group used a metal halide perovskite for this purpose. This is a material that promises particularly high efficiency in generating light – but on the other hand is difficult to process.</span><span> </span><span></span></p> <p><span>“Until now, it has not been possible to produce these kinds of semiconductor layers with sufficient quality from a liquid solution“, says List-Kratochvil.</span><span> </span><span>For example, LEDs could be printed just from organic semiconductors, but these provide only modest luminosity. “The challenge was how to cause the salt-like precursor that we printed onto the substrate to crystallise quickly and evenly by using some sort of an attractant or catalyst“, explains the scientist. The team chose a seed crystal for this purpose: a salt crystal that attaches itself to the substrate and triggers formation of a gridwork for the subsequent perovskite layers.</span><span> </span><span></span></p> <p><strong><span>Significantly better optical and electronic characteristics</span></strong><strong><span></span></strong></p> <p><span>In this way, the researchers created printed LEDs that possess far higher luminosity and considerably better electrical properties than could be previously achieved using additive manufacturing processes.</span><span> </span><span>But for List-Kratochvil, this success is only an intermediate step on the road to future micro- and optoelectronics that he believes will be based exclusively on hybrid perovskite semiconductors.</span><span> </span><span>“The advantages offered by a single universally applicable class of materials and a single cost-effective and simple process for manufacturing any kind of component are striking“, says the scientist.</span><span> </span><span>He is therefore planning to eventually manufacture all important electronic components this way in the laboratories of HZB and HU Berlin.</span><span> </span><span></span></p> <p><span>List-Kratochvil is Professor of Hybrid Devices at the Humboldt-Universität zu Berlin and head of a Joint Lab founded in 2018 that is operated by HU together with HZB.</span><span> </span><span>In addition, a team jointly headed by List-Kratochvil and HZB scientist Dr. Eva Unger is working in the Helmholtz Innovation Lab HySPRINT on the development of coating and printing processes – also known in technical jargon as "additive manufacturing" – for hybrid perovskites.</span><span> </span><span>These are crystals possessing a perovskite structure that contain both inorganic and organic components.</span><span></span></p> <p><span>&nbsp;</span><em><span>The work was published in Materials Horizons, the journal of the Royal Society of Chemistry, in an article entitled “</span></em><em><span>Finally, inkjet-printed metal-halide perovskite LEDs – utilizing seed-crystal templating of salty PEDOT:PSS“ by </span></em><em><span>Felix</span></em><em><span> </span></em><em><span>Hermerschmidt</span></em><em><span>, </span></em><em><span>Florian</span></em><em><span> </span></em><em><span>Mathies</span></em><em><span>, </span></em><em><span>Vincent</span></em><em><span> </span></em><em><span>R</span></em><em><span>. </span></em><em><span>F</span></em><em><span>. </span></em><em><span>Schr</span></em><em><span>ö</span></em><em><span>der</span></em><em><span>, </span></em><em><span>Carolin</span></em><em><span> </span></em><em><span>Rehermann</span></em><em><span>, </span></em><em><span>Nicolas</span></em><em><span> </span></em><em><span>Zorn</span></em><em><span> </span></em><em><span>Morales</span></em><em><span>, </span></em><em><span>Eva</span></em><em><span> </span></em><em><span>L</span></em><em><span>. </span></em><em><span>Unger</span></em><em><span>, </span></em><em><span>Emil</span></em><em><span> </span></em><em><span>J</span></em><em><span>. </span></em><em><span>W</span></em><em><span>. </span></em><em><span>List</span></em><em><span>-</span></em><em><span>Kratochvil</span></em><em><span>.</span></em><br><em><span></span></em></p> <p><em><span> </span></em><em><span>DOI</span></em><em><span>: 10.1039/</span></em><em><span>d</span></em><em><span>0</span></em><em><span>mh</span></em><em><span>00512</span></em><em><span>f</span></em><em><span></span></em></p> </div></div>]]>
            </description>
            <link>https://www.helmholtz-berlin.de/pubbin/news_seite?nid=21460;sprache=en</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752693</guid>
            <pubDate>Mon, 06 Jul 2020 20:59:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mean Squared Terror – GridSearch Is Not Enough]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752683">thread link</a>) | @amrrs
<br/>
July 6, 2020 | https://koaning.io/posts/mean-squared-terror/ | <a href="https://web.archive.org/web/*/https://koaning.io/posts/mean-squared-terror/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>2020-06-29 This blogpost was edited the day after it got posted. During my morning walk I realised that my code had a glaring bug in the statistics. I was reporting training set figures, not the validation set. I re-ran the system with the appropriate numbers and while the conclusions did not change, some of the figures/numbers did.</p>
</blockquote>
<p>When I started in data, many years ago, people were actively working on heuristics. These are rules that could look at data and then make appropriate decisions. In schematics, this was the norm;</p>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-1"></span>
<img src="https://koaning.io/posts/mean-squared-terror/then.png" alt="Those were the days." width="100%"></p><p>
Figure 1: Those were the days.
</p>
</div>
</div>
<p>You had to understand the data to come up with these rules and this was very time consuming. But then machine learning changed everything. Instead of writing rules that fit a problem, we provide labels and have a machine figure out the rules instead.</p>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-2"></span>
<img src="https://koaning.io/posts/mean-squared-terror/now.png" alt="The latest and greatest." width="100%"></p><p>
Figure 2: The latest and greatest.
</p>
</div>
</div>
<p>The latter approach has merit to it but it requires a new way of working. It also tends to be compute intensive because we’re interested in finding the best possible settings.</p>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-3"></span>
<img src="https://koaning.io/posts/mean-squared-terror/alg.png" alt="All those settings." width="100%"></p><p>
Figure 3: All those settings.
</p>
</div>
</div>
<p>To find the best settings for all of these models we’ve even got gridsearch via cross validation; an industry standard to make sure that we pick the best model.</p>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-4"></span>
<img src="https://koaning.io/posts/mean-squared-terror/settings.png" alt="All this expensive compute better be worth it." width="100%"></p><p>
Figure 4: All this expensive compute better be worth it.
</p>
</div>
</div>
<p>Don’t get me wrong, there’s merit to the methodology. We want to demonstrate consistent results in our models. But we’re representing <strong>all the possible properties of a model</strong> as a single number. That’s a massive reduction of information, and frankly, an overly simplified way to think about models.</p>
<h2 id="dangerzone">Dangerzone</h2>
<p>I’ve written before that “GridSearch is not Enough[tm]” but in this document I wanted to give an example of how the technique can also be a problem. GridSearch is insufficient at best, it can also be dangerous at worst.</p>

<p>The main reason is that I’ve seen people put blind faith into the methodology causing a blind spot for other issues with the model. I’ve also spoken to data scientists who think that machine learning algorithms are unbiased tools that find the “truth” in the data and that grid search is a methodological purity. This is a dangerous attitude so I figured I’d create a counter-example.</p>
<h2 id="experiment">Experiment</h2>
<p>So let’s do a small experiment. The goal is to see the effect of machine learning on a biased dataset. Given a biased dataset, will grid search amplify the bias in the dataset or reduce it?</p>
<p>I’ve draw a dataset using <a href="https://drawdata.xyz/">drawdata.xyz</a>. Let’s pretend that this usecase represents predicting salaries based on skill level. The skill level is plotted on the x-axis and the salary/reward is plotted on the y-axis. There’s two groups of datapoints and one represents a marginalized group. This group is under represented, only appears with low salaries and it also has a lower salary than it’s non-marginalised peers. The current illustration is a blunt representation of what might happen in a real life dataset (the bias can be more subtle) but the question is; what pattern will be picked up after grid search?</p>

<p>Below we’ll have a look at the results of three different models. We’ll also list the mean squared error that was reported back to us from the gridsearch.</p>

<h5 id="linear-model-with-dummy-variable">Linear Model with Dummy Variable</h5>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-6"></span>
<img src="https://koaning.io/posts/mean-squared-terror/plot-linear.png" alt="Mean Squared Error, Train: 1166.64 Test: 1767.36" width="100%"></p><p>
Figure 5: Mean Squared Error, Train: 1166.64 Test: 1767.36
</p>
</div>
</div>
<h5 id="nearest-neighbor-regression-with-scaling">Nearest Neighbor Regression with Scaling</h5>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-7"></span>
<img src="https://koaning.io/posts/mean-squared-terror/plot_nn.png" alt="Mean Squared Error, Train: 909.66 Test: 2337.65" width="100%"></p><p>
Figure 6: Mean Squared Error, Train: 909.66 Test: 2337.65
</p>
</div>
</div>
<h5 id="grouped-linear-model">Grouped Linear Model</h5>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-8"></span>
<img src="https://koaning.io/posts/mean-squared-terror/plot_group.png" alt="Mean Squared Error, Train: 993.57 Test: 1343.09" width="100%"></p><p>
Figure 7: Mean Squared Error, Train: 993.57 Test: 1343.09
</p>
</div>
</div>
<p>Notice how the model that has the lowest mean squared error is also the model that causes the most bias between groups for higher skill levels. This increase in bias <em>cannot</em> be blamed merely on the data. It’s the choice of the model that increases this bias which is the responsibility of the algorithm designer.</p>
<p>Now, you could argue that this is a theoretical dataset. No professional would include something like gender into a model predicting salary. <a href="https://github.com/scailable/sclbl-tutorials/issues/7">Right?</a> We can repeat the same exercise with something that correlates with a sensitive attribute instead but you can expect similar result. You can get a smaller mean squared error when you can learn the bias in the dataset. No matter how subtle.</p>
<p>This is what I find scary about gridsearch. People have been learned to trust it even though it can pick a model you should not consider. Notice how the grid search would tell us that there <em>should</em> be a big payment gap between the two groups even if they display high levels of skill. In algorithmic terms some might call this behavior “optimal” while in real life, you would call this sexism, ageism or racism.</p>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-9"></span>
<img src="https://koaning.io/posts/mean-squared-terror/mcsultancyy.png" alt="Mean Squared Terror: over 9000." width="100%"></p><p>
Figure 8: Mean Squared Terror: over 9000.
</p>
</div>
</div>
<p>The thing to remember here is that 100% unbiased datasets don’t really exist. This phenomenon of overfitting on a metric is something that gridsearch contributes to. Combine that with algorithm designers who don’t have domain knowledge in the domain that they’re applying your algorithm to and you might just get this.</p>
<div data-layout="l-body">
<div><p><span id="fig:unnamed-chunk-10"></span>
<img src="https://koaning.io/posts/mean-squared-terror/ivory.png" alt="Mean Squared Terror: np.inf" width="100%"></p><p>
Figure 9: Mean Squared Terror: np.inf
</p>
</div>
</div>
<h2 id="appendix">Appendix</h2>
<p>This post was prompted by a discussion on <a href="https://thegradient.pub/pulse-lessons/">twitter</a> as well as a discussion on <a href="https://www.linkedin.com/feed/update/urn:li:activity:6679637058597789696/?commentUrn=urn%3Ali%3Acomment%3A(activity%3A6679637058597789696%2C6679704886969475072)&amp;replyUrn=urn%3Ali%3Acomment%3A(activity%3A6679637058597789696%2C6679775009537343488)">linkedin</a>. It’s dissapointing to see data professionals be dismissive of how bias is amplified by algorithms. It’s not something the profession should be casual about.</p>
<!--radix_placeholder_article_footer-->
<p>
    <span>
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Mean%20Squared%20Terror&amp;url=https%3A%2F%2Fkoaning.io%2Fposts%2Fmean-squared-terror%2F">
        <i></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fkoaning.io%2Fposts%2Fmean-squared-terror%2F&amp;title=Mean%20Squared%20Terror">
        <i></i>
      </a>
    </span>
  </p>
<!--/radix_placeholder_article_footer-->
</div></div>]]>
            </description>
            <link>https://koaning.io/posts/mean-squared-terror/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752683</guid>
            <pubDate>Mon, 06 Jul 2020 20:58:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abusing linear regression to make a point]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 43 (<a href="https://news.ycombinator.com/item?id=23752561">thread link</a>) | @furcyd
<br/>
July 6, 2020 | http://www.goodmath.org/blog/2020/07/06/abusing-linear-regression-to-make-a-point/ | <a href="https://web.archive.org/web/*/http://www.goodmath.org/blog/2020/07/06/abusing-linear-regression-to-make-a-point/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>A bunch of people have been sending me links to a particularly sloppy article that (mis)uses linear regression to draw an incorrect conclusion from some data. So I guess I’ve got to got back to good-old linear regression, and talk about it a bit.</p>



<p>Let’s start with the basics. What is linear regression?</p>



<p>If you have a collection of data – typically data with one independent variable, and one dependent variable (that is, the first variable can vary any way it wants; changing it will change the second variable), then you’re probably interested in how the dependent variable relates to the independent. <em>If</em> you have reason to believe that they should have a linear relationship, then you’d like to know just what that linear relationship is.</p>



<p>If your data were perfect, then you’d just need to plot all of the data points on a graph, with the independent variable on the X axis, and the dependent on the Y, and then your graph would be a line, and you could get its slope and Y intercept, and thus completely capture the relationship.</p>



<p>But data is never perfect. There’s a lot of reasons for that, but no real set of collected data is ever perfect. No matter how perfect the real underlying linear relationship is, real measured data will always show some scatter. And that means that you can draw a lot of possible lines through the collected data. Which one of them represents the best fit?</p>



<p>Since that’s pretty abstract, I’m going to talk a bit about an example – the very example that was used to ignite my interest in math!</p>



<p>Back in 1974 or so, when I was a little kid in second grade, my father was working for RCA, as a physicist involved in manufacturing electronics for satellite systems. One of the important requirements for the products they were manufacturing was that they be <em>radiation hard</em> – meaning that they could be exposed to quite a bit of radiation before they would be damaged enough to stop working.</p>



<p>Their customers – NASA, JPL, and various groups from the U. S. Military, had very strong requirements. They had to show, for a manufacturing setup of a particular component, what the failure profile was.</p>



<p>The primary failure mode of these chips they were making was circuit trace failure. If a sufficiently energetic gamma ray hit one of the circuit traces, it was possible that the trace would burn out – breaking the circuit, and causing the chip to fail.</p>



<p>The test setup that that they used had a gamma ray emitter. So they’d make a manufacturing run to produce a batch of chips from the setup. Then they’d take those, and they’d expose them to increasing doses of radiation from the gamma emitter, and detect when they failed.</p>



<p>For trace failure, the probability of failure is linear in the size of the radiation dose that the chip is exposed to. So to satisfy the customer, they had to show them what the slope of the failure curve was. “Radiation hard” was defined as being able to sustain exposure to some dose of radiation with a specified probability of failure.</p>



<p>So, my dad had done a batch of tests, and he had a ton of little paper slips that described the test results, and he needed to computer the slop of that line – which would give the probability of failure as a multiple of the radiation dose.</p>



<p>I walked into the dining room, where he was set up doing this, and asked what he was doing. So he explained it to me. A lot like I just explained above – except that my dad was a much better teacher than me. I couldn’t explain this to a second or third grader the way that he did!</p>



<p>Anyway… The method that we use to compute the best line is called <em>least squares</em>. The intuition behind it is that you’re trying to find the line where the average distance of all of the datapoints from that line is the smallest. But a simple average doesn’t work well – because some of the data points are above the line, and some are below. Just because one point is, say, above a possible fit by 100, and another is below by 100 doesn’t mean that the two should cancel. So you take the distance between the data points and the line, and you square them – making them all positive. Then you find the line where that total is the smallest – and that’s the best fit.</p>



<p>So let’s look at a real-ish example.</p>



<p>For example, here’s a graph that I generated semi-randomly of data points. The distribution of the points isn’t really what you’d get from real observations, but it’s good enough for demonstration.<img src="http://www.goodmath.org/blog/wp-content/uploads/2013/01/graph.png" alt="scatter plot of randomly skewed data" srcset="http://www.goodmath.org/blog/wp-content/uploads/2013/01/graph.png 346w, http://www.goodmath.org/blog/wp-content/uploads/2013/01/graph-300x212.png 300w" sizes="(max-width: 346px) 100vw, 346px"></p>



<p>The way that we do that is: first we compute the means of <img src="http://l.wordpress.com/latex.php?latex=x&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="x" alt="x"> and <img src="http://l.wordpress.com/latex.php?latex=y&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="y" alt="y">, which we’ll call <img src="http://l.wordpress.com/latex.php?latex=%5Coverline%7Bx%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="\overline{x}" alt="\overline{x}"> and <img src="http://l.wordpress.com/latex.php?latex=%5Coverline%7By%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="\overline{y}" alt="\overline{y}">. Then using those, we compute the slope as:</p>



<p><img src="http://l.wordpress.com/latex.php?latex=%20m%20%3D%20%5Cfrac%7B%5CSigma_%7Bi%3D1%7D%5En%20%28x-%5Chat%7Bx%7D%29%28y-%5Chat%7By%7D%29%7D%7B%5CSigma_%7Bi%3D1%7D%5E%7Bn%7D%20%28x-%5Chat%7Bx%7D%29%5E2%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title=" m = \frac{\Sigma_{i=1}^n (x-\hat{x})(y-\hat{y})}{\Sigma_{i=1}^{n} (x-\hat{x})^2}" alt=" m = \frac{\Sigma_{i=1}^n (x-\hat{x})(y-\hat{y})}{\Sigma_{i=1}^{n} (x-\hat{x})^2}"></p>



<p>Then for the y intercept: <img src="http://l.wordpress.com/latex.php?latex=b%20%3D%20%5Chat%7By%7D%20-%20m%5Chat%7Bx%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="b = \hat{y} - m\hat{x}" alt="b = \hat{y} - m\hat{x}">.</p>



<p>In the case of this data: I set up the script so that the slope would be about 2.2 +/- 0.5. The slope in the figure is 2.54, and the y-intercept is 18.4.</p>



<p>Now, we want to check how good the linear relationship is. There’s several different ways of doing that. The simplest is called the correlation coefficient, or <img src="http://l.wordpress.com/latex.php?latex=r&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="r" alt="r">.</p>



<p><img src="http://l.wordpress.com/latex.php?latex=%20r%20%3D%20%5Cfrac%7B%5Cleft%28%5CSigma%20%28x-%5Chat%7Bx%7D%29%5Cright%29%20%5Cleft%28%5CSigma%20%28y%20-%20%5Chat%7By%7D%29%5Cright%29%7D%7B%5Csqrt%7B%20%5Cleft%28%5CSigma%20%28x-%5Chat%7Bx%7D%29%5E2%5Cright%29%20%5Cleft%28%5CSigma%20%28y%20-%20%5Chat%7By%7D%29%5E2%5Cright%29%20%7D%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title=" r = \frac{\left(\Sigma (x-\hat{x})\right) \left(\Sigma (y - \hat{y})\right)}{\sqrt{ \left(\Sigma (x-\hat{x})^2\right) \left(\Sigma (y - \hat{y})^2\right) }}" alt=" r = \frac{\left(\Sigma (x-\hat{x})\right) \left(\Sigma (y - \hat{y})\right)}{\sqrt{ \left(\Sigma (x-\hat{x})^2\right) \left(\Sigma (y - \hat{y})^2\right) }}"></p>



<p>If you look at this, it’s really a check of how well the variation between the measured values and the expected values (according to the regression) match. On the top, you’ve got a set of products; on the bottom, you’ve got the square root of the same thing squared. The bottom is, essentially, just stripping the signs away. The end result is that if the correlation is perfect – that is, if the dependent variable increases linearly with the independent, then the correlation will be 1. If the dependency variable decreases linearly in opposition to the dependent, then the correlation will be -1. If there’s no relationship, then the correlation will be 0.</p>



<p>For this particular set of data, I generated it with a linear equation with a little bit of random noise. The correlation coefficient is slighly greater than 0.95, which is exctly what you’d expect.</p>



<p>Ok, so that’s the basics of linear regression. Let’s get back to the bozo-brained article that started this.</p>



<figure><img src="http://www.goodmath.org/blog/wp-content/uploads/2020/07/EcCqXojUMAEBFnp.jpg" alt=""></figure>



<p>They featured this graph:</p>



<p>You can see the scatter-plot of the points, and you can see the line that was fit to the points by linear regression. How does that fit look to you? I don’t have access to the original dataset, so I can’t check it, but I’m guessing that the correlation there is somewhere around 0.1 or 0.2 – also known as “no correlation”.</p>



<p>You see, the author fell into one of the classic traps of linear regression. Look back at the top of this article, where I started explaining it. I said that <em>if</em> you had reason to believe in a linear relationship, then you could try to find it. That’s the huge catch to linear regression: no matter what data you put in, you’ll always get a “best match” line out. If the dependent and independent variables don’t have a linear relation – or don’t have any actual relation at all – then the “best match” fit that you get back as a result is garbage.</p>



<p>That’s what the graph above shows: you’ve got a collection of data points that to all appearances has no linear relationship – and probably no direct relationship at all. The author is interpreting the fact that linear regression gave him an answer with a positive slope as if that positive slope is meaningful. But it’s only meaningful <em>if</em> there’s actually a relationship present.</p>



<p>But when you look at the data, you don’t see a linear relationship. You see what looks like a pretty random scatterplot. Without knowing the correlation coefficient, we don’t know for sure, but that line doesn’t look to me like a particularly good fit. And since the author doesn’t give us any evidence beyond the existence of that line to believe in the relationship that they’re arguing for, we really have no reason to believe them. All they’ve done is demonstrate that they don’t understand the math that they’re using.</p>
					</div></div>]]>
            </description>
            <link>http://www.goodmath.org/blog/2020/07/06/abusing-linear-regression-to-make-a-point/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752561</guid>
            <pubDate>Mon, 06 Jul 2020 20:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A tool to check if your site is among the to-be-revoked SSL certs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752467">thread link</a>) | @Mojah
<br/>
July 6, 2020 | https://ohdear.app/tools/certificate | <a href="https://web.archive.org/web/*/https://ohdear.app/tools/certificate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                We can check if your HTTPS certificates are valid, trusted in modern browsers and have the correct certificate chain.
            </p><p>
                These same checks happen every 5 minutes to alert you of unwanted changes if you <a href="https://ohdear.app/register">sign
                    up</a> for an Oh Dear account.
            </p><div>
                    <p>
                        Recent tests
                    </p>

                    <p>
                        The following websites have been tested recently. You can click through to view their results.
                    </p>

                    <ul>
                                                    <li>
                                -
                                <a href="https://ohdear.app/tools/certificate/ebdf16ae-2d46-45e7-93b6-b2cdd5382860">api.mla.org
                                </a>

                                <span>
                                                                            ✅
                                                                    </span>

                                <span>1 minute ago</span>
                            </li>
                                                    <li>
                                -
                                <a href="https://ohdear.app/tools/certificate/e1b58d26-37d3-41d6-979f-71c8d3a05a4b">packstation.de
                                </a>

                                <span>
                                                                            ❌
                                                                    </span>

                                <span>2 minutes ago</span>
                            </li>
                                                    <li>
                                -
                                <a href="https://ohdear.app/tools/certificate/3c91133e-48ff-4494-a14b-4b68e4c04be1">dhl.de
                                </a>

                                <span>
                                                                            ❌
                                                                    </span>

                                <span>24 minutes ago</span>
                            </li>
                                                    <li>
                                -
                                <a href="https://ohdear.app/tools/certificate/fdfe6c8e-6bfc-459d-8a5f-18560a9f8953">apps.mla.org
                                </a>

                                <span>
                                                                            ❌
                                                                    </span>

                                <span>26 minutes ago</span>
                            </li>
                                                    <li>
                                -
                                <a href="https://ohdear.app/tools/certificate/3f40f0eb-6b81-4b35-9fd4-db52f533a79e">llnw.com
                                </a>

                                <span>
                                                                            ✅
                                                                    </span>

                                <span>27 minutes ago</span>
                            </li>
                                            </ul>
                </div><div>
                <p>
                    These tests are based on the actual checks Oh Dear performs for its subscribers. On top of these
                    availability checks we can also send a wide variety of notifications to keep you informed about your
                    websites' availability.
                </p>
                <p>
                    Want to learn more about what Oh Dear can do? Have a look at our <a href="https://ohdear.app/features">feature
                        set</a>.
                </p>
            </div></div>]]>
            </description>
            <link>https://ohdear.app/tools/certificate</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752467</guid>
            <pubDate>Mon, 06 Jul 2020 20:36:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interactive SVG Outline Maps in React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752451">thread link</a>) | @tderflinger
<br/>
July 6, 2020 | https://www.tderflinger.com/en/interactive-svg-map-munich | <a href="https://web.archive.org/web/*/https://www.tderflinger.com/en/interactive-svg-map-munich">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Interactive maps on the web are a great way to visualize information.
How to create an interactive outline map with React of the city of Munich
I want to show in this article.</p><p>The great project <a href="https://www.openstreetmap.org/">OpenStreeMap</a> offers a query tool to obtain
city outlines of boroughs in many formats. This query tool is called
<a href="https://overpass-turbo.eu/">Overpass Turbo</a>.</p><p>With the following query you get the administrative boundaries of the
city, which in the case of Munich are its boroughs.</p><div data-language="text"><pre><code>[out:json][timeout:300];

{{geocodeArea:München}}-&gt;.searchArea;

(
  relation["boundary"="administrative"]["admin_level"="9"](area.searchArea);
);

out body;
&gt;;
out skel qt;</code></pre></div><p>Press the “Run” button and then “Export” and download it as GPX.</p><p>For our purpose we need the outline information in Scalable Vector Graphics (SVG)
format.
There is an open source Python script that converts any GPX file to SVG.
It is called <a href="https://nasauber.de/opensource/gpx2svg">gpx2svg</a>.</p><div data-language="bash"><pre><code>python3 gpx2svg -i export.gpx -o export.svg</code></pre></div><p>Now can you edit the SVG file in Adobe Illustrator.
Export the file again as an SVG to make it responsive and suitable
for further processing, with the following options:</p><p>Other SVG programs like <a href="https://inkscape.org/">Inkscape</a> might also work, although
I have not tried them here.</p><p>Now you can paste the SVG inline into your React component.
For interactivity when the mouse moves over a borough you need to
add a mouseover listener. Also, a name attribute is added to
identify the name of the borough to each SVG path.
The style attribute is removed.</p><p>In this React component I have defined a callback property
that gets called whenever you hover the mouse over a borough.
The parameter is the name of the borough which then gets
displayed in the parent component.</p><div data-language="js"><pre><code><span>import</span> React <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> styled <span>from</span> <span>"@emotion/styled"</span><span>;</span>

<span>function</span> <span>MunichMap</span><span>(</span><span>props</span><span>)</span> <span>{</span>
  <span>const</span> <span>handleMouseOver</span> <span>=</span> <span>(</span><span>evt</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>for</span> <span>(</span><span>const</span> attr <span>of</span> evt<span>.</span>target<span>.</span>attributes<span>)</span> <span>{</span>
      <span>if</span> <span>(</span>attr<span>.</span>name <span>===</span> <span>"name"</span><span>)</span> <span>{</span>
        props<span>.</span><span>callback</span><span>(</span>attr<span>.</span>value<span>)</span><span>;</span>
      <span>}</span>
    <span>}</span>
  <span>}</span><span>;</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span>svg
        name<span>=</span><span>"Layer_1"</span>
        data<span>-</span>name<span>=</span><span>"Layer 1"</span>
        xmlns<span>=</span><span>"http://www.w3.org/2000/svg"</span>
        viewBox<span>=</span><span>"0 0 3001.18 2316.9"</span>
        style<span>=</span><span>{</span><span>{</span> width<span>:</span> <span>"50%"</span> <span>}</span><span>}</span>
      <span>&gt;</span>
        <span>&lt;</span>Borough
          d<span>=</span><span>"M2502.09,1752.49l2.2,2.39,2.06,3,15,14.69,8.37,4.7-1,1.88,7.15,5.27-9.88,18.26-1,1.61-.92,1.29-1.7,2.26-1.14,1.63-1,2-.6,1.39-.33,1.46-.15,1.37-.4,1-.14.22-.23.7.3.08.31.09.66,1.25,1.16,6.58-.11,1.55.17,1.15,3.19,1.09,9.1,2,9.36,3.11,5.35,1.64,5.71,1.36,10.77,3.41,6.44,2.88,13.62,5,5,2.46,10.38,4.08,7.27,2.83,9.23,3.24,3.38,1.4,1.94,1.13,8,3.28,2.39,1.2,8.11,2.88,8.68,3.74,3.68.92-.75,1.83,2.59.89,5,1.19,7.36,1.35,2.09.12.24-1.72,1.14.28,5.36.08,3.09,5.2,2.85,4,2.12,3.74,1.8,2.81,2.68,2.73,1.49,1.43,1.66,1.87,1.34,1.83,3.26,5,1,2.19,3.23,4.1,2.13,3.26,1.27,2,9-3.11,7.07-2.66-.31-1.94-.43-4.13-.69-5.33,3.47-2,6.37-4,9.45-5.32,4.6-2.61,4.06-2.38,10.83-6.3.82-.61,4.69-3.89,1-.38,2.43-.94,1.94-.05,4.22-.64,1.07-.36,1.12-.08,4.43.46,3.75-1.93,1.62-1.41,2.1-2.61,3.78-3.11,5.89-3.92,5.53-3.57,10.24-6.84,10.82-5.44,10.51-5.73,4.86-3,3.48-.54,2.75-.66,2.43-.67,3.93-2.75,3.75-2.8,4.12-3.14,3.19-2.16,7-3.81,12.08-6.33,2.86-1.71,1.64-1.28,2.6-2.24,2.07-2.31L2901,1794l1.67-2,.92-1.13,3.23-3.89,1.26-1.19,4-3.64,1.28-.93,2.18-1.59,1.53-4.41,1.61-4.92,1-6.86,0-4.65v-1.21l.32-2.39.18-1.28.93-2.17,5.29-18.81,1.09-6.6.63-5.14,2.32-12,.52-2.76.18-1,0-.3L2931,1704l.22-1.92-3.85,1-1.68.19-4.07-3-.77-.6-3.25-2.57-3.68-3.62-5.17-5.68-4.94-4.74-1.1-1-3.67-3.91-3.5-4.3-3.89-4.15-4.38-4-2.63-2.17-.55-.16L2898.6,1647l-49.89-16.21-40.58-13.09-.2.51-6.42-2.14-2.13,1-1.89,0-4.1-2.53-2.41-1.66-8.27-2.72-2.11-.2-.21-1.3-13.87-4.54-5.66-4.13.11-.2,5.91-7.75.42-.55-.24-.11,2.77-3.73,7.73,5.94,12.5-16.35-28-23.87,14.41-15.92,4.14,0,10.88-11.9,12.47,11.16,24.74,22.15,14.64,13.26,2.24,1.87,2.8-2.23,3.62-3.23,2.54-2.08,3.77-2.8,2.14-1.09,2.41-.86,3.16-.68,2.28-.33.73,0,1.75,1,.86.74-.2-1.29,10.22-6,1.87,4.08,6.1-6.8,9.52-10.58,10.38,13.13,13.77-13.36,2.42-2.61,9.92-25.66,3.36-9.21,5.14-13.66-8.26-7.51,1.79-2-7.17-8.31-9.3,6.22-14-11.94,8-5.83,14.08-10.27-1.42-2.56-5.4-7.74-10.6-14.75,18.14-8,6.74,15.32,19-8.42,12.85-5.7,8.44-3.69,2.55-1.26-1.27-3.21-.57-1.42-4.44-10.34,3-2.09,6.41-4.16,17.31-12.64,0-.61-8.48-10.19-11.79-14.12-15.07,11.57-6.5,5-24.15-9.37-5-3.45-2.52-2.79-2.08-2.32-1.18-.7-1.86,1.53L2909,1340.52l-8.78-10.1-7.82-9,.64,0,3.8-2.85,4.52-3.39,6.48-4.82,8.32-6.29-14-16.33-1.26-1.47L2920,1276l.59.09-11.27-13.22-12.52-14.52-1.1-1.28,0-1.26-5.24-2.95-11.19,2.13-7,1.36-8.73,1.63-9.56,1.83-19.5,3.74-2.35-2.74-.51.41,1.59,2.56-34.5,6.65L2797,1258l-.46.31,1.23,2.3-30.07,5.7-1.78.07-10.87,2.43-13.81,2.61-1.6-2-.51.37,1.05,1.78-11.07,2.07-11.22,2.26-18,3.44-12.44,2.37L2681,1283l-5.54,1.09-2.59-.71-2.93-.79-13,2.47-14,2.67-13.68,2.66,13.58-111.36-27.7-22.69-7.08-5.81-2.8-2.3-4.4-3.61-1.79-1.47-2.49-2-2.42-2,2.41-3H2595l.16-.78-5.36-4.33-6.8-5.42-7-5.6-2.39-1.93-4.25-3.54-1.3-.84-1.3-.48-7.74-1.94,0,.12-10.85-2.5-11.2-3.41-.25,4.21,0,9.09v9.51l.06,2.16.29,13.73-.15,4.57.31.55-.45,1.21-.4,4.48.2,2.72.26,16.45.47,6.91-.23,3.26-.7,5.09-.62,3.82-1.25,5-1.47,7.63-1.13,4-2.89,13L2526,1237l-6.1,28.36-.13,1.69-.16.65-.16,0-.67,3.19-.27,2.3,2.46,7.27.43,1.52.33,2,.06,2.49-.33,5-.46,2.43-1.4,4.14-3.17,8.46-.09,2,.69,6.21-2.26.45.28,3-.2,2.18-.62,2.12-.67,2-4.17,12.24,4.25,0,3.12.51,3.28.93,3.93,1.24-1.55,1.31-14.37,11,.05.14-3.82,2.28-4,3-2,2-3.88,5.23-2.11,1-2.44,1.56-1.12.86-.8.94-14.54,11.09L2459,1390.61l-9.6,7.24-5.51,4.17-6.5,5.51-4.21,3.55-4.29,3.42-2.62,2,.75,3.37.37,4.17.29,1,.59-.3,1.8,7.43,3.66,14.88,2.1,8.23,2.14,8.45.32.18-.39.74.5,1.77h.11l.42,1.4.55.86.1.09,1.75,4,1.88,3.92,2.34,3.74,2.74,3.44.15.54.31.56.47.46.88.64-.7,1.43-5.37,11-2.58,6.07-4.09,9.65-7,15.76-.51,1.63-.66,2.11-10.65,24.4.9,1.57-8.36,17.77L2402,1596.3l-5.86-2.91-2.29,4.48-2.54,4-8.1,18.7-2.37,5.3-5.16,11.83-1.93,4.62-1.64,4.19-5.49,14.08-11.53-6.46-6.76-3.31-3,1.34-1.55.7,5.68,5.2,13.83,13.43,10.57,9.62,7.61,7.53,7.37,6.85,3.73,6.47,11.14-.26h4.4l.37.34.45.21.48.12,3.67,0v2.79l21.79,0v.73h3.22v1l20.43,15.95h2.38V1724h2v1.11h2v1.11h2v1.11h1.95v1.1h7.85l11.69,6.46,13,16.72Z"</span>
          transform<span>=</span><span>"translate(0.67 0.5)"</span>
          name<span>=</span><span>"15 Riem - Trudering"</span>
          onMouseOver<span>=</span><span>{</span>handleMouseOver<span>}</span>
        <span>/</span><span>&gt;</span>
        <span>&lt;</span>Borough
          d<span>=</span><span>"M1076.9,2163.07l1.74-1.9-2.12-1.92L1075,2161l.4.37-3,3.3.63.58,2-2.13.88-1Z"</span>
          transform<span>=</span><span>"translate(0.67 0.5)"</span>
        <span>/</span><span>&gt;</span>
        <span>&lt;</span>Borough
          d<span>=</span><span>"M1573.35,1819.93l1-2,.61-1.22,1.15-1.86.84-1.15,1.14-1.48,1.37-1.47,2.06-2,2.35-1.76,3.12-2,1.39-.72.19.08.15,0,6.89-4.19,4.32-4.28,1.4-1.57,1.27-1.64,1.07-1.48,1.34-2.22,1.8-3.45.31-.44,2.33-2.65.62-.61-7.08-4.74.81-.75-.23-.26-.93.71-4.45-3,2.19-1.31.3-.28-.49,0-2.08.79-.57.31-4.64-3.1-.06-.06-5.9-4,1-4.94.09-.54.09-1.11-1.09-1.12h-.62v-.39l-.08-.09.08-.1v-.37l-.07-.12.11-.13-.09-.15.11-.13-.06-.11v-.28l-.15-.25-1.52-.05-.09,0h-.45v-.23l-.58,0,0,.2h-.47l-.12,0-1.5,0-.19.44,0,.82-.13.21h-.34l-.2,5h.42l-.67,5.7,0,.68.36,0-.28,1.38-.67,2.7-.68,2.11-1,2.71-2.9,5.48-5.19-2.43,2-2.54-10.33-5.09-3.48-1.9-6.67-2.59-3.53,8.93-5.71-2.14-3.86-1.07-2-.36-6-.39-5.06-1.12-6.42,0-2,1.55-1.49,1.22-2.29,2.17-5.39,9.1-1.38,2-2.24,2.86-8.09,9.32-.81,1.7-.11,1.4.38,8.23-.09,4.26-.92-.05,0-.73-.54-3.44-2.07-10,.06-.13-1.3-5.66-.28-1.33-.3-1.78-.3-2.19,0-.51-1.6.31-6.64,1.27-3.31.61-10.68,1.48-7.19.7-5.41.54.21-1.57-1.24.39-1.78.59-3.54,1.14.26-.71.3-6.86-3.25-13.28-13.73,1.83.36,2.77-.87-.09-.65,4.44,1.17.09.09,1.48-1,0,0,1.19-1.79.07-13.1,1.44-5.94.84-2.08,3.64-.83,1.7-2.34.37-7.61-4.19-3.21.72-3.55.72-2.7.52-2.3.36-1.93.22-.12-.05-10.56,2-6.91.63,0,.68-9.08.47-1.92-.1-2-.11-9.8.47-4.41.14-1.92-.16-1.64,0h-1.79l-6.34.76-5,.25-4.42.26-1.49.19-1.85.33-1.6.52-1.56.71-1.4.83-.48-.63-.52-.55-1-.9-2.35-1.93-1-1-.74-.86-.93-1.37-.2-.85-.15-.93-.57-4.26-.11-.51-.21-.47-1.93-3.16-1.29-.45-10.44,7.2-7.07,4.89-2.75,2-6.71,4.83-6,5-5.55,5.27-6,6.3-1.2-.3-3.55-.37-2.1-.17h-1.54l-1.26.08-3.42.32-1.61.17-2.06.34.32,5.53-5.88,1.16-3.87.85-1.13.32.1,4.34v0l-2,10.65-.39,2.37-.41,1.76h.16l.68,2.68.19,1,.11,1.2-.11.82-1.21.58-1.54-.85-.6-.27-.64-.19-.63-.13h-.85l-1.46,0-3,0-4,.09-.27-.18-3.51-.5-1.33,1.15-3-3.47-9-10.91-2.47-2.58-1.76-1.8-2.28-2.15-1.36-1-1.43-1.13-6.24-4.76-2.59-2.1-3.29-3.06-2.71-3.53-2-3.81-.62-1.64-.84-2.63-1.51,1.13-3.64,2.78-1,.31-2,.27-2,.09-.55.72-2.22,1.73.18.24-.3.24-.64-.9-2.34-.31-4.23,3.21-.32,2.37.92,1.19-12.54,9.51-19.23,14.65-6.54,5-2-1-35.94,22.78-11.13,8.31-11.23,8.33-.51.14-.4.1-.38,0-.93.17.07.89-17.08,4.37-8.68,1.8-14.72,2.12-.33-2.25-.6-.66-1.72-1.29-7.35-10.67-2.49,1.31-4.38-13.31L984.2,1872l-2.39,1.39-2.88,1.12-2.39,1.31-2,.61-13.6,5.4-3.72,1.2-.93.93-4.61,2.2-7.49,3.17-2.73,1.38-3.75,1.64-.29,1.64-.22,3.12,1.68.21-.74,4.12-1.29,6.84-.91,6.47-1.29,5.59-.39,3.51-.67,6.53-1.94,5.36-2.41,6.77-1.52,4.19-2.06,5.7-1.29,3.59-1.07,3-1.27,3.54,3.69,2.34,4.78,3.2,2.88,2.31,6.22,4.5,4.59,2.16.09.49-.23.36,2.45.76,2.25.4,1.71.14,4.06,0,2.86,0-.69,1.31L956,1982l-1.47,2.72-1.75,2.89-.5.81-.68,1.18-1.14,1.88-2.85,4.57-1.49,2.32-1.17,1.87-.93,1.21-1,.66-.5.29-2.61,1.14-3.75,1.53-1.28.36-1.61,2.7-1.15,2.35-2.42,4.82-1.87,3.9-1.69,3.29-2.41,4-4.67,7.52-1.3,2.52-1.19,2.3-1.64,4-.59,1.41-.91,2.78-.29.65-.67.94,19.33,12.3-2.74,2.86-4.56-3.75-3.58,5.68,3.17,2.65,1.84,2.14,3.13,2.47,3.92-5-3.13-2.38.09-1.07,2.78-3,13.07,7.93L967,2082.75l17.85,11.48,9.53,6,17.4,11.08,9.86,6.39,9.64,6.18,8.61,5.52,3.29,2.09,2.81,1.79-2.44,6.06-2.33,5.92-2,3.08-.93,2.27,1.69.77-4.29,8.36,11,5.5,7.24-14.76-11.24-5.16,4.87-10.88,2,1.31.15,0,4.16,2.56,7.81,5,6.24,3.93,5.18,3.35,10.69,6.76,1.31.79,17.6,11.15,18.53,11.79,18.56,11.83,17.19,11,17.06,11.08,2.82,1.85,5.92,4-5.6,8.42-.27,1.38-1,4.91.31,6,2.08,7.86-1.45.55h-2.23l.45,1.67,2.16,7.39,1.25,6.32,5.22,2.85,1,8.19.73,8,1.86,15.81.85,6.15,10.15,2.79,6.65,1.12,7.88,2.58,9.51,2.51,3.49.55,4.27-6.43,18.47-28,34,12.85,1.24-4.8,1.86-11,1.25-4.71,1.5-5.23,2.48.75,1.42-5.24,1.93-7,4.65,1.21,1-4.1,4.43-.29-.18-3.82,4.75-1.56.41,1,1.41-.65-1.54-3.67,1.94-.11,5.79-.26,4.42-.21,1.57-.06,1,.1,5.94.09,5.39.1,1.28.09.15,2.61,1,0-.57,3.19-.4,2-.32,2.15,5.91.8,1.2.17,1.15-14.88,4-5.87,2.49-3,4-1.09,6.6…</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tderflinger.com/en/interactive-svg-map-munich">https://www.tderflinger.com/en/interactive-svg-map-munich</a></em></p>]]>
            </description>
            <link>https://www.tderflinger.com/en/interactive-svg-map-munich</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752451</guid>
            <pubDate>Mon, 06 Jul 2020 20:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ages of Discord: A Structural-Demographic Analysis of American History]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23752331">thread link</a>) | @Reedx
<br/>
July 6, 2020 | https://theworthyhouse.com/2020/01/10/ages-of-discord-a-structural-demographic-analysis-of-american-history-peter-turchin/ | <a href="https://web.archive.org/web/*/https://theworthyhouse.com/2020/01/10/ages-of-discord-a-structural-demographic-analysis-of-american-history-peter-turchin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><figure><img src="https://i0.wp.com/theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Cover-7.jpg?w=840&amp;ssl=1" alt="" srcset="https://i0.wp.com/theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Cover-7.jpg?w=300&amp;ssl=1 300w, https://i0.wp.com/theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Cover-7.jpg?resize=100%2C150&amp;ssl=1 100w, https://i0.wp.com/theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Cover-7.jpg?resize=200%2C300&amp;ssl=1 200w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Cover-7.jpg?w=300&amp;ssl=1 300w, https://i0.wp.com/theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Cover-7.jpg?resize=100%2C150&amp;ssl=1 100w, https://i0.wp.com/theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Cover-7.jpg?resize=200%2C300&amp;ssl=1 200w" data-lazy-src="https://i0.wp.com/theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Cover-7.jpg?w=840&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>I am skeptical of those who predict the future by looking at the past. It’s not that history follows a random walk, like the stock market. Quite the contrary—it is easy to show certain patterns in history. But predicting how and when those patterns will yield any particular result in any given society seems like astrology. Peter Turchin, however, offers a very convincing, and very well-supported, tying of patterns to data. I’m still not sure it’s not astrology, but I’m half convinced. And this is a good book to read in January 2020—because right now is when Turchin predicts, in America, the swelling discord of the title.</p>
<p>This book is, fortunately, nothing like the terrible <em><a rel="noreferrer noopener" aria-label="The Fourth Turning (opens in a new tab)" href="https://theworthyhouse.com/2019/01/22/book-review-the-fourth-turning/" target="_blank">The Fourth Turning</a></em>, a more famous and very stupid book. Like that book, however, it does posit cycles in societies (as do many other books, ranging from <a rel="noreferrer noopener" aria-label="Ibn Khaldun’s Muqaddimah (opens in a new tab)" href="https://theworthyhouse.com/2019/08/09/ibn-khaldun-an-intellectual-biography-robert-irwin/" target="_blank">Ibn Khaldun’s </a><em><a rel="noreferrer noopener" aria-label="Ibn Khaldun’s Muqaddimah (opens in a new tab)" href="https://theworthyhouse.com/2019/08/09/ibn-khaldun-an-intellectual-biography-robert-irwin/" target="_blank">Muqaddimah</a> </em>to <a rel="noreferrer noopener" aria-label="Joseph Tainter’s The Collapse of Complex Societies (opens in a new tab)" href="https://theworthyhouse.com/2018/01/24/book-review-the-collapse-of-complex-societies-joseph-a-tainter/" target="_blank">Joseph Tainter’s </a><em><a rel="noreferrer noopener" aria-label="Joseph Tainter’s The Collapse of Complex Societies (opens in a new tab)" href="https://theworthyhouse.com/2018/01/24/book-review-the-collapse-of-complex-societies-joseph-a-tainter/" target="_blank">The Collapse of Complex Societies</a></em>). “[A] typical historical state goes through a sequence of relatively stable political regimes separated by unstable periods characterized by recurrent waves of internal war. The characteristic length of both stable (or integrative) and unstable (or disintegrative) phases is a century or longer, and the overall period of the cycle is around two to three centuries.” Among many other examples Turchin gives, <a href="https://theworthyhouse.com/2016/10/11/book-review-considerations-on-the-causes-of-the-greatness-of-the-romans-and-their-decline-montesquieu/" target="_blank" rel="noreferrer noopener" aria-label="the integrative phase of the Roman Republic (opens in a new tab)">the integrative phase of the Roman Republic</a> was 350–130 BC; its disintegrative phase was 130–30 BC, to be succeeded by Principate Rome. To take a less commonly known example, the integrative phase of Valois France was AD 1450–1560; its disintegrative phase was AD 1560–1660. Turchin sees America as being in a disintegrative phase that began in the 1970s and will peak starting in 2020. <em>Ages of Discord</em> is an attempt to substantiate that claim, and offers predictions of chaos in America’s near future. Like Hari Seldon in Isaac Asimov’s <em>Foundation</em>, Turchin sees this disintegrative phase as inevitable—but also, maybe, ameliorable.</p>
<p><span><span><a target="_blank" title="Print" rel="noopener" href="https://theworthyhouse.com/wp-content/uploads/2020/01/Ages-of-Discord-Turchin-PDF.pdf"><span>Print (PDF)</span></a></span></span></p><p>Since this is the turn of the decade, we have, over the past few weeks, been subjected to endless news articles claiming that the 2010s were the best decade ever. Turchin is having none of that. (And all those claims are stupid on their face—their sole substantive “argument” is that due to the spread of free markets, <a rel="noreferrer noopener" aria-label="poverty in the Third World (opens in a new tab)" href="https://theworthyhouse.com/2015/08/11/book-review-the-white-mans-burden-why-the-wests-efforts-to-aid-the-rest-have-done-so-much-ill-and-so-little-good-william-easterly/" target="_blank">poverty in the Third World</a> has declined sharply—which is true enough, but totally irrelevant to whether America had a good decade, or is going to have one over the next ten years). The method of <em>Ages of Discord </em>(which, interestingly, <a href="https://theworthyhouse.com/2019/06/19/the-war-on-normal-people-the-truth-about-americas-disappearing-jobs-and-why-universal-basic-income-is-our-future-andrew-yang/" target="_blank" rel="noreferrer noopener" aria-label="is given substantial attention in Presidential candidate Andrew Yang's recent book (opens in a new tab)">is given substantial attention in Presidential candidate Andrew Yang’s recent book</a>) is to use an enormous amount of data and mathematical modeling to add substance to Turchin’s theory of “secular cycles,” developed in an earlier book of that name by Turchin and Sergey Nefedov (where secular has its economic meaning of “a long-term trend of indefinite specific duration”). Turchin calls this the science of “cliodynamics,” a neologism formed from the name of the muse of history and the term for the science of why things change (and also reflecting that society is a web, a “dynamical system”). Cliodynamics is an attempt to view history through science, primarily through the science of statistics. It seeks to offer general principles that can be tested against historical data, and that testing is what Turchin offers here.</p>
<p>Turchin begins with the observation that, however it may feel to us, human societies are fragile. Somewhat melodramatically, he references the American Civil War, while unconvincingly disclaiming that he believes something like that is imminent. He <a rel="noreferrer noopener" aria-label="does not think that Steven Pinker is right (opens in a new tab)" href="https://theworthyhouse.com/2015/07/06/book-review-the-better-angels-of-our-nature-stephen-pinker/" target="_blank">does not think that Steven Pinker is right</a> that we are now more civilized than we used to be; for Turchin, there is no thing new under the Sun, except for, perhaps the science of cliodynamics. Turchin notes that in 2010 (this book was published in 2016) he predicted “the next decade is likely to be a period of growing instability in the United States and <a href="https://theworthyhouse.com/2017/09/08/book-review-the-strange-death-of-europe-douglas-murray/" target="_blank" rel="noreferrer noopener" aria-label="western Europe (opens in a new tab)">western Europe</a>.” He is well-satisfied that he was right, and I think most people would agree.</p>
<p>The framework of Turchin’s model, laid out in Part I, is the “Structural-Demographic Theory,” originated by Jack Goldstone to apply to agrarian societies and reformulated by Turchin and Nefedov in their earlier book to apply to industrial societies. SDT consists of three basic claims, or “principles.” First, population growth exceeding productivity (the Malthusian Trap, in essence) leads to falling wages, migration, and ultimately, wage protests such as riots. Actual starvation due to the Malthusian Trap is no longer a problem in industrial societies, of course—population increases rather lead to declining real wages, with similar negative effects on the wellbeing of the masses, “immiseration” (though the mechanics are more complex than in agrarian societies). This is the “labor oversupply principle.” Second, fast population growth also leads to “elite overproduction,” where elites compete for a largely fixed number of elite positions, which leads to elite disunity, the creation of a counter-elite, and elite conflict. This problem is worse in industrial societies, since unlike in agrarian societies, declining real wages actually benefit the elite, who get cheaper labor, and respond by engaging in ever greater, “runaway” consumption, exacerbating the intraelite conflict caused by their swelling ranks. This is the “elite overproduction principle.” And third, the “instability principle,” where population growth also leads to expansion of the state, resulting in increased taxes, which inevitably fail to cover expenses, leading to fiscal crisis. “As all these trends intensify, the end result is state bankruptcy and consequent loss of military control; elite movements of regional and national rebellion; and a combination of elite-mobilized and popular uprisings that expose the breakdown of central authority.” This drives the disintegrative phase of the secular cycle, involving increased mortality, decreased productivity, instability, political violence, war, and, potentially, collapse—followed, ultimately, by a new integrative phase, sometimes with a very different society, sometimes with much the same society, where the three principles reverse in unison.</p>
<p>Turchin is not claiming specific causation. He is showing correlations. He troubles himself to clarify that these three principles are simply proxies “for the movements of structural forces postulated by the theory. In other words, the Structural-Demographic Theory provides a holistic explanation not only for these three particular variables, but for a host of others.” Occasionally he will suggest possible causal links, the most notable being that elites, exhausted after a long period of instability (often including the death of many members of the elite), turn away from competition to cooperation, helping to end a disintegrative phase. (The <a href="https://theworthyhouse.com/2018/08/03/book-review-storm-storm-beginning-end-roman-republic-mike-duncan/" target="_blank" rel="noreferrer noopener" aria-label="end of the Roman Republic (opens in a new tab)">end of the Roman Republic</a> is the classic example.) Mostly, though, it is patterns tied to data that he offers, and often patterns within patterns.</p>
<p>Thus, his project is to develop mathematical models, then feed them historical data from different eras and see what comes out. This book is specifically written to apply such a model to the United States from its formation (roughly 1780) to the present (2016). It is not an easy read. Lengthy entire chapters are taken up with mathematical formulas—Turchin says the reader can skip these, but that undermines understanding, so I recommend against skipping. The point of the mathematics is to quantify and weight factors in a model that can be applied across different times and places, as well as perform various transforms and shifts, all of which Turchin explains (and he apparently offers most of his data and models for others to review). Complexities abound—for example, finding quantitative proxies for cultural mood, or for the willingness of elites to cooperate with each other, rather than engage in conflict. Much else goes into this, such as rejecting the idea of discrete generations, and instead modeling transmission of behavior across time, paying attention to the “fathers-and-sons dynamic,” feedback loops, and the intersection of different resulting sub-cycles, which aggregate to show certain patterns. Any reader is going to wonder if Turchin is fitting the math to his theories, but looking around, <a rel="noreferrer noopener" aria-label="nobody seems (opens in a new tab)" href="https://slatestarcodex.com/2019/08/12/book-review-secular-cycles/" target="_blank">nobody seems</a> to accuse him of <a href="https://slatestarcodex.com/2019/09/02/book-review-ages-of-discord/" target="_blank" rel="noreferrer noopener" aria-label="doing that (opens in a new tab)">doing that</a>. </p>
<p>After introducing the three principles of SDT as applied to industrial societies, and offering an explanation and justification of his mathematical approach, in Part II Turchin expands on each of the three principles as applied to America. In “Demography and Wellbeing,” Turchin examines statistics about and patterns in labor supply since 1780. He analyzes both immigration and native births, compared to real wages over time, both absolutely and relative to GDP per capita. He then ties the resulting graphs to measures of wellbeing, such as height of adults (which declined four centimeters from 1830 to 1900!), life expectancy, age of first marriage (which he notes is “only imperfectly correlated with social optimism”), and so forth.</p>
<p>Tellingly for modern debates, Turchin here draws the firm conclusion that when immigration is high, not only wages, but wellbeing, are low, and not just for a few years, but correlating over decades—including the most recent phase, since 1970, where wellbeing has objectively declined (contrary to the propaganda we are fed), while immigration has skyrocketed and real wages stagnated. He takes this as demonstrating the accuracy of the labor oversupply principle. As he goes along, Turchin is also combining the data, in the form of various graphs, that he discusses. So, for example, he shows that when you overlay a graph of mass wellbeing on a graph for elite overproduction, you see that since 1780 there is a precise inverse relationship between the two—just as the SDT predicts.</p>
<p>In “Elite Dynamics,” Turchin focuses on the ruling class, defined as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theworthyhouse.com/2020/01/10/ages-of-discord-a-structural-demographic-analysis-of-american-history-peter-turchin/">https://theworthyhouse.com/2020/01/10/ages-of-discord-a-structural-demographic-analysis-of-american-history-peter-turchin/</a></em></p>]]>
            </description>
            <link>https://theworthyhouse.com/2020/01/10/ages-of-discord-a-structural-demographic-analysis-of-american-history-peter-turchin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752331</guid>
            <pubDate>Mon, 06 Jul 2020 20:24:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a 486 from floppy with the most up-to-date stable Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 142 (<a href="https://news.ycombinator.com/item?id=23752284">thread link</a>) | @LeoPanthera
<br/>
July 6, 2020 | https://www.insentricity.com/a.cl/283 | <a href="https://web.archive.org/web/*/https://www.insentricity.com/a.cl/283">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>
	<iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="400" src="https://www.youtube.com/embed/oBeE_z4HTwg" width="600"></iframe></p>
<div>
	<p>
		Back in August of 2019 I had a&nbsp;<a href="https://www.reddit.com/r/retrobattlestations/comments/cr6x9a/contest_singalong_week_until_aug_25/">Sing-Along Week contest on RetroBattlestations</a>&nbsp;with the challenge of playing a MIDI file synchronized to a speech synthesizer singing the lyrics. In my stash of cards I found an MQX-32M MIDI card (Roland MPU-401 clone) which I wanted to use for converting MIDI signals to interface to an Apple II+ with an Echo II speech synthesizer, but ended up using a laptop with a USB MIDI interface. The&nbsp;<a href="https://www.reddit.com/r/retrobattlestations/comments/fz6is8/contest_pizza_week_through_april_19th/">Pizza Week contest</a>&nbsp;made me more interested in finding a 486 in a pizza box case and so my search began for a suitable case.</p>
	
	<p>
		Searching eBay wasn't easy because there's not really a good search term that would find the kind of case I wanted. I didn't bother trying to make a saved search since this project wasn't a high priority. Instead every once in a while something would inspire to go hit eBay and try some other search terms. A couple of weeks ago I spotted this 486 and made a guess of the size based on the size of the 5.25" bay. It's fairly slim, it has a riser card to turn the cards sideways and the case <em>is</em> shorter than an ISA card, but I don't feel like it's slim enough to call it a pizza box. It's close though!</p>
	
	<p>
		The motherboard is a <a href="https://stason.org/TULARC/pc/motherboards/T/TMC-RESEARCH-CORPORATION-486-PAT48PG4-VER-1-2A.html">TMC PAT48PG4</a> and it came with 32MB of RAM (technically 36MB, it had four 30 pin SIMMs in it too) and 4 cards: VGA, SoundBlaster, modem, and multi-function IO. The seller had tested it and was sold as non-working, won't POST, although he said the cards all worked. I mostly wanted it for the case so I wasn't concerned. Of course when I got it I had to see if the motherboard was really dead. It didn't work for me either but then I discovered if I hit the reset button it would give me some error beeps. I tried another power supply and it came up after hitting reset! It still doesn't cold boot when powered on, not sure if there's a bad cap or if the very slight battery damage (battery was removed before I got it) is preventing the reset line from being pulled after power on. Nonetheless it was working enough that I needed to explore its capabilities more.</p>
	
	<p>
		My ultimate goal is to get a <em>very recent</em>&nbsp;Linux distro and Python 3 installed to a "large" hard drive, but being that this is a 486 installing a current Linux distro isn't trivial. The only Linux distros that still support installing from floppy media are quite dated. Normally I would bypass a floppy install entirely and just boot an older computer via PXE and then install over the network. I thought I could <a href="https://ipxe.org/appnote/buildtargets">put iPXE on a floppy</a> and stick in an ISA NIC but iPXE just hangs without any error messages right after it's loaded from floppy.&nbsp;</p>
	
	<p>
		The BIOS is ancient and struggles with handling the "large" hard drive I hooked up. The drive is 8.45GB and the BIOS can only see it as an 8.0GB drive. Enabling LBA in the BIOS causes the computer to hang during POST after it detects the drive. Win98 fdisk insists the drive is only 504MB. FreeDOS can't see the drive at all. I tried sticking in a NIC with XTIDE ROM on the socket and XTIDE also insists there's no drive connected.</p>
	
	<p>
		Since I wanted to see how Linux would detect the drive that meant I needed to find a way to boot Linux. After a bit of googling I discovered the <a href="http://tiny.wiki.kernel.org/">make tinyconfig option</a> which makes a very small (but useless) kernel, small enough to fit on a floppy. <a href="https://weeraman.com/building-a-tiny-linux-kernel-8c07579ae79d">I enabled a couple of other options</a>, found a small enough initramfs, and was able to get it to boot on the 486. And as expected Linux has no problem with seeing that the drive is connected and the drive's full capacity.</p>
	
	<p>
		Next step is to actually get Linux installed to the hard drive. I'd rather not roll my own distro but maybe I'll have to. Another possibility is to boot Linux from floppy and then download a kernel and initrd from a current distro and kexec over to it. But that feels to me like reinventing iPXE.</p>
	<h4>
		Compiling the Linux Kernel From Source</h4>
	<p>
		A quick rundown of the steps to build the floppy image:</p>
</div>
<ul>
	<li>
		git clone https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git
		<ul>
			<li>
				v5.8-rc2-1-g625d3449788f&nbsp;at the time of writing</li>
		</ul>
	</li>
	<li>
		make ARCH=x86 tinyconfig</li>
	<li>
		make ARCH=x86 menuconfig
		<ul>
			<li>
				Set processor to 486: CONFIG_M486=y
				<ul>
					<li>
						Processor type and features &gt; Processor family &gt; 486</li>
				</ul>
			</li>
			<li>
				Enable tty: CONFIG_TTY=y
				<ul>
					<li>
						Device Drivers &gt; Character devices &gt; Enable TTY</li>
				</ul>
			</li>
			<li>
				Enable printk: CONFIG_PRINTK=y
				<ul>
					<li>
						General Setup &gt; Configure standard kernel features (expert users) &gt; Enable support for printk</li>
				</ul>
			</li>
			<li>
				Enable initramfs: CONFIG_INITRAMFS_COMPRESSION_GZIP=y
				<ul>
					<li>
						General Setup &gt;&nbsp;Initial RAM filesystem and RAM disk (initramfs/initrd) support &gt;&nbsp;Support initial ramdisk/ramfs compressed using gzip</li>
				</ul>
			</li>
			<li>
				Enable ELF: CONFIG_BINFMT_ELF=y
				<ul>
					<li>
						Executable file formats &gt;&nbsp;Kernel support for ELF binaries</li>
				</ul>
			</li>
		</ul>
	</li>
	<li>
		make ARCH=x86 bzImage</li>
</ul>


<p>
	Test boot with qemu:</p>
<div>
	<pre>qemu-system-i386 -kernel arch/x86/boot/bzImage -initrd ../system-image-486/rootfs.cpio.gz</pre>
</div>
<p>
	Create a blank floppy image:</p>
<div>
	<pre>dd if=/dev/zero of=linux-boot.img bs=1k count=1440
mkdosfs linux-boot.img
syslinux --install linux-boot.img
mount -o loop linux-boot.img /mnt
cp arch/x86/boot/bzImage /mnt
cp rootfs.cpio.gz /mnt</pre>
</div>
<p>
	Create /mnt/syslinux.cfg:</p>
<div>
	<pre>DEFAULT linux
LABEL linux
 SAY Now booting the kernel from SYSLINUX...
 KERNEL bzImage
 APPEND initrd=rootfs.cpio.gz
</pre><p>
	Write the image to a floppy:
	</p><pre>umount /mnt
fdformat /dev/fd0
ddrescue -f -D linux-boot.img /dev/fd0
</pre>
	
</div>

</div></div>]]>
            </description>
            <link>https://www.insentricity.com/a.cl/283</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752284</guid>
            <pubDate>Mon, 06 Jul 2020 20:20:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live from Adélie: Streaming Spotify on Musl]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752130">thread link</a>) | @sthrs
<br/>
July 6, 2020 | https://catfox.life/2020/07/06/live-from-adelie-streaming-spotify-on-musl/ | <a href="https://web.archive.org/web/*/https://catfox.life/2020/07/06/live-from-adelie-streaming-spotify-on-musl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Over the July 4th holiday weekend, I was working on a secret project.  It was a resounding success and I can now announce to the world: Spotify runs on musl distributions!</p>
<p>This article will describe how I went about accomplishing this feat.  If you just want to take Spotify for a test drive on your Adélie workstation or Void desktop, scroll to the “Instructions” heading.</p>
<h2>Greetz</h2>
<p>Thanks to these fine dwellers of IRC for helping make sense of the twisty mazes.</p>
<ul>
<li>[[sroracle]]</li>
<li>Aerdan</li>
<li>cb</li>
<li>dalias</li>
<li>skarnet</li>
</ul>
<h2>gcompat 0.4.0: how very cash LC_MONETARY of you</h2>
<p>The latest release version of gcompat did not get very far:</p>
<pre>awilcox on laptop spotify % ./spotify
Segmentation fault (core dumped)
</pre>
<p>Inspecting the core file was minimally helpful:</p>
<pre>Thread 1 "ld-musl-x86_64." received signal SIGSEGV, Segmentation fault.
0x0000000001d6ff60 in ?? ()
(gdb) bt
#0  0x0000000001d6ff60 in ?? ()
#1  0x00007fffffffd738 in ?? ()
#2  0x0000000001e94f13 in ?? ()
#3  0x00007fffffffd6d0 in ?? ()
#4  0x00007fffffffd738 in ?? ()
#5  0x0000000003e9d691 in ?? ()
#6  0x0000000003e9d698 in ?? ()
#7  0x0000000003e9d691 in ?? ()
#8  0x00007fffffffd738 in ?? ()
#9  0x00007fffffffdc40 in ?? ()
#10 0x0000000001ccd0f0 in ?? ()
#11 0x00007fffffffd7a0 in ?? ()
#12 0x0000000000000001 in ?? ()
#13 0x00007fffffffd720 in ?? ()
#14 0x0000000001e92e92 in ?? ()
#15 0x0000000003e9d691 in ?? ()
#16 0x0000000003e9d698 in ?? ()
#17 0x00007fffffffd738 in ?? ()
#18 0x00007fffffffd738 in ?? ()
#19 0x00007fffffffd760 in ?? ()
#20 0x0000000001e9dd51 in ?? ()
#21 0x00007fffffffdc40 in ?? ()
#22 0x0000000003e9b3e0 in ?? ()
#23 0x00007fffffffd7e8 in ?? ()
#24 0x00007fffffffd7b8 in ?? ()
#25 0x00007fffffffd7b8 in ?? ()
#26 0x00007fffffffd828 in ?? ()
#27 0x00007fffffffd810 in ?? ()
#28 0x0000000001e9df09 in ?? ()
#29 0x612f656d6f682f1a in ?? ()
#30 0x0000786f636c6977 in ?? ()
#31 0x0000000000000000 in ?? ()
(gdb) info registers
rax            0x54454e4f4d5f434c  6072345775086453580
rbx            0x53                83
rcx            0x53                83
rdx            0x2                 2
rsi            0x53                83
rdi            0x3e9b1a0           65647008
rbp            0x7fffffffd6f0      0x7fffffffd6f0
rsp            0x7fffffffd690      0x7fffffffd690
r8             0x0                 0
r9             0x0                 0
r10            0x1                 1
r11            0x7fffffffdb9c      140737488346012
r12            0x7fffffffd6b8      140737488344760
r13            0x7fffffffd6b0      140737488344752
r14            0x7fffffffd6a8      140737488344744
r15            0x7fffffffd6c0      140737488344768
rip            0x1d6ff60           0x1d6ff60
eflags         0x10202             [ IF RF ]
cs             0x33                51
ss             0x2b                43
ds             0x0                 0
es             0x0                 0
fs             0x0                 0
gs             0x0                 0
</pre>
<p>What are we trying to do?  Looking at symbols present in the Spotify binary, this is actually part of the G++ runtime; specifically, <code>std::ctype::do_tolower</code>:</p>
<pre>  1d6ff51:       48 8b 05 18 a8 12 02    mov    0x212a818(%rip),%rax        # 3e9a770 
  1d6ff58:       48 8b 40 70             mov    0x70(%rax),%rax
  1d6ff5c:       48 0f be cb             movsbq %bl,%rcx
=&gt;1d6ff60:       8a 1c 88                mov    (%rax,%rcx,4),%bl
  1d6ff63:       89 d8                   mov    %ebx,%eax
  1d6ff65:       5b                      pop    %rbx
  1d6ff66:       c3                      retq
</pre>
<p>That <code>rax</code> value looks suspicious, and we can see if we translate it to ASCII that it is the little-endian representation of the string “LC_MONETARY”.  We’re trying to reach 0x70 into a structure in %rax for a pointer value, but we’re getting a string instead.</p>
<p>It turns out that when libstdc++ is compiled on a glibc system, it will attempt to access the internal <code>__ctype_*</code> members in the <code>locale_t</code> of the current locale.  musl’s <code>locale_t</code> is not ABI-compatible with glibc’s.  In fact, it is only 48 bytes in length; 0x70 (or 112 bytes) is past the end of the locale object musl has provided it!</p>
<p>I implemented a <a href="https://code.foxkit.us/adelie/gcompat/-/commit/2eae317bd62a38645f35c46ca62cdde24ff718d8">stub locale module in gcompat</a>, and… it tried to exec <code>/proc/self/exe</code>, which broke under the gcompat loader.  This required me to write a patch <a href="https://code.foxkit.us/adelie/gcompat/-/commit/18a847c22a04de22cc9c431e87b63a0cfd5f1286">interposing the execv* functions</a> to catch this.  And suddenly…</p>
<h2>The lights that stop me turn to stone</h2>
<p>Slight success!  We have a Spotify window!</p>
<p><img data-attachment-id="269" data-permalink="https://catfox.life/2020/07/06/live-from-adelie-streaming-spotify-on-musl/photo_2020-07-05_13-26-11/" data-orig-file="https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg" data-orig-size="1280,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Blank Spotify" data-image-description="" data-medium-file="https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg?w=300" data-large-file="https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg?w=676" src="https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg?w=676" alt="Spotify, but only a white screen" srcset="https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg?w=676 676w, https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg?w=150 150w, https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg?w=300 300w, https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg?w=768 768w, https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg?w=1024 1024w, https://foxdotlife.files.wordpress.com/2020/07/photo_2020-07-05_13-26-11.jpg 1280w" sizes="(max-width: 676px) 100vw, 676px"></p>
<p>… but a blank white screen only.  After some inspecting, I found that one of the many zygotes CEF was forking was segfaulting:</p>
<pre>[158358.508029] ThreadPoolForeg[3230]: segfault at 0 ip 0000000000000000 sp 00007fe3203db448 error 14 in spotify[200000+1acd000]
[158365.067313] ThreadPoolForeg[3252]: segfault at 0 ip 0000000000000000 sp 00007f2d69c172e8 error 14 in spotify[200000+1acd000]
[158378.506832] ThreadPoolForeg[3312]: segfault at 0 ip 0000000000000000 sp 00007f52ed7c8448 error 14 in spotify[200000+1acd000]
[158383.654027] ThreadPoolForeg[3339]: segfault at 0 ip 0000000000000000 sp 00007fcb631eb2e8 error 14 in spotify[200000+1acd000]
</pre>
<p>I replaced libcef.so from the Spotify DEB package with a matched-version libcef.so from Spotify’s Open Source builds page.  This allowed me to have more debugging symbols, and generating a core dump revealed:</p>
<pre>Core was generated by `ld-linux-x86-64.so.2 --argv0 /usr/share/spotify/spotify --type=utility --field-'.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x0000000000000000 in ?? ()
[Current thread is 1 (LWP 12774)]
(gdb) bt
#0  0x0000000000000000 in ?? ()
#1  0x00007f79a8a3d671 in sqlite3MallocSize () at ../../third_party/sqlite/amalgamation/sqlite3.c:26957
#2  mallocWithAlarm () at ../../third_party/sqlite/amalgamation/sqlite3.c:26891
#3  sqlite3Malloc () at ../../third_party/sqlite/amalgamation/sqlite3.c:26913
#4  0x00007f79a8aff232 in sqlite3MallocZero () at ../../third_party/sqlite/amalgamation/sqlite3.c:27118
#5  pthreadMutexAlloc () at ../../third_party/sqlite/amalgamation/sqlite3.c:25755
#6  0x00007f79a8a4e9b2 in sqlite3MutexAlloc () at ../../third_party/sqlite/amalgamation/sqlite3.c:25298
#7  chrome_sqlite3_initialize () at ../../third_party/sqlite/amalgamation/sqlite3.c:24906
#8  0x00007f79a8a350bd in EnsureSqliteInitialized () at ../../sql/initialization.cc:55
#9  0x00007f79a8a30eb2 in OpenInternal () at ../../sql/database.cc:1357
#10 0x00007f79a8a30dfa in Open () at ../../sql/database.cc:270
#11 0x00007f79a8fb8de6 in InitializeDatabase () at ../../net/extras/sqlite/sqlite_persistent_store_backend_base.cc:99
#12 0x00007f79a8fb9751 in LoadNelPoliciesAndNotifyInBackground () at ../../net/extras/sqlite/sqlite_persistent_reporting_and_nel_store.cc:1041
#13 0x00007f79a5abe25b in Invoke&lt;void (leveldb_proto::ProtoDatabaseSelector::*)(base::OnceCallback), scoped_refptr, base::OnceCallback &gt; () at ../../base/bind_internal.h:498
#14 MakeItSo&lt;void (leveldb_proto::ProtoDatabaseSelector::*)(base::OnceCallback), scoped_refptr, base::OnceCallback &gt; ()
    at ../../base/bind_internal.h:598
#15 RunImpl&lt;void (leveldb_proto::ProtoDatabaseSelector::*)(base::OnceCallback), std::__1::tuple&lt;scoped_refptr, base::OnceCallback &gt;, 0, 1&gt; () at ../../base/bind_internal.h:671
#16 RunOnce () at ../../base/bind_internal.h:640
#17 0x00007f79a7776fa0 in Run () at ../../base/callback.h:98
#18 RunTask () at ../../base/task/common/task_annotator.cc:142
#19 0x00007f79a7792862 in base::internal::TaskTracker::RunBlockShutdown(base::internal::Task*) () at ../../base/task/thread_pool/task_tracker.cc:743
#20 0x00007f79a7792062 in RunTask () at ../../base/task/thread_pool/task_tracker.cc:598
#21 0x00007f79a77d42fb in RunTask () at ../../base/task/thread_pool/task_tracker_posix.cc:23
#22 0x00007f79a7791a43 in RunAndPopNextTask () at ../../base/task/thread_pool/task_tracker.cc:450
#23 0x00007f79a7798386 in RunWorker () at ../../base/task/thread_pool/worker_thread.cc:321
#24 0x00007f79a77980f4 in base::internal::WorkerThread::RunPooledWorker() () at ../../base/task/thread_pool/worker_thread.cc:223
#25 0x00007f79a77d4a05 in ThreadFunc () at ../../base/threading/platform_thread_posix.cc:81
#26 0x00007f79ac9fe2dd in ?? ()
#27 0x00007f79aca799e8 in ?? ()
#28 0x00007f7998247ce0 in ?? ()
#29 0x0000000000000000 in ?? ()
(gdb) frame 1
#1  0x00007f79a8a3d671 in sqlite3MallocSize () at ../../third_party/sqlite/amalgamation/sqlite3.c:26957
26957     return sqlite3GlobalConfig.m.xSize(p);
</pre>
<p>Inspecting the SQLite3 code, I realised that it was somehow getting a nullptr for the <code>malloc_usable_size</code> pointer.  Further inspection revealed that this was not exactly the case:</p>
<pre>(gdb) disassemble 0x7f79a77d5520
Dump of assembler code for function malloc_usable_size():
   0x00007f79a77d5520 :     push   %rbp
   0x00007f79a77d5521 :     mov    %rsp,%rbp
   0x00007f79a77d5524 :     mov    %rdi,%rsi
   0x00007f79a77d5527 :     mov    0x484a76a(%rip),%rdi        # 0x7f79ac01fc98 
   0x00007f79a77d552e :    mov    0x28(%rdi),%rax
   0x00007f79a77d5532 :    xor    %edx,%edx
   0x00007f79a77d5534 :    pop    %rbp
   0x00007f79a77d5535 :    jmpq   *%rax
End of assembler dump.
</pre>
<p>Looking at how <a href="https://chromium.googlesource.com/chromium/src/base/+/master/allocator/allocator_shim_default_dispatch_to_glibc.cc#60">the Chromium allocator works internally</a>, the issue is that <code>RTLD_NEXT</code> won’t work on libraries loaded before libcef.  And looking at the output of <code>ldd spotify</code> revealed both libm and libdl before libcef; musl always redirects these to libc for glibc ABI compatibility.</p>
<p>Using PatchELF to remove these two <code>DT_NEEDED</code>s from the binary yielded a surprising result…</p>
<h2>Music makes the people come together</h2>
<div data-shortcode="caption" id="attachment_274"><p><img aria-describedby="caption-attachment-274" data-attachment-id="274" data-permalink="https://catfox.life/2020/07/06/live-from-adelie-streaming-spotify-on-musl/screenshot_20200706_114641/" data-orig-file="https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png" data-orig-size="1280,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Spotify on Adélie 1.0-RC1" data-image-description="" data-medium-file="https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png?w=300" data-large-file="https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png?w=676" src="https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png?w=676" alt="Spotify on Adélie Linux" srcset="https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png?w=676 676w, https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png?w=150 150w, https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png?w=300 300w, https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png?w=768 768w, https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png?w=1024 1024w, https://foxdotlife.files.wordpress.com/2020/07/screenshot_20200706_114641.png 1280w" sizes="(max-width: 676px) 100vw, 676px"></p><p id="caption-attachment-274">Spotify, playing “Rhinestone Eyes” by Gorillaz, on my Adélie laptop</p></div>
<p>It works!  All the features I tested work: Spotify Connect, which means I can control the laptop’s playback using the iOS and Apple Watch apps; radio playback; Bluetooth speaker support.</p>
<h2>Instructions</h2>
<p>You will need to download the official Spotify 64-bit DEB.  I have not tested this on a 32-bit system yet, but I see no reason it won’t work.  Once you have the DEB, extract the data.tar.xz file somewhere.  Use PatchELF on the Spotify binary as so:</p>
<pre>$ patchelf --remove-needed …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://catfox.life/2020/07/06/live-from-adelie-streaming-spotify-on-musl/">https://catfox.life/2020/07/06/live-from-adelie-streaming-spotify-on-musl/</a></em></p>]]>
            </description>
            <link>https://catfox.life/2020/07/06/live-from-adelie-streaming-spotify-on-musl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752130</guid>
            <pubDate>Mon, 06 Jul 2020 20:05:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to BGP with Bird]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752093">thread link</a>) | @Agrosis
<br/>
July 6, 2020 | http://packetfire.org/post/intro-to-bgp/ | <a href="https://web.archive.org/web/*/http://packetfire.org/post/intro-to-bgp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3 id="introduction">Introduction:</h3>
<p>Border Gateway Protocol (BGP) is one of the core technologies involved in making our internet work, allowing networks to communicate their routes among eachother. Understanding how this tool can be used to define the topology of a network will both give you a better understanding of how internetworking and allow you translate this robustness into your own network.</p>
<p>By the end of this tutorial, you will be familiar with the core concepts of BGP and have the proper vocabulary to communicate this to another network engineer. You will also be able to use a userland routing daemon, BIRD, to establish peering sessions and begin announcing routes.</p>
<p>I plan to achieve this using a virtualized docker playground which can be downloaded <a href="https://github.com/ncatelli/bird_examples_docker.git">here</a>
. In order to complete this tutorial you will need to ensure you have docker and docker-compose installed.</p>
<h3 id="setup">Setup:</h3>
<p>To begin, you will need to clone the repo of the <a href="https://github.com/ncatelli/bird_examples_docker.git">bird_examples_docker</a> project.</p>
<div><pre><code data-lang="bash">ncatelli@ofet&gt; git clone https://github.com/ncatelli/bird_examples_docker.git
ncatelli@ofet&gt; cd bird_examples_docker
ncatelli@ofet&gt; docker-compose up -d
</code></pre></div><p>This should create three containers (peer1, peer2 and peer3), all of which have BIRD installed and have peering sessions established. Don’t worry if you don’t know what this means yet, we will cover it shortly after we have our BGP playground set up and ready to go.</p>
<h3 id="login-in-to-your-playground">Login in to your playground:</h3>
<p>We will start by connecting to peer1 and checking that everything was setup correctly.</p>
<div><pre><code data-lang="bash">ncatelli@ofet&gt; docker-compose exec peer1 bash
root@peer1:/# birdc show protocols
BIRD 1.6.6 ready.
name     proto    table    state  since       info
kernel1  Kernel   master   up     02:36:03    
device1  Device   master   up     02:36:03    
direct1  Direct   master   up     02:36:03    
peer2    BGP      master   up     02:36:08    Established   
peer3    BGP      master   up     02:36:07    Established    
</code></pre></div><p>If you see that peer2 and peer3 are “Established”, everything is working as expected and we are ready to go. Before we begin playing with this playground, I will provide a brief overview of how BGP works.</p>
<h3 id="bgp-overview">BGP Overview:</h3>
<h4 id="terminology">Terminology:</h4>
<p>Border Gateway Protocol (<a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol">BGP</a>) is an exterior gateway protocol that is used to exchange routing information between autonomous systems. An autonomous system (<a href="https://en.wikipedia.org/wiki/Autonomous_system_(Internet)">AS</a>) is an organizational unit of routing prefixes and policies. These AS are identified by a unique 16-bit, and later 32-bit, autonomous system number (ASN). For example, Facebook’s ASN would be 32934 or as commonly presented AS32934. The power of BGP lies in its ability to communicate routing protocols and policies among tens of thousands of decentralized AS.</p>
<p>The internet, along with many other networks, is composed of many autonomous systems that communicate between each other. This communication is facilitated by a peering session, which allows two AS to exchange policies, routes and link status. All of this information is exchanged between two BGP daemons, which will be listening on TCP port 179.</p>
<p>While BGP is considered an exterior gateway protocol that is used for routing between large organizations on the internet, it can also be used within an AS to enable their network engineers to control the topology of their internal network. This is where the terms exterior BGP (eBGP) and interior BGP (iBGP) stem from. iBGP will be our focus for the rest of this tutorial. We will now start experimenting with these peering sessions using BIRD and its interactive command-line tool, birdc.</p>
<h3 id="introduction-to-bird">Introduction to BIRD:</h3>
<p>BIRD is a fully-functional routing daemon that supports many different routing protocols, including BGP. BIRD provides a simple configuration format and command line utility for interacting with sessions. BIRD also comes with built-in support for both IPv4 and IPv6 and the respective tools to work with both protocols.</p>
<h4 id="examining-sessions">Examining Sessions:</h4>
<p>Similiar to how we verified that our docker environment was provisioned properly, we can view running sessions by running:</p>
<div><pre><code data-lang="bash">root@peer1:/# birdc show protocols
BIRD 1.6.6 ready.
name     proto    table    state  since       info
kernel1  Kernel   master   up     02:36:02    
device1  Device   master   up     02:36:02    
direct1  Direct   master   up     02:36:02    
peer2    BGP      master   up     02:36:07    Established   
peer3    BGP      master   up     02:36:06    Established         
</code></pre></div><p>This gives us a lot of information. However, let us focus on the last two entries, peer2 and peer3. We can see that they are both BGP protocols and that the info field is Established. Each of these entries correspond to a BGP session that peer1 has open with peer2 and peer3. To demonstrate the relationship of these values to our running sessions, let’s stop the bird service on peer2. In a new terminal window run the following to stop peer2, simulating a network failure.</p>
<div><pre><code data-lang="bash">ncatelli@ofet&gt; docker-compose stop peer2
Stopping bird_examples_peer2_1 ... <span>done</span>
</code></pre></div><div><pre><code data-lang="bash">root@peer1:/# birdc show protocols
BIRD 1.6.6 ready.
name     proto    table    state  since       info
kernel1  Kernel   master   up     02:36:02    
device1  Device   master   up     02:36:02    
direct1  Direct   master   up     02:36:02    
peer2    BGP      master   start  02:43:38    Connect       Socket: Connection closed
peer3    BGP      master   up     02:36:06    Established  
</code></pre></div><p>By restarting peer2, a BIRD should restart and subsequently the peering session should be reestablished.</p>
<div><pre><code data-lang="bash">ncatelli@ofet&gt; docker-compose start peer2
Starting peer2 ... <span>done</span>
</code></pre></div><div><pre><code data-lang="bash">root@peer1:/# birdc show protocols
BIRD 1.6.6 ready.
name     proto    table    state  since       info
kernel1  Kernel   master   up     02:36:02    
device1  Device   master   up     02:36:02    
direct1  Direct   master   up     02:36:02    
peer2    BGP      master   up     02:46:29    Established   
peer3    BGP      master   up     02:36:06    Established    
</code></pre></div><p>By stopping the bird daemon on peer2, we have made the TCP connection on port 179 close between peer1 and peer2. Doing this changes our peer session from Established to Connect. Established and Connect correspond to two of many BGP states, however for the sake of this tutorial we will focus only on Established and consider all other values as not-established. For those more curious, more information on session states can be found in the <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol#Finite-state_machines">wikipedia article on BGP</a>.</p>
<h4 id="configuring-a-bgp-session">Configuring a BGP Session</h4>
<p>Although we now know how to check whether our session are up in our BGP playground, it’s also important to understand how these sessions were configured in the first place. For that, we need to dig into the bird configuration files. Let’s look at the configuration files under /etc/bird on peer1.</p>
<div><pre><code data-lang="bash">root@peer1:~# cat /etc/bird/bird.conf
router id 10.0.0.10;

protocol kernel <span>{</span>
  metric 0;
  import none;
  learn;
  export all;
<span>}</span>

protocol device <span>{</span>
<span>}</span>

protocol direct <span>{</span>
<span>}</span>

protocol bgp peer2 <span>{</span>
  local as 64512;
  neighbor 10.0.0.11 as 64513;
  import all;
  export all;
<span>}</span>

protocol bgp peer3 <span>{</span>
  local as 64512;
  neighbor 10.0.100.11 as 64514;
  import all;
  export all;
</code></pre></div><p>We can see that the configuration required to establish these initial sessions is very minimal. Let’s dig deeper into what actually makes this work. For that, we will focus on one specific block. Our protocol bgp peer2 block:</p>
<div><pre><code data-lang="bash">protocol bgp peer2 <span>{</span>
  local as 64512;
  neighbor 10.0.0.11 as 64513;
  import all;
  export none;
<span>}</span>
</code></pre></div><p>Earlier in this tutorial, we discussed the difference between eBGP and iBGP and how large AS identify themselves with a unique ASN. However, a small section of the available ASN have been reserved for private iBGP use. This range is 64512 - 65534. Knowing this, we can see that we have allocated a ASN from the private range to our peer2. This <em>local as</em> statement refers to the ASN of your local machine. In this case, peer1 is assigned the ASN 64512.</p>
<p>Looking at the next statement, we can see a neighbor statement with both an IP and an additional AS. This IP corresponds to the host, or neighbor in BGP lingo, that we are attempting to establish a session with, while the AS 64513 corresponds to the AS we’ve assigned to the host, peer2. We can confirm this by looking at the configuration file on peer2.</p>
<div><pre><code data-lang="bash">root@peer2:/# grep -A4 peer1 /etc/bird/bird.conf
protocol bgp peer1 <span>{</span>
  local as 64513;
  neighbor 10.0.0.10 as 64512;
  export none;
<span>}</span>
</code></pre></div><p>It is these two directives in our protocol BGP blocks that handle the initial establishment of sessions.</p>
<p>While establishing and maintaining sessions is crucial to the operation of BGP, established sessions alone will not allow you to route any traffic. In the next section, we will explore some of the other elements of our configuration files and how we can use them to discover and announce routes between our nodes. Before we proceed with doing this. I’d like to review our current topology.</p>
<p>Currently we have three nodes in our network, peer1 (AS64512), peer2 (AS64513) and peer3 (AS64514). These are configured in the same broadcast domain however the peering is structured like peer3 &lt;-&gt; peer1 &lt;-&gt; peer2. This structure allows communication of routes from either peer2 or peer3 through our route server, peer1. Please keep this topology in mind as we proceed with the next step of this tutorial, advertising routes.</p>
<h3 id="advertising-routes-with-bgp">Advertising Routes with BGP:</h3>
<h4 id="kernel-protocol">Kernel Protocol:</h4>
<p>Before we begin announcing routes between bird daemons, we should first understand how BIRD communicates routes between the linux kernel and the BIRD daemon. This is where that kernel protocol block we saw earlier comes into play.</p>
<pre><code>protocol kernel {
  metric 0;
  learn;
  import none;
  export all; 
}
</code></pre><p>There are many options that can be specified in the kernel block, and more information on those can be found <a href="http://bird.network.cz/?get_doc&amp;f=bird-6.html#ss6.6">here</a>, however the bulk of what we want to do is defined by the import/export definitions.</p>
<pre><code>import none;
</code></pre><p>Tells BIRD to not read routes in from the kernel routing table into BIRD. We will be obtaining our routes via the direct protocol which we will configure shortly.</p>
<pre><code>export all;
</code></pre><p>Tells BIRD to export all routes learned by other announcements into the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://packetfire.org/post/intro-to-bgp/">http://packetfire.org/post/intro-to-bgp/</a></em></p>]]>
            </description>
            <link>http://packetfire.org/post/intro-to-bgp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752093</guid>
            <pubDate>Mon, 06 Jul 2020 20:01:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A small script to prevent AdBlockers from blocking Matomo Analytics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23752077">thread link</a>) | @l1am0
<br/>
July 6, 2020 | https://byrly.com/mcab | <a href="https://web.archive.org/web/*/https://byrly.com/mcab">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="buy-form-main">
<div>
<form url="https://gumroad.com/purchases">




















<p><span title="translation missing: en.checkout">Checkout</span></p>
<h4>MCAB (Matomo circumvent AdBlock)</h4>
<p>Enter your info to complete your purchase</p>


<div data-form-state="new">



<div>
<div>
<div>

<h4>Card</h4>
<div>


<p><span></span>
<img alt="pp" src="data:image/svg+xml;base64,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">
<img alt="paypal" src="data:image/svg+xml;base64,<svg width="100" height="32" viewBox="0 0 100 32" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMinYMin meet">
    <path fill="#ffffff" d="M 67.894 6.862 L 60.094 6.862 C 59.594 6.862 59.094 7.262 58.994 7.762 L 55.894 27.662 C 55.794 28.062 56.094 28.362 56.494 28.362 L 60.494 28.362 C 60.894 28.362 61.194 28.062 61.194 27.762 L 62.094 22.062 C 62.194 21.562 62.594 21.162 63.194 21.162 L 65.694 21.162 C 70.794 21.162 73.794 18.662 74.594 13.762 C 74.894 11.662 74.594 9.962 73.594 8.762 C 72.394 7.562 70.494 6.862 67.894 6.862 Z M 68.794 14.162 C 68.394 16.962 66.194 16.962 64.194 16.962 L 62.994 16.962 L 63.794 11.762 C 63.794 11.462 64.094 11.262 64.394 11.262 L 64.894 11.262 C 66.294 11.262 67.594 11.262 68.294 12.062 C 68.794 12.462 68.894 13.162 68.794 14.162 Z"></path>
    <path fill="#ffffff" d="M 12.394 6.862 L 4.594 6.862 C 4.094 6.862 3.594 7.262 3.494 7.762 L 0.394 27.762 C 0.294 28.162 0.594 28.462 0.994 28.462 L 4.694 28.462 C 5.194 28.462 5.694 28.062 5.794 27.562 L 6.594 22.162 C 6.694 21.662 7.094 21.262 7.694 21.262 L 10.194 21.262 C 15.294 21.262 18.294 18.762 19.094 13.862 C 19.394 11.762 19.094 10.062 18.094 8.862 C 16.994 7.562 14.994 6.862 12.394 6.862 Z M 13.294 14.162 C 12.894 16.962 10.694 16.962 8.694 16.962 L 7.494 16.962 L 8.294 11.762 C 8.294 11.462 8.594 11.262 8.894 11.262 L 9.394 11.262 C 10.794 11.262 12.094 11.262 12.794 12.062 C 13.294 12.462 13.494 13.162 13.294 14.162 Z"></path>
    <path fill="#ffffff" d="M 35.594 14.062 L 31.894 14.062 C 31.594 14.062 31.294 14.262 31.294 14.562 L 31.094 15.562 L 30.794 15.162 C 29.994 13.962 28.194 13.562 26.394 13.562 C 22.294 13.562 18.794 16.662 18.094 21.062 C 17.694 23.262 18.194 25.362 19.494 26.762 C 20.594 28.062 22.294 28.662 24.194 28.662 C 27.494 28.662 29.394 26.562 29.394 26.562 L 29.194 27.562 C 29.094 27.962 29.394 28.362 29.794 28.362 L 33.194 28.362 C 33.694 28.362 34.194 27.962 34.294 27.462 L 36.294 14.662 C 36.394 14.462 35.994 14.062 35.594 14.062 Z M 30.494 21.362 C 30.094 23.462 28.494 24.962 26.294 24.962 C 25.194 24.962 24.394 24.662 23.794 23.962 C 23.194 23.262 22.994 22.362 23.194 21.362 C 23.494 19.262 25.294 17.762 27.394 17.762 C 28.494 17.762 29.294 18.162 29.894 18.762 C 30.394 19.362 30.594 20.262 30.494 21.362 Z"></path>
    <path fill="#ffffff" d="M 91.094 14.062 L 87.394 14.062 C 87.094 14.062 86.794 14.262 86.794 14.562 L 86.594 15.562 L 86.294 15.162 C 85.494 13.962 83.694 13.562 81.894 13.562 C 77.794 13.562 74.294 16.662 73.594 21.062 C 73.194 23.262 73.694 25.362 74.994 26.762 C 76.094 28.062 77.794 28.662 79.694 28.662 C 82.994 28.662 84.894 26.562 84.894 26.562 L 84.694 27.562 C 84.594 27.962 84.894 28.362 85.294 28.362 L 88.694 28.362 C 89.194 28.362 89.694 27.962 89.794 27.462 L 91.794 14.662 C 91.794 14.462 91.494 14.062 91.094 14.062 Z M 85.894 21.362 C 85.494 23.462 83.894 24.962 81.694 24.962 C 80.594 24.962 79.794 24.662 79.194 23.962 C 78.594 23.262 78.394 22.362 78.594 21.362 C 78.894 19.262 80.694 17.762 82.794 17.762 C 83.894 17.762 84.694 18.162 85.294 18.762 C 85.894 19.362 86.094 20.262 85.894 21.362 Z"></path>
    <path fill="#ffffff" d="M 55.494 14.062 L 51.794 14.062 C 51.394 14.062 51.094 14.262 50.894 14.562 L 45.694 22.162 L 43.494 14.862 C 43.394 14.362 42.894 14.062 42.494 14.062 L 38.794 14.062 C 38.394 14.062 37.994 14.462 38.194 14.962 L 42.294 27.062 L 38.394 32.462 C 38.094 32.862 38.394 33.462 38.894 33.462 L 42.594 33.462 C 42.994 33.462 43.294 33.262 43.494 32.962 L 55.994 14.962 C 56.294 14.662 55.994 14.062 55.494 14.062 Z"></path>
    <path fill="#ffffff" d="M 95.494 7.462 L 92.294 27.762 C 92.194 28.162 92.494 28.462 92.894 28.462 L 96.094 28.462 C 96.594 28.462 97.094 28.062 97.194 27.562 L 100.394 7.662 C 100.494 7.262 100.194 6.962 99.794 6.962 L 96.194 6.962 C 95.794 6.862 95.594 7.062 95.494 7.462 Z"></path>
    <path fill="#003087" d="M 12 4.917 L 4.2 4.917 C 3.7 4.917 3.2 5.317 3.1 5.817 L 0 25.817 C -0.1 26.217 0.2 26.517 0.6 26.517 L 4.3 26.517 C 4.8 26.517 5.3 26.117 5.4 25.617 L 6.2 20.217 C 6.3 19.717 6.7 19.317 7.3 19.317 L 9.8 19.317 C 14.9 19.317 17.9 16.817 18.7 11.917 C 19 9.817 18.7 8.117 17.7 6.917 C 16.6 5.617 14.6 4.917 12 4.917 Z M 12.9 12.217 C 12.5 15.017 10.3 15.017 8.3 15.017 L 7.1 15.017 L 7.9 9.817 C 7.9 9.517 8.2 9.317 8.5 9.317 L 9 9.317 C 10.4 9.317 11.7 9.317 12.4 10.117 C 12.9 10.517 13.1 11.217 12.9 12.217 Z"></path>
    <path fill="#003087" d="M 35.2 12.117 L 31.5 12.117 C 31.2 12.117 30.9 12.317 30.9 12.617 L 30.7 13.617 L 30.4 13.217 C 29.6 12.017 27.8 11.617 26 11.617 C 21.9 11.617 18.4 14.717 17.7 19.117 C 17.3 21.317 17.8 23.417 19.1 24.817 C 20.2 26.117 21.9 26.717 23.8 26.717 C 27.1 26.717 29 24.617 29 24.617 L 28.8 25.617 C 28.7 26.017 29 26.417 29.4 26.417 L 32.8 26.417 C 33.3 26.417 33.8 26.017 33.9 25.517 L 35.9 12.717 C 36 12.517 35.6 12.117 35.2 12.117 Z M 30.1 19.317 C 29.7 21.417 28.1 22.917 25.9 22.917 C 24.8 22.917 24 22.617 23.4 21.917 C 22.8 21.217 22.6 20.317 22.8 19.317 C 23.1 17.217 24.9 15.717 27 15.717 C 28.1 15.717 28.9 16.117 29.5 16.717 C 30 17.417 30.2 18.317 30.1 19.317 Z"></path>
    <path fill="#003087" d="M 55.1 12.117 L 51.4 12.117 C 51 12.117 50.7 12.317 50.5 12.617 L 45.3 20.217 L 43.1 12.917 C 43 12.417 42.5 12.117 42.1 12.117 L 38.4 12.117 C 38 12.117 37.6 12.517 37.8 13.017 L 41.9 25.117 L 38 30.517 C 37.7 30.917 38 31.517 38.5 31.517 L 42.2 31.517 C 42.6 31.517 42.9 31.317 43.1 31.017 L 55.6 13.017 C 55.9 12.717 55.6 12.117 55.1 12.117 Z"></path>
    <path fill="#009cde" d="M 67.5 4.917 L 59.7 4.917 C 59.2 4.917 58.7 5.317 58.6 5.817 L 55.5 25.717 C 55.4 26.117 55.7 26.417 56.1 26.417 L 60.1 26.417 C 60.5 26.417 60.8 26.117 60.8 25.817 L 61.7 20.117 C 61.8 19.617 62.2 19.217 62.8 19.217 L 65.3 19.217 C 70.4 19.217 73.4 16.717 74.2 11.817 C 74.5 9.717 74.2 8.017 73.2 6.817 C 72 5.617 70.1 4.917 67.5 4.917 Z M 68.4 12.217 C 68 15.017 65.8 15.017 63.8 15.017 L 62.6 15.017 L 63.4 9.817 C 63.4 9.517 63.7 9.317 64 9.317 L 64.5 9.317 C 65.9 9.317 67.2 9.317 67.9 10.117 C 68.4 10.517 68.5 11.217 68.4 12.217 Z"></path>
    <path fill="#009cde" d="M 90.7 12.117 L 87 12.117 C 86.7 12.117 86.4 12.317 86.4 12.617 L 86.2 13.617 L 85.9 13.217 C 85.1 12.017 83.3 11.617 81.5 11.617 C 77.4 11.617 73.9 14.717 73.2 19.117 C 72.8 21.317 73.3 23.417 74.6 24.817 C 75.7 26.117 77.4 26.717 79.3 26.717 C 82.6 26.717 84.5 24.617 84.5 24.617 L 84.3 25.617 C 84.2 26.017 84.5 26.417 84.9 26.417 L 88.3 26.417 C 88.8 26.417 89.3 26.017 89.4 25.517 L 91.4 12.717 C 91.4 12.517 91.1 12.117 90.7 12.117 Z M 85.5 19.317 C 85.1 21.417 83.5 22.917 81.3 22.917 C 80.2 22.917 79.4 22.617 78.8 21.917 C 78.2 21.217 78 20.317 78.2 19.317 C 78.5 17.217 80.3 15.717 82.4 15.717 C 83.5 15.717 84.3 16.117 84.9 16.717 C 85.5 17.417 85.7 18.317 85.5 19.317 Z"></path>
    <path fill="#009cde" d="M 95.1 5.417 L 91.9 25.717 C 91.8 26.117 92.1 26.417 92.5 26.417 L 95.7 26.417 C 96.2 26.417 96.7 26.017 96.8 25.517 L 100 5.617 C 100.1 5.217 99.8 4.917 99.4 4.917 L 95.8 4.917 C 95.4 4.917 95.2 5.117 95.1 5.417 Z"></path>
</svg>
">
</p>

<p>or pay with</p>
</div>
</div>
<div>
<p><span>

<label for="save_card">Keep on file</label>
</span>
<label>Card Number</label>
<span></span>
<span></span>
<span>We do not keep any of your sensitive credit card information on file with us unless you ask us to after this purchase is complete.</span></p>
</div>

<p>
<label for="full_name">Full name</label>

</p>

</div>

</div>
</div>


<p><span>Please confirm your location:</span>

</p>
<p>
You'll be charged <strong>US$4.99</strong>.
</p>



</form>
<div>


<div>
<div>

<h4>
Your purchase was successful!
</h4>
<p>We charged your card and sent you a receipt</p>
</div>
<ul></ul>


<div>
<p># Thank you for purchasing MCAB</p><p>With MCAB you now have a powerfull tool at hand that supports your marketing afforts.</p><p>If any problems with MCAB come up, do not hesitate to write me an email: <a href="mailto:simon@byrly.com" target="_blank">simon@byrly.com</a>. I will try to help with your problem within 48 hours.</p><p>Please visit <a href="https://byrly.com/mcab/afterBuy.php" target="_blank">https://byrly.com/mcab/afterBuy.php</a> for further instructions.</p>
</div>


<p>
Good news! Since you already have a Gumroad account, it's also been added to your library.
</p>


</div>
</div>


</div>


</div></div>]]>
            </description>
            <link>https://byrly.com/mcab</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752077</guid>
            <pubDate>Mon, 06 Jul 2020 20:00:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design Docs at Google]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23751965">thread link</a>) | @cramforce
<br/>
July 6, 2020 | https://www.industrialempathy.com/posts/design-docs-at-google/ | <a href="https://web.archive.org/web/*/https://www.industrialempathy.com/posts/design-docs-at-google/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>One of the key elements of Google's software engineering culture is the use of defining software designs through design docs. These are relatively informal documents that the primary author or authors of a software system or application create before they embark on the coding project. The design doc documents the high level implementation strategy and key design decisions with emphasis on the trade-offs that were considered during those decisions.</p><p>As software engineers our job is not to produce code per se, but rather to solve problems. Unstructured text, like in the form of a design doc, may be the better tool for solving problems early in a project lifecycle, as it may be more concise and easier to comprehend, and communicates the problems and solutions at a higher level than code.</p><p>Besides the original documentation of a software design, design docs fulfill the following functions in the software development lifecycle:</p><ul><li><p>Early identification of design issues when making changes is still cheap.</p></li><li><p>Achieving consensus around a design in the organization.</p></li><li><p>Ensuring consideration of cross-cutting concerns.</p></li><li><p>Scaling knowledge of senior engineers into the organization.</p></li><li><p>Form the basis of an organizational memory around design decisions.</p></li><li><p>Acts as a summary artifact in the technical portfolio of the software designer(s).</p></li></ul><h2 id="anatomy-of-a-design-doc">Anatomy of a design doc <a href="#anatomy-of-a-design-doc">#</a></h2><p>Design docs are informal documents and thus don’t follow a strict guideline for their content. Rule #1 is: Write them in whatever form makes the most sense for the particular project.</p><p>Having said that, a certain structure has established itself as really useful.</p><h3 id="context-and-scope">Context and scope <a href="#context-and-scope">#</a></h3><p>This section gives the reader a very rough overview of the landscape in which the new system is being built and what is actually being built. This isn’t a requirements doc. Keep it succinct! The goal is that readers are brought up to speed but some previous knowledge can be assumed and detailed info can be linked to. This section should be entirely focused on objective background facts.</p><h3 id="goals-and-non-goals">Goals and non-goals <a href="#goals-and-non-goals">#</a></h3><p>A short list of bullet points of what the goals of the system are, and, sometimes more importantly, what non-goals are. Note, that non-goals aren’t negated goals like “The system shouldn’t crash”, but rather things that could reasonably be goals, but are explicitly chosen not to be goals. A good example would be “ACID compliance”; when designing a database, you’d certainly want to know whether that is a goal or non-goal. And if it is a non-goal you might still select a solution that provides it, if it doesn’t introduce trade-offs that prevent achieving the goals.</p><h3 id="the-actual-design">The actual design <a href="#the-actual-design">#</a></h3><p>This section should start with an overview and then go into details.</p><p><img alt="Visualization of how to draw an owl. First picture: two circles labeled &quot;1. Draw some circles&quot;. Second picture: Picture of an own labeled &quot;2. Draw the rest of the fucking owl&quot;" decoding="async" height="488" loading="lazy" sizes="(max-width: 608px) 100vw, 608px" src="https://www.industrialempathy.com/img/remote/ZCBwPv.jpg" srcset="https://www.industrialempathy.com/img/remote/ZCBwPv-1920w.jpg 1920w, https://www.industrialempathy.com/img/remote/ZCBwPv-1280w.jpg 1280w, https://www.industrialempathy.com/img/remote/ZCBwPv-640w.jpg 640w, https://www.industrialempathy.com/img/remote/ZCBwPv-320w.jpg 320w" width="600"></p><p>The design doc is <em>the place to write down the trade-offs</em> you made in designing your software. Focus on those trade-offs to produce a useful document with long-term value. That is, given the context (facts), goals and non-goals (requirements), the design doc is the place to suggest solutions and show why a particular solution best satisfies those goals.</p><p>The point of writing a document over a more formal medium is to provide the flexibility to express the problem set at hand in an appropriate manner. Because of this, there is no explicit guidance for how to actually describe the design.</p><p>Having said that, a few best practices and repeating topics have emerged that make sense for a large percentage of design docs:</p><h4 id="system-context-diagram"><strong>System-context-diagram</strong> <a href="#system-context-diagram">#</a></h4><p>In many docs a <em><a href="https://en.wikipedia.org/wiki/System_context_diagram">system-context-diagram</a></em> can be very useful. Such a diagram shows the system as part of the larger technical landscape and allows readers to contextualize the new design given its environment that they are already familiar with.</p><p><img alt="Block diagram showing how various systems are related to each other. The actual text is just examples and not needed to be seen to understand the example." decoding="async" height="333" loading="lazy" sizes="(max-width: 608px) 100vw, 608px" src="https://www.industrialempathy.com/img/remote/2mPr0N.png" srcset="https://www.industrialempathy.com/img/remote/2mPr0N-1920w.jpg 1920w, https://www.industrialempathy.com/img/remote/2mPr0N-1280w.jpg 1280w, https://www.industrialempathy.com/img/remote/2mPr0N-640w.jpg 640w, https://www.industrialempathy.com/img/remote/2mPr0N-320w.jpg 320w" width="655"><br><em>Example of a system-context-diagram.</em></p><h4 id="apis">APIs <a href="#apis">#</a></h4><p>If the system under design exposes an API, then sketching out that API is usually a good idea. In most cases, however, one should withstand the temptation to copy-paste formal interface or data definitions into the doc as these are often verbose, contain unnecessary detail and quickly get out of date. Instead focus on the parts that are relevant to the design and its trade-offs.</p><h4 id="data-storage">Data storage <a href="#data-storage">#</a></h4><p>Systems that store data should likely discuss how and in what rough form this happens. Similar to the advice on APIs, and for the same reasons, copy-pasting complete schema definitions should be avoided. Instead focus on the parts that are relevant to the design and its trade-offs.</p><h4 id="code-and-pseudo-code">Code and pseudo-code <a href="#code-and-pseudo-code">#</a></h4><p>Design docs should rarely contain code, or pseudo-code except in situations where novel algorithms are described. As appropriate, link to prototypes that show the implementability of the design.</p><h4 id="degree-of-constraint">Degree of constraint <a href="#degree-of-constraint">#</a></h4><p>One of the primary factors that would influence the shape of a software design and hence the design doc, is the degree of constraint of the solution space.</p><p>On one end of the extreme is the “greenfield software project”, where all we know are the goals, and the solution can be whatever makes the most sense. Such a document may be wide-ranging, but it also needs to quickly define a set of rules that allow zooming in on a manageable set of solutions.</p><p>On the other end are systems where the possible solutions are very well defined, but it isn’t at all obvious how they could even be combined to achieve the goals. This may be a legacy system that is difficult to change and wasn’t designed to do what you want it to do or a library design that needs to operate within the constraints of the host programming language.</p><p>In this situation you may be able to enumerate all the things you can do relatively easily, but you need to creatively put those things together to achieve the goals. There may be multiple solutions, and none of them are really great, and hence such a document should focus on selecting the best way given all identified trade-offs.</p><h3 id="alternatives-considered">Alternatives considered <a href="#alternatives-considered">#</a></h3><p>This section lists alternative designs that would have reasonably achieved similar outcomes. The focus should be on the trade-offs that each respective design makes and how those trade-offs led to the decision to select the design that is the primary topic of the document.</p><p>While it is fine to be succinct about solution that ended up not being selected, this section is one of the most important ones as it shows very explicitly why the selected solution is the best given the project goals and how other solutions, that the reader may be wondering about, introduce trade-offs that are less desirable given the goals.</p><h3 id="cross-cutting-concerns">Cross-cutting concerns <a href="#cross-cutting-concerns">#</a></h3><p>This is where your organization can ensure that certain cross-cutting concerns such as security, privacy, and observability are always taken into consideration. These are often relatively short sections that explain how the design impacts the concern and how the concern is addressed. Teams should standardize what these concerns are in their case.</p><p>Due to their importance, Google projects are required to have a dedicated privacy design doc, and there are dedicated reviews for privacy and security. While the reviews are only required to be completed by the time a project launches, it is best practice to engage with privacy and security teams as early as possible to ensure that designs take them into account from the ground up. In case of dedicated docs for these topics, the central design doc can, of course, reference them instead of going into detail.</p><h3 id="the-length-of-a-design-doc">The length of a design doc <a href="#the-length-of-a-design-doc">#</a></h3><p>Design docs should be sufficiently detailed but short enough to actually be read by busy people. The sweet spot for a larger project seems to be around 10-20ish pages. If you get way beyond that, it might make sense to split up the problem into more manageable sub problems. It should also be noted that it is absolutely possible to write a 1-3 page “mini design doc”. This is especially helpful for incremental improvements or sub tasks in an agile project–you still do all the same steps as for a longer doc, just keep things more terse and focused on a limited problem set.</p><h2 id="when-not-to-write-a-design-doc.">When <em>not</em> to write a design doc. <a href="#when-not-to-write-a-design-doc.">#</a></h2><p>Writing design docs is overhead. The decision whether to write a design doc comes down to the core trade-off of deciding whether the benefits in organizational consensus around design, documentation, senior review, etc. outweigh the extra work of creating the doc. At the center of that decision lies whether the solution to the design problem is ambiguous–because of problem complexity or solution complexity, or both. If it is not, then there is little value in going through the process of writing a doc.</p><p>A clear indicator that a doc might not be necessary are design docs that are really <em>implementation manuals</em>. If a doc basically says “This is how we are going to implement it” without going into trade-offs, alternatives, and explaining decision making (or if the solution is so obvious as to mean there were no trade-offs), then it would probably have been a better idea to write the actual program right away.</p><p>Finally, the overhead of creating and reviewing a design doc may not be compatible with prototyping and rapid iteration. However, most software projects do have a set of <em>actually known problems</em>. Subscribing to agile methodologies is not an excuse for not taking the time to get solutions to actually known problems right. Additionally, prototyping itself may be part of the design doc creation. “I tried it out and it works” is one of the best arguments for choosing a design.</p><h2 id="the-design-doc-lifecycle">The design doc lifecycle <a href="#the-design-doc-lifecycle">#</a></h2><p>The steps in the lifecycle of a design document are:</p><ol><li>Creation and rapid iteration</li><li>Review (may be in multiple rounds)</li><li>Implementation and iteration</li><li>Maintenance and learning</li></ol><h3 id="creation-and-rapid-iteration">Creation and rapid iteration <a href="#creation-and-rapid-iteration">#</a></h3><p>You write the doc. Sometimes together with a set of co-authors.</p><p>This phase quickly evolves into a time of rapid iteration where the doc is shared with colleagues who have the most knowledge about the problem space (often belonging to the same team) and through their clarifying questions and suggestions drive the doc to a first relatively stable version.</p><p>While you certainly find engineers and even teams who prefer version control and code …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.industrialempathy.com/posts/design-docs-at-google/">https://www.industrialempathy.com/posts/design-docs-at-google/</a></em></p>]]>
            </description>
            <link>https://www.industrialempathy.com/posts/design-docs-at-google/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23751965</guid>
            <pubDate>Mon, 06 Jul 2020 19:49:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Poles abroad complain they missed out in swift presidential election]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23751740">thread link</a>) | @ericdanielski
<br/>
July 6, 2020 | https://www.politico.eu/article/poles-abroad-missed-out-presidential-election | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/poles-abroad-missed-out-presidential-election">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
							
							

							
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div><p>As Poland prepares for <a href="https://www.politico.eu/article/polish-presidential-election-heads-to-second-round-andrzej-duda/">a tight runoff</a> in the country's presidential election, some Poles living abroad complain that their vote was not counted in the first round of the contest.</p>
<p>Due to a combination of the restricted timetable for the election, following the chaotic postponement of a May 10 poll, and coronavirus restrictions in the countries where foreign voters were trying to cast their ballots, many fear the same will happen in the crucial second round.</p>
<p>Incumbent President <a href="https://www.politico.eu/article/polish-presidential-election-heads-to-second-round-andrzej-duda/" target="_blank" rel="noopener noreferrer">Andrzej Duda won 43.5 percent of the vote on Sunday</a>, while liberal Warsaw Mayor Rafał Trzaskowski, representing the Civic Platform opposition party, secured 30.46 percent of the vote. If Duda loses in the second round, it will hamper the ruling Law and Justice Party's ability to enact its nationalist platform because the president has the power to veto legislation.</p>
<p>After the May poll was canceled, the new election date was announced by the government <a href="https://www.politico.eu/article/poland-sets-a-new-presidential-election-date/">on June 3</a>, giving embassies and consulates around the world less than a month to prepare postal ballots. In several countries, including the U.S., the U.K., and Belgium, the entire vote had to be organized by mail.</p>
<p>That resulted in a series of problems with ballots sent too late; others were not stamped and so invalid; and others never reached their intended recipients.</p>
<blockquote><p><span>“I don’t really know what I can expect from the second round, but my experience with the first round is not making me optimistic” <em>— Alicja Małek, an artist and architect from Amsterdam</em></span></p></blockquote>
<p><span>In several countries, such as Peru, Bolivia and the United Arab Emirates, the local authorities did not allow voting at all due to the coronavirus risks.&nbsp;</span></p>
<p><span>Alicja Małek, a 28-year-old artist and architect from Amsterdam, received her ballot paper last Monday. She posted it back using tracked mail to the consulate in The Hague on Tuesday.&nbsp;</span></p>
<p><span>“The letter hasn’t arrived, with no indication when it will arrive,” she said, meaning that her vote was not counted in the first round. She said that many of her friends are in a similar situation, with several not having received their ballot papers at all.&nbsp;</span></p>
<p><span>“I don’t really know what I can expect from the second round, but my experience with the first round is not making me optimistic,” Małek added.</span></p>
<h3>Disappearing ballots</h3>
<p><span>The Office for Democratic Institutions and Human Rights (ODIHR) at the Organization for Security and Co-operation in Europe, an intergovernmental watchdog that monitors the election worldwide, said on Monday that the speed of the election created “legal uncertainty."&nbsp;</span></p>
<p><span>“The legislation that enabled the election to take place was adopted in haste and without adequate public debate, at odds with the commitments made by all countries of the OSCE region,” it added in a statement.</span></p>
<p><span>The ODIHR stressed they don’t have a mandate to monitor how the vote was carried out abroad but also said they'd raised the issue with Polish officials.&nbsp;</span></p>
<p><span>“There will also be a second round of elections, and should there be any problems, it should be possible to rectify things with this regard,” said </span><span>Thomas Boserup, head of ODIHR’s special election assessment mission.</span></p>
<p><span>The Political Accountability Foundation, an NGO which monitored the election in Poland, has registered 160 complaints from voters abroad since Saturday afternoon.&nbsp;&nbsp;</span></p>
<p><span>“This is a very short election cycle and consulates, despite doing their best effort, did not have enough time and manpower to properly prepare for the election, especially in the case of countries such as the U.K or Germany where postal voting was the only way of voting,” said Zosia Lutkiewicz, the NGO's vice president.&nbsp;&nbsp;</span></p>
<p><span>She added that Poles are not used to voting by mail — around 4 percent of votes came to the consulates wrongly filed, according to <a href="https://wybory.gov.pl/prezydent20200628/en/wyniki/pl?fbclid=IwAR2FpWT0OJ71mRS2iYubntUbVFGy04AyUZQe1j3E2SLi5k90srpRp6pG31g" target="_blank">the official data</a>.</span></p>
<div id="attachment_1402524"><p><img aria-describedby="caption-attachment-1402524" src="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-714x475.jpg" alt="" width="714" height="475" srcset="https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-714x475.jpg 714w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-300x200.jpg 300w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-1024x682.jpg 1024w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-768x511.jpg 768w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-1536x1022.jpg 1536w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-2048x1363.jpg 2048w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-1160x772.jpg 1160w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-380x253.jpg 380w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-171x114.jpg 171w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-90x60.jpg 90w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-104x69.jpg 104w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-200x133.jpg 200w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-391x260.jpg 391w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-54x36.jpg 54w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-1082x720.jpg 1082w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-333x222.jpg 333w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-1120x745.jpg 1120w, https://g8fip1kplyr33r3krz5b97d1-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/GettyImages-1223412189-600x399.jpg 600w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-1402524">Incumbent President Andrzej Duda won 43.5 percent of the vote, while Warsaw Mayor Rafał Trzaskowski secured 30.46 percent | Omar Marques/Getty Images</p></div>
<p>A spokesperson for the Polish Ministry of Foreign Affairs denied that the short notice for the election had prevented people from voting, adding that there had been an "unprecedented operation" to make sure foreign voters could participate.</p>
<p><span>“We haven’t registered a big scale of problems linked to delivering the ballots on time, neither with sending the ballots back by the voters,” the spokesperson said in a statement. They noted that the percentage of returned ballots was higher than in previous years: 87 percent in the U.K., 83 percent in the U.S., 92 percent in Ireland and 79 percent in France. On average, 15 percent of ballots from registered voters were not returned.&nbsp;</span></p>

<p><em>For more polling data from across Europe visit </em><a href="https://www.politico.eu/europe-poll-of-polls/"><span>POLITICO</span></a><em><a href="https://www.politico.eu/europe-poll-of-polls/"> Poll of Polls</a>.</em></p>
<p><em>This story was updated on June 30 with the final election results.</em></p>

							
							
							<!--/.story-supplement-->

						</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/poles-abroad-missed-out-presidential-election</link>
            <guid isPermaLink="false">hacker-news-small-sites-23751740</guid>
            <pubDate>Mon, 06 Jul 2020 19:27:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not use your app state as a data cache]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23751641">thread link</a>) | @warpech
<br/>
July 6, 2020 | https://www.data-provider.org/docs/motivation | <a href="https://web.archive.org/web/*/https://www.data-provider.org/docs/motivation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><span><h3>Why you should not use your app state as a data cache</h3>
<h2>The problem</h2>
<p>As a front-end developer and what some call an "architect", I've worked in very big projects, so I spent lot of time of last years trying to achieve a fully modular system in which the different front-end teams could <strong>reuse elements across many applications</strong>.</p>
<p>For simple components this is a relativelly easy job, but, when the elements are connected to data origins or to a global state <em>(what I usually call a "module")</em>, then the thing changes, but why?...</p>
<p>In most cases, despite the fact of following recommended good practices and patterns <em>(very extended thanks to great tools and libraries like <a href="https://reactjs.org/">React</a>, <a href="https://redux.js.org/">Redux</a>, <a href="https://github.com/reduxjs/reselect">Reselect</a>, etc.)</em> the elements still were not 100% reusable. Some parts of its logic remained "coupled" to an upper level, which made almost impossible that ones could work without the others in a new and completely isolated environment.</p>
<h2>The causes</h2>
<p>I realized that usually it was due to the fact that these elements were <strong>delegating part of their responsibilities to another one</strong> without even realizing it. The other element normally is at charge of making a preliminary initialization, recovering certain data and setting it into the "state" <em>(a very usual example of this is the case where the user data are retrieved during the login phase, then saved into the state, and then accessed afterwards by a lot of elements which are presupposing that the data are always there, ready to be used)</em></p>
<p><img src="https://www.data-provider.org/docs/assets/schemas/wrong-state-usage.svg" alt="Wrong state usage"></p>
<p>Most of times this is made simply because we want to optimize, save resources avoiding multiple calls to the server and unnecessary extra computations, but, following this pattern, we are <strong>making our elements completely dependant</strong>. Those elements can not be instantiated without the other ones, and they probably will require an specific load order to work properly. Which is worse, the first element is probably preparing or formatting the data in an specific way to which the rest of elements can be highly coupled. These "hidden" dependencies can easily propagate by the entire system without having notice, and, if you are not very careful, all the system becomes an indivisible and "monolithic" great piece of software. You could end working in an scenario in which hundred of invisible dependencies make almost impossible to remove, modify, or replace some elements <em>(guess which ones)</em> without tons of pain, <strong>that is the time when you can rename your project to "Domino blocks play".</strong></p>
<p>At the heart of the matter, <strong>the problem is to use the global state as a cache for the data</strong>, and, as it is "global", an orchestrator is needed to be at charge about when to retrieve the data, when to invalidate caches and retrieve the data again, etc. If there is no a clear "orchestrator", we usually delegate this responsibilities to the element that seems to be the responsible one <em>(as in the login example)</em>, but, doing this, <strong>we are making dependant all the other elements needing some portion of the same data.</strong></p>
<h2>The solution</h2>
<p>So, maybe the solution can be to <strong>make every single element responsible of requesting always the data it needs</strong> <em>(connecting always them to the providers they want to read)</em>, and doing it <strong>in the most granular way possible</strong>, requesting only the data they want, and in the format they expect <em>(using specific selectors)</em>. Then, those selectors could be reused across many elements requiring the same data.</p>
<p><img src="https://www.data-provider.org/docs/assets/schemas/data-provider-usage.svg" alt="Data Provider usage"></p>
<p>This solution simply is at charge of providing cache and memoization in order to <strong>avoid unnecesary resources comsumption</strong>, and to abstract the elements about the fact of from where are they reading the data. They don't need to know about the existance of an "API", or a "State", or "localStorage", or whatever. They simply need the data, it is the "data layer" which should be the one responsible of knowing about where the data are being retrieved or sended.</p>
<p>In this way, each element has <strong>well defined dependencies</strong>, and you can move them from one project to another <em>(or from one part of your project to another)</em> without problem. The data will be requested and processed only when necessary, and only once (until the data decides that one cache has to be cleaned, then all of the elements connected to that data are informed about, so they can request it again).</p>
<p><a href="https://www.data-provider.org/img/front-end-architecture.png"><img src="https://www.data-provider.org/docs/assets/schemas/data-provider-usage-architecture.jpg" alt="Data Provider usage example"></a></p>
<h2>Concepts</h2>
<p>As a summary, main targets of this project are:</p>
<ul>
<li>Separate global state from data cache.</li>
<li>Force elements to always request for the data they need (but avoiding a negative performance impact due to usage of an internal cache).</li>
<li>Make dependencies with the data clearly identifiable and traceable.</li>
<li>Provide selectors allowing to combine data from different data origins or other selectors, keeping the same interface and principles.</li>
<li>Inform elements when the cache of a provider is invalidated, so impacted elements can request the data again.</li>
<li>Unify the interfaces of different data origins, in order to isolate the elements about the knowledge from where the data are being retrieved.</li>
<li>Provide simple methods to handle loading and error states.</li>
</ul>
<p>I hope that, <strong>if this library does not result useful, at least these principles do, because this is the really important part of the project, more than the code itself.</strong> At the end, all patterns described here can be implemented using combinations of other tools. This project simply tries to facilitate the process.</p>
</span></p></article></div></div>]]>
            </description>
            <link>https://www.data-provider.org/docs/motivation</link>
            <guid isPermaLink="false">hacker-news-small-sites-23751641</guid>
            <pubDate>Mon, 06 Jul 2020 19:17:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Programming Concepts Not Languages]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23751483">thread link</a>) | @rdd_user
<br/>
July 6, 2020 | https://remotedevdaily.com/learn-programming-concepts-not-languages/ | <a href="https://web.archive.org/web/*/https://remotedevdaily.com/learn-programming-concepts-not-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1707"><div><div><p>A good programmer or software developer should be learning programming concepts and not languages.</p><p>Knowing many programming languages is great. However, does this alone really make you a good programmer?</p><h3>Learning Languages</h3><p>There are so many programming languages out there from Python to C++ to Rust to Go, and many many more.</p><p>Knowing different programming languages and understanding their details and quirks is great.  There is absolutely nothing wrong with that.  The more you can learn about the tools you use everyday the better.</p><p>Over the years I've used many different languages ranging from low level languages like C++, to higher level languages like Ruby.</p><p>These days, I program a lot in python and javascript, and I love experimenting with new language features and discovering cool new code snippets.</p><p>However, I realize that simply knowing these languages doesn't make me a good programmer and doesn't say a lot about my skill set.</p><h3>Learn Concepts Not Languages</h3><p>The important thing is not just to learn a language itself.  We need to remember that programming languages are tools, and many of these tools change, evolve, and sometimes even become irrelevant. The moral of the story is that you shouldn't become dependent on a certain language.</p><p>You should learn how to use a language to solve a problem. And when you do that, you will inveitably pick up new concepts.</p><p>Let's use Python as an example. You don't want to just "learn python".  You want to, for example, learn how to use python to scrape data from a website. And by doing this, you will learn a ton of new and interesting concepts like how to make http requests, how to select html elements from the dom using xpaths and css selectors, among many other concepts.</p><p>We want to learn concepts, not just languages.</p><p>Here are some other examples:</p><ul><li>Maybe you want to learn how to use C++ to build a game and learn about the inner workings of computer graphics.</li><li>Maybe you want to learn how to use SQL to design efficient tables and optomize database queries.</li><li>Maybe you want to use Javascript with Vue.js or React to learn how to create reactive web pages.</li><li>Maybe you want to use Django to build a backend application and learn about how webservers handle incoming requests.</li></ul><h3>What Makes a Developer Valuable</h3><p>Knowing the languages and frameworks that a company or project uses is certainly a plus.</p><p>However, the true value that you'll bring to any project that you end up working on is your conceptual knowledge. Companies can find any number of applicants that have experience with their stack. But finding developers who have the deep experience and conceptual knowledge needed to use these tools to build well-designed software is much harder.</p><p>Good software developers are the people that focus on learning concepts and not just languages. Languages come and go, but the core fundamentals of computer science and programming do not.</p><p>I hope you enjoyed this article.  If you did, here are some other interesting <a href="https://remotedevdaily.com/" title="interesting articles">interesting articles</a> for you to read.</p></div></div></article></div>]]>
            </description>
            <link>https://remotedevdaily.com/learn-programming-concepts-not-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23751483</guid>
            <pubDate>Mon, 06 Jul 2020 19:02:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colleges Make More Money Than God by Giving It Away]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23751254">thread link</a>) | @yoloswagins
<br/>
July 6, 2020 | https://www.conradbastable.com/essays/the-uncharity-of-college-the-big-business-nobody-understands | <a href="https://web.archive.org/web/*/https://www.conradbastable.com/essays/the-uncharity-of-college-the-big-business-nobody-understands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="canvas">

    
    

    

    

    <!-- // page image or divider -->
    
      
        
      
    

    <section id="page" role="main" data-content-field="main-content" data-collection-id="5b7dc2f9032be4fd52b63a13" data-edit-main-image="Banner">

      <!-- // CATEGORY NAV -->
      

      <div>



  <article id="article-5c2404b22b6a28a419cd6f0f" data-item-id="5c2404b22b6a28a419cd6f0f">

    <!--POST HEADER-->

    <header>
  		
      
    </header>

    <!--SPECIAL CONTENT-->

    

    <!--POST BODY-->

    <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1545947593780" id="item-5c2404b22b6a28a419cd6f0f"><div><div><div data-block-type="44" id="block-yui_3_17_2_1_1545864346754_27558"><p>Some people naively dismiss the insane increases in the Cost of Education over the last 50 years as merely Vanilla flavored <a href="http://slatestarcodex.com/2017/02/09/considerations-on-cost-disease/">Cost Disease</a>. Don’t be fooled by the marshmallow swirl — this is Rocky Road, and the <del>shit</del> chocolatey-covered almond pieces are buried deep.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1545864346754_28615"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1546041358158-KLHTOS3JS2IYNUXNPJZ9/ke17ZwdGBToddI8pDm48kBk6r04uXAC0C2HbYLJzYPNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEOEL4QleIXhcx0ssLfUL4Bznh6sbXRorllMmU1ifqAN5uG45vQwBxdpDrCGUSSl5w/rocky_road.png" data-image="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1546041358158-KLHTOS3JS2IYNUXNPJZ9/ke17ZwdGBToddI8pDm48kBk6r04uXAC0C2HbYLJzYPNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEOEL4QleIXhcx0ssLfUL4Bznh6sbXRorllMmU1ifqAN5uG45vQwBxdpDrCGUSSl5w/rocky_road.png" data-image-dimensions="350x269" data-image-focal-point="0.5,0.5" alt="rocky_road.png" data-load="false" data-image-id="5c26b80df950b760dd3ce15e" data-type="image" src="https://www.conradbastable.com/essays/rocky_road.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1545864346754_367795"><div><p>A very brief summary of what’s to come in this essay:</p><ul data-rte-list="default"><li><p>College degrees are more valuable than ever in post-industrial economies, so applicants to top-tier schools are up 240% over the last 25 years&nbsp;</p></li><li><p>Meanwhile, available spots at top-tier colleges in America have increased just 2% over the last 25 &nbsp;years</p></li><li><p><strong>Microeconomics 101: Fixed Supply + Increased Demand =</strong> <strong>Increased Price</strong></p></li><li><p>That’s the obvious part</p></li><li><p><strong>The non-obvious part is that this is intentional</strong></p></li><li><p>Because the Charity-status (<strong><em> 501(c)(3)</em></strong> ) of Colleges in America depends on more-than-half of their students being unable to afford the education (read: “receiving financial aid”)</p><ul data-rte-list="default"><li><p>Not in any legal code and statute you can find — but because the Ivy League was sued by the Department of Justice for price-fixing and beat the case by arguing that since more than half their students received “financial aid” — a lot of it — this was a charitable <strong><em>gift policy</em></strong>, not a pricing policy, thus tying together the charity-status of College and the percent of students receiving “financial aid” in a court of law…</p></li><li><p>…and <a href="https://en.wikipedia.org/wiki/Common_law" target="_blank">Common Law</a> puts tremendous weight on those court decisions, to say nothing of the political pressure that could rapidly be brought to bear on Institutions with endowments bigger than the budgets of <a href="https://en.wikipedia.org/wiki/List_of_countries_by_government_budget" target="_blank">150 countries</a> and <a href="http://fortune.com/2018/02/22/us-companies-overseas-cash-tax-cut/" target="_blank">most of the Fortune 500</a>’s cash balances, yet which pay no taxes on their investments and charge middle-class Americans double-digit percentages of family Wealth for a degree whose cost is not tax deductible for the family paying $50,000+/year in tuition</p></li><li><p>All this is excused if people believe the <strong><em>true cost</em></strong> is even greater still, and merely attending college necessitates an act of immense generosity and charity on the part of that college…</p></li></ul></li><li><p>That Charity-status protects the Investment Returns of College Endowments from Uncle Sam  &amp; the IRS</p></li><li><p>Investment Returns Compound over time, and there is no more powerful force on Earth — anyone not playing the game to maximize Compound-returns will lose to everyone who is</p><ul data-rte-list="default"><li><p> Investment Returns already generate more revenue than undergrad tuition income at: Princeton <em>(</em><a href="https://finance.princeton.edu/princeton-financial-overv/report-of-the-treasurer/audited_financial_statement_fy17.pdf" target="_blank"><em>911% more</em></a><em>), </em>Harvard <em>(</em><a href="https://finance.harvard.edu/files/fad/files/final_harvard_university_financial_report_2017.pdf" target="_blank"><em>529% more</em></a><em>), </em>Yale <em>(</em><a href="https://your.yale.edu/sites/default/files/2016-2017_yale_financial_report.pdf" target="_blank"><em>254% more</em></a><em>), </em>MIT <em>(</em><a href="https://vpf.mit.edu/sites/default/files/downloads/TreasurersReport/MITTreasurersReport2017.pdf" target="_blank"><em>118% more</em></a><em>), </em>Stanford <em>(</em><a href="https://bondholder-information.stanford.edu/pdf/SU_AnnualFinancialReport_2017.pdf" target="_blank"><em>115% more</em></a><em>), </em>Brown <em>(</em><a href="https://www.brown.edu/about/administration/president/sites/president/files/Presidents_Financial_Report_FY17.pdf" target="_blank"><em>29% more</em></a><em>), </em>Duke <em>(</em><a href="https://finance.duke.edu/resources/docs/financial_reports2016-17.pdf" target="_blank"><em>13% more</em></a><em>), </em>Dartmouth <em>(</em><a href="https://www.dartmouth.edu/~control/docs/financialrept/2017-dcfinancialstmt.pdf" target="_blank"><em>9% more</em></a><em>), </em>and U Chicago <em>(</em><a href="https://finserv.uchicago.edu/sites/finserv.uchicago.edu/files/uploads/Documents/doc/F_666275_RESTRICTED_17_TheUniversityofChicago_FS.pdf" target="_blank"><em>6% more</em></a><em>) </em></p></li><li><p>Undergrad tuition brings in just 10% - 20% of total revenue at the Ivy League / Top-10 schools not listed above. Undergrad Tuition is not more than a quarter of revenue at any of these schools.</p></li></ul></li><li><p>Thus: <strong><em>if Colleges want to keep their Investment Returns tax-free,</em></strong><em> </em><strong><em>Tuition MUST remain unaffordable for at least 50% of undergrads</em></strong></p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1545864346754_493019"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1546060782288-I3FNN1ETZ8CEE7ETTRD0/ke17ZwdGBToddI8pDm48kLHg62m3M4WYld6nN3b6PCdZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFVmm4PIWmTUiypy4zscNAMZQI_zRDDTS6BxP_0GFw61h926scO3xePJoa6uVJa9B4/endowment_growth_example.png" data-image="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1546060782288-I3FNN1ETZ8CEE7ETTRD0/ke17ZwdGBToddI8pDm48kLHg62m3M4WYld6nN3b6PCdZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFVmm4PIWmTUiypy4zscNAMZQI_zRDDTS6BxP_0GFw61h926scO3xePJoa6uVJa9B4/endowment_growth_example.png" data-image-dimensions="435x329" data-image-focal-point="0.5,0.5" alt="You think its your TUITION dollars that add $1 billion a year to this?" data-load="false" data-image-id="5c2703eeb8a0456c72b2cd52" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1546060782288-I3FNN1ETZ8CEE7ETTRD0/ke17ZwdGBToddI8pDm48kLHg62m3M4WYld6nN3b6PCdZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFVmm4PIWmTUiypy4zscNAMZQI_zRDDTS6BxP_0GFw61h926scO3xePJoa6uVJa9B4/endowment_growth_example.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>You think its your TUITION dollars that add $1 billion a year to this?</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1545864346754_493305"><div><h2>Ricardo’s Cost Disease</h2><p>The traditional formulation of <a href="https://en.wikipedia.org/wiki/Baumol%27s_cost_disease" target="_blank">Baumol’s cost disease</a> is quite simple: the cost of [SOMETHING] is not related to the direct cost of providing that [SOMETHING], but to the cost of the [MOST PRODUCTIVE OTHER THING] that could have been provided with the same resources instead.</p><p>They say there is nothing new under the sun, so naturally Baumol’s cost disease is a restatement for the modern era of a Law of economics developed by a Founding Father of the dismal science: <a href="https://en.wikipedia.org/wiki/David_Ricardo" target="_blank">David Ricardo</a>.</p><blockquote><p><strong>The </strong><a href="https://en.wikipedia.org/wiki/Law_of_rent" target="_blank"><strong>Law of Rent</strong></a><strong> states that the rent of a land site is equal to the economic advantage obtained by using the site in its most productive use…</strong></p></blockquote><p>And Adam Smith himself <a href="https://en.wikipedia.org/wiki/Law_of_rent#Description" target="_blank">wrote</a> in The Wealth of Nations:</p><blockquote><p>The rent of land, therefore, considered as the price paid for the use of the land, is naturally a monopoly price. It is not at all proportioned to what the landlord may have laid out upon the improvement of the land, or to what he can afford to take; <strong>but to what the farmer can afford to give.</strong></p></blockquote><p>In a Feudal Agrarian society, land is the major productive asset. So of course this conversation between Adam Smith and David Ricardo would be about Rent — what else would the average man spend his Wealth on?</p><p>But in 2018, we’ve got so many potential outlets for Capital — capital C — that Ricardo’s Law of Rent bleeds into every possible cost, from Infrastructure to Education to the Barbershop.</p><p>However.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1584908947495_34685"><div><h2>Lay of the Land: Education is a More Complex Flavor of Cost Disease</h2><p>Conventional wisdom says “a generation” is <a href="https://www.quora.com/How-long-is-a-generation" target="_blank">about 25 years</a>, plus or minus 5.</p><p>3 months ago, the class of 2022 began their first semester at my alma mater: MIT.&nbsp;</p><p>A Generation ago, the class of 1997 also began their first semester.</p><p>How has this small world of education changed in one Generation?</p><p><strong>Total US College Enrollment Up</strong><a href="https://www.statista.com/statistics/183995/us-college-enrollment-and-projections-in-public-and-private-institutions/" target="_blank"><strong> 39%</strong></a><strong> from 1993 to 2018</strong></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1545864346754_68321"><div><p>How many people actually applied each year? Unclear. We genuinely don’t seem to have that data — or at least Google didn’t dig it up for me yet.</p><p>Similarly, you can cut the green line off on my <a href="https://www.conradbastable.com/essays/the-bermuda-triangle-of-wealth" target="_blank">previous essay’s</a> chart around 1993…</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1545864346754_68874"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1545948742163-IP20FRKN32DO3IK05HD4/ke17ZwdGBToddI8pDm48kHHgD9_KECcEbsXQOA8J9SNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzpRPwkEpjt2dM8kXTmtVU0T6wYUJOEtmPQg7B4UB630YJ_T3UQl5FSbQIoGYUx6bQ/cost_of_tuition.png" data-image="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1545948742163-IP20FRKN32DO3IK05HD4/ke17ZwdGBToddI8pDm48kHHgD9_KECcEbsXQOA8J9SNZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzpRPwkEpjt2dM8kXTmtVU0T6wYUJOEtmPQg7B4UB630YJ_T3UQl5FSbQIoGYUx6bQ/cost_of_tuition.png" data-image-dimensions="664x400" data-image-focal-point="0.5,0.5" alt="cost_of_tuition.png" data-load="false" data-image-id="5c254e4621c67c5f35edcc06" data-type="image" src="https://www.conradbastable.com/essays/cost_of_tuition.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1545864346754_73010"><div><p>…and see that the cost of this education has increased about 300% since 1993 <em>(1,225% / 300% - 1)&nbsp;</em></p><p>And to re-include just one more chart, you can see that 1993 marks a period that began a ~20% increase in real wages for male workers with Bachelor’s Degrees&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1546122117736_41409"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1546125397855-2IBFU1GFZQEK1X9OY3L5/ke17ZwdGBToddI8pDm48kAKiNhYkfKn2tAa220nHSzVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxTCUbs4sq9QFLWetzMSZImHTL4EuA8RKMPEGkv0WM6ZWUCgZh-Ld6r2qLDszHhEsQ/wages_by_education_level.png" data-image="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1546125397855-2IBFU1GFZQEK1X9OY3L5/ke17ZwdGBToddI8pDm48kAKiNhYkfKn2tAa220nHSzVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxTCUbs4sq9QFLWetzMSZImHTL4EuA8RKMPEGkv0WM6ZWUCgZh-Ld6r2qLDszHhEsQ/wages_by_education_level.png" data-image-dimensions="679x368" data-image-focal-point="0.5,0.5" alt="wages_by_education_level.png" data-load="false" data-image-id="5c280055575d1f0c316ffa3a" data-type="image" src="https://www.conradbastable.com/essays/wages_by_education_level.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1546122117736_41696"><div><p>So over this last Generation, <strong>a Bachelor’s Degree or higher has increased real wages by <em>20% - 40%</em>, the total number of college-enrolled students has increased 39%, and the cost has increased by <em>~300%</em>.</strong></p><p>Adam Smith suggests that <strong>the cost of this education should rise according to what the middle-class can afford to give.&nbsp;</strong></p><p>I concur.</p><p>David Ricardo suggests that <strong>the cost of this education should mirror the maximum possible benefit from the education</strong>, regardless of what major was chosen and GPA achieved.&nbsp;</p><p>I concur.</p><p>Baumol’s Cost Disease suggests that <strong>the cost of this education should rise with the productivity of the rest of our economy.&nbsp;</strong></p><p>I concur. And incidentally, the Cost of Tuition chart above is not-inflation-adjusted, so if we look at nominal-GDP between 1993 and 2018 we find it increased from <a href="https://fred.stlouisfed.org/series/GDP" target="_blank">$7,247B to $20,412B</a> — or <em>182%. </em>That is to say, perhaps as much as 2/3rds of the increase in the cost of education might be driven by an increase in overall productivity over the same time period — assuming that education is well-positioned to capture a large share of that surplus production.</p><p>Which it is.</p><p>But what of the remainder?</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1584908947495_35901"><div><h2>Mens et Manus and No More Bodies</h2><p>I’m going to focus on MIT because I love the school and I was lucky enough to get in 10 years ago today. I focus here because I know it best, and I know it is the best. Which brings me to MIT’s Class of 1997, who began their undergraduate journey 25 years ago. Being the advanced institute that it is, MIT kindly uploaded the admittance stats for this class:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1545864346754_74628"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1545948959835-B83LYXWOC2NFCO7IQ29V/ke17ZwdGBToddI8pDm48kASgs9pW1yuoQVjmYjEucPBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpy13-3CDPsy60vqK0VCwRbCLFTQoq0MXrRzkl_vC4gCtvjl2Ft3jCzhJm8o-jB2SmQ/mit_class_of_1997.png" data-image="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1545948959835-B83LYXWOC2NFCO7IQ29V/ke17ZwdGBToddI8pDm48kASgs9pW1yuoQVjmYjEucPBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpy13-3CDPsy60vqK0VCwRbCLFTQoq0MXrRzkl_vC4gCtvjl2Ft3jCzhJm8o-jB2SmQ/mit_class_of_1997.png" data-image-dimensions="627x239" data-image-focal-point="0.5,0.5" alt="http://news.mit.edu/1993/class-0331" data-load="false" data-image-id="5c254f1fb8a045c5250ec23c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1545948959835-B83LYXWOC2NFCO7IQ29V/ke17ZwdGBToddI8pDm48kASgs9pW1yuoQVjmYjEucPBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpy13-3CDPsy60vqK0VCwRbCLFTQoq0MXrRzkl_vC4gCtvjl2Ft3jCzhJm8o-jB2SmQ/mit_class_of_1997.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>http://news.mit.edu/1993/class-0331</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1545864346754_78798"><div><p>Yes, you read that right.</p><p><strong>32% of applicants were accepted to MIT last Generation.</strong></p><p>Total class size: 1,100.</p><p>Step forward a Generation, and look at today’s MIT Class of 2022:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1545864346754_79358"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1545949019549-60W2Y06JU628ZMUX1C42/ke17ZwdGBToddI8pDm48kPCYoWHyJoRLCmA_OJMuahFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIjPMdG7I8CEJL10av9L9H6LByu3ZBt12qqAXXTJqaW8k/mit_class_of_2022.png" data-image="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1545949019549-60W2Y06JU628ZMUX1C42/ke17ZwdGBToddI8pDm48kPCYoWHyJoRLCmA_OJMuahFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIjPMdG7I8CEJL10av9L9H6LByu3ZBt12qqAXXTJqaW8k/mit_class_of_2022.png" data-image-dimensions="788x176" data-image-focal-point="0.5,0.5" alt="https://web.archive.org/web/20181120235014/https://mitadmissions.org/apply/process/stats/" data-load="false" data-image-id="5c254f5bb8a045c5250ec608" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5a571a7d80bd5e91de77e8e6/1545949019549-60W2Y06JU628ZMUX1C42/ke17ZwdGBToddI8pDm48kPCYoWHyJoRLCmA_OJMuahFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIjPMdG7I8CEJL10av9L9H6LByu3ZBt12qqAXXTJqaW8k/mit_class_of_2022.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1545864346754_83289"><div><p>Of those 1,464 admits, <a href="https://web.archive.org/web/20181120235018/https://mitadmissions.org/apply/process/profile/" target="_blank">1,122 of them</a> ultimately decided to make MIT their home for the next 4 years (good choice!).</p><p>Thus, <strong>the Total Applicant Pool increased 239% over this 25 year period </strong>— from 6,410 to 21,706.</p><p>Meanwhile, <strong>Class Size increased 2% over that same time period</strong>, from 1,100 to 1,122 — just 22 extra bodies.</p><p><strong>The Cost of Tuition increased 171%</strong> — excluding room &amp; board and other expenses — from <a href="http://news.mit.edu/1993/tuition-0310" target="_blank">$19,000</a> to <a href="https://web.archive.org/web/20180922222114/https://sfs.mit.edu/undergraduate-students/the-cost-of-attendance/annual-student-budget/" target="_blank">$51,520</a>.</p><p><strong>Education therefore exists at the intersection of increased productivity driving up overall costs — Vanilla Cost Disease — with massively increased competition in an ever-growing applicant pool for a fixed number of spots. My claim is that this is a feature, not a bug.</strong></p><p>Due to the way signaling, ranking, social hierarchies, and prestige work in human society, opening a brand new University does not lower the value of MIT &amp; the Ivy League schools. It actually increases their value. <em>Not</em> attending has the same signaling weight as attending, just in the other direction.&nbsp;</p><p>In a world where<em> 32% </em>of applicants are accepted to MIT, perhaps the signaling value is moderately strong. In a world where <em>93.3%</em> of applicants are <em>rejected</em>, the signaling value of being one of the lucky few goes up, not down. People tend to like people that other people like (lol) — but they tend to avoid people that other people have rejected. The impulse to avoid is stronger than the impulse to seek-out, because the downsides of social-association can be unbounded.</p><p>Why is increasing competition …</p></div></div></div></div></div></div></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.conradbastable.com/essays/the-uncharity-of-college-the-big-business-nobody-understands">https://www.conradbastable.com/essays/the-uncharity-of-college-the-big-business-nobody-understands</a></em></p>]]>
            </description>
            <link>https://www.conradbastable.com/essays/the-uncharity-of-college-the-big-business-nobody-understands</link>
            <guid isPermaLink="false">hacker-news-small-sites-23751254</guid>
            <pubDate>Mon, 06 Jul 2020 18:43:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All the Loops in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23751168">thread link</a>) | @MH15
<br/>
July 6, 2020 | https://matthall.codes/blog/loops/ | <a href="https://web.archive.org/web/*/https://matthall.codes/blog/loops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Modern JavaScript supports many different looping constructs. I often use these
different constructs for working with arrays. This is a reference, for myself
and for others, written to augment the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Loops_and_iteration">existing</a> <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/forEach">MDN</a> <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map">documentation</a>.</p>
<p>An array <code>arr</code> is defined for all the below examples. The sample code for each
looping construct performs the same behavior.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#for-statement"><code>for</code> statement</a></li>
<li><a href="#dowhile-statement"><code>do...while</code> statement</a></li>
<li><a href="#while-statement"><code>while</code> statement</a></li>
<li><a href="#forin-statement"><code>for...in</code> statement</a></li>
<li><a href="#forof-statement"><code>for...of</code> statement</a></li>
<li><a href="#map-prototype"><code>map</code> prototype</a></li>
<li><a href="#reduce-prototype"><code>reduce</code> prototype</a></li>
<li><a href="#filter-prototype"><code>filter</code> prototype</a></li>
</ul>
<h2 id="basic-loop-constructs">Basic Loop Constructs</h2>
<h3 id="for-statement"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Loops_and_iteration#for_statement"><code>for</code> statement</a></h3>
<p>This is the standard C-style loop.</p>
<pre><code>let arr = ["a","b","c","d"]
for(var i = 0; i &lt; arr.length; i++) {
    console.log(i, arr[i])
}</code></pre>
<h3 id="dowhile-statement"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Loops_and_iteration#do...while_statement"><code>do...while</code> statement</a></h3>
<p>Repeat until condition is false.</p>
<pre><code>var i = 0;
do {
    console.log(i, arr[i])
    i++
} while (i &lt; arr.length)</code></pre>
<h3 id="while-statement"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Loops_and_iteration#while_statement"><code>while</code> statement</a></h3>
<p>Repeat while condition is true.</p>
<pre><code>var i = 0
while (i &lt; arr.length) {
    console.log(i, arr[i])
    i++
}</code></pre>
<h2 id="object-loop-constructs">Object Loop Constructs</h2>
<h3 id="forin-statement"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Loops_and_iteration#for...in_statement"><code>for...in</code> statement</a></h3>
<p>Executes on the properties (indices) of an object. In JavaScript, Arrays are objects, so
this is valid.</p>
<pre><code>for(var i in arr) {
    console.log(i, arr[i])
}</code></pre>
<h3 id="forof-statement"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Loops_and_iteration#for...of_statement"><code>for...of</code> statement</a></h3>
<p>Loops over the values of iterable objects including Array, Map and Set.</p>
<pre><code>var i = 0
for(var val of arr) {
    console.log(i, val)
    i++
}</code></pre>
<p>Note that <code>for...of</code> loops the values, while <code>for...in</code> loops the properties/indices.</p>
<h2 id="functional-loop-constructs">Functional Loop Constructs</h2>
<p>Multiple functional-style prototypes exist on the Array object. Handy for
list comprehensions or for rewriting complicated loops with simpler syntax,
especially with <code>reduce</code> and <code>filter</code>. Promotes immutability.</p>
<h3 id="map-prototype"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map"><code>map</code> prototype</a></h3>
<p>Calls a callback function once for each element and returns the resulting array.
This map callback prints trivial debug information for the array.</p>
<pre><code>function callback(value, index, array) {
    console.log(index, value)
    return `value: ${value}, index: ${index}`;
}
var mappedArr = arr.map(callback)</code></pre>
<p>Does not mutate the source array.</p>
<h3 id="reduce-prototype"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/reduce"><code>reduce</code> prototype</a></h3>
<p>Calls a reducer callback to accumulate the array values into a single value.
This reducer callback joins the array with commas, similar to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/join"><code>Array.prototype.join()</code></a>.</p>
<pre><code>function reducer(accumulator, value, index, array) {
    console.log(index, value)
    return accumulator + "," + value
}
var initialValue = ""
var joined = arr.reduce(reducer, initialValue)</code></pre>
<p>Does not mutate the source array. Note that if the <code>initialValue</code> parameter is
not included in the <code>arr.reduce()</code> call, the initial value is set to <code>array[0]</code>
and that first index will be skipped in the loop.</p>
<h3 id="filter-prototype"><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/filter"><code>filter</code> prototype</a></h3>
<p>Calls a filter callback to create a filtered array from the source array. The <code>filter</code> prototype
is very useful for cleaning <em>sparse arrays</em> as illustrated below or for, of course, filtering data
based on a condition in a more readable manner than with a <code>for</code> loop.</p>
<pre><code>function filter(value, index, array) {
    console.log(index, value)
    return typeof value !== 'undefined'
}
var filtered = arr.filter(filter)</code></pre>
<p>Does not mutate the source array.</p>
<h2 id="addendum">Addendum</h2>
<p>Discuss on <a href="https://news.ycombinator.com/item?id=23751168">HN</a></p>

    </article></div>]]>
            </description>
            <link>https://matthall.codes/blog/loops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23751168</guid>
            <pubDate>Mon, 06 Jul 2020 18:37:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make Your React App a Progressive Web App – Full Tutorial with TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23751111">thread link</a>) | @fgerschau
<br/>
July 6, 2020 | https://felixgerschau.com/how-to-make-your-react-app-a-progressive-web-app-pwa/ | <a href="https://web.archive.org/web/*/https://felixgerschau.com/how-to-make-your-react-app-a-progressive-web-app-pwa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group" id="gatsby-focus-wrapper"><div><div><div><div><div><p><span>
<a href="https://felixgerschau.com/static/6d8c36bb0114ba5df37b0150c1b8e9d4/29114/pwa-tutorial-thumbnail.png" target="_blank" rel="noopener">
<span></span>
<img alt="PWA Tutorial Thumbnail" title="PWA Tutorial Thumbnail" src="https://felixgerschau.com/static/6d8c36bb0114ba5df37b0150c1b8e9d4/5a190/pwa-tutorial-thumbnail.png" srcset="https://felixgerschau.com/static/6d8c36bb0114ba5df37b0150c1b8e9d4/772e8/pwa-tutorial-thumbnail.png 200w,https://felixgerschau.com/static/6d8c36bb0114ba5df37b0150c1b8e9d4/e17e5/pwa-tutorial-thumbnail.png 400w,https://felixgerschau.com/static/6d8c36bb0114ba5df37b0150c1b8e9d4/5a190/pwa-tutorial-thumbnail.png 800w,https://felixgerschau.com/static/6d8c36bb0114ba5df37b0150c1b8e9d4/c1b63/pwa-tutorial-thumbnail.png 1200w,https://felixgerschau.com/static/6d8c36bb0114ba5df37b0150c1b8e9d4/29007/pwa-tutorial-thumbnail.png 1600w,https://felixgerschau.com/static/6d8c36bb0114ba5df37b0150c1b8e9d4/29114/pwa-tutorial-thumbnail.png 1920w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><blockquote><p>The tutorial includes <strong>setting up a Service Worker with Webpack and Workbox</strong>, making it work with <strong>TypeScript and ESLint</strong>,
adding a <strong>manifest with icons for your home and splash screen</strong>, and finally, making your PWA <strong>compatible with iOS</strong> devices.</p></blockquote><p>At the beginning of this year, I started working on a project in my company where I would transform a ReactJS application for booking events
into a Progressive Web App. When I started to look into the topic, I couldn't find a resource that explained all the things I needed to know
to get started and that would cover the entire process of converting an existing ReactJS application into a Progressive Web App at a production-ready state.</p><p>I'll first explain to you the things you need to know about Progressive Web Apps to get started and afterward, I'll walk you, step by step,
through the process of making your ReactJS app a <strong> <em>Progressive</em> Web App</strong>.</p><p>If you follow along with the tutorial and there are any open questions or you got stuck, <strong>don't hesitate to contact me</strong>. You can find my contact information at the bottom
of this page.</p><blockquote><p>If you still need to sell the people at your company on developing a Progressive Web App, check out this <a href="https://developers.google.com/web/showcase" rel="noopener noreferrer" target="_blank">link</a>,
which provides lots of case studies that show that <strong>Progressive Web Apps increase customer retention, performance, and mobile experience</strong>.</p></blockquote><h5 id="table-of-contents"><a href="#table-of-contents" aria-label="table of contents permalink"></a>Table of Contents</h5><ul><li><p><a href="#prerequisites">Prerequisites</a></p></li><li><p><a href="#tools">Tools</a></p></li><li><p><a href="#terminology">Terminology</a></p><ul><li><p><a href="#application-shell">Application Shell</a></p></li><li><p><a href="#progressive-web-app">Progressive Web App</a></p></li><li><p><a href="#service-worker">Service Worker</a></p><ul><li><a href="#lifecycle">Lifecycle</a></li><li><a href="#caching-strategies">Caching strategies</a></li></ul></li><li><p><a href="#web-app-manifest">Web App Manifest</a></p></li></ul></li><li><p><a href="#debugging">Debugging</a></p></li><li><p><a href="#tutorial">Tutorial</a></p><ul><li><p><a href="#service-worker-setup">Service Worker Setup</a></p><ul><li><a href="#webpack">Webpack</a></li><li><a href="#create-the-service-worker-file">Create the Service Worker file</a></li><li><a href="#get-it-working-with-typescript">Get it working with TypeScript</a></li><li><a href="#and-eslint">...and ESLint</a></li><li><a href="#register-the-service-worker">Register the Service Worker</a></li></ul></li><li><p><a href="#adding-a-manifest-file">Adding a manifest file</a></p></li><li><p><a href="#making-it-ios-compatible">Making it iOS compatible</a></p><ul><li><a href="#home-screen-icon">Home screen icon</a></li><li><a href="#fullscreen-mode">Fullscreen mode</a></li><li><a href="#splash-screen">Splash screen</a></li></ul></li></ul></li><li><p><a href="#conclusion">Conclusion</a></p></li></ul><undefined></undefined><h2 id="prerequisites"><a href="#prerequisites" aria-label="prerequisites permalink"></a>Prerequisites</h2><p>This tutorial is for you if...</p><ul><li>you want to get into Progressive Web Apps but <strong>don't know where to start</strong>.</li><li>you want to get a <strong>better understanding of PWAs</strong> and of the terms around them.</li><li>you want to <strong>make your React app a <em>Progressive</em> Web App</strong>.</li><li>you are using <strong>Webpack</strong> for bundling your code.</li></ul><h5 id="webpack"><a href="#webpack" aria-label="webpack permalink"></a>Webpack</h5><p>Webpack is a <em>static module bundler</em> for JavaScript that we use for bundling our React project.</p><p>Create-React-App already uses Webpack under the hood, but having your own Webpack configuration gives you more control over the Service Worker.</p><h5 id="workbox"><a href="#workbox" aria-label="workbox permalink"></a>Workbox</h5><p>Workbox is a set of libraries, developed by Google, that facilitates setting up a Progressive Web App.</p><p>We will be using their <a href="https://developers.google.com/web/tools/workbox/modules/workbox-webpack-plugin">Webpack plugins</a>
for generating a precache manifest.</p><h5 id="typescript"><a href="#typescript" aria-label="typescript permalink"></a>TypeScript</h5><p><em>TypeScript extends JavaScript by adding types to the language. TypeScript speeds up your development experience by catching errors and providing fixes before you even run your code.</em></p><h2 id="terminology"><a href="#terminology" aria-label="terminology permalink"></a>Terminology</h2><p>Before we jump right into the tutorial, I want to explain the most important terms and concepts around Progressive Web Apps. This will help you during the tutorial
to understand what we are implementing, as well as later on when fighting bugs or adding new features.
If you are already familiar with these terms you can skip this part, but I encourage you to at least skim over the headlines.</p><h3 id="application-shell"><a href="#application-shell" aria-label="application shell permalink"></a>Application Shell</h3><p>This is a term you maybe don't know yet, but as a React developer, you are most likely already familiar with the concept behind it.</p><p>The application shell describes the minimal amount of code that is required to run your application. This doesn't include any dynamic data
fetched from the API.</p><p><span>
<a href="https://felixgerschau.com/static/862105321cb147522500ec53785158ea/0734a/app-shell-example.png" target="_blank" rel="noopener">
<span></span>
<img alt="App Shell Example" title="App Shell Example" src="https://felixgerschau.com/static/862105321cb147522500ec53785158ea/5a190/app-shell-example.png" srcset="https://felixgerschau.com/static/862105321cb147522500ec53785158ea/772e8/app-shell-example.png 200w,https://felixgerschau.com/static/862105321cb147522500ec53785158ea/e17e5/app-shell-example.png 400w,https://felixgerschau.com/static/862105321cb147522500ec53785158ea/5a190/app-shell-example.png 800w,https://felixgerschau.com/static/862105321cb147522500ec53785158ea/c1b63/app-shell-example.png 1200w,https://felixgerschau.com/static/862105321cb147522500ec53785158ea/29007/app-shell-example.png 1600w,https://felixgerschau.com/static/862105321cb147522500ec53785158ea/0734a/app-shell-example.png 4266w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>Example of an app shell architecture. The events of the calendar haven't been loaded yet</p><p>In other words, as <a href="https://developers.google.com/web/fundamentals/architecture/app-shell">Addy Osmani</a>
puts it: The app shell is similar to <strong>the bundle of code that you'd publish to an app store when building a native app.</strong></p><h3 id="progressive-web-app"><a href="#progressive-web-app" aria-label="progressive web app permalink"></a>Progressive Web App</h3><p>A Progressive Web App (PWA) is an application that expands the functionality of a regular website <strong>progressively</strong> by adding features that previously
were exclusive for native applications.
Such features include <strong>offline capabilities</strong>, access through an <strong>icon on the home screen,</strong> or <strong>push notifications</strong>.</p><p>It's a web-app that looks and feels like a native app but uses web-technologies.</p><p><span>
<a href="https://felixgerschau.com/static/a023400510825bd5df664d6a648c11dc/b8765/pwa-web-comparison-google-io-2019.png" target="_blank" rel="noopener">
<span></span>
<img alt="PWA Web Comparison" title="PWA Web Comparison" src="https://felixgerschau.com/static/a023400510825bd5df664d6a648c11dc/5a190/pwa-web-comparison-google-io-2019.png" srcset="https://felixgerschau.com/static/a023400510825bd5df664d6a648c11dc/772e8/pwa-web-comparison-google-io-2019.png 200w,https://felixgerschau.com/static/a023400510825bd5df664d6a648c11dc/e17e5/pwa-web-comparison-google-io-2019.png 400w,https://felixgerschau.com/static/a023400510825bd5df664d6a648c11dc/5a190/pwa-web-comparison-google-io-2019.png 800w,https://felixgerschau.com/static/a023400510825bd5df664d6a648c11dc/c1b63/pwa-web-comparison-google-io-2019.png 1200w,https://felixgerschau.com/static/a023400510825bd5df664d6a648c11dc/29007/pwa-web-comparison-google-io-2019.png 1600w,https://felixgerschau.com/static/a023400510825bd5df664d6a648c11dc/b8765/pwa-web-comparison-google-io-2019.png 2868w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>The installation process of a PWA doesn't involve an app store. It's installed directly through the browser.</p><p>PWAs are supported both on mobile and desktop browsers. As of writing this, all major browsers offer at least basic support.
Chrome offers full support on mobile and desktop, Safari and Firefox allow PWAs to be installed only on mobile.
All major browsers offer support for Service Workers, which is the core-technology powering PWAs. Check out this article if you want to know more about
the <a href="https://medium.com/@firt/progressive-web-apps-in-2020-c15018c9931c">state of PWAs in 2020</a>.</p><p>Progressive Web Apps are a <strong>progressive enhancement</strong> of your app. This means that even though not all features are available on all platforms,
the worst case is that people will use your page as a simple website.</p><p>The two very essential features that a Progressive Web App should have is a <strong>Service Worker</strong> and a <strong>manifest</strong>
(and the equivalent meta tags on iOS for full compatibility).</p><p>We'll now have a close look at what these two things are:</p><h3 id="service-worker"><a href="#service-worker" aria-label="service worker permalink"></a>Service Worker</h3><p>Service Workers are the core-technology behind PWAs. They are an extension of Web Workers. They enable native features like an <strong>offline experience</strong>
or <strong>push notifications</strong>.</p><p>Just like Web Workers, Service Workers allow JavaScript code to be run in the background. But they have a few additional capabilities. Service Workers
don't stop when the current tab is closed, which is crucial for offering push notifications.</p><p>Another important feature is that they can intercept network requests. This is important for adding offline capabilities to our app.</p><p><span>
<a href="https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/97a96/service-worker-stale-while-revalidate.png" target="_blank" rel="noopener">
<span></span>
<img alt="Stale-While-Revalidate illustrated" title="Stale-While-Revalidate illustrated" src="https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/5a190/service-worker-stale-while-revalidate.png" srcset="https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/772e8/service-worker-stale-while-revalidate.png 200w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/e17e5/service-worker-stale-while-revalidate.png 400w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/5a190/service-worker-stale-while-revalidate.png 800w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/c1b63/service-worker-stale-while-revalidate.png 1200w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/29007/service-worker-stale-while-revalidate.png 1600w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/97a96/service-worker-stale-while-revalidate.png 2400w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>Once installed, the Service Worker will first serve requests from the cache when possible.<br>What we see here is Workbox's "Stale-While-Revalidate" caching strategy.</p><p>Let's see how this works more in detail:</p><h4 id="lifecycle"><a href="#lifecycle" aria-label="lifecycle permalink"></a>Lifecycle</h4><p>A Service Worker has different states it goes through before and after controlling your page.
The browser will compare any new Service Worker file to the old one.</p><p>If there are any changes, the new version will <em>eventually</em> control the page. By default, a new Service Worker will keep <strong>waiting
until all tabs of the browser with the website open are closed.</strong> There are a few ways you can force the Service Worker to update faster,
I explain this in another tutorial about <a href="https://felixgerschau.com/create-a-pwa-update-notification-with-create-react-app/">how to create a PWA update notification</a>.</p><p>It's important to <strong>disable caching on the Service Worker file</strong>, so new Service Worker versions can be detected immediately.
You can do so by setting the <code>max-age</code> header to 0. How to do this exactly depends on your CDN and server configuration.</p><p><span>
<a href="https://felixgerschau.com/static/342701289f46b5d0461009c87c9b5963/97a96/service-worker-lifecycle.png" target="_blank" rel="noopener">
<span></span>
<img alt="Service Worker Lifecycle" title="Service Worker Lifecycle" src="https://felixgerschau.com/static/342701289f46b5d0461009c87c9b5963/5a190/service-worker-lifecycle.png" srcset="https://felixgerschau.com/static/342701289f46b5d0461009c87c9b5963/772e8/service-worker-lifecycle.png 200w,https://felixgerschau.com/static/342701289f46b5d0461009c87c9b5963/e17e5/service-worker-lifecycle.png 400w,https://felixgerschau.com/static/342701289f46b5d0461009c87c9b5963/5a190/service-worker-lifecycle.png 800w,https://felixgerschau.com/static/342701289f46b5d0461009c87c9b5963/c1b63/service-worker-lifecycle.png 1200w,https://felixgerschau.com/static/342701289f46b5d0461009c87c9b5963/29007/service-worker-lifecycle.png 1600w,https://felixgerschau.com/static/342701289f46b5d0461009c87c9b5963/97a96/service-worker-lifecycle.png 2400w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>A Service Worker becomes redundant when it's being replaced by a new one or when installation or activation failed.</p><p>If a Service Worker is <strong>activated</strong> this means that it's controlling the page.</p><p>You can see the current state of your Service Workers in the <em>Application</em> tab of the Chrome dev-tools.</p><h4 id="caching-strategies"><a href="#caching-strategies" aria-label="caching strategies permalink"></a>Caching strategies</h4><p>The caching strategies of Service Workers define how our app is going to behave when a network is available or not.</p><p>Workbox, which is a tool we'll use for creating our PWA, offers the following caching strategies. If no caching strategy is defined,
<strong>Workbox will use the cache-first strategy by default</strong>.</p><p>I adapted the illustrations from the Workbox documentation (<a href="https://developers.google.com/web/tools/workbox/modules/workbox-strategies">here</a>).</p><h5 id="stale-while-revalidate"><a href="#stale-while-revalidate" aria-label="stale while revalidate permalink"></a>Stale-While-Revalidate</h5><p><span>
<a href="https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/97a96/service-worker-stale-while-revalidate.png" target="_blank" rel="noopener">
<span></span>
<img alt="Stale-While-Revalidate illustrated" title="Stale-While-Revalidate illustrated" src="https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/5a190/service-worker-stale-while-revalidate.png" srcset="https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/772e8/service-worker-stale-while-revalidate.png 200w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/e17e5/service-worker-stale-while-revalidate.png 400w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/5a190/service-worker-stale-while-revalidate.png 800w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/c1b63/service-worker-stale-while-revalidate.png 1200w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/29007/service-worker-stale-while-revalidate.png 1600w,https://felixgerschau.com/static/ea3a52e6e6a2866a50264843d91ed102/97a96/service-worker-stale-while-revalidate.png 2400w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>We can see that the cache is being refreshed in the background after the cache assets have been served.</p><p>The Service Worker will <strong>serve the cached assets first and update the cache</strong> with the latest version afterward.</p><h5 id="cache-first"><a href="#cache-first" aria-label="cache first permalink"></a>Cache First</h5><p><span>
<a href="https://felixgerschau.com/static/d4f0a9a43ded09e79d1087efd72c6caf/c68a4/service-worker-cache-first.png" target="_blank" rel="noopener">
<span></span>
<img alt="Cache-First illustrated" title="Cache-First illustrated" src="https://felixgerschau.com/static/d4f0a9a43ded09e79d1087efd72c6caf/5a190/service-worker-cache-first.png" srcset="https://felixgerschau.com/static/d4f0a9a43ded09e79d1087efd72c6caf/772e8/service-worker-cache-first.png 200w,https://felixgerschau.com/static/d4f0a9a43ded09e79d1087efd72c6caf/e17e5/service-worker-cache-first.png 400w,https://felixgerschau.com/static/d4f0a9a43ded09e79d1087efd72c6caf/5a190/service-worker-cache-first.png 800w,https://felixgerschau.com/static/d4f0a9a43ded09e79d1087efd72c6caf/c1b63/service-worker-cache-first.png 1200w,https://felixgerschau.com/static/d4f0a9a43ded09e79d1087efd72c6caf/29007/service-worker-cache-first.png 1600w,https://felixgerschau.com/static/d4f0a9a43ded09e79d1087efd72c6caf/c68a4/service-worker-cache-first.png 2402w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>The cache access failed and the Service Worker uses the network as a fallback.</p><p>The Service Worker will <strong>serve the cached assets</strong> and will <strong>only query the network if the cache is not available</strong>.</p><p>Note that contrary to <em>stale-while-revalidate</em> this strategy doesn't update the cache in the background.</p><h5 id="network-first"><a href="#network-first" aria-label="network first permalink"></a>Network First</h5><p><span>
<a href="https://felixgerschau.com/static/ba275d1c297c70c624a8265bc83d6fd2/97a96/service-worker-network-first.png" target="_blank" rel="noopener">
<span></span>
<img alt="Network-First illustrated" title="Network-First illustrated" src="https://felixgerschau.com/static/ba275d1c297c70c624a8265bc83d6fd2/5a190/service-worker-network-first.png" srcset="https://felixgerschau.com/static/ba275d1c297c70c624a8265bc83d6fd2/772e8/service-worker-network-first.png 200w,https://felixgerschau.com/static/ba275d1c297c70c624a8265bc83d6fd2/e17e5/service-worker-network-first.png 400w,https://felixgerschau.com/static/ba275d1c297c70c624a8265bc83d6fd2/5a190/service-worker-network-first.png 800w,https://felixgerschau.com/static/ba275d1c297c70c624a8265bc83d6fd2/c1b63/service-worker-network-first.png 1200w,https://felixgerschau.com/static/ba275d1c297c70c624a8265bc83d6fd2/29007/service-worker-network-first.png 1600w,https://felixgerschau.com/static/ba275d1c297c70c624a8265bc83d6fd2/97a96/service-worker-network-first.png 2400w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>The cache is only being served if the network request fails.</p><p>The Service Worker will <strong>only use the cache if the network request fails</strong>.</p><h5 id="network-only"><a href="#network-only" aria-label="network only permalink"></a>Network Only</h5><p><span>
<a href="https://felixgerschau.com/static/ef21d1a7a2246d07e892bfbaae1b4101/97a96/service-worker-network-only.png" target="_blank" rel="noopener">
<span></span>
<img alt="Network-Only illustrated" title="Network-Only illustrated" src="https://felixgerschau.com/static/ef21d1a7a2246d07e892bfbaae1b4101/5a190/service-worker-network-only.png" srcset="https://felixgerschau.com/static/ef21d1a7a2246d07e892bfbaae1b4101/772e8/service-worker-network-only.png 200w,https://felixgerschau.com/static/ef21d1a7a2246d07e892bfbaae1b4101/e17e5/service-worker-network-only.png 400w,https://felixgerschau.com/static/ef21d1a7a2246d07e892bfbaae1b4101/5a190/service-worker-network-only.png 800w,https://felixgerschau.com/static/ef21d1a7a2246d07e892bfbaae1b4101/c1b63/service-worker-network-only.png 1200w,https://felixgerschau.com/static/ef21d1a7a2246d07e892bfbaae1b4101/29007/service-worker-network-only.png 1600w,https://felixgerschau.com/static/ef21d1a7a2246d07e892bfbaae1b4101/97a96/service-worker-network-only.png 2400w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><p>This caching strategy can be used for requests that always need to get the latest version.</p><p>The Service Worker will <strong>always get the assets from the network</strong>.</p><p>Workbox also allows you to have a <strong>cache only</strong> strategy. Since there aren't many use-cases for this, I didn't include it
in this overview.</p><h3 id="web-app-manifest"><a href="#web-app-manifest" aria-label="web app manifest permalink"></a>Web App Manifest</h3><p>Having a Service Worker controlling your page is one important part of PWAs, but it's only half of the equation. Only installing a Service
Worker will give your site offline capabilities and the possibility to add push notifications, but it still lacks the "look and feel"
of a native application.</p><p>That's where the Web App Manifest comes into play. It's a JSON file called <code>manifest.json</code>, located at the root of your project.
With this file, you'll be able to add a <strong>splash screen, name, icons</strong>, and more to your app.</p><p>Let's have a look at what are the essential fields for a PWA:</p><ul><li><p><strong>name</strong> and <strong>short_name</strong></p><p>The short name is what will be displayed on the home screen below your icon. The full name will be used in the android splash screen.</p></li><li><p><strong>start_url</strong></p><p>The entry point of the installed app.</p></li><li><p><strong>display</strong></p><p>Possible values are <code>fullscreen</code>, <code>standalone</code>, <code>minimal-ui</code>, and <code>browser</code>.
You probably want to use <code>fullscreen</code>, which will make the URL-bar disappear.</p></li><li><p><strong>icons</strong></p><p>These will be used for the app icon and the generated splash screen.</p></li><li><p><strong>theme_color</strong></p><p>This affects how the operating system displays the application. For example, this color can be used in the task switcher.</p></li><li><p><strong>background_color</strong></p><p>This color will be shown while the application's styles are loading.</p></li></ul><p>Be aware that the manifest is <strong>not <em>fully</em> compatible with iOS right now</strong>. On iOS, you'll need to specify the equivalent <code>meta</code> or <code>link</code> tags for these fields.
I'll explain what tags you need to add in the tutorial later on.</p><h2 id="debugging"><a href="#debugging" aria-label="debugging permalink"></a>Debugging</h2><p>To see whether your page's PWA capabilities are fully working there are a few places you can check in the Chrome DevTools:</p><h5 id="manifest"><a href="#manifest" aria-label="manifest permalink"></a>Manifest</h5><p>Under <code>Application</code> -&gt; <code>Manifest</code> you can see what fields are missing or have invalid values:</p><p><span>
<a href="https://felixgerschau.com/static/56c1c63930cf76ef2e5870a8f61363e1/6976b/debugging-pwas-chrome-manifest.png" target="_blank" rel="noopener">
<span></span>
<img alt="Debugging PWAs in Google Chrome - Manifest" title="Debugging PWAs in Google Chrome - Manifest" src="https://felixgerschau.com/static/56c1c63930cf76ef2e5870a8f61363e1/5a190/debugging-pwas-chrome-manifest.png" srcset="https://felixgerschau.com/static/56c1c63930cf76ef2e5870a8f61363e1/772e8/debugging-pwas-chrome-manifest.png 200w,https://felixgerschau.com/static/56c1c63930cf76ef2e5870a8f61363e1/e17e5/debugging-pwas-chrome-manifest.png 400w,https://felixgerschau.com/static/56c1c63930cf76ef2e5870a8f61363e1/5a190/debugging-pwas-chrome-manifest.png 800w,https://felixgerschau.com/static/56c1c63930cf76ef2e5870a8f61363e1/c1b63/debugging-pwas-chrome-manifest.png 1200w,https://felixgerschau.com/static/56c1c63930cf76ef2e5870a8f61363e1/29007/debugging-pwas-chrome-manifest.png 1600w,https://felixgerschau.com/static/56c1c63930cf76ef2e5870a8f61363e1/6976b/debugging-pwas-chrome-manifest.png 2172w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
</a>
</span></p><h5 id="audit"><a href="#audit" aria-label="audit permalink"></a>Audit</h5><p>In the <em>audit</em> tab of the DevTools, you're able to generate a lighthouse report. Make sure to select the "Progressive Web App" checkbox before hitting
the <em>Generate report</em> button.</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://felixgerschau.com/how-to-make-your-react-app-a-progressive-web-app-pwa/">https://felixgerschau.com/how-to-make-your-react-app-a-progressive-web-app-pwa/</a></em></p>]]>
            </description>
            <link>https://felixgerschau.com/how-to-make-your-react-app-a-progressive-web-app-pwa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23751111</guid>
            <pubDate>Mon, 06 Jul 2020 18:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buying and Selling stocks with maximum profit]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23750763">thread link</a>) | @codingifmycraft
<br/>
July 6, 2020 | http://codingismycraft.com/index.php/2020/07/05/buying-and-selling-stocks-with-maximum-profit/ | <a href="https://web.archive.org/web/*/http://codingismycraft.com/index.php/2020/07/05/buying-and-selling-stocks-with-maximum-profit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://codingismycraft.com/index.php/2020/07/05/buying-and-selling-stocks-with-maximum-profit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23750763</guid>
            <pubDate>Mon, 06 Jul 2020 18:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collection of foreign letters used in mathematics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23750745">thread link</a>) | @R3G1R
<br/>
July 6, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23750745</guid>
            <pubDate>Mon, 06 Jul 2020 18:01:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resizing Rotated Elements]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23750338">thread link</a>) | @bpierre
<br/>
July 6, 2020 | https://shihn.ca/posts/2020/resizing-rotated-elements/ | <a href="https://web.archive.org/web/*/https://shihn.ca/posts/2020/resizing-rotated-elements/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="articleBody">
  

<p>If you have ever used a visual editor — a WYSIWYG designer or a Graphics editor, you'd expect to be able to resize and rotate the selected shape or element. These are common operations, and yet when applied together can cause a bit of an itchy head.</p>
<h2>The Problem</h2>
<p>Let's take the most common use case - a rectangle (<em>Elements on a web page have a bounding rectangle, and vectors in graphics have a rectangular bounding box</em>). We usually represent the rectangle with four numbers - the <code>x, y</code> coordinates of the top-left corner of the rectangle, and the <code>width, height</code> of the rectangle.</p>
<p>For resizing this rectangle, common practice is to add four draggable handles at the corners of the rectangle. You can also add four additional handles in the middle of each side to resize in only one direction. <strong>For simplicity, I'm going to just add one handle</strong> - handle to move the bottom right corner of the rectangle.</p>
<p>To resize, one calculates how much <code>x</code> and <code>y</code> units the user has dragged the handle. Let's call the change in the values to be <code>𝝙x</code> and <code>𝝙y</code>. The new width and height of the rectangle would be <code>width + 𝝙x</code> and <code>height + 𝝙y</code> respectively.</p>
<p>Try dragging the bottom right handle in the rectangle below to see it resize.</p>

<p>In the interactive example above, there'a top handle which can be used to rotate the rectangle. <strong>Try rotating the rectangle above and then resize it.</strong> What do you see?</p>
<p>You will notice a couple of issues:</p>
<ol>
<li>When you resize the rectangle, the shape tends to move. i.e. you are dragging the bottom-right corner, but somehow the top-left corner is also moving.</li>
<li>The second one may be a bit more subtle to notice. The distance you drag horizontally or vertically does not quite match with the change in size you perceive in the rotated shape.</li>
</ol>
<h2>What's Happening?</h2>
<p>The rectangle is rotated about its center. In the diagram below <code>A'</code> is the new location of the top-left corner <code>A</code>.</p>
<figure>
  <img alt="How a rectangle is rotated" loading="lazy" width="491" height="351" src="https://shihn.ca/stuff/posts/resizing-rotated-elements/rot1.png">
</figure>
<p>When you increase the width by <code>𝝙x</code> and height by <code>𝝙x</code> you end up moving the center of the shape. Even though you have not changed the coordinates of <code>A</code>, the coordinates of <code>A'</code> will be different.</p>
<figure>
  <img alt="Rotated rectangle with different size moved the center" loading="lazy" width="607" height="412" src="https://shihn.ca/stuff/posts/resizing-rotated-elements/rot2.png">
</figure>
<p>This accounts for the first issue. The second issue is that we are changing the <code>width</code> and <code>height</code> based on the <code>x</code> and <code>y</code> changes of the bottom-right corner. That would be totally fine when the shape has not been rotated. But for rotated shapes, one needs to calculate the width and height changes based on the angle of rotation. The diagram below represents these changes as <code>𝝙x'</code> and <code>𝝙y'</code>.</p>
<figure>
  <img alt="Estimating size change on a rotated rectangle" loading="lazy" width="466" height="395" src="https://shihn.ca/stuff/posts/resizing-rotated-elements/rot3.png">
</figure>
<h2>The Solution - Do not move A'</h2>
<p>Let's address the first issue. As we move the bottom-right corner we want to ensure that the top-left corner does not change. Which means, <strong>when we resize a rotated rectangle, we should also update its position</strong>.</p>
<p>Let's calculate the coordinates for <code>A'</code>. We can use a <a href="https://en.wikipedia.org/wiki/Rotation_matrix">rotation matrix</a> to do that. We also have to consider that the rotation does not happen around the origin of the canvas, but around the center of the rectangle.</p>
<p>First let's establish the center of the rectangle <code>cx, cy</code>:</p>
<pre><code><br><span>const</span> cx <span>=</span> rectangle<span>.</span>x <span>+</span> rectangle<span>.</span>width <span>/</span> <span>2</span><span>;</span><br><span>const</span> cy <span>=</span> rectangle<span>.</span>y <span>+</span> rectangle<span>.</span>height <span>/</span> <span>2</span><span>;</span></code></pre>
<p>Now applying the combined matrix, we can create a <code>rotate</code> function that returns the coordinates after rotation:</p>
<pre><code><span>function</span> <span>rotate</span><span>(</span><span>x<span>,</span> y<span>,</span> cx<span>,</span> cy<span>,</span> angle</span><span>)</span> <span>{</span><br>  <span>return</span> <span>[</span><br>    <span>(</span>x <span>-</span> cx<span>)</span> <span>*</span> Math<span>.</span><span>cos</span><span>(</span>angle<span>)</span> <span>-</span> <span>(</span>y <span>-</span> cy<span>)</span> <span>*</span> Math<span>.</span><span>sin</span><span>(</span>angle<span>)</span> <span>+</span> cx<span>,</span><br>    <span>(</span>x <span>-</span> cx<span>)</span> <span>*</span> Math<span>.</span><span>sin</span><span>(</span>angle<span>)</span> <span>+</span> <span>(</span>y <span>-</span> cy<span>)</span> <span>*</span> Math<span>.</span><span>cos</span><span>(</span>angle<span>)</span> <span>+</span> cy<span>,</span><br>  <span>]</span><span>;</span><br><span>}</span><br><span>const</span> rotatedA <span>=</span> <span>rotate</span><span>(</span>rectangle<span>.</span>x<span>,</span> rectangle<span>.</span>y<span>,</span> cx<span>,</span> cy<span>)</span><span>;</span> </code></pre>
<p>As we were dragging the bottom-right corner of the rectangle, we knew what the value of <code>C'</code> (<code>rotatedC</code> in the code) should be. Since we want <code>A'</code> to remain the same, we can now calculate the new center by finding the midpoint between <code>A'</code> and <code>C'</code>.</p>
<pre><code><span>const</span> newCenter <span>=</span> <span>[</span><br>  <span>(</span>rotatedA<span>[</span><span>0</span><span>]</span> <span>+</span> rotatedC<span>[</span><span>0</span><span>]</span><span>)</span> <span>/</span> <span>2</span><span>,</span><br>  <span>(</span>rotatedA<span>[</span><span>1</span><span>]</span> <span>+</span> rotatedC<span>[</span><span>1</span><span>]</span><span>)</span> <span>/</span> <span>2</span><span>,</span><br><span>]</span><span>;</span></code></pre>
<p>Now to calculate the new top-left  coordinates for the rectangle, we simply rotate <code>A'</code> around the new center by the reverse angle <code>-angle</code>.</p>
<pre><code><span>const</span> newA <span>=</span> <span>rotate</span><span>(</span>rotatedA<span>[</span><span>0</span><span>]</span><span>,</span> rotatedA<span>[</span><span>1</span><span>]</span><span>,</span> newCenter<span>[</span><span>0</span><span>]</span><span>,</span> newCenter<span>[</span><span>1</span><span>]</span><span>,</span> <span>-</span>angle<span>)</span><span>;</span></code></pre>
<p>Setting the <code>x, y</code> of the rectangle to <code>newA</code> will ensure that the rotated rectangle does not visually shift when resized.</p>
<h2>Adjusted Width And Height</h2>
<p>Now let's deal with the second issue - we need a projection of what the width and height should be when there is no rotation. The answer is to build on top of the first solution.</p>
<p>We can calculate the unrotated coordinates of the bottom-right corner <code>C</code> by rotating the new coordinates of <code>C'</code> around the new center by the reverse angle.</p>
<pre><code><span>const</span> newC <span>=</span> <span>rotate</span><span>(</span>rotatedC<span>[</span><span>0</span><span>]</span><span>,</span> rotatedC<span>[</span><span>1</span><span>]</span><span>,</span> newCenter<span>[</span><span>0</span><span>]</span><span>,</span> newCenter<span>[</span><span>1</span><span>]</span><span>,</span> <span>-</span>angle<span>)</span><span>;</span></code></pre>
<p>The width and height of the rectangle can be calculated by measuring the difference in <code>x</code> and <code>y</code> values of <code>newC</code> and <code>newA</code>.</p>
<pre><code><span>const</span> newWidth <span>=</span> newC<span>[</span><span>0</span><span>]</span> <span>-</span> newA<span>[</span><span>0</span><span>]</span><span>;</span><br><span>const</span> newHeight <span>=</span> newC<span>[</span><span>1</span><span>]</span> <span>-</span> newA<span>[</span><span>1</span><span>]</span><span>;</span></code></pre>
<h2>Putting it all together</h2>
<p>Here's the solution implemented for you to play with:</p>

<p>The code put together:</p>
<pre><code><span>function</span> <span>adjustRectangle</span><span>(</span><span>rectangle<span>,</span> bottomRightX<span>,</span> bottomRightY<span>,</span> angle</span><span>)</span> <span>{</span><br>  <span>const</span> center <span>=</span> <span>[</span><br>    rectangle<span>.</span>x <span>+</span> rectangle<span>.</span>width <span>/</span> <span>2</span><span>,</span><br>    rectangle<span>.</span>y <span>+</span> rectangle<span>.</span>height <span>/</span> <span>2</span><br>  <span>]</span><span>;</span><br>  <span>const</span> rotatedA <span>=</span> <span>rotate</span><span>(</span>rectangle<span>.</span>x<span>,</span> rectangle<span>.</span>y<span>,</span> cx<span>,</span> cy<span>)</span><span>;</span><br>  <span>const</span> newCenter <span>=</span> <span>[</span><br>    <span>(</span>rotatedA<span>[</span><span>0</span><span>]</span> <span>+</span> bottomRightX<span>)</span> <span>/</span> <span>2</span><span>,</span><br>    <span>(</span>rotatedA<span>[</span><span>1</span><span>]</span> <span>+</span> bottomRightY<span>)</span> <span>/</span> <span>2</span><span>,</span><br>  <span>]</span><span>;</span><br>  <span>const</span> newTopLeft <span>=</span> <span>rotate</span><span>(</span><br>    rotatedA<span>[</span><span>0</span><span>]</span><span>,</span><br>    rotatedA<span>[</span><span>1</span><span>]</span><span>,</span><br>    newCenter<span>[</span><span>0</span><span>]</span><span>,</span><br>    newCenter<span>[</span><span>1</span><span>]</span><span>,</span><br>    <span>-</span>angle<br>  <span>)</span><span>;</span><br>  <span>const</span> newBottomRight <span>=</span> <span>rotate</span><span>(</span><br>    bottomRightX<span>,</span><br>    bottomRightY<span>,</span><br>    newCenter<span>[</span><span>0</span><span>]</span><span>,</span><br>    newCenter<span>[</span><span>1</span><span>]</span><span>,</span><br>    <span>-</span>angle<br>  <span>)</span><span>;</span><p>  rectangle<span>.</span>x <span>=</span> newTopLeft<span>[</span><span>0</span><span>]</span><span>;</span><br>  rectangle<span>.</span>y <span>=</span> newTopLeft<span>[</span><span>1</span><span>]</span><span>;</span><br>  rectangle<span>.</span>width <span>=</span> newBottomRight<span>[</span><span>0</span><span>]</span> <span>-</span> newTopLeft<span>[</span><span>0</span><span>]</span><span>;</span><br>  rectangle<span>.</span>height <span>=</span> newBottomRight<span>[</span><span>1</span><span>]</span> <span>-</span> newTopLeft<span>[</span><span>1</span><span>]</span><span>;</span><br><span>}</span></p></code></pre>

  </div></div>]]>
            </description>
            <link>https://shihn.ca/posts/2020/resizing-rotated-elements/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23750338</guid>
            <pubDate>Mon, 06 Jul 2020 17:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[D-Bus and Polkit, No More Mysticism and Confusion]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23750162">thread link</a>) | @venamresm__
<br/>
July 6, 2020 | https://venam.nixers.net/blog/unix/2020/07/06/dbus-polkit.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/unix/2020/07/06/dbus-polkit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p><img src="https://venam.nixers.net/blog/assets/dbus_polkit/freedesktop_logo.png" alt="freedesktop logo"></p>

<p>Dbus and Polkit are two technologies that emanate an aura of
confusion. While their names are omnipresent in discussions, and the
internet has its share of criticism and rants about them, not many have
a grasp of what they actually do. In this article I’ll give an
overview of these technologies.</p>

<p>D-Bus, or Desktop Bus, is often described as a software that allows other
processes to communicate with one another, to perform inter-process
communication (IPC). However, this term is generic and doesn’t convey
what it is used for. Many technologies exist that can perform IPC, from
plain socket, to messaging queue, so what differentiates D-Bus from them.</p>

<p>D-Bus can be considered a middleware, a software glue that sits
in the middle to provide services to software through a sort
of plugin/microkernel architecture. That’s what the bus metaphor
represents, it replicates the functionality of hardware buses, with
components attaching themselves to known interfaces that they implement,
and providing a mean of communication between them. With D-Bus these can
be either procedure calls aka methods or signals aka notifications.</p>

<p>While D-Bus does offer 1-to-1 and 1-to-many IPC, it’s more of a byproduct
of its original purpose than a mean of efficient process to process data
transfer — it isn’t meant to be fast. D-Bus emerges from the world of
desktop environments where blocks are well known, and each implements a
functionality that should be accessible from other processes if needed
without having to reinvent the transfer mechanism for each and every
software.<br>
This is the problem it tackles: having components in a desktop environment
that are distributed in many processes, each fulfilling a specific job. In
such case, if a process implements the behavior needed, instead of
reimplementing it, it can instead harness the feature already provided
by that other process.</p>

<p>Its design is heavily influenced by Service Oriented Architectures
(SOA), Enterprise Service Buses (ESB), and microkernel architectures.<br>
A bus permits abstracting communication between software, replacing
all direct contact, and only allowing them to happen on the bus
instead.<br>
Additionally, the SOA allows software to expose objects that have
methods that can be called remotely, and also allows other software to
subscribe/publish events happening in remote objects residing in
other software.<br>
Moreover, D-Bus provides an easy plug-and-play, a loose coupling,
where any software could detach itself from the bus and allow another
process to be plugged, containing objects that implement the same features
the previous process implemented.<br>
In sum, it’s an abstraction layer for functionalities that could be
implemented by any software, a standardized way to create pluggable
desktop components. This is what D-Bus is about, this is the role it
plays, and it explains the difficulty in grasping the concepts that
gave rise to it.</p>

<p>The big conceptual picture goes as follows.<br>
We have a D-Bus daemon running at an address and services that implement
well known behaviors. These services attach to the D-Bus daemon and the
attachment edge has a name, a bus name.<br>
Inside these services, there are objects that implement the well known
behavior. These objects also have a path leading to them so that you
can target which object within that service implements the specific
interface needed.<br>
Then, the interface methods and events can be called or registered
on this object inside this service, connected to this bus name, from
another service that requires the behavior implemented by that interface
to be executed.</p>

<p>This is how these particular nested components interact with one another,
and it gives rise to the following:</p>

<div><div><pre><code>Address of D-Bus daemon -&gt;
Bus Name that the service attached to -&gt;
Path of the object within this service -&gt;
Interface that this object implements -&gt;
Method or Signal concrete implementation
</code></pre></div></div>

<p>Or in graphical form:</p>

<p><img src="https://venam.nixers.net/blog/assets/dbus_polkit/dbus_method_invocation.png" alt="D-Bus ecosystem"></p>

<p>Instead of having everyone talk to one another:</p>

<p><img src="https://venam.nixers.net/blog/assets/dbus_polkit/processes_without_dbus.png" alt="p2p interaction"></p>

<p>Let’s take a method call example that shows these 3 required pieces
of information.</p>

<div><div><pre><code>org.gnome.SessionManager \
/org/gnome/SessionManager \
org.gnome.SessionManager.CanShutdown

   boolean true
</code></pre></div></div>

<p>Here, we have the service bus name <code>org.gnome.SessionManager</code>, the
object path <code>/org/gnome/SessionManager</code>, and the interface/method name
<code>org.gnome.SessionManager.CanShutdown</code>, all separated by spaces. If the
<code>/org/gnome/SessionManager</code> only implements a single interface then we
could call it as such <code>CanShutdown</code>, but here it doesn’t.</p>

<p>Let’s dive deeper into the pieces we’ve mentioned. They are akin to
the ones in an SOA ecosystem, but with the addition of the bus name,
bus daemon, and the abstraction for the plug-and-play.</p>

<ul>
  <li>Objects</li>
</ul>

<p>An object is an entity that resides in a process/service and that
effectuates some work. It is identified by a path name. The path name is
usually written, though not mandatory, in a namespace format where it
is grouped and divided by slashes <code>/</code>, just like Unix file system path.</p>

<p>For example: <code>/org/gnome/Nautilus/window/1</code>.</p>

<p>Objects have methods and signals, methods take input and return output,
while signals are events that processes can subscribe to.</p>

<ul>
  <li>Interfaces</li>
</ul>

<p>These methods and signals are concrete implementations of interfaces,
the same definition as in OOP.<br>
As with OOP, interfaces are a group of abstractions that have to be
defined in the object that implements them. The members, methods and
signals, are also namespaced under this interface name.</p>

<p>Example:</p>

<div><div><pre><code>interface=org.gnome.Shell.Introspect
member method=GetRunningApplications
absolute name of method=org.gnome.Shell.Introspect.GetRunningApplications
</code></pre></div></div>

<p>Some interfaces are commonly implemented by objects, such as the
<code>org.freedesktop.Introspectable</code> interface, which, as the name implies,
makes the object introspectable. It allows to query the object about
its capabilities, features, and other interfaces it implements. This is
a very useful feature because it allows discovery.<br>
It’s also worth mentioning that dbus can be used in a generic
way to set and get properties of services’ objects through the
<code>org.freedesktop.DBus.Properties</code> interface.</p>

<p>Interfaces can be described as standard, and for documentation, in D-Bus
XML configuration files so that other programmers can use the reference
to implement them properly. These files can also be used to auto-generate
classes from the XML, making it quicker to implement and less error-prone.<br>
These files can usually be found under <code>/usr/share/dbus-1/interfaces/</code>.
Our <code>org.gnome.Shell.Introspect</code> of earlier is there in the
file <code>org.gnome.Shell.Introspect.xml</code> along with our method
<code>GetRunningApplications</code>. Here’s an excerpt of the relevant section.</p>

<div><div><pre><code>&lt;!--
	GetRunningApplications:
	@short_description: Retrieves the description of all running applications

	Each application is associated by an application ID. The details of
	each application consists of a varlist of keys and values. Available
	keys are listed below.

	'active-on-seats' - (as)   list of seats the application is active on
								(a seat only has at most one active
								application)
--&gt;
&lt;method name="GetRunningApplications"&gt;
	&lt;arg name="apps" direction="out" type="a{sa{sv}}" /&gt;
&lt;/method&gt;
</code></pre></div></div>

<p>Notice the <code>type=</code> part, which describes the format of the output,
we’ll come back to what this means in the message format section,
but in short each letter represents a basic type. The <code>out</code> direction
means that it’s the type of an output value of the method, similarly
<code>in</code> is for method parameters. See the following example taken from
<code>org.gnome.Shell.Screenshot.xml</code>.</p>

<div><div><pre><code>&lt;!--
	ScreenshotArea:
	@x: the X coordinate of the area to capture
	@y: the Y coordinate of the area to capture
	@width: the width of the area to capture
	@height: the height of the area to capture
	@flash: whether to flash the area or not
	@filename: the filename for the screenshot
	@success: whether the screenshot was captured
	@filename_used: the file where the screenshot was saved

	Takes a screenshot of the passed in area and saves it
	in @filename as png image, it returns a boolean
	indicating whether the operation was successful or not.
	@filename can either be an absolute path or a basename, in
	which case the screenshot will be saved in the $XDG_PICTURES_DIR
	or the home directory if it doesn't exist. The filename used
	to save the screenshot will be returned in @filename_used.
--&gt;
&lt;method name="ScreenshotArea"&gt;
	&lt;arg type="i" direction="in" name="x"/&gt;
	&lt;arg type="i" direction="in" name="y"/&gt;
	&lt;arg type="i" direction="in" name="width"/&gt;
	&lt;arg type="i" direction="in" name="height"/&gt;
	&lt;arg type="b" direction="in" name="flash"/&gt;
	&lt;arg type="s" direction="in" name="filename"/&gt;
	&lt;arg type="b" direction="out" name="success"/&gt;
	&lt;arg type="s" direction="out" name="filename_used"/&gt;
&lt;/method&gt;
</code></pre></div></div>

<ul>
  <li>Proxies</li>
</ul>

<p>Proxies are the nuts and bolts of an RPC ecosystem, they represent
remote objects, along with their methods, in your native code as if
they were local. Basically, these are wrappers to make it more simple
to manipulate things on D-Bus programmatically instead of worrying about
all the components we’ve mentioned above. Programming with proxies might
look like this.</p>

<div><div><pre><code>Proxy proxy = new Proxy(getBusConnection(), "/remote/object/path");
Object returnValue = proxy.MethodName(arg1, arg2);
</code></pre></div></div>

<ul>
  <li>Bus names</li>
</ul>

<p>The bus name, or also sometimes called connection name, is the name
of the connection that an application gets assigned when it connects
to D-Bus. Because D-Bus is a bus architecture, it requires that each
assigned name be unique, you can’t have two applications using the
same bus name. Usually, it is the D-Bus daemon that generates this
random unique value, one that begins with a colon by convention,
however, applications may ask to own well-known names instead. These
well-known names, as reverse domain names, are for cases when people
want to agree on a standard unique application that should implement
a certain behavior. Let’s say for instance a specification for a
<code>com.mycompany.TextEditor</code> bus name, …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/unix/2020/07/06/dbus-polkit.html">https://venam.nixers.net/blog/unix/2020/07/06/dbus-polkit.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/unix/2020/07/06/dbus-polkit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23750162</guid>
            <pubDate>Mon, 06 Jul 2020 17:22:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data migration gotchas and lessons learned]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23750038">thread link</a>) | @iamnguele
<br/>
July 6, 2020 | https://www.codingnagger.com/2020/07/06/data-migration-gotchas-and-lessons-learned/ | <a href="https://web.archive.org/web/*/https://www.codingnagger.com/2020/07/06/data-migration-gotchas-and-lessons-learned/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A fair while ago I went through a data migration project and a few days ago I chatted with one of our architects to go through the various steps and the solution that I had picked up and<br>developed further. I think he needed the information for another data migration project he’ll be on.</p><p>As I went through it with him, I brought up the various data migration gotchas and issues we ran into. I now realise these can be useful to a larger number of people working on data migration projects. I heard these were quite common, mostly for companies that start a digital transformation. A data migration project will generally be about building a solution that will allow you to extract your legacy data, to transform it and eventually load it into your new system storage.</p><p>Surprisingly, I only worked on one data migration project since I jumped in the software world twelve years ago. It feels like yesterday that I was struggling to learn SQL. This one quite interesting you revolve exclusively around using procedural SQL on both Oracle and MariaDB. You will guess for yourself which one was the legacy system and which was the new shiny target. But this is not what today is about, today is about the biggest gotchas that I believe delayed our delivery. Views are my own, facts are for everyone, yada yada yada.</p><h2>Using SQL scripts as a primary tool</h2><p>I am actually starting with one gotcha that I didn’t highlight to my colleague yesterday that came back to my mind this morning. Don’t get me wrong, SQL is a powerful tool to retrieve and display data. However, when you have a team of several developers working on a codebase, making sure your changes integrate well with others is key.</p><p>The problem is that to validate different scenarios, we couldn’t just run classic unit tests for a few seconds or a couple of minutes. We could only run the actual migration, I wouldn’t call these integration tests because the environment would be different from the actual one (more on that later).</p><p>We had to spin up docker images then load dummy data for each scenario we prepared to face with the real data. I think our Jenkins builds at one point took up to 2-3 hours to complete. This makes local development harder as nobody would want to apply changes for 5 minutes to run tests for 2-3 hours, at first we moved towards running only the tests we were interested in. That painfully <a aria-label="undefined (opens in a new tab)" href="https://www.codingnagger.com/2019/01/31/slow-ci/" target="_blank" rel="noreferrer noopener">slow CI even inspired a post of mine from last year</a>. Eventually, we got it down to 40ish minutes, still slow but probably the best we could do considering what we were dealing with.</p><p>Now, I am not speaking from experience but a couple of architects I discussed with while and even after that project told me that using an actual programming language would have saved us from that pain. There you can test any component for every bit of retrieval, transformation and load in seconds. Then have a single integration test with your happy path scenario. We could have had CI builds running in under a minute. Lots of time that could have been saved.</p><h2>Mismatching source and target fields</h2><p>Mismatches were such a big pain point. I do not mean mistakenly pushing data from a legacy field to the wrong target field. I mean pushing data exactly where it should be but the target field has the wrong type. Due to the sensitive nature of the data, there was no getting our hands on the real data while developing the solution.</p><p>These issues only exposed themselves during production runs. You can have source fields that are strings matched with target fields that were integers. When all the test data contains numbers for that field it’s okay. But when you get even a couple of entries out of millions that turn out to have letters, all hell breaks loose. Other times data would be truncated because the target database would have target fields smaller than the ones there are meant to replicate from the source system. This one is not so much a data migration issue as we were not responsible for the target system design but that actually forced us to go and fix it as we were delivering that data migration solution. So yeah, not optimal.</p><p>The takeaway here would be, if you’re building a newer version of a system, make sure that the new database fields will actually match the format and type of the source data. We can’t afford to truncate addresses or phone numbers. Especially when the system requires that information.</p><h2>Lack of boundaries with other teams</h2><p>My team focus at that time is data migration. We build a solution to move data from one place to another. However, as mentioned above, we occasionally had to fix a target database built by other teams for various features. On top of that, I’m not sure how nor why we became the test data providers for other teams. Basically, instead of putting together test data to test their features, these teams would contact us to give them random database dumps.</p><p>It is quite silly in retrospect. So we had a class in the testing framework we built that we used to generate data. Data that we pushed to the source databases while we developed, then ran through the migration process to extract, transform and load it to the target database. Then extract a data dump from that target system to send it to them. It made sense to us because we didn’t want to craft target data when it wasn’t our role. However, I believe our boundary was too liberal. We should have put the bound at “you should craft your test data” stop there.</p><p>While it is good to help people where you can, you can’t do that to the point where you can’t do your own work. In the end, we were responsible for three massive parts of that project: data migration, fixing the target database and generating test data for everyone.</p><h2>Different environment setups</h2><p>I remember that back then, I didn’t think much of different setups between the various deployed environments. From dev to staging to production there were quite a few differences, which obviously we paid a price for down the line. Having different versions of Oracle DB or MariaDB shouldn’t be a big deal right? What about when the difference between a version and the next breaks all your SQL scripts. Like having to replace <strong><em>VALUES </em></strong>to <strong><em>VALUE</em></strong>.</p><p> Imagine the pain of getting your migration tool working locally, then push it through a slow CI process. Next, you deploy it to an environment, running your migration process and checks. All this for it to break in production because the MariaDB instance in production is older. Additionally, it was set up on an EC2 instance when the one in the staging environment was an RDS.</p><p>Working on a project where all the various environments you use for development are identical to production the output difference screams at me. You avoid a host of pains due to fix your code to work with all your integration environments. There is something wrong if the environments that should prove your solution works in production are nothing like production. Definitely the biggest learning I got from that experience.</p><h2>Wrapping up</h2><p>I will carry the lessons I learned through that old project for the rest of my life. I might even revisit this post to make sure I do not forget as these will be very useful the next time I work on data migration. Better yet, some of these can apply to more than just data migrations.</p><p> Even though I did not get to pick the tool in this case, this experience enforced my belief in picking the best tool for a job. While it is good to trust the information you get, it won’t hurt to have a look and confirm yourself. Sometimes it is as quick as a SQL query.</p><p>Next, make sure that wherever possible the environments you use to develop a solution match the production environments. You will avoid a host of integration issues.</p><p>And finally, when you have clearly defined responsibilities, avoid picking up new ones that will become a liability for your core work. Sergio Ramos isn’t the best defender in the world because he scored more than Firmino this season. He is the best because he actually does his defending work first which he excels at, then occasional goes and score a goal.</p><p>Thank you for reading. Don’t hesitate to <a aria-label="undefined (opens in a new tab)" href="https://twitter.com/CodingNagger" target="_blank" rel="noreferrer noopener">follow me on Twitter @CodingNagger</a>. Feel free to come read here anytime, I even write <a aria-label="undefined (opens in a new tab)" href="https://www.codingnagger.com/category/tutorials/" target="_blank" rel="noreferrer noopener">tutorials</a> and <a aria-label="undefined (opens in a new tab)" href="https://www.codingnagger.com/category/poetry-time-bursts-poems/" target="_blank" rel="noreferrer noopener">poetry</a>.</p><p><em>Cover picture by&nbsp;<a href="https://www.pexels.com/@vishnudeep-dixit-497799?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"><strong>vishnudeep dixit</strong></a>&nbsp;from<strong>&nbsp;</strong><a href="https://www.pexels.com/photo/flock-of-birds-on-water-1646139/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"><strong>Pexels</strong></a></em></p></div></div>]]>
            </description>
            <link>https://www.codingnagger.com/2020/07/06/data-migration-gotchas-and-lessons-learned/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23750038</guid>
            <pubDate>Mon, 06 Jul 2020 17:14:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19: Just the data (World and US)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23750012">thread link</a>) | @tomger
<br/>
July 6, 2020 | https://iterator.us/covid/ | <a href="https://web.archive.org/web/*/https://iterator.us/covid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iterator.us/covid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23750012</guid>
            <pubDate>Mon, 06 Jul 2020 17:12:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In depth documentation for terms in Postgres EXPLAIN]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23750003">thread link</a>) | @michristofides
<br/>
July 6, 2020 | https://www.pgmustard.com/docs/explain | <a href="https://web.archive.org/web/*/https://www.pgmustard.com/docs/explain">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-block-type="2" id="block-e6396e1de30e0e5ec293"><div><div><p>EXPLAIN is the command used to request the execution plan for a query. It is incredibly useful when you want to explore what is going on, and see if there could be a more efficient way.</p><p>PostgreSQL does an amazing job populating query plans with useful information, but reading and understanding them can be tricky.</p></div><p>Here is a simple example:</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592835612332_8258"><div><pre><code>Query
----------
explain select * from t order by c;

Query plan
----------
 Sort  (cost=813.32..837.48 rows=9664 width=32)
   Sort Key: c
   -&gt;  Seq Scan on t  (cost=0.00..173.64 rows=9664 width=32)</code></pre></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1592835612332_10672"><div><p>This tells us that Postgres would do a <a href="https://www.pgmustard.com/docs/explain/sequential-scan"><span>sequential scan</span></a> of our table “t”, then a <a href="https://www.pgmustard.com/docs/explain/sort"><span>sort</span></a> by column “c”. The numbers tell us the <a href="https://www.pgmustard.com/docs/explain/startup-cost"><span>startup cost</span></a>, the <a href="https://www.pgmustard.com/docs/explain/total-cost"><span>total cost</span></a>, the <a href="https://www.pgmustard.com/docs/explain/plan-rows"><span>plan rows</span></a>, and the <a href="https://www.pgmustard.com/docs/explain/plan-width"><span>plan width</span></a> at each stage.</p><p>We have documented many of the operations and field definitions you’re likely to come across while using EXPLAIN, along with performance advice and links to further learning resources.</p><p>For advice in the context of your query plans, check out our product <a href="https://www.pgmustard.com/"><span>pgMustard</span></a>.</p></div></div></div></div><div data-block-type="2" id="block-a208a1b75efd07c04504"><div><p>Last updated:<em> </em>June 2020, PostgreSQL 12</p><p>Issue reports and suggestions are welcome, please <a href="https://www.pgmustard.com/contact"><span>get in touch</span></a>. </p></div></div></div></div>]]>
            </description>
            <link>https://www.pgmustard.com/docs/explain</link>
            <guid isPermaLink="false">hacker-news-small-sites-23750003</guid>
            <pubDate>Mon, 06 Jul 2020 17:11:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clean Architecture, 2 years later]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23749962">thread link</a>) | @eminetto
<br/>
July 6, 2020 | https://eltonminetto.dev/en/post/2020-07-06-clean-architecture-2years-later/ | <a href="https://web.archive.org/web/*/https://eltonminetto.dev/en/post/2020-07-06-clean-architecture-2years-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    

<p>In February 2018 I wrote what would become the most relevant text I have ever published: <a href="https://eltonminetto.dev/en/post/2018-03-05-clean-architecture-using-go/">Clean Architecture using Golang</a>. With more than 105k views, the post generated presentations at some Go and PHP events and allowed me to talk about software architecture with several people.</p>

<p>Using this architecture for the development of <a href="https://codenation.dev/">Codenation</a>’s products, we gained experience and solved problems. We wrote some posts reporting these experiences:</p>

<ul>
<li><a href="https://eltonminetto.dev/en/post/2018-06-25-golang-usando-build-tags/">Golang: using build tags to store configurations</a></li>
<li><a href="https://eltonminetto.dev/en/post/2018-08-01-monorepo-drone/">Continuous integration in projects using monorepo</a></li>
<li><a href="https://eltonminetto.dev/en/post/2018-11-28-monitorando-app-go-com-supervisor/">Monitoring a Golang application with Supervisor</a></li>
<li><a href="https://eltonminetto.dev/en/post/2019-01-23-migracao-de-dados-com-go-e-mongodb/">Data Migration with Golang and MongoDB</a></li>
<li><a href="https://eltonminetto.dev/en/post/2019-08-08-golang-linguagem-script/">Using Golang as a scripting language</a></li>
<li><a href="https://eltonminetto.dev/en/post/2019-12-19-gomock/">Creating test mocks using GoMock</a></li>
<li><a href="https://eltonminetto.dev/en/post/2020-03-13-golang-prometheus/">Using Prometheus to collect metrics from Golang applications</a></li>
<li><a href="https://eltonminetto.dev/en/post/2020-04-08-golang-pprof/">Profiling Golang applications using pprof</a></li>
<li><a href="https://eltonminetto.dev/en/post/2020-04-21-golang-apitest/">Testing APIs in Golang using apitest</a></li>
</ul>

<p>After this whole experience I can say::</p>

<blockquote>
<p>Choosing Clean Architecture was the best technical decision we made!</p>
</blockquote>

<p>With this post, I want to share a <a href="https://github.com/eminetto/clean-architecture-go-v2">repository</a> with a new example implementation in Go. It is an update with improvements in the organization of codes and directories, as well as a more complete example for those who are looking to implement this architecture.</p>

<p>In the next topics, I explain what each directory means.</p>

<h2 id="entity-layer">Entity layer</h2>

<p>Let’s start with the innermost layer of the architecture.</p>

<p>According to <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob’s post</a>:</p>

<blockquote>
<p>Entities encapsulate <em>Enterprise wide</em> business rules. An entity can be an object with methods, or it can be a set of data structures and functions. It doesn’t matter so long as the entities could be used by many different applications in the enterprise.</p>
</blockquote>

<p>The structure looked like this:</p>

<p><a href="https://eltonminetto.dev/images/posts/1-entity_book.png"><img src="https://eltonminetto.dev/images/posts/1-entity_book.png" alt="entity"></a></p>

<p>In this package, we have the definition of the entity (<code>entity.go</code>) and the interfaces of the <code>Repository</code> and <code>Manager</code> (in <code>interface.go</code>). The <code>Manager</code> will use a <code>Repository</code> to perform basic operations on the entity, such as the famous <code>CRUD</code>.</p>

<p>We also have the implementations of the repository in <code>MySQL</code> (<code>repository_mysql.go</code>) and in-memory (<code>repository_inmem.go</code>), as well as the implementation of the <code>Manager</code> interface (in <code>manager.go</code>).</p>

<p>We also found the <code>mocks</code> generated by <code>Gomock</code>, as explained in this <a href="https://eltonminetto.dev/en/post/2019-12-19-gomock/">post</a>. The other layers of the architecture will use this mocks during the tests.</p>

<h2 id="use-case-layer">Use Case Layer</h2>

<p>According to Uncle Bob::</p>

<blockquote>
<p>The software in this layer contains application specific business rules. It encapsulates and implements all of the use cases of the system</p>
</blockquote>

<p>The structure looked like this:</p>

<p><a href="https://eltonminetto.dev/images/posts/2-domain_loan.png"><img src="https://eltonminetto.dev/images/posts/2-domain_loan.png" alt="domain"></a></p>

<p>In packages within <code>domain/usecase</code> we implement the business rules for our product. According to the definition of the architecture, these <code>UseCases</code> make use of the entities and the <code>Managers</code> that deal with them. It is also possible to see the existence of mocks, as the previous layer.</p>

<h2 id="controller-layer">Controller layer</h2>

<p>In this application, there are two ways to access the <code>UseCases</code>. The first is through an <code>API</code> and the second is using a command line application (<code>CLI</code>).</p>

<p>The <code>CLI</code>’s structure is very simple:</p>

<p><a href="https://eltonminetto.dev/images/posts/4-cmd.png"><img src="https://eltonminetto.dev/images/posts/4-cmd.png" alt="cli"></a></p>

<p>It makes use of domain packages to perform a book search:</p>
<div><pre><code data-lang="go"><span>dataSourceName</span> <span>:=</span> <span>fmt</span><span>.</span><span>Sprintf</span><span>(</span><span>"%s:%s@tcp(%s:3306)/%s?parseTime=true"</span><span>,</span> <span>config</span><span>.</span><span>DB_USER</span><span>,</span> <span>config</span><span>.</span><span>DB_PASSWORD</span><span>,</span> <span>config</span><span>.</span><span>DB_HOST</span><span>,</span> <span>config</span><span>.</span><span>DB_DATABASE</span><span>)</span>
<span>db</span><span>,</span> <span>err</span> <span>:=</span> <span>sql</span><span>.</span><span>Open</span><span>(</span><span>"mysql"</span><span>,</span> <span>dataSourceName</span><span>)</span>
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
  <span>log</span><span>.</span><span>Fatal</span><span>(</span><span>err</span><span>.</span><span>Error</span><span>())</span>
<span>}</span>
<span>defer</span> <span>db</span><span>.</span><span>Close</span><span>()</span>
<span>repo</span> <span>:=</span> <span>book</span><span>.</span><span>NewMySQLRepository</span><span>(</span><span>db</span><span>)</span>
<span>manager</span> <span>:=</span> <span>book</span><span>.</span><span>NewManager</span><span>(</span><span>repo</span><span>)</span>
<span>all</span><span>,</span> <span>err</span> <span>:=</span> <span>manager</span><span>.</span><span>Search</span><span>(</span><span>query</span><span>)</span>
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
  <span>log</span><span>.</span><span>Fatal</span><span>(</span><span>err</span><span>)</span>
<span>}</span>
<span>for</span> <span>_</span><span>,</span> <span>j</span> <span>:=</span> <span>range</span> <span>all</span> <span>{</span>
  <span>fmt</span><span>.</span><span>Printf</span><span>(</span><span>"%s %s \n"</span><span>,</span> <span>j</span><span>.</span><span>Title</span><span>,</span> <span>j</span><span>.</span><span>Author</span><span>)</span>
<span>}</span></code></pre></div>
<p>In the example above, you can see the use of the <code>config</code> package. You can see its structure below, and more details in this <a href="https://eltonminetto.dev/post/2018-06-25-golang-usando-build-tags/">post</a>.</p>

<p><a href="https://eltonminetto.dev/images/posts/3-config.png"><img src="https://eltonminetto.dev/images/posts/3-config.png" alt="config"></a></p>

<p>The <code>API</code> structure is more complex, with three packages: <code>handler</code>, <code>presenter</code>, and <code>middleware</code>.</p>

<p>The <code>handler</code> package handle <code>HTTP</code> <code>requests</code> and <code>responses</code>, as well as using existing business rules in the <code>domain</code>.</p>

<p><a href="https://eltonminetto.dev/images/posts/5-handler.png"><img src="https://eltonminetto.dev/images/posts/5-handler.png" alt="handler"></a></p>

<p>The <code>presenters</code> are responsible for formatting the data generated as a <code>response</code> by <code>handlers</code>.</p>

<p><a href="https://eltonminetto.dev/images/posts/6-presenter.png"><img src="https://eltonminetto.dev/images/posts/6-presenter.png" alt="presenter"></a></p>

<p>In this way, the entity <code>User</code>:</p>
<div><pre><code data-lang="go"><span>type</span> <span>User</span> <span>struct</span> <span>{</span>
   <span>ID</span>        <span>entity</span><span>.</span><span>ID</span>
   <span>Email</span>     <span>string</span>
   <span>Password</span>  <span>string</span>
   <span>FirstName</span> <span>string</span>
   <span>LastName</span>  <span>string</span>
   <span>CreatedAt</span> <span>time</span><span>.</span><span>Time</span>
   <span>UpdatedAt</span> <span>time</span><span>.</span><span>Time</span>
   <span>Books</span>     <span>[]</span><span>entity</span><span>.</span><span>ID</span>
<span>}</span></code></pre></div>
<p>It can be transformed into:</p>
<div><pre><code data-lang="go"><span>type</span> <span>User</span> <span>struct</span> <span>{</span>
   <span>ID</span>        <span>entity</span><span>.</span><span>ID</span> <span>`json:"id"`</span>
   <span>Email</span>     <span>string</span>    <span>`json:"email"`</span>
   <span>FirstName</span> <span>string</span>    <span>`json:"first_name"`</span>
   <span>LastName</span>  <span>string</span>    <span>`json:"last_name"`</span>
<span>}</span></code></pre></div>
<p>This gives us control over how an entity will be delivered via the <code>API</code>.</p>

<p>In the last package of the <code>API</code> we find the <code>middlewares</code>, used by several <code>endpoints</code>:</p>

<p><a href="https://eltonminetto.dev/images/posts/7-middleware.png"><img src="https://eltonminetto.dev/images/posts/7-middleware.png" alt="middlware"></a></p>

<h2 id="support-packages">Support packages</h2>

<p>They are packages that provide common functionality such as encryption, logging, file handling, etc. These features are not part of the domain of our application, and all the layers can use them. Even other applications can import and use these packages.</p>

<p><a href="https://eltonminetto.dev/images/posts/8-pkg.png"><img src="https://eltonminetto.dev/images/posts/8-pkg.png" alt="pkg"></a></p>

<p>The <a href="https://github.com/eminetto/clean-architecture-go-v2">README.md</a> contains more details, such as instructions for compilation and usage examples.</p>

<p>My goals with this post to strengthen my recommendation on this architecture and also to receive feedback about the codes.</p>

<p>If you want to learn how to use this architecture in your favorite programming language, you could use this repository as an example of this learning. That way, we can have different implementations, in different languages, to ease the comparison.</p>

<p>Special thanks to my friend <a href="https://twitter.com/hurrycaner">Gustavo Schirmer</a>  who gave great feedbacks on the text and the codes.</p>


  </article></div>]]>
            </description>
            <link>https://eltonminetto.dev/en/post/2020-07-06-clean-architecture-2years-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749962</guid>
            <pubDate>Mon, 06 Jul 2020 17:08:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1:60 scale Boeing 777 made from manila folders]]>
            </title>
            <description>
<![CDATA[
Score 785 | Comments 176 (<a href="https://news.ycombinator.com/item?id=23749821">thread link</a>) | @chha
<br/>
July 6, 2020 | https://www.lucaiaconistewart.com/model-777 | <a href="https://web.archive.org/web/*/https://www.lucaiaconistewart.com/model-777">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">

      
      



      <div id="content">

        
        
          
            

  


          
        

        <main id="page" role="main">

          

          <div data-content-field="main-content">
            
            <div data-type="page" data-updated-on="1561691883296" id="page-5cef0d874437940001629f3f"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1559268252785_9085"><p><h2><em>1:60 SCALE MODEL OF AN AIR INDIA BOEING 777-300ER, MADE ENTIRELY FROM MANILA FOLDERS</em></h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1559266243734_6718"><div><p>This project traces its beginnings to an <a href="https://www.lucaiaconistewart.com/architecture"><span>architecture class</span></a> in high school where we learned to use manila file folders to roughly model our building ideas. The more I worked with paper, the more I fell in love with its versatility. At some point, I got the idea to make a model of an airplane as a way of challenging myself with an unconventional shape.</p><p>Though the project began on a much smaller and simpler scale in mid-2008, it has since evolved through multiple revisions to become a highly detailed, true-to-life representation of a Boeing 777. I originally drew my plans by hand, but my desire to increase the accuracy and amount of detail led me to start using Adobe Illustrator to design and print increasingly intricate parts directly onto the folder.</p><p><em>The project has been in progress since May 2008</em></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_11179"><div><h2>RESEARCH</h2><p>I start with as much source material as I can. Often that means photos and videos found on the web, but sometimes I’m lucky enough to get my hands on technical drawings as well. I study these materials to form an understanding of the intrinsic shape and function of the particular section I’m working on. Once I feel confident in my basic understanding of the part, I can begin the design process.</p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_13965"><div><h2>DESIGN</h2><p>Much of my work consists of figuring out how to flatten 3-D shapes into 2-D slices that can be printed onto paper and assembled. I work in Adobe Illustrator to create 2-D plans for all the parts of which the final product will be comprised. I typically start the process by working out the general shape and dimensions of the piece, then I drill down, adding more detail and functionality. Once the design has been “frozen,” I work to break it down into individual pieces and arrange them for printing. Often, if a piece is complex and I’m unsure of how well it will function in reality, I build a small test section to verify my designs.</p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_16684"><div><h2>PRINTING &amp; ASSEMBLY</h2><p>This stage is as time-consuming as the design process. I cut folders down to printer-friendly sizes and print my plans directly onto them. Then, I cut out the individual pieces using an <a href="http://www.xacto.com/products/cutting-solutions/knives/detail/X3201" target="_blank"><span>Xacto knife</span></a>, arrange them into sections, and glue them together with <a href="https://www.aleenes.com/aleenes-clear-gel-tacky-glue" target="_blank"><span>Tacky Glue</span></a>. Often, a complex piece is actually a collection of much smaller sub-sections that each needs to be assembled separately before being joined together; this is especially true of something like the wing, which contains many articulating functions and thousands of parts.</p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1561353870131_383468"><div><h2>TOOLS</h2><p>My tools of choice include the aforementioned Xacto knife, a cutting mat, straight edges, squares, and a toothpick for the precise application of glue.</p></div></div></div></div><div data-block-json="{&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;url&quot;:&quot;https://www.youtube.com/watch?v=77oRSCxGmYA&quot;,&quot;html&quot;:&quot;<iframe src=\&quot;//www.youtube.com/embed/77oRSCxGmYA?wmode=opaque&amp;amp;enablejsapi=1\&quot; height=\&quot;480\&quot; width=\&quot;854\&quot; scrolling=\&quot;no\&quot; frameborder=\&quot;0\&quot; allowfullscreen=\&quot;\&quot;>\n</iframe>&quot;,&quot;resolveObject&quot;:&quot;Video&quot;,&quot;resolvedBy&quot;:&quot;youtube&quot;,&quot;resolved&quot;:true,&quot;description&quot;:&quot;Many people have asked how I design and build the parts for the manila folder 777 I'm putting together, and this video is perhaps the best answer yet. This covers the design and build process for the main landing gear, and was made from almost 130 hours of raw footage.&quot;,&quot;title&quot;:&quot;Manila Folder 777 - Main Landing Gear - Design+Build Time-lapse with Info! **60FPS**&quot;,&quot;height&quot;:480,&quot;thumbnail_width&quot;:480,&quot;width&quot;:854,&quot;version&quot;:&quot;1.0&quot;,&quot;type&quot;:&quot;video&quot;,&quot;thumbnail_height&quot;:360,&quot;authorName&quot;:&quot;Luca Iaconi-Stewart&quot;,&quot;authorUrl&quot;:&quot;https://www.youtube.com/user/lucaiaconistewart&quot;,&quot;providerName&quot;:&quot;YouTube&quot;,&quot;providerUrl&quot;:&quot;https://www.youtube.com/&quot;,&quot;thumbnailUrl&quot;:&quot;https://i.ytimg.com/vi/77oRSCxGmYA/hqdefault.jpg&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1559834399264_13753"><div><div><p><iframe scrolling="no" data-image-dimensions="854x480" allowfullscreen="" src="//www.youtube.com/embed/77oRSCxGmYA?wmode=opaque&amp;enablejsapi=1" width="854" data-embed="true" frameborder="0" height="480">
</iframe></p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1559269142757_26027"><p><h3>CLICK BELOW FOR MORE INFO ON EACH SECTION</h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1559870775542_20405"><div><p>Check out an expansive catalog of photos and videos about the project, and stay tuned for further updates!</p></div></div></div></div></div>
          </div>

          

          

        </main>

        

      </div>
    </div></div>]]>
            </description>
            <link>https://www.lucaiaconistewart.com/model-777</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749821</guid>
            <pubDate>Mon, 06 Jul 2020 16:57:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China's Inner Mongolia region reports bubonic plague case]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23749772">thread link</a>) | @finphil
<br/>
July 6, 2020 | https://www.ctvnews.ca/health/china-s-inner-mongolia-region-reports-bubonic-plague-case-1.5012060 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/health/china-s-inner-mongolia-region-reports-bubonic-plague-case-1.5012060">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>BEIJING -- 
	While China appears to have reduced coronavirus cases to near zero, other infectious threats remain, with local health authorities announcing a suspected bubonic plague case in the Inner Mongolia Autonomous Region.</p>
<p>
	Authorities in the Bayannur district raised the plague warning on Sunday, ordered residents not to hunt wild animals such as marmots and to send for treatment anyone with fever or showing other possible signs of infection.</p>
<p>
	Plague can be fatal in up to 90% of people infected if not treated, primarily with several types of antibiotics.</p>
<p>
	Pneumonic plague can develop from bubonic plague and results in a severe lung infection causing shortness of breath, headache and coughing.</p>
<p>
	China has largely eradicated plague, but occasional cases are still reported, especially among hunters coming into contact with fleas carrying the bacterium. The last major known outbreak was in 2009, when several people died in the town of Ziketan in Qinghai province on the Tibetan Plateau.</p>
<p>
	Along with the coronavirus, first detected in the central Chinese city of Wuhan late last year, China has dealt with African swine fever, which has devastated pig herds.</p>
<p>
	China has gone weeks without reporting a new death from the coronavirus, and on Monday reported just one new case of local infection in the capital, Beijing.</p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/health/china-s-inner-mongolia-region-reports-bubonic-plague-case-1.5012060</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749772</guid>
            <pubDate>Mon, 06 Jul 2020 16:51:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semantic and Instance Segmentation on iOS Using Flask API–DeepLabV3 Mask R-CNN]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23749721">thread link</a>) | @omarmhaimdat
<br/>
July 6, 2020 | https://heartbeat.fritz.ai/semantic-and-instance-segmentation-on-ios-using-a-flask-api-deeplabv3-and-mask-r-cnn-b141213de3e7 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/semantic-and-instance-segmentation-on-ios-using-a-flask-api-deeplabv3-and-mask-r-cnn-b141213de3e7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="a3a8">Computer Vision — iOS</h2><h2 id="52ea">Build an API that performs image segmentation and consume it with an iOS application</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@omarmhaimdat?source=post_page-----b141213de3e7----------------------" rel="noopener"><img alt="Omar M’Haimdat" src="https://miro.medium.com/fit/c/96/96/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="4a30">Let say you have an image, and you want to distinguish objects of interest— or in other words, find suitable local characteristics to distinguish them from other objects or from the background. This is called <a href="https://www.fritz.ai/image-segmentation/" target="_blank" rel="noopener">image segmentation</a> or semantic segmentation. When we segment a target object, we know which pixel belongs to which object. The image is divided into regions and the discontinuities serve as borders between the regions. One can also analyze the shape of objects using various morphological operators.</p><p id="e28c">To put it simply, segmentation consists of dividing a given image into regions having homogeneity according to a predefined criterion (gray level, colors, edges, classification, etc.). The objective of segmentation is to establish a compact description representative of an image’s content. This involves extracting visual clues relevant, sufficiently correlated with the entities that make up the scene from which the image is taken.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*zzAFn5mQNjepHrFVLezZEg.png" width="3264" height="1655" srcset="https://miro.medium.com/max/552/1*zzAFn5mQNjepHrFVLezZEg.png 276w, https://miro.medium.com/max/1104/1*zzAFn5mQNjepHrFVLezZEg.png 552w, https://miro.medium.com/max/1280/1*zzAFn5mQNjepHrFVLezZEg.png 640w, https://miro.medium.com/max/1400/1*zzAFn5mQNjepHrFVLezZEg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*zzAFn5mQNjepHrFVLezZEg.png?q=20"></p></div></div></div><figcaption>Figure 1: Sleepy dog aka “Dob” — semantic segmentation using DeepLabV3 on iOS</figcaption></figure><p id="010a">For example, we know the image above contains two distinct “objects” — a dog in green and a background in red. I can then isolate and extract a portion of the image (i.e. remove the background), or I can blur a portion of the background — (i.e. <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/building-an-image-segmentation-app-in-ios-3377eb4a3e7c">portrait mode</a>).</p><p id="66f8">In this article, I’ll create an API that will process an image and produce a pixel-level segmentation mask using instance and semantic segmentation. Then, I’ll create an iOS application that will consume the API.</p><h2 id="0e44">Overview:</h2><ol><li id="858b">Why segmentation?</li><li id="0f41">Create the Flask API</li><li id="db1e">Create the iOS application</li><li id="1041">Handle the API callbacks in the iOS application</li><li id="1537">Test and evaluate</li><li id="4ae2">Conclusion</li></ol><p id="a4fc">I have included code in this article where it’s most instructive. Full code and data can be found on my <a href="https://github.com/omarmhaimdat" target="_blank" rel="noopener">GitHub page</a>. Let’s get started.</p></div></div></section><hr><section><div><div><p id="c981">Let’s say you have a portrait image and you don’t particularly like the background, or you want to add something specific to the image—say some fun digital goggles, for example. In order to do so, you need to identify those regions and classify them, and segmentation does just that. Multiple techniques exist to tackle these kinds of problems, but the most common one these days is <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc">semantic segmentation.</a></p></div></div><div><div><div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2600/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg" width="1300" height="1300" srcset="https://miro.medium.com/max/552/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg 276w, https://miro.medium.com/max/1000/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg 500w" sizes="500px" data-old-src="https://miro.medium.com/max/60/1*XIWnqvdaUXa8QjxlXcDSnw.jpeg?q=20"></p></div></div></figure><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2476/1*tQJXuze-PRTC0mjPvVu3ew.jpeg" width="1238" height="1238" srcset="https://miro.medium.com/max/552/1*tQJXuze-PRTC0mjPvVu3ew.jpeg 276w, https://miro.medium.com/max/1000/1*tQJXuze-PRTC0mjPvVu3ew.jpeg 500w" sizes="500px" data-old-src="https://miro.medium.com/max/60/1*tQJXuze-PRTC0mjPvVu3ew.jpeg?q=20"></p></div></div><figcaption>Figure 2: portrait image (yours truly), original on the left and the segmented image on the right</figcaption></figure></div></div></div></div><div><div><p id="ef61">Once you can identify the background region, you can do whatever you want with it—in this case, we’ll edit the portrait by changing the photo’s background 😅.</p><p id="bb78">For more details on image segmentation’s applications, I wrote an article a few weeks back on Heartbeat:</p></div></div></section><hr><section></section><hr><section><div><div><p id="a2ef">Flask is a Python web application micro-framework built on the WSGI library of Werkzeug. Flask can be “micro”, but it’s ready for use in production for a variety of needs.</p><p id="f2a9">The “micro” in the micro-frame means that Flask aims to keep the kernel simple but expandable. Flask won’t make many decisions for you, like which database to use, but the decisions made are easy to change. Everything is yours, so Flask can be everything you need and nothing else.</p><p id="94ab">I prefer to use a library called <code><a href="https://flask-restful.readthedocs.io/en/latest/" target="_blank" rel="noopener">Flask-RESTful</a></code> made by Twilio that encourages best practices when it comes to APIs.</p><h2 id="f80b">Segmentation inference:</h2><p id="84b5">The segmentation API will use <a href="https://medium.com/u/6efe516bf69?source=post_page-----b141213de3e7----------------------" target="_blank" rel="noopener">Ayoola Olafenwa</a>’s newly published Python package. The package is pretty simple and straightforward, two types of segmentation are currently supported:</p><ul><li id="6974"><strong>Semantic segmentation:</strong> Classify each and every pixel and assign it to a specific class of objects. Let’s say you have multiple cars in a given image—they will all be classified as the same object and will share the same colormap.</li><li id="931c"><strong>Instance segmentation</strong>: Contrary to semantic segmentation, all objects are treated separately, even if they are of the same class.</li></ul><p id="0b62">For more details, <a href="https://medium.com/u/6efe516bf69?source=post_page-----b141213de3e7----------------------" target="_blank" rel="noopener">Ayoola Olafenwa</a> wrote an excellent article on the matter.</p><h2 id="4785">Set up a Python environment:</h2><p id="869d">Create a Python environment using your favorite method, and install the following packages:</p><pre><span id="b2a8">pip install tensorflow</span><span id="38a8">pip install keras</span><span id="21ae">pip install pillow</span><span id="55bd">pip install opencv-python</span><span id="b029">pip install sckit-image</span><span id="5613">pip install pixellib</span></pre><p id="764b">You’ll also need to download the models with preloaded weights using bash commands. They’re all Keras models, so you should expect <code>.h5</code> files:</p><pre><span id="148a"># deeplabV3 xception for semantic segmentation<br>wget <a href="https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5" target="_blank" rel="noopener">https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5</a></span><span id="0eaa"># Mask rcnn coco for instance segmentation<br>wget <a href="https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5" target="_blank" rel="noopener">https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5</a></span></pre><h2 id="d2c8">Build the API:</h2><p id="3271">Install <code>Flask</code> and <code>Flask-RESTful</code> packages:</p><pre><span id="8681">pip install Flask</span><span id="c5c1">pip install Flask-RESTful</span></pre><p id="8e38">We first need to create a set of constants, which will contain the model’s path, as well as the path where the images will be saved:</p><figure><div></div></figure><p id="47b0">Then we need to create an instance of the Flask app and create an <code>Api</code> object:</p><figure><div></div></figure><h2 id="2bdb">Create our classes and <code>POST</code> methods:</h2><p id="e0c6"><strong>Semantic Segmentation</strong></p><figure><div></div></figure><ul><li id="d89f">Create a class <code>SemanticSegmentation</code></li><li id="e16c">Create a method <code>post</code></li><li id="98c8">Parse the request (from the iOS application) and extract the <code>base64</code> image string</li><li id="dfcd">Decode the <code>base64</code> string and save the image in the directory using the native <code>base64</code> Python module</li><li id="6dcc">Instantiate an object of type <code>semantic_segmentation()</code> using <code>pixellib</code></li><li id="8a10">Load the model</li><li id="2d7e">Perform segmentation and save the segmented image</li><li id="7211">Encode the image to a <code>base64</code> format</li><li id="bfdd">Send a dictionary with a final <code>base64</code> image string</li></ul><p id="0472"><strong>Instance Segmentation</strong></p><figure><div></div></figure><ul><li id="231d">Create a class <code>InstanceSegmentation</code></li><li id="94cb">Create a method <code>post</code></li><li id="0cda">Parse the request (from the iOS application) and extract the <code>base64</code> image string</li><li id="412b">Decode the <code>base64</code> string and save the image in the directory using a native <code>base64</code> Python module.</li><li id="acc1">Instantiate an object of type <code>instance_segmentation()</code> using <code>pixellib</code></li><li id="7da3">Load the model</li><li id="ce2d">Perform segmentation and save the segmented image</li><li id="cc0f">Encode the image to a <code>base64</code> format</li><li id="bdb4">Send a dictionary with final <code>base64</code> image string</li></ul><p id="c797"><strong>Run the Flask API</strong></p><p id="7aba">Finally, you need to add the classes to the <code>Flask-RESTful</code> resource and set the entry point for each class like so:</p><figure><div></div></figure><p id="00f8">Flask’s default port is <code>5000</code> , which means you can call <code>POST</code> methods using the following URL:</p><ul><li id="01cd"><strong>Semantic</strong>: <code>http://127.0.0.1:5000/semantic</code></li><li id="be4c"><strong>Instance</strong>: <code>http://127.0.0.1:5000/instance</code></li></ul></div></div></section><hr><section></section><hr><section><div><div><p id="6454">Create a new “Single View Application” and make sure you choose Storyboard as User Interface.</p></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/6528/1*WDF0kMKDPKrS0rmGZTdcgA.png" width="3264" height="781" srcset="https://miro.medium.com/max/552/1*WDF0kMKDPKrS0rmGZTdcgA.png 276w, https://miro.medium.com/max/1104/1*WDF0kMKDPKrS0rmGZTdcgA.png 552w, https://miro.medium.com/max/1280/1*WDF0kMKDPKrS0rmGZTdcgA.png 640w, https://miro.medium.com/max/1456/1*WDF0kMKDPKrS0rmGZTdcgA.png 728w, https://miro.medium.com/max/1632/1*WDF0kMKDPKrS0rmGZTdcgA.png 816w, https://miro.medium.com/max/1808/1*WDF0kMKDPKrS0rmGZTdcgA.png 904w, https://miro.medium.com/max/1984/1*WDF0kMKDPKrS0rmGZTdcgA.png 992w, https://miro.medium.com/max/2160/1*WDF0kMKDPKrS0rmGZTdcgA.png 1080w, https://miro.medium.com/max/2700/1*WDF0kMKDPKrS0rmGZTdcgA.png 1350w, https://miro.medium.com/max/3240/1*WDF0kMKDPKrS0rmGZTdcgA.png 1620w, https://miro.medium.com/max/3780/1*WDF0kMKDPKrS0rmGZTdcgA.png 1890w, https://miro.medium.com/max/4320/1*WDF0kMKDPKrS0rmGZTdcgA.png 2160w, https://miro.medium.com/max/4800/1*WDF0kMKDPKrS0rmGZTdcgA.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*WDF0kMKDPKrS0rmGZTdcgA.png?q=20"></p></div></div><figcaption>Figure 3: create a new Single View Application</figcaption></figure></div><div><div><p id="405c">Now we have our project ready to go. I don’t like using storyboards myself, so the app in this tutorial is built programmatically, which means no buttons or switches to toggle — just pure code.</p><p id="3f19">To follow this method, you’ll have to delete the <code>main.storyboard</code> file and set your <code>SceneDelegate.swift</code> file (Xcode 11 only).</p><p id="a132">With Xcode 11, you’ll have to change the <code>Info.plist</code> file like so:</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3500/0*FYB2GZaYXtV9IMwB.png" width="1750" height="896" srcset="https://miro.medium.com/max/552/0*FYB2GZaYXtV9IMwB.png 276w, https://miro.medium.com/max/1104/0*FYB2GZaYXtV9IMwB.png 552w, https://miro.medium.com/max/1280/0*FYB2GZaYXtV9IMwB.png 640w, https://miro.medium.com/max/1400/0*FYB2GZaYXtV9IMwB.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*FYB2GZaYXtV9IMwB.png?q=20"></p></div></div></div><figcaption>Figure 4: delete the Storyboard Name from the .plist file</figcaption></figure><p id="913c">You need to delete the “Storyboard Name” in the file, and that’s about it.</p><p id="1ce8">Change the <code>SceneDelegate</code> with the following code:</p><figure><div></div></figure><h2 id="09ab">Create View Controllers</h2><p id="041c">We need two ViewControllers:</p><ul><li id="df48"><code><strong>ViewController()</strong></code><strong>:</strong></li></ul><p id="a66c">This is where we’ll set our application entry point and set the buttons that lead to the appropriate segmentation.</p><ul><li id="30fa"><code><strong>OutputViewController()</strong></code><strong>:</strong></li></ul><p id="d2a7">This controller will be used to select the image in order to send it to the API and receive the API callback as well.</p><h2 id="bf7f">Setup ViewController():</h2><p id="0b40"><strong>Label</strong></p><figure><div></div></figure><ul><li id="cad0">Instantiate a <code>UILabel</code> object</li><li id="566e">Set the font type (<em>Avenir-heavy</em>) and size</li><li id="509b">Set the label string—I chose to call the application “Segmentation API”, but that’s up to you to change it</li><li id="326f">Set the text color</li></ul><p id="1f5d"><strong>Logo</strong></p><figure><div></div></figure><ul><li id="786a">Instantiate a <code>UIImageView</code> and pick the image using the “image literal” function</li><li id="9f8b">Enable auto layout</li></ul><p id="923c"><strong>Buttons</strong></p><p id="03d5"><code>ViewController()</code> has two buttons, one for “Semantic segmentation” and the other one for “Instance segmentation”. I also created a custom Button called <code>MyButton()</code> to increase code reusability (available in the GitHub repository).</p><figure><div></div></figure><p id="91e4">Only the button title and target change, the rest is identical:</p><ul><li id="df95">Instantiate a <code>MyButton()</code> object</li><li id="7978">Enable auto layout</li><li id="469c">Set the title string</li><li id="6f62">Add an icon using SF Symbols</li><li id="8215">Add a target that will lead to <code>OutputViewController()</code></li></ul><p id="6745"><strong>Set up the layout</strong></p><figure><div></div></figure><ul><li id="502b">Add all the elements to the <code>ViewController</code>’s subview</li><li id="822d">Set up constraints for each element</li></ul><h2 id="00ee">Setup OutputViewController():</h2><ol><li id="0cd3"><strong>Output Image</strong></li></ol><figure><div></div></figure><ul><li id="e418">Instantiate an empty <code>UIImageView</code> object</li><li id="d200">Enable auto layout</li><li id="c8c8">Select the content mode—I chose <code>.scaleAspectFit</code></li><li id="4f0a">Enable <code>masksToBounds</code> in order to clip any layer bit outside the view boundaries</li></ul><p id="5ad6"><strong>2. Upload and camera button</strong></p><figure><div></div></figure><p id="05a3">The logic is the same as the buttons in <code>ViewController()</code> , the only important change is the target function.</p><p id="052e"><strong>3. Set up the target function for the buttons</strong></p><p id="437b">The function will be triggered when we click the button. The function is pretty simple, but you’ll need to add a description in the info.plist file and explain to the user why you need to use the camera or access the media library (The application will crash if you don’t specify it).</p><figure><div></div></figure><ul><li id="1931">Instantiate a <code>UIImagePickerController()</code></li><li id="a488">Choose the source type—either the media library or the camera</li><li id="252e">Set the editing to true if you want to crop the image before sending it to the API</li><li id="b403">Present the <code>UIImagePickerController()</code> view</li></ul><p id="0e39"><strong>4. Setup the layout</strong></p><p id="e634">Add the elements to the subview and set the constraints.</p></div></div></section><hr><section><div><div><p id="7cb4">The API expects a dictionary of type <code>[String: String]</code>—the key being “image” and the value being the image in the format of a <code>base64String</code> .</p><p id="c38f">I’m using the widely-used Swift package called <a href="https://github.com/Alamofire/Alamofire" target="_blank" rel="noopener">Alamofire</a>, which is excellent for handling HTTP networking with Swift. Install the package (I used pod) using your preferred method:</p><figure><div></div></figure><p id="38b6">Everything is happening in the image picker delegate implementation. Many things are happening here, so let’s break it down:</p><ul><li id="06ad">Create an object of the picked image and parse it as a <code>UIImage</code> object</li><li id="67fc">Convert the <code>UIImage</code> to a <code>base64</code> encoding with a significant compression ratio of 20%. You don’t have to do it, but it does improve the performance of the API</li><li id="1aef">Create the parameter that will be used to send the <code>POST</code> request value to be encoded into the <code>URLRequest</code></li><li id="e507">Perform the request using the Alamofire <code>request</code> method. Pass the API entry point, the type of method ( <code>POST</code> in our case), and the parameters</li><li id="a765">Handle the API response result. If successful, we’ll parse the API response as a …</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://heartbeat.fritz.ai/semantic-and-instance-segmentation-on-ios-using-a-flask-api-deeplabv3-and-mask-r-cnn-b141213de3e7">https://heartbeat.fritz.ai/semantic-and-instance-segmentation-on-ios-using-a-flask-api-deeplabv3-and-mask-r-cnn-b141213de3e7</a></em></p>]]>
            </description>
            <link>https://heartbeat.fritz.ai/semantic-and-instance-segmentation-on-ios-using-a-flask-api-deeplabv3-and-mask-r-cnn-b141213de3e7</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749721</guid>
            <pubDate>Mon, 06 Jul 2020 16:46:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Waymo Challenge Report]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23749716">thread link</a>) | @lucaszsloan
<br/>
July 6, 2020 | https://lucassloan.github.io/2020/07/03/waymo-challenge.html | <a href="https://web.archive.org/web/*/https://lucassloan.github.io/2020/07/03/waymo-challenge.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="the-waymo-challenge">The Waymo Challenge</h2>

<p>In August 2019, Waymo shared a portion of their self-driving car’s data as the <a href="https://blog.waymo.com/2019/08/waymo-open-dataset-sharing-our-self.html">Waymo Open Dataset</a>.  The data set contains LIDAR point clouds and images from the 5 cameras on the Waymo test cars.  I previously used this dataset as additional training data for <a href="https://github.com/LucasSloan/speedchallenge">my entry</a> in the <a href="https://github.com/commaai/speedchallenge">Comma.ai Speed Prediction Challenge</a>.  In March 2020, Waymo released a major update to their dataset and <a href="https://blog.waymo.com/2020/03/announcing-waymos-open-dataset-challenges.html">announced</a> the <a href="https://waymo.com/open/challenges">Waymo Open Dataset Challenges</a>.  There were five challenges:</p>

<ol>
  <li>2D Detection</li>
  <li>2D Tracking</li>
  <li>3D Detection</li>
  <li>3D Tracking</li>
  <li>3D Detection Domain Adaptation</li>
</ol>

<h2 id="the-2d-detection-challenge">The 2D Detection Challenge</h2>

<p>Since most of my prior experience was with 2D computer vision tasks, I decided to try my hand at the 2D Detection challenge.  The 2D detection challenge falls under the computer vision task of <a href="https://en.wikipedia.org/wiki/Object_detection">Object Detection</a>.  Object detection is a more difficult task than the canonical computer vision task of image recognition - in image recognition the model only has to choose which of the supplied labels most applies to the image overall, but in object detection, the model has to localize the objects in the image.</p>

<p>Specifically for the Waymo Challenge, the task was to draw bounding boxes around the vehicles, bikes and pedestrians:</p>

<p><img src="https://lucassloan.github.io/assets/images/ground_truth.png" alt="Sample Waymo bounding boxes" title="Sample Waymo bounding boxes"></p>

<p>There are 5 cameras on the Waymo test vehicle - the front, front right and front left cameras with a resolution of 1920x1280 and the side right and side left cameras with a resolution of 1920x886.</p>

<h2 id="how-object-detection-works">How object detection works</h2>

<p>Almost all object detection models are composed of 2 parts:</p>

<ol>
  <li>A backbone CNN to extract reduced resolution feature maps</li>
  <li>A smaller CNN to predict the objectness of regions of the feature maps</li>
</ol>

<p><img src="https://lucassloan.github.io/assets/images/object_detection_diagram.jpg" alt="Object detection diagram" title="Object detection diagram"></p>

<p>The backbone CNN, usually lifted from a high performing ImageNet classification model produces reduced resolution “images”.  Then many regions, tiled across the “image”, are snapshotted and fed into the smaller CNN.  The regions of “image” where the smaller CNN fires strongly are the predicted boxes of the overall network.</p>

<p>High performing object detection networks add a number of wrinkles on top of this basic scheme, such as running the smaller CNN over feature maps extracted at multiple resolutions to handle detecting objects of different sizes or adding another small CNN to suggest small offsets from the location implied by the where the snapshot was taken.</p>

<h2 id="choosing-a-model">Choosing a Model</h2>

<p>After I decided to tackle the 2D Detection challenge, I did a survey of the top models and honed in on 3 top choices:</p>

<h3 id="spinenet"><a href="https://arxiv.org/pdf/1912.05027.pdf">SpineNet</a></h3>

<p>SpineNet is a very interesting take on the <a href="https://www.reddit.com/r/ProgrammerHumor/comments/8c1i45/stack_more_layers/">stack more layers</a> approach to machine learning.  State of the art object detection models snapshot at different resolutions of feature maps, but the higher resolution feature maps are taken earlier in the backbone, which means that they’re the result of less processing.  SpineNet permutes a standard ResNet-50 architecture so that there are feature maps of multiple resolutions at the end of the network, so that all the feature maps can be the result of all 50 layers.</p>

<h3 id="yolov3"><a href="https://arxiv.org/pdf/1804.02767.pdf">YOLOv3</a></h3>

<p>YOLO (You Only Look Once) is a series of object detection models designed for high speed on commodity hardware.  The project focuses on hardware utilization to guide its design choices, over the raw FLOPs count used by others.</p>

<h3 id="efficientdet"><a href="https://arxiv.org/pdf/1911.09070.pdf">EfficientDet</a></h3>

<p>EfficientDet is a family of models built on top of the <a href="https://arxiv.org/pdf/1905.11946.pdf">EfficientNet</a> family of image recognition models.  It uses the EfficientNet models as the CNN backbone and introduces a new method of aggregating information across resolution scales, the BiFPN.</p>

<p>SpineNet seemed like a promising candidate from the paper, but while it was <a href="https://github.com/tensorflow/tpu/blob/master/models/official/detection/MODEL_ZOO.md">technically opensource</a>, it was written to be run on TPUs and there wasn’t a community trying to leverage it.  YOLOv3 was designed to be run on commodity GPUs, had a large community and active support from the authors, but it didn’t have state of the art performance and was written in a custom ML framework, darknet.  EfficientDet did have the state of the art performance.  It was open source, supported by the author and a substantial community and written in TensorFlow (the framework I have the most experience with).  I decided to focus on EfficientDet.</p>

<h3 id="training-efficientdet">Training EfficientDet</h3>

<p>After fighting the usual fires trying to get a new model working (formatting the data the way the model wants it, difficulties getting the dependencies installed), I was able to finetune the smallest EfficientDet model.  The smallest EfficientDet, d0, is trained on <a href="http://cocodataset.org/#home">the standard COCO dataset</a>, on which it gets an AP of 33.8%.  Unfortunately, finetuning from that checkpoint on the Waymo dataset resulted in much worse performance.</p>

<p>I was able to apply a fact that I had previously learned working on self-driving car data - presenting the frames in order is really bad for performance.  I shuffled my input data better and got much improved performance.  I also changed the learning rate to match the (smaller) batch size that I was training at and got better performance still.  At this point I hit a wall at only 13% AP.  Waymo had preseeded the leaderboard with 2 dummy entries that had ~20% AP, so this clearly wasn’t good enough.</p>

<p>I was training over a period of 10 epochs and the AP basically plateaued after the first 1 or 2 epochs.  I took a look at the code and found that EfficientDet uses a cosine decay rule, so I wondered whether my issue was that the learning rate was falling off too fast.  I switched it out for a constant learning rate, but it had roughly the same performance.  I also tried replacing the default SGD optimizer with an ADAM optimizer, which also had roughly the same performance.</p>

<p>At this point, the deficit versus the COCO AP score had me concerned there was a bug in my code, so I dumped an image with the model’s bounding boxes:</p>

<p><img src="https://lucassloan.github.io/assets/images/sky_boxes.jpg" alt="Sample model detections" title="Sample model detections"></p>

<p>Which made it clear that the model was basically learning, but it did have weird issues with boxes in the sky.  Interestingly, the equivalent boxes from the side cameras (with their different aspect ratio) didn’t have the weird sky boxes.</p>

<p>I also wrote <a href="https://github.com/LucasSloan/waymochallenge/blob/master/dump_tfrecord.py">a tool to dump my tfrecords to json</a> so I could see if there was some obvious flaw in my tfrecord converter, but there wasn’t any.</p>

<p>At this point, faced with consistently worse performance than the COCO dataset, I was concerned that my “finetuning” process was actually making the model worse at detecting things.  The COCO dataset has a bunch of categories that overlap with the Waymo dataset (car, truck -&gt; vehicle), so I was able to write a translation layer that converted the COCO labels to Waymo labels.  With the translation layer, I was able to see what the model’s performance was before finetuning.  EfficientDet d0, the one I was training, had an AP of 6% just mapping the COCO classes, but an AP of 13% after finetuning.  The middle EfficientDet (d4) had a mapped AP of 16% and the largest (d7) had a mapped AP of 19%.</p>

<p>I also took a look at the pictures that comprised the COCO dataset and discovered that the objects in it were usually much larger than the objects in the Waymo dataset.</p>

<p>Between these findings, it was pretty clear that:</p>

<ol>
  <li>Finetuning was working (6% -&gt; 13% AP)</li>
  <li>The Waymo dataset was much more challenging that the COCO dataset</li>
  <li>Larger models would perform better</li>
</ol>

<p>Unfortunately there were issues running larger models on the EfficientDet codebase.  It wasn’t designed for multi-gpu training - I attempted to use <a href="https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy">tf.distribute.Strategy</a> to parallelize the training, but some bug stopped it from working.  Another user’s attempted workaround resulted in my model failing with an out of memory error.  More importantly, EfficientDet was originally designed for TPUs and had some bug that caused much more memory usage on GPU.  On TPUs, the largest model could be run with a batchsize of 4 per 16 gb node.  On GPUs even with a batchsize of 1, the medium model couldn’t be trained.</p>

<p>At this point, the leaderboard had not only the Waymo dummy entries at 20% AP, but also some competitive scores at ~60% AP.  It seemed like I might be able to finetune a larger EfficientDet to beat the dummy entry scores, but I couldn’t possibly put together a really competitive score.</p>

<h2 id="yolov4">YOLOv4</h2>

<p>Fortunately, at this point the <a href="https://arxiv.org/pdf/2004.10934.pdf">YOLOv4 paper</a> came out.  It promised better performance than EfficientDet and emphasized that it was trainable on commodity hardware.</p>

<p>Unfortunately, YOLOv4 isn’t implemented in a standard framework like Tensorflow or Pytorch, it’s implemented in a custom framework called <a href="https://github.com/AlexeyAB/darknet">DarkNet</a>.  Getting it working required learning about CMake and Make, fixing a bug that prevented it from compiling with half-precision support and painfully learning that Make doesn’t natively take advantage of multi-core support.  It also takes in data as individual files, not optimized formats like tfrecord.  I was forced to move my data to my SSD to get full performance.</p>

<p>With all the setup difficulties sorted, I was able to train a YOLOv4 network with the recommended setup up.  I trained for several days and got a network with a performance of 34%!  That was much better than the 13% I’d gotten with EfficientDet.  Unfortunately, the default number that YOLO reports is the AP50 number, a less stringent test than the AP number that EfficientDet uses.  EfficientDet also reports the AP50 number, so I was able to guesstimate that my 34% would give me a true AP of around 20%.  That was maybe high enough to beat Waymo’s dummy entries, but nowhere near high enough to be competitive.</p>

<p>However, at this point, I was basically out of ideas for how to get a truly competitive score.  Since the ~20% AP was the highest number I had yet gotten, I put together the code necessary to turn the YOLO predictions into the Waymo format and uploaded my validation predictions.  <strong>Their system informed me that I had a score of 44%!</strong></p>

<h2 id="back-to-efficientdet">Back to EfficientDet</h2>

<p>At this point, I knew that my pessimism about the performance of my models was wrong - the Waymo metric was way more forgiving than either of the metrics I’d been paying attention to.  Now the job was to build on the models I had in order to beat the fore-runners.  Of …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lucassloan.github.io/2020/07/03/waymo-challenge.html">https://lucassloan.github.io/2020/07/03/waymo-challenge.html</a></em></p>]]>
            </description>
            <link>https://lucassloan.github.io/2020/07/03/waymo-challenge.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749716</guid>
            <pubDate>Mon, 06 Jul 2020 16:45:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code only says what it does]]>
            </title>
            <description>
<![CDATA[
Score 152 | Comments 107 (<a href="https://news.ycombinator.com/item?id=23749676">thread link</a>) | @mjb
<br/>
July 6, 2020 | http://brooker.co.za/blog/2020/06/23/code.html | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2020/06/23/code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>Only loosely related to what it should do.</p>


<p>Code says what it does. That's important for the computer, because code is the way that we ask the computer to do something. It's OK for humans, as long as we never have to modify or debug the code. As soon as we do, we have a problem. Fundamentally, debugging is an exercise in changing what a program does to match what it should do. It requires us to know what a program should do, which isn't captured in the code. Sometimes that's easy: What it does is crash, what it should do is <em>not crash</em>. Outside those trivial cases, discovering intent is harder.</p>

<p>Debugging when <em>should do</em> is subtle, such as when building distributed systems protocols, is especially difficult. In our <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a> paper, we say:</p>

<blockquote><p>Our code reviews, simworld tests, and design meetings frequently referred back to the TLA+ models of our protocols to resolve ambiguities in Java code or written communication.</p></blockquote>

<p>The problem is that the implementation (in Physalia's case the Java code) is both an imperfect implementation of the protocol, and an overly-specific implementation of the protocol. It's overly-specific because it needs to be fully specified. Computers demand that, and no less, while the protocol itself has some leeway and wiggle room. It's also overly-specific because it has to address things like low-level performance concerns that the specification can't be bothered with.</p>

<p><em>Are those values in an ArrayList because order is actually important, or because O(1) random seeks are important, or some other reason? Was it just the easiest thing to write? What happens when I change it?</em></p>

<p>Business logic code, while lacking the cachet of distributed protocols, have even more of these kinds of problems. Code both over-specifies the business logic, and specifies it inaccurately. I was prompted to write this by a tweet from @mcclure111 where she hits the nail on the head:</p>

<blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">Since most software doesn't have a formal spec, most software "is what it does", there's an incredible pressure to respect authorial intent when editing someone else's code. You don't know which quirks are load-bearing.</p>— mcc 🏳️‍⚧️🏳️‍🌈 (@mcclure111) <a href="https://twitter.com/mcclure111/status/1274422600236765186?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote>




<p>This is a major problem with code: <em>You don't know which quirks are load-bearing.</em> You may remember, or be able to guess, or be able to puzzle it out from first principles, or not care, but all of those things are slow and error-prone. What can we do about it?</p>

<p><strong>Design Documentation</strong></p>

<p>Documentation is uncool. Most software engineers seem to come out of school thinking that documentation is below them (<em>tech writer work</em>), or some weird thing their SE professor talked about that is as archaic as Fortran. Part of this is understandable. My own software engineering courses emphasized painstakingly documenting the implementation in UML. No other mention of documentation was made. Re-writing software in UML helps basically nobody. I finished my degree thinking that documentation was unnecessary busywork. Even the <a href="https://agilemanifesto.org/">Agile Manifesto</a> agreed with me<sup><a href="#foot1">1</a></sup>:</p>

<blockquote><p>Working software over comprehensive documentation</p></blockquote>

<p>What I discovered later was that design documentation, encoding the intent and decisions made during developing a system, helps teams be successful in the short term, and people be successful in the long term. Freed from fitting everything in my head, emboldened by the confidence that I could rediscover forgotten facts later, I could move faster. The same applies to teams.</p>

<p>One thing I see successful teams doing is documenting not only the <em>what</em> and <em>why</em> behind their designs, but the <em>how they decided</em>. When it comes time to make changes to the system—either for debugging or in response to changing requirements—these documents are invaluable. It's hard to decide whether its safe to change something, when you don't know why it's like that in the first place. The record of how you decided is important because you are a flawed human, and understanding how you came to a decision is useful to know when that decision seems strange, or surprising.</p>

<p>This documentation process doesn't have to be heavyweight. You don't have to draw painstaking <a href="https://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model">ER diagrams</a> unless you think they are helpful. You should probably ignore UML entirely. Instead, describe the system in prose as clearly and succinctly as you can. One place to start is by building an RFC template for your team, potentially inspired by one that you find on the web. <a href="https://static1.squarespace.com/static/56ab961ecbced617ccd2461e/t/5d792e5a4dac4074658ce64b/1568222810968/Squarespace+RFC+Template.pdf">SquareSpace</a>'s template seems reasonable. Some designs will fit well into that RFC format, other's won't. Prefer narrative writing where you can.</p>

<p>Then, keep the documents. Store them somewhere safe. Soak them in vinegar <a href="https://www.almanac.com/content/home-remedies-cough-relief">and tie them around your chest</a>. You're going to want to make sure that the people who need to maintain the system can find them. As they are spelunking through history, help them feel more like a library visitor and less like Lara Croft.</p>

<p>I'm not advocating for Big Design Up Front. Many of the most important things we learn about a project we learn during the implementation. Some of the most important things we learn years after the implementation is complete. Design documentation isn't a static one-time ahead-of-time deliverable, but an ongoing process. Most importantly, design documentation is not a commitment to bad ideas. If it's wrong, fix it and move forward. Documentation is not a deal with the devil.</p>

<p><strong>Comments</strong></p>

<p>Few topics invite a programmer flame war like comments. We're told that comments are silly, or childish, or make it hard to show how manly you are in writing that convoluted mess of code. If it was hard to write, it should be hard to read. After all, you're the James Joyce of code.</p>

<p>That silliness aside, back to @mcclure111's thread:</p>

<blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">This means comments that *reveal* authorial intent are valuable, and comments that reveal *there was no authorial intent* are even more valuable. Without those hints, you're left editing superstitiously, preserving quirks even when you don't know why. <a href="https://t.co/YhvWnXjp9i">https://t.co/YhvWnXjp9i</a></p>— mcc 🏳️‍⚧️🏳️‍🌈 (@mcclure111) <a href="https://twitter.com/mcclure111/status/1274422825831596039?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote>




<p>Comments allow us to encode <em>authorial intent</em> into our code in a way that programming languages don't always. Types, traits, interfaces, and variable names do put intent into code, but not completely (I see you, type system maximalists). These same things allow us to communicate a lack of intent—consider <a href="https://docs.oracle.com/javase/8/docs/api/java/util/RandomAccess.html">RandomAccess</a> vs <a href="https://docs.oracle.com/javase/8/docs/api/java/util/ArrayList.html">ArrayList</a>—but are also incomplete. Well-commented code should make the intent of the author clear, especially in cases where that intent is either lost in the translation to code, or where implementation constraints hide the intent of the design. Code comments that link back to design documents are especially useful.</p>

<p>Some languages need comments more than others. Some, like SQL, I find to nearly always obscure the intent of the design behind implementation details.</p>

<p><strong>Formal Specification</strong></p>

<p>In <a href="https://cacm.acm.org/magazines/2015/4/184705-who-builds-a-house-without-drawing-blueprints/fulltext">Who Builds a House Without Drawing Blueprints?</a> Leslie Lamport writes:</p>

<blockquote><p>The need for specifications follows from two observations. The first is that it is a good idea to think about what we are going to do before doing it, and as the cartoonist Guindon wrote: "Writing is nature's way of letting you know how sloppy your thinking is."</p>

<p>The second observation is that to write a good program, we need to think above the code level.</p></blockquote>

<p>I've found that specification, from informal specification with narrative writing to formal specification with TLA+, makes writing programs faster and helps reduce mistakes. As much as I like that article, I think Lamport misses a key part of the value of formal specification: it's a great communication tool. In developing some of the trickiest systems I've built, I've found that heavily-commented formal specifications are fantastically useful documentation. Specification languages are all about <em>intent</em>, and some make it easy to clearly separate intent from implementation.</p>

<p>Again, from our <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a> paper:</p>

<blockquote><p>We use TLA+ extensively at Amazon, and it proved exceptionally useful in the development of Physalia.  Our team used TLA+ in three ways: writing specifications of our protocols to check that we understand them deeply, model checking specifications against correctness and liveness properties using the TLC model checker, and writing extensively commented TLA+ code to serve as the documentation of our distributed protocols. While all three of these uses added value, TLA+’s role as a sort of automatically tested (via TLC),and extremely precise, format for protocol documentation was perhaps the most useful.</p></blockquote>

<p>Formal specifications make excellent documentation. Like design docs, they aren't immutable artifacts, but a reflection of what we have learned about the problem.</p>

<p><strong> Conclusion </strong></p>

<p>Building long-lasting, maintainable, systems requires not only communicating with computers, but also communicating in space with other people, and in time with our future selves. Communicating, recording, and indexing the intent behind our designs is an important part of that picture. Make time for it, or regret it later.</p>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> To be charitable to the Agile folks, <em>comprehensive</em> does seem to be load-bearing.</li>
</ol>


</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2020/06/23/code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749676</guid>
            <pubDate>Mon, 06 Jul 2020 16:41:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Initial Commit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23749294">thread link</a>) | @zakallen
<br/>
July 6, 2020 | https://zak.dev/2020/07/06/initial-commit.html | <a href="https://web.archive.org/web/*/https://zak.dev/2020/07/06/initial-commit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<figure><pre><code data-lang="bash"><span>mkdir </span>new-project-5 <span>&amp;&amp;</span> <span>cd </span>new-project-5
git init
<span>echo</span> <span>"wassup"</span> <span>&gt;&gt;</span> README.md
git add <span>.</span>
git commit <span>-m</span> <span>"initial commit"</span>
git remote add origin https://github.com...
git push origin master</code></pre></figure>

<p>Dopamine. Ah, the rush.</p>

<p>The endless possibilities of what this latest project can become. It’s not like all the others. It won’t end up in the old car graveyard like the rest.</p>

<p>A million dollars. Someone could eventually buy it for that much. Wait, a billion sounds way better. The amount of people that can be managed, mentored, all on this rocket ship. This side thing will help the world, make it a <strong>better place</strong>. This company will be different, we’ll even <em>think different</em>. Fridays will be off and everyone will be happy.</p>

<p>I wonder where we should put the campus. I like the idea of everyone being remote, but an office in the early days could make the innovation happen faster.</p>

<p>Wait, I need a name. No vowels, .io for sure. Something totally independent of the service we provide. I don’t want to be the next 24 Hour Fitness. Something like Lime, or Uber, or Zoom. It’s gotta be one syllable, easy to spell, easy to say. But I need to be able to have a good domain name. Nothing like justuse[name]co.io.</p>

<p><em>*Slack notification from 9-5*</em></p>

<p>I need to make sure that this project can scale. Am I picking the right language and framework? I’ve learned by doing, so I can pick a new one. But I’ve heard that when you’re serious, you should stick to something you already know so you can focus on the product. Yes, I’m definitely serious.</p>

<p><em>*Slack notification from 9-5*</em></p>

<p>Ok, looks like I’ll continue tomorrow. Wow, I made a lot of progress. This definitely won’t end up like the others.</p>

<figure><pre><code data-lang="bash">git log

commit 77734bb51b691cbc43f08ab58a46cc06c5dc79fc <span>(</span>HEAD -&gt; master, origin/master<span>)</span>
Author: zakallen &lt;hi@zak.dev&gt;
Date:   Thu Jun 18 08:46:28 2020 <span>-0700</span>
    initial commit</code></pre></figure>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://zak.dev/2020/07/06/initial-commit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749294</guid>
            <pubDate>Mon, 06 Jul 2020 16:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Concurrency Cost Hierarchy]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23749172">thread link</a>) | @benaadams
<br/>
July 6, 2020 | https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html | <a href="https://web.archive.org/web/*/https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<!-- boilerplate 
page.assets: /assets/concurrency-costs
assetpath: /assets/concurrency-costs
tablepath: /misc/tables/concurrency-costs
-->

<h2 id="introduction">Introduction</h2>

<p>Concurrency is hard to get <em>correct</em>, at least for those of us unlucky enough to be writing in languages which expose directly the guts of concurrent hardware: threads and shared memory. Getting concurrency correct <em>and</em> fast is hard, too. Your knowledge about single-threaded optimization often won’t help you: at a micro (instruction) level we can’t simply apply the usual rules of μops, dependency chains, throughput limits, and so on. The rules are different.</p>

<p>If that first paragraph got your hopes up, this second one is here to dash them: I’m not actually going to do a deep dive into the very low level aspects of concurrent performance. There are a lot of things we just don’t know about how atomic instructions and fences execute, and we’ll save that for another day.</p>

<p>Instead, I’m going to describe a higher level taxonomy that I use to think about concurrent performance. We’ll group the performance of concurrent operations into six broad <em>levels</em> running from fast to slow, with each level differing from its neighbors by roughly an order of magnitude in performance.</p>

<p>I often find myself thinking in terms of these categories when I need high performance concurrency: what is the best level I can practically achieve for the given problem? Keeping the levels in mind is useful both during initial design (sometimes a small change in requirements or high level design can allow you to achieve a better level), and also while evaluating existing systems (to better understand existing performance and evaluate the path of least resistance to improvements).</p>

<h3 id="a-real-world-example">A “Real World” Example</h3>

<p>I don’t want this to be totally abstract, so we will use a real-world-if-you-squint<sup id="fnref:realworld"><a href="#fn:realworld">1</a></sup> running example throughout: safely incrementing an integer counter across threads. By <em>safely</em> I mean without losing increments, producing out-of-thin air values, frying your RAM or making more than a minor rip in space-time.</p>

<h3 id="source-and-results">Source and Results</h3>

<p>The source for every benchmark here is <a href="https://github.com/travisdowns/concurrency-hierarchy-bench">available</a>, so you can follow along and even reproduce the results or run the benchmarks on your own hardware. All of the results discussed here (and more) are available in the same repository, and each plot includes a <code>[data table]</code> link to the specific subset used to generate the plot.</p>

<h3 id="hardware">Hardware</h3>

<p>All of the performance results are provided for several different hardware platforms: Intel Skylake, Ice Lake, Amazon Graviton and Graviton 2. However except when I explicitly mention other hardware, the prose refers to the results on Skylake. Although the specific numbers vary, most of the qualitative relationships hold for the hardware too, but <em>not always</em>. Not only does the hardware vary, but the OS and library implementations will vary as well.</p>

<p>It’s almost inevitable that this will be used to compare across hardware (“wow, Graviton 2 sure kicks Graviton 1’s ass”), but that’s not my goal here. The benchmarks are written primarily to tease apart the characteristics of the different levels, and <em>not</em> as a hardware shootout.</p>

<p>Find below the details of the hardware used:</p>

<table>
  <thead>
    <tr>
      <th>Micro-architecture</th>
      <th>ISA</th>
      <th>Model</th>
      <th>Tested Frequency</th>
      <th>Cores</th>
      <th>OS</th>
      <th>Instance Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Skylake</td>
      <td>x86</td>
      <td>i7-6700HQ</td>
      <td>2.6 GHz</td>
      <td>4</td>
      <td>Ubuntu 20.04</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Ice Lake</td>
      <td>x86</td>
      <td>i5-1035G4</td>
      <td>3.3 GHz</td>
      <td>4</td>
      <td>Ubuntu 19.10</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Graviton</td>
      <td>AArch64</td>
      <td>Cortex-A72</td>
      <td>2.3 GHz</td>
      <td>16</td>
      <td>Ubuntu 20.04</td>
      <td>a1.4xlarge</td>
    </tr>
    <tr>
      <td>Graviton 2</td>
      <td>AArch64</td>
      <td>Neoverse N1</td>
      <td>2.5 GHz</td>
      <td>16<sup id="fnref:g2cores"><a href="#fn:g2cores">2</a></sup></td>
      <td>Ubuntu 20.04</td>
      <td>c6g.4xlarge</td>
    </tr>
  </tbody>
</table>

<h2 id="level-2-contended-atomics">Level 2: Contended Atomics</h2>

<p>You’d probably expect this hierarchy to be introduced from fast to slow, or vice-versa, but we’re all about defying expectations here and we are going to start in the <em>middle</em> and work our way outwards. The middle (rounding down) turns out to be <em>level 2</em> and that’s where we will jump in.</p>

<p>The most elementary way to safely modify any shared object is to use a lock. It mostly <em>just works</em> for any type of object, no matter its structure or the nature of the modifications. Almost any mainstream CPU from the last thirty years has some type of locking<sup id="fnref:parisc"><a href="#fn:parisc">3</a></sup> instruction accessible to userspace.</p>

<p>So our baseline increment implementation will use a simple mutex of type <code>T</code> to protect a plain integer variable:</p>

<div><div><pre><code><span>T</span> <span>lock</span><span>;</span>
<span>uint64_t</span> <span>counter</span><span>;</span>

<span>void</span> <span>bench</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>holder</span><span>(</span><span>lock</span><span>);</span>
        <span>counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We’ll call this implementation <em><abbr title="Uses a std::mutex and std::lock_guard to protect a plain integer counter.">mutex add</abbr></em>, and on my 4 CPU Skylake-S i7-6700HQ machine, when I use the vanilla <code>std::mutex</code> I get the following results for 2 to 4 threads:</p>



<p>The reported value is the median of all trials, and the vertical black error lines at the top of each bar indicate the <em>interdecile range</em>, i.e., the values at the 10th and 90th percentile. Where the error bars don’t show up, it means there is no difference between the p10 and p90 values at all, at least within the limits of the reporting resolution (100 picoseconds).</p>

<p>This shows that the baseline contended cost to modify an integer protected by a lock starts at about 125 nanoseconds for two threads, and grows somewhat with increasing thread count.</p>

<p>I can already hear someone saying: <em>If you are just modifying a single 64-bit integer, skip the lock and just directly use the atomic operations that most ISAs support!</em></p>

<p>Sure, let’s add a couple of variants that do that. The <code>std::atomic&lt;T&gt;</code> template makes this easy: we can wrap any type meeting some basic requirements and then manipulate it atomically. The easiest of all is to use <code>std::atomic&lt;uint64&gt;::operator++()</code><sup id="fnref:post"><a href="#fn:post">4</a></sup> and this gives us <em><abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>atomic_counter</span><span>{};</span>

<span>void</span> <span>atomic_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>atomic_counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The other common approach would be to use <a href="https://en.wikipedia.org/wiki/Compare-and-swap">compare and swap (<abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr>)</a> to load the existing value, add one and then <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr> it back if it hasn’t changed. If it <em>has</em> changed, the increment raced with another thread and we try again.</p>

<p>Note that even if you use increment at the source level, the assembly might actually end up using <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr> if your hardware doesn’t support atomic increment<sup id="fnref:atomicsup"><a href="#fn:atomicsup">5</a></sup>, or if your compiler or runtime just don’t take advantage of atomic operations even though they are available (e.g., see what even the newest version of <a href="https://godbolt.org/z/5h4K7y">icc does</a> for atomic increment, and what Java did for years<sup id="fnref:java"><a href="#fn:java">6</a></sup>). This caveat doesn’t apply to any of our tested platforms, however.</p>

<p>Let’s add a counter implementation that uses <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr> as described above, and we’ll call it <em><abbr title="Uses a CAS loop to increment a single shared counter.">cas add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>cas_counter</span><span>;</span>

<span>void</span> <span>cas_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>uint64_t</span> <span>v</span> <span>=</span> <span>cas_counter</span><span>.</span><span>load</span><span>();</span>
        <span>while</span> <span>(</span><span>!</span><span>cas_counter</span><span>.</span><span>compare_exchange_weak</span><span>(</span><span>v</span><span>,</span> <span>v</span> <span>+</span> <span>1</span><span>))</span>
            <span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Here’s what these look like alongside our existing <code>std::mutex</code> benchmark:</p>



<p>The first takeaway is that, at least in this <em>unrealistic maximum contention</em> benchmark, using <abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr> (<a href="https://www.felixcloutier.com/x86/xadd"><code>lock xadd</code></a> at the hardware level) is significantly better than <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr>. The second would be that <code>std::mutex</code> doesn’t come out looking all that bad on Skylake. It is only slightly worse than the <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr> approach at 2 cores and beats it at 3 and 4 cores. It is slower than the atomic increment approach, but less than three times as slow and seems to be scaling in a reasonable way.</p>

<p>All of these operations are belong to <em>level 2</em> in the hierarchy. The primary characteristic of level 2 is that they make a <em>contended access</em> to a shared variable. This means that at a minimum, the line containing the data needs to move out to the caching agent that manages coherency<sup id="fnref:l3"><a href="#fn:l3">7</a></sup>, and then back up to the core that will receive ownership next. That’s about 70 cycles minimum just for that operation<sup id="fnref:inter"><a href="#fn:inter">8</a></sup>.</p>

<p>Can it get slower? You bet it can. <em>Way</em> slower.</p>

<h3 id="level-3-system-calls">Level 3: System Calls</h3>

<p>The next level up (“up” is not good here…) is level 3. The key characteristic of implementations at this level is that they make a <em>system call on almost every operation</em>.</p>

<p>It is easy to write concurrency primitives that make a system call <em>unconditionally</em> (e.g., a lock which always tries to wake waiters via a <code>futex(2)</code> call, even if there aren’t any), but we won’t look at those here. Rather we’ll take a look at a case where the fast path is written to avoid a system call, but the design or way it is used implies that such a call usually happens anyway.</p>

<p>Specifically, we are going to look at some <em>fair locks</em>. Fair locks allow threads into the critical section in the same order they began waiting. That is, when the critical section becomes available, the thread that has been waiting the longest is given the chance to take it.</p>

<p>Sounds like a good idea, right? Sometimes yes, but as we will see it can have significant performance implications.</p>

<p>On the menu are three different fair locks.</p>

<p>The first is a <a href="https://en.wikipedia.org/wiki/Ticket_lock">ticket lock</a> with a <code>sched_yield</code> in the spin loop. The idea of the yield is to give other threads which may hold the lock time to run. This <code>yield()</code> approach is publicly frowned upon by concurrency experts<sup id="fnref:notwhat"><a href="#fn:notwhat">9</a></sup>, who then sometimes go right ahead and use it anyway.</p>

<p>We will call it <abbr title="A ticket lock that calls sched_yield in a spin loop while waiting for its turn.">ticket yield</abbr> and it looks like this:</p>



<div><div><pre><code><span>/**
 * A ticket lock which uses sched_yield() while waiting
 * for the ticket to be served.
 */</span>
<span>class</span> <span>ticket_yield</span> <span>{</span>
    <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>dispenser</span><span>{},</span> <span>serving</span><span>{};</span>

<span>public:</span>
    <span>void</span> <span>lock</span><span>()</span> <span>{</span>
        <span>auto</span> <span>ticket</span> <span>=</span> <span>dispenser</span><span>.</span><span>fetch_add</span><span>(</span><span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_relaxed</span><span>);</span>

        <span>while</span> <span>(</span><span>ticket</span> <span>!=</span> <span>serving</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>))</span>
            <span>sched_yield</span><span>();</span>
    <span>}</span>

    <span>void</span> <span>unlock</span><span>()</span> <span>{</span>
        <span>serving</span><span>.</span><span>store</span><span>(</span><span>serving</span><span>.</span><span>load</span><span>()</span> <span>+</span> <span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_release</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre></div></div>

<p>Let’s plot the performance results for this lock alongside the existing approaches:</p>



<p>This is level 3 visualized: it is an order of magnitude slower than the level 2 approaches. The slowdown comes from the <code>sched_yield</code> call: this is a system call and these are generally on the order of 100s of nanoseconds<sup id="fnref:spectre"><a href="#fn:spectre">10</a></sup>, and it shows in the results.</p>

<p>This lock <em>does</em> have a fast path where <code>sched_yield</code> isn’t called: if the lock is available, no spinning occurs and <code>sched_yield</code> is never called. However, the combination of being a <em>fair</em> lock and the high contention in this test means that a lock convoy quickly forms (we’ll describe this in more detail later) and so the spin loop is entered basically …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</a></em></p>]]>
            </description>
            <link>https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749172</guid>
            <pubDate>Mon, 06 Jul 2020 15:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How I landed an interview almost every time I applied (as a developer)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23748953">thread link</a>) | @yassinerajallah
<br/>
July 6, 2020 | https://devhypercharged.com/how-to-land-an-interview-almost-every-time-as-a-programmer/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/how-to-land-an-interview-almost-every-time-as-a-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Applying to startups, medium-big corps is a tedious task. The standard is to apply to 100+ companies and prepare 100+ programming problems. Does it have to be this hard? Short answer no. In fact, I applied to 30 companies and landed 25 interviews. And the good news is, it generally doesn’t take more than 2 weeks to finish with all that interview process (of course it depends on the company)&nbsp;</span></p>
<p><span>Let’s get started already. If you are applying to:</span></p>

<h4><span>Startup/Medium-Size Company:</span></h4>
<p><span>The hiring process depends on the company. More often than not, you talk to the CEO/CTO and are judged over your “compatibility” with the workplace’s culture. Generally, the first interview is just to get to know you, your rate (please don’t ask for a crazy salary if you are just starting out), and what you can bring to the ecosystem. At later stages, you are assigned a take-home project or a live coding interview.</span></p>
<p><span>Your responsibility depends on how much funding the startup has and its burn rate. The lesser the investment, the more critical your responsibility. It makes sense because the founder(s) can’t hire another developer to help you out. And you probably have been hired because you’re full-stack. You are also expected to have an “entrepreneurial mindset”, you get the chance to make influential decisions. It’s important to know that you aren’t a “code monkey”.You’ll need to make well-thought decisions for the sake of the startup.&nbsp;</span></p>
<p><b>To land an interview, your best bet is to reach out to the founders: </b><span>Skip sending your application through the website. Instead, craft your best looking, most personal, and professional email out there. You research the startup, research the founders, and link what they work on to your skills.&nbsp;</span></p>
<ul>
<li><span>Be careful of sounding too general “I’m interested in your company, it’s truly something the world needs”; Say what is special about it, if you have a question or 2, you can include them. But the main purpose is to show your interest.&nbsp;</span></li>
</ul>

<ul>
<li><span>Include your resume and make sure it’s clean and spacious enough. No one wants to read a 2-page resume full of little details. The most important on the top, and shoot your shot, no time to waste.</span></li>
</ul>

<ul>
<li><span>Include a call to action at the end of your email “Would love to hear from you.”&nbsp;</span></li>
</ul>

<ul>
<li><span>You are set! You’ll be amazed by the response rate. And the founders are friendlier than you might think.</span></li>
</ul>
<p><span>To find startups that match your profile, you can use: </span></p>
<p><a href="https://angel.co/"><span>angel.co</span></a></p>
<p><a href="https://www.workatastartup.com/"><span>workatastartup.com</span></a></p>



<h4><span>Big tech</span></h4>
<p><span>This one is tricky. The application portals are heavily advertised and probably everyone applies through them. Result? Your application goes unnoticed.&nbsp;</span></p>
<p><span>I won’t beat around the bush, you need a recommendation. Unless you are some high profile employee at company X, you won’t be noticed. Most people I know got in with a recommendation. This legacy system puts other applicants at a disadvantage in the resume screening process.&nbsp;</span></p>
<p><span>But how can you get a recommendation? </span><span>So far there are 2 ways.</span></p>

<p><strong>Your circle/network</strong></p>
<p><span>Start by asking people in your circle. Note that a recommendation helps you with skipping the screening process and that’s it. The rest is on you. Being hired totally depends on your skills from this point forward.</span></p>
<p><strong>Create a relationship</strong></p>
<p><span>If you are applying to big corp XYZ, chances are you’re really interested in the company culture (salary aside). You can go on LinkedIn and connect with an employee from that company. Ideally, you want to stay in touch for months to come. A great way to do so is by asking questions!&nbsp; When you build this long term relationship, you can ask for a recommendation. Obviously, you don’t want to talk to employees just because of the recommendation, be authentic!&nbsp;</span></p>

<p><span>This brings it to the end of this article. If you learned something new or want to connect shoot me an email 🙂 Until next time. Take care!</span></p>
<p><span>Ps: If you found this helpful, please consider sharing and subscribing. It helps keep the website alive. Thank you!</span></p>

			
			
</div></div>]]>
            </description>
            <link>https://devhypercharged.com/how-to-land-an-interview-almost-every-time-as-a-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748953</guid>
            <pubDate>Mon, 06 Jul 2020 15:30:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can We Have Prosperity Without Growth? Yes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23748907">thread link</a>) | @paulpauper
<br/>
July 6, 2020 | https://greyenlightenment.com/can-we-have-prosperity-without-growth-yes/ | <a href="https://web.archive.org/web/*/https://greyenlightenment.com/can-we-have-prosperity-without-growth-yes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-20038">
	
	<!-- .entry-header -->

	<div>
		<p>The New Yorker <a href="https://www.newyorker.com/magazine/2020/02/10/can-we-have-prosperity-without-growth">asks</a> if it is possible to have prosperity without growth. My answer is an emphatic yes. </p>
<p>When pundits talk about slowing growth and stagnation, the are usually alluding to declining real US GDP growth, relative to the past:</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Quarterly_gross_domestic_product.png/1920px-Quarterly_gross_domestic_product.png"></p>
<p>Real GDP growth is around 2-3%/year, which is half it was 2-4 decades ago.</p>
<p>But does this mean less prosperity? The evidence shows the opposite, that prosperity has surged in spite of slowing growth.</p>
<p>Consider:</p>
<p>The 2009-2020 bull market is the longest and biggest ever on an inflation-adjusted basis. Trillion dollars of wealth has been created since 2009.</p>
<p>Supposed stagnation hasn’t stopped Tesla from surging above $700, a gain of 3000% since its IPO in 2010. </p>
<p>Over the past decade, billions of dollars wealth has been created in tech start-ups such as Uber, AirBNB, Dropbox, Snapchat, etc. One can argue that this is paper wealth and not ‘real’ wealth, but insiders and other shareholders are able to sell on the secondary market, so it’s not like this equity cannot be converted into cash. </p>
<p>The Nasdaq is up 400% since 2010, almost a bigger gain than even the ’90s.</p>
<p>In spite of low GDP growth, US real GDP growth still exceeds many large and developing economies such as Brazil, Spain, Turkey, UK, Italy, Germany, Japan, etc. Even though Brazil and Turkey have higher nominal GDP growth, inflation is so high and the US dollar is so strong that real GDP growth is worse than that of the US. </p>
<p>Home prices have recovered all their 2005-2008 losses and are making new highs in many regions such as the Bay Area. Many pundits predicted that home prices would take decades to recover, if ever, but it only took 5 years to make new highs, enriching landlords and homeowners:</p>
<p><img src="https://cdn.dqydj.com/wp-content/uploads/2019/10/median-home-price-1.png"></p>
<p>The Forbes 30 list is much wealthier now than ever before, and over the past decade their wealth has grown considerably on a real basis thanks to rapidly appreciating share prices such as tech stocks. </p>
<p>Why have stocks done so well? The answer is strong earnings growth and fat profits. Historically speaking, corporate profits are very high to GDP:</p>
<p><img src="https://static.seekingalpha.com/uploads/2019/9/2/saupload_Profits_2B_2525_2Bof_2BGDP.jpg"><src></src></p>
<p>As discussed in <a href="https://greyenlightenment.com/disagreeing-with-tyler-cowen-about-stagnation/">Disagreeing with Tyler Cowen about Stagnation and Innovation</a>, it’s possible to have huge real returns in the market in spite of low GDP growth. If large cap corporations are generating profit margins of 10-30% (especially for large cap tech such as Facebook, Microsoft, Google, and Apple), then investors stand to make a real return in excess of 8-28% whether in the form of dividends or share price appreciation (such as from buybacks or increased shareholder equity). This is how it’s possible for stocks to surge 10-30% every year even if GDP is only around 2-3%/year. </p>
<p>Shareholders seen their wealth surge since 2010. Defense companies, tech companies are generating hundreds of billions of dollars in free cash flow every quarter, the highest ever. The US govt. can borrow at just 2%/year for 10 years, and that money flows into the private sector and S&amp;P 500 stocks, which generate profit margins as high as 30%. This represents a significant real return for investors even if the national debt keeps rising. This is also why investors should not worry about the national debt. The S&amp;P 500 gained 30% in 2019 in spite the national debt rising to as high as $23 trillion and GDP growth only being only 2.5%, representing a real return of 28% for investors, which is huge. It also helps that the US dollar is also very strong. This means Americans are becoming not only nominally more wealthy but also wealthier relative to the rest of the world. As discussed <a href="http://greyenlightenment.com/economic-myths-part-1-budget-surpluses-are-good/">here</a>, the fears over the national debt are overblown and the interest paid on debt relative to GDP is the lowest in decades. </p>
<p><img src="https://i.redd.it/xpcizwgfra401.png"></p>
<p>Moreover, inflation is stubbornly low at just 2%/year in spite of large deficits and failed media predictions of how the Trump tariffs would cause high inflation, so this means a greater real return too both for stocks and real estate. This is also good for consumers and low inflation generally means a higher standard of living because purchasing power is higher; however, as many will point out, healthcare and college inflation is far higher than the CPI. But in regard to the latter, college grads have seen their wages rise on a real basis, especially since 2009, so this sorta helps cancel it out. </p>
<p>The US economy is being increasingly dominated by large companies that are able to generate large, reliable recurring revenues, protected by networking effects and intellectual property, such as Disney, Microsoft, and Facebook. Microsoft can keep selling the same version of Windows and Office over and over, with some small improvements every couple years. Facebook and Google have thousands of clients that they bill on a recurring basis for advertising, generating profit margins as high as 30%. </p>
<p>In spite of stagnant real wages for many middle and low-class jobs and high student loan debt, tons of people are making money in option trading, selling on Amazon, coding, social media, etc. 15 years ago these industries either didn’t exist or were in their infancy, such as Amazon’s third-party seller program. IQ matters a lot too. People who make a lot of money tend to be smarter than the general population, such as doctors, stock traders, or software developers. Doctor and lawyers go into a lot of debt early in their careers, but make it up with huge salaries, that grow on a real basis. A car salesman may make $200k but these tend to be huge outliers. The median tech worker does better than the median car salesman. However, those who are less intelligent have fared more poorly since 2010, and some have seen their wages stagnate on a real basis. </p>
<p>From <a href="http://greyenlightenment.com/18789/">The ’90s and now, part 14</a>:</p>
<blockquote><p>
On the flip side, although the past decade has been great for the investing class and tech class, perhaps the ’90s were better for the working and average-IQ class. Not everyone can be a millionaire or billionaire tech company founder, a Bain or McKinsey consultant, a YouTube or Instagram superstar, a software developer, an investment banker, or a cryptocurrency or option trading whiz. People of average IQ and ability are possibly falling between the cracks, unable to participate in the otherwise strong tech-and-finance-driven economy. There’s tons of wealth being created, but much of it it seems concentrated in the hands of a few. This is why there is the juxtaposition of today’s competitive economy with the acceptance or reconciliation of mediocrity, whether it’s popular subs such as /r/aftergifted or massively up-vpoted memes on /r/funny, the shared narrative being coping with failing to meet the high expectations America’s increasingly competitive, credential-driven economy and society imposes, where so many people are striving to get into top tech firms and top universities.
</p></blockquote>
<p>Shareholders are the biggest beneficiaries of this trend and have seen their wealth surge in recent decades on a real basis in spite of slow GDP growth. But unlike the top 10%, the poor and middle class are less likely to own stocks and have less of their net worth tied in equities. So for the wealthy and successful, things may seem prosperous, but for everyone else, maybe less so. </p>



<p><a target="_blank" onclick="window.open(this.href,'targetWindow','toolbar=no,location=0,status=no,menubar=no,scrollbars=yes,resizable=yes,width=600,height=250'); return false;" href="https://twitter.com/intent/tweet?via=&amp;text=Can%20We%20Have%20Prosperity%20Without%20Growth?%20Yes&amp;url=https://greyenlightenment.com/can-we-have-prosperity-without-growth-yes/"><img src="http://i.imgur.com/2QyuBgQ.png"></a>

<a target="_blank" onclick="window.open(this.href,'targetWindow','toolbar=no,location=0,status=no,menubar=no,scrollbars=yes,resizable=yes,width=600,height=250'); return false;" href="http://www.facebook.com/sharer.php?u=https://greyenlightenment.com/can-we-have-prosperity-without-growth-yes/" data-href="https://greyenlightenment.com/can-we-have-prosperity-without-growth-yes/" data-send="false" data-layout="button_count" data-width="60" data-show-faces="false" rel="nofollow"><img src="http://i.imgur.com/OBWIOxN.png"></a>

			</p></div><!-- .entry-content -->

	</article></div>]]>
            </description>
            <link>https://greyenlightenment.com/can-we-have-prosperity-without-growth-yes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748907</guid>
            <pubDate>Mon, 06 Jul 2020 15:26:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Purely Functional, Statically Typed Effect System for Python]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23748773">thread link</a>) | @suned
<br/>
July 6, 2020 | https://pfun.readthedocs.io/en | <a href="https://web.archive.org/web/*/https://pfun.readthedocs.io/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://pfun.readthedocs.io/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748773</guid>
            <pubDate>Mon, 06 Jul 2020 15:13:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon: The Company with a 100 CEOs Cannot Be Stopped]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23748686">thread link</a>) | @dsr12
<br/>
July 6, 2020 | https://www.anshublog.com/2017/07/amazon-company-with-100-ceos-cannot-be.html | <a href="https://web.archive.org/web/*/https://www.anshublog.com/2017/07/amazon-company-with-100-ceos-cannot-be.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div dir="ltr">

<h4>A company with a 100 CEOs can do anything.</h4>
<p>Amazon appears to be a unique success when it comes to not just the success it has achieved but the diversity of businesses it has succeeded in — from online retail to web services, and the march continues into many, many new lines of business.</p>
<p>Almost every large, successful company struggles with growing beyond its core business. Oracle is great at selling software, Salesforce is great at cloud CRM, Apple is great at selling devices and they do an okay to good job of selling products and services that are complimentary — often through the exact same distribution channel.</p>
<h4>The constraint is senior leadership bandwidth.</h4>
<p>If your CEO and executive leadership of the company need to be bought in before you can execute, as a business leader you have to now convince leaders who have great instincts for say a retail or ad business to grok an entirely new business model. This is not easy. Most companies fail here.</p>
<p>Google is a great example — it’s done a great job of winning the online search market and almost anything that can be monetized using the same business model — ads. But when it tries to get into new businesses like grocery delivery, selling phones (Motorola &amp; now Pixel), robots that walk, cars that drive themselves — it often appears to struggle on the goto-market and business side. Where it sets up clear business units with leaders it does well, YouTube under Susan Wojcicki being a great example.</p>
<h4 name="7d1e">What makes Amazon succeed where others struggle so&nbsp;hard?</h4>
<p>Amazon appears to be one company run well by Jeff Bezos and his direct reports like Andy Jassy — but in reality Amazon has succeeded in building a culture of 100 CEOs — it hires, grooms, develops and builds “General Managers” — there is literally over 100+ of them*.</p>
<h4>A company with a 100 CEOs can do anything.</h4>
<p>While many companies give GM like titles to their executives, they are often constrained by central planning of some sort. They pay what is known as the corporate <a data-href="https://stratechery.com/2013/the-uncanny-valley-of-a-functional-organization/" href="https://stratechery.com/2013/the-uncanny-valley-of-a-functional-organization/" rel="noopener noreferrer" target="_blank">strategy tax</a>. At a company like Oracle, I couldn’t price product A if it would impact the profitability and revenue of (cash cow) product B. Every major successful company learns to protect its cash cow — and while this initially helps, often for decades, it eventually turns into a millstone around the neck of every business. Be it mainframes, databases, ERPs, ad revenue, or whatever.</p>
<figure name="b526"><img data-height="1354" data-image-id="1*uQtrDSN4gU64-spaJLGT_A.png" data-width="2546" src="https://www.anshublog.com/wp-content/uploads/2017/07/1-uQtrDSN4gU64-spaJLGT_A.png"><figcaption>100 Mini-Me&nbsp;CEOs</figcaption></figure>
<p>(Technically speaking, the titles at Amazon are a little mixed. Not all GM’s lead businesses but many do — from Alexa to Redshift Analytics. But the business is structured around these BU leads some run all of India while some are growing new businesses like “live video”.)</p>
<h4 name="f879">Why can’t every company declare 100&nbsp;CEOs?</h4>
<p>Companies often talk about agility and the desire to move faster and move decision making to the edge but they are not truly built for it.</p>
<h4>Amazon was built ground up on APIs and Categories</h4>
<p>Amazon’s first foray into books meant when it entered new categories, it appointed GMs for new categories who ran them as businesses. Pretty close to how a brand manager at P&amp;G can make decisions around Tide.</p>
<p>But it was the key technological architectural decision of being API driven for every single (micro) service in the company that truly enabled <strong>Amazon to be a network of business units — </strong>interacting and doing business with each other with clear APIs and rules of engagement.</p>
<p>Companies like Google realize this and hence the move to Alphabet, and appointing a clear CEO of Google Cloud (Diane Greene) but its hard to retrofit this model unless you have practiced it and its deeply ingrained in your culture.</p>
<p>In some ways, GE was the original conglomerate with many businesses operating under leaders but they are big businesses.</p>
<blockquote name="100f"><p>Amazon grows BU’s that look like startups from $0 to $100M and sometimes to $1B+ under GM’s that literally start out with nothing more than an idea. Amazon’s database business is one such example.</p></blockquote>
<p>As Amazon, welcomes its one more CEO — Mackey of Whole Foods, its good to remember that he joins a long list of executives at Amazon running billion dollar businesses, and there will be more grown internally, and acquired.</p>
</div>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://www.anshublog.com/2017/07/amazon-company-with-100-ceos-cannot-be.html"
    dc:identifier="https://www.anshublog.com/2017/07/amazon-company-with-100-ceos-cannot-be.html"
    dc:title="Amazon: The Company with a 100 CEOs Cannot Be Stopped"
    trackback:ping="https://www.anshublog.com/2017/07/amazon-company-with-100-ceos-cannot-be.html/trackback" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://www.anshublog.com/2017/07/amazon-company-with-100-ceos-cannot-be.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748686</guid>
            <pubDate>Mon, 06 Jul 2020 15:05:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made a macro keypad with 3D-printed switches]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23748660">thread link</a>) | @jstanley
<br/>
July 6, 2020 | https://incoherency.co.uk/blog/stories/3pct-keyboard.html | <a href="https://web.archive.org/web/*/https://incoherency.co.uk/blog/stories/3pct-keyboard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>I made a macro keypad with 3d-printed switches</h3>
<p><i>Mon  6 July 2020</i></p>
<p><i>Tagged: <a href="https://incoherency.co.uk/blog/tags/electronics.html">electronics</a>, <a href="https://incoherency.co.uk/blog/tags/3dprinting.html">3dprinting</a></i></p>
<p>Latest on the 3d-printed keyboard switch project: I've reached a switch design that I think is probably reliable enough,
and I've put 3 of them together to form a macro keypad just to see how it all goes together before I commit to a
full keyboard. I don't have a number for how many presses the switch lasts, other than to say that
the motor on the testing machine stopped working before the switch did (after about 250,000 presses).</p>
<p><a href="https://img.incoherency.co.uk/2745"><img src="https://img.incoherency.co.uk/2745"></a></p>
<p>You can <a href="https://www.youtube.com/watch?v=uHkOPBxnLtM">watch my short demo video</a> if you want.</p>
<p>"80%" and "60%" keyboard layouts are quite popular, which are correspondingly reduced versions of a full keyboard layout.
I like to think of this keypad as a "3%" keyboard, it's fine as long as you only want to type "jes".</p>
<p><a href="https://img.incoherency.co.uk/2746"><img src="https://img.incoherency.co.uk/2746"></a></p>
<p>It's controlled by an Arduino Pro Micro. It's hard to tell from the pic because of the hot glue, but the switches are wired up to pins 2, 3, and 4, from
the other side of the board.</p>
<p>For the software side of it, I used the <a href="https://www.arduino.cc/reference/en/language/functions/usb/keyboard/">Arduino Keyboard library</a>,
using <a href="https://gist.github.com/jes/fe1aeb18457a06562516372684d1bd47">this quick and dirty Arduino code</a>.
Approximately all of the code is just related to the debounce logic.</p>
<p><a href="https://img.incoherency.co.uk/2748"><img src="https://img.incoherency.co.uk/2748"></a></p>
<p>The switches are printed in some generic no-name clear PETG.
The case and keycaps are printed in <a href="https://shop.prusa3d.com/en/prusament/711-prusament-pla-prusa-galaxy-black-1kg.html">Prusament Galaxy Black PLA</a>.
I'm a big fan of this filament. The glittery effect means the layer lines almost completely disappear. It's basically the same effect you get when printing with
carbon fibre-filled nylon, but with none of the difficulties of printing carbon fibre-filled nylon.</p>
<p>All of these parts, including the switches, were printed on my new <a href="https://www.prusa3d.com/original-prusa-mini/">Prusa Mini</a> printer, which arrived last week and I'm very pleased
with so far.</p>
<h2>Switches</h2>
<p>The problem with the switch design <a href="https://incoherency.co.uk/blog/stories/keyswitch-update.html">from last time</a> was that the copper tape was splitting apart, which prevents it from conducting along
its full length. I initially thought I had
solved this by applying a 2nd layer of copper tape, but that turned out not to be a workable solution. I did a bunch of tests of various combinations of 50% and 75% activation position, and 1 or 2 layers of copper
tape, and found no significant correlation between either of those 2 variables and how long the switch lasts. The switches lasted between 225 presses and 330,000 presses before
failure. 7 failed by the copper tape splitting, 2 failed by the PETG spiral spring breaking (both after more than 200,000 presses), and 1 didn't seem to have any broken parts, it just wasn't reliably working any more.</p>
<p>This is the CAD model of the latest design:</p>
<p><a href="https://img.incoherency.co.uk/2749"><img src="https://img.incoherency.co.uk/2749"></a></p>
<p>The "leaf spring" has that funny shape in its bend so that it can tilt easily, which ensures that it makes reliable contact with <i>both</i> contact wires, instead of
just the first one it happens to touch.</p>
<p>And here's a slow-motion video showing how it works (a slightly earlier iteration, but the same concept):</p>
<p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/peXFqVMugO4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Also, just for fun, I did some <a href="https://incoherency.co.uk/blog/stories/freecad-fea.html">FEA</a> on the spiral spring
design, and it behaved just like the real version:</p>
<p><a href="https://img.incoherency.co.uk/2724"><img src="https://img.incoherency.co.uk/2724"></a></p>
<p>The red areas show the areas of highest stress, and indeed the springs tend to break around
the middle of the spiral.</p>
<h2>Print your own</h2>
<p>I consider this a "release candidate" rather than a finished design, because there is still
some work to do on it (in particular, I want to make it a bit less tall). But you can have it if you want it.</p>
<p>You will need:</p>
<ul>
<li>FDM 3D printer (although I'd also be interested to see results from resin printers!)</li>
<li>PETG filament. You can try other materials. PLA works but makes for a heavier feel and breaks more quickly.</li>
<li>1.0 mm diameter copper wire, 90 mm length per switch should be more than enough</li>
</ul>
<p><a href="https://incoherency.co.uk/interest/3dpswitch-rc1.tar.gz">Download the STL files</a> and arrange them on the build plate something like this (you'll probably have to rotate the spiral spring):</p>
<p><a href="https://img.incoherency.co.uk/2750"><img src="https://img.incoherency.co.uk/2750"></a></p>
<p>I suggest printing more than 1 of the "leafspring" part as it is a small part quite likely to
have defects in the print. Make sure you're printing at
a fine enough quality level to include all the features. In particular, make sure (both) the spirals on
the spring are connected all the way around, and that the leaf spring is connected all the way
along. I use the "0.15mm QUALITY" setting in PrusaSlicer. You shouldn't need any support material.
You might need to enable "detect thin walls".</p>
<p>You might need to add up to -0.3mm of X/Y size compensation. I have found that when printing
this on the Prusa Mini, optimal clearance is achieved when the 3.0 mm plunger rides inside
a 3.0 mm hole. On previous printers I've owned, this wouldn't even fit together. I'm not sure
what's going on, but obviously I modeled it to print on my machine, so you might need to apply X/Y
compensation on yours.</p>
<p><b>Step 1:</b> Print the parts. It takes about 40 minutes for me.</p>
<p><b>Step 2:</b> Clean up any stringing inside the case from the PETG. I use a lighter to burn off the worst of it,
and then a Stanley knife to trim off what remains.</p>
<p><b>Step 3:</b> Examine the spiral spring and ensure that it moves freely. You might need to cut any
stringing between the spirals with a knife, or re-print with different X/Y compensation, depending on whether it is a few small
tight spots or bad clearance all the way along.</p>
<p><b>Step 4:</b> Slide the spiral spring into the shelf at the top of the case. The orientation is not
critical, I tend to slide it in with the smoothest sides against the case just to make life easy
for myself.</p>
<p><b>Step 5:</b> Push the plunger through the top hole in the case, through the hole in the spiral
spring, and through the middle hole in the case. Verify that it moves up and down freely and that
the spring reliably returns it to the top. If not, take it back out and trim the tight spots with
a knife.</p>
<p><b>Step 6:</b> Cut off about a 13mm length of the copper wire. Slide it into the hole in the
leaf spring. If you can't get it through, you might need to widen the hole with a pin or sharp tool of
some kind. Use whatever you have.</p>
<p><b>Step 7:</b> Press the plunger down slightly to expose the attachment end inside the lower
chamber of the switch. Using a small pair of pliers or tweezers, push the attachment part of the
leaf spring onto the end of the plunger. Make sure it is pushed home. Looking in the big hole
at the bottom of the case, you should see the leaf spring roughly centred. When you let go
of the plunger, the spiral spring should still be stretched out slightly. This is desired, without
this preload the switch would start moving at 0 force.</p>
<p><b>Step 8:</b> Cut off 2x roughly 35mm lengths of copper wire. Using a pair of pliers, put a bend about
5mm from
one end. Insert the non-bent end through 1 of the wire holes and out the other side. Bend the wire
down the other side, and then in whatever direction you want your contacts to point. Repeat for
the second wire.</p>
<p>You should now have something that looks a bit like this:</p>
<p><a href="https://img.incoherency.co.uk/2752"><img src="https://img.incoherency.co.uk/2752"></a></p>
<p>And that should be it! Manually press the switch a few times and visually verify that the middle
copper wire appears to be making good contact with the other 2 wires, and then you're ready to
assemble it into a circuit! If you want it mechanically attached to a PCB, you could leave a longer
length of wire coming out of the first side, and you'd then have 4 soldering points. Otherwise,
mount it inside a 14mm square hole. You'll probably need cut-outs in the corners to accommodate
the wires sticking out, like this:</p>
<p><a href="https://img.incoherency.co.uk/2753"><img src="https://img.incoherency.co.uk/2753"></a></p>
<p>If you make one (or more!) I'd be really interested to hear your opinion on what could be designed
better, and to see pictures of your results. Email me: <a href="mailto:james@incoherency.co.uk">james@incoherency.co.uk</a>.</p>
<h2>Next steps</h2>
<p>We're getting pretty close to being able to put together a finished keyboard. I still
have the following things to do:</p>
<h3>Testing</h3>
<p>It would be good to get an accurate value for the number of presses that the switches can take. I
think currently a lot of the variability comes from the height at which the switch is positioned
relative to the tester. If it's doing 0.1mm short of a full stroke, the switch is likely to last
significantly longer than if it is being hammered 0.1mm longer than a full stroke. This is hard to
configure as I have only very coarse control of the height.</p>
<p>I watched the Linus Tech Tips tours of <a href="https://www.youtube.com/watch?v=Pu1gP4PfqCQ">the
Cherry MX factory</a> and <a href="https://www.youtube.com/watch?v=9fNiJKh6q-E">the Omron factory</a>. They're both interesting and worth watching. I took a screenshot of this testing machine in the
Omron video:</p>
<p><a href="https://img.incoherency.co.uk/2712"><img src="https://img.incoherency.co.uk/2712"></a></p>
<p>So there we have a single motor raising a platform up and down which is pressing 10 switches
at once. The platform glides on a pair of linear rails, and the exact vertical position of the press
is finely adjusted with a separate screw for each switch. The moving platform also has
a spring at each end, I am not completely sure why, I think just to take up some of its weight, to
reduce the load on the motor.</p>
<p>But this is a much better way to gang-test switches than what I have at the moment, which involves
wiring up a separate motor for each switch and gets messy quickly:</p>
<p><a href="https://img.incoherency.co.uk/2755"><img src="https://img.incoherency.co.uk/2755"></a></p>
<p>I'm past the point where more testing is critical (famous last words, I know), but it would be good
to do anyway, so I'd like to make a small-scale copy of the Omron testing machine.</p>
<h3>Switches</h3>
<p>The switch fits in a 14mm square hole (apart from the protruding wires), which is the same size
as a Cherry MX switch, but the total height from the bottom of the switch to the top of the keycap
is almost twice as large, about 45 mm vs 25 mm:</p>
<p><a href="https://img.incoherency.co.uk/2757"><img src="https://img.incoherency.co.uk/2757"></a></p>
<p>This directly translates to increased keyboard height, so it would be good to cut this down
as much as possible. I should be able to lose 2 mm from the wire support at the bottom of the switch,
and another 1 or 2 mm in the height of the leaf spring attachment, but there's no way it's going to be
as thin as the Cherry MX.</p>
<p>I'd like to find a way to add a tactile bump (ideally with a clicky noise) to the motion of
the plunger. I did try simply adding a bump to the side of the casing that would catch on the
leaf spring, but it didn't work very reliably.</p>
<h3>Keycaps</h3>
<p>Currently my keycaps are based on the one I designed in <a href="https://incoherency.co.uk/blog/cad-dojo/stories/keycap.html">my
CAD Dojo project</a>. This is suboptimal for several reasons:</p>
<ol>
<li>adding text in FreeCAD is extremely time-consuming, and it can't be edited without deleting it …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://incoherency.co.uk/blog/stories/3pct-keyboard.html">https://incoherency.co.uk/blog/stories/3pct-keyboard.html</a></em></p>]]>
            </description>
            <link>https://incoherency.co.uk/blog/stories/3pct-keyboard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748660</guid>
            <pubDate>Mon, 06 Jul 2020 15:03:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Panic! Better, Fewer, Syntax Errors for LR Parsers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23748582">thread link</a>) | @matt_d
<br/>
July 6, 2020 | https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/ | <a href="https://web.archive.org/web/*/https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

<p><strong>Abstract</strong>  
<span>Syntax errors are generally easy to fix for humans, but not for parsers in general nor LR parsers in</span>
<span>particular. Traditional ‘panic mode’ error recovery, though easy to implement and applicable to</span>
<span>any grammar, often leads to a cascading chain of errors that drown out the original. More</span>
<span>advanced error recovery techniques suffer less from this problem but have seen little practical use</span>
<span>because their typical performance was seen as poor, their worst case unbounded, and the</span>
<span>repairs they reported arbitrary. In this paper we introduce the </span><span>CPCT</span><span>+</span>  <span>algorithm, and an</span>
<span>implementation of that algorithm, that address these issues. First, </span><span>CPCT</span><span>+</span> <span>reports the complete set of</span>
<span>minimum cost repair sequences for a given location, allowing programmers to select the one that</span>
<span>best fits their intention. Second, on a corpus of 200,000 real-world syntactically invalid Java</span>
<span>programs, </span><span>CPCT</span><span>+</span>  <span>is able to repair 98.37%</span><span>±</span><span>0.017% </span><span>of files within a timeout of 0.5s. Finally,</span>
<span>CPCT</span><span>+</span> <span>uses the complete set of minimum cost repair sequences to reduce the cascading error</span>
<span>problem, where incorrect error recovery causes further spurious syntax errors to be identified.</span>
<span>Across the test corpus, </span><span>CPCT</span><span>+</span> <span>reports 435,812</span><span>±</span><span>473 </span><span>error locations to the user, reducing the</span>
<span>cascading error problem substantially relative to the 981,628</span><span>±</span><span>0 </span><span>error locations reported by panic</span>
<span>mode.</span>
</p>

<h3><span>1</span> <a id="x1-10001"></a>Introduction</h3>
<!--l. 131--><p>Programming is a humbling job which requires acknowledging that we will make untold errors in
our quest to perfect a program. Most troubling are semantic errors, where we intended the
program to do one thing, but it does another. Less troubling, but often no less irritating, are
syntax errors, which are generally minor deviances from the exacting syntax required by a
compiler. So common are syntax errors that parsers in modern compilers are designed to cope
with us making several: rather than stop on the first syntax error, they attempt to
<span>recover </span>from it. This allows them to report, and us to fix, all our syntax errors in one
go.
</p><!--l. 141--><p>When error recovery works well, it is a useful productivity gain. Unfortunately, most current
error recovery approaches are simplistic. The most common grammar-neutral approach to error
recovery are those algorithms described as ‘panic mode’ (e.g.&nbsp;[<a href="#Xholub90compilerdesign">13</a>, p.&nbsp;348]) which skip input until
the parser finds something it is able to parse. A more grammar-specific variation of this
idea is to skip input until a pre-determined synchronisation token (e.g. ‘;’ in Java) is
reached&nbsp;[<a href="#Xdegano95comparison">8</a> , p.&nbsp;3], or to try inserting a single synchronisation token. Such strategies are
often unsuccessful, leading to a cascade of spurious syntax errors (see Figure&nbsp;<a href="#x1-1018r1">1<!--tex4ht:ref: fig:javaerror --></a> for an
example). Programmers quickly learn that only the location of the first error in a file – not
the reported repair, nor the location of subsequent errors – can be relied upon to be
accurate.
</p>
                                                                            
                                                                            
<hr><div>
                                                                            
                                                                            
                                                                            
                                                                            
<div><div><table id="TBL-1"><colgroup id="TBL-1-1g"><col id="TBL-1-1"><col id="TBL-1-2"></colgroup><tbody><tr id="TBL-1-1-"><td id="TBL-1-1-1"> <!--l. 159--><!--l. 160--><p><span>(a)</span> </p> </td><td id="TBL-1-1-2"> <div><!--l. 166-->
<p><span><a id="x1-1002r1"></a></span><span>class</span><span>&nbsp;</span><span>C</span><span>&nbsp;</span><span>{</span><span>&nbsp;</span><br><span><a id="x1-1003r2"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>int</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>y</span><span>;</span><span>&nbsp;</span><br><span><a id="x1-1004r3"></a></span><span>}</span>
</p>
  </div>                         </td>
</tr><tr id="TBL-1-2-"><td id="TBL-1-2-1"> <!--l. 173--><!--l. 175--><p><span>(c)</span> </p></td><td id="TBL-1-2-2"> <div><!--l. 181-->
<p><span><a id="x1-1006r1"></a></span><span>Parsing</span><span>&nbsp;</span><span>error</span><span>&nbsp;</span><span>at</span><span>&nbsp;</span><span>line</span><span>&nbsp;</span><span>2</span><span>&nbsp;</span><span>col</span><span>&nbsp;</span><span>9.</span><span>&nbsp;</span><span>Repair</span><span>&nbsp;</span><br><span>
<a id="x1-1007r2"></a></span><span>sequences</span><span>&nbsp;</span><span>found</span><span>:</span><span>&nbsp;</span><br><span><a id="x1-1008r3"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>1:</span><span>&nbsp;</span><span>Delete</span><span>&nbsp;</span><span>y</span><span>&nbsp;</span><br><span>
<a id="x1-1009r4"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>2:</span><span>&nbsp;</span><span>Insert</span><span>&nbsp;</span><span>,</span><span>&nbsp;</span><br><span><a id="x1-1010r5"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>3:</span><span>&nbsp;</span><span>Insert</span><span>&nbsp;</span><span>=</span>
</p>
  </div>                         </td>
</tr></tbody></table></div>
</div><div><div><table id="TBL-2"><colgroup id="TBL-2-1g"><col id="TBL-2-1"><col id="TBL-2-2"></colgroup><tbody><tr id="TBL-2-1-"><td id="TBL-2-1-1"> <!--l. 195--><!--l. 197--><p><span>(b)</span> </p> </td><td id="TBL-2-1-2"> <div><!--l. 203-->
<p><span><a id="x1-1012r1"></a></span><span>C</span><span>.</span><span>java</span><span>:2:</span><span>&nbsp;</span><span>error</span><span>:</span><span>&nbsp;</span><span>’;’</span><span>&nbsp;</span><span>expected</span><span>&nbsp;</span><br><span>
<a id="x1-1013r2"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>int</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>y</span><span>;</span><span>&nbsp;</span><br><span><a id="x1-1014r3"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>^</span><span>&nbsp;</span><br><span>
<a id="x1-1015r4"></a></span><span>C</span><span>.</span><span>java</span><span>:2:</span><span>&nbsp;</span><span>error</span><span>:</span><span>&nbsp;</span><span>&lt;</span><span>identifier</span><span>&gt;</span><span>&nbsp;</span><span>expected</span><span>&nbsp;</span><br><span>
<a id="x1-1016r5"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>int</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>y</span><span>;</span><span>&nbsp;</span><br><span><a id="x1-1017r6"></a></span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>&nbsp;</span><span>^</span>
</p>
  </div>                           </td>
</tr></tbody></table></div></div><p><span>
<span>Figure</span><span>&nbsp;1:  </span></span><span><span>An example of a simple, common Java syntax error (</span><a href="#x1-1001r1"><span>a</span></a><span>) and the problems traditional</span>
<span>error recovery has in dealing with it. </span><span>javac </span><span>(</span><a href="#x1-1011r2"><span>b</span></a><span>) spots the error when it encounters ‘</span><span>y</span><span>’. Its error</span>
<span>recovery algorithm then repairs the input by inserting a semicolon before ‘</span><span>y</span><span>’ (i.e.</span><span>&nbsp;making the input</span>
<span>equivalent to ‘</span><span>int x; y;</span><span>’). This then causes a spurious parsing error, since ‘</span><span>y</span><span>’ on its own is not</span>
<span>a valid statement. The </span><span>CPCT</span><span>+</span>  <span>error recovery algorithm we introduce in this paper produces the</span>
<span>output shown in (</span><a href="#x1-1005r3"><span>c</span></a><span>): after spotting an error when parsing encounters ‘</span><span>y</span><span>’, it uses the Java grammar</span>
<span>to find the complete  set  of  minimum  cost  repair  sequences  (unlike  previous  approaches  which</span>
<span>non-deterministically find one minimum cost repair sequence). In this case three repair sequences</span>
<span>are reported to the user: one can delete ‘</span><span>y</span><span>’ entirely (‘</span><span>int x;</span><span>’), or insert a comma (‘</span><span>int x, y;</span><span>’), or</span>
<span>insert an equals sign (</span><span>‘int x = y;’</span><span>).</span>
</span></p><!--tex4ht:label?: x1-1018r1 -->
                                                                            
                                                                            
</div><hr>
<!--l. 233--><p>It is possible to hand-craft error recovery algorithms for a specific language. These
generally allow better recovery from errors, but are challenging to create. For example,
the Java error recovery approach in the Eclipse IDE is 5KLoC long, making it only
slightly smaller than a modern version of Berkeley Yacc — a complete parsing system!
Unsurprisingly, few real-world parsers contain effective hand-written error recovery
algorithms.
</p><!--l. 240--><p>Most of us are so used to these trade-offs (cheap generic algorithms and poor recovery
vs.&nbsp;expensive hand-written algorithms and reasonable recovery) that we assume them to be
inevitable. However, there is a long line of work on more advanced generic error recovery
algorithms. Probably the earliest such algorithm is Aho and Peterson&nbsp;[<a href="#Xaho72minimum">1</a>], which, upon
encountering an error, creates on-the-fly an alternative (possibly ambiguous) grammar which
allows the parser to recover. This algorithm has fallen out of favour in programming
language circles, probably because of its implementation complexity and the difficulty of
explaining to users what recovery has been used. A simpler family of algorithms, which
trace their roots to Fischer <span>et al.</span>&nbsp;[<a href="#Xfischer79locally">11</a>], instead try to find a single minimum cost <span>repair</span>
<span>sequence </span>of token insertions and deletions which allow the parser to recover. Algorithms in
this family are much better at recovering from errors than naive approaches and can
communicate the repairs they find in a way that humans can easily replicate. However, such
algorithms have seen little practical use because their typical performance is seen as
poor and their worst case unbounded [<a href="#Xmckenzie95error">17</a>, p.&nbsp;14]. We add a further complaint: such
approaches only report a single repair sequence to users. In general – and especially in
syntactically rich languages – there are multiple reasonable repair sequences for a given
error location, and the algorithm has no way of knowing which best matches the user’s
intentions.
</p><!--l. 261--><p>In this paper we introduce a new error recovery algorithm in the Fischer <span>et al. </span>family, <span>CPCT</span><span>+</span>.
This takes the approach of Corchuelo <span>et al.</span>&nbsp;[<a href="#Xcorchuelo02repairing">5</a>] as a base, corrects it, expands it, and
optimises its implementation. <span>CPCT</span><span>+</span> is simple to implement (under 500 lines of Rust
code), is able to repair nearly all errors in reasonable time, reports the complete set of
minimum cost repair sequences to users, and does so in less time than Corchuelo <span>et</span>
<span>al.</span>.
</p><!--l. 269--><p>We validate <span>CPCT</span><span>+</span> on a corpus of 200,000 real, syntactically incorrect, Java programs
(Section&nbsp;<a href="#x1-140006">6<!--tex4ht:ref: experiment --></a>). <span>CPCT</span><span>+</span> is able to recover 98.37%<span>±</span><span>0.017% </span>of files within a 0.5s timeout and does so
while reporting fewer than half the error locations as a traditional panic mode algorithm: in other
words, <span>CPCT</span><span>+</span> substantially reduces the cascading error problem. We also show – for, as far as we
know, the first time – that advanced error recovery can be naturally added to a Yacc-esque
system, allowing users to make fine-grained decisions about what to do when error recovery has
been applied to an input (Section&nbsp;<a href="#x1-180007">7<!--tex4ht:ref: sec:api --></a>). We believe that this shows that algorithms such as <span>CPCT</span><span>+</span>
are ready for wider usage, either on their own, or as part of a multi-phase recovery
system.
</p>
<h4><span>1.1</span> <a id="x1-20001.1"></a>Defining the problem</h4>
<!--l. 285--><p>Formally speaking, we first test the following hypothesis:
</p><!--l. 287--><dl><dt>
<span>H1</span></dt><dd>The complete set of minimum cost repair sequences can be found in acceptable time.</dd></dl>
                                                                            
                                                                            
<!--l. 292--><p>The only work we are aware of with a similar concept of ‘acceptable time’ is&nbsp;[<a href="#XdeJonge12natural">6</a>], who define it
as the total time spent in error recovery per file, with a threshold of 1s. We use that
definition with one change: Since many compilers are able to fully execute in less than 1s,
we felt that a tighter threshold is more appropriate: we use 0.5s since we think that
even the most demanding users will tolerate such a delay. We strongly validate this
hypothesis.
</p><!--l. 300--><p>The complete set of minimum cost repair sequences makes it more likely that the programmer
will see a repair sequence that matches their original intention (see Figure&nbsp;<a href="#x1-1018r1">1<!--tex4ht:ref: fig:javaerror --></a> for an example;
Appendix&nbsp;<a href="#x1-28000A">A<!--tex4ht:ref: app:examples --></a> contains further examples in Java, Lua, and PHP). It also opens up a new
opportunity. Previous error recovery algorithms find a single repair sequence, apply that to the
input, and then continue parsing. While that repair sequence may have been a reasonable local
choice, it may cause cascading errors later. Since we have the complete set of minimum
cost repair sequences available, we can select from that set a repair sequence which
causes fewer cascading errors. We thus rank repair sequences by how far they allow
parsing to continue successfully (up to a threshold — parsing the whole file would, in
general, be too costly), and choose from the subset that gets furthest (note that the
time required to do this is included in the 0.5s timeout). We thus also test a second
hypothesis:
</p><!--l. 315--><dl><dt>
<span>H2</span></dt><dd>Ranking the complete set of minimum cost repair sequences by how far they allow
parsing to continue locally reduces the global cascading error problem.</dd></dl>
<!--l. 321--><p>We also strongly validate this hypothesis. We do this by comparing ‘normal’ <span>CPCT</span><span>+</span> with a
simple variant <span>CPCT</span><span>+</span><span>rev</span> which reverses the ranking process, always selecting from amongst the
worst …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/">https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/</a></em></p>]]>
            </description>
            <link>https://soft-dev.org/pubs/html/diekmann_tratt__dont_panic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748582</guid>
            <pubDate>Mon, 06 Jul 2020 14:56:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Visual Comparison of macOS Catalina and Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23748563">thread link</a>) | @tomduncalf
<br/>
July 6, 2020 | https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html | <a href="https://web.archive.org/web/*/https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p><img src="https://www.andrewdenty.com/blog/assets/img/catalina-vs-big-sur.jpg" alt="Catalina vs Big Sur">
This post is an attempt to provide a visual comparison of pretty dramatic UI changes between macOS Catalina and Big Sur.</p>
<p>Why did I end up doing this? Well, this week I installed the developer beta of macOS Big Sur as I was curious what impact the new UI would have on the <a href="https://www.andrewdenty.com/airtame-desktop-app.html">app I currently design</a>. I wanted to make sure my team was ahead of any coming changes as we were burned by changes in last year’s release of Catalina.</p>
<p>I found myself taking lots of screenshots to try and track the changes and thought this might be worth sharing. I decided to carry out a quick catalogue of the UI changes as this may be helpful to other people getting ready for macOS Big Sur.</p>
<p>All of the screenshots below are taken on a default install of macOS and the Catalina version is always on the left. I made a conscious effort not to resize any windows or change any default settings. I haven’t captured everything, but it is a good taste of the changes so far.</p>
<h2 id="first-impressions">First impressions</h2>


<p>At first glance macOS is a lot more colourful with, and the biggest obvious change is the bright, slightly more cartoonish iOS shaped icons. Everything is more rounded and it feels like everything has gotten a little bigger. Could this be the first hint that macOS is preparing for touch support in the future? One interesting tidbit, is that even though the icons are based around the capsule shape, many of them (like Contacts, or Preview) have elements which protrude from them giving an extra feeling of depth.</p>
<h2 id="finder-and-preview">Finder and Preview</h2>
<p>Finder sees some significant changes. Of all the places I think Apple needs to get the new UI spot on, is Finder. Overall the default size of Finder seems to be bigger in macOS Big Sur.</p>


<p>One thing that struck me at this point is that Finder looks a mess with many of the more advanced features enabled. The bottom screenshot shows Finder with a Path Bar, Status Bar and multiple tabs. To me, it seems like the design team have not yet been able to find a way to elegantly integrate these elements into the iOS inspired UI.</p>
<p>One final thing to note is that in Finder the search bar at the top right has been replaced with a search icon that expands when clicked. This change seems a little inconsistent as it’s not made it to Preview. I can guarantee this will result in fewer people discovering Finder’s Spotlight search goodness.</p>
<h2 id="preferences">Preferences</h2>
<p>Preferences sees quite a lot of change in some areas.
The Dock preferences pane has become “Dock and Menu Bar” and now integrates controls for the new macOS control center. It uses a nicely integrated sidebar to manage different categories.</p>
<p>It’s a shame that this sidebar hasn’t yet made it to other parts of the preferences UI with Network and Notifications still using a very old looking sidebar.</p>
<p>One aspect of preferences that has been quite controversial (on Twitter at least) is the new icons. I’m going to hold off judgement for now as they don’t yet look finished. For example, the Notifications icon does not even support retina displays.</p>


<p>You’ll notice that the Startup Disk pane uses apples new dialog box UI. This is quite a departure from the existing drop-down - it feels much more iOS-like.</p>
<h2 id="menu-bar-and-notification-center">Menu Bar and Notification Center</h2>
<p>This is one of the areas where macOS has changed the most. It’s also difficult to take decent screenshots of both of these. Control Center looks like it’s been badly photocopied and the Notification Center in Catalina has a bug whereby it renders at double it’s normal width.</p>
<p>What was obvious within a few minutes of use was that the Control Center is a massive improvement on Catalina’s row of scattered Menu bar icons. The updated WiFi menu is also a massive improvement, as the old list could easily be overwhelming with the number of WiFi networks displayed.</p>
<p>I’m less convinced that the Notification Center is easier to use though. Now it has no background, there is less to separate a list of notifications from my messy desktop!</p>
<p>I will try and get better screenshots for this section and update it in the near future.</p>


<h2 id="safari">Safari</h2>





<h2 id="reminders">Reminders</h2>


<h2 id="notes">Notes</h2>
<p>The biggest news in Notes is that after years, the Skeuomorphic paper texture has finally been retired!</p>


<h2 id="photos">Photos</h2>


<h2 id="apple-music-and-podcasts">Apple Music and Podcasts</h2>
<p>Music and Podcasts were brand new last year with the release of Catalina. It’s obvious that the new UI has been planned for a while as Apple Music and Podcasts are mostly indistinguishable from their initial Catalina release. For example both apps already include the new full height sidebar.</p>
<p>For me this illustrates a bigger point that <a href="https://twitter.com/stevesi/status/1275311056672325633" target="_blank">Steven Sinofsky recently made on Twitter</a> - that Apple is executing a meticulous multi-year strategy.</p>


<p>One area where changes are evident are is in preferences windows. Both apps make use of Apple’s new accent colour and new glyph icon library.</p>
<h2 id="other-bundled-apps">Other bundled apps</h2>
<p>It was impossible to go into depth with every single bundled app. On the whole, the updates to Maps, Books and Mail all look solid with extensive use of the new sidebar.</p>


<h2 id="utilities">Utilities</h2>
<p>Both Activity Monitor and Disk Utility have received a new style toolbar. As with Finder, there are no longer any rows meaning all elements are at the same level. On first impressions, I feel this is a little visually confusing and makes it harder to scan. The search field also loses a lot of its contrast.</p>
<p>Unsurprisingly Terminal is almost unchanged.</p>



<h2 id="almost-unchanged">Almost unchanged</h2>
<p>On the subject of unchanged apps, there were a number of other apps that are so far relatively unchanged.</p>
<p>Siri in macOS Big Sur shows no apparent changes. I think this is a little strange considering the overhaul Siri is receiving in iOS 14. There don’t even seem to be any radius changes to the borders.</p>
<p>The most extreme case of no change is Stickies. It’s completely identical between both releases. What’s more, I don’t think it’s changed much since MacOS 9 judging from its weird, retro controls.</p>


<p>Boot Camp is also practically unchanged, although this is perhaps unsurprising given Apple’s move to Apple Silicon, so presumably Boot Camp’s days are numbered. It did receive a new icon though.</p>
<h2 id="takeaways">Takeaways</h2>
<p>Overall, the UI changes in macOS aren’t as dramatic as I was expecting. Big Sur’s new UI feels like a largely incremental set of changes to make macOS feel more coherent with iOS and iPad OS. Even if there are a few teething issues and the look is a little jarring at first, this has to be a good thing in the long-term.</p>
<p>Having said that, Apple still has a vast amount of work to do to perfect the new macOS UI. It unsurprising as this is the first developer beta, but there are still many rough edges.</p>
<p>I hope in the long term they focus on creating consistent patterns: for example for the first launch experience of apps. Right now there are several different layouts and approaches to this UI. I also hope Apple don’t leave pro users behind. Right now some of the less frequently used UI elements such as status bars and path bars look a little unloved. They don’t feel well integrated into the UI and in some cases lack visual separation.</p>
<p>If you’re interested in reading even more about the design changes in macOS Big Sur, Cult of Mac have <a href="https://www.cultofmac.com/715717/fantastic-fugly-all-new-app-icons-macos-big-sur/" target="_blank">a comprehensive overview of the new icons</a>.</p>
</div>
</article></div>]]>
            </description>
            <link>https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748563</guid>
            <pubDate>Mon, 06 Jul 2020 14:55:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build to learn – tame your shiny object syndrome]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23748435">thread link</a>) | @BartBoch
<br/>
July 6, 2020 | https://almostcake.com/buildToLearn.php | <a href="https://web.archive.org/web/*/https://almostcake.com/buildToLearn.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
                        It sounds simple, yet, it's challenging.<br>
<b>"Build to learn."</b><br>
It's a fantastic tool for chaotic minds.<br>
A way to benefit from your shortcomings.<br>
If you ever fell for the shiny object syndrome (chasing new cool thing, instead of focusing on the present project), then this is for you!
And the best part - you can turn it to your advantage!<br>
Turn it to build momentum, to become a better, wiser, fuller person.</p><p>

When you fell for the shiny, new, better idea, you could've gone through the guilt and growing anxiety for not finishing things.<br>
For some of us, this could end up in depression or/and quitting the whole "maker" realm.<br>
In this post, I will provide you a valid solution to make the most out of the shiny object syndrome. If you have it, at least you can get something positive out of it.<br>
The method, disguised under many names, sometimes called "build to learn," "build to fail," "ship to learn," is meant to make the most of your nature of jumping between the projects.<br>
It's also a way for you to grow as a builder and founder.</p><p>

I first started flirting with the idea independently - then, I found out that there is a micro-movement of sorts doing the same.<br>
Two main places are hubs for this, New York and Silicon Valley. Only there you could try to hack success and look for possible anomalies to benefit from, and still get support from your social circles!<br>
It's evident that financial capital (New York) is much less flexible about it (cross the border and you are gone) than Silicon Valley (cross the border, let's hire him, he might know something we don't).<br>
And then, culture and social conveniences are limiting this movement elsewhere, causing people to quit.<br>
Sadly - if you are from outside of those areas - how can you explain to people around that success is not your goal, and failure is acceptable?<br>
It's easy to treat people trying this method like fakes or daydreamers.<br>
When you go to college and spend 3-5 years learning, then you are a smart person.<br>
If you do the same, but in real life, you might be seen as an outsider.</p><p>

Let's get to the point, though!<br>
The idea is quite simple but might be tricky to pull it off.<br>
It's based on you abandoning the goal of achieving success while focusing on educational aspects.<br>
To create projects that you will stretch and experiment to gain knowledge with a slight chance of success.<br>
So next time you see great opportunity, instead of wondering how you can ride it to the top, wonder what you can get out of it short term.<br>
Will it give you more knowledge?<br>
If so, then how?<br>
Is it worth "educational" wise?<br>
Will you learn new tech/marketing/business knowledge that would be difficult to obtain otherwise?</p><p>

The worst part of working on a project and then quitting it is to get nothing from it.<br>
Sure, we can read a lot of post-mortems, but many say the same things. They ignore the whole process and often end up in a cliche, like "a startup doing exactly this opened at the same time."<br>
And how can you learn from reading the same things over and over?<br>
Going through the process while closely observing everything that happens is key to extensive experience.<br>
Practical knowledge always beats the theoretical.</p><p>

"Build to learn" is about being practical - using theory as a ground, and then build using practical knowledge.<br>
But instead of building a castle, or a palace, we create a set of small constructions first to learn the basics.<br>
Once we can handle the basics, we move to more advanced stuff.<br>
Sooner or later, we will be building the mentioned castles!<br>
If you think you might end up building dozens of projects in search of your success story, you might accept that instead of lying to yourself, and get the most of it.<br>
There is nothing worst than wasting your talents on something meaningful.<br>
Try to push forward; you might finally realize what your real goal is. What's behind your deepest intentions.</p><p>

"Build to learn" is meant to fuel your creativity, not to kill it.<br>
The first step of it is to put a clear goal:<br>
"I build this to learn."<br>
Assume that trophies and achievements are secondary goals.<br>
After all, every major player like Mark Zuckerberg, Steve Jobs, or Richard Branson started with small projects (sometimes failing), then used the knowledge to build something big!</p><p>

Force yourself to break your ego-infused box and look outside of it, to see what are real reasons for you to fail. Learn and keep trying to understand the events happening around you.<br>
You might find out the shortcomings that were unnoticeable!</p><p>

With this reasoning, don't be afraid to keep trying (as long as you won't bet everything on it). Fail, embrace the knowledge you get from it, grow your own self, and be a better person.<br>
Don't fall in the trap of glorifying the failures though - praise the experience instead.<br>
Don't build another shiny project to be the next unicorn company. When you are ready to make the next big thing, you'll know it (and feel it). There will be no guessing, no wondering (at least in the way you see now). There will be calculation and logic behind it.</p><p>

<b>"Experience is simply the name we give our mistakes."</b> - Oscar Wilde.</p><p>

World culture is critical of repeatable failure, even for a good cause.<br>
Fail once - at least you tried, fail twice - you are a fool.<br>
The social pressure is probably the most challenging part of this method.<br>
If success (or at least how people perceive success) is not achieved, you will be labeled as an outsider or even a loser.<br>
Missing a common goal (becoming wealthy) is perceived as an overall failure.<br>
You cannot really translate the perception of failure to make it look normal.<br>
You risk getting your close ones to be skeptical and even cynical of your journey. In extreme cases, I know situations where close circles would turn aggressive against the "rule breaker."<br>
The more "failures" you "achieve," the more negative the overall attitude of the society around you will be.<br>
It's not an easy road, but it's fruitful, to say the least.<br>
You can achieve a level of understanding, where you will see ALL the mechanics behind the money-making machinery.</p><p>

There are some risks when doing this method (as with everything).<br>
Do it for not long enough, and you can get overconfident and biased.<br>
Do it for longer than you should, and you will need months to get out from the trap of setting yourself impossible challenges.<br>
Out of around dozens of people following this method (that I knew directly that is, I assume there are thousands globally), only a few completed it.<br>
Some of them quit due to social pressure (even from their partners). They still got something out of it, and all but one run a small business now (they are unable to scale/grow though).<br>
The rest created profitable companies, often one of the key players in their industry.<br>
From the original group, I was the one that took the longest to complete the road. This is because of the opportunity given to me. My partner was studying, so I did not need to focus on sorting our life as of yet. And I felt that I needed to learn more (programming, viral growth) and to make sure that my ego is under control. I needed more time because my whole life was bumpy, and I thought that some scars could affect my business sense.<br>
I did miss a deadline, though, where I could complete this process without the substantial side-effects.<br>
I knew from conversations with others that by doing this method for too long, you would need to unwind. I thought it would take 2-3 months, but I am in my 9th month, and I feel that I need 2-3 more. Don't get me wrong, I still make money online, but focusing on a small project that's growing slowly is critical to prepare myself mentally for starting massive projects.<br>
I am working on <b>Almost <span>Cake</span></b>, which quickly turned into my full-time job.<br>
<b>Almost <span>Cake</span></b> is a reanimation of one of my old build-to-learn projects that performed well. This is another excellent part of this method - you have a set of field-tested projects, where some might prove to be moneymakers.</p><p>

It took me a few years, and over 30 projects completed to get where I am now, but as said, I did the extreme version of it.<br>
One of the guys that now run a massive operation did 4 "build to learn" projects and spent 1,5 year before he moved ahead (he had some business background though).<br>
Another person with no business experience and with no business-oriented parents completed it with 7 projects and 3 years. He now runs a company that's one of the USA's leading players in his niche.<br>
So, it's hard to say how long you need this run, but the timeframe should not be of the importance here.<br>
The whole point of this method is to tame yourself and start getting somewhere with yourself.</p><p>

The key concerns of "build to learn" are:<br>
-Can you finish the project before you get bored of it? Don't invest in long term projects, when you have a track of abandoning them. You don't need to ship the product or make thousands of dollars. Focus on your initial goals first.<br>
-Can you determine small goals before starting to work on the product? Can you identify a few realistic things you want to get out of this project?<br>
-Will working on this project help you to move forward in a space you want to? If you will learn things you don't feel you need, then maybe it's better to focus elsewhere for now.<br>
-Do you really need to work on the project, or should you turn around and do something completely different? Something that is far beyond your comfort zone?<br>
-Do you have significant chances of achieving your goals with this project? Try not to pursue goals that you assume you will fail. You need to take care of your mental health and not put to much strain on it.</p><p>

Using the "build to learn" method should not become an excuse for you failing to ship. Either you build to learn, or you build to achieve something. You should never go in the middle of the project and say, "just kidding, I was doing it to learn."</p><p>

Sure, if you are already in the middle of the project, then change your goals. But don't do this for future …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://almostcake.com/buildToLearn.php">https://almostcake.com/buildToLearn.php</a></em></p>]]>
            </description>
            <link>https://almostcake.com/buildToLearn.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748435</guid>
            <pubDate>Mon, 06 Jul 2020 14:44:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop using utcnow and utcfromtimestamp (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23748239">thread link</a>) | @gilad
<br/>
July 6, 2020 | https://blog.ganssle.io/articles/2019/11/utcnow.html | <a href="https://web.archive.org/web/*/https://blog.ganssle.io/articles/2019/11/utcnow.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="content">
  <article>
    
    <div><!-- Early draft reviewed by Mahmoud Hashemi -->
<p>If you are the kind of developer who prefers to work in UTC, you may have seen Python's <tt>datetime.utcnow()</tt> and <tt>datetime.utcfromtimestamp()</tt> methods and thought, "Ah, yes, this is what I should do to work in UTC!" But alas, this is <em>not</em> the best way to work with UTC datetimes. In fact I would say that it is <em>extremely</em> rare that you would want to use either of these functions. Consider the following dangerous code:</p>
<div><pre><span></span><span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span>
<span>ts</span> <span>=</span> <span>1571595618.0</span>
<span>x</span> <span>=</span> <span>datetime</span><span>.</span><span>utcfromtimestamp</span><span>(</span><span>ts</span><span>)</span>
<span>x_ts</span> <span>=</span> <span>x</span><span>.</span><span>timestamp</span><span>()</span>

<span>assert</span> <span>ts</span> <span>==</span> <span>x_ts</span><span>,</span> <span>f</span><span>"{ts} != {x_ts}"</span>
</pre></div>
<p>When executed with your system locale set to UTC, this will succeed just fine, but when executed in any locale where the offset at that particular timestamp is something <em>other</em> than 0, the assertion fails — for example when executed with an <tt>America/New_York</tt> locale, you'll get <tt>AssertionError: 1571595618.0 != 1571610018.0</tt>.</p>
<p>This is due to an unfortunate quirk of history and a subtle shift in what it means for a datetime to be naive that took place in the Python 2 to 3 transition. I imagine that these functions would not exist if the <tt>datetime</tt> library were redesigned today, but at the moment there are a mix of harmful and harmless uses of them out there, and it's not a simple matter to rip them all out. <a href="#pytz-familiar" id="id1">[1]</a></p>
<p>Rather than make you stick around for a history lesson as to why this problem exists, I'm going to spoil the ending and say that the right thing to do is to pass a UTC object to the <tt>tz</tt> parameter of <tt>now()</tt> and <tt>fromtimestamp()</tt>, respectively, to get a <em>time zone-aware</em> datetime:</p>
<div><pre><span></span><span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span><span>,</span> <span>timezone</span>
<span>ts</span> <span>=</span> <span>1571595618.0</span>
<span>x</span> <span>=</span> <span>datetime</span><span>.</span><span>fromtimestamp</span><span>(</span><span>ts</span><span>,</span> <span>tz</span><span>=</span><span>timezone</span><span>.</span><span>utc</span><span>)</span>
<span>x_ts</span> <span>=</span> <span>x</span><span>.</span><span>timestamp</span><span>()</span>

<span>assert</span> <span>ts</span> <span>==</span> <span>x_ts</span><span>,</span> <span>f</span><span>"{ts} != {x_ts}"</span>  <span># This assertion succeeds</span>
</pre></div>
<div id="naive-datetimes-as-local-time">
<h2>Naive datetimes as local time</h2>
<p>When originally conceived, naive datetimes were intended to be abstract, not representing any specific time zone, and it was up to the program to determine what they represent — this is no different from abstract numbers which can represent mass in kilograms, distance in meters or any other specific quantity according to the programmer's intention. By contrast <em>aware</em> datetimes represent a specific point in time in a specific time zone. Awareness of the datetime's time zone allows you to do things like <a href="https://blog.ganssle.io/articles/2018/02/aware-datetime-arithmetic.html">arithmetic</a> and <a href="https://blog.ganssle.io/articles/2018/02/a-curious-case-datetimes.html">comparison</a> between time zones, conversion to other time zones and other operations which require a concrete datetime.</p>
<p>In Python 3, two things have changed that make <tt>utcnow</tt> unnecessary and, in fact, dangerous. The first is that a concrete time zone class, <tt>datetime.timezone</tt>, was introduced, along with a constant UTC object, <tt>datetime.timezone.utc</tt>. With this change, you now have a clear and unambiguous way to mark which of your datetimes are in UTC without bringing in third party code or implementing your own UTC class.</p>
<p>The change that made <tt>utcnow</tt> <em>dangerous</em> is that naive datetimes underwent a subtle shift in meaning: for certain operations that require interpreting a <tt>datetime</tt> as a fixed point in time, rather than throwing an error they would instead assume that the <tt>datetime</tt> represents the current system local time zone. So in Python 2, operations like <tt>astimezone()</tt> will raise an exception when called on a naive datetime:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span>
<span>&gt;&gt;&gt;</span> <span>from</span> <span>dateutil</span> <span>import</span> <span>tz</span>
<span>&gt;&gt;&gt;</span> <span>datetime</span><span>(</span><span>2015</span><span>,</span> <span>5</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>astimezone</span><span>(</span><span>tz</span><span>.</span><span>UTC</span><span>)</span>
<span>Traceback</span> <span>(</span><span>most</span> <span>recent</span> <span>call</span> <span>last</span><span>):</span>
  <span>File</span> <span>"&lt;stdin&gt;"</span><span>,</span> <span>line</span> <span>1</span><span>,</span> <span>in</span> <span>&lt;</span><span>module</span><span>&gt;</span>
<span>ValueError</span><span>:</span> <span>astimezone</span><span>()</span> <span>cannot</span> <span>be</span> <span>applied</span> <span>to</span> <span>a</span> <span>naive</span> <span>datetime</span>
</pre></div>
<p>but in Python 3 it will use your system's locale (on my machine it's <tt>America/New_York</tt>) and convert accordingly:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span>
<span>&gt;&gt;&gt;</span> <span>from</span> <span>dateutil</span> <span>import</span> <span>tz</span>
<span>&gt;&gt;&gt;</span> <span>datetime</span><span>(</span><span>2015</span><span>,</span> <span>5</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>astimezone</span><span>(</span><span>tz</span><span>.</span><span>UTC</span><span>)</span>
<span>datetime</span><span>.</span><span>datetime</span><span>(</span><span>2015</span><span>,</span> <span>5</span><span>,</span> <span>1</span><span>,</span> <span>4</span><span>,</span> <span>0</span><span>,</span> <span>tzinfo</span><span>=</span><span>tzutc</span><span>())</span>
</pre></div>
<p>This is why the example that I started this post off with fails. The <tt>.timestamp()</tt> method gives a representation of a <em>fixed point in time</em>, not a point on the calendar; it returns <a href="https://en.wikipedia.org/wiki/Unix_time">Unix time</a>, which is the number of seconds since 1970-01-01T00:00:00 UTC, and if you call it on a naive datetime, Python will assume that that datetime represents your machine's local time, even if you originally intended it to be UTC.</p>
</div>
<div id="conclusions">
<h2>Conclusions</h2>
<p>Even without the change in Python's model of what a naive datetime means, I would still recommend that you not use <tt>utcnow()</tt> or <tt>utcfromtimestamp()</tt> simply because it's the wrong abstraction: to do so would be to represent a concrete point in time as an <em>abstract</em> datetime. <a href="#now-concrete" id="id2">[2]</a> You know that your datetime represents UTC, and it's easy to mark that clearly in Python, so there's very little reason <em>not</em> to do it. As it says in the warning recently added to <a href="https://docs.python.org/3/library/datetime.html#datetime.datetime.utcnow">the documentation</a>, you should prefer to use <tt>now</tt> in place of <tt>utcnow</tt> and <tt>fromtimestamp</tt> in place of <tt>utcfromtimestamp</tt>, so replace:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>dt_now</span> <span>=</span> <span>datetime</span><span>.</span><span>utcnow</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>dt_ts</span> <span>=</span> <span>datetime</span><span>.</span><span>utcfromtimestamp</span><span>(</span><span>1571595618.0</span><span>)</span>
</pre></div>
<p>with</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>from</span> <span>datetime</span> <span>import</span> <span>timezone</span>
<span>&gt;&gt;&gt;</span> <span>dt_now</span> <span>=</span> <span>datetime</span><span>.</span><span>now</span><span>(</span><span>tz</span><span>=</span><span>timezone</span><span>.</span><span>utc</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>dt_ts</span> <span>=</span> <span>datetime</span><span>.</span><span>fromtimestamp</span><span>(</span><span>1571595618.0</span><span>,</span> <span>tz</span><span>=</span><span>timezone</span><span>.</span><span>utc</span><span>)</span>
</pre></div>
<p>or the equivalent using positional arguments.</p>
<p>One last thing to note: the reason that we cannot simply change <tt>utcnow()</tt> into an alias for <tt>now(timezone.utc)</tt> in the standard library is that would change the semantics of how those datetimes are treated by their consumers (and as such it would not be backwards-compatible). You should keep this in mind when converting over old code that uses <tt>utcnow</tt> and <tt>utcfromtimestamp</tt> — you will need to make sure that any code that consumes your datetimes is expecting an aware datetime. In my experience, this is not a high bar to clear, but you probably don't want to just do a search-and-replace on untested code before deploying to production and leaving work for the weekend.</p>
</div>

</div>
  </article>
</section>


    </div></div>]]>
            </description>
            <link>https://blog.ganssle.io/articles/2019/11/utcnow.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748239</guid>
            <pubDate>Mon, 06 Jul 2020 14:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Addio Redis, I'm leaving Redis Labs]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23748190">thread link</a>) | @kristoff_it
<br/>
July 6, 2020 | https://kristoff.it/blog/addio-redis/ | <a href="https://web.archive.org/web/*/https://kristoff.it/blog/addio-redis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Thanks Antirez for the code, the Redis manifesto, and for the free karma especially.</p><div><p>Last week I resigned from my position as developer advocate at Redis Labs.</p>
<p>I’ve never talked much about Redis on this blog because I made a point of trying to write interesting posts about different topics, and also to avoid any form of conflict of interest: I didn’t want people to think this blog was being used as a marketing outlet by Redis Labs.</p>
<p>Now that I’m not with the company anymore, I’m looking forward to sharing some of my thoughts on open-source software and related topics, using the direct and energetic tone that I always employ here. </p>
<p>This was the first job I took that wasn’t strictly about programming. It taught me a lot about communication, how information flows between groups of people, and how companies try to shape that flow.</p>
<p>While Redis Labs as a company isn’t perfect — I wouldn’t have left otherwise, and it wouldn’t have hired me in the first place, as I’m not perfect either — I’m happy with my experience overall. The one regret I have is that my position was in part meant to help the community better understand Redis, and I’m leaving behind me basically the same level of confusion that was there when I joined 1.5 years ago.</p>
<p>Redis is less obvious to describe than other tools in the same space, but that alone is not enough to explain why no one seems to agree on what Redis is good at, or what even is Redis. To me, the current situation seems caused by an ongoing turf war between tech companies, starting from the direct competitors of Redis Labs, up to the Cloud giants, who see themselves as the ultimate gatekeepers of modern software architecture.</p>
<p>Each of these factions wants Redis to be a different thing, and so they spend their budget accordingly, starting from developer advocates like me, up to de-facto astroturfers that I’ll leave unnamed. While you and I, dear reader, are surely immune to marketing and scummy tactics, those techniques do work wonders on the public, and the strength of true statements is only used as a way of making marketing spend more efficient.</p>
<p>This is where I imagined I would spell out my take on Redis, but <a href="http://antirez.com/news/133" target="_blank" rel="nofollow noopener noreferrer">now that Antirez has left the project</a>, it doesn’t matter anymore. Whatever Redis is going to be in the future, it will be shaped by sales tactics, whatever the Clouds are going to do next, and other uninspired metrics.</p>
<p>Since this is my goodbye post to Redis, let me add an over-the-top Italian skit before jumping into the lessons learned.</p>
<h2 id="if-redis-were-pasta"><a href="#if-redis-were-pasta" aria-label="if redis were pasta permalink"></a>If Redis were pasta</h2>
<p>If Redis were pasta, it would be served in a restaurant called Salvatore’s. It would be a plate of spaghetti with tomato sauce and a single leaf of basil on top; basically the Italian symbol for a simple, versatile meal. </p>
<p>Big tech would be like McDonald’s and Burger King: convinced that the future of nutrition is fast-food and constantly screaming that Redis can’t be considered a real meal as it doesn’t contain any bacon: “Come eat our new burger, which now contains an extra 4th layer of meat, exquisitely designed to make it easier to digest the meal!”</p>
<p>On a table you would find Jepsen, essentially the equivalent of Yelp, ideally meant to keep restaurants honest, generally correct, but ultimately not that different from other tech companies, and thus well deserving of <a href="https://www.youtube.com/watch?v=pDlR_ccnZww" target="_blank" rel="nofollow noopener noreferrer">boogers and cum</a>.</p>
<p>Antirez, largely preferring cooking over serving, would end up selling the restaurant to the waiters, who at that point would make their priority to turn the restaurant into an Olive Garden.</p>
<h2 id="lessons-learned"><a href="#lessons-learned" aria-label="lessons learned permalink"></a>Lessons learned</h2>
<p>So where’s the Redis community in this story? Well, those are just the silent, mostly anonymous regulars that come, eat, and then go on with their lives. </p>
<p>It’s the people that occasionally show up on HN and point out that they’re happy with what Redis does for them, and that they rarely think about it even, as the software tends to chug along nicely. As much as I sympathize with them, the ultimate lesson I learned is that a passive community will inevitably lead to the death of a project.</p>
<p>While the “<a href="https://news.ycombinator.com/item?id=23690123" target="_blank" rel="nofollow noopener noreferrer">spontaneus software</a>” world is busy infighting, big tech is systematically strip-mining it of any value, even when 99% of the value gets lost in the process. Tech companies are willing to go to any length to capture that 1%, and over time have learned to use Free software arguments against Free software itself, to ensure nobody would stop them.</p>
<p>The future of what we call today open-source software needs to learn to be in equal parts principled and pragmatic. The principles of human spontaneity must be preserved, to ensure we don’t turn in yet another fast-food chain, but we must understand that sophisticated ethical arguments require an equally sophisticated infrastructure beneath them, as without the latter the former can’t materialize into reality.</p>
<p>We need to keep our communities as much as possible engaged and invested in the success of our projects. The flow of information must be kept open and at high pressure, to ensure that our values and goals are well-understood by the majority of the community. Failing to do that means becoming servants of large donors and opening the community to all kinds of manipulations.</p>
<p>We need to reinvent the way we approach spontaneous collaboration in software and we must understand that it’s not going to be a peaceful process. Maybe it’s my native-american blood talking, but I feel I’m ready to get up close and personal with the world I dealt with for the last 1.5 years, except this time I won’t be wearing formal attire.</p>
<p><strong>I’m joining the Zig Software Foundation as VP of Community and it’s going to be my honor and pleasure to try to make all of this a reality for at least one project.</strong> If you want to follow us on this journey, <a href="https://zig.show/" target="_blank" rel="nofollow noopener noreferrer">join us Saturday 11th on Twitch for the live announcement and first fundraising</a>. It’s going to be fun and, if we hit the corresponding donation goal, I will reveal my (until now) secret recipe for a nice summer pasta. Not as simple as Salvatore’s, but pretty good nevertheless.</p>
<p>You can find more info at <a href="https://zig.show/" target="_blank" rel="nofollow noopener noreferrer">https://zig.show</a>.</p>
<figure>
    <span>
      <a href="https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/fb329/IMG_5653.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/f5e3c/IMG_5653.webp 100w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/f2fbe/IMG_5653.webp 200w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/e227a/IMG_5653.webp 400w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/965c5/IMG_5653.webp 600w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/0cbce/IMG_5653.webp 800w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/34ef4/IMG_5653.webp 1920w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/5fb09/IMG_5653.jpg 100w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/f544b/IMG_5653.jpg 200w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/41689/IMG_5653.jpg 400w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/82472/IMG_5653.jpg 600w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/a296c/IMG_5653.jpg 800w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/fb329/IMG_5653.jpg 1920w" sizes="(max-width: 400px) 100vw, 400px" type="image/jpeg">
        <img src="https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/41689/IMG_5653.jpg" alt="A photo I took at the last AWS reinvent." title="Fuck you AWS.">
      </picture>
  </a>
    </span>
    <figcaption>Fuck you AWS.</figcaption>
  </figure></div></div>]]>
            </description>
            <link>https://kristoff.it/blog/addio-redis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748190</guid>
            <pubDate>Mon, 06 Jul 2020 14:23:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Berkshire Hathaway sitting on $137B in cash?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23747918">thread link</a>) | @sunnykgupta
<br/>
July 6, 2020 | https://eachlist.com/why-is-berkshire-hathaway-sitting-on-137-billion-in-cash/ | <a href="https://web.archive.org/web/*/https://eachlist.com/why-is-berkshire-hathaway-sitting-on-137-billion-in-cash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>Think finance and Mr. Buffet is one of the first names that comes to mind. Warren Buffet has had humble beginnings, his life changed drastically with an impulsive takeover of the Berkshire Hathaway Inc.</p>



<p>If you aren’t aware of the history behind Buffet’s reasoning behind acquiring Berkshire, it is worth reading and marvelling over.</p>



<p>Over the course of next few decades, Warren Buffet went on to take the company to new highs. In 2019, the company reported having more than 817 Billion USD in assets. </p>



<p>The most surprising part for avid investors though, has been the fact that Berkshire Hathaway has north of $137 Billion in cash and cash reserves!</p>



<p>That is a lot of cash to keep in had, especially when the markets seem to be going up. Most recently in May 2020, they exited almost all their holdings in the airline industry netting them about $6 Billion.</p>



<p>Does that mean Berkshire thinks the markets are overvalues and hyped at the moment? It is not very clear.</p>



<p><strong>UPDATE:</strong> As we were about to publish this article, we got a notification about <a href="https://eachlist.com/buffets-10-billion-bet-on-dominion-energy-inc/">Berkshire’s largest deal in 4 years – the $10 Billion bet on Dominion Energy.</a></p>

</div></div>]]>
            </description>
            <link>https://eachlist.com/why-is-berkshire-hathaway-sitting-on-137-billion-in-cash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747918</guid>
            <pubDate>Mon, 06 Jul 2020 14:01:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Pyret Code; or a Rationale for the Pyret Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747849">thread link</a>) | @todsacerdoti
<br/>
July 6, 2020 | http://pyret.org/pyret-code/index.html | <a href="https://web.archive.org/web/*/http://pyret.org/pyret-code/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <!-- Main column -->
        <div id="content">






          <div>
          
          <div>

          

          <p>We need better languages for introductory computing. A good introductory language makes good compromises between expressiveness and performance, and between simplicity and feature-richness. Pyret is our evolving experiment in this space.</p>

          <h3 id="why-not-just-use-java-python-racket-ocaml-or-haskell">Why not just use Java, Python, Racket, OCaml, or Haskell?</h3>

          <p>One of the enduring lessons from the Racket project is that <em>no full-blown, general-purpose programming language</em> is particularly appropriate for introductory education. By the time a language grows to be useful for building large-scale systems, it tends to have accumulated too many warts, odd corners, and complex features, all of which trip up students. The <a href="http://cs.brown.edu/~sk/Publications/Papers/Published/fffkf-drscheme-journal/">journal paper for DrScheme</a>  (the old name for DrRacket) explains this in some detail.</p>

          <p>In that respect, the closest fellow travelers of us Pyreteers are the Racketeers (see how that works?). In fact, the first version of Pyret was merely a <code>#lang</code> in Racket. Nevertheless, Pyret represents a departure from Racket (for now and for the near future, at least) for several reasons:</p>

          <ul>
           <li>
            <p>We wanted to experiment with syntax. Much as many of us love  parentheses, we fear that Racket will always bump into an acceptance  threshold due to its syntax. We’re delighted to see the growing  adoption in industry of languages like Racket and Clojure, and maybe  the days of paren-phobia are over. But academics are far more  hidebound than industrial programmers!</p></li>
           <li>
            <p>We wanted to build a really great run-time system for the Web browser. Going through Racket and  <a href="http://cs.brown.edu/~sk/Publications/Papers/Published/yk-whalesong-racket-browser/">Whalesong</a>  proved to be a non-starter in terms of performance, and Racket has  many features that make an efficient implementation on today’s  JavaScript very hard. Building a native JavaScript implementation  was the only option we could see. Over time, as technology changes,  this could change.</p></li>
           <li>
            <p>Though our pedagogy draws from and is very similar to that of the  Racketeers, it also diverges in some ways, reflecting the somewhat  different backgrounds and preferences of team. Pyret embodies <em>our</em>  educational philosophy. We felt we could more easily experiment if  we had a clean-slate design than if we had to keep fitting our work  into the constraints of Racket.</p></li>
           <li>
            <p>Ultimately, Racket’s <code>#lang</code> facilities, though designed to create  new languages—and a great prototyping ground for Pyret—proved to not  be quite enough to support a language creation process of the scale  of Pyret; and the need for a strong Web run-time system also meant  that we did not get enough out of the Racket ecosystem.  Nevertheless, that only represents the state of systems today; if  someday the two grew closer together, many or all of us would  rejoice.</p></li></ul>

          <h3 id="will-pyret-ever-be-a-full-fledged-programming-language">Will Pyret ever be a full-fledged programming language?</h3>

          <p>Yes.</p>

          <p>First of all, Pyret is much more powerful than you might realize. Pyret is already fully-fledged enough to self-host its compiler, which is a non-trivial and realistic challenge. What that means is, when you run Pyret in your browser, it loads JavaScript code that implements a Pyret-to-JavaScript compiler (i.e., it compiles the Pyret you type into JavaScript and runs it in the browser). This compiler was produced by the Pyret-to-JavaScript compiler by compiling the Pyret-to-JavaScript compiler. Take a look at the compiler’s <a href="https://github.com/brownplt/pyret-lang/">bootstrapping phases</a> to get a sense of its sophistication.</p>

          <p>Second, underneath Pyret is a very powerful run-time system based on over a decade of research. You don’t see it as a user of the language, and that’s the point. Many other languages expose the crippling limitations of JavaScript’s run-time to users (e.g., can’t halt a long-running computation, can’t yield control to the event loop, etc.). These languages effectively let <em>the medium become part of the message</em>, whereas we believe programmers — especially early-stage student programmers — should not have to confront these complexities, which are irrelevant to (and often significantly interfere with) the material they are trying to learn. Imagine if other languages said, “We’d love to give you function calls, but your machine’s instruction set doesn’t contain them, so we can’t — sorry!” Yet they do the equivalent when it comes to giving you control over your computation on top of JavaScript. In contrast, Pyret is uncompromising.</p>

          <p>Third, if you want to teach a media-rich curriculum, you actually need a pretty full-featured language at least under the hood. For instance, Pyret’s built-in support for reactive programming requires a much more sophisticated run-time system — and corresponding language features — than one that didn’t offer this at all or just punted to JavaScript for this support. (Essentially, event-loops are first-class entities in the language.) We just haven’t emphasized these features when talking about Pyret, focusing instead on the curriculum they support.</p>

          <p>Broadly, we view <em>building an awesome teaching language</em> as a useful design discipline that necessarily entails all the features typically expected of a mature language. When building a language, you’re constantly confronted with questions: what to do next, how to do it, and whether to do it at all. Language designers therefore need a mental framework that guides their choices. For some, it might be “Build an awesome language for shared-memory concurrency!” For others it might be “Build an awesome language for writing scientific computations very, very concisely!” For us, it’s “Build an awesome teaching language!” So whenever we’re confronted with a design (or implementation) choice, we first ask how it would play out <em>in this specific context</em>. Then we ask how it would impact our long-term goal. We have yet to find actual contradictions between the two, but it’s certainly re-ordered priorities.</p>

          <h3 id="there-are-lots-of-kinds-of-education">There are lots of kinds of “education”.</h3>

          <p>That’s right. We are focused on introductory programming education at a high-school and collegiate level — what is often called “CS 1” and “CS 2” (roughly, the first year of college). Pyret is being actively <em>used</em> in everything from high-schools to upper-level collegiate courses, giving us a tight feedback loop.</p>

          <p>Of course, even in that setting there are differences of opinion about what needs to be taught. Some believe inheritance is so important it should be taught early in the first semester. We utterly reject this belief (as someone once wisely said, “object-oriented programming does not scale down”: what is the point of teaching classes and inheritance when students have not yet done anything interesting enough to encapsulate or inherit from?). Some have gone so far as to start teaching with Turing Machines. Unsurprisingly, we reject this view as well.</p>

          <p>What we do not take a dogmatic stance on is exactly how early state and types should be introduced. Pyret has the usual stateful operations. We discussed this at some length, but eventually decided an introduction to programming <em>must</em> teach state. Pyret also has optional annotations, so different instructors can, depending on their preference, introduce types at different times.</p>

          <h3 id="what-are-some-ways-the-educational-philosophy-influences-the-language">What are some ways the educational philosophy influences the language?</h3>

          <p>Pyret is driven by the <a href="http://www.htdp.org/"><em>How to Design Programs</em></a> (HtDP) philosophy of programming education; one could almost view it as a language designed to make teaching from HtDP comfortable. However, we also have our own curricular ideas that extend or run parallel to those of HtDP, which we are steadily writing up in <a href="http://papl.cs.brown.edu/"><em>Programming and Programming Languages</em></a> (PAPL). PAPL both exclusively uses Pyret and is slowly turning into a definitive book for teaching with it.</p>

          <p>Some of our central ideas include:</p>

          <ul>
           <li>
            <p>Languages should offer a rich set of values. For instance, images  should be primitive values, fully supported by the environment. This  improves the teaching of several things, from image-based  composition exercises (which are often far more interesting than  composition over numbers) to animations and games.</p></li>
           <li>
            <p>Languages should offer syntactic support for as much as possible of  the HtDP design recipe. (Pyret does not offer explicit support for  templates, but then again we’re rethinking the pedagogy of the  template step.)</p></li>
           <li>
            <p>Design recipe support includes good data definition primitives, including  the expression of invariants. Therefore, Pyret has support for refinements  (which are currently checked dynamically; a future version may add static  support, but this is not our highest priority). In particular, by allowing  algebraic datatypes to also be objects, Pyret offers significant flexibility  and expressiveness.</p></li>
           <li>
            <p>Students should be able to easily write examples as a precursor to  writing code. In this regard, Pyret borrows but (we believe) syntactically  improves upon Racket’s <code>check-expect</code> family of operations with <a href="https://www.pyret.org/docs/latest/testing.html">examples and  testing</a>.</p></li>
           <li>
            <p>Students should easily be able to escalate from simple examples to  sophisticated testing, such as writing test oracles.</p></li>
           <li>
            <p>Equality is subtle and languages should respect its nuances.  Students must understand the meaning of equality and its  consequences, especially with regard to observations in the presence  of state. Therefore, Pyret has carefully developed  <a href="https://www.pyret.org/docs/latest/equality.html">equality primitives</a>.</p></li></ul>

          <h3 id="is-pyret-also-a-research-project">Is Pyret also a research project?</h3>

          <p>Yes and no.</p>

          <p>Yes in that, broadly speaking, we view what we are doing as very much a research effort. We have specific, novel goals in mind (some of which we’ve described elsewhere in this document), and finding good solutions to achieve those goals will require innovation. This is the very essence of research. Some of that research is on the curricular side, though, and may not require any language innovation. Indeed, as much as possible we want …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://pyret.org/pyret-code/index.html">http://pyret.org/pyret-code/index.html</a></em></p>]]>
            </description>
            <link>http://pyret.org/pyret-code/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747849</guid>
            <pubDate>Mon, 06 Jul 2020 13:54:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Satellite – Second Epoch]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747845">thread link</a>) | @cameron_b
<br/>
July 6, 2020 | https://satellite.earth/pub/@sbowman:welcome-to-the-second-epoch | <a href="https://web.archive.org/web/*/https://satellite.earth/pub/@sbowman:welcome-to-the-second-epoch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://satellite.earth/pub/@sbowman:welcome-to-the-second-epoch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747845</guid>
            <pubDate>Mon, 06 Jul 2020 13:53:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dlang for JavaScript Developers – Functions and Control Flow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747652">thread link</a>) | @crazypython
<br/>
July 6, 2020 | https://crazypython.github.io/CrazyPython/dlangforjsdevs.html | <a href="https://web.archive.org/web/*/https://crazypython.github.io/CrazyPython/dlangforjsdevs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://crazypython.github.io/CrazyPython/dlangforjsdevs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747652</guid>
            <pubDate>Mon, 06 Jul 2020 13:31:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A group of techies are helping 47 countries make better Covid-19 decisions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747628">thread link</a>) | @daveatauquan
<br/>
July 6, 2020 | https://help-corona.org/articles/The-HELP-Story-So-Far/ | <a href="https://web.archive.org/web/*/https://help-corona.org/articles/The-HELP-Story-So-Far/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div id="content" itemprop="articleBody">
				<p>The HELP project is a non-commercial, volunteer led project to model the combined health and economic impacts of COVID-19. Founded with the understanding that a successful approach to managing the crisis required analysis that combined the health and economic impacts from the bottom up. In other words we’re a team that’s aiming to help countries find lockdown strategies that save lives and the economy, not lives or the economy.</p>

<p>The team itself has an incredibly strong background in development and data science, with members working at firms including:</p>

<ul>
  <li>Goldman Sachs</li>
  <li>Google</li>
  <li>Gusto</li>
  <li>Microsoft</li>
  <li>(plus throw in a couple founders too!)</li>
</ul>

<p>The project had a strong start with our health model (the <a href="https://blog.auquan.com/page/cvdmdl2">Auquan-SEIR model</a>) being used by the CDC as part of their ensemble models. This put the work alongside models from seasoned academics from Harvard, John Hopkins, MIT and Imperial in the UK. This provided a clear indication of the quality of work the team was able to produce and the real value that could be delivered by community efforts.</p>

<p>The next big step for the project was joining the <a href="https://www.tropicalmedicine.ox.ac.uk/news/como-consortium-the-covid-19-pandemic-modelling-in-context">COMO consortium</a>. The COMO consortium is a group of academics (e.g. <a href="https://www.tropicalmedicine.ox.ac.uk/team/lisa-white">Oxford</a>, <a href="https://weillcornell.org/nathanielhupert">Cornell</a> and the <a href="https://www.linkedin.com/in/keyrellous-adib/">WHO</a>) that are working to help policymakers in 47 different low and middle income countries to plan their exit strategies. Countries involved include, but are not limited to, Brazil, some US states and the <a href="http://www.emro.who.int/index.html">WHO-EMRO</a> block of countries. Together HELP and COMO have set up an economic working group combining our expertise with their WHO, and country specific, economists to deliver actionable models for countries that need the support right now.</p>

<p>In an effort for transparency, the team has decided to open source all of the code produced and provide regular updates on the <a href="https://www.help-corona.com/">website</a>. In the last couple of weeks we have released the V0 model, which uses simplified models to create a proof of concept of how the final model will work together. The overall process can be seen below:</p>

<p><img src="https://help-corona.org/images/model_example.png" alt="Model Flow Diagram"></p>

<p>To view the V0 code, see the project’s <a href="https://github.com/Auquan/help_project/">Github repository</a>.</p>

<p>The team is currently working towards the next iteration of the model that will be delivered in the coming two weeks. Improvements in this version will include:</p>

<ul>
  <li>The ability to apply more historical lockdown strategies</li>
  <li>The ability to use the PyRoss health model as well as the AuquanSEIR model</li>
  <li>Development work on an Agent based and a SAM based economic model</li>
  <li>Improvement of the optimisation module and movement towards using WELBYs as an objective measure</li>
</ul>

				<hr>
				<!-- /.footer -->
				
			</div><!-- /.content -->
		</div></div>]]>
            </description>
            <link>https://help-corona.org/articles/The-HELP-Story-So-Far/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747628</guid>
            <pubDate>Mon, 06 Jul 2020 13:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[H.266/Versatile Video Coding (VVC)]]>
            </title>
            <description>
<![CDATA[
Score 434 | Comments 382 (<a href="https://news.ycombinator.com/item?id=23747626">thread link</a>) | @caution
<br/>
July 6, 2020 | https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1 | <a href="https://web.archive.org/web/*/https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747626</guid>
            <pubDate>Mon, 06 Jul 2020 13:28:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An interview with spatial dataviz artist Craig Taylor]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23747622">thread link</a>) | @robhawkes
<br/>
July 6, 2020 | https://spatialawareness.xyz/blog/an-interview-with-spatial-artist-craig-taylor/ | <a href="https://web.archive.org/web/*/https://spatialawareness.xyz/blog/an-interview-with-spatial-artist-craig-taylor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>One of the most enviable and rare traits is the ability to consistently produce work that is unique and immediately recognisable as to who made it. If you think of the people who inspire you most in the spatial community, they all probably demonstrate this trait to some degree. Not many people can claim this, and many strive to achieve it.</p><p>Craig Taylor has this trait in abundance — his approach to spatial visualisation being both unique and incredibly beautiful. His body of work is growing by the day (I'm starting to think he never sleeps), and you've probably already seen it even if you didn't realise he was behind it. He firmly stands between the two realms of art and spatial data analysis, expertly taking complex spatial data and communicating it in a way that is both beautiful and insightful.</p><p>I've been a big fan of Craig and his work for a while now — he's had a huge impact on my own work and how I want to approach spatial visualisation — so it was a delight to finally meet him in person at an event at Ordnance Survey last year. It also turns out we have a lot in common, like both living in the arse-end of nowhere in the North West of the UK.</p><p>I recently had the pleasure of interviewing him for Spatial Awareness; learning about his journey with spatial visualisation, getting insight into his work and technique, and finding out just how he manages to consistently churn out so many amazing visualisations.</p><p>So please, grab yourself a panad (Welsh slang for a cup of tea), relax and enjoy this insight into the mind and technique of Craig Taylor. I'm certain you will find it as interesting as I have.</p><hr><p><em>Do you have a burning question for Craig? Add a comment at the end of the interview. Also, let me know who else you'd like to see interviewed and I'll try and make it happen.</em></p><p><em>What did you think of the format of this interview? Would you like to see more free-form discussions in a podcast or video format? I'd love to hear your thoughts.</em></p><p><em>— Robin</em></p><hr><p><strong>First of all I'd like to thank you Craig for taking the time out to do this interview, I know these things take a lot of time and energy.</strong></p><p><strong>Can you begin by introducing yourself for anyone who isn't already aware of who you are?</strong></p><figure><img src="https://res.cloudinary.com/spatialawareness/image/upload/w_1000/v1593859644/ghost/manual/i02lvtaktbbwwk5exruk.jpg" alt=""></figure><p>Well I am the Data Viz Design Manager at <a href="https://www.itoworld.com/">Ito World</a> and run our service sector which delivers bespoke 3D cinematic animations to clients. Generally these visualisations revolve around the use of transit data and are used by our clients to tell a story or derive some insight.</p><p>Outside of Ito World I run my <a href="https://mapzilla.co.uk/">Mapzilla website</a> and spend too much of my free time finding new ways of visualising 3D data. Houdini has been a great outlet for me at the moment as it mirrors my node-based workflows I utilise in Ito World.</p><p>Oh and I have two wonderful spaniels Bryn and Toby who wanted a shoutout!</p><figure><img src="https://res.cloudinary.com/spatialawareness/image/upload/w_1000/v1593859644/ghost/manual/tlm7p8e4itzouyuppzbm.jpg" alt=""><figcaption>Craig's adorable spaniels 😍</figcaption></figure><p><strong>You can also follow Craig and his work through his Twitter and Instagram feeds.</strong></p><!--kg-card-begin: html--><figure>
  <a href="https://twitter.com/CraigTaylorViz">
    <div>
      <p>Craig Taylor (@CraigTaylorViz)</p>
      <p>Data Visualisation Design Manager @Itoworld</p>
      <p><img src="https://abs.twimg.com/favicons/twitter.ico">
        <span>Twitter</span>
      </p>
    </div>
    <p><img src="https://res.cloudinary.com/spatialawareness/image/twitter_name/w_600/CraigTaylorViz.jpg">
    </p>
  </a>
</figure>
<!--kg-card-end: html--><!--kg-card-begin: html--><figure>
  <a href="https://www.instagram.com/mapzilla_art/">
    <div>
      <p>Craig Taylor (mapzilla_art)</p>
      <p>All maps and design are my own work. I tweet [at]craigtaylorviz</p>
      <p><img src="https://www.instagram.com/static/images/ico/favicon-192.png/68d99ba29cc8.png">
        <span>Instagram</span>
      </p>
    </div>
    <p><img src="https://scontent-lht6-1.cdninstagram.com/v/t51.2885-19/s320x320/17494655_377410459307232_652583382563160064_a.jpg?_nc_ht=scontent-lht6-1.cdninstagram.com&amp;_nc_ohc=15bUdy15proAX_cyZ70&amp;oh=9c095290bbffc6a8d4d0f1fd075e1117&amp;oe=5F295724">
    </p>
  </a>
</figure>
<!--kg-card-end: html--><p><strong>I've always found it fascinating to hear the different journeys people go on to get where they are today.</strong></p><p><strong>How did you first get into spatial visualisation?</strong></p><p>I have always been interested in the design side of cartography after being introduced to GIS through university however the emphasis here was on the spatial analytics, which was great, but design never seemed to be as important. It wasn’t until I started working with Landscape Architects that I appreciated how important design was.</p><p>Ever since that I have tried to position myself in roles that see spatial design as a must and not just a nice to have.</p><p><strong>And what was your first job in the field?</strong></p><p>GIS Technician with Mouchel Engineering in 2008, I was lucky to get a job in GIS right after my MSc in Environmental Informatics. It was a great role but a completely different ‘GIS’ to what University taught us. There was a lot of plan production, a lot of digitising and the inevitable ’CAD to GIS’ wrangling, which back in 2008 wasn’t a whole load of fun!</p><hr><!--kg-card-begin: html--><p>Master mapman GIS weirdo</p><!--kg-card-end: html--><hr><p><strong>So fast-forwarding to the present day. Where do you work now, and what do you do there?</strong></p><p>DataViz Design Manager at Ito World for the past 3 years. Well according to my family in a recent quiz I'm an ‘illustrator of pointless flight and commuter data’ or ‘master mapman GIS weirdo.’ There is probably a bit of truth in both but I am in charge of delivering our 3D cinematic visualisations to a variety of clients. As I mentioned earlier usually these clients have transit data they want visualising in new or exciting ways.</p><p>Recently I have been working a lot with our internal archived data at Ito World whether that is finding new ways to visualise GTFS feeds or looking at visualising our prediction systems. I am lucky it’s such a creative role and also have access to an amazing toolset developed by our CTO <a href="https://twitter.com/halbertram">Hal Bertram</a>.</p><hr><!--kg-card-begin: html--><p>It’s the manipulation and animation of data to create something people might not have seen before that drives me to constantly seek new ways of visualising geo data</p><!--kg-card-end: html--><hr><p><strong>You mention that you've always been interested in the design side of cartography.</strong></p><p><strong>What are the driving factors in why you make maps? And what excites you about working with spatial visualisation?</strong></p><p>I think everyone resonates with ‘place’ in one way or another and I find visualising geography fascinating but I love it when a ‘place’ comes to life through animation.</p><p>Take airport runways for instance, visualising the plane activity throughout a day is mesmerising and deriving the patterns and digital contrails the aircraft leave is something that you can’t appreciate until you see it animated. Or bus journeys and how the daily patterns of activity can create an urban heartbeat, or maybe turning drive-time catchments into coral formations.</p><p>It’s the manipulation and animation of this data to create something people might not have seen before that drives me to constantly seek out new ways of visualising geo data.</p><p><strong>If you look back over your career so far, what would you say is your favourite piece of work? There's a lot to choose from!</strong></p><p><a href="https://mapzilla.co.uk/work/coral-cities">Coral Cities</a>! It was the first major project which I thought could be classed as art, or at least close to art! I started looking at ways of manipulating drive-time catchments into 3D geometry and eventually came up with the Coral City concept.</p><figure><iframe src="https://player.vimeo.com/video/267964121?app_id=122963" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" title="UK Coral Cities"></iframe></figure><p>From there the project grew and grew, we created small multiple posters and visualisations which got used on huge screens at the LA Autoshow! They were featured in fast company and even made it into Andy Kirks latest edition of Data Visualisation.</p><p>It’s the only project I’ve worked on where my wife asked for a custom poster to go in the house!</p><p><strong>Your <a href="https://mapzilla.co.uk/work/plotmypaws">PlotMyPaws</a> project is definitely one of my favourites, it's both visually compelling and also a fascinating insight into the crazy world of dogs.</strong></p><p><strong>Do you plan to revisit it?</strong></p><p>I loved PlotMyPaws — it epitomised why I love working with spatial data but also the value in creating your own unique datasets. The insight that came from visualising where my dogs were running and eventually lots of other peoples dogs in my village was amazing and super interesting, even if I took the concept a bit far with 3D heatmaps and such the like!</p><figure><iframe src="https://player.vimeo.com/video/289237729?app_id=122963" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></figure><p>I did begin a PlotMyPup sequel when our second puppy arrived, Toby, but I felt I was repeating a lot of what I did the first time round with a slightly bigger dog. I’d love to expand the project and get more people tracking their dogs, but it’s tricky unless people invest in trackers themselves.</p><p><strong>Your work at Ito World is always inspirational. Tell me some more about your favourite projects there.</strong></p><p>We recently delivered three data visualisations to TomTom for a number of cities showcasing their mobility products. They wanted to showcase how their data could be used to understand mobility within a city.</p><p>Each visualisation was split into three parts, a general heartbeat of traffic during the day, a comparison of traffic on a specific day with a public bank holiday and an insight into how congestion accumulates on a number of busy roads and intersections within a city.</p><figure><iframe src="https://player.vimeo.com/video/358101779?app_id=122963" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" title="TomTom: Visualising Probe Data in Amsterdam"></iframe></figure><p>It was fascinating how detailed their GPS traces are and they were happy for us to explore a few new visualisation styles including ‘congestion explosions’ which show traffic build up on key streets.</p><p><a href="https://medium.com/@craig.taylor_72813/tomtom-visualising-amsterdams-heartbeat-7939e9b60d66">I wrote a blog on the evolving design</a> we iterated through throughout the project.</p><p><strong>We've seen so far that a lot of your visualisations are animated and 3D. What hardware and software do you use to create them?</strong></p><p>All of our service work at Ito World is produced using our ‘Designer’ tool, it’s built on OpenGL and it optimised for fast rendering and designing on the fly meaning we can be really flexible when it comes to clients requirements.</p><figure><iframe src="https://player.vimeo.com/video/334480610?app_id=122963" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" title="Ito World Showreel 2019 4k"></iframe></figure><p>Outside of Ito I am a huge fan of Cinema4D and the <a href="https://cinemaplugins.com/c4d-plugins/dem-earth/">DEM Earth plugin</a> and have dabbled in Blender during my early foray into 3D. As of late I am finding myself hooked on Houdini which feels as close to our Ito tool in terms of node based workflows as anything I have used. It’s incredibly powerful for animating 3D spatial data and is really fun to use.</p><p>Most of my projects are spatially orientated so I flip between QGIS and ArcMap depending on my mood!</p><p>Finally most projects are compiled and edited in After Effects and I am a huge fan of most of the Adobe Creative Suite really, back when I was making static maps Illustrator was my go-to-tool!</p><p><strong>You also tend to focus on pre-rendered visualisations over realtime. Do you feel there are benefits of rendered output over realtime?</strong></p><p>I suppose with rendered outputs you get the ability to hook into 3rd party renderers like Octane or Redshift etc. Octane has some great tools for rendering particles or hair on the fly without creating geometry so can be really beneficial when it comes to creating complex spatial scenes.</p><p>However looking …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://spatialawareness.xyz/blog/an-interview-with-spatial-artist-craig-taylor/">https://spatialawareness.xyz/blog/an-interview-with-spatial-artist-craig-taylor/</a></em></p>]]>
            </description>
            <link>https://spatialawareness.xyz/blog/an-interview-with-spatial-artist-craig-taylor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747622</guid>
            <pubDate>Mon, 06 Jul 2020 13:27:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How I Built HelioHex]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23747596">thread link</a>) | @vb42
<br/>
July 6, 2020 | https://vinaybhaip.com/blog/2020/07/05/heliohex | <a href="https://web.archive.org/web/*/https://vinaybhaip.com/blog/2020/07/05/heliohex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <!--more-->

<p><em>TLDR: I built HelioHex: a highly-configurable, modular, hexagon-based lighting system from scratch that is controllable from any device and syncs to Spotify.</em></p>

<h2 id="table-of-contents">Table of Contents</h2>
<ol>
  <li><a href="#inspiration">Inspiration</a></li>
  <li><a href="#research">Research</a></li>
  <li><a href="#vision">Vision</a></li>
  <li><a href="#construction">Construction</a>
    <ol>
      <li><a href="#materials">Materials</a></li>
      <li><a href="#wooden-frames">Wooden Frames</a></li>
      <li><a href="#light-diffusion">Light Diffusion</a></li>
    </ol>
  </li>
  <li><a href="#electronics">Electronics</a>
    <ol>
      <li><a href="#wiring-lights">Wiring Lights</a></li>
      <li><a href="#supplying-current">Supplying Current</a></li>
      <li><a href="#extending-wires">Extending Wires</a></li>
    </ol>
  </li>
  <li><a href="#software">Software</a>
    <ol>
      <li><a href="#spotify-syncing">Spotify Syncing</a></li>
      <li><a href="#web-app-controller">Web App Controller</a>
 <!-- 3. [Starting on Boot](#starting-on-boot) --></li>
    </ol>
  </li>
  <li><a href="#final-touches">Final Touches</a></li>
  <li><a href="#reflections">Reflections</a></li>
</ol>



<p>For the past three months, I’ve been building a highly configurable, modular, hexagon-based lighting system from scratch. Here’s a demo:</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/8TQva79vo88" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p>Here’s some of the highlights of HelioHex:</p>

<ul>
  <li>Different lighting ‘modes’
    <ul>
      <li>Set the color of the whole display</li>
      <li>Set the color of individual hexagons</li>
      <li>Generate a random aesthetically-pleasing color palette</li>
      <li>Sync the color of the display to the time of the day</li>
    </ul>
  </li>
  <li>Spotify integration
    <ul>
      <li>Matches up the colors of each hexagon to the features of the song playing</li>
      <li>Changes depending on the emotions of the song e.g. sadder songs are more blue</li>
    </ul>
  </li>
  <li>Adaptable web controller
    <ul>
      <li>Use any device on the network to control the device</li>
      <li>Control all the different modes and brightness of the display</li>
      <li>Shows a virtual visualization of the display</li>
    </ul>
  </li>
  <li>Flexible design
    <ul>
      <li>Arrange the hexagons in whatever pattern you like - change the settings in one file and everything automatically updates</li>
      <li>Expand the structure easily if you build more hexagons</li>
    </ul>
  </li>
</ul>

<h2 id="inspiration">Inspiration</h2>

<p>Late March, I realized that all my schoolwork and testing would soon be over. In an effort to avoid spending my quarantine solely indulging in video games and Netflix, I sought a project.</p>

<p>While brainstorming ideas, I came across the <a href="https://nanoleaf.me/en/consumer-led-lighting/products/smarter-series/nanoleaf-light-panels-smarter-kit/">Nanoleaf Light Panels</a>, a vibrant lighting system that gamers frequently display in their rooms. I thought that I could extend the functionality of this to show lights based off events, like if I received a notification on my phone. And maybe Facebook notifications could be blue, Snapchat notifications yellow, and email notifications red. All of the pieces of this project were starting to come together until I saw the pricetag: <strong>$200</strong>.</p>

<p>Nope. No way was I gonna spend $200 on some lights. To make it worse, that was the price for nine measely panels. Don’t get me wrong - it looked impressive, just not worth a little over $20 per panel. And even if I still wanted it, the $200 set was sold out - I’d have to cough up $300 for fifteen panels instead.</p>

<p>Perhaps the coolest application of the Nanoleaf Light Panels is the <a href="https://www.youtube.com/watch?v=o41emqmX6ds">Rhythm Edition</a>, which syncs your lighting system to music. Watching the demo left me… disappointed. It was highly customizable, but perhaps too customizable. I just wanted to click a button and have the lighting system sync up to all the nuances in the song - if the song was going to have the bass drop, I wanted to emphasize that and to make the lights to feel alive. Maybe I’m in the minority here, but I was pretty unsatisfied - especially considering I’d be shelling out hundreds of dollars for this.</p>

<p>Then something clicked; why don’t I just build my own system? I could customize it to my heart’s desire and I could make it for a lot cheaper than $200. I would also learn a lot from this project - it seemed perfect. And so, I set out to build my own lighting system - HelioHex.</p>

<h2 id="research">Research</h2>

<p>As should be with any project, the first step was research. <a href="https://www.youtube.com/watch?v=2OP-oEbzB6g">This DIY video from NerdForge</a> looked very similar to what I wanted. The key features I wanted to adopt from this was the modularity, the hexagon design (because it looked really cool), and the remote controller. However, I felt the app he developed didn’t make the most of the lights - specifically, I wanted to sync up my own system with Spotify. Also, he 3D-printed the frame for the hexagons. Unfortunately, I do not have the luxury of a 3D-printer (and I couldn’t 3D-print at the library due to the lockdown). This motivated me to alternatively make a wooden frame to give off a sleek, less-manufactured look.</p>

<p>I also <a href="https://www.youtube.com/watch?v=7vGa1oAYAX8">checked out</a> <a href="https://www.youtube.com/watch?v=PwmheNfCnXM">many</a> <a href="https://www.instructables.com/id/DIY-Hexagonal-Nanoleaf-LED-Light/">more</a> <a href="https://www.thingiverse.com/thing:3354082">guides</a> that helped me frame my goals. Ultimately, this research helped me answer one big question: was this project attainable?</p>

<p>The answer was a confident ¯\<em>(ツ)</em>/¯. A lot of the electronics scared me and the coding seemed decently formidable. I like challenges, though, so I went for it. Also, given that I had boatloads of free time, it seemed like I had nothing better to do.</p>

<h2 id="vision">Vision</h2>

<p>The next step for me was to create a concrete vision of my desired end-result. First up were the non-negotiables - things my project HAD to have to consider it successful:</p>

<ul>
  <li>Working lights that are easily controllable by a remote controller</li>
  <li>Seamless integration with a music app</li>
  <li>Modularity - changing the arrangement of the hexagon units should be relatively easy</li>
  <li>Self containment - each unit is independent of other units</li>
  <li>Preset lighting modes that “look nice”</li>
  <li>A clean UI for the remote controller</li>
</ul>

<p>Next up were some nice to haves - not needed, but would make me feel really accomplished</p>
<ul>
  <li>No <a href="https://en.wikipedia.org/wiki/Hard_coding">hard coding</a></li>
  <li>Anyone should be able to control the lighting system</li>
  <li>Each individual hexagon “unit” can have their color set</li>
</ul>

<p>Some of these goals were scary, especially when you combine them together - having the ability to set individual hexagon colors without hardcoding while having the UI of the remote controller look clean? Yeesh.</p>

<p>The next step was materializing this vision. What helped me was using a <a href="https://en.wikipedia.org/wiki/Kanban_board">Kanban Board</a>. I wrote mini tasks for myself to reach different goals - divided into sections like software, hardware, and construction and prioritized by importance. A Kanban Board made this ambitious project much more digestable. It also made sure that I wouldn’t spend time on unnecessary, small fixes unless they were needed. The goal was to build the system as quickly as possible, and then go back and optimize it. Basically the <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile Development Technique</a>. Totally see how helpful it is now and why companies emphasize it so heavily.</p>

<h2 id="construction">Construction</h2>

<h3 id="materials">Materials</h3>

<table>
  <thead>
    <tr>
      <th>Material</th>
      <th>Cost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://www.amazon.com/CHINLY-Individually-Addressable-Waterproof-waterproof/dp/B06XNJSKXN/ref=sr_1_5">LED Strip</a></td>
      <td>$29.90</td>
    </tr>
    <tr>
      <td><a href="https://www.amazon.com/ALITOVE-Female-Connector-WS2812B-SK6812-RGBW/dp/B071H5XCN5/ref=sr_1_5">JST Connectors</a></td>
      <td>$10.99</td>
    </tr>
    <tr>
      <td><a href="https://www.amazon.com/dp/B075SXMD9Z/ref=sspa_dk_detail_3">RF Remote Controller</a></td>
      <td>$8.99</td>
    </tr>
    <tr>
      <td><a href="https://www.homedepot.com/p/Sande-Plywood-Common-5-2-mm-x-2-ft-x-4-ft-Actual-0-205-in-x-23-75-in-x-47-75-in-103064/202093790">Plywood</a></td>
      <td>$10.96</td>
    </tr>
    <tr>
      <td><a href="https://www.homedepot.com/p/OPTIX-23-75-in-x-47-75-in-White-Acrylic-Light-Panel-1A20084A/100564898">Acrylic Light Panel</a></td>
      <td>$12.48</td>
    </tr>
    <tr>
      <td><a href="https://www.microcenter.com/product/622539/raspberry-pi-4-model-b---8gb-ddr4">Raspberry Pi 4</a></td>
      <td>$35.00</td>
    </tr>
    <tr>
      <td><a href="https://www.amazon.com/CHINLY-Universal-Regulated-Switching-Transformer/dp/B01LZRIWZD/ref=sr_1_4">Power Supply</a></td>
      <td>$20.99</td>
    </tr>
    <tr>
      <td><a href="https://www.lowes.com/pd/Southwire-25-ft-14-AWG-Stranded-Black-Copper-THHN-Wire-By-the-Roll/1000992054">Wires</a> x3</td>
      <td>$18.81</td>
    </tr>
    <tr>
      <td><a href="https://www.homedepot.com/p/Legrand-5-ft-Non-Metallic-Raceway-Wire-Channel-White-NMW1/100038290">Cord Cover</a></td>
      <td>$8.12</td>
    </tr>
    <tr>
      <td>Hot glue, super glue, push pins, clamps, etc.</td>
      <td>$30.00</td>
    </tr>
    <tr>
      <td><strong>Total</strong></td>
      <td><strong>$186.24</strong></td>
    </tr>
  </tbody>
</table>

<p>I got under my goal of $200! Ended up saving about $15 for three months of my time.</p>

<p>To be fair, I did buy other materials that I never ended up using and did not account for tax. This means that the <em>actual</em> cost of this project probably was $50-$100 higher, but we’ll just say it’s under $200 because it makes me feel better.</p>

<h3 id="wooden-frames">Wooden Frames</h3>

<p>The first legitimate step in the project was to create the casing for each unit. All the guides I found used 3D printed cases, which was inaccessible for me, so I used wood. I bought a 24” by 12” wooden sheet and cut it out into rectangular pieces. I used a hexagon shape for each unit so I had to glue six of these rectangles together. I hotglued a metal hinge into the shape of a 120° angle and used that as a reference to put the rectangles together. The structural integrity of each hexagon was important so I used a trifecta of super glue, hot glue, and wood glue.</p>

<p><img src="https://vinaybhaip.com/blog/assets/images/heliohex/wooden-hexagon-construction.jpg" alt="Wooden Hexagon Construction">
<em>Wooden hexagon construction. In the foreground, wooden side pairs are joined together that will eventually form full hexagons. In the background, you see that my worktable was a messy ping-pong table.</em></p>

<p>In the above picture, you’ll notice small triangles cut out at the bottom of each plywood piece. This allows for wires to pass through connecting units. In line with my goal of modularity, this cutout was on every side so I could configure my system however I’d like. I made eight of these units, the most I could make given the length of the LED strip.</p>

<h3 id="light-diffusion">Light Diffusion</h3>

<p>The goal of this lighting system was to have each hexagon display a uniform, individual color. To achieve this uniformity, the material on top of each hexagon must evenly diffuse light from the LED strip that lines the inner perimeter of each hexagon.</p>

<p>This is where the acrylic sheet comes in. The sheet I bought is basically the same material as the light panels that covers school ceilings.</p>

<p>The problem is that acrylic is very brittle to the point that any cut I made - using scissors, a saw, even with the knife Home Depot recommended - completely fragmented the acrylic. After spending a week trying to figure it out, I decided to hold it off till I could laser cut it when the lockdown lifted.</p>

<p>In the meanwhile, I used a poor man’s acrylic - paper. It served its purpose for how easy it was to use.</p>

<p><img src="https://vinaybhaip.com/blog/assets/images/heliohex/paper-light.gif" alt="Paper Light">
<em>Paper hexagons put on top of each unit. The lighting is controlled by a cheap RF remote.</em></p>

<p>Although it does look pretty cool, there’s a couple of problems. First, it’s not clean. Paper doesn’t give off that professional vibe I’m striving for and if I’m spending months on this, might as well make it look good. Second, paper is really flimsy. It wouldn’t stick well with tape, and I didn’t want a permanent solution like glue because I knew I wanted to change it eventually. Lastly, it doesn’t diffuse the light THAT well; it does the job, but it’s nothing amazing.</p>

<p><img src="https://vinaybhaip.com/blog/assets/images/heliohex/acrylic-sheet-light.jpg" alt="Acrylic Sheet Light">
<em>The uncut acrylic sheet on top of a lit unit.</em></p>

<p>These images don’t do justice to the acrylic sheet. It looks miles better with material that’s meant to diffuse light. Instead of waiting for a laser cutter for who knows how long, I got lucky when a friend allowed me to borrow their <a href="https://en.wikipedia.org/wiki/Circular_saw">hand-held circular saw</a>. The fine teeth on this allowed me to cut the acrylic with no worry.</p>

<p><img src="https://vinaybhaip.com/blog/assets/images/heliohex/acrylic-sheet-after.jpg" alt="Acrylic Sheet After">
<em>The acrylic sheet after I cut it. On the left of the sheet you can see the jaggedness resulting from my previous methods.</em></p>

<p>It turned out a success! I hotglued the cut-out acrylic pieces to the hexagons and shaved down the sharp edges.</p>

<h2 id="electronics">Electronics</h2>

<p>This is what I was worried about the most. Despite having taken multiple classes in high school dealing with electronics, I had no idea what I was doing - evident by me <em>almost</em> setting the house on fire a few times.</p>

<h3 id="wiring-lights">Wiring Lights</h3>

<p>I cut up the light strip to put 36 LEDs in each hexagon unit. Each LED draws 50mA at full brightness, meaning for eight hexagons, I would need 14.4 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vinaybhaip.com/blog/2020/07/05/heliohex">https://vinaybhaip.com/blog/2020/07/05/heliohex</a></em></p>]]>
            </description>
            <link>https://vinaybhaip.com/blog/2020/07/05/heliohex</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747596</guid>
            <pubDate>Mon, 06 Jul 2020 13:24:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low floor, wide walls, high ceiling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747513">thread link</a>) | @yarapavan
<br/>
July 6, 2020 | http://gordonbrander.com/pattern/low-floor-wide-walls-high-ceiling/ | <a href="https://web.archive.org/web/*/http://gordonbrander.com/pattern/low-floor-wide-walls-high-ceiling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>"Low floor, wide walls" is the mantra that guides the design of MIT's <a href="https://scratch.mit.edu/">Scratch language</a>.</p>
<blockquote>
<p>When discussing technologies to support learning and education, my mentor Seymour Papert often emphasized the importance of “low floors” and “high ceilings.” For a technology to be effective, he said, it should provide easy ways for novices to get started (low floor) but also ways for them to work on increasingly sophisticated projects over time (high ceiling).</p>
<p>For a more complete picture, we need to add an extra dimension: wide walls. It’s not enough to provide a single path from low floor to high ceiling; we need to provide wide walls so that kids can explore multiple pathways from floor to ceiling.</p>
</blockquote>
<p>— <a href="https://design.blog/2016/08/25/mitchel-resnick-designing-for-wide-walls/">Mitchel Resnick</a></p>
<p>This gives us a lens through which evaluate tools:</p>
<ul>
<li>Low floor: how easy is it to learn?</li>
<li>Wide walls: how inclusive is it? How many different use-cases does it serve?</li>
<li>High ceiling: does it scale with growth?</li>
</ul>
<p>Most programming tools focus exclusively on creating a high ceiling. By choosing the other two neglected dimensions, Scratch has carved out a durable niche for itself. It is widely used in intro-to-programming courses, beginner robotics, after-school classes... any place a simple but open-ended programming model is needed.</p>
<hr>
<p>Product development has a natural bias toward pushing the ceiling higher — focusing on the needs of the most valuable customer, where the highest amount of value may be extracted. This is one of the driving forces of disruption in the <span>Innovator's Dilemma</span>.</p>
<p>How can your product focus on:</p>
<ul>
<li>Lowering the floor — becoming simpler, cheaper, "good enough"</li>
<li>Widening the walls — serving an ignored audience or market</li>
</ul>
<hr>
<p><a href="http://gordonbrander.com/pattern/design-patterns/">Design patterns</a>, <span>Toy</span></p>

      
      
        <h2>↑ Links here</h2>
        
          
        
          
        
      
    </div></div>]]>
            </description>
            <link>http://gordonbrander.com/pattern/low-floor-wide-walls-high-ceiling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747513</guid>
            <pubDate>Mon, 06 Jul 2020 13:14:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast and Efficient Pitch Detection: Revisited]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747315">thread link</a>) | @bigboat
<br/>
July 6, 2020 | https://www.cycfi.com/2020/07/fast-and-efficient-pitch-detection-revisited/ | <a href="https://web.archive.org/web/*/https://www.cycfi.com/2020/07/fast-and-efficient-pitch-detection-revisited/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<h2>Reload</h2>



<p>Last year, I wrote a series of articles about Bitstream Autocorrelation:</p>



<ol><li><a href="https://www.cycfi.com/2018/06/fast-and-efficient-pitch-detection-synth-tracking/">Synth Tracking</a></li><li><a href="https://www.cycfi.com/2018/04/fast-and-efficient-pitch-detection-bliss/">Bliss!</a></li><li><a href="https://www.cycfi.com/2018/03/fast-and-efficient-pitch-detection-bitstream-autocorrelation/">Bitstream Autocorrelation</a></li></ol>



<p>The code has matured significantly from its inception. It is long overdue, but now, as promised, it’s time to write about the technical details.&nbsp;Check out the <a href="https://www.cycfi.com/2019/02/q-audio-dsp-library/">Q Audio DSP Library</a>&nbsp;where this is being actively developed.</p>



<p><strong>Note</strong>: Reading up on the previous articles is a prerequisite for understanding this post.</p>



<h2>Quick Overview</h2>



<p>For those who tuned in late, Bitstream Autocorrelation, or BACF, is an accurate, extremely fast and efficient, time-domain pitch detection algorithm. BACF can be at least as accurate as any Autocorrelation based pitch detection schemes. Unlike the standard Autocorrelation function, or ACF, BACF works on zero crossings —the Bitstream, using bitwise operations. </p>



<p>BACF is extremely fast. The computation consumes an average of 50 nanoseconds per sample, on a 2016 MacBook Pro, tracking complex guitar phrases that exhibit typical playing techniques such as legato, hammer-on, pull-off, vibrato, staccato, and right-hand tapping.</p>



<blockquote><p><em>Autocorrelation, also known as&nbsp;serial correlation, is the&nbsp;</em><a href="https://en.wikipedia.org/wiki/Correlation">correlation</a><em>&nbsp;of a&nbsp;</em><a href="https://en.wikipedia.org/wiki/Signal_(information_theory)">signal</a><em>&nbsp;with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations as a function of the time lag between them. The analysis of autocorrelation is a mathematical tool for finding repeating patterns, such as the presence of a&nbsp;</em><a href="https://en.wikipedia.org/wiki/Periodic_signal">periodic signal</a><em>&nbsp;obscured by&nbsp;</em><a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a><em>, or identifying the&nbsp;</em><a href="https://en.wikipedia.org/wiki/Missing_fundamental_frequency">missing fundamental frequency</a><em>&nbsp;in a signal implied by its&nbsp;</em><a href="https://en.wikipedia.org/wiki/Harmonic">harmonic</a><em>&nbsp;frequencies. It is often used in&nbsp;</em><a href="https://en.wikipedia.org/wiki/Signal_processing">signal processing</a><em>&nbsp;for analyzing functions or series of values, such as&nbsp;</em><a href="https://en.wikipedia.org/wiki/Time_domain">time domain</a><em>&nbsp;signals. (From Wikipedia)</em></p></blockquote>



<p><strong>I was not the first…</strong> Initially, I noted that “As far as I can tell, this is my invention, but please tell me if there’s something I am missing and if I’m not the first to actually do it this way”. Recently, I was informed that there exists a prior invention in the 80s for a hardware based approach. The inventor is David Warrender and here’s the patent for his invention: <a href="https://patents.google.com/patent/US4429609A/en?oq=4429609">Pitch analyzer</a>. The patent is now expired.</p>



<p><strong>Note:</strong> While I developed the code for a very specific source input: the guitar, the algorithm is generic and can be applied to other sources. Venturing outside the guitar realm is something I am very interested in, but unfortunately I have no time for… Yet…</p>



<h2>Data Flow</h2>



<figure><img src="https://www.cycfi.com/wp-content/uploads/2020/07/bacf-dataflow-1-1024x67.png" alt="" srcset="https://www.cycfi.com/wp-content/uploads/2020/07/bacf-dataflow-1-1024x67.png 1024w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-dataflow-1-768x51.png 768w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-dataflow-1-1536x101.png 1536w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-dataflow-1-2048x135.png 2048w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-dataflow-1-1200x79.png 1200w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-dataflow-1-600x39.png 600w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-dataflow-1-300x20.png 300w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>Zero Crossing</h3>



<p>A <em>zero_crossing</em> class saves zero-crossing information necessary to extract accurate timing information such as periods between pulses for performing analysis.</p>



<div><figure><img src="https://www.cycfi.com/wp-content/uploads/2020/07/zero_crossing.png" alt="" width="117" height="176"><figcaption>Zero Crossing Event</figcaption></figure></div>



<p>Each zero crossing pulse is saved in a ring buffer of <em>info</em> elements. Data include the maximum height of the waveform bounded by the pulse, the pulse width, as well as the leading edge and trailing edge frame positions (number of samples from the start) and y coordinates (the sample values before and after each zero crossing) of the zero crossings.</p>



<p>Sub-sample accurate period computation can be obtained using linear-interpolation of the x and y locations of each zero-crossing event. See image at the right. The two points P1 and P2 are the previous and current positions of the zero-crossing event from the raw data samples. The actual zero-crossing is the point where the dark blue line intersects the horizontal dotted line. </p>



<h3>Bitset</h3>



<p>After collecting twice the BACF <em>window’s</em> worth of zero-crossing information, where the BACF <em>window</em> size is the period of the lowest frequency we want to detect, we transfer the information to a temporary <em>bitset</em> class, which stores the zero crossing bits as 32-bit or 64-bit integers (using the native integer size of the platform). Only significant pulses —those whose pulse heights are above a certain percentage (currently 80%) of the maximum pulse height of all pulses collected, are transferred to the <em>bitset</em>. This will eliminate spurious lower-level pulses and significantly improve detection.</p>



<h3>BACF</h3>



<p>Now we compute the bitstream autocorrelation using the XOR operation. A single XOR operation works on N bits of an integer. We get a speedup factor of N (e.g. 64 for a 64 bit machine) compared to standard ACF, and moreover, integer bit operations are a lot faster than floating-point multiplications.</p>



<p>With XOR you get a one when there’s a mismatch:</p>


<p>0 ^ 0 = 0<br data-rich-text-line-break="true">0 ^ 1 = 1<br data-rich-text-line-break="true">1 ^ 0 = 1<br data-rich-text-line-break="true">1 ^ 1 = 0</p>


<p>After XOR, the number of bits (set to 1) is counted. The lower the count, the higher the periodicity. A count of zero gives perfect correlation: there is no mismatch. Modern CPUs provide operations for counting bits in an integer. These are exposed by modern C++ compilers as built-in functions (e.g. <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html">__builtin_popcountll</a>). The bit count, together with the window size, are used to provide a normalized <em>periodicity</em> value that ranges from 0.0 to 1.0, where 1.0 signifies perfect correlation.</p>



<h3>Sub-Collector</h3>



<div><figure><img src="https://www.cycfi.com/wp-content/uploads/2018/03/wiki_autocorrelation.png" alt="" srcset="https://www.cycfi.com/wp-content/uploads/2018/03/wiki_autocorrelation.png 166w, https://www.cycfi.com/wp-content/uploads/2018/03/wiki_autocorrelation-130x300.png 130w" sizes="(max-width: 166px) 100vw, 166px"></figure></div>



<div><div>
<p>Unlike standard autocorrelation (image at the right) where the signal window is successively shifted/delayed and correlated against the unshifted reference signal to get the peaks (or valleys, depending on detection scheme), we only need to correlate using the zero-crossing edges —another significant speedup.</p>



<p>Potential periods are the distances from each of the collected zero-crossing leading edge. For each potential period, we compute the BACF, discard ones with low periodicity, and collect the most significant results. Longer periods typically (but not always) have better BACF results due to better resolution from more samples. But longer periods may also be sub-harmonics of shorter periods. This is taken into account, and detected by determining if the durations are close to integer multiples of a known shorter period. </p>



<p>The sub-collector returns the period (taking advantage of sub-sample accurate computation) of the leading-edge-pair with the best <em>periodicity</em> index, divided by the integer multiple of the period of the shortest leading-edge-pair, with a sufficiently good periodicity index. The sub-collector also returns the <em>periodicity</em> index. </p>



<p>Essentially, the BACF result is only used as a hint used to choose the best edges that demarcate the correct cycle. The accuracy obtained from computing the period from the zero-crossing edges is superior to that found by extrapolating the period from the BACF’s periodicity peak.</p>




</div></div>



<p>For illustration, the figure below exemplifies a specific BACF in action.</p>



<div><figure><a href="https://www.cycfi.com/wp-content/uploads/2020/07/bacf_diagram-3.png"><img src="https://www.cycfi.com/wp-content/uploads/2020/07/bacf_diagram-3-1024x690.png" alt="" width="640" srcset="https://www.cycfi.com/wp-content/uploads/2020/07/bacf_diagram-3-1024x690.png 1024w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf_diagram-3-768x517.png 768w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf_diagram-3-1200x808.png 1200w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf_diagram-3-600x404.png 600w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf_diagram-3-300x202.png 300w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf_diagram-3.png 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div>



<p>The waveform at the top is the raw audio. The middle is the zero-crossing waveform, with non-significant pulses removed by the zero-crossing to bitset transfer filter as described in the Bitset section. The third is the computed BACF periodicity.</p>



<p>There are two distinct candidate periods, p1 and p2, demarcated by edge-pairs, with a duration less than the BACF window (the third, p3 is not distinct; it has the same duration as p2). These periods correspond to the dotted red BACF sections in the graph. It is obvious in this example that the second period, p2, is the best candidate since it has the best periodicity index. The period of p2 is returned, along with its periodicity index (the peak in the BACF result).</p>



<p>Suppose, however that there are more edges that correspond to multiple peaks in the BACF. As described in the Sub-Collector section, we return the period of the best edge-pair (best <em>periodicity</em>), divided by the integer multiple of the period of the shortest edge-pair (with sufficiently good <em>periodicity</em>). The image below is an example with multiple BACF peaks.</p>



<div><figure><a href="https://www.cycfi.com/wp-content/uploads/2020/07/bacf-multiple-peaks-1.png"><img src="https://www.cycfi.com/wp-content/uploads/2020/07/bacf-multiple-peaks-1-1024x682.png" alt="" width="640" srcset="https://www.cycfi.com/wp-content/uploads/2020/07/bacf-multiple-peaks-1-1024x682.png 1024w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-multiple-peaks-1-768x512.png 768w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-multiple-peaks-1-1200x800.png 1200w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-multiple-peaks-1-600x400.png 600w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-multiple-peaks-1-300x200.png 300w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-multiple-peaks-1.png 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div>



<p>Higher frequencies will tend to have more peaks within the BACF window of interest. An octave above the lowest frequency of interest will have two significant peaks. Two octaves above, like in the example above, will have four. We take advantage of the multiple significant peaks to improve precision due to the fact that longer periods will average out to better precision —there are more samples to count (the period is proportional to the number of samples between two edges). That, and sub-sample accuracy from linear interpolation of the zero-crossing edges, contribute to excellent overall precision from the lowest to the highest frequency.&nbsp;</p>



<h3>Bias</h3>



<p>Consider this BACF snapshot:</p>



<div><figure><a href="https://www.cycfi.com/wp-content/uploads/2020/07/bacf-d-string-1.png"><img src="https://www.cycfi.com/wp-content/uploads/2020/07/bacf-d-string-1-1024x682.png" alt="" width="640" srcset="https://www.cycfi.com/wp-content/uploads/2020/07/bacf-d-string-1-1024x682.png 1024w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-d-string-1-768x512.png 768w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-d-string-1-1200x800.png 1200w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-d-string-1-600x400.png 600w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-d-string-1-300x200.png 300w, https://www.cycfi.com/wp-content/uploads/2020/07/bacf-d-string-1.png 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div>



<p>That is the BACF of the guitar’s D string as it evolves around 14 seconds after note onset. I amplified the raw waveform to make it clear that the second harmonic dominates the fundamental. Here, it is clear that the BACF still detects the fundamental (the higher peak), but at some point, the second harmonic will become more powerful and its BACF peak will eventually catch up. At that point, without taking into account the history of detected frequencies, the second harmonic will be detected as the fundamental. There will be a sudden octave jump.</p>
<p>The <em>bias</em> section takes into account the history and deals with abrupt harmonic shifts (not limited to the first harmonic only). Sudden jumps are not normal. The bias section compares the incoming frequency with the current detected frequency. If a sudden jump is detected, and the incoming frequency is a harmonic of the previous frequency, within a specific deviation (plus minus a few cents), the bias section will prefer the older stable frequency, using the incoming frequency (which may have shifted a bit), divided by the integer multiple of the previous stable frequency.</p>
<p>Finally, the bias section also employs a 3-point median filter in case there’s true (non-harmonic) shift. The median filter eliminates spurious spikes that can happen every once in a while.</p>



<h2>Results</h2>



<p>The <a href="https://www.cycfi.com/2019/02/q-audio-dsp-library/">Q Audio DSP Library</a> includes a comprehensive test suite. Here are the results from the latest tests involving pitch detection:</p>



<figure><table><tbody><tr><td><strong>Test Case</strong></td><td><strong>Average Error</strong> (cents)</td><td><strong>Min Error </strong>(cents)</td><td><strong>Max Error </strong>(cents)</td></tr><tr><td> Test_middle_C</td><td> 0.001236</td><td> 0.00009617</td><td> 0.00231753</td></tr><tr><td> Test_middle_A</td><td> 0.001998</td><td> 0.0</td><td> 0.00552</td></tr><tr><td> Test_low_E</td><td> 0.00003447</td><td> 0.00003447</td><td> 0.00003447</td></tr><tr><td> Test_E_12th</td><td> 0.0000359</td><td> 0.00003447</td><td> 0.0001258</td></tr><tr><td> Test_E_24th</td><td> 0.00018</td><td> 0.00003447</td><td> 0.000606</td></tr><tr><td> Test_A</td><td> 0.00012</td><td> …</td></tr></tbody></table></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cycfi.com/2020/07/fast-and-efficient-pitch-detection-revisited/">https://www.cycfi.com/2020/07/fast-and-efficient-pitch-detection-revisited/</a></em></p>]]>
            </description>
            <link>https://www.cycfi.com/2020/07/fast-and-efficient-pitch-detection-revisited/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747315</guid>
            <pubDate>Mon, 06 Jul 2020 12:50:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaving a steady corporate job for a freelancing career was a risk, initially]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747286">thread link</a>) | @hrishikesh1990
<br/>
July 6, 2020 | https://content.remote.tools/leaving-a-steady-corporate-job-to-pursue-a-freelancing-career-was-a-risk-initially/ | <a href="https://web.archive.org/web/*/https://content.remote.tools/leaving-a-steady-corporate-job-to-pursue-a-freelancing-career-was-a-risk-initially/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	
	<div>

		
		<!-- #masthead -->

		
		<div>

			
			<div>

				
				<div>

					
					<div id="content">

						
	<div id="primary">

		
		<main id="main">

			
			
				
					
<article id="post-1636">

	<!-- Full Post Layout -->
	
	

			<div>
										
					
	<!-- Full Post Layout and Full Content -->
	<div>

		
		<div>

			<div>
<h2 id="1-hey-can-you-please-introduce-yourself">1. Hey, can you please introduce yourself?</h2>



<div><p>Hey! My name is Relja Damnjanovic, I come from Belgrade, Serbia and I’ve been working as a freelance developer for more than 9 years now, and loving every bit of it! Why? Because it’s awesome! 🙂 To tell you the truth, I’m very passionate about many things in life, I love basketball and sports in general, I’m very active in all kinds of sport events, I adore travelling and music festivals, and freelancing is something that is helping me pursue both (or all) my passions.&nbsp;</p></div>



<div><p>For the past 8 or 9 years I’ve been dealing with eCommerce platforms. I started as a regular developer, but grew to be a full-stack developer and even learned a thing or two about running online business, some tips and tricks only masters of the trade tend to use. Magento is my platform of choice, in a way I like its complexity because it allows you to build some amazing things in it, though I do have experience with some other platforms as well.&nbsp;</p></div>



<h2 id="2-what-motivated-you-to-choose-remote-working">2. What motivated you to choose remote working?</h2>



<div><p>I’m a Computer Science graduate from a University in Belgrade, and I do have both corporate and freelance experience. Naturally, both have its benefits, I’d be lying if I said freelancing is some sort of perfect work setup. It’s not, it has its own ups and downs and at times it can be a bit too chaotic and uncertain. Corporate working is definitely a more stable and steady type of work, and to some people that is very important, which is completely understandable.&nbsp;</p></div>



<div><p>What really attracted me towards freelancing and remote work is a certain type of freedom you gain with it. You get to choose when you work, on which projects, from where, you’re free to organise your own life in accordance with your work obligations. In a way you are your own boss. That alone means a lot, and it allowed me to fully explore things in a greater manner. I got to travel around the world and become a digital nomad, attend concerts, run marathons all the while my professional career was going forward in its own way.&nbsp;</p></div>



<div><figure><img src="https://content.remote.tools/wp-content/uploads/2020/07/1-1024x682.jpg" alt=" Got to travel around the world" srcset="https://content.remote.tools/wp-content/uploads/2020/07/1.jpg 1024w, https://content.remote.tools/wp-content/uploads/2020/07/1-300x200.jpg 300w, https://content.remote.tools/wp-content/uploads/2020/07/1-768x512.jpg 768w, https://content.remote.tools/wp-content/uploads/2020/07/1-380x253.jpg 380w, https://content.remote.tools/wp-content/uploads/2020/07/1-800x533.jpg 800w, https://content.remote.tools/wp-content/uploads/2020/07/1-1160x773.jpg 1160w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://content.remote.tools/wp-content/uploads/2020/07/1.jpg 1024w, https://content.remote.tools/wp-content/uploads/2020/07/1-300x200.jpg 300w, https://content.remote.tools/wp-content/uploads/2020/07/1-768x512.jpg 768w, https://content.remote.tools/wp-content/uploads/2020/07/1-380x253.jpg 380w, https://content.remote.tools/wp-content/uploads/2020/07/1-800x533.jpg 800w, https://content.remote.tools/wp-content/uploads/2020/07/1-1160x773.jpg 1160w" data-src="https://content.remote.tools/wp-content/uploads/2020/07/1-1024x682.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Got to travel around the world</figcaption></figure></div>



<h2 id="3-what-were-your-initial-months-like-did-it-live-up-to-your-expectations">3. What were your initial months like? Did it live up to your expectations?</h2>



<div><p>Beginnings are tough, that’s for sure. I come from a very modest family, and things in my surroundings were not ideal, so leaving a steady corporate job to go and pursue a freelancing career was a risk and a challenge. From this perspective right now I can say it is one of the best decisions I made in my life, but back then it was difficult. &nbsp;</p></div>



<blockquote><div><p>When you are at the beginning of the freelance career you don’t have the luxury to choose projects you like and you are very limited in negotiating budgets and your fees. It’s simple – you need money to survive and you’re not certain whether another opportunity will come next week or in two months. Also, chances are your portfolio is not that glamorous when you are at the start of the road.&nbsp;</p></div></blockquote>



<div><p>But you overcome it, day by day, month after month, you learn, you grow, you become more efficient, and in the end you get an opportunity to title yourself as a “full-time freelancer” and with it reap all the benefits it brings with itself.&nbsp;</p></div>



<h2 id="4-how-did-you-find-remote-working-roles">4. How did you find remote working roles?</h2>



<div><p>In my experience there are 3 ways you can get work and explore new opportunities.&nbsp;</p></div>



<div><p>The first one, and most stable one, is by recommendation, whether it be by your friends, old colleagues or old clients. If someone can vouch for you then the level of mutual understanding and trust between you and your new client is on the decent level from the very beginning. Of course, the crucial condition for this is that you do your work in a highly professional way and deliver good results.&nbsp;</p></div>



<div><p>The second one is your personal presence on the web, your own website, social profiles on various work networks etc. These are not ideal and it’s not always that you will find a common ground with a potential client (as it is in general in the business world), but look at it this way – if someone somewhere is looking for an expert in your area, for a certain project they have in mind, you’d want them to find you and tell you about it.&nbsp;</p></div>



<div><p>The third one are the freelance networks and job sites. These should definitely be your main point of interest. There are various types of networks, and each has a unique set of benefits they offer to the freelancer, so it’ll take some time to try out and see which one suits you the most.&nbsp;</p></div>



<div><p>I find that networks like Toptal suit me the most because they give two-way guarantees to both developers and clients, thus assuring both sides in project cooperation show a significant level of professionalism and seriousness, which is highly valued when it comes to business.&nbsp;</p></div>



<h2 id="5-what-have-been-the-best-good-and-worst-aspects-of-remote-working-for-you">5. What have been the best, good and worst aspects of remote working for you?</h2>



<div><p>Working remotely allowed me to become a digital nomad, at least for some time. And it doesn’t matter whether you are a hardcore nomad or occasional, it’s a wonderful experience, to be given a chance to travel, explore different countries, different cultures, cuisines, etc. It gives you a whole new perspective and understanding of the world we live in, makes you value what you have more and also gives you opportunities to try new things and improve your own way of living.&nbsp;</p></div>



<div><figure><img src="http://content.remote.tools/wp-content/uploads/2020/07/5-1024x1024.jpg" alt="Made me become a digital nomad" srcset="https://content.remote.tools/wp-content/uploads/2020/07/5.jpg 1024w, https://content.remote.tools/wp-content/uploads/2020/07/5-150x150.jpg 150w, https://content.remote.tools/wp-content/uploads/2020/07/5-300x300.jpg 300w, https://content.remote.tools/wp-content/uploads/2020/07/5-768x768.jpg 768w, https://content.remote.tools/wp-content/uploads/2020/07/5-80x80.jpg 80w, https://content.remote.tools/wp-content/uploads/2020/07/5-380x380.jpg 380w, https://content.remote.tools/wp-content/uploads/2020/07/5-800x800.jpg 800w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://content.remote.tools/wp-content/uploads/2020/07/5.jpg 1024w, https://content.remote.tools/wp-content/uploads/2020/07/5-150x150.jpg 150w, https://content.remote.tools/wp-content/uploads/2020/07/5-300x300.jpg 300w, https://content.remote.tools/wp-content/uploads/2020/07/5-768x768.jpg 768w, https://content.remote.tools/wp-content/uploads/2020/07/5-80x80.jpg 80w, https://content.remote.tools/wp-content/uploads/2020/07/5-380x380.jpg 380w, https://content.remote.tools/wp-content/uploads/2020/07/5-800x800.jpg 800w" data-src="http://content.remote.tools/wp-content/uploads/2020/07/5-1024x1024.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>Made me become a digital nomad</figcaption></figure></div>



<div><p>The “ugly side” of the remote work can sometimes be quite stressful and exhausting. You know that case when you plan a new release deployment and on the very day, in the midst of it, your power grid goes out, or the internet connection goes down. Usually, you tend to keep some sort of a backup approach for these, but they’re often not that effective. &nbsp;</p></div>



<div><p>Also, working remotely means you will quite often work with people in different time-zones, which is in general fine, however, sometimes when it’s something urgent or critical and you’re the one they rely on, then it can lead to a sleepless night(s) and disturbance in your everyday routine. It’s very rare but it can happen, and when it does you need to understand it comes with a job and it’s something you need to fight through.&nbsp;</p></div>







<div><p>There are a couple of things I tend to use on all my projects. Given that I work remotely quite often I’d need to do some sort of communication with clients or colleagues. For these I find Slack and Zoom to be precisely what I need and what fulfils my necessities.&nbsp;</p></div>



<div><p>For more technical stuff I always use a GIT repository, most often on BitBucket or GitHub. A task management tool is, in my opinion, a must have, and for these I usually circle between Basecamp, Jira or Kanbanery. A good IDE is also a vital part of your project performance and here I reside much on PHPStorm and (sometimes) Sublime.&nbsp;</p></div>



<div><p>Finally, having a virtual project setup and environment proved to be very efficient and speeds up some of the necessary work processes, so for those I like to use Docker or Vagrant.&nbsp;</p></div>



<h2 id="7-your-most-exciting-hilarious-experience-since-you-started-working-remotely">7. Your most exciting/ hilarious experience since you started working remotely.</h2>



<div><p>Meeting someone you’ve been working with for quite a while in person is truly a wonderful experience. You can actually work with someone, talk and chat even for a year or so without actually meeting them in person. Then when you do for the first time you get a strange feeling of a very familiar thing you have never seen before. Kind of like deja vu.&nbsp;</p></div>



<div><p>Working remotely gives you a chance to meet and get to know people from all around the world, and to understand their culture and the way of living better. You’d be amazed how things can be different if you just travel a couple of hours by plane, in any direction.&nbsp;</p></div>



<h2 id="8-what-is-your-golden-advice-to-a-new-remote-worker">8. What is your golden advice to a new remote worker?</h2>



<blockquote><p>Simply put – in the words of Jeremy Irons from “Lion King” – Be Prepared. Plan your life and plan your activities accordingly. You’ll hit an obstacle from time to time, it’s going to be tough, but if you are prepared you’ll push through it and will continue to grow.&nbsp;<br></p></blockquote>



<div><p>Always be polite and professional when talking to your clients, even if you think that they do not deserve it. Maintaining a good and friendly relationship will make stuff easier when something critical pops up (and it always does).&nbsp;</p></div>



<div><p>Be responsible and be professional towards your work. Make sure to deliver the work in agreed terms and timelines, and make sure the results of your work are of high quality. This will make your life much easier in the years to come, as a satisfied client is always a good source for new potential clients.&nbsp;</p></div>



<div><p>Finally, enjoy the ride! Explore new options, new adventures, new opportunities, pursue what you want and like, and not what somebody else might like. Your life will flourish.&nbsp;</p></div>



<h2 id="9-how-do-you-see-your-career-shaping-up-and-your-goals">9. How do you see your career shaping up and your goals?</h2>



<div><p>There are so many things I still want to learn and achieve professionally. I’m a senior full-stack developer, and yet I feel like I’m still at the beginning of the road, there are so many things to try out and so many options to explore. The very nature of my profession requires me to constantly learn new things and increase my knowledge, as the technology and system architecture evolves from day to day. But being a freelancer gives me more power in determining which way I want to go and how I want to develop, and just that is what I’m really satisfied with.&nbsp;</p></div>



<h2 id="10-how-do-you-expect-remote-working-to-evolve-in-the-future">10. How do you expect remote working to evolve in the future?</h2>



<div><p>Most digital professions are location independent. I think in the time to come, more and more companies will follow the path of quite a few very successful remote companies and will try to organise their departments in such a way. This will not be definitive, for sure, because some types of work require a constant collaboration and heavy brainstorming sessions, which are definitely more efficient when you are in person with a group of people. Also, remote work is not a blessing to everyone, someone likes the …</p></div></div></div></div></div></article></main></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://content.remote.tools/leaving-a-steady-corporate-job-to-pursue-a-freelancing-career-was-a-risk-initially/">https://content.remote.tools/leaving-a-steady-corporate-job-to-pursue-a-freelancing-career-was-a-risk-initially/</a></em></p>]]>
            </description>
            <link>https://content.remote.tools/leaving-a-steady-corporate-job-to-pursue-a-freelancing-career-was-a-risk-initially/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747286</guid>
            <pubDate>Mon, 06 Jul 2020 12:46:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[M60 – Open-Source USB&BLE, Hot-Swappable Mechanical Keyboard Powered by Python]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23747255">thread link</a>) | @kfihihc
<br/>
July 6, 2020 | https://makerdiary.com/pages/m60-mechanical-keyboard | <a href="https://web.archive.org/web/*/https://makerdiary.com/pages/m60-mechanical-keyboard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="PageContainer">

    <main id="MainContent" role="main" tabindex="-1">
      <div id="shopify-section-landing-page-hero"><div data-section-id="landing-page-hero" data-section-type="hero-section">
  
     <a href="https://github.com/makerdiary/python-keyboard" aria-label="View source on GitHub"></a>
  
<div id="Hero-landing-page-hero" data-layout="full_width" data-bg="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_300x300.jpg?v=1593771860" data-bgset="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_180x.jpg?v=1593771860 180w 120h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_360x.jpg?v=1593771860 360w 240h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_540x.jpg?v=1593771860 540w 360h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_720x.jpg?v=1593771860 720w 480h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_900x.jpg?v=1593771860 900w 600h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1080x.jpg?v=1593771860 1080w 720h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1296x.jpg?v=1593771860 1296w 864h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1512x.jpg?v=1593771860 1512w 1008h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1728x.jpg?v=1593771860 1728w 1152h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1950x.jpg?v=1593771860 1950w 1300h,
    
    
    
    
    
    
    
    
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0.jpg?v=1593771860 2048w 1365h" data-sizes="auto" data-parent-fit="cover"><div>
        <div><h2>M60 Mechanical Keyboard</h2><p>An Open Source, USB &amp; BLE 5.0, Modular, Hot-Swappable, 60% Keyboard powered by Python</p><p><a href="https://makerdiary.com/products/m60-mechanical-keyboard-pcba" aria-label="Pre-Order PCBA: M60 Mechanical Keyboard PCBA (Pre-Order)">Pre-Order PCBA</a></p></div>
      </div>
    </div>
    </div>



</div>





<div id="shopify-section-landing-page-map">

<div id="MapSection--landing-page-map" data-section-id="landing-page-map" data-section-type="map">
  <div>
    <div>
      <div>
        
        
          <h3>The Story of M60</h3>
        
        
          <p>A few months ago, we made a hand-wired keyboard and brought Python to it. This project received plenty of attention, but it is difficult for most people to make such a keyboard. We believe that a Python powered keyboard will make a big difference. We'd really like to take this work further, so we start to design a new keyboard hardware. It is called <em>M60</em>.</p>
          
        
      </div>
    </div>
    
  </div>
</div>




</div>

<div>

<div id="shopify-section-landing-page-feature-row">
<div>
  

  <div>
    
      
    <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-connectivity-1_1080x_5c2254bf-6f4a-41b8-a449-1c0f4088f20a_600x600@2x.jpg?v=1593785687" alt="" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-connectivity-1_1080x_5c2254bf-6f4a-41b8-a449-1c0f4088f20a_200x200.jpg?v=1593785687" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-connectivity-1_1080x_5c2254bf-6f4a-41b8-a449-1c0f4088f20a_{width}x.jpg?v=1593785687">

        
      
    </p>
  
    

    <div>
      
        <h2>USB Type-C &amp; BLE 5.0 Connectivity</h2>
      
      
        <p>M60 uses Nordic’s nRF52840 SoC to provide USB Type-C wired and Bluetooth LE 5.0 wireless connectivity. It can easily pair to your PC, laptop, smartphone, or tablet with Bluetooth LE.</p>
      
      
    </div>

    
  </div>
</div>


</div>

<div id="shopify-section-landing-page-feature-row-1">
<div>
  

  <div>
    

    <div>
      
        <h2>Powered by Python</h2>
      
      
        <p>It's not just a keyboard but also a USB drive containing Python files. Its Python code can be changed with any text editor and executed simultaneously, which makes it super easy to customize the keyboard or to add a new function. No need to download any software or setup a development environment.</p>
      
      
    </div>

    
      
    <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-2-python_1_600x600@2x.jpg?v=1593761089" alt="" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-2-python_1_200x200.jpg?v=1593761089" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-2-python_1_{width}x.jpg?v=1593761089">

        
      
    </p>
  
    
  </div>
</div>




</div>

<div id="shopify-section-landing-page-feature-row-2"><div>
  

  <div>
    
      
    <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-3_600x600@2x.jpg?v=1593752688" alt="" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-3_200x200.jpg?v=1593752688" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-3_{width}x.jpg?v=1593752688">

        
      
    </p>
  
    

    <div>
      
        <h2>Modular, Hot-Swappable &amp; Solder-Free</h2>
      
      
        <p>To take advantage of the <a href="https://makerdiary.com/products/nrf52840-m2-module" title="nRF52840 M.2 Module w/ PCB Antennas">removable M.2 module</a> and hot-swap sockets, assembly made easy. Everyday we find innovative assembly solutions to make things even easier for you because we care about the quality of our products.</p>
      
      
    </div>

    
  </div>
</div>




</div>



</div>

<div id="shopify-section-landing-page-logo-list">

<div>
  
    
  

  
    <ul>
      
        <li>
          
          
              
          
          
          
            <p>GitHub</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Cross-platform</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Multi-connections</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Python</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>60% Layout</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Multi-layers</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Highly configurable</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>RGB Lighting</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Battery</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>NKRO - Anti-ghost</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Productivity</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Modular Design</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>BLE 5.0</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>USB Type-C</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>NFC</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Hot-swappable</p>
          
        </li>
      
    </ul>
  

  
</div>




</div>

<div id="shopify-section-landing-page-hero-small">


<div data-section-id="landing-page-hero-small" data-section-type="hero-section"><div id="Hero-landing-page-hero-small" data-layout="full_width" data-bg="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_300x300.jpg?v=1593684925" data-bgset="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_180x.jpg?v=1593684925 180w 65h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_360x.jpg?v=1593684925 360w 130h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_540x.jpg?v=1593684925 540w 194h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_720x.jpg?v=1593684925 720w 259h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_900x.jpg?v=1593684925 900w 324h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1080x.jpg?v=1593684925 1080w 389h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1296x.jpg?v=1593684925 1296w 466h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1512x.jpg?v=1593684925 1512w 544h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1728x.jpg?v=1593684925 1728w 622h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1950x.jpg?v=1593684925 1950w 702h,
    
    
    
    
    
    
    
    
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x.jpg?v=1593684925 2048w 737h" data-sizes="auto" data-parent-fit="cover"><div>
        <div><p>We have prepared a few M60 PCBAs for developers before launch. If you really want to get involved early in the process, you can apply for an engineering sample.</p><p><a href="https://forms.office.com/Pages/ResponsePage.aspx?id=DQSIkWdsW0yxEjajBLZtrQAAAAAAAAAAAAa__aO1qn1UQktDRjFSN1FWRFRFRU0yRzhOT0xIUlNKSi4u" aria-label="Request a Sample">Request a Sample</a></p></div>
      </div>
    </div>
    </div>



</div>



<div id="shopify-section-landing-page-feature-update">
<div>
  
    
  

    <ul>
      
        <li>
          <article aria-labelledby="FeaturedBlogTitle-0-landing-page-feature-update">
            <header>
              <a href="https://makerdiary.com/blogs/mechanical-keyboards/the-story-of-m60-mechanical-keyboard">
                
                  
                  


                  <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/articles/m60-feature-row-1-1080x_1024x1024_45ae6d5b-e37c-4137-a179-bf1f89d42730_345x345@2x.jpg?v=1593768689" alt="M60 Mechanical Keyboard - from Prototype to Production" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/articles/m60-feature-row-1-1080x_1024x1024_45ae6d5b-e37c-4137-a179-bf1f89d42730_300x300.jpg?v=1593768689" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/articles/m60-feature-row-1-1080x_1024x1024_45ae6d5b-e37c-4137-a179-bf1f89d42730_{width}x.jpg?v=1593768689">
                    </p>
                  
                

                <h3 id="FeaturedBlogTitle-0-landing-page-feature-update">
                  M60 Mechanical Keyboard - from Prototype to Production
                </h3>
              </a>

              

              
                <span>
                  <time datetime="2020-07-03T08:49:00Z">July 3, 2020</time>
                </span>
              
            </header>

            <div>
              <p><span>A few months ago, we made a hand-wired keyboard powered by Python. It's a typical prototype, which got a lot of feedback. So we decided to turn the prototype into production, to make a new keyboard called M60.</span>
                
              </p>

              

              <ul>
                <li>
                  <a href="https://makerdiary.com/blogs/mechanical-keyboards/the-story-of-m60-mechanical-keyboard" aria-label="Read more: M60 Mechanical Keyboard - from Prototype to Production">
                    Read more
                  </a>
                </li>

                
              </ul>
            </div>
          </article>
        </li>
      
        <li>
          <article aria-labelledby="FeaturedBlogTitle-1-landing-page-feature-update">
            <header>
              <a href="https://makerdiary.com/blogs/mechanical-keyboards/a-hand-wired-usb-bluetooth-keyboard-powered-by-python">
                
                  
                  


                  <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/articles/python-inside-keyboard_345x345@2x.png?v=1593765150" alt="Hand-wiring a USB &amp; Bluetooth keyboard powered by Python" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/articles/python-inside-keyboard_300x300.png?v=1593765150" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/articles/python-inside-keyboard_{width}x.png?v=1593765150">
                    </p>
                  
                

                <h3 id="FeaturedBlogTitle-1-landing-page-feature-update">
                  Hand-wiring a USB &amp; Bluetooth keyboard powered by Python
                </h3>
              </a>

              

              
                <span>
                  <time datetime="2020-05-04T11:39:00Z">May 4, 2020</time>
                </span>
              
            </header>

            <div>
              <p>Before making this keyboard, I knew Python can be used in a microcontroller thanks to MicroPython and its variant CircuitPython. But I did not know Python can work so well and be so powerful in a keyboard. It's beyond my expectation.</p>

              

              <ul>
                <li>
                  <a href="https://makerdiary.com/blogs/mechanical-keyboards/a-hand-wired-usb-bluetooth-keyboard-powered-by-python" aria-label="Read more: Hand-wiring a USB &amp; Bluetooth keyboard powered by Python">
                    Read more
                  </a>
                </li>

                
              </ul>
            </div>
          </article>
        </li>
      
    </ul>
  

  
    
    
  
</div>




</div>


    </main>

    

    

  </div></div>]]>
            </description>
            <link>https://makerdiary.com/pages/m60-mechanical-keyboard</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747255</guid>
            <pubDate>Mon, 06 Jul 2020 12:42:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Logic Pro X (Getting Started with Music Production)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747236">thread link</a>) | @tosh
<br/>
July 6, 2020 | https://artlapinsch.com/2020/04/24/learning-logic-pro-x-getting-started-with-music-production/ | <a href="https://web.archive.org/web/*/https://artlapinsch.com/2020/04/24/learning-logic-pro-x-getting-started-with-music-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1600">
			
	
	<div>
		<div>
			<p>After years of daydreaming I finally started making music myself. 🎹</p>
<p>This post is mainly a collection of concepts/resources/links/learnings that have helped me.</p>
<hr>

<h3>Selecting your Workhorse: Which DAW?</h3>
<p>Real studio production is for the 1% <em>(professional musicians/producers; people with a lot of money to spare)</em>.</p>
<p>For the rest of us music creation happens on a computer – specifically in a <strong>DAW</strong> <em>(Digital Audio Workstation)</em>.</p>
<p>There are a lot of <a href="https://blog.landr.com/best-daw/" target="_blank" rel="noopener">guides</a> on the Internet, but effectively the decision comes down to the following:</p>
<ul>
<li><strong>Budget:</strong> How much are you willing/able to spend?</li>
<li><strong>Platform:</strong> MacOS vs. Windows vs. Linux all might have different restrictions</li>
<li><strong>Network:</strong> What are your friends using and recommending?</li>
<li><strong>Preference:</strong> Familiarity with a workflow or certain features that you specifically want from your DAW.</li>
</ul>
<figure><img src="https://pics.me.me/ableton-cubase-logic-pro-x-reason-100-hardware-which-daw-3837042.png" alt="I'm the tattooed guy. (source: https://bit.ly/34ZEaUz)" width="500" height="387"><figcaption>I’m the tattooed guy. (source: <a href="https://bit.ly/34ZEaUz" rel="nofollow">https://bit.ly/34ZEaUz</a>)</figcaption></figure>
<p>My situation when deciding:</p>
<ol>
<li>I didn’t know if music production is just a momentary itch or rather a hobby I’d do mid-/long-term &gt;&gt;&gt; hence didn’t want to spend too much</li>
<li>I had a MacBook</li>
<li>Most of my friends were using Ableton <em>(b/c Berlin)</em> but I heard that Logic Pro X &amp; ProTools are standards in many studios across the world</li>
</ol>
<p>Ultimately I chose <strong>Logic Pro X</strong> since it offers the full version for $199 <em>(thousands of instruments, powerful stock plugins/effects, etc.)</em> – I also considered Ableton Live 10 but it was significantly more expensive for the full version.</p>
<p>Most DAWs offer free trials <em>(<a href="https://www.ableton.com/en/trial/" target="_blank" rel="noopener">Ableton</a> + <a href="https://www.apple.com/logic-pro/" target="_blank" rel="noopener">Logic</a> currently offer 90 day trials)</em>.</p>
<h3>Other Tools: What Do You <em>Actually</em> Need?</h3>
<h5><strong>Must Have</strong></h5>
<ul>
<li><strong>Computer:</strong> Your computer is your studio</li>
<li><strong>Headphones:</strong> If you invest in one thing of equipment it should be a good pair of headphones <em>(comfortable; good sound; good insulation [if you prefer])</em>. I’m using a pair of <a href="https://www.amazon.de/Sony-kabelloser-High-Resolution-Cancelling-Akkulaufzeit-Schwarz/dp/B01LD5GO5U" target="_blank" rel="noopener">Sony MDR 1000x</a> headphones.</li>
</ul>
<h5><strong>Next Steps</strong></h5>
<ul>
<li><strong>Audio Interface:</strong> I use a <a href="https://www.native-instruments.com/en/products/komplete/audio-interfaces/komplete-audio-6/" target="_blank" rel="noopener">Native Instruments Komplete Audio 6</a> to connect the various elements <em>(headphones; studio monitors; midi input; external audio sources; etc.)</em> of the setup.</li>
<li><strong>Midi Keyboard:</strong> Makes it easier to play/enter sounds in your DAW. I use a <a href="https://www.thomann.de/de/akai_mpk_mini_mk2.htm" target="_blank" rel="noopener">AKAI MPK mini mk2</a>. Get’s the job done.</li>
<li><strong>Studio Monitors:</strong> Having headphones on 24/7 can accelerate ear fatigue. It helps to have an external source of sound. I currently rock a pair of <a href="https://www.presonus.com/products/Eris-E45" target="_blank" rel="noopener">presonus eris e4.5</a> on <a href="https://www.justmusic.de/Recording/Studiomonitore/Zubehoer-fuer-Studiomonitore/Justin-SPS-Desktop-Monitor-Stand?utm_source=PSM&amp;utm_medium=Guenstiger&amp;utm_term=10026396" target="_blank" rel="noopener">justIn stands</a> so that the speakers are on head/ear level.</li>
<li><strong>Audio Recorder:</strong> If you want to start recording audio <em>(guitar; voice; DJ set from mixer; ambient sound as samples)</em> then a good audio recorder does the trick. I decided Xoom &amp; Tascam recorders and went for the <a href="https://tascam.com/us/product/dr-40x/top" target="_blank" rel="noopener">Tascam DR-40X</a> since (1) it was recommended by a friend and (2) it seems that it does not need an attenuator when recording DJ sets.</li>
</ul>
<h5>Nice to Have</h5>
<ul>
<li><strong>Synthesizer:</strong> If you want to play around with a physical box instead of typing in commands into a computer keyboard you should go for a digital or analogue <a href="https://www.youtube.com/watch?v=UmcOvAv-egI" target="_blank" rel="noopener">synth</a>. I snagged a used <a href="https://www.korg.com/us/products/dj/monotribe/" target="_blank" rel="noopener">Korg monotribe</a> from ebay. There’s something about haptic play with instruments – it seems to accelerate ‘understanding/grasping’. // With them you can do all sorts of crazy modular synthesis as explained in the video below:</li>
</ul>
<p><span><iframe width="1088" height="612" src="https://www.youtube.com/embed/vvBl3YUBUyY?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<h3>Picking Projects: Original Tracks vs. Remixes?</h3>
<p>It’s much easier for me to deliver output if I have a deadline and accountability towards someone.</p>
<p>That’s why I decided to focus on remixes for a start. A couple of benefits I get out of that:</p>
<ul>
<li><strong>Inspiration:</strong> Remixing means re-imagining an existing piece of music. You can use either element of the original <em>(key of the track ; melody; rhythm; mood/vibe; etc.)</em> – you don’t start from zero.</li>
<li><strong>Samples:</strong> If someone shares stems with you it’s legally cleared. Avoids headaches. <em>(Let’s be real… at the beginning no one is going to listen to the music // chances are low that you get a letter from the rights holders)</em>. Still, better safe than sorry.</li>
<li><strong>Accountability:</strong> If you promise a remix you have to deliver. If not, your reputation suffers. That’s a good incentive.</li>
</ul>
<p>My first project was a remix of a <a href="https://soundcloud.com/borfd" target="_blank" rel="noopener">friend</a>‘s track:</p>


<hr>

<p>So, you want to produce your first track. What now? 🤔</p>
<h3>Core Idea: How to Find Inspiration?</h3>
<p>I recently watched a Masterclass with Hans Zimmer (film composer) where he talks about starting with a <strong>core idea</strong>. Usually something simple enough to play with one finger on a piano. It is easier to expand a simple idea than finding simplicity in a complex idea.</p>
<p>When I start working on a pice of music I go through the following points:</p>
<ul>
<li><strong>Emotion:</strong> Which emotions do I want to trigger? Is it rather melancholic or happy?</li>
<li><strong>Tempo:</strong> Is it fast or slow?</li>
<li><strong>Sound:</strong> Does the sound need recognizable elements? Classical music has orchestral sounds, Maya music has flutes and wooden mallets, etc.</li>
<li><strong>Inspiration:</strong> For a remix, do I like the vocals, the synth, the bass line, the percussion? What can I start with – remove the rest – and then build upon?</li>
</ul>
<h3>Building Melodies: How to Get Chord Progressions?</h3>
<p>Music theory to the rescue:</p>
<p><span><iframe width="1088" height="612" src="https://www.youtube.com/embed/rgaTLrZGlk0?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;start=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Once I find a key I like I would search for standard chords and progressions in said key. An example for <a href="http://www.piano-keyboard-guide.com/key-of-c-minor.html" target="_blank" rel="noopener">C minor</a> would be the following:</p>
<figure><img src="https://i1.wp.com/www.piano-keyboard-guide.com/wp-content/uploads/2015/04/piano-chords-in-the-key-of-c-minor-746x1024.png" alt="Standard chords in C minior key (source: https://bit.ly/3ePllIf)" width="746" height="1024"><figcaption>Standard chords in C minior key (source: <a href="https://bit.ly/3ePllIf" rel="nofollow">https://bit.ly/3ePllIf</a>)</figcaption></figure>
<p>This gives a good starting point to play around with melodies and standard progressions. Obviously, if you only stick to standard progressions it can sound predictable but that’s the joy of uncovering a melody that works for you.</p>
<h3>Creating Depth: Sound Design and Layering Sounds</h3>
<p><a href="https://www.quora.com/What-is-layering-in-music-production-and-how-to-do-it-on-FL-studio" target="_blank" rel="noopener">Layering</a> is the name of the game.</p>
<p>Usually at this step I would do the following:</p>
<ul>
<li>Take the core idea and loop it as a 4-bar or 8-bar loop</li>
<li>Add tracks/channels with new sounds to see what fits <em>(try sounds across the entire sound spectrum: low / low-mids / high-mids / high)</em></li>
<li>When all elements are in place tweak/adjust the sounds of each track/channel so that I like it</li>
</ul>
<h3>Building the Narrative: Arranging the Track</h3>
<p>When all sounds are selected it is time to go from a repetitive 4-/8-bar loop to an actual arrangement. I usually go through the following steps:</p>
<ul>
<li><strong>Structure:</strong> Think of simple arrangement structure <em>(Intro &gt; Beat Intro &gt; Verse &gt; Break &gt; Verse &gt; Breakdown &gt; Buildup &gt; Verse &gt; Outro)</em></li>
<li><strong>Curation:</strong> Select which elements go in which section</li>
<li><strong>Listen:</strong> Listen from start to finish to hear what needs improvement <em>(e.g. ‘sounds too busy’ &gt; solution: ‘remove elements’; etc.)</em></li>
<li><strong>Rinse &amp; Repeat:</strong> This step takes quite some time since now it’s detail work</li>
</ul>
<figure data-shortcode="caption" id="attachment_1616" aria-describedby="caption-attachment-1616"><img data-attachment-id="1616" data-permalink="https://artlapinsch.com/2020/04/24/learning-logic-pro-x-getting-started-with-music-production/screenshot-2020-04-24-at-15-25-09/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png" data-orig-size="2560,1440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Learning Logic Pro X: Getting Started with Music Production" data-image-description="<p>Learning Logic Pro X: Getting Started with Music Production</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=1024" src="https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=1088" alt="Arrangement + Mixing View of One of My Remixes" srcset="https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=1088 1088w, https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=2176 2176w, https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=150 150w, https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=300 300w, https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=768 768w, https://qndtoolkit.files.wordpress.com/2020/04/screenshot-2020-04-24-at-15.25.09.png?w=1024 1024w" sizes="(max-width: 1088px) 100vw, 1088px"><figcaption id="caption-attachment-1616">Arrangement + Mixing View of One of My Remixes</figcaption></figure>
<h3>Mixing/Mastering: Making It Sound Good</h3>
<p>This step is still so far above my head but these videos have helped to grasp the basics of mixing:</p>
<p><span><iframe width="1088" height="612" src="https://www.youtube.com/embed/vry9ZDGr56E?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p><em>* This section will be extended in the future.&nbsp;</em></p>
<hr>

<p>2 main ideas have been helpful:</p>
<h3>Simplicity</h3>
<ul>
<li><strong>Core Idea:</strong> Finding a simple element as a starting point for production.</li>
<li><strong>Setup:</strong> Starting exclusively with stock/default plug-ins in Logic Pro X and going deep in the standard setup vs. remaining shallow in an abundance of 3rd-party plug-ins.</li>
<li><strong>Tracks:</strong> Keeping tracks simple at 10-15 elements max.</li>
<li><strong>Constraints:</strong> Time/tooling/idea constraints are a good and fuel creativity. That’s why I’m starting with remixes.</li>
</ul>
<h3>Hygiene</h3>
<ul>
<li><strong>Version Control:</strong> Save every major update to your track&nbsp;<em>(e.g. new instrument added; drum pattern adjusted; etc.) </em>is saved as a new version of the project (v001, v002, v003…)</li>
<li><strong>Backups:</strong> After a session save the latest version of your track in cloud storage or on an external hard drive.</li>
<li><strong>Shortcuts:</strong> Learn your tool and how to use it efficiently.</li>
<li><strong>Standardization:</strong> Standardize naming conventions for your tracks/channels (e.g. Lead_…; Vox_…; SFX_…) and bundle/color/route them for faster work.</li>
</ul>
<hr>
<p><em>Thank you for reading this post.&nbsp;</em></p>
<p><em>I’m always looking for collaboration opportunities, so if you are producing/mixing/etc. please</em><em>&nbsp;<a href="https://soundcloud.com/artlapinsch" target="_blank" rel="noopener">get in touch</a>.&nbsp;</em></p>

<hr>
<h2><b>Helpful Resources</b></h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=rgaTLrZGlk0&amp;t=1s" target="_blank" rel="noopener">Learn music theory in half an hour.</a> <em>(Andrew Huang)</em> – Good intro.</li>
<li><a href="https://learningmusic.ableton.com/">Get started making music</a> <em>(Ableton) –&nbsp;</em>Fun little introduction to making electronic music. Geared towards Ableton’s DAW/workflows.</li>
<li><a href="https://www.youtube.com/watch?v=hU5XhG5Ywbk&amp;list=PLXmi76euGSyzX8KMPAHJPyOSZy5w4CsV9" target="_blank" rel="noopener">Logic Pro X – Video Tutorial Series</a> <em>(Music Tech Help Guy) –&nbsp;</em>Best tutorial channel for Logic Pro X. Solid progression and goes into sufficient detail.</li>
<li><a href="https://www.youtube.com/channel/UCTNAGAxqqanthoCgmrbHbBA/videos" target="_blank" rel="noopener">How To Series</a> <em>(Julien Earle)</em> – Amazing track deconstruction/production videos on various styles of electronic music. [recommended by my boys <a href="https://mannwife.bandcamp.com/" target="_blank" rel="noopener">Man &amp; Wife</a>]</li>
<li><a href="https://www.attackmagazine.com/technique/" target="_blank" rel="noopener">Technique</a> <em>(Attack Magazine)</em> – Great collection of tutorials/in-depth walk-throughs ranging from modular synthesis to beat programming.</li>
<li><a href="https://www.residentadvisor.net/features.aspx?series=production" target="_blank" rel="noopener">The Art of Production</a> <em>(Resident Advisor)</em> – Producers talk about their philosophies and techniques. Very cool stuff.</li>
<li><span><a href="https://www.youtube.com/watch?v=Ce8r9RfK1wk&amp;list=PL_QcLOtFJOUgNxURr8B4lNtf_3e9fWZzl" target="_blank" rel="noopener">Rhythm Roulette</a> <em>(Mass Appeal)</em> – Artists are blindfolded and pick 3 vinyls at random, then they have to come up with something interesting.</span></li>
<li><a href="https://www.youtube.com/watch?v=-mt-S7L7va4&amp;list=PLg5ScSqSDXsvXVvNqW42AjfOmPjIupYZH" target="_blank" rel="noopener">Against the Clock</a> <em>(Fact Magazine)</em> – Artists have 10 minutes to produce the basis for a track.</li>
<li><a href="http://everynoise.com/" target="_blank" rel="noopener">Every Noise</a> – Interactive overview of all styles of music <em>(from latin tech house to jewish cantorial)</em>. Crazy!</li>
</ul>
<h2>Related Blog Posts</h2>
<ul>
<li><a href="https://artlapinsch.com/2019/08/18/sound-and-hearing-protection/" target="_blank" rel="noopener">Sound and Hearing Protection: Best Practices for Musicians</a></li>
<li><a href="https://artlapinsch.com/2019/09/28/spotify-takeover/" target="_blank" rel="noopener">Music Is the Answer: Spotify Takeover for xpsr</a></li>
<li><a href="https://artlapinsch.com/2019/11/24/one-night-in-istanbul-disko-no-disko-x-mitte-karakoy/" target="_blank" rel="noopener">One Night in Istanbul: Disko No Disko x Mitte Karakoy</a></li>
</ul>
					</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</div>
</article></div>]]>
            </description>
            <link>https://artlapinsch.com/2020/04/24/learning-logic-pro-x-getting-started-with-music-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747236</guid>
            <pubDate>Mon, 06 Jul 2020 12:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Face Search Engine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23747157">thread link</a>) | @stevoo
<br/>
July 6, 2020 | https://pimeyes.com/en/ | <a href="https://web.archive.org/web/*/https://pimeyes.com/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="search-component">
<video playsinline="playsinline" autoplay="autoplay" muted="muted" loop="loop" poster="https://pimeyes.com/assets/images/search_video2.jpg">
<source src="https://pimeyes.com/assets/images/search_video2.mp4" type="video/mp4">
<source src="https://pimeyes.com/assets/images/search_video3.webm" type="video/webm">
</video>
<div>
<div>

<p>UPLOAD YOUR PHOTO AND FIND WHERE YOUR FACE IMAGE APPEARS ONLINE. START PROTECTING YOUR PRIVACY.</p>
</div>
 </div>
<svg width="40px" height="100%" viewBox="0 0 247 390" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:1.5;">
<path id="wheel" d="M123.359,79.775l0,72.843" style="fill:none;stroke:#fff;stroke-width:20px;"></path>
<path id="mouse" d="M236.717,123.359c0,-62.565 -50.794,-113.359 -113.358,-113.359c-62.565,0 -113.359,50.794 -113.359,113.359l0,143.237c0,62.565 50.794,113.359 113.359,113.359c62.564,0 113.358,-50.794 113.358,-113.359l0,-143.237Z" style="fill:none;stroke:#fff;stroke-width:20px;"></path>
</svg> </section>
<section id="mainpage-content">
<div id="description">
<p>
PimEyes is a powerful face search engine that will help you find your face in the Internet. PimEyes focuses only on faces. Composition and colors of the image are not important. Our engine does not compare haircut, only facial features matter. It supports various scenarios - for example, authenticate people for access, protect privacy against scammers or unauthorized photo usage.
</p>
</div>


<div id="try-alerts">
<div>
<div>
<h3>PimEyes <span>Alerts</span></h3>
<p>Get the report when we find face similar to yours.<br>It’s simple.<br>It’s free.</p>
<p><a href="https://pimeyes.com/en/alerts" data-action-name="mainpage_alerts_info">
<span>Learn more</span>
</a>
</p></div>

</div>
</div>
<div id="try-premium">
<div>
<p><img src="data:image/png;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs=" data-src="/svg/logo-white-premium.svg" alt="PimEyes Premium" width="252" height="82"></p><div>
<p>
The best search results are available only for premium members. With premium access you will improve quality of search and unlock all results.
</p>
<p><a href="https://pimeyes.com/en/premium" data-action-name="mainpage_premium_info">
<span>Get premium</span>
</a>
</p></div>
</div>
</div>
</section>







</div></div>]]>
            </description>
            <link>https://pimeyes.com/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747157</guid>
            <pubDate>Mon, 06 Jul 2020 12:28:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wirecard: What went wrong and what BaaS need to do about regulations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747074">thread link</a>) | @bankingnews
<br/>
July 6, 2020 | https://marcelvanoost.nl/blog/wirecard-went-wrong-baas-need-do-about-regulations | <a href="https://web.archive.org/web/*/https://marcelvanoost.nl/blog/wirecard-went-wrong-baas-need-do-about-regulations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>Wirecard has been one of the biggest accounting scandals in German history and certainly in Europe, so what went wrong? Here is my quick guide and some alternatives.</em></p>
<p>In 2015, the Financial Times began to publish a series of articles called “House of Wirecards”, investigating inconsistencies in the Wirecard’s accounts. The FT suggested there was a whole of €250m in the group’s accounts, Wirecard responded with letters from a UK law firm denying allegations.</p>
<p>That was just the beginning of a stream of allegations and Wirecard’s denial of wrongdoings.</p>
<p>In 2016, anonymous short sellers published a dossier of allegations related to money laundering, which Wirecard denies and German financial regulator - BaFin - started to investigate other allegations of market manipulation. But that didn’t hit Wirecard’s price shares.</p>
<p>Wirecard shares hit a peak price in August 2018, valuing the group at €24bn. At the time Wirecard group had 5,000 employees and processed payments for around 250,000 merchants, prepaid cards and provided contactless technology for smartphone payments.</p>
<p><img src="https://watsnet.s3.us-east-2.amazonaws.com/uploads/media_image/image/8201/normal_Picture_2.png" alt="" width="70%"></p>
<p>Fast forward to June 2020 and Wirecard is supposed to publish audited results of 2019 - that’s when things started to come to light about Wirecard’s accounting. To everyone’s dismay, he group had €1.9bn missing from balances, leaving the fintech sector in turmoil.</p>
<p>How could this happen to a company that had been around 20 years, constantly expanding? The first concrete allegation came about last October when the <a href="https://www.ft.com/content/1e753e2b-f576-4f32-aa19-d240be26e773">Financial Times</a> reported that Wirecard staff would be conspiring to fraudulently inflate sales and profits at Wirecard subsidiaries in Dubai and Dublin and also misleading EY, the group’s auditor for almost a decade.</p>
<p>So, EY went to finally check Wiriecards subsidiaries in Singapore, Philippines and Dubai, and surprisingly (for EY),&nbsp; none of these banks had any dealings with Wirecard. In fact, they never had even dealt with Wirecard’s group. And that’s how the missing €1.9bn was discovered.</p>
<p>The group consisted of the holding company,&nbsp; Wirecard AG, that went bust but they had many subsidiaries like Wirecard Solutions in the UK, Wirecard Bank in Germany, Al Alaam in UAE, just to name a few.</p>
<p>How come all this could get passed BaFin? Well, BaFin claimed that they only regulated Wirecard Bank, the German subsidiary, not Wirecard AG - the holding company.&nbsp; Many experts found it strange that BaFin said the Wirebank is fine but didn’t check the balance sheet of the holding company. Also, nobody believed the FT and no-one looked at EY and their procedure for years.&nbsp;</p>
<p>Now, those who have been hit hard by Wirecard AG going bust were the many startups that used them as their payment system.&nbsp;</p>
<p>Only in the UK, 70 fintechs that used Wirecard Card Solutions (WCS) got their operations suspended and hundreds of thousands customer accounts were frozen by FCA (Financial Conduct Authority), with well known fintechs - Curve, Pockit, Anna Money and Soldo, being affected.&nbsp;</p>
<p>The UK fintech community didn’t see FCA’s decision coming as many fintechs relied on Wirecard solely.&nbsp; In a <a href="https://sifted.eu/articles/wirecard-impact-uk-fintech/">recent interview</a>, Nigel Verdon, founder of open banking platform Railsbank, said: <em>“I think the UK will be hit more than Germany”.&nbsp;&nbsp;</em></p>
<p>As of 30th June, the FCA’s restrictions on Wirecard clients were lifted but It might take weeks, if not months, for the UK fintechs to recover. For instance, Curve has been working hard to migrate their services away from Wirecard and return to business.</p>
<p>Some fintech experts said that the current model of “Banking-as-Service could implode” because of Wirecard. I’m not sure if I completely agree with this statement because the problem isn’t BaaS <em>per se</em> but regulations around it.</p>
<p>Like Chris Skinner said in a <a href="https://thefinanser.com/2020/06/baas-will-continue-and-wirecard-will-lead-to-micro-regulations.html/">recent post</a>:&nbsp; “<em>More granular regulation would reflect the world of BaaS. Regulations would work at process levels rather than at entity levels, and accountability would be at the process level not at the entity level.”</em></p>
<p><strong><em>In your opinion, what kind of new regulations should be implemented?</em></strong></p>
<p><strong><em>Leave your suggestions in the comments section!</em></strong></p>
<h3>Alternatives to Wirecard</h3>
<p>Here is my round up of alternatives to Wirecard:</p>
<p><strong>Railsbank</strong>&nbsp;</p>
<p><a href="https://www.railsbank.com/">Railsbank</a> is a global open banking and regtech platform based in London. Railsbank was the pioneer and innovator in the global Banking as a Platform (BaaP) sector, enabling banks, businesses and brands to define the future of consumer and SME finance.&nbsp; Currently, Railsbank is live and enabling customers in the UK, Europe, SE Asia and the US. It is the only global BaaP player.</p>
<p><strong>Treezor</strong></p>
<p>Founded in Paris, <a href="https://www.treezor.com/en/">Treezor</a> owns a European License and is one of the approved suppliers for MasterCard Prepaid.</p>
<p>Treezor positions itself as a one-stop shop solution, is an electronic money institution with payment services accredited by the French Prudential Supervision and Resolution Authority (ACPR). As an e-money issuer and a payment institution, Treezor is a white label solution dedicated for prepaid cards, e-wallet, marketplaces, crowdfunding and collaborative consumption platforms.</p>
<p><strong>solarisBank</strong></p>
<p><a href="https://www.solarisbank.com/en/">solarisBank</a> is the first Banking-as-a-Service platform with a full banking license that enables companies to offer their own financial products. Through APIs, partners gain access to solarisBank’s modular services including payments and e-money, lending, digital banking as well as services provided by integrated third party providers. The company is able to passport the license to other EEA countries in order to serve business partners in nearly any European country.</p>
<p><strong>Bankable</strong></p>
<p><a href="https://www.bnkbl.com/">Bankable</a> provides Banking as a Service solution. Their core virtual account management platform is available in white-label or via APIs enabling anyone to deploy payment solutions – including virtual account services, e-ledgers, virtual &amp; plastic card programmes, and e-wallet &amp; light banking solutions.</p>
<p>Their key competitive advantage lies in their technology, where their virtual account management platform is core to the broader payment services that they enable.&nbsp;</p>
<p><strong>Contis</strong></p>
<p><a href="https://contis.com/">Contis</a> is an FCA regulated Electronic Money Institution and the principal member of Visa, providing end-to-end banking and payments solutions, including BIN sponsorship, card issuing and payment processing.</p>
<p>Contis also offers its own alternative banking and payments products direct to customers.</p>
<p><strong>PPS</strong></p>
<p><a href="https://www.pps.edenred.com/">PPS</a> is a Mastercard and Visa Principal Member and an FCA regulated Electronic Money Institution, offering a range of services including processing, UK and SEPA banking solutions, BIN sponsorship, eWallet provision, compliance and fraud services, supply chain management, customer services and end-to-end program design and management. It also offers innovative programmes across multiple media and form factors, including physical, virtual and NFC, PPS process from a global in-house processing platform.</p>
<p><strong>Viva Wallet</strong></p>
<p><a href="https://www.vivawallet.com/">Viva Wallet</a> is a European Fintech disruptor on a mission to change how businesses pay and get paid. They&nbsp; are the first European payment services provider entirely cloud-based, over Microsoft Azure. Viva Wallet is a Principal Member of Visa and MasterCard for acquiring and issuing services with direct connectivity to the Card Schemes providing processing services through our own platform.</p>
<p><strong>Rapyd</strong></p>
<p><a href="https://www.rapyd.net/">Rapyd</a> does for fintech what the cloud did for IT - providing “Fintech-as-Service”. Their Global Payments Network connects the company to all the ways the world likes to pay and the infrastructure to create each client’s own fintech solutions, like ewallets, cards and financial services.&nbsp;</p>
<p><strong>Marqeta</strong></p>
<p><a href="https://www.marqeta.com/">Marqeta</a> brings speed and efficiency to card issuing and payment processing with the world's first open API platform. Their platform was built from the ground up to power an innovative payment experience for many of the apps and services you enjoy daily. Today, Marqeta has 350+ employees and operates globally in the US, UK, EU, Canada and soon APAC.</p>
<p><em>Do you want to be the first to read the next weekly overview? Sign up for my Weekly Digital Banking Newsletter&nbsp;</em><a href="https://mailchi.mp/3051a1b88cc4/challengerbanksnewsletter" target="_blank" rel="nofollow noopener"><em>here</em></a><em>.</em></p>
<p><em>Is weekly not enough for you? And do you want to be in the loop with the latest FinTech news every weekday? You should sign up for my Daily FinTech Roundup&nbsp;</em><a href="https://mailchi.mp/3051a1b88cc4/challengerbanksnewsletter" target="_blank" rel="nofollow noopener"><em>here</em></a><em>&nbsp;</em></p>
<p><em>And last but not least: follow me on&nbsp;</em><a href="https://twitter.com/oost_marcel" target="_blank" rel="nofollow noopener"><em>Twitter</em></a><em>&nbsp;or&nbsp;</em><a href="https://t.me/joinchat/AAAAAE-X6LFJtaeSCXibkw" target="_blank" rel="nofollow noopener"><em>Telegram</em></a><em>&nbsp;channel to be the first to hear about any update from the Digital Banking industry!</em></p>          
          </div></div>]]>
            </description>
            <link>https://marcelvanoost.nl/blog/wirecard-went-wrong-baas-need-do-about-regulations</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747074</guid>
            <pubDate>Mon, 06 Jul 2020 12:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Choose a Startup Name]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747071">thread link</a>) | @Headqq
<br/>
July 6, 2020 | https://www.purrweb.com/blog/how-to-choose-a-startup-name/ | <a href="https://web.archive.org/web/*/https://www.purrweb.com/blog/how-to-choose-a-startup-name/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        

                          <p><a href="https://www.purrweb.com/"><i><span>MVP development for startups</span></i></a><i><span> is anything but trivial. The same goes for picking a startup name. Unlike baby names, ‘I do like the way it sounds’ is not the only decision criterion for startups. The name should be clear, catchy, and legally acceptable.</span></i></p>
<p><span>How to come up with an absolutely stunning (not just gut-feeling-based) startup name? This article will give you an answer.</span></p>
<ul>
<li><b>Keywords</b><span>. Come up with a few keywords to get started. You can try Google AdWords to get the keywords people use when searching for similar products. Look for related search queries as well. Then play with the results: mash words together, remove vowels or change certain letters. This is not a magic formula for getting a name that will pocket you billions, but a working option to consider. </span>In case you end up with nothing, steal the keywords your competitors use. Then do the rest.</li>
<li><b>Competitors</b><span>: Get inspiration from rapidly-growing companies that are playing in the same space. Then go for something distinctive, even if a product is</span><del><span> a popular app’s clone</span></del><span> not that unique.</span></li>
</ul>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2.jpg"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-1024x858.jpg" alt="" width="1024" height="858" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-1024x858.jpg 1024w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-300x251.jpg 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2-768x643.jpg 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image2.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></a><span>Are you sure that the world needs another Insta-whatever app? Nah, man. To attract users, you have to create something new&nbsp;</span></p>
<ul>
<li><b>Domain name: </b><span>Is .com available for your app’s name? To search for domain availability, you can use </span><a href="https://www.godaddy.com/"><span>GoDaddy.com</span></a><span> or </span><a href="https://www.networksolutions.com/"><span>NetworkSolutions.com</span></a><span>. We’re not convincing you to ignore other domains (there is a bunch of alternatives like .co, .io or .net), but .com is still the king and remains the most trusted one.</span></li>
<li><b>Trademark. </b><span>There might be no one in your state with the name you’re going to use. But someone in another state might be using it as a trademark. ‘Simply ignore this’ rule doesn’t work here. </span><span>There’s nothing worse than stepping into trademark conflict when trying to expand a business (this typically occurs after a startup team has already spent a lot on app development and marketing).</span></li>
</ul>
<p><span>Find out if your startup name is already registered. If you’re from the USA, you can check it at </span><a href="https://www.uspto.gov/"><span>USPTO.gov</span></a><span> and see whether a certain name has been trademarked or not.&nbsp;</span></p>
<p><span>P.S: Consider consulting an attorney to know exactly your startup name doesn’t infringe on someone else’s trademark.&nbsp;&nbsp;</span></p>
<ul>
<li><b>Social networks</b><span>. Is there anything else to do to choose a startup name? Do a search on websites like Facebook, Linkedin or Instagram (</span><span>anything that might be relevant to your startup promotion in the future) </span><span>and see what you find before maintaining a social media presence.</span></li>
<li><b>App Stores</b><span>: Go to both Apple Store and Google Play and check if there’s someone who already uses the name you want to go with. Even if you think you’ll never need a mobile app. One day you’ll be ready to expand the audience and it would be smart to do app name search beforehand.&nbsp;</span></li>
</ul>
<h2><b>How to choose a startup name? A few words on being ‘clear and catchy’</b></h2>
<p><span>How to come up with something truly memorable and easy-to-get? Check out this example to ensure you clearly understand how to choose a startup name:&nbsp;</span></p>
<p><a href="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.jpg"><img src="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.jpg" alt="" width="1920" height="1080" srcset="https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1.jpg 1920w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-300x169.jpg 300w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-768x432.jpg 768w, https://www.purrweb.com/blog/wp-content/uploads/2020/07/image1-1024x576.jpg 1024w" sizes="(max-width: 1920px) 100vw, 1920px"></a><span>Can you explain what the app ‘TripAdvisor’&nbsp; does? Of course, it provides trip recommendations. Done!</span></p>
<p><span>As for the ‘catchiness’, simply test it out on your own. Gather 10 random people, expose them to a few names and then follow up a week later. The names remembered are catchy. Choose a startup name — this ain’t atomic physics, huh?&nbsp;&nbsp;</span></p>

              </div></div>]]>
            </description>
            <link>https://www.purrweb.com/blog/how-to-choose-a-startup-name/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747071</guid>
            <pubDate>Mon, 06 Jul 2020 12:14:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write good Wiki documentation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23747062">thread link</a>) | @twhitmore
<br/>
July 6, 2020 | http://literatejava.com/documentation/how-to-write-good-wiki-documentation/ | <a href="https://web.archive.org/web/*/http://literatejava.com/documentation/how-to-write-good-wiki-documentation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-567">
	
	<!-- .entry-header -->

		<div>
		<p>Documentation is important. All of us have experienced the challenge of finding the documentation we need, and most of us have struggled to try and write well.&nbsp;&nbsp;But it need not be so difficult.</p>
<p>Following is an easy approach plus a few guidelines that will help to produce &amp; maintain real, usable, documentation easily.</p>

<h2>The Easy Way to Write Documentation</h2>
<p>The easiest way to write documentation, is to start a page quickly and get a couple of sections and basic bullet points down. This will take only 15-30 minutes and captures much of the value. Finish for now.</p>
<p>Over the next day, you’ll likely think of a couple of points you missed.&nbsp; Take 15 minutes to add those in, and wrap the content up.</p>
<p>Once you’ve done this a few times, you’ll find you are capturing the most useful content quickly, and fairly comprehensively; and that doing this takes little difficulty.</p>
<p>It is always possible to spend longer and capture more detail, but much of the value for most audiences is in the big picture. So you do not need to capture the world now.&nbsp;Over time, you and your team, can always return to add more.</p>
<p>Documentation should be a live, as-you-go process which the entire team contributes to.</p>
<p data-pm-slice="1 1 []">The best time to write documentation is when you are working on that area; but don’t hesitate to back-fill gaps as you find them. Frequent small improvements make a big difference.</p>
<h2>Principles</h2>
<p data-pm-slice="1 1 []">Many people struggle to know how to start writing a page, or to know what goals it should fulfill. A few simple principles will help.</p>
<h3>Within the Page</h3>
<p data-pm-slice="1 1 []">Within a single page, a few basics are key:</p>
<ol>
<li><strong>Target the audience.</strong>
<ul>
<li>Think of the audience who will need to read your documentation. They probably have some general technical knowledge, but don’t know your specific feature or acronyms. Express your writing so they can understand.</li>
</ul>
</li>
<li><strong>Identify the page well. </strong>
<ul>
<li>For example, give the page a good title; and provide a concise statement of what the page is about at the top. This is because the first thing readers need, are to find the page and determine whether it relates to their question.</li>
</ul>
</li>
<li><strong>Front-load an overview.</strong>
<ul>
<li>A concise overview enables audiences to understand what something is, and the basic ideas of how it should work. The overview is often the most useful useful and valuable part of the documentation, for the majority of audiences, and should be presented as the first section in the page.</li>
</ul>
</li>
<li><strong>Combine brief narrative with bullet points.</strong>
<ul>
<li>Bullet points are faster to read &amp; write and express clear facts.</li>
</ul>
</li>
<li><strong>Link to related content.</strong>
<ul>
<li>Links are hugely important in Wiki and web content. They show readers what content is specifically related and important, and enable an audience to rapidly explore connected pages &amp; topics to understand the area.</li>
</ul>
</li>
</ol>
<h3>Organizing Content within the Wiki</h3>
<p data-pm-slice="1 1 []">When organizing pages within a Confluence hierarchy, keep these principles in mind to help audiences find &amp; navigate content:</p>
<ol>
<li><b>Structure the hierarchy&nbsp;by Topic or Category.</b>
<ul>
<li>Categories can be: <strong>business function/ audience, software component, feature, lifecycle status</strong>, etc.</li>
<li>Note that some pages can benefit from organizing their child content with more than one dimension. For example, existing features could be grouped by component, while planned features could be grouped under status.</li>
</ul>
</li>
<li><strong>Front-load useful information.</strong>
<ul>
<li>Always ensure that key information such as Overview, Status and Navigation are available on the upper pages;<br>
do not push these down to child pages.</li>
</ul>
</li>
<li><strong>Manage the number of children;</strong> but balance this against cohesiveness and front-loading information.</li>
<li><strong>Keep content cohesive.</strong></li>
<li><strong>Use ‘aspect pages’ or mentions where topics interact across the&nbsp;</strong><b>hierarchy</b>.
<ul>
<li>Placing a contextual mention or aspect page in the other hierarchy, makes the topic clearly visible from the perspective of that audience/ business function/ component.</li>
</ul>
</li>
</ol>
<h2>Writing a Page – 7 Key Steps</h2>
<p data-pm-slice="1 1 []">Here are seven simple steps to help you write a useful page:</p>
<table data-number-column="false" data-layout="default" data-autosize="true">
<tbody>
<tr>
<td><strong>Title for searchability</strong></td>
<td>Title the page by what the audience might be looking for. Use commonly-understood terminology.</td>
</tr>
<tr>
<td><strong>‘Statement of Purpose’ at the top</strong><br>
also, <strong>Status</strong> (if not current &amp; active)</td>
<td>Start the page with 1-2 sentences on what the page is about. Write from the perspective of a reader who is not immediately familiar with the topic, using standard Business English. This will place it into context for the reader, and enable them to easily understand whether the page is relevant to them.</td>
</tr>
<tr>
<td><b>Contents</b></td>
<td>If you’ve got more than a couple of sections of content, add a ‘Table of Contents’ macro before the Overview.</td>
</tr>
<tr>
<td><strong>‘Overview’ section</strong></td>
<td>Write a couple of paragraphs of narrative and/or bullet points, stating the most important points about the topic. Use an H1 or H2 heading.&nbsp;<strong>A clear Overview is often the most important part of the documentation.</strong>
<p>Key aspects to cover in the Overview include:</p>
<ol>
<li><strong>Purpose</strong> and context – what is the purpose of the component/ feature/ topic, and what wider context this exists in.</li>
<li><strong>Lifecycle</strong> – what is its lifecycle? Often a brief statement, but for more complex lifecycles state where it comes from/ is created and where it goes to/ is consumed.</li>
<li><strong>Interactions</strong> – what else does it interact with.</li>
<li>sometimes <strong>Technical Underpinnings</strong> – less important to understanding what something is, but if there’s space in the Overview we can add a simple point or two.</li>
</ol>
</td>
</tr>
<tr>
<td><strong>Brief Narrative + Bullet Points</strong></td>
<td>Use a little narrative first, then get straight into the bullet points. Bullet points are preferable to&nbsp; narrative because:
<ul>
<li>They’re fast &amp; easy to write</li>
<li>They’re easier to read</li>
<li>They avoid wasting time faffing around with all the connecting words needed for narrative writing.</li>
</ul>
</td>
</tr>
<tr>
<td><strong>Detail Sections</strong><br>
(where applicable)</td>
<td>The Overview intends to convey “what it is” in 10-15 seconds. Detail beyond this, should be structured into one or more Detail sections.
<p>If the page is getting longer than two screen-heights or the detail would be useful to less than 20% of the audience or page views (eg. detailed trouble-shooting or technical procedures), consider pushing the less-relevant detail sections down to a child page.</p></td>
</tr>
<tr>
<td><strong>Child Page/ Subcategory Navigation</strong><br>
(where applicable)</td>
<td>Add a “Section” heading and use a Confluence ‘Children’ macro with depth=1 or 2, to show child pages automatically.
<p data-pm-slice="1 1 [&quot;table&quot;,null,&quot;tableRow&quot;,null,&quot;tableCell&quot;,null]">This front-load navigation on the page; and will be self-maintaining, unlike manually curated links.</p>
</td>
</tr>
<tr>
<td><strong>‘See Also’ links</strong></td>
<td>Add a ‘See Also’ heading and bullet-point a few relevant links. These may be useful lateral links, or particularly important child or parent pages. These enable lateral navigation across hierarchy boundaries, and greatly improve the ability of readers to explore &amp; understand a topic.</td>
</tr>
</tbody>
</table>

<h2>Organizing Content – Another 7 Steps</h2>
<p data-pm-slice="1 1 []">While the number is purely coincidental, another seven basic steps will help you organize content:</p>
<table data-number-column="false" data-layout="default" data-autosize="true">
<tbody>
<tr>
<td><strong>Organize the Top Level</strong></td>
<td>The top level is most important, as it where many users start navigating. Lay out a clear structure that addresses business functions, audiences and technical structure in a meaningful way.</td>
</tr>
<tr>
<td>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null]"><b>Structure the hierarchy&nbsp;by Topic or Category</b></p>
</td>
<td>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null,&quot;orderedList&quot;,null,&quot;listItem&quot;,null]">Categories can be: <strong>business function/ audience, software component, feature, lifecycle status</strong>, etc.</p>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null,&quot;orderedList&quot;,null,&quot;listItem&quot;,null]">If you have a few child topics, these can be listed directly. If you have many child topics, group some or all of them under category subpages.</p>
</td>
</tr>
<tr>
<td>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null]"><strong>Front-load useful information</strong></p>
</td>
<td>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null,&quot;orderedList&quot;,null,&quot;listItem&quot;,null]">Always ensure that key information such as Overview, Status etc are available on the upper pages; do not push these down to child pages.</p>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null,&quot;orderedList&quot;,null,&quot;listItem&quot;,null]">The corollary of this is, as a page gets large, to push infrequently-used content down.</p>
</td>
</tr>
<tr>
<td>&nbsp;<strong>Front-load navigation</strong></td>
<td>Category pages should offer a prominent navigation section. The Confluence ‘Children’ macro with depth=1 or depth=2 is great to build quick &amp; easy navigation for readers.
<p>While it’s good to offer the most important child pages/ resources as curated links, prefer to supplement this with a ‘Children’ macro for most navigation as it’s self-maintaining.</p></td>
</tr>
<tr>
<td>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null]"><strong>Manage the number of children</strong></p>
</td>
<td>&nbsp;But balance this against the benefits of cohesiveness and front-loading information.
<ul>
<li>A guideline of five to eight is children is ideal, but should be balanced against other factors.</li>
<li>It is very reasonable to bend the guideline where good reasons exist. It’s common for a top-level page to have 12-15 children, or a major category landing page where numerous facets converge to have 10-14 children.</li>
</ul>
</td>
</tr>
<tr>
<td>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null]"><strong>Keep content cohesive</strong></p>
</td>
<td>Balance this with other factors, but it’s beneficial to keep the most useful aspects of a topic together.
<p>Do consider this in terms of the audience &amp; how often content will be used. Different audiences or infrequently-used content may provide good reasons to split something out.</p></td>
</tr>
<tr>
<td>
<p data-pm-slice="1 1 [&quot;orderedList&quot;,null,&quot;listItem&quot;,null]"><strong>Topics interacting across the&nbsp;</strong><b>hierarchy</b></p>
</td>
<td>Where topics interact across the hierarchy, create an ‘Aspect page’ or mention in that part of the hierarchy.
<ul>
<li>For a small or modest interaction: bidirectional links and either a brief bullet point or a section in the page, might suffice.</li>
<li>For a major interaction: create an ‘Aspect page’ in the other hierarchy, presenting that aspect of the topic. Link this aspect page and the main topic bidirectionally.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<h2>How to Design a Hierarchy</h2>
<p>In a Wiki hierarchy, content should be organized by key factors including organizational purpose, software component, feature area, and specific feature.</p>
<p>The appropriate categorization approach and order in which levels can best be structured, may vary somewhat according to the needs of the particular organization &amp; software product.</p>
<p>In recent roles I have had success with the hierarchies similar to the following:</p>
<ol>
<li>Business Function/ Audience
<ul>
<li>eg. Technical Reference, Developer Guides, Testing, Releasing, Support etc.</li>
<li>Note that we split ‘technical/ architecture reference’ materials from all ‘developer practice/ process how-to’. This enabled a useful separation between actionable guidance &amp; tutorial material, and the ‘why is it designed this way’ reference material.</li>
</ul>
</li>
<li>Software Component</li>
<li>Feature Area</li>
<li>Specific Features
<ul>
<li>Overview, major functionalities, relationships &amp; interactions with other components</li>
</ul>
</li>
<li>Subordinate Details (if needed).</li>
</ol>
<h3>Categorizing Child Pages</h3>
<p>W…</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://literatejava.com/documentation/how-to-write-good-wiki-documentation/">http://literatejava.com/documentation/how-to-write-good-wiki-documentation/</a></em></p>]]>
            </description>
            <link>http://literatejava.com/documentation/how-to-write-good-wiki-documentation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747062</guid>
            <pubDate>Mon, 06 Jul 2020 12:13:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Country-scale detection from 56 annotations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23746916">thread link</a>) | @jre
<br/>
July 6, 2020 | https://cloud.picterra.ch/public/showcase/seges/index.html | <a href="https://web.archive.org/web/*/https://cloud.picterra.ch/public/showcase/seges/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="sections">
    <section id="intro">
      <div>
        
        <p><a href="https://picterra.ch/" target="_blank">Picterra</a> enables users to train custom detectors - deep learning models - and apply them at scale on drone, aerial or satellite imagery. Without writing a single line of code.</p>
        <p>This is an example of how SEGES - one of Picterra's customers - was
          able to detect 26.000 slurry tanks over Denmark in a few hours with only 56
          training annotations. The end goal is to estimate the ammonia emissions.</p>

        <p href="#"><span></span>Scroll to continue</p>
      </div>
    </section>
    <section id="denmark">
      <div>
        <p>SEGES is a part of the agricultural advisory service and owned by the Danish farmers.</p>
        <p>In order to calculate the total Danish emission of ammonia the Ministry of Environment needed
          data on the total number of slurry tanks and information on the coverage of the tanks, as the emission
          factors are lower for covered tanks than from uncovered tanks.</p>

        <blockquote>The area highlighted in white is Denmark</blockquote>
        <p href="#"><span></span>Scroll to continue</p>
      </div>
    </section>
    <section id="detection_example">
      <div>
        <p>To conduct their analysis, SEGES had to detect <i>slurry tanks</i>.</p>
        <p>Slurry tanks are round-shaped objects. There is quite some variety in their appearance
          though because they can be filled or empty and they can have a roof or not.
          They also look similar to silos that are also found near farms.
        </p>
        <p><img src="https://cloud.picterra.ch/public/showcase/seges/slurry_tanks_examples.png"></p><blockquote>The map shows a few example of slurry tanks</blockquote>
        <p href="#"><span></span>Scroll to continue</p>
      </div>
    </section>
    <section id="detection_area_example">
      <div>
        <p>Slurry tanks are built next to farms. So circles around each farm in Denmark were used as detection areas. </p>
        <p>Detection areas focus the detector on specific part of the image to save processing resources and speed up the detection process.</p>
        <blockquote>Detection areas are displayed as purple circles on the map</blockquote>
        <p href="#"><span></span>Scroll to continue</p>
      </div>
    </section>
    <section id="detection_areas">
      <div>
        <p>There are 34,000 such detection areas, spread over the whole country.</p>
        <blockquote>Each purple dot is a detection area</blockquote>
        <p href="#"><span></span>Scroll to continue</p>
      </div>
    </section>
    <section id="detections">
      <div>
        <p>A total of 26000 slurry tanks were detected.</p>
        <p>SEGES combined the detections with internal data about the type of production for each farm to produce area statistics for the various categories. These statistics
        were then used to produce an estimate of slurry tanks ammonia emissions.</p>

        <p href="#"><span></span>Scroll to continue</p>
      </div>
    </section>
    <section id="detections_hexagons">
      <div>
        <p>The detections can be visualized in various ways. For example, this
        is a heatmap visualization.</p>

        <p>Liked this story ? Give <a href="https://picterra.ch/" target="_blank">Picterra</a>
        a try and share it !</p>

        

      </div>
    </section>
  </div></div>]]>
            </description>
            <link>https://cloud.picterra.ch/public/showcase/seges/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746916</guid>
            <pubDate>Mon, 06 Jul 2020 11:52:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How People Learn – The Brain Basics]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23746896">thread link</a>) | @iuliangulea
<br/>
July 6, 2020 | https://iuliangulea.com/blog/how-people-learn-the-brain-basics/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>Have you ever thought about how people learn? What happens inside your brain when you learn some new information or practice a novel skill? And is there a way to enhance the outcomes of learning?</p>
<p>This article is the first in the series on “How People Learn,” in which I invite you to embark on a journey toward a better understanding of the most sophisticated construct in the Universe—the human brain.</p>
<p>And I would like to start with and exercise. You will need a piece of paper and something to write with. When you have them ready, write down the following sentence:</p>
<blockquote>
<p><strong>I can write fast and beautiful.</strong></p>
</blockquote>
<p>It should be pretty easy, if not effortless, isn’t it?</p>
<p>Now, I would like you to write the same sentence one more time, below the first one, but at this time, use the opposite hand (let’s call it the inexperienced hand). Therefore, if you initially wrote the sentence with your right hand, switch your pen to the left side and vice-versa.</p>
<p>Think about how was it now? Unless you are a person that learned to write with both hands, I bet your second sentence is not that beautiful, and you wrote it not that fast either. When I was lecturing at the university and doing this exercise with my students, it took them somewhere between 3 to 10 times longer to write down the second sentence than the first one.</p>
<p>If you did follow through and write the two sentences, I highly encourage you to write it with the inexperienced hand for the third (and last) time below the first two sentences. It should be slightly easier to write it now, but there will still be inadvertent trembling and awkward lines.</p>
<p>How do you explain this? You know how each letter should look, how it should be tilted, and how curved it should be—you possess the theory at 100%. Yet very few can draw a well-rounded letter ‘a’ or ‘o’ with their inexperienced hand. It is very likely that you are also holding your pen as though it weighs 5kg, and your hand is trembling in the process.</p>
<h2 id="a-primer-on-brain-structure">A Primer On Brain Structure</h2>
<p>The answer resides in the structure of the brain. As you might know, the brain consists of brain cells called “neurons.” Let’s represent a neuron as in the next image.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/one-neuron.png" alt="A Conceptual Representation Of A Neuron"></p>
<p>Neurons connect to other neurons, forming a complex net of interconnected brain cells. According to the latest plausible estimates,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> there are 86 billion neurons in a human brain. And each cell can connect to up to ten thousand other neurons. That is an astounding amount!</p>
<p>I will not attempt to draw such a complex, interconnected set of neurons as in a human brain. I will not try to represent even the 302 neurons with its ~7,500 connections of a roundworm.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Instead, I will rely on this <em>extremely</em> simplified version of a <strike>brain</strike> group of interconnected neurons to describe some essential events that take place inside one’s brain.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/many-interconnected-neurons.png" alt="A Conceptual Representation Of Many Interconnected Neurons"></p>
<p>All our memories, experiences, skills, thoughts, sensations, etc. are encoded and stored within those interconnected brain cells.</p>
<h2 id="neural-patterns">Neural Patterns</h2>
<p>Neurons communicate with each other through electric pulses and chemical neurotransmitters. Whenever we do something or think about something, specific neurons responsible for that action or thought get activated by sending impulses to each other. For instance, when you raise your right hand, a particular group of neurons gets activated simultaneously:</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-raise-hand.png" alt="A conceptual representation of the neural pattern responsible for raising your right hand"></p>
<p>When you write, another group of neurons fires together:</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-write.png" alt="A conceptual representation of the neural pattern responsible for writing"></p>
<p>These groups of neurons that fire together are called <em>neural patterns.</em> When activated, they are responsible for specific actions or thoughts. Keep in mind that the examples above are extremely simplified. Real patterns spread throughout large portions of the brain and can incorporate billions of neurons.</p>
<p>Note that these patterns can overlap, meaning that the same neuron or even huge chunks of neurons can be part of several patterns. Below you can see that <em>“writing”</em> and <em>“raising hand”</em> share some of their neurons.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-common-neurons.png" alt="A conceptual representation of the neurons that participate in both raising hand and speaking"></p>
<p>This explains the associative nature of memory and our experiences—as you are thinking about something specific (i.e., your favorite childhood cartoon), parts of the neural patterns that get activated are also parts of circuits related to other memories. That gives you the possibility to “hop” from one memory to the other. Just try to recall an instance of when you watched that cartoon and let your mind wander for some time. You’ll be pleasantly surprised with where it might lead you.</p>
<h2 id="it-is-not-only-about-the-number-of-connections">It Is Not Only About The Number Of Connections</h2>
<p>Besides the number of neurons, one essential thing that characterizes a pattern is the strength of its connections. A connection can be strong or can be weak, and it represents the relationship between two neurons.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-strong-connections.png" alt="A conceptual representation of a neural pattern with different connection strengths between neurons"></p>
<p>In the image above, the thicker lines represent more durable links. The stronger a bond is, the easier it is to communicate between neurons through it, and the harder and longer it takes to break it apart. We’ll see the implications of this in the next section below.</p>
<p>Therefore, activities that we know how to do and with which we have experience and thoughts that we think about often have strong links between neurons in their associated patterns. Conversely, skills we have just begun to practice, or thoughts we rarely think about have weak circuits.</p>
<p>To make an analogy, think of a link between two neurons as a pathway during winter.</p>
<figure>
    <img src="https://storage.needpix.com/rsynced_images/trace-3438236_1280.jpg" alt="Snow Trail"> <figcaption>
            <p>Source:
                    <a href="https://www.needpix.com/photo/download/1618289/trace-snow-background-mood-wintry-snow-tramp-footprints-snow-lane-deep-snow">Needpix.com</a></p>
        </figcaption>
</figure>

<p>Initially, when you have to go from point A to B, there is no path, so you have to walk through deep snow, leaving a narrow trail in the process. Have you ever walked in deep snow? That is exhausting, and so forming new circuits is. But the more you travel along that path, the more trodden it becomes, and the easier it is to walk it. Eventually, it will become a wide sidewalk that you can use to travel between point A and B effortlessly. But if you will abandon that path, the snow will gradually claim it back, until one day it will just disappear.</p>
<h2 id="the-process-of-forming-new-circuits">The Process Of Forming New Circuits</h2>
<p>Thus, all the information we know and skills we possess are encoded in our brains’ neural patterns. It is time to discuss the process of brain circuits administration. Research from the last 100 years has incredibly advanced the understanding of how the brain rewires itself. This process is called  <em>Neuroplasticity.</em></p>
<blockquote>
<p><strong>Neuroplasticity,</strong> also known as <strong>brain plasticity,</strong> is the ability of the brain to undergo biological changes ranging from the cellular level (i.e., individual neurons) all the way to large-scale changes involving cortical remapping.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
</blockquote>
<p>One of the fundamental principles of how neuroplasticity functions is the idea that individual connections within the brain are continually being created, strengthened, or removed, largely dependent upon how they are used.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Thus, neurons that are in close proximity and fire at the same time tend to form new connections (or, if they are already connected, the link strengthens). But in case a relationship is not used, it weakens over time, and eventually, it disappears, leaving the two neurons disconnected.</p>
<p>This theory was first introduced by Donald Hebb in 1949, and it is often summarized as <em>“neurons that fire together, wire together."</em></p>
<h2 id="going-back-to-writing">Going Back To Writing</h2>
<p>Knowing all that about our brain circuits and how they function, let’s analyze the previous writing exercise and describe it using our freshly acquired information.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-write-strong-connections.png" alt="Strong neural circuit responsible for writing with the experienced hand"></p>
<p>When you first wrote the sentence with your “regular” hand, you have used your existing, robust neural pattern responsible for writing with that hand. That’s why it felt natural and seamless.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/2-hands-with-question-mark.png" alt="Inexistent neural circuit responsible for writing with the inexperienced hand"></p>
<p>But when you switched to the other hand, no pattern was found responsible for writing with that hand, so a new one started to emerge.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/2-hands-with-both-patterns.png" alt="Emerging neural circuit responsible for writing with the experienced hand"></p>
<p>Different neurons fired together while you were striving to write each letter, and new links started to form. In case you followed my advice and wrote the sentence for the third time, the writing process should have flown more easygoing. That’s because the new pattern is strengthening in the brain! The more you will practice writing with that hand, the easier it will become for you.</p>
<p>This simple exercise demonstrated a fundamental truth that we sometimes ignore:</p>
<blockquote>
<p><strong>Knowledge != Skills</strong></p>
</blockquote>
<p>We have a sound pattern responsible for the knowledge about each individual letter and another circuit that is responsible for writing those letters. If you would take one thing out of this article, please remember this: <strong>knowledge</strong> does not necessarily mean <strong>skills.</strong> You might know something (the alphabet), but this does not imply than you will be able to write those letters.</p>
<p>This principle applies to many areas of our lives. For instance, reading a book on self-improvement, sales, public speaking, or anything else, does not magically teach you the skills described in those books. Reading those books will strengthen your neuronal pattern related to knowing. It’s like learning the shape of letters, the theory. Only when you begin to write, when you apply the theory into practice, then you start developing the patterns responsible for the actual skills.</p>
<p>There is much more to possessing an ability than just knowing the theory:</p>
<ul>
<li>Knowing the shape of the letters is not enough to be able to write. You need to develop proper muscle movement to hold the pen and draw the lines that form the letters.</li>
<li>Knowing some five steps to efficient sales is not enough to be a salesman. You need to learn to listen to customers, understand what relevant questions to ask, process the information you receive, formulate correct benefits that solve their problems, etc.</li>
<li>Knowing how to write code does is not enough to be a programmer. You need to understand how to define the architecture of a project based on the requirements, how to organize and structure your code, how to test it, etc.</li>
</ul>
<p>It does not mean that the theory is not essential. Conversely, knowledge about a domain helps you gain experience faster since you can interpret how good or bad the outcome of your practice is. As described in <a href="https://iuliangulea.com/blog/the-path-toward-mastery-how-to-become-an-expert/">The Pyramid Of Mastery</a>, knowledge and skills are complementary. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">https://iuliangulea.com/blog/how-people-learn-the-brain-basics/</a></em></p>]]>
            </description>
            <link>https://iuliangulea.com/blog/how-people-learn-the-brain-basics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746896</guid>
            <pubDate>Mon, 06 Jul 2020 11:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Infecting Android applications – The new way]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23746805">thread link</a>) | @thatskriptkid
<br/>
July 6, 2020 | https://orderofsixangles.com/en/2020/04/07/android-infection-the-new-way.html | <a href="https://web.archive.org/web/*/https://orderofsixangles.com/en/2020/04/07/android-infection-the-new-way.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        <small>7 April 2020</small>

<p>
    
    <small>tags: <em>android</em> - <em>malware</em></small>
    
    
</p>



<p><img src="https://orderofsixangles.com/assets/images/infecting_android/silent_night.png" alt=""></p>

<ul>
  <li><a href="#foreword">Foreword</a></li>
  <li><a href="#disadvantages-of-the-current-approach">Disadvantages of the current approach</a></li>
  <li><a href="#description-of-a-new-approach">Description of a new approach</a></li>
  <li><a href="#the-benefits-of-the-new-approach">The benefits of the new approach</a></li>
  <li><a href="#identifying-necessary-modifications-in-androidmanifestxml-and-patching">Identifying necessary modifications in AndroidManifest.xml and patching</a></li>
  <li><a href="#creating-files-to-be-injected-in-the-target-application">Creating files to be injected in the target application</a></li>
  <li><a href="#identifying-the-necessary-modifications-in-dex-and-patching">Identifying the necessary modifications in DEX and patching</a></li>
  <li><a href="#results">Results</a></li>
  <li><a href="#limitations-of-the-new-approach">Limitations of the new approach</a></li>
  <li><a href="#further-poc-improvements">Further PoC improvements</a></li>
  <li><a href="#faq">FAQ</a></li>
</ul>

<h2 id="foreword">Foreword</h2>

<p><strong>Idea authors: Erbol &amp; Thatskriptkid</strong></p>

<p><strong>Author of drawing: @alphin.fault <a href="https://www.instagram.com/alphin.fault">instagram</a></strong></p>

<p><strong>Author of the article and proof-of-concept code: Thatskriptkid</strong></p>

<p><strong><a href="https://github.com/thatskriptkid/apk-infector-Archinome-PoC">Proof-of-Concept Link</a></strong></p>

<p>Target audience of the article - people who have an idea of the current way of infecting android applications through smali code patching and want to learn about a new and more effective way. If you are not familiar with the current infection practice, read my article - <a href="https://orderofsixangles.com/en/2019/07/17/steal-ds-en.html">How to steal digital signature using Man-In-The-Disk</a>, chapter - “Creating payload”. The technique described here was completely invented by us; there is no description of such a method in the Internet.</p>

<p>Our technique:</p>
<ol>
  <li>Does not use bugs or android vulnerabilities</li>
  <li>Not intended for cracking applications (removing ads, licenses, etc.).</li>
  <li>Designed to add malicious code without any interference with the target application or its appearance.</li>
</ol>

<h2 id="disadvantages-of-the-current-approach">Disadvantages of the current approach</h2>

<p>The way to inject malicious code by decoding the application to smali code and patching it is the only and widely practiced method to date. <a href="https://github.com/JesusFreke/smali">smali/backsmali</a> is the only tool used for this. It is the basis for all known apk infectors, for example:</p>

<ol>
  <li><a href="https://github.com/dana-at-cp/backdoor-apk">backdoor-apk</a>.</li>
  <li><a href="https://github.com/Screetsec/TheFatRat">TheFatRat</a></li>
  <li><a href="https://github.com/jbreed/apkwash">apkwash</a></li>
  <li><a href="https://github.com/sensepost/kwetza">kwetza</a></li>
</ol>

<p>Malware also uses smali/backsmali and patching. The work algorithm of the Trojan <a href="https://vms.drweb.com/virus/?i=17771929&amp;lng=en">Android.InfectionAds.1</a>:</p>

<p><img src="https://orderofsixangles.com/assets/images/infecting_android/img_for_paper/android_infection_ads_01_en.png" alt=""></p>

<p>Decoding and patching involves changing the original classesN.dex file. This leads to two problems:</p>

<ol>
  <li>Overstepping <a href="https://developer.android.com/studio/build/multidex#about">the limit of 65536</a> methods <a href="https://github.com/JesusFreke/smali/issues/629">in one DEX file</a> if there is too much malicious code.</li>
  <li>The application can check the integrity of DEX files</li>
</ol>

<p>DEX decoding/disassembling is a complex process that requires constant updating and <a href="https://github.com/JesusFreke/smali/issues/595">highly dependent on the android version</a>.</p>

<p>Almost all available infection/modification tools are written in Java and/or depend on JVM - this greatly narrows the scope of use and makes it impossible to launch the infectors on routers, embedded systems, systems without JVM, etc.</p>

<h2 id="description-of-a-new-approach">Description of a new approach</h2>

<p>There are several types of starting applications in the android, one of which is called cold start. Cold start happens when application is started for the first time.</p>

<p><img src="https://orderofsixangles.com/assets/images/infecting_android/img_for_paper/cold_launch.png" alt=""></p>

<p>The execution of an application starts with the creation of an Application object. Most android applications have their own Application class, which should extends the main class <code>android.app.Applciation</code>. An example of a class:</p>

<div><div><pre><code><span>package</span> <span>test.pkg</span><span>;</span>
<span>import</span> <span>android.app.Application</span><span>;</span>
<span>public</span> <span>class</span> <span>TestApp</span> <span>extends</span> <span>Application</span> <span>{</span>

    <span>public</span> <span>TestApp</span><span>()</span> <span>{}</span>

    <span>@Override</span>
    <span>public</span> <span>void</span> <span>onCreate</span><span>()</span> <span>{</span>
        <span>super</span><span>.</span><span>onCreate</span><span>();</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The class <code>test.pkg.TestApp</code> should be registered in AndroidManifest.xml:</p>

<div><div><pre><code><span>&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span>&lt;manifest</span> <span>xmlns:android=</span><span>"http://schemas.android.com/apk/res/android"</span>
    <span>package=</span><span>"com.example"</span><span>&gt;</span>

    <span>&lt;application</span>
        <span>android:icon=</span><span>"@mipmap/ic_launcher"</span>
        <span>android:label=</span><span>"Test"</span>
        <span>android:roundIcon=</span><span>"@mipmap/ic_launcher_round"</span>
        <span>android:name=</span><span>"test.pkg.TestApp"</span><span>&gt;</span>
    <span>&lt;/application&gt;</span>
<span>&lt;/manifest&gt;</span>
</code></pre></div></div>

<p>The process of launching such an application:</p>

<p><img src="https://orderofsixangles.com/assets/images/infecting_android/img_for_paper/Usual_app_launch.png" alt=""></p>

<p>The basic requirements for our infection techniques have been defined:</p>

<ol>
  <li>Execution of malicious code, at application launch</li>
  <li>Saving all steps of the process of launching the original application</li>
</ol>

<p>The injection of the malicious code took place at the stage of the <em>cold start</em>:<em>Application Object creation-&gt;Application Object Constructor</em>. A malicious Application class was created, injected in the APK and spelled out in <em>AndroidManifest.xml</em>, instead of the original one. To preserve the previous execution chain, it was inherited from <code>test.pkg.TestApp</code>.</p>

<p>Malicious Application class:</p>

<div><div><pre><code><span>package</span> <span>my.malicious</span><span>;</span>
<span>import</span> <span>test.pkg</span><span>;</span>
<span>public</span> <span>class</span> <span>InjectedApp</span> <span>extends</span> <span>TestApp</span> <span>{</span>

    <span>public</span> <span>InjectedApp</span><span>()</span> <span>{</span>
        <span>super</span><span>();</span>
        <span>executeMaliciousPayload</span><span>();</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Modified AndroidManifest.xml:</p>

<div><div><pre><code><span>&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span>&lt;manifest</span> <span>xmlns:android=</span><span>"http://schemas.android.com/apk/res/android"</span>
    <span>package=</span><span>"com.example"</span><span>&gt;</span>

    <span>&lt;application</span>
        <span>android:icon=</span><span>"@mipmap/ic_launcher"</span>
        <span>android:label=</span><span>"Test"</span>
        <span>android:roundIcon=</span><span>"@mipmap/ic_launcher_round"</span>
        <span>android:name=</span><span>"my.malicious.InjectedApp"</span><span>&gt;</span>
    <span>&lt;/application&gt;</span>
<span>&lt;/manifest&gt;</span>
</code></pre></div></div>

<p>The process of launching malicious code inside an infected application (modifications are marked in red):</p>

<p><img src="https://orderofsixangles.com/assets/images/infecting_android/img_for_paper/Infected_app_launch.png" alt=""></p>

<p>Applied modifications:</p>

<ol>
  <li>The class <code>my.malicious.InjectedApp</code> was added to the original APK</li>
  <li>In AndroidManifest.xml the line <code>test.pkg.TestApp</code> has been replaced with <code>my.malicious.InjectedApp</code></li>
</ol>

<h2 id="the-benefits-of-the-new-approach">The benefits of the new approach</h2>

<p>It is possible to apply necessary modifications to the APK:</p>

<ol>
  <li>Without AndroidManifest.xml decoding/encoding</li>
  <li>Without DEX dissasembling/assembling</li>
  <li>Without making changes to the original DEX files</li>
</ol>

<p>These facts allow you to infect almost any existing application without restrictions. Adding your own class and modifying the manifest works much faster than decoding DEX. The malicious code injected by our technology starts immediately, as we are injected right at the beginning of the application launch process. The described infection technique doesn’t depend on the architecture and version of the android (with a few exceptions).</p>

<p>The PoC for demonstration was written in Go and is capable to be extended to a full featured tool. PoC is compiled into one binary file and does not use any runtime dependencies. Using Go allows using cross compilation to build an infector for almost any architecture and OS.</p>

<p>Testing of infected APK by PoC was on:</p>

<div><div><pre><code>NOX player 6.6.0.8006-7.1.2700200616, Android 7.1.2 (API 25), ARMv7-32

NOX player 6.6.0.8006-7.1.2700200616, Android 5.1.1 (API 22), ARMv7-32

Android Studio Emulator, Android 5.0 (API 21), x86

Android Studio Emulator, Android 7.0 (API 24), x86

Android Studio Emulator, Android 9.0 (API 28), x86_64

Android Studio Emulator, Android 10.0 (API 29), x86

Android Studio Emulator, Android 10.0 (API 29), x86_64

Android Studio Emulator, Android API 30, x86

Xiaomi Mi A1
</code></pre></div></div>

<p>We managed to successfully infect a huge number of applications (for obvious reasons, the names are hidden). We managed to successfully infect applications that cannot be decoded using smali/backsmali, and therefore by existing tool.</p>

<h2 id="identifying-necessary-modifications-in-androidmanifestxml-and-patching">Identifying necessary modifications in AndroidManifest.xml and patching</h2>

<p>One of the modifications required for the infection is to replace the string in AndroidManifest.xml. It is possible to patch the string without decoding/encoding the manifest.</p>

<p>APKs contain the manifest in binary encoded form. The structure of the binary manifest is undocumented and represents a custom XML encoding algorithm from Google. For convenience, <a href="https://github.com/thatskriptkid/Kaitai-Struct-Android-Manifest-binary-XML">was created</a> a description in <a href="https://kaitai.io/">Kaitai Struct</a> that can be used as documentation.</p>

<p>AndroidManifest.xml structure (in brackets - size in bytes):</p>

<p><img src="https://orderofsixangles.com/assets/images/infecting_android/img_for_paper/Manifest_draw.png" alt=""></p>

<p>Two applications with different class names were developed to detect changes in the manifest, after patching the original Application class name to a malicious one. The applications were built into an APK and unpacked to produce binary manifests.</p>

<p>An example of the original manifest:</p>

<div><div><pre><code><span>&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span>&lt;manifest</span> <span>xmlns:android=</span><span>"http://schemas.android.com/apk/res/android"</span>
    <span>package=</span><span>"com.qoogle.service.outbound.thread.safe.eng.packages.packas.pack.level.random"</span><span>&gt;</span>

    <span>&lt;application</span>
        <span>android:icon=</span><span>"@mipmap/ic_launcher"</span>
        <span>android:label=</span><span>"MinDEX"</span>
        <span>android:roundIcon=</span><span>"@mipmap/ic_launcher_round"</span>
        <span>android:name=</span><span>"test.pkg.TestApp"</span><span>&gt;</span>
    <span>&lt;/application&gt;</span>

<span>&lt;/manifest&gt;</span>
</code></pre></div></div>

<p>An example of a patched manifest:</p>

<div><div><pre><code><span>&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span>&lt;manifest</span> <span>xmlns:android=</span><span>"http://schemas.android.com/apk/res/android"</span>
    <span>package=</span><span>"com.qoogle.service.outbound.thread.safe.eng.packages.packas.pack.level.random"</span><span>&gt;</span>

    <span>&lt;application</span>
        <span>android:icon=</span><span>"@mipmap/ic_launcher"</span>
        <span>android:label=</span><span>"MinDEX"</span>
        <span>android:roundIcon=</span><span>"@mipmap/ic_launcher_round"</span>
        <span>android:name=</span><span>"test.pkg.TestAppAAAAAAAAA"</span><span>&gt;</span>
    <span>&lt;/application&gt;</span>

<span>&lt;/manifest&gt;</span>
</code></pre></div></div>

<p>The length of the fully-qualified class name has increased by 9 characters. Both files were opened in <a href="https://www.fairdell.com/hexcmp/">HexCmp</a>, to get the diff.</p>

<p>Changes to the manifest and explanation of reasons:</p>



.
  .
  <table>
<thead>
  <tr>
    <th>field</th>
    <th>offset</th>
    <th>description</th>
    <th>diff_count</th>
    <th>explanation</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>header.file_len</td>
    <td>0x4</td>
    <td>Total file length</td>
    <td>0x10</td>
    <td>In the original manifest there was 0x2 bytes of alignment, in the modified version they are not required. <br>Strings in the binary manifest are stored in UTF-16 format, i.e. one character takes 0x2 bytes.<br>In total, we increased the string by 9 characters (0x12 bytes) minus 0x2 alignment bytes, it equals to 0x10 byte difference</td></tr>
  <tr>
    <td>header.string_table_len</td>
    <td>0xC</td>
    <td>Length of array of strings</td>
    <td>0x10</td>
    <td>The string is in an array of strings. The explanation for the 0x10 byte difference is the same as for header.file_len.</td>
  </tr>
  <tr>
    <td>string_offset_table.offset</td>
    <td>0x7C</td>
    <td>Offset to the line following the modified</td>
    <td>0x12</td>
    <td>string_offset_table stores offset up to strings in an array of manifest strings. Since the length of the string has increased, <br>the line following it has been moved further by 0x12 bytes. Alignment is not taken into account here, as it <br> is located before the array of strings.</td></tr>
</tbody>
</table>

<p><img src="https://orderofsixangles.com/assets/images/infecting_android/img_for_paper/Manifest_diff_1.png" alt=""></p>



<table>
<thead>
  <tr>
    <th>field</th>
    <th>offset</th>
    <th>description</th>
    <th>diff_count</th>
    <th>explanation</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>strings.len</td>
    <td>0x2EA</td>
    <td>String length</td>
    <td>0x9</td>
    <td>The number of characters by which the string has increased</td>
  </tr>
</tbody>
</table>

<p><img src="https://orderofsixangles.com/assets/images/infecting_android/img_for_paper/Manifest_diff_2.png" alt=""></p>

<p>In the structure of the manifest given at the beginning, after <code>strings</code> follows <code>padding</code> to align <code>resource_header</code>. In the original manifest, the last line of <code>uses-sdk</code> ends on the offset <code>0x322</code> (orange), which means that two bytes of alignment (green) for <code>resource_header</code> have been added.</p>

<p><img src="https://orderofsixangles.com/assets/images/infecting_android/img_for_paper/Manifest_alignment_original.png" alt=""></p>

<p>In the modified version, <code>string_table</code> ends in offset <code>0x334</code> (orange) and then immediately …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orderofsixangles.com/en/2020/04/07/android-infection-the-new-way.html">https://orderofsixangles.com/en/2020/04/07/android-infection-the-new-way.html</a></em></p>]]>
            </description>
            <link>https://orderofsixangles.com/en/2020/04/07/android-infection-the-new-way.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746805</guid>
            <pubDate>Mon, 06 Jul 2020 11:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PSA: Please Just Close Your Files]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23746724">thread link</a>) | @ingve
<br/>
July 6, 2020 | https://theartofmachinery.com/2020/07/06/please_close_files.html | <a href="https://web.archive.org/web/*/https://theartofmachinery.com/2020/07/06/please_close_files.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <p>An article called “<a href="https://coady.github.io/posts/closing-files/">Contrarian view on closing
      files</a>” is on the front page of Hacker News right now with over 60 upvotes. It starts off with a quote from
      the <a href="https://google.github.io/styleguide/pyguide.html#311-files-and-sockets">Google Python style
      guide</a>:</p>
      <blockquote>
        <p>Explicitly close files and sockets when done with them. Leaving files, sockets or other file-like objects
        open unnecessarily has many downsides […]</p>
      </blockquote>
      <p>The article’s main complaint is that “this advice is applying a notably higher standard of premature
      optimization to file descriptors than to any other kind of resource”. It complains that it’s “depressingly
      commonplace” to see code like this:</p>
      <figure>
        <pre><code data-lang="python"><span>with</span> <span>open</span><span>(</span><span>"README.md"</span><span>)</span> <span>as</span> <span>readme</span><span>:</span>
    <span>long_description</span> <span>=</span> <span>readme</span><span>.</span><span>read</span><span>()</span></code></pre>
      </figure>
      <p>Sure, if it’s a one-off read of a doc file, you can almost certainly get away with just <code>open("README.md").read()</code>, but I honestly have no idea what’s
      depressing about code that just works reliably.</p>
      <p>Leaving files and sockets open is something that you can usually get away with, until weird stuff happens.
      And, no, it’s not just about running out of file descriptors (although that does happen, too). I’ve previously
      written about <a href="https://theartofmachinery.com/2018/12/05/gc_not_enough.html">servers that mysteriously ran out of disk space because
      (spoiler) they were deleting files that hadn’t been closed properly</a>. Regardless of how awesome your computer
      and network equipment are, the number of TCP connections you can make to a given host and port are limited by a
      16 bit integer (and practically always limited more by your <a href="https://ma.ttias.be/linux-increase-ip_local_port_range-tcp-port-range/">network settings</a>), then you get
      network failures. Writing to files that you don’t explicitly close (or flush) is especially dicey — the write
      might actually happen straight away, then on another day or another environment it might get delayed.</p>
      <p>Sure, these failure modes aren’t very common, but they definitely happen. I can think of three examples right
      now from the past few years of my day job. Closing files as a habit is easier than figuring out when it’ll go
      wrong.</p>
      <p>The article has an example of a function that lazily loads JSON given a file path string. Sure, it doesn’t
      work properly if you close the file inside the function, but I’d say the problem is in the API design: the file
      handle resource straddles the interface.</p>
      <p>The first good alternative is to keep the file handle completely inside: take a path argument, load the data
      eagerly, close the file and return the parsed data. The other good alternative is to keep the file handle
      completely outside: take a file handle as argument and return it wrapped in a lazy JSON parser. Either way makes
      it easier to see how and where the file should be closed.</p>
      <p>The Google advice is pretty solid: when you’re done with a file or socket, just close it. I’ll add: sure,
      maybe it won’t always be obvious when you’re done with a handle, but perhaps that code design is making life more
      “exciting” than necessary. Production failures are more depressing than file closing code ever will be.</p>
    </div></div>]]>
            </description>
            <link>https://theartofmachinery.com/2020/07/06/please_close_files.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746724</guid>
            <pubDate>Mon, 06 Jul 2020 11:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A secure, decentralized search engine for journalists]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23746557">thread link</a>) | @fgeorgy
<br/>
July 6, 2020 | https://actu.epfl.ch/news/a-secure-decentralized-search-engine-for-journalis/ | <a href="https://web.archive.org/web/*/https://actu.epfl.ch/news/a-secure-decentralized-search-engine-for-journalis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p> An EPFL laboratory has developed Datashare Network, a decentralized search engine paired with a secure messaging system that allows investigative journalists to exchange information securely and anonymously. An scientific article on this subject will be presented during the Usenix Security Symposium which will be held online from August 12 to 14.<br></p><div id="news-content-text" itemprop="description"><p>The International Consortium of Investigative Journalists (ICIJ),&nbsp;which has over 200 members in 70 countries, has&nbsp;broken a number of important stories, particularly ones that expose medical fraud and tax evasion.&nbsp;One of its most famous investigations was the Panama Papers, a trove of millions of documents that revealed the existence of several hundred thousand shell companies whose owners included cultural figures, politicians, businesspeople and sports personalities.&nbsp;To complete an investigation of this size is only possible through international cooperation between journalists. When sharing such sensitive files, however, a leak can jeopardize not only&nbsp;the story’s publication, but also the safety of&nbsp;the&nbsp;journalists and sources involved. At the ICIJ’s behest, EPFL’s Security and Privacy Engineering (SPRING) Lab recently developed Datashare Network, a fully anonymous, decentralized system for searching and exchanging information. A paper about it will be presented during the Usenix Security Symposium, a worldwide reference for specialists, which will be held online from 12 to 14 August.</p><p><strong>Anonymity at every stage</strong></p><p>Anonymity is the backbone of the system. Users can search and exchange information without revealing their identity, or the content of their queries, either to colleagues or to the ICIJ. The Consortium ensures that the system is running properly but remains unaware of any information exchange. It issues virtual secure tokens that journalists can attach to their messages and documents to prove to others that they are Consortium members. A centralized file management system would be too conspicuous a target for hackers; since the ICIJ does not have servers in various jurisdictions, documents are typically stored on its members’ servers or computers. Users provide only the elements that enable others to link to their investigation.</p><p>Users searching for information enter keywords in the search engine. If the search produces hits, they can then contact colleagues – whose identity remains protected – who are in possession of potentially relevant documents. Search queries are sent encrypted to all users, if there is a macth the querier gets an alert and can decide whether they wish to enter in contact and share information. “Given the fact that users work in different time zones, some with only a few hours of internet access per day, it was critical that searches and responses could take place asynchronously,” notes Carmela Troncoso, who runs the SPRING Lab at the School of Computer and Communication Sciences (IC). Another messaging system, also secure and anonymous, is subsequently used for two-way exchanges.</p><p><strong>Two completely new secure applications</strong></p><p>“This system, which addresses real-world needs, has enabled SPRING to tackle some interesting challenges,” notes Troncoso. The research team drew on existing authentication mechanisms and anonymous communication primitives, which they then optimized. They also developed two completely new secure building blocks that are described in the paper being published today in connection with the Usenix Security Symposium – an asynchronous search engine and a messaging system. A new protocol, known as “multi-set private set intersection” (MS-PSI), ensures the security of the search engine, allowing users to easily search a large number of databases without increasing the risk of leaks. The messaging system relies on a large number of single-use virtual mailboxes and is based on the well-known “pigeonhole” system, which chooses one option at random, in this case one of the mailboxes. Currently, the system does not allow users to exchange documents. “At this stage in the process, journalists are using other secure messaging systems,” Troncoso says.</p><p>Working with the Consortium has allowed SPRING to frame new requirements that are rarely examined in the scientific literature. Datashare can be scaled to thousands of users and millions of documents while encrypting all communications. “The hurdles we encountered during the development process, however, have paved the way to a new area of research with significant potential for other fields,” Troncoso concludes.</p></div></div>]]>
            </description>
            <link>https://actu.epfl.ch/news/a-secure-decentralized-search-engine-for-journalis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746557</guid>
            <pubDate>Mon, 06 Jul 2020 10:59:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ongoing Accomplishment of the Big Five]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23746521">thread link</a>) | @barry-cotter
<br/>
July 6, 2020 | https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/ | <a href="https://web.archive.org/web/*/https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-732">
	<!-- .entry-header -->

	
	
	<div>
		
<p><em>by a literal banana</em></p>
<p>I have been trying to understand the “<a href="https://en.wikipedia.org/wiki/Lexical_hypothesis" target="_blank" rel="noopener">lexical hypothesis</a>” of personality, and its modern descendant, the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits" target="_blank" rel="noopener">Five Factor Model of personality</a>, for <a href="https://carcinisation.com/2020/01/27/ignorance-a-skilled-practice/">several</a> <a href="https://carcinisation.com/2020/06/24/the-extended-sniff-test/">months</a>. In that time, I have said some provocative things about the Big Five, and even some unkind things that I admit were unbecoming to a banana. Here, I wish to situate the Five Factor Model in the context of its historical development and modern use, and to demonstrate to the reader the surprising accomplishment that it represents for the field of psychology.<span id="more-732"></span></p>
<p>In personality research, the “lexical hypothesis” refers to a hypothesis attributed to Francis Galton (1884). Galton supposed that each human language would reflect important realities of human character within that language and culture. In particular, he noted that the words used to evaluate character and personality are very numerous (he estimated over a thousand, using a thesaurus), and often overlap in meaning.</p>
<p>But Galton immediately left his thesaurus behind, readily admitting of the impossibility of <a href="https://carcinisation.com/2020/06/26/words-fail/">defining</a> any aspect of character. Rather, he turned to experimental means of testing the character in various ways, and insisted that <em>no particular map or model of personality is needed to start from</em>.</p>
<p>Nowhere in his essay does Galton propose surveys as a means for studying character. He would probably regard such methods as unscientific, as indicated in his final paragraph:</p>
<blockquote><p>[C]haracter ought to be measured by carefully recorded acts, representative of the usual conduct. An ordinary generalisation is nothing more than a muddle of vague memories of inexact observations. It is an easy vice to generalise. We want lists of facts, every one of which may be separately verified, valued and revalued, and the whole accurately summed. It is the statistics of each man’s conduct in small every-day affairs, that will probably be found to give the simplest and most precise measure of his character.</p></blockquote>
<p>The methods that Galton proposed are exclusively non-linguistic. For instance, he commented that observing children involved in play quickly gives one an idea of each child’s emotional expression. Galton’s proposed methods prefigure both hidden camera prank shows and Goffman’s “breaching experiments:”</p>
<blockquote><p>I will not attempt to describe particular games of children or of others, nor to suggest experiments, more or less comic, that might be secretly made to elicit the manifestations we seek, as many such will occur to ingenious persons. They exist in abundance, and I feel sure that if two or three experimenters were to act zealously and judiciously together as secret accomplices, they would soon collect abundant statistics of conduct. They would gradually simplify their test conditions and extend their scope, learning to probe character more quickly and from more of its sides.</p></blockquote>
<p>Other methods Galton expressed enthusiasm for include heart rate measurement (he wore a home-brew heart-rate-measuring apparatus while he delivered the lecture that makes up the text) and methods discoverable from personal context (giving an example from Benjamin Franklin, of a man with one attractive and one deformed leg, who kept track of which leg his interlocutors paid attention to, as a gauge of their optimism or pessimism). Galton would be surprised, I think, to find that the most promising and scientific theory of personality in the twenty-first century is premised entirely on survey responses as its “facts.”</p>
<p>Early in the study of personality, there was a major shift of meaning in the lexical hypothesis. At first, the thesaurus and the word list were its tools of study (e.g., Allport &amp; Odbert, 1936); the idea was to find common factors of meaning in the words themselves. Of course, there is no particularly scientific way to decide how much the word “annoying” is the same as “obnoxious,” or how much either is the same as “low-status.” The major shift was to begin to measure the correlations of an entirely different construct: the correlations of the words <em>when used to describe a particular person</em>. That is, rather than trying to measure the underlying meaning of words, researchers began to measure the degree to which different words were applied to the same person. “Sameness” and “correlation” were no longer distinguishable concepts for the methods.</p>
<p>Initially, lists of adjectives, and eventually, short survey questions, were administered to subjects, who described either a person they knew or themselves. When the responses were subjected to factor analysis—a mathematical analysis to reveal the structure of correlations between responses—a varying number of factors emerged, depending on the methods and the researchers and the questions and the subjects, and these factors were given varying names. Since the early 1990s, the Five Factor Model has been dominant, although the names of the factors vary somewhat even today. The acronym OCEAN is used for the traits: Openness to experience (sometimes called “intellect” or “imagination” or “open-mindedness”), Conscientiousness, Extraversion (sometimes called “surgency”), Agreeableness, and Neuroticism (sometimes called “negative emotionality” or “emotional stability” reversed).<span>&nbsp;</span></p>
<p>Today, the five traits are measured with various survey instruments, with five questions on the shortest version (one for each aspect) and sixty questions on a common long-form version (that used by Soto, 2019). Survey instruments are validated in a number of ways: how much their responses correlate between testings (test-retest reliability, with astrological sign as the gold standard), how much different raters agree using the criteria (inter-rater reliability), and a nebulous concept of construct validity, which sometimes includes scientific gestures designed to ensure that the instrument measures what it purports to measure. Many papers present elaborate numerical artifacts of validation, and I have found that some characterize the validity of their instruments as “good” without providing an indication of what would be “not good enough.” From a brief review of dozens of validated instruments in social psychology, it seems to me that it is relatively easy to “validate” meaningless instruments. As long as the mathematical bona fides are present, the construct need not be meaningful in other ways. (The reader who is rightly suspicious of my broad and unsourced claims may wish to search Google Scholar with variations of “scale,” “inventory,” and “survey instrument,” and examine the results critically. The naming of factors is often a particularly interesting step.)</p>
<p>The strong claim made by advocates of the Five Factor Model is that any set of questions describing a human being, administered to subjects and the responses subjected to factor analysis, will reveal the same five factors (paraphrasing Jordan Peterson in <a href="https://youtu.be/pCceO_D4AlY" target="_blank" rel="noopener">this video</a>, around 11:10-16:40). This strong claim, though dubious in a number of respects, is a major part of the basis for the scientific legitimacy of the Big Five. It is interesting to see which aspects of the strong claim are admitted to be false by advocates of the Big Five, and how much is excused on the grounds that <i>at least it’s something</i>. The Five Factor Model is not perfect, advocates grant, but it is better than nothing. It is not clear how they measure “better than nothing;” this is a potentially interesting hypothesis in need of precisification, perhaps.</p>
<p>The Big Five exist as a special, scientifically validated property of language and survey methods, and that is one basis for their legitimacy. The other basis for the legitimacy of the Five Factor Model is its <i>replicable correlation with consequential life outcomes</i>. We know that the Big Five are not merely phantoms that fall out of a certain analysis of a certain use of language in WEIRD college students, because these traits are reliably correlated with things we care about.<span>&nbsp;</span></p>
<p>One of the most interesting features of the Big Five is the nature of its scientific evidence. Observe what is held out as a “replication” of the theory, and you will discover the theory’s true nature. The most impressive aspect of the ongoing accomplishment of the Five Factor Model is the degree to which it <i>deflects curiosity </i>about its underlying meaning with <i>rituals of scientific validation</i>, regardless of the rituals’ appropriateness in context. Since “replication” is the scientific ritual most recently shown to detect poor science in psychology, being shown to reliably “replicate” is a huge boost to the credibility of a theory.<span>&nbsp;</span></p>
<p>The interesting thing about the Five Factor Model is what it gets away with, in terms of being considered a theory, even though it is not causal, and makes no predictions. What counts as a “replication” of the Five Factor Model, as in Soto (2019), is the following: a correlation is found between one or more factors of the Five Factor Model and some other construct, and that correlation is found again in another sample, regardless of the size of the correlation. In almost all cases, and in 100% of Soto (2019)’s measures, the construct compared to a Big Five factor is derived from an online survey instrument.</p>
<p>What counts as a “consequential life outcome” is also fascinating. In most cases, the life outcome constructs are vague abstractions measured with survey instruments, much like the Big Five themselves. For instance, the life outcome “Inspiration” is measured with the Inspiration Scale, which asks the subject in four ways how often and how deeply inspired they are. Amazingly, this scale correlates a little bit with Extraversion and with Open-mindedness. Do these personality traits “predict” the life outcome of inspiration? Is “Inspiration” as instrumentalized here meaningfully different from the Big Five constructs, such that this correlation is meaningful?<span>&nbsp;</span></p>
<p>Compare the items for the construct “Inspiration” with the items for Extraversion and Open-mindedness used in Soto (2019):</p>
<p><b>Inspiration Scale Items</b></p>
<ul>
<li>I experience inspiration.</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</a></em></p>]]>
            </description>
            <link>https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746521</guid>
            <pubDate>Mon, 06 Jul 2020 10:55:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Raku for Beginners – Vadim Belman]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23746373">thread link</a>) | @lizmat
<br/>
July 6, 2020 | https://vrurg.github.io/arfb.html | <a href="https://web.archive.org/web/*/https://vrurg.github.io/arfb.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        
        <p>Articles in the series are not finalized and could be subject for further
changes. I gladly accept any related
<a href="https://github.com/vrurg/vrurg.github.io/issues/new/choose">reports</a> or
<a href="https://github.com/vrurg/vrurg.github.io/compare">corrections</a>.</p>

<p>Thank you and have a great time reading!</p>

<div>
  <article itemscope="" itemtype="https://schema.org/CreativeWork">
    
    <h2 itemprop="headline">
      
        <a href="https://vrurg.github.io/arfb-publication/01-introduction/" rel="permalink">Introduction
</a>
      
    </h2>
    
      <p> 




  2 minute read

</p>
    
    <p itemprop="description">I’m starting a series of articles devoted to Raku for beginners. But…

</p>
  </article>
</div>

<div>
  <article itemscope="" itemtype="https://schema.org/CreativeWork">
    
    <h2 itemprop="headline">
      
        <a href="https://vrurg.github.io/arfb-publication/02-everything-is-an-object-mop/" rel="permalink">Everything Is An Object. MOP.
</a>
      
    </h2>
    
      <p> 




  12 minute read

</p>
    
    <p itemprop="description">As this series is not a typical beginner guide it is starting with a non-typical
subject.

</p>
  </article>
</div>

<div>
  <article itemscope="" itemtype="https://schema.org/CreativeWork">
    
    <h2 itemprop="headline">
      
        <a href="https://vrurg.github.io/arfb-publication/03-containers-and-symbols/" rel="permalink">Containers And Symbols
</a>
      
    </h2>
    
      <p> 




  8 minute read

</p>
    
    <p itemprop="description">I’m not going to be original anyway and gonna start with the most traditional example around:

my $foo = “Hello world!”;
say $foo;


It shouldn’t be to hard ...</p>
  </article>
</div>



        
      </section>

      

      

      
    </div></div>]]>
            </description>
            <link>https://vrurg.github.io/arfb.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746373</guid>
            <pubDate>Mon, 06 Jul 2020 10:28:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My 10 Years of Programming Experience]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23746291">thread link</a>) | @yamrzou
<br/>
July 6, 2020 | https://iximiuz.com/en/posts/my-10-years-of-programming-experience/ | <a href="https://web.archive.org/web/*/https://iximiuz.com/en/posts/my-10-years-of-programming-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a name="cut"></a>
<a href="https://edition.cnn.com/2019/12/21/us/when-does-the-decade-end-begin-trnd/index.html">Regardless of whether it's the end of the calendar decade or not</a> it's the end of a programming decade for me. I started early in 2010 and since then I've been programming almost every day, including weekends and vacations. This was a really exciting period in my life and I realized that it's been a while since 2010 only recently. So, I decided to put into words some of my learnings from that time. Warning: the content of this article is highly opinionated and extremely subjective.
<a name="eofcut"></a></p>
<h2 id="combine-object-oriented-procedural-and-functional-programming-techniques">Combine object-oriented, procedural, and functional programming techniques</h2>
<p><i>OOP to me means only messaging, local retention and protection and hiding of state-process, and extreme late-binding of all things.</i></p>
<p><i>–– Dr. Alan Kay</i></p>


<p>Object-oriented programming seems to be a prevalent technique these days. Different people hear different things when one says <em>object-oriented</em>. I personally don't treat inheritance and polymorphism as necessary attributes of object-orientation. However, hiding and protection of the state by providing public methods is the mandatory attribute of the approach to me. Entities combining the hidden state with the public methods are called objects and they communicate with each other by sending messages (i.e. invoking the public methods of other objects). Most probably, this definition of OOP is too narrow, but these aspects seem the most practical and useful to me. I try to employ them to express any <em>suitable</em> problem in code.</p>
<p>However, the keyword in the previous paragraph is <em>suitable</em>. Yes, there are problems that fit well into the OO-paradigm. For instance, consider the <em>vector</em> - an abstract data structure solving <em>the dynamic array</em> problem:</p>
<pre><code>class Vector&lt;T&gt; {
    private int size;
    private int capacity;
    private T items;

    public Vector(int capacity) {
        this.size = 0;
        this.capacity = capacity;
        this.items = new T[capacity];
    }

    public int size() {
        return this.size;
    }

    public void push(T elem) {
        if (this.size == this.capacity) {
            this.realloc();
        }
        this.items[this.size++] = elem;
    }

    private realloc();

    // ...
}</code></pre>
<p>The <em>vector</em> hides its state (current size, current capacity, etc) and allows the modification only through its public interface. Thus, assuming the proper implementation, the consistency of the state is maintained constantly.</p>
<p>However, not every problem can be easily designed in terms of objects and their communications. And I'm not talking here about some specific domains. Consider the very common problem of registering a new user:</p>
<pre><code>def register_user(name, email):
    user = User(name, email)

    user_repo.save(user)
    start_trial_period(user)
    schedule_welcome_email(user)

    # etc, etc...

    return user</code></pre>
<p>What kind of object should be the owner of the <code>register_user()</code> method? Early at my programming career, I would argue that there should exist a <em>registration service</em> class. However, what's about its state? What attributes should the registration service possess? Are we modifying its state by registering a new user?</p>
<p>Another time, you can find yourself writing a method which performs some computation related to the current class but without accessing its attributes:</p>
<pre><code>class HttpClient:
    def __init__(self, foo, bar, baz, ...):
        pass

    def request(self, url, query, headers, etc, attempts=1):
        for c in range(attempts):
            resp = self._do_request(url, query, headers, etc)
            if is_fine(resp):
                return resp

            self.sleep(self._backoff_delay(c))

        raise Exception('HTTP request failed')

    def _backoff_delay(self, attempt_no):
        return min(1000, 100 * (attempt_no + 1))</code></pre>
<p>The <code>_backoff_delay</code> method can easily be just a self-sufficient function. And there is a huge benefit of having this function separate from the class - its testing becomes much simpler. If the function stayed a method, in order to test the backoff delay computation algorithm we would need to create an instance of the <code>HttpClient</code> supplying all its dependencies (and probably the dependencies of the dependencies) as well as the fake HTTP request parameters. With the pure function we can just do:</p>
<pre><code>assert _backoff_delay(0) == 100
assert _backoff_delay(1) == 200
assert _backoff_delay(10) == 1000</code></pre>
<p>So, eventually, I came to a conclusion, that from time to time it's absolutely fine to have just a function performing some logic. Quoting the gorgeous <a href="https://www.python.org/dev/peps/pep-0020/"><em>Zen of Python</em></a> –– [...] practicality beats purity. <a href="https://pyvideo.org/pycon-us-2012/stop-writing-classes.html">Stop writing classes</a> for the sake of having classes. Use classes (or objects) only, if the problem fits well into the OO-paradigm. <a href="https://en.wikipedia.org/wiki/Procedural_programming">Procedural programming</a> is a valid and very powerful technique.</p>
<p>I confess, that for a long time I was biased toward the pure OO, ignoring and avoiding other approaches. Accepting the procedural style helped me to become a better programmer. At least I hope so.</p>
<p>However, during my career, I met quite a few developers with the opposite skewness. People have been applying procedural programming even for tasks when one can benefit from the OO-paradigm a lot:</p>
<pre><code>interface Player {
    cursed: boolean;
    scores: number;
}

function collectCoint(p: Player) {
    if (!p.cursed) {
        p.scores += 100;
    }
}

function killMonster(p: Player, m: Monster) {
    if (!p.cursed) {
        p.scores += m.rank;
    }
}</code></pre>
<p>We have a struct <code>Player</code> here and all its attributes are public. We also have a bunch of business logic functions, performing some game actions. These functions are so easy to test. Forge a fresh player object, pass it into the function and check the attributes afterward. However, there is a problem with this approach. Imagine, we added a new function:</p>
<pre><code>function savePrincess(p: Player) {
    p.scores += 100500;
}</code></pre>
<p>It's so easy to forget about the <code>is cursed</code> check. Thus, we broke the game logic by violating the consistency of the player's state. Having an OO-implementation of the player would allow us to avoid such a pitfall:</p>
<pre><code>class Player {
    addScores(score: number) {
        if (!this.cursed) {
            this.score += number;
        }
    }
}</code></pre>
<p>So, how to decide between these two techniques? My personal waymark is a potential violation of the incapsulation. If I see a publicly exposed state and a number of functions here and there modifying it, I will immediately factor it out to a class. In all the other cases, the procedural approach is superior due to its simplicity.</p>
<p>But what's about <a href="https://en.wikipedia.org/wiki/Functional_programming">the functional programming paradigm</a>? I incorporated it in my style on a lower-level. If my strategy is rather based on a mix of object-oriented and structural approaches, my tactic is based on functional methods. Compare the following implementations of a hypothetical <code>revenue</code> function:</p>
<pre><code>function revenue(orders) {
    let total = 0;
    for (const o of orders) {
        if (o.paid) {
            total += o.price;
        }
    }
    return total * fee;
}

// vs

function revenue(orders) {
    return _.sum(orders.filter(x =&gt; x.paid).map(x =&gt; x.price)) * fee;
}</code></pre>
<p>Due to its declarative form, the second version is much shorter. It even resembles the human-readable text. One can read it as <code>a sum of all paid order prices multiplied by the fee rate</code>.</p>
<p>Let's try to go one step further:</p>
<pre><code>function promoEligible(user, orders, etc...) {
    let total = 0;
    for (const o of orders) {
        if (o.paid) {
            total += o.price;
        }
    }

    if (total == 0) {
        return false;
    }


    // ...
    // do 42 more checks before returning true.
    // ...
}</code></pre>
<p>If we follow the imperative way here, the <code>total</code> variable will stay around until the very end of our function even though it was needed only at the very beginning. This increases the mental load, especially when I need to read this code a month later. I'd rewrite it as follows:</p>
<pre><code>function promoEligible(user, orders, etc...) {
    return orders.some(x =&gt; x.paid)
        &amp;&amp; anotherCheck(user)
        &amp;&amp; oneMoreCheck(etc);
}</code></pre>
<p>No single extra local variables have been introduced on the <code>promoEligible()</code> level.</p>
<p>I'd not call this technique full-fledged functional programming. It's rather an excerpt of some techniques. Once I started writing code in this way, I rarely can find for-loops in my code, my utility functions tend to be smaller and <em>pure</em> (i.e. avoiding mutation of their arguments, as well as any other side-effects) and my variables - to be immutable. And for some reason, I feel safer and sleep better.</p>
<p>I came to this technique rather intuitively, but it seems that modern languages like Rust are trying to make these patterns the first-class citizens. Variables in Rust are immutable by default and almost every statement in Rust is an expression, e.g.:</p>
<pre><code>let res = match compute_something() {
    VeryGood(x) =&gt; 5 * x,
    GoodEnough(x) =&gt; 2 * x,
};</code></pre>
<p>Take a look at the <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html"><code>std::iter::Iterator</code></a> trait, it's full of map-reduce alike methods:</p>
<pre><code>let a = [0i32, 1, 2];
let mut iter = a.iter().filter(|x| x.is_positive());

let a = [1, 2, 3];
let mut iter = a.iter().map(|x| 2 * x);

let a = [1, 2, 3];
let (even, odd): (Vec&lt;i32&gt;, Vec&lt;i32&gt;) = a
    .iter()
    .partition(|&amp;n| n % 2 == 0);

let a = [1, 2, 3];
let sum: i32 = a.iter().sum();</code></pre>
<p>The <a href="https://doc.rust-lang.org/std/result/enum.Result.html">error handling</a> and the <a href="https://doc.rust-lang.org/std/option/enum.Option.html"><em>optional</em></a> value also support functional-alike styles, not only in Rust, but in modern Java as well:</p>
<pre><code>Optional.ofNullable(smth).orElseThrow(NullPointerException::new);</code></pre>
<h2 id="use-fewer-local-variables">Use fewer local variables</h2>
<p>In my opinion, variables increase the mental load by introducing extra state and decreasing the expressiveness of the code, making it lower-level. And eventually, they complicate the refactoring.</p>
<blockquote><p lang="en" dir="ltr">Unpopular opinion: variables (even immutable) are harmful. Try to avoid them in your code. Functional programming techniques and decomposition often helps. Unnecessary variables are evil!<a href="https://twitter.com/hashtag/programming?src=hash&amp;ref_src=twsrc%5Etfw">#programming</a> <a href="https://twitter.com/hashtag/stateless?src=hash&amp;ref_src=twsrc%5Etfw">#stateless</a></p>— Ivan Velichko (@iximiuz) <a href="https://twitter.com/iximiuz/status/1194141015919210496?ref_src=twsrc%5Etfw">November 12, 2019</a></blockquote> 

<p>Imagine, you have a function with two local variables:</p>
<pre><code>function doStuff() {
    // ...

    const color = pickColor();
    const temperature = measureTemperature();

    …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iximiuz.com/en/posts/my-10-years-of-programming-experience/">https://iximiuz.com/en/posts/my-10-years-of-programming-experience/</a></em></p>]]>
            </description>
            <link>https://iximiuz.com/en/posts/my-10-years-of-programming-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746291</guid>
            <pubDate>Mon, 06 Jul 2020 10:12:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five Computers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23746253">thread link</a>) | @ingve
<br/>
July 6, 2020 | https://deprogrammaticaipsum.com/five-computers/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/five-computers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>There is no direct evidence that Thomas Watson, Sr. predicted in 1943 that there would be “a world market for five computers”. First, he probably didn’t know about computers back then: in the 1940s computers were classified research projects at the UK Government Code and Cipher School and the US Army, while Watson’s IBM were famously <a href="https://www.huffpost.com/entry/ibm-holocaust_b_1301691">involved with the other side</a> during the war. Second, it’s just not something there’s evidence of him talking about. When IBM presented plans for their early commercial computers to various businesses, they got about ten immediate sign-ups and as many expressions of interest. That’s already a market for twenty computers. Various people in government on both sides of the pond, including the UK National Physical Laboratory’s head Sir Charles Darwin (grandson of the one you’ve heard of), may have said that their respective government’s <em>laboratory</em> needs could be satisfied by a small number of computers, but these seem to be estimates of immediate resource usage rather than predictions of future market growth.</p>
<p>Like the 640k RAM thing attributed to Bill Gates, the five computers quote seems to be a fabrication from a later age, invented to teach us a lesson about the futility of grand predictions. It’s a shame, though, because the five computers prediction looks like it may come true very soon.</p>
<p>Through a combination of adoption of virtualisation technologies (theoretically improving the portability of software deployments) and consolidation onto a small number of providers (practically ensuring that no such portability occurs), three of the five computers can easily be identified. Amazon, Alphabet’s Google and Microsoft each run one of the world’s three largest commercial computer-time rental businesses. Their three CFOs each centrally command an economy worth in the region of $1T (particular quotes taken from Yahoo! Finance on 14th June valued Amazon at $1.27T, Alphabet at $0.96T, and Microsoft at $1.42T), though as we shall soon see it’s probably best to see them as department heads of a single multi-trillion global computer economy encompassing the three businesses and more. To put that into comparison with other planned economies, the Soviet Union reached a GDP of $1T in 1979 and $2T before its dissolution a little over a decade later.</p>
<p>So which computers are fourth and fifth in the global market? Certainly none of the other cloud providers, who are all tiny in comparison. The closest runner is Alibaba ($0.58T), but forget the other western runners, Oracle ($0.16T) and IBM ($0.11T). They can both be seen as attempts to extract rental income from their existing hardware platforms – SPARC and RS6000/Power, respectively.</p>
<p>And talking of RISC CPU designs leads us to disregard another wannabe competitor who’d definitely <em>like</em> to be in the big five, but seems destined to come crashing back down to the ground. As excitement mounts over whether certain high-profile computer vendors may switch to using the ARM CPU design in their systems, ARM sales and revenue are down and parent company Softbank is suffering losses, too (both directly, and its $100B Vision Development Fund). ARM’s heritage is in desktop and mobile computing (the chip was designed to run the Acorn Archimedes line of personal computers, and when ARM was spun out of Acorn they received funding from Apple to develop chips for the Newton line of handheld computers). This is clearly a market that current CEO, Simon Segars, sees as legacy business, the cash cow that he can squeeze to fund his real interest in the Internet of Things. Thus ARM’s new goal, to enable “a trillion connected devices”.</p>
<p>You could see Softbank’s pattern of investments as an attempt to create that fourth computer in the market of five, the distributed computer of things. Whether you’re in the office (Slack, We), at home (Grofers, FirstCry, OpenDoor), or inbetween (Cambridge Mobile Telematics, Mapbox, GetAround), Softbank are hoping that you’re connected to Masa’s computer. Their particular choices, and scattergun approach, mean that this is unlikely to coalesce within the funds and time available to Softbank. It’s unlikely that they’d take ARM down with them before someone stepped in to buy it out. Which brings us on to the <em>real</em> contender for the world’s fourth computer:</p>
<p>Apple. The Apple cloud is a computer that contains a lot of music, TV shows, movies, games, books, news reports, and storage space that users of Apple’s consumer electronics can rent access on. As a cross-selling deal, a small amount of access is offered with the sale of each of the consumer devices. Unlike the other three computers we’ve seen so far (Amazon’s, Alphabet’s, and Microsoft’s), you can’t rent time directly on the Apple computer to run your own code. You can upload your own software, but you rely on people discovering and choosing to run it themselves. The execution is actually done on the end devices, not on the Apple computer, though the documents people create may be synced via the Apple computer. By the way, Apple’s planned economy currently amounts to $1.47T.</p>
<p>You may notice that described this way, the Apple computer sounds a lot like the Ethereum computer, and expect me to suggest that it’s the fifth computer, or maybe the bitcoin computer, but no. It’s the Facebook computer. Like the four previously mentioned, the Facebook computer is a huge distributed computer with billions of users, running lots of different applications. Like the Apple computer, you can’t just run your own code on the Facebook computer (well you <em>can</em> run games), but that doesn’t matter, because most people use computers for the same reasons. The big feature of the Facebook computer is the contacts app, which has about a third of the world’s population on.</p>
<p>Those are the five computers of the world market, together directly controlling $5.8T of the world’s assets, roughly 2/3 the value of the total amount of gold in the world. Indirectly, their influence through app stores, subscription fees, software providers who are dependent on their services, resellers and so on is significantly larger.</p>
<p>And it’s important to consider them together, because the veneer of competing in an open market only goes so deep. Look at any relevant trade association and you’ll see the trillion-dollar computer vendors working together toward their common interests, for example the Cloud Native Computing Foundation (Alibaba, Amazon, Apple, Softbank ARM, Google, IBM, Microsoft, Oracle, others), or the Linux Foundation (Fujitsu, Google, IBM, Microsoft, Oracle, Alibaba, Facebook, Amazon, Softbank ARM, others). There is really one central computing economy, controlling well over six trillion dollars of technology investment, with five different public faces.</p>
<p>How did the market for computers get consolidated to this extent? It certainly wasn’t inevitable. Early examples of outsourced computing were advantageous because the hardware was so expensive, needed specialist and frequent handling, and there just wasn’t much of it about. Those early IBM systems that Watson found more than five customers for could be rented for around $12k-18k per <em>month</em>, so you had to be sure that your computing job was going to save a few people’s salaries before you even ran it in the cloud.</p>
<p>Where companies did invest in computing hardware, offering the platform as a service to others help to offset the purchase and development costs. The first commercial computer in the UK was the Lyons Electronic Office I, developed from the EDSAC machine by food producer Lyons. LEO/I also ran payroll for Ford UK, and weather simulations for the Met Office (until they bought their own Ferranti computer). It was in use between the 1950s and the 1980s, demonstrating great longevity in the days before planned obsolence.</p>
<p>During those decades, the smaller size of components, greater reliability, lower costs, improved usability and application combined with the business vision of key people who set out to provide “a computer on every desktop”. Rather than a small number of computers becoming more capable, capabilities became more widespread, more distributed, more affordable, and more accessible. Computers shrank in size and cost until every office building, every cubicle, every home, eventually every pocket could contain one.</p>
<p>None of the technical, physical or practical trends described above have reversed to lead to the cloud computing consolidation we see today, and the world market for five computers. The only change that can account for this behaviour is the business vision, and the direction in which the cadre of executives take their companies.</p>
<p>Since the dot com crash of 1999-2001, investors have looked to seed companies with the smallest amount of money possible to lead to either a rapid collapse or rapid growth supported by multiple follow-on investment rounds until an eventual exit. Hockey-stick charts, “disruption”, “MVPs”, “growth hacking”, “fail fast” are not neutral business advice, but a particular way of working designed to minimise risk and maximise payoff for a small clique of rich investors who expect the money they lend out to work its way back into the system – perhaps through cloud subscription fees paid to companies they hold positions in. Don’t go buying expensive capital investments like offices, desks or computers when you can rent them…from us.</p>
<p>This has led to the situation where computing applications are architected with the goal of rapidly meeting the goal of tomorrow’s investor presentation, regardless of the effect this has on the later costs or usability of the product. One workload I now support would cost an estimated £6000 per month to run on one of the large cloud providers, which would allow me to purchase the actual hardware in use four times over every year. But “spinning up an instance” today using free credits means you can worry about that cost later, whereas ordering a box from Dell means waiting two to three business days by which …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deprogrammaticaipsum.com/five-computers/">https://deprogrammaticaipsum.com/five-computers/</a></em></p>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/five-computers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746253</guid>
            <pubDate>Mon, 06 Jul 2020 10:04:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing Images On The World's Top 100 Websites]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23746233">thread link</a>) | @matylla
<br/>
July 6, 2020 | https://optidash.ai/blog/optimizing-images-on-the-worlds-top-100-websites | <a href="https://web.archive.org/web/*/https://optidash.ai/blog/optimizing-images-on-the-worlds-top-100-websites">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>The world’s most visited websites receive insane amounts of traffic and push petabytes of data to visitors all around the globe. Because images alone represent over 60% of today’s Internet traffic, one would think that the top 100 websites would keep their images as light as possible. At the end of the day, saving millions of dollars in yearly bandwidth and storage fees seems like a good strategy. Let’s find out how well visual content is treated on these websites.</p><h2>Methodology</h2><p>The only 100% reliable way to fetch all images from those websites is by using a real browser on a desktop machine. That’s why we’ve manually crawled websites in this test and exported all network activity as HAR files. While Puppeteer with <code>stealth</code> plugin and an auto-rotating proxy seems to produce acceptable results for the majority of use cases, we wanted to be absolutely sure we’re getting all visuals. Test results are only as good as the input data used to compute them.</p><p>Collected HAR files were loaded to and parsed in our test application. We then extracted all requests with a matching <code>image/*</code> mime type and discarded those with body length less than 100 bytes as those were mainly 1x1 GIF tracking pixels.</p><p>One of the major benefits of recording and using HAR files is that all binary responses are already <code>base64</code>-encoded right into them so we only had to load them into temporary buffers and save the binaries to disk:</p><pre><code>(async () =&gt; {
    const src = Buffer.from(response.content.text, "base64");

    try {
        await fs.writeFile(`./sites/${site_name}/images/${file_name}`, src);
    } catch(err) {
        console.error(err);
    }
})();</code></pre><h2>Test results</h2><p>We’ve pumped all the source images through the <a href="https://docs.optidash.ai/">Optidash API</a>. In total, we’ve collected and optimized <strong>8353 images</strong> and saved <strong>32.61% of the initial file size</strong>.</p><p>The actual optimization and recompression results were measured using the following formula:</p><pre><code>100 * (original_size - optimized_size) / original_size</code></pre><h2>Image formats</h2><p>JPEG is still the most commonly used image format with a 53% share followed by PNG (23%) and WebP (16%). It’s worth noting that on some websites, most notably StackOverflow, Amazon AWS, and Atlassian, SVGs are used almost exclusively.</p><div><figure><img srcset="https://optidash.ai/assets/images/blog/optimization-stats-q2-2020/image-formats.png, https://optidash.ai/assets/images/blog/optimization-stats-q2-2020/image-formats@2x.png 2x" width="313"></figure></div><h2>JPEG images</h2><ul><li>The most commonly used (24% of all the JPEGs) encoding quality is <code>87</code> followed by <code>77</code> (8.6%) and <code>100</code> (8.3%).</li><li><strong>Only 31%</strong> of JPEG images use progressive coding.</li><li><code>4:2:0</code> is the most commonly used sampling scheme (69%) followed by <code>4:4:4</code> (30%) and <code>4:2:2</code> (1%)</li></ul><p>The stats above show great potential for further reducing the file size of JPEG images. Progressive coding along with <code>4:2:0</code> sampling scheme and ideal Q value predicted on a per-image basis will yield enormous savings.</p><h2>WebP images</h2><p>Exactly 33.33% of the top 100 websites use WebP on as a primary image format. It’s good to see more developers decide to go the extra mile and ensure WebP variants of their website’s visual content. But serving WebP images is one thing and optimizing them is something they should consider. We’ve been able to further optimize all of the WebP content using a near-lossless algorithm and saw substantial savings there.</p><h2>Interesting stats</h2><ul><li>The total weight of visual content across all 100 websites is <strong>228.96MB</strong>.</li><li>The website with the largest number of images (397) is <a href="https://www.rakuten.co.jp/">Rakuten</a>.</li><li>The website with the heaviest visual content (11.1MB) is <a href="https://www.sina.com.cn/">Sina</a>.</li><li>The top five heaviest images were served on Sina (<a href="https://n.sinaimg.cn/tech/510/w343h167/20200630/9c8b-ivrxcex7479562.gif">3.7MB</a>), Reddit (<a href="https://styles.redditmedia.com/t5_2x4yx/styles/communityIcon_ex5aikhvi3i41.png">3.6MB</a>), IMDB (<a href="https://m.media-amazon.com/images/M/MV5BNmI3YjUxMGYtNDZmMC00ZTVlLTg5MjgtOTU2MGNkNDhlMGI2XkEyXkFqcGdeQXVyMDM2NDM2MQ@@._CR515,799,4800,2700.jpg">3.0MB</a>), Office (<a href="https://blobs.officehome.msocdn.com/images/content/images/office-apps-347d86a528.gif">2.8MB</a>) and BBC (<a href="https://ychef.files.bbci.co.uk/original/p08hn1gz.jpg">1.9MB</a>).</li></ul><h2>Detailed results</h2><p>Below we present a detailed list of the top 100 websites along with optimization results. Please <a href="https://optidash.ai/contact">reach out to us</a> if you want to get access to the dataset used for compiling the following table.</p><div><table><thead><tr><td>Rank</td><td>Site</td><td>Images</td><td>Before</td><td>After</td><td>Savings</td><td>Savings %</td></tr></thead><tbody><tr><td>01</td><td>google.com</td><td>5</td><td>92 kB</td><td>81.8 kB</td><td>10.2 kB</td><td>11.12%</td></tr><tr><td>02</td><td>youtube.com</td><td>54</td><td>815 kB</td><td>751 kB</td><td>64.2 kB</td><td>7.88%</td></tr><tr><td>03</td><td>tmall.com</td><td>154</td><td>15.4 MB</td><td>7.99 MB</td><td>7.43 MB</td><td>48.16%</td></tr><tr><td>04</td><td>qq.com</td><td>37</td><td>630 kB</td><td>340 kB</td><td>290 kB</td><td>46.02%</td></tr><tr><td>05</td><td>baidu.com</td><td>20</td><td>83.4 kB</td><td>36.1 kB</td><td>47.2 kB</td><td>56.64%</td></tr><tr><td>06</td><td>facebook.com</td><td>8</td><td>116 kB</td><td>56.4 kB</td><td>59.8 kB</td><td>51.44%</td></tr><tr><td>07</td><td>sohu.com</td><td>184</td><td>7.82 MB</td><td>5.15 MB</td><td>2.66 MB</td><td>34.07%</td></tr><tr><td>08</td><td>taobao.com</td><td>142</td><td>2.61 MB</td><td>2.28 MB</td><td>327 kB</td><td>12.53%</td></tr><tr><td>09</td><td>yahoo.com</td><td>146</td><td>2.84 MB</td><td>2.3 MB</td><td>541 kB</td><td>19.05%</td></tr><tr><td>10</td><td>amazon.com</td><td>213</td><td>2.84 MB</td><td>2.4 MB</td><td>434 kB</td><td>15.31%</td></tr><tr><td>11</td><td>jd.com</td><td>166</td><td>4.65 MB</td><td>3.02 MB</td><td>1.63 MB</td><td>35.09%</td></tr><tr><td>12</td><td>360.cn</td><td>140</td><td>3.77 MB</td><td>2.28 MB</td><td>1.48 MB</td><td>39.32%</td></tr><tr><td>13</td><td>wikipedia.org</td><td>4</td><td>86.4 kB</td><td>83.9 kB</td><td>2.45 kB</td><td>2.84%</td></tr><tr><td>14</td><td>login.tmall.com</td><td>7</td><td>162 kB</td><td>114 kB</td><td>47.9 kB</td><td>29.61%</td></tr><tr><td>15</td><td>weibo.com</td><td>159</td><td>2.38 MB</td><td>1.89 MB</td><td>490 kB</td><td>20.55%</td></tr><tr><td>16</td><td>live.com</td><td>48</td><td>4.38 MB</td><td>3.95 MB</td><td>427 kB</td><td>9.74%</td></tr><tr><td>17</td><td>zoom.us</td><td>73</td><td>2.44 MB</td><td>1.05 MB</td><td>1.38 MB</td><td>56.76%</td></tr><tr><td>18</td><td>reddit.com</td><td>151</td><td>9.72 MB</td><td>4.34 MB</td><td>5.38 MB</td><td>55.38%</td></tr><tr><td>19</td><td>sina.com.cn</td><td>187</td><td>11.1 MB</td><td>5.78 MB</td><td>5.28 MB</td><td>47.71%</td></tr><tr><td>20</td><td>netflix.com</td><td>7</td><td>603 kB</td><td>480 kB</td><td>124 kB</td><td>20.53%</td></tr><tr><td>21</td><td>microsoft.com</td><td>23</td><td>275 kB</td><td>266 kB</td><td>9.14 kB</td><td>3.32%</td></tr><tr><td>22</td><td>xinhuanet.com</td><td>292</td><td>8.35 MB</td><td>3.84 MB</td><td>4.51 MB</td><td>54.05%</td></tr><tr><td>23</td><td>okezone.com</td><td>132</td><td>1.6 MB</td><td>1.44 MB</td><td>165 kB</td><td>10.28%</td></tr><tr><td>24</td><td>vk.com</td><td>9</td><td>182 kB</td><td>181 kB</td><td>613 B</td><td>0.34%</td></tr><tr><td>25</td><td>office.com</td><td>12</td><td>3.37 MB</td><td>2.86 MB</td><td>512 kB</td><td>15.16%</td></tr><tr><td>26</td><td>instagram.com</td><td>10</td><td>990 kB</td><td>525 kB</td><td>464 kB</td><td>46.93%</td></tr><tr><td>27</td><td>myshopify.com</td><td>2</td><td>5.28 kB</td><td>5.06 kB</td><td>218 B</td><td>4.13%</td></tr><tr><td>28</td><td>csdn.net</td><td>107</td><td>3.83 MB</td><td>1.4 MB</td><td>2.43 MB</td><td>63.38%</td></tr><tr><td>29</td><td>alipay.com</td><td>11</td><td>699 kB</td><td>448 kB</td><td>251 kB</td><td>35.86%</td></tr><tr><td>30</td><td>yahoo.co.jp</td><td>168</td><td>1.44 MB</td><td>1.23 MB</td><td>209 kB</td><td>14.52%</td></tr><tr><td>31</td><td>bing.com</td><td>19</td><td>461 kB</td><td>324 kB</td><td>137 kB</td><td>29.71%</td></tr><tr><td>32</td><td>bongacams.com</td><td>84</td><td>1.6 MB</td><td>1.5 MB</td><td>102 kB</td><td>6.38%</td></tr><tr><td>33</td><td>blogger.com</td><td>43</td><td>1.5 MB</td><td>1.4 MB</td><td>103 kB</td><td>6.88%</td></tr><tr><td>34</td><td>twitch.tv</td><td>63</td><td>863 kB</td><td>641 kB</td><td>222 kB</td><td>25.75%</td></tr><tr><td>35</td><td>aliexpress.com</td><td>197</td><td>4 MB</td><td>2.88 MB</td><td>1.12 MB</td><td>28.08%</td></tr><tr><td>36</td><td>google.com.hk</td><td>5</td><td>91.9 kB</td><td>81.7 kB</td><td>10.2 kB</td><td>11.13%</td></tr><tr><td>37</td><td>zhanqi.tv</td><td>109</td><td>2.65 MB</td><td>1.31 MB</td><td>1.33 MB</td><td>50.37%</td></tr><tr><td>38</td><td>naver.com</td><td>53</td><td>1.56 MB</td><td>904 kB</td><td>656 kB</td><td>42.05%</td></tr><tr><td>39</td><td>ebay.com</td><td>16</td><td>227 kB</td><td>146 kB</td><td>81.1 kB</td><td>35.69%</td></tr><tr><td>40</td><td>tianya.cn</td><td>8</td><td>202 kB</td><td>88.5 kB</td><td>113 kB</td><td>56.11%</td></tr><tr><td>41</td><td>livejasmin.com</td><td>166</td><td>2.21 MB</td><td>2 MB</td><td>213 kB</td><td>9.60%</td></tr><tr><td>42</td><td>amazon.co.jp</td><td>247</td><td>4.57 MB</td><td>4.18 MB</td><td>387 kB</td><td>8.47%</td></tr><tr><td>43</td><td>apple.com</td><td>18</td><td>358 kB</td><td>229 kB</td><td>129 kB</td><td>35.99%</td></tr><tr><td>44</td><td>google.co.in</td><td>5</td><td>91.9 kB</td><td>81.7 kB</td><td>10.2 kB</td><td>11.13%</td></tr><tr><td>45</td><td>chaturbate.com</td><td>125</td><td>1.79 MB</td><td>1.64 MB</td><td>146 kB</td><td>8.19%</td></tr><tr><td>46</td><td>adobe.com</td><td>27</td><td>1.01 MB</td><td>746 kB</td><td>259 kB</td><td>25.79%</td></tr><tr><td>47</td><td>china.com.cn</td><td>111</td><td>6.3 MB</td><td>2.91 MB</td><td>3.39 MB</td><td>53.80%</td></tr><tr><td>48</td><td>amazon.in</td><td>314</td><td>4.91 MB</td><td>4.43 MB</td><td>480 kB</td><td>9.77%</td></tr><tr><td>49</td><td>tribunnews.com</td><td>151</td><td>1.2 MB</td><td>1.03 MB</td><td>171 kB</td><td>14.25%</td></tr><tr><td>50</td><td>babytree.com</td><td>77</td><td>1.89 MB</td><td>862 kB</td><td>1.03 MB</td><td>54.38%</td></tr><tr><td>51</td><td>twitter.com</td><td>15</td><td>298 kB</td><td>262 kB</td><td>36.1 kB</td><td>12.13%</td></tr><tr><td>52</td><td>linkedin.com</td><td>29</td><td>371 kB</td><td>160 kB</td><td>211 kB</td><td>56.77%</td></tr><tr><td>53</td><td>msn.com</td><td>181</td><td>3.79 MB</td><td>2.08 MB</td><td>1.72 MB</td><td>45.30%</td></tr><tr><td>54</td><td>yandex.ru</td><td>28</td><td>273 kB</td><td>207 kB</td><td>65.7 kB</td><td>24.08%</td></tr><tr><td>55</td><td>sogou.com</td><td>9</td><td>20 kB</td><td>18.9 kB</td><td>1.1 kB</td><td>5.49%</td></tr><tr><td>56</td><td>huanqiu.com</td><td>48</td><td>1.22 MB</td><td>745 kB</td><td>480 kB</td><td>39.18%</td></tr><tr><td>57</td><td>aparat.com</td><td>245</td><td>9.24 MB</td><td>6.16 MB</td><td>3.08 MB</td><td>33.38%</td></tr><tr><td>58</td><td>yy.com</td><td>188</td><td>5.41 MB</td><td>3.34 MB</td><td>2.07 MB</td><td>38.31%</td></tr><tr><td>59</td><td>dropbox.com</td><td>24</td><td>1.04 MB</td><td>924 kB</td><td>115 kB</td><td>11.05%</td></tr><tr><td>60</td><td>wordpress.com</td><td>38</td><td>1.66 MB</td><td>1.66 MB</td><td>1.21 kB</td><td>0.07%</td></tr><tr><td>61</td><td>ok.ru</td><td>21</td><td>1.88 MB</td><td>1.13 MB</td><td>750 kB</td><td>39.91%</td></tr><tr><td>62</td><td>pornhub.com</td><td>72</td><td>917 kB</td><td>792 kB</td><td>125 kB</td><td>13.66%</td></tr><tr><td>63</td><td>mail.ru</td><td>67</td><td>1.02 MB</td><td>664 kB</td><td>356 kB</td><td>34.90%</td></tr><tr><td>64</td><td>whatsapp.com</td><td>8</td><td>321 kB</td><td>301 kB</td><td>19.3 kB</td><td>6.04%</td></tr><tr><td>65</td><td>google.co.jp</td><td>5</td><td>91.9 kB</td><td>81.7 kB</td><td>10.2 kB</td><td>11.13%</td></tr><tr><td>66</td><td>google.com.br</td><td>5</td><td>91.9 kB</td><td>81.7 kB</td><td>10.2 kB</td><td>11.13%</td></tr><tr><td>67</td><td>medium.com</td><td>19</td><td>54.3 kB</td><td>33.9 kB</td><td>20.5 kB</td><td>37.67%</td></tr><tr><td>68</td><td>imdb.com</td><td>53</td><td>4.65 MB</td><td>4.62 MB</td><td>26.3 kB</td><td>0.57%</td></tr><tr><td>69</td><td>err.tmall.com</td><td>9</td><td>33.2 kB</td><td>26.6 kB</td><td>6.6 kB</td><td>19.86%</td></tr><tr><td>70</td><td>imgur.com</td><td>153</td><td>5.31 MB</td><td>4.46 MB</td><td>848 kB</td><td>15.97%</td></tr><tr><td>71</td><td>17ok.com</td><td>165</td><td>7.97 MB</td><td>6.29 MB</td><td>1.68 MB</td><td>21.13%</td></tr><tr><td>72</td><td>aws.amazon.com</td><td>131</td><td>1.84 MB</td><td>1.33 MB</td><td>510 kB</td><td>27.76%</td></tr><tr><td>73</td><td>cnn.com</td><td>70</td><td>1.74 MB</td><td>1.21 MB</td><td>527 kB</td><td>30.33%</td></tr><tr><td>74</td><td>spotify.com</td><td>4</td><td>5.47 kB</td><td>2.26 kB</td><td>3.21 kB</td><td>58.66%</td></tr><tr><td>75</td><td>indeed.com</td><td>1</td><td>775 B</td><td>775 B</td><td>0 B</td><td>0.00%</td></tr><tr><td>76</td><td>google.cn</td><td>2</td><td>29.1 kB</td><td>17.6 kB</td><td>11.6 kB</td><td>39.70%</td></tr><tr><td>77</td><td>nytimes.com</td><td>131</td><td>6.67 MB</td><td>4.35 MB</td><td>2.31 MB</td><td>34.70%</td></tr><tr><td>78</td><td>xvideos.com</td><td>54</td><td>791 kB</td><td>677 kB</td><td>114 kB</td><td>14.43%</td></tr><tr><td>79</td><td>jrj.com.cn</td><td>132</td><td>2.41 MB</td><td>1.44 MB</td><td>963 kB</td><td>40.00%</td></tr><tr><td>80</td><td>1688.com</td><td>234</td><td>9.84 MB</td><td>5.19 MB</td><td>4.65 MB</td><td>47.26%</td></tr><tr><td>81</td><td>bbc.com</td><td>68</td><td>9.7 MB</td><td>7.47 MB</td><td>2.22 MB</td><td>22.93%</td></tr><tr><td>82</td><td>etsy.com</td><td>9</td><td>349 kB</td><td>276 kB</td><td>72.9 kB</td><td>20.92%</td></tr><tr><td>83</td><td>mama.cn</td><td>102</td><td>3.32 MB</td><td>1.54 MB</td><td>1.78 MB</td><td>53.69%</td></tr><tr><td>84</td><td>rakuten.co.jp</td><td>397</td><td>3.2 MB</td><td>2.45 MB</td><td>749 kB</td><td>23.41%</td></tr><tr><td>85</td><td>grid.id</td><td>60</td><td>1.15 MB</td><td>924 kB</td><td>225 kB</td><td>19.56%</td></tr><tr><td>86</td><td>amazon.de</td><td>226</td><td>3.53 MB</td><td>3.04 MB</td><td>488 kB</td><td>13.86%</td></tr><tr><td>87</td><td>udemy.com</td><td>30</td><td>522 kB</td><td>436 kB</td><td>85.2 kB</td><td>16.33%</td></tr><tr><td>88</td><td>amazon.co.uk</td><td>305</td><td>4.8 MB</td><td>4.05 MB</td><td>746 kB</td><td>15.55%</td></tr><tr><td>89</td><td>flipkart.com</td><td>138</td><td>751 kB</td><td>744 kB</td><td>6.74 kB</td><td>0.90%</td></tr><tr><td>90</td><td>paypal.com</td><td>15</td><td>490 kB</td><td>484 kB</td><td>6.2 kB</td><td>1.26%</td></tr><tr><td>91</td><td>google.de</td><td>5</td><td>92 kB</td><td>81.8 kB</td><td>10.2 kB</td><td>11.12%</td></tr><tr><td>92</td><td>roblox.com</td><td>14</td><td>695 kB</td><td>593 kB</td><td>102 kB</td><td>14.67%</td></tr><tr><td>93</td><td>okta.com</td><td>30</td><td>438 kB</td><td>340 kB</td><td>98.4 kB</td><td>22.46%</td></tr><tr><td>94</td><td>soundcloud.com</td><td>28</td><td>2.7 MB</td><td>2.17 MB</td><td>527 kB</td><td>19.53%</td></tr><tr><td>95</td><td>pixnet.net</td><td>63</td><td>522 kB</td><td>366 kB</td><td>157 kB</td><td>29.99%</td></tr><tr><td>96</td><td>office365.com</td><td>11</td><td>1.65 MB</td><td>492 kB</td><td>1.16 MB</td><td>70.15%</td></tr><tr><td>97</td><td>detik.com</td><td>131</td><td>4.27 MB</td><td>2.16 MB</td><td>2.11 MB</td><td>49.45%</td></tr><tr><td>98</td><td>booking.com</td><td>59</td><td>1.28 MB</td><td>1.12 MB</td><td>162 kB</td><td>12.67%</td></tr><tr><td>99</td><td>atlassian.com</td><td>49</td><td>751 kB</td><td>686 kB</td><td>65 kB</td><td>8.66%</td></tr><tr><td>100</td><td>stackoverflow.com</td><td>32</td><td>181 kB</td><td>139 kB</td><td>42.3 kB</td><td>23.34%</td></tr></tbody></table></div></article></div>]]>
            </description>
            <link>https://optidash.ai/blog/optimizing-images-on-the-worlds-top-100-websites</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746233</guid>
            <pubDate>Mon, 06 Jul 2020 09:59:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Industrial Society and its Future”: the writings of the Unabomber]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 167 (<a href="https://news.ycombinator.com/item?id=23746087">thread link</a>) | @roelp_be
<br/>
July 6, 2020 | https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/ | <a href="https://web.archive.org/web/*/https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Preface to this blog post</h2>



<p>Why review a book from the hand of a notorious terrorist who killed three and maimed dozens of people? That seems like the right question to answer before continuing this blog post. <a href="https://en.wikipedia.org/wiki/Ted_Kaczynski">Theodore J. Kaczynski</a> is an extremely intelligent yet wounded man. He’s been a victim of cold-war era social experiments and, throughout his life, has always been an outsider. He retreated from society and lived like a hermit in the woods in Montana. Nevertheless, he was an activist in search of attention for his ideology and manifesto.</p>



<p>Numerous human lives have been sacrificed on the altars of freedom, ideology, and a better world. Wherever you position yourself on the political spectrum, from left to right, your heroes have blood on their hands. Reagan, Lenin, Bush, Mao, Napoleon, Robespierre, Obama, Chavez, Macron, Selassie, and Guevara, in one way or another, are responsible for the death and suffering of many. Yet we read their memoirs, manifestoes, and biographies. We have their posters on the walls of our children’s rooms. In this light, <strong>the refusal to read and review <em>Industrial Society and its Future</em> would be an act of hypocrisy. </strong></p>



<p>Finally, the central claim that technology is inherently bad for society is of relevance to this blog. I completely distance myself from the man’s actions, but his manifesto definitely struck a chord. I currently cannot think of a better way to scrutinize my techno-optimism than to write about it.</p>



<h2>The Power Process</h2>



<p><em>Industrial Society and its Future</em> is an essay of 232 numbered paragraphs in which Kaczynski explains what’s wrong with society, how it should be, and how we can get there. The most interesting parts of the essay describe the core concept of the <em>Power Process</em>, its consequences, and how technology has an impact on it.</p>



<p><strong>Human drives</strong> can be classified in three broad categories:</p>



<ul><li>Drives that can be satisfied with minimal effort: a walk around the block.</li><li>Drives that can be satisfied at the cost of serious effort: chopping down a tree for burning wood.</li><li>Drives that cannot be satisfied, no matter the effort one puts in it: somersault from a high cliff and survive it</li></ul>



<p>Kaczynski claims that <strong>all humans need a power process</strong>: (1) we all need goals, (2) effort to attain them, and (3) the attainment of some of these goals. Finally, it requires a degree of (4) autonomy. Consequently, the power process is part of the second category of human drives.</p>



<p>If unattained goals result in death, they are important. If the non-attainment of one’s goals is compatible with survival (i.e. not important), it will lead to defeatism, low self-esteem, and depression (as I explain later on). In the Western world, one only needs minimum effort to survive. Satisfying biological needs has been reduced to triviality. One can live off welfare checks, or have a bullshit job to satisfy physical needs. The only thing required is a minimal degree of obedience. Humans have given up autonomy and effort to attain the needs to survive — the important goals.  That’s why humans artificially create the four components of the power process for themselves: they are involved in <strong>surrogate activities</strong>: long-distance running, blogging, collecting stamps, gardening and even pursuing an academic career. </p>



<h2>Technology messes with the power process</h2>



<p>Kaczynski distinguishes between <strong>two kinds of technology</strong>: The first one is <strong>small-scale technology</strong>, like a mill or a water wheel. The second kind is <strong>organization-dependent technology</strong> that requires large-scale social organization: A refrigerator depends on complicated and industrially created parts and requires electricity. The first kind can produce real progress and freedom. The second kind has a negative impact on our freedom: the externalities outweigh the benefits. It’s <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">the prisoner’s dilemma</a> on a global scale.</p>



<p>Since the Industrial Revolution, most new technologies are of the second kind. The wave of <em>smart</em> and <em>connected</em> devices and software that’s heading our way is no different. Algorithms can curate all available information on our timelines, only inviting more and more (fake?) articles to be produced. Autonomous cars are safer and offer the freedom to keep the hands of the wheel. Yet as self-driving cars are simply sensors on wheels, you will have zero privacy regarding your location. Self-service checkouts are supposed to be faster. Yet as supermarket customers more often use them, fewer registers with cashiers will be available, reducing human personal contact. Oh, and you need a loyalty card, which is digital-only, for which you need a smartphone.</p>



<p>Social and psychological problems arise when humans cannot go through the power process. <strong>In modern society, technology (especially of the second kind) tends to push drives into the first group</strong>: gathering food is now <a href="https://www.ubereats.com/">one tap away</a>.  Intimacy can be achieved by <a href="https://tinder.com/">swiping</a> or paying a <a href="https://www.pornhub.com/live">minimum fee</a>. Leisure can be found on <a href="https://www.netflix.com/be-en/">Netflix</a> or <a href="https://store.steampowered.com/">Steam</a>. Turn up the heat by asking your <a href="https://store.google.com/us/magazine/compare_thermostats">Nest</a>. </p>



<p>On the other hand,<strong> technology also moved other drives into the third category</strong>. With urbanization reaching record numbers; experiencing authenticity, harmony, nature, silence, and clean air is nearly impossible for many inhabitants of this planet.</p>



<p><strong>Some important goals that remain in the second category, like achieving status, can no longer be done autonomously</strong>. To reach the highest echelons of the corporate ladder, one needs to adhere to company culture, engage in networking, and pass opaque assessments. A management position is often at the goodwill of another manager, higher up.</p>



<p>The primitive man only had to fear disease and certain aspects of the environment. He could accept this stoically, or invent gods and demons. But these problems weren’t man-made, imposed on them by someone’s decision which he had no impact on. Although many of us create them for themselves, for others,<strong> surrogate activities do not suffice. The results are aggression, mental breakdowns, burnouts, depressions, mid-life crises, and declining fertility.</strong> As decisions are increasingly outsourced to <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"><em>trustworthy </em>and <em>unbiased</em> machines</a> — think<a href="https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html"> facial recognition by police departments</a>, or <a href="https://www.technologyreview.com/2019/01/21/137783/algorithms-criminal-justice-ai/">algorithms sending people to jail</a> — hopelessness and rebellion will only increase.</p>



<p>In modern society, mental health is defined by how one behaves in accord with the needs of the system.</p>



<h2>Technology is a rational response to problems</h2>



<p>A compromise between freedom and technology is impossible because technology is a more powerful social force than the aspiration for freedom. That’s because each new technology appears to be desirable<strong> and only threatens our freedom later on</strong>. Motorized transport allows us to travel a lot farther. Yet once the adoption of cars reaches a critical threshold, one is <em>expected</em> to own a car: Local shops and public services disappear and become centralized in malls and government buildings. The internet allowed us to communicate with each other faster than ever. As companies adopted the internet, one can no longer apply for a job without an internet connection. Technology changes society as to make itself indispensable.</p>



<p>The following words read like a prophecy: “<em>Generally speaking, <strong>technological control over human behavior will probably not be introduced with a totalitarian intention</strong> or even through a conscious desire to restrict human freedom. Each new step in the assertion of control over the humankind will be taken as a rational response to a problem that faces society…”</em></p>



<p>For example, society has given up privacy to battle COVID-19 with apps and track&amp;trace strategies. Facebook promised us freedom of speech and unlimited reach, but without the financial means, you’re <a href="https://blog.hootsuite.com/facebook-algorithm/">shouting in a vacuum</a>. The Patriot Act (and the <a href="https://www.aclu.org/issues/national-security/privacy-and-surveillance/surveillance-under-patriot-act">mass surveillance technology</a> that came with it) was designed to battle terrorism but introduced legal arbitrariness. These three examples were all <strong>rational responses to existing problems but produced unforeseen externalities</strong>.</p>



<p>As technology makes itself indispensable, machines will take care of more and more tasks and “<em>on those who are employed, ever-increasing demands will be placed: the will need more training, more and more ability, and will have to be ever more reliable, conforming and docile, because they will be more and more like cells of a giant organism.</em>“</p>



<p>Think of the swarm of Uber or Lyft drivers who took a short training on how to use the app and are now driving people around in servile silence. Their data feeds the algorithm, and the algorithm thinks for them. <strong>The only thing left is to abide by the system.</strong></p>



<h2>Revolution</h2>



<p>Which brings us to Kaczynski’s “solution”. This topic lacks the depth and cunning analogies that can be found in the earlier chapters. His recipes aren’t new: one can find elements of <a href="https://en.wikipedia.org/wiki/Mikhail_Bakunin">Bakunist</a>, <a href="https://en.wikipedia.org/wiki/Cultural_hegemony">Gramscist</a>, and <a href="https://en.wikipedia.org/wiki/Foco">Debrayist</a> thinking.</p>



<p>Because technology is the strongest social force, <strong>gradual change is impossible</strong>. The only way to break this circle, this slippery slope to servitude to the machine, is a revolution. While the system might collapse under its own internal difficulties, Kaczynski claims we should promote social stress and instability in industrial society. Humanity should return to nature to live in small groups and to be in control of life-and-death issues: food, clothing, shelter, and defense. This is true freedom: the power to control the circumstances of one’s own life. It’s not an ideology, it’s Nature with a big N:</p>



<p><em>“We have no illusions about the feasibility of creating a new, ideal form of society. Our goal is only to destroy the existing form of society.”</em></p>



<h2>Final thoughts</h2>



<p>Manifestos are always dull, so I didn’t expect this book to be an enjoyable read. But quite a lot of insights were so masterfully crafted, that I often had to allow my mind to wander off in a quest to find (counter-)examples and arguments to what I just read. If you’re into political theory, this will be a treat.</p>



<p>Nevertheless, the structure of the book and the order of the chapters seemed strange to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/">https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/</a></em></p>]]>
            </description>
            <link>https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746087</guid>
            <pubDate>Mon, 06 Jul 2020 09:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Stockholm Rail Network Map]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745992">thread link</a>) | @omelekhin
<br/>
July 6, 2020 | https://spartrafikkarta.se/en | <a href="https://web.archive.org/web/*/https://spartrafikkarta.se/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://spartrafikkarta.se/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745992</guid>
            <pubDate>Mon, 06 Jul 2020 09:06:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 0 Password, never losing your password manager password]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745988">thread link</a>) | @AutumnWu
<br/>
July 6, 2020 | https://www.bluespace.tech/blog/0password/ | <a href="https://web.archive.org/web/*/https://www.bluespace.tech/blog/0password/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        <p><img src="https://www.bluespace.tech/blog/0password/forgot-password.png"></p>
        <p>A few months ago, Scott Stein shared an article on CNet, <a href="https://www.cnet.com/news/password-managers-great-until-you-lose-access-world-password-day/">Password managers are great -- until you lose your password manager password</a>. Many people shared and retweeted the article. You know that feeling if you ever lost the password to your password manager.</p>
        <h2 id="why-do-password-managers-require-a-master-password">Why do password managers require a master password?</h2>
        <p>The earliest first generation password managers can manage passwords, by keeping them somewhere, but not protect them well.</p>
        <p>About 20 years ago, <a href="https://en.wikipedia.org/wiki/PBKDF2">PBKDF2</a> was recommended as a standard. It transforms a simple password into a complex key which can be used in cryptographic algorithms.</p>
        <p>Since then, lots of second and third generation password managers have been emerging. They derive encryption key from master password, then encrypt user data with the key. This is how it works:</p>
        <pre>            <code><p>graph TD

            subgraph 1. key derivation

            password --&gt; PBKDF2(PBKDF2)
            salt --&gt; PBKDF2
            PBKDF2 --&gt;|derive| key[[key]]

            end

            subgraph 2. encryption

            key --&gt; AES(AES)
            plaintext --&gt; AES
            AES --&gt; |encrypt| ciphertext[(ciphertext)]

            end

            style password fill:#fff, stroke: #aaa
            style ciphertext fill: #ddd, stroke: #aaa
            style salt fill:#fff
            style plaintext fill:#fff, stroke: #aaa
            </p></code>
        </pre>
        <blockquote>
        <p>In cryptography,</p>
        <ul>
        <li><code>plaintext</code> is unencrypted data intended to be encrypted;</li>
        <li><code>ciphertext</code> is the output of encryption of <code>plaintext</code>.</li>
        </ul>
        </blockquote>
        <p>To get the <code>plaintext</code> back, password managers derive the key just as above, but perform decrypt operation instead of encrypt operation in the second step.</p>
        <pre>            <code><p>graph TD

            subgraph 1. key derivation

            password --&gt; PBKDF2(PBKDF2)
            salt --&gt; PBKDF2
            PBKDF2 --&gt;|derive| key[[key]]

            end

            subgraph 2. decryption

            key --&gt; AES(AES)
            ciphertext[(ciphertext)] --&gt; AES
            AES --&gt; |decrypt| plaintext

            end

            style password fill:#fff, stroke: #aaa
            style salt fill:#fff
            style plaintext fill:#fff, stroke: #aaa
            style ciphertext fill:#ddd, stroke: #aaa
            </p></code>
        </pre>
        <p>I will not go deep for it in this article. If you are interested in the details, please checkout this series <a href="https://www.bluespace.tech/blog/evolution-of-password-manager/">The evolution of password manager</a>.</p>
        <p>Essentially, to encrypt user data, password managers must rely on some <strong>secret controlled by the user</strong>, so that hackers cannot get data from the ciphertext.</p>
        <h2 id="secret-in-security-chip">Secret in security chip</h2>
        <p><img src="https://www.bluespace.tech/blog/0password/security-chip.png" alt=""></p>
        <p><a href="https://developer.android.com/guide/topics/connectivity/nfc/hce#SecureElement">NFC card emulation with a secure element in Android.</a></p>
        <p>Nowadays, most smartphones, except some low-end ones, are equipped with a dedicated security chip(Trusted Execution Environment, Secure Element, or Secure Enclave in iOS). Emulated payment cards in iPhone and Android wallet apps are secured by this chip.</p>
        <p>Our fourth generation password manager, ID Guard Offline, can be safely used without a master password. The secret for encryption can be secured by the chip which is much more reliable than human brain. Again, if you are interested in how it works, please checkout <a href="https://www.bluespace.tech/blog/evolution-of-password-manager/fourth-generation-password-manager.html">The Evolution of Password Manager (4/4)</a>.</p>
        <h3 id="master-password">Master password</h3>
        <p>Scott Stein, the CNet staff, lost all his passwords because of forgetting master password. It is the nature of the algorithm above. In addition to using security chip protection, ID Guard Offline also offers master password protection (users can choose whether to use it). So our users may also encounter the same problem. We believe that availability is just as important as confidentiality to password managers and we need to resolve that problem.</p>
        <p>Some password manager providers allow user to reset master password, Google for example. If a user can reset master password and continue to view passwords stored previously, then those passwords are not secured by the master password.</p>
        <p>Our team of course do not compromise on security. The master password can never be reset. Then, is it possible to get the master password back when our user cannot recall it?</p>
        <h3 id="find-back-my-password">Find back my password</h3>
        <p>Some social services offer user account recovery with the help of trusted contacts when the user forgets the password. Here is how it works.</p>
        <ul>
        <li>The user is required to ask his/her trusted contacts to accomplish some tasks(e.g. sending a code).</li>
        <li>The service detects whether those trusted contacts complete the tasks.</li>
        <li>If so, the service lets the user login and asks he/she to reset password.</li>
        </ul>
        <p>Inspired by this, we have a simple idea: ask friends to help find password back. And finally, we perfected this design after several iterations.</p>
        <ol>
        <li>
            <p>Ask friends to save my password</p>
            
            <p>The first idea coming into our minds was just asking friends to save the password. When forgetting the password, ask a friend to tell me the password. It's like asking a friend to keep my house keys temporarily.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/key.jpg" alt=""></p>
            
            <p>Obviously, this is not safe. Passwords are always meant to be kept secretly. Lots of users reuse their passwords, one leaked password can endanger a large number of accounts.</p>
            

        </li>
        <li>
            <p>Encrypt the password then send to friends</p>
            
            <p>Encryption is a good idea. The problem is how to choose/derive the encryption key. We cannot ask user to set another password to encrypt the password, right?</p>
            
            <img src="https://www.bluespace.tech/blog/0password/russian-doll.jpg" alt="">
            
            <p>Stay safe</p>
            
            <p>If the encryption does not depend on user's secret, the encryption key must be hardcoded. We will not make <a href="https://team-sik.org/sik-2016-022/">the same mistake like other password managers did years ago</a>.</p>
            
        </li>
        <li>
        <p>Encrypt the password with a key inside the security chip on smartphone, and send only the <code>ciphertext</code> to friends</p>
        <pre>            <code>
                <p>graph TD

                key[[key]] --&gt; AES(AES)
                password --&gt; AES
                AES --&gt;|encrypt| ciphertext[(password file)]

                key --&gt; phone[Secure Element]
                ciphertext --&gt; friend[saved by friend]

                style password fill:#fff, stroke: #aaa
                style ciphertext fill: #ddd, stroke: #aaa
                style phone fill: #b3d26a
                style friend fill: #acf
                </p></code>
            </pre>
            <p>In this proposal, a password file(<code>ciphertext</code>) is kept by each friend, but the <code>keys</code> are secured by the security chip on the phone.
            The password can be decrypted if a friend sends back the password file, when finding back the password.</p>
            <pre>                <code><p>graph TD

                subgraph 1. find back password

                masterPasswordKey[[key]] --&gt; masterPasswordAes(AES)
                masterPasswordCiphertext[(password file)] --&gt; masterPasswordAes
                masterPasswordAes --&gt;|decrypt| password

                end

                subgraph 2. key derivation

                password --&gt; PBKDF2(PBKDF2)
                salt --&gt; PBKDF2
                PBKDF2 --&gt;|derive| key[[key]]

                end

                subgraph 3. decryption

                key --&gt; AES(AES)
                ciphertext[(ciphertext)] --&gt; AES
                AES --&gt; |decrypt| plaintext

                end

                style masterPasswordCiphertext fill: #ddd, stroke: #aaa
                style password fill:#fff, stroke: #aaa
                style ciphertext fill: #ddd, stroke: #aaa
                style salt fill:#fff
                style plaintext fill:#fff, stroke: #aaa
                </p></code>
            </pre>
        <p>Friends are required to save the password file into ID Guard Offline, which is secured by the security chip on the phone. So hackers cannot steal the password file. This finding back master password mechanism does not weaken the security of the data stored in ID Guard Offline.</p>
        <ul>
        <li>If a hacker steals a user's phone and unlocks it(by screen PIN), he/she still needs to enter the master password.
        <ul>
        <li>If the hacker does not know the master password, he/she has to steal and unlock the phone of a friend, and crack ID Guard Offline app on that friend's phone, which is really hard.</li>
        </ul>
        </li>
        <li>If a hacker cracks and gets the password file from a friend, he/she cannot decrypt the ciphertext without the encryption key inside the security chip on the user's phone.</li>
        </ul>
        </li>
        </ol>
        <h3 id="how-to-setup-and-find-back-the-password">How to setup and find back the password?</h3>
        <p>So how to use it?</p>
        <ol>
        <li>
            <p>If you are using master password to unlock the app, go to the <code>Find back master password</code> setup view, enter your friend's name, and touch <code>Send</code> button.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/send-password-file.png" alt=""></p>
            
        </li>
        <li>
            <p>Send the password file to your friend and ask him/her to save it in ID Guard Offline.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/save-password-file.png" alt=""></p>
            
        </li>
        <li>
            <p>If you forget your master password, you can check out the list of friends who can help you.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/friend-list.png" alt=""></p>
            
        </li>
        <li>
            <p>Ask a friend to send back the password file, open it with ID Guard Offline to unlock it. You need to change unlock method immediately.</p>
            
            <p><img src="https://www.bluespace.tech/blog/0password/unlock-successfully.png" alt=""></p>
            
        </li>
        </ol>
        <h3 id="comparison">Comparison</h3>
        <h4 id="recover-account-with-trusted-contacts">Recover account with trusted contacts</h4>
        <p>Trusted contacts must be very trustworthy when using the account recovery feature offered by social services. Otherwise, those "bad friends" can hack into my account by initializing the account recovery process and completing the tasks required by the service.</p>
        <p>We borrow the idea from social services, but in our design, friends can be somewhat dependable because they cannot decrypt my passwords without the key. Also, I can get my password back as long as one of my friends can give me the password file.</p>
        <h4 id="password-managers-can-reset-master-password">Password managers can reset master password</h4>
        <p>Both those …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.bluespace.tech/blog/0password/">https://www.bluespace.tech/blog/0password/</a></em></p>]]>
            </description>
            <link>https://www.bluespace.tech/blog/0password/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745988</guid>
            <pubDate>Mon, 06 Jul 2020 09:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critical flaw in OpenSSH Client allows targeted man-in-the-middle (MitM) attacks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745977">thread link</a>) | @darshansavla
<br/>
July 6, 2020 | https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8464"><div><div><div><h2>Researchers find critical flaw in OpenSSH Client versions 5.7 to 8.3 that allows targeted MitM attacks using information leakage in SSH Clients</h2><p>Security researchers from German security firm FZI have found a critical flaw in the OpenSSH Client version 5.7 to 8.3. The critical vulnerability in OpenSSH clients lies due to an information leak in the initial key exchange message of the SSH protocol.</p><p>OpenSSH Client is an SSH client is a program that allows users to establish a secure and authenticated SSH connections to SSH servers. The OpenSSH source code is available free to everyone via the Internet. The devs had released the OpenSSH Client version 8.3 on 27th May 2020. However, the security researchers from FZI say that even the newly released version is susceptible to MITM attack due to the flaw.</p><p>The OpenSSH Client flaw has <strong>Observable Discrepancy</strong> leading to an information leak in the algorithm negotiation. This allows man-in-the-middle attackers to target initial connection attempts (where no host key for the server has been cached by the client). The OpenSSH Client vulnerability has been issued the identifier – <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-14145">CVE­-2020-­14145</a> and has a severity score of 4.7/10.</p><p>FZI says that any potential hacker can detect if an SSH client using the default configuration stores a host key for the target server. Once this is detected, the hacker can conduct a man-in-the-middle (MITM) attack on the clients that connect to a server for the first time and avoid clients that would show a warning because of a changed host key. Clients that connect to a server for the first time, ask the user to confirm the fingerprint of the host key. Users that compare the shown fingerprint by a known value are safe. However, many users rely on trust on first use and accept host keys without verification. These types of users are vulnerable to the MITM attack.</p><p>FZI states that they tested out their Proof of Concept in OpenSSH 8.2 and 8.3 portable and the tests showed that the host key algorithm list differs from the default list for all algorithm types that are not certificate-based, namely ECDSA, Ed25519, and RSA. This means that in the default configuration an attacker can identify users connecting to a server for the first time without false positives.</p><h2>Proof of Concept</h2><blockquote><p>$ ./ssh-detect.py -r OpenSSH-8.2-init.pcap<br> Client Key Exchange Init 192.168.102.1:33580 -&gt; 192.168.102.134:22</p><p>Host Key Algorithms:<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="bcd9dfd8cfdd91cfd4dd8e91d2d5cfc8cc8e898a91dfd9cec891ca8c8dfcd3ccd9d2cfcfd492dfd3d1">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="d6b3b5b2a5b7fba5beb7e4fbb8bfa5a2a6e5eee2fbb5b3a4a2fba0e6e796b9a6b3b8a5a5bef8b5b9bb">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="cca9afa8bfade1bfa4adfee1a2a5bfb8bcf9fefde1afa9beb8e1bafcfd8ca3bca9a2bfbfa4e2afa3a1">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="95e6feb8f0f6f1e6f4b8e6fdf4a7b8fbfce6e1e5a7a0a3b8f6f0e7e1b8e3a5a4d5fae5f0fbe6e6fdbbf6faf8">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="cbb8b8a3e6aeaff9fefefaf2e6a8aeb9bfe6bdfbfa8ba4bbaea5b8b8a3e5a8a4a6">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="097a62247a7a61246c6d3b3c3c3830246a6c7b7d247f39384966796c677a7a61276a6664">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="d1a3a2b0fca2b9b0e3fce4e0e3fcb2b4a3a5fca7e1e091bea1b4bfa2a2b9ffb2bebc">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="eb99988ac698838ad9c6d9deddc6888e999fc69ddbdaab849b8e85989883c5888486">[email&nbsp;protected]</a><br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="ef9c9c87c29d9c8ec28c8a9d9bc299dfdeaf809f8a819c9c87c18c8082">[email&nbsp;protected]</a><br> ecdsa-sha2-nistp256<br> ecdsa-sha2-nistp384<br> ecdsa-sha2-nistp521<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="25564e08404641564408564d4417084b4c565155171013654a55404b56564d0b464a48">[email&nbsp;protected]</a><br> ssh-ed25519<br> <a href="https://androidrookies.com/cdn-cgi/l/email-protection" data-cfemail="1b687036686873367e7f292e2e2a225b746b7e7568687335787476">[email&nbsp;protected]</a><br> rsa-sha2-512<br> rsa-sha2-256<br> ssh-rsa</p><p>Client Version: SSH-2.0-OpenSSH_8.2 (known)<br> Default algorithm list detected! Client doesn’t store host key.</p></blockquote><p>FZI states that they notified the OpenSSH Client devs about the vulnerability but they have taken no action. However, the GitHub page of OpenSSH Client shows that devs are working on version 8.4. But it is not known whether the new version will patch the <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-14145">CVE­-2020-­14145</a> vulnerability.</p><h2>Mitigation of the OpenSSH Client vulnerability</h2><p>FZI says there are some configuration options in OpenSSH Client that can be used to mitigate the vulnerability. OpenSSH Client provides users alternative ways to validate host keys, namely SSHFP records and host certificates. These should be used if DNSSEC or a PKI are available.&nbsp; They can also enable UpdateHostKeys and set the option HostKeyAlgorithms after connecting to each server at least once.</p><p>You can download the FZI’s OpenSSH Client vulnerability report <a href="https://www.fzi.de/fileadmin/user_upload/2020-06-26-FSA-2020-2.pdf">here</a>(PDF).</p></div></div></div></article><div><h3>About Author</h3><section> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20100%20100'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=100&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><div> <p>Hacker, coder, Jouno by night
When a good man is hurt, all who would be called good must suffer with him</p></div></section></div></div>]]>
            </description>
            <link>https://androidrookies.com/critical-flaw-in-openssh-client-versions-5-7-to-8-3-allows-targeted-man-in-the-middle-mitm-attacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745977</guid>
            <pubDate>Mon, 06 Jul 2020 09:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fatal Flaw of Ownership Semantics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745863">thread link</a>) | @signa11
<br/>
July 6, 2020 | https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/ | <a href="https://web.archive.org/web/*/https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
<header>
	
	
	<p>
		<span>2020-06-21</span>
		</p>
</header>
<p>I have been toying with a theoretical idea for the past 18 months off-and-on in my head and I have not fully articulated it aloud yet. It is regarding the concept of <em>Ownership Semantics</em> (OS) or <em>Move Semantics</em> in programming languages. Fundamentally this article is a criticism of the concept and states that the concept is a duality of traditional OOP but applied to a different area.</p>
<h2 id="general-definitions-of-terminology">General Definitions of Terminology</h2>
<p>A general list of definitions of terminology used within this article in order to minimize confusion.</p>
<ul>
<li>
<p>A <em>Value</em> is a datum with an associated type</p>
</li>
<li>
<p>A <em>(Data) Type</em> is an attribute of a value which encodes information about how the data value can be operated upon</p>
</li>
<li>
<p>An <em>Object</em> is a value with associated behaviour, and thus implies it has <em>agency</em></p>
</li>
<li>
<p>A <em>Class</em> is the data type of an <em>Object</em></p>
</li>
<li>
<p>A hierarchy of value ownership is a hierarchy of responsibility of values</p>
</li>
<li>
<p>An <em>Owned-Value</em> is a value which belongs to a hierarchy of value ownership, which implies it is governed by an <em>agent</em></p>
</li>
<li>
<p>An <em>Agent</em> is an actor with the capacity to act within a given environment</p>
</li>
<li>
<p>A <em>Model of Interpretation</em> is a way to view and analyse a subject</p>
</li>
<li>
<p>A <em>Paradigm</em> is a way of classifying models of structure of programming languages; a <em>Paradigm</em> is a <em>model of interpretation</em></p>
</li>
<li>
<p><em>Object Orient(at)ed Programming (OOP)</em> - A paradigm of structuring a program around the sole concept of <em>Objects</em>, commonly through coupling data and code into a single unit.</p>
</li>
<li>
<p><em>Ownership/Move Semantics (OS)</em> - Orientation around responsibility of values in a hierarchical fashion</p>
</li>
</ul>
<h2 id="foundations-of-the-object-orientation-paradigm">Foundations of the Object Orientation Paradigm</h2>
<p>Though the original conception of the term coined by Alan Kay<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> was never used as he intended it to be, the term <em>Object Orient(at)ed Programming (OOP)</em> has been commonly understood to be a paradigm of structuring a program around the concept of <em>Objects</em>, commonly through coupling data and code into a single unit. Many languages support multiple paradigms, including aspects for the OOP paradigm, but I would class those as multiparadigm rather than being <em>solely</em> an OOP language.</p>
<p>Most languages implement <em>Objects</em> and <em>Classes</em> in the Simula tradition; most of the notable OOP languages have a similar form by defining methods (member functions) within the class definition. Traditionally languages such as Java can be classed as <em>solely</em> an OOP language.</p>
<p>Most traditional OOP languages are based around the concept of <em>inheritance</em>, a mechanism of deriving a class data type from another class data type and retaining similar information. Most people generally view inheritance as a combination of <a href="https://en.wikipedia.org/wiki/Subtyping">subtyping</a> and <a href="https://en.wikipedia.org/wiki/Dynamic_dispatch">dynamic dispatch</a> through <a href="https://en.wikipedia.org/wiki/Virtual_method_table">virtual method tables (vtables)</a>. This has lead to many discussions asking whether a language can be called as OOP if it does not support inheritance<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p>In recent times, <em>inheritance</em> has been falling out of fashion in favour of <em>composition</em><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. This is mostly due to the issue of conforming a <em>class</em> to a strict (singular) hierarchy of agency when in reality, things can belong to many (if not infinite) categories and hierarchies, as well as another aspect which I will be discussing throughout this article.</p>
<p>There are many criticisms of OOP<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup><sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup><sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup><sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup> but my general criticism is that by placing emphasis on trying to solve problem in the type system, it shifts focus from the data structures and algorithms, <a href="https://www.gingerbill.org/article/2020/05/31/progamming-pragmatist-proverbs/#the-concept-of-programming">the core of what a program fundamentally is</a>.</p>
<p>Since objects themselves are being treated <em>as if</em> they have behaviour (not just type properties), they are effectively being treated as if they were <em>agents</em> in the program. This mental model has many conclusions, many of which cause issues.</p>
<p>In my article <a href="https://www.gingerbill.org/article/2020/05/31/progamming-pragmatist-proverbs/"><em>Pragmatism in Programming Proverbs</em></a>, I state:</p>
<blockquote>
<p>Object orientated programming is a form of misinterpreted and misapplied Aristotelian Metaphysics applied to a domain it was never meant to model</p>
</blockquote>
<p>What I mean by this statement is that <em>artificially</em> conforming any/all relationships between data and types to an artificial hierarchy of <em>agency</em> is a form of naïve-Aristotelian metaphysics. Since there is no actual <em>agency</em> in the programming objects, it is a partial fallacy. When trying to conform a program to have a particular structure when it does not naturally, the absence of a structure in a program is more useful than a bad structure.</p>
<h3 id="methods">Methods</h3>
<p>The concept of adding methods to classes/objects has proven useful to many. The real questions are:</p>
<ul>
<li>Why?</li>
<li>And how do people actually conceptualize methods on a day-to-day basis?</li>
</ul>
<p>For most people, I am going to bet that methods, in languages with an emphasis on inheritance rather than composition (such as C++ or Java), are treated as a way of categorizing and associating functions/procedures with a data record. There are a few reasons for this approach:</p>
<ul>
<li>Easy to organize and search for procedures by a data type</li>
<li>Allowing methods as a form of syntactic sugar for writing calls in a <em>subject verb object</em> manner e.g. <code>foo_do_thing(x, y)</code> vs <code>x.do_thing(y)</code></li>
<li>Mental model of behaviour for objects</li>
</ul>
<p>From experience, I have found that long time users of “OOP” languages eventually start treating methods primarily in the first two approaches.</p>
<p>I will not go into depth about the other main aspects of OOP such as encapsulation, local retention, forms of polymorphism, etc, as the hierarchical nature is the fundamental aspect of focus for this article. The (linear) hierarchy of agency is the main problem. The reason why people argue for <em>composition over inheritance</em> is that it flattens this linear hierarchy, reducing its effect. It is the transition from <a href="https://en.wikipedia.org/wiki/Nominal_type_system">nominal typing</a> to <a href="https://en.wikipedia.org/wiki/Structural_type_system">structural typing</a>, which is more flexible because many data structures and problems have a <em>non-linear</em> nature to them, which <em>linear</em> approaches <strong>cannot</strong> handle. When trying to adhere to the the strict hierarchical type system approaches, it leads to numerous issues because data is more commonly graph-like (non-linear) than tree-like (linear) for most problems. This strict hierarchy does occur with encapsulation at the object level too, a strict hierarchy of messages/references; this hierarchical nature arises from the concept agency itself, inheritance is not the root cause.</p>
<p><strong>n.b.</strong> Inheritance is not all bad and does have many real life practical uses, but these costs must be known before using them, like with any tool.</p>
<p><strong>n.b.</strong> The linearity is with regards to the data structures themselves and not the algorithms.</p>
<h2 id="foundations-of-the-ownership-semantics-paradigm">Foundations of the Ownership Semantics Paradigm</h2>
<p><a href="https://en.wikipedia.org/wiki/C%2B%2B">C++11</a> introduced the concept of <em>move semantics</em> or <em>ownership semantics</em> (OS), a way to minimize the copying of data through copy constructors. It utilizes the added concept of r-value references (<code>T &amp;&amp;</code>) as a means to do this. However, the concept began to be used for a lot more than its basic purpose. The concept adds the high level abstraction of “moving” objects rather than “copying” objects. Physically, a computer only ever copies and this high level abstraction, to treat objects <em>as if</em> they were “real objects”, is not what actually happens. It is also a <a href="https://en.wikipedia.org/wiki/Category_mistake">category error</a> to treat them as “real objects” since “real objects” and “programming objects” have little connection with each other ontologically. When a value or object is “moved”, this means is that the <em>responsibilities</em> of the resources of that object have been transferred to another object or environment—<em>agents</em>. In this case, ownership/move semantics is fundamentally based around the <em>responsibilities of values</em> by tracking value usage.</p>
<p>In this model of agency, the arena of agency can take on many forms, such as blocks, procedure bodies, or aggregate values. Therefore some <em>owned-values</em> also <em>own</em> other values, and thus a value could have agency.</p>
<p>If we were to call Ownership Semantics a paradigm, it would be the orientation around the <em>responsibility of values</em> in a hierarchical fashion, placing emphasis on this system of responsibility, shifting focus from data structures and algorithms.</p>
<p>The concept of <em>responsibility</em> and <em>ownership</em> is similar to the real world counter parts in that to own something means to have exclusive use and full responsibility over it.</p>
<p><a href="https://www.rust-lang.org/">Rust</a> is a multi-paradigm programming language but at its core is an Ownership-Orientated language. Everything in Rust has a concept of <em>“ownership”</em> and <em>lifetime</em> associated with it. Rust is designed around trying to be first and foremost “safe”, especially with regards to concurrency. Rust derives from the C++ family in terms of philosophy and style, but uses a more <a href="https://www.gingerbill.org/article/2018/03/12/on-the-aesthetics-of-the-syntax-of-declarations/">qualifier-focused</a> declaration syntax and many concepts from functional languages from the <a href="https://en.wikipedia.org/wiki/ML_%28programming_language%29">ML family</a>.</p>
<p><em>Lifetimes</em> are theoretically orthogonal to <em>ownership</em> but in practical, they usually are intrinsically coupled. I will not discuss the problems with object-based lifetimes in this article.</p>
<p>The following Rust code can be used to demonstrate this responsibility transfer between different capturing things such as <code>let</code> statements:</p>
<pre><code>pub struct Foo {
	value: i32,
}

fn main() {
	let foo = Foo{value: 123};
	let bar = foo; // the responsibility of `foo` is transferred to `bar`

	println!("{}", foo.value); // error: use of moved value: `foo.value`
	println!("{}", bar.value);
}

</code></pre>
<p>Rust is an immutable-by-default language, with the option to opt into mutability with <code>mut</code>. Immutability helps a lot with mathematical proofs for logic since things things can be “flattened” quite easily, however virtually all computers are fundamentally mutable things, even if the abstraction of immutability is a useful tool. As a result, the ownership semantics system requires a few more rules to take into account mutability, by adding the concept of “borrowing” through references. The general rules for the borrow checker are:</p>
<ul>
<li>Each value may have as many immutable borrows as you want</li>
<li>Each value may only have one mutable borrow at a time</li>
<li>Each value may not borrow immutably and mutably at the same time</li>
<li>Values will be “dropped” when the owning connecting goes out of scope</li>
<li>Taking a value by <code>self</code> <code>Drop</code>s the original value</li>
</ul>
<p>When using Rust (or move semantics to their full extent in C++11), most people will fight the borrow …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/">https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/</a></em></p>]]>
            </description>
            <link>https://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745863</guid>
            <pubDate>Mon, 06 Jul 2020 08:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News Design Is Ugly]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23745595">thread link</a>) | @neilpanchal
<br/>
July 6, 2020 | https://neil.computer/notes/hacker-news-design-is-ugly/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/hacker-news-design-is-ugly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        <h2>Hacker News Design is Ugly</h2>
        <p>This thing is straight up ugly. It is too simple, useful, pragmatic, dense and practical. Boring. These days the cool things are purple gradients, lots of negative space and loss of contrast. People on HN keep <a href="https://news.ycombinator.com/item?id=23199603">raving</a> about this design thing but boy they are so wrong.</p><p>Let's fix it.</p><h2 id="current-state">Current State</h2><p>This is what HN front-page looks like when you login. It has absolutely zero pop. Typical engineers, what do they know about design?</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>Let's make it pop, shall we?</p><h2 id="fixing-hn-design">Fixing HN Design</h2><p>First things first. <em>Padding</em>. When I am bored, running out of ideas, I like to do one thing that usually makes things 10x better. Padding is like a chef's knife in the kitchen. Know how to use it well and you'll be cutting through information rich UI like butter. It is what sets professional designers from these gray-beard types.</p><p>It is difficult to do it right, so please allow me to exemplify the process. First, add padding to the <code>body</code> tag.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>See the difference? Holy crap. The UI just suddenly started <em>breathing</em>.</p><p>Let's add more spacing between this conjested highly dense information rich piece of shit.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>The color orange is fine with me but it is not gonna get you through the design school and into the real world. The world today demands magenta. Magenta/Purple/Cyan all inspired by Stripe UI since 2015 or so and it really set the standard for a modern color palette. Throw your creativity and objectivity away, the trend dictates what we should choose<em>.</em> May be it PANTONE will come up with a <a href="https://www.pantone.com/color-intelligence/color-of-the-year/color-of-the-year-2020">color of the year</a> and it will change. But as per current design trends, purple is the safe choice.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>BAM. What you didn't notice is I also got rid of all background colors to flatten things a bit. I hate borders which are a graphical device invented to create logical spatial layouts but those things are for boring websites for techy folks.</p><p>Next up. Pro tip: Border-radius. It is not as complicated as it sounds. Simply put, we like to make things rounded as allows us to compete for a one of those web design <a href="https://www.awwwards.com/">awwwards</a> and border-radius is a mandatory requirement before creating a <a href="https://dribbble.com/">dribbble</a> account. So we must comply without the thought of originality.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>See? It really ties the web page together.</p><p>Those pesky informative sub-titles are jarring as it helps the user too much. Let's make it so that it loses contrast and fades away in the background. As a side effect, it makes the whole thing more minimal. Minimalism at all costs. Try to make things minimal by removing features and neutring functionality - no one will ever notice. </p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>It looks minimal af.</p><p>That's all folks. Hacker News redesigned. These are the basics but if there is enough interest, I can probably make another tutorial on how to do <em>this</em>:</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png" alt="" width="2510" height="2166" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Until then, go here and browse some more trends to follow at the cost of authenticity, objectivity, originality, reasoning and fundamental understanding of how to design user interfaces: <a href="https://www.google.com/search?q=design+trends+2020">https://www.google.com/search?q=design+trends+2020</a></p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/hacker-news-design-is-ugly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745595</guid>
            <pubDate>Mon, 06 Jul 2020 07:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handling deeplinks in iOS 14 and SwiftUI 2.0 with onOpenURL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745576">thread link</a>) | @dwltz
<br/>
July 6, 2020 | https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/ | <a href="https://web.archive.org/web/*/https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This article covers beta technology and it's up to date for Xcode 12 beta 1</p></blockquote><p>Starting with iOS 14, we can write apps that are fully built using SwiftUI, dropping the need to have <code>AppDelegate</code> and <code>SceneDelegate</code> files entirely. For as long as I remember, I've <a href="https://www.donnywals.com/handling-deeplinks-in-your-app/">handled deeplinks</a> in my <code>AppDelegate</code> and for the past year in the <code>SceneDelegate</code>. So when Apple introduced developers to this new <code>@main</code> annotated <code>App</code> struct style of building apps, I'm sure we all had the same question on our mind. How does the new <code>App</code> struct work with deeplinks and other tasks that are normally performed in the <code>AppDelegate</code>?</p><p>Luckily, Apple engineers made sure that handling deeplinks in our apps is still possible with the new <code>onOpenURL(perform:)</code> view modifier.</p><h2>Handling deeplinks with onOpenURL</h2><p>The new <code>onOpenURL(perform:)</code> view modifier is new in iOS 14. It allows developers to register a URL handler on their views so they can respond to URLs by modifying state for their views as needed.</p><p>This is vastly different from how we're used to dealing with URLs in UIKit and the <code>SceneDelegate</code> flow.</p><p>The old way of handling deeplinks requires you to handle each link in the <code>SceneDelegate</code> (or <code>AppDelegate</code>). You would have to manipulate the selected tab in a <code>UITabBarViewController</code>, or present a <code>UIViewController</code> by inspecting the current view controller hierarchy and pushing the needed <code>UIViewController</code> from right inside of the <code>SceneDelegate</code>.</p><p>In SwiftUI, you can use the <code>onOpenURL(perform:)</code> on the root of your scene as follows:</p><pre><code>@main
struct MyApplication: App {
  var body: some Scene {
    WindowGroup {
      ContentView()
        .onOpenURL { url in
          // handle the URL that must be opened
        }
    }
  }
}</code></pre><p>I will cover what it means exactly to handle the url in the next section of this article, but usually it will involve mutating some state to load and display the view associated with the URL that must be opened.</p><p>What's really neat is that you can specify multiple <code>onOpenURL</code> handlers throughout your app. This means that you can make multiple, smaller changes to your app state which means that you no longer have one place where all of your deeplink handling and view manipulation takes place.</p><p>Furthermore, <code>onOpenURL</code> is called when your app is in the foreground, background or not running at all. This means that there is now a single entry point for your app to handle URLs. Even if your app is relaunched after being force-closed.</p><p>In the next section, I will show you an example of how you can select a tab in a <code>TabView</code> depending on the URL that your app is requested to open. After that, I will show you how to navigate to a list item in a view that's embedded in a <code>TabView</code> by adding a second <code>onOpenURL</code> view modifier on a child <code>View</code> that contains a <code>List</code>.</p><h2>Activating a tab in a TabView when opening a URL</h2><p>In SwiftUI, views are a function of their state. This means that virtually everything in a SwiftUI application can be represented and manipulated as a data model. This means that we can represent the currently selected tab in a SwiftUI <code>TabView</code> as a property on an <code>App</code> struct.</p><p>The following code shows how:</p><pre><code>struct MyApplication: App {
  @State var activeTab = 0

  var body: some Scene {
    WindowGroup {
      TabView(selection: $activeTab) {
        HomeView()
          .tabItem {
            VStack {
              Image(systemName: "house")
              Text("Home")
            }
          }
          .tag(0)

        SettingsView()
          .tabItem {
            VStack {
              Image(systemName: "gearshape")
              Text("Settings")
            }
          }
          .tag(1)
      }
      .onOpenURL { url in
        // determine which tab should be selected and update activeTab
      }
    }
  }
}</code></pre><p>What's important to notice here is the <code>activeTab</code> property. This property is marked as <code>@State</code> and represents the selected tab in the <code>TabView</code>. When creating the <code>TabView</code>, I pass a binding to <code>activeTab</code> to the <code>TabView</code>'s initializer. Setting the <code>TabView</code> up like this means that updating <code>activeTab</code> will cause the <code>TabView</code> to update its selected tab as well.</p><p>Notice that I set a <code>tag</code> on the views that are added to the <code>TabView</code>. This <code>tag</code> is used to identify the <code>TabView</code>'s items. When <code>activeTab</code> matches one of the <code>tag</code>s associated with your views, the <code>TabView</code> will activate the matching tab.</p><p>In this case that means setting <code>activeTab</code> to <code>1</code> would activate the tab that displays <code>SettingsView</code>.</p><p>Let's see how you can implement <code>onOpenURL</code> to figure out and activate the correct tab. To do this, I'm going to introduce an extension on <code>URL</code>, and a new type called <code>TabIdentifier</code>:</p><pre><code>enum TabIdentifier: Hashable {
  case home, settings
}

extension URL {
  var isDeeplink: Bool {
    return scheme == "my-url-scheme" // matches my-url-scheme://&lt;rest-of-the-url&gt;
  }

  var tabIdentifier: TabIdentifier? {
    guard isDeeplink else { return nil }

    switch host {
    case "home": return .home // matches my-url-scheme://home/
    case "settings": return .settings // matches my-url-scheme://settings/
    default: return nil
    }
  }
}</code></pre><p>The code above is just a convient way to figure out which tab belongs to a <code>URL</code> without having to duplicate logic all over the app. If you decide to implement a similar object, the <code>isDeeplink</code> computed property should be updated according to the URLs you want to support. If you're implementing Universal Links, you'll want to check whether the <code>URL</code>'s <code>host</code> property matches your hostname. I've set up a very minimal check here for demonstration purposes where I only care about the URL scheme.</p><p>The <code>tabIdentifier</code> property is a computed property that uses the <code>host</code> property to determine which tab should be selected. For a Universal Link you'll probably want to use the <code>pathComponents</code> property and compare using the second entry in that array, depending on your mapping strategy. Again, I set this up to be very basic.</p><p>You can use this basic setup in the <code>App</code> struct as follows:</p><pre><code>struct MyApplication: App {
  @State var activeTab = TabIdentifier.home

  var body: some Scene {
    WindowGroup {
      TabView(selection: $activeTab) {
        HomeView()
          .tabItem {
            VStack {
              Image(systemName: "house")
              Text("Home")
            }
          }
          .tag(TabIdentifier.home) // use enum case as tag

        SettingsView()
          .tabItem {
            VStack {
              Image(systemName: "gearshape")
              Text("Settings")
            }
          }
          .tag(TabIdentifier.settings) // use enum case as tag
      }
      .onOpenURL { url in
        guard let tabIdentifier = url.tabIdentifier else {
          return
        }

        activeTab = tabIdentifier
      }
    }
  }
}</code></pre><p>Because I made <code>TabIdentifier</code> <code>Hashable</code>, it can be used as the <code>activeTab</code> identifier. Each tab in the <code>TabView</code> is associated with a <code>TabIdentifier</code> through their tags, and by reading the new <code>tabIdentifier</code> that I added to <code>URL</code> in my extension, I can easily extract the appropriate tab identifier associated with the URL that I need to open.</p><p>As soon as I assign the acquired <code>tabIdentifier</code> to <code>activeTab</code>, the <code>TabView</code> is updated marking the appropriate tab as selected along with displaying the appropriate <code>View</code>.</p><p>Of course this is only half of what you'll want to typically do when opening a deeplink. Let's take a look at activating a <code>NavigationLink</code> in a different view next.</p><h2>Handling a URL by activating the correct NavigationLink in a List</h2><p>You already know how to activate a tab in a <code>TabView</code> when your app needs to handle a URL. Often you'll also need to navigate to a specific detail page in the view that's shown for the selected tab item. The cleanest way I have found to do this, is by adding a second <code>onOpenURL</code> handler that's defined within the detail view that should activate your navigation link.</p><p>When you define multiple <code>onOpenURL</code> handlers, the system will call them all, allowing you to make small, local changes to your view's data model. Like selecting a tab in the <code>App</code> struct, and activating a <code>NavigationLink</code> in a child view. Before I show you how to do this, We'll need another extension on <code>URL</code> to extract the information we need to activate the appropriate <code>NavigationLink</code> in a <code>List</code>:</p><pre><code>enum PageIdentifier: Hashable {
  case todoItem(id: UUID)
}

extension URL {
  var detailPage: PageIdentifier? {
    guard let tabIdentifier = tabIdentifier,
          pathComponents.count &gt; 1,
          let uuid = UUID(uuidString: pathComponents[1]) else {
      return nil
    }

    switch tabIdentifier {
    case .home: return .todoItem(id: uuid) // matches my-url-scheme://home/&lt;item-uuid-here&gt;/
    default: return nil
    }
  }
}</code></pre><p>I've added a new enum called <code>PageIdentifier</code>. This enum has a single case with an associated value. This associated value represents the identifier of the object that I want to deeplink to. My app is a to-do app, and each to-do item uses a <code>UUID</code> as its unique identifier. This is also the identifier that's used in the deeplink. The approach above is similar to what I've shown in the previous section and if you decide you like my URL parsing approach, you'll have to make some modifications to adapt it in your app.</p><p>The next step is to implement the <code>HomeView</code>, and select the appropriate item from its list of items:</p><pre><code>struct HomeView: View {
  @StateObject var todoItems = TodoItem.defaultList // this is just a placeholder.  
  @State var activeUUID: UUID?

  var body: some View {
    NavigationView {
      List(todoItems) { todoItem in
        NavigationLink(destination: TodoDetailView(item: todoItem), tag: todoItem.id, selection: $activeUUID) {
          TaskListItem(task: todoItem)
        }
      }
      .navigationTitle(Text("Home"))
      .onOpenURL { url in
        if case .todoItem(let id) = url.detailPage {
          activeUUID = id
        }
      }
    }
  }
}</code></pre><p>Notice that my <code>HomeView</code> has a property called <code>activeUUID</code>. This property serves the exact same purpose that <code>activeTab</code> fulfilled in the previous section. It represents the identifier for the item that should be selected.</p><p>When creating my <code>Navigat…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/">https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/</a></em></p>]]>
            </description>
            <link>https://www.donnywals.com/handling-deeplinks-in-ios-14-with-onopenurl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745576</guid>
            <pubDate>Mon, 06 Jul 2020 07:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Writing Incentive Token]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745400">thread link</a>) | @vecio
<br/>
July 6, 2020 | https://vec.io/posts/a-writing-incentive-token | <a href="https://web.archive.org/web/*/https://vec.io/posts/a-writing-incentive-token">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>After I made an announcement to write an article everyday, I have thought about an idea to issue a token for my readers, they bought one token for some price, and if I failed to produce enough good articles within the year, they could get their money back by returning the token. Further more, they could even get back double the price they paid, to punish my failing.</p>

<h2 id="subscription-insurance">Subscription Insurance</h2>

<p>At first it was just yet another idea flashing around, but when I broke the consecutive writings the day before yesterday, the idea appeared again and I realized it more interesting than what I thought.</p>

<p>The first impression of it is more like a bet on something, readers bet one buck on my future works and if I failed they would get  two bucks back. But the difference from a pure bet is they could get something, e.g. reading my thoughts. I’m not saying I’m a genius or fame that my thoughts are important and whenever you read you earn something, treat me like a normal author and the readers someone who like my stories, they pay upfront to buy out my future publications.</p>

<p>Imagine that you love a novel very very much, a series, e.g. <em>A Song of Ice and Fire</em>, and you are eager to read new chapters, but the author keeps delaying, even years after years. However if you pay upfront, it’s like many people make a subscription contract with the author, and they would be incentivized or pushed harder to finish it, otherwise the author must refund the subscription payments, and even a double punishment.</p>

<p>When treating the idea as a subscription advance payment system, it sounds familiar and much more reasonable and feasible, better than a pure bet. It acts as the insurance both for the reader and writer, reader would be guaranteed with good content or money back, and writer with income assurance for their future works. To make things easier for both parties, they could set up a soft cap, e.g. if and only if more than 1,000 readers paid or $100,000 money received, the contract would become effective, otherwise disqualified and hurt nothing. This much money guarantees the writer to work full time on the story, win-win.</p>

<h2 id="blockchain-and-token">Blockchain and Token</h2>

<p>Cryptos are only useful when they are used in a useful situation, i.e. the situation would go very well without any cryptos inside, and cryptos or blockchains are just something to make things better and easier, not to make up some things. The idea described here is of course a useful and meaningful one. But I don’t believe it needs a new blockchain to make things better, a simple transparent token would fulfill all good additions.</p>

<p>Readers may be afraid that they paid upfront and the writer take all the money without delivering anything, and the punishment won’t work neither. Obviously they should rely on some agent or platform to escrow the payments, then the problem becomes the trustworthy of the agent or platform, what if they stole our money, even if they won’t do bad things intentionally, they are still likely to embezzle the fund to do something else. Then they ask another accountant party to guard the agent’s bank account, all seems good now. Assume the accountant is good enough at the work, they would be expensive. Both the agent and accountant cost lots of money, and still they are not transparent for readers and writers, considering the high possibility of frauds in stocks even if such strict SEC rules and laws.</p>

<p>A writing incentive token would solve all the problems.</p>

<ol>
  <li>Issue the token with a smart contract on some decentralized blockchain.</li>
  <li>Readers pay BTC to buy tokens.</li>
  <li>If not enough tokens sold during a period, contract refunds automatically.</li>
  <li>If enough BTC received, contract goes effective.</li>
  <li>All BTC is locked by the contract for 1 year.</li>
</ol>

<p>Then all money and token are transparent on blockchain for anyone to audit at any time, and almost free, only a few bucks of blockchain transaction fees. They can add more rules, e.g. allowing the writer to withdraw some limited BTC from the contract to cover their daily expense, or allowing the readers to vote for an early refund if they realize the writer produces nothing or worse updates.</p>

<p>So good.</p>

<h2 id="steemits">Steemits</h2>

<p>Many people familiar with blockchain may have heard about the steemit blockchain, it describes itself as, <em>“Steemit has redefined social media by building a living, breathing,  and growing social economy - a community where users are rewarded for sharing their voice. It’s a new kind of attention economy.”</em></p>

<p>Most people’s first impression about steemit is spam, many many spam, wether the article, or the comments, or even the votes. This destiny is written in its mission, users are rewarded for sharing their voice, all determined by the system. The system has some decentralized rules written in the code, to judge whether an article or comment is good, to determine the score of a vote. The result is spammers could easily pass all the rules and produce good spam to trick the system, and consequences are good articles disappear because they can’t get enough <em>attention economy</em>.</p>

<p>Spams are so popular not just because the judgement of the system, mainly the $STEEM reward. The system issues some new money everyday, to reward the users for sharing spams. Though they are new issued money, but every $STEEM in the world will be diluted every single day, so the spams are actually rewarded by all $STEEM holders though they never read that article. How come you reward something you never read? Because the system believes that spam is good and you should reward the author, you can’t find anything like this to use your money to encourage and produce spam automatically, not surprisingly the $STEEM price keeps dropping. Maybe most people actually cares about the $STEEM price instead of spam.</p>

<p>Steemit is a failure and deserves it, because it tries to reinvent something useless. Most blockchain projects try to do something with the technology, just because they guess the technology is cool. At most time the correct way to do things is exploring the reality to find something people actually need, and make it better with some technology. Something then technology, not technology followed by something. iPhone and Tesla are commonly treated as the most breakthrough tech innovations in recent decades, and they still follow this order.</p>

<p>Steemit is a failure, so are all steemits.</p>

  </div></div>]]>
            </description>
            <link>https://vec.io/posts/a-writing-incentive-token</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745400</guid>
            <pubDate>Mon, 06 Jul 2020 07:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++?? A Critique of C++ (1992)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745291">thread link</a>) | @alexeiz
<br/>
July 5, 2020 | https://www.modulaware.com/mdlt28.htm | <a href="https://web.archive.org/web/*/https://www.modulaware.com/mdlt28.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="Arial">
<hr>
<h3>The ModulaTor's Forum</h3>
<p>
Subject: Re: C++?? A C++ Critique
<br>From: Guenter Dotzel
<br>To: Ian Joyner &gt;INTERNET: ian@syacus.acus.oz.au
</p><p>
Ian, 
</p><p>
I'm concerned about the recent popularization of both C and C++. Either one of 
these languages seems to be pervasive when talking about a programming 
language. 
</p><p>
I enjoyed reading your article entitled "C++?? A C++ Critique" dated Nov-1992. 
Your article seems to clarify most aspects and rumors about C++. 
</p><p>
According to Prof. Gutknecht from ETH-Zuerich, who talked about the Tragedy 
of Programming Language Development at the 2nd European Modula-2 
Conference, Leicester/UK, Sep-1992, the main features that made C++ "the 
definite programming languages" are: 
</p><p>
C++ supports several programming paradigms and blends, gives access to all 
[abstraction] levels and encuroage breaks of abstraction, is not dangerous 
powerful, is a tricky and challenging game and has completely lost its identity. 
</p><p>
I think your article could help the not so programming language design sensitive 
average application programmers to get a feeling what C++ is all about. I 
assume that even Modula-2 and Oberon-2 programmers would be interested in 
reading your article to find some arguments against C++. I know that they often 
get asked Why don't you switch to modern, popular, high-level, OO-languages 
such as C++? 
</p><p>
As the editor of our monthly, non-commercial, pure-technical, Modula-2 and 
Oberon-2 related newsletter called The ModulaTor, I'd like to ask you for 
permission to publish your article in an upcoming issue of this newsletter. 
</p><p>
Greetings, Guenter 
</p><p>
From: ian@syacus.acus.oz.au
<br>Subject: Re: C++?? A C++ Critique
<br>To: 100023.2527@compuserve.com
<br>Date: Wed, 18 Nov 92 12:16:32 EST
</p><p>
Dear Guenter, 
</p><p>
I would be very pleased for you to publish the second edition of my article. 
Thanks for thinking of it. 
</p><p>
As for C++ being a modern language rather than Modula-2 of Oberon, the 
reverse is the case. I find it depressing to think that we are now stuck with a 
language full of compromises that were made for small machines of 25 years 
ago. The Algol style languages, and Pascal forward were designed to be much 
less technology dependent, and so are still relevant today. 
</p><p>
Anyway I think that those who have suffered C silently in the past are now 
finding a voice to be able to counter the criticism and arrogance of the C world to 
view all other languages as second rate, and old. I hope you find the critique 
useful and interesting. If so, please feel free to distribute it among your peers 
and friends. 
</p><p>
[Ed. note: additional notes received from Ian in Jun-1995 via Ruslan, a friend at 
IUE, Moscow:] 
</p><hr>
<p>
C++ is a language that is coming under ever more intense criticism. Bjarne 
Stroustrup finds this unfair, as he says the language delivers what they set out 
to do. However, C++ is a poor implementation of OO technology, and its 
shortcomings need to be criticised. One critique of C++ is my own C++?? 
Critique. 
</p><p>
Another appraisal of C++ as compared to Eiffel is in Richard Wiener's "Software 
Development using Eiffel: There can be life other than C++" (Prentice Hall), a 
very even handed treatment of the subject. 
</p><p>
Undoubtedly, one person who has set the watermark for OO technology is 
Bertrand Meyer, the creator of Eiffel. He has written several books describing 
object technology which should be read. He pulls no punches in his criticism of 
C++. The recommended <i>Bertrand Meyer</i> reading is 
<a href="http://www.amazon.com/exec/obidos/ASIN/0136291554/modulaware">
"Object-oriented Software Construction"</a>, 2nd edition, 1995,
and 
<a href="http://www.amazon.com/exec/obidos/ASIN/0131928333/modulaware">
"Object Success: A Managers guide to object orientation, 
its impact on the corporation and its use for 
reengineering the software process"</a>.
Both books Prentice Hall. 
</p><p>
I believe that Object-oriented technology has a lot to offer in helping with the 
problems faced by modern and complex software systems. However, to many 
object-oriented people, C++ is the biggest disappointment of all, bringing all the 
bad old ways and a lot of unnecessary complexity to object-orientation. You do 
not need a language so riddled with low level constructs. The correct way is to 
use a pure OO language, and only interface to C, or other low level languages 
through external mechanisms. That way will ensure maintainability, portability, 
and quality. 
</p><p>
I wish you success in your quest for building quality software cost effectively, 
and I think you will find part of the answer to the goal in Object-orientation, but 
not in C++. Critics of C++ are not religious fanatics and cranks as many C++ 
proponents would make out. We realise the shortcomings of C++, and advise 
looking into some of the better ways that are available. 
</p><hr>
Several sites have offered to make the C++?? Critique available by ftp. I would 
like to thank Indiana University, University of Western Australia, Brown 
University and IRISA/CNRS France for their help, and many other sites who 
have done this voluntarily without solicitation. The sites that I know about who 
have given me permission to advertise their service are: 
<pre>U.S West Indiana University:

      Machine:       moose.cs.indiana.edu
      IP #           129.79.254.191
      Directory:     pub
      Compressed:    cpp.crit/cpp.crit.ps.Z
      Hours:         After 6pm Eastern US Please

Australia/Asia University of Western Australia:

      Machine:       redback.cs.uwa.edu.au
      IP #           130.95.80.61
      Directory:     /Others/Quinn
      File:          c++.ps.Z
      Please read:   /ComSci/ReadMeAboutRedback

U.S East Brown University:

      Machine:       ftp.brown.edu
      Directory:     /pub/c++
      File:          C++-Critique-2ed.PS

France/Europe IRISA/CNRS:

      Machine:       irisa.irisa.fr
      IP #           131.254.254.2
      Directory:     pub/c++
      File:          cpp.crit.ps.Z
</pre>
<p>
Please observe Indiana's after hours embargo, as they have offered to do this 
completely voluntarily. 
</p><p>
Please report any problems to ian@syacus.acus.oz.au. Thank you. Also, if you 
need text or uncompressed postscript, please contact me directly. 
</p><p>
I hope you find the critique useful and interesting. If so, please feel free to 
distribute it among your peers and friends. 
</p><p>
Printing problems? 
</p><p>
If you find the file does not print, you might find that the control D (^D or EOT) as 
the first character in the file is upsetting your printer. Some printers seems to 
require this, and others don't. Just remove it if you have a problem. 
</p><p>
If there are carriage returns that your printer objects to remove all ^M 
characters. 
</p><p>
Some printers are fussy about the page size. I have formatted it for U.S Letter, 
as it is shorter than A4 and so should avoid any truncation problems. However, 
this is a problem for some A4 printers. If this is the case, replace the line: 
</p><p>
/oldDictCount countdictstack def {letter 
</p><p>
by 
</p><p>
/oldDictCount countdictstack def {a4 
</p><p>
The papertray command might have to be changed from 0 to 1. 
</p><p>
Otherwise, make sure that you have 'uncompress'ed the file, and that you are 
sending it to a PostScript printer. 
</p><pre>Ian Joyner  ACUS (Australian Centre for Unisys Software)    ian@syacus.acus.oz
"Where is the man with all the great directions?...You can't imagine it,
 how hard it is to grow, Can you imagine the order of the universe?" ABWH
Disclaimer:Opinions and comments are personal.
115-117 Wicks Rd, North Ryde, N.S.W Australia 2113
Tel 61-2-390 1328       Fax 61-2-390 1391
</pre>
<hr>
<h3>C++?? A Critique of C++ </h3>
<p>
(2nd Edition) 
</p><p>
© (1992) by Ian Joyner, c/- Unisys - ACUS, 115 Wicks Rd, North Ryde, Australia 
2113, Tel: +61-2-390 1328, Fax +61-2-390-1391, Email/Internet: 
ian@syacus.acus.oz.au 
</p><p>
[Editors note: Permission for publication in The ModulaTor was granted by the 
author in Nov-1992] 
</p><pre><span face="Courier"> Introduction..........................................................4

 The Role of a Programming Language....................................5
   Safety and Courtesy Concerns........................................8

 C++ Specific Criticisms...............................................8
   Virtual Functions...................................................8
   Pure Virtual Functions.............................................11
   The Nature of Inheritance..........................................12
   Function Overloading...............................................13
   Virtual Classes....................................................14
   Name overloading...................................................14
   Polymorphism and Inheritance.......................................16
   '.'  and '-&gt;'......................................................17
   Anonymous parameters in Class Definitions..........................17
   Nameless Constructors..............................................18
   Constructors and Temporaries.......................................18
   Optional Parameters................................................18
   Bad deletions......................................................19
   Local entity declarations..........................................19
   Members............................................................20
   Friends............................................................20
   Static.............................................................21
   Union..............................................................21
   Nested Classes.....................................................21
   Global Environments................................................22
   Header Files.......................................................22
   Class Interfaces...................................................23
   Class header declarations..........................................23
   Garbage Collection.................................................24
   Type-safe linkage..................................................25
   C++ and the software lifecycle.....................................26
   Reusability and Communication......................................27
   Reusability and …</span></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.modulaware.com/mdlt28.htm">https://www.modulaware.com/mdlt28.htm</a></em></p>]]>
            </description>
            <link>https://www.modulaware.com/mdlt28.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745291</guid>
            <pubDate>Mon, 06 Jul 2020 06:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three things you should know before starting a Patreon page]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745272">thread link</a>) | @exolymph
<br/>
July 5, 2020 | http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon | <a href="https://web.archive.org/web/*/http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0e74a9a2acebd70c05fe"><div><p>For the three years starting in April of 2017, I ran much of <a href="http://theprepared.org/newsletter" target="_blank">The Prepared’s</a> (and ultimately my family’s) income through Patreon. I started doing so as an experiment - one that by any measure has been a success. But while Patreon was instrumental in that process, I recommend that creators <strong>not</strong> structure their incomes and careers around Patreon. Here’s why.</p><p>Like many creators, I chose Patreon’s “pay by the creation” (rather than “pay by the month) mode. This directly incentivizes creators to continue doing the actual work, and keeps them accountable to the commitments they make. </p><p>But what Patreon doesn’t tell you is that fans can optionally set a monthly cap on their spending, and that cap can be arbitrarily low - even <strong>less than your per-creation commitment level.</strong> In other words, a reader of my weekly newsletter could pledge $5 per newsletter, but then set a $2 monthly cap. The worst part about this is that there’s literally nowhere in the Patreon backend that I can see this cap. I spoke to Patreon’s product team about this in late 2018, and they told me that the best thing I could do is to look at my creation-by-creation analytics at the end of the month and see which of my patrons paid for which creations; if a person doesn’t show up at the end of the month, then they must have set a cap.</p><p>This is a totally unscalable solution, and it makes the process of issuing patron rewards excruciatingly hard to manage. Creators need the ability to quickly and easily determine <strong>who</strong> is paying them for <strong>what</strong>; Patreon makes this impractically hard.</p><p>Further:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593267194369_49688"><div><ul data-rte-list="default"><li><p>Patreon provides email alerts for when a new patron makes a pledge, but has <strong>no email or push notifications for when patrons delete pledges.</strong> </p></li><li><p>Patreon has no creator-side notification system for declined charges or charges that are flagged for fraud. Worse yet, their patron-side notification system appears to be totally ineffective; many long time patrons (and personal friends of mine) were genuinely shocked to hear, many months later, that their monthly charges had been declined - leading to their pledges being automatically canceled by Patreon. Even worse, Patreon’s “Declines” page, which shows the total declined amount on a month by month basis, has no way of showing which patrons’ pledges were declined - you instead need to go into the “Relationship Manager” and filter by “Declined” to see whose charges have gone through, and when.</p></li><li><p>If you, as a creator, go through all of the effort to find charges that<em> </em>have been declined or marked as fraud, it can then be really difficult to recoup that revenue. This is mostly a result of the fact that most Patreon creators charge a small amount of money (a couple dollars) per month. In theory you could email or message the patron when their charge doesn’t go through, but in practice it feels a bit weird to be hounding someone over (say) $4. If the pledge was billed on an annual basis, though, it might be a big enough sum to warrant the effort. </p></li><li><p>Patreon uses accounting terms with little regard for their generally accepted meaning. See the screenshot above, which is titled “Earnings Projections” but then actually lists <em>gross revenue.</em> In accounting, <em>earnings</em> is the same as <em>profit - </em>it’s what a company has left <strong>after every expense is paid, </strong>whereas <em>gross revenue</em> is the total amount that a company takes in and doesn’t take into account expenses at all. In other words, Patreon is suggesting that the numbers here are what will be deposited into my bank account - but once Patreon takes their platform fees, it’ll actually be significantly less. This kind of sloppy terminology is all over Patreon’s creator backend, and no matter how you slice it is either the result of gross incompetence or a deliberate desire to deceive creators.</p></li></ul><p>Between credit card processing fees (2.9% plus $0.30 per transaction) and Patreon’s cut (between 5% and a whopping 12%), your earnings will be <em>significantly</em> less than your top line pledged amount. In practice, I saw total fees of between 8-12%. (Note: I signed up for Patreon before they shifted to tiered pricing, and now have a “Founder” Pro plan at a 5% platform fee rate. If you signed up for a Pro or Premium account today, you’d pay Patreon 3% or 7% more than I do, respectively.)</p><p>If Patreon were actively bringing customers to me - if normal people were just out there browsing Patreon for awesome things to support - then that might make sense. <strong>But the reality is that success on Patreon is inextricably tied to having your own platform and community.</strong> All Patreon does is manage recurring payment processing - a commodity service that many companies do for a drastically lower fee structure. Sure, ostensibly you can also be having conversations with patrons, generating some kind of community there, etc - but every step you take to encourage users to interact with you on Patreon, the more you undermine your own platform. In other words, Patreon engages in rent seeking - but they ultimately do it on <strong>your</strong> platform, and don’t bring a built-in audience with which to raise you higher.</p><p>When I transitioned off of Patreon, I moved to a combination of Quickbooks Online ($645/year; note that <a href="https://www.propublica.org/article/inside-turbotax-20-year-fight-to-stop-americans-from-filing-their-taxes-for-free" target="_blank">Intuit is a terrible company</a>) and Squarespace’s ($480/year) recurring products feature. The result is that my processing fees dropped dramatically. At my peak Patreon earnings, I was spending almost $300/month ($3600/year) on Patreon’s platform fees. My current revenue is roughly 3x what it was then, but I’m paying 68% less than I used to be.<strong> My current payments, web hosting, and accounting software outlay is $1,125 a year; if I had remained on Patreon my annual fees would be about $10,000.</strong></p><p>Okay, you’re saying - so Patreon isn’t the perfect all-in-one platform that will allow me to bill, chat with, and build my audience. But maybe it’s a piece of a larger puzzle?</p><p>It’s a great idea, but unfortunately Patreon does a terrible job integrating with the other services that I use to run my business.</p><p>The first thing I’d want from Patreon is an easy way to automatically share my content (which most creators distribute elsewhere - for me, it’s Mailchimp) to Patreon. But while Patreon does have a public API, it’s poorly developed (there is no sandbox/testing area, and the most recent updates to <a href="https://github.com/Patreon/patreon-python" target="_blank">their API libraries</a> are from January of 2019) and only allows browsing/looking up data on Patreon; you cannot post content to your Patreon account via the API. This lack of functionality also exists in Zapier’s implementation of the Patreon API: You can use Patreon as a trigger, but not as an action.</p><p>What this means is that creators are inherently tied to Patreon’s terrible, horrible, clicky clicky GUI. You are completely tied to the limitations that are built into Patreon’s web product, and don’t have the ability to build automations that’ll speed up your content and customer management.</p><p>Patreon also fails to integrate well with accounting software - something that flies in the face of their promise to give creators “the stability you need to build an independent creative&nbsp;career.” Their API (and Zapier’s implementation of it) only provides <em>pledge</em> activity, and is therefore inaccurate (caps, declines, and fraud aren’t factored in - it’s a guesstimate at what you might make in the future) in all of the ways described above.</p><p>I really can’t stress this enough: <strong>If your intention is to build a meaningful income, there are much better options out there than Patreon. </strong>What Patreon <em>does</em> offer is a quick way to see whether people on the internet will pay you a little money for something that you’re already doing for free. </p><p>This is a nontrivial thing, but it’s something that you should really think through before you start a Patreon page. If it’s a success, then it’ll likely make a lot of sense for you to transition <em>off</em> of Patreon at some point in the foreseeable future. That might be fine - especially if you’re really early on and success feels like a longshot - but The Prepared’s transition off of Patreon required a lot of management on my part and resulted in roughly 1/3 of my patrons dropping their pledges. </p><p>To be clear: I’m deeply appreciative of all of the people and companies who supported me through Patreon, and it really is true that those first couple of dollars made a big impact in the path of my career. But Patreon as a platform did remarkably little to support me along that journey, even after I became a moderately successful creator and took quite a bit of time to explain my frustrations to both their customer service &amp; user research teams.</p></div></div></div>]]>
            </description>
            <link>http://pencerw.com/feed/2020/6/24/three-things-all-creators-should-know-about-patreon</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745272</guid>
            <pubDate>Mon, 06 Jul 2020 06:35:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to process more than 350K requests per month free using 3 free ETA services]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23745223">thread link</a>) | @Gen1us
<br/>
July 5, 2020 | https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.maddevs.io/@meder33kg?source=post_page-----6edc6affface----------------------" rel="noopener"><img alt="Akkozov Meder" src="https://miro.medium.com/fit/c/96/96/2*87H69ujCEx7VLZYSZPQyig.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Estimated time of arrival." src="https://miro.medium.com/max/8000/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg" width="4000" height="2172" srcset="https://miro.medium.com/max/552/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 276w, https://miro.medium.com/max/1104/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 552w, https://miro.medium.com/max/1280/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 640w, https://miro.medium.com/max/1400/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg?q=20"></p></div></div></div><figcaption>Estimated time of arrival</figcaption></figure><p id="cce6">This is a story on how to not spend even a penny by using three ETA (estimated time of arrival) services instead of one. Everything is based on my personal experience working as a back-end developer at GoDee project. GoDee is a start-up project that offers booking seats on a bus online. You could find more information about this project here:</p><p id="e338">GoDee is a public transportation service. Bus transportation by GoDee is more convenient than motorbikes common for Southeast Asia and cheaper than a taxi. The app-based system allows users to find an appropriate route, select the time, book the seat, and pay for the ride online. And one of the problems of GoDee is traffic jams that severely impact the user experience. Users get tired of waiting and get annoyed by trying to guess the bus arrival time. So, to make the commuting more convenient, it needed service to calculate the bus’s approximate arrival time, aka ETA.</p><p id="5226">Developing ETA from scratch would take at least a year. So, to speed up the process, GoDee decided to implement the Google Distance Matrix API tool. Later they developed their own Pifia micro-service.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/500/1*vq9Ao08BtAdAMx5OYhbSlA.gif" width="250" height="429" data-old-src="https://miro.medium.com/freeze/max/34/1*vq9Ao08BtAdAMx5OYhbSlA.gif?q=20"></p></div></div></figure><p id="b97d">Over time, the business grew, and the user base increased. We encountered a problem with increasing requests in the Google Distance Matrix API.</p><h2 id="8971">Why is this a problem?</h2><p id="2a4f">Because every request costs money, Google API provides 10.000 free queries per month, after which every 1.000 queries are charged $20. At that time, we had about 150,000 requests per month.</p><p id="7492">My mentor was very dissatisfied with that. And said that system should change caching to store ETA every 30 minutes. At that time, the system sent requests to the Google API every 3 seconds to get fresh data. However, such a caching algorithm wasn’t efficient, since minibuses were stuck in traffic. And so the distance only changed once every ten minutes. There was another nuance. For example, five users are asking for information about the same bus, and this is the same request. The cache solved this type of problem.</p><figure><div></div><figcaption>Сache Code</figcaption></figure><p id="8a43">The cache worked, but not for long since GoDee grew even further and faced the same problem — the number of queries has increased again.</p><p id="9a57">It was decided to replace the Google API with OSRM. Basically, OSRM is a service for building a route based on ETA (this is a rough but the short description, if you need details, here is the <a href="http://project-osrm.org/" target="_blank" rel="noopener">link</a>).</p><blockquote><p id="113f">The Open Source Routing Machine or OSRM is a C++ implementation of a high-performance routing engine for the shortest paths in road networks.</p><p id="15be">Wikipedia.</p></blockquote><p id="97d4">OSRM has one problem: it builds routes and calculates ETA without taking traffic into account. To solve this problem, I started looking for services that can provide information about traffic in the specified part of the city. HERE Traffic was providing the data I needed. After a little study of the documentation, I wrote a small code that gets traffic information every 30 minutes. And to upload traffic information to OSRM, I wrote a small script with the command <code>./osrm-contract data.osrm --segment-speed-file updates.csv</code> (more details <a href="https://github.com/Project-OSRM/osrm-backend/wiki/Traffic" target="_blank" rel="noopener">here</a>).</p><p id="cbda">Math time: every half of the hour, there is a request to HERE to get traffic information this are two requests per hour, that is, a day is 48 requests (24 * 2 = 48) and a month is about ≈ 1.488 (48*31 = 1.488) a year 17.520. Yes, we have these free requests from HERE for 15 years would be enough.</p><figure><div></div><figcaption>Code for getting traffic</figcaption></figure><p id="b1d9">Preliminary tests showed that the service works perfectly, but there is a problem, HERE gives traffic information in “gibberish” and the data does not match the OSRM format. In order for the information to fit, you need to use another service HERE for geocoding + OSRM (for getting points on the map). This is approximately 450.000 requests per month. Later, OSRM was abandoned because the number of requests exceeded the free limit. We didn’t give up and enabled the HERE Distance Matrix API and temporarily removed the Google Distance Matrix API. The logic HERE is simple: we send coordinates from point A to point B and get the bus arrival time.</p><figure><div></div></figure><p id="2e81">After we installed everything on the test server and started checking, we received the first feedback from the testers. They said that ETA reads the time incorrectly. We started looking for the problem, looked at logs (we used Data dog for logs), logs, and tests showed that everything works perfectly. We decided to ask about the problem in a little more detail, and it turned out that if the car is in traffic for 15 minutes, ETA shows the same time. We decided that this is because of the cache because it stores the original time and does not update it for 30 minutes.</p><p id="1d5a">We started looking for the problem, at the beginning we checked the data on the web version of the HERE Distance Matrix API (which is called we go here), everything worked fine, we received the same ETA. This problem was also checked on the google map service. There was no problem. The services themselves show this ETA. We explained everything to testers and businesses, and they accepted everything.</p><p id="18ce">Our team lead suggested connecting another ETA service and returning the Google API as a backup option and writing code with the logic of switching services (the switch was needed if the requests pass the free number of requests).</p><p id="e9c2">The code works the following way:</p><pre><span id="b4e7">val = getCount() // getting the number of queries used</span><span id="9ff9"><em>if</em> getMax() &lt;= val { // checking for the limit of free requests for the service used</span><span id="e935">newService = switchService(s) // // if the limit is reached, switch the service return</span><span id="cae7"><em>return</em> newService(from, to) // giving the logic of the new service </span></pre><p id="054f">We found the following Mapbox service, connected it, installed it, and it worked. As a result, our ETA had:</p><blockquote><p id="625d">“Here” — 250,000 free requests per month<br>Google — 10,000 free requests per month<br>Mapbox — 100,000 free requests per month</p></blockquote><p id="4def">Always look for alternatives, sometimes it happens that the business doesn't want to pay the money for the service and refuses it. As a developer who has worked hard on the service, you should bring the task to real use. This article describes how we were trying to connect more services for the free use of ETA because the business did not want to pay for the service.</p><p id="4330">P.S. As a developer, I believe that if the tool is good and does its job well, then you can pay for the tool’s services (or find Open source projects :D).</p><figure><div></div></figure></div></div></section></div></div>]]>
            </description>
            <link>https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745223</guid>
            <pubDate>Mon, 06 Jul 2020 06:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overcoming Serverless Limitations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23745034">thread link</a>) | @linuxdude
<br/>
July 5, 2020 | https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/ | <a href="https://web.archive.org/web/*/https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-330">

	

	
		<p><img width="2240" height="1260" src="https://talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?is-pending-load=1" alt="" data-attachment-id="333" data-permalink="https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/oakbur-quill-co-2/" data-orig-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=2240%2C1260&amp;ssl=1" data-orig-size="2240,1260" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Oakbur Quill Co." data-image-description="" data-medium-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?fit=1024%2C576&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?w=2240&amp;ssl=1 2240w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=2048%2C1152&amp;ssl=1 2048w, https://i0.wp.com/talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?resize=1200%2C675&amp;ssl=1 1200w" data-lazy-sizes="(max-width: 2240px) 100vw, 2240px" data-lazy-src="https://talkingserverless.com/wp-content/uploads/2020/07/Oakbur-Quill-Co.-1.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">		</p><!-- .post-thumbnail -->

	
	<div>
		




<p>While Serverless provides<a href="https://talkingserverless.com/2020/05/12/serverless-a-developer-perspective/"> developers many advantages</a>, they also impose many constraints on developers in terms of architecture, deployment options, etc.. While these constraints<a href="https://talkingserverless.com/2020/06/08/top-considerations-for-serverless-developers/"> require developers</a> to change the way they develop and deploy their applications, there are many ways developers can overcome these limitations or find a workaround to manage them gracefully. As we attend meetups, we hear many questions/concerns from developers about the Serverless limitations. In this post, we will talk about some of the limitations and how developers can overcome these limitations.</p>



<ul><li><b>Stateful Applications:</b> Functions as a Service started off as a platform for stateless applications but the trend is changing slowly. It is possible to maintain the state between invocations using various data stores offered by the cloud providers but it came with enormous operational overhead, complexity, and runaway costs / poor SLAs when not managed properly. Now, many new vendors like<a href="https://go.zoho.com/yIl"> Zoho Catalyst</a> or Nimbella are offering FaaS platforms with integrated data stores, giving developers an easy option to build stateful applications</li><li><b>Mitigating DDOS:</b> Pay per invocation model of FaaS brings this question into focus as developers (and other decision-makers) ponder using FaaS in their organizations. The DDOS risk is not any different from DDOS attacks on applications running on containers or virtual machines but the correlation between the number of invocations of the function with costs amplifies the threat. In many cases, FaaS vendors may try to reduce the impact of DDOS but the users also bear the responsibility to mitigate the attacks. They can use services like Cloudflare to fend away DDOS attacks. They can also resort to throttling as a way to fend off DDOS attacks but, when used pre-emptively, it may end up impacting the application. Using an alerting mechanism for DDOS and then taking quick remediation like throttling may also help. Some FaaS providers like AWS allow developers to use API Gateway with a key, thereby, limiting the access to API gateways</li><li><b>Latency Issues:</b> When a Serverless platform is used to deploy a small component of a larger complex application, latency could be an impact as these components talk to the rest of the application through REST API calls. This latency in the inter-component communications along with the fact that that the other components of the application may be deployed using other services offered by the cloud provider from a different location may impact, adding latency. This can be mitigated using a loosely coupled architecture like Microservices architecture where FaaS can be used for one or more Microservices</li><li><b>Scaling Issues:</b> While using certain FaaS services for stateful applications, there could be scaling issues. Stress on the datastore could be timing out the requests sent through various API Gateway endpoints. One way to mitigate this is by using one endpoint for writing to the data store and one for reading the data. Now the load can be distributed better by using a Queuing service while writing to the datastore. For the most part, these constraints can be mitigated by using smarter architecture but it may not always be the possibility</li><li><b>Cold Start Problem:</b> Cold start may appear like a problem in FaaS but it is leveraged by cloud providers to provide the service at such low costs. Some providers impose cold start as a constraint but others keep the containers encapsulating the functions warm to avoid the cold start problem. If your application’s user experience cannot afford cold start, it is better to pick a provider who keeps the containers warm to avoid the cold start problem</li><li><b>Integration Testing:</b> One of the biggest problems faced by developers is Integration Testing. In traditional environments, developers will have all the components available locally and they can do the integration testing before the code is pushed into the DevOps pipeline. With FaaS, it is not possible. One way to overcome this limitation is to do the integration testing remotely with the cloud provider than doing it locally. Since FaaS provides a cost-effective way to deploy the application, using the service for dev and test is the right way to deploy applications. This also removes the usual friction that happens between developer and ops teams where each team blames the other for the application failures due to differences in environment</li><li><b>Vendor Lock-in:</b> Vendor lock-in is definitely a limitation with Serverless computing. Some vendors mitigate this risk by offering their service based on an open-source FaaS offering. However, this mitigation is superficial as most of the lock-in happens with the application dependencies like the database service used, etc.. Instead, our suggestion is to use disposable applications while using FaaS. FaaS reduces the cost of deploying applications but it also reduces the cost of developing applications. This combination of a reduction in development and deployment costs is the secret behind the success of FaaS. Disposable applications are applications that cost less to create a new application than change the application as you move from one type of service to another or move cloud providers. By using disposable applications, users need not worry about the lock-in costs and they can focus on building apps and deploying them quickly. When the time to change comes, they can just throw away the existing application and quickly build a new one</li></ul>



<p>Yes, Serverless computing adds lots of constraints for developers and these constraints help the cloud providers to offer the service at a very low cost. By understanding the limitations, developers can easily mitigate the impact of limitations.</p>

	</div><!-- .entry-content -->

	</article></div>]]>
            </description>
            <link>https://talkingserverless.com/2020/07/05/overcoming-serverless-limitations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745034</guid>
            <pubDate>Mon, 06 Jul 2020 05:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Go lesson learned: sometimes I don't want to use goroutines if possible]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744957">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>A Go lesson learned: sometimes I don't want to use goroutines if possible</h2>

	<p><small>July  5, 2020</small></p>
</div><div><p>We have a heavily NFS based server environment <a href="https://support.cs.toronto.edu/">here</a>, with <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">multiple NFS servers</a> and an IMAP server that accesses
all mailboxes over NFS. That IMAP server has had <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/LoadAverageIMAPImpactQuestion">ongoing issues
with elevated load averages</a>,
and what at least seems to be IMAP slowness. However, our current
metrics leave a lot of uncertainties about the effects of all of
this, because we basically only have a little bit of performance
data for a few IMAP operations. One thing I'd like to do is gather
some very basic Unix level NFS performance data from our IMAP server
and from some other machines, to see if I can see anything.</p>

<p>One very simple metric is how long it takes to read a little file
from every NFS filesystem we have mounted on a machine. As it
happens, we already have the little files (they're used for another
system management purpose), so all I need is a program to open and
read each one while timing how long it takes. There's an obvious
issue with doing this sequentially, which is that if there's a
single slow filesystem, it could delay everything else.</p>

<p>The obvious answer here was Go, goroutines, and some form of goroutine
pool. Because the goroutines just do IO (and they're only being
used to avoid one bit of IO delaying another separate bit), the
natural size of the goroutine pool is fairly large, say 50 to 100
goroutines (<a href="https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ManyNFSFilesystemsWhy">we have a lot of NFS filesystems</a>).  This is quite easy and obvious
to implement in Go, so I put together a little Go program for it
and watched the numbers it generated as they jumped around.</p>

<p>Then, out of reflexive caution, I tried running the same program
with a goroutine pool size of 1, which more or less forced serial
execution (the pool goroutine infrastructure was still active but
there was only one worker goroutine doing all the reading). To my
surprise the 'time to read a file' number for all filesystems was
visibly and decidedly lower. I could run the program side by side
with the two different goroutine pool sizes and see this clearly.</p>

<p>Some thinking gave me a possible reason why this is so. My core
code does essentially the following (minus error checking):</p>

<blockquote><pre>start := time.Now()
file, err := os.Open(target)
n, err := file.Read(buffer)
duration := time.Now().Sub(start)
</pre>
</blockquote>

<p>This sequence makes two system calls and <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">each system call is a
potential goroutine preemption point</a>. If
a goroutine gets preempted during either system call, it can only
record the finishing time once it's scheduled again (and finishes
the read, if it was preempted in the open). If there are 50 or more
goroutines all doing this, some of them could well be preempted and
then not scheduled for some time, and that scheduling delay will
show up in the final duration. When there aren't multiple goroutines
active, there should be very little scheduling delay and the recorded
durations (especially the longest durations) will be lower. And the
ideal situation for essentially no goroutine contention is of course
one goroutine.</p>

<p>(Technically this makes two more system calls to get the time at
the start and the end of the sequence, but on modern systems,
especially Linux, these don't take long enough to trigger <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoSchedulerAndSyscalls">Go's
system call preemption</a> and probably don't
even enter the kernel itself.)</p>

<p>Because I still worry about individual slow filesystems slowing
everything down (or stalls on some filesystems), my solution was a
more complicated work pool approach that starts additional worker
goroutines only when all of the current ones seem to have stalled
for too long.  If all goes well (and it generally does in my testing),
this runs with only one goroutine.</p>

<p>(My current code has the drawback that once the goroutine worker
pool expands, all of them stay active, which means that enough
slow filesystems early on in the checks could get me back to the
thundering herd problem. I'm still thinking about that issue.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/GoWhenNotManyGoroutines</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744957</guid>
            <pubDate>Mon, 06 Jul 2020 05:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Facebook Ads to Land an Interview at Reddit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744652">thread link</a>) | @shsachdev
<br/>
July 5, 2020 | https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>
    The traditional way to get a job interview is to submit your resume and pray. 
    </p>
    <p>
    Everyone does this and it’s taken to be the default because it’s easy. You can send the same resume with the click of a button to totally different companies, no effort on your part other than preparing the resume.
    </p>
    <center>
            <img src="https://www.careerfair.io/assets_fbads/resume_blast.png" width="515" height="354" alt="">
              </center>


    
    <p>
    There’s no way to stand out, no uniqueness. 
    </p>
    <p>
    Generally, the way to get around this is to ask for a referral or to reach out to someone at the company for some sort of informational interview. Both of these methods allow for a more personalized approach to job hunting. 
    </p>
    <p>
    But is it possible to go even one step further? 
    </p>
    
    
    
    <p>
    In 2016, <a href="https://www.linkedin.com/in/dumbfounder/">Chris Seline</a> was coming off a failed startup and looking for new opportunities. 
    </p>
    <p>
    Unlike most other people, though, Chris wasn’t a fan of the resume blast method. 
    </p>
    <p>
    His strategy was to target specific companies and try to get noticed creatively rather than use the traditional channels and get lost in the shuffle. 
    </p>
    <p>
    Chris decided that he really wanted to work for Reddit. 
    </p>
    <p>
    His plan was to write a <a href="https://twicsy-blog.tumblr.com/post/135712326189/hey-reddit-lets-make-some-recommendations">blog post</a> and then email it to the CEO of Reddit. 
    </p>
    <p>
    The blog post is thorough - it’s 2000 words, technical, and you can tell a lot of effort was put into it. 
    </p>
    <p>
    Even if Chris had emailed his post to the Reddit CEO, there’s a strong chance he would have gotten an interview. 99% of applicants don’t put this much effort into an application and receiving such a personalized email is a positive signal. 
    </p>
    <p>
    But Chris didn’t just email him. 
    </p>
    
    
    
    <p>
    He decided to use Facebook Ads to target the CEO of Reddit (Steve Huffman). 
    </p>
    <p>
    Here’s how he did it:
    </p>
    <ol>
    
    <li>Find the Reddit CEO’s public Facebook profile
    
    </li><li>Use this to find out where he lived, what he liked, what he was interested in, etc
    
    </li><li>Use the above to run a super targeted FB Ads Campaign
    </li>
    </ol>
    <p>
    Note that Chris only wanted <em>one</em> person to click on this Ad, that’s why he had to go super targeted. 
    </p>

    <center>
        <img src="https://www.careerfair.io/assets_fbads/new_fb_ad.png" width="529" height="492" alt="">
          </center>
    
    
    
    
    <p>
    Chris ended up spending $10. The ad reached 197 people. 4 People clicked on it. One of them was the CEO of Reddit.
    </p>
    <p>
    Next thing you know, Reddit HR reached out to schedule an interview. Nicely done. 
    </p>
    <p>
    I contacted Chris to find out if he actually got the job - here’s what he said:
    </p>

    <blockquote>
    
        I did not. It turns out they were just starting a search for "head of search" at Reddit, and asked if I would like to interview for that job. That would have been my dream job, and definitely worth a move across the country, even with 3 kids and a wife in tow (I live in DC), so naturally I was very excited and said yes. But after a few talks they thought I didn't have enough experience with big companies, so they asked if I would be interested in an IC role. I was, but I wasn't willing to move across the country for that, and they didn't want to hire remote workers. So that was that.
        <span>Chris Seline</span>
    </blockquote>
   
    
    
    
    <p>
    The reason this is a fun story is because of the FB Ads. 
    </p>
    <p>
    But I think what people may gloss over is the amount of time and research Chris put into writing the blog post that he eventually showed to the Reddit CEO. 
    </p>
    <p>
    If we go back to the beginning of this case study, notice how I mentioned that just blasting a resume to a company signals nothing unique and frankly a lack of effort. 
    </p>
    <p>
    A good way to resolve problems is to invert them - if we do that here, we get the following:
    </p>

    <center>
        <img src="https://www.careerfair.io/assets_fbads/blast_v_tailored.png" width="536" height="225" alt="">
          </center>
    
    <p>
    Chris’ blog post was well researched, relevant, and made him stand out. The FB Ads targeting was just the cherry on top.
    </p>
    <p>
    Next time you see a job you really want to get, think about how you can go that one step further. 
    </p>
    <p>
    Thanks to Chris for responding to my email. You can read his original blog post on this <a href="https://twicsy-blog.tumblr.com/post/174063770074/how-i-targeted-the-reddit-ceo-with-facebook-ads-to">here</a>. 
    </p>
        </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/how-to-land-interview-using-fb-ads</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744652</guid>
            <pubDate>Mon, 06 Jul 2020 04:18:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a RISC-V OS in Rust: Userspace Processes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744622">thread link</a>) | @azhenley
<br/>
July 5, 2020 | http://osblog.stephenmarz.com/ch11.html | <a href="https://web.archive.org/web/*/http://osblog.stephenmarz.com/ch11.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
<p>This is chapter 11 of a multi-part series on <a href="http://osblog.stephenmarz.com/index.html">writing a RISC-V OS in Rust</a>.</p>
<p><a href="http://osblog.stephenmarz.com/index.html">Table of Contents</a> → <a href="http://osblog.stephenmarz.com/ch10.html">Chapter 10</a> → (Chapter 11)</p>

<p>1 Jun 2020: Patreon only</p>
<p>8 Jun 2020: Public</p>
<h2>Resources and References</h2>
<p>
The ELF standard can be found here: <a href="http://osblog.stephenmarz.com/files/elf.pdf">ELF File Format (PDF)</a>.
</p>
<h2>Introduction</h2>
<p>
This is the moment we've all been waiting for. Ten chapters of setup have led us to this moment--to finally be able to load a process from the disk and run it. The file format for executables is called ELF (executable and linkable format). I will go into some detail about it, but there are plenty of avenues you can explore with this one file type.
</p>
<h2>The ELF File Format</h2>
<p>
The executable and linkable format (ELF) is a widely used file format. If you've used Linux, you no doubt have seen it or the effects of it. This file format contains an ELF header, followed by program headers. Each time, we're telling the OS where the linker has mapped the executable sections. If you don't remember, we have a .text section for CPU instructions, .rodata for global constants, .data for global initialized variables, and .bss section for global uninitialized variables. In the ELF format, the compiler decides where to put these. Also, since we're using virtual memory addresses, the ELF header specifies the <em>entry point</em>, which is what we'll put in the program counter when scheduling a process for the first time.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/elf_format.png"><img src="http://osblog.stephenmarz.com/imgs/elf_format.png"></a>
</p>
<p>
[joke]My handwriting hasn't improved since I was 4[/joke]
</p>
<p>
Let's look at some Rust structures that will help us. These are in elf.rs.
</p>
<pre><code>
#[repr(C)]
pub struct Header {
    pub magic: u32,
    pub bitsize: u8,
    pub endian: u8,
    pub ident_abi_version: u8,
    pub target_platform: u8,
    pub abi_version: u8,
    pub padding: [u8; 7],
    pub obj_type: u16,
    pub machine: u16, // 0xf3 for RISC-V
    pub version: u32,
    pub entry_addr: usize,
    pub phoff: usize,
    pub shoff: usize,
    pub flags: u32,
    pub ehsize: u16,
    pub phentsize: u16,
    pub phnum: u16,
    pub shentsize: u16,
    pub shnum: u16,
    pub shstrndx: u16,
}
</code>
</pre>
<p>
All ELF files start with this ELF Header structure. The very top is 0x7f followed by capital ELF, which is 0x7f 0x45 0x4c and 0x46 as you can see below. I took a simple hexdump of the ls (list) command. You can see sure as sh*t that the magic is right there.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/ls_elf.png"><img src="http://osblog.stephenmarz.com/imgs/ls_elf.png"></a>
</p>
<p>
The rest of the fields will tell us for which architecture this ELF file was made. RISC-V has reserved 0xf3 as its machine type. So, when we load an ELF from the disk, we must make sure it's for the correct architecture. You'll also notice that <code>entry_addr</code> is up there too. This is a virtual memory address where <code>_start</code> begins. Our _start just simply calls main and then when main returns, it calls the exit system call. This is how most programs actually work, but they do a much more rigorous job including getting command line arguments and so forth. Right now, we don't have those.
</p>
<p>
The field that we need to know is the <code>phoff</code> field which specifies the program headers' offset. The program headers is a table of one or more program sections. I took a snapshot of ls (again) and the program headers. You can do the same using <code>readelf -l /bin/ls</code>. The code below shows how I read the ELF header in Rust.
</p>
<pre><code>
let elf_hdr;
unsafe {
  elf_hdr = (buffer.get() as *const elf::Header).as_ref().unwrap();
}
if elf_hdr.magic != elf::MAGIC {
  println!("ELF magic didn't match.");
  return;
}
if elf_hdr.machine != elf::MACHINE_RISCV {
  println!("ELF loaded is not RISC-V.");
  return;
}
if elf_hdr.obj_type != elf::TYPE_EXEC {
  println!("ELF is not an executable.");
  return;
}
</code>
</pre>
<p>
You can see that now we're at the program headers, which I took a snapshot of for /bin/ls.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/ls_program_headers.png"><img src="http://osblog.stephenmarz.com/imgs/ls_program_headers.png"></a>
</p>
<p>
The program headers have the following structure in Rust.
</p>
<pre><code>
#[repr(C)]
pub struct ProgramHeader {
    pub seg_type: u32,
    pub flags: u32,
    pub off: usize,
    pub vaddr: usize,
    pub paddr: usize,
    pub filesz: usize,
    pub memsz: usize,
    pub align: usize,
}
</code>
</pre>
<p>
/bin/ls uses shared libraries, but we're not that good, yet. So, the only program headers we care about are the ones shown by LOAD. These are the sections that we need to load into memory for our static binaries. In the ProgramHeader structure, we need seg_type to be LOAD. The flags tell us how to protect the virtual memory. There are three flags EXECUTE (1), WRITE (2), and READ (4). We also need the off (offset), which tells us where in the ELF file that section to load into the program memory is contained. Finally, the vaddr is what we need to point the MMU to where we loaded this section into memory. You can see how I did this in test.rs in the test_elf() function.
</p>
<pre><code>
for i in 0..elf_hdr.phnum as usize {
  let ph = ph_tab.add(i).as_ref().unwrap();
  if ph.seg_type != elf::PH_SEG_TYPE_LOAD {
    continue;
  }
  if ph.memsz == 0 {
    continue;
  }
  memcpy(program_mem.add(ph.off), buffer.get().add(ph.off), ph.memsz);
  let mut bits = EntryBits::User.val();
  if ph.flags &amp; elf::PROG_EXECUTE != 0 {
    bits |= EntryBits::Execute.val();
  }
  if ph.flags &amp; elf::PROG_READ != 0 {
    bits |= EntryBits::Read.val();
  }
  if ph.flags &amp; elf::PROG_WRITE != 0 {
    bits |= EntryBits::Write.val();
  }
  let pages = (ph.memsz + PAGE_SIZE) / PAGE_SIZE;
  for i in 0..pages {
    let vaddr = ph.vaddr + i * PAGE_SIZE;
    let paddr = program_mem as usize + ph.off + i * PAGE_SIZE;
    map(table, vaddr, paddr, bits, 0);
  }
}
</code>
</pre>
<p>
All I do with the code above is enumerate all of the program headers. The ELF header tells us how many there are via the phnum field. We then check the segment type to see if it is LOAD. If it isn't, we skip it. Then, we check to see if that segment actually contains anything. If not, there's no use in loading it. Then, we copy what we read from the filesystem (buffer) into the process' memory (program_mem). Since these are virtual memory address, the rest of the code determines how we should map the pages.
</p>
<h2>Executing the Process</h2>
<p>
We need to map a few things, including the stack and the program. Also, don't forget to set the program counter to the entry_addr!
</p>
<pre><code>
(*my_proc.frame).pc = elf_hdr.entry_addr;
(*my_proc.frame).regs[2] = STACK_ADDR as usize + STACK_PAGES * PAGE_SIZE;
(*my_proc.frame).mode = CpuMode::User as usize;
(*my_proc.frame).pid = my_proc.pid as usize;
(*my_proc.frame).satp = build_satp(SatpMode::Sv39, my_proc.pid as usize, my_proc.root as usize);
</code>
</pre>
<p>
In here, regs[2] is the stack pointer (SP). This must be valid and mapped, otherwise the process will immediately page fault. Now that everything is set up, our last bit of execution is to add it to the process list. When the scheduler gets around to it, it will run our newly minted process!
</p>
<pre><code>
if let Some(mut pl) = unsafe { PROCESS_LIST.take() } {
  println!(
            "Added user process to the scheduler...get ready \
            for take-off!"
  );
  pl.push_back(my_proc);
  unsafe {
    PROCESS_LIST.replace(pl);
  }
}
else {
  println!("Unable to spawn process.");
}
</code>
</pre>
<h2>Writing Userspace Programs</h2>
<p>
We don't have a C library, yet. However, I'm making the OS come close to the newlib, which is a small C-library mainly for embedded systems. For now, I made a small library called <code>startlib</code> that will get us off the ground, and I copied printf into it.
</p>
<pre><code>
.section .text.init
.global _start
_start:
  call	main
  li	a0, 93
  j 	make_syscall
</code>
</pre>
<p>
The _start is a special label that the compiler will use as the entry point address. Recall that we set this in the program counter when we made a new process. After main returns, we schedule a system call number 93, which is the <code>exit</code> system call. All this system call does is deschedule the process and free all of its resources.
</p>
<p>
There are other utilities, including printf in our small library, but let's make a simple program to see if we can get it to work. To be more robust, I'm going to stretch all of our available sections to see if they load properly.
</p>
<pre><code>
#include &lt;printf.h&gt;

const int SIZE = 1000;
int myarray[SIZE];
int another_array[5] = {1, 2, 3, 4, 5};

int main()
{
  printf("I'm a C++ program, and I'm running in user space. How about a big, Hello World\n");
  printf("My array is at 0x%p\n", myarray);
  printf("I'm going to start crunching some numbers, so gimme a minute.\n");
  for (int i = 0;i &lt; SIZE;i++) {
    myarray[i] = another_array[i % 5];
  }
  for (int i = 0;i &lt; 100000000;i++) {
    myarray[i % SIZE] += 1;
  }
  printf("Ok, I'm done crunching. Wanna see myarray[0]? It's %d\n", myarray[0]);
  return 0;
}
</code>
</pre>
<p>
The program doesn't really do anything useful, but it will see if system calls work as well as context switching. On QEMU, this takes around 5 to 8 seconds to run on my machine at home.
</p>
<p>
We then compile this using our C++ toolchain (if you have one). <code>riscv64-unknown-elf-g++ -Wall -O0 -ffreestanding -nostartfiles -nostdlib -static -march=rv64g -mabi=lp64d -I./startlib -L./startlib -o helloworld.elf helloworld.cpp -lstart</code>
</p>
<p>
If you don't have a toolchain, you can download my program here: <a href="http://osblog.stephenmarz.com/helloworld.elf">helloworld.elf</a>. This requires that you have the systems calls identical to mine since it goes by a system call number.
</p>
<h2>Uploading the Program</h2>
<p>
We can use Linux to upload our elf file.
</p>
<p>
<a href="http://osblog.stephenmarz.com/imgs/upload_hw.png"><img src="http://osblog.stephenmarz.com/imgs/upload_hw.png"></a>
</p>
<p>
Take note of the inode number (26) and the file size (14776). Yours might be different, so make sure you stat it! Modify test.rs and put your inode and file size at the top.
</p>
<pre><code>
let files_inode = 26u32; // Change to yours!
let files_size = 14776; // Change to yours!
let bytes_to_read = 1024 * 50;
let mut buffer = BlockBuffer::new(bytes_to_read);
let bytes_read = syscall_fs_read(
                                  8,
                                  files_inode,
                                  buffer.get_mut(),
                                  bytes_to_read as u32,
                                  0,
);
if bytes_read != files_size {
  println!(
            "Unable to load program at inode {}, which should \
            be {} bytes, got {}",
            files_inode, files_size, bytes_read
  );
  return;
}
</code>
</pre>
<p>
This will use our filesystem read call to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://osblog.stephenmarz.com/ch11.html">http://osblog.stephenmarz.com/ch11.html</a></em></p>]]>
            </description>
            <link>http://osblog.stephenmarz.com/ch11.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744622</guid>
            <pubDate>Mon, 06 Jul 2020 04:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to civics in the 21st century]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744433">thread link</a>) | @natural219
<br/>
July 5, 2020 | https://cjohnson.io/civics/ | <a href="https://web.archive.org/web/*/https://cjohnson.io/civics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>"Men, at some time, are masters of their fates;"</p>
        <p>The fault, dear Brutus, lies not in our stars --</p>
        <p>but in ourselves, that we are underlings"</p>
      </div>
      
      <h4>Introduction to civics in the 21st century</h4>
      <p>You are a young adult. You are upset about things going on in America. Maybe you are angry, scared, confused, depressed -- or maybe you feel a strange joy about everything burning down (I've certainly felt that). Maybe you're just so burned out from the insanity that is American politics that you just feel nothing at all anymore.</p>

      <p>Maybe you have some ideas on how to fix things; maybe if everyone adopted the tenets of Marxist socialism, everything would be solved. Maybe big government is the problem; if everyone with power and wealth just left us alone, we could fend for ourselves in peace. Maybe you're already doing good work at a business, philanthropy, or in the government, but you're troubled at how out-of-touch the rest of America seems. Maybe you've been radicalized into a weird internet philosophy, like neoreaction, or you listen to popular cathartic podcasts like <em>Chapo Trap House</em> (I love those guys).</p>

      <p>Maybe you don't have any ideas. You keep your head down, try to avoid the news and politics, and just focus on your work, your friends, and your health (good response, IMO!). Maybe you're so utterly depressed about everything that you've become a <a href="https://www.youtube.com/watch?v=x9yQhJ02Zbc">doomer</a>; you just want to see everything crumble, and the only activity you have energy for is laying down and rotting (trust me, been there too).</p>
      <p>I'm here to tell you that Iâ€¦â€¦...have absolutely no idea how to fix anything. Honestly, we're probably boned.</p>
      <p>The events of 2020 -- covid, BLM, whatever the hell is going on in Washington DC -- have just been mind-boggling, depressing, and terrifying beyond comprehension. Even worse, 2020 has arrived after decades of deterioration of American ideas and institutions; on the global stage, we are now a complete joke. Especially in the eyes of China; a rising great power that challenges us in ways we've never had to contend with before.</p>
      <p>I don't know how to fix America. But I do know one thing -- the boomers probably won't pull us out of this one. I have no problem with boomers; they're just old people, and eventually, boomerdom will come for us all. They've spent all their lives fighting the battles of the 20th century, and their efforts have kept us safe* and (relatively***) prosperous, while we watch Twitch streams, struggle to find a rewarding career, try to find love, and argue with each other about how best we should treat everybody.</p>
      <p>And honestly? None of this was our fault. We were just kids, teengaers, and fresh college graduates, as the grownups -- likely through benign negligence -- careened American society into the ground. But every year that passes, and the gerontocracy continues to prove its inability to deal with the 21st century (especially with the rise of digital technology), <br><strong>it increasingly becomes our responsibility to fix it.</strong></p>
      <p>Young people are way smarter, more empathetic, and more capable than the old guard imagine. I have some measure of faith that we'll eventually figure it out. But the boomers have one big advantage over us; they are, for the very large part, masters of practicing <em>civility</em>.</p>
      <p>This webpage is a short series of essays on the concept of <em>civics</em>, specifically targeted to the young adults of America. Briefly put, civics is the art of getting along in a democracy. It's quite possible that democracy itself is over (we discuss this in length in the last piece). But for now, if young people want to make effective change, and to make our slice of the world a better place, we need to practice being good citizens. These essays contain some ideas on how we might start doing that.</p>
      <p>==</p>
      <p>This series contains five main parts. It starts with a meditation on <em>black lives matter</em>. The brutal murder of George Floyd kicked off an incredible display of patriotic energy, setting off a series of dizzying events in June. It was this event that inspired me to begin writing; I wanted to do something, but couldn't clarify exactly what I could positively contribute. By the way; black lives matter. It's okay to say it.</p>
      <p>The second essay is a whirlwind tour of the critical -- and potentially lethal -- multitude of crises we face as a society. Many of these issues are purposefully downplayed in popular media, with the (admirable) intent of protecting people from mass panic. I actually agree with the principle of preventing mass panic, but at some point, we will have to learn about and face these problems head on. (If you're not used to ruminating on the collapse of civilization, this essay has the potential to cause anxiety). The second part addresses what we can do about it; the short answer is, mostly nothing.</p>
      <p>The third essay is actually a bit of a detour (this was originally supposed to be three parts), on recent developments in a niche internet community I've been a part of for years. If you want a window into the digital culture that raised me personally, this essay could be illustrative. It also contains some general considerations on the trials and tribulations of being an influential public figure. (In short, it's bad; if you can at all help it, don't become a public figure).</p>
      <p>The fourth essay ends with a grand discussion of different types of political systems. American-style democracy, for all the good it has done, is still just an experiment. It might not actually be around forever. We consider the alternative of totalitarianism, which is the logical step backwards if democratic-style governance proves itself to be ultimately infeasible. The meat of my argument is here; what it means to be a good citizen, and how we might get there.</p>
      <p>Finally, I say a few words on something very important to me.</p>
      <p>==</p>
      <p>Here are the essays. You can read them in any order; it might actually be best to start with part 4, since it contains the most actually new ideas -- if you're already familiar with how screwed we are, part 2 is mostly just a recap. I would love to hear any feedback, thoughts, or ideas you have when reading this; my contact information is at the bottom.</p>
      <div id="table-of-contents">
        <p><a href="https://cjohnson.io/civics/black-lives-matter">Part 1 [Prelude]</a>: Black lives matter</p>
        <p><a href="https://cjohnson.io/civics/america-in-2020">Part 2</a>: The state of America in 2020</p>
        <p><a href="https://cjohnson.io/civics/movements-and-communities">Part 2.5</a>: Movements vs communities</p>
        <p><a href="https://cjohnson.io/civics/scott-alexander">Part 3 [Interlude]</a>: The case of Scott Alexander</p>
        <p><a href="https://cjohnson.io/civics/on-good-citizens">Part 4</a>: On being a good citizen</p>
        <p><a href="https://cjohnson.io/civics/christianity">Part 5</a>: A brief note on Christianity</p>
        <p><a href="https://cjohnson.io/civics/writing">[Postlude 1]</a>: On writing</p>
        <p><a href="https://cjohnson.io/civics/philosophy">[Postlude 2]</a>: On philosophy</p>
      </div>
      <p>==</p>
      <p>General disclaimer on writing: I write in a very dense, long-winded style. I use some internet slang, some cuss words, and lots of ideas and concepts that are defined elsewhere. If you don't know what something means, try Googling it.</p>
      <p>Overall, I recommend going slow; this will probably take at least an hour to read, and many of the things I talk about are just poorly-defined shorthands for much larger discussions that have happened in the past, or in other forums. Feel free to skip over any section that seems confusing or weird. Finally, my advice for dense writing in general; it is best consumed sober.</p>
      <p>Thanks, and I hope you enjoy. If you want to connect, you can find me on Twitter at @spiderfoods, or you can send an email to inbox@cjohnson.io.</p>
    </div></div>]]>
            </description>
            <link>https://cjohnson.io/civics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744433</guid>
            <pubDate>Mon, 06 Jul 2020 03:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spot the Difference: Leaking Metadata Warning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23744222">thread link</a>) | @rwoll
<br/>
July 5, 2020 | https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/ | <a href="https://web.archive.org/web/*/https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>I took a picture of a pretty flower on my walk. When I got home, I logged on to
my email via a web browser and sent the picture (<code>original_flower.heic</code>) to a
privacy-focused friend along with a poem that I hoped they would enjoy.
They responded with a puzzle:</p>

<blockquote>
<p>Your photo (<code>original_flower.heic</code>) is attached along with another photo (<code>updated_flower.heic</code>) that’s nearly identical.</p>

<p>Spot the difference! :)</p>
</blockquote>

<p>Visually the photos looked identical. I confirmed their visual similarity via
a <a href="https://en.wikipedia.org/wiki/Perceptual_hashing">perceptual hashing</a> <a href="https://pypi.org/project/ImageHash/">tool</a>.
It wasn’t just my eyes! However, the hashes of the files themselves were different so
I suspected photo metadata must be different.
I ran the photos through <a href="https://exiftool.org/"><code>exiftool</code></a> and discovered the original photo I sent
(<code>original_flower.heic</code>) contained <strong>145</strong> different metadata attributes<sup id="fnref:1"><a href="#fn:1">1</a></sup> including
privacy-sensitive info like the time I took the photo and the exact location I took
the photos (i.e. GPS Coordinates) while the updated version (<code>updated_flower.heic</code>)
had most of these fields removed except for essential fields.</p>

<p>Most phones automatically record and embed sensitive time and location information
in photos and users unkowingly share this info with third-parties while only intending
to share the visual content of the photo. It would be helpful if the built-in photo
apps warn you when you are sharing a photo that this information will be sent and allow you to quickly remove it before
sharing. Additionally, browsers themselves should consider scanning files on upload
for sensitive metadata content and warn the user before completing the upload or provide a quick way for the sensitive info to be stripped right there in the upload dialog. (This would never be exhasutive, but
doing it for photos probably covers a lot of the cases where users accidentally share
more than they intended.)</p>

<p>If you are comfortable with the commandline, you can view photo metadata via:</p>

<pre><code>$ exiftool /path/to/photo.png
</code></pre>

<p>and remove non-essential fields via:</p>

<pre><code>$ exiftool -all= /path/to/photo.png
</code></pre>

<p>However, it would be neat to see OSes and browsers automatically provide this
option before data changes hands from the user to a third-party.</p>


    </section></div>]]>
            </description>
            <link>https://theinternetbytes.com/2020/07/05/spot-the-difference-leaking-metadata-awareness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744222</guid>
            <pubDate>Mon, 06 Jul 2020 02:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CoreBGP – Plugging in to BGP]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23744167">thread link</a>) | @jordanwhited
<br/>
July 5, 2020 | https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/ | <a href="https://web.archive.org/web/*/https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<hr>
<p><img src="https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/cover.png" alt="cover"></p>
<hr>

<p><a href="https://tools.ietf.org/html/rfc4271" target="_blank">BGP</a> is one of many protocols that powers the Internet. Chances are you have heard of it, even if you don’t work in or around the computer networking space. If you aren’t familiar, I’ll try to provide some quick background:</p>
<ul>
<li>BGP is a <a href="https://en.wikipedia.org/wiki/Distance-vector_routing_protocol" target="_blank">distance-vector routing protocol</a> used to disseminate routing information.</li>
<li>A BGP speaker implements a <a href="https://en.wikipedia.org/wiki/Finite-state_machine" target="_blank">finite state machine</a> with 6 states:
<ul>
<li>Idle</li>
<li>Active</li>
<li>Connect</li>
<li>OpenSent</li>
<li>OpenConfirm</li>
<li>Established</li>
</ul>
</li>
<li>Inputs to the BGP FSM include messages, timer events, and administrative events.</li>
<li>Routing information is exchanged via UPDATE messages in the Established state.</li>
<li>BGP is extensible; speakers communicate their capabilities via OPEN messages.</li>
</ul>
<p>Expanding on that last bullet point, it’s difficult to summarize exactly how/where BGP is used due to its flexibility and extensibility. Various <a href="https://ietf.org/about/" target="_blank">IETF</a> Working Groups continue to publish BGP-related RFCs for a protocol that took shape in the early 90s. As the BGP landscape and application widens, we need software that enables us to keep up.</p>
<p>In this post I’ll provide some of my personal experience and history working with BGP, and introduce a new BGP library, <a href="https://github.com/jwhited/corebgp" target="_blank">CoreBGP</a>, which can be used to build the next generation of BGP-enabled applications.</p>

<p>In October of 2010 I attended my first <a href="https://www.nanog.org/" target="_blank">NANOG</a> meeting in Atlanta, GA after accidentally falling into the position of Network Operations Engineer at work. I worked for a modest-sized hosting provider at the time, and was intrigued with BGP. Upon arriving in Atlanta, I vaguely remember some confusion after telling a cab driver that the hotel I needed to be dropped at was on Peachtree St. I later learned that there are 71 streets in Atlanta with a variant of “Peachtree” in their name, according to <a href="https://en.wikipedia.org/wiki/Peachtree_Street#Nomenclature" target="_blank">Wikpedia</a>.</p>
<p>I got where I needed to go, eventually, and the first talk I attended was <a href="https://archive.nanog.org/meetings/nanog50/presentations/Sunday/NANOG50.Talk33.NANOG50-BGP-Techniques.pdf" target="_blank">BGP techniques for Internet Service Providers</a> by <a href="http://www.bgp4all.com.au/" target="_blank">Philip Smith</a>. Philip started with the basics before getting into the techniques used at ISPs. So many light bulbs went off for me during this talk. I have yet to see any other BGP presentation cover such a breadth of information but still do it in a way that is beginner-friendly, useful as a refresher for any expert, and just downright interesting.</p>
<p>Fast-forward 10 years and I’ve gained a fair share of experience operating networks that use BGP. In more recent years I’ve shifted to software engineering where I’ve had the opportunity to implement various BGP-enabled applications for network observability, data analytics, and SDN purposes.</p>
<p>Each time I started a new BGP-enabled app, I had to answer the following question – which existing BGP implementation should be its foundation?</p>

<p>Of the handful of open source BGP implementations out there, I’ve had hands-on experience with projects making use of:</p>
<ul>
<li><a href="https://bird.network.cz/" target="_blank">BIRD</a></li>
<li><a href="https://osrg.github.io/gobgp/" target="_blank">GoBGP</a></li>
<li><a href="https://www.opendaylight.org/what-we-do/odl-platform-overview" target="_blank">OpenDaylight</a></li>
<li><a href="https://www.quagga.net/" target="_blank">Quagga</a></li>
</ul>
<p>BIRD shines where a <a href="https://bird.network.cz/?get_doc&amp;v=20&amp;f=bird-5.html" target="_blank">rich policy language</a> is needed. GoBGP has a <a href="https://github.com/osrg/gobgp/tree/master/api" target="_blank">feature-rich gRPC API</a>, and can be embedded as a library. OpenDaylight’s BGP implementation is part of a larger SDN controller solution and has extensive support for <a href="https://docs.opendaylight.org/en/stable-oxygen/user-guide/bgpcep-guide/bgp/bgp-user-guide-linkstate-family.html" target="_blank">BGP-LS</a>. Quagga can reliably produce <a href="https://tools.ietf.org/html/rfc6396" target="_blank">MRT</a> dumps and has been around a long time, though I believe <a href="https://frrouting.org/" target="_blank">FRRouting</a> is now considered its successor.</p>
<p>These are all mature, established implementations. Some of them are in production at large ISPs, <a href="https://www.digitalocean.com/blog/scaling-droplet-public-networking/" target="_blank">Cloud Providers</a>, and <a href="https://joinup.ec.europa.eu/collection/open-source-observatory-osor/document/bird-manages-routing-worlds-largest-internet-exchanges-bird" target="_blank">Internet Exchange Points</a>. They are purpose-built and make various tradeoffs to suit their use cases (programming language, threading model, data structures, API, etc…).</p>
<p>But what if we are building something that doesn’t line up with the primary use cases of these widely used implementations? We may be locked in to decisions that are ultimately burdensome if we choose to build around them. Swapping in our own data structures for routing tables, or adding a new NLRI is non-trivial. Even if an implementation is intended to be embedded as library, it can still back us into a corner with resource consumption. There’s clearly a need to plug in or hook into specific parts of the BGP FSM, without inheriting decisions that went into a full-blown BGP daemon.</p>
<p>At the 27th IEEE International Conference On Network Protocols (ICNP), a group from the Université catholique de Louvain presented a paper on <code>The Case for Pluginized Routing Protocols</code>:</p>
<blockquote>
<p>Abstract—Routing protocols such as BGP and OSPF are key components of Internet Service Provider (ISP) networks. These protocols and the operator’s requirements evolve over time, but it often takes many years for network operators to convince their different router vendors and the IETF to extend routing protocols. Some network operators, notably in enterprise and datacenters have adopted Software Defined Networking (SDN) with its centralised control to be more agile. We propose a new approach to implement routing protocols that enables network operators to innovate while still using distributed routing protocols and thus keeping all their benefits compared to centralised routing approaches. We extend a routing protocol with a virtual machine that is capable of executing plugins. These plugins extend the protocol or modify its underlying algorithms through a simple API to meet the specific requirements of operators. We modify the OSPF and BGP implementations provided by FRRouting and demonstrate the applicability of our approach with several use cases.</p>
<p>— <!-- raw HTML omitted -->The Case for Pluginized Routing Protocols<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>In their paper they present a method for plugging into a previously mentioned open-source BGP implementation, FRRouting. Plugins exist at a function level, either prior to invocation (PRE), as a replacement (REPLACE), or just before returning (POST). Much of their BGP plugin focus is around the reception of messages, and decisions made shortly after:</p>
<blockquote>
<p>The BGP daemon is also extended similarly. We add insertion points on functions receiving BGP messages from neighbours, on filters and inside the decision process. We also expose specific functions to the plugins that are executed by the uBPF VM.</p>
<p>— <!-- raw HTML omitted -->The Case for Pluginized Routing Protocols<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>They take a clever approach with plugin sandboxing by leveraging a user space eBPF VM (<a href="https://github.com/iovisor/ubpf" target="_blank">uBPF</a>) linked to the FRRouting protocol implementation. Each plugin compiles to eBPF bytecode and runs inside of said VM. Plugins can be loaded and unloaded without impacting the primary protocol implementation. Using an eBPF VM also allowed them to utilise all the pre-existing Linux Kernel tooling.</p>
<p>I found this approach inspiring, but still not quite a match for my use cases:</p>
<ul>
<li>Plugins appear to be built around “incoming” events, or messages. What if I want to inject an UPDATE message to a peer irrespective of what FRRouting wants to send?</li>
<li>FRRouting was not built with this plugin model in mind. Changes/Updates to FRRouting will result in a maintenance headache for the VM hook points.</li>
<li>eBPF bytecode is typically compiled from C. Writing C can be time-consuming in comparison to more modern languages.</li>
<li>I need to be an FRRouting expert to do anything non-trivial.</li>
</ul>
<p>This experience and research led me to create CoreBGP, a BGP library that I could re-use across my BGP-enabled applications.</p>

<p>CoreBGP is a BGP library written in Go that implements the BGP FSM with an event-driven, pluggable model. It exposes an API that empowers the user to:</p>
<ul>
<li>send and validate OPEN message capabilities</li>
<li>handle “important” state transitions</li>
<li>handle incoming UPDATE messages</li>
<li>send outgoing UPDATE messages</li>
</ul>
<p>CoreBGP does not decode UPDATE messages (besides header validation), manage a routing table, or send its own UPDATE messages. These responsibilities are all passed down to the user. Therefore, the intended user is someone who wants that responsibility.</p>
<p>The primary building block of CoreBGP is a Plugin, defined by the following interface:</p>
<div><pre><code data-lang="go"><span>// Plugin is a BGP peer plugin.
</span><span></span><span>type</span> Plugin <span>interface</span> {
	<span>// GetCapabilities is fired when a peer's FSM is in the Connect state prior
</span><span></span>	<span>// to sending an Open message. The returned capabilities are included in the
</span><span></span>	<span>// Open message sent to the peer.
</span><span></span>	<span>GetCapabilities</span>(peer <span>*</span>PeerConfig) []<span>*</span>Capability

	<span>// OnOpenMessage is fired when an Open message is received from a peer
</span><span></span>	<span>// during the OpenSent state. Returning a non-nil Notification will cause it
</span><span></span>	<span>// to be sent to the peer and the FSM will transition to the Idle state.
</span><span></span>	<span>//
</span><span></span>	<span>// Per RFC5492 a BGP speaker should only send a Notification if a required
</span><span></span>	<span>// capability is missing; unknown or unsupported capabilities should be
</span><span></span>	<span>// ignored.
</span><span></span>	<span>OnOpenMessage</span>(peer <span>*</span>PeerConfig, capabilities []<span>*</span>Capability) <span>*</span>Notification

	<span>// OnEstablished is fired when a peer's FSM transitions to the Established
</span><span></span>	<span>// state. The returned UpdateMessageHandler will be fired when an Update
</span><span></span>	<span>// message is received from the peer.
</span><span></span>	<span>//
</span><span></span>	<span>// The provided writer can be used to send Update messages to the peer for
</span><span></span>	<span>// the lifetime of the FSM's current, established state. It should be
</span><span></span>	<span>// discarded once OnClose() fires.
</span><span></span>	<span>OnEstablished</span>(peer <span>*</span>PeerConfig, writer UpdateMessageWriter) UpdateMessageHandler

	<span>// OnClose is fired when a peer's FSM transitions out of the Established
</span><span></span>	<span>// state.
</span><span></span>	<span>OnClose</span>(peer <span>*</span>PeerConfig)
}
</code></pre></div><p>Here’s an example Plugin that logs when a peer enters/leaves an established state and when an UPDATE message is received:</p>
<div><pre><code data-lang="go"><span>type</span> plugin <span>struct</span>{}

<span>func</span> (p <span>*</span>plugin) <span>GetCapabilities</span>(c <span>*</span>corebgp.PeerConfig) []<span>*</span>corebgp.Capability {
	caps <span>:=</span> <span>make</span>([]<span>*</span>corebgp.Capability, <span>0</span>)
	<span>return</span> caps
}

<span>func</span> (p <span>*</span>plugin) <span>OnOpenMessage</span>(peer <span>*</span>corebgp.PeerConfig, capabilities []<span>*</span>corebgp.Capability) <span>*</span>corebgp.Notification {
	<span>return</span> <span>nil</span>
}

<span>func</span> (p <span>*</span>plugin) <span>OnEstablished</span>(peer <span>*</span>corebgp.PeerConfig, writer corebgp.UpdateMessageWriter) corebgp.UpdateMessageHandler {
	log.<span>Println</span>(<span>"peer established"</span>)
	<span>// send End-of-Rib
</span><span></span>	writer.<span>WriteUpdate</span>([]<span>byte</span>{<span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>})
	<span>return</span> p.handleUpdate
}

<span>func</span> (p <span>*</span>plugin) <span>OnClose</span>(peer <span>*</span>corebgp.PeerConfig) {
	log.<span>Println</span>(<span>"peer closed"</span>)
}

<span>func</span> (p <span>*</span>plugin) <span>handleUpdate</span>(peer <span>*</span>corebgp.PeerConfig, u []<span>byte</span>) <span>*</span>corebgp.Notification {
	log.<span>Printf</span>(<span>"got update message of len: %d"</span>, <span>len</span>(u))
	<span>return</span> <span>nil</span>
}
</code></pre></div><p>Plugins are attached to peers when they are added to the Server, which manages their lifetime:</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/">https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/</a></em></p>]]>
            </description>
            <link>https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744167</guid>
            <pubDate>Mon, 06 Jul 2020 02:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forecasting the Weather with Neural Odes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743860">thread link</a>) | @ChrisRackauckas
<br/>
July 5, 2020 | https://sebastiancallh.github.io/post/neural-ode-weather-forecast/ | <a href="https://web.archive.org/web/*/https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Weather forecasting is a tricky problem. Traditionally, it has been done
by manually modelling weather dynamics using differential equations, but this
approach is highly dependent on us getting the equations right. To
avoid this problem, we can
use machine learning to <a href="https://ai.googleblog.com/2020/03/a-neural-weather-model-for-eight-hour.html" target="_blank">directly predict the weather</a>, which
let’s us make predictions without modelling the dynamics. However, this
approach requires huge amounts of data to reach good performance.
Fortunately, there is a middle ground: What if we instead use machine
learning to model the <em>dynamics</em> of the weather?</p>

<p>Instead of trying to model how the weather will look in the next time step, what if
we instead model how the weather changes between time steps? More concretely: What if we
learn the <em>differential equations</em> that govern the change in weather?
In this blog article we are going to use <a href="https://julialang.org/" target="_blank">Julia</a> and the <a href="https://github.com/SciML" target="_blank">SciML</a> ecosystem
to do just that. We are going to see how neural ordinary differential
equations (neural ODEs) relate to “regular” networks, how to train
them and see how they can extrapolate time series from just a tiny
amount of training data.</p>

<h2 id="neural-odes-for-time-series">Neural ODEs for time series</h2>

<p>To start us off, let’s talk about how <a href="https://arxiv.org/abs/1806.07366" target="_blank">neural ODEs</a> are used for time
series modeling.
Recall that in a standard machine learning setting we
would assume a discrete set of observations \(y_0, y_1, \dots y_k, \)  \( y_i \in
\mathbb{R}^n \) at time points
\(t_0, t_1, \dots t_k, \), \(t_i \in \mathbb{R} \) to be related through some function \( y_i =
f(t_i; \theta) \) where \( \theta \) are learnable parameters.
However, in a neural ODE we consider a continuous setting and
instead assume that the <em>change</em> in \(y\) is governed by an ODE</p>

<p>\[ \frac{\delta y}{\delta t} = f(y; \theta). \]</p>

<p>The goal is hence not to learn the relationship between \(y\) and
\(t\), but the underlying dynamics of change. If the
dynamics are constant, this has very powerful generalisation capabilities.
It is helpful to think of this formulation as “a neural network inside
an ODE” or maybe “an ODE with learnable parameters”. In fact, the “forward pass”
through a neural ODE is exactly solving an <a href="https://en.wikipedia.org/wiki/Initial%5Fvalue%5Fproblem" target="_blank">initial value problem</a>,
where \( y(t_0) \) is the input features and we replace hand-crafted
equations with a neural network. This means that a <em>single</em>
forward pass gives us an entire trajectory in contrast to e.g. <a href="https://www.deeplearningbook.org/contents/rnn.html" target="_blank">RNN</a>s,
where each forward pass through the model gives a single prediction.</p>

<p>To make this more concrete,
consider a forward pass for \(y(t_0) =
1.0\) where the model has been trained on \(f^{\star}(x) =
\exp(1.5x)\). A forward pass means inputting \(y(t_0)\) and then using
an ODE solver to step forward in time. When the ODE solver
evaluates \(f\), it uses a neural network to predict \( \frac{\delta y}{\delta t} \).</p>

<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/neural-ode-explanation.gif" alt="Figure 1: Solving a simple initial value problem using a trained neural ODE. The only difference from a &amp;ldquo;regular&amp;rdquo; initial value problem is that the ODE is governed by a neural network instead of a hand-crafted set of equations. Since the network has already been trained, it accurately model dynamics."> <figcaption>
            <p>Figure 1: Solving a simple initial value problem using a trained neural ODE. The only difference from a “regular” initial value problem is that the ODE is governed by a neural network instead of a hand-crafted set of equations. Since the network has already been trained, it accurately model dynamics.</p>
        </figcaption>
</figure>


<p>So how do we train a network inside an ODE? As long as we can
take gradients of \(\theta\) with respect to the loss we can train it
using standard gradient based methods. Fortunately,
<code>DiffEqFlux</code> takes care of everything required to do this for us.
There are <a href="https://docs.sciml.ai/latest/analysis/sensitivity/#Sensitivity-Algorithms-1" target="_blank">several strategies</a> that can be specified to compute
gradients, and depending on
the problem you might prefer one over the other. However, for this article
the default <code>InterpolatingAdjoint</code> will be perfectly fine.</p>

<h3 id="model-implementation">Model implementation</h3>

<p>Now that we have a good conceptual idea of the model, let’s see it
in practice. We are going to use <a href="https://github.com/JuliaDiffEq/DiffEqFlux.jl" target="_blank">DiffEqFlux</a> to do the heavy lifting, which combines the ODE
solvers of <a href="https://github.com/SciML/DifferentialEquations.jl" target="_blank">DifferentialEquations.jl</a> with the differentiable
programming capabilities of <a href="https://github.com/FluxML/Flux.jl" target="_blank">Flux.jl</a>. Using <code>DiffEqFlux</code>, we can simply
construct a neural network to model \(f\) and plug that into a <code>NeuralODE</code>
object. The <code>NeuralODE</code> object itself has a few additional important
hyper-parameters though. Firstly, we have to <a href="https://docs.sciml.ai/stable/solvers/ode%5Fsolve/" target="_blank">specify an ODE solver</a> and a time span to
solve on. We will use the <code>Tsit5</code> solver, which uses an explicit
method. Secondly, the parameters <code>reltol</code> and <code>abstol</code> let us configure the solution
error tolerance to trade off accuracy and training time.
Recall that a forward pass means solving an initial value problem,
hence a lower tolerance gives a more accurate solution, and in turn
better gradient estimates. But of course, this requires
more function evaluations and are consequently slower to compute.</p>


<div><pre><code data-lang="julia"><span>using</span> DiffEqFlux

<span>function</span> neural_ode(t, data_dim; saveat <span>=</span> t)
    f <span>=</span> FastChain(FastDense(data_dim, <span>32</span>, swish),
		     FastDense(<span>32</span>, <span>64</span>, swish),
		     FastDense(<span>64</span>, <span>32</span>, swish),
		     FastDense(<span>32</span>, data_dim))

    node <span>=</span> NeuralODE(f, (minimum(t), maximum(t)), Tsit5(),
		     saveat <span>=</span> saveat, abstol <span>=</span> <span>1e-9</span>,
		     reltol <span>=</span> <span>1e-9</span>)
<span>end</span></code></pre></div>
<h2 id="the-delhi-dataset">The Delhi dataset</h2>

<p>The <a href="https://www.kaggle.com/sumanthvrao/daily-climate-time-series-data" target="_blank">dataset</a> we are going to use comprises daily
measurements of the climate in Delhi over several years.
The entire dataset is a single time series, where the last part is
set aside for testing. We will combine both the train and test set though,
since we won’t even need half of the training set to fit a good model.
Let’s load up the data and visualize it.</p>


<div><pre><code data-lang="julia"><span>using</span> DataFrames, CSV
delhi_train <span>=</span> CSV<span>.</span>read(<span>"data/timeseries/dehli-temp/DailyDelhiClimateTrain.csv"</span>)
delhi_test <span>=</span> CSV<span>.</span>read(<span>"data/timeseries/dehli-temp/DailyDelhiClimateTest.csv"</span>)
delhi <span>=</span> vcat(delhi_train, delhi_test)</code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-data-visualisation.svg" alt="Figure 2: Visualisation of the raw data. There is a clear seasonal trend, but there are some extreme outliers among the pressure measurements, which make it difficult to see any patterns."> <figcaption>
            <p>Figure 2: Visualisation of the raw data. There is a clear seasonal trend, but there are some extreme outliers among the pressure measurements, which make it difficult to see any patterns.</p>
        </figcaption>
</figure>


<p>Something is off with the air pressure measurements, indicated by the
extreme outliers after 2016. However, prior to 2016 the measurements
show a nice periodic behavior.</p>

<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/pressure-prior-2016.svg" alt="Figure 3: Zooming in on the pressure before 2016 reveal the same pleasant seasonal behavior as in the other measurements."> <figcaption>
            <p>Figure 3: Zooming in on the pressure before 2016 reveal the same pleasant seasonal behavior as in the other measurements.</p>
        </figcaption>
</figure>


<p>As an aside, if you read the dataset description it claims that the <code>Mean pressure</code>
variable is measured in <a href="https://en.wikipedia.org/wiki/Standard%5Fatmosphere%5F(unit)" target="_blank">atm</a>. Now, I have never been to Delhi, but I have my doubts since that would
mean that the city of Delhi suffers under a <em>thousand atmospheres
worth of pressure</em>. While such a phenomenon would be pretty cool and without a doubt get
scientists excited, I think it is more likely the units simply got mixed up, and the
actual unit pressure is millibar. Anyway, let’s prepare the data for model training.</p>

<h3 id="data-pre-processing">Data pre-processing</h3>

<p>All the metrics vary a lot from day to day, so to emphasis the overall
trend in the data we will average the observations into months.</p>


<div><pre><code data-lang="julia"><span>using</span> Statistics
<span>using</span> Base<span>.</span>Iterators<span>:</span> take, cycle

delhi[<span>:</span>,<span>:</span>year] <span>=</span> <span>Float64</span><span>.</span>(year<span>.</span>(delhi[<span>:</span>,<span>:</span>date]))
delhi[<span>:</span>,<span>:</span>month] <span>=</span> <span>Float64</span><span>.</span>(month<span>.</span>(delhi[<span>:</span>,<span>:</span>date]))
df_mean <span>=</span> by(delhi,
	     [<span>:</span>year, <span>:</span>month],
	     <span>:</span>meantemp <span>=&gt;</span> mean,
	     <span>:</span>humidity <span>=&gt;</span> mean,
	     <span>:</span>wind_speed <span>=&gt;</span> mean,
	     <span>:</span>meanpressure <span>=&gt;</span> mean)
rename!(df_mean, [<span>:</span>year, <span>:</span>month, <span>:</span>meantemp,
		  <span>:</span>humidity, <span>:</span>wind_speed, <span>:</span>meanpressure])

df_mean[<span>!</span>,<span>:</span>date] <span>.=</span> df_mean[<span>:</span>,<span>:</span>year] <span>.+</span> df_mean[<span>:</span>,<span>:</span>month] <span>./</span> <span>12</span>;</code></pre></div>
<p>In addition to averaging, we will normalize the data. The features are
normalized to have zero mean and unit variance, and the temporal
dimension is shifted to start at \(0\). Finally, we take the first
\(20\) observations as our training data and leave the remaining for testing.</p>


<div><pre><code data-lang="julia">t <span>=</span> df_mean[<span>:</span>, <span>:</span>date] <span>|&gt;</span>
    t <span>-&gt;</span> t <span>.-</span> minimum(t) <span>|&gt;</span>
    t <span>-&gt;</span> reshape(t, <span>1</span>, <span>:</span>)

y <span>=</span> df_mean[<span>:</span>, features] <span>|&gt;</span>
    y <span>-&gt;</span> <span>Matrix</span>(y)<span>'</span> <span>|&gt;</span>
    y <span>-&gt;</span> (y <span>.-</span> mean(y, dims <span>=</span> <span>2</span>)) <span>./</span> std(y, dims <span>=</span> <span>2</span>)

T <span>=</span> <span>20</span>
train_dates <span>=</span> df_mean[<span>1</span><span>:</span>T, <span>:</span>date]
test_dates <span>=</span> df_mean[T<span>+</span><span>1</span><span>:</span><span>end</span>, <span>:</span>date]
train_t, test_t <span>=</span> t[<span>1</span><span>:</span>T], t[T<span>:</span><span>end</span>]
train_y, test_y <span>=</span> y[<span>:</span>,<span>1</span><span>:</span>T], y[<span>:</span>,T<span>:</span><span>end</span>];</code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-data-split.svg" alt="Figure 4: The normalized data split into test and train. This is what the model will &amp;ldquo;see&amp;rdquo; during training and evaluation."> <figcaption>
            <p>Figure 4: The normalized data split into test and train. This is what the model will “see” during training and evaluation.</p>
        </figcaption>
</figure>


<p>Since we are training our model using gradient descent, we run the
risk of getting stuck into a bad local minima. This is particularly
true when training on a periodic time series, since the model can easily
settle with predicting the time series mean. Mini-batching can be used to mitigate
this, but for this problem we are going to employ a <a href="https://diffeqflux.sciml.ai/dev/examples/local%5Fminima/" target="_blank">different method</a>.
We are going to train on the first couple of observations until
convergence, then introduce a few more observations. Then train until
convergence, introduce some more observations, etc… By doing this, we
let the model adapt to local changes, resulting in a better fit. The
code below implements this training procedure.</p>


<div><pre><code data-lang="julia"><span>using</span> OrdinaryDiffEq, Flux, Optim, CUDA, Random
CUDA<span>.</span>allowscalar(<span>false</span>)

<span>function</span> train(node, t, y, y0, θ <span>=</span> <span>nothing</span>; maxiters, lr)
    predict(θ) <span>=</span> <span>Array</span>(node(y0, θ))
    loss(θ) <span>=</span> <span>begin</span>
	    ŷ <span>=</span> predict(θ)
	    l <span>=</span> Flux<span>.</span>mse(ŷ, y)
	    <span>return</span> l, ŷ
    <span>end</span>

    losses <span>=</span> []
    params <span>=</span> []
    cb(θ, l, ŷ) <span>=</span> <span>begin</span>
	    push!(losses, l)
	    push!(params, copy(θ))
	    <span>false</span>
    <span>end</span>

    θ <span>=</span> θ <span>==</span> <span>nothing</span> <span>?</span> node<span>.</span>p <span>:</span> θ
    res <span>=</span> DiffEqFlux<span>.</span>sciml_train(loss, θ, ADAMW(lr),
				 maxiters <span>=</span> maxiters,
				 cb <span>=</span> cb, save_best <span>=</span> <span>true</span>)
    <span>return</span> res<span>.</span>minimizer, losses, params
<span>end</span>

Random<span>.</span>seed!(<span>1</span>);
y0 <span>=</span> train_y[<span>:</span>,<span>1</span>]
maxiters <span>=</span> <span>200</span>
losses <span>=</span> []
θs <span>=</span> []
θ <span>=</span> <span>nothing</span>
num_obs <span>=</span> <span>4</span><span>:</span><span>4</span><span>:</span>length(train_t)
<span>for</span> k <span>in</span> num_obs
    node <span>=</span> neural_ode(train_t[<span>1</span><span>:</span>k], size(y, <span>1</span>))
    θ, loss, param <span>=</span> train(node, train_t[<span>1</span><span>:</span>k], train_y[<span>:</span>,<span>1</span><span>:</span>k], y0, θ,
			   maxiters <span>=</span> maxiters, lr <span>=</span> <span>5e-3</span>);
    losses <span>=</span> vcat(losses, loss)
    θs <span>=</span> vcat(θs, param)
<span>end</span></code></pre></div>
<figure>
    <img src="https://sebastiancallh.github.io/ox-hugo/delhi-training2.gif" alt="Figure 5: Animation of training through incrementally adding observations. When new observations are added the loss curve makes a sudden jump, but quickly settles down again. This process successfully avoids bad local minima and results in a very nice fit."> <figcaption>
            <p>Figure 5: Animation of training through incrementally adding observations. When new observations are added the loss curve makes a sudden jump, but quickly settles down again. This process successfully avoids bad local minima and results in a very nice fit.</p>
        </figcaption>
</figure>


<p>The model trains in a minute or two and fits nicely to the training data.
Of course, a more interesting question is whether the model
generalises or not. We solve the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">https://sebastiancallh.github.io/post/neural-ode-weather-forecast/</a></em></p>]]>
            </description>
            <link>https://sebastiancallh.github.io/post/neural-ode-weather-forecast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743860</guid>
            <pubDate>Mon, 06 Jul 2020 01:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What should we do about network-effect monopolies]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23743610">thread link</a>) | @dmnd
<br/>
July 5, 2020 | https://www.benkuhn.net/nwe/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/nwe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Many large companies today are software monopolies that give their product away for free to get monopoly status, then do <a href="https://github.com/uBlockOrigin/uBlock-issues/issues/338#issuecomment-496009417" target="_blank">the</a> <a href="http://www.fbpurity.com/news/important-news-facebooks-legal-team-have-told-me-i-am-banned-from-facebook-because-of-f-b-purity/" target="_blank">most</a> <a href="https://www.theverge.com/2019/6/28/19154220/grubhub-seamless-fake-restaurant-domain-names-commission-fees" target="_blank">horrible</a> <a href="https://www.nytimes.com/wirecutter/blog/amazon-counterfeit-fake-products/" target="_blank">things</a> <a href="https://www.theverge.com/2020/6/16/21293419/hey-apple-rejection-ios-app-store-dhh-gangsters-antitrust" target="_blank">once</a> <a href="https://www.polemicdigital.com/google-amp-go-to-hell/" target="_blank">they’ve</a> <a href="https://thetechnoskeptic.com/yelp-extortion-starring-role/" target="_blank">won</a>. (<a href="https://www.benkuhn.net/skinner/">Previously</a>, <a href="https://www.benkuhn.net/product/">previously</a>.) Can we do anything about this?</p><p>Unfortunately, “you’re the product” is a popular business model for a reason: businesses like Facebook would be really hard to support without them.</p><p>Facebook would be suicidal to charge its users money, because its entire selling point is that everyone uses it, and “everyone” <em>hates</em> paying money. In the US, Facebook makes over $25 per person on ads (<a href="https://www.statista.com/statistics/251328/facebooks-average-revenue-per-user-by-region/" target="_blank">source</a>). Can you imagine if instead of ads they tried to charge people $25 a year?</p><p>Even on the margin, anything that costs Facebook users also makes it less valuable for its remaining users—it’s a negative feedback loop. The same goes for any other site where users create value for other users, like Twitter or Craigslist or Yelp or Wikipedia. (It’s not an accident that these are some of the most stagnant popular websites!)</p><p>In fact, this is a fundamental problem with <a href="https://en.wikipedia.org/wiki/Network_effect" target="_blank">network effects</a> and low marginal costs. If a company wants to maintain a network effect, they need as many users as possible. If their marginal cost is low, then the easiest way to get users is to give the product away. To do that, they have to get paid by someone else. And when they start getting paid by someone else, they’ll inevitably start prioritizing that person’s interests.</p><p>Historically with other network-effect businesses, we’ve addressed this in a few different ways:</p><ul><li><p>regulation (e.g. local utilities)</p></li><li><p>breakups (e.g. Bell)</p></li><li><p>standardization and interoperability (e.g. email, the Web, cryptocurrency)</p></li></ul><p>So far for tech monopolies, people seem to be focused mostly on breakups—e.g. Facebook from Instagram/Whatsapp—but standardization seems to have produced much better outcomes in the past. (I like email and the Web a lot more than National Grid…) I’d be interested to see more exploration of that option!</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/nwe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743610</guid>
            <pubDate>Mon, 06 Jul 2020 00:46:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lorentz Transformation Derivation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743557">thread link</a>) | @keyboardman
<br/>
July 5, 2020 | https://leimao.github.io/blog/Lorentz-Transformation-Derivation/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Lorentz-Transformation-Derivation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In my previous blog post <a href="https://leimao.github.io/blog/Special-Relativity/">“Special Relativity Explained”</a>, I have explained special relativity and its several key consequences based on the Lorentz transformation.</p>



<p>Since I did not give a derivation for Lorentz transformation last time, in this blog post, I would like to present the derivations in detail.</p>

<h3 id="postulates-of-special-relativity">Postulates of Special Relativity</h3>

<p>Lorentz transformation was derived based on the following two postulates only.</p>

<h4 id="first-postulate-principle-of-relativity">First Postulate (Principle of Relativity)</h4>

<p>The laws of physics take the same form in all inertial frames of reference.</p>

<h4 id="second-postulate-invariance-of-light-speed">Second Postulate (Invariance of Light Speed)</h4>

<p>As measured in any inertial frame of reference, light is always propagated in empty space with a definite velocity $c$ that is independent of the state of motion of the emitting body. It is also equivalent to say, the speed of light in free space has the same value $c$ in all inertial frames of reference.</p>

<h3 id="derivation">Derivation</h3>

<p>In the spacetime, we have two reference frames, a reference frame $S$ and another reference frame $S’$ moving at a velocity $v$ with respect to it. So the two reference frames in this scenario are inertial reference frame. The coordinate axes in each reference frame are parallel, i.e., the $x$ and $x’$ axes are parallel, the $y$ and $y’$ axes are parallel, and the $z$ and $z’$ axes are parallel, and remain mutually perpendicular. We assume the relative motion is along the coincident $xx’$ axes. At $t = t’ = 0$, the origins of both coordinate systems are the same, $(x,y,z) = (x’,y’,z’) = (0, 0, 0)$.</p>



<p>An event in the time space could be observed and recorded by the observers on the two reference frames using spacetime coordinates $(t,x,y,z)$ in the reference frame $S$ and $(t’,x’,y’,z’)$ in the reference frame $S’$, respectively.</p>



<p>We want to set up the mapping between $(t,x,y,z)$ and $(t’,x’,y’,z’)$ for the same event.</p>

<h4 id="lorentz-transformation-is-linear-transformation">Lorentz Transformation is Linear Transformation</h4>

<p>We propose the spacetime transformation from the reference frame $S$ to the reference frame $S’$ to have the following form.</p>



<p>Note that we could eliminate the variables $y$ and $z$ in the functions $f_t$ and $f_x$ because of $y$ and $z$ are constants.</p>



<p>Now that we have proposed the form of transformation, there could be an infinite number of transformations that satisfied the form. What exactly the transformation is?</p>



<p>Suppose we have two events, one event has coordinates $(t_1,x_1,y_1,z_1)$ observed in the reference frame $S$ and coordinates $(t’_1,x’_1,y’_1,z’_1)$ observed in the reference frame $S’$, another one has coordinates $(t_2,x_2,y_2,z_2)$ observed in the reference frame $S$ and coordinates $(t’_2,x’_2,y’_2,z’_2)$ observed in the reference frame $S’$. Note that because reference frame $S’$ is moving along the $xx’$ axes, $y_1 = y’_1$, $z_1 = z’_1$, $y_2 = y’_2$, $z_2 = z’_2$.</p>



<p>Without loss of generality, we set $t_1 = t^{\prime}_1 = 0$, $x_1 = x^{\prime}_1 = 0$.</p>





<p>The two events, $(t_1,x_1,y_1,z_1)$ and $(t_2,x_2,y_2,z_2)$ observed in reference frame $S$, $(t’_1,x’_1,y’_1,z’_1)$ and $(t’_2,x’_2,y’_2,z’_2)$ observed in reference $S’$ have become equivalent to $(0,0,y_1,z_1)$ and $(\Delta t,\Delta x,y_2,z_2)$ observed in reference frame $S$, $(0,0,y’_1,z’_1)$ and $(\Delta t^{\prime},\Delta x^{\prime},y’_2,z’_2)$ observed in reference $S’$.</p>



<p>Based on the principle of relativity assumption, the transformation still holds. We have</p>



<p>and</p>



<p>This means the distances and time elapsed could also be transformed using the exact transformation for coordinates!</p>



<p>Ignoring uninteresting $y$ and $z$, we could equivalently write</p>





<p>We set a column vector $p = [t, x]^{\top}$ and this $p$ is a tensor in physics. It is also equivalent to write</p>



<p>This is also further equivalent to</p>



<p>In the next step, we would like to further show</p>



<p>Similarly suppose we have two events, one event has coordinates $(t_1,x_1,y_1,z_1)$ observed in the reference frame $S$ and coordinates $(t’_1,x’_1,y’_1,z’_1)$ observed in the reference frame $S’$, another one has coordinates $(t_2,x_2,y_2,z_2)$ observed in the reference frame $S$ and coordinates $(t’_2,x’_2,y’_2,z’_2)$ observed in the reference frame $S’$. In addition, in the reference frame it is observed that $t_2 = k t_1$ and $x_2 = k x_1$. Based on the principal of relativity assumption, $t’_2 = k t’_1$ and $x’_2 = k x’_1$.</p>



<p>Because</p>





<p>Therefore,</p>



<p>Because we have shown that</p>



<p>This is exactly the <a href="https://en.wikipedia.org/wiki/Linear_map#Definition_and_first_consequences">definition of a linear function</a> for function $f$ ($f_t$ and $f_x$), and note that this linear function $f$ has no bias term. Therefore, $f(p) = Mp$ for some matrix $M \in \mathbb{R}^{2 \times 2}$, and Lorentz transformation is a linear transformation.</p>

<h4 id="lorentz-transformation">Lorentz Transformation</h4>

<p>Because Lorentz transformation is a linear transformation, we could assume</p>



<p>Then the problem is very like the machine learning regression problem where we have to find the values for parameter $A$, $B$, $C$, and $D$. To solve this regression problem, we need some concrete data.</p>



<p>Because the reference frame $S’$ is moving at velocity $v$ with respect to the reference frame $S$. At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, we know $x = vt$ in the reference frame $S$ overlaps with the origin $x’ = 0$ in the reference frame $S’$. Note that $x = vt + 1$ in the reference frame $S$ does not necessary overlaps with $x’ = 1$ in the reference frame $S’$, although this is true in <a href="https://en.wikipedia.org/wiki/Galilean_transformation">Galilean transformations</a>.</p>



<p>We found the relationships between $C$ and $D$.</p>



<p>In addition, because the reference frame $S$ is moving at velocity $-v$ with respect to the reference frame $S’$. At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, we know $x = 0$ in the reference frame $S$ overlaps with the origin $x’ = -vt$ in the reference frame $S’$.</p>



<p>We cancel the variable $t’$ and get</p>



<p>So</p>



<p>This reduced the number of free parameters from four to two.</p>



<p>There could many different ways to derive the values for $B$ and $D$, but usually the simplest way is to directly do thought experiments using light. Here is one thought experiment, and there could be many others.</p>



<p>Suppose we shot a beam of light in the reference frame $S’$, At time $t$ in the reference frame $S$ and $t’$ in the reference frame $S’$, the event of the head of the light beam has $x = ct$ in the reference frame $S$ and reference $x’ = ct’$ frame $S’$, where $c$ is the light speed constant, based on the invariance of light speed assumption.</p>



<p>We cancel the variable $t’$ and get</p>



<p>We could then get the relationship between $B$ and $D$</p>



<p>Now the linear transformation has become</p>



<p>We are able to derive the inverse transformation as well.</p>



<p>That the reference frame $S’$ is moving at a velocity $v$ with respect to the reference frame $S$ is equivalent to that the reference frame $S$ is moving at a velocity $-v$ with respect to the reference frame $S’$. Based on the principle of relativity assumption, the linear transformation also has the same form, which is</p>



<p>This means that</p>



<p>Therefore,</p>



<p>We often use $\gamma$ to represent this factor, and this factor is called Lorentz factor.</p>



<p>The linear transformation is called Lorentz transformation.</p>



<p>We could further include the other two dimensions for $yy’$ and $zz’$.</p>



<p>Sometimes, to make the transformation matrix symmetric, we have the following equivalent form.</p>



<p>where</p>



<p>This concludes the derivation.</p>

<h3 id="conclusions">Conclusions</h3>

<p>The derivation of Lorentz transformation is mathematically simple. It only requires to use the basic linear algebra, or even just high school math. However, since the transformation is against our common sense, and the derivation is only based on the two “simple” postulates, we have to be aware not to introduce additional assumptions during derivation.</p>



<p>In high school physics class or college physics class for non-physics-major students, the lecturers would usually just present the Lorentz transformation and skip the derivation in the lectures for special relativity.</p>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Lorentz-Transformation-Derivation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743557</guid>
            <pubDate>Mon, 06 Jul 2020 00:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimum Viable Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743502">thread link</a>) | @shosti
<br/>
July 5, 2020 | https://eevans.co/blog/minimum-viable-kubernetes/ | <a href="https://web.archive.org/web/*/https://eevans.co/blog/minimum-viable-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section class="page">
  <article>
    <header>
      
    </header>

    
<p>
If you're reading this, chances are good that you've heard of Kubernetes. (If
you haven't, how exactly did you end up here?) But what actually is Kubernetes?
Is it <a href="https://kubernetes.io/">"Production-Grade Container Orchestration"</a>?  Is it a <a href="https://platform9.com/blog/kubernetes-as-a-cloud-native-operating-system-on-premises-too/">"Cloud-Native
Operating System"</a>? What do either of those phrases even mean?
</p>
<p>
To be completely honest, I'm not always 100% sure. But I think it's interesting
and informative to take a peek under the hood and see what Kubernetes actually
<em>does</em> under the many layers of abstraction and indirection. So just for fun,
let's see what the absolute bare minimum "Kubernetes cluster" actually looks
like. (It's going to be a lot more minimal than setting up Kubernetes <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">the hard
way</a>.)
</p>
<p>
I'm going to assume a basic familiarity with Kubernetes, Linux, and containers,
but nothing too advanced. By the way, this is all for learning/exploration
purposes, so don't run any of it in production!
</p>
<h2 id="headline-1">
Big Picture View
</h2>
<p>
Kubernetes has a lot of components and it's sometimes a bit difficult to keep
track of all of them. Here's what the overall architecture looks like according
to <a href="https://commons.wikimedia.org/w/index.php?curid=53571935">Wikipedia</a>:
</p>
<p>
<img src="https://eevans.co/blog/minimum-viable-kubernetes/k8s-arch.png" alt="k8s-arch.png" title="k8s-arch.png">
</p>
<p>
There are at least eight components listed in that diagram; we're going to be
ignoring most of them. I'm going to make the claim that the minimal thing you
could reasonably call Kubernetes consists of three essential components:
</p>
<ul>
<li>
<p>
kubelet
</p>
</li>
<li>
<p>
kube-apiserver (which depends on etcd as its database)
</p>
</li>
<li>
<p>
A container runtime (Docker in this case)
</p>
</li>
</ul>
<p>
Let's take a closer look at what each of these do, according to <a href="https://kubernetes.io/docs/concepts/overview/components/">the docs</a>. First,
<strong>kubelet</strong>:
</p>
<blockquote>
<p>
An agent that runs on each node in the cluster. It makes sure that containers
are running in a Pod.
</p>
</blockquote>
<p>
That sounds simple enough. What about the <strong>container runtime</strong>?
</p>
<blockquote>
<p>
The container runtime is the software that is responsible for running
containers.
</p>
</blockquote>
<p>
Tremendously informative. But if you're familiar with Docker, than you should
have a basic idea of what it does. (The details of the separation of concerns
between the container runtime and kubelet are actually a bit subtle, but I won't
be digging into them here.)
</p>
<p>
And the <strong>API server</strong>?
</p>
<blockquote>
<p>
The API server is a component of the Kubernetes control plane that exposes the
Kubernetes API. The API server is the front end for the Kubernetes control
plane.
</p>
</blockquote>
<p>
Anyone who's ever done anything with Kubernetes has interacted with the API,
either directly or through kubectl. It's the core of what makes Kubernetes
Kubernetes, the brain that turns the mountains of YAML we all know and love (?)
into running infrastructure. It seems obvious that we'll want to get it running
for our minimal setup.
</p>
<h2 id="headline-2">
Prerequisites If You Want to Follow Along
</h2>
<ul>
<li>
<p>
A Linux virtual or corporeal machine you're OK messing around with as
root (I'm using Ubuntu 18.04 on a VM).
</p>
</li>
<li>
<p>
That's it!
</p>
</li>
</ul>
<h2 id="headline-3">
The Boring Setup
</h2>
<p>
The machine we're using needs Docker installed. (I'm not going to dig too much
into how Docker and containers work; there are some <a href="https://blog.lizzie.io/linux-containers-in-500-loc.html">amazing rabbit holes</a> already
out there if you're interested.) Let's just install it using <code>apt</code>:
</p>
<div>
<div><pre><code data-lang="text">$ sudo apt install docker.io
$ sudo systemctl start docker</code></pre></div>
</div>
<p>
Next we'll need to get the Kubernetes binaries. We actually only need kubelet to
bootstrap our "cluster", since we can use kubelet to run the other server
components. We'll also grab kubectl to interact with our cluster once it's up
and running.
</p>
<div>
<div><pre><code data-lang="text">$ curl -L https://dl.k8s.io/v1.18.5/kubernetes-server-linux-amd64.tar.gz &gt; server.tar.gz
$ tar xzvf server.tar.gz
$ cp kubernetes/server/bin/kubelet .
$ cp kubernetes/server/bin/kubectl .
$ ./kubelet --version
Kubernetes v1.18.5</code></pre></div>
</div>
<h2 id="headline-4">
Off To The Races
</h2>
<p>
What happens when we try to run kubelet?
</p>
<div>
<div><pre><code data-lang="text">$ ./kubelet
F0609 04:03:29.105194    4583 server.go:254] mkdir /var/lib/kubelet: permission denied</code></pre></div>
</div>
<p>
kubelet needs to run as root; fair enough, since it's tasked with managing the
entire node. Let's see what the CLI options look like:
</p>
<div>
<div><pre><code data-lang="text">$ ./kubelet -h
&lt;far too much output to copy here&gt;
$ ./kubelet -h | wc -l
284</code></pre></div>
</div>
<p>
Holy cow, that's a lot of options! Thankfully we'll only need a couple of them
for our setup. Here's an option that looks kind of interesting:
</p>
<blockquote>
<p>
<code>--pod-manifest-path</code> string
</p>
<p>
Path to the directory containing static pod files to run, or the path to a
single static pod file. Files starting with dots will be ignored. (DEPRECATED:
This parameter should be set via the config file specified by the Kubelet's
–config flag. See
<a href="https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/">https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/</a> for
more information.)
</p>
</blockquote>
<p>
This option allows us to run <a href="https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/">static pods</a>, which are pods that aren't managed
through the Kubernetes API. Static pods aren't that common in day-to-day
Kubernetes usage but are very useful for bootstrapping clusters, which is
exactly what we're trying to do here. We're going to ignore the loud deprecation
warning (again, don't run this in prod!) and see if we can run a pod.
</p>
<p>
First we'll make a static pod directory and run kubelet:
</p>
<div>
<div><pre><code data-lang="text">$ mkdir pods
$ sudo ./kubelet --pod-manifest-path=pods</code></pre></div>
</div>
<p>
Then, in another terminal/tmux window/whatever, we'll make a pod manifest:
</p>
<div>
<div><pre><code data-lang="text">$ cat &lt;&lt;EOF &gt; pods/hello.yaml
apiVersion: v1
kind: Pod
metadata:
  name: hello
spec:
  containers:
  - image: busybox
    name: hello
    command: ["echo", "hello world!"]
EOF</code></pre></div>
</div>
<p>
kubelet starts spitting out some warnings; other than that it anti-climatically
appears that nothing really happened. But not so! Let's check Docker:
</p>
<div>
<div><pre><code data-lang="text">$ sudo docker ps -a
CONTAINER ID        IMAGE                  COMMAND                 CREATED             STATUS                      PORTS               NAMES
8c8a35e26663        busybox                "echo 'hello world!'"   36 seconds ago      Exited (0) 36 seconds ago                       k8s_hello_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_4
68f670c3c85f        k8s.gcr.io/pause:3.2   "/pause"                2 minutes ago       Up 2 minutes                                    k8s_POD_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_0
$ sudo docker logs k8s_hello_hello-mink8s_default_ab61ef0307c6e0dee2ab05dc1ff94812_4
hello world!</code></pre></div>
</div>
<p>
kubelet read the pod manifest and instructed Docker to start a couple of
containers according to our specification. (If you're wondering about that
"pause" container, it's Kubernetes hackery that's used to reap zombie processes
—see <a href="https://www.ianlewis.org/en/almighty-pause-container">this blog post</a> for the gory details.) kubelet will run our <code>busybox</code>
container with our command and restart it ad infinitum until the static pod is
removed.
</p>
<p>
Let's congratulate ourselves: we've just figured out one of the world's most
convoluted ways of printing out text to the terminal!
</p>
<h2 id="headline-5">
Getting etcd running
</h2>
<p>
Our eventual goal is to run the Kubernetes API, but in order to do that we'll
need <a href="https://etcd.io/">etcd</a> running first. A static pod ought to fit the bill. Let's run a minimal
etcd cluster by putting the following in a file in the <code>pods</code> directory
(e.g. <code>pods/etcd.yaml</code>):
</p>
<div>
<div><pre><code data-lang="yaml"><span>apiVersion</span>: v1
<span>kind</span>: Pod
<span>metadata</span>:
  <span>name</span>: etcd
  <span>namespace</span>: kube-system
<span>spec</span>:
  <span>containers</span>:
  - <span>name</span>: etcd
    <span>command</span>:
    - etcd
    - --data-dir=/var/lib/etcd
    <span>image</span>: k8s.gcr.io/etcd:<span>3.4.3-0</span>
    <span>volumeMounts</span>:
    - <span>mountPath</span>: /var/lib/etcd
      <span>name</span>: etcd-data
  <span>hostNetwork</span>: <span>true</span>
  <span>volumes</span>:
  - <span>hostPath</span>:
      <span>path</span>: /var/lib/etcd
      <span>type</span>: DirectoryOrCreate
    <span>name</span>: etcd-data</code></pre></div>
</div>
<p>
If you've ever worked with Kubernetes, this kind of YAML file should look
familiar. There are only two slightly unusual things worth noting:
</p>
<ul>
<li>
<p>
We mounted the host's <code>/var/lib/etcd</code> to the pod so that the etcd data will
survive restarts (if we didn't do this the cluster state would get wiped every
time the pod restarted, which would be a drag even for a minimal Kubernetes
setup).
</p>
</li>
<li>
<p>
We set <code>hostNetwork: true</code> which, unsurprisingly, sets up the etcd pod to use
the host network instead of the pod-internal network (this will make it easier
for the API server to find the etcd cluster).
</p>
</li>
</ul>
<p>
Some quick sanity checks show that etcd is indeed listening on localhost and
writing to disk:
</p>
<div>
<div><pre><code data-lang="text">$ curl localhost:2379/version
{"etcdserver":"3.4.3","etcdcluster":"3.4.0"}
$ sudo tree /var/lib/etcd/
/var/lib/etcd/
└── member
    ├── snap
    │&nbsp;&nbsp; └── db
    └── wal
        ├── 0.tmp
        └── 0000000000000000-0000000000000000.wal</code></pre></div>
</div>
<h2 id="headline-6">
Running the API server
</h2>
<p>
Getting the Kubernetes API server running is even easier. The only CLI flag we
have to pass is <code>--etcd-servers</code>, which does what you'd expect:
</p>
<div>
<div><pre><code data-lang="yaml"><span>apiVersion</span>: v1
<span>kind</span>: Pod
<span>metadata</span>:
  <span>name</span>: kube-apiserver
  <span>namespace</span>: kube-system
<span>spec</span>:
  <span>containers</span>:
  - <span>name</span>: kube-apiserver
    <span>command</span>:
    - kube-apiserver
    - --etcd-servers=http://<span>127.0.0.1</span>:<span>2379</span>
    <span>image</span>: k8s.gcr.io/kube-apiserver:v1<span>.18.5</span>
  <span>hostNetwork</span>: <span>true</span></code></pre></div>
</div>
<p>
Put that YAML file in the <code>pods</code> directory and the API server will start. Some
quick <code>curl</code> ing shows that the Kubernetes API is listening on port 8080 with
completely open access—no authentication necessary!
</p>
<div>
<div><pre><code data-lang="text">$ curl localhost:8080/healthz
ok
$ curl localhost:8080/api/v1/pods
{
  "kind": "PodList",
  "apiVersion": "v1",
  "metadata": {
    "selfLink": "/api/v1/pods",
    "resourceVersion": "59"
  },
  "items": []
}</code></pre></div>
</div>
<p>
(Again, don't run this setup in production! I was a bit surprised that the
default setup is so insecure, but I assume it's to make development and testing
easier.)
</p>
<p>
And, as a nice surprise, kubectl works out of the box with no extra
configuration!
</p>
<div>
<div><pre><code data-lang="text">$ ./kubectl version
Client Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.5", GitCommit:"e6503f8d8f769ace2f338794c914a96fc335df0f", GitTreeState:"clean", BuildDate:"2020-06-26T03:47:41Z", GoVersion:"go1.13.9", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.5", GitCommit:"e6503f8d8f769ace2f338794c914a96fc335df0f", GitTreeState:"clean", BuildDate:"2020-06-26T03:39:24Z", GoVersion:"go1.13.9", Compiler:"gc", Platform:"linux/amd64"}
$ ./kubectl get pod
No resources found in default namespace.</code></pre></div>
</div>
<p>
Easy, right?
</p>
<h2 id="headline-7">
A Problem
</h2>
<p>
But digging a bit deeper, something seems amiss:
</p>
<div>
<div><pre><code data-lang="text">$ ./kubectl get pod -n kube-system
No resources found in kube-system namespace.</code></pre></div>
</div>
<p></p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eevans.co/blog/minimum-viable-kubernetes/">https://eevans.co/blog/minimum-viable-kubernetes/</a></em></p>]]>
            </description>
            <link>https://eevans.co/blog/minimum-viable-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743502</guid>
            <pubDate>Mon, 06 Jul 2020 00:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transducers and Effects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743381">thread link</a>) | @lioeters
<br/>
July 5, 2020 | http://mikeinnes.github.io/2020/06/12/transducers.html | <a href="https://web.archive.org/web/*/http://mikeinnes.github.io/2020/06/12/transducers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  <p>Clojure has introduced a very interesting idea called ‘transducers’, which decouple sequence transformations (mapping, filtering etc) from sequence implementations like vectors, lazy lists and channels. Transducers and their benefits are well-covered elsewhere, but I’d like to explore some tradeoffs, and compare an alternative (and extremely hypothetical) design based on a staple of the functional programming world, effect handlers.</p>

<p>There are many useful operations that we can carry out on <em>sequences</em>, like mapping, filtering, interleaving, partitioning and so on. Ideally, we’d like to apply these tools to any sequence of values, including list data structures and strings but also channels and observables. Unfortunately, it’s common to have to <a href="https://github.com/ReactiveX/RxClojure">reimplement</a> each function we want for new sequences.</p>

<p>Abstracting over sequences is difficult, and requires a significantly more powerful approach than the usual polymorphism and data abstraction. To see why, imagine a somewhat-general <code>map</code> using <code>empty</code> and <code>conj</code>.</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>map</span><span>'</span><span> </span><span>[</span><span>f</span><span> </span><span>xs</span><span>]</span><span>
  </span><span>(</span><span>loop</span><span> </span><span>[</span><span>xs</span><span> </span><span>xs</span><span>
         </span><span>ys</span><span> </span><span>(</span><span>empty</span><span> </span><span>xs</span><span>)]</span><span>
    </span><span>(</span><span>if</span><span> </span><span>(</span><span>empty?</span><span> </span><span>xs</span><span>)</span><span>
      </span><span>ys</span><span>
      </span><span>(</span><span>recur</span><span> </span><span>(</span><span>rest</span><span> </span><span>xs</span><span>)</span><span>
             </span><span>(</span><span>conj</span><span> </span><span>ys</span><span> </span><span>(</span><span>f</span><span> </span><span>(</span><span>first</span><span> </span><span>xs</span><span>)))))))</span><span>
</span></code></pre></div></div>

<p>Unfortunately, aside from the fact that this has the wrong ordering for some data structures, and could only work with channels if you have language-level coroutines (which Clojure, thanks to the JVM, doesn’t), this definition of <code>map</code> simply can’t be used to produce lazy sequences. Here’s how we implement the lazy version:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>map</span><span>'</span><span> </span><span>[</span><span>f</span><span> </span><span>xs</span><span>]</span><span>
  </span><span>(</span><span>lazy-seq</span><span>
   </span><span>(</span><span>when</span><span> </span><span>(</span><span>not</span><span> </span><span>(</span><span>empty?</span><span> </span><span>xs</span><span>))</span><span>
     </span><span>(</span><span>cons</span><span> </span><span>(</span><span>f</span><span> </span><span>(</span><span>first</span><span> </span><span>xs</span><span>))</span><span> </span><span>(</span><span>map</span><span>'</span><span> </span><span>f</span><span> </span><span>(</span><span>rest</span><span> </span><span>xs</span><span>))))))</span><span>
</span></code></pre></div></div>

<p>The problem is that the basic structure of the code has changed, from an iterative (tail recursive) form ideal for eager data structures to the context-preserving recursion needed for laziness. Other constructs, like channels, might require yet different organisation, eg as a state machine.</p>

<p>Clojure resolves this with two insights:</p>

<ol>
  <li>A <em>process</em> (eg working with lists or channels in some way) can usually be seen as a kind of <code>fold</code>, with an appropriate <em>step function</em> of the form <code>result –&gt; input –&gt; result</code>.</li>
  <li><code>map</code>, <code>filter</code> and friends extend processes by <em>wrapping</em> the step function, eg <code>step' = (result, input) –&gt; step(result, f(input))</code> to map <code>f</code> alongside whatever was happening before.</li>
</ol>

<p>Processes can therefore accept step-wrapping functions (transducers) to alter their behaviour. The upshot is that you can create and compose objects representing mapping, filtering etc and use them generically on channels, sequences, vectors and so on.</p>

<p>To solve our <code>map</code> problem, we can write data structure production and lazy-sequence production (or channel production, or …) as a single ‘transducible process’. Functions like <code>map</code> and <code>filter</code> become transducers which we can hand to these processes to modify their behaviour. Thus we can write <code>map</code> only once, yet use it with many sequence types.</p>

<h2 id="a-sequence-of-caveats">A sequence of caveats</h2>

<p>The problem that transducers solve is an important one; transducers themselves are elegant in conception and clean to work with as a user. However, if you look into how transducers are put together under the hood – or try to implement one yourself – you might find them less easy on the eyes.</p>

<div><div><pre><code><span>;; Guess what this function does for your next lockdown quiz</span><span>
</span><span>(</span><span>defn</span><span> </span><span>take</span><span> </span><span>[</span><span>n</span><span>]</span><span>
  </span><span>(</span><span>fn</span><span> </span><span>[</span><span>rf</span><span>]</span><span>
    </span><span>(</span><span>let</span><span> </span><span>[</span><span>nv</span><span> </span><span>(</span><span>volatile!</span><span> </span><span>n</span><span>)]</span><span>
      </span><span>(</span><span>fn</span><span>
        </span><span>([]</span><span> </span><span>(</span><span>rf</span><span>))</span><span>
        </span><span>([</span><span>result</span><span>]</span><span> </span><span>(</span><span>rf</span><span> </span><span>result</span><span>))</span><span>
        </span><span>([</span><span>result</span><span> </span><span>input</span><span>]</span><span>
          </span><span>(</span><span>let</span><span> </span><span>[</span><span>n</span><span> </span><span>@</span><span>nv</span><span>
                </span><span>nn</span><span> </span><span>(</span><span>vswap!</span><span> </span><span>nv</span><span> </span><span>dec</span><span>)</span><span>
                </span><span>result</span><span> </span><span>(</span><span>if</span><span> </span><span>(</span><span>pos?</span><span> </span><span>n</span><span>)</span><span>
                          </span><span>(</span><span>rf</span><span> </span><span>result</span><span> </span><span>input</span><span>)</span><span>
                          </span><span>result</span><span>)]</span><span>
            </span><span>(</span><span>if</span><span> </span><span>(</span><span>not</span><span> </span><span>(</span><span>pos?</span><span> </span><span>nn</span><span>))</span><span>
              </span><span>(</span><span>ensure-reduced</span><span> </span><span>result</span><span>)</span><span>
              </span><span>result</span><span>)))))))</span><span>
</span></code></pre></div></div>

<p>The elegance of transducers is somewhat eroded as we try to make them more general, and even then they have significant limitations. In particular:</p>

<ul>
  <li>Transducers like <code>dedupe</code> and <code>take</code> create stateful step functions, which adds extra constraints needed for correctness.</li>
  <li>Others like <code>take-while</code> need an explicit cancellation mechanism, and you want to be careful not to double-wrap the cancellation. Handling initialisation and completion adds yet more burden to implementations.</li>
  <li>Transducible processes themselves <a href="https://clojure.org/reference/transducers#_creating_transducible_processes">can be hard to implement</a>, mainly because of the above concerns, but it’s also because some things (eg lazy sequences) <a href="https://github.com/clojure/clojure/blob/30a36cbe0ef936e57ddba238b7fa6d58ee1cbdce/src/jvm/clojure/lang/TransformerIterator.java">aren’t naturally built with <code>fold</code></a>.</li>
  <li>There is no support for functions that take or produce multiple sequences (<code>interleave</code>, <code>concat</code>, <code>split-with</code> etc).</li>
</ul>

<h2 id="an-effective-alternative">An effective alternative</h2>

<p>Consider the following notation for <code>mapping</code> and <code>filtering</code>, inspired by <a href="https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/sequences">F#’s list comprehensions</a>. I’m using a hypothetical C/Koka-like syntax here but all my examples could be converted to simple Clojure equivalents (<code>loop</code>/<code>recur</code> and explicit passing of variables, <code>for</code>, etc).</p>

<div><div><pre><code><span>fn</span> <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>yield</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>filtering</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
      <span>yield</span><span>(</span><span>x</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As a notation, this seems abstract enough. There’s no dependence on how we get values (<code>xs</code> could be anything and iteration can use a generic protocol). It avoids expressing how we build an output sequence, or even whether we do, just what values appear in it. F# lets us omit the <code>yield</code> (eg <code>for x in xs –&gt; x^2</code>), which makes things look more like a traditional list comprehension, but for clarity we’ll keep them explicit.</p>

<p>The key idea is to make this code run via <em>effect handlers</em> (implemented in F#, with lexical scope, as ‘computation expressions’<sup id="fnref:1"><a href="#fn:1">1</a></sup>), which let us plug in a definition of <code>yield</code>. Effect handlers have their origin in strongly-typed functional programming but they are really quite lisp-y, and can be thought of as resumable exceptions.<sup id="fnref:2"><a href="#fn:2">2</a></sup></p>

<p>At the simplest, we can just create an empty array and append to it each time a value is <code>yield</code>ed:</p>

<div><div><pre><code><span>ys</span> <span>=</span> <span>[]</span>
<span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>ys</span> <span>=</span> <span>append</span><span>(</span><span>ys</span><span>,</span> <span>x</span><span>)</span>
  <span>resume</span><span>()</span>
<span>}</span>
<span>return</span> <span>ys</span>
</code></pre></div></div>

<p><code>yield(x)</code> is a bit like throwing an exception, except that after handling it we can jump back to where we were with <code>resume</code>.</p>

<p>Instead of building a list, we can do a map-reduce without any intermediate collection being constructed.</p>

<div><div><pre><code><span>sum</span> <span>=</span> <span>0</span>
<span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>sum</span> <span>+=</span> <span>x</span>
  <span>resume</span><span>()</span>
<span>}</span>
<span>return</span> <span>sum</span>
</code></pre></div></div>

<p>This can compile down to the tight loop we want for simple data structures.<sup id="fnref:3"><a href="#fn:3">3</a></sup> But what’s going to be really mind-bending is how straightforwardly we can turn our loop into a lazy sequence.</p>

<div><div><pre><code><span>ys</span> <span>=</span> <span>handle</span> <span>{</span>
  <span>mapping</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span>
  <span>nil</span>
<span>}</span> <span>with</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>{</span>
  <span>cons</span><span>(</span><span>x</span><span>,</span> <span>LazySeq</span><span>(</span><span>resume</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>What’s happening here is that <code>yield</code> doesn’t call <code>resume</code>, so the loop gets paused the first time it is called, and the whole block returns a <code>cons</code>. <code>resume</code> will get called when we try to access the tail of <code>ys</code>, restarting the loop. The loop hits the next <code>yield</code>, suspends, and returns a new <code>cons</code> with item two and a new <code>resume</code>, and so on. Eventually the <code>mapping</code> will finish and <code>resume</code> returns <code>nil</code>, completing the list.<sup id="fnref:4"><a href="#fn:4">4</a></sup></p>

<p><code>mapping</code> here takes on the role of transducer, expressing what <code>map</code> does abstractly without nailing down the details. Effect handlers then allow us to instantiate <code>mapping</code> as a set of concrete processes, and potentially very different ones depending on the context. In all we can achieve the same core goal in a wonderfully expressive way.</p>

<p>With this in mind, we can blend Clojure’s <code>into</code> and F#’s <code>seq</code> into one list comprehension construct which picks the appropriate <code>yield</code> handler for the kind of sequence we are building.</p>

<div><div><pre><code><span>fn</span> <span>map</span><span>(</span><span>f</span><span>,</span> <span>xs</span><span>)</span> <span>{</span>
  <span>into</span> <span>empty</span><span>(</span><span>xs</span><span>)</span> <span>{</span>
    <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
      <span>yield</span><span>(</span><span>f</span><span>(</span><span>x</span><span>))</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This <code>map</code> can behave appropriately, and generate efficient code, whether <code>xs</code> is a vector, persistent list, lazy list, string, channel, observable, promise or whatever, which solves our generic implementation problem. And we can compose pipelines just like we did before with <code>(-&gt;&gt; xs (map f) (filter g))</code>.<sup id="fnref:5"><a href="#fn:5">5</a></sup></p>

<p>As F# has shown, this way of defining sequence transformations is really expressive. If we want to cancel we can just break out of the loop (or the loop/recur equivalent).</p>

<div><div><pre><code><span>// Take while</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
    <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>break</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>If we need state, a local variable is enough, since the loop has its own scope.</p>

<div><div><pre><code><span>// Dedupe</span>
<span>last</span> <span>=</span> <span>nil</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>if</span> <span>x</span> <span>!=</span> <span>last</span> <span>{</span>
    <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>}</span>
  <span>last</span> <span>=</span> <span>x</span>
<span>}</span>
</code></pre></div></div>

<p>Concatenating sequences is easy, because we can happily have multiple loops, and <code>interleave</code> is easy because we can put <code>yield</code> wherever we want. We can even use nested loops, and I’d argue that the intent is clearer in these than even the simplest transducer implementations. They strike close to the essence of the transformation, without any incidental complexity.</p>

<div><div><pre><code><span>// Concat</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span> <span>yield</span><span>(</span><span>x</span><span>)</span> <span>}</span>
<span>for</span> <span>y</span> <span>in</span> <span>ys</span> <span>{</span> <span>yield</span><span>(</span><span>y</span><span>)</span> <span>}</span>
<span>// Interleave</span>
<span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>zip</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span> <span>{</span>
  <span>yield</span><span>(</span><span>x</span><span>)</span>
  <span>yield</span><span>(</span><span>y</span><span>)</span>
<span>}</span>
<span>// Cartesian Product</span>
<span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
  <span>for</span> <span>y</span> <span>in</span> <span>ys</span> <span>{</span>
    <span>yield</span><span>((</span><span>x</span><span>,</span> <span>y</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We can even imagine supporting multiple output sequences, so long as there’s some way of identifying them, for example to partition a channel into matching and non-matching events.</p>

<div><div><pre><code><span>// Split-with</span>
<span>into</span> <span>empty</span><span>(</span><span>xs</span><span>)</span> <span>-&gt;</span> <span>(</span><span>trues</span><span>,</span> <span>falses</span><span>)</span> <span>{</span>
  <span>for</span> <span>x</span> <span>in</span> <span>xs</span> <span>{</span>
    <span>if</span> <span>f</span><span>(</span><span>x</span><span>)</span> <span>{</span>
      <span>yield</span><span>(</span><span>trues</span><span>,</span> <span>x</span><span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>yield</span><span>(</span><span>falses</span><span>,</span> <span>x</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<h2 id="asynchronous-evolution">Asynchronous Evolution</h2>

<p>The above examples, taking things from one bunch of sequences and putting them into another bunch, might begin to look familiar. That’s because the Shyamalan-esque twist to this story is that Clojure <em>already had this abstraction all along</em>, via the <a href="https://github.com/clojure/core.async">core.async</a> library. The relationship of <code>go</code> blocks to our generalised list comprehensions is that</p>

<ol>
  <li>Instead of iterating <code>for x in xs</code> we have an explicit <code>&lt;!</code> (take) operation, which is itself an effect; it suspends the code and falls back to a handler, which can <code>resume</code> with a value when one is available.</li>
  <li><code>yield</code> is replaced by the <code>&gt;!</code> (put) effect.</li>
  <li>Both <code>&gt;!</code> and <code>&lt;!</code> are linked to identities (channels), which means multiple inputs and outputs are supported.</li>
</ol>

<p>So we can draw a clear path from list comprehensions to async blocks, two features which might not seem all that related at first, by generalising in some ways and specialising in others. This …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://mikeinnes.github.io/2020/06/12/transducers.html">http://mikeinnes.github.io/2020/06/12/transducers.html</a></em></p>]]>
            </description>
            <link>http://mikeinnes.github.io/2020/06/12/transducers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743381</guid>
            <pubDate>Mon, 06 Jul 2020 00:10:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust for JavaScript Developers – Functions and Control Flow]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 73 (<a href="https://news.ycombinator.com/item?id=23743363">thread link</a>) | @rkwz
<br/>
July 5, 2020 | http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/ | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is the third part in a series about introducing the Rust language to JavaScript developers. Here are the past chapters:</p>
<ol>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-tooling-ecosystem-overview/">Tooling Ecosystem Overview</a></li>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-variables-and-data-types/">Variables and Data Types</a></li>
</ol>
<h2 id="Functions"><a href="#Functions" title="Functions"></a>Functions</h2><p>Rust’s function syntax is pretty much similar to the one in JavaScript.</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> income <span>=</span> <span>100</span><span>;</span>
  <span>let</span> tax <span>=</span> <span>calculate_tax</span><span>(</span>income<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> tax<span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>calculate_tax</span><span>(</span>income<span>:</span> i32<span>)</span> <span>-&gt;</span> i32 <span>{</span>
  <span>return</span> income <span>*</span> <span>90</span> <span>/</span> <span>100</span><span>;</span>
<span>}</span></code></pre>
<p>The only difference you might see above is the type annotations for arguments and return values.</p>
<p>The <code>return</code> keyword can be skipped and it’s very common to see code without an explicit return. If you’re returning implicitly, make sure to remove the semicolon from that line. The above function can be refactored as:</p>
<pre><code>fn main() {
  let income = 100;
  let tax = calculate_tax(income);
  println!("{}", tax);
}

fn calculate_tax(income: i32) -&gt; i32 {
<span>- return income * 90 / 100;</span>
<span>+ income * 90 / 100</span>
}</code></pre>
<h2 id="Arrow-Functions"><a href="#Arrow-Functions" title="Arrow Functions"></a>Arrow Functions</h2><p>Arrow functions are a popular feature in modern JavaScript - they allow us to write functional code in a concise way.</p>
<p>Rust has something similar and they are called “Closures”. The name might be a bit confusing and would require getting used to because in JavaScript, closures can be created using both normal and arrow functions.</p>
<p>Rust’s closure syntax is very similar to JavaScript’s arrow functions:</p>
<p><strong>Without arguments:</strong></p>
<pre><code>
<span>let</span> greet <span>=</span> <span>(</span><span>)</span> <span>=</span><span>&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>

<span>greet</span><span>(</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> greet <span>=</span> <span>||</span> <span>println!</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>

<span>greet</span><span>(</span><span>)</span><span>;</span> </code></pre>
<p><strong>With arguments:</strong></p>
<pre><code>
<span>let</span> greet <span>=</span> <span>(</span>msg<span>)</span> <span>=</span><span>&gt;</span> console<span>.</span><span>log</span><span>(</span>msg<span>)</span><span>;</span>

<span>greet</span><span>(</span><span>"good morning!"</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> greet <span>=</span> <span>|</span>msg<span>:</span> <span>&amp;</span>str<span>|</span> <span>println!</span><span>(</span><span>"{}"</span><span>,</span> msg<span>)</span><span>;</span>

<span>greet</span><span>(</span><span>"good morning!"</span><span>)</span><span>;</span> </code></pre>
<p><strong>Returning values:</strong></p>
<pre><code>
<span>let</span> add <span>=</span> <span>(</span>a<span>,</span> b<span>)</span> <span>=</span><span>&gt;</span> a <span>+</span> b<span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> add <span>=</span> <span><span>|</span>a<span>:</span> i32<span>,</span> b<span>:</span> i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span> a <span>+</span> b <span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<p><strong>Multiline:</strong></p>
<pre><code>
<span>let</span> add <span>=</span> <span>(</span>a<span>,</span> b<span>)</span> <span>=</span><span>&gt;</span> <span>{</span>
  <span>let</span> sum <span>=</span> a <span>+</span> b<span>;</span>
  <span>return</span> sum<span>;</span>
<span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> add <span>=</span> <span><span>|</span>a<span>:</span> i32<span>,</span> b<span>:</span> i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span>
  <span>let</span> sum <span>=</span> a <span>+</span> b<span>;</span>
  <span>return</span> sum<span>;</span>
<span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<p>Here’s a cheatsheet:<br><img src="http://www.sheshbabu.com/images/2020-rust-for-javascript-developers-3/image-2.png" alt=""></p>
<p>Closures don’t need the type annotations most of the time, but I’ve added them here for clarity.</p>
<h2 id="If-Else"><a href="#If-Else" title="If Else"></a>If Else</h2><pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> income <span>=</span> <span>100</span><span>;</span>
  <span>let</span> tax <span>=</span> <span>calculate_tax</span><span>(</span>income<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> tax<span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>calculate_tax</span><span>(</span>income<span>:</span> i32<span>)</span> <span>-&gt;</span> i32 <span>{</span>
  <span>if</span> income <span>&lt;</span> <span>10</span> <span>{</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span> <span>else</span> <span>if</span> income <span>&gt;=</span> <span>10</span> <span>&amp;&amp;</span> income <span>&lt;</span> <span>50</span> <span>{</span>
    <span>return</span> <span>20</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>return</span> <span>50</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<h2 id="Loops"><a href="#Loops" title="Loops"></a>Loops</h2><p>While loops:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> count <span>=</span> <span>0</span><span>;</span>

  <span>while</span> count <span>&lt;</span> <span>10</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> count<span>)</span><span>;</span>
    count <span>+=</span> <span>1</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Normal <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for" target="_blank" rel="noopener">for loops</a> don’t exist in Rust, we need to use <code>while</code> or <code>for..in</code> loops. <code>for..in</code> loops are similar to the <code>for..of</code> loops in JavaScript and they loop over an iterator.</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>for</span> n <span>in</span> numbers<span>.</span><span>iter</span><span>(</span><span>)</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> n<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Notice that we’re not iterating directly over the array but instead using the <code>iter</code> method of the array.</p>
<p>We can also loop over <a href="https://doc.rust-lang.org/reference/expressions/range-expr.html" target="_blank" rel="noopener">ranges</a>:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>for</span> n <span>in</span> <span>1</span><span>..</span><span>5</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> n<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<h2 id="Iterators"><a href="#Iterators" title="Iterators"></a>Iterators</h2><p>In JavaScript, we can use array methods like map/filter/reduce/etc instead of <code>for</code> loops to perform calculations or transformations on an array.</p>
<p>For example, here we take an array of numbers, double them and filter out the elements that are less than 10:</p>
<pre><code><span>function</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>let</span> double <span>=</span> <span>(</span>n<span>)</span> <span>=</span><span>&gt;</span> n <span>*</span> <span>2</span><span>;</span>
  <span>let</span> less_than_ten <span>=</span> <span>(</span>n<span>)</span> <span>=</span><span>&gt;</span> n <span>&lt;</span> <span>10</span><span>;</span>

  <span>let</span> result <span>=</span> numbers<span>.</span><span>map</span><span>(</span>double<span>)</span><span>.</span><span>filter</span><span>(</span>less_than_ten<span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>result<span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>In Rust, we can’t directly use map/filter/etc over vectors, we need to follow these steps:</p>
<ol>
<li>Convert the vector into an iterator using <code>iter</code>, <code>into_iter</code> or <code>iter_mut</code> methods</li>
<li>Chain <code>adapters</code> such as map/filter/etc on the iterator</li>
<li>Finally convert the iterator back to a vector using <code>consumers</code> such as <code>collect</code>, <code>find</code>, <code>sum</code> etc</li>
</ol>
<p>Here’s the equivalent Rust code:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>vec!</span><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>let</span> double <span>=</span> <span><span>|</span>n<span>:</span> <span>&amp;</span>i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span> n <span>*</span> <span>2</span> <span>}</span><span>;</span>
  <span>let</span> less_than_10 <span>=</span> <span><span>|</span>n<span>:</span> <span>&amp;</span>i32<span>|</span></span> <span>-&gt;</span> bool <span>{</span> <span>*</span>n <span>&lt;</span> <span>10</span> <span>}</span><span>;</span>

  <span>let</span> result<span>:</span> Vec<span>&lt;</span>i32<span>&gt;</span> <span>=</span> numbers<span>.</span><span>iter</span><span>(</span><span>)</span><span>.</span><span>map</span><span>(</span>double<span>)</span><span>.</span><span>filter</span><span>(</span>less_than_10<span>)</span><span>.</span><span>collect</span><span>(</span><span>)</span><span>;</span>

  <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> result<span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>You should be able to understand most of the code above but you might notice few things off here:</p>
<ul>
<li>The usage of <code>&amp;</code> and <code>*</code> in the closure</li>
<li>The <code>Vec&lt;i32&gt;</code> type annotation for the <code>result</code> variable</li>
</ul>
<p>The <code>&amp;</code> is the reference operator and the <code>*</code> is the dereference operator. The <code>iter</code> method instead of copying the elements in the vector, it passes them as references to the next adapter in the chain. This is why we use <code>&amp;i32</code> in the map’s closure (double). This closure returns <code>i32</code> but <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter" target="_blank" rel="noopener">filter</a> calls its closure (less_than_10) with reference so that’s why we need to use <code>&amp;i32</code> again. To dereference the argument, we use the <code>*</code> operator. We’ll cover this in more detail in future chapters.</p>
<p>Regarding <code>Vec&lt;i32&gt;</code>, so far we haven’t added type annotations to variables as Rust can infer the types automatically, but for <code>collect</code>, we need to be explicitly tell Rust that we expect a <code>Vec&lt;i32&gt;</code> output.</p>
<p>Aside from map and filter, there are ton of other <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html" target="_blank" rel="noopener">useful adapters</a> that we can use in iterators.</p>
<p>Thanks for reading! Feel free to follow me in <a href="https://twitter.com/sheshbabu" target="_blank" rel="noopener">Twitter</a> for updates :)</p>
</div></div>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743363</guid>
            <pubDate>Mon, 06 Jul 2020 00:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I’m Writing a Book on Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23743218">thread link</a>) | @gedigi
<br/>
July 5, 2020 | https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/ | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I’ve now been writing a book on <strong>applied cryptography</strong> for a year and a half.
I’m nearing the end of my journey, as I have one last ambitious chapter left to write: next-generation cryptography (a chapter that I’ll use to talk about cryptography that will become more and more practical: post-quantum cryptography, homomorphic encryption, multi-party computation, and zk-SNARKs).</p>
<p>I’ve been asked multiple times <strong>why write a new book about cryptography?</strong> and <strong>why should I read your book?</strong>.
To answer this, you have to understand when it all started…</p>
<h2>Diagrams are everything</h2>
<p>Today if you want to learn about almost anything, you just google it.
Yet, for cryptography, and depending on what you're looking for, resources can be quite lacking.</p>
<p>It all started a long time ago.
For a class, I had to implement a <a href="https://www.paulkocher.com/doc/DifferentialPowerAnalysis.pdf">differential power analysis attack</a>, a breakthrough in cryptanalysis as it was the first side-channel attack to be published.
A differential power analysis uses the power consumption of a device during an encryption to leak its private key.
At the time, I realized that great papers could convey great ideas with very little emphasis on understanding.
I remember banging my head against the wall trying to figure out what the author of the white paper was trying to say.
Worse, I couldn’t find a good resource that explained the paper.
So I banged my head a bit more, and finally I got it.
And then I thought I would help others.
So I drew some diagrams, animated them, and recorded myself going over them.
That was <a href="https://www.youtube.com/watch?v=gbqNCgVcXsM">my first screencast</a>.</p>
<p>This first step in education was enough to make me want to do more.
I started making more of these videos, and started writing more articles about cryptography on this blog (today totaling more than 500 articles).</p>
<p><img alt="we want to know" src="https://www.cryptologie.net/upload/we_want_to_know.png"></p>
<p>I realized early that diagrams were extremely helpful to understand complicated concepts, and that strangely most resources in the field shied away from them.</p>
<p>For example, anyone in cryptography who thinks about AES-CBC would immediately think about the following wikipedia diagram:</p>
<p><img alt="aes cbc" src="https://www.cryptologie.net/upload/600px-CBC_encryption.svg_.png"></p>
<p>So here I was, trying to explain everything I learned, and thinking hard about what sorts of simple diagrams could easily convey these complex ideas.
That’s when I started thinking about a book, years and years before <a href="https://manning.com/">Manning Publications</a> would reach out to me with a book deal.</p>
<h2>The applied cryptographer curriculum</h2>
<p> I hadn’t started cryptography due to a long-life passion.
I had finished a bachelor in theoretical mathematics and didn’t know what was next for me.
I had also been programming my whole life, and I wanted to reconcile the two.
Naturally, I got curious about cryptography, which seemed to have the best of both world, and started reading the different books at my disposal.
I quickly discovered my life's calling.</p>
<p>Some things were annoying me though. In particular, the long introductions that would start with history.
I was only interested in the technicalities, and always had been.
I swore to myself, if I ever wrote a book about cryptography, I would not write a single line on Vigenère ciphers, Caesar ciphers, and others.</p>
<p>And so after applying to the masters of Cryptography at the university of Bordeaux, and obtaining a degree in the subject, I thought I was ready for the world.
Little did I know.
What I thought was a very applied degree actually lacked a lot on the real world protocols I was about to attack.
I had spent a lot of time learning about the mathematics of elliptic curves, but nothing about how they were used in cryptographic algorithms.
I had learned about LFSRs, and ElGamal, and DES, and a series of other cryptographic primitives that I would never see again.</p>
<p>When I started working in the industry at Matasano, which then became NCC Group, my first gig was to audit <a href="https://www.openssl.org/">OpenSSL</a> (the most popular TLS implementation).
Oh boy, did it hurt my brain.
I remember coming back home every day with a strong headache.
What a clusterfuck of a library.
I had no idea at the time that I would years later become a co-author of TLS 1.3.</p>
<p><img alt="sign" src="https://www.cryptologie.net/upload/7._Note_that_digital_signatures_are_specified_with_a_hash_function,_allowing_you_to_.png"></p>
<p>But at that point I was already thinking: this is what I should have learned in school.
The knowledge I’m getting now is what would have been useful to prepare me for the real world.
After all, I was now a security practitioner specialized in cryptography.
I was reviewing real-world cryptographic applications.
I was doing the job that one would wish they had after finishing a cryptography degree.
I implemented, verified, used, and advised on what cryptographic algorithms to use.</p>
<p>This is the reason I’m the first reader of the book I’m writing.
This is what I would have written to my past self in order to prepare me for the real world.</p>
<h2>The use of cryptography is where most of the bugs are</h2>
<p>My consulting job led me to audit many real world cryptographic applications like the <a href="https://www.nccgroup.com/us/about-us/newsroom-and-events/blog/2015/may/openssl-audit/">OpenSSL</a>, the <a href="https://www.nccgroup.trust/globalassets/our-research/us/public-reports/2018/final_public_report_ncc_group_google_encryptedbackup_2018-10-10_v1.0.pdf">encrypted backup system of Google</a>, the <a href="https://blog.cloudflare.com/ncc-groups-cryptography-services-audit-of-tls-1-3/">TLS 1.3 implementation of Cloudflare</a>, the <a href="https://letsencrypt.org/2015/04/14/ncc-group-audit.html">certificate authority protocol of Let’s Encrypt</a>, the <a href="https://www.nccgroup.com/us/our-research/zcash-overwinter-consensus-and-sapling-cryptography-review/">sapling protocol of Zcash</a>, the <a href="https://blog.nucypher.com/security-audits--round-1--3/">threshold proxy re-encryption scheme of NuCypher</a> and dozens and dozens of other real-world cryptographic applications that I unfortunately cannot mention publicly.</p>
<p>Early in my job, I was tasked to audit the custom protocol a big corporation (that I can’t name) had written to encrypt their communications.
It turns out that, they were signing everything but the ephemeral keys, which completely broke the whole protocol (as one could have easily replaced the ephemeral keys).
A rookie mistake from anyone with some experience with secure transport protocols, but something that was missed by people who thought they were experienced enough to roll their own crypto.
I remember explaining the vulnerability at the end of the engagement, and a room full of engineers turning silent for a good 30 seconds.</p>
<p>This story repeated itself many times during my career.
There was this time where while auditing a cryptocurrency for another client, I found a way to forge transactions from already existing ones (due to some ambiguity of what was being signed).
Looking at TLS implementations for another client, I found some subtle ways to break an RSA implementation, which in turned transformed into a white paper (with one of the inventor of RSA) leading to a number of <a href="https://eprint.iacr.org/2018/1173">Common Vulnerabilities and Exposures (CVEs) reported to a dozen of open source projects</a>.
More recently, reading about Matrix as part of writing my book, I realized that their authentication protocol was completely broken, <a href="https://matrix.org/security-disclosure-policy/">leading to a complete break of their end-to-end encryption</a>.</p>
<p><img alt="comic" src="https://www.cryptologie.net/upload/HEY_MERE_S_AN.png"></p>
<p>There’s so many details that can unfortunately collapse under you, when making use of cryptography.
At that point, I knew I had to write something about it.
This is why my book contains many of these anecdotes.</p>
<p>As part of the job, I would review cryptography libraries and applications in a multitude of programming languages.
I discovered bugs (for example <a href="https://cryptologie.net/article/347/my-first-cve-o/?utm_content=buffer5c408&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">CVE-2016-3959</a> in Golang’s standard library), I researched ways that libraries could fool you into misusing them (for example see my paper <a href="https://eprint.iacr.org/2016/644">How to Backdoor Diffie-Hellman</a>), and I advised on what libraries to use.
Developers never knew what library to use, and I always found the answer to be tricky.</p>
<p>I went on to invent the <a href="https://discocrypto.com/">disco protocol</a>, and wrote a fully-featured cryptographic library in less than 1,000 lines of code in several languages.
Disco only relied on two cryptographic primitives: the permutation of SHA-3 and curve25519.
Yes, from only these two things in 1,000 lines of code a developer could do any type of authenticated key exchange, signatures, encryption, MACs, hashing, key derivation, etc.
This gave me a unique perspective as to what a good cryptographic library was supposed to be.</p>
<p>I wanted my book to contain these kind of practical insights.
So naturally, the different chapters contain examples on how to do crypto in different programming languages, using well-respected cryptographic libraries.</p>
<h2>A need for a new book?</h2>
<p>As I was giving <a href="https://www.blackhat.com/us-17/training/beyond-the-beast-a-broad-survey-of-crypto-vulnerabilities.html">one of my annual cryptography training at Black Hat</a>, one student came to me and asked if I could recommend a good book or online course on cryptography.
I remember advising the student to read <a href="http://toc.cryptobook.us/">the book from Boneh &amp; Shoup</a> and <a href="https://crypto.stanford.edu/~dabo/courses/OnlineCrypto/">Cryptography I from Boneh on Coursera</a>.</p>
<p>The student told me “<em>Ah, I tried, it’s too theoretical!</em>”.
This answer stayed with me.
I disagreed at first, but slowly realized that they were right.
Most of these resources were pretty heavy in math, and most developers interacting with cryptography don’t want to deal with math.
 What else was there for them?
The other two somewhat respected resources at the time were Applied Cryptography and Cryptography Engineering (both from Schneier).
But these books were starting to be quite outdated.
Applied Cryptography spent 4 chapters on block ciphers, with a whole chapter on cipher modes of operation but none on authenticated encryption.
Cryptography Engineering had a single mention of elliptic curve cryptography (in a footnote).</p>
<p>On the other hand, many of my videos or blog posts were becoming good primary references for some cryptographic concepts.</p>
<p><strong>I knew I could do something special</strong>.</p>
<p>Gradually, many of my students started becoming interested in cryptocurrencies, asking more and more questions on the subject.
At the same time, I started to audit more and more cryptocurrency applications.
I finally moved to a job at Facebook to work on <a href="https://libra.org/">Libra</a>.
Cryptocurrency was now one of the hottest field to work on, mixing a multitude of extremely interesting cryptographic primitives that so far had seen no real-world use case (zero knowledge proofs, aggregated signatures, threshold cryptography, multi-party computations, consensus protocols, cryptographic accumulators, verifiable random functions, verifiable delay functions, ... the list goes on)</p>
<p><strong>I was now in a unique position</strong>.</p>
<p>I knew I could write something that would tell students, developers, consultants, security engineers, and others, what modern applied cryptography was all about.</p>
<p><img alt="book" src="https://www.cryptologie.net/upload/needs_to_send_a_let.png"></p>
<p>This was going to be a book with very little …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/">https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/</a></em></p>]]>
            </description>
            <link>https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743218</guid>
            <pubDate>Sun, 05 Jul 2020 23:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary: Designing Data-Intensive Applications by Martin Kleppmann]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23743185">thread link</a>) | @hoanhan101
<br/>
July 5, 2020 | https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps | <a href="https://web.archive.org/web/*/https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Principles and practicalities of data systems and how to build data-intensive applications.</p><time datetime="2020-07-05T00:00:00-04:00"> July 5, 2020 · 30 mins read · <a href="https://hoanhan101.github.io/category/System-design-notes">System design notes</a><hr> </time><h2 id="i-4-fundamental-ideas-that-we-need-in-order-to-design-data-intensive-applications">I. 4 fundamental ideas that we need in order to design data-intensive applications.</h2><ul><li>Reliable, scalable, maintainable applications.<ul><li>Reliability means continuing to work correctly, even when things go wrong. Common faults and preventions include:<ul><li>Hardware faults: hard disks crash, blackout, incorrect network configuration,…<ul><li>Add redundancy to individual hardware components to reduce the failure rate.</li><li>As long as we can restore a backup onto a new machine quickly, the downtime is not fatal.</li></ul></li><li>Software faults: bug, out of shared resources, unresponsive service, cascading failure,…<ul><li>There’s no quick solution other than thorough testing, measuring, monitoring, analyzing.</li></ul></li><li>Human errors: design error, configuration error,…<ul><li>Enforce good design, good practice and training.</li><li>Decouple the places where people make the most mistake.</li><li>Automate testing: unit test, integration test, end-to-end test.</li><li>Allow quick recovery rollback strategy.</li><li>Set up details monitoring</li></ul></li></ul></li><li>Scalability describes a system’s ability to cope with increased load.<ul><li>Describing load: requests per second, read/write radio, active users, cache hit rate,…</li><li>Describing performance:<ul><li>When you increase a load parameter, keep system resources unchanged, how is performance affected?</li><li>When you increase a load parameter, how much do you increase the resources if you want to keep performance unchanged?</li></ul></li><li>Approaches for coping with load:<ul><li>Scaling up (vertical scaling): move to a more powerful machine.</li><li>Scaling out (horizontal scaling): distribute the load across different machines.</li></ul></li></ul></li><li>Maintainability focuses on 3 design principles:<ul><li>Operability: make it easy for operation teams to keep the system running smoothly.<ul><li>Provide monitoring system health.</li><li>Support for automation and integration tools.</li><li>Have Good documentation.</li></ul></li><li>Simplicity: make it easy for new engineers to understand the system.<ul><li>Provide good abstraction layers that allow us to extract parts of a large system into well-defined, reusable components.</li></ul></li><li>Evolvability: make it easy for engineers to make changes.<ul><li>Follow agile approach.</li></ul></li></ul></li></ul></li><li>Data models and query languages.<ul><li>Data started out being represented as one big tree, though it wasn’t good for representing many-to-many relationships models, so the relational model was invented.</li><li>However, some applications didn’t fit well into the relational model, non-relational NoSQL was born:<ul><li>Document database: self-contained documents, rare relationships between one model and another.</li><li>Graph database: anything is related to everything.</li></ul></li></ul></li><li>Storage and retrieval.<ul><li>Data structres that power your database:<ul><li>Hash indexes:<ul><li>Basically key-value pairs where each key is mapped to a byte offset in the data file.</li><li>Can also split it into smaller chunks/segments for easy storing.</li><li>Even though it’s easy to understand and implement, it has memory constrains that the hash table must fit in memory. Also range queries are not efficient since hashed keys are not put next to each other.</li></ul></li><li>Sorted String Table (SSTable) and Log-Structured Merge-Tree (LSM-trees):<ul><li>SSTable maintains a list of key-value pairs that is sorted by key.</li><li>The table can also be split into smaller segments and merging is simple as it is sorted.</li><li>Maintaining a sorted structure on disk is possible, though keeping it in memory is easy as we can use a tree data structure such as Red-Black trees or AVL trees (memtable).</li><li>If the database crashes, memtable might be lost though we can keep a separate log for it, inspired by LSM-tree indexing structure.</li></ul></li><li>B-trees:<ul><li>Like SSTables, B-trees keep key-value pairs sorted by key, which allows efficient key-value lookups and range queries.</li><li>Instead of breaking down the database into variable-size segments and always writing sequentially, B-trees break into fixed-size blocks/pages and reading/writing one page at a time.</li><li>Every modification is first written to a write-ahead log (WAL) so that the index can be restored to a consistent state after a crash.</li></ul></li></ul></li><li>Transactional processing or analytic?<ul><li>The basic database access pattern is similar to processing business transaction (create, read, update, delete record), as known as online transaction processing (OLTP).</li><li>Since OLTP are expected to be highly available as they’re critical to the operation of the business, they’re reluctant to let business analysts run ad-hoc analytic queries.</li><li>A data warehouse is a separate database that analysts can query without affecting OLTP operations.<ul><li>Data is extracted from OLTP databases, transformed into an analysis-friendly schema, cleaned up, and then loaded into the data warehouse.</li><li>A big advantage of using a separate data warehouse is that the data warehouse can be optimized for analytic access patterns.</li><li>2 popular schemas that data are stored in are star schema, snowflake schema.</li></ul></li></ul></li><li>Column-oriented storage:<ul><li>In most OLTP databases, storage is laid out in a row-oriented fashion: all the values from one row of a table are stored next to each other. In the column-oriented storage, all the values are stored from each column together instead.</li><li>Since the sequences of values for each column are often look repetitive (distinct values are small), they often lend themselves well to compression.</li></ul></li><li>Aggregation:<ul><li>Since data warehouse queries often involve an aggregate function, such as COUNT, SUM, AVG, MIN or MAX, we can cache these aggregated values that are used often.</li><li>One way of creating such a cache is a materialized view, while data cube is a special case.</li></ul></li></ul></li><li>Encoding and evolution.<ul><li>Formats for encoding data.<ul><li>Many languages come with built-in support for encoding in-memory objects to byte sequences though they are not used because it’s language-specific and don’t show good performance.</li><li>JSON, XML are widely known, supported due to the fact that they are simple, can be used by many languages and have built-in support for web browser. However, there are a lot of ambiguity around the encoding of numbers and they also don’t support binary encoding (compact, efficient encoding). Hence the development of MessagePack, BSON, BJSON, and so on.</li><li>Thrift and Protocol Buffers are binary encoding libraries that require a schema for any data that is encoded, that is clearly defined forward and backward compatibility semantics. They come with a code generation tool that produces classes that implement the schema in various programming languages.</li><li>There’s is also a binary encoding library Avro that is good for processing large files as in Hadoop’s use cases.</li></ul></li><li>Modes of data flow (from one process to anther).<ul><li>Databases: the process writing to the database encodes the data, and the process reading from the database decodes it.</li><li>Calls to services, REST and RPC (gRPC): client encodes a request, server decodes the request and encodes a response, and client finally decodes the response.</li><li>Asynchronous message-passing (RabbitMQ, Apache Kafka): nodes send each other messages that are encoded by the sender and decoded by the recipient.</li></ul></li></ul></li></ul><h2 id="ii-replication-partitioningsharding-transactions-and-what-it-means-to-achieve-consistency-and-consensus-in-a-distributed-system">II. Replication, partitioning/sharding, transactions, and what it means to achieve consistency and consensus in a distributed system.</h2><ul><li>Replication.<ul><li>Why would you want to replicate data?<ul><li>Reduce latency by keeping data geographically close to users.</li><li>Increase availability.</li><li>Increase throughput.</li></ul></li><li>2 types of algorithms are leader-based replication and leaderless replication.</li><li>Leader-based replication:<ul><li>Workflow:<ul><li>One of the replicas is designed as the leader while others are followers.</li><li>Client must send write request to the leader though can send read request to both leader and followers.</li><li>After the leader writes data to its local storage, it sends the changes to all of its followers so that they can self apply accordingly.</li></ul></li><li>An important detail of a replicated system is whether the replication happens synchronously or asynchronously.<ul><li>Even though the advantage of synchronous replication is that followers is that the follower is guaranteed to have an up-to-date data, if the synchronous follower doesn’t respond, the write cannot be processed, thus the leader must block all writes and wait until one is available again.</li><li>It is impractical for all followers to be synchronous so leader-based replication is often configured to be completely asynchronous.</li></ul></li><li>From time to time, you need to set up new followers to increase the number of replicas, or to replace failed nodes. This can usually be done without downtime by maintaining a consistent snapshot of the leader’s database.</li><li>If the follower goes down, it can recover quite easily from its logs that it has received from the leader. Later when it’s able to talk to the leader again, it can request all the missing data and catch up to the leader.</li><li>If the leader goes down, a possible approach is failover: one of the followers needs to be promoted to be the new leader using a consensus algorithm, clients and followers need to be configured to talk to the new leader. However, failover can go wrong as well (two leaders, choosing the right timeout before the leader is declared dead,…) as there are no easy solutions to these.</li><li>Different implementation of replication logs:<ul><li>Statement-based replication: the leader logs every write request that it executes, and sends that statement log to its followers. Even though it seems reasonable, non-deterministic function, such as NOW() to get current date and time, is likely to generate a different value on each replica.</li><li>Write-ahead log (WAL) shipping: similar to B-tree’s approach where every modification is first written to a WAL, besides writing the log to disk, the leader also sends it to its followers so that they can build a copy of the exact same data structures as found on the leader.</li><li>Logical log replication: allow the replication log to be decoupled from the storage engine by using different log formats.</li><li>Trigger-based replication: register a trigger to only replicate subset of the data, or from one kind of database to another and so on.</li></ul></li><li>Replication lags:<ul><li>If the user view the data shortly after making the write, new data may have not yet reach the replica. In this case, we need …</li></ul></li></ul></li></ul></li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps">https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps</a></em></p>]]>
            </description>
            <link>https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743185</guid>
            <pubDate>Sun, 05 Jul 2020 23:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Letters to a New Developer, the Book]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23743072">thread link</a>) | @mooreds
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/the-book/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/the-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
		<div id="content">

	<div id="primary">
		<main id="main" role="main">

			
				
<article id="post-7718" class="page">
			<!-- .entry-header -->
	<div>
		
<p>“Letters To a New Developer” is now a book! Here’s the cover:</p>



<figure><img data-attachment-id="7720" data-permalink="https://letterstoanewdeveloper.com/letters-to-a-new-developer/" data-orig-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png" data-orig-size="827,1181" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="letters-to-a-new-developer" data-image-description="" data-medium-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=210" data-large-file="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717" src="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717" alt="" srcset="https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=717 717w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=105 105w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=210 210w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png?w=768 768w, https://letterstoanewdeveloper.files.wordpress.com/2020/07/letters-to-a-new-developer.png 827w" sizes="(max-width: 717px) 100vw, 717px"><figcaption>The Cover of Letters to a New Developer</figcaption></figure>



<p>It’s based on this blog, with ideas, text and guest posts drawn from it. The format is similar: letters covering a variety of topics. However, all the content has been thoroughly reviewed, organized and rewritten. You’ll also see new letters covering topics such as why to build a personal board of advisors and discovering your wood lot (trust me, it makes sense when you read it).</p>



<p>The current launch date is <strong>Sep 9, 2020</strong>. You can pre-order it here:</p>



<ul><li><a href="https://www.indiebound.org/book/9781484260739">Indiebound</a></li><li><a href="https://bookshop.org/books/letters-to-a-new-developer-what-i-wish-i-had-known-when-starting-my-development-career/9781484260739">Bookshop</a></li><li><a href="https://www.amazon.com/Letters-New-Developer-Starting-Development/dp/1484260732/">Amazon</a></li><li><a href="https://www.barnesandnoble.com/w/letters-to-a-new-developer-dan-moore/1137054764">Barnes and Noble</a></li><li><a href="https://www.apress.com/us/book/9781484260739">Apress US website</a> (where you can buy the PDF) </li><li><a href="https://www.apress.com/gp/book/9781484260739">Apress European website</a></li></ul>



<p>Here’s the provisional table of contents:</p>



<ol><li>Introduction (they wouldn’t let me call it Chapter 0, even though developers start there)</li><li>Your first month</li><li>Questions</li><li>Writing</li><li>Tools</li><li>Practices</li><li>The Business</li><li> Learning</li><li>Mistakes</li><li>Career</li><li>Community</li></ol>



<p>If you’d rather be reminded when it is launches, please <a href="https://letterstoanewdeveloper.com/contact/">contact me and let me know</a>. You’ll also get a PDF of a sample letter.</p>
	</div><!-- .entry-content -->

	</article><!-- #post-## -->

				
			
		</main><!-- #main -->
	</div><!-- #primary -->

<!-- #secondary -->

		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/the-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743072</guid>
            <pubDate>Sun, 05 Jul 2020 23:24:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Object Pascal Introduction for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 67 (<a href="https://news.ycombinator.com/item?id=23742999">thread link</a>) | @eatonphil
<br/>
July 5, 2020 | http://newpascal.org/assets/modern_pascal_introduction.html | <a href="https://web.archive.org/web/*/http://newpascal.org/assets/modern_pascal_introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<h2 id="_why">1. Why</h2>
<div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
This is a modified version of the original document from Michalis, because we (authors of <a href="http://newpascal.org/">http://newpascal.org/</a> and <a href="http://synopse.info/">http://synopse.info/</a> ) prefer the "mode delphi" without the "generic" / "specialize" keywords.
</td>
</tr>
</tbody></table>
</div>
<p>There are many books and resources about Pascal out there, but too many of them talk about the old Pascal, without classes, units or generics.</p>
<p>So I wrote this quick introduction to what I call <strong>modern Object Pascal</strong>. Most of the programmers using it don’t really call it <em>"modern Object Pascal"</em>, we just call it  <em>"our Pascal"</em>. But when introducing the language, I feel it’s important to emphasize that it’s a modern, object-oriented language. It evolved a <strong>lot</strong> since the old (Turbo) Pascal that many people learned in schools long time ago. Feature-wise, it’s quite similar to C++ or Java or C#.</p>
<div>
<ul>
<li>
<p>It has all the modern features you expect — classes, units, interfaces, generics…​</p>
</li>
<li>
<p>It’s compiled to a fast, native code,</p>
</li>
<li>
<p>It’s very type safe,</p>
</li>
<li>
<p>High-level but can also be low-level if you need it to be.</p>
</li>
</ul>
</div>
<p>It also has excellent, portable and open-source compiler called the <em>Free Pascal Compiler</em>, <a href="http://freepascal.org/">http://freepascal.org/</a> . And an accompanying IDE (editor, debugger, a library of visual components, form designer) called <em>Lazarus</em> <a href="http://lazarus.freepascal.org/">http://lazarus.freepascal.org/</a> . Myself, I’m the creator of <em>Castle Game Engine</em>, <a href="https://castle-engine.io/">https://castle-engine.io/</a> , which is a cool portable 3D and 2D game engine using this language to create games on many platforms (Windows, Linux, MacOSX, Android, iOS, web plugin).</p>
<p>This introduction is mostly directed at programmers who already have experience in other languages. We will not cover here the meanings of some universal concepts, like <em>"what is a class"</em>, we’ll only show how to do them in Pascal.</p>
</div>
</div>
<div>
<h2 id="_basics">2. Basics</h2>
<div>
<div>
<h3 id="__hello_world_program">2.1. "Hello world" program</h3>
<div>
<div>
<pre><code data-lang="pascal"><span>{$mode delphi}</span> 

<span>program</span> MyProgram; 
<span>begin</span>
  Writeln(<span><span>'</span><span>Hello world!</span><span>'</span></span>);
<span>end</span>.</code></pre>
</div>
</div>
<p>This is a complete program that you can <em>compile</em> and <em>run</em>.</p>
<div>
<ul>
<li>
<p>If you use the command-line FPC, just create a new file <code>myprogram.lpr</code> and execute <code>fpc myprogram.lpr</code>.</p>
</li>
<li>
<p>If you use <em>Lazarus</em>, create a new project (menu <em>Project</em> → <em>New Project</em> → <em>Simple Program</em>). Save it as <code>myprogram</code> and paste this source code as the main file. Compile using the menu item <em>Run → Compile</em>.</p>
</li>
<li>
<p>This is a command-line program, so in either case — just run the compiled executable from the command-line.</p>
</li>
</ul>
</div>
<p>The rest of this article talks about the Object Pascal language, so don’t expect to see anything more fancy than the command-line stuff. If you want to see something cool, just create a new GUI project in <em>Lazarus</em> (<em>Project</em> → <em>New Project</em> → <em>Application</em>).
Voila — a working GUI application, cross-platform, with native look everywhere, using a comfortable visual component library. The <em>Lazarus</em> and <em>Free Pascal Compiler</em> come with lots of ready units for networking, GUI, database, file formats (XML, json, images…​), threading and everything else you may need. I already mentioned my cool <em>Castle Game Engine</em> earlier:)</p>
</div>
<div>
<h3 id="_functions_procedures_primitive_types">2.2. Functions, procedures, primitive types</h3>
<div>
<div>
<pre><code data-lang="pascal"><span>{$mode delphi}</span>

<span>program</span> MyProgram;

<span>procedure</span> MyProcedure(<span>const</span> A: Integer);
<span>begin</span>
  Writeln(<span><span>'</span><span>A + 10 is: </span><span>'</span></span>, A + <span>10</span>);
<span>end</span>;

<span>function</span> MyFunction(<span>const</span> S: <span>string</span>): <span>string</span>;
<span>begin</span>
  Result := S + <span><span>'</span><span>strings are automatically managed</span><span>'</span></span>;
<span>end</span>;

<span>var</span>
  X: Single;
<span>begin</span>
  Writeln(MyFunction(<span><span>'</span><span>Note: </span><span>'</span></span>));
  MyProcedure(<span>5</span>);

  
  X := <span>15</span> / <span>5</span>;
  Writeln(<span><span>'</span><span>X is now: </span><span>'</span></span>, X); 
  Writeln(<span><span>'</span><span>X is now: </span><span>'</span></span>, X:<span>1</span>:<span>2</span>); 
<span>end</span>.</code></pre>
</div>
</div>
<p>To return a value from a function, assign something to the magic <code>Result</code> variable. You can read and set the <code>Result</code> freely, just like a local variable.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> MyFunction(<span>const</span> S: <span>string</span>): <span>string</span>;
<span>begin</span>
  Result := S + <span><span>'</span><span>something</span><span>'</span></span>;
  Result := Result + <span><span>'</span><span> something more!</span><span>'</span></span>;
  Result := Result + <span><span>'</span><span> and more!</span><span>'</span></span>;
<span>end</span>;</code></pre>
</div>
</div>
<p>You can also treat the function name (like <code>MyFunction</code> in example above) as the variable, to which you can assign. But I would discourage it in new code, as it looks "fishy" when used on the right side of the assignment expression. Just use <code>Result</code> always when you want to read or set the function result.</p>
<p>If you want to call the function itself recursively, you can of course do it. If you’re calling a parameter-less function recursively, be sure to specify the parenthesis (even though in Pascal you can usually omit the parentheses for a parameter-less function), this makes a recursive call to a parameter-less function different from accessing this function’s current result. Like this:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> ReadIntegersUntilZero: <span>string</span>;
<span>var</span>
  I: Integer;
<span>begin</span>
  Readln(I);
  Result := IntToStr(I);
  <span>if</span> I &lt;&gt; <span>0</span> <span>then</span>
    Result := Result + <span><span>'</span><span> </span><span>'</span></span> + ReadIntegersUntilZero();
<span>end</span>;</code></pre>
</div>
</div>
<p>You can call <code>Exit</code> to end the execution of the procedure or function before it reaches the final <code>end;</code>. If you call parameter-less <code>Exit</code> in a function, it will return the last thing you set as <code>Result</code>. You can also use <code>Exit(X)</code> construct, to set the function result and exit <strong>now</strong> — this is just like <code>return X</code> construct in C-like languages.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> AddName(<span>const</span> ExistingNames, NewName: <span>string</span>): <span>string</span>;
<span>begin</span>
  <span>if</span> ExistingNames = <span><span>'</span><span>'</span></span> <span>then</span>
    Exit(NewName);
  Result := ExistingNames + <span><span>'</span><span>, </span><span>'</span></span> + NewName;
<span>end</span>;</code></pre>
</div>
</div>
</div>
<div>
<h3 id="_testing_if">2.3. Testing (if)</h3>
<p>Use <code>if .. then</code> or <code>if .. then .. else</code> to run some code when some condition is satisfied. Unlike in the C-like languages, in Pascal you don’t have to wrap the condition in parenthesis.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A: Integer;
  B: boolean;
<span>begin</span>
  <span>if</span> A &gt; <span>0</span> <span>then</span>
    DoSomething;

  <span>if</span> A &gt; <span>0</span> <span>then</span>
  <span>begin</span>
    DoSomething;
    AndDoSomethingMore;
  <span>end</span>;

  <span>if</span> A &gt; <span>10</span> <span>then</span>
    DoSomething
  <span>else</span>
    DoSomethingElse;

  
  B := A &gt; <span>10</span>;
  <span>if</span> B <span>then</span>
    DoSomething
  <span>else</span>
    DoSomethingElse;
<span>end</span>;</code></pre>
</div>
</div>
<p>The <code>else</code> is paired with the last <code>if</code>. So this works as you expect:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> A &lt;&gt; <span>0</span> <span>then</span>
  <span>if</span> B &lt;&gt; <span>0</span> <span>then</span>
    AIsNonzeroAndBToo
  <span>else</span>
    AIsNonzeroButBIsZero;</code></pre>
</div>
</div>
<p>While the example with nested <code>if</code> above is correct, it is often better to place the nested <code>if</code> inside a <code>begin</code> …​ <code>end</code> block in such cases. This makes the code more obvious to the reader, and it will remain obvious even if you mess up the indentation. The improved version of the example is below. When you add or remove some <code>else</code> clause in the code below, it’s obvious to which condition it will apply (to the <code>A</code> test or the <code>B</code> test), so it’s less error-prone.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> A &lt;&gt; <span>0</span> <span>then</span>
<span>begin</span>
  <span>if</span> B &lt;&gt; <span>0</span> <span>then</span>
    AIsNonzeroAndBToo
  <span>else</span>
    AIsNonzeroButBIsZero;
<span>end</span>;</code></pre>
</div>
</div>
</div>
<div>
<h3 id="_logical_relational_and_bit_wise_operators">2.4. Logical, relational and bit-wise operators</h3>
<p>The <em>logical operators</em> are called <code>and</code>, <code>or</code>, <code>not</code>, <code>xor</code>. Their meaning is probably obvious (search for <em>"exclusive or"</em> if you’re unsure what <em>xor</em> does:). They take <em>boolean arguments</em>, and return a <em>boolean</em>. They can also act as <em>bit-wise operators</em> when both arguments are integer values, in which case they return an integer.</p>
<p>The <em>relational (comparison)</em> operators are <code>=</code>, <code>&lt;&gt;</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;=</code>. If you’re accustomed to C-like languages, note that in Pascal you compare two values (check are they equal) using a single equality character <code>A = B</code> (unlike in C where you use <code>A == B</code>). The special <em>assignment</em> operator in Pascal is <code>:=</code>.</p>
<p>The <em>logical (or bit-wise) operators have a higher precedence than relational operators</em>. So you may need to use parenthesis around some expressions.</p>
<p>For example this is a compilation error:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A, B: Integer;
<span>begin</span>
  <span>if</span> A = <span>0</span> <span>and</span> B &lt;&gt; <span>0</span> <span>then</span> ... </code></pre>
</div>
</div>
<p>The above fails to compile, because the compiler sees the bit-wise <code>and</code> inside: <code>(0 and B)</code>.</p>
<p>This is correct:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A, B: Integer;
<span>begin</span>
  <span>if</span> (A = <span>0</span>) <span>and</span> (B &lt;&gt; <span>0</span>) <span>then</span> ...</code></pre>
</div>
</div>
<p>The <em>short-circuit evaluation</em> is used. Consider this expression:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> MyFunction(X) <span>and</span> MyOtherFunction(Y) <span>then</span>...</code></pre>
</div>
</div>
<div>
<ul>
<li>
<p>It’s guaranteed that <code>MyFunction(X)</code> will be evaluated first.</p>
</li>
<li>
<p>And if <code>MyFunction(X)</code> returns <code>false</code>, then the value of expression is known (the value of <code>false and whatever</code> is always <code>false</code>), and <code>MyOtherFunction(Y)</code> will not be executed at all.</p>
</li>
<li>
<p>Analogous rule is for <code>or</code> expression. There, if the expression is known to be <code>true</code> (because the 1st operand is <code>true</code>), the 2nd operand is not evaluated.</p>
</li>
<li>
<p>This is particularly useful when writing expressions like</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> (A &lt;&gt; <span>nil</span>) <span>and</span> A.IsValid <span>then</span>...</code></pre>
</div>
</div>
<p>This will work OK, even when <code>A</code> is <code>nil</code>.</p>
</li>
</ul>
</div>
</div>
<div>
<h3 id="_testing_single_expression_for_multiple_values_case">2.5. Testing single expression for multiple values (case)</h3>
<p>If a different action should be executed depending on the value of some expression, then the <code>case .. of .. end</code> statement is useful.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>case</span> SomeValue <span>of</span>
  <span>0</span>: DoSomething;
  <span>1</span>: DoSomethingElse;
  <span>2</span>: <span>begin</span>
       IfItsTwoThenDoThis;
       AndAlsoDoThis;
     <span>end</span>;
  <span>3</span>..<span>10</span>: DoSomethingInCaseItsInThisRange;
  <span>11</span>, <span>21</span>, <span>31</span>: AndDoSomethingForTheseSpecialValues;
  <span>else</span> DoSomethingInCaseOfUnexpectedValue;
<span>end</span>;</code></pre>
</div>
</div>
<p>The <code>else</code> clause is optional. When no condition matches, and there’s no <code>else</code>, then nothing happens.</p>
<p>In you come from C-like languages, and compare this with <code>switch</code> statement in these languages, you will notice that there is no automatic <em>fall-through</em>. This is a deliberate blessing in Pascal. You don’t have to remember to place <code>break</code> instructions. In every execution, <em>at most one</em> branch of the <code>case</code> is executed, that’s it.</p>
</div>
<div>
<h3 id="_enumerated_and_ordinal_types_and_sets_and_constant_length_arrays">2.6. Enumerated and ordinal types and sets and constant-length arrays</h3>
<p>Enumerated type in Pascal is a very nice, opaque type. You will probably use it much more often than enums in other languages:)</p>
<div>
<div>
<pre><code data-lang="pascal"><span>type</span>
  TAnimalKind = (akDuck, akCat, akDog);</code></pre>
</div>
</div>
<p>The convention is to prefix the enum names with a two-letter shortcut of type name, hence <code>ak</code> = shortcut for <em>"Animal Kind"</em>. This is a useful convention, since the enum names are in the unit (global) namespace. So by prefixing them with <code>ak</code> prefix, you minimize the chances of collisions with other identifiers.</p>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
The collisions in names are not a show-stopper. It’s Ok for different units to define the same identifier. But it’s a good idea to try to avoid the collisions anyway, to keep code simple to understand and grep.
</td>
</tr>
</tbody></table>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
You can avoid placing enum names in the global namespace by directive <code>{$scopedenums on}</code>. This means you will have to access them qualified by a type name, like <code>TAnimalKind.akDuck</code>. The need for <code>ak</code> prefix disappears in this situation, and you will probably just call the enums <code>Duck, Cat, Dog</code>. This is …</td></tr></tbody></table></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://newpascal.org/assets/modern_pascal_introduction.html">http://newpascal.org/assets/modern_pascal_introduction.html</a></em></p>]]>
            </description>
            <link>http://newpascal.org/assets/modern_pascal_introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742999</guid>
            <pubDate>Sun, 05 Jul 2020 23:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Black Face: Neuland and Lithos as Stereotypography (2004)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742978">thread link</a>) | @cardamomo
<br/>
July 5, 2020 | https://linedandunlined.com/archive/new-black-face/ | <a href="https://web.archive.org/web/*/https://linedandunlined.com/archive/new-black-face/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
		</header>

		<blockquote>
  <p>“The Neuland Question comes up regularly, and alas without much resolution….” –Jonathan Hoefler</p>
</blockquote>

<p>The “Neuland Question” to which Jonathan Hoefler refers involves not just Neuland, a “display” typeface hand-carved in 1923 by Rudolf Koch (<a href="#p1">Plate 1</a>), but also Lithos, another “display” typeface digitally created in 1989 by Carol Twombly (<a href="#p2">Plate 2</a>). The Question can be put simply: How did these two typefaces come to signify Africans and African-Americans, regardless of how a designer uses them, and regardless of the purpose for which their creators originally intended them? The investigation of this question has four parts: first, an examination of the environments in which Koch and Twombly created the original typefaces; second, an examination of the graphic culture that surrounded African-Americans prior to the creation of Neuland through a close viewing of tobacco ephemera; third, an examination of the Art Deco (French Modern) style, the graphic culture most prevalent in the United States at the time of Neuland’s release; and finally, an examination of the ways designers use Neuland and Lithos today.</p>

<h2 id="plate-1"><a name="p1">Plate 1</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/01.jpg" alt="Neuland"></p>

<h2 id="plate-2"><a name="p2">Plate 2</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/02.jpg" alt="Lithos"></p>

<p>Rudolf Koch was born in 1876 and had a career that was both uninteresting and undistinguished until he enlisted in the German Army in 1907 to fight in World War I. Upon returning from the war, he commented to his close friend Siegfried Guggenheim that he was “profoundly stirred” by his experiences (10). The horrors of war inspired Koch to seek religion for himself and then preach the benefits of a religious life to his countrymen. Having experimented with the art of calligraphy shortly before enlisting, Koch returned to the art after WWI with the intention of making bold, noticeable typefaces that would shout to other Germans that following God’s path would help them find comfort from the trauma of war. Guggenheim notes, “Koch’s fonts after the war were designed for broadsides, postcards, etc. – not books [… they were designed] to demonstrate his religious fervency” (11–13). Neuland was such a face. Yale University Printer John Gambell suggests that Koch designed the face with the intent of making a modern version of the German black letter (or black face) style. Black letter fonts were used at the time for the setting of important texts, especially Bibles and church-related documents. Koch’s “new black face” attempted to preserve the flared, interlocking forms of the traditional black letter style, while at the same time adopting the sans-serif style around which modernists, like Paul Renner, were building their typefaces. Renner’s Futura, the quintessential example of modernist typography, was designed in 1927, only four years after the Klingspor Type Foundry released Koch’s Neuland (Rock).</p>

<p>Koch’s settings of Neuland in the original German specimen book published by the Klingspor Type Foundry support Gambell’s suggestion. He sets the type with minimal leading and kerning as black letter was typically set (<a href="#p345">Plate 3</a>). He inserts woodcuts and Greek cross-shaped (+) ampersands as well (<a href="#p345">Plate 4</a>), a common practice with black letter texts. However, Koch broke with black letter typesetting standards by stripping Neuland of the delicately interlocking serifs commonly used in black letter typography. The result, a font composed of heavy black forms, was visible from great distances and easily distinguishable from lighter-weight typefaces on a page. These qualities made Neuland suitable to advertising. Koch even attempted to set a classified ad in Neuland at the end of the German specimen book (<a href="#p345">Plate 5</a>).</p>

<h2 id="plates-3-4-and-5"><a name="p345">Plates 3, 4, and 5</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/03-04-05.jpg" alt="Koch lettering"></p>

<p>By the time Neuland reached the United States, its distributor, the Continental Typefounder’s Association, had little interest in Neuland’s uses as a modern black letter, and the specimen book that they prepared promoted Neuland as exclusively an advertising typeface, a “type that attracts attention” (Koch, Loose File, “Klingspor Type Foundry”). The American specimen book showed Neuland used in advertising settings from bank bonds to drywall contracting (<a href="#p6">Plate 6</a>). Because of the absence of a black letter tradition in the United States and because of the way the Continental Typefounder’s Association promoted Neuland, Koch’s intentions for the font were entirely lost immediately after its introduction in America.</p>

<h2 id="plate-6"><a name="p6">Plate 6</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/06.jpg" alt="Neuland specimen"></p>

<p>Just as Koch was trying to modernize an ancient form of writing with Neuland in 1923, so too was Carol Twombly with Lithos in 1989. Jonathan Hoefler suggests that “Lithos [is] an interpretation of ancient lapidary writing.” Twombly herself corroborates this:</p>

<blockquote>
  <p>Inscriptions honoring public figures or dedications for temples were intended for public viewing in ancient Greece. Geometric letterforms, free of adornment were chiseled into the stone. These basic shapes are the inspiration for Lithos.</p>
</blockquote>

<p>Letterforms like those that inspired Lithos can be seen not only on ancient Greek temples, but also on many modern buildings built in the Classical or Gothic styles, such as on the front entrance to Sterling Memorial Library at Yale University. In his famous book <em>The Elements of Typographic Style</em>, critic Robert Bringhurst notes that many modern typefaces take their inspiration from architectural sources, and, indeed, many of Twombly’s typefaces, like Lithos, come from ancient architecture: Trajan, a serifed face, evolved from carvings on columns in ancient Rome; and Charlemagne, another serifed face, evolved from carvings found in Byzantine temples.</p>

<p>Although Twombly left Trajan and Charlemagne relatively unaltered from their original forms, she made a substantial alteration in Lithos. Twombly decided to create a bold weight for Lithos in addition to its book weight, even though bold-weighted letterforms were nonexistent in ancient Greece. John Gambell suggests that Twombly “may have felt the font was not marketable today without a bold weight.” Regardless of her reasons, Lithos’ bold-weighted anachronism is now Neuland’s bastard child. Lithos’ flared edges, heavy lines, square characters, and pen-like strokes are analogous to Neuland’s trademark elements, and the fonts are virtually identical to the untrained eye. Indeed, Lithos’ close formal approximation to Neuland makes it virtually interchangeable with Neuland for designers working on African and African-American projects.</p>

<p>Because Lithos follows Neuland historically and formally, and because printers and designers used Neuland in African and African-American projects before Twombly even conceived Lithos, the resolution of the Neuland Question rests in reconstructing Neuland’s history.</p>

<p>Primarily because of both constant anti-African-American sentiment and the socioeconomic status of African-Americans during and after the Civil War, African-American graphic culture in the United States prior to Neuland’s release in 1923 and before the Harlem Renaissance in general was unimportant at best and nonexistent at worst. In short, African-Americans did not have the buying power or the social acceptance required to cultivate a significant graphic culture. What graphic culture they did have centered around their depiction in advertisements for products associated with slavery: tobacco and cotton.</p>

<p>Tremendous amounts of ephemera surrounded the tobacco industry from the 1850s until the 1930s, much of which involved racist uses of African-Americans as mascots. Much of this ephemera took the form of trading cards given out in general stores, on street corners, or wherever tobacco was sold (<a href="#p7">Plate 7</a>). These trading cards were common media for advertising from the 1850s to the 1930s, and generally involved a caricatured picture of a “Negro” and a slogan in dialect (“Sho’ fly, git away from dar”) on the front and information about the product on the back (<a href="#p8">Plate 8</a>). As tobacco companies had to make these cards cheaply and copiously, the text on the back of these cards was often poorly set with cheap woodblock type rather than with more expensive metal type.</p>

<p>While today woodblock type has a certain nostalgic appeal, designers and typophiles (typographic historians and typography enthusiasts) into the 1950s saw woodblock letters as nothing but lower-class. Immediately upon its release, designers and typophiles linked Neuland’s forms with woodblock type and responded accordingly. In his book <em>Typographic Milestones</em>, typophile Allan Haley charges “Neuland is not considered a particularly practical, useful, or attractive typeface” (70). He later reiterates his point, saying, “[Neuland is] not especially attractive, nor even very useful […] its realistic applications are quite limited” (73). Typophiles like Haley frequently omitted Neuland from typographic histories altogether, and Neuland soon became a member of the family of fonts that designers call “garbage type”: esoteric, inelegant, difficult to set, and destined, like tobacco ephemera, for the garbage. Neuland’s figurative status as “garbage type” became a literal truth when, as popular design legend has it, printers threw the face away after becoming frustrated with the extraordinary weight of the thick lead letters and the large amount of space the alphabet consumed in their often small print shops.</p>

<h2 id="plate-7"><a name="p7">Plate 7</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/07.jpg" alt="Trade cards"></p>

<h2 id="plate-8"><a name="p8">Plate 8</a></h2>

<p><img src="https://linedandunlined.com/images/neuland/08.jpg" alt="Trade cards"></p>

<p>Apart from being perceived as cheap “garbage,” woodblock type carried with it a legacy of cultural stereotype. Woodblock type was also known as “circus type” because of its frequent use in promoting circuses. An entire culture of “stereotypography” developed around these playful woodblock typefaces as certain “circus types” came to stand for stereotypical visual associations that Americans held about the cultures that the “circus types” were designed to represent. For example, circus promoters used the woodblock type Tokyo when promoting performers from the Orient (<a href="#p9">Plate 9</a>). Hometown, another “circus type,” is a near match for Neuland (<a href="#p10">Plate 10</a>), as is Othello, a heavy (black) sign-lettering typeface whose name alludes to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linedandunlined.com/archive/new-black-face/">https://linedandunlined.com/archive/new-black-face/</a></em></p>]]>
            </description>
            <link>https://linedandunlined.com/archive/new-black-face/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742978</guid>
            <pubDate>Sun, 05 Jul 2020 23:13:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remotely upgrading OpenWrt 15.05 to 19.07 on NAND flash boards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742942">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://gir.st/blog/upgrading-openwrt.html | <a href="https://web.archive.org/web/*/https://gir.st/blog/upgrading-openwrt.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><a href="https://gir.st/">Home</a> | <a href="https://gir.st/blog">Blog</a> | <a href="https://gir.st/blog/upgrading-openwrt.html"><b>Upgrading OpenWrt (guide)</b></a>



<p>This guide will explain how to remotely, i.e. without having physical access to the machine, upgrade an embedded device from OpenWrt 15.05 or lower to LEDE 17.01 or OpenWrt 18.06/19.07. This process is usually not possible on systems equipped with NAND flash storage due to the root file system having been switched from yaffs2 to UBIFS without an official migration path in newer releases.
</p><p>This guide was written for our migration of Mikrotik Routerboard 450G, but should be applicable to a wide range of devices and possibly even manufacturers. Apply your usual judgement for when to deviate from the instructions.

</p><h2>Overview</h2>
<p>On a high level, the upgrade will take place in three parts: First, we prepare a specialized image (kernel + minimal initramfs) that fits solely within the "kernel" partition (<code>/dev/mtdblock5</code> on a Routerboard 450G). Secondly, we will replace the currently installed kernel with our boot image and boot from it. Finally, we transfer the stock <code>sysupgrade.bin</code> and our backup <code>tar.gz</code> and flash it using the official method—sysupgrade(8).

</p><figure> <!-- draw.io is neat :) -->
<svg width="312px" height="81px" viewBox="-0.5 -0.5 312 81"><!--{{{-->
<ellipse cx="60" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="59.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Prepare bespoke</text>
<text x="59.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">initramfs image</text>
<path d="M 120 40 L 173.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 178.88 40 L 171.88 43.5 L 173.63 40 L 171.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>

<ellipse cx="240" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="239.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Replace kernel and</text>
<text x="239.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">boot custom image</text>
<path d="M 300 40 L 353.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 358.88 40 L 351.88 43.5 L 353.63 40 L 351.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>


</svg><!--}}}--><svg width="312px" height="81px" viewBox="311 -0.5 312 81"><!--{{{-->
<path d="M 300 40 L 353.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 358.88 40 L 351.88 43.5 L 353.63 40 L 351.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>


<ellipse cx="420" cy="40" rx="60" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<text x="419.5" y="36.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">Transfer and flash</text>
<text x="419.5" y="50.5" fill="#000000" font-family="Helvetica" font-size="12px" text-anchor="middle">stock OpenWrt</text>
<path d="M 480 40 L 533.63 40" fill="none" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 538.88 40 L 531.88 43.5 L 533.63 40 L 531.88 36.5 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10"></path>

<ellipse cx="581" cy="40" rx="41" ry="40" fill="#ffffff" stroke="#000000"></ellipse>
<path d="M 549.2 44.08 C 549.2 56.25 563.44 66.12 581 66.12 C 598.56 66.12 612.8 56.25 612.8 44.08" fill="none" stroke="#000000" stroke-width="1.63" stroke-miterlimit="10"></path>
<path d="M 553.39 41.63 L 545.02 46.53" fill="#ffffff" stroke="#000000" stroke-miterlimit="10"></path>
<path d="M 608.61 41.63 L 616.98 46.53" fill="#ffffff" stroke="#000000" stroke-miterlimit="10"></path>
<ellipse cx="562.59" cy="28.57" rx="2.5102040816326534" ry="6.530612244897959" fill="#ffffff" stroke="#000000" stroke-width="4.9"></ellipse>
<ellipse cx="599.41" cy="28.57" rx="2.5102040816326534" ry="6.530612244897959" fill="#ffffff" stroke="#000000" stroke-width="4.9"></ellipse>
</svg><!--}}}-->
<figcaption>High level strategy</figcaption>
</figure>
<p>In the following steps, I will start with a bulleted list of the tasks, then explain them in detail.

</p><h2>Step 0: Backing up and checking compatibility</h2>
<ul>
<li>Prepare a backup with <kbd>sysupgrade -b /tmp/config.tar.gz</kbd>
</li><li>Verify the target device uses SLC NAND with <kbd>dmesg | grep nand</kbd>
</li></ul>
<p>If you intend to keep your current configuration, you should follow the <a href="https://openwrt.org/docs/guide-user/installation/generic.sysupgrade#preparing_for_an_openwrt_upgrade">Preparing To Upgrade</a> section from the OpenWrt documentation. <kbd>sysupgrade -b /tmp/config.tar.gz</kbd> should get you close. Keep in mind that OpenWrt has been overhauled dramatically, and changes to your configuration will probably be necessary.
</p><p>But before we can initiate the upgrade, we need to make sure your NAND flash is compatible with UBIFS. For a <a href="https://lists.openwrt.org/pipermail/openwrt-devel/2018-October/014454.html">short period of time in 2010</a>, Mikrotik installed cheaper and less reliable <abbr title="multi level cell">MLC</abbr> flash chips instead of the more reliable <abbr title="single level cell">SLC</abbr> ones. UBIFS predates MLC flash and will destroy it even when just reading from it due to a lack of an error correction daemon to fix the constantly occurring bitflips; the kernel will refuse to operate on such chips.
<br>To find out if you are affected, issue <kbd>dmesg | grep nand</kbd>. This command will return information about the chip on your device, including the type of NAND technology used (SLC or MLC). Flash storage from Samsung, Winbond, Numonyx or Micron is supposedly safe, while Hynix requires a closer look. Sadly, there is nothing you can do but to decommission the device if it has an MLC flash.
<!--<p>Side note: the <i>why</i> is pretty interesting, but would go far beyond the scope of this guide, so I'll just link you to the <a href="https://lists.openwrt.org/pipermail/openwrt-devel/2018-October/014324.html">mailing list thread</a> and the <a href="https://en.wikipedia.org/wiki/Multi-level_cell">MLC Wikipedia page</a>.-->
</p><details><summary>Sample <code>dmesg</code> output</summary>
SLC example:
<pre>[    2.252914] nand: device found, Manufacturer ID: 0x20, Chip ID: 0xdc
[    2.259309] nand: ST Micro NAND04GW3B2DN6
[    2.263313] nand: 512 MiB, <b>SLC</b>, erase size: 128 KiB, page size: 2048, OOB size: 64</pre>
MLC example:
<pre>[    0.825198] nand: device found, Manufacturer ID: 0xec<!--not actually hynix' ID-->, Chip ID: 0xdc
[    0.831588] nand: Hynix NAND 512MiB 3,3V 8-bit
[    0.836191] nand: 512MiB, <b>MLC</b>, page size: 2048, OOB size: 64</pre>
</details>

<h2>Step 1: Preparing an OpenWrt boot image</h2>
<ul>
<li>Set up an <a href="https://openwrt.org/docs/guide-developer/quickstart-build-images">OpenWrt build environment</a>, and configure it to include just the bare minimum
</li><li>Push additional files into your image using the <code>files/</code> directory
</li><li>Build <code>openwrt-*-vmlinux-initramfs-lzma.elf</code> with <kbd>make FILES=files/</kbd>
</li></ul>
<p>To get around the problem that the old kernel can't read the new filesystem and vice versa, we temporarily boot into a self-contained <i>initramfs</i> environment. This is essentially just a Linux kernel that has its own file system embedded and lives entirely in the kernel partition. Given our size constraints (~3.4MB), this image needs to be stripped down as much as possible and only come with a basic configuration to reach your network.
</p><p>Begin by following the <a href="https://openwrt.org/docs/guide-developer/quickstart-build-images">Quick Image Building Guide</a>. Start off by verifying that your build environment is working correctly by compiling a normal OpenWrt image by just modifying the Target System settings. <!--Note that the build system (not just during <code>feeds update</code>, but during <code>make</code> as well) requires connecting to a multitude of external hosts, so you might need an exception from your corporate firewall if you are behind such one. The error message in non-verbose mode is quite cryptic.-->
</p><p>When you feel ready, reissue <kbd>make menuconfig</kbd> and disable as much packages as possible. A <code>&lt;*&gt;</code> or <code>[*]</code> indicates that the package will be pre-installed and take up precious disk space. However, you must install an ssh daemon (dropbear) and the sysupgrade tool. You could also directly modify the <code>.config</code> file in your OpenWrt build environment.
</p><details><summary>Sample <code>.config</code> file</summary>
<pre><!--{{{-->
CONFIG_MODULES=y
CONFIG_HAVE_DOT_CONFIG=y
CONFIG_TARGET_ar71xx=y
CONFIG_TARGET_ar71xx_mikrotik=y
CONFIG_TARGET_ar71xx_mikrotik_DEVICE_nand-large=y
CONFIG_HAS_SUBTARGETS=y
CONFIG_HAS_DEVICES=y
CONFIG_TARGET_BOARD="ar71xx"
CONFIG_TARGET_SUBTARGET="mikrotik"
CONFIG_TARGET_PROFILE="DEVICE_nand-large"
CONFIG_TARGET_ARCH_PACKAGES="mips_24kc"
CONFIG_DEFAULT_TARGET_OPTIMIZATION="-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc"
CONFIG_CPU_TYPE="24kc"
CONFIG_LINUX_4_14=y
CONFIG_DEFAULT_base-files=y
CONFIG_DEFAULT_busybox=y
CONFIG_DEFAULT_dnsmasq=y
CONFIG_DEFAULT_dropbear=y
CONFIG_DEFAULT_firewall=y
CONFIG_DEFAULT_fstools=y
CONFIG_DEFAULT_ip6tables=y
CONFIG_DEFAULT_iptables=y
CONFIG_DEFAULT_iwinfo=y
CONFIG_DEFAULT_kmod-ath9k=y
CONFIG_DEFAULT_kmod-gpio-button-hotplug=y
CONFIG_DEFAULT_kmod-ipt-offload=y
CONFIG_DEFAULT_kmod-usb-ledtrig-usbport=y
CONFIG_DEFAULT_kmod-usb-ohci=y
CONFIG_DEFAULT_kmod-usb2=y
CONFIG_DEFAULT_libc=y
CONFIG_DEFAULT_libgcc=y
CONFIG_DEFAULT_logd=y
CONFIG_DEFAULT_mtd=y
CONFIG_DEFAULT_nand-utils=y
CONFIG_DEFAULT_netifd=y
CONFIG_DEFAULT_odhcp6c=y
CONFIG_DEFAULT_odhcpd-ipv6only=y
CONFIG_DEFAULT_opkg=y
CONFIG_DEFAULT_ppp=y
CONFIG_DEFAULT_ppp-mod-pppoe=y
CONFIG_DEFAULT_swconfig=y
CONFIG_DEFAULT_uboot-envtools=y
CONFIG_DEFAULT_uci=y
CONFIG_DEFAULT_uclient-fetch=y
CONFIG_DEFAULT_urandom-seed=y
CONFIG_DEFAULT_urngd=y
CONFIG_DEFAULT_wpad-basic=y
CONFIG_AUDIO_SUPPORT=y
CONFIG_GPIO_SUPPORT=y
CONFIG_PCI_SUPPORT=y
CONFIG_USB_SUPPORT=y
CONFIG_USB_GADGET_SUPPORT=y
CONFIG_BIG_ENDIAN=y
CONFIG_USES_INITRAMFS=y
CONFIG_USES_SQUASHFS=y
CONFIG_USES_MINOR=y
CONFIG_HAS_MIPS16=y
CONFIG_NAND_SUPPORT=y
CONFIG_mips=y
CONFIG_ARCH="mips"
CONFIG_TARGET_ROOTFS_INITRAMFS=y
CONFIG_TARGET_INITRAMFS_COMPRESSION_LZMA=y
CONFIG_EXTERNAL_CPIO=""
CONFIG_TARGET_ROOTFS_TARGZ=y
CONFIG_TARGET_ROOTFS_SQUASHFS=y
CONFIG_TARGET_SQUASHFS_BLOCK_SIZE=256
CONFIG_TARGET_UBIFS_FREE_SPACE_FIXUP=y
CONFIG_TARGET_UBIFS_JOURNAL_SIZE=""
CONFIG_SHADOW_PASSWORDS=y
CONFIG_KERNEL_BUILD_USER=""
CONFIG_KERNEL_BUILD_DOMAIN=""
CONFIG_KERNEL_PRINTK=y
CONFIG_KERNEL_CRASHLOG=y
CONFIG_KERNEL_SWAP=y
CONFIG_KERNEL_DEBUG_FS=y
CONFIG_KERNEL_KALLSYMS=y
CONFIG_KERNEL_DEBUG_KERNEL=y
CONFIG_KERNEL_DEBUG_INFO=y
CONFIG_KERNEL_AIO=y
CONFIG_KERNEL_FHANDLE=y
CONFIG_KERNEL_FANOTIFY=y
CONFIG_KERNEL_MAGIC_SYSRQ=y
CONFIG_KERNEL_COREDUMP=y
CONFIG_KERNEL_ELF_CORE=y
CONFIG_KERNEL_PRINTK_TIME=y
CONFIG_KERNEL_CGROUPS=y
CONFIG_KERNEL_FREEZER=y
CONFIG_KERNEL_CGROUP_FREEZER=y
CONFIG_KERNEL_CGROUP_DEVICE=y
CONFIG_KERNEL_CGROUP_PIDS=y
CONFIG_KERNEL_CPUSETS=y
CONFIG_KERNEL_CGROUP_CPUACCT=y
CONFIG_KERNEL_RESOURCE_COUNTERS=y
CONFIG_KERNEL_MM_OWNER=y
CONFIG_KERNEL_MEMCG=y
CONFIG_KERNEL_MEMCG_KMEM=y
CONFIG_KERNEL_CGROUP_SCHED=y
CONFIG_KERNEL_FAIR_GROUP_SCHED=y
CONFIG_KERNEL_RT_GROUP_SCHED=y
CONFIG_KERNEL_BLK_CGROUP=y
CONFIG_KERNEL_NET_CLS_CGROUP=y
CONFIG_KERNEL_NETPRIO_CGROUP=y
CONFIG_KERNEL_NAMESPACES=y
CONFIG_KERNEL_UTS_NS=y
CONFIG_KERNEL_IPC_NS=y
CONFIG_KERNEL_USER_NS=y
CONFIG_KERNEL_PID_NS=y
CONFIG_KERNEL_NET_NS=y
CONFIG_KERNEL_DEVPTS_MULTIPLE_INSTANCES=y
CONFIG_KERNEL_POSIX_MQUEUE=y
CONFIG_KERNEL_SECCOMP_FILTER=y
CONFIG_KERNEL_SECCOMP=y
CONFIG_KERNEL_IP_MROUTE=y
CONFIG_KERNEL_SQUASHFS_FRAGMENT_CACHE_SIZE=3
CONFIG_KERNEL_CC_OPTIMIZE_FOR_PERFORMANCE=y
CONFIG_USE_SSTRIP=y
CONFIG_USE_UCLIBCXX=y
CONFIG_PKG_CHECK_FORMAT_SECURITY=y
CONFIG_PKG_ASLR_PIE_REGULAR=y
CONFIG_PKG_CC_STACKPROTECTOR_REGULAR=y
CONFIG_KERNEL_CC_STACKPROTECTOR_REGULAR=y
CONFIG_KERNEL_STACKPROTECTOR=y
CONFIG_PKG_FORTIFY_SOURCE_1=y
CONFIG_PKG_RELRO_FULL=y
CONFIG_BINARY_FOLDER=""
CONFIG_DOWNLOAD_FOLDER=""
CONFIG_LOCALMIRROR=""
CONFIG_AUTOREBUILD=y
CONFIG_BUILD_SUFFIX=""
CONFIG_TARGET_ROOTFS_DIR=""
CONFIG_EXTERNAL_KERNEL_TREE=""
CONFIG_KERNEL_GIT_CLONE_URI=""
CONFIG_BUILD_LOG_DIR=""
CONFIG_EXTRA_OPTIMIZATION="-fno-caller-saves -fno-plt"
CONFIG_TARGET_OPTIMIZATION="-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc"
CONFIG_SOFT_FLOAT=y
CONFIG_USE_MIPS16=y
CONFIG_EXTRA_BINUTILS_CONFIG_OPTIONS=""
CONFIG_EXTRA_GCC_CONFIG_OPTIONS=""
CONFIG_GDB=y
CONFIG_USE_MUSL=y
CONFIG_SSP_SUPPORT=y
CONFIG_BINUTILS_VERSION_2_31_1=y
CONFIG_BINUTILS_VERSION="2.31.1"
CONFIG_GCC_VERSION="8.3.0"
CONFIG_LIBC="musl"
CONFIG_TARGET_SUFFIX="musl"
CONFIG_IB=y
CONFIG_IB_STANDALONE=y
CONFIG_TARGET_PREINIT_SUPPRESS_STDERR=y
CONFIG_TARGET_PREINIT_TIMEOUT=2
CONFIG_TARGET_PREINIT_IFNAME=""
CONFIG_TARGET_PREINIT_IP="192.168.1.1"
CONFIG_TARGET_PREINIT_NETMASK="255.255.255.0"
CONFIG_TARGET_PREINIT_BROADCAST="192.168.1.255"
CONFIG_TARGET_INIT_PATH="/usr/sbin:/usr/bin:/sbin:/bin"
CONFIG_TARGET_INIT_ENV=""
CONFIG_TARGET_INIT_CMD="/sbin/init"
CONFIG_TARGET_INIT_SUPPRESS_STDERR=y
CONFIG_PER_FEED_REPO=y
CONFIG_FEED_packages=y
CONFIG_FEED_luci=y
CONFIG_FEED_routing=y
CONFIG_FEED_telephony=y
CONFIG_PACKAGE_base-files=y
CONFIG_PACKAGE_busybox=y
CONFIG_BUSYBOX_CUSTOM=y
CONFIG_BUSYBOX_DEFAULT_HAVE_DOT_CONFIG=y
CONFIG_BUSYBOX_DEFAULT_INCLUDE_SUSv2=y
CONFIG_BUSYBOX_DEFAULT_LONG_OPTS=y
CONFIG_BUSYBOX_DEFAULT_SHOW_USAGE=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_VERBOSE_USAGE=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_COMPRESS_USAGE=y
CONFIG_BUSYBOX_DEFAULT_LFS=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_DEVPTS=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_PIDFILE=y
CONFIG_BUSYBOX_DEFAULT_PID_FILE_PATH="/var/run"
CONFIG_BUSYBOX_DEFAULT_FEATURE_PREFER_APPLETS=y
CONFIG_BUSYBOX_DEFAULT_BUSYBOX_EXEC_PATH="/proc/self/exe"
CONFIG_BUSYBOX_DEFAULT_FEATURE_SYSLOG=y
CONFIG_BUSYBOX_DEFAULT_PLATFORM_LINUX=y
CONFIG_BUSYBOX_DEFAULT_CROSS_COMPILER_PREFIX=""
CONFIG_BUSYBOX_DEFAULT_SYSROOT=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_CFLAGS=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_LDFLAGS=""
CONFIG_BUSYBOX_DEFAULT_EXTRA_LDLIBS=""
CONFIG_BUSYBOX_DEFAULT_INSTALL_APPLET_SYMLINKS=y
CONFIG_BUSYBOX_DEFAULT_PREFIX="./_install"
CONFIG_BUSYBOX_DEFAULT_NO_DEBUG_LIB=y
CONFIG_BUSYBOX_DEFAULT_FEATURE_BUFFERS_GO_ON_STACK=y</pre></details></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gir.st/blog/upgrading-openwrt.html">https://gir.st/blog/upgrading-openwrt.html</a></em></p>]]>
            </description>
            <link>https://gir.st/blog/upgrading-openwrt.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742942</guid>
            <pubDate>Sun, 05 Jul 2020 23:08:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a winning 4K intro in Rust]]>
            </title>
            <description>
<![CDATA[
Score 322 | Comments 81 (<a href="https://news.ycombinator.com/item?id=23742870">thread link</a>) | @Dowwie
<br/>
July 5, 2020 | https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html | <a href="https://web.archive.org/web/*/https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4371838969983872321" itemprop="description articleBody">
<div><p><span>I recently wrote my first 4K intro in Rust and released it at the Nova 2020 where it took first place in the new school intro competition. Writing a 4K intro is quite involved and requires you to master many different areas at the same time. Here I will focus on what I learned about making Rust code as small as possible.</span></p><p><iframe allowfullscreen="" height="322" src="https://www.youtube.com/embed/SIkkYRQ07tU" width="387" youtube-src-id="SIkkYRQ07tU"></iframe></p><p>You can view the demo on<span>&nbsp;</span><a href="https://www.youtube.com/watch?v=SIkkYRQ07tU">youtube</a>, download the executable at<span>&nbsp;</span><a href="https://www.pouet.net/prod.php?which=85924">pouet</a><span>&nbsp;</span>or get the source code from<span>&nbsp;</span><a href="https://github.com/janiorca/sphere_dance">github</a></p><p>A 4K intro is a demo where the entire program ( including any data ) has two be 4096 bytes or less so it is important that the code is as space efficient as possible. Rust has a bit of a reputation for creating bloated executables so I wanted to find out if is possible to create very space efficient code with it.</p><p>The entire intro is written in a combination of Rust and glsl. Glsl is used for rendering everything on screen but Rust does everything else; world creation, camera and object control, creating instruments and playing music etc.</p><p>Some of the features I depend on, such as xargo, are not yet part of stable Rust so I use the nightly rust toolchain. To install and use the nightly toolchain as default you need the following rustup commands.</p><pre data-info="" data-role="codeBlock"><code>rustup toolchain install nightly
rustup default nightly
</code></pre><p>I use<span>&nbsp;</span><a href="http://crinkler.net/">crinkler</a><span>&nbsp;</span>to compress the object file generated by the rust compiler.</p><p>I also used<span>&nbsp;</span><a href="https://github.com/laurentlb/Shader_Minifier">shader minifier</a><span>&nbsp;</span>for pre-processing the<span>&nbsp;</span><code>glsl</code><span>&nbsp;</span>shader to make it smaller and more crinkler friendly. The shader minifier doesn't support output into<span>&nbsp;</span><code>.rs</code><span>&nbsp;</span>files so I ended up using its raw output and manually copying it into my<span>&nbsp;</span><a href="http://shader.rs/">shader.rs</a><span>&nbsp;</span>file. (In hindsight, I should have written something to automate that stage. Or even created a PR for shader minifier)</p><p>The starting point was the proof of concept code I developed earlier (<a href="https://www.codeslow.com/2020/01/writing-4k-intro-in-rust.html">https://www.codeslow.com/2020/01/writing-4k-intro-in-rust.html</a>) which I thought was pretty lean at the time. That article also goes into but more detail about setting up the<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file and how to use xargo for compiling tiny executable.</p><p>Many of the most effective size optimizations have nothing to do with clever hacks but are the result of rethinking the design.</p><p>My initial design had one part of the code creating the world, including placing the spheres and another part was responsible for moving the spheres. At some point I realized that the sphere placement and sphere moving code were doing very similar things and I could merge them into one sightly more complicated function that did both. Unfortunately, this type of optimization can make the code less elegant and readable.</p><p>At some point you have to look at the compiled assembly code to understand what the code gets compiled into and what size optimizations are worth it. The Rust compiler has a very useful option,<span>&nbsp;</span><code>--emit=asm</code><span>&nbsp;</span>for outputting assembler code. The following command creates a<span>&nbsp;</span><code>.s</code><span>&nbsp;</span>assembly file;</p><pre data-info="" data-role="codeBlock"><code>xargo rustc --release --target i686-pc-windows-msvc -- --emit=asm
</code></pre><p>It is not necessary to be an expert in assembler to benefit from studying the assembler output but it definitely helps to have a basic understanding assembler syntax. The release version uses<span>&nbsp;</span><code>opt-level = "z</code><span>&nbsp;</span>which causes the compiler to optimize for the smallest possible size. This can make it a bit tricky to work out which part of the assembly code corresponds to which part of the Rust code.</p><p>I discovered that the Rust compiler can be surprisingly good at minimizing code; getting rid of unused code and unnecessary parameters and folding code. It can also do some strange things which is why it is essential to occasionally study the resulting assembly code.</p><p>I worked with two versions of the code; one version does logging and allows the viewer to manipulate the camera which is used for creating interesting camera paths. Rust allows you to define<span>&nbsp;</span><strong>features</strong><span>&nbsp;</span>that you can use to optionally include bits of functionality. The<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file has a<span>&nbsp;</span><strong>[features]</strong><span>&nbsp;</span>section that lets you declare the available features and their dependencies. My 4K intro has the following section in the<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file;</p><pre data-info="toml" data-role="codeBlock"><span>[</span><span>features</span><span>]</span>
<span>logger</span> <span>=</span> <span>[</span><span>]</span>
<span>fullscreen</span> <span>=</span> <span>[</span><span>]</span>
</pre><p>Neither of the optional features has dependencies so they effectively work as being conditional compilation flags. The conditional blocks of code are preceded by<span>&nbsp;</span><code>#[cfg(feature)]</code><span>&nbsp;</span>statement. Using features in itself does not make the code smaller but it makes development process much nicer when you easily switch between different feature sets.</p><pre data-info="rust" data-role="codeBlock">        <span>#[cfg(feature = "fullscreen")]</span>
        <span>{</span>
            
        <span>}</span>

        <span>#[cfg(not(feature = "fullscreen"))]</span>
        <span>{</span>
            
        <span>}</span>
</pre><p>Having inspected the compiled code I am certain that only the selected features get included in the compiled code.</p><p>One of the main uses of<span>&nbsp;</span><strong>features</strong><span>&nbsp;</span>was to enable logging and error checking for the debug build. The code loading and compiling the glsl shader failed frequently and without useful error messages it would have been extremely painful to find the problems.</p><p>When putting code inside an<span>&nbsp;</span><code>unsafe{}</code><span>&nbsp;</span>block I sort of assumed that all safety checks would be disabled within this block but this is not true, all the usual checks are still applied and these checks can be expensive.</p><p>By default Rust range checks all array accesses. Take the following Rust code</p><pre data-info="rust" data-role="codeBlock">    delay_counter <span>=</span> sequence<span>[</span> play_pos <span>]</span><span>;</span>
</pre><p>Before doing the table look up the compiler would insert code that checks that play_pos is not indexing past the end of sequence and panic if that was the case. This adds considerable size to the code as there can be a lot of table look-ups like this.</p><p>Converting the above code into</p><pre data-info="rust" data-role="codeBlock">    delay_counter <span>=</span> <span>*</span>sequence<span>.</span><span>get_unchecked</span><span>(</span> play_pos <span>)</span><span>;</span>
</pre><p>tells the compiler to not perform any range checks and just do the table look-up. This is clearly a potentially dangerous operation and can thus only be performed within an<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code block</p><p>Initially all my loops used the idiomatic rust way of doing loops, using the<span>&nbsp;</span><code>for x in 0..10</code><span>&nbsp;</span>syntax which I just assumed would be compiled into tightest possible loop. Surprisingly, this was not the case. The simplest case;</p><pre data-info="rust" data-role="codeBlock"><span>for</span> x <span>in</span> <span>0</span><span>..</span><span>10</span> <span>{</span>
    
<span>}</span>
</pre><p>would get translated into assembly code that did the following;</p><pre data-info="" data-role="codeBlock"><code>    setup loop variable
loop:
    check for loop condition    
    if loop finished, jump to end
    // do code inside loop
    unconditionally jump to loop
end:
</code></pre><p>whereas if did the following rust code</p><pre data-info="rust" data-role="codeBlock"><span>let</span> x <span>=</span> <span>0</span><span>;</span>
<span>loop</span><span>{</span>
    
    x <span>+=</span> <span>1</span><span>;</span>
    <span>if</span> i <span>==</span> <span>10</span> <span>{</span>
        <span>break</span><span>;</span>
    <span>}</span>
<span>}</span>
</pre><p>would get directly compiled into;</p><pre data-info="" data-role="codeBlock"><code>    setup loop variable
loop:
    // do code inside loop
    check for loop condition    
    if loop not finished, jump to loop
end:
</code></pre><p>Note that the loop condition is checked at the end of each loop which makes the unconditional jump unnecessary. This is small space saving for one loop but they do add up when there are 30 loops in the program.</p><p>The other, much harder to understand, problem with the idiomatic Rust loop is that in some cases it the compiler would add some additional iterator setup code that really bloated the code. I never fully understood what triggered this additional iterator setup as it was always trivial to replace the<span>&nbsp;</span><code>for {}</code><span>&nbsp;</span>constructs with a<span>&nbsp;</span><code>loop{}</code><span>&nbsp;</span>construct.</p><p>I spent a lot of time optimizing the<span>&nbsp;</span><code>glsl</code><span>&nbsp;</span>code and one of the best class of optimizations ( which also usually made the code run faster) was to operate on an entire vector at a time instead of operating at a component at a time.</p><p>For example, the ray tracing code use a fast<span>&nbsp;</span><a href="http://www.cse.yorku.ca/~amana/research/grid.pdf">grid traversal algorithm</a><span>&nbsp;</span>to check which parts of the map each ray visits. The original algorithm considers each axis separately but it is possible to rewrite the algorithm so it considers all axes at the same time and does not need any branches. Rust doesn't really have a native vector type like glsl but you can use intrinsics to tell it to use SIMD instructions.</p><p>To use intrinsics I would convert the following code</p><pre data-info="rust" data-role="codeBlock">        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>0</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>0</span> <span>]</span><span>*</span>camera_speed<span>;</span>
        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>1</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>1</span> <span>]</span><span>*</span>camera_speed<span>;</span>
        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>2</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>2</span> <span>]</span><span>*</span>camera_speed<span>;</span>
</pre><p>into</p><pre data-info="rust" data-role="codeBlock">        <span>let</span> <span>mut</span> dst<span>:</span>x86<span>:</span><span>:</span>__m128 <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_load_ps</span><span>(</span>global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>)</span><span>;</span>
        <span>let</span> <span>mut</span> src<span>:</span>x86<span>:</span><span>:</span>__m128 <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_load_ps</span><span>(</span>camera_rot_speed<span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>)</span><span>;</span>
        dst <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_add_ps</span><span>(</span> dst<span>,</span> src<span>)</span><span>;</span>
        core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_store_ss</span><span>(</span> <span>(</span><span>&amp;</span><span>mut</span> global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>)</span><span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>,</span> dst <span>)</span><span>;</span>
</pre><p>which would be quite a bit smaller ( but a lot less readable ). Sadly, for some reason this broke the debug build while working perfectly on the release build. Clearly, this is a problem with my intrinsics knowledge and not a problem with Rust. This is something I would spend more time on for my next 4K intro as the space saving were significant.</p><p>There are lot of standard Rust crates for loading OpenGL functions but by default they all load a very large set of OpenGL functions. Each loaded function takes up some space because the loader has to know its name. Crinkler does a very good job of compressing this kind of code but it is not able to completely get rid of the overhead so I had to create my own version<span>&nbsp;</span><code>gl.rs</code><span>&nbsp;</span>that only includes the OpenGL functions that are used in the code.</p><p>My first objective was to write a competitive proper 4K intro to prove that language was suitable for scenarios where every single byte counts and you really need low level control. Typically this has been the sole domain of assembler and C. The secondary objective was to write it using idiomatic Rust as much possible.</p><p>I think I was fairly successful on the first objective. At no point during the development did I feel that Rust was holding me back in any way or that I was sacrificing performance or capabilities because I was using Rust rather than C.</p><p>I was less successful on the second objective. There is far too much<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code that doesn't really need to be there.<span>&nbsp;</span><code>Unsafe</code><span>&nbsp;</span>has a corrupting effect; it is very easy to use<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code to quickly accomplish something (like using mutable statics) but once the unsafe code is there it begets more unsafe code and suddenly it …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html">https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html</a></em></p>]]>
            </description>
            <link>https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742870</guid>
            <pubDate>Sun, 05 Jul 2020 23:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Poor Man's Cluster]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23742683">thread link</a>) | @FilingTrader
<br/>
July 5, 2020 | http://www.regressionist.com/2020/07/05/poor-mans-cluster/ | <a href="https://web.archive.org/web/*/http://www.regressionist.com/2020/07/05/poor-mans-cluster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/cluster.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/cluster.jpg 765w, http://www.regressionist.com/wp-content/uploads/2020/06/cluster-300x229.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/cluster-624x476.jpg 624w" sizes="(max-width: 765px) 100vw, 765px"></figure>



<p>This part might just be me cargo-culting, but I feel like even a startup quant fund needs a compute cluster. I once even heard a joke that any self-respecting quant should be able expand their computational needs to fill an arbitrarily large number of servers. The cluster I’ve just built is a low-budget clunker, made of a motley bunch of leftover and refurbished servers, linked together with parts off eBay. But I’m very proud of it!</p>



<h2>Maximum compute per dollar</h2>



<div><p>New servers cost a fortune, and only a small fraction of the cost is for the actual CPU. These servers are designed for use cases that cannot tolerate downtime, where the administrators are remote, and where all the hardware and even software must be supported by some company with expensive contracts. In contrast, my cluster is designed only for research. Downtime is ok, as long as no data gets lost and I get get back up and running easily. So, my focus is only on maximizing performance given a limited budget. I’m optimizing for compute per dollar. (Incidentally, I’ve found the <a href="https://www.cpubenchmark.net/cpu_list.php">PassMark CPU mark</a> to accurately reflect how well each CPU can handle my workload.)</p><p>There is a stigma around buying refurbished enterprise grade equipment that I don’t understand. Basic compute servers that cost $25k three years ago now cost only $2.5k, refurbished at places like <a href="https://www.metservers.com/">metservers.com</a> or <a href="https://www.stalliontek.com/">stalliontek.com</a>. Both of these companies provide warranties, too. Even better, these are real servers that already exist and can be shipped to you immediately, rather than waiting months for new ones due to things like worldwide memory shortages. New <a href="https://store.mellanox.com/products/mellanox-mcx515a-ccat-connectx-5-en-network-interface-card-100gbe-single-port-qsfp28-pcie3-0-x16-tall-bracket-rohs-r6.html">Mellanox 100GbE</a> infiniband cards cost $795 each, but on <a href="https://www.ebay.com/sch/i.html?_nkw=Mellanox+ConnectX-3+56GbE&amp;_sacat=0&amp;LH_TitleDesc=0&amp;_osacat=0&amp;_odkw=Mellanox+ConnectX-3+56">eBay 56GbE cards</a> can be bought for $40 each.</p></div>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/R630_front.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/R630_front.jpg 598w, http://www.regressionist.com/wp-content/uploads/2020/07/R630_front-300x87.jpg 300w" sizes="(max-width: 598px) 100vw, 598px"></figure>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/R630_back.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/R630_back.jpg 594w, http://www.regressionist.com/wp-content/uploads/2020/07/R630_back-300x107.jpg 300w" sizes="(max-width: 594px) 100vw, 594px"></figure>



<h2>NVMe vs. memory</h2>



<p>Memory can really drive up the cost of a server, doubling or tripling the price. I don’t think loading up on RAM is cost-effective at scale. Instead, I recommend NVMe drives as an affordable alternative. Typical RAM for a refurbished Dell R630 server would be DDR4-2133, which has bandwidth of 136Gbps. The Samsung 970 EVO Plus 2TB NVMe drive has a read speed of 28Gbps. With the right software, an old infiniband card can max out its 56Gbps bandwidth by reading simultaneously from NVMe drives on only 2-3 other boxes in the cluster. For my workload, this is close enough to RAM speed that I/O ceases to be a bottleneck, and I can focus on just getting the computations done.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram.png 828w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-300x200.png 300w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-768x512.png 768w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-624x416.png 624w" sizes="(max-width: 828px) 100vw, 828px"></figure>



<p>I have also chosen to go with retail NVMe drives. They cost far less than enterprise NVMe drives, and they have the same speed (PCIe Gen 3.0 x4) as all but the very newest enterprise drives. The advantage of enterprise drives is the longer lifetime, measured in hundreds or thousands of Terabytes written). But I tend to read far more than I write. Another advantage is that some enterprise drives are dual-port. This is a high-availability feature that allows two hosts to access the same drive, keeping it connected in case of host failure. But as I’ve said, I don’t need expensive high-availability features.</p>



<h2>Distributed storage</h2>



<p>Having a distributed filesystem simplifies coding on a cluster. It makes it feel almost like just working on one big machine. Each job reads and writes to a shared filesystem that is mounted locally, using traditional posix system calls.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs.png 901w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-300x142.png 300w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-768x364.png 768w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-624x296.png 624w" sizes="(max-width: 901px) 100vw, 901px"></figure>



<p>After searching out <a href="http://www.regressionist.com/2020/06/20/reviews-of-distributed-filesystems/">filesystem reviews</a>, I decided to use <strong>MooseFS</strong> for my robust storage. It is easy to configure. It can handle my collection of drives of all sizes, and is robust to the failure of a drive, or even an entire server. It also has a nice browser-based monitoring tool. I have set it up to store one copy of each data chunk on an SSD, and the replicated chunk on a regular spinning disk. The clients are configured to prefer SSD chunkservers, which makes reading reasonably fast. Note: chunkserver labels apply to the whole server, so don’t mix SSDs and HDDs in one server if you want to explicitly prioritize reading from SSDs.</p>



<p>I considered paying for MooseFS Pro, but decided it was too expensive. For a 20TB lifetime license for versions 3.x and 4.x, I was quoted $1,620, or $810 if it was for non-commercial use. The main two benefits of getting a Pro license are 1) getting the high-availability of multiple online master servers instead of just metaloggers, and 2) getting erasure coding for more efficient use of storage space. The erasure coding is interesting to me, but for slow storage, big disks are really cheap. So, storing multiple full copies of a file isn’t such a big deal.</p>



<p>For serious speed, I’ve chosen <strong>BeeGFS</strong> with NVMe drives. BeeGFS supports RDMA (remote direct memory access) with infiniband, so it can move data between boxes without involving the CPUs. It is very fast. It is also relatively easy to configure. I am treating this sort of like volatile storage, and I have not set up “buddy mirrors.” Since I will lose data if my hardware fails, I frequently rsync with the robust storage. I was disappointed to find out that even Pro BeeGFS doesn’t support erasure coding. It would make more sense to use with these expensive NVMe drives. However, erasure coding also slows down both reading and writing. So, I’m ok with giving up robustness in order to have one blazing fast filesystem.</p>



<h2>Conclusion</h2>



<p>Benchmarking a distributed filesystem is complicated and workload-dependent. But everything is working as I hoped. My cluster is mostly hyperconverged, with CPU and storage combined in each server. However, I do have some servers that are clients/CPU only. They are less powerful, so I keep them powered off until needed, to conserve energy. I got an APC AP7911A rack-mount PDU on eBay, so controlling power to the different ports is easy.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/apc-1.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/apc-1.png 488w, http://www.regressionist.com/wp-content/uploads/2020/07/apc-1-300x225.png 300w" sizes="(max-width: 488px) 100vw, 488px"></figure>



<p>Building a cluster has been a lot of fun, and previously slow processes are now excitingly fast. But I’m anxious to begin real research now, and stop messing around with infrastructure.</p>



<h2>Appendix A, configuring infiniband on CentOS 7</h2>



<p>As a non-HPC guy, learning about infiniband, and getting the network functioning was the hardest part of building the cluster. It took me a long time, and lots of reading and trial-and-error. For that reason, I think it’s worth posting detailed instructions on what eventually worked for me. I don’t believe I’m getting all that is possible out of my infiniband network, but I’m still very pleased with it.</p>



<h3>The cards</h3>



<p>I went with 79DJ3 Mellanox ConnectX-3 CX353A FDR InfiniBand + 56GbE/ 40GbE Single QSFP+ RDMA cards. The most recent ones I ordered on eBay were $35 each. I believe the PCIe lanes cannot handle the full bandwidth of the dual-port cards, which is why I stayed with the simpler single-port card/setup. I did have to order replacement brackets for a couple of my high-profile-PCIe computers.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3.png 785w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-300x186.png 300w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-768x476.png 768w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-624x387.png 624w" sizes="(max-width: 785px) 100vw, 785px"></figure>



<h3>The cables</h3>



<p>I went with Mellanox MC2207130-0A1 1.5M IB FDR QSFP copper cables for about $20 each. Fiber optic cables are better for long distances, but these passive cables have worked perfectly.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1024x768.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1024x768.jpg 1024w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-300x225.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-768x576.jpg 768w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1536x1152.jpg 1536w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-624x468.jpg 624w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>The switch</h3>



<p>There are two switches that will work. The first is a small unmanaged switch, the Mellanox SX6005. It runs about $90 used:</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005.png 807w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-300x201.png 300w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-768x514.png 768w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-624x418.png 624w" sizes="(max-width: 807px) 100vw, 807px"></figure>



<p>The second is the larger, managed, Mellanox SX6036. It runs about $300 used:</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1024x353.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1024x353.jpg 1024w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-300x103.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-768x264.jpg 768w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1536x529.jpg 1536w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-624x215.jpg 624w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>If you have more than one switch involved, you can daisy chain them together. You can even run multiple cables between them, which will reduce the bottleneck between the switches. No special configuration is necessary, just plug in multiple cables, and it will spread the load among them to some degree.</p>



<h3>Subnet manager</h3>



<p>There needs to be exactly one subnet manager for the infiniband network. The managed switch can provide this service, but you need to enable it in the configuration interface. The unmanaged switch cannot provide this service. In that case, you need to run a subnet manager on one server. <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-configuring_the_subnet_manager">It is trivial to install on CentOS 7:</a></p>



<pre><code>yum install opensm
systemctl enable opensm
systemctl start opensm</code></pre>



<h3>Software</h3>



<p>I’m using CentOS 7 on my cluster, because at this time neither MooseFS nor BeeGFS supports CentOS 8. When I first played around with Ubuntu, it was much more difficult to get infiniband working. And I also had to downgrade its kernel to get BeeGFS working. I don’t think it is worth all that hassle, and CentOS 7 is working great.</p>



<pre><code># install packages
yum groupinstall "Infiniband Support"
yum install net-tools mstflint infiniband-diags iperf

# disable firewall
systemctl status firewalld
systemctl stop firewalld
systemctl disable firewalld

# disable SELINUX
nano /etc/selinux/config
# set, then reboot
SELINUX=disabled

# start the RDMA service
systemctl start rdma
systemctl enable rdma</code></pre>



<h3>Updating the card firmware</h3>



<p>After installing the infiniband card, find out the PCI address:</p>



<pre><code># Check the device’s PCI address
lspci | grep Mellanox
# 04:00.0 Network controller: Mellanox Technologies MT27500 Family [ConnectX-3]
# so "04:00.0" is the address</code></pre>



<p>Next, use the PCI address to find the card’s PSID, and note the current firmware version:</p>



<pre><code># Identify the adapter card's PSID (last line of the output)
mstflint -d 04:00.0 q
#Image type:            FS2
#FW Version:            2.32.5100
#FW Release Date:       3.9.2014
#Rom Info:              type=PXE version=3.4.306 proto=IB
#Device ID:             4099
#Description:           Node             Port1            Port2            Sys image
#GUIDs:                 e41d2d0300b2bdc0 e41d2d0300b2bdc1 e41d2d0300b2bdc2 e41d2d0300b2bdc3 
#MACs:                                       e41d2db2bdc1     e41d2db2bdc2
#VSD:                   
#PSID:                  DEL1100001019</code></pre>



<p>Now use the PSID to find the latest firmware version:</p>



<pre><code># Download the firmware BIN file from the Mellanox website that matches your card's PSID:
http://www.mellanox.com/page/firmware_table_dell?mtag=oem_firmware_download
Adapters
Dell EMC ConnectX-3 Firmware Download Center
2.42.5000
079DJ3
DEL1100001019
http://www.mellanox.com/downloads/firmware/fw-ConnectX3-rel-2_42_5000-079DJ3-FlexBoot-3.4.752.bin.zip</code></pre>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.regressionist.com/2020/07/05/poor-mans-cluster/">http://www.regressionist.com/2020/07/05/poor-mans-cluster/</a></em></p>]]>
            </description>
            <link>http://www.regressionist.com/2020/07/05/poor-mans-cluster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742683</guid>
            <pubDate>Sun, 05 Jul 2020 22:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Triplebyte data download doesn’t give you all your data]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742473">thread link</a>) | @wolfgang42
<br/>
July 5, 2020 | https://www.linestarve.com/blog/post/triplebyte-data-download/ | <a href="https://web.archive.org/web/*/https://www.linestarve.com/blog/post/triplebyte-data-download/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="<%= page.layout %>-<%= page.slug %>" itemscope="" itemprop="blogPost">
	<div>
		<div>
			<div>
				<p>In May of last year I decided to start looking for a new job, and started by taking <a href="https://triplebyte.com/">Triplebyte</a>’s quiz. Having passed that, I spent the next three months going through the rest of their process, from a <a href="https://triplebyte.com/interview_guide">two-hour remote interview</a> all the way through to final negotiations with the company whose offer I selected. Throughout the process they were extremely competent and helpful, and at the end of it all I had only good things to say about them. They made the whole process go extremely smoothly, answered all the questions I had and gave me a ton of advice on the whole process, and their screening process was not only great from the my perspective but also gave me confidence in the quality of all their candidates.</p>

<p>Then, a little over a month ago, I got an email announcing the upcoming launch of Triplebyte’s new public profiles. I thought they were was a neat idea, and made a note that I should turn mine on next time I started a job hunt. Then someone <a href="https://news.ycombinator.com/item?id=23279837">posted the email on Hacker News</a>, pointing out that buried in the middle of the email was the fact that these new profiles were going to be opt-<em>out,</em> and unless I turned it off in the next week my profile would become public. This understandably caused an uproar, which the Triplebyte CEO Ammon <a href="https://news.ycombinator.com/item?id=23280460">completely misinterpreted</a>, posting a series of <a href="https://news.ycombinator.com/item?id=23280120">inflammatory comments</a> that <a href="https://news.ycombinator.com/item?id=23280472">misunderstood what people were upset about</a> before vanishing. A few days later he came back with a very apologetic email explaining that they weren’t going to go through with it after all, though it received <a href="https://news.ycombinator.com/item?id=23303037">mixed reactions</a>, with a lot of people being concerned that the idea had been considered at all.</p>

<p>In the midst of all this, I submitted a request through the <a href="https://triplebyte.com/privacy-center">Triplebyte privacy center</a> to download my data. (I considered deleting my account, but decided to give them the benefit of the doubt until things settled down.) After approving the request by clicking an email link, I was informed that it might take up to 30 days to complete my request, so I settled down to wait. As the weeks passed, I thought that the sudden influx of requests must have overwhelmed whoever was responsible for gathering the data from all the systems it was stored in.</p>

<p>Then, 36 days after I first submitted the request, I got an email informing me that my data was now ready to be downloaded. I clicked the link in the email, and then another link on the next page, and finally I got—</p>

<p>A 2,917 byte JSON blob.</p>

<p><em>Odd,</em> I thought, <em>that seems like an awfully long time for so little data.</em> (It’s just over 81 bytes per day, in fact, though I realize that’s a silly metric.) Still, I was relieved to know that they hadn’t been gathering reams of data about me behind my back. Scanning over the minified data, it looked like all they had was my address, some information I’d given them about my past jobs and preferred languages, and a couple of recent IP addresses. Seemingly they hadn’t even kept any information at all about my job search with them.</p>

<p>Then I opened up the file in a JSON viewer and gradually realized: <em>this was not all the information they had.</em> It wasn’t even all of the information they were <em>willing to admit</em> they had—it was missing some obvious things, like the text descriptions on the <code>education</code> and <code>work experience</code> objects, which were prominently displayed on my profile page. As far as I can tell, all I got was a sloppy attempt at making it look at a casual glance like they’d given me what I asked for.</p>

<p>This raises serious concerns for me about Triplebyte, even more so than their plan to make profiles public by default, which started this all. That may well have been born of overenthusiastic naïvité, and was quickly rescinded after being exposed to public comment. After that fiasco, though, I would have expected them to double down on making sure that they were taking privacy seriously. They had over a month before sending me this data to fix any issues with the system, and instead they sent me some slapdash attempt at maybe giving me a whiff of my data.</p>

<p>Triplebyte (as they explain in their privacy center) “care deeply about how your personal information is used and shared,” but apparently not enough to actually put effort into getting it right when you ask for it.</p>

<p>(I’ve sent them an email asking what happened to the rest of the data, and will update this post when I get a response. As it’s the weekend I may not hear back for a few days.)</p>

			</div>
		</div>
	</div>
</article></div>]]>
            </description>
            <link>https://www.linestarve.com/blog/post/triplebyte-data-download/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742473</guid>
            <pubDate>Sun, 05 Jul 2020 22:02:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design of modern OS for next century (1998)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23742432">thread link</a>) | @smallstepforman
<br/>
July 5, 2020 | http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html | <a href="https://web.archive.org/web/*/http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<td><p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/mediaos_175.gif" width="175" height="94"></p>

<p><span size="-1">Technical White Paper</span><i><br clear="ALL"></i><b><span size="+3">The Media OS</span></b></p>

<p><i>The needs of digital content design, not to mention physics <br clear="ALL">and economics, are coming into conflict with current <br clear="ALL">OS
architectures. A new definition, the Media OS, <br clear="ALL">can unlock
the door to more powerful media-based personal <br clear="ALL">systems,
and extract more performance from the systems <br clear="ALL">we are using
today.</i></p>



<p>In 1985, a new concept in personal computing began to take hold. Known
as "desktop publishing" and sparked by graphical user interfaces
and the invention of the laser printer, this new use for PCs grew from a
special interest group into a major market that changed the face of paper
publishing, from newsletters to annual reports to advertising. And in the
process, computer-based publishing sold millions of people on the usefulness
of personal computers, and changed the very nature of their work.</p>

<p>A decade later, desktop publishing as we have known it is coming to an
end. It is not the message that is being changed, but the way the message
is being conveyed. CD-ROMs provide us with a high capacity distribution
mechanism that costs pennies to produce in volume. DVDs are on the horizon,
promising to obliterate the CD-ROM and take capacities to new levels. And
the Internet is rushing towards universal coverage, able to deliver any
type of information, to any user, for the cost of the communications channel
and an inexpensive server.</p>

<p>This <i>digital media</i> is changing the way the message is conveyed.
Instead of static images on a page, digital media presents us with a mix
of text, digital audio, digital video, two-way communications, and 3D graphics
and animations.</p>

<p>Content designers everywhere, already computerized by the previous revolution,
have taken to the new media like ducks to water, experimenting with audio,
video and graphics in a myriad of combinations.</p>

<p>In response to the demand of the new media, production lead times are
shrinking from months to days, or even hours. These digital designers are
using new sets of software tools to manipulate this high bandwidth information
in as real-time as possible.</p>

<p>And in the process, they are bringing the personal computer as we know
it to its knees.</p>



<hr><b>Today's Limitations</b><hr>

<p>The computing industry has grown up with promises of doubling processing
power and halving equipment costs every 18 months or so. That pace hasn't
slowed. We have vastly more powerful hardware today than we had even three
years ago.</p>

<p>But the demands of digital media are increasing the need for processing
power at an even faster rate. Digital design requires that we squeeze every
bit of performance out of our current systems, and that we look to opening
new avenues for gaining performance, even as microprocessors continue to
advance.</p>

<p>Unfortunately, in the process applications are exceeding what the current
generation of operating systems were designed to do. Almost all existing
systems were originally designed decades ago, when the idea of personal
computers dealing with real-time video, audio, communications and other
high-bandwidth applications was practically science fiction. Windows 95 has
its roots in DOS, Windows NT in the VAX systems originally designed by DEC,
Mac OS in the early ideas of Xerox Parc and Mach in the labs of Carnegie-Mellon,
both designed in the late 1970s.</p>

<p>As the importance of audio, video and interactive communications has
increased in recent years, we've had to devise increasingly clever -- and
complex -- methods of delivering the performance required of media-based
applications because the <i>foundations</i> of today's systems were simply
not designed with high-bandwidth media in mind.</p>

<p>One example of aging foundations is the use of multiple processors in
a single system. The architectures of most of today's mainstream operating
systems are optimized for execution on uniprocessor systems, an assumption
borne of the days when microprocessors were very expensive. Adding multiprocessor
(MP) capability to these systems is difficult, and often goes only half way.
To gain the maximum benefit, all operating system services and applications
must be written with MP capability in mind, something that is virtually
impossible to do without major disruption. Those of today's systems that
can make some use of multiple processors do so in a coarse-grain way, failing
to take maximum advantage of the hardware resources available.</p>

<p>In addition, as more and more features have been added to today's operating
systems, layers of software "silt" have built up upon their architectural
foundations. These layers deliver new services, route around services no
longer required, provide specialized functions for individual applications
that can't be delivered any other way, and, most of all, provide a level
of backward compatibility. Unfortunately, as this software silt builds up,
it consumes more of the computer's processing power and hardware resources.
And it adds to the complexity of the system -- reducing performance, lowering
stability, and lengthening the time it takes to deliver new software.</p>

<p>This increasing complexity has had two effects. First, customers are
paying for more expensive hardware than they should, just to obtain acceptable
performance with mainstream productivity applications. The effort to counteract
this problem forms the basis of the <i>network computer </i>(NC) concept
-- by simplifying operating systems, moving to modern applications, and removing
the silt, computing can become less expensive.</p>

<p>And second, users are not able to take advantage of the real processing
power that is inherent in today's advanced microprocessors because of the
operating systems silt that lies in the way, making media-based applications
more expensive, and less powerful, than they should be. Solving this problem
lies at the heart of the <i>Media OS</i> concept.</p>



<hr><b>The Necessities of Digital Media</b><hr>

<p>It's not enough to add a few features and call an operating system a
"Media OS." An operating system needs to be architected to deal
natively with digital media. Our experiences with today's generation of
personal computers provide a glimpse at what is necessary to create a true
media-based system, and to squeeze the most possible power out of a system's
hardware resources. From this experience, we can identify five broad areas
in which a media-based system must excel.</p>

<p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/proc_cycles_sm.gif" width="207" height="255"><b>Maximize Processing Power</b></p>

<p>The power of microprocessors continues to advance at a predictable pace.
However, the needs of digital content creators have outstripped even the
best efforts of microprocessor makers, and physics, to keep up. A Media
OS can't rely simply on single processors to handle the load, which means
that it must be <i>multiprocessor capable.</i></p>

<p>Why are multiprocessor systems important? Today, the power of personal
computer systems is generally dependent on a single microprocessor. This
means that we must wait for new, faster generations of microprocessors to
become available in order to build more powerful personal computers.</p>

<p>Multiprocessing gives us a way around this problem. First, it gives us
access to even more powerful systems. We can multiply the effect of increases
in microprocessor performance across multiple processors, rather than just
one. This can provide access to vastly more powerful systems than we have
today, yet with today's PC technologies.</p>

<p>Second, multiprocessing provides us with a more economical way of reaching
a given performance point. The highest performance processor, 400 MHz today,
costs significantly more than 300 MHz processors. Thus it can cost just
as much to put two 300 MHz processors into a system as it does to put a
single 400 MHz processor. Yet the two processors combined deliver 600 MHz
of available cycles. The result is that using a multiprocessor approach
opens a new axis for hardware manufacturers to explore in price-performance
-- leading to new performance levels and options for end users.<img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/price_perf_sm.gif" width="274" height="206"></p>

<p>Opening up new, multiprocessor-based solutions for the mainstream is
a key requirement as we take media design into the next century. There are
a number of other ways to maximize processor performance. For example, how
an operating system implements multiprocessor capability can be even more
important than the capability itself. We'll examine this further a bit later
in this discussion.</p>



<p><b>Graphics Power and Flexibility</b></p>

<p>In addition to consuming massive amounts of processing power, a key characteristic
of the work of digital designers is that it involves the manipulation of
graphics, preferably in real-time (manipulation with no "lag"
or processing time from the user's perspective.) To accomplish this, media-based
systems have to address two things involving graphics capabilities.</p>

<p>First they need to take advantage of specialized graphics coprocessors.
Graphics co-processing is a specialized type of multiprocessing that can
help increase the performance of a system dramatically. This is especially
true in 3D graphics and video compression and decompression, where 
function-specific chips can boost throughput significantly.</p>

<p>Second, the graphics capabilities must be flexible. The types of graphics
work being done by digital designers varies greatly. Some do more 3D work
than video, others more 2D than 3D, and so on. Because of this, a Media
OS must be flexible enough to allow hardware to be configured in the way
that's best for the end user. In addition, flexibility and modularity means
that graphics hardware can be upgraded as new, more powerful solutions become
available, or as the user's needs change.</p>



<p><b>Access to Large Amounts of Storage</b></p>

<p>Another key characteristic of digital design is the amount of data required.
We have moved from floppy storage, to hard drive storage, to CD-ROMs, providing
us with direct access to significantly more data than only a few years ago.
Average hard drive sizes have increased from a few hundred megabytes and
are now approaching 4 gigabytes.</p>

<p><img src="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/resources/file_size.gif" width="189" height="192">
But this is nothing compared to what's going to be required
in the near future. One hour of digital …</p></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html">http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html</a></em></p>]]>
            </description>
            <link>http://testou.free.fr/www.beatjapan.org/mirror/www.be.com/products/beos/mediaos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742432</guid>
            <pubDate>Sun, 05 Jul 2020 21:57:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contrarian view on closing files]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 110 (<a href="https://news.ycombinator.com/item?id=23742390">thread link</a>) | @coady
<br/>
July 5, 2020 | https://coady.github.io/posts/closing-files/ | <a href="https://web.archive.org/web/*/https://coady.github.io/posts/closing-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<div>

<div>
<div>
<h2 id="Contrarian-view-on-closing-files.">Contrarian view on closing files.<a href="#Contrarian-view-on-closing-files.">¶</a>
</h2>
<p>It has become conventional wisdom to always explicitly close file-like objects, via context managers.
The <a href="https://google.github.io/styleguide/pyguide.html#311-files-and-sockets">google style guide</a>
is representative:</p>
<blockquote>
<p>Explicitly close files and sockets when done with them.
Leaving files, sockets or other file-like objects open unnecessarily has many downsides, including:</p>
<p>They may consume limited system resources, such as file descriptors.</p>
<ul>
<li>Code that deals with many such objects may exhaust those resources unnecessarily if they're not returned to the system promptly after use.</li>
<li>Holding files open may prevent other actions being performed on them, such as moves or deletion.</li>
<li>Files and sockets that are shared throughout a program may inadvertantly be read from or written to after logically being closed. If they are actually closed, attempts to read or write from them will throw exceptions, making the problem known sooner.</li>
</ul>
<p>Furthermore, while files and sockets are automatically closed when the file object is destructed, tying the life-time of the file object to the state of the file is poor practice, for several reasons:</p>
<ul>
<li>There are no guarantees as to when the runtime will actually run the file's destructor. Different Python implementations use different memory management techniques, such as delayed Garbage Collection, which may increase the object's lifetime arbitrarily and indefinitely.</li>
<li>Unexpected references to the file may keep it around longer than intended (e.g. in tracebacks of exceptions, inside globals, etc).</li>
</ul>
<p>The preferred way to manage files is using the "with" statement:</p>

<pre><code>with open("hello.txt") as hello_file:
    for line in hello_file:
        print line</code></pre>
</blockquote>
<h3 id="In-theory">In theory<a href="#In-theory">¶</a>
</h3>
<p>Good points, and why limit this advice to file descriptors?  Any resource may be limited or require exclusivity;  that's why they're called resources.  Similarly one should always explicitly call <code>dict.clear</code> when finished with a <code>dict</code>.  After all, "there are no guarantees as to when the runtime will actually run the &lt;object's&gt; destructor.  And "code that deals with many such objects may exhaust those resources unnecessarily", such as memory, or whatever else is in the <code>dict</code>.</p>
<p>But in all seriousness, this advice is applying a notably higher standard of premature optimization to file descriptors than to any other kind of resource.  There are plenty of Python projects that are guaranteed to run on CPython for a variety of reasons, where destructors are immediately called.  And there are plenty of Python projects where file descriptor usage is just a non-issue.  It's now depressingly commonplace to see this in <code>setup.py</code> files:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>with</span> <span>open</span><span>(</span><span>"README.md"</span><span>)</span> <span>as</span> <span>readme</span><span>:</span>
    <span>long_description</span> <span>=</span> <span>readme</span><span>.</span><span>read</span><span>()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<p>Let's consider a practical example: a <code>load</code> function which is supposed to read and parse data given a file path.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>import</span> <span>csv</span>
<span>import</span> <span>json</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""the supposedly bad way"""</span>
    <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>filepath</span><span>))</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""the supposedly good way"""</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>file</span><span>)</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""with a different file format"""</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>return</span> <span>csv</span><span>.</span><span>reader</span><span>(</span><span>file</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>Which versions work correctly?  Are you sure?  If it's not immediately obvious why one of these is broken, that's the point.  In fact, it's worth trying out before reading on.</p>
<p>...</p>
<p>The <code>csv</code> version returns an iterator over a closed file.  It's a violation of procedural abstraction to know whether the result of <code>load</code> is lazily evaluated or not; it's just supposed to implement an interface.  Moreover, according to this best practice, it's <em>impossible</em> to write the <code>csv</code> version correctly.  As absurd as it sounds, it's just an abstraction that can't exist.</p>
<p>Defiantly clever readers are probably already trying to fix it.  Maybe like this:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>yield from</span> <span>csv</span><span>.</span><span>reader</span><span>(</span><span>file</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>No, it will not be fixed.  This version only appears to work by <em>not</em> closing the file until the generator is exhausted or collected.</p>
<p>This trivial example has deeper implications.  If one accepts this practice, then one must also accept that storing a file handle anywhere, such as on an instance, is also disallowed.  Unless of course that object then virally implements it owns context manager, ad infinitum.</p>
<p>Furthermore it demonstrates that often the context is not being managed locally.  If a file object is passed another function, then it's being used outside of the context.  Let's revisit the <code>json</code> version, which works because the file is fully read.  Doesn't a json parser have some expensive parsing to do after it's read the file?  It might even throw an error.  And isn't it desirable, trivial, <a href="https://github.com/python/cpython/blob/master/Lib/json/__init__.py#L274">and likely</a> that the implementation releases interest in the file as soon as possible?</p>
<p>So in reality there are scenarios where the supposedly good way could keep the file open <em>longer</em> than the supposedly bad way.  The original inline version does exactly what it's supposed to do: close the file when all interested parties are done with it.  Python uses garbage collection to manage shared resources.  Any attempt to pretend otherwise will result in code that is broken, inefficient, or reinventing reference counting.</p>
<p>A true believer now has to accept that <code>json.load</code> is a useless and dangerous wrapper, and that the only correct implementation is:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>contents</span> <span>=</span> <span>file</span><span>.</span><span>read</span><span>()</span>
    <span>return</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>contents</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>This line of reasoning reduces to the absurd: a file should never be passed or stored anywhere.  Next an example where the practice has caused real-world damage.</p>
<h3 id="In-practice">In practice<a href="#In-practice">¶</a>
</h3>
<p><a href="https://requests.readthedocs.io/en/master/">Requests</a> is one of the most popular python packages, and <a href="https://docs.python.org/3/library/http.client.html#module-http.client">officially recommended</a>.  It includes a <a href="http://requests.readthedocs.org/en/latest/user/advanced/#session-objects">Session</a> object which supports closing via a context manager.  The vast majority of real-world code uses the the top-level functions or single-use sessions.</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>...</span><span>)</span>

<span>with</span> <span>requests</span><span>.</span><span>Session</span><span>()</span> <span>as</span> <span>session</span><span>:</span>
    <span>response</span> <span>=</span> <span>session</span><span>.</span><span>get</span><span>(</span><span>...</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>Sessions manage the connection pool, so this pattern of usage is establishing a new connection every time.  There are popular standard API clients which seriously do this, for every single request to the same endpoint.</p>
<p>Requests' documentation prominently states that "Keep-alive and HTTP connection pooling are 100% automatic".  So part of the blame may lay with that phrasing, since it's only "automatic" if sessions are reused.  But surely a large part of the blame is the dogma of closing sockets, and therefore sessions, explicitly.
The whole point of a connection pool is that it may leave connections open, so users who genuinely need this granularity are working at the wrong abstraction layer.  <code>http.client</code> is already builtin for that level of control.</p>
<p>Tellingly, requests' own top-level functions didn't always close sessions.  There's a long history to that code, including a <a href="https://github.com/kennethreitz/requests/commit/3155bc99362a8c6ab136b6a3bb999732617cd2e5">version that only closed sessions on success</a>.  An older version was <a href="https://github.com/kennethreitz/requests/issues/1882">causing warnings</a>, when run to check for such warnings, and was being blamed for the <em>appearance</em> of <a href="https://github.com/kennethreitz/requests/issues/1685">leaking memory</a>.  Those threads are essentially debating whether a resource pool is "leaking" resources.</p>

</div>
</div>
</div>
<div>

<div>
<div>
<h3 id="Truce">Truce<a href="#Truce">¶</a>
</h3>
<p>Prior to <code>with</code> being introduced in Python 2.5, it was <em>not</em> recommended that inlined reading of a file required a <code>try... finally</code> block.  Far from it, in the past idioms like <code>open(...).read()</code> and <code>for line in open(...)</code> were lauded for being succinct and expressive.  But if all this orphaned file descriptor paranoia was well-founded, it would have been a problem back then too.</p>
<p>Finally, let's address readability.  It could be argued (though it rarely is) that showing the reader when the file is closed has inherent value.  Conveniently, that tends to align with having opened the file for writing anyway, thereby needing an reference to it.  In which case, the readability is approximately equal, and potential pitfalls are more realistic.  But readability is genuinely lost when the file would have been opened in a inline expression.</p>
<p>The best practice is unjustifiably special-casing file descriptors, and not seeing its own reasoning through to its logical conclusion.  This author proposes advocating for <em>anonymous read-only</em> <code>open</code> expressions.  Your setup script is not going to run out of file descriptors because you wrote <code>open("README.md").read()</code>.</p>

</div>
</div>
</div>
</div>
    </div></div>]]>
            </description>
            <link>https://coady.github.io/posts/closing-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742390</guid>
            <pubDate>Sun, 05 Jul 2020 21:50:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Zola (static site generator) Workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742328">thread link</a>) | @0xC45
<br/>
July 5, 2020 | https://0xc45.com/blog/my-zola-workflow/ | <a href="https://web.archive.org/web/*/https://0xc45.com/blog/my-zola-workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<h2 id="overview">Overview</h2>
<p>To build this website, I use the <a href="https://www.getzola.org/">Zola static site engine</a>. So far, it has worked great. In this blog post, I will discuss my workflow improvements for using Zola, developing my blog posts, and publishing this website. As a quick intro, however, I will give a brief summary of the main features of Zola and why I chose to use it.</p>
<h3 id="what-is-zola">What is Zola?</h3>
<p>Zola advertises itself as a static site engine. It "compiles" Markdown content files, HTML templates (based on the <a href="https://tera.netlify.app/">Tera template engine</a>), and <a href="https://sass-lang.com/">Sass</a> styling into static HTML and CSS pages. This way, a Zola website does not require any server-side code to "render" the website pages.</p>
<p>In addition, Zola has several convenience features that one would want for a blog or website, such as built-in <a href="https://www.getzola.org/documentation/content/syntax-highlighting/">syntax highlighting</a>, simplified <a href="https://www.getzola.org/documentation/templates/pagination/">pagination</a>, and auto-generation of <a href="https://www.getzola.org/documentation/templates/feeds/">atom/rss feeds</a>.</p>
<p>So, Zola is an all-in-one tool for generating static websites. As a blog author, I can mainly focus on writing my blog post content (in Markdown). I don't have to worry too much about HTML syntax, CSS styling, linking, pagination, or my Atom feed (after the initial setup and creation of my site theme). When I'm done writing a blog post, I "generate" the static site with Zola. All of the repetitive and error-prone work is handled for me and the actual static website pages are produced.</p>
<h3 id="why-use-zola">Why use Zola?</h3>
<p>There are many competing static site generators out there. Zola is but one of many. Currently, Hugo and Jekyll are probably the two most popular static site generators. However, for this website, I chose to use Zola for a few reasons:</p>
<ul>
<li>It's simple. It doesn't have a ridiculous number of features that will confuse me and distract me from actually writing blog posts.</li>
<li>It's capable. It has all the feature that I need.</li>
<li>It's a relatively new project. Why not give it a try?</li>
</ul>
<h2 id="my-zola-workflow">My Zola Workflow</h2>
<p>Rather than repeat stuff you can find in the Zola documentation, in this blog post I will cover three of my personal "workflow hacks" for working with Zola. Hopefully at least a couple of these patterns are useful to you.</p>
<h3 id="git-pre-push-hook">Git pre-push Hook</h3>
<p>Because this blog is hosted on Github pages, <code>git push</code> is equivalent to publishing the site. Early on, I made the mistake of writing an entire blog post, but forgetting to "generate" the static site. So, I made a commit, pushed, and nothing happened.</p>
<p>To prevent myself from making this mistake again, I added a "pre-push" hook to my git repo. Now, git will refuse to push if the generated static site is out of date.</p>
<p>Here is my simple "pre-push" git hook:</p>
<pre><code><span>#!/usr/bin/env bash

</span><span>project_root</span><span>="$</span><span>( </span><span>git</span><span> rev-parse</span><span> --show-toplevel </span><span>)</span><span>"
</span><span>pushd </span><span>"$</span><span>{</span><span>project_root</span><span>}</span><span>" &amp;&gt; /dev/null || </span><span>exit</span><span> 1
</span><span>make </span><span>&amp;&gt; /dev/null
</span><span>num_diff_files</span><span>="$</span><span>( </span><span>git</span><span> diff</span><span> --name-only </span><span>| </span><span>wc -l </span><span>)</span><span>"
</span><span>num_untracked_files</span><span>="$</span><span>( </span><span>git</span><span> ls-files</span><span> --others --exclude-standard </span><span>| </span><span>wc -l </span><span>)</span><span>"
</span><span>if </span><span>[ </span><span>"$</span><span>{</span><span>num_diff_files</span><span>}</span><span>" != "</span><span>0</span><span>" </span><span>] </span><span>|| </span><span>[ </span><span>"$</span><span>{</span><span>num_untracked_files</span><span>}</span><span>" != "</span><span>0</span><span>" </span><span>] </span><span>; </span><span>then
  </span><span>echo </span><span>"</span><span>diff detected after running </span><span>\`</span><span>make</span><span>\`</span><span>, not pushing</span><span>"
  </span><span>exit</span><span> 1
</span><span>fi
</span><span>popd </span><span>&amp;&gt; /dev/null || </span><span>exit</span><span> 1
</span></code></pre>
<p>In summary, this git hook builds the site (with Zola) and then checks if any git diff is detected. If there is a git diff (or new, un-tracked file), the hook will prevent the <code>git push</code> from running.</p>
<p>As you might notice, this script depends on <code>make</code>. To build the website, I have a Makefile target (which will be discussed soon).</p>
<h3 id="docker-image">Docker Image</h3>
<p>Next, rather than install the <code>zola</code> binary on my base system, I decided to create a docker image that contains Zola. So, I now have a portable means to generate the site. In the future, I could potentially add some sort of continuous deployment automation to regenerate the site on every git push using this docker image. Additionally, the docker image locks Zola at a specific version (which I can be conscientious about upgrading).</p>
<p>Here is my Zola docker image: <a href="https://github.com/0xC45/zola-docker">https://github.com/0xC45/zola-docker</a>.</p>
<h3 id="makefile">Makefile</h3>
<p>Lastly, I use a Makefile to build the site. Because I use a docker image to run Zola, some of the commands are quite complicated. Particularly, it was somewhat difficult to set up UID/GID mapping and port binding. Using a Makefile documents the commands in code and saves me from having to remember them. Here is my Makefile:</p>
<pre><code><span>.PHONY</span><span>: all</span><span>
all</span><span>:</span><span>
	PROJECT_ROOT</span><span>=</span><span>"</span><span>$$(</span><span>git rev-parse --show-toplevel</span><span>)</span><span>" &amp;&amp; \
	docker run \
	  --rm \
	  -it \
	  -u </span><span>$$(</span><span>id -u </span><span>$${</span><span>USER</span><span>})</span><span>:</span><span>$$(</span><span>id -g </span><span>$${</span><span>USER</span><span>}) </span><span>\
	  -v "</span><span>$${</span><span>PROJECT_ROOT</span><span>}</span><span>:/site" \
	  zola:v0.11.0 \
	  bash -c 'cd /site &amp;&amp; zola build -o docs'</span><span>

.PHONY</span><span>: serve</span><span>
serve</span><span>:</span><span>
	PROJECT_ROOT</span><span>=</span><span>"</span><span>$$(</span><span>git rev-parse --show-toplevel</span><span>)</span><span>" &amp;&amp; \
	docker run \
	  --rm \
	  -it \
	  -u </span><span>$$(</span><span>id -u </span><span>$${</span><span>USER</span><span>})</span><span>:</span><span>$$(</span><span>id -g </span><span>$${</span><span>USER</span><span>}) </span><span>\
	  -v "</span><span>$${</span><span>PROJECT_ROOT</span><span>}</span><span>:/site" \
	  -p 127.0.0.1:1111:1111 \
	  zola:v0.11.0 \
	  bash -c 'cd /site &amp;&amp; zola serve -i 0.0.0.0'</span><span>

.PHONY</span><span>: </span><span>clean
</span><span>clean</span><span>:
	</span><span>rm -rf docs/
</span></code></pre>
<p>There are three main targets: <code>all</code>, <code>serve</code>, and <code>clean</code>.</p>
<ul>
<li><code>all</code>: This target generates the static site.</li>
<li><code>serve</code>: This target runs a "development" server on my local machine, allowing me to preview changes.</li>
<li><code>clean</code>: This target deletes the directory containing the generated static site.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>So, there you have it. These are my custom workflow improvements for using the Zola static site engine. So far, Zola has been a fantastic utility for generating my blog site. Of course, it does not have all the features of other popular static site generators, but it's perfect for my use case. It's simple, easy to use, fast, and capable. I definitely recommend checking it out.</p>

    </section></div>]]>
            </description>
            <link>https://0xc45.com/blog/my-zola-workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742328</guid>
            <pubDate>Sun, 05 Jul 2020 21:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with TypeScript 4.0's Variadic Tuple Types (Variadic Kinds)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742046">thread link</a>) | @munchor
<br/>
July 5, 2020 | https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/ | <a href="https://web.archive.org/web/*/https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        




<main id="site-main" role="main">
    <div>

        <article>

            


            <section>
                <p>I wrote some code over 2 years ago that can't be properly typed with either <a href="https://flow.org/">Flow</a> or <a href="https://www.typescriptlang.org/">TypeScript</a>, but with the introduction of <a href="https://github.com/microsoft/TypeScript/pull/39094">Variadic Tuple Types</a> coming in TypeScript 4.0, I decided to give this piece of code a second look.</p><p>We have a function called <code>innerJoin</code> which takes in 2+N arguments:</p><ol><li>A <code>comparator</code> function</li><li>A <code>merge</code> function</li><li>A variadic list of arrays that all have to be sorted the same way: <code>...arrs</code></li></ol><p>The inner join function loops through all of the arrays "at the same time", looks for items that need to be merged based on some "join predicate" (the <code>comparator</code> function) and then calls the <code>merge</code> function with all of those items to generate a "merged" item that will go on the end result array.</p><p>Here's an example of how to use this function in a very simple test case:</p><pre><code>function idComparator(a: { id: number }, b: { id: number }) {
    if (a.id &lt; b.id) {
        return -1;
    } else if (a.id === b.id) {
        return 0;
    } else {
        return 1;
    }
}

const array1 = [
    {
        id: 1,
        name: "David",
    },
    {
        id: 2,
        name: "Miguel",
    },
];

const array2 = [
    {
        id: 1,
        country: "Portugal",
    },
    {
        id: 2,
        country: "Portugal",
    },
    {
        id: 3,
        country: "USA",
    },
];

expect(
    innerJoin(idComparator, (a, b) =&gt; ({ ...a, ...b }), array1, array2)
).toEqual([
    {
        id: 1,
        name: "David",
        country: "Portugal",
    },
    {
        id: 2,
        name: "Miguel",
        country: "Portugal",
    },
]);
</code></pre><p>As you can see, a match was found for items 1 and 2, which resulted in a "merge" and item 3 was only present in one of the arrays, so it doesn't appear in the end result. A visualization of this algorithm can be seen here:</p><figure><img src="https://davidgomes.com/content/images/2020/05/merge_join.gif" alt=""></figure><p>So, how was this function implemented? (The comments should explain everything you need to know)</p><p><strong>inner-join.js</strong></p><p>(Notice that this is a JavaScript file which means that any potential type errors on it will go unnoticed)</p><pre><code>// This file's type definitions live in inner-join.d.ts, as we need to separate
// the type definition from the type implementation.

import _ from "lodash";

// All the arrays have to be sorted the same way. If not, the behavior
// of this function is *undefined*.
//
// A good visualization of this algorithm can be found here:
// http://sqlity.net/wp-content/uploads/2012/12/merge-join-algorithm.gif.
export default function innerJoin(comparator, merge, ...arrs) {
    const output = [];

    let iterators = _.fill(Array(arrs.length), 0);

    // We should only continue looping if none of the pointers is
    // at the end of their respective array. This is because we can
    // only match if we have a value from each array.
    const canContinue = () =&gt;
        _.every(arrs, (arr, index) =&gt; iterators[index] &lt; arr.length);

    // Gets all the current values by grabbing the value we are
    // currently pointing to for each array.
    const getAllValues = () =&gt;
        _.map(arrs, (arr, index) =&gt; arr[iterators[index]]);

    // Tests whether all current values match by comparing all of them
    // against the first element.
    const allValuesEqual = () =&gt;
        _.every(
            arrs,
            (arr, index) =&gt;
                comparator(arrs[0][iterators[0]], arr[iterators[index]]) === 0
        );

    while (canContinue()) {
        const values = getAllValues();
        const comparison = allValuesEqual();

        if (comparison) {
            output.push(merge(...values));
            iterators = _.map(iterators, it =&gt; ++it);
        } else {
            let minimumIndex = 0;

            let i;
            for (i = 1; i &lt; arrs.length; i++) {
                if (
                    comparator(
                        arrs[i][iterators[i]],
                        arrs[minimumIndex][iterators[minimumIndex]]
                    ) === -1
                ) {
                    minimumIndex = i;
                }
            }

            iterators[minimumIndex]++;
        }
    }

    return output;
}</code></pre><p>As you can see on the very first line of the <code>inner-join.js</code> file, the type definitions for this file live elsewhere: in <code>inner-join.d.ts</code>. Let's see what that file looks like:</p><p><strong>inner-join.d.ts</strong></p><pre><code>export default function innerJoin&lt;T1, T2, T3&gt;(
    comparator: (first: T1, second: T2) =&gt; -1 | 0 | 1,
    merge: (first: T1, second: T2) =&gt; T3,
    arr1: Array&lt;T1&gt;,
    arr2: Array&lt;T2&gt;
): Array&lt;T3&gt;;

export default function innerJoin&lt;T1, T2, T3, T4&gt;(
    comparator: (first: T1, second: T2 | T3) =&gt; -1 | 0 | 1,
    merge: (first: T1, second: T2, third: T3) =&gt; T4,
    arr1: Array&lt;T1&gt;,
    arr2: Array&lt;T2&gt;,
    arr3: Array&lt;T3&gt;
): Array&lt;T4&gt;;</code></pre><p>The <code>innerJoin</code> function is generic over an arbitrary number of types, so typing it alongside its implementation without variadic tuple types is not possible. So, we had to move its type definitions to a separate file. On the separate file, we hand-type the function's type definition for 4 and 5 arguments. If we ever need to call this function with more arguments, we'll have to manually add more type definitions in this file.</p><p>While this isn't great, it's also not a huge problem since we can easily generate 20 or 30 of these type definitions and not have to worry about it for a long time. Some open source libraries like <a href="https://github.com/reduxjs/reselect">reselect</a> have been doing <a href="https://github.com/reduxjs/reselect/blob/36f256b59b876705144147d409a73a3c4cb3c64d/src/index.d.ts#L21">this as well</a> for a long time.</p><h2 id="rewriting-our-code-using-typescript-4-0-s-variadic-tuple-types">Rewriting our code using TypeScript 4.0's Variadic Tuple Types</h2><p>The first thing we have to define is what <code>innerJoin</code> is generic <em>over.</em> That's easy, it is generic over 2 "things":</p><ul><li>A tuple type corresponding to the types of all the arrays that will be passed in (e.g., if generic over <code>[A, C]</code>, then it must receive as arguments <code>[Array&lt;A&gt;, Array&lt;C&gt;]</code>.</li><li>The output type of the join (e.g., if generic over <code>M</code>, it must return <code>Array&lt;M&gt;</code>).</li></ul><p>We can easily express this as:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    ...
): MergedType { ... }</code></pre><p>Now let's think about the input types:</p><ul><li>The <code>comparator</code> function which receives 2 arguments: an element from the first array and an element from either one of the remaining arrays. This function has to return 0, -1 or 1.</li><li>The <code>merge</code> function which receives N arguments: on element from each of the input arrays. This function has to return an instance of <code>MergedType</code>.</li><li><code>arrs</code>: the list of input arrays.</li></ul><p>The <code>comparator</code> is a function that receives an argument with type <code>T[0]</code> (the type of the first element in the tuple) and another argument with the union type of all the other types in <code>T[1...N]</code>. We can use <code><a href="https://dev.to/kjleitz/comment/gb5d">DropFirstInTuple</a></code> and then use the <code>A[number]</code> syntax. What this syntax means is that we want to get the type of what we can index out of <code>A</code> with a <code>number</code> — if <code>A</code> is a tuple, then <code>A[number]</code> will correspond to the union type of all the element types of <code>A</code>). Here's all of that together:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    ...
): MergedType { ... }</code></pre><p>(The <code>DropFirstInTuple</code> type was written by <a href="https://github.com/kjleitz">Keegan Leitz</a>, and I found it <a href="https://dev.to/kjleitz/comment/gb5d">here</a>)</p><p>The <code>merge</code> function is fairly simple to type:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    merge: (...t: T) =&gt; MergedType,
    ...
): MergedType { ... }</code></pre><p>The list of input <code>arrs</code> is a little bit more challenging to type:</p><pre><code>export default function innerJoin&lt;
    T extends unknown[], 
    MergedType
&gt;(
    comparator: (t1: T[0], tOther: DropFirstInTuple&lt;T&gt;[number]) =&gt; -1 | 0 | 1,
    merge: (...t: T) =&gt; MergedType,
    ...arrs: { [K in keyof T]: Array&lt;T[K]&gt; }
): MergedType { ... }</code></pre><p><code>{ [K in keyof T]: Array&lt;T[K]&gt; }</code> can be explained as follows:</p><blockquote>For each key of <code>T</code> (<code>T</code> is a tuple type, so the keys are numbers like 0, 1, 2, etc.), we need the value to be an <code>Array&lt;T[K]&gt;</code>.</blockquote><p>To exemplify, if <code>T</code> is <code>[A, C]</code> then <code>{ [K in keyof T]: Array&lt;T[K]&gt; }</code> will be <code>[Array&lt; A&gt;, Array&lt;C&gt;]</code>.</p><p>Using TypeScript 4.0, we've been able to type our <code>innerJoin</code> function! However, there is a TypeScript error further down in the file:</p><pre><code>...
    const getAllValues = () =&gt;
        arrs.map((arr, index) =&gt; arr[iterators[index]]);

...

    if (comparison) {
        output.push(merge(...values));
...</code></pre><pre><code>Argument of type 'unknown[]' is not assignable to parameter of type 'T'.
  'unknown[]' is assignable to the constraint of type 'T', but 'T' could be instantiated with a different subtype of constraint 'unknown[]'.</code></pre><p>So the issue is that the TypeScript type checker doesn't understand that <code>getAllValues</code> returns a value of type <code>T</code>. If we try to annotate the output of <code>getAllValues</code> as <code>T</code>, we get the same error. The core issue is that we're <strong>mapping</strong> over a tuple type and so TypeScript just can't guess that the return type of <code>map</code> will be of type <code>T</code> since that would require the type checker understanding that <code>map</code> is an ordered traversal over a finite set of elements.</p><p>To get around this, we need to use a (dreaded) type assertion:</p><pre><code>// Gets all the current values by grabbing the value we are
// currently pointing to for each array.
// TYPE ASSERTION: This function leverages a type assertion which is
// something one should never do as they are not type safe. However, there
// is no other way to map over a tuple type and return another tuple type.
const getAllValues = () =&gt;
    arrs.map((arr, index) =&gt; arr[iterators[index]]) as T;</code></pre><p>And that's it! Here's the final <code>inner-join.ts</code>:</p><pre><code>// This file's type definitions live in inner-join.d.ts, as we need to separate
// the type definition from the type implementation.

import _ from "lodash";

// CREDIT to https://github.com/kjleitz for this type:
// https://dev.to/kjleitz/comment/gb5d

// Drops the first element of a tuple. Example:
//
//   type Foo = DropFirstInTuple&lt;[string, number, boolean]&gt;;
//   //=&gt; [number, boolean]
//
export type DropFirstInTuple&lt;T extends any[]&gt; = ((...args: T) =&gt; any) extends (arg: any, ...rest: infer U) =&gt; any ? U : T;

// All the arrays have to be sorted the same way. If …</code></pre></section></article></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/">https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/</a></em></p>]]>
            </description>
            <link>https://davidgomes.com/refactoring-some-code-to-use-typescripts-variadic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742046</guid>
            <pubDate>Sun, 05 Jul 2020 21:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Estimated Cost of the DMT Machine Elves Prime Factorization Experiment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23741946">thread link</a>) | @palimpsests
<br/>
July 5, 2020 | https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/ | <a href="https://web.archive.org/web/*/https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<blockquote><p>“Okay,” I said. “Fine. Let me tell you where I’m coming from. I was reading&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else">Scott McGreal’s blog</a>, which has some&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201210/dmt-aliens-and-reality-part-1">good</a>&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201210/dmt-aliens-and-reality-part-2">articles</a>&nbsp;about so-called DMT entities, and mentions how they seem so real that users of the drug insist they’ve made contact with actual superhuman beings and not just psychedelic hallucinations. You know,&nbsp;<a href="http://smile.amazon.com/gp/product/0062506528/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0062506528&amp;linkCode=as2&amp;tag=slastacod-20&amp;linkId=BKGSPUHIEWFDXXWZ">the usual</a><img src="http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&amp;l=as2&amp;o=1&amp;a=0062506528" alt="" width="1" height="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">&nbsp;Terence McKenna stuff. But in&nbsp;<a href="https://www.psychologytoday.com/blog/unique-everybody-else/201408/dmt-gateway-reality-fantasy-or-what">one</a>&nbsp;of them he mentions a paper by Marko Rodriguez called&nbsp;<a href="http://www.ayahuasca-info.com/data/articles/paralleldmt.pdf"><i>A Methodology For Studying Various Interpretations of the N,N-dimethyltryptamine-Induced Alternate Reality</i></a>, which suggested among other things that you could prove DMT entities were real by taking the drug and then asking the entities you meet to factor large numbers which you were sure you couldn’t factor yourself. So to that end, could you do me a big favor and tell me the factors of 1,522,605,027, 922,533,360, 535,618,378, 132,637,429, 718,068,114, 961,380,688, 657,908,494, 580,122,963, 258,952,897, 654,000,350, 692,006,139?</p>
<p>– <a href="http://slatestarcodex.com/2015/04/21/universal-love-said-the-cactus-person/">Universal Love, Said the Cactus Person</a>, by <a href="http://slatestarcodex.com/">Scott Alexander</a></p></blockquote>
<p>In the comments…</p>






<p>I was a little curious about how such a prime experiment would go and how much it would cost. It looks like one could probably run an experiment with a somewhat OK chance at success for under $1k.</p>
<p>We need to estimate the costs and probabilities of memorizing a suitable composite number, buying DMT, using DMT and getting the requisite machine-elf experience (far from guaranteed), being able to execute a preplanned action like asking about a prime, and remembering the answer.</p>
<div>
<p>1. The smallest RSA number not <a href="https://en.wikipedia.org/wiki/RSA_numbers#RSA-220">yet factored is 220 digits</a>. The RSA numbers themselves are useless for this experiment because if one did get the right factors, because it’s so extraordinarily unlikely for machine-elves to really be an independent reality, a positive result would only prove that someone had stolen the RSA answers or hacked a computer or something along the lines. RSA-768 was factored in 2009 using ~2000 CPU-years, so we need a number much larger; since Google has several million CPUs we might want something substantially larger, at least 800 digits. We know from mnemonists that numbers that large can be routinely memorized, and an 800 digit decimal can be <a href="http://www.recordholders.org/en/list/memory.html#numbers-1h">memorized in an hour</a>.&nbsp;Chao Lu memorized <a href="http://www.pi-world-ranking-list.com/lists/details/luchaointerview.html">67k digits of Pi in 1 year</a>. So the actual memorization time is not significant. How much training does it take to memorize 800 digits? I remember a famous example in WM research of how WM training does not necessarily transfer to anything, of a student taught to memorize digits, <a href="https://www.cmu.edu/dietrich/psychology/">Ericsson &amp; Chase</a>’s&nbsp;whose digit span went from ~7 to ~80 after 230 hours of training; digit span is much more demanding than a one-off memorization. <a href="https://publishup.uni-potsdam.de/opus4-ubp/frontdoor/deliver/index/docId/3846/file/1987_mnemonic.pdf">This</a> does something similar using more like 80 hours of training. Foer’s _Moonwalking With Einstein: The Art and Science of Remembering Everything_ doesn’t cover much more than a year or two and fairly undemanding training regimen, and he performed well. So I’m going to guess that to memorize a number which would be truly impressive evidence (and not simply evidence for a prank or misdeeds by a hobbyist, RSA employee, Google, or the NSA) would require ~30h of practice.<br>
2. some browsing of the DMT category on the current leading black-market suggests that 1g of DMT from a reputable seller costs ฿0.56 or ~$130. The linked paper says smoking DMT for a full trip requires 50mg/0.05g so our $130 buys ~19 doses.<br>
3. The <a href="http://www.ayahuasca-info.com/data/articles/paralleldmt.pdf">linked paper</a>&nbsp;says that 20% of Strassman’s injected-DMT trips give a machine-elf experience; hence the 1g will give an average of ~3-4 machine-elfs and 19 trips almost guarantees at least 1 machine-elf assuming 20% success-rate (1-(1-0.2)^19 = 98%). Since the 20% figure comes from injected DMT and DMT of a controlled high quality, probably this is optimistic for anyone trying out smoking DMT at home, but let’s roll with it.<br>
4. in a machine-elf experience, how often could we be lucid enough to wake up and ask the factoring question? No one’s mentioned trying so there’s no hard data, but we can borrow from a similar set of experiments in verifying altered states of consciousness, Laberge’s lucid dreaming experiments in which subjects had to exert control to wiggle their eyes in a fixed pattern. <a href="http://diyhpl.us/~bryan/papers2/dreaming/Lucidity%20Institute%20Research%20Papers.pdf#page=163">This study</a> gives several flows from # of nights to # of verifications, which all are roughly 1/3 – 1/4; so given our estimated 3-4 machine-elfs, we might be able to ask 1 time. If the machine-elves are guaranteed to reply correctly, then that’s all we need.<br>
5. at 30 hours of mnemonic labor valued at minimum wage of $8 and $130 for 19 doses, that gives us an estimate of $370 in costs to ask an average of once; if we amortize the memorization costs some more by buying 2g, then we instead spend $250 per factoring request for 2 tries; and so on down to a minimum cost of (130/19)*5 = $34 per factoring request. To get n=10 requests, we’d need to spend a cool ((30*8) + 10*130)=$1540.<br>
6. power analysis for a question like this is tricky, since we only need one response with the *right* factors; probably what will happen is that the machine-elfs will not answer or any answer will be ‘forgotten’. You can estimate other stuff like how likely the elves are to respond given 10 questions and 0 responses (flat prior’s 95% CI: 0-28%), or apply decision-theory to decide when to stop trying (tricky, since any reasonable estimate of the probability of machine-elves will tell you that at $35 a shot, you shouldn’t be trying at all).</p>
<p>Hence, you could get a few attempts at somewhere under $1k, but exactly how much depends sensitively on what fraction of trips you get elves and how often you manage to ask them; the DMT itself doesn’t cost *that* much per dose (like ~$7) but it’s the all the trips where you don’t get elves or you get elves but are too ecstatic to ask them anything which really kill you and drive up the price to $34-$250 per factoring request. Also, there’s a lot of uncertainty in all these estimates (who knows how much any of the quoted rates differ from person to person?).</p>
<p>I thought this might be a fun self-experiment to do, but looking at the numbers and the cost, it seems pretty discouraging.</p>
<hr>
<p><strong>Related Empirical Paradigms for Psychedelic Research</strong>:</p>
<ol>
<li><a href="https://qualiacomputing.com/2016/10/29/lsd-and-quantum-measurements-can-you-see-schrodingers-cat-both-dead-and-alive-on-acid/">LSD and Quantum Measurement</a> (an experiment that was designed, coded up, and conducted to evaluate whether one can experience multiple Everett branches at once while on LSD).</li>
<li><a href="https://qualiacomputing.com/2015/05/22/how-to-secretly-communicate-with-people-on-lsd/">How to Secretly Communicate with People on LSD</a>&nbsp;(a method called <em>Psychedelic Cryptography</em>&nbsp;which uses the slower qualia decay factor induced by psychedelics, aka. “tracers”, in order to encode information in gifs that you can only decode if you are sufficiently high on a psychedelic).</li>
<li><a href="https://qualiacomputing.com/2015/04/20/psychophysics-for-psychedelic-research-textures/">Psychophysics for Psychedelic Research: Textures</a>&nbsp;(an experimental method developed by <a href="http://cvcl.mit.edu/SUNSeminar/Balas_texture_VR06.pdf">Benjamin Bala</a>&nbsp;based on the <a href="http://www.cns.nyu.edu/~lcv/texture/">textural&nbsp;mongrel</a> paradigm proposed by&nbsp;<a href="http://www.cns.nyu.edu/~eero/">Eero Simoncelli</a>&nbsp;and extended to provide insights into psychedelic visual perception. See: <a href="http://scarlet.stanford.edu/teach/index.php/Psychophysical_assessments_of_Portilla_and_Simoncelli's_texture_synthesis_algorithm">analysis</a>).</li>
</ol>
</div>
					</div></div>]]>
            </description>
            <link>https://qualiacomputing.com/2018/10/15/estimated-cost-of-the-dmt-machine-elves-prime-factorization-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741946</guid>
            <pubDate>Sun, 05 Jul 2020 21:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Risk management and RR ratio in trading, a quantitative approach]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741918">thread link</a>) | @ohlongjohn
<br/>
July 5, 2020 | https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/ | <a href="https://web.archive.org/web/*/https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    
<p><strong>Contents in this article:</strong></p>



<ol><li><a href="#introduction">Opening note</a></li><li><a href="#portfolio">Portfolio</a></li><li><a href="#acc-size">Account Size</a></li><li><a href="#acc-risk">Account Risk</a></li><li><a href="#trade-risk">Trade Risk</a></li><li><a href="#pos-size">Position Sizing</a></li><li><a href="#final">Final Word</a></li></ol>



<h2 id="introduction">Introduction </h2>



<p>Be it small or large, any kind of portfolio needs proper risk management. The whole point of risk management is to allow you to continue trading, as simple as that. It keeps you for making repeated mistakes that can otherwise blow up your account . Keep in mind that one poorly managed trade can wipe out months or even years of consistent positive trading.</p>



<p>The basis of risk management is that it helps avoid making emotional decisions because we do make those type of decisions, we are either hyped or scared to win or lose more assets. With a strict trading plan your trading and investment decisions can be regulated easily. Coming up with a set of rules is the best way to go, each of us is different so not all the rules are the same but a few of them apply to everyone.</p>



<p>These rules have the purpose of managing risk, and eliminate rash decisions, they will allow you to stay in the game more than you would without them.</p>



<p>When creating your risk system you will need to take in mind factors like investment timeframe, risk tolerance, and how much you can risk. An important aspect that you should not forget is that recovering losses is more difficult than creating small profits. Psychologically it plays an enormous pressure on us to know that we started at $1000, we are down at $600 and we need to recover the initial investment. Some even go as far as quitting straight away after the first losses. Everything here is tied toghether, risk, psychology, trade amount, etc. We’ll dive deeper into the subject.</p>



<h2 id="portfolio">Portfolio</h2>



<p>A portfolio is the mix of all assets you hold or want to invest into. Portfolio diversification is a very important aspect of diversification and should be taken very seriously. A correctly diversified portfolio holds assets from real state to cryptocurrency (eg. Bitcoin, Ethereum, XRP). The portfolio can also be a division of trading accounts across different exchanges or brokers.</p>



<p>How about testing our services for free for&nbsp;<strong>7 days</strong>? Go for it, worst case scenario – you learn something new 👉 <a rel="noreferrer noopener" href="https://t.me/sublime_signals_payment_bot" target="_blank"><strong>interact with our bot</strong></a></p>



<h2 id="acc-size">Account Size</h2>



<p>Simple as it may sound, the account size is very important in risk management. The account size is part of your portfolio risk management plan. For beginners it is important to calculate, allocate and split the  account size into multiple smaller accounts. Multiple accounts, multiple strategies. Consider it as A/B testing, each account with it’s own starting balance, it’s own strategy. At the end of the month compare the winners with the losers and see what worked best…. <em><strong>Improvise, overcome, adapt.</strong></em> This also removes the possibility of risking too much.</p>



<p>One example would be : You beleave Bitcoin will go higher in the longterm and have some in your hardware wallet and some in your trading account, the smart thing to do is not to trade the BTC you have in your hardware wallet.</p>



<p>Allocating the capital is up you, you can split it in equal slices or any other way you want, <strong>just split it</strong>!</p>



<h2 id="acc-risk">Account Risk</h2>



<p>I am still amazed of how many people still don’t understand the difference between account risk and account size. The Account risk is determined by taking note of the account size. You will risk x% of your account size on a single trade.</p>



<p>Now there is a fixed rule for this , it’s <strong>called the 2% rule</strong> and basically it tells you to not risk more than 2% of your account size in one trade. This is where most people get it wrong . The 2% risk size does not mean you trade 2% of your account, it means the loss you might have must not exceed this limit.</p>



<p>In order to establish the 2% of risk you are willing to take on a trade, you first need to establish the entry, exit and stop loss of your trade. You also need to take into consideration that if you’re using leverage that will affect your losses.</p>



<div><p><strong>Risk/Reward ratio</strong><br>The risk reward ratio also called RR is the ratio between the possible losses and the possible winning , Risk / Reward. It helps us see if a trade is viable at a glance. <br>The higher the ratio, the better the trade(Ex. A ratio of 0,5/1 is bad , a ratio of 3/1 is good).<strong>The minimum accepted RR ratio at Sublime Traders is 1,7/1 and in rare cases.</strong></p><p>This part is where many cryptocurrency signal providers start to act funny, let me explain why. Because signal providers want to have as many signals as possible they post trades that have 1/1 Ratio or even lower. The problem here is obvious for seasoned traders, the thing is <strong>you can not be consistently profitable with a 1/1 RR ratio or lower, in fact the minimum is 1,5/1 and you really have to master your entries for this to be viable</strong>. </p></div>



<p>Let me explain further. Say you have a 3/1 RR ratio which is a good ratio, in the long run you win because for every trade you lose 1 and you win 3, this means you only need to win 3,33 trades out of 10 in order to be break even. With a ratio of 1/1 you can not possibly sustain constant profit because the risk and the rewards are the same.<br>I really can’t stress how important this aspect is please read several times until you understand this aspect perfectly, stop trading 1/1’s, it’s stupid😊</p>



<p><strong>Pro tip</strong> : The <strong>tradingview</strong> chart suite which has been <a rel="noreferrer noopener" href="https://sublimetraders.com/new-crypto-traders/10-trading-tools-every-crypto-trader-should-know/" target="_blank"><strong>reviewed here</strong></a> offers simple inputs for risk amount and risk reward ratio with the <strong>position tool</strong>.</p>



<figure><img src="https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17.png" alt="" srcset="https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17.png 908w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-300x243.png 300w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-768x621.png 768w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-370x300.png 370w, https://sublimetraders.com/wp-content/uploads/2020/06/Screenshot-at-Jun-15-14-57-17-85x70.png 85w" sizes="(max-width: 908px) 100vw, 908px"></figure>



<h2 id="trade-risk">Trade Risk</h2>



<p>So far we have our account size and account risk , let’s now determine the position size of a single trade. Losses are <strong>always</strong> part of the game so this needs to be taken into consideration when determining the entry size of your position. </p>



<p>Lets clear things out with a list of to do’s when posting a trade:</p>



<ul><li>Identify entry</li><li>Identify Take profit</li><li>Identify Stop Loss</li><li>Identify RR ratio</li><li>If ratio &gt; 1,7/1 then post trade (there you go, i created a short if statement for algo trading)</li></ul>



<h2 id="pos-size">Position sizing</h2>



<p>This part is the most difficult when setting up a trade. It takes into consideration or the elements we mentioned before.</p>



<p>Let’s take an example:</p>



<ul><li>Account size – $1000</li><li>Account risk – 2%</li><li>Distance to stop loss(invalidating point) – 5%</li></ul>



<pre>position size&nbsp;=&nbsp;account size&nbsp;x&nbsp;account risk&nbsp;/&nbsp;invalidation point
position size&nbsp;=&nbsp;$1000&nbsp;x&nbsp;0.02&nbsp;/&nbsp;0.05
position size = $400</pre>



<p>What this does it it protects your capital from heavy losses and it basically allows you to stay in the game. Remember to add trading fees to your calculation for bigger sizes. Trading fees vary from exchange to exchange but in general they are 0,1% on every trade for spot exchanges, and 0,075% for  takers on futures like <a href="https://partner.bybit.com/b/sublimetraders">Bybit</a> and -0,025 for makers (you get paid for limit orders).</p>



<h2 id="final">Final Word</h2>



<p>Our job is to provide clear <strong>entry</strong>, <strong>take profits</strong> and <strong>stop loss</strong> for every trade you post, you on the other hand need to manage your risk properly by following this guide or doing your own research.</p>
                    
                                            
                                    </div></div>]]>
            </description>
            <link>https://sublimetraders.com/cryptocurrency-market-analysis/risk-management-ratio-sizing-crypto-trades/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741918</guid>
            <pubDate>Sun, 05 Jul 2020 20:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comprehensive list of Dos-based palmtop computers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741810">thread link</a>) | @Ijumfs
<br/>
July 5, 2020 | http://www.tankraider.com/DOSPALMTOP/list.html | <a href="https://web.archive.org/web/*/http://www.tankraider.com/DOSPALMTOP/list.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.tankraider.com/DOSPALMTOP/list.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741810</guid>
            <pubDate>Sun, 05 Jul 2020 20:46:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on the Raspberry Pi 4 and 10k TCP connections with Vert.x]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741598">thread link</a>) | @asadawadia
<br/>
July 5, 2020 | https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv | <a href="https://web.archive.org/web/*/https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I recently picked up a Raspberry Pi 4 [4GB edition]. 
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593971667034/LD9-XNgaz.jpeg?auto=format&amp;q=60" alt="B15DC608-54AE-476A-AE53-FCB3E3EC6889.jpg"></p>
<h2 id="background-context">Background Context</h2>
<p>I had been debating picking up a Linux system for some dev work. I don't like using Docker right from the get go as a dev environment. My general workflow for any project goes in the following steps - for a Kotlin project</p>
<ol>
<li>Run from IDE</li>
<li>Run from terminal via build tool such as maven or bazel</li>
<li>Compile to a fat jar and run using <code>java -jar &lt;project&gt;.jar</code></li>
<li>Run fat jar on a Linux server [now possible]</li>
<li>Run as a docker container</li>
<li>Run as a Kubernetes deployment</li>
</ol>
<p>I know many devs have jumped directly to step 5 but I think it is still important to make sure that steps 1-4 are compiling and running properly.  Step 1 is still important because other devs, who do not have context, will navigate to your project [in their IDE] to add new features or fix bugs. Very likely, they will add a bunch of print statements in the project and start making requests to see what the internals look like. I guess you could use the documentation on confluence but sometimes it is easier and faster to just log-dump the request. They should to be able to spin the service up easily when they have no context. The project should not fail to startup because a required environment variable was not set - set a sane default, log the behaviour [such as persistence disabled] and proceed.</p>
<p>If for any reason you think this is a lot of work - I present you Margaret Hamilton the lead developer on the Apollo mission standing next to the hard copy of the code base.
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593974553056/BUndgAHNK.gif?auto=format,compress&amp;gif-q=60" alt="apollo.gif"></p>
<h2 id="vps-vs-raspberry-pi">VPS vs Raspberry Pi</h2>
<p>I was thinking of getting a digital ocean VPS - with the 1CPU 1GB ram costing about $5/month or $20 for the 2CPU 4GB ram. The monthly cost was definitely a factor since I was planning on running multiple things 24/7 and not just one small app. The advantage was being able to easily expose it on the internet for demo reasons. For an in house server, I would have to port forward on my router, which I was [and still am] not a big fan of. Ngrok [<a href="https://ngrok.com/" target="_blank">ngrok.com</a>] definitely could be a quick workaround. Another concern was that I love doing benchmarks and load testing. I did not want to cause any DDoS triggers on DO's end getting my account suspended or anything like that.</p>
<p>I picked up the CanaKit Raspberry Pi 4 Starter Kit (4GB RAM) from Amazon. Definitely a bit more expensive than I thought it was going to be all things considered. It was relatively easy to set up the heat sinks and the case. Hooked it up to a keyboard, mouse, and my TV to install the OS. I don't need a GUI so I installed the headless Raspberry Pi OS which is debian based [apt - not yum]. <code>raspberrypi.local</code> is set up to connect to the Pi.</p>
<pre><code>pi@raspberrypi ➜  ~ uname <span>-a</span>
Linux raspberrypi 4.19.118-v7l+ 
</code></pre><h2 id="what-s-running-on-it-">What's running on it?</h2>
<p>A server is useless if it is not running anything. I had a few things I knew I was going to set up. The first was a DNS level ad blocker pi hole [<a href="https://pi-hole.net/" target="_blank">pi-hole.net</a>]. Gave my Pi a static IP via DHCP reservation in my Rogers router and set up pi hole to block out any ads for all devices that used it as a DNS Server. Just this one application alone made the pi worth it. Pi hole helps quite a bit. Doesn't block everything [like ads on YouTube in mobile] but it is good enough. Also caches the DNS responses so browsing seems a bit zippier too. It is PHP based so it needs a webserver to call out to the php scripts - lighthttpd in this case. Not a big fan of this. Why are we still using PHP + web servers in 2020??</p>
<p>List of other things I set up not including things like zsh and htop:</p>
<ol>
<li>OpenJDK [OpenJ9 seems to have limited to no support for ARM]</li>
<li>Redis</li>
<li>Postgres</li>
<li>Grafana</li>
<li>Prometheus</li>
<li>MongoDB</li>
<li>InfluxDB [docker container]</li>
<li>Docker registry [docker container]</li>
<li>Node.js for Vue.js dev work</li>
<li>Caddy</li>
<li>Nginx [inactive]</li>
<li>rustc and go</li>
</ol>
<p>I set up gitea [ <a href="https://gitea.io/en-us" target="_blank">gitea.io/en-us</a> ] which is a self hosted git server as well - but the SSH permissions to push/pull got borked :(</p>
<p>I installed caddy as a reverse proxy for the pi to route to various services I have running behind it. Caddy is similar to nginx but with slightly easier configurations and automatic HTTPS setup.</p>
<pre><code>
localhost, raspberrypi.<span>local</span> {
     route / {
        respond <span>"{time.now.common_log} {system.os} {system.arch} {http.request.proto} {http.request.method} {http.request.uri}"</span>
    }
}
</code></pre><pre><code>➜  ~ curl -k https:
<span>05</span>/Jul/<span>2020</span>:<span>15</span>:<span>17</span>:<span>16</span> -<span>0400</span> linux arm HTTP/<span>2.0</span> GET /
</code></pre><h2 id="load-testing-and-10k-connections">Load testing and 10k connections</h2>
<p>Running wrk on Caddy [with logging turned on] I got the following results</p>
<pre><code>$ wrk -t <span>32</span> -c <span>64</span> -d20s https:
Running <span>20s</span> test @ https:
  <span>32</span> threads and <span>64</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     <span>7.15</span>ms    <span>3.91</span>ms  <span>60.06</span>ms   <span>83.81</span>%
    Req/Sec   <span>291.33</span>     <span>36.82</span>   <span>390.00</span>     <span>74.65</span>%
  <span>185508</span> requests in <span>20.07s</span>, <span>25.12</span>MB read
Requests/sec:   <span>9241.25</span>
Transfer/sec:      <span>1.25</span>MB
</code></pre><p>Next I setup a Vert.x TCP server and used tcpkali [ <a href="https://github.com/satori-com/tcpkali" target="_blank">github.com/satori-com/tcpkali</a> ] to see if the Pi could handle 10k concurrent connections.</p>
<p>As always, I opted to use vert.x to create the tcp server. A tcp server in vert.x can be spun up very easily with the following lines of code</p>
<pre><code><span>val</span> vertx = Vertx.vertx()

vertx.createNetServer().connectHandler { 
  
  it.handler { 
    
  }
}.listen(<span>9091</span>)
</code></pre><p>I also added some prometheus metrics:</p>
<ol>
<li>Node exporter to get the system information of the pi during the load test</li>
<li>Micrometer bindings to get the JVM information</li>
<li>Vert.x metrics to get the net server connection count + a custom packet received counter</li>
</ol>
<p>The entire main function can be viewed in here - <a href="https://gist.github.com/asad-awadia/93ba7c1eba6d6b8a8a84e9f20721d983" target="_blank">gist.github.com/asad-awadia/93ba7c1eba6d6b8..</a></p>
<p>Then the test began using tcpkali <code>tcpkali -m '$' -r 10 -c 10k -T 240s --connect-rate=1000 &lt;pi-ip&gt;:9091</code></p>
<p>Some grafana screenshots:</p>
<p>Vert.x net server connections + packet received
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977834283/PQWiJouxr.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.48.09 PM.png"></p>
<p>CPU usage
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977882225/wuc7a5Z-X.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.47.17 PM.png"></p>
<p>JVM memory used - vert.x is really memory efficient
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977897137/fNbEQl2Xw.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.47.05 PM.png"></p>
<p>Node exporter quick stats
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1593977918587/Z5FjhSwyO.png?auto=format&amp;q=60" alt="Screen Shot 2020-07-04 at 12.46.00 PM.png"></p>
<p>For a tiny little device it seems more than capable for a single dev. I would not use it as a build server for your company's production apps but to have an always on linux system available is really nice to have.</p>
</div></div>]]>
            </description>
            <link>https://aawadia.hashnode.dev/thoughts-on-the-raspberry-pi-4-10k-tcp-connections-with-vertx-ckc9huyxk0087mns121re4awv</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741598</guid>
            <pubDate>Sun, 05 Jul 2020 20:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Time to Reassess the Developer Career Ladder]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741511">thread link</a>) | @caution
<br/>
July 5, 2020 | https://cult.honeypot.io/reads/reassess-the-developer-career-ladder | <a href="https://web.archive.org/web/*/https://cult.honeypot.io/reads/reassess-the-developer-career-ladder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The career ladder for software engineers is often confusing and inconsistent.&nbsp; Many people who go into software development tend to go in with tunnel vision - they don’t even think about the career ladder because they’re so focused on the next pay bump or the next feature release. Also, they know that there are at least two steps in the ladder to worry about before anything dramatic can happen: junior developers become mid level developers and mid level developers become senior developers. But what about after that?&nbsp;</p><p>A lot of the problems that developers complain about in the tech industry are nested within that question. If you’ve been coding for the last four or five years of your life, spending more time in front of the computer than in front of other people, chances are your social skills might have taken a hit. If you are an extrovert or even moderately outgoing, this probably wouldn’t be a big deal. But if you’ve always been the type to prefer staying indoors, or worse, preferred the company of computers over people, a manager is probably the last thing you want to be.</p><h3><b>The Problem with Promoting All Senior Developers to Managers</b></h3><p>Unfortunately many organizations promote senior developers to managerial roles. There is a mistaken assumption among people in leadership that those who develop a high level of expertise in their field will naturally be good at managing. They fail to consider that what makes a good software engineer and what makes a good manager can often be at odds with each other. Good developers are detail-oriented, deep thinkers who thrive on solving technical challenges that are, at the end of the day, either solved or not solved. Good managers can see the big picture, and thrive on solving problems at the organizational level that require negotiating with, compromising, and sometimes confronting other people.&nbsp; These types of problems rarely have a black and white outcome, and usually there is no tangible reward besides the relative happiness of the employees.&nbsp;&nbsp;</p><p>I have experienced this first hand with one of my past managers. He had an impressive looking resume, having worked on the ground level of many start-ups as CTO and founder, but he seemed to be much more proud of the fact that he had been coding for three decades. On the surface he seemed like he would make a good manager, probably because he exuded a great deal of confidence. Unfortunately it ended up being quite the opposite. It took months for leadership to take action despite many employee complaints. What was especially uncomfortable was the way the manager responded when he discovered he was under fire. At every 1:1 he would ask me directly for negative feedback I had about him, as if I would just tell him to his face. It was incredibly awkward, and demonstrated a complete failure of grasping social norms. Not to mention empathy for the other person in the room and how they might feel being asked such questions. He also seemed to believe that if nobody gave them the negative feedback to their face, that this must mean he was actually performing well.&nbsp;</p><p>Ultimately, this particular manager was much better suited to programming as an individual contributor rather than leading a team.&nbsp;</p><h3><b>Alternative pathways for senior developers</b></h3><p>Luckily, some companies have moved away from promoting all of their software engineers to managers. One alternative approach is to give software developers three different “tracks” to choose from. Developers can take on a range of leadership responsibilities depending on the track. For instance, there is the team lead track where senior engineers become lead developers that make some of the more challenging and difficult technical decisions for the team. They also help mentor their teammates but do not take on as many managerial duties as an engineering manager.&nbsp;</p><p>For developers who have no interest in taking on leadership duties, there is the option of becoming a software architect. These developers get to make technical decisions that usually impact the future of the company and are often trusted with the keys to the kingdom. These developers are the ones who understand how all the software fits together and have a mental model that includes every little nook and cranny of code.&nbsp;</p><p>The best part about having this three track system for promoting software engineers is that there is wiggle room to switch between tracks if a developer decides they want to try something different or if it turns out they are not well suited for the track they are on. It reduces the risk of creating terrible managers that end up causing other developers to quit or lose motivation. The personality and attitude of managers in an organization often influence the culture. It’s important for leadership to reach out to their direct reports and be able to identify and fix issues when they arise.&nbsp;</p><p>Unfortunately, even this three track system is not bulletproof. Favouritism, slowness in moving people to a different track, and poor promotion metrics can cause even the best system to fall apart. Start-ups can be especially vulnerable to developers that can suck up to the CEO and bypass formal processes. While large companies tend to have less of that problem, they often adopt ranking systems that may or may not be effective at identifying the best employees, depending on how easy it is to play the system and how many people fall between the cracks.&nbsp;</p><p>Muddying the waters even further is the fact that developers often switch jobs when they don’t see a path forward at their current company. My first official title when I broke into the field was “Software Engineer.” When I moved to DC it became “UI/UX Developer” and I negotiated a pretty hefty pay raise in light of the difference in cost of living from Missouri. The following job ended up giving me a senior title despite the fact that I had less than 2 years of experience in the industry. They gave developers seniority not purely based on years of experience, but based on that developer’s salary.&nbsp;</p><p>This led to a strange and somewhat uncomfortable situation for me when, two jobs later, I found myself back in a mid-level title. From an outsider’s perspective, it sort of looked like a demotion. I didn’t know whether to remove “senior” on my past positions on LinkedIn or whether that would end up hurting me more. It happens because there is no standard for rating a developer’s skill level across the industry, and certainly no standard for pay depending on that level.&nbsp;</p><h3><b>A potential solution?</b></h3><p>That is why some developers have been calling for the creation of an organization responsible for standardizing the requirements and skills that developers need across the United States in order to create a more level playing field and also a system that allows developers to advocate for themselves and figure out if they are being underpaid. Unlike these three track systems which still allow managers to make decisions based on their own opinion about a developer, a trade organization for developers would create a third party that holds managers accountable.&nbsp;</p><p>Certainly there are potential problems that could be introduced by a trade organization, but right now the software engineering industry is basically the wild west when it comes to promotions. You have developers with 10 years of experience being paid 45K alongside junior developers at start-ups making upwards of 100K. Underrepresented folks in tech are still seeing a gap between their paychecks and those of their white male counterparts. Every time I got a new job part of me felt like I was back at square one again. As technology becomes more and more complex and humans rely on it on a daily basis, it seems the lack of a trade industry could not only be problematic but even catastrophic.&nbsp;</p><h3><b>Technology Industry Standards Impact Millions</b></h3><p>Having no coding standard for, say, a social media company, might seem inconsequential, but when you have software operating planes and cars and security there are lives at stake. It’s not just about making developers’ lives easier and fairer, it’s about creating a system where technology can actually be reliable and not subject to the whims of a company CEO that wants to save some money by telling developers to cut corners. Developers and frankly, the human race, deserves better.&nbsp;</p></div></div>]]>
            </description>
            <link>https://cult.honeypot.io/reads/reassess-the-developer-career-ladder</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741511</guid>
            <pubDate>Sun, 05 Jul 2020 20:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All about the upcoming Playstation 5]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741507">thread link</a>) | @ezrakewa
<br/>
July 5, 2020 | https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html | <a href="https://web.archive.org/web/*/https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div id="post-body-8407308363661742376" itemprop="articleBody">
<meta content=" PS5 release, price, hardware: All information about the PlayStation 5      The PlayStation 5 is the successor to the PS4. So far, no design..." name="twitter:description">
<div id="adsense-target">
<p><span>PS5 release, price, hardware: All information about the PlayStation 5</span></p><p><a href="https://1.bp.blogspot.com/-jCSyAezVgZ8/XwIrvQTt6GI/AAAAAAAAAaU/6rrqXXf6ylYcHL3txXfpSEXY-uHSbF47gCLcBGAsYHQ/s1600/ps5family-peripherie_6103290.jpg" imageanchor="1"><img data-original-height="720" data-original-width="1280" height="360" src="https://1.bp.blogspot.com/-jCSyAezVgZ8/XwIrvQTt6GI/AAAAAAAAAaU/6rrqXXf6ylYcHL3txXfpSEXY-uHSbF47gCLcBGAsYHQ/s640/ps5family-peripherie_6103290.jpg" width="640"></a></p>
<p><span><br></span>
<br>
<span>The PlayStation 5 is the successor to the PS4. So far, no design, price or launch date are known. But there is still a lot of known information and many credible rumors. In this article we collect all information and news about the price, release, hardware and games.</span></p><p>

<span>We have collected all the information and rumors of the past few years for you so that you can find everything there is to know and expect about PlayStation 5 at a glance:</span><br>
<span><br></span>
<span><b>PS5 release - when does the console appear?</b></span><br>
<span>The most important question first: when will the PS5 come out? We know that, according to Sony's official statement, the next-gen console will appear at the end of 2020 , during the so-called Holiday Season (more or less the extended Christmas business. Everything is possible here from late October to mid-December).</span><br>
<span><br></span>
<span>According to Sony, the target release period is still certain despite the corona crisis. This was confirmed by Sony Interactive Entertainment President Jim Ryan in early April 2020.</span><br>
<span><br></span>
<span><b>Price - What will the PS5 cost?</b></span><br>
<span>The PS4 cost just under 400 euros for the launch , the PS4 Pro also went over the counter for 400 euros at the beginning. However, it is becoming increasingly unlikely that the PS5 will be offered at the same price. It will probably be more expensive than the PS4 and PS4 Pro .</span><br>
<span><br></span>
<span>What does Sony say about the PS5 price? According to Sonys Mark Cerny, the system architect of the PS5, the console "should offer a reasonable and attractive cost factor" . Hiroki Totoki, Chief Finanical Officer at Sony, said the price of the next-gen console also depends on the competition . Apparently, Sony is planning to undercut Microsoft again.</span><br>
<span><br></span>
<span>What are the rumors about the price? According to insiders, Sony is currently struggling to keep production costs below $ 450 . A Bloomberg report from April 2020 also fits in with this: Individual components are expensive and sometimes fiercely competitive, because different manufacturers would try to do so at the same time. According to Bloomberg, PS5 estimates are between $ 499 and $ 549.</span><br>
<span><br></span>
<span><b>PlayStation 5 design - what does the PS5 look like?</b></span><br>
<span>The PS5 was unveiled as part of Sony's reveal event on June 11th. The console is available in two models, one with a drive and one without. The latter is accordingly slimmer.</span><br>
<span>In addition to the missing drive and the slightly customized design, there are other differences between the standard model of the PS5 and the Digital Edition:</span><br>
<span>PS5 advertising slogan: The official slogan for the Next Gen console for the system is "Play Has No Limits", probably an allusion to the significantly increased speed of the system.</span><br>
<span><br></span>
<span>By the way, you can already put the PS5 in your apartment. At least as a virtual 3D model thanks to the corresponding AR app.</span><br>
<span><br></span>
<span><b>PS5 peripherals - This is the PlayStation 5 family</b></span><br>
<span>In addition to the actual PS5 console, Sony has also introduced some peripheral devices that belong to the expanded circle of the PlayStation family. If you want to stock up on it, you can choose among:</span><br>
<span><br></span>
<span>HD camera with two 1080p lenses</span><br>
<span>PULSE ED wireless headset</span><br>
<span>Media remote control</span><br>
<span>DualSense charging station</span><br>
<span><b><br></b></span></p><p><a href="https://1.bp.blogspot.com/-DDwTZYOD8RE/XwIr_UWQC7I/AAAAAAAAAac/Ct_ZL3kft0ANis5JnnsgRheCs__tFl2JgCLcBGAsYHQ/s1600/ps5-playstation-5-reveal_6103769.jpg" imageanchor="1"><img data-original-height="347" data-original-width="617" height="358" src="https://1.bp.blogspot.com/-DDwTZYOD8RE/XwIr_UWQC7I/AAAAAAAAAac/Ct_ZL3kft0ANis5JnnsgRheCs__tFl2JgCLcBGAsYHQ/s640/ps5-playstation-5-reveal_6103769.jpg" width="640"></a></p>
<p><span><b><br></b></span>
<span><b>Hardware specs of the PS5</b></span><br>
<span>The exact hardware details of the PlayStation 5 were revealed by Sony's console architect Mark Cerny in March 2020. Here are the key performance data:</span><br>
<span><br></span>
<span>CPU: eight-core Zen 2 with 3.5 GHz clocking</span><br>
<span>GPU: 10.28 teraflops, 36 CUs (RDNA 2)</span><br>
<span>RAM: 16GB GDDR6</span><br>
<span>Hard drive: 825GB SSD</span><br>
<span>Extended storage: SSD slot</span><br>
<span>Drive: 4K UHD Blu-Ray drive</span><br>
<span>For comparison: the standard PS4 only comes to 1.84 TeraFLOPS, the Pro to 4.2 TeraFLOPS.</span><br>
<span><br></span>
<span>About the CPU: The Zen 2 CPU comes from the manufacturer AMD and contains 8 cores, just like the PS4 Pro. It was probably just not necessary to top up here, after all the Zen architecture ensures that the PS5 should run significantly faster even at the same clock rate.</span><br>
<span><br></span>
<span>SSD ensures more speed</span><br>
<span>Although the storage capacity is slightly reduced compared to the PS4 Pro and Xbox Series X, as John Linnemann from Digital Foundry announced on Twitter, the speed of the hard drive (5.5GB / s Raw / 9GB / s Compressed) is "the craziest" the PS5 ". Not only is it already very fast from the pure values, the SSD should also be a lot faster than that of the Xbox Series X.</span><br>
<span><br></span>
<span>Speed ​​example: If 1GB of data was previously loaded from the PS4 in 20 seconds, 2GB of data should now be processed in 0.27 seconds.</span></p><p>

<span>More memory? The SSD hard drive storage of the PS5 can be expanded by the way . And that with standard external SSDs that are checked for compatibility by Sony. However, this will only be possible after the launch. In addition, the operating system of the PS5 significantly smaller than that of the PS4, which means that less memory is blocked by the OS.</span><br>
<span><br></span>
<span>Faster data processing speed: thanks to SSD, the PS5 is even 100 times faster than the PS4, according to Sony. Sony is referring to the data processing speed of the Next Gen console (not the loading speed in games).&nbsp;</span></p><p>

<span>The built-in SSD should also reduce the charging times by a multiple compared to the PS4 Pro .</span><br>
<span><br></span>
<span><span><br></span><span></span><span>PS5 is supposed to get by without loading screens.</span></span>
<span>In a video, Sony shows how fast the PS5 is actually . Using the example of Marvel's Spider-Man, the loading times of the Next Gen console are compared with the PS4 Pro - and the difference is huge, at least in this game.</span><br>
<span><br></span>
<span>In fact, Sony's vision is to eliminate the loading screens entirely. According to Sony, the ultra-fast SSD is the key to the next generation and the first step to make loading screens a thing of the past.</span><br>
<span><br></span>

<span><b>What should the graphics of the PS5 offer?</b></span><br>
<span>8K resolution confirmed: As Sony's systems engineer Mark Cerny revealed in an interview, the PS5 is said to support 8K resolution. Even 4K screens are not yet widespread, so you can imagine how many users can actually enjoy 8K content directly at launch (the short answer: everyone who has between 5,000 and 15,000 euros for an 8K monitor).</span><br>
<span><br></span>
<span>Ray tracing on the PS5.</span><br>
<span>When it comes to hardware, it is also important to know that ray tracing on the PS5 is not anchored in the software, but in the hardware. "There is ray tracing acceleration in the GPU unit," Cerny is quoted as saying.</span><br>
<span><br></span>
<span>More freedom in downloading and installing.</span><br>
<span>The use of storage space on the PS5 should become more economical due to the type of game installation . Games should be able to be saved in granular form, which means that only the parts of the title that we want to play have to be downloaded, for example only the multiplayer campaign of a title, when we are already through with the single player.</span><br>
<span><br></span>
<span>Blu-ray drive confirmed for PS5</span><br>
<span>Yes, the next PlayStation will definitely use physical storage media. System architect Mark Cerny confirmed this in an exclusive Wired article .</span><br>
<span><br></span>
<span>BluRays should continue to function as the medium, as Cerny also reveals. In contrast to the currently available PS4 Pro, the optical drive should also be able to be used as a 4k Blu-Ray player.</span><br>
<span><br></span>
<span><b>Improved heat management</b></span><br>
<span>According to a Bloomberg report , Sony "unusually" spends a lot of money on a PS5 cooling system . This could suggest that the sometimes extreme volume of the PS4 fans should be contained.</span><br>
<span><br></span>
<span>What many of you should also be very happy about is a statement by Cerny about the heat sensitivity of the PS5. If the PS4 was still on its knees when the outside temperature was high, this should change in the future:</span><br>
<span><br></span>
<span>"" All work processes of the PS5 run at the same performance level in every environment. The outside temperature is not critical. ""</span><br>
<span><br></span>
<span><b>PS5: downward compatibility confirmed</b></span><br>
<span>Clear answer: According to system architect Mark Cerny, the next hardware generation of the PlayStation family will be compatible with the PS4 software . Thanks to the existing drive, we can also insert and play our favorite titles of the current console generation on the PS5. The goal is to almost all offer over 4000 PS4 games - in improved quality.</span><br>
<span><br></span>
<span>Own PS4 mode: We now have more specific information on PS4 downward compatibility. The PS5 comes with its own mode for PS4 games, of which at least 100 are already available for launch. According to Sony, these were successfully tested on the PS5. However, it is not excluded that this catalog will be expanded at the start.</span><br>
<span><br></span>
<span>Also applies to PSVR: The PSVR headset is also taken into account in downward compatibility and will also connect to the PS5.</span><br>
<span><br></span>
<span>New engine is supposed to make retro titles even prettier: Sony is said to even be working on a so-called "remastering engine" that should allow older titles to be graphically enhanced. That would be comparable to the possibilities of the Xbox One X, for which old Xbox titles can also be optimized.</span><br>
<span><br></span>
<span><b>PS5: what about VR?</b></span><br>
<span>So far, it is only known that the PSVR headset of the PS4 will be backwards compatible on the new console. So far there are only various rumors and pending patents about a possible PSVR2 for the PS5, so far Sony has not commented on this topic.</span><br>
<span><br></span>
<span>PS5 controller: what can we expect from the DualSense?</span><br>
<span>The new controller that the PS5 will introduce was officially unveiled on April 7: it's called DualSense.</span><br>
<span>What can the new PS5 controller do?</span><br>
<span><br></span>
<span>haptic feedback</span><br>
<span>Adaptive trigger</span><br>
<span>Rechargeable batteries</span><br>
<span>Create Button replaces the Share Button</span><br>
<span>Built-in microphone</span><br>
<span>Lightbar now next to the touchpad</span><br>
<span><br></span>
<span>PS5 controller becomes backwards compatible</span><br>
<span>Similar to the PS5 itself, the DualSense should also be compatible with the PlayStation 4 . This can be found on the French PlayStation website.</span><br>
<span><br></span>
<span>The other way round, there are rumors that the PS4 controller can also be connected to the PS5 . However, this has not been confirmed.</span><br>
<span><br></span>
<span>At least three more years of support for the PS4</span><br>
<span>Even after the launch of the PS5, the previous generation should not be dropped. According to a presentation at an investor conference , the PS4 should remain the engine for Sony's profitability for at least three years.</span><br>
<span><br></span>
<span>how do you see it? What are your wishes for the PS5? And what do you think is not possible?</span></p>
</div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html">https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html</a></em></p>]]>
            </description>
            <link>https://www.4alltech.com/2020/07/when-does-ps5-appear-what-hardware-will.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741507</guid>
            <pubDate>Sun, 05 Jul 2020 20:09:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Thinker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23741488">thread link</a>) | @TheThinkerCEO
<br/>
July 5, 2020 | http://barisciencelab.tech/TheThinker.html | <a href="https://web.archive.org/web/*/http://barisciencelab.tech/TheThinker.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
 
  <!--<div id="preloader"></div>-->
    <!--<div id="content">-->

      

 <!--
 <script src="//code.jquery.com/jquery.min.js"></script>
<script>
$.get("ThinkMenu.html", function(data){
    $("#nav-placeholder").replaceWith(data);
});
</script>
 
 
 
 <div id="nav-placeholder"></div>
 -->
 
 
      <nav role="navigation" aria-label="main navigation">



  



    
	   
	   
  <br>
    <!--<button class="button is-info" id="showModal" style = "margin-top:-2vh;">Apply</button>-->

	
	

	<!--
     <div class="navbar-item">
        <div class="buttons">
          <a class="button is-primary" href = "https://forms.gle/21Yp4J9h9v45uDcA8" >
            <strong>Apply</strong>
          </a>
        </div>
      </div>
      -->
  
</nav>
  
  <div>
  <center>
<div>
  <p><span><p>The Thinker</p></span>   

  </p>
  <p><span><p><span><a href="http://barisciencelab.tech/TheThinker.html"><img src="https://i.imgur.com/laASlTU.png" alt=""></a></span>
  </p></span>
</p></div>
    
    </center>
    
  </div>
 
 
      <section>
  <div>


<!--
 <div class = "columns fifty">
    <div class = "column is-12">-->
   <!--
    <article class = "title is-child blue" style = "padding: 2%;">
        <center>
        
        <h2 class = "post__title">Read in another Language: </h2>
        
        
        <div id="google_translate_element"></div>

        <script type="text/javascript">
        function googleTranslateElementInit() {
          new google.translate.TranslateElement({pageLanguage: 'en'}, 'google_translate_element');
        }
        </script>
        
        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
</center>
    </article>
    --><!--
    </div>
</div>-->

<!--
<section class="hero is-info" style = "margin-bottom:-5%;">
  <div class="hero-body">
    <div class="container">
      <h1 class="title appsnews">
        Congratulations!
      </h1>
      <h2 class="subtitle">
        <a href = "https://www.youtube.com/watch?v=1joMpCeueO0&t=994s"><b>Interviews here</b></a>. 11 Journalists have been accepted to <i>The Thinker</i>! Their Profiles will be released shortly. 
      </h2>
    </div>
  </div>
</section>-->



<br>
<div>
      <div>
        <article>
          <a href="">United States</a>

          <h2>Christians: Sinners or Saints?</h2>
          <p>Religions have their respective symbols, The jews have the Jewish Star, the Hindus have the Swastika, and the Christians have the Cross. But why a Cross? What is Christianity, really? Why was Jesus crucified? And what are my personal thoughts on Christianity? I. What are the basic functions of Christianity? We will discuss and then answer all of these, and set out to explore the intricate set of connections and rules that is Christianity. Come with me on this learning journey.</p>
          <figure>
    <img src="https://i2-prod.mirror.co.uk/incoming/article12562538.ece/ALTERNATES/s1227b/The-wedding-of-Prince-Harry-and-Meghan-Markle-Ceremony-St-Georges-Chapel-Windsor-Castle-Berkshi.jpg">
    <figcaption>
        Th prince and princess of England marrying in a catholic church.
    </figcaption>
</figure>
        </article>
      </div>

 <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/06022020Interview.html">"Education, not Violence", pleads Black Student</a></h2>
                     

          <p>Ithaca University Student and KIPP H.S. Graduate Christian supports the protests, but condemns the looters, echoing Booker T. Washington's philosophy that Eduaction, not violence, is the path to reform.</p>
          <figure>
    <img src="https://i.imgur.com/tjHNu1z.png">
    <figcaption>
        "I know it's easy to loot when you see others doing it, but please -- Rise above that. You gotta set a model, an example for others to follow" - Christian Brown
    </figcaption>
</figure>
        
        </article>
      </div>

    <!--   <div class="tile is-parent">
        <article class="tile is-child green post oneman">
          <a class="post__category" href="">United States</a>
          <h2 class="post__title">George Floyd Protests</h2>
          <div class="post__content">Relationship between Law Enforcement and Protestors have found Floyd as the catalyst for their (mutually-self assured) destruction. The protests have unified and equally divided a nation tore in anger. We await to see developments such as whether the largest cities around the nation implement a curfew in this distressing time. </div>
        </article>
      </div>-->
    </div>
  <div>

      <div>
        <article>
                <p><span>LIVE</span>
                  <span id="headlineTime"></span>
                </p>
              
   
          <h2><a href="http://barisciencelab.tech/Judaism.html">Ruthless Against Judaists</a></h2>
         <p>Jews have faced many a crisis. From the Israeli Palestinian Conflicts to the Holocaust, and from Adam and Eve to Jacob, we dive into the history of the religion that has stood strong in times of need. Exactly what has this religion faced, and where are its origins? Take a look at the history of how they've been mistreated and tyrannized, and the causes of which thousands of children and adults have been martyred. Let's look at a different perspective, and love all religions, even if they aren't ours. Get ready to put yourself in the shoes of the Jews. </p>
            
            <figure>
    <img src="https://haam.org/wp-content/uploads/2019/02/860373-efade7b2-1d47-11e4-8adb-938012f29f27.jpg">
    <figcaption>
        Jews have been persecuted by many religions, races, and empires for years. They were first maltreated by the Arabs, then the Brits, and finally the Germans. Take a look at the history of how they've been mistreated and tyrannized, and the causes of which thousands of children and adults have been martyred. </figcaption>
</figure>


        </article>
        
      </div>

      <div>
        <article>
           
          <h2><a href="http://barisciencelab.tech/Heinz.html">A Battle to Live: Life or Law?</a></h2>
          <p>Once upon a time, there was a man named Mr. Heinz. He was a poor man; he only made a thousand bucks a year. He saved up every single penny he could after a while, and that got him to 3,575 bucks a year. But on the fifth night of February 1977, Mr. Heinz faced a heart-wrenching dilemma: should he save his wife or break the law?</p>
        
        </article>
        
        
        <article>
           
          <h2><a href="http://barisciencelab.tech/06072020Interview.html" onmouseover="this.style.color='#ab0808'" onmouseout="this.style.color='#ff0000'">"Trump is a tragedy", Columbia Scientist</a></h2>
          <p>They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. Indeed, what the von Gutfelds have lived through is little short of remarkable: the Holocaust, Hitler, and now COVID. </p>
        
        </article>
      </div>
    </div>
    
    

    <!-- FIRST ROW -->
   <!--
   <div class = "columns one">
       <div class = "column is-6">
           
            <article class="tile is-child tealish post fiveman">
          <a class="post__category" href="">America</a>
          <h2 class="post__title"><a href = "06132020Interview.html">"People are worth more than buildings", Columbia Graduate</a></h2>
          <div class="post__content">At a time of National Crisis, how do we grapple with our own responsibilities? This is the question I myself struggle to answer every day. But it doesn't have to be so: As Jordan Mahr of Columbia University exclaims, the socio-moral responsibilities of today are simply a consequence of our nation's high standing on Maslow's Hierarchy of Needs. It is because of this shared prestige and rare privilege that we are afforded the oppurtunity adress these difficult issues in the first place. </div>
                <figure class="imghvr-fade" style = "margin-top:-2vh; margin-left:2%;">
    <img src="JordanMahr.png" style = "width:110%">
    <figcaption>
        Jordan Mahr graduated from Columbia University in Theatre last year, in 2020. He was born in New Jersey and studied Drama and Performance with a Concentration in Acting at Columbia University and trained at the Royal Academy of Dramatic Art.  
    </figcaption>
</figure>
        </article>
        
         
       </div>
    
     <div class="tile is-vertical is-parent">
            <article class="tile is-child red post">
          <a class="post__category" href="">Politics</a>
          <h2 class="post__title"><a href = "06072020Interview.html" style = "color: red;" onMouseOver="this.style.color='#ab0808'"
   onMouseOut="this.style.color='#ff0000'">"Trump is a tragedy", Columbia Scientist</a></h2>
          <div class="post__content">They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. Indeed, what the von Gutfelds have lived through is little short of remarkable: the Holocaust, Hitler, and now COVID. I can only look in awe as Columbia Adjunct Senior Research Scientist von Gutfeld laments at the state of American Leadership during a time of global crisis, giving a scalding rebuke of Trump and his reaction the Pandemic and Protests.</div>
                <figure class="imghvr-fade" style = "margin-top:-3vh; margin-left:2%;">
    <img src="https://i.imgur.com/r0WasA0.png" style = "width:110%"></a>
    <figcaption>
        They've lived through some of the greatest moments in History: the moon landing, the birth of the UN, UNICEF, and WHO, and witnessed some of its worst -- the Holocaust, Nazi Germany, and COVID19, to name just a few. 
    </figcaption>
</figure>
        </article>
           
     
      </div>
    </div>
    -->
    
    <div>
       <div>
              
      
            <article>
          
          
          <h2><a href="http://barisciencelab.tech/GestaltSwitch.html">What do you see?</a></h2>
          <p>Superposition is impossible. I want to be in London and New York at the same time, but I can't -- reality prohibits me. By extension, one can't get a head and tail from the same coin flip; nor can we have day and night simulatenously. With this law in mind, I want to ask you a question. It has no right answer, but it will demonstrate your thinking.</p>
                <center><figure>
    <img src="http://brainden.com/images/optical-illusions-big.gif">
    <figcaption>
        Do you see a young lady or an ugly old woman? If you see the young lady, look corefally at the ears -- they're the eyes of the old lady. If you look at the picture long enough, you should experience a 'Gestalt Switch'.
    </figcaption>
</figure></center>
        </article>
        
       </div>
       <div>
                <article>
         
         
          <h2><a href="http://barisciencelab.tech/Dowry.html">The Danger of Dowry</a></h2>
          <p>Dowry is like a social disease in some South Asian countries such as Bangladesh, Pakistan and India. Everyday women become victims because of dowry violence. Most of the groom's family demands dowry from the bride's family. </p>
          
        </article>
         <article>
          
          
          <h2><a href="http://barisciencelab.tech/TheOriginalRelativist.html">Galileo: The Original Relativist</a></h2>
          <p>The Catholic Church took 350 years to concede that Galileo was indeed right that the Copernican Model of the Solar System was correct. This was in 1992, when the Pope formally closed the 13-year investigation into the Church's condemnation of the reknowned Scientist. </p>
        </article>
           </div>
   </div>

    <!-- SECOND ROW -->
    <div>
      <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/AMileWideAnInchDeep.html">A Mile Wide and an Inch Deep Curriculum</a></h2>
          <p>America is known for excellence in education. No wonder, America won 385 out of 860 Nobel Prizes in which Harvard and Columbia together won 250 Prizes that is 29% of total Prize. However, there is a problem: K-12 Education is in crisis, which led to an educational revolution, of which Common Core is the outcome.</p>
                <figure>
    <img src="https://images.collegexpress.com/article/test-prep-tips-tricks-strategies-taking-SAT-ACT.jpg">
    <figcaption>
        The Common Core is an educational program launched by the National Governors Associatoin (NGA) and the Council of Chief State School Officers (CCSSO). It was established in 2010 in a hope to create a national, uniform cirriculum in Mathematics and Science.    </figcaption>
</figure>
        </article>
      </div>

      <div>
        <article>
          
          <h2><a href="http://barisciencelab.tech/06042020Interview.html" onmouseover="this.style.color='white'" onmouseout="this.style.color='white'">"It's all good", shouts Sikh</a></h2>
          <p>Mr. Ranbir, retired construction worker and evergreen optimist, hails from Punjab, India. "I love everybody", he says in broken English. "They say, 'we no like Muslims'. But no, I love everyone. Muslims, Hindu, Christian, everybody, everybody.".</p>
        </article>
        
        
        <article>
          <a href="">Science</a>
          <h2>The Story of SpaceX</h2>
          <p>Third time wasn't the charm for the now-nationally admired commercial space organization.</p>
        
        </article>
      </div>

      
    </div>

    <!-- THIRD ROW -->
    <div>
      <div>
        <div>
          <div>
            <article>
              <a href="">United States</a>
              <h2>A Nation in Distress</h2>
              <p>What does it take to break a nation? A democracy? The richest in the world? Now we know: a 7 mm virus and racism. These two make a dangerous combustion that mix the fire and fury of a nation tore down.</p>
          
            </article>
          </div>
          <div>
            <article>
              <a href="">India</a>
              <h2>The State of India</h2>
              <p>India is in a truly unique crisis: hunger has ravaged the poor, most of whom work in the informal economy. And the informal economy is more than 90% of India's economy, making the effects of unemployment all the more worse. </p>
            
            </article>
          </div>
          
          
          <div>
            <article>
              <a href="">Bangladesh</a>
              <h2>Hurricane Amphan Tears Bangladesh</h2>
              <p>She was at the height of her career when COVID19, Poverty, Hunger, Unemployment, and a killer Hurricane all struck at once. Will the eight largest nation in the world persevere as it did in 1974? Or will it fall to an untimely death?</p>
            
            </article>
          </div>
        </div>

        <div>
          <div>
            <article>
              <a href="">Women</a>
              <h2>A Mother's Worry</h2>
              <p>Lockdowns worldwide are still in-effect in many countries, and this has caused domestic abuse cases to shoot up. In addition, how can mothers and fathers alike educate their children during this time of remote learning?</p>
          
            </article>
          </div>
          <div>
            <article>
              <a href="">Science</a>
              <h2>The Galilean Man</h2>
              <p>For much of the 19th century, Galilean Transformations were the way to go to identify observers, events, and movements across space-time. Let's try to understand the theory behind it all.</p>
            
            </article>
          </div>
        </div>
      </div>

      <div>
        <article>
          <a href="">Pakistan</a>
          <h2>A Crash in Pakistan</h2>
          <p>The plane was traveling from Lahore to Karachi, when it crashed, killing 97 of 99 people aboard. 2 survivors recount their horror stories in their memorable encounter with death. COVID19 has uniquely affected the aviation industry, and although this is mere speculation -- the crash in Pakistan is most likely to exacerbate the problems. </p>
            <figure>
    <img src="https://gumlet.assettype.com/nationalherald%2F2020-05%2Fe05d32e5-62c5-4455-b04d-fcf24b0d955f%2Fpak_plane.jpg?rect=0%2C0%2C720%2C405&amp;auto=format%2Ccompress&amp;format=webp&amp;w=750&amp;dpr=1.0">
    <figcaption>
        The plane was heading from Lahore to Karachi, and crashed killing 97 of the 99 people aboard, including children.
    </figcaption>
</figure>
          
                      <figure>
    <img src="https://specials-images.forbesimg.com/imageserve/1196884876/960x0.jpg?fit=scale">
    <figcaption>
        In Pakistan, planes don't have to undergo background checks prior to flying, which may be one of the many factors contributing to the crash of the flight.
    </figcaption>
</figure>
        </article>
      </div>
    </div>

  </div>
  <!-- /container -->
</section>
<!--      
<div class="fancy-hr"><hr></div>

<center><p class="title is-3" width = "">From the Editor-In-Chief</p></center>
      
<center>      
<div class="fancy-hr"><hr></div>

 <div class="container" style = "width:50vw; height: 55vh;">
	<div id="player" data-plyr-provider="youtube" data-plyr-embed-id="-9lQ_CbCetw"></div>
</div>
          </center>-->


<center><p>Good News</p></center>
      
      

      <section>
  <div>
    <p>
      
      <h2>
        SpaceX Dragon succesfully 'soft-docked' with the ISS 
      </h2>
    </p>
    <br>
  </div>
  
</section>
      
      
      <section>
 
  

</section>

<div>
    <p>
      Brooklyn and Manhattan have been the center of most of the protests occuring in New York City. Queens has also recently erupted in protests driven by the death of George Floyd. Protests have recently escalated even further, reaching into violent territory: police have literally driven cars into protestors; protestors have lit police cars on fire, in return, and the whole city seems to be descending into the stages of preliminary stages of anarchy.
      </p>
    
    
</div>

            
      
      
        <section>
    <div>
      <div>
        <div>
          <div>
            <div>
              <figure>
                <img src="https://static01.nyt.com/newsgraphics/2020/05/29/floyd-protests-map/assets/images/ny-brooklyn-0530-1440.jpg" alt="a random image">
              </figure>
            </div>
            <div>
              <p>A Microcosm of the Future</p>
              <p>Are the riots, looting, and protests of America Today a sign of America from the future? But things have only been getting started. A problem much larger than COVID19 is emerging, and that is Global Warming. It is so existential that we have a hard time thinking about it, and thus acting on that fear. It is essential that we understand the present, should we hope to …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://barisciencelab.tech/TheThinker.html">http://barisciencelab.tech/TheThinker.html</a></em></p>]]>
            </description>
            <link>http://barisciencelab.tech/TheThinker.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741488</guid>
            <pubDate>Sun, 05 Jul 2020 20:05:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The key points of Software Design X-Rays]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23741261">thread link</a>) | @nicoespeon
<br/>
July 5, 2020 | https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>How do you analyze a very large Legacy codebase?</p><p>Where do you start when your system is distributed across dozens of micro-services?</p><p>How do you identify development bottlenecks and prioritize refactoring?</p><p>In his book <!-- -->[Software Design X-Rays]<!-- -->(<a href="https://www.google.com/search?q=software+design+x-rays&amp;oq=soft">https://www.google.com/search?q=software+design+x-rays&amp;oq=soft</a>, Adam Tornhill presents a very unique approach to answer these questions. It’s a mix of software architecture and human psychology that generates powerful techniques to tackle large codebases.</p><p>Yet, I realized it’s not a very known book.</p><blockquote><p>I’ve read <a href="https://www.google.com/search?q=your+code+as+a+crime+scene">Your Code as a Crime Scene</a> from the same guy. How is this different?</p></blockquote><p>Well, “Software Design X-Rays” was written after “Your Code as a Crime Scene”. While the forensics flavor of the book was fun and all, Adam stopped referring it too much to avoid getting the reader distracted. The content is much more polished!</p><p>Let me give you my summary of what’s inside the book and why I think it can help you:</p><h2 id="tackle-technical-debt-with-behavioral-code-analysis"><a href="#tackle-technical-debt-with-behavioral-code-analysis" aria-label="tackle technical debt with behavioral code analysis permalink"></a>Tackle Technical Debt with Behavioral Code Analysis</h2><p>The book focuses on giving you the answers to these 3 questions:</p><ol><li>Where’s the code with the higher interest rate?</li><li>Does your architecture support the way your system evolves?</li><li>Are there any productivity bottlenecks for inter-team coordination?</li></ol><p>To do so, Adam presents a technique called <strong>Behavioral Code Analysis</strong>. It uses the information contained in your Version Control System (VCS) to help you make smart decisions on large codebases.</p><h3 id="identify-your-system-hotspots"><a href="#identify-your-system-hotspots" aria-label="identify your system hotspots permalink"></a>Identify your system Hotspots</h3><p>Technical Debt isn’t really a problem if you don’t have to maintain it.</p><p>Static analysis tools consider all debt to be equivalent. They report countless of code smells that you have no choice but to focus on the critical ones. Still, that leaves plenty of things to clean up!</p><p>That’s why you should use the time dimension to identify <strong>Hotspots</strong>: places where you should focus the Refactor efforts in a large codebase if you want to be super effective.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="hotspots" title="" src="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png" srcset="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/00d96/hotspots.png 148w,https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/0b23c/hotspots.png 295w,https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png 572w" sizes="(max-width: 572px) 100vw, 572px">
    </span>
  </span>
  
  </a>
    </undefined></p><p><undefined>
  <a href="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/11d19/code-that-matters.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="code that matters" title="" src="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/799d3/code-that-matters.png" srcset="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/00d96/code-that-matters.png 148w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/0b23c/code-that-matters.png 295w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/799d3/code-that-matters.png 590w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/11d19/code-that-matters.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>If you want to learn how to generate and use these, I presented the technique in details:</p><ul><li><a href="https://understandlegacycode.com/blog/focus-refactoring-with-hotspots-analysis">Focus refactoring on what matters with Hotspots Analysis</a></li><li><a href="https://understandlegacycode.com/blog/convince-management-to-address-tech-debt-with-enclosure-diagrams">Convince managers to address Tech Debt with Enclosure Diagrams</a></li></ul><p>Interestingly, hotspots tend to stay here because people are afraid to tackle them. So they attract even more complexity and become problematic bottlenecks.</p><h3 id="loc-a-simple-and-efficient-indicator-of-code-complexity"><a href="#loc-a-simple-and-efficient-indicator-of-code-complexity" aria-label="loc a simple and efficient indicator of code complexity permalink"></a>LOC: a simple and efficient indicator of code complexity</h3><p>When it comes to evaluating the complexity of the code, many metrics compete. The most popular is probably Cyclomatic Complexity. Yet, it’s fascinating to see that the count of Lines Of Code (LOC) is often a <em>good enough</em> indicator!</p><p>As it’s a language-neutral metric, it’s very easy to generate regardless of your language tooling. You can use <a href="http://cloc.sourceforge.net/">cloc</a> for that:</p><pre data-language="bash" data-index="0"><p><code><span><span>cloc </span><span>.</span><span> --csv --quiet --report-file=your_project.csv</span></span></code></p></pre><p>Another language-neutral metric that works well is the <strong>Indentation Level</strong>. Indentation carries the meaning of logical splits. That’s a good indicator that code is complex.</p><p>The limit of using these is when you have a change in the coding style in the history of the project. But because these metrics are simple, it makes no sense to look at specific values and thresholds. <strong>It’s the trend that matters</strong>. That’s usually enough.</p><h3 id="evaluate-hotspots-with-complexity-trends"><a href="#evaluate-hotspots-with-complexity-trends" aria-label="evaluate hotspots with complexity trends permalink"></a>Evaluate Hotspots with Complexity Trends</h3><p>If you analyze the evolution of complexity of a file over time, you get the story of that file:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/48606/complexity-trend.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="complexity trend" title="" src="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/799d3/complexity-trend.png" srcset="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/00d96/complexity-trend.png 148w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/0b23c/complexity-trend.png 295w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/799d3/complexity-trend.png 590w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/48606/complexity-trend.png 701w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>That’s helpful to show the impact of refactoring to non-technical managers. That helps them visually see the effects of such work, and the results on team productivity.</p><h3 id="perform-x-rays-analysis-to-narrow-even-deeper"><a href="#perform-x-rays-analysis-to-narrow-even-deeper" aria-label="perform x rays analysis to narrow even deeper permalink"></a>Perform X-Rays analysis to narrow even deeper</h3><p>Once you identified Hotspots, you can apply the same logic at the file level to find the complex functions:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/11d19/x-ray.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="x ray" title="" src="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/799d3/x-ray.png" srcset="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/00d96/x-ray.png 148w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/0b23c/x-ray.png 295w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/799d3/x-ray.png 590w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/11d19/x-ray.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>This is what Adam calls “X-Ray analysis”. Here’s the rough recipe:</p><ol><li>Fetch the source code of the file for each revision from Git</li><li>Run a <code>git diff</code> for every revision to list the modifications</li><li>Match the <code>diff</code> results to the functions that existed in this version (parsing the code is necessary here)</li><li>Perform a Hotspot calculation for the functions<ul><li>Change Frequency = times a function was changed</li><li>Complexity = length or indentation level of the function</li><li>Combine them to calculate the score</li></ul></li></ol><p><undefined>
  <a href="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/e7347/x-ray-results.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="x ray results" title="" src="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/799d3/x-ray-results.png" srcset="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/00d96/x-ray-results.png 148w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/0b23c/x-ray-results.png 295w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/799d3/x-ray-results.png 590w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/e7347/x-ray-results.png 849w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>With the Hotspot + X-Ray techniques, you can take a 400kLOC codebase and focus on the few hundred lines of code that will have the most impact if they are refactored.</p><p>It’s good to know you can perform a cheap X-Ray with git log, using the <code>-L</code> option:</p><pre data-language="bash" data-index="1"><p><code><span><span>git log -L:intel_crtc_page_flip:drivers/gpu/drm/i915/intel_display.c</span></span></code></p></pre><h2 id="coupling-in-time-where-surprises-happen"><a href="#coupling-in-time-where-surprises-happen" aria-label="coupling in time where surprises happen permalink"></a>Coupling in Time: where surprises happen</h2><p>You generally forget about the time dimension when you analyze the code to evaluate its design. That’s a mistake! <strong>Change Coupling</strong> is when files change together over time.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="change coupling" title="" src="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png" srcset="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/00d96/change-coupling.png 148w,https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/0b23c/change-coupling.png 295w,https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png 545w" sizes="(max-width: 545px) 100vw, 545px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>2 files might change together accidentally. But if they changed together in many commits, with a high degree of coupling, then there’s a high chance these 2 files are coupled!</p><p>This allows you to identify things that empirically belong together. If these files are not co-located, then there might be a problem with the current design. Maybe there’s a bad abstraction or maybe there’s copy-pasted code that keeps evolving together.</p><p>Expected coupling:</p><ul><li>highly-cohesive files (same module)</li><li>code &amp; tests</li></ul><p>Unexpected coupling:</p><ul><li>low-cohesive files (different modules)</li><li>surprising relationships</li></ul><p>Since you’re using git metadata to determine these coupling, it’s <strong>language agnostic</strong>. Therefore, you can detect coupling across stacks, like between front-end and back-end.</p><p>A limit of this technique is the commit patterns developers use. If a developer always commits tests and code independently, you can adapt the technique and consider commits from the same author in a 24h sliding window as “coupled together”. Usually, that’s good enough.</p><h3 id="identify-actual-code-duplication"><a href="#identify-actual-code-duplication" aria-label="identify actual code duplication permalink"></a>Identify actual code duplication</h3><p>Copy-paste is not bad in itself.</p><p>It’s only bad if you need to keep changing all occurrences together. Hence, if you integrate a metric of <em>Similarity</em> in your Change Coupling analysis, you can detect problematic copy-paste:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/388a9/change-coupling-copy-paste.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="change coupling copy paste" title="" src="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/799d3/change-coupling-copy-paste.png" srcset="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/00d96/change-coupling-copy-paste.png 148w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/0b23c/change-coupling-copy-paste.png 295w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/799d3/change-coupling-copy-paste.png 590w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/388a9/change-coupling-copy-paste.png 681w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Fixing code duplication is often a quick win. It helps getting started in refactoring a Hotspot.</p><p>As a rule of thumb: <strong>things that are coupled should be co-located</strong>.</p><h2 id="the-principles-of-code-age"><a href="#the-principles-of-code-age" aria-label="the principles of code age permalink"></a>The Principles of Code Age</h2><p>Code is only desirable in 2 states:</p><ol><li>Very recent, because it’s fresh in your mind</li><li>Very old, because it means it has stabilized</li></ol><p>When you meet a very old code, you can encapsulate that into a library and extract it from your codebase. That’s less code to deal with, which is good for developers and onboarding!</p><p><strong>Old code usually has no bugs.</strong></p><p>A code that doesn’t stabilize is problematic. It usually means you need to patch it. Because you don’t know it very well, there’s a high chance of creating bugs by ignorance. By creating more bugs, you need to update the code again: it doesn’t stabilize.</p><h3 id="calculate-the-age-of-code"><a href="#calculate-the-age-of-code" aria-label="calculate the age of code permalink"></a>Calculate the age of code</h3><p>The algorithm is simple:</p><ol><li>List modified files with <code>git ls-files</code></li><li>Get the last modification date for each file with <code>git log -l --format="%ad" --date=short -- path/to/file</code></li><li>Calculate the age of the file</li></ol><p>If the codebase was not maintained for some time, consider the youngest one to be 0.</p><h3 id="refactor-towards-code-of-similar-age"><a href="#refactor-towards-code-of-similar-age" aria-label="refactor towards code of similar age permalink"></a>Refactor towards code of similar age</h3><p>Within the same packages, you can identify the code of different ages (very old AND very recent). Try to understand why some code fails to stabilize.</p><p>Maybe you’ll be able to extract parts of it that would actually stabilize.</p><p>Maybe you’ll identify different concepts that are mixed. So you can refactor the structure of the code:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="architecture" title="" src="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png" srcset="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/00d96/architecture.png 148w,https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/0b23c/architecture.png 295w,https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png 564w" sizes="(max-width: 564px) 100vw, 564px">
    </span>
  </span>
  
  </a>
    </undefined></p><h2 id="beyond-conways-law"><a href="#beyond-conways-law" aria-label="beyond conways law permalink"></a>Beyond Conway’s Law</h2><h3 id="development-congestion"><a href="#development-congestion" aria-label="development congestion permalink"></a>Development Congestion</h3><p>When you put too many developers on the same code, it’s hard to keep productive. That’s because the code constantly changes: the code you wrote three days ago is now different, so you have to constantly re-discover what it does. The risk of bug is high.</p><p>This is <em>Development Congestion</em>.</p><p>That’s why if you put more people on a late project, the project will be even later.</p><p>Code reviews and automated tests can mitigate the risk of bugs.</p><h3 id="the-problem-of-having-too-many-contributors"><a href="#the-problem-of-having-too-many-contributors" aria-label="the problem of having too many contributors permalink"></a>The problem of having too many contributors</h3><p><strong>Many minor contributors you have in the last 3 months = higher chances to have bugs</strong>.</p><p>That’s because contributors don’t have the full context of what they change.</p><p>With many contributors, <em>diffusion of responsibility</em> makes the codebase rot because each developer thinks someone else will take care of refactoring.</p><p>Also, many contributors lead to <em>process loss</em> (waste) due to communication overhead.</p><p>Thus, you need to introduce <strong>areas of responsibility</strong> to give teams full ownership. Other teams may contribute through PRs, but one team should own their part, be involved in reviews, and have the final word.</p><p>Finally, <strong>teams should have a broader knowledge boundary (what they know) than their operational boundary (what they change)</strong>. You can make that happen with:</p><ul><li>Teams demoing what they’re working on</li><li>Inter-teams code reviews to spread knowledge</li><li>Make people move between teams</li></ul><h3 id="calculating-the-diffusion-score"><a href="#calculating-the-diffusion-score" aria-label="calculating the diffusion score permalink"></a>Calculating the Diffusion score</h3><p>You can count the number of developers on a specific part of the code from git:</p><pre data-language="bash" data-index="2"><p><code><span><span>git shortlog -s --after=2020-01-12 -- some/module/path | wc -l</span></span></code></p></pre><p>If you analyze the distribution of contributions on a part of the code, you get a <em>Diffusion</em> score:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion formula" title="" src="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png" srcset="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/00d96/diffusion-formula.png 148w,https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/0b23c/diffusion-formula.png 295w,https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png 497w" sizes="(max-width: 497px) 100vw, 497px">
    </span>
  </span>
  
  </a>
    </undefined>
<undefined>
  <a href="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion results" title="" src="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png" srcset="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/00d96/diffusion-results.png 148w,https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/0b23c/diffusion-results.png 295w,https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png 474w" sizes="(max-width: 474px) 100vw, 474px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>You can generate an enclosure diagram to identify bottlenecks in your large codebase:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion diagram" title="" src="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png" srcset="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/00d96/diffusion-diagram.png 148w,https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/0b23c/diffusion-diagram.png 295w,https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png 466w" sizes="(max-width: 466px) 100vw, 466px">
    </span>
  </span>
  
  </a>
    </undefined></p><h3 id="keep-a-decision-log"><a href="#keep-a-decision-log" aria-label="keep a decision log permalink"></a>Keep a decision log</h3><p><a href="https://understandlegacycode.com/blog/earn-maintainers-esteem-with-adrs">Architecture Decision Record (ADR)</a> are very useful to simply keep track of architectural decisions in the project.</p><p>They help people understand why and how decisions were taken in the past. This is useful to re-evaluate them later in the project, as well as spreading knowledge.</p><h3 id="a-few-management-pitfalls"><a href="#a-few-management-pitfalls" aria-label="a few management pitfalls permalink"></a>A few management pitfalls</h3><p>Adam gives a few pieces of advice to managers, referring to human psychology. Whether you’re a Tech Lead or a non-technical manager, these are gold.</p><p>First, you should never …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/">https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/</a></em></p>]]>
            </description>
            <link>https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741261</guid>
            <pubDate>Sun, 05 Jul 2020 19:37:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Collapse of civilisation is the most likely outcome’: top climate scientists]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23741179">thread link</a>) | @1qazxsw23edc
<br/>
July 5, 2020 | https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/ | <a href="https://web.archive.org/web/*/https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
<p>Australia’s top climate scientist says “we are already deep into the trajectory towards collapse” of civilisation, which may now be inevitable because 9 of the 15 known global climate tipping points that regulate the state of the planet have been activated.</p>



<p>Australian National University emeritus professor Will Steffen (pictured) told <em>Voice of Action</em> that there was already a chance we have triggered a “global tipping cascade” that would take us to a less habitable “Hothouse Earth” climate, regardless of whether we reduced emissions.</p>



<p>Steffen says it would take 30 years at best (more likely 40-60 years) to transition to net zero emissions, but when it comes to tipping points such as Arctic sea ice we could have already run out of time. </p>



<p>Evidence shows we will also lose control of the tipping points for the <a rel="noreferrer noopener" href="https://www.theguardian.com/world/2019/jul/25/amazonian-rainforest-near-unrecoverable-tipping-point?CMP=share_btn_tw" data-type="https://www.theguardian.com/world/2019/jul/25/amazonian-rainforest-near-unrecoverable-tipping-point?CMP=share_btn_tw" target="_blank">Amazon rainforest</a>, the West Antarctic ice sheet, and the Greenland ice sheet in much less time than it’s going to take us to get to net zero emissions, Steffen says.</p>



<p>“Given the momentum in both the Earth and human systems, and the growing difference between the ‘reaction time’ needed to steer humanity towards a more sustainable future, and the ‘intervention time’ left to avert a range of catastrophes in both the physical climate system (e.g., melting of Arctic sea ice) and the biosphere (e.g., loss of the Great Barrier Reef), we are already deep into the trajectory towards collapse,” said Steffen.</p>



<p>“That is, the intervention time we have left has, in many cases, shrunk to levels that are shorter than the time it would take to transition to a more sustainable system.</p>



<p>“The fact that many of the features of the Earth System that are being damaged or lost constitute ‘tipping points’ that could well link to form a ‘tipping cascade’ raises the ultimate question: Have we already lost control of the system? Is collapse now inevitable?”</p>



<p>This is not a unique view – leading Stanford University biologists, who were first to reveal that we are already experiencing the sixth mass extinction on Earth, released <a href="https://www.theguardian.com/environment/2020/jun/01/sixth-mass-extinction-of-wildlife-accelerating-scientists-warn" data-type="https://www.theguardian.com/environment/2020/jun/01/sixth-mass-extinction-of-wildlife-accelerating-scientists-warn" target="_blank" rel="noreferrer noopener">new research this week</a> showing species extinctions are accelerating in an unprecedented manner, which may be a tipping point for the collapse of human civilisation.</p>



<p>Also in the past week <a rel="noreferrer noopener" href="https://www.smh.com.au/environment/climate-change/australia-among-global-hot-spots-as-droughts-worsen-in-warming-world-20200601-p54ydh.html?btis" data-type="https://www.smh.com.au/environment/climate-change/australia-among-global-hot-spots-as-droughts-worsen-in-warming-world-20200601-p54ydh.html?btis" target="_blank">research emerged</a> showing the world’s major food baskets will experience more extreme droughts than previously forecast, with southern Australia among the worst hit globally.</p>



<p>Steffen used the metaphor of the Titanic in one of his recent talks to describe how we may cross tipping points faster than the time it would take us to react to get our impact on the climate under control.</p>



<p>“If the Titanic realises that it’s in trouble and it has about 5km that it needs to slow and steer the ship, but it’s only 3km away from the iceberg, it’s already doomed,” he said.</p>



<h3>‘This is an existential threat to civilization’</h3>



<p>Steffen, along with some of the world’s most eminent climate scientists, laid out our predicament in the starkest possible terms in a <a href="https://www.nature.com/articles/d41586-019-03595-0" data-type="https://www.nature.com/articles/d41586-019-03595-0" target="_blank" rel="noreferrer noopener">piece for the journal Nature</a> at the end of last year.</p>



<p>They found that 9 of the 15 known Earth tipping elements that regulate the state of the planet had been activated, and there was now scientific support for declaring a state of planetary emergency. These tipping points can trigger abrupt carbon release back into the atmosphere, such as the release of carbon dioxide and methane caused by the irreversible thawing of the Arctic permafrost.</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1.jpg 907w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-300x209.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-768x536.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-143x100.jpg 143w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-500x349.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-690x482.jpg 690w" sizes="(max-width: 907px) 100vw, 907px"><figcaption>9 of 15 known Earth tipping points have been activated</figcaption></figure>



<p>“If damaging tipping cascades can occur and a global tipping point cannot be ruled out, then this is an existential threat to civilization,” they wrote.</p>



<p>“No amount of economic cost–benefit analysis is going to help us. We need to change our approach to the climate problem.</p>



<p>“The evidence from tipping points alone suggests that we are in a state of planetary emergency: both the risk and urgency of the situation are acute.”</p>



<p>Steffen is also the lead author of the heavily cited 2018 paper, <a rel="noreferrer noopener" href="https://www.pnas.org/content/115/33/8252" data-type="https://www.pnas.org/content/115/33/8252" target="_blank">Trajectories of the Earth System in the Anthropocene</a>, where he found that “even if the Paris Accord target of a 1.5°C to 2°C rise in temperature is met, we cannot exclude the risk that a cascade of feedbacks could push the Earth System irreversibly onto a ‘Hothouse Earth’ pathway.”</p>



<p>Steffen is a global authority on the subject of tipping points, which are prone to sudden shifts if they get pushed hard enough by a changing climate, and could take the trajectory of the system out of human control. Further warming would become self-sustaining due to system feedbacks and their mutual interaction.</p>



<p>Steffen describes it like a row of dominos and his concern is we are already at the point of no return, knocking over the first couple of dominos which could lead to a cascade knocking over the whole row.</p>



<p>“Some of these we think are vulnerable in the temperature range we’re entering into now,” said Steffen.</p>



<p>“If we get those starting to tip we could get the whole row of dominos tipping and take us to a much hotter climate even if we get our emissions down.”</p>



<p>Even the notoriously conservative United Nations Intergovernmental Panel on Climate Change (IPCC) has found that already with the 1.1°C of warming we have had to date, there was a moderate risk of tipping some of these – and the risk increased as the temperatures increased.</p>



<p>Steffen believes we are committed to at least a 1.5°C temperature rise given the momentum in the economic and climate system, but we still have a shot at staying under 2°C with urgent action.</p>



<h3>+4°C world would support &lt; 1 billion people</h3>



<p>Professor Hans Joachim Schellnhuber, director emeritus and founder of the Potsdam Institute for Climate Impact Research, believes if we go much above 2°C we will quickly get to 4°C anyway because of the tipping points and feedbacks, which would spell the end of human civilisation.</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1024x680.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1024x680.jpg 1024w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-300x199.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-768x510.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1536x1020.jpg 1536w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-151x100.jpg 151w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-500x332.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-690x458.jpg 690w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>“There is a very big risk that we will just end our civilisation”: Professor Schellnhuber</figcaption></figure>



<p>Johan Rockström, the head of one of Europe’s leading research institutes, warned in 2019 that in a 4°C-warmer world it would be “difficult to see how we could accommodate a billion people or even half of that … There will be a rich minority of people who survive with modern lifestyles, no doubt, but it will be a turbulent, conflict-ridden world”.</p>



<p>Schellnhuber, one of the world’s leading authorities on climate change, said that if we continue down the present path “there is a very big risk that we will just end our civilisation. The human species will survive somehow but we will destroy almost everything we have built up over the last two thousand years.”</p>



<p>Schellnhuber said in a <a rel="noreferrer noopener" href="https://youtu.be/4PTRTwn3wrg" data-type="https://youtu.be/4PTRTwn3wrg" target="_blank">recent interview</a> that the IPCC report stating we could stay below 1.5°C of warming was “slightly dishonest” because it relies on immense negative emissions (pulling CO2 out of the air) which was not viable at global scale. He said 1.5°C was no longer achievable but it was still possible to stay under 2°C with massive changes to society.</p>



<p>If we don’t bend the emissions curve down substantially before 2030 then keeping temperatures under 2°C becomes unavoidable. The “carbon law” <a rel="noreferrer noopener" href="https://science.sciencemag.org/content/355/6331/1269" data-type="https://science.sciencemag.org/content/355/6331/1269" target="_blank">published in the journal Science</a> in 2017 found that, to hold warming below 2°C, emissions would need to be cut in half between 2020 and 2030.</p>



<p>Steffen told <em>Voice of Action</em> that the three main challenges to humanity – climate change, the degradation of the biosphere and the growing inequalities between and among countries – were “just different facets of the same fundamental problem”.</p>



<p>This problem was the “neoliberal economic system” that spread across the world through globalisation, underpinning “high production high consumption lifestyles” and a “religion built not around eternal life but around eternal growth”.</p>



<p>“It is becoming abundantly clear that (i) this system is incompatible with a well-functioning Earth System at the planetary level; (ii) this system is eroding human- and societal-well being, even in the wealthiest countries, and (iii) collapse is the most likely outcome of the present trajectory of the current system, as prophetically modelled in 1972 in the Limits to Growth work,” Steffen told <em>Voice of Action</em>.</p>



<h3>Eternal growth is not possible</h3>



<p>The <a href="https://www.clubofrome.org/report/the-limits-to-growth/" data-type="https://www.clubofrome.org/report/the-limits-to-growth/" target="_blank" rel="noreferrer noopener">Limits to Growth model</a> released by the Club of Rome in 1972 looked at the interplay between food production, industry, population, non-renewable resources and pollution.</p>



<p>The basic findings were that you can’t grow the system indefinitely as you will cause environmental and resource issues that will ultimately cause the whole global system to collapse (ABC’s This Day Tonight program covered it <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=cCxPOqwCr1I" data-type="https://www.youtube.com/watch?v=cCxPOqwCr1I" target="_blank">here</a>). At the time of the model’s release it accurately reproduced the historical data from 1900 to 1970.</p>



<p>A <a rel="noreferrer noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0959378008000435" data-type="https://www.sciencedirect.com/science/article/abs/pii/S0959378008000435" target="_blank">2008 study</a> by Graham Turner, then a senior CSIRO research scientist, used three decades of real-world historical data to conclude that the Limits to Growth model’s predictions were coming to pass: “30 years of historical data compare favourably with key features of a business-as-usual [BAU] scenario called the ‘standard run’ scenario, which results in collapse of the global system midway through the 21st century.”</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-1024x547.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-1024x547.jpg 1024w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-300x160.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-768x410.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-187x100.jpg 187w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-500x267.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-690x369.jpg 690w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner.jpg 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Former CSIRO scientist Graham Turner has been warning about collapse for decades</figcaption></figure>



<p>Turner ran updated figures through the model <a rel="noreferrer noopener" href="https://www.ingentaconnect.com/contentone/oekom/gaia/2012/00000021/00000002/art00010" data-type="https://www.ingentaconnect.com/contentone/oekom/gaia/2012/00000021/00000002/art00010" target="_blank">again in 2012</a> for another peer-reviewed paper, and <a rel="noreferrer noopener" href="https://sustainable.unimelb.edu.au/__data/assets/pdf_file/0005/2763500/MSSI-ResearchPaper-4_Turner_2014.pdf" data-type="https://sustainable.unimelb.edu.au/__data/assets/pdf_file/0005/2763500/MSSI-ResearchPaper-4_Turner_2014.pdf" target="_blank">again in 2014</a> when he had joined the University of Melbourne’s Sustainable Society Institute.</p>



<p>“Data from the forty years or so since the LTG study was completed indicates that the world is closely tracking the BAU scenario,” Turner concluded in the 2014 paper.</p>



<p>“It is notable that there does not appear to be other economy-environment models that have demonstrated such comprehensive and long-term data agreement.”</p>



<p>Turner semi-retired in 2015 but runs a small organic market garden on a rural property in the NSW south coast’s Bega Valley.</p>



<p>He and his wife grow most of their own food and live off grid powered by a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/">https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/</a></em></p>]]>
            </description>
            <link>https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741179</guid>
            <pubDate>Sun, 05 Jul 2020 19:27:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Destroyer2 – Open Source Battleship Game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741169">thread link</a>) | @unonymous
<br/>
July 5, 2020 | https://umcconnell.github.io/destroyer2/ | <a href="https://web.archive.org/web/*/https://umcconnell.github.io/destroyer2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app" data-server-rendered="true"><div><header> <a href="https://umcconnell.github.io/destroyer2/" aria-current="page"><!----> <span>Destroyer2</span></a> </header>   <main aria-labelledby="main-title"><header><img src="https://umcconnell.github.io/destroyer2/logo.svg" alt="hero"> <!----> <p>
      A real-time multiplayer battleship game
    </p> <p><a href="https://umcconnell.github.io/destroyer2/guide/">
  Get Started →
</a></p></header> <div><div><h2>Fast</h2> <p>Enjoy great performance with Node.js™, Redis™ and WebSockets.</p></div><div><h2>Simple</h2> <p>Simple server setup and deployment. Check the guide for simple deployment instructions, including for Docker™!</p></div><div><h2>Powerful</h2> <p>Automatic room cleanup, network loss resilience, and more!</p></div></div> <div><h3 id="quick-start"><a href="#quick-start">#</a> Quick start</h3> <div><pre><code><span># Clone</span>
<span>git</span> clone https://github.com/umcconnell/destroyer2.git
<span>cd</span> destroyer2

<span># Setup</span>
<span># Make sure you have docker and docker-compose installed!</span>
./docker/deploy.sh simple

<span># Done!</span>
<span># Visit http://localhost:8080 to get started</span>
</code></pre></div></div> <!----></main></div></div></div>]]>
            </description>
            <link>https://umcconnell.github.io/destroyer2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741169</guid>
            <pubDate>Sun, 05 Jul 2020 19:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UBC quietly changes references to Taiwan amid sensitive political climate]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23741119">thread link</a>) | @abc-xyz
<br/>
July 5, 2020 | https://www.ubyssey.ca/news/taiwan-references-changed/ | <a href="https://web.archive.org/web/*/https://www.ubyssey.ca/news/taiwan-references-changed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <p>UBC has quietly made a significant change in the way it refers to Taiwan in its annual enrolment report.</p><p>In <a href="https://academic.ubc.ca/sites/vpa.ubc.ca/files/documents/2018-19%20Enrolment%20Report.pdf" target="_blank"><u>past reports</u></a>, the university simply listed the island as “Taiwan,” but in the recent <a href="https://bog3.sites.olt.ubc.ca/files/2020/01/4_2020.02_Enrolment-Annual-Report.pdf" target="_blank"><u>2019/20</u></a> enrolment report, it was lengthier: “Taiwan (Province of China).”</p><p>In a written statement from Kurt Heinrich, UBC Media Relations senior communications director, he said this is because in 2018, UBC’s data governance steering committee adopted International Organization for Standardization (ISO) data standards.</p><p>The ISO, which is recognized by the United Nations, has referred to Taiwan as “Province of China” <a href="https://www.taiwannews.com.tw/en/news/3812381" target="_blank"><u>since 1974</u></a> under ISO 3166, and the UN switched its recognition of China from the Republic of China (Taiwan) to the People’s Republic of China (Mainland China) in 1971.</p><p>In a later email, the university stated that the adoption of ISO standards was “necessary for the university’s successful transition to Workday,” UBC’s partner for its software overhaul that will replace aging systems. Elsewhere on UBC websites, however, the island is still referred to as “Taiwan.”</p><p>The nature of Taiwan’s sovereignty is a deeply political debate. Taiwan, which boasts its own democratically elected government, claims to be an independent nation. Mainland China, on the other hand, claims Taiwan to be an integral province of China.</p>
<p>“To put ‘Province of China’ after the name is to politicize the name,” said Dr. Timothy Brook, a UBC professor and an expert in Chinese history.</p><p>Many countries have <a href="https://www.newsweek.com/who-recognizes-taiwan-two-change-china-1460559" target="_blank"><u>switched their allegiance</u></a> from Taipei to Beijing in recent decades. In 1970, Canada severed diplomatic ties with Taipei in favour of Beijing, but Canada and Taiwan maintain strong trade and informal ties.</p><p>UBC’s decision to make the change to label Taiwan as a “Province of China” came at a low point in Chinese–Canadian relations, following the <a href="https://www.ctvnews.ca/world/trudeau-says-china-made-obvious-link-between-meng-and-two-michaels-1.4994128" target="_blank"><u>arrests</u></a> of Huawei CFO Meng Wanzhou in Vancouver, and the <a href="https://www.theglobeandmail.com/politics/article-china-suggests-it-will-free-two-michaels-if-canada-allows-huawei/" target="_blank"><u>two Michaels</u></a> in China, which Brook described as “political hostage taking.”</p><p>For UBC, the stakes for appeasing China are high. Huawei has granted <a href="https://nationalpost.com/news/meng-wanzhou-arrest-caused-ubc-leaders-concern-over-enrolment-fundraising-internal-documents-show" target="_blank"><u>$9.5 million</u></a> in funding for research projects at UBC in recent years, which continued even after Meng’s December 2018 arrest.</p><p>Chinese students make up more than one third of all international students at UBC. In 2019/20, international student tuition made up <a href="https://bog3.sites.olt.ubc.ca/files/2020/04/2.1_2020.04_Budget-Fiscal-2020-2021.pdf" target="_blank"><u>$507 million</u></a> in revenue compared to $386 million from domestic students. Rising Canadian–Chinese tensions have made UBC administrators fear potential impacts on Chinese student enrolment and funding.</p><p>In 2019, Vice-Provost International Murali Chandrashekaran sent an <a href="https://nationalpost.com/news/meng-wanzhou-arrest-caused-ubc-leaders-concern-over-enrolment-fundraising-internal-documents-show" target="_blank"><u>email</u></a> to colleagues calling for a campus-wide meeting to address this, “given our significant reliance on China for students/$.”</p><p>If diplomatic tensions reach a point where China restricts students from going to UBC, as<a href="https://www.ubyssey.ca/news/ubc-urges-saudi-arabia-students-to-contact-enrolment-services/" target="_blank"><u> Saudi Arabia did in 2018</u></a>, UBC could face a significant <a href="https://theprovince.com/pmn/news-pmn/canada-news-pmn/credit-agency-warns-big-risk-to-canadian-schools-if-china-pulls-students/wcm/268ed61c-89fd-41e0-8a2d-3aba815152e3" target="_blank"><u>credit risk</u></a>, according to prominent credit agency Moody’s.</p><p>Anxieties surrounding Chinese interference also exist at other Canadian universities. At McMaster University, a Chinese student group had its club status <a href="https://www.scmp.com/news/china/diplomacy/article/3036309/chinese-student-association-mcmaster-university-loses-appeal" target="_blank"><u>revoked</u></a> after allegations it reported a talk by a Uyghur–Canadian woman to the Chinese consulate. At the University of Toronto, Chemi Lhamo, student union president and Canadian of Tibetan origins, was met with widespread <a href="https://www.cbc.ca/news/canada/toronto/china-tibet-student-election-1.5019648" target="_blank"><u>backlash</u></a> by Chinese students after her election win.</p>
<p>Yves Tiberghien, a UBC political science professor focusing on China and the Asia-Pacific Region, said he “can’t imagine” that the change in recognition of Taiwan in the recent enrolment report was due to Chinese financial influence.</p><p>“If I had to guess,” he added, the technical committee that decided this likely “did not have the full knowledge” of the sensitive political nature of the Taiwan–China relationship.</p><p>According to Brook, however, it is “entirely possible” that there were some Chinese pressures. “I wouldn’t be surprised if every Chinese consulate in Canada was going around and looking at things like universities to see how [they] refer to Taiwan, but I have no evidence of this,” he said. “It would be entirely in keeping with the kind of broader diplomatic initiatives that the [People’s Republic of China]’s been making over the last five years.”</p><p>While the university claims the decision was made for technical purposes, it did not respond to a follow-up email asking whether the committee responsible for the change was aware of the political context around the name.</p><p>“I wish they hadn’t done it,” said Tiberghien. “I don’t think it’s a good idea because it’s stepping into something that’s raw right now … the last thing you want is to step into this now.”</p>
      
      </div></div>]]>
            </description>
            <link>https://www.ubyssey.ca/news/taiwan-references-changed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741119</guid>
            <pubDate>Sun, 05 Jul 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HiddenAds up to no good again and spreading via Android gaming apps]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23741108">thread link</a>) | @realpanzer
<br/>
July 5, 2020 | https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/ | <a href="https://web.archive.org/web/*/https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1870">

                    
                    
                    
                    <div>
                        
<p>I recently discovered a large campaign of HiddenAds on the Google Play Store, spreading via gaming apps. The initial discovery was made through an apklab.io automated detection that was based on similar features of a previous HiddenAds campaign that was present on the Play Store. Upon further analysis of the app through <a href="https://www.apklab.io/">apklab.io</a>, Avast’s mobile threat intelligence platform, I was able to identify a wider campaign by comparing similar activities, features, and network traffic. In total, I found 47 apps.</p>



<p>The apps’ poor reviews on the Play Store, combined with their capability to hide their icon and display ads outside the apps confirmed that they are part of the HiddenAds family.</p>



<h2><strong>One app leads to 47&nbsp;</strong></h2>



<p>Once I determined that the <a href="https://play.google.com/store/apps/details?id=com.dancing.color.road.ball.run.music">Dancing Run</a> app I found belongs to the HiddenAds family, I utilized <a href="https://www.apklab.io/">apklab.io</a> to conduct a search for similar apps.&nbsp;</p>



<p>I started my search by looking at the app’s entry points, as apklab.io groups apps with the same activities, receivers and services. The ability to see how many apps share an entry point is a useful feature in identifying unique shared features, and helped me find a set of entry points created for the original app.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1.png 1022w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1-300x173.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-1-768x443.png 768w" sizes="(max-width: 1022px) 100vw, 1022px"><figcaption>Entrypoints section of apklab.io.</figcaption></figure></div>



<p>I then searched the apklab.io database for apps with these unique entry points by using <strong>service:com.alive.ALiveService. </strong>To further narrow down the search results, I added the <strong>is:PlayFrosting</strong> parameter to find similar apps on the Play Store.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-1024x671.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-1024x671.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-300x197.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1-768x503.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/twitter-thread-2-1.png 1064w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Filtering search results to narrow down APKs on Play Store.</figcaption></figure></div>



<p>Apklab.io allows various filtering criteria in its search. I conducted another search with <strong>f:HideApplicationIconFromLauncher </strong>to identify apps that hide their icon from the launcher.</p>



<p>Continuing the search, I was able to discover more similar apps using the network dump dynamic feature. It collects information on the app network activity and in this case a specific URL was accessed by several of these apps.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-1024x429.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-1024x429.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-300x126.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-768x322.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic.png 1182w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Dynamic network dump results.</figcaption></figure></div>



<p>I used the URL search filter <strong>host:”res.resvivinew.com”</strong> and found additional HiddenAds apps that shared this URL connection.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-1024x731.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-1024x731.png 1024w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-300x214.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search-768x548.png 768w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/URL-Dynamic-search.png 1052w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>URL search results find additional apps.</figcaption></figure></div>



<p>I combined these methods of searching with other accessed URLs and activities. I was able to detect over 200 HiddenAds APKs. Of these, 47 apps were active on the Play Store. Apklab.io is a great tool for initial discovery and assessment of how widespread a particular family of apps is.</p>



<h2><strong>Taking a closer look</strong></h2>



<p>When diving deeper into the apps’ code, it became apparent that the apps are in fact repackaged games with an added layer of HiddenAds code. The newer versions of these apps only had slightly different code, but overall the apps all have nearly identical HiddenAds code. The added code is intentionally obfuscated and contains the ability to hide the icon from the launcher. The apps wait for a period of time after installation, then initiate the hide icon process.</p>



<p>In <a href="https://www.apklab.io/apk.html?hash=523f50a5fac3aa3f8aaaa3dffa807c61e194b2c6a3c58eb77d89c24656dca829">Throw Master</a>, one of the apps I analyzed, a ten minute delay execution timer starts as soon as the app is installed. This allows enough time to play the first three free levels of the game. The game regularly checks the timer while in use. Meanwhile, a broadcast receiver monitors the USER_PRESENT broadcasts which indicates if the phone is unlocked. If it is, it resets the timer. Once the ten minute delay is reached, the hide icon job is triggered.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1.png 556w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-1-300x60.png 300w" sizes="(max-width: 556px) 100vw, 556px"><figcaption>Main launcher activity used in the hide icon process.</figcaption></figure></div>



<p>The process starts by disabling the main launcher activity, in this case <strong>SplashActivity</strong> is the main launcher activity.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2.png 615w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-2-300x95.png 300w" sizes="(max-width: 615px) 100vw, 615px"><figcaption>PackageManager used to disabled main launcher activity.</figcaption></figure></div>



<p><strong>PackageManager </strong>is used to hide the icon from the launcher through <strong>setComponentEnabledSetting</strong>. This setting disables the main launcher activity and as a side effect hides the app’s launcher icon. </p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3.png 646w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/Code-snipper-3-300x142.png 300w" sizes="(max-width: 646px) 100vw, 646px"><figcaption>INSTALL_SHORTCUT is used to create a shortcut.</figcaption></figure></div>



<p>The app then creates a shortcut on the home screen using the <strong>INSTALL_SHORTCUT </strong>launcher action. The shortcut differs from a launcher icon in that, even if deleted, it doesn’t remove the application from the device.</p>



<p>The user may figure out the app is the source of the ads and delete the newly created shortcut, however, this will not remove the app from the device. To the users’ frustration, the ads will continue until the app is removed via the device app settings.</p>



<p>Once the icon is hidden, the apps start to display ads outside of the apps. The apps have the ability to display intrusive ads over other apps via banners and notifications. Several apps even open the browser to display additional ads.</p>



<h2>Play Store warning signs</h2>



<p>Another shared attribute of these apps is that the developer only has a single app on their developer profile with a generic email address. Similarly, the Terms of Service are identical for all of the apps, likely pointing to an organized campaign by one actor. These warning signs could potentially be recognized by users.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1.png 695w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-1-300x104.png 300w" sizes="(max-width: 695px) 100vw, 695px"><figcaption>Generic developer name and email address.</figcaption></figure></div>



<p>The developers likely spread out the apps under different developer profiles to avoid detection and to make the adware removal more difficult.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1.png 866w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1-300x187.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-2-1-768x479.png 768w" sizes="(max-width: 866px) 100vw, 866px"><figcaption>Single app attributed to each developer profile.</figcaption></figure></div>



<p>The app reviews are a potential telltale sign for the regular user as they showcase the frustration and malicious features present in the app.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1.png 695w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/app-dev-3-1-253x300.png 253w" sizes="(max-width: 695px) 100vw, 695px"><figcaption>Users correctly point out the adware features of the app.</figcaption></figure></div>



<h2>Spread</h2>



<p>Combined, the apps have been downloaded more than 15 million times. Several of these apps have been on the Play Store since early May, contributing to their high downloads.</p>



<figure><table><tbody><tr><td><strong>App Name</strong></td><td><strong>Downloads</strong></td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.draw.color.number.paint.lvye">Draw Color by Number</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.skate.board.fly.chute.race">Skate Board</a><a href="https://play.google.com/store/apps/details?id=com.skate.board.fly.chute.race"> – New</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.differences.findout.spot10">Find Hidden Differences</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.shooter.master.bullet.puzzle.huahong">Shoot Master</a></td><td>1,000,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.love.finddifferences.sogoodgame">Spot Hidden Differences</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.dancing.color.road.ball.run.music">Dancing Run – Color Ball Run</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.find.five.differences.puzzle.dawang">Find 5 Differences</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.cut.wood.joyworker.woodgames">Joy Woodworker</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.throw.master.toss.jump.higher">Throw Master</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.throw.into.space.toss.high.up.hang">Throw into Space</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.divide.it.cut">Divide it – Cut &amp; Slice Game</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.tony.shoot.newmigame">Tony Shoot – NEW</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.assassin.legend.killer.attack.sanyi">Assassin Legend</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.stacking.guys.newbee.game">Stacking Guys</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.play.boy.face.game">Save Your Boy</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.walkthrough.knife.assassin.hunter.baoer">Assassin Hunter 2020</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.stealinggames.run">Stealing Run</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.fly.skater.newrace.rungame">Fly Skater 2020</a></td><td>500,000</td></tr><tr><td><a href="https://play.google.com/store/apps/details?id=com.sports.disc.fly.fight">Disc Go！</a></td><td>500,000</td></tr></tbody></table><figcaption><br>Most downloaded HiddenAds discovered on Play Store.</figcaption></figure>



<p>It appears the campaign initially targeted users in India and South East Asia. Based on previous HiddenAds campaigns, the apps likely spread through game ads focused in these regions. Due to the generic developer details and Terms of Service, I cannot pinpoint where the developers of these apps are from. The map below indicates the initial 200 downloads of the <a href="https://www.apklab.io/apk.html?hash=15d9f6ebe532dc631b73d66cfd1d8ae8a608a53628bfff63924a1ed07f356559">Find 5 Differences</a> app recorded by Avast Mobile Security. The other investigated apps share a similar trend of initial downloads.</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1.png 1015w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1-300x166.png 300w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/06/spread-map-1-768x425.png 768w" sizes="(max-width: 1015px) 100vw, 1015px"><figcaption>Map shows the % spread of first 200 downloads recorded by Avast.</figcaption></figure></div>



<p>I believe that the initial spread across other regions that can be seen in the map above, is likely “collateral damage” caused by the apps’ presence on the Play Store.</p>



<p>While this gives us a snapshot of the initial spread, the current prevalence of these apps differs. Based on Avast’s internal statistics, this HiddenAds campaign is currently most prevalent in Brazil, India and Turkey.</p>



<figure><table><tbody><tr><td><strong>Country</strong></td><td><strong>Share</strong></td></tr><tr><td>Brazil</td><td>21%</td></tr><tr><td>India</td><td>8.10%</td></tr><tr><td>Turkey</td><td>6.30%</td></tr><tr><td>Argentina</td><td>5.60%</td></tr><tr><td>Mexico</td><td>3.70%</td></tr></tbody></table><figcaption><br>Percentage spread of Avast users who have downloaded at least one of the HiddenAds apps in the last two weeks by country.</figcaption></figure>



<p>The HiddenAds campaign was able to spread globally due to its presence on the Play Store. Once the apps are removed from the Play Store, the user numbers will likely go down rapidly.</p>



<h2>Summary</h2>



<p>Thanks to <a href="https://www.apklab.io/">apklab.io</a>, we were able to find 47 apps violating Google’s developer <a href="https://play.google.com/about/monetization-ads/ads/">Ads</a> and <a href="https://play.google.com/about/spam-min-functionality/">Spam</a> policies, in addition to the original app we found. We have reported these to Google, and at the time of posting, Google removed 30 of the apps. Campaigns like HiddenAds apps may slip into the Play Store through obfuscating their true purpose or through incremental version updates that introduce intrusive ads and hide icon features once they have been downloaded by users. It is difficult to prevent future campaigns from making their way onto the Play Store, as the actors behind the campaign use one-off developer accounts for each uploaded app. Avast will monitor further developments of the HiddenAds campaigns through apklab.io features, as well as via automated detections.</p>



<h2>Samples</h2>



<p>Due to the number of samples, we’ve only selected the APKs that were present on the Play Store and put them into this <a href="https://docs.google.com/spreadsheets/d/19duB05JzEaXmxbW382Leby9d6gEnQbwEgI4u5Y0ZOJw/edit#gid=0">spreadsheet</a>.</p>



<h2>Tips on avoiding adware</h2>



<ul><li>Install a trustworthy antivirus app. Antivirus acts as a safety net and can protect you from adware.</li><li>Exercise caution when downloading apps. Read app reviews before installing a new app, carefully reading both positive and negative reviews. Notice if reviewers comment on whether or not the app does what it says it will do. If an app’s review includes comments like “this app doesn’t do what it promises” or “this app is packed with adware,” – think twice about downloading the app! &nbsp;Reviews like this are a sign that something isn’t right.</li><li>Always carefully check app permissions, closely looking to see if they make sense. Granting incorrect permissions can send sensitive data to cybercriminals, including information such as contacts stored on the device, media files and insights into personal chats. If anything seems out of the ordinary or beyond what seems appropriate, the app should not be downloaded.</li></ul>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://decoded.avast.io/jakubvavra/hiddenads-up-to-no-good-again-and-spreading-via-android-gaming-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741108</guid>
            <pubDate>Sun, 05 Jul 2020 19:14:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport makes up only 6% of the greenhouse gas emissions from food]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 73 (<a href="https://news.ycombinator.com/item?id=23741040">thread link</a>) | @shafyy
<br/>
July 5, 2020 | https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>There's a common misconception that eating locally produced foods is important from an environmental point of view. Even the <a href="https://twitter.com/UN/status/1188622911080415235">UN tweeted about it.</a> This is wrong.</p><p>Transport makes up only 6% of the greenhouse gas emissions from food:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/How-much-of-GHGs-come-from-food-1-.png" alt="" width="3889" height="3935" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/How-much-of-GHGs-come-from-food-1-.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/How-much-of-GHGs-come-from-food-1-.png 1000w, https://blog.yeticheese.com/content/images/size/w1600/2020/07/How-much-of-GHGs-come-from-food-1-.png 1600w, https://blog.yeticheese.com/content/images/size/w2400/2020/07/How-much-of-GHGs-come-from-food-1-.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://ourworldindata.org/environmental-impacts-of-food">Our World in Data</a>.</figcaption></figure><p>The reason for this is that most foods are transported by ship and not plane. Only about 0.16% of food miles are done by plane:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/share-food-miles-by-method.png" alt="" width="3400" height="2400" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/share-food-miles-by-method.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/share-food-miles-by-method.png 1000w, https://blog.yeticheese.com/content/images/size/w1600/2020/07/share-food-miles-by-method.png 1600w, https://blog.yeticheese.com/content/images/size/w2400/2020/07/share-food-miles-by-method.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://ourworldindata.org/grapher/share-food-miles-by-method">Our World in Data</a>.</figcaption></figure><p>It makes sense to try and avoid foods that are transported by air. Typically, those are foods which are highly perishable, such as asparagus, green beans and berries.</p><p>In some cases, eating local food even has a more negative impact on the environment than buying something that has been produced half way around the world. For example, heated greenhouses are energy intensive and can produce more greenhouse gases than transporting something for thousands of kilometers by water or road.</p><p>It's clear that avoiding meat and dairy has a much bigger impact on reducing greenhouse gas emissions.</p><p>So, why do people keep saying that we should eat local?</p><p>It could just be ignorance. However, I think that it's often a straw man argument pushed by interest groups that want to keep selling meat and dairy. It is something that is easy to do and seems to make sense on the surface to many people. Let's take another look at that UN tweet from before:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png" alt="" width="1194" height="634" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 1000w, https://blog.yeticheese.com/content/images/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 1194w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://twitter.com/UN/status/1188622911080415235">Tweet from @UN</a> on Oct 28, 2019.</figcaption></figure><p>In addition to eating local food, they also recommend unplugging unused appliances and using less hot water. Like avoiding plastic bags or plastic straws, this is good advice but a long shot from making a meaningful impact on climate change.</p><p>Arguments like these try to shift away the spot light from big companies who collectively make up a large chunk of the greenhouse gas emissions to individuals. People think that they did something meaningful by buying local food, which, as we have seen, is not the case.</p><p>I'm not saying that we shouldn't do those things. We absolutely should, but it shouldn't be the main talking points of organizations like the UN or WWF.</p><p>To make real change, we must eat less meat and dairy, move to more renewable energy sources and reduce air and road travel significantly.</p><p>PS: I'm only talking about the impact on climate change in this article. Eating local and organic food has other benefits such as supporting the local economy and in most cases it's a good idea to do it.</p><p>Comments or questions? Join in on the discussion on <a href="https://twitter.com/yeticheeseparty/status/1279850824378781697?s=20">this Twitter thread</a>. </p><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->


<div id="mc_embed_signup">
<p>
    Our plant-based Yeti Feta will be available to order soon. Leave your email below and we'll let you know when it's ready. (No newsletters or other shenanigans)
</p>

</div>

<!--End mc_embed_signup--><!--kg-card-end: html-->
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741040</guid>
            <pubDate>Sun, 05 Jul 2020 19:05:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Organising WS2811 LEDs]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23741036">thread link</a>) | @iamflimflam1
<br/>
July 5, 2020 | https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html | <a href="https://web.archive.org/web/*/https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Lots of LEDs? It’s not Christmas yet!</p>

<p>I had a big bundle of addressable WS2811 LED strings and an ESP-CAM board (an ESP32 dev board with a camera). There’s only one possible project that you can do with these components. Turn the disorganised chaos of lights into something a bit more organised.</p>

<p>As an added bonus I’ve ended up duplicating the image processing code in JavaScript so you don’t even need a camera on your ESP32 board - you can just use a plain dev board to drive the LEDs.</p>

<p>You can see the results of my efforts in the video below and I’ll run through a bit more detail of the code in the following text.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Ueim2Ko8VWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The full sample code can be found here: <a href="https://github.com/atomic14/self-organising-leds">https://github.com/atomic14/self-organising-leds</a></p>

<p>If you want to do this yourself then you will need an ESP32 dev board of some kind and of course you’ll need some kind of addressable LEDs. I’m using the <a href="https://github.com/FastLED/FastLED">FastLED</a> library for driving the LEDs so with some small code changes you can probably support pretty much any addressable LEDs.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/boards.jpg" alt="ESP32 and ESP-CAM Boards"></p>

<p>Our challenge comes down to a very basic problem, given access to a stream of images from a camera identity the approximate locations of each LED in 2D space. Once you’ve done that it’s a simple problem to map from each LED’s x and y location onto a frame buffer containing the pattern you want to show.</p>

<p>There’s a bunch of boiler plate code to initialise the ESP-CAM - I took inspiration from the sample code <a href="https://randomnerdtutorials.com/esp32-cam-video-streaming-face-recognition-arduino-ide/">here</a> and copied the bits I needed to get the camera up and running.</p>

<p>An important change I’ve made is only capture greyscale images at the lowest framesize:</p>

<div><div><pre><code><span>config</span><span>.</span><span>pixel_format</span> <span>=</span> <span>PIXFORMAT_GRAYSCALE</span><span>;</span>
<span>config</span><span>.</span><span>frame_size</span> <span>=</span> <span>FRAMESIZE_QQVGA</span><span>;</span>
</code></pre></div></div>

<p>And then to grab a frame from the camera we simply do:</p>

<div><div><pre><code>    <span>camera_fb_t</span> <span>*</span><span>fb</span> <span>=</span> <span>esp_camera_fb_get</span><span>();</span>
    <span>Frame</span> <span>*</span><span>frame</span> <span>=</span> <span>new</span> <span>Frame</span><span>(</span><span>fb</span><span>);</span>
    <span>esp_camera_fb_return</span><span>(</span><span>fb</span><span>);</span>
</code></pre></div></div>

<p>With our Frame class grabbing a copy of the pixels along with the width and the height of the image.</p>

<div><div><pre><code><span>pixels</span> <span>=</span> <span>(</span><span>uint8_t</span> <span>*</span><span>)</span><span>malloc</span><span>(</span><span>fb</span><span>-&gt;</span><span>height</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>width</span><span>);</span>
<span>memcpy</span><span>(</span><span>pixels</span><span>,</span> <span>fb</span><span>-&gt;</span><span>buf</span><span>,</span> <span>fb</span><span>-&gt;</span><span>height</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>width</span><span>);</span>
<span>width</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>width</span><span>;</span>
<span>height</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>height</span><span>;</span>
<span>length</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>width</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>height</span><span>;</span>
</code></pre></div></div>

<p>The image below shows a frame grabbed from the ESP-CAM sensor.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/grabbed-frame.png" alt="Grabbed Frame"></p>

<p>For the JavaScript version of this code it’s a bit more complicated. One of the biggest problems is that we need to be running over HTTPS to have access to the camera - more on this later….</p>

<div><div><pre><code><span>const</span> <span>stream</span> <span>=</span> <span>await</span> <span>navigator</span><span>.</span><span>mediaDevices</span><span>.</span><span>getUserMedia</span><span>({</span>
  <span>video</span><span>:</span> <span>{</span> <span>facingMode</span><span>:</span> <span>"</span><span>environment</span><span>"</span> <span>},</span>
  <span>audio</span><span>:</span> <span>false</span><span>,</span>
<span>});</span>
<span>const</span> <span>canPlayListener</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>// the video is loaded and we can grab frames</span>
  <span>onVideoReady</span><span>(</span><span>video</span><span>);</span>
  <span>video</span><span>.</span><span>removeEventListener</span><span>(</span><span>"</span><span>canplay</span><span>"</span><span>,</span> <span>canPlayListener</span><span>);</span>
<span>};</span>
<span>video</span><span>.</span><span>addEventListener</span><span>(</span><span>"</span><span>canplay</span><span>"</span><span>,</span> <span>canPlayListener</span><span>);</span>
<span>video</span><span>.</span><span>srcObject</span> <span>=</span> <span>stream</span><span>;</span>
<span>video</span><span>.</span><span>play</span><span>();</span>
</code></pre></div></div>

<p>Once we have a video stream coming from the camera we can grab a frame by drawing the video to a canvas context and then getting the imageData from it.</p>

<div><div><pre><code><span>function</span> <span>getVideoFrame</span><span>(</span><span>video</span><span>:</span> <span>HTMLVideoElement</span><span>,</span> <span>canvas</span><span>:</span> <span>HTMLCanvasElement</span><span>)</span> <span>{</span>
  <span>const</span> <span>width</span> <span>=</span> <span>video</span><span>.</span><span>videoWidth</span><span>;</span>
  <span>const</span> <span>height</span> <span>=</span> <span>video</span><span>.</span><span>videoHeight</span><span>;</span>
  <span>const</span> <span>context</span> <span>=</span> <span>canvas</span><span>.</span><span>getContext</span><span>(</span><span>"</span><span>2d</span><span>"</span><span>);</span>
  <span>// draw the video to the canvas</span>
  <span>context</span><span>!</span><span>.</span><span>drawImage</span><span>(</span><span>video</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>);</span>
  <span>// get the raw image bytes</span>
  <span>const</span> <span>imageData</span> <span>=</span> <span>context</span><span>!</span><span>.</span><span>getImageData</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>);</span>
  <span>// convert to greyscale</span>
  <span>const</span> <span>bytes</span> <span>=</span> <span>new</span> <span>Uint8Array</span><span>(</span><span>width</span> <span>*</span> <span>height</span><span>);</span>
  <span>for</span> <span>(</span><span>let</span> <span>y</span> <span>=</span> <span>0</span><span>;</span> <span>y</span> <span>&lt;</span> <span>height</span><span>;</span> <span>y</span><span>++</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>let</span> <span>x</span> <span>=</span> <span>0</span><span>;</span> <span>x</span> <span>&lt;</span> <span>width</span><span>;</span> <span>x</span><span>++</span><span>)</span> <span>{</span>
      <span>const</span> <span>r</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span><span>];</span>
      <span>const</span> <span>g</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span> <span>+</span> <span>1</span><span>];</span>
      <span>const</span> <span>b</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span> <span>+</span> <span>2</span><span>];</span>
      <span>// https://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale</span>
      <span>const</span> <span>grey</span> <span>=</span> <span>Math</span><span>.</span><span>min</span><span>(</span><span>255</span><span>,</span> <span>0.299</span> <span>*</span> <span>r</span> <span>+</span> <span>0.587</span> <span>*</span> <span>g</span> <span>+</span> <span>0.114</span> <span>*</span> <span>b</span><span>);</span>
      <span>bytes</span><span>[</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>]</span> <span>=</span> <span>grey</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>return</span> <span>bytes</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/phone-interface.png" alt="Phone Interface"></p>

<p>Now we can grab frames we just need to grab a frame with no LEDs lit, light one LED, grab another frame and then compare the two. The difference should tell us where the LED is. To avoid noise or small movements of the camera having a bit impact we apply a guassian blur to the captured frames before taking the difference.</p>

<p>This is a of course a very naive and simple algorithm and could easily be improved on.</p>

<p>In the C++ code of the ESP32 we do all this directly in code. In the JavaScript version we call API functions on the web interface of the ESP32 to turn LEDs on and off and once we’ve finished the processing send up the calculated positions of the LEDs to the board.</p>

<p>In our ESP32 code we create a framebuffer and draw patterns into it. We then use the locations of each LED to work out what color it should be.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/organised.jpg" alt="Organised"></p>

<p>To solve the issue of needing HTTPS to access the camera and also needing the API calls to be HTTPS as well (we can’t mix content nowadays!) we need a way of serving both the UI and the API from the ESP32 web server over HTTPS. There are web servers that support HTTPS and self signed certificates available for the ESP32 but this leads to other problems and would require a rewrite of the device code. An easy workaround to this problem is to use a service such as <a href="https://ngrok.com/">ngrok</a> to provide a secure URL from the cloud through our computer to the ESP32 device. Slightly convoluted, but it works!</p>

<p>This in only needed if you are not using an ESP-CAM and have to use your phone’s camera for calibrating the LEDs. Sign up for a free acount with ngrok and then find the IP address of your ESP32 board:</p>

<div><div><pre><code>ping espcam.local
PING espcam.local (10.0.1.17): 56 data bytes
64 bytes from 10.0.1.17: icmp_seq=0 ttl=255 time=14.343 ms
64 bytes from 10.0.1.17: icmp_seq=1 ttl=255 time=6.493 ms
</code></pre></div></div>

<p>Take the IP-Address and ask ngrok to start proxying requests for us:</p>

<div><div><pre><code>ngrok http 10.0.1.17 -inspect=false
</code></pre></div></div>

<p>You’ll need steady hands - there’s quite a lot of latency going on so the space between turning an LED on and off and grabbing a frame can be quite large. I slightly moved as I was taking the frame to show the locations so the positions are slightly off.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/located.png" alt="LED locations"></p>

<p>Checkout the video to see how well it works - surprising for such a simple algorithm.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Ueim2Ko8VWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

          </div></div>]]>
            </description>
            <link>https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741036</guid>
            <pubDate>Sun, 05 Jul 2020 19:04:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn about transaction isolation levels]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740921">thread link</a>) | @lanraccoon
<br/>
July 5, 2020 | https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/ | <a href="https://web.archive.org/web/*/https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Databases are everywhere and they’re here to stay. If you’re a bit familiar with <a href="https://en.wikipedia.org/wiki/Relational_database">relational databases</a> you are probably familiar with transactions. Transactions are pretty powerful tools when working with databases. They allow multiple users to play nicely with each other while working on the same database. However, with more and more users connecting to the same database, you’re bound to run into performance issues sooner or later.&nbsp;</p>
<p>Powerful as they are, transactions are a double edge sword. Used incorrectly they can, and will eat up your database’s resources. Transaction isolation levels, are a way to fine-tune the I (Isolation) bit of ACID (Atomicity, Consistency, Isolation, Durability). You can increase concurrency if you are willing to make a compromise about what <em>Isolated </em>actually means.&nbsp;</p>
<h3>Isolation issues</h3>
<p>First things first, what can possibly go wrong ? Assuming that each statement abides by the ACID principles (which they are), when multiple statements are run by different users at the same time, you can run into issues such as:&nbsp;</p>
<ul><li><strong>Dirty reads</strong> – Data is being read while in the process of being updated. For example: Bob changes a row a part of a transaction. Alice reads that row and gets the data that is saved in the database. Bob then rolls back the transaction. In this case Alice has data that technically never existed.</li><li><strong>Non-repeatable reads</strong> – Subsequent reads don’t return consistent results. For example: Alice starts a transaction that reads data on a row. Bob changes that row and commits the changes. Alice, while in the same transaction, reads the same row again and gets a new value for the data.&nbsp;</li><li><strong>Phantom reads</strong> – Subsequent select statements may return different results. For example: Alice runs a select statement with a where clause that returns multiple rows. Bob inserts a row that fits with the where clause of the statement that Alice ran previously and commits the result. Alice runs the same select statement that she previously ran, and she now gets new rows as a result.&nbsp;</li></ul>
<h3>Database locks</h3>
<p>We saw what can go wrong, now let’s see how we can defend against it. Firstly, the tools: database locks. Once a transaction acquires a lock on a resource, they can limit the access other transactions have on that same resource by preventing other transactions from acquiring their locks. This, combined with the fact that each transaction needs to acquire the appropriate lock before they make operations, gives us a pretty comprehensive and mechanism that we can play with.</p>
<p>Different databases have different models for locks, but they share common patterns:</p>
<h4>Level:</h4>
<ul><li>Row level: Locks are placed on a single table row</li><li>Table level: Locks are placed on the table</li><li>Page level: This is an intermediary lock (between row and table) and applies to a page – a subset of the table rows, typically, the amount of data that can be read from the disk in a single disk operation.&nbsp;</li><li>Database level: As you can imagine, a&nbsp; lock that applies to the whole database.&nbsp;</li></ul>
<h4>Concurrency:&nbsp;</h4>
<ul><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842304.html">Shared locks</a>, also known as read locks. A shared lock on a resource is usually requested when a transaction wants to read data (i.e. select operations). Multiple transactions can acquire shared locks on a resource, meaning that multiple transactions can read data at the same time.</li><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842279.html">Exclusive locks</a>, also known as write-locks. An exclusive lock can only be acquired by a single transaction at a time. If there is another transaction who has a lock on the resource (shared or exclusive), the transaction will wait for the other transaction to release the locks. While a transaction holds an exclusive lock, no other transactions can acquire any locks on the resource (shared or exclusive)&nbsp;</li><li><a href="https://docs.oracle.com/javadb/10.8.3.0/devguide/cdevconcepts842385.html">Update locks</a>, are a more relaxed version of the exclusive lock. An update lock can be acquired on an object that has a shared lock on it. When the transaction is ready to update the object, it will convert the update lock into an exclusive lock. Please note that update locks can be acquired an object that has a shared lock on it, but a shared lock cannot be acquired on an object that has an update lock.&nbsp;</li></ul>
<h3>Transaction isolation level</h3>
<p>Transactions make use of these locks to implement different isolation levels. At a really high level, isolation levels are a way to balance concurrency with isolation. The higher the isolation level, the more restrictive locks are going to be, thus the more transactions will have to wait to acquire said locks, which will result in a lower total number of transaction. As they say, there’s no such a thing as a free lunch. These are the transaction isolation levels:</p>
<h4>Read uncommitted</h4>
<p>This is the most relaxed isolation level. It allows the current transaction to read data that hasn’t been committed by other transactions yet. Transactions don’t acquire any locks for resources. This can potentially result in reading that that is in the middle of modified by other transactions.&nbsp;</p>
<h4>Read committed</h4>
<p>The transaction can only read data that has been committed. The transaction acquires shared locks when reading resources and it releases them as soon as the read statement is complete. This means that we are only read data that has completed updating, but since we’re releasing the lock after each instruction, we can get different results on subsequent reads.&nbsp;</p>
<h4>Repeatable reads</h4>
<p>The transaction acquires a shared lock when it wants to read a resource and keeps the locks to the end of the transaction. As we keep shared locks throughout the transaction, we ensure that all reads return the same data, since we are keeping other transactions from modifying the data until the transaction ends.&nbsp;</p>
<h4>Snapshot</h4>
<p><sub>* This is available in SQL Server.&nbsp;</sub></p>
<p>All the reads inside the transaction return the data as it was available at beginning of the transaction. It’s as if the transaction takes a snapshot of the data at the beginning and uses that throughout the transaction. It’s functionally similar to the Serializable level described below, but it makes use of a slightly different mechanism to achieve that.&nbsp;</p>
<h4>Serializable</h4>
<p>This is the highest isolation level available. The transaction acquires read locks for resources that need to be read and keeps them for the duration of the transaction, thus ensuring that data, once read, it stays the same for the duration of the transaction. It also acquires exclusive locks when updating the data and releases them at the end of the transaction. Additionally, the transaction places row range locks on of any rows matching conditions in the current transaction, so that we avoid phantom reads.&nbsp;</p>
<h3>Conclusion</h3>
<p>To summarize, every time you use a transaction in your code, you should take a moment and consider the appropriate isolation level that is needed. You can just put everything as serializable and call it a day, but in most cases, such a strong restriction is not needed and you would only be introducing unnecessary delays into your database. For most cases, a choice between Read Committed and Repeatable Reads would be enough. Keep this table in your mind as it should help you decide. Always use the most relaxed isolation level your app can afford.&nbsp;</p>
<figure><table><tbody><tr><td></td><td><strong>Dirty Reads</strong></td><td><strong>Non-Repeatable Reads</strong></td><td><strong>Phantom Reads</strong></td></tr><tr><td><strong>Read uncommitted</strong></td><td><span>Maybe</span></td><td><span>Maybe</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Read committed</strong></td><td><span>Never</span></td><td><span>Maybe</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Repeatable reads</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Maybe</span></td></tr><tr><td><strong>Snapshot</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Never</span></td></tr><tr><td><strong>Serializable</strong></td><td><span>Never</span></td><td><span>Never</span></td><td><span>Never</span></td></tr></tbody></table></figure>
<h3>Further reading</h3>
<ul><li><a href="https://lanraccoon.com/2020/http-rest-api-cheatsheet/">HTTP – REST API – Cheatsheet</a></li><li><a href="https://lanraccoon.com/2019/jack-of-all-trades-general-programmer/">Jack of all trades – a case for a general programmer</a></li><li><a href="https://lanraccoon.com/2018/async-programming-models-part-1/">Async programming models part I</a></li><li><a href="https://lanraccoon.com/2018/async-programming-part-ii/">Async programming models part II</a></li></ul>


</div></div>]]>
            </description>
            <link>https://lanraccoon.com/2020/learn-about-transaction-isolation-levels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740921</guid>
            <pubDate>Sun, 05 Jul 2020 18:48:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SemVer Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740913">thread link</a>) | @mikebike
<br/>
July 5, 2020 | https://jolynch.github.io/posts/semver_considered_harmful/ | <a href="https://web.archive.org/web/*/https://jolynch.github.io/posts/semver_considered_harmful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>In the past ten years or so, <a href="https://semver.org/">Semantic Versioning</a> a.k.a
“SemVer” has become extremely popular in the software development world. The
idea is that libraries and services can convey information to users about how
the application programming interface
(<a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a>) of
that library/package/service is evolving just using the version number. This
information is conveyed through three dotted numbers that form a logical clock
for totally ordering changes to the software API:</p>

<center><h3>Semantic Version Numbers</h3></center>
<div><pre><code data-lang="text">====================== Specification ========================

Version = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;

Major: this number goes up when the public API breaks
Minor: this number goes up when the public API changes
Patch: this number goes up when the public API doesn't change

====================== Examples =============================

# A Minor API change happened, safe to upgrade
1.4.5 -&gt; 1.5.0

# API breakage, probably unsafe to upgrade
1.7.0 -&gt; 2.0.0

# Who knows what will happen
0.182.13 -&gt; 0.182.14
=============================================================</code></pre></div>

<p>Armed with this information, software developers can theoretically upgrade
without fear of the new version breaking their code.</p>



<p>I believe that this versioning scheme, in practice, is problematic and creates
a large amount of pain in our industry. Three concrete failure modes I witness
frequently are:</p>

<ol>
<li>Most packaging systems (deb, rpm, python, ruby, java, etc …) cannot
simultaneously install multiple major versions of the same package name.
This often leaves users unable to upgrade to the latest major version due to
(reasonable) fear of breakages.</li>
<li>Frequent major version bumps frequently break functional code, leading
to <a href="https://en.wikipedia.org/wiki/Dependency_hell">dependency hell</a> where
library/service authors mix and match min, max, and exact version pins on
major versions to try to work around various incompatibilities. These pins
inevitably conflict.</li>
<li>There is still no standard way to derive the source code which produced the
artifact or seeing the difference between two versions. This makes it hard
to verify how the API is breaking or whether it will break specific usage
patterns.</li>
</ol>

<p>There is also the somewhat annoying issue of the plethora of <code>0.X</code> artifacts,
which happen because developers, somewhat reasonably, don’t want to release
a public API they will have to stand behind until they can be certain they
can.</p>

<p>Ultimately these factors lead to software developers, myself included, viewing
dependency upgrades with great trepidation. Quite reasonably developers defend
themselves from breakage by either not upgrading their dependencies (unless
they are forced to), vendoring dependent code, or skipping dependencies all
together and just writing it themselves.</p>

<h2 id="reduce-the-fear-breaking-versions-must-cohabitate">Reduce the Fear: Breaking Versions Must Cohabitate</h2>

<p>The use of the major version number in SemVer to indicate API breakage is by
far the most problematic aspect of the design. In an ideal world, packaging
systems and programming languages would automatically namespace different major
versions, and code that depends on a particular major version would have all
references specifically reference the major version namespace. Unfortunately,
we do not live in an ideal world and most packaging systems simply don’t
support this.  Three examples that I personally struggle with frequently:</p>

<p><strong>Debian packages (<code>apt</code>/<code>aptitude</code> in particular)</strong>: You only get one version
and the higher one is almost always chosen even if that may break less-than
pins. A common practice with debian packages to work around these limitations
is to release new packages with a different name.</p>

<p><strong>Java libraries (<code>mvn</code>/<code>gradle</code> in particular)</strong>: In a given class path you
can only have one implementation of a given package. Even if you manage to
convince gradle or maven to pull down multiple versions of a <code>.jar</code>, good luck
getting the JVM to not pick one implementation arbitrarily. As a result, Java
developers often resort to hacks like
<a href="https://imperceptiblethoughts.com/shadow/">package path rewriting</a>.</p>

<p><strong>Python libraries (<code>pip</code> in particular)</strong>: While the Python community has
moved towards isolated virtual environments which does make this issue slightly
less of an issue (and with tools like <code>docker</code> or
<a href="https://github.com/spotify/dh-virtualenv"><code>dhvirtualenv</code></a> it gets even
better), you still can’t install multiple versions of the same package in the
same virtualenv. Most Python projects I am aware of either don’t work around
this and break all the things, or release multiple package names.</p>

<p>These problems are even worse for client libraries, where the library is wrapping a
remote (often backwards incompatible) API change. For me this has been one of the
hardest parts of upgrading distributed datastores that I work on because we
often can’t use the vanilla client libraries during migration (e.g.
<a href="https://curator.apache.org/">Curator</a> 2 vs Curator 4, Elasticsearch 2 vs 5,
etc …). In my experience with most client library upgrades you have to create
an internal company fork that renames and relocates the package so we can run
both datastore APIs at the same time and have the client gracefully migrate
from the old version to the new one.</p>

<p>In an ideal world, remote APIs would remain backwards compatible for at least a
single major version to give users an upgrade path, but I find that many
developers argue that they don’t need to remain backwards compatible across a
major version (this is what SemVer says after all …). I wish this argument
was soundly rejected.</p>

<p>How can we fix this problem given the current constraints we operate under?
Well, we are left with a reasonably simple option: <strong>put the API version
semantics in the name of the package.</strong> Some example API migrations where I
have been able to take advantage of this technique are:</p>

<ul>
<li><code>boto</code> to <code>boto3</code> (Python,
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">docs</a>):
An extremely prevalent library for accessing AWS services</li>
<li><code>elasticsearch</code> to <code>elasticsearch2</code> (Python, <a href="https://github.com/elastic/elasticsearch-py/issues/515">motivation</a>): A Python client library for the
Elasticsearch search engine.</li>
<li>Every Linux kernel package ever (the Linux kernel has this figured out!). The
Kernel not only prohibits breaking user-space, but they give their users a
great way to install multiple kernels at the same time.</li>
<li>Cassandra’s Thrift API
(<a href="https://github.com/Netflix/Astyanax">Netflix Astyanax</a>)
to Cassandra’s CQL API
(<a href="https://github.com/datastax/java-driver">Datastax Java Driver</a>): The client
drivers for the Cassandra database.</li>
</ul>

<h2 id="reduce-the-fear-binary-versions-can-be-traced-to-source">Reduce the Fear: Binary Versions Can be Traced to Source</h2>

<p>In my experience, software engineers spend a non trivial amount of time trying
to figure out “what actually changed between these two released versions”. One
of the explicit goals of <code>SemVer</code> was to help developers reason about change.
As a developer myself I accidentally break things in minor versions all the
time, so I understand that this can happen. I don’t mind the breakage as much
as being unable to debug what broke, since projects use many different ways of
relating released versions to code.</p>

<p>Some projects do use <a href="https://git-scm.com/book/en/v2/Git-Basics-Tagging">git
tags</a> to achieve this
auditability, but this isn’t mandatory so some (many?) projects don’t do it.
The commit id may, in some cases, be a better identifier since the commit id
must exist and <code>git</code> has a really easy way to view <a href="https://git-scm.com/docs/git-diff">changes between two
commits</a>. In fact, as far as I know, the
commit id is always easily comparable in practically every source control
system.</p>

<p><a href="https://en.wikipedia.org/wiki/Changelog">Changelogs</a> are also <em>nice</em>, but
while I can typically assume projects use source control since it is strictly
easier than not using source control, I don’t think it is reasonable to expect
developers, often working for free, to take the time to summarize their
software changes into English changelogs. Writing clear and actionable English
is difficult, potentially more difficult than the code itself. Certainly, I
appreciate every project maintainer who takes the time to summarize changes in
a release, but I don’t think it’s fair to <em>expect</em> it in the same way most
consumers of software expect producers to use source control.</p>



<p>Both of these problems can be remedied with a straightforward evolution to
<code>SemVer</code> in which we make some small changes to include a great deal more
semantic information in the package name and version number. I call it
semantic package names and it consists of two changes:</p>

<ol>
<li>Use package (=module) names to indicate an API has broken, not versions.</li>
<li>Attempt to include a source identifier in the version.</li>
</ol>

<p>For example, <code>elasicsearch5</code> is the python library that functions with the
Elasticsearch server version 5.  Applications such as Elasticsearch or
Cassandra release named packages that unambiguously communicate the major
version API that is supported by that package. One possible example for Apache
Cassandra might be <code>cassandra-21x</code>, <code>cassandra-30x</code>, <code>cassandra-311x</code>, and
<code>cassandra-40x</code> for the <code>2.1</code>, <code>3.0</code>, <code>3.11</code>, <code>4.0</code> branches respectively.</p>

<p>I know this is not new, many software projects already follow this kind of scheme
such as the Linux kernel (a.k.a “Never break userspace”) or the Go
<a href="https://golang.org/cmd/go/#hdr-Module_compatibility_and_semantic_versioning">programming language</a>.
I just believe that if every software project and language I interacted with
followed this pattern the whole industry would become more efficient and spend
less time fearing dependency updates. I have also found myself using this
technique internally to every company I’ve worked at to manage software change.</p>

<p>In addition to using semantic package names, I prefer when packages include a
fourth piece of metadata in their version number indicating the source version
that produced the artifact. Depending on the packaging system this is usually
either another dotted version (making it a four-tuple) or a <code>-</code> suffix.</p>

<center><h3> Better Semantic Versioning </h3></center>

<div><pre><code data-lang="text">====================== Specification ========================
&lt;Package Version&gt; = &lt;Package Name&gt;:&lt;Version Number&gt;
&lt;Version Number&gt;  = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;&lt;Identifier&gt;

Package Name: This name changes when the public API breaks
Major: this number goes up with "major" public API additions
Minor: this number goes up with "minor" public API additions
Patch: this number goes up on every release
Identifier: For packaging systems that support it, this
            string relates directly to a specific source
            code that produced the artifact.

An example of an identifier in git would be the first 8</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jolynch.github.io/posts/semver_considered_harmful/">https://jolynch.github.io/posts/semver_considered_harmful/</a></em></p>]]>
            </description>
            <link>https://jolynch.github.io/posts/semver_considered_harmful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740913</guid>
            <pubDate>Sun, 05 Jul 2020 18:47:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to start a company without losing all your favorite stuff]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740752">thread link</a>) | @RobbieStats
<br/>
July 5, 2020 | https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html | <a href="https://web.archive.org/web/*/https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <div>
  <div>
    <div>
      <div>
        <p>
          <span>June 24, 2020</span>
          /
          <span>
            by Andrew Fisher
          </span>
        </p>
        <h3><a href="https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">How to start a company...without maybe losing all your favorite stuff</a></h3>
        <p><em>The TL;DR (“too long, didn’t read”) version: Corporations and LLCs are the best choice for almost all new businesses, and Startomatic can get yours formed with no guesswork and no headaches.</em></p>

<p><strong>Most founders</strong> have some idea of the variety of legal forms that they have to choose from when creating their new company. Who hasn’t heard of a corporation or a limited liability company (LLC)?</p>
<p>Only slightly less recognizable are entities like general partnerships (GPs), limited partnerships (LP’s) , sole proprietorships, and non-profit corporations.</p>
<p>And what about those more “exotic” choices - professional corporations (PCs), professional limited liability companies (PLLCs), and even <em>limited liability limited partnerships</em> (LLLPs) (holy cow)??</p>
<p>As if that’s not enough, where do “C-corporations” and “S-corporations” fit into all of this? Well… they don’t, really. But more on that later…&nbsp;</p>
<p>So any business founder has the right to be confused about choosing an entity type, and it’s no wonder so many feel the safe option is to seek out a business lawyer for solid advice. At Startomatic, we agree that lawyers can be <em>extremely </em>helpful in setting up many types of businesses with large or complex ownership bases, or those that are going to take in professional investment money (think venture capital investments in preferred stock) right after forming.&nbsp;</p>
<p>But <strong>for companies with just a few owners</strong> (somewhere south of 6-8) and a straightforward initial capital structure (all owners get the same type of equity), the best advice is <strong>KISS - Keep It Simple, Startups</strong>.&nbsp;</p>
<p><strong>THE AWESOMENESS OF LIMITED LIABILITY&nbsp;</strong></p>
<p>Your first question might be “why do I need an entity at all (and what the heck is an ‘entity’ anyway)?”&nbsp;</p>
<p><em>Entity </em>is the catch-all term lawyers use to describe corporations, LLCs, and all of the other types of legal business forms described above.&nbsp;&nbsp;</p>
<p>And the best reason for running your business as an entity? It’s because you probably like your car, and your house, and your priceless collection of Pink Floyd on vinyl. If you run your business as an entity, all of those items of personal property are off limits if your new business fails and owes your creditors (landlord, material suppliers, contractors) money. Without an entity between you and your business’s creditors, those creditors can sue you personally and take your records AND your record player.&nbsp;</p>
<p>But if your company is a corporation, LLC or other entity with the legal protection of <strong>limited liability</strong>, those creditors can only go after the assets of the company (in most cases). Your classic Camaro is safe.</p>
<p>Using an entity to run your company has some other benefits as well - it can be easier to get business banking services, buy (or be bought by) another company, and enter into contacts. But the number one reason is the beauty and safety of<em> limited liability</em>.&nbsp;</p>
<p><strong>CORPORATIONS - THE GRANDDADDY OF BUSINESS ENTITIES&nbsp;</strong></p>
<p>Cast your mind way back, so far back that avocado toast wasn’t even a thing yet, and you’ll get to the 1790s. That’s when corporations took off in the U.S., and there’s a reason they’re still the dominant business form for most companies, particularly large ones: <em>there’s no mystery about how corporations work</em>.&nbsp;</p>
<p>Every corporation is owned by its <em>shareholders </em>(or stockholders; the terms are interchangeable), managed by one or more <em>directors </em>(the “Board of Directors” or sometimes just the “Board”), and operated by its <em>officers </em>(President, Secretary, etc.)&nbsp;</p>
<p>For this reason, professional investors (think: venture capitalists) tend to prefer investing in corporations. It’s also possible to grant employees stock options (the ability to buy stock in the corporation in the future) to encourage them to do their best work and to stick around. Stock options just don’t work well in LLCs, for a number of reasons that are WAY too boring to go into here.&nbsp;</p>
<p>On the flip side, the well-defined structure of a corporation makes them less flexible and means there are more corporate “housekeeping” matters to occupy your precious business time and attention. And as always, taxes come into play: a corporation’s earnings may be taxed twice (yikes!), once at the corporation level, and again when earnings are distributed to the shareholders. (But see the discussion on S-corporations, below.)&nbsp;</p>
<p>Here’s the skinny on corporations:</p>
<p><strong>PROS of a Corporation:</strong></p>
<ul><li>Limited liability</li><li>Professional investors generally prefer corporations&nbsp;</li><li>Easy to issue equity incentives (stock or stock options) to employees and others</li></ul>
<p><strong>CONS of a Corporation:&nbsp;</strong></p>
<ul><li>Double taxation (without an S-election; see below)&nbsp;</li><li>Limited flexibility in management&nbsp;</li><li>Generally more complex to manage than an LLC&nbsp;</li></ul>
<p><strong>LLCS - THE CORPORATION’S YOUNGER, WILDER SIBLING&nbsp;</strong></p>
<p>Corporations were almost 200 years old when the limited liability company came onto the business scene in the 1990’s. LLCs are basically state-approved contracts creating companies with the key benefit of limited liability (hence their creative naming) but much more flexibility in management and ownership structure than corporations.&nbsp;</p>
<p>LLCs are owned by their <em>members </em>and are managed either directly by those members or by <em>managers</em>. If compared to corporations, members are similar to shareholders, and managers are like a combination of directors and officers.&nbsp;</p>
<p>The LLC’s major difference from corporations is that the contract governing the LLC (usually called an Operating Agreement or an LLC Agreement) can say pretty much whatever the owners want it to say. So the financial terms of investment, tax allocations, and cash distributions, as well as who makes the management decisions in the company, can be anything the members (owners) agree to.</p>
<p>Perhaps most beneficially, LLCs are usually subject to <strong>pass-through taxation </strong>by the IRS, which means the company’s profits (and losses) are “passed through” directly to the owners - avoiding the corporation’s double taxation issue described above. This is the same way partnerships are taxed.&nbsp;</p>
<p>While the LLC’s flexibility is appealing to some, it has the drawbacks of being unattractive to many investors, and making it so awkward to issue incentive compensation (stock options) that it’s generally not even worth trying.</p>
<p><strong>PROS of an LLC:</strong></p>
<ul><li>Limited liability, just like a corporation&nbsp;</li><li>Single level of taxation usually means tax savings&nbsp;</li><li>Flexibility in financial and management means the owners can decide exactly how they want the business to run&nbsp;</li><li>Fewer time-sucking administrative requirements than corporations</li></ul>
<p><strong>CONS of an LLC:&nbsp;</strong></p>
<ul><li>Professional investors generally prefer corporations&nbsp;</li><li>Nearly impossible to issue equity incentives to employees and others&nbsp;</li></ul>
<p><strong>TAXES ALWAYS COMPLICATE THINGS: THE S-ELECTION&nbsp;</strong></p>
<p>The<em> double taxation</em> problem of corporations does have a solution - but it’s one that comes with significant limitations (of course, darn that IRS…)&nbsp;</p>
<p>An<em> S-corporation</em> isn’t actually a <em>type </em>of corporation at all; it’s just a description of a corporation that has elected with the IRS to be taxed like a partnership. By making this election, the corporation doesn’t pay taxes on its income; instead, the shareholders report and pay taxes on the company’s earnings (and can take the losses) directly on their own tax returns. This is “pass-through” taxation, just like the default taxation of an LLC.&nbsp;</p>
<p>So what are the limits on an S-corporation? They’re pretty significant. An S-corporation:&nbsp;</p>
<ul><li>Can have no more than 100 shareholders&nbsp;</li><li>Can have only one class of stock (so no preferred stock, which is what outside investors usually want)&nbsp;</li><li>Can only have shareholders who are individuals (so no companies can be shareholders, again meaning many investors are shut out)&nbsp;</li><li>All shareholders must be U.S. citizens or lawful permanent residents&nbsp;</li></ul>
<p><em>OK, but then what’s a C-corporation?</em> Easy. It’s just a corporation that has not made an S-election.&nbsp;</p>
<p><strong>Should your <u>corporation </u>make an S-election?&nbsp;</strong></p>
<p><em>Probably yes</em>, if BOTH of the following are true: (a) you meet all of the basic requirements described in the section above, and (b) you don’t intend to raise funds from outside investors in the near term. Keep in mind that you can always change from an S-corporation to a C-corporation in the future - you just have to make a filing with the IRS (and of course there are a few <a href="https://www.irs.gov/forms-pubs/revoking-a-subchapter-s-election" target="_blank">restrictions</a>).&nbsp;</p>
<p><strong>Should your <u>LLC </u>make an S-election?&nbsp;</strong></p>
<p><em>Wait, so an LLC can make an s-election, and choose to be taxed like an S-corporation??</em> We hear you, this is confusing. For now, suffice it to say that there are some very specific circumstances in which an LLC might choose S-corporation taxation - and Startomatic supports that option - but generally speaking LLCs are better off without an S-election. We’ll blog more about this soon and link to it here when we do.</p>
<p><strong>HOW TO CHOOSE: CORPORATION OR LLC&nbsp;</strong></p>
<p>If you’re still unsure, take a look again at the lists of pros and cons above under the corporation and LLC sections. If you meet criteria for either entity and see benefits in each, in our experience the LLC offers more flexibility with less administrative headaches than a corporation, plus the automatic benefit of pass-through taxation, so it’s generally the right choice for new small businesses.&nbsp;&nbsp;</p>
<p><strong>SOLE PROPRIETORSHIPS ARE EASY… AND RISKY&nbsp;</strong></p>
<p>A quick note about <em>sole proprietorships</em>, which you may have heard of. A sole proprietorship is just running your business without an entity. It’s easy, fast, and usually free, but it’s missing the key benefit of limited liability (your classic Camaro isn’t safe any more), and for this reason it’s usually not a good choice.&nbsp;</p>
<p>That said, there are few businesses where the risk is so low that using a sole proprietorship may be a reasonable choice in order to save on filing fees and administrative work of setting up and operating an entity. For that reason, Startomatic will begin offering sole proprietorships in the near future - stay tuned.&nbsp;</p>
<p><strong>S…</strong></p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html">https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html</a></em></p>]]>
            </description>
            <link>https://startomatic.com/blog/2020/06/24/how-to-start-a-company-without-maybe-losing-all-your-favorite-stuff-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740752</guid>
            <pubDate>Sun, 05 Jul 2020 18:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Lambda Abuse]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740734">thread link</a>) | @luminousmen
<br/>
July 5, 2020 | https://luminousmen.com/post/aws-lambda-abuse | <a href="https://web.archive.org/web/*/https://luminousmen.com/post/aws-lambda-abuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>I have already written quite a lot about the <a href="https://luminousmen.com/post/how-to-start-your-blog-for-20-cents">serverless approach</a>, the AWS Lambda service in particular, and how I use it for my own personal purposes. In this post, we will walk once again through how AWS Lambda set up and running. We will talk about strategies to mitigate the impact of DDoS attacks (the days of DoS are long gone) and create fail-safe serverless applications. There is very little information on this topic, although it is quite important and most common when discussing AWS security.</p>
<p>P.S. Unfortunately, this post has not been sponsored.</p>
<hr>
<p>Briefly about AWS Lambda. AWS Lambda is an AWS computing service that allows us to run simple functions as FaaS in the cloud. AWS Lambda performs all administration for us, including server and operating system maintenance, resource allocation, automatic scaling, monitoring, and logging. All you have to do is provide code in one of the languages that AWS Lambda supports.</p>
<p>Advantages of using the AWS Lambda:</p>
<ul>
<li><strong>Cost-effective</strong>. You only pay when the service is running(but some services cost a lot).</li>
<li><strong>No ops</strong>. You do not need to manage anything yourself. AWS takes care of the operating system, deployment, scaling, and so on.</li>
<li><strong>Speed</strong>. The lambda itself goes up and runs very fast(but there are overhead on spinning up the runtime).</li>
<li><strong>Scalability</strong>. Functions can be run in parallel with limit depending on the region, from 1000 to 3000 copies maximum. And if you want, this limit can be increased.</li>
</ul>
<p>The work of AWS Lambda is quite simple and clear. The first time a function is called, an instance of a custom function is created, the runtime is created which passes on queries and answers between AWS Lambda and the function code. The function handler is started to handle the event. The source of the event(called trigger) can be a wide variety of things inside the AWS, the most popular triggers for the web I would call AWS CloudFront, AWS API Gateway, and AWS SQS. When the function has processed an event it returns a response and remains active — it waits for the next events to be passed. As more events arrive, the internal AWS Lambda schedulers direct them to the warm(already running) instances if there is one and create new instances as needed. When the number of requests decreases, AWS Lambda stops unused instances to free up the resources for other functions.</p>
<p>The number of instances of functions that serve requests at a given time is called <em>concurrency</em>. And this is essentially horizontal scalability inside the AWS Lambda. When requests arrive faster than your function can scale, or when your function is on the maximum concurrent level, the additional requests fail with the 429 status (too many requests).</p>
<p>In terms of security, each function of AWS Lambda works in its own isolated environment, with its own resources and file system. It stores code on an Amazon S3 and encrypts it at rest.</p>
<p>When you deploy an endpoint that is open to the world, you open it not only for use but also for abuse.</p>
<h2>DDoS 101</h2>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse/aws-lambda-abuse-2.JPG" alt="DDoS"></p>
<p>Imagine someone who wants to disrupt the bus system. Thousands of people get on the bus at the beginning of the route and ride aimlessly through the city from end to end without leaving at the stops. The transport keeps going, but in fact, the traffic is paralyzed. People are standing at intermediate stops and are sadly watching the crowded buses without being able to push through. People are unable to get home, and the bus company is suffering losses due to low passenger traffic.</p>
<p>This is easy to apply for web applications — basically, an attacker is trying to overload some component of the system to bring it to some critical point after which there will be a system failure, it can be a communication channel, a queue of requests or just an overload of the system handler.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse/aws-lambda-abuse-3.JPG" alt="DNS DDoS"></p>
<p>Probably the most popular DDoS attack because of its cheapness and difficulty to block it is DNS (Domain Name Server) DDoS. In the DNS DDoS, the attacker tries to overwhelm the capacity of the target's DNS name servers in an attempt to prevent the name server query resolution. Blocking DNS makes the target application or website unavailable to users even if the rest of the infrastructure is running normally. Going back to the bus system analogy, imagine that the buses are running on schedule, they are empty and everything seems fine, but the bus doors just don't open — people just can't get in.</p>
<p>In AWS it is a bit more complicated because, as it has already been said, both management and scaling take place on the AWS side, and therefore control.</p>
<h2>AWS Lambda at scale</h2>
<p>AWS provides services and mechanisms to avoid common abuse methods but often, as with typical DDoS attacks, it doesn't know what traffic is and isn't abusive.</p>
<p>AWS itself is incredibly huge and has many regions, availability zones, and edge locations, which allows to eliminate bad traffic to some extent and absorbs the rest. But it is not enough just to use the lambda function thinking that AWS will do everything for you automatically. You can of course, but in the end, you can get either a broken service or a huge bill or all at once. AWS imposes limits on the number of concurrent handlers, you have to think about where the traffic is coming from, how DNS resolves, and if you use any external AWS services it sometimes makes sense to migrate them all inside AWS for more complete control. Services such as AWS Route53 and AWS CloudFront which allow you to take advantage of the variety of internal AWS infrastructure — which itself is built quite interestingly.</p>
<p><img src="https://iamluminousmen-media.s3.amazonaws.com/media/aws-lambda-abuse-1.JPG" alt="AWS"></p>
<p>I tried to illustrate an example of incoming traffic to lambda service located in one region. As you can see, there are many steps before you get to the lambda itself. It all starts with a DNS resolution of a record on one of the name servers in AWS Route53(this is the service that is responsible for name resolution and stuff) that is intentionally hosted on the edge locations so that clients from different networks and locations have their own quick way to the service while having more than one path in case of localized outages. Also, there is AWS CloudFront (you can use Lambda@Edge option in lambda) on the edge locations — it is a content delivery network for delivery of all static and dynamic content, which allows users not to go directly to the function if it is not necessary. So Route 53 can assign different users to the closest AWS CloudFront instances (which can already be in the same edge location) which can already have the necessary content. Sounds great, right?</p>
<p>An example of how it works step by step:</p>
<ul>
<li>When the request is sent by the user, the DNS resolves at the user's closest edge location where AWS Route 53 is located.</li>
<li>Route 53 forwards the request to the nearest edge location where AWS CloudFront is located.</li>
<li>Then, there can be two possibilities i.e. whether files requested are in cache or not. If files are in the cache then CloudFront returns them.</li>
<li>CloudFront compares the specifications in your distribution with the request. Then trigger the AWS Lambda function with the user request.</li>
<li>The origin server sends the requested files to the CloudFront edge location.</li>
<li>When the first byte of the requested files arrives, CloudFront starts sending the files to the user.</li>
<li>It also saves the files to the internal cache of CloudFront(for specified TTL) so they could be accessed easily in the future if the same or another user requests them.</li>
</ul>
<p>You can of course use the API Gateway in an edge-optimized mode in front of your API for about the same purposes (caching and function trigger). However, this is likely to be more expensive, the API Gateway charges for the size of the cache per hour, CloudFront charges per request, and data transfer. But of course, everything depends on the specific architecture, purpose and workload.</p>
<p>The API Gateway is essentially a proxy server that the user is accessing, and this proxy server is calling the lambda. Typically, the API Gateway can also do SSL certificate processing, load balancing, authorization and authentication, caching, request content compression. But it's not that effective under abuse as CloudFront.</p>
<h2>How to mitigate the impact</h2>
<p>As always, this requires a multi-level approach and everything depends very much on the specific architecture, the workflow, and of course the budget.</p>
<h3>Check your code</h3>
<p>Let's start with the dumbest and traditionally most effective method. Make sure your code does not "hang" on unexpected input. You should carefully check all edge cases and think about possible inputs that may cause function timeouts, <a href="https://en.wikipedia.org/wiki/ReDoS">ReDoS attacks</a>, or long payloads. An attacker may take advantage of this weakness.</p>
<h3>Configure alerts</h3>
<p>Another incredibly brilliant idea if you don't want to get a huge bill at some point — set up the billing alerts. It's very easy and fast to set up (it's better to do it through AWS Budgets than through AWS SNS and AWS Cloudwatch), but it's very useful — you will be informed in case of a problem.</p>
<p>Also, I would advise making limits on billing. Of course, everything depends on the specific business task of the service and maybe it's better to overpay, but have a working endpoint.</p>
<h3>Use throttling(reserved concurrency)</h3>
<p>We have already found out that the AWS Lambda provides multiple instances running concurrently to scale functions, but if you have several Lambda functions running at the same time and one of them is under abuse, the resources of other functions may be exhausted because of it. The AWS Lambda has a default limit on the number of concurrent executions per account per region. And if your functions exceed this limit, additional user requests will be throttled by AWS with 429 status as it was described earlier.</p>
<p>But the concurrency level can be set on per-function bases. Besides AWS Lambda, the API Gateway supports throttling as well. The defaults are reasonable, but you can alter them however you like. For example, you can allow 5 calls per second if it makes sense for your application, after which the API Gateway will block additional …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://luminousmen.com/post/aws-lambda-abuse">https://luminousmen.com/post/aws-lambda-abuse</a></em></p>]]>
            </description>
            <link>https://luminousmen.com/post/aws-lambda-abuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740734</guid>
            <pubDate>Sun, 05 Jul 2020 18:23:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Persuasion]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23740669">thread link</a>) | @apsec112
<br/>
July 5, 2020 | https://www.persuasion.community/p/the-purpose-of-persuasion | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/the-purpose-of-persuasion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6649732,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Friends,</p><p>I'm floored by the response of the past three days.</p><p>Once I hit <em>send</em>, this article will land in the inboxes of over 15,000 people. When we launched, my main fear was that the world would not be interested in a community that pledges to defend the values of a free society; now, my main fear is that we won't be able to live up to the hype.</p><p>So, here's my promise: We will do our very best to earn your trust. Some great articles will be coming your way soon. We are getting ready to announce more events and high-level members of the community. I hope you will join us for our inaugural townhall, which will take place next Sunday, July 12th, at 4pm EST. (Watch this space for the invite.) I'm very, very excited about what lies ahead. But I also know that it is hard to build this kind of community from the ground up, and that we will undoubtedly make mistakes along the way. Please bear with us when we do.</p><p>In the meanwhile, I want to take you a little deeper into the thinking that went into creating <em>Persuasion</em>. Why this project? Why now? And how can just a bunch of us—even if we are a much larger bunch than I could possibly have dreamed a few days ago—really make a difference to the future of free societies in the United States and around the world? The key to an answer lies in a short (and necessarily schematic) history of American intellectual life over the past half century. </p><p>Fifty years ago, the most important American institutions enjoyed a degree of legitimacy that is now hard to fathom. Nearly every American watched the news on one of the three network television stations. Nearly every American had a positive opinion of Princeton and Stanford. Nearly every Member of Congress believed that the advice of the Brookings Institution or the Council on Foreign Relations was to be taken seriously.&nbsp;</p><p>These institutions had much to recommend them: They gave the public a shared set of facts and assumptions, which could form the basis of political debate. And, though they never thought of their primary goal as fighting for the ideals of a free society, their operating system was philosophically liberal: From CBS to Harvard to Brookings, senior decision makers instinctively believed in values like free speech and due process.</p><p>However, these institutions also suffered from two important shortcomings. First, the people they admitted into their gilded halls only represented a small slice of America's population: sexism, racism and homophobia were <em>far</em> more prevalent in these institutions than they are today. The views they considered serious sometimes included the morally abhorrent.&nbsp;</p><p>Second, the realm of the “reasonable" was rather narrow. And, though this narrowness of debate constituted the lesser injustice, it was—at least in the short term—the cause of greater instability: Having come to believe that they could never quite speak in their own voices in the halls of the Brookings Institution or the column inches of the <em>New York Times</em>, a few assorted bands of malcontents started to cast around for an alternative. </p><p>Of these, the group that had the biggest impact on public life in America was a band of devoted conservatives, determined to create an ideological counter-establishment that could rival the mainstream.&nbsp;What started with <em>National Review</em>, an ideological fighting magazine, quickly grew into a sprawling and immensely powerful network of conservative institutions. The Heritage Foundation was set up to rival the influence of Brookings. The Federalist Society sought to change the ideological composition of America's judiciary. Fox News did its dismal best to spread the ideas of the conservative movement beyond the Beltway. A whole network of activist groups provided conservatives with an ideological foundation, a group of friends, and a professional home. Measured by its own ambitions,&nbsp;the movement was a staggering success.</p><p>Other minoritarian ideological movements took a page out of the same playbook. In 1960, a libertarian was a person with idiosyncratic views and no obvious political home. Then, the Institute for Humane Studies started to advocate libertarian ideas on college campuses, <em>Reason </em>took up their public defense, and a reinvigorated American Enterprise Institute set out to influence legislators on Capitol Hill. By 1980, the influence and intellectual self-confidence of libertarians had increased enormously.</p><p>The further left has always had its share of counter-establishment institutions. <em>The Nation</em>, after all, is one of the oldest magazines in the country, and some academic disciplines have long been at the forefront of leftist thought. But the left, too, has of late succeeded in building a more cohesive network of fighting institutions, as universities have become much more progressive, movements like the Democratic Socialists of America have awakened from decades of peaceful slumber, and publications like <em>Jacobin </em>have infused the movement with fresh intellectual energy.</p><p>Five or ten years ago, our potted history might have concluded here. Ideological movements from conservative to libertarian to leftist had fighting institutions of their own. Though philosophical liberals did not have a comparable home, they could confidently express their views within mainstream institutions.&nbsp;</p><p>But then those institutions started to change.</p><p>The story of that change has attracted an immense amount of attention over the past months. I won't bore you with a detailed recap of its most worrying manifestations, from the firing of James Bennet to the uncritical celebration of Robin DiAngelo. Nor do I want to suggest that these changes have completely delegitimized the mainstream: These institutions have not yet become wholly illiberal, and the advocates of a free society would be foolish to stop fighting for them.</p><p>But the erosion of values like free speech and due process within mainstream institutions does put philosophical liberals at a unique disadvantage. It is difficult to convey just how many amazing writers, journalists, and think-tankers—some young and some old, some relatively obscure and others very famous—have privately told me that they can no longer write in their own voices; that they are counting the days until they get fired; and that they don't know where to turn if they do. (Astonishingly, a number of them are far enough to the left to have supported Bernie Sanders in the primaries.)</p><p>This, to me, is a huge part of the reason why the defenders of the free society have seemed to lack conviction in recent months and years. Feeling, at best, begrudgingly tolerated by the institutions that employ them, they are always on the back foot: writing and speaking with one eye on Twitter, one eye on a hostile editor, and one eye on the attacks being shared on their own company’s Slack channel. (As you may have noticed, that requires too many eyes.)</p><p>But, if this situation helps to explain the collective lack of confidence among the advocates of a free society, it also points the way to an obvious solution. <strong>Instead of lamenting our loss of control over the establishment, we should follow the lead of other movements that have successfully built their own counter-establishment institutions.</strong><em>&nbsp;</em></p><p><em>That </em>is the goal I had in mind in starting <em>Persuasion</em>.</p><p>One core element of this project is a publishing platform explicitly devoted to debating, articulating, and defending the values of a free society. Emulating what <em>Reason</em>, <em>Jacobin,</em> and the <em>National Review</em> have accomplished within their own ideological traditions, I hope to create a space in which philosophical liberals can ask hard questions and come up with compelling answers. This requires both a commitment to a set of shared aspirations and enough diversity of opinion to force us to think very hard about how we can make the world a better place. This is a space for people who are open to changing their minds, but not their fundamental values.</p><p>But creating a modern reinvention of a fighting magazine, devoted to defending the ideals of a free society, is not my only ambition. If places like the <em>National Review</em> had a tremendous influence on our society, it is also because they became the nucleus of a cohesive community, which seeded a much wider archipelago of allied institutions. This is why I take the community element of <em>Persuasion</em>—all the live events, book clubs and social gatherings we'll experiment with over the coming months—so seriously. And it is also why I hope that this particular venture will spawn many formally independent organizations that share our founding values.</p><p>Before I close, let me say two quick words about some of the establishment institutions whose recent fate I have been lamenting. The first is that we must do what we can to preserve those universities, publications, and think tanks that still operate with fundamentally (small l) liberal assumptions. For example, I deeply love <em>The Atlantic</em>, and will continue to write for it. A small fighting institution that primarily addresses a devoted crowd of philosophical liberals neither is nor should be in competition with a large general interest magazine whose readership will always span a much broader ideological range. Part of the reason why we should articulate these values as clearly, forcefully, and persuasively as possible within these pages is to maximize the likelihood that they will continue to form the implicit operating system of vitally important publications like <em>The Atlantic</em>.&nbsp;</p><p>The second thing is that our ambition needs to extend beyond nostalgia. There is much to lament about the changes that have taken place in some of the country's most important institutions over the past years. But there is also much to criticize in what these institutions looked like at their supposed best. Our goal is not to return to a golden age that has, sadly, never existed; it is to build societies that live up to the noble and ambitious values of freedom and justice better than any society of the past.</p><p>The examples I have used here&nbsp;are very …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/the-purpose-of-persuasion">https://www.persuasion.community/p/the-purpose-of-persuasion</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/the-purpose-of-persuasion</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740669</guid>
            <pubDate>Sun, 05 Jul 2020 18:16:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Introduction to JIT Compilers: JITs are not very Just-in-time]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 93 (<a href="https://news.ycombinator.com/item?id=23740655">thread link</a>) | @chrisseaton
<br/>
July 5, 2020 | https://carolchen.me/blog/jits-intro/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/jits-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p><em>If you are familiar with how JITs generally work (if you get what the title is referring to), I recommend skimming this or going straight to reading <a href="https://carolchen.me/blog/jits-impls">How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More</a></em> </p>
<p>My mentor, <a href="https://chrisseaton.com/">Chris</a>, who took me from “what is a JIT” to where I am now once told me that compilers were just bytes in bytes out and not at all low-level and scary. This is actually fairly true, and it's fun to learn about compiler internals and often useful for programmers everywhere!</p>
<p>This blog post gives background on how programming languages are implemented and how JITs work. It'll introduce the implementation details of the Julia language, though it won't talk about specific implementation details or optimizations made by more traditional JITs. Check out <a href="https://carolchen.me/blog/jits-impls">How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More</a> to read about how meta-tracing is implemented, how Graal supports C extensions, the relationship of JITs with LLVM and more!</p>
<h2 id="how-programming-languages-are-implemented">How Programming Languages are Implemented<a href="#how-programming-languages-are-implemented" aria-label="Anchor link for: how-programming-languages-are-implemented"> <i></i></a>
</h2>
<p>When we run a program, it’s either interpreted or compiled in some way. The compiler/interpreter is sometimes referred to as the "implementation" of a language, and one language can have many implementations. You may have heard things like "Python is interpreted", but that really means the reference(standard/default) implementation of Python is an interpreter. Python is a language specification and <em>CPython</em> is the interpreter and implementation of Python. </p>
<p>An interpreter is a program that directly executes your code. Well-known interpreters are usually written in C. Ruby, Python and PHP are written in C. Below is a function that loosely models how an interpreter might work:</p>
<pre><code><span>func </span><span>interpret</span><span>(</span><span>code </span><span>string</span><span>) {
  </span><span>if </span><span>code </span><span>== </span><span>"print('Hello, World!')" </span><span>{
    </span><span>print</span><span>(</span><span>"Hello, World"</span><span>);
  } </span><span>else if </span><span>code </span><span>==</span><span> “</span><span>x </span><span>= </span><span>0</span><span>; </span><span>x </span><span>+= </span><span>4</span><span>; </span><span>print</span><span>(</span><span>x</span><span>)” {
    variable_x </span><span>:= </span><span>0 
    </span><span>variable_x </span><span>+= </span><span>4
    </span><span>print</span><span>(</span><span>x</span><span>)
  }
}
</span></code></pre>
<p>A compiler is a program that translates code from some language to another language, though it usually refers to a destination language that is a machine code. Examples of compiled languages are C, Go and Rust.</p>
<pre><code><span>func </span><span>compile</span><span>(</span><span>code </span><span>string</span><span>) {
  []</span><span>byte </span><span>compiled_code </span><span>= </span><span>get_machine_code</span><span>(</span><span>code</span><span>);
  </span><span>write_to_executable</span><span>(</span><span>compiled_code</span><span>);
}
</span></code></pre>
<p>The difference between a compiled and interpreted language is actually much more nuanced. C, Go and Rust are clearly compiled, as they output a machine code file - which can be understood natively by the computer. The compile and run steps are fully distinct.</p>
<p>However, compilers can translate to any target language (this is sometimes called transpiling). Java for example, has a two-step implementation. The first is compiling Java source to bytecode, which is an Intermediate Representation (IR). The bytecode is then JIT compiled - which involves interpretation.</p>
<p>Python and Ruby also execute in two steps. Despite being known as interpreted languages, their reference implementations actually compile the source down to a bytecode. You may have seen .pyc files (not anymore in Python3) which contain Python bytecode! The bytecode is then interpreted by a virtual machine. These interpreters use bytecode because programmers tend to care less about compile time, and creating a bytecode language allows the engineers to specify a bytecode that is as efficient to interpret as possible. </p>
<p>Having bytecode is how languages check syntax before execution (though they could technically just do a pass before starting the interpreter). An example below shows why you would want to check syntax before runtime.</p>
<pre><code><span>sleep</span><span>(</span><span>1000</span><span>)
bad syntax beep boop beep boop
</span></code></pre>
<p>Another important note is that interpreted languages are typically slower for various reasons, the most obvious being that they're executed in a higher level language that has overhead execution time. The main reason is that the dynamic-ness of the languages they tend to implement means that they need many extra instructions to decide what to do next and how to route data. People still choose to build interpreters over compilers because they're easier to build and are more suited to handle things like dynamic typing, scopes etc (though you could build a compiler that has the same features). </p>
<h3 id="so-what-is-a-jit">So What is a JIT?<a href="#so-what-is-a-jit" aria-label="Anchor link for: so-what-is-a-jit"> <i></i></a>
</h3>
<p>A JIT compiler doesn't compile code Ahead-Of-Time (AOT), but still compiles source code to machine code and therefore is not an interpreter. JITs compile code at runtime, while your program is executing. This gives the JITs flexibility for dynamic language features, while maintaining speed from optimized machine code output. JIT-compiling C would make it slower as we'd just be adding the compilation time to the execution time. JIT-compiling Python would be fast, as compilation + executing machine code can often be faster than interpreting, especially since the JIT has no need to write to a file (disk writing is expensive, memory/RAM/register writing is fast). JITs also improve in speed by being able to optimize on information that is only available at runtime.</p>
<h3 id="julia-a-jit-compiler-that-s-just-in-time">Julia: a JIT Compiler that's Just-in-time<a href="#julia-a-jit-compiler-that-s-just-in-time" aria-label="Anchor link for: julia-a-jit-compiler-that-s-just-in-time"> <i></i></a>
</h3>
<p>A common theme between compiled languages is that they're statically typed. That means when the programmer creates or uses a value, they’re telling the computer what type it is and that information is guaranteed at compile time.</p>
<p>Julia is dynamically typed, but internally Julia is much closer to being statically typed.</p>
<pre><code><span>function </span><span>multiply</span><span>(x, y)
  x </span><span>*</span><span> y
</span><span>end
</span></code></pre>
<p>Here is an example of a Julia function, which could be used to multiply integers, floats, vectors, strings etc (Julia allows operator overloading). Compiling out the machine code for <em>all</em> these cases is not very productive for a variety of reasons, which is what we'd have to do if we wanted Julia to be a compiled language. Idiomatic programming means that the function will probably only be used by a few combinations of types and we don't want to compile something that we don't use yet since that's not very jitty (this is not a real term).</p>
<p>If I were to code <code>multiply(1, 2)</code>, then Julia will compile a function that multiplies integers. If I then wrote <code>multiply(2, 3)</code>, then the already-compiled code will be used. If I then added <code>multiply(1.4, 4)</code>, another version of the function will be compiled. We can observe what the compilation does with <code>@code_llvm multiply(1, 1)</code>, which generates LLVM Bitcode (not quite machine code, but a lower-level Intermediate Representation).</p>
<pre><code><span>define i64 @julia_multiply_17232(i64, i64) {
top</span><span>:</span><span>
; ┌ @ int</span><span>.</span><span>jl</span><span>:</span><span>54</span><span> within `*'
   </span><span>%</span><span>2 </span><span>=</span><span> mul i64 </span><span>%</span><span>1</span><span>, </span><span>%</span><span>0</span><span>
; └
  ret i64 </span><span>%</span><span>2</span><span>
}
</span></code></pre>
<p>And with <code>multiply(1.4, 4)</code>, you can see how complicated it can get to compile even one more function. In AOT compiled Julia, all (some optimizations can be made to reduce) of these combinations would have to live in the compiled code even if only one was used, along with the control flow to delegate. </p>
<pre><code><span>define double @julia_multiply_17042(double, i64) {
top</span><span>:</span><span>
; ┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>312</span><span> within `*'
; │┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>282</span><span> within `promote'
; ││┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>259</span><span> within `_promote'
; │││┌ @ number</span><span>.</span><span>jl</span><span>:</span><span>7</span><span> within `convert'
; ││││┌ @ float</span><span>.</span><span>jl</span><span>:</span><span>60</span><span> within `</span><span>Float64</span><span>'
       </span><span>%</span><span>2 </span><span>=</span><span> sitofp i64 </span><span>%</span><span>1</span><span> to double
; │└└└└
; │ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>312</span><span> within `*' @ float</span><span>.</span><span>jl</span><span>:</span><span>405
   </span><span>%</span><span>3 </span><span>=</span><span> fmul double </span><span>%</span><span>2</span><span>, </span><span>%</span><span>0</span><span>
; └
  ret double </span><span>%</span><span>3</span><span>
}
</span></code></pre>
<p>The general strategy of “assume a type and compile/behave based on that” is called type inferencing, which Julia mildly uses in the examples above. There are a lot of other compiler optimizations that are made, though none of them are very specific to JITs as Julia may be better described as a lazy AOT compiler.</p>
<p>The simplicity of this kind of jitting makes it easy for Julia to also supply AOT compilation. It also helps Julia to benchmark very well, definitely a tier above languages like Python and comparable to C (I'd cite numbers, but those are always nuanced and I don't want to get into that).</p>
<h3 id="so-what-is-a-jit-take-two">So What is a JIT? Take Two.<a href="#so-what-is-a-jit-take-two" aria-label="Anchor link for: so-what-is-a-jit-take-two"> <i></i></a>
</h3>
<p>Julia is actually the jittiest JIT I'll discuss, but not the most interesting as a "JIT". It actually compiles code right before the code needs to be used -- just in time. Most JITs however (Pypy, Java, JS Engines), are not actually about compiling code just-in-time, but compiling <em>optimal code</em> at an optimal time. In some cases that time is actually never. In other cases, compilation occurs more than once. In a vast majority of the cases compilation doesn't occur until after the source code has been executed numerous times, and the JIT will stay in an interpreter as the overhead to compilation is too high to be valuable.</p>
<p><img src="https://carolchen.me/blog/img/jits/jitbrr.jpg" alt=""></p>
<p>The other aspect at play is generating <em>optimal code</em>. Assembly instructions are not created equal, and compilers will put a lot of effort into generating well-optimized machine code. Usually, it is possible for a human to write better assembly than a compiler (though it would take a fairly smart and knowledgeable human), because the compiler cannot dynamically analyze your code. By that, I mean things like knowing the possible range of your integers or what keys are in your map, as these are things that a computer could only know after (partially) executing your program. A JIT compiler can actually do those things because it interprets your code first and gathers data from the execution. Thus, JITs are expensive in that they interpret, and add compilation time to execution time, but they make it up in highly optimised compiled code. With that, the timing of compilation is also dependent on whether the JIT has gathered enough valuable information.</p>
<p>The cool part about JITs is that I was sort of lying when I said a JIT implementation of C could not be faster than existing compiled implementations. It would not be feasible to try, but jit-compiling C in the way I just described is not a strict superset of compiling a language and thus it is not logically impossible to compile code fast enough to make up for the compile+profile+interpreting time. If I "JIT compiled" C similarly to how Julia does it (statically compile each function as it's called), it would be impossible to …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/jits-intro/">https://carolchen.me/blog/jits-intro/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/jits-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740655</guid>
            <pubDate>Sun, 05 Jul 2020 18:14:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multiple Dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23740622">thread link</a>) | @wikunia
<br/>
July 5, 2020 | https://opensourc.es/blog/basics-multiple-dispatch/ | <a href="https://web.archive.org/web/*/https://opensourc.es/blog/basics-multiple-dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From time to time I hear that my posts are a little bit too deep and complicated for beginners. I totally agree: especially in my newest series on <a href="https://opensourc.es/blog/constraint-solver-1">"How to build a constraint solver from scratch?"</a> which is probably a never ending series. I do like to blog about it and will continue but this series is different.</p>
<p>Julia is a relatively young language and not too many people are using it. It thrives in scientific computing but I believe that it can be used for general computing (probably where start up time is not that relevant) i.e. I do use it for creating this blog with <a href="https://franklinjl.org/">Franklin</a> which I blogged a bit about as well <a href="https://opensourc.es/blog/Franklin.jl">here</a>.</p>
<p>This series tries to explain some of the core concepts of Julia and maybe some packages to beginners. I, the explainer of this stuff here, am by no means an expert in any of these. If you know this blog then you might know that I'm trying to explain stuff directly after I've learned them to hopefully be able to communicate better than some people who do this their entire life and are experts in it. Blogs from experts are sometimes hard to follow for me, so maybe also for you. I'll let them proof read my blog post just to be sure that there is nothing wrong with what I explain ;)</p>
<p>Posts in this series can be reached over the side bar. </p>
<p>Post 2: <a href="https://opensourc.es/blog/basics-repl-revise">REPL &amp; Revise</a></p>
<p>Okay everyone ready?</p>

<h2 id="what_is_dispatch"><a href="#what_is_dispatch">What is dispatch?</a></h2>
<p>In every programming language there are <code>functions</code> which have the purpose of providing structure and reusability of code. The functions have a <code>name</code> and some <code>arguments</code>.  They are defined like</p>
<pre><code>def add(x, y):
    return x + y</code></pre>
<p>In Python this can be called with <code>add(2,3)</code> which gives the expected <code>5</code> but also <code>add("2","3")</code> gives <code>'23'</code> which might make sense or not depending on who you ask :D</p>
<p>Now how about <code>add("2", 3)</code> ?</p>
<p>This results in an error <code>TypeError: can only concatenate str (not "int") to str</code> which again can make sense. Well I would say it does but Javascript does something different:</p>
<pre><code>function add(x,y) {
    return x+y
}</code></pre>
<p>will produce <code>"23"</code> for that.</p>
<p>Then there are of course languages like <code>C++</code> where this all is not that simple because we need to introduce types:</p>
<pre><code>int add(int x, int y) {
  return x+y;
}</code></pre>
<p>There it is clear for everyone that it takes two <code>int</code> and returns one <code>int</code>. Because it is a compiled language we would get an error directly when trying to call it with <code>add("2", 3)</code>.</p>
<p>Now what is the point? We can see different concepts here with having static types as in C++ and dynamic typing in JS and Python. They both have pros and cons which is probably obvious.  The one is easier to reason about and the others are maybe easier to hack around with.</p>
<p>Let's go into dispatching on those three languages:</p>
<p>In Python it is: Ah okay the user wants to call <code>add</code>:</p>
<ul>
<li><p>We have the <code>add</code> function</p>
</li>
<li><p>Lets call it with the arguments.</p>
</li>
<li><p>Good that works as it expects two arguments and we have two.</p>
</li>
</ul>
<p>Then we might get to the point where the function doesn't work like for <code>add("2", 3)</code> and throw an error or it works out and the answer is returned. </p>
<p>It is basically the same in JS. There are possibility some "extensions" like Typescript where things might happen differently. I haven't programmed with any of those languages lately so keep that in mind.</p>
<p>In <code>C++</code> more things are going on as each variable has a static type and one can check directly whether this fits or not. This means as we can later see that there can be more functions with the same name. I'll explain the difference between function overloading and multiple dispatch in that part ;)</p>
<p>In all of these languages we can have classes such that we might have a class <code>Manufacturer</code> and we can define <code>add(self, thing)</code> or something like that and can call the function with  <code>manufacturer.add(thing)</code>. This can be kind of seen as single dispatch. Dispatch is basically the process of deciding which function to call. Here it depends on the type of <code>manufacturer</code>. Is it a <code>Manufacturer</code> or a <code>Box</code>? For a <code>Box</code> we might have defined a class <code>Box</code> and <code>add(self, box)</code> inside of it.</p>
<div><p>⚠ Note</p> <p>These examples are more from the Python world but hopefully convey the point.</p></div>
<p>For people coding in Julia for longer this might sound like a weird concept. Actually writing about it, I am thinking: How would I do some things, where I use multiple dispatch all the time (like in the ConstraintSolver) in one of those languages?</p>
<p>Before I explain multiple dispatch I want to note:</p>
<p>Yes there are ways in Python for single dispatching like <a href="https://www.blog.pythonlibrary.org/2016/02/23/python-3-function-overloading-with-singledispatch/">@singledispatch</a> but given that the main posts I found when searching are 3-4 years old I doubt that a lot are using it :D</p>
<p>And it is still single dispatch.</p>
<h2 id="how_does_dispatch_work_in_julia"><a href="#how_does_dispatch_work_in_julia">How does dispatch work in Julia?</a></h2>
<p>Now that there is that out of our way let us have a look at one example in Julia:</p>
<pre><code>add(x, y) = x+y</code></pre>
<p>just to show a neat little way of defining one-line functions... (or as they are called in Julia: Methods)</p>
<p>The interesting things is when you type this in the Julia REPL (Read-eval-print loop) you get:</p>
<pre><code>julia&gt; add(x, y) = x+y
add (generic function with 1 method)</code></pre>
<p>calling that function works basically like in Python (from the user perspective for now). It doesn't work for strings though.</p>
<div><p>⚠ Note</p> <p>Julia and <code>+</code> for strings: Julia is a mathematical language and <code>+</code> is commutative whereas concatenating strings is not. So <code>"2"+"3"</code> is not <code>"3"+"2"</code>. Therefore Julia decided to use <code>*</code> instead. Which is commutative for numbers but not matrices for example.</p></div>
<p>Okay where did I interrupt myself? ... Ah yeah so we have an <code>add</code> function with one method now in the REPL. That looks like we might be able to add a new one, right?</p>
<div><p>⚠ Note</p> <p>As correctly pointed out on <a href="https://www.reddit.com/r/Julia/comments/hfk3u3/basics_multiple_dispatch_start_of_a_new_series/fvykyl3?utm_source=share&amp;utm_medium=web2x">Reddit</a>: I use mostly the word function. In Julia there is actually a difference between functions and methods. There is one <code>+</code> function with a lot of different implementations: called methods.</p></div>
<pre><code>julia&gt; add(x,y) = 2x+y
add (generic function with 1 method)</code></pre>
<p>okay that did not work because it still allows all types of inputs (and throws an error later when it doesn't work) because the compiler had no way to decide which <strike> function</strike>method to call. </p>
<p>Should it guess? It just overwrites the old method.</p>
<p>A small side step again: Let's check what happens when we call <code>add("2", "3")</code>
</p><pre><code>julia&gt; add("a", "b")
ERROR: MethodError: no method matching *(::Int64, ::String)
Closest candidates are:
  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:529
  *(::Missing, ::AbstractString) at missing.jl:174
  *(::T, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:54
  ...
Stacktrace:
 [1] add(::String, ::String) at ./REPL[3]:1
 [2] top-level scope at REPL[4]:1</code></pre>
<p>That error occurs when calling <code>2x</code> where it figured that <code>2</code> is an integer and <code>x = "2"</code> is a string. It gives us information of what kind of types it can multiply.</p>
<p>Let's pick one: </p><pre><code>*(::T, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:54</code></pre>
<p>This tells us that we can multiply two numbers of those types when they are the same. So <code>UInt8</code> with <code>UInt8</code> but I come to that syntax later.</p>
<p>You might wonder how many of those <code>*</code> <strike> functions</strike>methods there are: <code>357</code> is the answer which you get when typing</p>
<pre><code>julia&gt; methods(*)
...</code></pre>
<p>which gives you a long list with all kind of weird types where it sometimes spreads over several lines. I mean what is this? :D</p>
<pre><code>[345] *(A::LinearAlgebra.LQ{TA,S} where S&lt;:AbstractArray{TA,2}, B::Union{DenseArray{TB,1}, DenseArray{TB,2}, Base.ReinterpretArray{TB,1,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReinterpretArray{TB,2,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReshapedArray{TB,1,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReshapedArray{TB,2,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, SubArray{TB,1,A,I,L} where L where I&lt;:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, Base.ReshapedArray{T,N,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, DenseArray}, SubArray{TB,2,A,I,L} where L where I&lt;:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArra…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opensourc.es/blog/basics-multiple-dispatch/">https://opensourc.es/blog/basics-multiple-dispatch/</a></em></p>]]>
            </description>
            <link>https://opensourc.es/blog/basics-multiple-dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740622</guid>
            <pubDate>Sun, 05 Jul 2020 18:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get Used to Failure (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740513">thread link</a>) | @mooreds
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Dear new developer,</p>
<p>I was chatting with someone <a href="https://letterstoanewdeveloper.com/2018/10/24/join-a-meetup/">I met at a meetup</a> who was about to graduate from a bootcamp. I asked him what his advice to a new developer would be. He said that it would be “get used to failure, and get used to working through it.”</p>
<p>I thought that advice was great.</p>
<p>I often tell colleagues that “if it is easy, someone would have already automated it”. This means that when you are working on a software problem, the problem <strong>by definition</strong> hasn’t been solved within your organization (that you know of; I’ll come back to that). This means that you’ll most often be failing. Just like scientists who try to narrow down their scope of inquiry so they can have useful experiments, you’ll try to narrow down the problem and pattern match and research so that you can have a working solution. But just like the <a href="https://en.wikipedia.org/wiki/Michelson%E2%80%93Morley_experiment">best planned experiments fail</a>, so will you, often.</p>
<p>There are two additional complexities that software developers have that scientists do not.</p>
<p>The tools that software developers use are themselves software and are being developed. Imagine trying to build a house when the hammers and saws that you are using are themselves changing at a rapid pace. This means that the solution that may have worked in the past is suboptimal.</p>
<p>And the real world that scientists operate on and try to understand doesn’t often change daily. The business world that software developers operate on and try to understand can change on the whim of a person in authority. This is an <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">essential complexity</a> of software development.</p>
<p>This experience requires you to get used to failure, both at the micro and macro levels. And to keep going. You just need to be tenacious and realize that you’ll solve the problem. Also, recognize the frustration and realize that everyone is going through it. A coach once taught me that running is hard for everyone, whether you are running a 5 minute mile or a 10 minute mile. The same is true for development. Learning something new is difficult and frustrating, whether it’s your first programming language or the intricacies of a build and deployment process that is new to you.</p>
<p>Get used to failure and remember that everyone else encounters it.</p>
<p>I mentioned I’d return to the caveat that problems you tackle haven’t been solved “that you know of”. Back in the dark ages before the internet was widespread, distribution of software knowledge was slow and driven by email, bulletin boards, journals and books. Now we have google and stack overflow. This helps with coming up to speed on external software that will help you solve problems. I’ve yet to see an internal system that works well for sharing knowledge, but it is incumbent on you and your teams to search out solutions within your organization.</p>
<p>Once you have a problem defined (even partially), resist the temptation to dive in and start building a solution. Rather, pop your head up and ask around and see if anyone has solved your problem. Or even one third of it. You may or may not re-use their solution, but it will inform your solution even if you don’t.</p>
<p>Sincerely,</p>
<p>Dan</p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2018-12-31T10:23:42-07:00">December 31, 2018</time><time datetime="2019-08-14T07:38:03-06:00">August 14, 2019</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2018/12/31/get-used-to-failure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740513</guid>
            <pubDate>Sun, 05 Jul 2020 17:56:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JWT Authentication with Delphi (2017)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740445">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/ | <a href="https://web.archive.org/web/*/http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        <h2>JWT authentication with Delphi. Part 1</h2>
                        
                    </div><div>
                        <div>
                            <!-- Articles Index -->  

  

<hr>

<p>  
This is the first article I will write about JWT and authentication technologies using Delphi, specifically I'll cover the topic of authentication (mostly in a HTTP world) using tokens (specifically JSON Web Tokens).  
</p>

<p>  
The Delphi library used in this article is the open source <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a> library (created by me) and available on <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>GitHub</strong></a>. This library is listed on the <a href="https://jwt.io/" target="_blank"><strong>JWT.io</strong></a> site and  
it's already used in several projects (open source and commercial) but before we dive into the code let’s cover some basics about JWT's.  
</p>



<p>  
Authentication is the process of identifying someone (or something) determining that is who is claimed to be. Remember that in this article I will be speaking only about authentication and not authorization (that is giving individuals access to system objects based on their identity)  
</p>

<!-- WiRL -->  



<h2 id="sessionbasedauthentication">Session based authentication  </h2>

<p>  
In the HTTP world, applications have traditionally used session cookies to store authentication information. The mechanism relies on session IDs stored server-side. The session storage is typically an in-memory list/table (that is server-specific), or a separate session storage layer (often the back-end database).  
</p>

<p>  
In HTTP the communication is essentially stateless, so the cookie (that contains the session ID) is used by the server as a “key” to retrieve information about the client side (user or process). The cookie is created by the server and sent to the client, in the next request, the cookie is bounced back so the server can lookup the session ID in the session table.  
</p>

<p>Disadvantages of “cookie” based auth:</p>

<ul>
<li><strong>Sessions</strong>: Sessions are just stored on server’s memory</li>
<li><strong>Mobile</strong>: Native mobile apps seems to have problems working with cookies so if we need to query a remote API, maybe session auth is not the best solution.</li>
<li><strong>CSRF</strong>: (Cross-Site Request Forgery) If we go down the cookies way, you really need to do CSRF to avoid cross site requests. That is something we can forget when using JWT as you will see.</li>
<li><strong>CORS</strong>: (Cross-Origin Resource Sharing) Have you fight with CORS and cookies? No need to wrestle using JWT.</li>
</ul>

<h2 id="tokenbasedauthentication">Token based authentication  </h2>

<p>  
The main problem of a session based authentication is that the server must maintains a list of session to be able to “validate” the incoming request and that is a problem because only one server knows how to validate a client request (no scalability or availability).  
</p>

<p>  
So, token authentication was developed to solve problems of server-side session IDs. Using tokens instead of session IDs has the effect of lowering the server load and remove the need of storing an in-memory session table or having an expensive session storage layer (performance). JWT are stateless by definition so they are perfect for this task (more on that, later).  
</p>

<p>  
Before a token is created the user must, obviously, supply verifiable credentials (standard username/password pair, API keys, hardware IDs, or even tokens from another service) and consequently perform some sort of “login” action.  
</p>

<p>  
Keep in mind that JWT is not the only “standard” token representation out there, <b>SWT</b> (Simple Web Token) is (was) a proposed standard (Microsoft 2009) and <b>SAML</b> (Security Assertion Markup Language Token) is an open-standard for exchanging authentication and authorization data between parties based on XML (SAML 2.0, OASIS Standard 2005).  
</p>

<h2 id="oauth2">OAuth 2  </h2>

<p>  
Often I read about OAuth 2 and JWT as if they were comparable (and competing) standards… well, they are not!  
</p>

<p>  
OAuth 2 is an authorization framework that can employ JWT as the format for the OAuth 2 tokens, remember that OAuth2 is not an authentication protocol (because OAuth2 doesn’t know nothing about the user). OAuth 2 is a rather complex topic and I think I will write another article on this topic.  
</p>



<p>  
A JSON Web Token or JWT (pronounced “jot”) is a signed piece of data in JSON format and because it's signed the recipient (the server) can, and must, verify its authenticity.  
</p>

<p>  
The workflow is basically this: a user wants to authenticate so he sends the username and password (for example), the server validates the user and creates a (cryptographically) signed token and then sends it back to the user. The user sends the token with the next request and the server checks if the signature is genuine and (eventually) grants the access to the requested resource. In detail:  
</p>

<ol>
<li>The user sends username and password to an authentication service  </li>
<li>The authentication service responds with a signed JWT with information about the user  </li>
<li>The user requests a resource on the server sending the token back  </li>
<li>The server checks the signature and if it's genuine the access is granted</li>
</ol>

<!-- Linux Daemon -->  



<h2 id="afirstlooktoajwt">A first look to a JWT  </h2>

<p>This is what a JWT looks like:</p>

<pre><code><span>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</span>.<span>eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9</span>.<span>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</span></code>
</pre>

<p>The same JWT decoded:</p>

<pre><code>{
  "alg": "HS256",
  "typ": "JWT"
}
.
{
  "sub": "1234567890",
  "name": "John Doe",
  "admin": true
}
.
HMACSHA256(  
  base64UrlEncode(header),
  base64UrlEncode(payload),
  secret
)
</code></pre>

<p>As you can see the token is composed of three parts:</p>

<ol>
<li>In the first part (called <b>header</b>) are stored information about the signing algorithm and the type of payload (JWT)  </li>
<li>The second (the <b>payload</b>) contains the actual user data (claims)  </li>
<li>The third part is the <b>signature</b> computed (in this example) with the HMACSHA256 algorithm.</li>
</ol>

<h2 id="whatisjose">What is JOSE?  </h2>

<p>  
Before I talked about the Delphi JWT library <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a>, but what is JOSE? (and no, is not my name!). <b>JOSE</b> stands for <b>JSON Object Signing and Encryption</b> and is a (set of) standard that provides a general approach to signing and encryption of any content. JOSE consists of several RFC:  
</p>

<ul>
<li><a href="https://tools.ietf.org/html/rfc7519">JWT (JSON Web Token)</a> describes representation of claims encoded in JSON</li>
<li><a href="https://tools.ietf.org/html/rfc7515">JWS (JSON Web Signature)</a> describes producing and handling signed messages</li>
<li><a href="https://tools.ietf.org/html/rfc7516">JWE (JSON Web Encryption)</a> describes producing and handling encrypted messages</li>
<li><a href="https://tools.ietf.org/html/rfc7518">JWA (JSON Web Algorithms)</a> describes cryptographic algorithms used in JOSE</li>
<li><a href="https://tools.ietf.org/html/rfc7517">JWK (JSON Web Key)</a> describes format and handling of cryptographic keys in JOSE</li>
</ul>

<p>  
<b>In a nutshell:</b> the JWT contains the claims, the JWS is the JWT when signed, the JWE is the JWT when encrypted, the JWA defines the algorithms used in JOSE and the JWK describes the handling of the cryptographic keys used in the process.  
</p>

<p>  
Often the term JWT is used when describing some other JOSE definitions so, for simplicity, in this article I will be using the term JWT.  
</p>

<h2 id="jwtandrest">JWT and REST  </h2>

<p>  
JWT have become very popular with the wide adoption of REST architectural style, but we can use JWT tokens to authenticate in various context, not only REST applications.  
</p>

<p>  
Tokens (and JWTs) are merely an authentication representations and so they can be used in multiple scenarios:  
</p>

<ul>
<li>REST services authentication</li>
<li>OAuth 2.0 communications</li>
<li>CSRF (Cross Site Request Forgery) protection schemes</li>
<li>More in general as session IDs (eventually inside a cookie)</li>
</ul>

<p>  
In this article(s) I will focus on REST technologies but I will give some example of using JWT in other contexts.  
</p>

<!-- Neon -->  



<h2 id="jwtbenefitsinarestfulservice">JWT benefits in a RESTful service  </h2>

<p>  
In his famous dissertation, Roy T. Fielding defines 6 constraints for (truly) RESTful services:  
</p>

<ol>
<li>Client/server architecture  </li>
<li>Stateless communication  </li>
<li>Cache (on the client)  </li>
<li>Uniform Interface  </li>
<li>Layered system  </li>
<li>Code on-demand</li>
</ol>

<p>  
The most important (to me) is the second (and consequently the third one) that states REST interactions between client and server must be stateless by nature.  
</p>

<p>  
That means that requests (from the client) must contain all of the information necessary to understand the request and so they cannot take advantage of any stored context on the server and this, unfortunately, includes the session table typically stored on servers (automatic session management is one of the most publicized features of HTTP server frameworks).  
</p>

<p>  
The second constraint (if satisfied) induces the properties of <b>visibility</b> (looking at a request is sufficient to visualize the interaction), <b>reliability</b> (failure of one request does not influence others), and <b>scalability</b> (a server can switch a request to another server). Given these advantages you can see why this constraint is so important when building a REST server! Oh, and remember that JWT helps you to achieve this goal because:  
</p>

<ul>
<li>Using JWTs there’s no need of sessions</li>
<li>Using JWTs there’s no need of session storage (on server)</li>
<li>Using JWTs there’s no need of garbage collection of expired sessions</li>
</ul>

<h2 id="conclusion">Conclusion  </h2>

<p>  
So, as you can see, JWT is a simple and yet powerful technology to accomplish several tasks.  
</p>

<p>  
In the next post I will explain in detail the JWT’s claims and we'll start to explore the <a href="https://github.com/paolo-rossi/delphi-jose-jwt" target="_blank"><strong>delphi-jose-jwt</strong></a> library features.  
</p>

<p>  
<img src="http://blog.paolorossi.net/content/images/2017/04/firma-round.png" width="200">  
</p>




                        </div>
                        
                    </div></div>]]>
            </description>
            <link>http://blog.paolorossi.net/2017/04/27/jwt-authentication-with-delphi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740445</guid>
            <pubDate>Sun, 05 Jul 2020 17:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write That Down (2018)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740444">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | https://letterstoanewdeveloper.com/2018/12/28/write-that-down/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2018/12/28/write-that-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>This is a guest blog post from John Obelenus. Enjoy.</em></p>
<p>Dear new developer,</p>
<p id="bfca">Even when I was a kid in school I hardly wrote things down. That’s why we had textbooks after all! I was baffled by other students in college furiously transcribing every word that came out of the professor’s mouth. Now I have a career in the world of software where we track everything. Git holds all the code commits, email is never really deleted, and project management and issue tracking tools keep track of what we’re doing and have done. How could anything go missing?</p>
<p id="7f29">I constantly looking for things and cannot find them. I get a bug report, look at the code and say to myself “That is obviously wrong, let’s fix it.” I look at the offending commit that introduced the bug (of course it was me). But what is not there? The reason for the change. So I look at the project management tool we use. And someone definitely asked for a change, but, I’m still not sure why. So I search through my email for the few days before I made the change, and…nothing. I still cannot really figure out why we all decided to make a change which introduced a bug.</p>
<p id="f3ec">Or, worse yet, someone asks for a change. All well and good. Then a month later, someone asks to change it back. So you shake your head and make the change. Then someone is confused why this is happening, and calls a meeting and invites you to help figure it out. What are you going to bring to this meeting? Did you write anything down? I never used to. Now I do.</p>
<p id="2737">Now I have a notepad next to my laptop. And I have a notebook on the shelf. I make better use of git messages and write down who asked for changes. When working on a feature, or a bug, and find something…“interesting” I make a Github wiki entry explaining it. I write a comment in the code base explaining it. There are two kinds of documentation — useful documentation, and redundant documentation.</p>
<p id="2f04">No doubt many people have told you to comment your code. I hope many people have told you never to comment a loop with <code>// loop over the array</code>. That is not increasing clarity, its just duplicating what the code is doing. Adding noise, not signal. My contention is that comments are rarely useful for explaining “What this code does…” but rather, explains “Because of X, we are going to do…”.</p>
<p id="50b8">Future you is going to be very happy if you start documenting the intent behind what you’re doing. Good code is easy to read. Bad code is capable of being understood with time. But code doesn’t tell you why you’re doing all this work in the first place. Maybe something has changed and you don’t even need this code anymore — deleting code is the most satisfying feeling. But you won’t know unless you know the intent, the purpose, of the code. And the rest of the folks you’re working with are going to be very happy as well.</p>
<p id="f74a">If you write everything down (and make it public), they won’t need to tap you on the shoulder when you’re in “The Zone” to ask. When someone wants to set a meeting to understand why things are “The Way They Are” you already captured that information. You can send them the link and kill the meeting (Ok, maybe killing meetings is more satisfying than killing code).</p>
<p id="2b74">We only have so much time in our life, and we already work long hours. Let’s make future us happier by writing things down, so we don’t have to figure it all out again. We figured it out once when we wrote the code. So capture the knowledge in that moment in time. And Write It Down!</p>
<p>Sincerely,</p>
<p>John Obelenus</p>
<p><a href="https://medium.com/@jobelenus/write-that-down-adf7baa3d92b">(Previously published at Medium)</a></p>
<p><em>John Obelenus solves problems and saves time through software and crushing entropy<br>
</em></p>

<p><em>J</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2018-12-28T19:38:58-07:00">December 28, 2018</time><time datetime="2019-02-03T09:41:16-07:00">February 3, 2019</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2018/12/28/write-that-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740444</guid>
            <pubDate>Sun, 05 Jul 2020 17:48:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nine properties of logarithm: theory and examples]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740417">thread link</a>) | @R3G1R
<br/>
July 5, 2020 | https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm | <a href="https://web.archive.org/web/*/https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://mathvault.ca/wp-content/uploads/Logarithm-Post.jpg" alt="The Ultimate Guide to Logarithm - Properties of Logarithm, Complex Logarithm and More!" width="800" height="480" title="Logarithm Post" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20480'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Logarithm-Post.jpg"></p><p>For the very vast majority of humans on earth, there is a topic found in the good&nbsp;old math textbooks that many of us still even dread contemplating about, as&nbsp;it seems to mess with our brain in a rather<em>&nbsp;particular</em> way.&nbsp; The name? <a href="https://en.wiktionary.org/wiki/logarithmus" target="_blank" rel="noopener noreferrer">$\displaystyle \text{Logarithmus}$</a> — or <strong>Logarithm</strong> in English to be sure!</p><p>As terrible-sounding as it is, logarithm seems to have this <em>distinct</em> characteristic of metaphorically leaving a <em>bad taste</em> in our mouth. In fact, even for those who managed to maneuver around&nbsp;it back in high school, logarithm still remains largely as an <em>evasive</em> concept. The <strong>“I-can-manipulate-expressions-without-understanding-anything” syndrome</strong>&nbsp;runs rampant when it comes to logarithm.</p><p>Indeed, here in North America, the&nbsp;grade school curriculum has the propensity of overemphasizing the&nbsp;<strong>mechanics</strong>&nbsp;at the expense of&nbsp;<strong>basic theory</strong>, leaving us with the <em>formidable</em> task of filling in the <em>logarithmic</em> knowledge gap, which includes — among others&nbsp;— the theory behind the <strong>properties of logarithm</strong>, and its intended <strong>computational use</strong> in handling&nbsp;numbers with an&nbsp;<strong>order of magnitude</strong> veering towards the extremes.</p><p>So with that in mind, if you think that the time might have finally come to tame this <em>monster</em> we call logarithm, then it would be our pleasure to congratulate your timing on this very honorable act. And if&nbsp;you are simply looking to&nbsp;explore further into the rabbit hole, that would be <em>doubly</em> appreciated as well, for regardless of your motivation, the <strong>taming</strong>/<strong>musing</strong> is on!&nbsp;&nbsp;🙂<span id="more-5976"></span></p><h2 id="review"><span id="Logarithm_%E2%80%94_A_Review"></span><a href="#toc">Logarithm — A Review</a><span></span></h2><h3 id="terms"><span id="Terminology"></span><a href="#toc">Terminology</a><span></span></h3><p>Given a <em>real number</em> $x$, one of the challenges in <strong>elementary algebra</strong> is to express $x$ as a <em>power</em> of another number $b$ (known as the <strong>base</strong>). More specifically, we are interested in finding a&nbsp;number $\Box$ such that:</p><p>\begin{equation*} x = b^\Box \end{equation*}</p><p>As it turns out, this problem — in the <em>crude</em> form that it currently is at least — needs to be patched up first&nbsp;before any meaningful discussion can take place. For example:</p><ul><li>If the base is <em>negative</em>, then its powers need not be necessarily&nbsp;<a href="https://mathvault.ca/math-glossary/#welldefined"><strong>well-defined</strong></a> (e.g., $\displaystyle (-e)^{\frac{1}{2}}$).</li><li>If the base is $\displaystyle 1$, then any power of it would be just $1$, in which case, it would be <em>impossible</em>&nbsp;for it to generate any&nbsp;number that’s not $1$. A&nbsp;similar remark applies to the case&nbsp;where&nbsp;the base is equal to $0$.</li></ul><p>For these reasons, in the context of <strong>power determination</strong>, it’s customary to require&nbsp;the&nbsp;base $b$ to be a <em>positive</em> number — that is not equal to $1$. While under this assumption, any power of $b$ would necessarily have to be <em>positive</em>, it would also transpire —under this setup — that <em>any</em>&nbsp;positive number can be expressed as a power of $b$ in a <em>unique</em> way. That is, as long as $x$ is <em>positive</em>, there will be a <em>unique</em> number $\Box$ (known as the&nbsp;<strong>exponent</strong>) such that:</p><p>\begin{equation*} x= b^{\Box} \end{equation*}</p><p>in which case, we will simply call $\Box$ the <strong>logarithm</strong> of $x$ (in base $b$). In other words, logarithm is basically what happens when we expressed a number as a <em>power</em>, and then take the <em>exponent</em> from that power —&nbsp;It gives&nbsp;us the <strong>magnitude</strong> of a number, with respect to the base in question.</p><p>For example, when we try to express the number $64$ as a power of $2$, we get that $64= 2^6$. This alone shows that $6$ is the logarithm of $64$ — &nbsp;with respect to the base $2$.</p><p>Notation-wise, the logarithm of $x$ in <strong>base</strong> $b$ is denoted by $\log_b x$, with $x$ also being called&nbsp;the <strong>argument</strong> of the logarithm. When considered as a function, $\log_b x$ is defined on all <em>positive</em> numbers — as long as&nbsp;the base $b$ is <strong>valid</strong> (i.e.,&nbsp;&nbsp;$\displaystyle b&gt;0, b \ne 1$) .</p><p>To begin,&nbsp;we first note that <em>regardless</em> of the value of the base $b$, we always have that:</p><ul><li>$\displaystyle \log_b 1 = 0$ (since $0$ is the number $b$ needs to be raised to yield $1$)</li><li>$\displaystyle \log_b b&nbsp;= 1$ (since $1$ is the number $b$ needs to be raised to yield $b$)</li><li>$\displaystyle \log_b \frac{1}{b} = -1$ (since $-1$ is the number $b$ needs to be raised to yield $\displaystyle \frac{1}{b}$)</li></ul><p>Because these results are almost immediate and sufficiently notable, we’ll simply&nbsp;refer to&nbsp;them as the&nbsp;<strong>trivial logarithmic identities</strong>.</p><p>In addition,&nbsp;since $\log_b x$ stands for the number which&nbsp;<em>exponentiates</em> to $x$, we also have that by definition:</p><p>\begin{align*}b^{\log_b x} &amp; = x \qquad (\text{for all }x&gt;0)\end{align*}</p><p>On the other hand,&nbsp;we also have that:</p><p>\begin{align*} \log_b (b^x) = x \qquad (\text{for all } x \in \mathbb{R}) \end{align*}</p><p>Since one can see by inspection that $x$ is precisely the number which exponentiates to $b^x$.</p><p>For&nbsp;example, since $\displaystyle \log_2 53$ is the number that $2$ needs to raise to yield $53$, we have that $\displaystyle 2^{\log_2 53} =53$. Similarly, since $\displaystyle 10^{-\pi}$ is a power of $10$ with the exponent $-\pi$, we can infer&nbsp;that $\displaystyle \log_{10} \left(10^{-\pi}\right) = -\pi$.</p><h3 id="10"><span id="Common_Logarithm_(Base_10)"></span><a href="#toc">Common Logarithm (Base 10)</a><span></span></h3><p>Being the inverse of the exponential function $\displaystyle 10^x$, the base-$10$ logarithmic function — also known as the&nbsp;<a href="https://en.wikipedia.org/wiki/Common_logarithm" target="_blank" rel="noopener noreferrer"><strong>common logarithm</strong></a> — is customarily denoted by $\log_{10} x$, $\log x$, or simply $\lg x$ for short. The common logarithm is of great interest to us, primarily&nbsp;due to the prevalence of the&nbsp;<strong>decimal number system</strong> in various cultures around the world.</p><div><p><strong>Caution</strong></p><p>Note that in older scientific texts and some textbooks in higher mathematics, $\log x$ can also refer to — and usually is — the <a href="#e">natural logarithm of base $e$</a>.</p></div><p>When the common logarithm of a number is calculated, the&nbsp;<em>decimal representation</em> of the logarithm is usually split into two parts: the integer component&nbsp;(a.k.a., <strong>characteristic</strong>) and the fractional component&nbsp;(a.k.a., <strong>mantissa</strong>). The characteristic in essence tells us &nbsp;the <strong>number of digits</strong> the original number has, and the mantissa hints at the extent to which this&nbsp;number is close to its next power of $10$. These are the facts that make common logarithm a&nbsp;particularly handy tool in determining the <strong>order of magnitude</strong> of an <em>exceptionally&nbsp;large</em> (or <em>small</em>) number.</p><p>For example, to figure out the magnitude of the number $50!$ (i.e., $50 \times \cdots \times 1$), we proceed to calculate its logarithm, yielding that: \[ \log (50!) \approx 64.483 \] which means that $50! \approx 10^{64.483} =$ $10^{64}10^{0.483} \approx$ $10^{64} \cdot 3.04$, suggesting that $50!$ is a $65$<em>-digit number</em> which starts with $3$ — the <strong>characteristic</strong> $64$ gives away the number of digits, and the <strong>mantissa</strong> $0.483$ reveals&nbsp;the rest about the number itself.</p><p>Take home message? There is no need to&nbsp;write out a number in full to figure out its <em>approximate size</em>!</p><h3 id="2"><span id="Binary_Logarithm_(Base_2)"></span><a href="#toc">Binary Logarithm (Base 2)</a><span></span></h3><p>Being the inverse of the exponential function $2^x$, the <a href="https://en.wikipedia.org/wiki/Binary_logarithm" target="_blank" rel="noopener noreferrer"><strong>binary logarithm</strong></a>&nbsp;function $\log_2 x$ is extensively used in the field of <strong>computer science</strong>, primarily due to the fact that computers store information in <strong>bits</strong> (i.e., digits which takes $0$ or $1$ as possible values).</p><p>Similar to the case in base $10$, binary logarithm can be used to figure out&nbsp;the number of digits&nbsp;of a positive integer&nbsp;in <a href="https://en.wikipedia.org/wiki/Binary_number#Counting_in_binary" target="_blank" rel="noopener noreferrer"><strong>binary representation</strong></a>. In addition, binary logarithm is also used to figure out the <em>depth</em> of a <a href="https://en.wikipedia.org/wiki/Binary_tree" target="_blank" rel="noopener noreferrer"><strong>binary tree</strong></a>, or even the <em>number of operations</em> required by certain <strong>computer algorithms</strong>&nbsp;(this falls into a topic known as&nbsp;<a href="https://en.wikipedia.org/wiki/Time_complexity" target="_blank" rel="noopener noreferrer"><strong>algorithmic time complexity</strong></a>).</p><p>Beyond&nbsp;the world of computers, binary logarithm is also used in&nbsp;<strong>music theory</strong> to conceptualize the <em>highness</em>&nbsp;of&nbsp;musical notes, based&nbsp;on the fundamental&nbsp;observation&nbsp;that <em>raising</em>&nbsp;a note by an <strong>octave</strong>&nbsp;increases the frequency of the note by&nbsp;<em>twofold</em>. As a result, it is often convenient to conceive a&nbsp;<strong>musical interval</strong>&nbsp;as the binary logarithm of the <a href="https://en.wikipedia.org/wiki/Interval_ratio" target="_blank" rel="noopener noreferrer"><strong>frequency ratio</strong></a>.</p><h3 id="e"><span id="Natural_Logarithm_(Base_$e$)"></span><a href="#toc">Natural Logarithm (Base $e$)</a><span></span></h3><p>In some textbooks concerned with a more rigorous development&nbsp;of&nbsp;<a href="https://en.wikipedia.org/wiki/Transcendental_function" target="_blank" rel="noopener noreferrer"><strong>transcendental functions</strong></a>, the base-$\displaystyle e$ logarithmic function — otherwise known as&nbsp;<strong>natural logarithm</strong>, $\log_e x$ or simply $\ln x$ — are sometimes defined as the <em>area</em>&nbsp;between the <strong>reciprocal function</strong>&nbsp;$\frac{1}{x}$ and the x-axis from $1$ to $x$ (hence the term <em>natural</em>).</p><div id="attachment_5991"><p><img aria-describedby="caption-attachment-5991" src="https://mathvault.ca/wp-content/uploads/Harmonic-Series.png" alt="Natural Logarithm and the Divergence of the Harmonic Series" width="295" height="230" title="Harmonic Series" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20295%20230'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Harmonic-Series.png"></p><p id="caption-attachment-5991">Defined as the area underneath the reciprocal function, the function $\ln x$ increases without bound as $x$ increases, thereby showing that the <strong>Harmonic Series</strong> (i.e., $ \frac{1}{1} + \frac{1}{2}+ \ldots$ ) — whose area is even greater than that of $\ln x$ — diverges to $+ \infty$ as well.</p></div><p>Under this definition, it could be shown that the inverse of $\ln x$ is precisely the <strong>natural&nbsp;exponential function</strong> $e^x$, leading to the&nbsp;following&nbsp;<em>standard</em>&nbsp;definition of&nbsp;natural logarithm:</p><blockquote><h6>Given a positive number $x$,&nbsp;$\ln x$ denotes the number that $e$ needs to be raised, to&nbsp;become $x$.</h6></blockquote><p>Unlike the number $10$ — which is preferred due to the prevalence of&nbsp;<strong>decimal numbering system</strong> — the number $\displaystyle e$ is one of the <a href="https://mathvault.ca/hub/higher-math/math-symbols/#Constants" target="_blank" rel="noopener noreferrer">special constants</a>&nbsp;that&nbsp;pops up surprisingly often in various mathematical discourses —&nbsp;<em>irrespective</em> of the&nbsp;number system being chosen.&nbsp;As a result, mathematicians tend to consider base $e$ as more <em>natural</em> than base $10$ — even though some&nbsp;applied scientists and engineers beg to differ in various occasions…</p><p>Actually, to illustrate the scope of these&nbsp;<em>intellectual biases</em>&nbsp;among the scientific community, here’s an interesting account from <a href="https://en.wikipedia.org/wiki/Common_logarithm#History" target="_blank" rel="noopener noreferrer">Wikipedia</a>&nbsp;on the <strong>historical development</strong>&nbsp;of the&nbsp;notations for logarithms:</p><blockquote><h6>Because base 10 logarithms were most useful for computations, engineers generally simply wrote “log(x)” when they meant log<sub>10</sub>(x). Mathematicians, on the other hand, wrote “log(x)” when they meant log<sub>e</sub>(x) for the natural logarithm. Today, both notations are found. Since hand-held electronic calculators are designed by engineers rather than mathematicians, it became customary that they follow engineers’ notation. So the notation, according to which one writes “ln(x)” when the natural logarithm is intended, may have been further popularized by the very invention that made the use of “common logarithms” far less common, electronic calculators.</h6></blockquote><h3 id="arbitrary"><span id="Logarithm_of_an_Arbitrary_Base"></span><a href="#toc">Logarithm of an Arbitrary Base</a><span></span></h3><div id="attachment_6036"><p><img aria-describedby="caption-attachment-6036" src="https://mathvault.ca/wp-content/uploads/Graphs-of-Different-Logarithms.png" alt="Graphs of the Logarithmic Functions of base 2, e and 10" width="297" height="223" title="Graphs of Different Logarithms" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20297%20223'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Graphs-of-Different-Logarithms.png"></p><p id="caption-attachment-6036">Graphs of the logarithmic functions of base $2$, $\displaystyle e$ and $10$. Note that&nbsp;<strong>binary logarithm</strong> attains $1$ when $x=2$, <strong>natural logarithm</strong>&nbsp;when $x=e$ and&nbsp;<strong>common logarithm</strong>&nbsp;only when $x=10$.</p></div><p>In addition to the three most …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm">https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/logarithm-theory/#Properties_of_Logarithm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740417</guid>
            <pubDate>Sun, 05 Jul 2020 17:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[George Washington Statue Toppled by Portland Protesters on the Eve of Juneteenth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23740401">thread link</a>) | @donald2025
<br/>
July 5, 2020 | https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth | <a href="https://web.archive.org/web/*/https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-labelledby="title-0">
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  <p>&nbsp;&nbsp;&nbsp;&nbsp; A group of protesters gathered around a statue of George Washington in Portland, Oregon, on Thursday night and lit a fire on its head before pulling it to the ground. Washington, the nation’s first president, owned slaves but later in life began to oppose slavery and in his will ordered that his slaves be freed after his wife’s death.</p>
<p>&nbsp;Protests following Floyd’s death initially focused on the circumstances of his death and concerns about the police investigation, however, demonstrations have grown around the topic of monuments of historical figures.</p>
<p><span>After the founding father’s statue came crashing down, vandals defaced it with graffiti, then left it face-down in Rose City Park before fleeing around 11 p.m., the station reported.</span></p>
<p><span>"Maybe it's time for George Washington to go to a museum or go somewhere else," Johnson said</span></p>
<p><span>Johnson says he saw what happened late last night when the statue came down.<br>"It was not an angry mob, it was just people trying to take down something they did not like," Johnson said.</span></p>

<p><strong>George Washington statue torn down&nbsp;Portland, Thursday night 18, June, 2020</strong></p>
<p><img alt="" src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/George_Washington_statue_toppled_2048x2048.jpg?v=1592655866"></p>
<p>&nbsp;Activists first focused on monuments of Confederate leaders, who seceded from the union in defense of slavery. Since then, activists have gone on to target other controversial historical figures, such as&nbsp;Christopher Columbus and George Washington.</p>
<p>As of Friday morning, the statue remained on the ground, covered in spray paint. Some of the messages written on the toppled monument included: “BLM,” an acronym for Black Lives Matter; “You’re on native land;” “f— cops;” “white fragility;” and “no good cops.”</p>
<p>&nbsp;On Friday morning, Andy tweeted a video of the toppled statue:&nbsp;</p>

<blockquote>
<p lang="en" dir="ltr">Portland wakes up to see what antifa did overnight. A century old statue of George Washington was toppled &amp; set on fire with an American flag. “White fragility,” “Damn white men” &amp; other messages are written on the moment. On the ground nearby: “Defund white men.” <a href="https://t.co/zjrsZHJC9o">pic.twitter.com/zjrsZHJC9o</a></p>
— Andy Ngô (@MrAndyNgo) <a href="https://twitter.com/MrAndyNgo/status/1273969935497084930?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>
<blockquote></blockquote>

<p><strong>&nbsp;George Washington statue in Portland toppled, protests continue Portland, June 19, 2020</strong></p>
<p><img src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/portland_6_2048x2048.jpg?v=1592663423" alt=""></p>
<p><span>A group of people tore down a statue of George Washington that stood on the lawn of the German American Society in Northeast Portland.</span></p>
<p><span><strong>Caesar the 'no drama llama' march protest in Portland Friday, June 19, 2020</strong></span></p>
<p><span>Caesar the 'no drama llama' offers support and love at protestors.&nbsp;Caesar has joined many marches and protests for a variety of groups promoting civil rights and equality and frequent charity events.<br></span></p>
<p><span>Caesar is one of 15 llamas who reside at McCool’s Mystic Llama Farm in Jefferson, Oregon, about 75 miles south of Portland. McCool said, "It was important to him to make the 150-mile round-trip drive with Caesar to lend support and hopefully a calming presence for both protesters and police officers."</span></p>
<p><img alt="" src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/portland_protests_2_2048x2048.jpg?v=1592654519"></p>
<p>&nbsp;Zane Sparling <strong>tweeted</strong>: "<span>George Washington statue in Portland will be removed by crane TODAY and put in storage. No long term decisions made regarding reinstallation."</span></p>
<p>&nbsp;Just spoke with the Regional Arts &amp; Culture Council.&nbsp;</p>
<blockquote>
<div lang="en" dir="ltr"><p>George Washington statue in Portland will be removed by crane TODAY and put in storage. No long term decisions made regarding reinstallation. </p><p>Spokeswoman for RACC says statue caused “harm” <a href="https://t.co/7S0wQUY68y">pic.twitter.com/7S0wQUY68y</a></p></div>
— Zane Sparling (@PDXzane) <a href="https://twitter.com/PDXzane/status/1274044114779009025?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>
<blockquote></blockquote>
<p>
Matt Rashleigh <strong>tweeted</strong>: "The George Washington statue on NE Sandy in #Portland #Oregon has been pulled down and vandalized. Portland Police officers inspected the damage.&nbsp;<span><span>Someone left a note and a few dollars on it next to the spray painted bronze"</span></span></p><blockquote>
<p lang="en" dir="ltr">The George Washington statue on NE Sandy in <a href="https://twitter.com/hashtag/Portland?src=hash&amp;ref_src=twsrc%5Etfw">#Portland</a> <a href="https://twitter.com/hashtag/Oregon?src=hash&amp;ref_src=twsrc%5Etfw">#Oregon</a> has been pulled down and vandalized. Portland Police officers inspected the damage. Someone left a note and a few dollars on it next to the spray painted bronze. <a href="https://twitter.com/hashtag/koin6news?src=hash&amp;ref_src=twsrc%5Etfw">#koin6news</a> <a href="https://t.co/e5LYbDtvMa">pic.twitter.com/e5LYbDtvMa</a></p>
— Matt Rashleigh (@Matt_KOIN) <a href="https://twitter.com/Matt_KOIN/status/1273885631949594624?ref_src=twsrc%5Etfw">June 19, 2020</a>
</blockquote>

<p><span>Images from the scene show the statue lying face down on the ground and covered in graffiti that read: ‘Genocidal colonist’</span></p>
<p><span>A spokeswoman for the Regional Arts &amp; Culture Council — the nonprofit tasked with maintaining local public art — said a city crew would remove the statue by end of day Friday, June 19, for storage. No final decision about reinstallation has been made.</span></p>
<p><img src="https://cdn.shopify.com/s/files/1/0402/2131/1132/files/The_George_Washington_incident_1024x1024.jpg?v=1593956279" width="1024x1024" height="1024x1024"></p>
<h3><span>Support #BlackLivesMatter movement and get your&nbsp;<span><a href="https://blacklivesmatter-clothing.com/">"I CAN'T BREATHE" T-Shirt</a></span>, We're donating a percentage of every purchase to support&nbsp;</span></h3>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://blacklivesmatter-clothing.com/blogs/news/george-washington-statue-toppled-by-portland-protesters-on-the-eve-of-juneteenth</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740401</guid>
            <pubDate>Sun, 05 Jul 2020 17:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Utility ISort 5.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23740400">thread link</a>) | @throwaway333444
<br/>
July 5, 2020 | https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/ | <a href="https://web.archive.org/web/*/https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/timothycrosley/isort/edit/develop/docs/major_releases/introducing_isort_5.md" title="Edit this page"></a>
                
                
                
<p><a href="https://timothycrosley.github.io/isort/"><img alt="isort 5 - the best version of isort yet" src="https://raw.githubusercontent.com/timothycrosley/isort/develop/art/logo_5.png"></a></p>
<p>isort 5.0.0 is the first major release of isort in over five years and the first significant refactoring of isort since it was conceived more than ten years ago.
It's also the first version to require Python 3 (Python 3.6+ at that!) to run - though it can still be run on source files from any version of Python.
This does mean that there may be some pain with the upgrade process, but we believe the improvements will be well worth it.</p>
<p><a href="https://timothycrosley.github.io/isort/CHANGELOG/">Click here for an attempt at full changelog with a list of breaking changes.</a></p>
<p><a href="https://timothycrosley.github.io/isort/docs/upgrade_guides/5.0.0/">Using isort 4.x.x? Click here for the isort 5.0.0 upgrade guide.</a></p>
<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/0.-try/">Try isort 5 right now from your browser!</a></p>
<p>So why the massive change?</p>

<div><pre><span></span><code><span>isort --profile black .</span>
<span>isort --profile django .</span>
<span>isort --profile pycharm .</span>
<span>isort --profile google .</span>
<span>isort --profile open_stack .</span>
<span>isort --profile plone .</span>
<span>isort --profile attrs .</span>
<span>isort --profile hug .</span>
</code></pre></div>


<p>isort is very configurable. That's great, but it can be overwhelming, both for users and for the isort project. isort now comes with profiles for the most common isort configurations,
so you likely will not need to configure anything at all. This also means that as a project, isort can run extensive tests against these specific profiles to ensure nothing breaks over time.</p>

<div><pre><span></span><code><span>import</span> <span>a</span>  <span># &lt;- These are sorted</span>
<span>import</span> <span>b</span>

<span>b</span><span>.</span><span>install</span><span>(</span><span>a</span><span>)</span>

<span>import</span> <span>os</span>  <span># &lt;- And these are sorted</span>
<span>import</span> <span>sys</span>


<span>def</span> <span>my_function</span><span>():</span>
    <span>import</span> <span>x</span>  <span># &lt;- Even these are sorted!</span>
    <span>import</span> <span>z</span>
</code></pre></div>


<p>isort 5 will find and sort contiguous section of imports no matter where they are.
It also allows you to place code in-between imports without any hacks required.</p>




<p>isort has been refactored to use a streaming architecture. This means it can sort files of <em>any</em> size (even larger than the Python interpreter supports!) without breaking a sweat.
It also means that even when sorting imports in smaller files, it is faster and more resource-efficient.</p>

<p>Sorting the same file with the same configuration should give you the same output no matter what computer or OS you are running. Extensive effort has been placed around refactoring
how modules are placed and how configuration files are loaded to ensure this is the case.</p>

<div><pre><span></span><code><span>cimport</span> <span>ctime</span>
<span>from</span> <span>cpython</span> <span>cimport</span> <span>PyLong_FromVoidPtr</span>
<span>from</span> <span>cpython</span> <span>cimport</span> <span>bool</span> <span>as</span> <span>py_bool</span>
<span>from</span> <span>cython.operator</span> <span>cimport</span> <span>dereference</span> <span>as</span> <span>deref</span>
<span>from</span> <span>cython.operator</span> <span>cimport</span> <span>preincrement</span> <span>as</span> <span>preinc</span>
<span>from</span> <span>libc.stdint</span> <span>cimport</span> <span>uint64_t</span><span>,</span> <span>uintptr_t</span>
<span>from</span> <span>libc.stdlib</span> <span>cimport</span> <span>atoi</span><span>,</span> <span>calloc</span><span>,</span> <span>free</span><span>,</span> <span>malloc</span>
<span>from</span> <span>libc.string</span> <span>cimport</span> <span>memcpy</span><span>,</span> <span>strlen</span>
<span>from</span> <span>libcpp</span> <span>cimport</span> <span>bool</span> <span>as</span> <span>cpp_bool</span>
<span>from</span> <span>libcpp.map</span> <span>cimport</span> <span>map</span> <span>as</span> <span>cpp_map</span>
<span>from</span> <span>libcpp.pair</span> <span>cimport</span> <span>pair</span> <span>as</span> <span>cpp_pair</span>
<span>from</span> <span>libcpp.string</span> <span>cimport</span> <span>string</span> <span>as</span> <span>cpp_string</span>
<span>from</span> <span>libcpp.vector</span> <span>cimport</span> <span>vector</span> <span>as</span> <span>cpp_vector</span>
<span>from</span> <span>multimap</span> <span>cimport</span> <span>multimap</span> <span>as</span> <span>cpp_multimap</span>
<span>from</span> <span>wstring</span> <span>cimport</span> <span>wstring</span> <span>as</span> <span>cpp_wstring</span>
</code></pre></div>


<p>isort 5 adds seamless support for Cython (<code>.pyx</code>) files.</p>

<div><pre><span></span><code><span>import</span> <span>e</span>
<span>import</span> <span>f</span>

<span># isort: off  &lt;- Turns isort parsing off</span>

<span>import</span> <span>b</span>
<span>import</span> <span>a</span>

<span># isort: on  &lt;- Turns isort parsing back on</span>

<span>import</span> <span>c</span>
<span>import</span> <span>d</span>
</code></pre></div>


<p>isort 5 adds support for <a href="https://timothycrosley.github.io/isort/docs/configuration/action_comments/">Action Comments</a> which provide a quick and convient way to control the flow of parsing within single source files.</p>

<div><pre><span></span><code><span>import</span> <span>isort</span>

<span>isort</span><span>.</span><span>code</span><span>(</span><span>"""</span>
<span>import b</span>
<span>import a</span>
<span>"""</span><span>)</span> <span>==</span> <span>"""</span>
<span>import a</span>
<span>import b</span>
<span>"""</span>
</code></pre></div>


<p>isort now exposes its programmatic API as a first-class citizen. This API makes it easy to extend or use isort in your own Python project. You can see the full documentation for this new API <a href="https://timothycrosley.github.io/isort/reference/isort/api/">here</a>.</p>

<p>A major focus for the release was to give isort a solid foundation for the next 5-10 years of the project's life.
isort has been refactored into functional components that are easily testable. The project now has 100% code coverage.
It utilizes tools like <a href="https://hypothesis.readthedocs.io/en/latest/">Hypothesis</a> to reduce the number of unexpected errors.
It went from fully dynamic to fully static typing using mypy. Finally, it utilizes the latest linters both on (like <a href="https://deepsource.io/gh/timothycrosley/isort/">DeepSource</a>) and offline (like <a href="https://flake8.pycqa.org/en/latest/">Flake8</a>) to help ensure a higher bar for all code contributions into the future.</p>

<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/0.-try/">Try isort 5 right now from your browser!</a></p>
<p>OR</p>
<p>Install isort locally using <code>pip3 install isort</code>.</p>
<p><a href="https://timothycrosley.github.io/isort/docs/quick_start/1.-install/">Click here for full installation instructions.</a></p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://timothycrosley.github.io/isort/docs/major_releases/introducing_isort_5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740400</guid>
            <pubDate>Sun, 05 Jul 2020 17:42:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ongoing Accomplishment of the Big Five]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740367">thread link</a>) | @elsewhen
<br/>
July 5, 2020 | https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/ | <a href="https://web.archive.org/web/*/https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-732">
	<!-- .entry-header -->

	
	
	<div>
		
<p><em>by a literal banana</em></p>
<p>I have been trying to understand the “<a href="https://en.wikipedia.org/wiki/Lexical_hypothesis" target="_blank" rel="noopener">lexical hypothesis</a>” of personality, and its modern descendant, the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits" target="_blank" rel="noopener">Five Factor Model of personality</a>, for <a href="https://carcinisation.com/2020/01/27/ignorance-a-skilled-practice/">several</a> <a href="https://carcinisation.com/2020/06/24/the-extended-sniff-test/">months</a>. In that time, I have said some provocative things about the Big Five, and even some unkind things that I admit were unbecoming to a banana. Here, I wish to situate the Five Factor Model in the context of its historical development and modern use, and to demonstrate to the reader the surprising accomplishment that it represents for the field of psychology.<span id="more-732"></span></p>
<p>In personality research, the “lexical hypothesis” refers to a hypothesis attributed to Francis Galton (1884). Galton supposed that each human language would reflect important realities of human character within that language and culture. In particular, he noted that the words used to evaluate character and personality are very numerous (he estimated over a thousand, using a thesaurus), and often overlap in meaning.</p>
<p>But Galton immediately left his thesaurus behind, readily admitting of the impossibility of <a href="https://carcinisation.com/2020/06/26/words-fail/">defining</a> any aspect of character. Rather, he turned to experimental means of testing the character in various ways, and insisted that <em>no particular map or model of personality is needed to start from</em>.</p>
<p>Nowhere in his essay does Galton propose surveys as a means for studying character. He would probably regard such methods as unscientific, as indicated in his final paragraph:</p>
<blockquote><p>[C]haracter ought to be measured by carefully recorded acts, representative of the usual conduct. An ordinary generalisation is nothing more than a muddle of vague memories of inexact observations. It is an easy vice to generalise. We want lists of facts, every one of which may be separately verified, valued and revalued, and the whole accurately summed. It is the statistics of each man’s conduct in small every-day affairs, that will probably be found to give the simplest and most precise measure of his character.</p></blockquote>
<p>The methods that Galton proposed are exclusively non-linguistic. For instance, he commented that observing children involved in play quickly gives one an idea of each child’s emotional expression. Galton’s proposed methods prefigure both hidden camera prank shows and Goffman’s “breaching experiments:”</p>
<blockquote><p>I will not attempt to describe particular games of children or of others, nor to suggest experiments, more or less comic, that might be secretly made to elicit the manifestations we seek, as many such will occur to ingenious persons. They exist in abundance, and I feel sure that if two or three experimenters were to act zealously and judiciously together as secret accomplices, they would soon collect abundant statistics of conduct. They would gradually simplify their test conditions and extend their scope, learning to probe character more quickly and from more of its sides.</p></blockquote>
<p>Other methods Galton expressed enthusiasm for include heart rate measurement (he wore a home-brew heart-rate-measuring apparatus while he delivered the lecture that makes up the text) and methods discoverable from personal context (giving an example from Benjamin Franklin, of a man with one attractive and one deformed leg, who kept track of which leg his interlocutors paid attention to, as a gauge of their optimism or pessimism). Galton would be surprised, I think, to find that the most promising and scientific theory of personality in the twenty-first century is premised entirely on survey responses as its “facts.”</p>
<p>Early in the study of personality, there was a major shift of meaning in the lexical hypothesis. At first, the thesaurus and the word list were its tools of study (e.g., Allport &amp; Odbert, 1936); the idea was to find common factors of meaning in the words themselves. Of course, there is no particularly scientific way to decide how much the word “annoying” is the same as “obnoxious,” or how much either is the same as “low-status.” The major shift was to begin to measure the correlations of an entirely different construct: the correlations of the words <em>when used to describe a particular person</em>. That is, rather than trying to measure the underlying meaning of words, researchers began to measure the degree to which different words were applied to the same person. “Sameness” and “correlation” were no longer distinguishable concepts for the methods.</p>
<p>Initially, lists of adjectives, and eventually, short survey questions, were administered to subjects, who described either a person they knew or themselves. When the responses were subjected to factor analysis—a mathematical analysis to reveal the structure of correlations between responses—a varying number of factors emerged, depending on the methods and the researchers and the questions and the subjects, and these factors were given varying names. Since the early 1990s, the Five Factor Model has been dominant, although the names of the factors vary somewhat even today. The acronym OCEAN is used for the traits: Openness to experience (sometimes called “intellect” or “imagination” or “open-mindedness”), Conscientiousness, Extraversion (sometimes called “surgency”), Agreeableness, and Neuroticism (sometimes called “negative emotionality” or “emotional stability” reversed).<span>&nbsp;</span></p>
<p>Today, the five traits are measured with various survey instruments, with five questions on the shortest version (one for each aspect) and sixty questions on a common long-form version (that used by Soto, 2019). Survey instruments are validated in a number of ways: how much their responses correlate between testings (test-retest reliability, with astrological sign as the gold standard), how much different raters agree using the criteria (inter-rater reliability), and a nebulous concept of construct validity, which sometimes includes scientific gestures designed to ensure that the instrument measures what it purports to measure. Many papers present elaborate numerical artifacts of validation, and I have found that some characterize the validity of their instruments as “good” without providing an indication of what would be “not good enough.” From a brief review of dozens of validated instruments in social psychology, it seems to me that it is relatively easy to “validate” meaningless instruments. As long as the mathematical bona fides are present, the construct need not be meaningful in other ways. (The reader who is rightly suspicious of my broad and unsourced claims may wish to search Google Scholar with variations of “scale,” “inventory,” and “survey instrument,” and examine the results critically. The naming of factors is often a particularly interesting step.)</p>
<p>The strong claim made by advocates of the Five Factor Model is that any set of questions describing a human being, administered to subjects and the responses subjected to factor analysis, will reveal the same five factors (paraphrasing Jordan Peterson in <a href="https://youtu.be/pCceO_D4AlY" target="_blank" rel="noopener">this video</a>, around 11:10-16:40). This strong claim, though dubious in a number of respects, is a major part of the basis for the scientific legitimacy of the Big Five. It is interesting to see which aspects of the strong claim are admitted to be false by advocates of the Big Five, and how much is excused on the grounds that <i>at least it’s something</i>. The Five Factor Model is not perfect, advocates grant, but it is better than nothing. It is not clear how they measure “better than nothing;” this is a potentially interesting hypothesis in need of precisification, perhaps.</p>
<p>The Big Five exist as a special, scientifically validated property of language and survey methods, and that is one basis for their legitimacy. The other basis for the legitimacy of the Five Factor Model is its <i>replicable correlation with consequential life outcomes</i>. We know that the Big Five are not merely phantoms that fall out of a certain analysis of a certain use of language in WEIRD college students, because these traits are reliably correlated with things we care about.<span>&nbsp;</span></p>
<p>One of the most interesting features of the Big Five is the nature of its scientific evidence. Observe what is held out as a “replication” of the theory, and you will discover the theory’s true nature. The most impressive aspect of the ongoing accomplishment of the Five Factor Model is the degree to which it <i>deflects curiosity </i>about its underlying meaning with <i>rituals of scientific validation</i>, regardless of the rituals’ appropriateness in context. Since “replication” is the scientific ritual most recently shown to detect poor science in psychology, being shown to reliably “replicate” is a huge boost to the credibility of a theory.<span>&nbsp;</span></p>
<p>The interesting thing about the Five Factor Model is what it gets away with, in terms of being considered a theory, even though it is not causal, and makes no predictions. What counts as a “replication” of the Five Factor Model, as in Soto (2019), is the following: a correlation is found between one or more factors of the Five Factor Model and some other construct, and that correlation is found again in another sample, regardless of the size of the correlation. In almost all cases, and in 100% of Soto (2019)’s measures, the construct compared to a Big Five factor is derived from an online survey instrument.</p>
<p>What counts as a “consequential life outcome” is also fascinating. In most cases, the life outcome constructs are vague abstractions measured with survey instruments, much like the Big Five themselves. For instance, the life outcome “Inspiration” is measured with the Inspiration Scale, which asks the subject in four ways how often and how deeply inspired they are. Amazingly, this scale correlates a little bit with Extraversion and with Open-mindedness. Do these personality traits “predict” the life outcome of inspiration? Is “Inspiration” as instrumentalized here meaningfully different from the Big Five constructs, such that this correlation is meaningful?<span>&nbsp;</span></p>
<p>Compare the items for the construct “Inspiration” with the items for Extraversion and Open-mindedness used in Soto (2019):</p>
<p><b>Inspiration Scale Items</b></p>
<ul>
<li>I experience inspiration.</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/">https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</a></em></p>]]>
            </description>
            <link>https://carcinisation.com/2020/07/04/the-ongoing-accomplishment-of-the-big-five/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740367</guid>
            <pubDate>Sun, 05 Jul 2020 17:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V, China, Nightingales]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740272">thread link</a>) | @ceohockey60
<br/>
July 5, 2020 | https://interconnected.blog/riscv-china-nightingales/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/riscv-china-nightingales/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>【想看中文的<a href="https://interconnected.blog/riscv-china-nightingales/#chinese-version-below">读者请点击这里</a>或滚动到本页下方】</p><p>Last weekend, I read <a href="https://www.huxiu.com/article/360061.html">a long, epic piece of techlore</a> that chronicled the fierce and bitter rivalry between TSMC and Samsung in their fight to become the world’s number 1 chip foundry, which stretched back three decades and continues today.</p><p>Among the many dramatic details was the “Nightingale program” that TSMC started in the mid-2010s to jumpstart its R&amp;D, because it was falling behind Samsung and losing Apple’s A9 chip orders to the Korean conglomerate. TSMC conceived of a three-shift, 24-hour non-stop R&amp;D operation, taking a page out of their fellow Taiwanese manufacturing behemoth Foxconn’s assembly operation. The “Nightingales” were engineers and researchers, who were willing to work the “graveyard shift” for a 30% increase in base salary and 50% increase in dividend payout. Due to this program, <strong>the total working hours clocked in Taiwan in 2014 was 2135</strong>, apparently the most of any economy in the world that year.</p><p>TSMC, and arguably Taiwan’s entire economy, was confronting an existential struggle at that time. SMIC (the largest chip foundry in China), and arguably China’s technological and economic future, is confronting a similarly existential struggle on a larger scale.</p><p>There are many interconnected elements that, when put together, could determine how China will come out on the other end of this struggle -- <strong>RISC-V, foundry technology, the “New Infrastructure” stimulus program, open source, and a few key TSMC personnels</strong>, who are now at the helm of China’s semiconductor industry.</p><p>Let’s take a look at each of them, sequentially and interconnectedly.</p><h2 id="risc-v-strengths-and-weaknesses">RISC-V: Strengths and Weaknesses</h2><p>The conversation around China’s journey towards technological self-reliance often involves <strong>RISC-V</strong> -- an open standard Instruction Set Architecture (ISA) for hardware that’s under open source licenses, thus any one can run, change, copy, and distribute it, in accordance with<a href="https://www.gnu.org/philosophy/free-sw.en.html"> the four freedoms</a> of open source.</p><figure><img src="https://lh6.googleusercontent.com/sVMZ8L3CA61u_kc0hdRdB9AItYEuK65vUJ70os7CAaFpogycLyqhYL_BbwMndKktijiEAF8Bi9WLyKCmW5ztmGE3Zhw2dQrRP0VwWcxWIsUqTFVFfYXIS4K5wp_SDExCRiug0cE1" alt=""><figcaption>RISC-V Ecosystem, courtesy of SiFive.</figcaption></figure><p>However, RISC-V is still young. Its<a href="https://riscv.org/specifications/"> user-space ISA</a> and<a href="https://riscv.org/specifications/privileged-isa/"> privileged ISA</a> wasn’t frozen, and thus ready for large-scale software and hardware development, until June 2019. The technology and community ecosystem is maturing, and support from large Chinese organizations has a lot to do with it. Of <a href="https://riscv.org/members-at-a-glance/">the six Premier Members</a> of the official RISC-V foundation, RISC-V International, &nbsp;four are Chinese organizations -- Alibaba, Huawei, RIOS Lab, and the Institute of Computing Technology of the Chinese Academy of Sciences.</p><p>But in the near future (say the next five years), what can RISC-V, the technology, realistically enable China to accomplish?</p><p><strong>What is it good for?</strong> &nbsp;RISC-V is a very good foundation for rapidly prototyping and building <strong>special purpose</strong> chips. The development cycle and experience feels closer to software than hardware. This speed in development is partly because it’s open-sourced -- no hassle in getting a commercial license, as oppose to its proprietary counterparts like ARM -- and also partly because the ISA itself is simplified and “reduced” (i.e. the R in RISC), as opposed to CISC (the C means “complex”) which underpins more powerful, proprietary ISAs like Intel’s x86. This reduced architecture enables and optimizes simple computation instructions well, literally elementary school math: addition, subtraction, multiplication, division, etc. It’s less capable of supporting complex mathematical operations, like matrix multiplication and partial derivative (used widely in Deep Learning AI).</p><p>Thus, in reality, chips designed using RISC-V have been used most commonly in <strong>IoT and embedded systems</strong> scenarios. Because of its simplicity and malleability, RISC-V chips also <strong>tend to have low power consumption</strong>, which is a good attribute when battery life is an issue, e.g. wearable devices. This reduced simplicity also means that the compiler (the software layer that translates code, like C, into machine instructions for a chip to execute) does not need to be purposefully designed to optimize performance on RISC-V. Using some common compilers <a href="https://riscv.org/software-status/#c-compilers-and-libraries">like GCC, which RISC-V </a>supports, will do.</p><p><strong>What does it lack? </strong>As you might’ve guessed, RISC-V’s reduced simplicity is also the source of its limitations. While many people like to pit RISC-V against a general purpose ISAs, like Intel’s, <strong>they are more compliments than competitors. </strong>In fact, special purpose RISC-V chips that accelerate certain computations for AI workloads do run side-by-side along general purpose Intel chips in the cloud. It’ll be a long time (more than five years, in my opinion) before RISC-V can enable the design of a <strong>general purpose</strong> chip that powers our iPhones, laptops, or cloud computing servers in a data center, with enough developers incentivized to both extend the ISA and the compiler and other infrastructure software on top of it.</p><p><strong>Can RISC-V become general purpose some day?</strong> Of course. <strong>But that’s not an inevitability</strong>. It’s <strong>a strategic choice</strong> that the RISC-V community can make and work towards, with all the complexity in upstream coordination, developer community building, and open governance, not to mention the work of building the technology itself, that must be executed collectively. That possible future is perhaps the most interesting question when we think about China’s self-reliance, which I’ll discuss in more detail below <strong>in the context of fostering open source</strong>.</p><h2 id="-new-infrastructure-">“New Infrastructure”</h2><p>With the strengths and weaknesses of RISC-V in mind, let’s see where RISC-V chips could get deployed in China’s economy and infrastructure in the foreseeable future.</p><p>It’s no secret that central government industrial policy matters a lot in China, even though its market-driven economy is what materializes much of that vision. The most relevant piece of policy is <a href="http://www.china.org.cn/business/2020-04/22/content_75961988.htm">the “New Infrastructure” spending plan </a>that came out of the National Development and Reform Commission, as a response to the COVID-19 pandemic to boost the economy. This infrastructure stimulus plan sits in a larger context of two other long-term strategic plans: Made in China 2025 and China Standards 2035.</p><p>The details of this “New Infrastructure” plan have emerged in the last couple months, with major emphasis in IT and digital infrastructure, not just traditional infrastructure like highways and railroads. As it often happens in China, the signals sent from the top have already shifted private investment dollars. Nascent chip startups, all of a sudden, are <a href="https://uk.reuters.com/article/uk-china-semiconductors-analysis/sino-u-s-tech-race-turbo-charges-china-chip-investment-triggering-bubble-fear-idUKKBN23V3CO">enjoying investor attention and bubbly valuations</a>.</p><p>With that said, here are some of the “New Infrastructure” sectors that I think RISC-V could play an immediate role in, given its strengths:</p><ul><li>IoT</li><li>Smart transportation</li><li>New energy vehicle chargers</li><li>Limited AI (specific workloads that need customized acceleration)</li><li>Autonomous vehicles (limited to certain types of sensors and data collection)</li></ul><p>And as for sectors that I don’t see RISC-V making much of a dent, given its current limitations:</p><ul><li>Cloud computing</li><li>5G (both base station construction and consumer devices)</li><li>Blockchain</li><li>Data centers</li><li>Big data</li><li>Large-scale AI training and production deployment</li></ul><p>As you can see, RISC-V impact would be limited,<strong> but not insignificant</strong>. The logical next step would be for China to help evolve RISC-V <strong>into a more general purpose ISA</strong>, and reduce its reliance on proprietary solutions from ARM or Intel that could always be subjected to more sanctions.</p><p>The path to that end would have to be fostering open source <strong>and doing it the right way.</strong></p><h2 id="fostering-open-source-the-right-way">Fostering Open Source, the Right Way</h2><p>Open source has been popping up in <a href="https://mp.weixin.qq.com/s/Qcze4R-7zL2wjMh_DNVCIQ">a lot of discussions</a> in various Chinese technical and R&amp;D communities, triggered in particular by MATLAB being now off-limit to Chinese universities that are on the U.S. export control entity list. The discussion inevitably leads to open source: are there open source alternatives to MATLAB? What about CAD softwares, like EDA tools, which every chip foundry needs? Will there be an open source EDA option?</p><p>Implicit in these discussions is a predominant “takers” mentality towards open source. In China, open source solutions are mostly seen as “free stuff” that you can take and use, without any expectation or incentive to give back (or in open source parlance: “contribute upstream”).</p><p>It’s already happening in RISC-V. Alibaba <a href="https://www.techspot.com/news/81177-china-alibaba-making-16-core-25-ghz-risc.html">sports the fastest RISC-V based processor to date</a>, but there’s no intention to my knowledge for the design to also be open-sourced or at least publicly shared for the benefit of the ecosystem. Many small startups in China, now showered with new investments, are doing the same -- using RISC-V to make special purpose chips that are effectively proprietary.</p><p><em>(This is not to generalize that all Chinese organizations are bad open source players; some are contributing a lot and have open source in their DNA. I’ve profiled many of the big tech firms and some startups from the lens in Part II of my “</em><a href="https://interconnected.blog/open-source-in-china-the-game/"><em>Open Source in China</em></a><em>” series.)</em></p><p><strong>If</strong> China hopes to evolve RISC-V into a more powerful, general-purpose building block to achieve semiconductor self-reliance, Chinese organizations, both individually and collectively, would have to shift from a zero-sum “takers” mentality to a positive-sum “stakeholders” mentality. What that means in reality is absorbing and practicing the open source way of doing things -- not just contributing code upstream and being more willing to share, but also behaviors like transparent governance, open discussions with other stakeholders and developers, and clear due process for decision-making, big and small. <strong>These are both technical and human complexities.</strong></p><p>With an existential struggle at hand, there’s reason to believe that Chinese companies may behave differently for the sake of achieving a national imperative and be less concerned about the tit-for-tat, zero-sum nature of market competition, which is quite cutthroat in China. And<strong> if done right</strong>, RISC-V could unleash massive technological innovation broadly and help China deal with its existential struggle specifically.</p><h2 id="foundries-smic-hsmc">Foundries: SMIC, HSMC</h2><p>Let’…</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/riscv-china-nightingales/">https://interconnected.blog/riscv-china-nightingales/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/riscv-china-nightingales/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740272</guid>
            <pubDate>Sun, 05 Jul 2020 17:22:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laptop Battery Insights]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23740187">thread link</a>) | @theocs
<br/>
July 5, 2020 | https://blog.cfelde.com/2020/07/laptop-battery-insights/ | <a href="https://web.archive.org/web/*/https://blog.cfelde.com/2020/07/laptop-battery-insights/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p>Back in 2016 I mentioned that I started <a href="https://blog.cfelde.com/2016/01/tracking-my-laptop-battery/">tracking my laptop battery statistics</a> on my then new MBP. Well, now that laptop has reached EOL, with its batteries getting swollen and the fan often running a bit fast, probably due to all the dust inside it.</p>
<p>While I didn’t have any complaints about the overall performance of my trusty old laptop, after 5-6 years of everyday use, I felt it was time to upgrade. And it didn’t feel safe with the batteries swelling either! I might look into refurbishing it, if the cost of new batteries aren’t too ridiculous.</p>
<p>Anyway, as I mentioned in my previous battery blog post, I started logging battery statistics once every half hours, on a simple cron job, with a simple little script.</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2016/01/script-1024x361.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2016/01/script-1024x361.png 1024w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-300x106.png 300w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-768x270.png 768w, https://blog.cfelde.com/wp-content/uploads/2016/01/script-660x232.png 660w, https://blog.cfelde.com/wp-content/uploads/2016/01/script.png 1204w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>So let’s take a look at 5-6 years of data, starting with battery capacity:</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date.png 600w, https://blog.cfelde.com/wp-content/uploads/2020/07/Battery-max-capacity-vs-Date-300x186.png 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>
<p>Got to say that I’m impressed with the overall trend here. I was expecting it to have a stronger downwards trend, considering age and usage, but also compared to the number of hours of use I got when running on batteries. I guess maybe I incorrectly remember how long I initially could run it on batteries when it was new.</p>
<p>What about cycle count then?</p>
<figure><img src="https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date.png" alt="" srcset="https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date.png 600w, https://blog.cfelde.com/wp-content/uploads/2020/07/Usage-hours-acc-vs-Date-300x186.png 300w" sizes="(max-width: 600px) 100vw, 600px"></figure>
<p>Here we see the battery cycle count in red, using the y-axis on the right, together with the accumulated hours of use. As expected these follow each other.</p>
<p>I’ve seen some state that Apple expects a battery to retain 80% of it’s capacity at 1000 cycles. I’m not close to 1000 cycles, but compared to the slow downwards trend on the capacity chart, that’s maybe not unreasonable. However, with the swelling going on, I wouldn’t be comfortable trying to get to 1000 cycles.</p>
<p>I’ve <a href="https://docs.google.com/spreadsheets/d/1HA-T8m78_6uhR_hYgmkW-WktgLQ1JX6ufjH3s_bri-Y/edit?usp=sharing">published all the charts and raw data on Google Sheets</a>, so feel free to look around. The only other chart I considered including was one showing average and median use by day. But, as it turns out, these were rather equal, with a little peak on Tuesdays. These aren’t maybe that insightful anyway, as I often just leave my laptop running.</p>
</div>
</div></div>]]>
            </description>
            <link>https://blog.cfelde.com/2020/07/laptop-battery-insights/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740187</guid>
            <pubDate>Sun, 05 Jul 2020 17:10:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing a Rust web framework]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23740028">thread link</a>) | @LukeMathWalker
<br/>
July 5, 2020 | https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<blockquote>
<p><em>This post was originally meant as a section of <a href="https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/"><strong>Zero To Production</strong></a> to explain the reasoning behind our technology choice. It eventually grew so large to be its own article!</em></p>

<p><em>You can discuss the article on <a href="https://news.ycombinator.com/item?id=23740028">HackerNews</a> or <a href="https://www.reddit.com/r/rust/comments/hlpsw5/choosing_a_rust_web_framework_2020_edition/">r/rust</a></em>.</p>
</blockquote>

<p>As of July 2020, the main web frameworks in the Rust ecosystem are:</p>

<ul>
<li><a href="https://actix.rs/"><code>actix-web</code></a>;<br></li>
<li><a href="https://rocket.rs/"><code>rocket</code></a>;<br></li>
<li><a href="https://github.com/http-rs/tide"><code>tide</code></a>;<br></li>
<li><a href="https://github.com/seanmonstar/warp"><code>warp</code></a>.</li>
</ul>

<p>Which one should you pick if you are about to start building a new <strong>production-ready</strong> API in Rust?</p>

<p>I will break down where each of those web frameworks stands when it comes to:</p>

<ul>
<li><a href="#1-comprehensiveness">Comprehensiveness</a>;<br></li>
<li><a href="#2-community-and-adoption">Community and adoption</a>;<br></li>
<li><a href="#3-sync-vs-async">Sync vs Async</a>, as well as their choice of <a href="#3-1-futures-runtime">futures runtime</a>;<br></li>
<li><a href="#4-documentation-tutorials-and-examples">Documentation, tutorials and examples</a>;<br></li>
<li><a href="#5-api-and-ergonomics">API and ergonomics</a>.</li>
</ul>

<p>I will in the end make <a href="#6-our-choice">my recommendation</a>.<br>
Worth remarking that there are no absolutes: different circumstances (and taste) might lead you to a different pick.</p>

<h2 id="1-comprehensiveness">1. Comprehensiveness</h2>

<p><code>actix-web</code>, <code>tide</code> and <code>warp</code> are <em>slim</em> web frameworks: they offer you an HTTP web server, routing logic, middleware infrastructure and basic building blocks and abstractions to parse, manipulate and respond to HTTP requests.</p>

<p><code>rocket</code> takes a different approach - it aims to be batteries-included: the most common needs should be covered by functionality provided out-of-the-box by <code>rocket</code> itself, with hooks for you to extend <code>rocket</code> if your usecase needs it.<br>
It should not come as a surprise then that <code>rocket</code> ships an easy-to-use <a href="https://rocket.rs/v0.4/guide/state/#databases">integration to manage connection pools</a> for several popular database (e.g. Postgres, Redis, Memcache, etc.) as well as its own <a href="https://rocket.rs/v0.4/guide/configuration/">configuration system</a> in <a href="https://api.rocket.rs/v0.4/rocket_contrib/"><code>rocket-contrib</code></a>, an ancillary crate hosted in <code>rocket</code>’s own repository.</p>

<p>We can compare them to frameworks available in other ecosystems:</p>

<ul>
<li><code>actix-web</code>, <code>tide</code> and <code>warp</code> are closer in spirit to <a href="https://palletsprojects.com/p/flask/"><code>Flask</code></a> from Python or <a href="https://expressjs.com/"><code>Express</code></a> from Javascript - they might be opinionated, but they do not ship a configuration management system or an ORM integration out of the box. You are in charge of structuring your API as you deem appropriate, bringing all the necessary crates and patterns into the picture;<br></li>
<li><code>rocket</code> is closer to <a href="https://www.djangoproject.com/"><code>Django</code></a> from Python or <a href="https://symfony.com/"><code>Symphony</code></a> from PHP: a stable and solid core with a set of high-quality in-tree components to fulfill your every day needs when building a solid web application. <code>rocket</code> has still a long way to go to match its peers in breadth and scope, but it is definitely off to a good start.</li>
</ul>

<p>Of course this is a snapshot of the landscape as of today, but the situation is continuously shifting according to the maintainers’ intentions - e.g. <code>actix-web</code> has slowly been accumulating more and more supporting functionality (from security to session management) in <a href="https://github.com/actix/actix-extras"><code>actix-extras</code></a>, under the umbrella of the <code>actix</code> GitHub organization.<br>
Furthermore, using a slim web framework does not force you to write everything from scratch as soon as the framework is falling short of your needs: you can leverage the ecosystem built by the community around it to avoid re-inventing the wheel on every single project.</p>

<h2 id="2-community-and-adoption">2. Community and adoption</h2>

<p>Numbers can be misleading, but they are a good conversation starting point. Looking at <a href="https://crates.io/">crates.io</a>, we have:</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th>Total Downloads</th>
<th>Daily Downloads</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>actix-web</code></td>
<td>~1250k</td>
<td>~3000</td>
</tr>

<tr>
<td><code>rocket</code></td>
<td>~525k</td>
<td>~1000</td>
</tr>

<tr>
<td><code>warp</code></td>
<td>~435k</td>
<td>~3000</td>
</tr>

<tr>
<td><code>tide</code></td>
<td>~47k</td>
<td>~300</td>
</tr>
</tbody>
</table>

<p>The number of total downloads is obviously influenced by how long a framework has been around (e.g. <code>actix-web:0.1.0</code> came out at the end of 2017!) while daily downloads are a good gauge for the current level of interest around it.</p>

<p>You should care about adoption and community size for a couple of reasons:</p>

<ul>
<li>consistent production usage over years makes it way less likely that you are going to be the first one to spot a major defect. Others cried so that you could smile (most of the time);<br></li>
<li>it correlates with the number of supporting crates for that framework;<br></li>
<li>it correlates with the amount of tutorials, articles and helping hands you are likely to find if you are struggling.</li>
</ul>

<p>The second point is particularly important for slim frameworks.<br>
You can get a feel of the impact of community size, once again, by looking at the number of results popping up on <a href="https://crates.io/">crates.io</a> when searching a framework name:</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th># results</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>rocket</code></td>
<td>178</td>
</tr>

<tr>
<td><code>actix-web</code></td>
<td>113</td>
</tr>

<tr>
<td><code>warp</code></td>
<td>57</td>
</tr>

<tr>
<td><code>tide</code></td>
<td>20</td>
</tr>
</tbody>
</table>

<p>Will all those crates be relevant? Unlikely.<br>
Will a fair share of them be outdated or unproven? Definitely.</p>

<p>Nonetheless it is a good idea, before starting a project, to have a quick look for functionality you know for a fact you will need. Let’s make a couple of quick examples with features we will be relying on in the email newsletter implementation we are building in <em>Zero To Production</em>:</p>

<ul>
<li>if you need to add Prometheus’ metrics to your API you can get off the ground in a couple of minutes with <a href="https://crates.io/crates/actix-web-prom"><code>actix-web-prom</code></a> or <a href="https://crates.io/crates/rocket_prometheus"><code>rocket-prometheus</code></a>, both with thousands of downloads. If you are using <code>warp</code> or <code>tide</code> you will have to write the integration from scratch;<br></li>
<li>if you want to add distributed tracing, <a href="https://crates.io/crates/actix-web-opentelemetry"><code>actix-web-opentelemetry</code></a> has your back. You will have to re-implement it if you choose any other framework.</li>
</ul>

<p>Most of these features are not too much work to implement, but the effort (especially maintenance) compounds over time. You need to choose your framework with your eyes wide open on the level of commitment it is going to require.</p>

<h2 id="3-sync-vs-async">3. Sync vs Async</h2>

<p>Rust landed its <code>async</code>/<code>await</code> syntax in version <code>1.39</code> - a game changer in terms of ergonomics for asynchronous programming.<br>
It took some time for the whole Rust ecosystem to catch up and adopt it, but it’s fair to say that crates dealing with IO-bound workloads are now generally expected to be async-first (e.g. <code>reqwest</code>).</p>

<p>What about web frameworks?<br>
<code>actix-web</code> adopted <code>async</code>/<code>await</code> with its <code>0.2.x</code> release, same as <code>warp</code>, while <code>tide</code> was using <code>async</code>/<code>await</code> before its stabilisation relying on the <code>nightly</code> Rust compiler.<br>
<code>rocket</code>, instead, still exposes a synchronous interface. <code>async</code>/<code>await</code> support is expected as part of its next <code>0.5</code> release, <a href="https://github.com/SergioBenitez/Rocket/issues/1065">in the making since last summer</a>.</p>

<p>Should you rule out <code>rocket</code> as a viable option because it does not yet support asynchronous programming?<br>
It depends.<br>
If you are implementing an application to handle high volumes of traffic with strict performance requirements it might be better to opt for an async web framework.<br>
If that is not the case, the lack of async support in <code>rocket</code> should not be one of your primary concerns.</p>

<h3 id="3-1-futures-runtime">3.1. Futures runtime</h3>

<p><code>async</code>/<code>await</code> is not all sunshine and roses.<br>
Asynchronous programming in Rust is built on top of the <code>Future</code> trait: a future exposes a <code>poll</code> method which has to be called to allow the future to make progress. You can think of Rust’s futures as <em>lazy</em>: unless polled, there is no guarantee that they will execute to completion.<br>
This is often been described as a <em>pull</em> model compared to the <em>push</em> model adopted by other languages<sup id="fnref:async-announcement"><a href="#fn:async-announcement">1</a></sup>, which has some interesting implications when it comes to performance and task cancellation.</p>

<p>Wait a moment though - if futures are lazy and Rust does not ship a runtime in its standard library, who is in charge to call the <code>poll</code> method?<br>
<strong>BYOR</strong> - <strong>B</strong>ring <strong>Y</strong>our <strong>O</strong>wn <strong>R</strong>untime!<br>
The async runtime is literally a dependency of your project, brought in as a crate.<br>
This provides you with a great deal of flexibility: you could indeed implement your own runtime optimised to cater for the specific requirements of your usecase (see <a href="http://smallcultfollowing.com/babysteps/blog/2019/12/09/async-interview-2-cramertj/#async-interview-2-cramertj">the Fuchsia project</a> or <a href="https://github.com/bastion-rs/bastion"><code>bastion</code></a>’s actor framework) or simply choose the most suitable on a case-by-case basis according to the needs of your application.<br>
That sounds amazing on paper, but reality is a bit less glamorous: interoperability between runtimes is quite poor at the moment; mixing runtimes can be painful, often causing issues that are not straight-forward either to triage, detect or solve.<br>
While most libraries should not depend on runtimes directly, relying instead on the interfaces exposed by the <a href="https://docs.rs/futures/0.3.5/futures/"><code>futures</code></a> crate, this is often not the case due to historical baggage (e.g. <code>tokio</code> was for a long time the only available runtime in the ecosystem), practical needs (e.g. a framework has to be able to spawn tasks) or lack of standardisation (e.g. the ongoing discussion on the <code>AsyncRead</code>/<code>AsyncWrite</code> traits - see <a href="http://smallcultfollowing.com/babysteps/blog/2020/01/20/async-interview-5-steven-fackler/">here</a> and <a href="http://smallcultfollowing.com/babysteps/blog/2020/03/10/async-interview-7-withoutboats/#async-interview-7-withoutboats">here</a>).<br>
Therefore picking an async web framework goes beyond the framework itself: you are choosing an ecosystem of crates, suddenly making it much more cumbersome to consume libraries relying on a different async runtime.</p>

<p>The current state of affairs is far from ideal, but if you are writing async Rust today I’d recommend you to make a <em>deliberate</em> choice when it comes to your async runtime.</p>

<p>The two main general-purpose async runtimes currently available in Rust are <a href="https://tokio.rs/"><code>tokio</code></a> and <a href="https://github.com/async-rs/async-std"><code>async-std</code></a>.<br>
<code>tokio</code> has been around for quite some time and it has seen extensive production usage. It is fairly tunable, although this results in a larger and more complex API surface.<br>
<code>async-std</code> was released almost a year ago, around the time of <code>async</code>/<code>await</code> stabilization. It provides great ergonomics, while leaving less room for configuration knobs.</p>

<p><a href="https://crates.io/">crates.io</a> can once again be used as a gauge for adoption and readiness:</p>

<table>
<thead>
<tr>
<th>Runtime</th>
<th>Total Downloads</th>
<th>Daily Downloads</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>tokio</code></td>
<td>~9600k</td>
<td>~30k</td>
</tr>

<tr>
<td><code>async-std</code></td>
<td>~600k</td>
<td>~4k</td>
</tr>
</tbody>
</table>

<p>How do frameworks map to runtimes?</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th>Runtime</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>actix-web</code></td>
<td><code>tokio</code></td>
</tr>

<tr>
<td><code>rocket</code> (<code>0.5.x</code>)</td>
<td><code>tokio</code></td>
</tr>

<tr>
<td><code>tide</code></td>
<td><code>async-std</code></td>
</tr>

<tr>
<td><code>warp</code></td>
<td><code>tokio</code></td>
</tr>
</tbody>
</table>

<h2 id="4-documentation-tutorials-and-examples">4. Documentation, tutorials and examples</h2>

<p>Having to dive into the source code to understand how something works can be fun (and educational!), but it should be a choice, not a necessity.<br>
In most situations I’d rather rely on the framework being well-documented, including non-trivial examples of relevant usage patterns.<br>
Good documentation, tutorials and fully-featured examples are <strong>mission-critical</strong> if you are working as part of a team, especially if one or more teammates are not experienced Rust developers.</p>

<p>Rust’s tooling treats documentation as a first class concept (just run <code>cargo doc --open</code> to get auto-generated docs for your project!) and it grew to be part of the culture of the Rust community itself. Library authors generally take it seriously and web frameworks are no exception to the general tendency: what you can find on <a href="https://docs.rs/">docs.rs</a> is quite thorough, with contextual examples …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/">https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740028</guid>
            <pubDate>Sun, 05 Jul 2020 16:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Pandas: Comparing Dask, Ray, Modin, Vaex, and Rapids]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 33 (<a href="https://news.ycombinator.com/item?id=23740012">thread link</a>) | @FHMS
<br/>
July 5, 2020 | https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Python and its most popular data wrangling library, Pandas, are soaring in popularity. Compared to competitors like Java, Python and Pandas make data exploration and transformation <strong>simple</strong>.</p><p>But both Python and Pandas are known to have issues around <strong>scalability</strong> and <strong>efficiency</strong>.</p><p>Python loses some efficiency right off the bat because it’s an interpreted, dynamically typed language. But more importantly, Python has always focused on simplicity and readability over raw power. Similarly, Pandas focuses on offering a simple, high-level API, largely ignoring performance. In fact, the creator of Pandas wrote “<a href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">The 10 things I hate about pandas</a>,” which summarizes these issues:</p><figure id="w-node-412b9aecdea3-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62e9007b2509635bd1ba2_image3.png" alt="Ten things Wes McKinney hates about Pandas."></p><figcaption>Performance issues and lack of flexibility are the main things Pandas’ own creator doesn’t like about the library. (<a href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">source</a>)</figcaption></figure><p>So it’s no surprise that many developers are trying to add more power to Python and Pandas in various ways. Some of the most notable projects are:</p><ul role="list"><li><a href="https://www.datarevenue.com/ml-tools/dask"><strong>Dask</strong></a><strong>:</strong> a low-level scheduler and a high-level partial Pandas replacement, geared toward running code on compute clusters.</li><li><strong>Ray:</strong> a low-level framework for parallelizing Python code across processors or clusters.</li><li><a href="https://www.datarevenue.com/ml-tools/modin"><strong>Modin</strong></a><strong>:</strong> a drop-in replacement for Pandas, powered by either <strong>Dask</strong> or <strong>Ray</strong>.</li><li><a href="https://www.datarevenue.com/ml-tools/vaex"><strong>Vaex</strong></a><strong>:</strong> a partial Pandas replacement that uses lazy evaluation and memory mapping to allow developers to work with large datasets on standard machines.</li><li><a href="https://www.datarevenue.com/ml-tools/rapids"><strong>RAPIDS</strong></a><strong>: </strong>a collection of data-science libraries that run on GPUs and include <a href="https://github.com/rapidsai/cudf">cuDF</a>, a partial replacement for Pandas.</li></ul><p>There are others, too. Below is an overview of the Python data wrangling landscape:</p><figure id="w-node-78c43e6cecae-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62eb85c7038610cea20d0_image2.png" alt="A graph showing how often popular data wrangling libraries are compared in Google searches."></p><figcaption>Dask, Modin, Vaex, Ray, and CuDF are often considered potential alternatives to each other. Source: Created with <a href="https://anvaka.github.io/vs/?query=Dask">this tool</a></figcaption></figure><p>So if you’re working with a lot of data and need faster results, which should you use?</p><h2><strong>Just tell me which one to try</strong></h2><p>Before you can make a decision about which tool to use, it’s good to have some more context about each of their approaches. We’ll compare each of them closely, but you’ll probably want to try them out in the following order:</p><ul role="list"><li><strong>Modin</strong>, with <strong>Ray</strong> as a backend. By installing these, you might see significant benefit by changing just a single line (`import pandas as pd` to `import modin.pandas as pd`). Unlike the other tools, Modin aims to reach full compatibility with Pandas.</li><li><strong>Dask</strong>,<strong> </strong>a larger and hence more complicated project. But Dask also provides <a href="https://docs.dask.org/en/latest/dataframe.html">Dask.dataframe</a>, a higher-level, Pandas-like library that can help you deal with <a href="https://en.wikipedia.org/wiki/External_memory_algorithm">out-of-core</a> datasets.</li><li><strong>Vaex, </strong>which is designed to help you work with large data on a standard laptop. Its Pandas replacement covers some of the Pandas API, but it’s more focused on exploration and visualization.</li><li><strong>RAPIDS, </strong>if you have access to NVIDIA graphics cards<strong>.</strong></li></ul><h2><strong>Quick comparison</strong></h2><p>Each of the libraries we examine has different strengths, weaknesses, and scaling strategies. The following table gives a broad overview of these. Of course, as with many things, most of the scores below are heavily dependent on your exact situation.&nbsp;</p><figure id="w-node-3fc1cb6579be-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62ef85090a97b0c469fa9_image5.png" alt="A table comparing the tools across maturity, popularity, ease of adoption, and other metrics."></p><figcaption>Dask and Ray are more mature, but Modin and Vaex are easier to get started with. Rapids is useful if you have access to GPUs.</figcaption></figure><p>These are subjective grades, and they may vary widely given your specific circumstances. When assigning these grades, we considered:</p><ul role="list"><li><strong>Maturity: </strong>The time since the first commit and the number of commits.</li><li><strong>Popularity: </strong>The number of GitHub stars.</li><li><strong>Ease of Adoption: </strong>The amount of knowledge expected from users, presumed hardware resources, and ease of installation.</li><li><strong>Scaling ability: </strong>The broad dataset size limits for each tool, depending on whether it relies mainly on RAM, hard drive space on a single machine, or can scale up to clusters of machines.&nbsp;</li><li><strong>Use case: </strong>Whether the libraries are designed to speed up Python software in general (“<strong>General</strong>”), are focused on data science and machine learning (“<strong>Data science</strong>”), or are limited to simply replacing Pandas’ ‘DataFrame’ functionality (“<strong>DataFrame</strong>”).</li></ul><h2><strong>CPUs, GPUs, Clusters, or Algorithms?</strong></h2><p>If your dataset is too large to work with efficiently on a single machine, your main options are to run your code across…</p><ul role="list"><li><strong>...multiple threads or processors:</strong> Modern CPUs have several independent cores, and each core can run many threads. Ensuring that your program uses all the potential processing power by parallelizing across cores is often the easiest place to start.</li><li><strong>...GPU cores: </strong>Graphics cards were originally designed to efficiently carry out basic operations on millions of pixels in parallel. However, developers soon saw other uses for this power, and “GP-GPU” (general processing on a graphics processing unit) is now a popular way to speed up code that relies heavily on matrix manipulations.</li><li><strong>...compute clusters: </strong>Once you hit the limits of a single machine, you need a networked cluster of machines, working cooperatively.</li></ul><p>Apart from adding more hardware resources, clever algorithms can also improve efficiency. Tools like Vaex rely heavily on <a href="https://en.wikipedia.org/wiki/Lazy_evaluation"><strong>lazy evaluation</strong></a><strong> </strong>(not doing any computation until it’s certain the results are needed) and <a href="https://en.wikipedia.org/wiki/Memory-mapped_file"><strong>memory mapping</strong></a><strong> </strong>(treating files on hard drives as if they were loaded into RAM).</p><p>None of these strategies is inherently better than the others, and you should choose the one that suits your specific problem.</p><p>Parallel programming (no matter whether you’re using threads, CPU cores, GPUs, or clusters) offers many benefits, but it’s also quite complex, and it makes tasks such as debugging far more difficult.</p><p>Modern libraries can hide some – but not all – of this added complexity. No matter which tools you use, you’ll run the risk of expecting everything to work out neatly (below left), but getting chaos instead (below right).</p><figure id="w-node-7b8872b99c95-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5efef852495a4ce0972910e9_image4_s.jpg" alt="Puppies in a row eating food from different bowls – and then chaos ensues."></p><figcaption>Parallel processing doesn’t always work out as neatly as you expect. (<a href="https://www.reddit.com/r/aww/comments/2oagj8/multithreaded_programming_theory_and_practice/">Source</a>)</figcaption></figure><h2><strong>Dask vs. Ray vs. Modin vs. Vaex vs. RAPIDS</strong></h2><p>While not all of these libraries are direct alternatives to each other, it’s useful to compare them each head-to-head when deciding which one(s) to use for a project.</p><p>Before getting into the details, note that:</p><ul role="list"><li>RAPIDS is a collection of libraries. For this comparison, we consider only the <strong>cuDF</strong> component, which is the RAPIDS equivalent of Pandas.</li><li>Dask is better thought of as two projects: a low-level Python scheduler (similar in some ways to Ray) and a higher-level Dataframe module (similar in many ways to Pandas).</li></ul><h3><strong>Dask vs. Ray</strong></h3><p>Dask (as a lower-level scheduler) and Ray overlap quite a bit in their goal of making it easier to execute Python code in parallel across clusters of machines. Dask focuses more on the data science world, providing higher-level APIs that in turn provide partial replacements for Pandas, NumPy, and scikit-learn, in addition to a low-level scheduling and cluster management framework.</p><p>The creators of Dask and Ray discuss how the libraries compare in <a href="https://github.com/ray-project/ray/issues/642">this GitHub thread</a>, and they conclude that the scheduling strategy is one of the key differentiators. Dask uses a centralized scheduler to share work across multiple cores, while Ray uses distributed bottom-up scheduling.</p><h3><strong>Dask vs. Modin</strong></h3><p>Dask (the higher-level Dataframe) acknowledges the limitations of the Pandas API, and while it partially emulates this for familiarity, it doesn’t aim for full Pandas compatibility. If you have complicated existing Pandas code, it’s unlikely that you can simply switch out Pandas for Dask.Dataframe and have everything work as expected. By contrast, this is exactly the goal Modin is working toward: 100% coverage of Pandas. Modin can run on top of Dask but was originally built to work with Ray, and that integration remains more mature.</p><h3><strong>Dask vs. Vaex</strong></h3><p>Dask (Dataframe) is not fully compatible with Pandas, but it’s pretty close. These close ties mean that Dask also carries some of the baggage inherent to Pandas. Vaex deviates more from Pandas (although for basic operations, like reading data and computing summary statistics, it’s very similar) and therefore is also less constrained by it.</p><p>Ultimately, Dask is more focused on letting you scale your code to compute clusters, while Vaex makes it easier to work with large datasets on a single machine. Vaex also provides features to help you easily visualize and plot large datasets, while Dask focuses more on data processing and wrangling.</p><h3><strong>Dask vs. RAPIDS (cuDF)</strong></h3><p>Dask and RAPIDS play nicely together via an integration <a href="https://rapids.ai/dask.html">provided by</a> RAPIDS. If you have a compute cluster, you should use Dask. If you have an NVIDIA graphics card, you should use RAPIDS. If you have a compute cluster of NVIDIA GPUs, you should use both.</p><h3><strong>Ray vs. Modin or Vaex or RAPIDS</strong></h3><p>It’s not that meaningful to compare Ray to Modin, Vaex, or RAPIDS. Unlike the other libraries, Ray doesn’t offer high-level APIs or a Pandas equivalent. Instead, Ray powers Modin and <a href="https://docs.ray.io/en/latest/tune.html">integrates with RAPIDS</a> in a similar way to Dask.</p><h3><strong>Modin vs. Vaex</strong></h3><p>As with the Dask and Vaex comparison, Modin’s goal is to provide a full Pandas replacement, while Vaex deviates more from Pandas. Modin should be your first port of call if you’re looking for a quick way to speed up existing Pandas code, while Vaex is more likely to be interesting for new projects or specific use cases (especially visualizing large datasets on a single machine).</p><h3><strong>Modin vs. RAPIDS (cuDF)</strong></h3><p>Modin scales Pandas code by using many CPU cores, via Ray or Dask. RAPIDS scales Pandas code by running it on GPUs. If you have GPUs available, give RAPIDS a try. But the easiest win is likely to come from Modin, and you should probably turn to RAPIDS only after you’ve tried Modin first.</p><h3><strong>Vaex vs. RAPIDS (cuDF)</strong></h3><p>Vaex and RAPIDS are similar in that they can both provide performance boosts on a single machine: Vaex by better utilizing your computer’s hard drive and processor cores, and RAPIDS by using your computer’s GPU (if it’s available and compatible). The RAPIDS project as a whole aims to be much broader than Vaex, letting you do machine learning end-to-end without the data leaving your GPU. Vaex is better for prototyping and data exploration, letting you explore large datasets on consumer-grade machines.</p><h2><strong>Final remarks: Premature optimization is the root of all evil</strong></h2><p>It’s fun to play with new, specialized tools. That said, many …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray">https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740012</guid>
            <pubDate>Sun, 05 Jul 2020 16:47:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3DChan V2, a 3D Imageboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23739898">thread link</a>) | @alexkrunch
<br/>
July 5, 2020 | https://3dchan.net/v3/ | <a href="https://web.archive.org/web/*/https://3dchan.net/v3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://3dchan.net/v3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739898</guid>
            <pubDate>Sun, 05 Jul 2020 16:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Play Hex against our RL agent]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739873">thread link</a>) | @natufunu
<br/>
July 5, 2020 | https://cleeff.github.io/hex | <a href="https://web.archive.org/web/*/https://cleeff.github.io/hex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cleeff.github.io/hex</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739873</guid>
            <pubDate>Sun, 05 Jul 2020 16:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installment Subscription]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739829">thread link</a>) | @mikeberv
<br/>
July 5, 2020 | https://www.billiondollarstartupideas.com/ideas/installment-subscription | <a href="https://web.archive.org/web/*/https://www.billiondollarstartupideas.com/ideas/installment-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1593965992303" id="item-5f01f8bcc7077935484de88c"><div><div><div data-block-type="2" id="block-68653710b4fd3b7e6d4e"><div><p><strong>Problem: </strong>When you subscribe to something, you don’t built any equity or ownership. As soon as you cancel your subscription, you lose access to whatever you used to have. This phenomenon also happens with rent.</p><p><strong>Solution: </strong>A platform that specializes in creating financial instruments focused on the intersection of monthly subscriptions &amp; marginal cost to own. For example, Disney recently released Hamilton on Disney+ (<a href="https://www.theverge.com/2020/5/12/21255693/hamilton-musical-disney-plus-early-release-date-streaming-broadway-miranda">over a year early, too</a>) and is requiring that people subscribe to Disney+ in order to access it. What if, in addition, Disney allowed people to download the video and own it at a marginal cost, like an additional $0.99 or $4.99? Since subscriptions are often in the back of consumers’ minds (they only pay once a year or once a month) it’s much easier to sell add-ons to consumers once they are already on a subscription service.</p><p>This business would take a model that is already proven in gaming (in-game purchases) to generate new revenue sources for subscription companies. This model is extremely successful in gaming (<a href="https://www.gamesindustry.biz/articles/2018-06-27-69-percent-of-fortnite-players-have-bought-in-game-purchases-average-spend-is-usd85">69% of Fortnite players have bought in-game purchases and the average spend is $85</a>, netting <a href="https://www.businessinsider.com/how-much-money-does-fortnite-make-2019-1#:~:text=More%20specifically%3A%20%22Fortnite%22%20made,revenue%20numbers%20for%20%22Fortnite.%22">over $2.5 billion annually</a>), but has not been applied in other contexts. In their article on how the “<a href="https://www.theinformation.com/articles/pandemic-forces-studios-to-think-outside-the-box-on-movie-releases?utm_campaign=article_email&amp;utm_content=article-4411&amp;utm_medium=email&amp;utm_source=sg">Pandemic Forces Studios to Think Outside the Box on Movie Releases</a>,” <a href="https://www.theinformation.com/reporters/jessica-toonkel">Jessica Toonkel</a> and <a href="https://www.theinformation.com/reporters/tom-dotan">Tom Dotan</a> describe the pros and cons of a similar rent-to-buy option:</p><blockquote><p><strong>Introduce a rent-to-buy option.</strong>&nbsp;Give consumers the option, once they have rented a movie, to pay a little extra to own the film.&nbsp;</p><p><strong>Pros:</strong>&nbsp;This could drive more purchases of movies, as people would only fork over the extra money once they know they’ll like it enough to watch it again.&nbsp;</p><p><strong>Cons</strong>: Such an approach would only work for certain kinds of films, particularly children’s movies that kids are likely to watch repeatedly.</p></blockquote><p>This would be an innovation on the subscription-as-a-service and general subscription-based business models that have been extremely popular given the democratization of the internet.</p><p><strong>Monetization: </strong>Selling installment subscriptions as a service, or building a platform that takes a percentage of revenues to create these unique installment subscriptions.</p><p><strong>Contributed by: </strong><a href="https://www.michaelbervell.com/">Michael Bervell</a> (Billion Dollar Startup Ideas)</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.billiondollarstartupideas.com/ideas/installment-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739829</guid>
            <pubDate>Sun, 05 Jul 2020 16:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Here Is What You Need To Know Before Learning Code. Bookmark This Guide]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23739809">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			
<p>Before starting out, I’d like to take a minute to thank you for reading &amp; sharing my last article<span>&nbsp;</span><em><a href="https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/">“You Need To Know These 7 Traps That Make Your Software Useless”</a></em></p>
<p>Since we have numerous new members joining the club, feel free to send me your requests, topics, comments, advice, and I’ll make sure to reply to each one of your emails!</p>
<p>Without further ado, let’s dive in.</p>
<p>Learning how to code can be daunting, the progress is slow, the concepts are unique, and the positive feedback loop that will keep you motivated is hard to maintain. Countless are the articles that tell you should learn some framework X because it’s the future or master a language Y because it’s robust. Personally, I wouldn’t have learned multiple stacks (Deep learning, iOS dev, Android dev, Game dev, Cloud services) had I found the right source to guide me. And this is what I wished I had known:</p>
<p>Before choosing what programming language/framework to learn, let’s establish these first principles:</p>
<h3><strong>Programming is an investment&nbsp;</strong></h3>
<p>Learning programming and taking it to the next level are two different things, this is what you’ll be working with for years to come, the market is competitive but you definitely have a spot – if you work hard+smart enough. You don’t need to be a genius but willing to sit down and work. Had I told anyone I wanted to learn deep learning when I was still a freshman with 0 experience in coding, they’d have laughed their life off.</p>
<p>When you pick a programming language, you’ll start building “assets”. Think of assets as utilities that help you in video games. The harder the level, the more you need them to win fast. Typically, after 2 or 3 side projects, you’ll be having a folder full of code snippets that will save you hours! (I’m constantly taking code from projects I’ve finished 3 years ago)</p>
<p>No, you don’t need to stick with your programming language and you can always bounce off to something else. That might sound counter-intuitive, but at least before switching, you’ll have an important cognitive asset:</p>
<ul>
<li>The ability to make complex decisions fast.</li>
<li>Knowing how to learn the new programming language/framework faster &amp; more reliably</li>
<li>Apply the same general concepts onto the new PL</li>
</ul>
<p>However, I don’t recommend switching areas frequently unless you have a valid technical reason for doing so.</p>
<h3><strong>You can’t skip the basics</strong></h3>
<p>Not fun to hear, I’m fully aware. But learning the basics is your first step into programming. Here, you build your tools, learn facts, and polish your skills. Many people struggle with this phase, and when stuck, they think programming isn’t for them.</p>
<p>Think of this step as learning how to reason in sequence. The human brain is a supercomputer on steroids, 1 + 1 appears trivial since you are looking at an equation from a top view. However, the machine only gets to look at 1 operand at a time, so you have to declare your intentions first then tell it what to do with your intentions.</p>
<p>Finally, you elevate your reasoning by solving a real-world problem using an algorithm (a set of instructions).</p>
<p>Again, it doesn’t have to be daunting or scary, as I always say, take an hour or two a day and learn at your own pace. Don’t compare with others because chances are you’ll feel overtaken. And there is no room for intelligence or stupidity in learning code. Only actions and results.</p>
<p>To close off this first part, I invite you to experiment and try whatever works for you. This isn’t the absolute rule on how to learn how to code. If the analogies aren’t that practical for you then great! set your own. If my logic is flawed, then also great, rethink yours! It’s always great to experiment.</p>
<p>Now let’s get you started with choosing the right platform, here is what you should know:</p>
<h2><strong>Gaming<span>&nbsp;</span></strong></h2>
<ul>
<li>Unity is your friend. I still remember the day I decided to make games and become a game dev. The language is C# and unbelievably easy to learn.</li>
<li>Some people prefer using Xcode, but the software is platform restricted, and from my experience, I found it a thousand times easier to learn game dev on Unity than Xcode</li>
<li>The game engine (Unity) does the heavy lifting, you tell the objects to move by a given speed and whether they can collide or not, and there you go, the embedded physics kick in</li>
<li>You’ll have a huge boost by learning design using Blender (An open-source software for design and animation) or similar. Nevertheless, it’s not required, but there will be instances when you wish you’d known how to design</li>
<li>You can compile your game for whatever platform! (Desktop, consoles, web, mobile, etc..) Check out<span>&nbsp;</span><a href="https://unity.com/features/multiplatform">this link</a><span>&nbsp;</span>for more info</li>
<li>The industry is competitive and requires a lot of discipline since you’ll be working long hours. Some like it some don’t, it’s up to you to decide</li>
<li>You are restricted a bit in terms of employment. There are only as many game dev companies out there, and if you don’t like the domain anymore, you’ll need to learn another skill instead of reusing what you already know</li>
<li>Game physics are annoying sometimes, however, the more you learn, the easier it gets – Classic debugging scenario. Game dev is inherently time-consuming given the small details to address. Also, often you’ll get unwanted guests: Bugs. The combinations of physics are near unlimited, sometimes you’ll find yourself debugging for 5 hours a small bug that you simply can’t fix. In this scenario, you can get help from someone you know or revert back to online forums.</li>
<li>No, you won’t make “easy” money with game development. It will take a bit of time to learn how to make smooth, flawless mechanics. So if you are doing it for the money only, maybe you want to save yourself the frustration.</li>
<li>If you are doing it by passion, by no means try it out! you’ll have so much fun creating weird games. Let your imagination go wild, it only gets better from there!</li>
</ul>
<h2><strong>Competitive Programming</strong></h2>
<ul>
<li>Simply practice and resilience: Back in freshman year, I decided to dive into competitive programming. It sounded nerdy and cool. I finished the “cracking the coding interview” by Google. Which contains 150 programming interview questions. I noticed slight progress given the giant amount of work I had to endure for a full summer.</li>
<li>If you want to make money through this, you sure love making money the hard way, but it’s doable. Nevertheless, this is a great way to get into big techs if you rank top in programming contests.</li>
<li>You only remember as much as you practice. The hidden trump card about Competitive programming isn’t the difficulty of the problems but how prepared are you. You don’t have to remember how you solved a problem but where you missed. If you stop practicing, you’ll feel you lost that ‘cognitive prowess’ that helped you draw links between multiple parts of the question.</li>
<li>More often than not, the standard programming language is C++. Python is on the rise too.</li>
</ul>
<h2><strong>Mobile Development</strong></h2>
<ul>
<li>Android or iOS, it’s up to you to choose. I prefer coding for iOS (Swift) because it feels much cleaner. Back in Android (Java/Kotlin), I had to deal with preliminary problems like fixing “Gradle” after an update to just get the project going. Also, I felt that Android was a bit messy to code for in a native language. So I switched to iOS.</li>
<li>iOS is more restricted, you need to pay $100/year for the Apple Developer Program. Also, you need the membership if you want to include advanced features in your app such as Deep Links, notifications, background activity, etc…</li>
<li>Android on the other side, you pay $25 for a<span>&nbsp;</span><strong>lifetime.</strong><span>&nbsp;</span>You submit as many apps as you want, and no one is restricting you in any way. You have a wide audience of developers and potential users waiting for your app. But on the other side, you are competing with more people.</li>
<li>Why not both? Use a framework! I learned both Android &amp; iOS dev and now I’m switching completely to Flutter (more on this in the last paragraph). Using a framework helps with coding for multiple platforms using the same code base. You don’t want to do double the work, and maintaining just 1 app needs<span>&nbsp;</span><strong>many!<span>&nbsp;</span></strong>people. It’s not a matter of “competency” but resources. If I judge by my skills, I don’t need anyone technical on my team, but often than not, I need many people to help me out because there are many small details to take care of.</li>
<li>App developers have a favorable edge in the job market. Mobile users are on the rise. According to BankMyCell, 3.5B people are using their smartphone and it’s only been growing to date</li>
<li>Career-wise, you can work anywhere from the comfort of your home. Also, you ‘ll progress quite fast if you know what you’re doing. Salaries are on the rise too, and the benefits are staggering. Finally, you’re not limited to some predefined companies, you can work for startups, freelance, build your own project, and so on.</li>
<li>This area is getting more &amp; more competitive, and there is a slight switch that is happening, which is the move to software development kits (aka Flutter, React native, etc…). Instead of paying a full-stack mobile dev to write code for 1 platform only, you can have the same code base work for multiple platforms.</li>
</ul>
<h2><strong>Web Development</strong></h2>
<ul>
<li>Web dev is in some serious demand as well. Here you don’t have a predefined programming language because you can literally combine multiple ones, for example: Html + CSS + JS. I never wanted to learn web dev because of javascript. Spaghetti language (sorry!) Also the idea of learning multiple languages to do 1 thing never made sense to me. However, in your case, this isn’t a problem anymore. If you are passionate about creating websites or Web apps, you can go for frameworks such as React Js or Flutter (in Beta). And you’re sorted for life.</li>
<li>No, you don’t need to worry about the “no-code tools” and the “website builders”. These can only help as much. If you want to focus on the backend (servers, technical logic, business logic, etc…) you are in a much better position given that each use case is different. And for a no-code tool to handle that, it’s pretty unreasonable.</li>
<li>Web Development is a dimension in itself. I’m not a web developer and don’t want to snap off someone …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/">https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/</a></em></p>]]>
            </description>
            <link>https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739809</guid>
            <pubDate>Sun, 05 Jul 2020 16:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bug in Wireshark can be exploited by hackers for Denial of Service(DoS) attack]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739708">thread link</a>) | @vvpvijay
<br/>
July 5, 2020 | https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8459"><div><div><div><h2>A flaw in network pentesting tool Wireshark allows hackers to remotely launch Denial of Service (DoS) and make CPU consume more resources</h2><p>If you are a hacker or a security researcher, you have probably used Wireshark. Wireshark is the world’s most popular network protocol analyzer. The software is free and open-source. <a href="https://www.wireshark.org/security/wnpa-sec-2020-09.html">Security researchers</a> have found a new vulnerability in the popular network sniffing tool. This vulnerability has been given the unique identifier <strong><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-15466">CVE-2020-15466</a> and has a severity score of 5.7/10. </strong>The vulnerability could be exploited remotely by potential hackers to make the victim’s PC and CPU consume more resources and launch a denial of service (DoS) attack.</p><p><a href="https://androidrookies.com/the-complete-wireshark-cheat-sheet-to-live-sniff-network-traffic/" target="_blank"><span>The complete Wireshark cheat sheet to live-sniff network traffic</span></a></p><p>The vulnerability in Wireshark versions 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4 exists due to an infinite loop within the GVCP dissector, allowing remote threat actors to deploy DoS attacks. A malicious hacker can pass a specially designed package tracking file to the vulnerable application, which will consume all system resources, leading to the DoS condition.</p><p>The report says that thought this Wireshark vulnerability can be exploited remotely by hackers, they have not found any evidence of it being exploited in the wild. Security researchers have also not found any malware variants authored to take advantage of the GVCP dissector infinite loop in Wireshark.</p><p>The <a href="https://bugs.wireshark.org/bugzilla/show_bug.cgi?id=16029">Wireshark developers</a> have already fixed the issue and have requested all the Wireshark users to update to the patched Wireshark version 3.2.5 which is available below:</p><div id="dl_box"><div id="accordion_download"><p>Wireshark developers have noted that there is no workaround for this particular vulnerability and Wireshark users have to to download the Wireshark version 3.2.5 to mitigate the risk of exploitation.</p></div></div></div></div></div></article><div><h3>About Author</h3><section> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20100%20100'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=100&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><div> <p>Hacker, coder, Jouno by night
When a good man is hurt, all who would be called good must suffer with him</p></div></section></div></div>]]>
            </description>
            <link>https://androidrookies.com/bug-in-wireshark-can-be-exploited-by-hackers-for-denial-of-servicedos-attack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739708</guid>
            <pubDate>Sun, 05 Jul 2020 16:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oops, I Wrote a C++ Compiler/Interpreter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739677">thread link</a>) | @pcr910303
<br/>
July 5, 2020 | https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html | <a href="https://web.archive.org/web/*/https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><strong>TL;DR</strong> I wrote a .NET library that can compile C/C++ code into
a byte code that it can also interpret. It is used in my
app <a href="http://icircuitapp.com/">iCircuit</a> to simulate Arduinos.
You can use it yourself with the nuget package <a href="https://www.fuget.org/packages/CLanguage">CLanguage</a>.</p>

<p><img src="https://praeclarum.org/images/2018/cdemo.gif" alt="Arduino code being edited in iCircuit"></p>

<h2 id="arduino-support-for-icircuit">Arduino Support for iCircuit</h2>

<p>The most requested feature for iCircuit, for years, has
been to support Arduino components.
I agreed with all my users that it would be an amazing
feature, but it was also a pretty big request that I wasn’t
sure I could complete.</p>

<p>I could easily add a component that <em>looked</em> like an Arduino -
had all the right pins, maybe even blinked an LED. However,
what people really wanted was a <em>programmable</em> Arduino
integrated into the circuit simulator.</p>

<p>Arduinos are programmed in C++ with a small base library known
as “Wiring”. Therefore, in order to simulate an Arduino, I
needed a C/C++ compiler and I needed to re-implement Wiring. Oh, and that compiler needs to
run on iOS, integrate into my circuit simulation, handle
bad code such as infinite loops and bad pointers, 
work within the sandbox (which means interpretation instead
of real execution), and it has to run on 4 platforms (iOS, Mac, Android, Windows).</p>

<p>Like I said, it was a big request! As tough as all that sounds,
I still personally wanted the feature and decided to find a way
to make it happen. Way back in 2010, I started work.</p>

<p>I first looked around for small C++ compilers and
interpreters that I could
get to work on iOS, Android, and Windows (iCircuit runs everywhere).
Sadly, the research was grim as no compiler
met all my requirements. Some would be nice and small but
only emit X86 code meaning I would have to write an X86 simulator. Others were so big and had so many dependencies
that I just gave up trying to get it to compile for iOS.</p>

<p>Fortunately in 2010, I was full of hubris and I figured now was the time in my life to write a C++ compiler. Oh how foolish…</p>

<h2 id="the-halcyon-days-of-2010">The Halcyon Days of 2010</h2>

<p>Compilers and Interpreters are, in principle, very simple
programs. I’d written a bunch of interpreters at this point
in my career and even wrote a couple simple compilers for very
small languages. I knew that C++ was a complex language, at
least syntactically (with all its type declarations) but that
its semantics - its model of computation - was rather basic.
I considered myself a good C++ programmer and thought I knew
the language inside and out. How hard could it be?</p>

<p>Like I said, hubris.</p>

<p>And so I embarked on writing my C++ compiler in C#
(the language iCircuit is written in).
I started by writing a C compiler because C++ is a monster of a
language. Most Arduino programs only use C features (I thought),
so it seemed like a reasonable starting point.</p>

<h3 id="writing-the-parser">Writing the Parser</h3>

<p>C is nice because you can actually parse it using
a <em>grammar definition</em> - a file that states the syntax of
the language. Grammars are great because you can use a code
generator to automatically create a parser for your language from this 
definition. This means you can focus on the semantics of
the language and let the parser generator deal with the syntax.</p>

<p>Back in 1985 someone posted a <a href="https://www.lysator.liu.se/c/ANSI-C-grammar-y.html">YACC grammar definition for C</a>
which served as my starting point.
I then used the <a href="https://www.cs.rit.edu/~ats/projects/lp/doc/jay/package-summary.html">jay parser generator</a> (the same tools used to generate the mono C# parser)
as my parser generator. This tool takes the grammar definition
and spits out nasty C# code to parse files. The
code is nasty because it’s fast and eschews standard coding
conventions for performance. I love it.</p>

<p>The process of creating the parser went very smoothly thanks
to this. The real work involves creating C# syntax classes
that mirror the grammar. These classes form the Abstract
Syntax Tree (AST) of the compiler. You can see the results
of this work by <a href="https://github.com/praeclarum/CLanguage/blob/master/CLanguage/Parser/CParser.jay">looking at my modified grammar</a>.</p>

<p>I ended up writing a <a href="https://github.com/praeclarum/CLanguage/tree/master/CLanguage/Syntax">variety of syntax classes</a> such as:</p>

<ul>
  <li><code>ForStatement</code> that captures the syntax of <code>for</code> loops</li>
  <li><code>BinaryExpression</code> that handles most math operators such as <code>+</code> and <code>*</code></li>
  <li><code>Block</code> that captures a sequence of statements</li>
</ul>

<p>And this is the point where I realized C was a bit more complex than I liked to think. My syntax classes were filled with scary names like “abstract
specifiers”, “type specifier”, “type qualifier”, “multi declarations”, and so on. I knew C
declarations were nutty but, oh my, they’re a disaster.</p>

<p>I was scared, but combatted that fear by writing a bunch of unit tests.
I figured, yes this problem is hard, but it’s just big - there was an end in sight. Maximum effort would be needed and would, hopefully, be rewarded.</p>

<p>And so I pressed on. I just kept writing sample code after sample code until
I understood how my concept of the language related to this
grammar. After some time, I was able to wrestle all these “specifiers”
into more manageable objects.</p>

<h3 id="definitions-and-types">Definitions and Types</h3>

<p>The next step to writing a compiler is
discovering definitions in code. Variable definitions, function
definitions, type definitions, all that. C and C++ are a little
wild because you can declare things multiple times but you can
only define them once. While C++ is designed to be compiled using
only a single pass over the AST, I ended up writing a multi-pass
compiler with separate stages for declaration discovery, resolution,
and emission.</p>

<p>Once I found declarations and definitions, I needed to build
a type system. Thankfully, at first glance, C’s types are very
basic. You have the machine types (ints and floats), 
structures, and, uh oh, pointers. The compiler would have to munge
around all the code and assemble and unify all these types.
I spent days and days just getting the integers right.</p>

<p>For example, we all know what this means:</p>



<p>But what does</p>

<div><div><pre><code><span>int</span> <span>long</span> <span>long</span> <span>short</span> <span>long</span> <span>foo</span><span>;</span>
</code></pre></div></div>

<p>mean? Unfortunately, that is valid code according to the grammar
I’m using, but it’s obviously not valid C code. 
The compiler has to deal with this kind of craziness.
Not even the integers are simple in C…</p>

<h3 id="emitting-executable-code">Emitting Executable Code</h3>

<p>Now it’s time for the compiler to earn its keep and emit
executable code. Most C compilers would emit X86 or ARM assembly.
However, there was no point in doing that as I can’t natively
execute code on iOS.</p>

<p>I decided to instead devise my own
virtual machine and byte code that would be easy to interpret.
I figured that if I controlled the compiler and the byte code
then I could arrange things to make the interpreter simple
and yet still expressive.</p>

<p>This was a bit of a gamble as it increased the number of
decisions I had to make. However, most byte codes I looked into
were very complex and I knew (I thought) I could keep my code
small and simple.</p>

<p>I settled on a stack-based virtual machine that is very similar
to how the Common Language Runtime (CLR) works. Every function
had a stack and computations were performed by pushing and popping
numbers to and from that stack. This is different from most real
machines like X86 that are <em>register-based</em> not stack-based.
Register-based machines scared me a bit because they reminded
me of very hard to read chapters of very hard to read books.
I knew how to implement them, but I lacked experience with them
and went with the simpler design.</p>

<p>Now that I had a semi-specified byte code and virtual machine,
it was only a matter of translating my syntax tree into byte
code. If you ignore performance, this is a trivial step for the compiler.
You can see, for example, how <code>if</code> statements get compiled by looking at the
<code>DoEmit</code> method of <code>IfStatement</code>:</p>

<div><div><pre><code><span>protected</span> <span>override</span> <span>void</span> <span>DoEmit</span> <span>(</span><span>EmitContext</span> <span>ec</span><span>)</span>
<span>{</span>
    <span>var</span> <span>falseLabel</span> <span>=</span> <span>ec</span><span>.</span><span>DefineLabel</span> <span>();</span>
    <span>var</span> <span>endLabel</span> <span>=</span> <span>ec</span><span>.</span><span>DefineLabel</span> <span>();</span>

    <span>Condition</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>
    <span>ec</span><span>.</span><span>EmitCastToBoolean</span> <span>(</span><span>Condition</span><span>.</span><span>GetEvaluatedCType</span> <span>(</span><span>ec</span><span>));</span>
    <span>ec</span><span>.</span><span>Emit</span> <span>(</span><span>OpCode</span><span>.</span><span>BranchIfFalse</span><span>,</span> <span>falseLabel</span><span>);</span>

    <span>TrueValue</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>
    <span>ec</span><span>.</span><span>Emit</span> <span>(</span><span>OpCode</span><span>.</span><span>Jump</span><span>,</span> <span>endLabel</span><span>);</span>

    <span>ec</span><span>.</span><span>EmitLabel</span> <span>(</span><span>falseLabel</span><span>);</span>
    <span>FalseValue</span><span>.</span><span>Emit</span> <span>(</span><span>ec</span><span>);</span>

    <span>ec</span><span>.</span><span>EmitLabel</span> <span>(</span><span>endLabel</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This code first emits the condition. It then emits a branch to one of two
blocks - either the main body (<code>TrueValue</code>) or the <code>else</code> body (<code>FalseValue</code>).</p>

<p>I stole this emit architecture from the mono compiler - always steal from the best.</p>

<p>Most of those early decisions paid off well and after a few weeks
of work I was able to compile and interpret the most basic of
Arduino programs.</p>

<p>It was the hardest I ever had to work to get a stupid LED to blink.</p>

<h3 id="enough">Enough</h3>

<p>But that victory was met by a cold realization
of just how much more work was left to be done.</p>

<p>My compiler was working but it could only do math with 32 bit integers. My clever interpreter was stack based - which,
turns out, is not at all compatible with C’s flat memory model.
I had no idea how I would make real pointers work. I still
didn’t have support for structs. And this was all just for the
C compiler - I still needed to add C++ features!</p>

<p>And so, sadly, I gave up. It’s never easy to admit, but sometimes
problems are just too big for you.</p>

<h2 id="2018">2018</h2>

<p>Eight years is a long time and it’s funny how memories distort. 
I was working on the feature set for iCircuit 2 and Arduino was the first item on that list.
I knew I had a compiler capable of making an LED blink, and my memory
told me the compiler was nearly done it just needed a <em>bit</em> more work.
This time I reopened the code reluctantly, without hubris, mostly
curious to see what I would find.</p>

<p>I was pleasantly surprised to see how much ground I had covered
so long ago. I also realized that my memory betrayed me - the compiler had some
serious defects (no support for strings as a prime example) and that it was
going to be a lot of work to finish it. I remembered why I stopped 8 years ago.</p>

<p>However, after some thought, I decided that it was still useful.
It allowed you to use
the majority of the features of the Arduino and provided all the basics
you needed to write fun programs. 
I decided to release that compiler in <strong>iCircuit 1.9</strong> to 
finally provide the most requested feature of the app.</p>

<p>I was nervous, but very pleased to see that the 
Arduino component quickly became one of the most-used components in the app
and users seemed to love it.</p>

<h3 id="back-to-work">Back …</h3></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html">https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html</a></em></p>]]>
            </description>
            <link>https://praeclarum.org/2018/08/27/oops-i-wrote-a-c-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739677</guid>
            <pubDate>Sun, 05 Jul 2020 16:06:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Population Based Training]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739659">thread link</a>) | @keyboardman
<br/>
July 5, 2020 | https://leimao.github.io/blog/Population-Based-Training/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Population-Based-Training/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Training a machine learning model often requires a lot of hyperparameters, such as learning rate and regularization strength. The initial values of the hyperparameters and optionally how the hyperparameters are dynamically tuned during training would have a huge impact on the performance of the optimized model.</p>



<p>Given the combination of hyperparameter schedules are usually infinite, it is often not possible to do exhaustive search to find the best hyperparameter schedule for optimization, even with a lot of computer resources. Instead, what people often do is do hyperparameter grid search to some extent and optionally further fine-tune hyperparameters based on experience with a little bit more trials. While such method works well in practice, it requires a lot of human intervention and possibly miss a better model. Therefore, finding good hyperparameters and hyperparameter tuning approaches during optimization become critical for modeling.</p>



<p>In this blog post, I would like to discuss the <a href="https://arxiv.org/abs/1711.09846">population based training</a>, with a genetic algorithm inspired hyperparameter tuning schedule, proposed by DeepMind.</p>

<h3 id="machine-learning-optimization-theories">Machine Learning Optimization Theories</h3>

<p>Mathematically, a model consists of model parameters $\theta$, and our goal is to maximize or minimize an evaluation objective $Q(\theta)$. Typically, this $Q(\theta)$ already contains the entire model, the validation data, and a performance metric. For example, the evaluation objective for machine translation could be applying the validation data to the model, getting the outputs from the model, and compute the BLEU score, the performance metric, using the model outputs and ground truth labels. The evaluation objective $Q(\theta)$ does not have to be differentiable with respect to the model parameters $\theta$, and sometimes it could even be a black-box!</p>



<p>To maximize or minimize an evaluation objective $Q(\theta)$, we would need to find the optimized model parameters $\theta$, using some optimization techniques. In practice, we don’t want to use the evaluation objective for optimization, or the evaluation objective $Q(\theta)$ could not be directly used for optimization. For instance, the evaluation objective uses validation data and if we use the evaluation objective for optimization, the generalization of the optimized model would be usually poor in practice. Another common obstacle is that some optimization techniques requires the evaluation objective $Q(\theta)$ to be differentiable with respect to the model parameters $\theta$, but sometimes it is not the case.</p>



<p>Since the evaluation objective $Q(\theta)$ could not often be directly used for optimization, and we would propose a <a href="https://www.mathworks.com/help/gads/what-is-surrogate-optimization.html">surrogate objective</a> $\hat{Q}(\theta)$, hoping that by optimizing $\hat{Q}(\theta)$ with respect to the model parameters $\theta$, we would also achieve a good evaluation objective $Q(\theta)$. In machine learning, this surrogate objective is sometimes called training objective, and it contains the training data and the performance metric does not have to be the same to the one used in the evaluation objective. For example, the performance metric we used in machine translation model training is the sum of cross entropies, rather than BLEU score.</p>



<p>With the surrogate objective $\hat{Q}(\theta)$, finding the optimal parameters $\theta^{\ast}$ that maximize or minimize $\hat{Q}(\theta)$ does not happen magically. We would often need to use some optimization techniques to find the optimal parameters $\theta^{\ast}_{\hat{Q}(\theta)}$. Those optimization techniques would often introduce auxillary parameters $h$, which are often called as hyperparameters, to assist the finding of $\theta^{\ast}$. Therefore, given certain optimization techniques, the surrogate objective becomes $\hat{Q}(\theta | h)$. The hyperparameters could be some of the famous ones, such as the learning rate for gradient descent, and the regularization strength to prevent overfitting. However, this introduces some problems. The optimal parameters $\theta^{\ast}_{\hat{Q}(\theta|h)}$ for $\hat{Q}(\theta | h)$ might not be the same to the optimal parameters $\theta^{\ast}_{Q(\theta)}$ for $Q(\theta)$ which we truly care. Different $h$ would lead to different $\theta^{\ast}_{\hat{Q}(\theta|h)}$ and thus different values of $Q(\theta^{\ast}_{\hat{Q}(\theta|h)})$ which might or might not be close to $Q(\theta^{\ast}_{Q(\theta)})$.</p>



<p>Assuming the optimization technique would gives us good $\theta$ for $\hat{Q}(\theta | h)$, sometimes it could even be he the optimal parameters $\theta^{\ast}_{\hat{Q}(\theta|h)}$, how do we tune hyperparameters $h$ such that $Q(\theta)$ is as close to $Q(\theta^{\ast}_{Q(\theta)})$ as possible? Population based training, using the evolution of hyperparameters, is trying to solve this problem.</p>

<h3 id="population-based-training">Population Based Training</h3>

<p>Before we discuss the population based training, we would like to briefly review how people typically do hyperparameter tuning.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-28-Population-Based-Training/hyperparameter-tuning-paradigm.png">
    <figcaption>Hyperparameter Tuning Approaches</figcaption>
</figure>
</div>

<p>The sequential hyperparameter tuning approach is the most tedious for human beings but uses the least computation resources. We use one set of hyperparameters to train and evaluate the model. Based on the evaluation, we tune the hyperparameter and start the next round of training. We only runs one training instance throughout the entire tuning process but it could take a long time to find a good model that we feel satisfied with.</p>



<p>The parallel hyperparameter tuning approach is computation resource constrained. We run many training instances for different hyperparameters asynchronously, and find the best hyperparameters that gives the best evaluations. This approach, in my opinion, could hardly be called as “tuning”, since there is actually no tuning at all. The number of training instances we could run and the number of hyperparameters we would explore are solely dependent on how much computation resources we have and how much computation resource one training instance takes.</p>



<p>The population based hyperparameter tuning approach is a combination of the sequential approach and the parallel approach, with the human intervention in the sequential approach replaced with an automation from genetic algorithm. We run many training instance asynchronously with different hyperparameters $h_0$, and each training instance is updating the model parameters $\theta$ iteratively. At some point during the training, we compare the performances of all the training instances, and find out the one with the best performance. The rest of the training instances would start to use the exact same model parameters $\theta$ and the hyperparameters $h$ that the best training instance uses, which is called “exploitation”. Then, the hyperparameters $h$ for all the training instance other than the best training instance would be subject to some mutations, which is called “exploration”. In particular, “exploitation” means using the best configurations that the best training instance uses for all the training instances, “exploration” means mutating the hyperparameters for all the training instances other than the best training instance. The idea of population based training is simple and should be extremely familiar to the people who have experiences working with genetic algorithms.</p>

<h3 id="population-based-training-example">Population Based Training Example</h3>

<p>The DeepMind authors prepared a simple example to illustrate how the population based hyperparameter tuning approach is different from the other hyperparameter tuning approaches, such as grid search, given the same amount of computation resources.</p>



<p>In this particular setting, the evaluation objective is to maximize</p>



<p>where $\theta_0$ and $\theta_1$ are model parameters. The evaluation objective is treated as a black-box which we throw in $\theta_0$ and $\theta_1$ and generates a score. The maximum evaluation score it could achieve is $1.2$ when $\theta_0 = 0$ and $\theta_0 = 1$.</p>



<p>The surrogate objective we proposed is to maximize</p>



<p>where $h_0$ and $h_1$ are hyperparameters. We would use gradient ascent iteratively, with a fixed learning rate $\eta$, to optimize this surrogate objective, given the hyperparameters $h_0$ and $h_1$ and initial parameters $\theta_0$ and $\theta_1$.</p>



<p>Lucky us, the surrogate objective is very close to the black-box evaluation objective. If somehow we could be more lucky and use hyperparameters $h_0=1$ and $h_1=1$, optimizing surrogate objective would be equivalent to optimizing the evaluation objective, and we would be the most likely to have the maximum evaluation score.</p>



<p>We were given computation resources that allows running two training instances simultaneously. This time, we are not extremely lucky again. We used $\{h_0=1, h_1=0\}$ and $\{h_0=0, h_1=1\}$ as the initial hyperparameters for the two training instances, respectively. We want to check which hyperparameter tuning approach results in the best evaluation score, given the same amount of computation resources.</p>



<p>To make it “fair”, the model should be initialized with parameters $\theta_0=0.9$ and $\theta_1=0.9$, and each training instance is only allowed to use gradient ascent to update the hyperparameter $40$ times. The author did not mention what learning rate $\eta$ to use, but is the same for all training instances in all hyperparameter tuning approaches.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2020-06-28-Population-Based-Training/pbt-example.png">
    <figcaption>Population Based Training Example</figcaption>
</figure>
</div>

<p>The DeepMind authors created contour plots to make it easy to understand. The lighter the region is in the plot, the higher the evaluation score is. One training instance is denoted using black nodes, where each node represents the model parameters for each update iteration. The other training instance is denoted using red nodes. There are $2 \times 40 = 80$ nodes in total in one contour plot.</p>



<p>For grid search, because there is no actual hyperparameter tuning during training, $h_0$ and $h_1$ remain the same for the two training instances and the evaluation score is much lower than the possible …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Population-Based-Training/">https://leimao.github.io/blog/Population-Based-Training/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Population-Based-Training/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739659</guid>
            <pubDate>Sun, 05 Jul 2020 16:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keanu: Probabilistic programming with Bayesian network models]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739643">thread link</a>) | @memexy
<br/>
July 5, 2020 | https://improbable-research.github.io/keanu/docs/getting-started/ | <a href="https://web.archive.org/web/*/https://improbable-research.github.io/keanu/docs/getting-started/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<h2 id="your-model-as-a-bayesian-network">Your model as a Bayesian Network</h2>

<p>You need to describe your model to Keanu as a Bayesian network. A network is built from vertices. 
Vertices represent variables, which may be random or deterministic, and edges represent dependencies between variables. 
Your model’s state (i.e. data) is housed in these vertices as the vertex’s <code>value</code>. 
The value of a vertex can depend on the value of a parent vertex and can be updated in one of
two ways.</p>

<p>Let’s look at an example of two vertices A and B that contain some numbers as their values. Numbers from A and B are 
added together, which yields C.</p>



<p>If the number in A changes then the number in C will change as well and likewise for changes from B.</p>

<p>You can describe this in Keanu as:</p>

<div><div><pre><code><span>DoubleVertex</span> <span>A</span> <span>=</span> <span>new</span> <span>GaussianVertex</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>);</span>
<span>DoubleVertex</span> <span>B</span> <span>=</span> <span>new</span> <span>GaussianVertex</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>);</span>
<span>DoubleVertex</span> <span>C</span> <span>=</span> <span>A</span><span>.</span><span>plus</span><span>(</span><span>B</span><span>);</span>
</code></pre></div></div>

<h3 id="propagating-changes-forward">Propagating changes forward</h3>

<p>If you change A, you can tell C to recalculate based off of A’s new value and B’s unchanged value. 
To do this:</p>



<h3 id="evaluating-upstream-changes">Evaluating upstream changes</h3>

<p>But if you want to change both A and B then you probably don’t want to have C update twice. In that
case you would prefer to calculate C after both and A and B have changed and therefore calculating 
C once. This can be done by:</p>

<div><div><pre><code><span>A</span><span>.</span><span>setValue</span><span>(</span><span>1.234</span><span>);</span>
<span>B</span><span>.</span><span>setValue</span><span>(</span><span>4.321</span><span>);</span>
<span>C</span><span>.</span><span>lazyEval</span><span>();</span>
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>A</span><span>.</span><span>setValue</span><span>(</span><span>1.234</span><span>);</span>
<span>B</span><span>.</span><span>setValue</span><span>(</span><span>4.321</span><span>);</span>
<span>VertexValuePropagation</span><span>.</span><span>cascadeUpdate</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>);</span>
</code></pre></div></div>

<h3 id="observing-a-value">Observing a value</h3>

<p>Another central concept to Bayesian networks is observations. The value of a vertex can be “observed”, which
effectively locks the value of the vertex. Observing a vertex raises a flag on the vertex that tells an
inference algorithm to treat the vertex in a special way.</p>

<p>Observing vertices that contain numbers is a special case and is described more in the docs on <a href="https://improbable-research.github.io/keanu/docs/vertex-summary">Double vertices</a>.
In the interest of keeping this simple, take for example the case where instead of multiplying A and B, we apply the logical AND operator to their values.</p>

<div><div><pre><code>(A) _
     \
     AND -&gt; (C)
(B) _/
</code></pre></div></div>

<p>In this example, A and B contain boolean values and C is true only if both A and B are true. To describe this network in Keanu:</p>

<div><div><pre><code><span>BooleanVertex</span> <span>A</span> <span>=</span> <span>new</span> <span>BernoulliVertex</span><span>(</span><span>0.5</span><span>);</span>
<span>BooleanVertex</span> <span>B</span> <span>=</span> <span>new</span> <span>BernoulliVertex</span><span>(</span><span>0.5</span><span>);</span>
<span>BooleanVertex</span> <span>C</span> <span>=</span> <span>A</span><span>.</span><span>and</span><span>(</span><span>B</span><span>);</span>
</code></pre></div></div>

<p>To observe that C is true:</p>



<p>Now you can infer that A and B are also both true by sampling from the posterior distribution. Note: we will be covering MCMC sampling in the <a href="https://improbable-research.github.io/keanu/docs/inference-posterior-sampling/">Posterior Sampling</a> section.</p>

<div><div><pre><code><span>A</span><span>.</span><span>observe</span><span>(</span><span>true</span><span>);</span>
<span>B</span><span>.</span><span>observe</span><span>(</span><span>true</span><span>);</span>

<span>KeanuProbabilisticModel</span> <span>model</span> <span>=</span> <span>new</span> <span>KeanuProbabilisticModel</span><span>(</span><span>C</span><span>.</span><span>getConnectedGraph</span><span>());</span>
<span>NetworkSamples</span> <span>posteriorSamples</span> <span>=</span> <span>Keanu</span><span>.</span><span>Sampling</span><span>.</span><span>MetropolisHastings</span><span>.</span><span>withDefaultConfig</span><span>().</span><span>getPosteriorSamples</span><span>(</span>
    <span>model</span><span>,</span>
    <span>Arrays</span><span>.</span><span>asList</span><span>(</span><span>A</span><span>,</span> <span>B</span><span>),</span>
    <span>100000</span>
<span>).</span><span>drop</span><span>(</span><span>10000</span><span>).</span><span>downSample</span><span>(</span><span>2</span><span>);</span>
<span>double</span> <span>probabilityOfA</span> <span>=</span> <span>posteriorSamples</span><span>.</span><span>get</span><span>(</span><span>A</span><span>).</span><span>probability</span><span>(</span><span>isTrue</span> <span>-&gt;</span> <span>isTrue</span><span>.</span><span>scalar</span><span>()</span> <span>==</span> <span>true</span><span>);</span>
<span>//probabilityOfA evaluates to 1.0</span>
</code></pre></div></div>
<p><strong>You may be wondering why we go to all the hassle of doing inference</strong> rather than just writing something like the following:</p>
<div><div><pre><code><span>//WRONG</span>
<span>A</span><span>.</span><span>lazyEval</span><span>();</span>
<span>B</span><span>.</span><span>lazyEval</span><span>();</span>
<span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>A</span><span>.</span><span>getValue</span><span>().</span><span>scalar</span><span>());</span>
</code></pre></div></div>
<p>The issue here is that A and B are vertices in the computation graph that describes our prior and taking the value from A and B will just return a random value as if the BernoulliVertex was referenced in isolation. 
In this very contrived example it seems obvious to us how the value of C should propagate values to A and B but this is not always so straightforward.
In general, this process is known as <em>variable elimination</em> and it is not supported by Keanu. 
Therefore, in order to infer the values of A and B, you have to perform inference using a posterior sampling algorithm like <a href="https://improbable-research.github.io/keanu/docs/inference-posterior-sampling/">MCMC</a>.</p>

<p><strong>You may also be wondering why we also observe A and B to be true</strong> in the above code. 
This is so that when our sampling algorithm (MCMC) starts to sample from the posterior, it will start from a network with a probability that is non-zero.
If we do not include this, then our network will get a random starting value, e.g. A is false and B is true, and then will discover that it is actually not possible to be in this state and will throw an error.</p>

<p>In general, A and B are known as <em>latent variables</em> because we do not directly observe them. In more complex cases, we may not know what starting state (like A: true, B: true in this case) to use. 
There are a couple of techniques that solve this problem so that we can leverage Bayesian Inference.
Firstly, you might choose to use the <code>ParticleFilter</code> class in order to find the most probable state to start your algorithm from.
Alternatively, you can create a new Bayesian network and use this to probe some random configurations a certain number of times to see if it can find a possible one.</p>
<div><div><pre><code><span>BayesianNetwork</span> <span>bayesianNetwork</span> <span>=</span> <span>new</span> <span>BayesianNetwork</span><span>(</span><span>C</span><span>.</span><span>getConnectedGraph</span><span>());</span>
<span>bayesianNetwork</span><span>.</span><span>probeForNonZeroProbability</span><span>(</span><span>10</span><span>);</span>
</code></pre></div></div>
<p>Now you can run MCMC on the BayesNet as it will start off in the correct configuration.</p>

<p>Instead of running MCMC you could also run one of our <a href="https://improbable-research.github.io/keanu/docs/inference-map">inference algorithms</a>.</p>

						</div><!-- /.content -->
					</div></div>]]>
            </description>
            <link>https://improbable-research.github.io/keanu/docs/getting-started/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739643</guid>
            <pubDate>Sun, 05 Jul 2020 16:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Python Reference Ever]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739589">thread link</a>) | @pizzaburek
<br/>
July 5, 2020 | https://gto76.github.io/python-cheatsheet | <a href="https://web.archive.org/web/*/https://gto76.github.io/python-cheatsheet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <span><i></i></span>
   <div><br><div><h2 id="toc"><a href="#toc" name="toc">#</a>Contents</h2><pre><code><strong>ToC</strong> = {
    <strong><span><span>'1. Collections'</span></span></strong>: [<a href="#list">List</a>, <a href="#dictionary">Dictionary</a>, <a href="#set">Set</a>, <a href="#tuple">Tuple</a>, <a href="#range">Range</a>, <a href="#enumerate">Enumerate</a>, <a href="#iterator">Iterator</a>, <a href="#generator">Generator</a>],
    <strong><span><span>'2. Types'</span></span></strong>:       [<a href="#type">Type</a>, <a href="#string">String</a>, <a href="#regex">Regular_Exp</a>, <a href="#format">Format</a>, <a href="#numbers">Numbers</a>, <a href="#combinatorics">Combinatorics</a>, <a href="#datetime">Datetime</a>],
    <strong><span><span>'3. Syntax'</span></span></strong>:      [<a href="#arguments">Args</a>, <a href="#inline">Inline</a>, <a href="#closure">Closure</a>, <a href="#decorator">Decorator</a>, <a href="#class">Class</a>, <a href="#ducktypes">Duck_Type</a>, <a href="#enum">Enum</a>, <a href="#exceptions">Exception</a>],
    <strong><span><span>'4. System'</span></span></strong>:      [<a href="#exit">Exit</a>, <a href="#print">Print</a>, <a href="#input">Input</a>, <a href="#commandlinearguments">Command_Line_Arguments</a>, <a href="#open">Open</a>, <a href="#path">Path</a>, <a href="#oscommands">OS_Commands</a>],
    <strong><span><span>'5. Data'</span></span></strong>:        [<a href="#json">JSON</a>, <a href="#pickle">Pickle</a>, <a href="#csv">CSV</a>, <a href="#sqlite">SQLite</a>, <a href="#bytes">Bytes</a>, <a href="#struct">Struct</a>, <a href="#array">Array</a>, <a href="#memoryview">Memory_View</a>, <a href="#deque">Deque</a>],
    <strong><span><span>'6. Advanced'</span></span></strong>:    [<a href="#threading">Threading</a>, <a href="#operator">Operator</a>, <a href="#introspection">Introspection</a>, <a href="#metaprograming">Metaprograming</a>, <a href="#eval">Eval</a>, <a href="#coroutines">Coroutine</a>],
    <strong><span><span>'7. Libraries'</span></span></strong>:   [<a href="#progressbar">Progress_Bar</a>, <a href="#plot">Plot</a>, <a href="#table">Table</a>, <a href="#curses">Curses</a>, <a href="#logging">Logging</a>, <a href="#scraping">Scraping</a>, <a href="#web">Web</a>, <a href="#profiling">Profile</a>,
                       <a href="#numpy">NumPy</a>, <a href="#image">Image</a>, <a href="#audio">Audio</a>, <a href="#pygame">Games</a>, <a href="#pandas">Data</a>, <a href="#cython">Cython</a>]
}
</code></pre></div></div>






<div><h2 id="main"><a href="#main" name="main">#</a>Main</h2><pre><code><span>if</span> __name__ == <span>'__main__'</span>:     
    main()
</code></pre></div>

<div><h2 id="list"><a href="#list" name="list">#</a>List</h2><pre><code>&lt;list&gt; = &lt;list&gt;[from_inclusive : to_exclusive : ±step_size]
</code></pre></div>

<pre><code>&lt;list&gt;.append(&lt;el&gt;)            
&lt;list&gt;.extend(&lt;collection&gt;)    
</code></pre>
<pre><code>&lt;list&gt;.sort()
&lt;list&gt;.reverse()
&lt;list&gt; = sorted(&lt;collection&gt;)
&lt;iter&gt; = reversed(&lt;list&gt;)
</code></pre>
<pre><code>sum_of_elements  = sum(&lt;collection&gt;)
elementwise_sum  = [sum(pair) <span>for</span> pair <span>in</span> zip(list_a, list_b)]
sorted_by_second = sorted(&lt;collection&gt;, key=<span>lambda</span> el: el[<span>1</span>])
sorted_by_both   = sorted(&lt;collection&gt;, key=<span>lambda</span> el: (el[<span>1</span>], el[<span>0</span>]))
flatter_list     = list(itertools.chain.from_iterable(&lt;list&gt;))
product_of_elems = functools.reduce(<span>lambda</span> out, el: out * el, &lt;collection&gt;)
list_of_chars    = list(&lt;str&gt;)
</code></pre>
<ul>
<li><strong>Module <a href="#operator">operator</a> provides functions itemgetter() and mul() that offer the same functionality as <a href="#lambda">lambda</a> expressions above.</strong></li>
</ul>
<pre><code>&lt;int&gt; = &lt;list&gt;.count(&lt;el&gt;)     
index = &lt;list&gt;.index(&lt;el&gt;)     
&lt;list&gt;.insert(index, &lt;el&gt;)     
&lt;el&gt; = &lt;list&gt;.pop([index])     
&lt;list&gt;.remove(&lt;el&gt;)            
&lt;list&gt;.clear()                 
</code></pre>
<div><h2 id="dictionary"><a href="#dictionary" name="dictionary">#</a>Dictionary</h2><pre><code>&lt;view&gt; = &lt;dict&gt;.keys()                          
&lt;view&gt; = &lt;dict&gt;.values()                        
&lt;view&gt; = &lt;dict&gt;.items()                         
</code></pre></div>

<pre><code>value  = &lt;dict&gt;.get(key, default=<span>None</span>)          
value  = &lt;dict&gt;.setdefault(key, default=<span>None</span>)   
&lt;dict&gt; = collections.defaultdict(&lt;type&gt;)        
&lt;dict&gt; = collections.defaultdict(<span>lambda</span>: <span>1</span>)     
</code></pre>
<pre><code>&lt;dict&gt; = dict(&lt;collection&gt;)                     
&lt;dict&gt; = dict(zip(keys, values))                
&lt;dict&gt; = dict.fromkeys(keys [, value])          
</code></pre>
<pre><code>&lt;dict&gt;.update(&lt;dict&gt;)                           
value = &lt;dict&gt;.pop(key)                         
{k <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> v == value}    
{k: v <span>for</span> k, v <span>in</span> &lt;dict&gt;.items() <span>if</span> k <span>in</span> keys}  
</code></pre>
<div><h3 id="counter">Counter</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> Counter
<span>&gt;&gt;&gt; </span>colors = [<span>'blue'</span>, <span>'blue'</span>, <span>'blue'</span>, <span>'red'</span>, <span>'red'</span>]
<span>&gt;&gt;&gt; </span>counter = Counter(colors)
<span>&gt;&gt;&gt; </span>counter[<span>'yellow'</span>] += <span>1</span>
Counter({<span>'blue'</span>: <span>3</span>, <span>'red'</span>: <span>2</span>, <span>'yellow'</span>: <span>1</span>})
<span>&gt;&gt;&gt; </span>counter.most_common()[<span>0</span>]
(<span>'blue'</span>, <span>3</span>)
</code></pre></div>



<pre><code>&lt;set&gt;.add(&lt;el&gt;)                                 
&lt;set&gt;.update(&lt;collection&gt;)                      
</code></pre>
<pre><code>&lt;set&gt;  = &lt;set&gt;.union(&lt;coll.&gt;)                   
&lt;set&gt;  = &lt;set&gt;.intersection(&lt;coll.&gt;)            
&lt;set&gt;  = &lt;set&gt;.difference(&lt;coll.&gt;)              
&lt;set&gt;  = &lt;set&gt;.symmetric_difference(&lt;coll.&gt;)    
&lt;bool&gt; = &lt;set&gt;.issubset(&lt;coll.&gt;)                
&lt;bool&gt; = &lt;set&gt;.issuperset(&lt;coll.&gt;)              
</code></pre>
<pre><code>&lt;el&gt; = &lt;set&gt;.pop()                              
&lt;set&gt;.remove(&lt;el&gt;)                              
&lt;set&gt;.discard(&lt;el&gt;)                             
</code></pre>
<div><h3 id="frozenset">Frozen Set</h3><ul>
<li><strong>Is immutable and hashable.</strong></li>
<li><strong>That means it can be used as a key in a dictionary or as an element in a set.</strong></li>
</ul><pre><code>&lt;frozenset&gt; = frozenset(&lt;collection&gt;)
</code></pre></div>


<div><h2 id="tuple"><a href="#tuple" name="tuple">#</a>Tuple</h2><p><strong>Tuple is an immutable and hashable list.</strong></p><pre><code>&lt;tuple&gt; = ()
&lt;tuple&gt; = (&lt;el&gt;, )
&lt;tuple&gt; = (&lt;el_1&gt;, &lt;el_2&gt; [, ...])
</code></pre></div>


<div><h3 id="namedtuple">Named Tuple</h3><p><strong>Tuple's subclass with named elements.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Point = namedtuple(<span>'Point'</span>, <span>'x y'</span>)
<span>&gt;&gt;&gt; </span>p = Point(<span>1</span>, y=<span>2</span>)
Point(x=<span>1</span>, y=<span>2</span>)
<span>&gt;&gt;&gt; </span>p[<span>0</span>]
<span>1</span>
<span>&gt;&gt;&gt; </span>p.x
<span>1</span>
<span>&gt;&gt;&gt; </span>getattr(p, <span>'y'</span>)
<span>2</span>
<span>&gt;&gt;&gt; </span>p._fields  
(<span>'x'</span>, <span>'y'</span>)
</code></pre></div>


<div><h2 id="range"><a href="#range" name="range">#</a>Range</h2><pre><code>&lt;range&gt; = range(to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive)
&lt;range&gt; = range(from_inclusive, to_exclusive, ±step_size)
</code></pre></div>

<pre><code>from_inclusive = &lt;range&gt;.start
to_exclusive   = &lt;range&gt;.stop
</code></pre>
<div><h2 id="enumerate"><a href="#enumerate" name="enumerate">#</a>Enumerate</h2><pre><code><span>for</span> i, el <span>in</span> enumerate(&lt;collection&gt; [, i_start]):
    ...
</code></pre></div>

<div><h2 id="iterator"><a href="#iterator" name="iterator">#</a>Iterator</h2><pre><code>&lt;iter&gt; = iter(&lt;collection&gt;)                 
&lt;iter&gt; = iter(&lt;function&gt;, to_exclusive)     
&lt;el&gt;   = next(&lt;iter&gt; [, default])           
&lt;list&gt; = list(&lt;iter&gt;)                       
</code></pre></div>

<div><h3 id="itertools">Itertools</h3><pre><code><span>from</span> itertools <span>import</span> count, repeat, cycle, chain, islice
</code></pre></div>

<pre><code>&lt;iter&gt; = count(start=<span>0</span>, step=<span>1</span>)             
&lt;iter&gt; = repeat(&lt;el&gt; [, times])             
&lt;iter&gt; = cycle(&lt;collection&gt;)                
</code></pre>
<pre><code>&lt;iter&gt; = chain(&lt;coll_1&gt;, &lt;coll_2&gt; [, ...])  
&lt;iter&gt; = chain.from_iterable(&lt;collection&gt;)  
</code></pre>
<pre><code>&lt;iter&gt; = islice(&lt;collection&gt;, to_exclusive)
&lt;iter&gt; = islice(&lt;collection&gt;, from_inclusive, to_exclusive [, +step_size])
</code></pre>
<div><h2 id="generator"><a href="#generator" name="generator">#</a>Generator</h2><ul>
<li><strong>Any function that contains a yield statement returns a generator.</strong></li>
<li><strong>Generators and iterators are interchangeable.</strong></li>
</ul><pre><code><span><span>def</span> <span>count</span><span>(start, step)</span>:</span>
    <span>while</span> <span>True</span>:
        <span>yield</span> start
        start += step
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>counter = count(<span>10</span>, <span>2</span>)
<span>&gt;&gt;&gt; </span>next(counter), next(counter), next(counter)
(<span>10</span>, <span>12</span>, <span>14</span>)
</code></pre>
<div><h2 id="type"><a href="#type" name="type">#</a>Type</h2><ul>
<li><strong>Everything is an object.</strong></li>
<li><strong>Every object has a type.</strong></li>
<li><strong>Type and class are synonymous.</strong></li>
</ul><pre><code>&lt;type&gt; = type(&lt;el&gt;)                          
&lt;bool&gt; = isinstance(&lt;el&gt;, &lt;type&gt;)            
</code></pre></div>


<pre><code><span>&gt;&gt;&gt; </span>type(<span>'a'</span>), <span>'a'</span>.__class__, str
(&lt;<span><span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;, &lt;<span>class</span> '<span>str</span>'&gt;)
</span></code></pre>
<div><h4 id="sometypesdonothavebuiltinnamessotheymustbeimported">Some types do not have built-in names, so they must be imported:</h4><pre><code><span>from</span> types <span>import</span> FunctionType, MethodType, LambdaType, GeneratorType
</code></pre></div>

<div><h3 id="abstractbaseclasses">Abstract Base Classes</h3><p><strong>Each abstract base class specifies a set of virtual subclasses. These classes are then recognized by isinstance() and issubclass() as subclasses of the ABC, although they are really not.</strong></p><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections.abc <span>import</span> Sequence, Collection, Iterable
<span>&gt;&gt;&gt; </span>isinstance([<span>1</span>, <span>2</span>, <span>3</span>], Iterable)
<span>True</span>
</code></pre></div>


<pre><code>┏━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┯━━━━━━━━━━━━┓
┃                  │  Sequence  │ Collection │  Iterable  ┃
┠──────────────────┼────────────┼────────────┼────────────┨
┃ list, range, str │     ✓      │     ✓      │     ✓      ┃
┃ dict, set        │            │     ✓      │     ✓      ┃
┃ iter             │            │            │     ✓      ┃
┗━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┷━━━━━━━━━━━━┛
</code></pre>
<pre><code><span>&gt;&gt;&gt; </span><span>from</span> numbers <span>import</span> Integral, Rational, Real, Complex, Number
<span>&gt;&gt;&gt; </span>isinstance(<span>123</span>, Number)
<span>True</span>
</code></pre>
<pre><code>┏━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃                    │ Integral │ Rational │   Real   │ Complex  │  Number  ┃
┠────────────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ int                │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ fractions.Fraction │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ float              │          │          │    ✓     │    ✓     │    ✓     ┃
┃ complex            │          │          │          │    ✓     │    ✓     ┃
┃ decimal.Decimal    │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre>
<div><h2 id="string"><a href="#string" name="string">#</a>String</h2><pre><code>&lt;str&gt;  = &lt;str&gt;.strip()                       
&lt;str&gt;  = &lt;str&gt;.strip(<span>'&lt;chars&gt;'</span>)              
</code></pre></div>

<pre><code>&lt;list&gt; = &lt;str&gt;.split()                       
&lt;list&gt; = &lt;str&gt;.split(sep=<span>None</span>, maxsplit=<span>-1</span>)  
&lt;list&gt; = &lt;str&gt;.splitlines(keepends=<span>False</span>)    
&lt;str&gt;  = &lt;str&gt;.join(&lt;coll_of_strings&gt;)       
</code></pre>
<pre><code>&lt;bool&gt; = &lt;sub_str&gt; <span>in</span> &lt;str&gt;                  
&lt;bool&gt; = &lt;str&gt;.startswith(&lt;sub_str&gt;)         
&lt;bool&gt; = &lt;str&gt;.endswith(&lt;sub_str&gt;)           
&lt;int&gt;  = &lt;str&gt;.find(&lt;sub_str&gt;)               
&lt;int&gt;  = &lt;str&gt;.index(&lt;sub_str&gt;)              
</code></pre>
<pre><code>&lt;str&gt;  = &lt;str&gt;.replace(old, new [, count])   
&lt;str&gt;  = &lt;str&gt;.translate(&lt;table&gt;)            
</code></pre>
<pre><code>&lt;str&gt;  = chr(&lt;int&gt;)                          
&lt;int&gt;  = ord(&lt;str&gt;)                          
</code></pre>
<ul>
<li><strong>Also: <code><span>'lstrip()'</span></code>, <code><span>'rstrip()'</span></code>.</strong></li>
<li><strong>Also: <code><span>'lower()'</span></code>, <code><span>'upper()'</span></code>, <code><span>'capitalize()'</span></code> and <code><span>'title()'</span></code>.</strong></li>
</ul>
<div><h3 id="propertymethods">Property Methods</h3><pre><code>┏━━━━━━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┯━━━━━━━━━━┓
┃               │ [ !#$%…] │ [a-zA-Z] │  [¼½¾]   │  [²³¹]   │  [0-9]   ┃
┠───────────────┼──────────┼──────────┼──────────┼──────────┼──────────┨
┃ isprintable() │    ✓     │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isalnum()     │          │    ✓     │    ✓     │    ✓     │    ✓     ┃
┃ isnumeric()   │          │          │    ✓     │    ✓     │    ✓     ┃
┃ isdigit()     │          │          │          │    ✓     │    ✓     ┃
┃ isdecimal()   │          │          │          │          │    ✓     ┃
┗━━━━━━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┷━━━━━━━━━━┛
</code></pre></div>

<ul>
<li><strong>Also: <code><span>'isspace()'</span></code> checks for <code><span>'[ \t\n\r\f\v…]'</span></code>.</strong></li>
</ul>
<div><h2 id="regex"><a href="#regex" name="regex">#</a>Regex</h2><pre><code><span>import</span> re
&lt;str&gt;   = re.sub(&lt;regex&gt;, new, text, count=<span>0</span>)  
&lt;list&gt;  = re.findall(&lt;regex&gt;, text)            
&lt;list&gt;  = re.split(&lt;regex&gt;, text, maxsplit=<span>0</span>)  
&lt;Match&gt; = re.search(&lt;regex&gt;, text)             
&lt;Match&gt; = re.match(&lt;regex&gt;, text)              
&lt;iter&gt;  = re.finditer(&lt;regex&gt;, text)           
</code></pre></div>

<ul>
<li><strong>Search() and match() return None if they can't find a match.</strong></li>
<li><strong>Argument <code><span>'flags=re.IGNORECASE'</span></code> can be used with all functions.</strong></li>
<li><strong>Argument <code><span>'flags=re.MULTILINE'</span></code> makes <code><span>'^'</span></code> and <code><span>'$'</span></code> match the start/end of each line.</strong></li>
<li><strong>Argument <code><span>'flags=re.DOTALL'</span></code> makes dot also accept the <code><span>'\n'</span></code>.</strong></li>
<li><strong>Use <code><span>r'\1'</span></code> or <code><span>'\\1'</span></code> for backreference.</strong></li>
<li><strong>Add <code><span>'?'</span></code> after an operator to make it non-greedy.</strong></li>
</ul>
<div><h3 id="matchobject">Match Object</h3><pre><code>&lt;str&gt;   = &lt;Match&gt;.group()                      
&lt;str&gt;   = &lt;Match&gt;.group(<span>1</span>)                     
&lt;tuple&gt; = &lt;Match&gt;.groups()                     
&lt;int&gt;   = &lt;Match&gt;.start()                      
&lt;int&gt;   = &lt;Match&gt;.end()                        
</code></pre></div>

<div><h3 id="specialsequences">Special Sequences</h3><ul>
<li><strong>By default digits, alphanumerics and whitespaces from all alphabets are matched, unless <code><span>'flags=re.ASCII'</span></code> argument is used.</strong></li>
<li><strong>Use a capital letter for negation.</strong></li>
</ul><pre><code><span>'\d'</span> == <span>'[0-9]'</span>                                
<span>'\w'</span> == <span>'[a-zA-Z0-9_]'</span>                         
<span>'\s'</span> == <span>'[ \t\n\r\f\v]'</span>                        
</code></pre></div>


<div><h2 id="format"><a href="#format" name="format">#</a>Format</h2><pre><code>&lt;str&gt; = <span>f'<span>{&lt;el_1&gt;}</span>, <span>{&lt;el_2&gt;}</span>'</span>
&lt;str&gt; = <span>'{}, {}'</span>.format(&lt;el_1&gt;, &lt;el_2&gt;)
</code></pre></div>

<div><h3 id="attributes">Attributes</h3><pre><code><span>&gt;&gt;&gt; </span><span>from</span> collections <span>import</span> namedtuple
<span>&gt;&gt;&gt; </span>Person = namedtuple(<span>'Person'</span>, <span>'name height'</span>)
<span>&gt;&gt;&gt; </span>person = Person(<span>'Jean-Luc'</span>, <span>187</span>)
<span>&gt;&gt;&gt; </span><span>f'<span>{person.height}</span>'</span>
<span>'187'</span>
<span>&gt;&gt;&gt; </span><span>'{p.height}'</span>.format(p=person)
<span>'187'</span>
</code></pre></div>

<div><h3 id="generaloptions">General Options</h3><pre><code>{&lt;el&gt;:&lt;<span>10</span>}                                     
{&lt;el&gt;:^<span>10</span>}                                     
{&lt;el&gt;:&gt;<span>10</span>}  …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gto76.github.io/python-cheatsheet">https://gto76.github.io/python-cheatsheet</a></em></p>]]>
            </description>
            <link>https://gto76.github.io/python-cheatsheet</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739589</guid>
            <pubDate>Sun, 05 Jul 2020 15:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Interface of Kai Krause's Software]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739545">thread link</a>) | @bschne
<br/>
July 5, 2020 | https://www.mprove.de/script/99/kai/index.html | <a href="https://web.archive.org/web/*/https://www.mprove.de/script/99/kai/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<div>
				<div>
					<h2 skip="">Contents</h2>
					<ol>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#history"><b>Meta-History</b></a></li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#software"><b>The Software</b></a>
							<ul>
								<li>Maximize the Interface</li>
								<li>Full Screen Mode</li>
								<li>Rooms</li>
								<li>Minimize the Interface</li>
								<li>The Desktop</li>
							</ul>
						</li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#interfacelanguage"><b>Kai’s Interface Language</b></a>
							<ul>
								<li>Unfolding functionality</li>
								<li>MouseOver</li>
								<li>MouseDragging instead of Value-Slider</li>
								<li>Memory Dots / Five Favorites</li>
								<li><nobr>Transparency &amp; Shadows (KPT Lens f/x, Poser</nobr><nobr>)</nobr></li>
								<li>Full Screen Mode, <a href="https://www.mprove.de/script/99/kai/index.html#rooms">Rooms Metaphor</a></li>
								<li>Workspace – Desktop</li>
								<li>MetaWindow</li>
							</ul>
						</li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#references"><b>References</b></a></li>
					</ol>
				</div>
			</div>
			<h2><a name="history" id="history"></a>Meta-History</h2>
			<h3>CV</h3>
			<p><a id="Truong97" name="Truong97"></a><strong><a href="https://en.wikipedia.org/wiki/Kai_Krause">Kai Krause</a></strong> [today: <a href="http://kai.sub.blue/">kai.sub.blue</a>]was born 1957 in Dortmund. He came to California in 1976 with two friends. He worked as a musician for <em>Disney Sound Effects</em>; <strike>the sound track for “Star Trek: The Movie” was created on his synthesizers</strike>*. <span>* In fact Kai won a Clio Award for his sound effects in a Star Wars radio spot.</span> <a href="https://en.wikipedia.org/wiki/Emerson,_Lake_&amp;_Powell">Emerson, Lake &amp; Powell</a> bought sound systems from him and he is still working with <a href="https://petergabriel.com/">Peter Gabriel</a> today in order to fulfill his vision of visualized music as 3D sculptures. [<a href="https://www.mprove.de/script/99/kai/index.html#refTruong97">Truong97</a>]</p>
			<p>He was running a forum for several years on AOL: <a href="https://www.mprove.de/script/90/KPT/index.html"><em>Kai’s Power Tips &amp; Tricks</em></a>. He gave people tips and little pieces of code on line, simply because they shared his passion for computer graphics. This became an extensive and valuable collection of practical information how to get special effects with <em>Adobe Photoshop</em>. It can still be downloaded from several web sites. [<a id="KaiTT" name="KaiTT" href="https://www.mprove.de/script/99/kai/index.html#refKaiTT">KaiTT</a>]</p>
			<h3>The Company</h3>
			<p><img src="https://www.mprove.de/script/99/kai/_media/high/history.jpg" height="441" width="803"></p>
			<p>Fig. 1 Timeline with companies and products</p>
			<p><em>Harward Systems Corporation</em> (HSC Software Corp.) [also <em>Happy Software Company</em>] was founded by John Wilczak. Ben Weiss and Kai joined him in 1991 at HSC and created the first version of <em>Kai’s Power Tools</em>. KPT is a set of plug-ins that use the Adobe Photoshop programing interface for 3rd party filters. Many ideas from <a href="https://www.mprove.de/script/90/KPT/index.html">Kai’s Power Tips &amp; Tricks</a> get implemented as simple and easy to use pieces of software. KPT evolved until version 3 in 1995. This release contains the <em>Texture Explorer</em>, the <em>Spheroid Designer</em> and <em>KPT Lens f/x</em> among others. <em>Convolver</em> came out as a separate product. HSC was renamed to <em>MetaTools, Inc.</em> the same year.</p>
			<p>Eric Wenger and Phil Clevenger came into the team to develop a landscape-simulating product called <em>Bryce</em> (named after the <a href="https://www.nps.gov/brca/index.htm">Bryce Canyon</a>). They started creating other kinds of software starting with <em>Kai’s Power GOO</em>, <em>Kai’s Photo Soap</em> and <em>Kai’s Power Show</em>. Before GOO, Kai was well known only by computer artists as a creator of creative tools. With GOO, Kai became noticed by a much broader audience. People played with GOO. The complex and difficult algorithms are well hidden by the interface. Even children can change images of their classmates or teachers to funny caricatures. Kai himself calls this sort of computer programs <em>funware</em>.</p>
			<p>In 1998 Phil Clevenger and Kai managed to transfer the main interface concepts from Bryce to <em>Poser3</em>. Poser was originally created by <em>Fractal Design</em>. The companies MetaTools and Fractal Design merged in 1997. The new company was named <a href="https://en.wikipedia.org/wiki/MetaCreations"><em>MetaCreations Corp</em>.</a> In 1998 it had about 300 employees. The main office is in Santa Barbara, CA, but several other facilities e.g. in San Francisco, are part of MetaCreations. <a id="MCRE" name="MCRE"></a>[<a href="https://www.mprove.de/script/99/kai/index.html#refMCRE">MCRE</a>]</p>
			<h4>Update π-day 2018</h4>
			<ul>
				<li><a href="https://www.scribd.com/document/373825984/MataTools-Flyer-1996">MetaTools Flyer 1996</a></li>
				<li><a href="http://vv.arts.ucla.edu/teaching/software/lifeintheuniverse/"><em>Life in the Universe (1997)</em></a> – <a href="http://victoriavesna.com/index.php?p=teaching&amp;item=2">course material by Victoria Vesna</a>, UCLA (Thanks to Christopher Cowan for sharing the link.)
					<ul>
						<li><a href="https://www.facebook.com/kaikemono/posts/10216470444058859" target="_blank"><strike>Some thoughts by the designer Kai Gradert</strike></a></li>
					</ul>
				</li>
			</ul>
			<h2><a name="software" id="software"></a>The Software</h2>
			<h3>Maximize the Interface</h3>
			<h4>Full Screen Mode</h4>
			<p><a id="Kai95-1" name="Kai95-1"></a>Kai describes how it came to the large dialogs in KPT3:</p>
			<blockquote>
				<p>»I would love to interact with the image in the way that Levels or Curves does, but the plug-in interface as of today simply will not allow it. What that leads to is simply that the plug-in gets a rectangle and is supposed to do something with the pixels in some other room and then give them back.« [<a href="https://www.mprove.de/script/99/kai/index.html#refKai95">Kai95</a>]</p>
			</blockquote>
			<p>Many of the filters in KPT3 like <em>KPT Texture Explorer</em>, <em>KPT Spheroid Designer</em> and <em>KPT Convolver</em> use a rectangular area that fits on a 14" monitor. All other elements get blacked out – no menu bar, no Photoshop image window and no desktop. The user experience is really like coming into a room with a special suited environment for one specific task.</p>
			<p><a name="Fig2 KPT Texture"></a><img src="https://www.mprove.de/script/99/kai/_media/high/KPT3TextureExplorer.jpg" height="460" width="640"></p>
			<p>Fig. 2 KPT Texture Explorer 3.0</p>
			<p>KPT Texture Explorer is a modal dialog, that is especially prepared to create textures and nothing else.</p>
			<p><img id="spheroiddesigner" src="https://www.mprove.de/script/99/kai/_media/high/KPT3SpheroidDesigner.jpg" name="spheroiddesigner"></p>
			<p>Fig. 3 KPT Spheroid Designer 3.0</p>
			<p>KPT Spheroid Designer is meant to create collections of special looking orbs. Different controls allow the definition of light or to select a special surface structure for the orbs. The KPT users manual notes that Spheroid Designer may seem to resemble glass balls dropped into mud, but actually it’s meant to be glass balls embedded in an “old stale brownie”. [<a href="https://www.mprove.de/script/99/kai/index.html#refLombreglia97">Lombreglia97</a>]<br>
					<a id="kansei" name="kansei"></a></p>
			<p><a name="Fig4 KPT Convolver"></a><img id="convolver" src="https://www.mprove.de/script/99/kai/_media/high/KPTConvolver.jpg" name="convolver"></p>
			<p>Fig. 4 KPT Convolver</p>
			<p><a id="Tog96" name="Tog96"></a><a href="http://asktog.com/">Bruce “Tog” Tognazzini</a> writes about <em>Kansei Engineering</em>:</p>
			<blockquote>
				<p>»Since the year A.D. 618 the Japanese have been creating beautiful Zen gardens, environments of harmony designed to instill in their users a sense of serenity and peace. […] Every rock and tree is thoughtfully placed in patterns that are at once random and yet teeming with order. Rocks are not just strewn about; they are carefully arranged in odd-numbered groupings and sunk into the ground to give the illusion of age and stability. Waterfalls are not simply lined with interesting rocks; they are tuned to create just the right burble and plop. […]<br>
					
					Kansei speakes to a totality of experience: colors, sounds, shapes, tactile sensations, and kinesthesia, as well as the personality and consistency of interactions.« [<a href="https://www.mprove.de/script/99/kai/index.html#refTog96">Tog96</a>, pp. 171]</p>
			</blockquote>
			<p>Then Tog comes to software design:</p>
			<blockquote>
				<p>»Where does kansei start? Not with the hardware. Not with the software either. Kansei starts with attitude, as does quality. The original <a href="https://www.mprove.de/visionreality/text/3.1.6_xeroxstar.html">Xerox Star</a> team had it. So did the <a href="https://www.mprove.de/visionreality/text/3.1.8_lisa.html">Lisa</a> team, and the <a href="https://www.mprove.de/visionreality/text/3.1.9_macintosh.html">Mac</a> team after. All were dedicated to building a single, tightly integrated environment – a totality of experience. […]<br>
					KPT Convolver […] is a marvelous example of kansei design. It replaces the extensive lineup of filters that graphic designers traditionally grapple with when using such tools as Photoshop with a simple, integrated, harmonious environment.<br>
					In the past, designers have followed a process of picturing their desired end result in their mind, then applying a series of filters sequentially, without benefit of undo beyond the last-applied filter. Convolver lets users play, trying any combination of filters at will, either on their own or with the computer’s aid and advice. […] Both time and space lie at the user’s complete control.« [<a href="https://www.mprove.de/script/99/kai/index.html#refTog96">Tog96</a>, pp. 174]</p>
			</blockquote>
			<p>Many of the interface ideas evolved from <em>KPT</em> into <em>Bryce</em>. It is a whole environment that covers the complete screen. It overcomes the limitation of a fixed 14" rectangle, because the interface scales itself to the according screen dimensions. The same holds for <em>Poser3</em> and <em>KPT5</em> as they were shipped late in 1998.</p>
			<p><img id="bryce" src="https://www.mprove.de/script/99/kai/_media/high/bryce_full.jpg" name="bryce"></p>
			<p>Fig. 5 Bryce 2</p>
			<h4><a id="rooms" name="rooms"></a><a name="Lombreglia97"></a>Rooms</h4>
			<blockquote>
				<p>»The writer <a href="https://en.wikipedia.org/wiki/John_Updike">John Updike</a> is said to have several different writing rooms in his home, each used for a different kind of work -- a fiction room, a poetry room, a room for writing essays and book reviews. All writers want a special room for working (with door, without telephone), but why would any writer -- even such a deservedly successful and prosperous one as John Updike -- need entirely different rooms for different kinds of writing?<br>
					Actually, I know exactly why. Mr. Updike’s arrangement sounded great to me the first time I heard about it. I’m sure working in those rooms is his way of staying inspired, fighting boredom and distraction, getting creative work done by being in a space that’s not only set aside for work but that also somehow provokes that work, probably in quite subtle ways.« [<a href="https://www.mprove.de/script/99/kai/index.html#refLombreglia97">Lombreglia97</a>]</p>
			</blockquote>
			<p><a name="Fig6 GOO"></a><img id="goo" src="https://www.mprove.de/script/99/kai/_media/high/GOO.jpg" name="goo"></p>
			<p>Fig. 6 Kai’s Power GOO</p>
			<p>The <em>GOO room</em> is a specialized environment for shifting pixels around. But because Kai’s Power GOO is one of the first stand-alone applications from MetaTools some operating systems tasks like opening and closing images need to be accessible within the application. In order not to clutter the room that is special suited to edit the image, other rooms become part of the application. <span><a href="http://www.macworld.com/article/3005783/software-graphics/an-ode-to-kais-power-goo.html"><span>cf. An ode to Kai’s Power Goo, Macworld 11/2015</span></a></span> E.g. <em>Kai’s Photo Soap</em> (Fig. 7) initially presents you with a series of seven “rooms” – In, Prep, Tone, Color, Detail, Finishing and Out – which one can enter to perform particular tasks.</p>
			<p><img id="soap-rooms" src="https://www.mprove.de/script/99/kai/_media/high/SoapRooms.jpg" name="soap-rooms"></p>
			<p>Fig. 7 Plan-Room in Kai’s Photo Soap</p>
			<h3><a id="Bier93" name="Bier93"></a>Minimize the Interface</h3>
			<p>The concept of Magic Lenses was introduced by [<a href="https://www.mprove.de/script/99/kai/index.html#refBier93">Bier et al. 93</a>]. Two years later Kai designed a tool for KPT3 that can be dragged on top of an image. A circled look-through area shows a preview of the selected filter attributes.</p>
			<p><img id="lens" src="https://www.mprove.de/script/99/kai/_media/high/KPTLens.jpg" name="lens"></p>
			<p>Fig. 8 KPT Lens f/x 3.0 on top of a Photoshop image window</p>
			<p><a name="Kai95-2"></a>Kai himself describes the design concept that lead to the lens tool in KPT3:</p>
			<blockquote>
				<p>»What is called the “lenses” was in alpha known as the Dragon, as in “drag-on-the-image” and its design concept was so simple: make a precision instrument, like a little Swiss Army knife or a watch or microscope (it was also known as the fx Scope…) which has just a few very tiny controls around a center window. In this window a number of effects could be shown exactly as they would appear, over the real image, and updated in realtime.<br>
					It’s a lovely idea to keep all kinds of options hidden inside little wheels and dials that pop out to set and hide themselves during use… I think we have barely begun to use all the possibilities of that. And the actual interaction with the screen image is still a little clunky, hampered by the very illegality of bypassing the plug-in interface altogether.« [<a href="https://www.mprove.de/script/99/kai/index.html#refKai95">Kai95</a>]</p>
			</blockquote>
			<p>Soap is the consequent next step into this direction. The tools no longer need to be modal like the KPT lens; they can be used in a very natural modeless manner. Pens, brushes and erasers are distributed all over the workspace. They are large, they cast <strike>real</strike> virtual shadows, and the tips of the tools get pressed down while they are in use.</p>
			<p><img id="soap" src="https://www.mprove.de/script/99/kai/_media/high/Soap.jpg" name="soap" height="500" width="776"></p>
			<p>Fig. 9 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mprove.de/script/99/kai/index.html">https://www.mprove.de/script/99/kai/index.html</a></em></p>]]>
            </description>
            <link>https://www.mprove.de/script/99/kai/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739545</guid>
            <pubDate>Sun, 05 Jul 2020 15:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Understand Things]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739474">thread link</a>) | @nqureshi
<br/>
July 5, 2020 | https://nabeelqu.co/understanding | <a href="https://web.archive.org/web/*/https://nabeelqu.co/understanding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nabeelqu.co/understanding</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739474</guid>
            <pubDate>Sun, 05 Jul 2020 15:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JIT Compilers Are Implemented and Fast: Julia, PyPy, LuaJIT, Graal and More]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23739416">thread link</a>) | @kipply
<br/>
July 5, 2020 | https://carolchen.me/blog/jits-impls/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/jits-impls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>This post goes into details of 5+ JITs and various optimization strategies and discuss how they work with different JITs. Information in this blog post is more <em>depth-first</em>, thus there are many important concepts that may be skipped.</p>
<p>For background on JIT compilers see <a href="https://carolchen.me/blog/jits-intro">A Deep Introduction to JIT Compilers: JITs are not very Just-in-time</a>. If the title does not make sense to you then it may be worth a skim. </p>
<blockquote>
<p><em>Mild Disclaimers, can be skipped</em>.</p>
</blockquote>
<blockquote>
<p>I will often describe an optimization behaviour and claim that it probably exists in some other compiler. Though I don't always check if an optimization exists in another JIT (it's sometimes ambiguous), I'll always state explicitly if I know it’s there. 
I will also provide code examples to show where an optimization might occur, however the optimization may not necessarily occur for that code because another optimization will take precedence. There may also be some general oversimplifications, but not more than I think exists in most posts like these. </p>
</blockquote>
<h2 id="table-of-contents-highlights">Table of Contents / Highlights<a href="#table-of-contents-highlights" aria-label="Anchor link for: table-of-contents-highlights"> <i></i></a>
</h2>
<ul>
<li><a href="https://carolchen.me/blog/jits-impls/#wait-but-you-said-meta-tracing">Meta-tracing in Pypy works</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#interpreting-c">How GraalVM languages support C extensions</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#go-back-to-the-interpreted-code-it-ll-be-faster">Deoptimisation</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#wet-code-is-fast-code-inlining-and-osr">Inlining and OSR</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#what-if-instead-of-instruction-based-ir-like-everyone-else-we-had-a-big-graph-and-also-it-modifies-itself">Seas of Nodes</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#yay-jit-compiled-code-let-s-compile-it-again-and-again">Tiering JITs</a></li>
</ul>

<p>LuaJIT employs a method called tracing. Pypy does meta-tracing, which involves using a system to generate tracing interpreters and JITs. Pypy and LuaJIT are not the reference implementations of Python or Lua, but a projects on their own. I would describe LuaJIT as shockingly fast, and it describes itself as one of the fastest dynamic language implementations -- which I buy fully.</p>
<p>To determine when to start tracing, the interpreting loop will look for "hot" loops to trace (the concept of "hot" code is universal to JITS!). Then, the compiler will "trace" the loop, recording executed operations to compile well optimized machine code. In LuaJIT, the compilation is performed on the traces with an instruction-like IR that is unique to LuaJIT. </p>
<h3 id="how-pypy-implements-tracing"><strong>How Pypy Implements Tracing</strong><a href="#how-pypy-implements-tracing" aria-label="Anchor link for: how-pypy-implements-tracing"> <i></i></a>
</h3>
<p>Pypy will start tracing a function after 1619 executions, and will compile it after another 1039 executions, meaning a function has to execute around 3000 times for it to start gaining speed. These constants were carefully tuned by the Pypy team (lots of constants are tuned for compilers in general!).</p>
<p>Dynamic languages make it hard to optimize things away. The following code could be statically eliminated by a stricter language, as <code>False</code> will always be falsy. However, in Python 2, that could not have been guaranteed before runtime.</p>
<pre><code><span>if </span><span>False</span><span>:
  </span><span>print</span><span>(</span><span>"FALSE"</span><span>)
</span></code></pre>
<p>For any sane program, the conditional will always be false. Unfortunately, the value of <code>False</code> could be reassigned and thus if the statement were in a loop, it could be redefined somewhere else. For this case, Pypy would build a "guard". When a guard fails, the JIT will fall back to the interpreting loop. Pypy then uses another constant (200), called <em>trace eagerness</em> to decide whether to compile the rest of the new path till the end of the loop. That sub-path is called a <em>bridge</em>.</p>
<p>Pypy also exposes all those constants as arguments that can be tweaked at execution, along with configuration for unrolling (expanding loops) and inlining! It also exposes some hooks so we can see when things are compiled. </p>
<pre><code><span>def </span><span>print_compiler_info</span><span>(</span><span>i</span><span>):
  </span><span>print</span><span>(i</span><span>.</span><span>type)
pypyjit</span><span>.</span><span>set_compile_hook</span><span>(print_compiler_info)

</span><span>for </span><span>i </span><span>in </span><span>range</span><span>(</span><span>10000</span><span>):
  </span><span>if </span><span>False</span><span>:
    </span><span>pass

</span><span>print</span><span>(pypyjit</span><span>.</span><span>get_stats_snapshot</span><span>()</span><span>.</span><span>counters)
</span></code></pre>
<p>Above, I set up a plain python program with a compile hook to print the type of compilation made. It also prints some data at the end, where I can see the number of guards. For the above I get one compilation of a loop and 66 guards. When I replaced the if statement with just a pass under the for-loop, I was left with 59 guards.</p>
<pre><code><span>for </span><span>i </span><span>in </span><span>range</span><span>(</span><span>10000</span><span>):
  </span><span>pass </span><span># removing the `if False` saved 7 guards!
</span></code></pre>
<p>With these two lines added to the for loop, I will get two compilations, with the new one being of type 'bridge'!</p>
<pre><code><span>if </span><span>random</span><span>.</span><span>randint</span><span>(</span><span>1</span><span>, </span><span>100</span><span>) </span><span>&lt; </span><span>20</span><span>:
  </span><span>False </span><span>= </span><span>True
</span></code></pre><h3 id="wait-but-you-said-meta-tracing">Wait, but you said Meta-tracing!<a href="#wait-but-you-said-meta-tracing" aria-label="Anchor link for: wait-but-you-said-meta-tracing"> <i></i></a>
</h3>
<p>The concept behind meta-tracing is “write an interpreter, get a compiler for free!” or more magically, “turn your interpreter into a JIT-compiler!”. This is just obviously a great thing, since writing compilers is hard so if we can get a great compiler for free that’s just a good deal. Pypy "has" an interpreter and a compiler, but there’s no explicit implementation of a traditional compiler.</p>
<p>Pypy has a toolchain called RPython (which was built for Pypy). It is a framework program for implementing interpreters. It is a language in that it specifies a subset of the Python language, namely to force things like static typing. It is a language to write an interpreter in. It is not a language to code in typed-Python, since it doesn’t care or have things like standard libraries or packages. Any RPython program is a valid Python program. RPython programs are transpiled to C and then compiled. Thus, the RPython meta-compiler exists as a compiled C program.</p>
<p>The “meta” in meta-tracing comes from the fact that the trace is on the execution of the interpreter rather than the execution of the program. The interpreter more or less behaves as any interpreter, with the added capability of tracing its own operations, and being engineered to optimize those traces by updating the path of the interpreter (itself). With further tracing, the path that the interpreter takes becomes more optimized. With a very optimized interpreter taking a specific, optimized path, the compiled machine code being used in that path from the compiled RPython can be used as the compilation. </p>
<p>In short, the “compiler” in Pypy is compiling your interpreter, which is why Pypy is sometimes referred to as a meta-compiler. The compiler is less for the program you're trying to execute, but rather for compiling the trace of the optimizing interpreter!</p>
<p>Metatracing might be confusing, so I wrote a very bad metatracing program that can only understand <code>a = 0</code> and <code>a++</code>to illustrate.</p>
<pre><code><span># interpreter written with RPython
</span><span>for </span><span>line </span><span>in </span><span>code:
  </span><span>if </span><span>line </span><span>== </span><span>"a = 0"</span><span>:
    </span><span>alloc</span><span>(a, </span><span>0</span><span>)
  </span><span>elif </span><span>line </span><span>== </span><span>"a++"</span><span>:
    </span><span>guard</span><span>(a, </span><span>"is_int"</span><span>) </span><span># notice how in Python, the type is unknown, but after being interpreted by RPython, the type is known
    </span><span>guard</span><span>(a, </span><span>"&gt; 0"</span><span>)
    </span><span>int_add</span><span>(a, </span><span>1</span><span>)
</span></code></pre>
<p>If I ran the following in a hot loop;</p>
<pre><code><span>a </span><span>= </span><span>0
</span><span>a</span><span>++
</span><span>a</span><span>++
</span></code></pre>
<p>Then the traces may look something like:</p>
<pre><code><span># Trace from numerous logs of the hot loop
</span><span>a </span><span>= </span><span>alloc</span><span>(</span><span>0</span><span>) </span><span># guards can go away
</span><span>a </span><span>= </span><span>int_add</span><span>(a, </span><span>1</span><span>)
a </span><span>= </span><span>int_add</span><span>(a, </span><span>2</span><span>)

</span><span># optimize trace to be compiled
</span><span>a </span><span>= </span><span>alloc</span><span>(</span><span>2</span><span>) </span><span># the section of code that executes this trace _is_ the compiled code
</span></code></pre>
<p>But the compiler isn't some special standalone unit, it's built into the interpreter! So the interpreter loop would actually look something like this</p>
<pre><code><span>for </span><span>line </span><span>in </span><span>code:
  </span><span>if </span><span>traces</span><span>.</span><span>is_compiled</span><span>(line):
    </span><span>run_compiled</span><span>(traces</span><span>.</span><span>compiled</span><span>(line))
    </span><span>continue
  elif </span><span>traces</span><span>.</span><span>is_optimized</span><span>(line):
    </span><span>compile</span><span>(traces</span><span>.</span><span>optimized</span><span>(line))
      </span><span>continue
  elif </span><span>line </span><span>== </span><span>"a = 0"
  </span><span># ....
</span></code></pre><h2 id="an-introduction-to-jvms">An Introduction to JVMs<a href="#an-introduction-to-jvms" aria-label="Anchor link for: an-introduction-to-jvms"> <i></i></a>
</h2>
<p>Disclaimer: I worked on/with a Graal-based language, <a href="https://github.com/oracle/truffleruby">TruffleRuby</a> for four months and loved it.</p>
<p>Hotspot (named after looking for <em>hot</em> spots) is the VM that ships with standard installations of Java, and there are actually multiple compilers in it for a tiered strategy. Hotspot is open source, with 250,000 lines of code which contains the compilers, and three garbage collectors. It does an <em>awesome</em> job at being a good JIT, there are some benchmarks that have Hotspot on par with C++ impls (oh my gosh so many asterisks on this, you can Google to find all the debate). Though Hotspot is not a tracing JIT, it employs a similar approach of having an interpreter, profiling and then compiling. There is not a specific name for what Hotspot does, though the closest categorization would probably be a Tiering JIT. </p>
<p>Strategies used in Hotspot inspired many of the subsequent JITs, the structure of language VMs and especially the development of Javascript engines. It also created a wave of JVM languages such as Scala, Kotlin, JRuby or Jython. JRuby and Jython are fun implementations of Ruby and Python that compile the source code down to the JVM bytecode and then have Hotspot execute it. These projects have been relatively successful at speeding up languages like Python and Ruby (Ruby more so than Python) without having to implement an entire toolchain like Pypy did. Hotspot is also unique in that it's a JIT for a less dynamic language (though it's technically it's a JIT for JVM bytecode and not Java). </p>
<p><img src="https://carolchen.me/blog/img/jits/vms.png" alt=""></p>
<p>GraalVM is a JavaVM and then some, written in Java. It can run any JVM language (Java, Scala, Kotlin, etc). It also supports a Native Image, to allow AOT compiled code through something called Substrate VM. Twitter runs a significant portion of their Scala services with Graal, so it must be pretty good, and better than the JVM in some ways despite being written in Java. </p>
<p>But wait, there's more! GraalVM also provides Truffle, a framework for implementing languages through building Abstract Syntax Tree (AST) interpreters. With Truffle, there’s no explicit step where JVM bytecode is created as with a conventional JVM language, rather Truffle will just use the interpreter and communicate with Graal to create machine code directly with profiling and a technique called partial evaluation. Partial evaluation is out of scope for this blog post, tl;dr it follows metatracing’s “write an interpreter, get a compiler for free” philosophy but is approached differently.</p>
<blockquote>
<p>TruffleJS, the Truffle implementation of Javascript outperforms the JavaScript V8 engine on select benchmarks which is really impressive since V8 has had numerous more years of development, Google money+resources poured in and some crazy skilled people working on it. TruffleJS is still by no means “better” than V8 (or other JS engines) on most measures but it is a sign of promise for Graal. </p>
</blockquote>

<h3 id="interpreting-c">Interpreting C<a href="#interpreting-c" aria-label="Anchor link for: interpreting-c"> <i></i></a>
</h3>
<p>A common problem with JIT implementations is support for C Extensions. Standard interpreters such …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/jits-impls/">https://carolchen.me/blog/jits-impls/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/jits-impls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739416</guid>
            <pubDate>Sun, 05 Jul 2020 15:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Andrew Wilkinson and Tiny Capital]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23739381">thread link</a>) | @colinkeeley
<br/>
July 5, 2020 | https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual | <a href="https://web.archive.org/web/*/https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-db1d94e86a488296a48d"><div><blockquote><p><em>“Let someone else run the marathon and incentivize them.”&nbsp;</em></p><p><em>-Andrew Wilkinson</em></p></blockquote><p><strong>What is Tiny?</strong></p><p><a href="http://tinycapital.com/">Tiny</a>&nbsp;is a long term holding company for internet businesses started by&nbsp;<a href="https://twitter.com/awilkinson">Andrew Wilkinson</a>&nbsp;and&nbsp;<a href="https://twitter.com/_sparling_?lang=en">Chris Sparling</a>. They take majority, generally whole, stakes in "profitable, simple, and often boring” internet businesses.&nbsp;</p><p><strong>Why are holding companies and micro private equity interesting?&nbsp;</strong></p><p>I suspect this is the most dependable way to become very wealthy. It isn’t as glamorous or as quick (potentially) as founding or investing in the next multi-billion dollar startup. This is a longer-term grind it out approach.&nbsp;</p><p>Starting companies is fun, but anyone who has done it knows it is a lot of work. Buying established businesses with existing cash flow isn’t as sexy so I suspect it is wildly underrated as a way of building wealth.&nbsp;</p><p>The reality is that it is easier to buy and improve businesses than to start them. It is easier to go from 3 to 10 than from 0 to 1. Even for the folks that have done it before.&nbsp;</p><p>There isn’t much info on how holding companies or micro-PEs like Tiny actually operate. I’ve listened to every podcast Andrew has been on and compiled these notes from them.&nbsp;</p><p>Here is what they are doing behind the scenes.</p><p><strong>How Andrew got started? Where the capital comes from?</strong></p><p>In 2006, Andrew founded&nbsp;<a href="http://metalab.co/">MetaLab</a>, a Victoria, Canada-based design agency shortly after high school. After rapid growth, he used the profits to diversify into a variety of businesses, which today form Tiny, a holding company he owns fully with his business partner Chris Sparling.&nbsp;</p><p>Agencies traditionally aren’t very profitable, but MetaLab is able to charge San Francisco agency rates and only pay Victoria, Canada wages.&nbsp;</p><p>Tiny shifted its focus from starting businesses to buying them in 2013 when MetaLab and all their other businesses combined were doing $7M/year in profit. Tiny is fully self-funded today.</p><p><strong>What’s the scale of Tiny now?</strong></p><p>Comfortably not tiny. It sounds like somewhere around $80-95M revenue per year (double-digit millions is what Andrew says) with highly profitable businesses. They have around 350-400 employees across 20ish companies.&nbsp;</p><p><strong>What Tiny looks for in businesses to buy?</strong></p><p>From their site:</p><blockquote><p><em>3-5+ years of operating history</em></p><p><em>Profits. A minimum $500k/year in annual profit, as high as $15MM.</em></p><p><em>A high-quality team in place. This is negotiable if the business is simple to operate and the team wants to leave.</em></p><p><em>We are open to owners sticking around, leaving cold turkey, or transitioning out over time. We'll work with you to transition.</em></p><p><em>Simple internet businesses that have high margins, don't require tons of people or complex technology, and have a competitive advantage that protects them from competitors. For example: A dominant brand, a large and loyal community, a niche vertical, or something similar.</em></p></blockquote><p>Andrew describes these businesses as "New Zealand companies.”</p><p>What is a New Zealand company?</p><ul data-rte-list="default"><li><p>It is in the middle of nowhere, nobody is paying attention to it, but it is quietly growing. It is not at risk of nuclear war.&nbsp;</p></li><li><p>It is self-sufficient and thriving. It’s food &amp; energy independent. A "safe" business isn't beholden to benevolent gatekeepers like Google or Facebook to reach their customer.&nbsp;</p></li></ul><p>Andrew is always worried about staying power.&nbsp;</p><p>An example of one of his New Zealand business is Dribbble:</p><ul data-rte-list="default"><li><p>Top 1,000 site on the internet&nbsp;</p></li><li><p>A huge community of designers</p></li><li><p>Profitable</p></li><li><p>Few competitors. Big companies are not trying to kill it or compete.&nbsp;</p></li><li><p>Not dependent on Facebook or Google for traffic. People type Dribbble.com into the address bar to visit.&nbsp;</p></li></ul><p><strong>Types of businesses Tiny has bought/started?</strong></p><p>I don’t know if this is by design, but it seems like Andrew has progressed from services to tools/products to platforms/communities to digital marketplaces.&nbsp;</p><ul data-rte-list="default"><li><p>Agencies: MetaLab (design agency), Double Up (podcast growth agency), 8020 (no-code agency)</p></li><li><p>SaaS tools:&nbsp;Flow&nbsp;(product management), Castro (podcast player), Supercast (podcast subscriptions)</p></li><li><p>Products: Caramba (furniture)</p></li><li><p>Communities: Dribbble&nbsp;(designer community)</p></li><li><p>Media: Designer News, RideHome (podcast network)</p></li><li><p>Job Boards:&nbsp;We Work Remotely (remote job board)</p></li><li><p>Digital goods marketplaces: Creative Market, Pixel Union</p></li></ul><p><strong>How Tiny companies operate?</strong></p><p>Tiny companies have fewer information responsibilities than typical PE-owned companies. There are no formal board meetings for example.&nbsp;</p><p>Once a month companies send Tiny a finance-only update with the P&amp;L, balance sheet, and KPIs. No operational info is included.&nbsp;</p><p>Once a quarter companies send Tiny a SWOT (strengths, weaknesses, opportunities, and threats) analysis.&nbsp;</p><p>Companies contact Tiny ASAP for emergencies, major news, or decisions.&nbsp;</p><p>Some CEOs will go 6 months or more without speaking with Andrew.&nbsp;</p><p><strong>How Tiny launches new businesses?</strong></p><p>Tiny’s primary business is buying majority stakes in businesses, not starting them. For a while Andrew would start a new business in any niche he was interested in. He tries to avoid that now and thinks it’s a lot better to buy something that is already good.</p><p>When Andrew does start a new business now, he delegates almost all aspects of it. He recently said he only spent something like 4 hours on each of the new businesses he has launched.&nbsp;</p><p>Andrew will pay for all the work to be done and the investment will form his stake in the business. He will find a CEO to run the business and pay the new CEOs a month or two of salaries to get things going. Then he’ll help with intros, but otherwise, he’ll be hands-off. All in he said it takes $10-50k to get off the ground with a great operator.</p><p><strong>Why do Founders sell to Tiny?</strong></p><p>Tiny is positioned as the good guys of private equity. The Berkshire Hathway of internet businesses.</p><p>They have become known for doing simple acquisitions. Andrew didn’t like the traditional acquisition process: long due diligence, and renegotiation of terms. Warren Buffet does deals in seven days and those are larger, more complex businesses. Smaller deals should be even quicker.</p><p>A challenge with this model is that it is difficult to acquire tech companies at reasonable prices. Acquiring boring traditional businesses is easier because the valuations are so much lower than tech companies. To successfully use this approach you need discipline around what you’re willing to pay for a business and a reputation for being easy to work with. Andrew gets deals by being a nice guy and offering a good home for businesses to live on. Contrast this with the typical PE approach of dramatically cutting costs (ie firing everyone) and squeezing as much profit out as possible. Some founders are looking more for freedom and an easy process than maximizing their financial outcome. </p><p>These smaller PE opportunities are underserved relative to the typical VC businesses. The lifestyle businesses that VC shuns are Andrew’s ideal companies. He is fishing in a less crowded pond. </p><p>Andrew will occasionally pay 10x for an amazing business, but that is rare.&nbsp;</p><p><strong>What happens to businesses after the sale?&nbsp;</strong></p><p>For the employees, it is business as usual for the most part. The goal is for the employees to not even notice.&nbsp; </p><p>The biggest difference is that Tiny becomes the bank. Cash is kept in the company based on historical working capital needs and any extra goes to the head office for new acquisitions.&nbsp; </p><p>Often Tiny buys product or designer-led startups that have grown organically. They will put standard best-practice marketing and sales processes in place and sometimes raise prices. Each company has its own CEO with a few exceptions like all job boards (5+) are under one CEO.&nbsp; </p><p>Tiny has a preference for remote companies where they can hire more affordably. Andrew estimates the cost of running a business in Canada can be 60-65% the cost of in California. Struggling American companies with inflated cost structures can reduce costs by moving to Canada. Canadian arbitrage includes lower salaries, not needing to pay medical benefits, SRED, and cheaper currency.</p><p><strong>Who runs the business after a sale?&nbsp;</strong></p><p>Often Andrew is buying from bootstrapped founders that have been at it for 5-10 years and want to move on.</p><p>Finding great people to run these companies is one of the hardest aspects of this model.&nbsp;</p><p>Andrew deals with this by paying up and hiring CEOs that have managed similar businesses at larger scales already before instead of trying to find underpriced less-experienced talent.&nbsp;</p><p>Months before closing on a deal Andrew works to identify opportunities for the business and a new leader to come in.&nbsp;</p><p>He finds these new CEOs through his existing CEOs by asking “we’re about to buy a business who’s the smartest person you know in the space."</p><p><strong>What does the operating company and Andrew do day-to-day?</strong></p><blockquote><p><em>“Entrepreneurship is just delegation”&nbsp;</em></p><p><em>-Andrew Wilkinson</em></p></blockquote><p>Andrew spends time looking for new deals and looking at their existing portfolio and thinking "how they could get fucked”.&nbsp;</p><p>Andrew says his strengths are:</p><ul data-rte-list="default"><li><p>Laser focused on problems for a short period of time. Moves fast.&nbsp;</p></li><li><p>Very good at 0 to 1. Burns bright for 15 days.&nbsp;</p></li><li><p>Inch deep and a mile wide</p></li><li><p>Not good at execution or day to day details</p></li></ul><p>Being comfortable with delegation is key to this model. Andrew is the owner, not the CEO. The owner can’t constantly be delegating what can or can’t be done or the CEO grows resentful. Some comfort with decisions being made that you don’t agree with comes with the territory. Large decisions that require more capital than usual are a discussion.&nbsp;</p><p><strong>How connected are businesses in the holding company?</strong></p><p>Tiny companies are not at all connected. They each operate independently.&nbsp;</p><p>CEOs will take calls and give advice on best practices, but nothing beyond small favors. Real work gets paid for. Tiny pays all companies for the work they do for the holding company and all work between companies is paid at the full rate.&nbsp;</p><p>Synergies are appealing, but they generally just make the CEOs resentful so they are avoided entirely.&nbsp;</p><p><strong>How much debt do they use?</strong></p><p>Tiny uses little debt for acquisitions (less than Berkshire Hathaway) and they like to pay off debt within 6 months. Debt comes from&nbsp;<a href="https://en.wikipedia.org/wiki/Business_Development_Bank_of_Canada"><strong>BDB of Canada</strong></a>, or traditional banks.</p><p><em>If you …</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual">https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual</a></em></p>]]>
            </description>
            <link>https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739381</guid>
            <pubDate>Sun, 05 Jul 2020 15:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciphering Repeated-Key XOR Ciphertexts Using Hamming Distance]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739362">thread link</a>) | @arpitbbhayani
<br/>
July 5, 2020 | https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Encryption is a process of encoding messages such that it can only be read and understood by the intended parties. The process of extracting the original message from an encrypted one is called Decryption. Encryption usually scrambles the original message using a key, called the encryption key, that the involved parties agree on.</p>
<p>In the previous essay, we went through the <a href="https://arpitbhayani.me/blogs/decipher-single-xor">Single-byte XOR cipher</a> and found a way to decipher it without having any knowledge of the encryption key. In this essay, we find how to break a <a href="https://en.wikipedia.org/wiki/XOR_cipher">Repeating-key XOR cipher</a> with variable key length. The problem statement, defined above, is based on <a href="https://cryptopals.com/sets/1/challenges/6">Cryptopals Set 1 Challenge 6</a>.</p>

<p>The Repeating-key XOR cipher algorithm works with an encryption key with no constraint on its length, which makes it much stronger than a Single-byte XOR Cipher, where the encryption key length was restricted to a single byte.</p>
<h2>Encryption</h2>
<p>A plain text is encrypted using an encryption key by performing a bitwise <a href="https://en.wikipedia.org/wiki/Exclusive_or">XOR</a> operation on every character. The encryption key is repeated until it XORs every single character of the plain text and the resultant stream of bytes is again translated back as characters and sent to the other party. These encrypted bytes need not be among the usual printable characters and should ideally be interpreted as a stream of bytes. Following is the python-based implementation of this encryption process.</p>
<pre><code><span><span>def</span> <span>repeating_key_xor</span><span>(text: bytes, key: bytes)</span> -&gt; bytes:</span>
    <span>"""Given a plain text `text` as bytes and an encryption key `key`
    as bytes, the function encrypts the text by performing
    XOR of all the bytes and the `key` (in repeated manner) and returns
    the resultant XORed byte stream.
    """</span>
    
    
    
    repetitions = <span>1</span> + (len(text) // len(key))
    key = key * repetitions
    key = key[:len(text)]

    
    <span>return</span> bytes([b ^ k <span>for</span> b, k <span>in</span> zip(text, key)])
</code></pre>
<p>As an example, we encrypt the plain text - <code>secretattack</code> - with encryption key <code>$^!</code> and as per the algorithm, we first repeat the encryption key until it matches the length of the plain text and then XOR it against the plain text. The illustration below shows the entire encryption process.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png" alt="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png"></p>
<p>For the first character in plain text - <code>s</code> - the byte i.e. ASCII value is <code>115</code> which when XORed with <code>$</code> results in <code>87</code> whose character equivalent is <code>W</code>, similarly for the second character <code>e</code> the encrypted byte is <code>;</code>, for <code>c</code> it is <code>B</code>, for the fourth character <code>r</code>, since the key repeats, the XOR is taken with <code>$</code> to get <code>V</code> and the process continues. The resultant encrypted text using repeated-key XOR on the plain text <code>secretattack</code> with key <code>$^!</code> is <code>W;BV;UE*UE=J</code>.</p>
<h2>Decryption</h2>
<p>Decryption is a process of extracting the original message from the encrypted ciphertext given the encryption key. XOR has a <a href="https://brainly.in/question/3038497">property</a> - if <code>a = b ^ c</code> then <code>b = a ^ c</code>, hence the decryption process is exactly the same as the encryption i.e. we first repeat the encryption key till it matches the length and then perform bitwise XOR with the ciphertext - the resultant bytes stream will be the original message.</p>
<p>Since encryption and decryption both have an exact same implementation - we pass the ciphertext to the function <code>repeating_key_xor</code>, defined above, to get the original message back.</p>
<pre><code><span>&gt;&gt;&gt; </span>repeating_key_xor(<span>b'W;BV;UE*UE=J'</span>, <span>b'$^!'</span>)
<span>b'secretattack'</span>
</code></pre>

<p>Things become really interesting when, given the encryption algorithm, we have to recover the original message from the ciphertext with no knowledge of the encryption key. Just like solving any other problem, the crux of deciphering the message encrypted using repeated-key XOR cipher is to break it down into manageable sub-problems and tackle them independently. We break this deciphering problem into the following two sub-problems:</p>
<ul>
<li>Finding the length of the Encryption Key</li>
<li>Bruteforce with all possible keys and finding the "most English" plain text</li>
</ul>
<h2>Finding the length of the Encryption Key</h2>
<p>In order to recover the original text from the cipher, we first find the length of the encryption key used and then apply brute force with all possible keys of the estimated length and deduce the plain text. Finding the length of the Encryption key makes the deciphering process quicker as it eliminates a lot of false keys and thus reducing the overall effort required during the brute force. In order to find the length of the Encryption Key, we need to have a better understanding of a seemingly unrelated topic - Hamming Distance.</p>
<h3>Hamming Distance</h3>
<p>Hamming distance between two bytes is the number of positions at which the corresponding bits differ. For a stream of bytes, of equal lengths, it is the sum of Hamming Distances between the corresponding bytes. Finding differences between bits can be efficiently done using bitwise XOR operation as the operation yields <code>0</code> when both the bits are the same and <code>1</code> when they differ. So for computing Hamming Distance between two bytes we XOR the bytes and count the number of <code>1</code> in its binary representation.</p>
<pre><code><span><span>def</span> <span>hamming_distance_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; int:</span>
    <span>"""Given two stream of bytes, the function returns the Hamming Distance
    between the two.
    Note: If the two texts have unequal lengths, the hamming distance is
    computed only till one of the text exhausts, other bytes are not iterated.
    """</span>
    dist = <span>0</span>
    <span>for</span> byte1, byte2 <span>in</span> zip(text1, text2):
        dist += bin(byte1 ^ byte2).count(<span>'1'</span>)
    <span>return</span> dist

<span>&gt;&gt;&gt; </span>hamming_distance_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>4</span>
</code></pre>
<p>In the example above, we find that the hamming distance between two bytestreams <code>ab</code> and <code>zb</code> is <code>4</code>, which implies that the byte streams <code>ab</code> and <code>zb</code> differ at <code>4</code> different bits in their binary representations.</p>
<h3>Hamming Score</h3>
<p>Hamming distance is an absolute measure, hence in order to compare hamming distance across byte streams of varying lengths, it has to be normalized with the number of pairs of bits compared. We name this measure - Hamming Score - which thus is defined as the Hamming Distance per unit bit-pair. In python, Hamming Score is implemented as:</p>
<pre><code><span><span>def</span> <span>hamming_score_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; float:</span>
    <span>"""Given two streams of bytes, the function computes a normalized Hamming
    Score based on the Hamming distance.
    Normalization is done by dividing the Hamming Distance by the number of bits
    present in the shorter text.
    """</span>
    <span>return</span> hamming_distance_bytes(text1, text2) / (<span>8</span> * min(len(text1), len(text2)))

<span>&gt;&gt;&gt; </span>hamming_score_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>0.25</span>
</code></pre>
<h3>What can we infer through Hamming Distance?</h3>
<p>Hamming Distance is an interesting measure; it effectively tells us the minimum number of bit flips required to convert one bytestream into another. It also implies that (on average) if the numerical values of two bytestreams are closer then their Hamming Distance and Hamming Score will be lower i.e it would take fewer bit flips to convert one into another.</p>
<p>This is evident from the fact that the average Hamming distance between any two bytes <code>[0-256)</code> picked at random is <code>3.9999</code> while that of any two lowercased English characters <code>[97, 122]</code> is just <code>2.45</code>. Similar ratios are observed for Hamming Score where <code>0.4999</code> is of the former while <code>0.3072</code> is of the later.</p>
<p>This inference comes in handy when we want to find out the length of Encryption Key in Repeating-key XOR Cipher as illustrated in the section below.</p>
<h3>Formal definition of encryption and decryption processes</h3>
<p>Say if <code>p</code> denotes the plaintext, <code>k</code> denotes the encryption key which is repeated to match the length of the plain text, and <code>c</code> denotes the ciphertext, we could define encryption and decryption processes as</p>
<pre><code>encryption: c[i] = p[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(c))
decryption: p[i] = c[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(p))
</code></pre>
<p>The above definitions, along with the rules of XOR operations, implying that if we XOR two bytes of the ciphertext, encrypted (XORed) using the same byte of the encryption key, we are effectively XORing the corresponding bytes of the plain text. If <code>k'</code> is the byte of the encryption key <code>k</code> which was used to encrypt (XOR) the bytes <code>p[i]</code> and <code>p[j]</code> of the plain text to generate <code>c[i]</code> and <code>c[j]</code> of the ciphertext, we could derive the following relation</p>
<pre><code># k' <span>is</span> the common byte <span>of</span> the key i.e. k' = k = k

c XOR c = (p XOR k') XOR (p XOR k')
              = p XOR k' XOR k' XOR p
              = p XOR 0 XOR p
              = p XOR p
</code></pre>
<p>The above relation, <code>c[i] XOR c[j]</code> equal to <code>p[i] XOR p[j]</code>, holds true only because both the bytes were XORed with the same byte <code>k'</code> of the encryption key; which in fact helped reduce the expression. If the byte from the encryption key which was used to XOR the pain texts were different then the relation was irreducible and we could not have possibly setup this relation.</p>
<h3>Chunking of ciphertext</h3>
<p>Chunking is the process where the ciphertext is split into smaller chunks (segments) of almost equal lengths. For example, chunking the ciphertext <code>W;BV;UE*UE=J</code> for chunk length <code>4</code> would create <code>3</code> chunks <code>W;BV</code>, <code>;UE*</code> and <code>UE=J</code>. The illustration below shows the chunks that would be formed for <code>W;BV;UE*UE=J</code> with chunks lengths varying from 2 to 6.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png" alt="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png"></p>
<h3>XOR of the chunks</h3>
<p>Something very interesting happens when we compute the Average Hamming Score for all possible chunk lengths. If we consider the ciphertext <code>b'W;BV;UE*UE=J</code> and we chunk it with lengths varying from 2 to 6, we get the following distribution for the Average Hamming Score for each of the chunk length.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png" alt="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png"></p>
<p>From the distribution above it is evident that the score was minimum at chunk length equalling <code>3</code>, which actually was the length of the Encryption Key used on the plain text. Is this mere coincidence or are we onto something?</p>
<p>When chunk length is equal to the length of the encryption key, the XOR operation on any two chunks will reduce the expression to XOR of the corresponding plain texts (as seen above), because there will be a perfect alignment of bytes from ciphertext and bytes from the keys i.e every <code>i</code>th byte from both the chunks would have been XORed with <code>i</code>th byte from the encryption key.</p>
<p>We have established that for chunk length equal to the length of the encryption key <code>c[i] XOR c[j]</code> …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn">https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn</a></em></p>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/decipher-repeated-key-xor?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739362</guid>
            <pubDate>Sun, 05 Jul 2020 15:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas to make daily stand-up meetings engaging in remote work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739264">thread link</a>) | @notatechie
<br/>
July 5, 2020 | https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/ | <a href="https://web.archive.org/web/*/https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content-container">

        	<div id="post-content">
			
            	   <p><img src="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg" alt="daily standup meetings for remote employee engagement" width="840" height="472" srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg 840w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-300x169.jpg 300w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-768x432.jpg 768w" sizes="(max-width: 840px) 100vw, 840px" data-srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg 840w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-300x169.jpg 300w, https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams-768x432.jpg 768w" data-src="https://www.peoplebox.ai/wp-content/uploads/2020/06/MS-teams.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p>Source – Microsoft teams</p>
<p><span><span>D</span>aily standup meetings are a routine part of a manager’s life.&nbsp;</span><span>They serve as an axis to keep the team well-connected and in touch with each other’s role in achieving the common goal.&nbsp;</span></p>
<p><span>In the wake of COVID-19 pandemic, the world continues to embrace remote work more and more.</span></p>
<p><span>Consequently, a manager has to reinvent her strategies with a </span><a href="https://www.peoplebox.ai/blog/remote-first-vs-remote-friendly-companies-whats-the-difference/"><span>remote-friendly approach</span></a><span> and find ways to maintain high </span><a href="https://www.peoplebox.ai/blog/how-important-is-remote-employee-engagement-to-team-productivity/"><span>remote employee engagement</span></a><span>.</span></p>

<div>
<p><strong>Some of the biggest problems a manager with remote employees face is eliminating the communication gap and daily standup meetings can be an effective way to deal with it.</strong></p>
</div>



<p><span>A standup meeting can also help a manager in improving remote employee engagement and increasing productivity besides removing barriers to communication.</span></p>
<p><span>All you need to do is follow certain tips to ensure that you derive maximum value from the time you spend in your daily standup meetings.</span></p>
<p><span>In this article, we set out to explore what exactly is a daily standup meeting, how it can make a difference to your remote team and what you can do to make it more effective and engaging.&nbsp;</span></p>
<p><span>So, let’s begin.</span></p>
<h2><b>What is a daily standup meeting?</b></h2>
<p><span>In an agile team, a daily standup meeting is where the team gets together every day for a specific time to discuss the daily progress and the plan to be followed.&nbsp;</span></p>
<p><span>As the name suggests, people often do not sit down in this meeting to avoid long discussion, stress on the urgency and keep the meeting straight-to-the-point and time-bound.</span></p>
<p><span>It is supposed to last for 15 minutes and addresses three main questions&nbsp;</span></p>
<ul>
<li><span>What has been achieved?</span></li>
<li><span>What remains to be done?</span></li>
<li><span>Are there any issues that are hampering the completion of a task?&nbsp;</span></li>
</ul>
<h2><b>Why are daily-standup meetings vital in remote work?</b></h2>
<p><span>The purpose of a daily standup meeting is to keep everyone on the same page which becomes even more important when you are managing a remote team.&nbsp;</span></p>
<p><span>In a regular office scenario, team members can walk up to each other to clear doubts and are&nbsp; aware of the real-time updates which cannot happen in a remote work setup.&nbsp;</span></p>
<p><span>Hence, a standup meeting serves as a tool to address issues collectively and improve transparency amongst team members.&nbsp;</span></p>
<p><span>A team with remote employees, however,&nbsp; may have members distributed over different geographical locations.&nbsp;</span></p>
<p><span>The absence of physical proximity makes communication and coordination more complex with remote employees.</span></p>
<p><span>Thus, the role of standup meetings expand and become more essential.</span></p>

<div>
<p><strong>In a remote work environment, standup meetings become a focal point of bringing the whole team together daily and discuss action items, strategies and blockers on a common platform for better synergy. </strong></p>
</div>

<p><span>Mostly, a standup meeting is the only time when the remote employees are present with other team members in the same capacity.</span></p>
<p><span>It keeps them in the loop and more connected.</span></p>
<h2><b>Difference between daily standup and status update meeting</b></h2>
<p><span>Their difference lies in the question they aim to answer.&nbsp;</span></p>
<p><span>In a status update meeting, the main concern is – “</span><b><i>How much work has been completed?”</i></b></p>
<p><span>But, in a daily standup meeting, the core theme is – “</span><b><i>What is your action plan for the day?”</i></b></p>

<div>
<p><strong>A status update meeting focuses on the progress of the deliverables whereas a daily standup meeting aims to improve planning and achieve maximum team collaboration. </strong></p>
</div>


<p><span>A status update meeting helps a manager in knowing what an individual employee has completed up to a point of time.&nbsp;</span></p>
<p><span>A daily standup meeting, on the other hand, concentrates upon how a team can achieve its goals together and the roadblocks the team is focusing on.&nbsp;</span></p>
<p><span>A status update meeting wants to know the results whereas a daily standup meeting aims to understand the future course of action.&nbsp;</span></p>
<h2><b>Benefits of daily standup meetings for remote employees</b></h2>
<p><span>Besides the advantages of flexibility and freedom, remote work also ushers in a set of unique challenges.</span></p>
<p><span>Lack of coordination and miscommunication happen to be some of the problems that remote employees face.</span></p>
<p><span>But, they’re only the tip of the iceberg.</span></p>
<p><span>There’re many intricate issues that a remote employee may face which are completely different from that of a regular office-going employee.</span></p>
<p><span>A daily standup meeting can help a manager streamline a lot of them. Here’s how –&nbsp;</span></p>
<h3><span><span>1 </span></span><b>Helps in building team rapport</b></h3>
<p><b><span>One of the major challenges of remote work is lack of human connection. </span></b></p>
<p><b><span>The lack of personal connection and acquaintance may cause major obstacles and hamper interpersonal coordination.</span></b></p>

<div>
<p><strong>A daily standup meeting allows the entire team to be present at the same time on the same platform even if it’s virtual. </strong></p>
</div>


<p><span>Your remote employees will get a chance to interact with other team members and learn more about them.</span></p>
<h3><span><span>2 </span></span><b>Removes roadblocks</b></h3>
<p><b><span>For a remote employee, their manager is their immediate and often the first&nbsp; point of contact for every issue they may be facing.</span></b></p>
<p>Some of the problems can easily be solved with the help of a fellow team member instead of reaching out to you directly.</p>
<p><span>However, remote employees are not acquainted enough with their teammates and are reluctant to contact them.</span></p>

<div>
<p><strong>A daily standup gives them a chance to get to know the entire team and helps them get familiar with other employees’ personalities and skills. </strong></p>
</div>


<p><span>It also eases their hesitation in approaching others and they may even solve many problems with their team member’s help rather than approaching you for every single issue.</span></p>
<h3><span><span>3 </span></span><b>Encourages knowledge transfer</b></h3>
<p><b><span>Your remote employees work independently and depend upon their knowledge, research and your guidance for learning and execution of their task.&nbsp;</span></b></p>
<p><span>In a shared workspace,&nbsp; team members tend to consult each other and rely on each other’s expertise to get things done.</span></p>
<p><span>There will always be an Alex who’s great at excel or a Tina who can make a presentation look better with a few tweaks.&nbsp;</span></p>
<p><span>A remote employee might not get the opportunity to know either Alex or Tina without a daily standup meeting.</span></p>

<div>
<p><strong>When every employee shares their issues on a common platform, they may be able to find help or suggestions from another team member. </strong></p>
</div>


<p><span>This exchange will encourage the transfer of valuable information and strengthen your team.&nbsp;</span></p>
<h3><span><span>4 </span></span><b>Improved coordination</b></h3>
<p><b><span>A daily standup meeting will ensure that all your direct reports are aware of the progress and the upcoming action plan.&nbsp;</span></b></p>
<p><span>This way everyone is aware of the responsibilities and there’s no scope of miscommunication or confusion.</span></p>
<p><span>Increased transparency and better communication lead to maximum coordination and saving of time.&nbsp;</span></p>
<h3><span><span>5 </span></span><b>Instill a recognition of shared goals</b></h3>
<p><b><span>Often, remote employees become isolated and estranged from the organizational goals.&nbsp;</span></b></p>
<p><span>They know that they’re expected to deliver 5 articles, or deploy the code, or provide 5 designs by the end of the period.&nbsp;</span></p>
<p><span>However, they don’t know how it contributes to the company and how it affects the overall process.</span></p>
<p><span>In a daily standup meeting, they get a complete view of the bigger picture and where they stand in it.&nbsp;</span></p>
<p><span>It instils a sense of belonging and helps them realize where they fit in the puzzle.</span></p>
<p><span>This knowledge of their work’s importance will </span><a href="https://www.peoplebox.ai/blog/how-to-boost-employee-morale-through-one-on-one-meetings/"><span>boost their morale</span></a><span> and will make them feel included.&nbsp;</span></p>
<h2><b>How can daily stand-up meetings help in remote employee engagement?</b></h2>
<p><span>Due to the precautions being taken up after the Coronavirus outbreak, the number of remote employees will rise inevitably.</span></p>
<p><span>A </span><a href="https://www.gartner.com/en/newsroom/press-releases/2020-04-03-gartner-cfo-surey-reveals-74-percent-of-organizations-to-shift-some-employees-to-remote-work-permanently2"><span>research by Gartner</span></a><span> reveals that 74% of CFOs are planning to shift a considerable number of their employees to remote work permanently.</span></p>

<p><img src="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png" alt="daily standup and status update meeting" width="744" height="311" srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png 744w, https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work-300x125.png 300w" sizes="(max-width: 744px) 100vw, 744px" data-srcset="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png 744w, https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work-300x125.png 300w" data-src="https://www.peoplebox.ai/wp-content/uploads/2020/06/Gartner-remote-work.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>

<p><span>While this move opens up new avenues to retain and hire diverse talent, it also poses the challenge of re-imagining the strategies to keep remote employees engaged and well-coordinated.</span></p>
<p><span>In a traditional workplace, daily standup meetings have been playing the role of channelizing better management among the team.&nbsp;</span></p>
<p><span>As a manager, you already know the ropes of conducting these meetings in a way that they are productive, engaging and interesting.&nbsp;</span></p>
<p><span>With the shift in workplace dynamics, you will have to accommodate remote employees and ensure that they are well-represented in the meeting.&nbsp;</span></p>
<p><span>Here’re a few tips that can help you out.&nbsp;</span></p>
<h2><b>Tips for productive &amp; engaging daily standup meetings for remote teams</b></h2>
<h3><span><span>1 </span></span><b>Decide a fixed time</b></h3>
<p><b><span>The reason why we have a standup meeting is to inculcate a routine of accountability, discipline and concrete planning in our team.&nbsp;</span></b></p>
<p><span>And, this is why you must decide upon a fixed time to conduct it every day.</span></p>
<p><span>If you change the time often, it will lead to confusion, delay and late arrival or absence of many employees.&nbsp;</span></p>
<p><span>With fixed time, your entire team will become habitual and will embrace it in their daily routine.&nbsp;</span></p>
<p><span>Ideally, a daily standup meeting should happen either at the beginning or the end of the day.</span></p>

<div>
<p><strong>A standup meeting at the start of the workday helps in planning the day while the one at the end helps in preparing your employees for what to expect the next day. </strong></p>
</div>


<p><span>In case, your remote employees are working from another timezone, you will need to ensure that they’re comfortable with the time.&nbsp;</span></p>
<p><span>Remember, a daily standup meeting will garner positive results only if all your team members are present; including your remote employees.&nbsp;</span></p>
<p><b><img alt="" width="20" height="28" data-src="https://www.peoplebox.ai/wp-content/uploads/2019/12/Untitled.png" src="https://www.peoplebox.ai/wp-content/uploads/2019/12/Untitled.png"> Pro tip: </b><span>Send out a calendar invite which includes a link to the virtual meeting and use the same link daily. </span></p>
<p><span>This will help all your direct reports in finding the meeting link every day without having to contact you or someone else.</span></p>
<h3><span><span>2 </span></span><b>Decide upon tech tools</b></h3>
<p><b><span>Now that your team has remote employees, you are more likely to conduct the daily standup meeting virtually.&nbsp;</span></b></p>
<p><span>Thus, it becomes important to have the right </span><a href="https://www.peoplebox.ai/blog/tools-for-effective-remote-one-on-one-meetings/"><span>tech tool</span></a><span>s for your support.</span></p>
<p><span>For a daily standup meeting, you will require the following kind of tools –</span></p>
<ul>
<li><span>A video conferencing tool like Skype or Google meet</span></li>
<li><span>A task management tool to keep a note of all the action items</span></li>
<li><span>An easy-to-use screen sharing mechanism</span></li>
</ul>
<p>Make sure that everyone agrees on the tools decided upon and have no technical difficulties in accessing them.</p>
<p><span>It’s a good idea to have a trial …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/">https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/</a></em></p>]]>
            </description>
            <link>https://www.peoplebox.ai/blog/how-to-use-daily-standup-meetings-for-remote-employee-engagement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739264</guid>
            <pubDate>Sun, 05 Jul 2020 15:13:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Learning for Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739249">thread link</a>) | @kiyanwang
<br/>
July 5, 2020 | https://thevaluable.dev/learning-developer-efficiently-effectively/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/learning-developer-efficiently-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/learning_developer/no-mistake.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/learning_developer/no-mistake.jpg" alt="Learning ">
                </picture>
            

            <p>“I’m trying to go down a bottomless pit. I’ll never make it till the end.”</p>
<p>That’s what I thought when I tried to create my own video game. I was young, beautiful, and I was struggling to use <code>for</code> loops and <code>arrays</code> at the same time.
There was so much to learn!</p>
<p>Fortunately, I found the strength to continue. More and more, the concepts behind programming began to make sense. From there, learning wasn’t a chore anymore, but an intrepid journey. Going through a book about C and trying to create my own adventure on MS-DOS was a crazy Indiana Jone’s-like discovery I’ll never forget.</p>
<p>My first video game wasn’t great, but it was mine. It was <em>my</em> creation. Yet, what I remember today, with a tear in my left eye, is not the result, but the learning process itself. It was these “Aha!” moments which brought me the most joy!</p>
<p>I love learning. For a long, long time. That’s why I tried, through the years, to make my learning gradually more effective and efficient.</p>
<p>Learning is essential for developers. We need to learn about the new breakthroughs, discoveries, and changes in the industry.</p>
<p>We need to learn about our history, to know what’s really new, what’s not, and what to do with it, <em>in what context</em>.</p>
<p>We need to learn about the business domain of the company we’re working with.</p>
<p>We need to learn how to better communicates with our teammates.</p>
<p>We need to learn about what our customers really want.</p>
<p>The list goes on and on.</p>
<p>As you might have guessed, this article will brush over the wide subject of learning, as a developer. We’ll try to answer these questions together:</p>
<ul>
<li>What’s learning?</li>
<li>Why do we learn? Should learning serve a goal?</li>
<li>How to avoid ineffective learning methods, procrastination, and distractions?</li>
<li>Should we have a mentor or learn by ourselves?</li>
<li>Is practice only makes perfect?</li>
<li>How to test ourselves to avoid the illusion of competence?</li>
<li>Are feedback important? What kind of feedback can you get? What feedback should you be interested in?</li>
</ul>
<p>Ready to dive? Good. Take your machete and let’s go together through the Deep Jungle of Knowledge.</p>
<h2 id="whats-learning">What’s learning?</h2>
<p>Sometimes, we can be very surprised of the meaning of common words. Especially if we never question their definitions.</p>
<p>For example, I’m always surprised to hear people saying that learning is only a question of memory. It’s not wrong, but it’s incomplete.</p>
<p>According to the <a href="https://www.lexico.com/definition/learning" target="_blank" rel="noopener">oxford dictionary</a>, learning means:</p>
<blockquote>
<p>The acquisition of knowledge or skills through study, experience, or being taught.</p>
</blockquote>
<p>This gives us clues about how to learn (study, experience, or being taught), but not really about the meaning of “acquisition of knowledge”.</p>
<p>Let’s look at the definition of <a href="https://www.lexico.com/definition/knowledge" target="_blank" rel="noopener">knowledge</a>:</p>
<blockquote>
<p>Facts, information, and skills acquired through experience or education; the theoretical or practical understanding of a subject.</p>
</blockquote>
<p>We can already see, thanks to these definitions, two main foundations for learning:</p>
<ol>
<li>Understanding</li>
<li>Remembering (acquisition)</li>
</ol>
<p>I’ll add a third one:</p>
<ol start="3">
<li>Transfer</li>
</ol>
<p>Transfer is applying the knowledge from the learning context to another context. For example, it could be applying the programming knowledge your learned at school to the side project you always dreamt to build.</p>
<p>Transfer is not a necessity for learning. After all, you can understand and remember something without ever using what you learned.</p>
<p>However, most of the time, we learn in hope to apply the knowledge acquired. That’s why it’s still a major component of our learning experiences.</p>
<h2 id="why-learning">Why Learning?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learn-good.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learn-good.jpg" alt="There is only good in learning">
</picture>



<h3 id="enriching-your-life">Enriching Your Life</h3>
<p>Learning will enrich your life in multiple ways:</p>
<ul>
<li>Your opinions will evolve.</li>
<li>Your vision on the world will change.</li>
<li>You’ll feel strong connections with people who share your interests, creating passionate and mind-binding conversations.</li>
</ul>
<p>Learning can open doors in your professional life:</p>
<ul>
<li>It can help you climbing the corporate ladder.</li>
<li>It can help you to negotiate a better salary. After all, we are <a href="https://en.wikipedia.org/wiki/Knowledge_worker" target="_blank" rel="noopener">knowledge workers</a>: our worth is <em>partly</em> our knowledge.</li>
<li>It will create opportunities for <a href="https://thevaluable.dev/guide-debate-software-developer-skill/">healthy debates with your fellow colleagues</a>.</li>
<li>Your CTO might call you <a href="https://thevaluable.dev/software-developer-titles-junior-senior/">“Rockstar” or “Ninja”</a> too, you lucky pit of knowledge!</li>
</ul>
<h3 id="learning-with-or-without-goals">Learning With or Without Goals?</h3>
<p>When you try to learn something, it’s useful to have concrete goals you want to achieve with the knowledge acquired. These goals could be a good occasion to <em>transfer</em> your knowledge.</p>
<p>For example, you want to learn programming because you always dreamt to create a revolutionary video game, where you can break bricks with a ball. Maybe you want to learn what’s the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, to finally refactor your favorite legacy application.</p>
<p>Without meaningful goals, it will be difficult to be motivated in the long run. Learning is not easy. Understanding can be a daunting task (depending of what you learn), remembering even more so, and transfer is maybe the worst of all.</p>
<p>It takes time, too. That’s why being able to reach concrete goals with your new skills and knowledge can be very satisfying. It will give you the needed motivation to continue on your learning path.</p>
<p>It’s even more true when you try to learn complex topics. Your motivation is something you should try to assess and even measure along the way, to see if you need to boost it by making (and finishing) something important to you.</p>
<p>It’s always possible to learn for the sake of learning. Heck, I do it quite a lot myself. Yet, you need to have a good confidence on your motivation, and you need to be aware of the benefits of the learning journey itself.</p>
<p>If you have difficulties to find concrete ideas and goals where you can transfer your new knowledge, I wrote a whole article about techniques <a href="https://thevaluable.dev/generate-programming-side-project-ideas/">to generate project ideas</a>.</p>
<h2 id="how-deep-do-you-want-to-go">How Deep Do You Want to Go?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/experts.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/experts.jpg" alt="Being an expert is not necessarily your goal">
</picture>



<p>Now that you have your goals, you need to decide <em>how much</em> you want to learn.</p>
<p>After all, you don’t need to be an expert in everything.</p>
<p>Moreover, knowledge acquisition is not like buying a new table for your living room. You need some maintenance not to forget the knowledge and skills acquired.</p>
<p>It means that you need to constantly refresh your knowledge and skills, for everything you want to be an expert at. It takes time, energy, and require, again, a lot of motivation.</p>
<p>For example, let’s say that your life’s dream is to write a PHP script to rename automatically thousands of your holidays pictures. You don’t need to be a PHP evangelist to answer your needs. Trying to understand superficially how PHP works to accomplish what you want might be enough.</p>
<p>Superficial learning works well if you don’t have any goal, too. You can read about programming paradigms for example, by pure curiosity, to have a global overview of all of them. You can still dive deeper if you wish later.</p>
<p>Beyond the superficial, the <a href="https://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition" target="_blank" rel="noopener">Dreyfus model of competence</a> can help you deciding how competent you want to become:</p>
<ul>
<li><strong>Novice</strong> - Shallow understanding, or no understanding at all.</li>
<li><strong>Advanced Beginner</strong> - Can make things works, often rely on following a series of steps.</li>
<li><strong>Competent</strong> - Can spot the roots of problems (background understanding), know all the rules and can select a rule depending of the situation. Still make many mistakes.</li>
<li><strong>Proficient</strong> - Very conscious about performance, know perfectly what approaches to take in what situation.</li>
<li><strong>Expert</strong> - Intuition very well developed, apply his skills without thoughts, performances look magical.</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=i1nzADdV6zk" target="_blank" rel="noopener">Choose your destiny</a>, depending on your needs!</p>
<h2 id="preparing-your-learning-sessions">Preparing Your Learning Sessions</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.jpg" alt="You need to prepare your environment to learn efficiently">
</picture>



<p>Let’s see now how you should prepare yourself before learning anything.</p>
<p>The following advice won’t change your life from one day to another. You need to work on it, actively seeking to apply these advice, day after day. The rewards are, however, huge. I promise.</p>
<h3 id="the-mistakes-to-avoid">The Mistakes to Avoid</h3>
<p>Let’s go back years in your past, when you were young, innocent, and not a caffeine junky yet.</p>
<p>You’re at school. The teacher is speaking about whatever subject he wants you to learn. His tone is monotonous, he doesn’t believe in what he’s saying, you think about what you’ll eat at lunch.</p>
<p>You’re bored.</p>
<p>The seconds feel like minutes. Minutes feel like hours. You can’t do anything, except waiting. Will it ever end? Will you feel joy again? Is it the end of time?</p>
<p>Finally, against all odds, the course end. The teacher ask you to learn a new chapter of your book. He will test you next time.</p>
<p>At home, you read again and again the learning material. You have difficulties to concentrate, but you’re a serious boy (or girl), so you push yourself through. After five reading, you judge yourself good enough to pass the next test.</p>
<p>You close your book, satisfied with yourself, and switch on the TV, because Youtube might not exist yet.</p>
<p>What I just described is the worst way to learn something. <em>Passively</em> listening to somebody, then <em>passively</em> going through some learning materials might teach you something, but very, very slowly. You don’t need to be in a class for that: just switch on Youtube and consume <em>passively</em> any video on programming.</p>
<p>When you close your book after your passive learning, you think you learned something. Yet, when you’ll pass your test, you’ll understand that you really didn’t.</p>
<p>This is called <strong>illusion of competence</strong>: we have often the <em>impression</em> we learned something, even if we didn’t.</p>
<p>You should spend most of your time <em>actively learning</em>. You need to be an actor in your own learning, not only consuming it like you would consume Netflix.</p>
<p>I would compare active learning as playing a video game. Yes, I was a video game junky.</p>
<p>When you play, you’re actively doing something. Consequently, I’m sure you can remember many more video games than what you read in your last books.</p>
<p>This is due to two things:</p>
<ol>
<li>Video games are fun. You can make your learning experience fun, too. More you’ll learn what you love, more you’ll like the process of learning.</li>
<li>Playing is an active endeavor, not a passive one.</li>
</ol>
<p>That being said, before actively learning, you need first …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/learning-developer-efficiently-effectively/">https://thevaluable.dev/learning-developer-efficiently-effectively/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/learning-developer-efficiently-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739249</guid>
            <pubDate>Sun, 05 Jul 2020 15:11:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Must Know 7 Traps That Make Your Software Useless]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739023">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
			
<p><span>One of the unspoken areas about software development is building usable software. Learning how to code, coding something, and having it used by thousands is no easy task. In this article, I’ll be discussing the most important pillars that you need to address before launching your product.&nbsp;</span></p>

<p><span>My first app ever made was a social media, if you exceed 100 comments/post the app becomes crazy slow, the database over fetches, authentication was broken, and the whole world was burning down. Not a great spot to be in, but this goes without saying that paying close attention to some little details will save you months of technical debt and headache.&nbsp;</span></p>

<p><span>Note: Each point can be open for debate, this is what will get you started, the more you learn, the more reliable your app becomes.</span></p>

<p><span>Think of this as a checklist for your next product:</span></p>

<h2><span><strong>1- Code Safety</strong></span></h2>

<p><span>While coding (or when finished) the app, you want to make sure that the environment is safe, no user data is leaking, and the app is reliable and ready to scale for any spikes of usage.&nbsp;</span></p>

<ul>
<li><span>Avoid unwrapping values the unsafe way (aka check if the value is nil) then execute your logic. Surprisingly, this isn’t talked about that much and as a fresh software developer, you never know what will crash your app. You should never be 100% sure that a value won’t be nil, weird stuff happens.&nbsp;</span></li>
<li><span>Avoid retain cycles: While these are caused unintentionally and not easy to detect, you will need to run a check for your app to detect if memory is retained for some unused objects. Each IDE has tools to help you check for retain cycles and you need to make use of them. Xcode for example has a tab where you can detect memory spikes, deallocations, and CPU usage. There are many ways to detect if something is wrong with your app, hardware-wise, make sure to search on the net depending on your platform.&nbsp;</span></li>
</ul>

<figure><span><a href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" target="_blank" rel="noreferrer noopener"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" alt="" data-src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6b161812-de63-476e-b3c7-011b91f60f1f_606x619.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></span></figure>

<ul>
<li><span>Protect your secret keys! More often than not, you’ll find yourself using 3rd party services. These services provide a “secret key” and a “test key” to get access to their API. In production you use the “secret key” and it’s secret for a reason. If leaked, another person will use it and you’ll pay the bill 🙂 not so fun. Even worse, this might leak your users’ data or even shut down the servers. That’s why it’s important to make use of “environment variables”. As the name applies, these are variables that live in the local machine. Say when a script wants to have access to that secret key, it can get it from the local machine. This way, you aren’t hardcoding anything into the script and at the same time keeping your code clean and secure.</span></li>
<li><span>Passwords: Now this is an underrated problem that isn’t talked about and can bring down a whole corporation. In some cases, when you aren’t using reliable 3rd party services for authentication such as AWS &amp; Firebase, you need to be hashing the passwords yourself. Personally, I always keep the hashing function as part of the API in a separate file. I include a random environment variable that I can keep track of which dictates how the password will be generated for a specific user depending on the information provided. And we are set! I don’t need to know my users’ password, I trigger the “sign-in” by triggering the same hashing function using the environment variable I stored before and everything is secure.</span></li>
<li><span>Don’t keep “Logs” (similar to print) when building for production! This is a great way to shoot yourself in the leg, keeping logging functions extends to the build and if you are logging sensitive information you’ll get in trouble. Just stick with classic print() statements; these are safe for usage in production and aren’t logged (from an iOS point of view)</span></li>
</ul>

<h2><span><strong>2-</strong> <strong>Help your project help you</strong></span></h2>

<p><span>After building a couple of apps in different areas with moderate difficulty, you’ll wish you’ve done many things differently, note these down and use them in your next project! My projects went from utter spaghetti mess to a clean hierarchy.&nbsp;</span></p>

<ul>
<li><span>In my case, I found it hard to keep track of the placement of my files in Xcode, so for each screen, I had a folder. The folder contains front-end logic, backend-logic, and unique utilities. As for general utilities, I’d keep them in a global folder to refer to them from every other file.</span></li>
<li><span>Think of factorizing the most. When coding, you want to have a file work as a global factor for other scripts that use the same functionality.</span></li>
<li><span>At some point, you’ll realize you are dealing with many folders, and your project is huge, but this is a thousand times better than having everything crammed into one folder and you waste 30seconds to just find a file</span></li>
</ul>

<p><span>You don’t need to follow my pattern. Find yours and keep experimenting.&nbsp;</span></p>

<h2><span><strong>3-</strong> <strong>Your servers will make you pay for what you don’t know (Literally)&nbsp;</strong></span></h2>

<p><span>Sometimes it’s tempting to use 3rd party services since they can make life easier. I’m all down for using these services and in fact, I use them a lot. However, you need to know the inside outs of their billing policies and know what you are billed for.&nbsp;</span></p>

<p><span>Rule of thumb:&nbsp;</span></p>

<ul>
<li><span>Add a service&nbsp;<strong>only when&nbsp;</strong>it can save you costs and/or enhance your UX. Yes, I just said you need to add a service that will save you money. For example; AWS has a free-tier usage per service. So instead of putting the pressure on just 1 service, you can make use of multiple, you take the roundabout but you end up saving costs early on.&nbsp;</span></li>
<li><span>Algorithmically speaking, you can save Database costs on your client-side. The intuitive way is by making fewer calls, caching user information, and preloading data for future usage. This obviously adds more work client-side, but it’s getting easier to integrate offline capabilities than ever.&nbsp;&nbsp;</span></li>
</ul>

<blockquote>
<p><span>Note:&nbsp; by experience, I noticed the more you save money client-side, the better is your UX, and the higher the performance gets. I’m aware this is a bold point to make so I’ll leave diving into it for another episode.</span></p>
</blockquote>

<ul>
<li><span>Scalability wise, make sure to keep your code usable for huge traffic spikes, these are basic algorithm analysis techniques and they are often shorter to code. For example: Use built-in sort functions, don’t’ iterate every time on a list of 100 items and above, cache your results, make use of dynamic programming (in short the previous result helps with the next result; read more on this&nbsp;<a href="https://medium.com/free-code-camp/demystifying-dynamic-programming-3efafb8d4296">here</a>)&nbsp;</span></li>
</ul>

<h2><span><strong>4- Just when you think you’re done…. Layout Issues</strong></span></h2>

<p><span>By now, you might think you’re done, but there is a bit more to the story. You’re very close though cheer up!&nbsp;</span></p>

<p><span>Often when building your projects, checking tutorials, StackOverflow, etc… you find hardcoded pixel values, typically: (width: 100, height: 100) or similar. These hardcoded are made for simplicity’s sake. No, your app won’t scale because each device has different # of pixels, etc.. That’s why:</span></p>

<ul>
<li><span>When coding, avoid using hardcoded values and make use of a percentage. You can have 2 static variables in a separate class from which you get the height and width of the current screen. This way while coding my layout I have fast access and scalable way of presenting my layout.&nbsp;</span>
<ul>
<li><span>Typically, you ‘ll be calling the class as : SomeClass.screenWidth * 0.5, this means “make my button’s width half of the super view’s width”</span></li>
<li><span>Same applies for the height</span></li>
</ul>
</li>
<li><span>Test on different physical devices, simulators aren’t that bad but sometimes screw up layout-wise, they also have more performance since they run on your computer. Sometimes when a layout or animation looks smooth, you might want to test it on a&nbsp; physical device and double-check for yourself.</span></li>
</ul>

<p><span>Don’t stress over the layout too much, have a fair looking one, make use of 3rd party packages/plugins/libraries for animation, there are many free services that help make your app look neat for the least effort possible. Remember, we are all about 20% investment 80% return in this newsletter 🙂</span></p>

<h2><span><strong>5-</strong> <strong>Client Error Handling: You can get away with this, but don’t overlook it</strong></span></h2>

<p><span>Error handling is fun, right? Or you might think you don’t need it so you just use a standard popup to show any “Error, try again later” message. DON’T. Bad coding, bad bad bad. Every app will crash/fail at some point, you want to provide a targetted message to what happened. While you can’t know every reason for failure, you know the error code. To get my projects up and running, I embed the error code with a standard failure popup, this way, when a user reports the problem during beta/production, I check the logs for the code. Fast and easy debugging!</span></p>

<p><span>At a later stage, you want to remove the codes and move to “natural language explanation”. You’ll start working on this when the time comes for enhancing your UX further.</span></p>

<h2><span><strong>6-</strong> <strong>Cross Services Error Handling</strong></span></h2>

<p><span>Same as in the previous case, but one important matter to take into consideration, if you are dealing with a financial backend (aka Stripe, etc..) you want to have your webhooks (API that receives transaction calls from Stripe, Paypal, etc… and here you update your database) react the right way. Error handling here is critical because you don’t want to flag a user as non-paying because they had their payment attempt succeed but you failed to call the database and make the necessary updates.</span></p>

<h2><span><strong>7-</strong> <strong>Test Cases: You can get away with this too</strong></span></h2>

<p><span>Writing test cases is indispensable for reliable software, especially when scaling and adding more features as a team. You never know who coded what and how that reacted with a piece of code you’ve written. If you are a solo developer and about to ship a basic product, you might get away with skipping this step but you need to keep in mind you’ll have to write test cases to avoid basic bugs in the future.</span></p>

<p><span>Well, this was a lengthy one. I hope you found this article helpful; sorry I had to make it this long but the process had to be detailed and practical. Consider sharing with your friends and anyone who might find this article helpful; and if you aren’t subscribed, consider doing so!&nbsp;</span></p>

<p><span>Until the next time, take care, byeeeeeee 🙂</span></p>

			
			
</div></div>]]>
            </description>
            <link>https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739023</guid>
            <pubDate>Sun, 05 Jul 2020 14:41:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Productivity Templates – by experienced project delivery manager]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738963">thread link</a>) | @sssmith12
<br/>
July 5, 2020 | https://slidegame.io/templates/productivity | <a href="https://web.archive.org/web/*/https://slidegame.io/templates/productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://slidegame.io/templates/productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738963</guid>
            <pubDate>Sun, 05 Jul 2020 14:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: “Watch” any subreddit. Fetches videos from any subreddit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738962">thread link</a>) | @paashabhai
<br/>
July 5, 2020 | https://arbazsiddiqui.github.io/rSlashVideos/ | <a href="https://web.archive.org/web/*/https://arbazsiddiqui.github.io/rSlashVideos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://arbazsiddiqui.github.io/rSlashVideos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738962</guid>
            <pubDate>Sun, 05 Jul 2020 14:34:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prepare Emacs to Code in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738932">thread link</a>) | @frag
<br/>
July 5, 2020 | https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/ | <a href="https://web.archive.org/web/*/https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>Configuring Emacs as an IDE is not really a piece of cake, especially when “good” is not enough. When it comes to programming in Rust I personally enjoy IDEs like Visual Studio Code (the debugging scripts are really powerful). However the versatility of Emacs is unbeatable, especially in those situations in which one doesn’t really want to use different applications and wants to build a camp in one of them and stay there forever :) Since I am one of those people, I put together a configuration that would definitely make my life easier when I code in Rust or simply edit some text.</p> <p>Feel free to copy and share the <code>init.el</code> below (this goes under <code>~/.emacs.d/</code>)</p> <div><div><pre><code>(require 'package)
(add-to-list 'package-archives
         '("melpa" . "http://melpa.org/packages/") t)

(package-initialize)

;; yup this is for a f'ing copy&amp;paste
(setq x-select-enable-clipboard t)

(when (not package-archive-contents)
    (package-refresh-contents))

(unless (package-installed-p 'use-package)
  (package-install 'use-package))

(require 'use-package)

;; Rust stuff
(require 'rust-mode)
(add-hook 'rust-mode-hook
          (lambda () (setq indent-tabs-mode nil)))
(setq rust-format-on-save t)
(define-key rust-mode-map (kbd "C-c C-c") 'rust-run)
(add-hook 'rust-mode-hook 'cargo-minor-mode)

(add-hook 'rust-mode-hook
          (lambda ()
            (local-set-key (kbd "C-c &lt;tab&gt;") #'rust-format-buffer)))

(require 'company)
(require 'racer)
(require 'rust-mode)
(require 'electric)
(require 'eldoc)
(require 'flycheck)
(require 'flycheck-rust)

(add-to-list 'auto-mode-alist '("\\.rs\\'" . rust-mode))
(add-hook 'rust-mode-hook  #'company-mode)
(add-hook 'rust-mode-hook  #'racer-mode)
(add-hook 'racer-mode-hook #'company-mode)
(add-hook 'racer-mode-hook #'eldoc-mode)
(add-hook 'flycheck-mode-hook #'flycheck-rust-setup)

(define-key rust-mode-map (kbd "TAB") #'company-indent-or-complete-common)
(setq company-tooltip-align-annotations t)

;;(add-hook 'rust-mode-hook
;;          '(lambda ()
;;             (setq racer-cmd (concat (getenv "HOME") "/.cargo/bin/racer"))
;;             (setq racer-rust-src-path (concat (getenv "HOME") "/.rust-dev/rust/src"))
;;             (local-set-key (kbd "TAB") #'company-indent-or-complete-common)
;;             (electric-pair-mode 1)))
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;



(setq use-package-always-ensure t)

(add-to-list 'load-path "~/.emacs.d/custom")

(require 'setup-general)

(if (version&lt; emacs-version "24.4")
    (require 'setup-ivy-counsel)
  (require 'setup-helm)
  (require 'setup-helm-gtags))
;; (require 'setup-ggtags)
(require 'setup-cedet)
(require 'setup-editing)

;; (require-package 'atom-one-dark-theme)
;; (require-package 'golden-ratio)
;; (require 'golden-ratio)


;; function-args
;; (require 'function-args)
;; (fa-config-default)
;; (define-key c-mode-map  [(tab)] 'company-complete)
;; (define-key c++-mode-map  [(tab)] 'company-complete)
(custom-set-variables
 ;; custom-set-variables was added by Custom.
 ;; If you edit it by hand, you could mess it up, so be careful.
 ;; Your init file should contain only one such instance.
 ;; If there is more than one, they won't work right.
 '(package-selected-packages
   (quote
    (vscode-icon dired-explorer dired-sidebar racer projectile-codesearch smex flycheck-rust cargo rust-mode zygospore helm-gtags helm yasnippet ws-butler volatile-highlights use-package undo-tree iedit dtrt-indent counsel-projectile company clean-aindent-mode anzu))))
(custom-set-faces
 ;; custom-set-faces was added by Custom.
 ;; If you edit it by hand, you could mess it up, so be careful.
 ;; Your init file should contain only one such instance.
 ;; If there is more than one, they won't work right.
 )


;; UI stuff
;; Set initial frame size and position
(defun my/set-initial-frame ()
  (let* ((base-factor 0.70)
         (a-width (* (display-pixel-width) base-factor))
         (a-height (* (display-pixel-height) base-factor))
         (a-left (truncate (/ (- (display-pixel-width) a-width) 2)))
         (a-top (truncate (/ (- (display-pixel-height) a-height) 2))))
    (set-frame-position (selected-frame) a-left a-top)
    (set-frame-size (selected-frame) (truncate a-width)  (truncate a-height) t)))
(setq frame-resize-pixelwise t)
(my/set-initial-frame)

;; (load-theme 'atom-one-dark t)
(blink-cursor-mode 0)
(setq-default cursor-type 'bar)
(set-cursor-color "#cccccc")
(setq ring-bell-function 'ignore)
(golden-ratio-mode 1)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Editing stuff
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(require 'saveplace)
;; (require-package 'rainbow-mode)
(require 'flycheck)

;; Highlights matching parenthesis
(show-paren-mode 1)

;; Highlight current line
(global-hl-line-mode 1)

;; Interactive search key bindings. By default, C-s runs
;; isearch-forward, so this swaps the bindings.
(global-set-key (kbd "C-s") 'isearch-forward-regexp)
(global-set-key (kbd "C-r") 'isearch-backward-regexp)
(global-set-key (kbd "C-M-s") 'isearch-forward)
(global-set-key (kbd "C-M-r") 'isearch-backward)
(define-key global-map (kbd "RET") 'newline-and-indent)

(add-hook 'after-init-hook #'global-flycheck-mode)

;; When you visit a file, point goes to the last place where it
;; was when you previously visited the same file.
;; http://www.emacswiki.org/emacs/SavePlace

(setq-default save-place t)
;; keep track of saved places in ~/.emacs.d/places
(setq save-place-file (concat user-emacs-directory "places"))

;; Emacs can automatically create backup files. This tells Emacs to
;; put all backups in ~/.emacs.d/backups. More info:
;; http://www.gnu.org/software/emacs/manual/html_node/elisp/Backup-Files.html
(setq backup-directory-alist `(("." . ,(concat user-emacs-directory
                                               "backups"))))
(setq auto-save-default nil)

(defun toggle-comment-on-line ()
  "Comment or uncomment current line."
  (interactive)
  (comment-or-uncomment-region (line-beginning-position) (line-end-position)))
(global-set-key (kbd "C-;") 'toggle-comment-on-line)

;; (add-hook 'prog-mode-hook #'rainbow-delimiters-mode)


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Navigation
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(require 'ido)
(require 'recentf)
;; (require-package 'ido-ubiquitous)
;; (require-package 'smex)
;; (require-package 'projectile)

(setq recentf-save-file (concat user-emacs-directory ".recentf"))
(recentf-mode 1)
(setq recentf-max-menu-items 40)

;; (ido-mode t)
;; (setq ido-enable-flex-matching t)
;; (setq ido-use-filename-at-point nil)
;; (setq ido-auto-merge-work-directories-length -1)
;; (setq ido-use-virtual-buffers t)

;; (ido-ubiquitous-mode 1)

;; Shows a list of buffers
(global-set-key (kbd "C-x C-b") 'ibuffer)


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Sidebar stuff
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(use-package vscode-icon)

(use-package dired-sidebar
  :ensure t
  :demand t
  :custom
  (dired-sidebar-theme 'vscode)
  :commands (dired-sidebar-toggle-sidebar))

(add-to-list 'load-path "/home/frag/.emacs.d/dired-sidebar")
(require 'dired-sidebar)
(dired-sidebar-toggle-sidebar)

(setq dired-sidebar-subtree-line-prefix "__")
(setq dired-sidebar-theme 'vscode)
(setq dired-sidebar-use-term-integration t)
(setq dired-sidebar-use-custom-font t)
</code></pre></div></div> </div> </article>  </div></div>]]>
            </description>
            <link>https://codingossip.github.io/2020/prepare-emacs-to-code-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738932</guid>
            <pubDate>Sun, 05 Jul 2020 14:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DNS Resolution and Records for Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23738908">thread link</a>) | @paashabhai
<br/>
July 5, 2020 | https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/ | <a href="https://web.archive.org/web/*/https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h2>
<p>Domain Name System (DNS) is something which we all use everyday without knowing the internal workings of it. How does a url we enter in our browser gets redirected to a specific server? How is it so fast? If you have setup any website you might be familiar with adding A record and CNAMEs. But what are they? What <code>@</code> as a host means? When to use what? This article try to answer all these questions. We will cover what DNS is, how does it work, what are different DNS records and their use cases.</p>
<h2 id="what-is-a-domain-name"><a href="#what-is-a-domain-name" aria-label="what is a domain name permalink"></a>What is a Domain Name?</h2>
<p>Lets first understand what a domain name is before we can jump into DNS. A domain name is a unique text identifier for a website or server. The domain name for this website is <code>arbazsiddiqui.me</code>. A domain has following structure :</p>
<div data-language="text"><pre><code>&lt;subdomain&gt;.&lt;domain&gt;.&lt;TLD&gt;</code></pre></div>
<p>Lets understand this via an example of <code>blog.arbazsiddiqui.me</code>.</p>
<p><code>.me</code> is the <code>Top Level Domain (TLD)</code>. This is the root of the domain and encompasses all domains in it. <code>.com</code>, <code>.org</code>, <code>.io</code> are all example of TLDs. <code>arbazsiddiqui</code> is the <code>domain</code> and technically a <code>subdomain</code> of <code>.me</code>. <code>blog</code> is a subdomain of <code>arbazsiddiqui</code>. We can chain this as far as we want, only thing to understand here is that <code>TLD</code> is the root and all subsequent domains are <code>subdomains</code> of the previous one.</p>
<h2 id="what-is-dns"><a href="#what-is-dns" aria-label="what is dns permalink"></a>What is DNS?</h2>
<p>The Domain Name System (DNS) is the phonebook of the internet. DNS is the mechanism which is responsible for converting human friendly urls like <code>arbazsiddiqui.me</code> to machine understandable IP addresses (<code>104.198.14.52</code> in this case). Each device connected to the Internet has a unique IP address which other machines use to find the device. DNS eliminate the need for humans to memorize IP addresses. </p>
<h2 id="how-does-dns-work"><a href="#how-does-dns-work" aria-label="how does dns work permalink"></a>How does DNS work?</h2>
<p>The process of finding a host name's IP address is called DNS resolution or DNS lookup. A server queries a bunch of other servers if they have the IP address of requested domain name. The other server might not know the IP of the requested domain but will point it to another server which might know it. After following up this chain we will eventually end up with the IP address of our domain. </p>
<p>A DNS resolution will typically require 4 hops (in a non cached scenario). </p>
<ol>
<li><strong>DNS Resolver</strong> : The DNS resolver is the computer that responds to a request from a client and takes the time to track down the DNS record. It will query all other subsequent servers on your behalf and after finding the IP address will respond with it.</li>
<li><strong>Root nameserver</strong> : This is the first step towards finding the IP of requested domain. A root nameserver has the IP address of TLD nameservers. So if you are requesting <code>example.com</code>, root nameserver will point DNS resolver to the IP address of TLD nameserver for <code>.com</code> and DNS resolver can process from there.</li>
<li><strong>TLD nameserver</strong> : TLD nameservers contain the IP addresses of all the subdomains which are the part of their TLD. So in our case of <code>example.com</code>, the <code>.com</code> TLD (which was pointed to use by <code>root nameserver</code>) will point DNS resolver towards the <code>Authoritative nameserver</code> of <code>example.com</code>. </li>
<li><strong>Authoritative nameserver</strong> : An authoritative DNS server is a server that actually holds, and is responsible for, DNS resource records. This is the server at the bottom of the DNS lookup chain that will respond with the queried resource record, ultimately allowing the web browser making the request to reach the IP address needed to access a website or other web resources. In our case, it will respond back with IP address <code>104.198.14.52</code> to the DNS resolver which will respond the same back to client. This marks the complete chain of a DNS lookup.</li>
</ol>
<p><span>
      <a href="https://www.arbazsiddiqui.me/static/db3c8c0870e1e9acf669cafbadc8ce69/f84cf/DNS-Lookup.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="DNS Lookup" title="DNS Lookup" src="https://d33wubrfki0l68.cloudfront.net/1a64d403b736a3ca4484b7d01be2af97595c2cd4/6cb51/static/db3c8c0870e1e9acf669cafbadc8ce69/faddd/dns-lookup.jpg" srcset="https://d33wubrfki0l68.cloudfront.net/bfa0948e86d586451ef4ba90b9b704006e942c03/c7c72/static/db3c8c0870e1e9acf669cafbadc8ce69/6a7c0/dns-lookup.jpg 213w,
https://d33wubrfki0l68.cloudfront.net/30ce1c0983d3fb89cf61182b8504c2353b1fef28/67f56/static/db3c8c0870e1e9acf669cafbadc8ce69/b9721/dns-lookup.jpg 425w,
https://d33wubrfki0l68.cloudfront.net/1a64d403b736a3ca4484b7d01be2af97595c2cd4/6cb51/static/db3c8c0870e1e9acf669cafbadc8ce69/faddd/dns-lookup.jpg 850w,
https://d33wubrfki0l68.cloudfront.net/5164b9b355447618c8bdc9481c7e10868993357a/52178/static/db3c8c0870e1e9acf669cafbadc8ce69/f84cf/dns-lookup.jpg 880w" sizes="(max-width: 850px) 100vw, 850px" loading="lazy">
  </a>
    </span></p>
<p>To know the IP address of a domain name you can simple do : </p>
<div data-language="terminal"><pre><code>dig arbazsiddiqui.me +short

104.198.14.52</code></pre></div>
<p><code>104.198.14.52</code> is the IP address of server hosting <code>arbazsiddiqui.me</code>.</p>
<h2 id="dns-records"><a href="#dns-records" aria-label="dns records permalink"></a>DNS Records</h2>
<p>DNS records are instructions that live in authoritative nameservers and provide information about a domain including what IP address is associated with that domain and how to handle requests for that domain. You as website owner are responsible for telling the Authoritative nameserver (the last stop in DNS lookup) the address of the server your website is hosted on. DNS records allows you to do multiple things such as adding subdomains. A record typically consist of three things a <code>Type</code>, a <code>Host</code> and a <code>Value</code>. Lets look at record types one by one.</p>
<h3 id="a-records"><a href="#a-records" aria-label="a records permalink"></a>A records</h3>
<p>An A record maps a domain name to an IPv4 address. It’s what you use to point <code>arbazsiddiqui.me</code> to <code>104.198.14.52</code>.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>@</td>
<td>104.198.14.52</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>The above record means that when someone types <code>arbazsiddiqui.me</code> in the browser, the request will be directed to server on IP <code>104.198.14.52</code>. The <code>@</code> here indicates that this is a record for the root domain, and the ‘14400’ value is the TTL (Time To Live), listed in seconds. This means that if an A record gets updated, it takes 240 minutes (14400 seconds) to take effect.</p>
<blockquote>
<p>Some registrars like goDaddy call Host as Name.</p>
</blockquote>
<p>The <code>AAAA</code> record does the same for IPv6</p>
<h3 id="cname"><a href="#cname" aria-label="cname permalink"></a>CNAME</h3>
<p>A CNAME record is used when a domain or subdomain is an alias of another domain. In other words when you want to add a subdomain like <code>www</code> or <code>blog</code> to
<code>arbazsiddiqui.me</code>. The CNAME record's value is <strong>always</strong> another domain and NOT the IP address. Hence if you want to add a subdomain <code>www</code> to <code>arbazsiddiqui.me</code>, it will look like this : </p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>CNAME</td>
<td>www</td>
<td>arbazsiddiqui.me</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>This record states that when <code>www.arbazsiddiqui.me</code> is typed in browser, trigger a lookup for <code>value</code> which in this case is <code>arbazsiddiqui.me</code>. This will eventually serve the A record for <code>arbazsiddiqui.me</code> from above section. So CNAMEs can point to other domains or subdomains but the chain will eventually end up to an A record which will be used to serve website.</p>
<p>CNAME can also be used to point to another app hosted somewhere like heroku or netlify.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>CNAME</td>
<td>www</td>
<td>trusting-jennings-f13c44.netlify.com</td>
<td>14400</td>
</tr>
</tbody>
</table>
<h3 id="txt"><a href="#txt" aria-label="txt permalink"></a>TXT</h3>
<p>The text record let’s a domain administrator enter text into the DNS record. It is most commonly used to determine the ownership of the domain. For example to claim a domain on google search console you will have to add a token as TXT record so that google knows that you are the legit owner of your domain. </p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>TXT</td>
<td>@</td>
<td>google-site-verification=xyz</td>
<td>14400</td>
</tr>
</tbody>
</table>
<h3 id="mx"><a href="#mx" aria-label="mx permalink"></a>MX</h3>
<p>The mail exchange record directs email to a mail server. The value of MX record should be a domain.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Host</th>
<th>Value</th>
<th>Priority</th>
<th>TTL</th>
</tr>
</thead>
<tbody>
<tr>
<td>MX</td>
<td>@</td>
<td>mailhost.example.com</td>
<td>3</td>
<td>14400</td>
</tr>
<tr>
<td>MX</td>
<td>@</td>
<td>mailhost2.example.com</td>
<td>4</td>
<td>14400</td>
</tr>
</tbody>
</table>
<p>The new field <code>priority</code> here indicates the the order in which the message will be tried. Here <code>mailhost.example.com</code> will be tried first as it has higher priority and if it fails it will try <code>mailhost2.example.com</code>.</p>
<h2 id="caching"><a href="#caching" aria-label="caching permalink"></a>Caching</h2>
<p>In <a href="#how-does-dns-work">DNS lookup</a> section we saw that a DNS resolution is a 4 hop process, but on a good internet connection things work in a seamless manner. DNS uses UDP protocol which is fast but still doing so many resolution so quickly wont be possible without introducing caching. DNS responses are cached at many different levels. In your browser, in your domestic router, and also in intermediary networking hardware.</p>
<p>And if there’s caching, there’s also a way to expire the cache, and that’s the TTL (time to live). Any DNS record will have an associated TTL value, and that’s how much time their value can be stored (cached) by any involved party. You can change this at any time from the DNS server.</p>
<h2 id="hosts-file"><a href="#hosts-file" aria-label="hosts file permalink"></a>Hosts File</h2>
<p>All OS provides us with a <code>hosts</code> file. We can keep a list of domains and their respective IP addresses here. If a domain is listed here, it will take precedence over the normal DNS lookup flow and the clients will directly try to connect with IP listed against an IP. A line from <code>hosts</code> file looks like this : </p>

<p>Adding the websites you visit the mosts and their respective IPs might seem a good idea and will definitely save you some time spent in resolution but its too much of a hassle to keep this updating if the IP changes or as you get addicted to more websites. For this use case we can use tools like <a href="http://www.thekelleys.org.uk/dnsmasq/doc.html" target="_blank" rel="noopener noreferrer">dnsmasq</a> which is light weight caching server.</p>
<p>However hosts file is great way to check your new server without changing anything publicly, just edit this file and manually set your domain to point to the IP address of your new server, and you’ll be able to test it for real with a browser.</p>
<p>Another great use case of hosts file is to block unwanted sites by adding their domain to loopback IP <code>127.0.0.1</code>. This can be done to block ads, malwares or cure reddit addiction. Just add following lines to your <code>/etc/hosts</code> file: </p>

<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>Its easy to forget the internal workings of internet behind all the cat videos. DNS resolution is one such internal mechanism which makes up the internet and its good to know how it works under the hood. In this article we learned what DNS is and how does a url in browser gets converted to an IP address. We also looked at DNS records and their respective use cases.</p></div></article></div>]]>
            </description>
            <link>https://www.arbazsiddiqui.me/dns-resolution-and-records-for-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738908</guid>
            <pubDate>Sun, 05 Jul 2020 14:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Stress Response Cycle: The Surprising Science Behind Feeling Better]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738861">thread link</a>) | @coffeeandjunk
<br/>
July 5, 2020 | https://coffeeandjunk.com/stress-response-cycle/ | <a href="https://web.archive.org/web/*/https://coffeeandjunk.com/stress-response-cycle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <!-- 
            <figure class="post-full-image">
                <img
                    srcset="/content/images/size/w300/2020/07/stress-response-cycle.jpg 300w,
                            /content/images/size/w600/2020/07/stress-response-cycle.jpg 600w,
                            /content/images/size/w1000/2020/07/stress-response-cycle.jpg 1000w,
                            /content/images/size/w2000/2020/07/stress-response-cycle.jpg 2000w"
                    sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px"
                    src="/content/images/size/w2000/2020/07/stress-response-cycle.jpg"
                    alt="The Stress Response Cycle: The Surprising Science Behind Feeling Better"
                />
            </figure>
             -->

            <section>
                <div>
                    <p>The internet is littered with infinite content on managing stress. Most of them don’t know what they are talking about. The basic premise is always to “learn to chill”. But if it were so simple, there wouldn’t have been so many motivational videos and blog posts in the first place.</p><p>Stress is a physiological phenomenon, and unless we understand the science behind it, we cannot possibly know how to manage it. In her phenomenal book, <a href="https://amzn.to/31Kh4S5"><em>Come As You Are</em></a>, sex educator Emily Nagoski talks about the physiology of stress, and gives us important pointers to deal with it.</p><p>Let’s start by separating <em>stressors</em> from <em>stress</em>. Your stressors are the things that activate the stress response. For example, exams, bills, family, office, fretting about your career, all of that.</p><p>Your stress is the system of changes activated in your brain and body in response to those stressors. We refer stress as the fight-or-flight response, but its full description is: fight, flight, or freeze response. Stress is an evolutionarily adaptive mechanism that allows you to respond to perceived threats, such as being chased by a lion.</p><p>These days we are not chased by lions, and yet our body’s response to threats such as an incompetent boss is largely the same as it would be to a lion. Our primitive brain doesn’t differentiate much.</p><p>When your brain perceives a threat, you experience a massive biochemical and physiological change. Your bloodstream is flooded by adrenaline and cortisol. Your heart rate, respiration rate and blood pressure increases. Your immune and digestive functioning gets suppressed. Your pupils are dilated thereby shifting you into a vigilant and battle-ready state. You body prepares itself for the action to come.</p><p>What the “action” will be depends on the nature of the perceived threat. If it’s a lion, your brain informs you it’s the kind of threat that you are most likely to survive by trying to escape—flight. If the lion doesn’t get hold of you, you reach your village safely, and rejoice in relief.</p><p>There are times when your brain decides that you can best survive a threat by conquering—fight. You jump on the thief who tries to run off with your wallet.</p><p>This is the stress response cycle. It starts with a stressor (when your brain screams, I’m at risk), action (fight or flight), and relief (I’m safe). These two responses—fight and flight—are both accelerator stress response—the “GO!”</p><p>But suppose a stressor is such that your brain determines that you can neither survive it by escaping nor by conquering. The lion has already grabbed you, you don’t have any weapons to attack, and it’s too late to run. Your body has undergone a series of changes to prepare itself to deal with the threat, but this time you get the brakes stress response—the freeze—the “STOP!” instead of the “GO!” Your body shuts down. You can’t move, or can move only sluggishly. You senses slow down and you become dizzy. You surrender!</p><p>Animals in the wild play possum as a last-ditch effort to convince a predator that they’re already dead. Surrender also facilitates a painless death. But if an animal survives such an intense threat to its life, it shakes before getting up. It trembles. Its paws vibrate. It heaves a great big sigh. And then it gets up, shakes itself off before trotting away.</p><p>What’s happening here is that freeze has interrupted the “GO!” stress response of fight or flight, leaving all that adrenaline to go stale inside the animal’s body. When the animal shakes and shudders and sighs, its body releases the brake, completes the process triggered by fight/flight, and purges the residue, thereby completing the cycle.</p><p>My girlfriend underwent surgery a couple of years back. After coming out of anaesthesia, she started screaming and yelling with any obvious cause. Emily Nagoski calls it “the Feels”. Anaesthesia is medically induced freeze. She wasn’t in any danger, but she had a lot of Feels that needed to work themselves out in order to complete the cycle. Only rarely in our everyday lives does unlocking from freeze take such a dramatic form, but even in its smaller scale, that’s how the stress response cycle works, beginning, middle, and end—all innately built into the nervous system. The cycle needs to complete in order to relieve stress.</p><p>It sounds very simple, and it is. But stress is more complex in us humans due to modernity and other cultural reasons. For starters, modern stressors are lower in intensity and longer in duration—<em>chronic stressors</em>, in contrast to <em>acute stressors</em> like being chased by a lion.</p><p>Acute stressors have a clear beginning, middle, and end. Completing the cycle—running, surviving, celebrating—is inherently built in. It’s not so with chronic stressors. If our stress is chronic and we don’t take deliberate steps to complete the cycle, all that activated stress just hangs out inside us, making us sick, tired, and unable to experience pleasure in anything.</p><p>On top of that, our emotion-dismissing culture is uncomfortable with the Feels. As a result, most people’s idea of stress management is some version of “just relax” as if stress can be turned off like a light switch.</p><p>But most importantly, our ultrasocial human brains are really good at self-inhibition, stopping the stress response mid-cycle because “now is not an appropriate time for the Feels”—especially if you are in a public pace. We use this self-inhibition in order to facilitate social cooperation. We don’t want to freak anybody out, do we?</p><p>But unfortunately, our culture has eliminated all appropriate times for Feels. We’ve locked ourselves, culturally, into our own fear, rage, and despair. Hence most people resort to doing things that distract them from stress, such as alcohol, endless partying, binging on fast-food and Netflix. They’re all intended to do one thing: manage the underlying feelings. But it can be done in a healthy way as well. We just have to build time, space, and strategies for discharging our stress response cycles. That is the only way to deal with stress.</p><p>Think about what your body recognises as the behaviours that save you from lions. When you’re being chased by a lion, what do you do? You run. So when you’re stressed out by your job, what do you do? You run…or walk, or get on a bicycle, or go out dancing.</p><p>Physical activity is the single most efficient strategy to complete the stress response cycle, and recalibrate your central nervous system into a calm state. When people say, “Exercise is good for stress,” that is for real.</p><p>Alan Turing famously ran miles everyday to relieve stress. When asked why he does that he said, “I have such a stressful job that the only way I can get it out of my mind is by running hard; it’s the only way I can get some release.”</p><p>In his phenomenal book <a href="https://amzn.to/38v0jf9"><em>Spark: The Revolutionary New Science of Exercise and the Brain </em></a>, the author John J. Ratey, who’s an MD, talks about how simple physical actives like running, jogging, skipping can help us become not only fitter, but also happier and sharper.</p><p>In communities like No Lights No Lycra (NLNL), strangers gather to dance in the dark together, all sober, to shake the blues away. They are present in over 75 locations around the world, including Mumbai.</p><p>If you really want to move your body, you don’t have to go very far. Your home can become your stage. I personally, love to dance. Not that I’m a good dancer, but I love this as an activity to release inhibitions, move moods, and work up a sweat.</p><p>Few other activities that help you “feel better” are: sleep, humour, affection, meditation, allowing yourself a good old cry, or a primal scream.</p><p><a href="https://amzn.to/31Lb2Rh">Sleep</a> is essentially trauma and stress therapy, and I cannot “stress” more upon the importance of 8 hrs of daily sleep, no matter what.</p><p>If you are naturally humorous, it helps. If you are comfortable enough to crack bad jokes just to keep yourself entertained, it helps as well. Since we’re spending so much of time together after the lockdown, my girlfriend and I do this all the time. We crack silly jokes that others would find weird, childish, and sometimes even stupid. But this helps us deal with the day-to-day tribulations related to work and household chores.</p><p>A warm affectionate hug from your partner, your friend, or your parents is a great stress reliever. An affectionate hug essentially says, “You’re okay. You got it. It’s gonna be fine.” Hug more. Hug often.</p><p>If you’ve ever locked yourself in your room and sobbed for ten minutes or got on the top of a building and shouted your lungs out, and then at the end heaved a great big sigh and felt tremendously relieved, you have essentially helped yourself complete the stress response cycle.</p><p>Art, used in the same way, can help. My girlfriend’s sister does paintings in gouache. It started out as a hobby, but eventually it became a way discharge stress through the creative process. Journaling helps in similar ways. When mental health professionals suggest journaling or other expressive hobbies, they don’t mean that the construction of sentences or the task of drawing is inherently therapeutic, rather they are encouraging you to complete the cycle by pursuing little creative endeavours.</p><figure><img src="https://coffeeandjunk.com/content/images/2020/07/image.png"><figcaption>One of my girlfriend's sister's work</figcaption></figure><p>Don’t forget to treat yourself with affection during stressful times. I’ve known people for whom a hot shower and the rituals of painting their nails or doing their hair or putting on makeup fully transition them from a stressed-out state of mind to a warm, social state of mind.</p><p>These rituals and behaviours are forms of self-kindness. Apes eat insects out of each other’s fur. Bath bombs and body glitters are the modern human equivalent.</p><p>My point is, everybody has something that works—and everyone’s strategy is different. Whatever strategy you use, take deliberate steps to complete the cycle. Allow yourself to coast to the end without hitting the brake. As Emily Nagoski says, emotions are like tunnels; you have to walk all the way through the …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coffeeandjunk.com/stress-response-cycle/">https://coffeeandjunk.com/stress-response-cycle/</a></em></p>]]>
            </description>
            <link>https://coffeeandjunk.com/stress-response-cycle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738861</guid>
            <pubDate>Sun, 05 Jul 2020 14:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A few thoughts on the Zephyr's ASDL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738815">thread link</a>) | @isidentical
<br/>
July 5, 2020 | https://tree.science/transitional-asdl.html | <a href="https://web.archive.org/web/*/https://tree.science/transitional-asdl.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>The Zephyr Abstract Syntax Description Language or shortly Zephyr's ASDL is a 
well known; mature (released at 1997~), descriptive language for defining ASTs 
(nodes and leaves) and other tree-like data structures. When it got released (and
even after one or two decades) it was more than capable of being used in major compilers,
including CPython's bytecode compiler (from v2.5~). But after having quite a bit
of experience with it, I started to realize that it can be improved in a few ways.
The whole post will contain my own humble opinions. Please feel free share your
own ones with me through the contact information at the end of the post. I'm currently
working on a demo project to enpower all the ideas that are being mentioned below, and
it would be really nice to hear from you about these.</p>

<p>Every field declaration in ASDL consists from this form <code>[type][qualifier]? [name]</code>;
where <code>[type]</code> is either something defined in the current spec, or a built-in one 
(such as <code>identifier</code>). And the <code>[qualifier]</code> is a mutually exclusive and optional
qualifier for the given type. There are 2 kinds of qualifiers <code>[qualifier]={?, *}</code>.
A question mark (<code>?</code>) means it can be either empty or something that belongs to the
<code>[type]</code>. On the other side, a star (<code>*</code>) means it is a zero or more element sequence
of given <code>[type]</code>. In theory, these 2 qualifiers might seem enough, but giving a basic
example might prove the otherwise. Let's imagine a simple AST of a python function.</p>
<div><pre><span></span>function = Function(identifier name, expr? returns, stmt* body)
</pre></div>


<p>It has a name, an optional return annotation, and a list of statements as it's body.
Which looks very accurate, right?</p>
<div><pre><span></span><span>def</span> <span>foo</span><span>()</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span>pass</span>

<span>def</span> <span>bar</span><span>():</span>
    <span>pass</span>
    <span>pass</span>
</pre></div>


<p>If we try to address these functions in the AST which we created earlier, it will
look something like this;</p>
<div><pre><span></span><span>Function</span><span>(</span><span>"foo"</span><span>,</span> <span>Expr</span><span>(</span><span>int</span><span>),</span> <span>[</span><span>PassStmt</span><span>()])</span>
<span>Function</span><span>(</span><span>"bar"</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>PassStmt</span><span>(),</span> <span>PassStmt</span><span>()])</span>
</pre></div>


<p>And there is nothing that looks wrong with this form, as long as it is generated
by some kind of parser. But Python allows users to craft and compile arbitrary ASTs.
As you might know, the function bodies in Python have to at least 1 statement, but
the ASDL implies that it might have zero (since <code>*</code> means zero or more). There goes the
conflict, this AST, <code>Function("baz", None, [])</code> is valid according to the ASDL spec,
but it later on it might crash the interpreter or might not pass the validation at all.
For CPython, there is a custom AST validator, which comes with the burden of maintenance,
just for ensuring that user crafted AST's won't crash the compiler.</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>import</span> <span>ast</span>
<span>&gt;&gt;&gt;</span> <span>foo_mod</span> <span>=</span> <span>ast</span><span>.</span><span>parse</span><span>(</span><span>"def foo(): pass"</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>foo_mod</span><span>.</span><span>body</span><span>[</span><span>0</span><span>]</span><span>.</span><span>body</span><span>.</span><span>clear</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>compile</span><span>(</span><span>foo_mod</span><span>,</span> <span>"&lt;test&gt;"</span><span>,</span> <span>"exec"</span><span>)</span>
<span>Traceback</span> <span>(</span><span>most</span> <span>recent</span> <span>call</span> <span>last</span><span>):</span>
  <span>File</span> <span>"&lt;stdin&gt;"</span><span>,</span> <span>line</span> <span>1</span><span>,</span> <span>in</span> <span>&lt;</span><span>module</span><span>&gt;</span>
<span>ValueError</span><span>:</span> <span>empty</span> <span>body</span> <span>on</span> <span>FunctionDef</span> <span>&lt;=</span> <span>custom</span> <span>error</span>
</pre></div>


<div><pre><span></span><span>static</span> <span>int</span>
<span>validate_nonempty_seq</span><span>(</span><span>asdl_seq</span> <span>*</span><span>seq</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>what</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>owner</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>asdl_seq_LEN</span><span>(</span><span>seq</span><span>))</span>
        <span>return</span> <span>1</span><span>;</span>
    <span>PyErr_Format</span><span>(</span><span>PyExc_ValueError</span><span>,</span> <span>"empty %s on %s"</span><span>,</span> <span>what</span><span>,</span> <span>owner</span><span>);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
<span>static</span> <span>int</span>
<span>validate_body</span><span>(</span><span>asdl_seq</span> <span>*</span><span>body</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>owner</span><span>)</span>
<span>{</span>
    <span>return</span> <span>validate_nonempty_seq</span><span>(</span><span>body</span><span>,</span> <span>"body"</span><span>,</span> <span>owner</span><span>);</span>
<span>}</span>
<span>...</span>
    <span>case</span> <span>FunctionDef_kind</span><span>:</span>
        <span>return</span> <span>validate_body</span><span>(</span><span>stmt</span><span>-&gt;</span><span>v</span><span>.</span><span>FunctionDef</span><span>.</span><span>body</span><span>,</span> <span>"FunctionDef"</span><span>)</span>
</pre></div>


<p>Also this is not the only case where the AST doesn't comply with ASDL. For an example,
the AST of an dictionary defined as <code>Dict(expr* keys, expr* values)</code>, which means that
it has two list of <em>expressions</em> that are named <code>keys</code> and <code>values</code>. That makes sense
since, AST of <code>{'a': 'b'}</code> is just <code>Dict([Constant('a')], [Constant('b')])</code>. But when it
comes to dict unpacking inside of another dictionary with double-star operator, the AST
looks like this;</p>
<div><pre><span></span>Input: {**a, b:c}
Output:
Dict(
    keys=[
        None,
        Name(id='b', ctx=Load()),
    ],
    values=[
        Name(id='a', ctx=Load()),
        Name(id='c', ctx=Load()),
    ],
)
</pre></div>


<p>Did you see that there is an outlier among the <code>keys</code>, the <code>None</code>. This is because that field
qualifiers are mutually exclusive, and you can't chain them. Things like this would make the
ASDL a context-dependent thing and in some cases, they might increase the maintenance burden
(such as external verifiers, which I'll also address in the next section). The solution would
be as simple as just extending the current qualifiers and make them chainable. There are 2 design
I have in my mind. The first one is introducing new qualifiers in the same form</p>
<div><pre><span></span>* =&gt; zero or more sequence
+ =&gt; one or more sequence
? =&gt; optional
[&lt;field type&gt;] =&gt; also optional but chainable

FunctionDef(identifier name, expr? returns, stmt+ body)
Dict([expr]* keys, expr* values)
</pre></div>


<p>the second one is kind-a different might be hard to process in big ASDL's but more explicit.</p>
<div><pre><span></span>ZeroOrMore[&lt;field type&gt;] =&gt; such as *
OneOrMore[&lt;field type&gt;] =&gt; such as +
Opt/Optional[&lt;field type&gt;] =&gt; such as * or [&lt;field type&gt;]

FunctionDef(identifier name, Opt[returns], OneOrMore[body])
Dict(ZeroOrMore[Opt[keys]], ZerOrMore[values])
</pre></div>



<p>Integrating some source code inside of grammars isn't a new idea, a recent example would be the
Python's new parser generator, and the <a href="https://github.com/python/cpython/blob/master/Grammar/python.gram">grammar</a>
it consumes. I believe that this can be integrated very quickly to the ASDL itself, with a new but not an unorthodox
syntax. The purpose of these actions is going to be both verification and transitions (not limited to that). 
It might open a way to language extensions.</p>
<p>Bringing such actions would require a metadata format to the ASDL modules, the best form I can think of is
something similar to python decorators that will annotate the ASDL modules (namespaces, which are not
part of the original <a href="https://everet.org/wp-content/uploads/2012/05/The-Zephyr-Abstract-Syntax-Description-Language.pdf">paper</a>).</p>
<div><pre><span></span>@&lt;key&gt; &lt;value&gt;
module &lt;name&gt; {}

@actions C
@version 3.8
module Example {}
</pre></div>


<p>The action syntax will depend on the action's purpose</p>
<div><pre><span></span>{verify, transition} $left::right [where $condition] {
    [ACTION]
}
</pre></div>


<h2>Verifier Actions</h2>
<p>As I mentioned earlier, languages that allow users to create external ASTs requires a custom
validation step. Type checking will help in most cases, but there will be still some esoteric
ones left. It might be a controversial thing since some people might not want to host their
source code inside of a text spec (I dont know, maybe for their linters / formatters, or other
purposes), but this will ensure that the validation process is public and the clients of this AST
will know what nodes will be validated and which kind of methods will be used for their validation.</p>
<div><pre><span></span>verify $nodes::$fields [where $condition] {
    [ACTION]
}

verify Dict::(keys, values) {
    return len(keys) == len(values)
}

verify ImportFrom::level {
    return level &gt;= 0
}

verify Try::(handlers, finalbody, orelse) where len(handlers) == 0 {
    if len(finalbody) == 0 and len(orelse) &gt; 0:
        return False
    ...
}
</pre></div>


<h2>Transitioning</h2>
<p>Here it comes the other big problem and a use case for actions, the AST changes. If you are writing some kind of tool that consumes the AST (e.g: linter), it is not uncommon for you to get broken
in every release. The reason for that is  AST is also an internal format and things might just change
for internal reasons and no one gives you a guarantee about it won't change again. So you have to test
your tool on every major release and ensure the breakages are gone by creating tons of workarounds.</p>
<p>This is the case for even the simplest change, like changing the name of a node. The solution would be
a simple layer of "compatibility". The way it should work is that, for old nodes, it is going to keep
the same structure as the old ASTs even though the name of the form of that node is changed. Achieving
such a thing would be available in 2 ways: keeping ASDL of every version (and it would be definitely a
mess), or only the generated code for that nodes as a part of that "compatibility" layer. I'd personally
go for the latter. Let's do an imaginary example of 3 different language versions;</p>
<div><pre><span></span>@version 3.6
module Example {
    number = NumOrFloat(object value)
           | Complex(object value)
}
</pre></div>


<div><pre><span></span>@version 3.7
module Example {
    number = Num(object value)
           | Float(object value)
           | Complex(object value)
</pre></div>


<div><pre><span></span>@version 3.8
module Example {
    number = Number(object value, str kind)
</pre></div>


<p>The <code>3.6</code> version has 2 nodes, <code>NumOrFloat</code> for numbers and floats and <code>Complex</code> for imaginary numbers.
The <code>3.7</code> form splits <code>NumOrFloat</code> into 2 different nodes, a <code>Num</code> node and a <code>Float</code> node. And finally,
the <code>3.8</code> version has only 1 constructor, it is the <code>Number</code>, with an additional <code>kind</code> field. In theory
that no matter which version you are, in the "compatibility" layer, you would only have the <code>NumOrFloat</code> and
the <code>Complex</code> nodes. For providing that we need some kind of action to do the transition. </p>
<div><pre><span></span>transition $source::$destination [where $condition] {
    [ACTION]
}

transition Number::(Num, Float, Complex) {
    switch (origin-&gt;kind) {
        case 'integer':
            return Num(origin-&gt;value);
        case 'float':
            return Float(origin-&gt;value);
        case 'complex':
            return Complex(origin-&gt;value);
    }
}
</pre></div>


<p>The example upper takes a <code>3.8</code> <code>Number</code> node and outputs a <code>3.7</code> node (<code>Num</code>, <code>Float</code>, or <code>Complex</code>). This is
also going to be the case for <code>3.7</code>, it will take a <code>3.7</code> AST and output a <code>3.6</code> version. So in the end, all ASTs
will be the same in the imaginary "compatibility" layer.</p>
<div><pre><span></span>@version 3.7
module Example {
    number = Num(object value)
           | Float(object value)
           | Complex(object value)

    transition Float::NumOrFloat {
        return NumOrFloat(origin-&gt;value);
    }
}
</pre></div>



<p>I guess this is all, thanks for reading this and if you have any extra thoughts about this, I really want to listen to
all of them. Please contact me through <code>isidentical [at] tree.science</code> or twitter/telegram/discord (<code>@isidentical</code>)</p>
    </div></div>]]>
            </description>
            <link>https://tree.science/transitional-asdl.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738815</guid>
            <pubDate>Sun, 05 Jul 2020 14:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Development on GNU/Linux]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738681">thread link</a>) | @zooboole
<br/>
July 5, 2020 | https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69 | <a href="https://web.archive.org/web/*/https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>
                  Our website is made possible by displaying online advertisements to our visitors.
                  Please consider supporting us by disabling your ad blocker.
                </p>
              
              



              

              <p>There is a general concept that the nearer your web development environment is to your live web hosting environment the less the unexpected snags you will have to fix. The current usage of the Unix and Linux operating system for web servers is estimated as of 2020 at 67%.</p>

<p>So there is a very good chance that your web application will end up on a Linux OS server; you can increase that figure if you take into account Cloud technology which is primarily Linux.</p>

<p>This article looks at some of the nuances of using Linux for web development. I am of course biased in that I am a long time user of GNU/Linux particularly Slackware; currently, I maintain <a href="https://slackbuilds.org/repository/14.2/academic/latex2html/?search=latex2html" target="_blank">Latex2html</a> for the Slackware repository and contribute to <a href="https://docs.slackware.com/howtos:misc:anatomy_of_a_slackbuild" target="_blank">the Docs</a>.</p>

<p>I did use to use Windows for web stuff and it wasn't too bad in the old days when Windows Desktop as default was less cluttered. However generally I ended having to pay for third-party software such as CuteFTP. One day I built a new Desktop PC with a brand new blank hard drive. A blank hard drive with no OS! So it was decision time to pay for a Windows Install Disk, then have to pay for Office Suite or see what Linux can do.</p>

<p>I installed Linux and never looked back. As for CuteFTP I soon discovered there was a large repository where I could obtain the software free of Adverts, free of shareware and free of malware.</p>

<p>I mean it's hard enough coding and getting code bugs without throwing in, is that problem may be due to dodgy software I just installed?</p>

<p>When last in Ghana general comments to me were "why should I bother with that complicated Linux, when I can have Windows for free".</p>

<p>I don't buy that argument; if it was as simple as that why is not everybody in Ghana going from A to B on horses instead of cars. I mean a horse pretty much can do everything a car can, go uphill get you from A to B and only needs a bag of oats and a rub down!</p>

<p>It probably about decision and motivation. Let me just say I'm not here to judge and my air of superiority in using Slackware was recently given a knock and made me think from communication from <strong>Richard Stallman</strong> only last week.</p>

<blockquote>
  <p>Running an unauthorized copy of Windows still gives Microsoft power
  over you. So I say: an unauthorized copy of Windows is a very bad
  thing -- almost as bad as an authorized copy ;-{.</p>
  
  <p>Slackware GNU/Linux has two flaws. It contains nonfree programs. <a href="https://gnu.org/distros" target="_blank">See</a>
  <br> The developers call it "<strong>Slackware Linux</strong>"
  which is unfair to the GNU Project. <a href="https://gnu.org/gnu/linux-and-gnu.html">See</a>
   and <a href="https://gnu.org/gnu/gnu-linux-faq.html" target="_blank">this</a>, plus <a href="https://gnu.org/gnu/the-gnu-project.html" target="_blank">the history</a>.</p>
  
  <p><br> —  Dr. Richard Stallman</p>
</blockquote>

<p>So GNU/Linux Slackware is free as in free beer but not in terms of free in access to all of its code.</p>

<p>If you have only ever used Windows there will be a learning curve but there are choices on how fast you learn Linux. Things would be better if in 3rd World Countries such as Ghana they were serious in embracing Linux users and putting Linux onto the school Curriculum.</p>

<p>Some say Linux is complicated but more me I find it a more minimal experience especially using XFCE Desktop. I recently looked at a friend's laptop that was 30 gig and had Windows 10 on it. The hard drive was full but Windows wanted to do it said 2.8gig of updates. To be honest, how you can find your way around the system with all that clutter on the Desktop is beyond me!</p>

<p>The way I think about Linux is to use a car metaphor. Your Diesel car uses diesel and your petrol car, petrol. Apart from that, a driver uses his steering wheel, breaks, etc without a second thought about the engineering concept of the 4 stroke engine.</p>

<p>It's a bit like that in Linux. Once installed and you log in; you have at your disposal Firefox web browser and to all intents and purposes wouldn't know if you were on Linux or Windows.</p>

<p>All the other stuff like LibreOffice is available from the menu; the layout of LibreOffice is user-intuitive and you can save files as "doc".</p>

<p>Basically, the least complicated way is to use Linux as a normal user. In this case "file permissions" are set so that you will not be challenged.</p>

<p>On my Slackware GNU/Linux I have:</p>

<pre><code>bash-5.0$ php -v


PHP 7.4.1 (cli) (built: Dec 19 2019 00:29:31) ( ZTS )

Copyright (c) The PHP Group

Zend Engine v3.4.0, Copyright (c) Zend Technologies

with Zend OPcache v7.4.1, Copyright (c), by Zend Technologies

bash-5.0$
</code></pre>

<p>So with PHP 7.4.1 that's quite adequate to work for say CodeIgniter 4 or Symfony.</p>

<p>Since around 5.5 PHP came with its dev server you can simply do PHP development on your Desktop.</p>

<p>If for instance I download and unzip the latest CodeIgniter, cd into it and run this command:</p>

<pre><code>bash-5.0$ php spark serve

CodeIgniter CLI Tool - Version 4.0.3 - Server-Time: 2020-07-03 06:08:42am

CodeIgniter development server started on `http://localhost:8080`
</code></pre>

<p>Press Control-C to stop.</p>

<pre><code>[Fri Jul 3 12:08:42 2020] PHP 7.4.1 Development Server (http://localhost:8080) started
</code></pre>

<p>I am up and running and can see the landing page at <code>http://localhost:8080</code></p>

<p><img src="https://phpocean.com/assets/images/forum-uploads/de56d459c998c14d57b76a3c4a12d5e0.png" alt="PHP Development server"></p>

<p>As I previously said its best to develop in as near to as your live environment will be so maybe apache might be more appropriate. Also, MySQL needs a database server so you can't use MySQL with the above method but what you can do is easily use sqlite3.</p>

<p>I have a few projects I'm working on and one risk leaving things on the Desktop is that they are easily likely to be wiped.</p>

<p>Developing PHP on Linux in the apache web server is not that complicated; I have it set up so that each project has its own directory located at var/www/htdocs</p>

<blockquote>
  <p>|- htdocs</p>
  
  <p>|-- CI</p>
  
  <p>|-- gbn</p>
  
  <p>|-- ginabrookes</p>
  
  <p>|-- ginbrookes</p>
  
  <p>|-- index.php</p>
  
  <p>|-- mysymfony</p>
</blockquote>

<p>I access via a web page and via a set up using <code>httpd-vhosts.conf</code> file.</p>

<p>Basically, I give each project a different Local host address so that I can directly access each project</p>

<p>such as :</p>

<pre><code>127.0.0.2

127.0.0.3
</code></pre>

<p>In <code>httpd-vhosts.conf</code> file, I could do:</p>

<pre><code>&lt;VirtualHost 127.0.0.7:80&gt;

ServerName ginabrookes.com

ServerAlias www.ginabrookes.com

DocumentRoot "/var/www/htdocs/ginabrookes/public"

&lt;Directory "/var/www/htdocs/ginabrookes/public&gt;

Order allow, deny

Allow from All

AllowOverride All

Require all granted

&lt;/Directory&gt;

&lt;/VirtualHost&gt;
</code></pre>

<p>Or by editing I can use a domain name in the web address bar by matching IP to a name.</p>

<h3>For loopbacking.</h3>

<pre><code>127.0.0.1 localhost

127.0.0.1 darkstar.citreon.org darkstar

127.0.0.2 CI.org

127.0.0.6 ginbrookes.com

127.0.0.7 ginabrookes.com
End of hosts.
</code></pre>

<p>There are some quirks to editing the development code since files within the system that are not in your usual userspace come under root or apache.</p>

<p>Maybe I can address that at another time.</p>

<p>When you first use Linux as a "normal" user; it's not so bad; everything
is there from the menu such as Firefox and generally everything works no problem. You can create documents, open them later, and edit - no problem. Everything is fine in your "normal user space".</p>

<p>Then one day like being in some old mansion you get inquisitive and start to look into other areas, but you find all the doors locked. You try to do something and get a "permission denied" you start feeling like your under "house arrest" and maybe a panic attack coming on.</p>

<p>Well, that's one way of looking at it. Basically, everything outside your normal userspace comes under <code>root</code> or other labels.</p>

<p>Apache webserver is located in the central system, not in your user
space; this is probably one of the main bugs bears Windows users will
have.</p>

<p>If you have a PHP framework inside at directory say called my "mydev",
located at <code>/var/www/htdocs/mydev</code> then you are going to get a shock 
when you open up say a PHP class and edit something- you can't do it
because you don't have permission to do so.</p>

<p>In a nutshell, Linux is a multi-user system; it's designed so that users
don't wander into unknown territory and mess up the whole system.</p>

<p>So if you have web dev in Apache web server and can't edit the code
then how do you get around it?</p>

<p>Well if you look in <code>/etc/httpd/httpd.conf</code> you will find what Apache
runs as in terms of who owns it and under whose permission it runs
under.</p>

<p>Generally, you should see :</p>

<pre><code>user: Apache
group: Apache
</code></pre>

<p>So maybe your know thinking "oh I see it's like one of those poncy
exclusive golf clubs" - I can't get in unless I'm a member!</p>

<p>Sort of.</p>

<p>So say your user name is "andrew" how does andrew get into the
exclusive "apache" club? well, you can run this command:</p>

<pre><code># usermod -a -G apache andrew
</code></pre>

<p>That code will keep all the existing groups andrew belongs to but also, add andrew to the "apache" group.</p>

<p>To make sure your "mydev" is set up
you can run:</p>

<pre><code>bash-5.0# chown apache:apache mydev -R
bash-5.0# chmod 775 mydev -R
</code></pre>

<p>What <code>chmod 775</code> means is that the owner can read, write and execute and the group can do the same - that means that since user Andrew belongs to the Apache group he can now edit code no problem.</p>

<p>The 5 at the end of 775 means everybody else but owner and group. They can read the code, run it but they can't change the code.</p>

<p>Linux permission is a subject in itself. Of course, all this seems
complicated but just like some club that does car mechanics
if you have some guiding hand at a Linux group, it will all be clear.</p>

<p>Apart from maybe seeming complex to start with, Linux has benefits and
features:</p>

<p>It's a very robust system that can cope with erratic "dumsor" in Ghana
generally, you don't have to worry about viruses. There is an Aladdin's cave of software you can add to your system free.</p>

<p>Unlike Windows where you have the choice of either cloned and
very likely insecure system or pay every two years for a new OS; you can
upgrade your Linux system.</p>

<p>Once you get into Linux, then open software is at your door.
Then a brave new world beckons of getting involved with others on coding projects.</p>

<p>Also with Linux, you can …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69">https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69</a></em></p>]]>
            </description>
            <link>https://phpocean.com/tutorials/computer-skills/web-development-on-gnu-linux/69</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738681</guid>
            <pubDate>Sun, 05 Jul 2020 13:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost in Transition: How I'm Fixing My To-Do List]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738567">thread link</a>) | @dickiebush
<br/>
July 5, 2020 | https://www.dickiebush.com/articles/lost-in-transition-todo-list | <a href="https://web.archive.org/web/*/https://www.dickiebush.com/articles/lost-in-transition-todo-list">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-cf6e5a3f19c5dee8c56a"><div><p>I love a crisp to-do list.</p>
<p>Cracking open my notebook, I'm greeted by the column of unchecked boxes set the night before. I’m motivated by the potential for a day well-spent.</p>
<p>"Today's the day I get it all done," I say.</p>
<p>The morning always starts well. Coffee in-hand, I dive head-first into the first task with excitement. Because it's at the top of the list, it always gets done.</p>
<p>It's after this first checkmark goes into my notebook that my day starts to wobble. The rest of the day whizzes by in a blur. As the day comes to a close, the list of unchecked boxes glares back at me.</p>
<p>I've been thinking more about why this happens. And what I've found is single tasks get are easy to do. It's the transition between tasks when things start to crumble.</p>
<p>If I was able to check a box and move onto the next one, I would get through my list every time.</p>
<p>But checking a box usually comes with a break. And that breaks leads me to Twitter. And Twitter can lead me anywhere. </p>
<p>Before I know it, I'm lost in transition.</p>

<p>I lose myself in transition for three reasons:</p>
<ol>
<li>The next to-do is vague</li>
<li>The next to-do uses a different kind of thinking</li>
<li>The list itself is too long</li>
</ol>
<p>When the next task is vague, it can be intimidating. So I've started being very specific with the exact action that gets the task started.</p>
<p>Instead of "☐ Write Blog Post" I scribble "☐ Open Notion and Brainstorm Three Sentence Ideas."</p>
<p>When the next task uses a different kind of thinking, there is a high start-up cost. Switching from programming to writing looks doable on paper, but never works out in practice.</p>
<p>So I've started grouping together tasks which require the same way of thinking. I then structure my day around these groups, slotting the tasks accordingly. I'm most creative and productive early in the morning, but more thoughtful and analytical in the afternoon. When I'm through my morning creative tasks, I'll take a long walk and get ready for the analytical part of my day.</p>
<p>Finally, when the list is too long, I sometimes give up entirely. There are few more ambitious people than my 9 PM self setting my intentions for the next day. So recently I've started splitting my list into two lists — a "have-to-do" and a "nice-to-do."</p>
<p>The "have-to-do" is always shorter than the "nice-to-do." As long I check off each of the "have-to-dos," I feel good at the end of the day. Anything from the "nice-to-do" is just bonus points.</p>
<p>The last thing I'm doing when my list is too long is to simply shorten it. I look the list up and down, find the two lowest leverage tasks, and cross them out. It always pains me to do this, but I know it's the right thing to do. </p>

<p>We all want to get more done. If you experience similar feelings about your to-do list, give these tactics a try. The subtle changes have made me more effective and leave me closing each day a bit more fulfilled.</p>
</div></div></div>]]>
            </description>
            <link>https://www.dickiebush.com/articles/lost-in-transition-todo-list</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738567</guid>
            <pubDate>Sun, 05 Jul 2020 13:41:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most logical explanation is that it comes from a laboratory]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23738545">thread link</a>) | @markdog12
<br/>
July 5, 2020 | https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860 | <a href="https://web.archive.org/web/*/https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            <section>

                
                <div>

    

            <h2>NYHET</h2>



        

        

            <h3 itemprop="description">
            The well-known Norwegian virologist Birger Sørensen and his colleagues have examined the corona virus. They believe it has certain properties which would not evolve naturally. These conclusions are politically controversial, but in this interview he shares the findings behind the headlines.
            </h3>

    

</div>


                <div><p>“I understand that this is controversial, but the public has a legitimate need to know, and it is important that it is possible to freely discuss alternate hypotheses on how the virus originated” Birger Sørensen starts to explain when Minerva visits him in his office one morning in Oslo.</p><p>Despite the explosiveness of his statements and research, Sørensen remains calm and collected.</p><p>Sørensen has been a point of controversy ever since former MI6 director Richard Dearlove cited a yet to be published article by Sørensen and his colleagues in an interview with The Daily Telegraph. The article claims that the virus that causes Covid-19 most likely has not emerged naturally.</p><p>“It’s a shame that there has already been so much talk about this, because I have yet to publish the article where I put forward my analysis”, Sørensen says in the form of an exasperated sigh.</p><p>Together with his colleagues, Angus Dalgleish and Andres Susrud have authored an article that looks into the most plausible explanations regarding the origins of the novel coronavirus. The article builds upon an already published article in the Quarterly Review of Biophysics that describes newly discovered properties in the virus spike protein. The authors are still in dialogue with scientific journals regarding an upcoming publication of the article.</p><p>News outlets are thus confronted with a difficult question: Are the findings and arguments Sørensen and his colleagues put forward of a sufficiently high quality to be presented and discussed in the public sphere? Sørensen explains that they in their dialogue with scientific journals are encountering a certain reluctance to publishing the article – without, however, proper scientific objections. Minerva has read a draft of the article, and has after an overall assessment decided that the findings and arguments do deserve public debate, and that this discussion cannot depend entirely on the publication process of scientific journals.</p><p>In this interview with Minerva, Sørensen therefore puts forward his hypothesis on why it is highly unlikely that the coronavirus emerged naturally.</p><p>On May 18th, WHO decided to conduct an inquiry into the coronavirus epidemic in China. Sørensen believes that it is important that this inquiry looks into new and alternate explanations for how the virus originated, beyond the already well-known suggestion that the virus originated in the Wuhan Seafood Market.</p><p>“There are very few who still believe that the epidemic started there, so as of today we have no good answers on how the epidemic started. Then we must also dare to look at more controversial, alternative explanations for the origin,” Sørensen says.</p><p>Birger Sørensen and one of his co-authors, Angus Dalgleish, are already known as HIV researchers par excellence.</p><p>In 2008, Sørensen’s work came to international <a href="https://www.dagensperspektiv.no/2008/norsk-firma-med-hiv-gjennombrudd">attention</a> when he launched a new immunotherapy for HIV. <a href="https://www.nature.com/search?author=%22Angus%20G.+Dalgleish%22">Angus Dalgleish</a> is the professor at St. George’s Medical School in London who became world famous in 1984 after having <a href="https://www.nature.com/articles/312763a0">discovered</a> a novel receptor that the HIV virus uses to enter human cells.</p><p>The purpose of the work Sørensen and his colleagues have done on the novel coronavirus, has been to produce a vaccine. And they have taken their experience in trialling HIV vaccines with them to analyse the coronavirus more thoroughly, in order to make a vaccine that can protect against Covid-19 without major side effects.</p><h2>Exceptionally well adjusted</h2><p>“The difference between our approach and other vaccine manufacturers is that we have a chemistry background, and we analyse the virus in detail as if we were making a drug,” Sørensen starts to explain.</p><p>“Biology is also chemistry, so by considering the virus from a chemistry perspective, we carry out more detailed analysis, zooming in on certain components.”</p><p>Sørensen takes us through the basic elements of their approach:</p><p>“The first thing you need to establish is which parts of the virus are changing, and which parts are stable. If you want to make a vaccine that lasts, you must stimulate the immune system to react against those parts of the virus that are constant, otherwise the effect will disappear and, in the worst-case scenario, lead to increased illness.</p><p>“Once we know this, we can try to make a vaccine. Where we differ is that we are trying to make a vaccine that uses elements that have as little in common with the body’s natural components as possible, so that the immune system is taught to recognise exactly what the vaccine should protect against”, Sørensen elaborates.</p><p>Sørensen believes this is an important insight which will prevent the immune system from being falsely stimulated in a way that could lead the vaccine to create too many dangerous side effects in the vaccinated person.</p><p>“When we have not succeeded in creating an HIV vaccine, despite the enormous efforts put into that endeavour for the past 30 years, it is because we haven’t understood this,” Sørensen continues.</p><p>He believes that there has not been enough interaction between the part of the pharmaceutical industry that makes HIV medicines and the part that runs the vaccine research. As a consequence, the knowledge you need to make a successful vaccine against HIV in the big pharmaceutical companies has not been adequately exploited by the big, international HIV preventing vaccine studies that have been carried out.”</p><p>Asked about what significance his approached has had when he has analyzed the coronavirus, Sørensen explains:</p><p>“We have examined which components of the virus are especially well suited to attach themselves to cells in humans. And we have done this by comparing the properties of the virus with human genetics. What we found was that this virus was exceptionally well adjusted to infect humans.”</p><p>He pauses for a second.</p><p>“So well that it was suspicious,” he adds.</p><h2>Perfected to infect humans</h2><p>It is already known that the novel coronavirus, like the virus that caused the SARS epidemic in Southeast Asia in 2002-2003, could attach itself to the ACE-2 receptors in the lower respiratory tract.</p><p>“But what we have discovered is that there are properties in this new virus which enables it to use an additional receptor, and create a binding to human cells in the upper respiratory tract and the intestines which is strong enough to produce an infection,” Sørensen elaborates.</p><p>Sørensen says that it is the use of this additional receptor that most likely results in a different illness in Covid-19 patients than the one resulting from SARS.</p><p>“This is what enables the virus to transmit to a greater degree between humans, without the virus having attached itself to the ACE-2 receptors in the lower respiratory tract, where it causes deep pneumonia.</p><p>“That is also why so many of the Covid-19 patients have mild symptoms at the start of the illness, and are contagious before they develop severe symptoms,” he adds.</p><p>It might also explain why some people are ‘super spreaders’ without being ill themselves, Sørensen says.</p><p>In the already published article Sørensen and his colleagues Angus Dalgleish and Andres Susrud describe what they claim is curious about the spike protein of the coronavirus, which makes it especially well suited to infect humans. These findings are the foundation for the hypothesis Sørensen and his colleagues develop in the new article, where they claim that the virus is not natural in origin.</p><div id="factbox-361864">
    <div>
        
        <h2>FACT BOX – Spike Protein</h2>
        <p>A spike protein is a part of the virus attached to the surface of the virus. The spike protein is used by the virus when it enters cells, enabling it to stick in humans. The properties of the spike determines which receptors a virus can utilise and thus which cells the virus can enter to create illness.</p>
        
    </div>
    
</div><p>“There are several factors that point towards this,” says Sørensen. “Firstly, this part of the virus is very stable; it mutates very little. That points to this virus as a fully developed, almost perfected virus for infecting humans.</p><p>“Secondly, this indicates that the structure of the virus cannot have evolved naturally. When we compare the novel coronavirus with the one that caused SARS, we see that there are altogether six inserts in this virus that stand out compared to other known SARS viruses,” he goes on explaining.</p><p>Sørensen says that several of these changes in the virus are unique, and that they do not exist in other known SARS coronaviruses.</p><p>“Four of these six changes have the property that they are suited to infect humans. This kind of aggregation of a type of property can be done simply in a laboratory, and helps to substantiate such an origin,” Sørensen points out.</p><h2>An artificially created virus</h2><p>Asked about whether this implies that the virus is not natural, Sørensen goes on to explain the laboratory process that leads to the creation of new viruses.</p><p>“In a sense it is natural. But the natural processes have most likely been accelerated in a laboratory,” he explains. “It’s also possible for a virus to attain these properties in nature, but it’s not likely. If the mutations had happened in nature, we would have most likely seen that the virus had attracted other properties through mutations, not just properties that help the virus to attach itself to human cells.”</p><p>Sørensen vividly explains this argument:</p><p>“Imagine that you have cultivated a billion coronaviruses you have gathered from nature, then you take this mass of viruses and inject them into a human cell culture from for example the upper respiratory tract. As a result, a few of these viruses will change in order to better attach themselves to …</p></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860">https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860</a></em></p>]]>
            </description>
            <link>https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738545</guid>
            <pubDate>Sun, 05 Jul 2020 13:38:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New revamped version of the AnyMeal recipe management software]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23738543">thread link</a>) | @wedesoft
<br/>
July 5, 2020 | https://www.wedesoft.de/software/2020/06/30/anymeal/ | <a href="https://web.archive.org/web/*/https://www.wedesoft.de/software/2020/06/30/anymeal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.wedesoft.de/software/2020/06/30/anymeal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738543</guid>
            <pubDate>Sun, 05 Jul 2020 13:37:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tatsuo Horiuchi is painting pictures on PC with MS EXCEL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23738479">thread link</a>) | @donbox
<br/>
July 5, 2020 | http://pasokonga.com/index.htm | <a href="https://web.archive.org/web/*/http://pasokonga.com/index.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>順次パソコン画をUPしていきますのでよろしくお願いいたします<br>
When you want to see lager picture , click the  paintings listed hereunder.<br>
<b><span color="#ff0000" size="2">The pictures shown on this site are "ExcellArt"by TatsuoHoriuchi,<br>
which were drawn and painted with Excel suported on PC originaly,</span><span color="#ff0000" size="3"><br>
</span><span color="#ff0000" size="2">and were re-formatted(rasterized) into JPG for the data-compression.</span></b><br>
And w<span size="4">hen you wont to contact T.Horiuchi, please click mailto; </span><i><b><span size="4" color="#ff0000"><a href="mailto:cbl97790@pop06.odn.ne.jp">pasokongaka</a></span></b></i><br>
</p><div>
  <div>
    <p><b><span lang="EN-US">If you want such small size copy  as size:A3(42cm</span>＊<span lang="EN-US">29.7cm),it is possible to print on A3size paper and to ship.<o:p></o:p></span></b></p>
    <p><b><span lang="EN-US">and the price of this is JP\6500, and the cost of air parcel will be JP\3500.<o:p></o:p></span></b><b><span lang="EN-US"><o:p>&nbsp;</o:p></span></b></p>
    <p><span lang="EN-US">we will send the invoice by e-mail through PayPal system according to
    your information which picture you want to buy.<o:p></o:p></span><span color="#000000" size="4"><b>

<br>
    </b></span></p></div>
</div></div>]]>
            </description>
            <link>http://pasokonga.com/index.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738479</guid>
            <pubDate>Sun, 05 Jul 2020 13:27:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Top 3 Reasons Why Your Side-Projects Fail (As A Programmer)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738458">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			
<p>The road to creating the first successful startup / side-project is spiky. The reasons for you to fail are endless and the reasons to win are complex. How can you get your next big thing? And what is stopping you from achieving it as a software developer?</p>
<p>As a senior undergrad and aspiring entrepreneur, I created over 7 projects over the past 3 years. All of them miserably failed and lessons were learned the hard way. You don’t have to go through the same experience to learn the same lessons, here is the final summary of my 3 years journey</p>
<h2><strong>1 – Build and launch</strong></h2>
<p>This might sound trivial, but you actually need to launch. No, you don’t need the best looking product out there to be able to compete, and yes you can find people interested in your product specifically. The internet is an endless source of attention, wherever you go, there is at least 1 person that wished for a solution to a problem you are solving. If the problem you are solving isn’t a priority for the end consumer, you will know. Your project can only grow as much as you believe it can. You are the ship captain and you are the god of that little project, make it or kill it.</p>
<p>In my countless attempts to build a unicorn (jargon for a startup valued at at least $1B) I often never understood why my project was going to work or fail so I quit. Fun fact, soon after, people made it with the same exact idea. I often acted out of ambition, and needless to say, resilience is what gets you to success. The more you endure, the closer you get to where you want.</p>
<p>Before even launching your solution to a problem, think of what approach you are adopting:</p>
<p><strong>Product focused approach:&nbsp;</strong>Your sole purpose is the product, you forget about the market because you are sure the product solves the problem for some people out there. So you strive to make the best UI/UX product out there. The initial time investment makes the approach high-risk high-reward. Personally, I’m not a big fan, if you don’t know someone who can build an optimized and off the charts UI/UX product design, maybe you want to let this one approach down. You’d be better off with having an MVP (minimal viable product) a product with core features only.</p>
<p><strong>Market focused approach:</strong>&nbsp;This approach is the low-risk high-reward investment. You iterate crazy fast over multiple ideas and see what sticks. You can literally skip building a product, set up a landing page, and start talking to people. This approach is not easy either because it will require building your communication skills and learning how to ask questions. I recommend reading ‘The Mom Test’ for this purpose.</p>
<p>This approach is more secure since there is no upfront investment, and if you are building something not wanted, you’ll know it. You will for sure. On the other side, you are building a product with the community, so even though you are working on the project solo or duo, in practice you aren’t, since you get help as much as you talk to users.</p>
<h2><strong>2 – Build but listen</strong></h2>
<p>If you are building a high-end or low-end product, you want to keep talking to people. Think of it this way: You are sailing a ship at 1 in the morning, darkness is your refuge, and there is a storm. Your only way out is to look at the stars. But there are no stars! In this context, your users are your stars, no matter how much you shy away you’ll end up hurting yourself. No matter how confident you are building the right thing, you are putting your confidence into a reality check.</p>
<p>Some developers aren’t comfortable talking to people while others can: Fun fact, you still need to do it. And it’s only a matter of time until you realize that your end users are people like you because you are solving the problem for yourself, to begin with.</p>
<p>Main take away: build a rocket ship or a cookie, you still need to talk to users. Crazy how many people don’t do it and end up wasting 5 – 7 months of development (yup that’s me)</p>
<h2><strong>3 – Manage but learn</strong></h2>
<p>One of your duties as a software developer is switching hats – You didn’t sign up for this did you- One time you’ll act as the technical guru of the project and another you’ll need to make business decisions. Your project is a bottle in a sea, who will even notice it? Forget money, for the time being, no ads, no paid marketing. First, you need to build your ‘business’ skills: promote your product, look at analytics, draw correlations between features and retention, bootstrapping, etc.. You don’t need me to mention all of the problems because they are countless, and this is what’s exciting! You’ll find yourself forgetting your code and reading a huge stack of articles on how to promote your product.</p>
<p>Playing the business person is overwhelming, that’s why it is advised to have a cofounder. Finding one isn’t easy but doable. Sharing the tasks never exempts you from learning the business side of things but at least will lift off some pressure.</p>
<p>As a business person, you don’t want to be stiff, stubborn, or sensitive! If your decision is bad and someone told you, then guess what: you found a valuable member for the project. Not anyone dares to criticize a friend’s product, and the faster you acknowledge your mistakes, the faster you learn, the higher you climb toward your long-waited goal. Obviously, I’m not implying that you should always say you are wrong even if you don’t believe so.</p>
<p>Finally, read! Okay this is probably the best piece of information there is on this article. As cheesy as it might sound, reaaaaaaad!!!! It opens doors you never knew existed. In fact, you can play a game – what I did and had instantaneous results – curate 5 to 6 high detail articles about 1 niche topic. Read all of them and highlight what you find important. Guess what, you are now in the top 1% of your competitors in that specific niche.</p>
<p>If you found this article helpful share it with 1 person that you believe will learn from it, keep the flow of positivity and information going. Thank you sooooo much for reading this. Until the next time, bye 🙂</p>

			
			
</div></div>]]>
            </description>
            <link>https://devhypercharged.com/the-top-3-reasons-why-your-side-projects-fail-as-a-programmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738458</guid>
            <pubDate>Sun, 05 Jul 2020 13:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remap Enter to Control in GNU/Linux (2020 Edition)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738344">thread link</a>) | @todsacerdoti
<br/>
July 5, 2020 | http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/ | <a href="https://web.archive.org/web/*/http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><strong>Note:</strong> Check out my <a href="http://emacsredux.com/blog/2013/11/12/a-crazy-productivity-boost-remap-return-to-control/">original article from 2013</a> about the rationale behind this remapping.</p>

<p>Recently I’ve switched back from macOS to GNU/Linux, as my primary development
environment, and I found out that my <a href="http://emacsredux.com/blog/2016/01/30/remap-return-to-control-in-gnu-slash-linux/">old article</a> on remapping <code>Enter</code>
to <code>Control</code> was no longer the optimal way to achieve this (e.g. - <code>xcape</code>
operates at the X level, which means it doesn’t work with Wayland or without a
GUI). It took me a bit of digging, but eventually I found
<a href="https://gitlab.com/interception/linux/plugins/dual-function-keys">dual-function-keys</a>
(a plugin for the <a href="https://gitlab.com/interception/linux/tools">interception
framework</a>), which does exactly
what I needed and it does it splendidly.</p>

<p>Unfortunately, the tool is not packaged for most
GNU/Linux distros<sup id="fnref:1"><a href="#fn:1">1</a></sup>, but setting it up from source is not that complex. In this article
I’ll share instructions that are specific to Ubuntu, but they should be
easy to modify for other Linux distros.</p>

<p>Let’s kick it off by downloading and installing the <code>interception</code> framework and
<code>dual-function-keys</code>:</p>

<pre><code># install build deps
$ sudo apt install libudev-dev libyaml-cpp-dev libevdev-dev cmake
# create a folder where to clone the source code
$ mkdir src &amp;&amp; cd src
# clone the necessary code
$ git clone https://gitlab.com/interception/linux/tools
$ git clone https://gitlab.com/interception/linux/plugins/dual-function-keys
# build and install the interception framework
$ cd tools
$ mkdir build
$ cd build
$ cmake ..
$ make
$ sudo make install
$ cd ../..
# build the dual-function-keys plugin
$ cd dual-functions-keys
$ make &amp;&amp; sudo make install
</code></pre>

<p>That wasn’t so hard, right? Now we have to create a couple of configuration files and we’re ready for action. The first one is <code>.dual-function-keys.yaml</code> (normally placed in your home folder):</p>

<div><div><pre><code><span># /home/username/.dual-function-keys.yaml</span>
<span>TIMING</span><span>:</span>
  <span>TAP_MILLISEC</span><span>:</span> <span>200</span>
  <span>DOUBLE_TAP_MILLISEC</span><span>:</span> <span>150</span>

<span>MAPPINGS</span><span>:</span>
  <span>-</span> <span>KEY</span><span>:</span> <span>KEY_ENTER</span>
    <span>TAP</span><span>:</span> <span>KEY_ENTER</span>
    <span>HOLD</span><span>:</span> <span>KEY_RIGHTCTRL</span>
</code></pre></div></div>

<p>That’s the main config for <code>dual-function-keys</code>, where we’re specifying the duration of a tap and double tap and our remapping rules. In our case there’s a single rule - <code>Enter</code> acts as <code>Enter</code> on tap (when pressed briefly) and as (right) <code>Control</code> when held down longer.</p>

<p>Then we need to create <code>/etc/udevmon.yaml</code> (you’ll need <code>sudo</code> for this):</p>

<div><div><pre><code><span># /etc/udevmon.yaml</span>
<span>-</span> <span>JOB</span><span>:</span> <span>"</span><span>intercept</span><span> </span><span>-g</span><span> </span><span>$DEVNODE</span><span> </span><span>|</span><span> </span><span>dual-function-keys</span><span> </span><span>-c</span><span> </span><span>/home/bozhidar/.dual-function-keys.yaml</span><span> </span><span>|</span><span> </span><span>uinput</span><span> </span><span>-d</span><span> </span><span>$DEVNODE"</span>
  <span>DEVICE</span><span>:</span>
    <span>EVENTS</span><span>:</span>
      <span>EV_KEY</span><span>:</span> <span>[</span><span>KEY_ENTER</span><span>]</span>
</code></pre></div></div>

<p><strong>Note:</strong> Update the path the <code>.dual-function-keys.yaml</code> accordingly.</p>

<p>Finally we need to create a <code>systemd</code> service definition file for <code>udevmon</code> and start the new service:</p>

<div><div><pre><code><span># /etc/systemd/system/udevmon.service</span>

<span>[</span><span>Unit</span><span>]</span>
<span>Description=udevmon</span>
<span>Wants=systemd-udev-settle.service</span>
<span>After=systemd-udev-settle.service</span>

<span>[</span><span>Service</span><span>]</span>
<span>ExecStart=/usr/bin/nice -n -20 /usr/local/bin/udevmon -c /etc/udevmon.yaml</span>

<span>[</span><span>Install</span><span>]</span>
<span>WantedBy=multi-user.target</span>
</code></pre></div></div>

<p>Now we simply have to enable the <code>udevmon</code> service our remapping will kick in:</p>

<pre><code>$ sudo systemctl enable --now udevmon
</code></pre>

<p>That’s all! Now you can start enjoying your beloved productivity boost!</p>

<p>You can achieve a lot more with <code>dual-function-keys</code>, so I’d advice you to explore the
tool further. Keep hacking!</p>

<h2 id="alternatives">Alternatives</h2>

<p>Another option I considered was <a href="https://github.com/mooz/xkeysnail">xkeysnail</a>, which
seemed a bit simpler to setup, as it’s written in Python, and even has an <a href="https://github.com/mooz/xkeysnail/blob/master/example/config.py">example config geared towards Emacs users</a>. You might want to check it out.</p>

<p>If someone’s using another approach to achieve the same result I’d love to hear about it!</p>



  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://emacsredux.com/blog/2020/07/05/remap-enter-to-control-in-gnu-linux-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738344</guid>
            <pubDate>Sun, 05 Jul 2020 12:58:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Roam Research for Daily Productivity]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738309">thread link</a>) | @austinrileygray
<br/>
July 5, 2020 | https://www.austinrileygray.com/blog/roam-research-for-daily-productivity | <a href="https://web.archive.org/web/*/https://www.austinrileygray.com/blog/roam-research-for-daily-productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>The Daily Routine</h2><p>Since making the switch to Roam for my productivity tool, I’ve started to enjoy the ease and simplicity of using the tool. Once I allocated time to develop a system that works for me within the tool, it streamlined my morning routine even more so than my last system in Notion. The greatest difference between the two systems is that I no longer have to store my daily notes page in any sort of hierarchy. Roam automatically saves a track record of my Daily Notes to the database, and they’re always searchable by date. On top of that, it’s also great to create pages on the fly with the [[]] keyboard shortcut for brain dumping thoughts around different topics / people / projects / strategies that come up while working. These pages are automatically saved to the database and are always searchable by topic/keyword as well.&nbsp;</p><div><p>Here's a screenshot of how I've been starting my days using my new productivity system in Roam:&nbsp;</p></div><figure id="w-node-1f15fb71f55a-83977b8e"><p><img src="https://uploads-ssl.webflow.com/5e0949b376f1c6bbe8b688cf/5f01cba0c33c889141c3a884_1rg6YpfCcukznlGOo47tYT9kplx8MGgbfu_BsPwrUMPZi_LwR_Ry1BjMyFlnCpldvSn6Wg7ZdCchsuUNaIQ-SJNooEEJGmz2ucQIRs11Meek7Ku--W3F1crKMvswN4-NPb92-Hwr.png" alt=""></p></figure><p>As you can see, I've saved this “Daily Routine” template as a favorite in my sidebar so that I can easily access this routine each morning when I begin my workday. The first thing I do when getting to my desk is copy this structure into my "Daily Notes" page. If you're not familiar with Roam yet, the tool automatically creates a new page each day under "Daily Notes." I'll break down each section of my Daily Routine below.&nbsp;<br></p><h3>Ramp Up</h3><p>This section consists of some daily habits I like to complete each morning to get my mind right for the work day. I start with 10 mins of meditation, move into a super quick workout with some pushups and situps to spark some good endorphins, write out what I'm thankful for, and finish by defining the most important project that I need to focus on. This process takes roughly 15 mins from start to finish. Once I'm done, I move directly into my Productive Cycle.<br></p><h3>Productive Cycle</h3><div><p>I've been geeking out on Deep Work since finishing the book in Q1. Through months of testing and iterations, I’ve developed a system that allows me to move the needle on my projects in an undistracted setting. Within my "Productive Cycle," I aim for 3 separate "Power Hours." This allows focused space and time to move projects forward first thing in the morning. By doing this at the beginning of my workday, I can dedicate the remainder of the day to the "shallow work" such as answering emails, jumping on zoom calls, and customer support. When I'm ready to begin each Power Hour, I expand the bullet point within Roam and begin answering the questions I’ve pre-programmed in the template shown below:</p></div><figure id="w-node-a26275288014-83977b8e"><p><img src="https://uploads-ssl.webflow.com/5e0949b376f1c6bbe8b688cf/5f01cba0dc9b2d35c5563a4d_Xe5t7sLEYqrXeMbp1r5WRoEynfcdmg85zqSnhpdiOTVV5KtQMTLIFyjPEo0QCFW4sXtJqlTw7p4vyhj0SmoBtDJL52ogVt3IK8tss4e3yTTF5HdEDQjt8zq3JpAVvbjLeclT4vFN.png" alt=""></p></figure><h4>Power Hours</h4><p>By answering the questions that I've pre-programmed for each Power Hour, I'm able to get crystal clear on exactly what I'm working on for the next hour. I've done some research and have learned that the brain can optimally focus for a a maximum time blocks of 45-52 minutes before needing a break. Therefore, I aim for 45 minutes of focus on the defined activity. Setting an alarm for your finish time does something to the brain to cut out any distractions that would take away from completing the activity. Even though the timer aspect has a profound effect on staying focused, it’s inevitable that some activities naturally require a few minutes over the allocated time block to complete. By setting the timer for 45 minutes, I’ve allowed for 7 minutes of buffer should the activity require extra time. Ultimately, by defining a time period for my work, I’m naturally more inclined to stay focused on the activity at hand.<br></p><h4>Planning &amp; Reflecting</h4><p>The planning portion takes roughly 2-3 mins before starting the actual focused work, and the "Reflect" section takes another 2-3 mins on the back end. If my project goes over the 45 minutes and runs closer to 52 minutes, this puts me really close to the 60 minute mark for the total session length.&nbsp;<br></p><p>By reflecting at the end of each Power Hour before my break, I can quickly capture what I completed and/or what still needs to be done to complete the defined activity. If I completed the activity, I use this time to write down what activity I should work on during the next Power Hour.<br></p><h4>Breaks</h4><p>When I complete each Power Hour, I take a 10 minute break to refill my coffee/tea and water bottle, use the restroom, and take a quick walk outside to get some Vitamin D and quickly check my phone to make sure nothing urgent is being requested from me.&nbsp;<br></p><p>I’ve noticed that there are some mornings where I’m so in the zone that breaks seem like a nuisance. But, I’ve been working to stay diligent in giving my brain a quick rest in between Power Hours and it seems to be working so far. Not only do breaks physically give your brain a rest, they also create clear stopping and starting points for different activities. AND, on top of that, breaks are a good time to add in some more pushups and situps to keep the blood flow moving :)&nbsp;</p><h4>Schedule</h4><p>I've been starting my Productive Cycle by jumping into my first Power Hour at 7 am so I can be done no later than 11 am.&nbsp; I’m aiming for 3 Power Hour sessions per morning, so after I add in the 10 minute breaks, it puts me finishing somewhere around 10:30am. Inevitably, I often get pulled into a request that needs my attention during a break, so I’ve been allowing the 30 minute buffer zone between 10:30 and 11 to make up for any lost time.<br></p><p>If you're interested in joining me in these Productive Cycle sessions, I've opened up a virtual link for others to join me and some other Green Spaces members via zoom. Send me an email to <a href="mailto:austinrileygray@gmail.com">austinrileygray@gmail.com</a> and let me know that you're interested in joining the Productive Cycle and I'll send over a free link to join the next cycle via Zoom. I’ve noticed an even greater amount of accountability and focus when doing these cycles with other movtivated individuals.&nbsp;<br></p><h3>Journal</h3><p>This is where I brain dump during the day. If I have a thought, idea, or to-do, this is the section where I place them. Creating to-do's in Roam is easy... all I have to do is type "/ todo" and click enter and a to-do is automatically created. I follow each to-do with /"today" "/tomorrow" or "/date picker" depending on which day I plan to complete the activity. This is nice because the to-do will show up on whichever day I assign it to in the daily notes filter.&nbsp;<br></p><h3>Reflect</h3><p>This is arguably the most important section of my daily routine and often the most neglected. With that being stated, reflecting on the day helps tremendously with knowing what I should be working on for the next day. When I take the time to complete this section, I'm laser focused on what needs to be done the next morning when starting my workday.&nbsp;<br></p><p>When I don't reflect at the end of the day, I end up wasting precious productive morning time thinking about what I need to work on when I'm starting the next day.&nbsp;<br></p><p>Moral of the story is: <strong>MAKE TIME TO REFLECT.</strong> This is as much of a reminder to myself as anything. It literally takes 5 minutes or less and is arguably the most valuable 5 minutes of each day.&nbsp;<br></p><h2>Conclusion</h2><p>Since incorporating this system into my daily routine, I can say with confidence that I've been more productive with my projects than I've ever been in my whole life. Completing my Productive Cycle first thing in the morning allows me to get what I need to get done before I get pulled into the daily whirlwind. It's great because I can dedicate the rest of the day to shallow work and being reactive without feeling bad about it. And working deeply is FUN and ENJOYABLE. I’m able to get into a state of "flow" that is hard for me to find outside of snowboarding or mountain biking.&nbsp;<br></p></div></div>]]>
            </description>
            <link>https://www.austinrileygray.com/blog/roam-research-for-daily-productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738309</guid>
            <pubDate>Sun, 05 Jul 2020 12:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solve problems more effectively by adopting a strategic mindset]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738231">thread link</a>) | @ChrisHardman29
<br/>
July 5, 2020 | https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset | <a href="https://web.archive.org/web/*/https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sivv.io/article/5f01979d48951651ff15cb0b/Solve-problems-more-effectively-by-adopting-a-strategic-mindset</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738231</guid>
            <pubDate>Sun, 05 Jul 2020 12:38:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terminal illness: useful tips for being productive in the terminal]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738202">thread link</a>) | @ingve
<br/>
July 5, 2020 | https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/ | <a href="https://web.archive.org/web/*/https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Just a disclaimer - I'm no terminal professional. Yet, over the 7 last years, I've learned a few very nice-to-know techniques that you might not have heard of. There's no guarantee that you'll learn anything from this, but a pretty bit chunk of my readers might learn at least a thing or two.</p><blockquote>A little side note here - these commands are meant for OSX only. They might work on Linux or WLS, but I haven't tried them out.</blockquote><h2>Use the clipboard!</h2><p>Every once in a while, you have some data in the clipboard that you want to use somehow, or you want to copy the output of a command into the clipboard. Either way - it's very possible to do!</p><p>So there are two commands you need to know - <code>pbcopy</code> and <code>pbpaste</code>. You can use them together with the pipe operator <code>|</code> and the "to file" operator <code>&gt;</code> to do really cool stuff. Here's a few examples:</p><p>To paste whatever is in your clipboard into a new file - let's say ".env" - you can do this:</p><pre><code>$ pbpaste &gt; .env</code></pre><p>No more creating a new file, then opening it in vim or VSCode to paste and save - now you can just type a few characters and get the job done!</p><p>Similarly, if you want to copy a file to the clipboard, you use the pipe operator and <code>pbcopy</code>. This is how it looks:</p><pre><code>$ cat .env | pbcopy</code></pre><p><code>cat</code> echoes out the entire contents of a file (in this instance <code>.env</code>) and the pipe operator passes it as input to the <code>pbcopy</code> command. Voilá - now you can copy the content of entire files without opening them!</p><p>I use this all the time when I need to copy my ssh key and paste it into GitHub or BitBucket. </p><p>You don't have to limit yourself to files though - pbcopy is much more flexible than that. Whatever you pipe in can be placed on the clipboard - so if you want to copy the result of a program (let's say an encryption program or a password generator), you just pipe it on in.</p><h2>Doing more with <code>less</code></h2><p>I often use the tiny file reader program <code>less</code> to scan, search and read through files. It's really powerful if you know how to use it, but even if you're just using it for the first time, you can just use the arrow keys on your keyboard to scroll through files directly in the terminal.</p><p>Now, I use this mostly to read configuration files, and if I come across something I need to change, I've always had to close the file I was looking at, and open it in an editor like <code>vim</code>. </p><p>Luckily - you can just type <code>v</code>, and the default editor (typically <code>vim</code>) opens up, focused on the <em>same line you were at</em>. Once you close <code>vim</code> (provided you know how to close <code>vim</code>), you're placed back in the same spot as you were as well.</p><p>Also - you can go the start of the document with <code>g</code>, and to the end with <code>shift + g</code>. You can search for a phrase by tapping <code>/</code>, and typing out whatever you're looking for. Navigate through the occurrences by <code>n</code> (forward) and <code>N</code> (backwards). And there's a ton of other things you can do (which you can read about <a href="https://www.linode.com/docs/quick-answers/linux/how-to-use-less/">here</a>).</p><h2>Open files and folders with <code>open</code></h2><p>Often times, you stumble across a file you want want to open the file's default application. That might be a video, an audio clip or perhaps a CSV file. You could exit the flow you're in, of course, and use Finder to navigate to your file and double click it - but we can do better.</p><p>If you want to open any file, you can use the <code>open</code> command to get it done from the terminal:</p><pre><code>$ open videos/screen_recording.mp4
$ open package.json
$ open images/vacation.png</code></pre><p>I usually don't open a lot of files this way, but I do open folders! Just use <code>open</code> on any folder, and you'll get started right away!</p><pre><code>$ open ~/Documents
$ open . # opens the current folder</code></pre><h2>Some power characters!-</h2><p>There are two really nice characters to know when using the terminal, and those two are <code>-</code> and <code>!</code>. </p><p>The <code>-</code> character (dash, hyphen, whatever you call it) works well in two contexts. You can add it to the <code>cd</code> command to return to the previous directory you were in, and you can add it to <code>git checkout</code> to check out the previous branch you were on.</p><pre><code># Example of using cd -
~/Documents $ cd /usr/bin
/usr/bin $ cd -
~/Documents $

# Example of using git checkout -
(master) $ git checkout feature-branch
(feature-branch) $ git checkout -
(master) $</code></pre><p>The exclamation mark is also pretty neat - it lets you search the history of command you've done previously, or re-use the arguments to the last command you used.</p><pre><code>$ !cat
$ # shows you the last command you ran that started with cat

$ less a.txt b.txt
$ vim !* # opens a.txt and b.txt in vim

$ less a.txt b.txt
$ vim !$ # opens b.txt in vim</code></pre><p>It's a neat little trick that I know for some reason, but I never use. Perhaps you'll find some use for it though!</p><p>Much more usable, however is the double exclamation point! Especially in conjunction with the <code>sudo</code> command. If you've ever run a command and realized you had to run it as an administrator, you can simply do <code>sudo !!</code> and re-run it with sudo!</p><pre><code>$ chmod +x /usr/share/firmlinks
chmod: Unable to change file mode on /usr/share/firmlinks: Operation not permitted
$ sudo !!
$</code></pre><h3>Searching the command history</h3><p>Speaking of command history - you don't really need the ! command when you know about the Ctrl+R shortcut! Tap it once, and you'll be able to do an interactive autocomplete search of your entire command history!</p><h2>Oh my...</h2><p>Lastly, I want to talk about oh-my-zsh. Zsh (pronounced sea shell) is a popular alternative to the well known bash shell, and <code>oh-my-zsh</code> is a small framework that adds a ton of useful functionality, aliases and plugins to make your workflow as smooth as possible.</p><p>If you haven't installed it already, you can do so by visiting their <a href="https://ohmyz.sh/">home page</a>. Next, pop up <a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Cheatsheet">this cheat sheet</a> and start learning. There's a ton of useful shortcuts for git (like <code>gst</code> for <code>git status</code> and <code>gc</code> for <code>git commit</code>), but also really nifty commands like <code>...</code> for navigating two directories up or <code>take deep/directory/tree</code> for creating a new directory and navigating into it.</p><p>In addition, there are tons of great themes and plugins available to make your terminal super powerful. I've had <code>oh-my-zsh</code> installed for years, and I just love it more for every passing day.</p><h2>Last words</h2><p>These are some of my favorite tips for being productive in the terminal. There are tons of stuff I've skipped - like how to grep or exit vim - but to be honest I don't use those a lot either. I hope you found at least one new technique to add to your roster - and that you promise to share your favorite commands with me on Twitter.</p></div></div></div>]]>
            </description>
            <link>https://www.selbekk.io/blog/2020/07/useful-tips-for-being-productive-in-the-terminal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738202</guid>
            <pubDate>Sun, 05 Jul 2020 12:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738148">thread link</a>) | @refrigerator
<br/>
July 5, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The finance world is quickly entering the mainstream —</p><p>Every month a notable company goes public. Every week a hot startup raises millions of dollars. And every day moms, pops, and teens check on their stocks. </p><p>Whether a company builds rocket engines or mobile apps, they tell their story using the same language —&nbsp;financial statements. Here's how they work.</p><p>Let's say you run a subscription t-shirt business.</p><p>It's going well — you have happy customers and healthy profit. You're thinking of buying your own factory to make more t-shirts, more quickly, and more cheaply.</p><p>There's just one problem — you can't afford a factory.</p><p>So, you ask the bank for a loan. Your company is profitable and the factory will pay for itself in 3 years, so you know you'll be able to pay it back. But while you know this, the bank doesn't — you'll need to convince them. The bank, however, doesn't know anything about the subscription clothing business.</p><p>To get on the same page, you need a shared language for talking about your business.</p><p><h4 id="heading-1">Double-entry Bookkeeping: The birth of accounting</h4></p><p>Double-entry bookkeeping was the first formalism in finance. The Middle East had it in the <a href="https://www.jstor.org/stable/40697986" target="_blank">first century AD</a>, Korea independently got it in the <a href="https://www.worldcat.org/issn/1598-2661" target="_blank">11th century</a>, and by the <a href="https://web.archive.org/web/20170627232023/http://130.74.92.202:82/record=b1000778" target="_blank">1500s</a>, it had been well-documented across Europe.</p><p>It's a simple concept designed to reduce errors when documenting transactions: every entry to an "account" requires an equal and opposite entry to another "account".</p><p>If you bought some cotton to turn into t-shirts, you might record the transaction like this:</p><p>‍</p><figure id="w-node-371c827e421c-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde0379b53032713cde77_bookkeeping.png" alt=""></p></figure><p>‍</p><p>When you spend $100 on cotton, your "Cash" account gets debited (loses) $100, and your "Materials" account gets credited (gains) $100. The underlying principle is that <em>you can't create something out of nothing</em>.</p><p>This might seem contrived, but with more and more transactions, it can help you spot errors. Since every entry has an equal and opposite entry, the sum of all the debits should always equal the sum of all the credits. If not, you know you made a mistake, and you can look back through your transactions to find it.</p><p>A list of transactions is pretty interesting — it tells a very detailed story about what your company's been up to. Certainly enough to answer the bank's questions when you ask for loan.</p><p>But just as the bank doesn't have time to learn about subscription t-shirts businesses, they don't have time to go through thousands of transactions. To understand what's going on, they need a shorter summary.</p><p><h4 id="heading-2">Financial Statement #1: The Balance Sheet</h4></p><p>If you went through all your transactions and worked out the net value of each account, you'd be able to see things like</p><ul role="list"><li>How much cash you have in the bank</li><li>The total value of the cotton in your inventory</li><li>How much money you owe to your cotton suppliers</li></ul><p>This will give you a snapshot of the current state of your company, split up into "everything you own" (<strong>Assets</strong>) and "everything you owe" (<strong>Liabilities</strong>) — a <strong>Balance Sheet</strong>. These generally won't be equal — ideally your assets will be worth more than your liabilities.</p><p>The difference between the assets and the liabilities is what you, the owner of the company, can rightfully stake a claim to. Crudely, if you sold all your assets today and used that money to pay off all your debts, you'd be left with a pile of cash all to yourself.</p><p>This idea is usually expressed by the "accounting equation":</p><p><strong>Assets - Liabilities = Shareholders Equity</strong></p><p>This is where the "balance" comes in: both sides of the equation are equal. Note that this equation is actually a definition — it asserts that the value of the <strong>Shareholders Equity</strong> is the difference between <strong>Assets</strong> and <strong>Liabilities</strong>. This is the same equation that underpins double-entry bookkeeping.</p><p>Here's what your balance sheet might look like:</p><p>‍</p><figure id="w-node-89b5b437bd58-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde1a11602b68a068a079_balance-sheet.png" alt=""></p></figure><p>‍</p><p>The bank will be interested in seeing this before giving you a loan. It's a quick 'n' dirty way for them to understand the big picture:</p><ul role="list"><li>The orders of magnitude involved — does this company operate in the thousands, millions, or billions?</li><li>An estimate for how much the company is "worth", based on the shareholders equity</li><li>An indication of company health — is the company drowning in debt?</li></ul><p>Financiers often calculate metrics based on the balance sheet, to further summarise the information and to compare numbers across companies.</p><p>The <strong>Debt/Equity Ratio</strong> is a big one, telling you how much a company relies on borrowing money. If it's too high then the company might be too dependent on loans, but if it's too low, this might indicate an inefficiency, since borrowing money to spend on growth can be quicker than earning it the hard way.</p><p>So — the balance sheet summarises a lot about your company, in a way that the bank can understand.</p><p>Unfortunately, it doesn't answer a crucial question — "Do you make money?"</p><p><h4 id="heading-3">Financial Statement #2: The Income Statement (P&amp;L)</h4></p><p>The balance sheet is a snapshot of a single point in time. To understand whether a company makes money, you need see how things change over a period of time (e.g. every month).</p><p>The first thing you need to know is how much money you receive — your <strong>Revenue</strong>. You don't keep all of it — there are costs and expenses along the way — so you need to subtract these. The final number you end up with is your <strong>Profit</strong> — the money you've made at the end of the day.</p><p>Here's how you might do the calculation:</p><p>‍</p><figure id="w-node-a4e76259fbb4-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe0c6c8f0be2b6743533b_p%26l.png" alt=""></p></figure><p>‍</p><p>You start at Revenue (the top line), subtract your costs, and end up at Profit (the "bottom line" — get it?). This is a simple <strong>Profit &amp; Loss (P&amp;L)</strong>, or <strong>Income Statement</strong>. Most companies make one every month, to keep an eye on things. </p><p>‍</p><figure id="w-node-fec0fade16bf-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe17879b5309ce33ce18b_35274025-14536291245349646_origin.png" alt=""></p></figure><p>‍</p><p>With a P&amp;L, you and the bank can understand what's going in and out of your business. If your P&amp;L consistently shows a profit, then the bank will be happy, and so will you.</p><p>In theory, this is very simple. But in practice, each P&amp;L item has hidden nuances to address.</p><p>Let's take just the top line — what does <strong>Revenue</strong> actually mean?</p><p><strong>What is revenue?</strong></p><p>When you started selling shirts, it was a simpler time — you bought them in bulk from China and sold them at the local market.</p><p>Revenue, too, was simple — it was the cold hard cash in your hand.</p><p>But things changed. You started taking bulk orders from shops, who pay you 1 month after you deliver the shirts. And when you went online, your customers started paying you for 12 month subscriptions, all in one go.</p><p>It turns out that if you keep thinking of revenue as "cash in your hand", then things get a little weird —</p><ul role="list"><li>When you get a bulk order, your expenses shoot up. But since you don't get paid until next month, your profit goes way down this month.</li><li>When someone buys a 12-month subscription, your revenue spikes up. But for the next 11 months you have to keep delivering on the order (non-zero cost) without further payments (zero revenue) — your bottom line takes a hit.</li></ul><p>Bulk orders and upfront payments are great for your business, but if revenue means "cash in hand", then your P&amp;L might tell the opposite story.</p><p>A better way to think about revenue is as "the value of products delivered or service provided".</p><p>In each month of a subscription, you do 1 month of work. So even with 12 months' payment upfront, you only recognise 1/12th of that payment as revenue each month. The remaining 11/12th becomes <strong>Deferred Revenue.</strong> This is actually a liability on your balance sheet — your customers have essentially given you a loan which you must pay back each month, in the form of t-shirts.</p><p>The same principle applies for bulk orders — you recognise the revenue when you deliver the product, <em>not</em> when you get paid.</p><p>This is called <strong>Accrual Accounting</strong>, and it more accurately answers the question "Do you make money?".</p><p>So — you've got a balance sheet, showing your current financial state, and you've got a P&amp;L, showing how things change over time. The bank, however, remains unsatisfied.</p><p>Sadly, consistent profits, measured with accrual accounting, can still leave you penniless on payday.</p><p><h4 id="heading-4">Financial Statement #3: The Cashflow Statement</h4></p><p>In 1863, the Dowlais Iron Company had a dilemma.</p><p>On paper, things were great — they'd recovered from a downturn and were posting healthy profits. To smelt more iron, they set out to buy a new blast furnace. But despite their promising P&amp;L, it turned out that they had no cash to buy it.</p><p>What gives?</p><p>Their problem was in spending cash too quickly — as soon as they got some, they'd use it on inventory (iron ore, etc). The profits were rolling in, but the cash wasn't sticking around.</p><p>The company needed a way to understand how cash was coming in and out — the cashflow. Their solution was the origin of the modern <strong>Cashflow Statement</strong>.</p><p>Like the P&amp;L, the cashflow statement shows how things change over each month, but crucially, it only focuses on cash — how much you started with, what you spent it on, where you got more of it, and how much you ended up with. In short, the cashflow statement explains the difference between one balance sheet and the next.</p><figure id="w-node-508193268673-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe644e9cf27ec56e99c29_Untitled-3.png" alt=""></p></figure><p>The bank should now have enough information to decide whether to give you a loan:</p><ul role="list"><li>Balance Sheet — shows everything that you own, and everything that you owe</li><li>P&amp;L/Income Statement — shows how your business operates</li><li>Cashflow Statement — shows how you spend and earn cash</li></ul><p>These financial statements are a shared language, letting businesses communicate across industries and borders. They also "flatten" a business' evolving operations — new business models, delivery methods, and products — to give a coherent view of a company through time.</p><p>Investors use financials to judge performance, lenders use them to assess credit-worthiness, and governments use them to make sure that taxes are correctly paid.</p><p>But the whole system only works if every company follows the same rules when compiling their financials. These rules require years of study to fully understand (this is why accountants exist) and include:</p><ul role="list"><li>How to recognise revenue —&nbsp;accrual accounting</li><li>How to "amortise" costs — spreading upfront expenses over time</li><li>How to "capitalise"&nbsp;costs —&nbsp;turning big purchases into assets on the balance sheet</li></ul><p>Who made these rules?</p><p><h4 id="heading-5">Accounting Standards: Mind the GAAP</h4></p><p>The Industrial Revolution …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.causal.app/blog/whats-a-financial-statement">https://www.causal.app/blog/whats-a-financial-statement</a></em></p>]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738148</guid>
            <pubDate>Sun, 05 Jul 2020 12:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redis running inside Docker container on Nvidia Jetson Nano]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738070">thread link</a>) | @gkorland
<br/>
July 5, 2020 | https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/ | <a href="https://web.archive.org/web/*/https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure><img src="https://collabnix.com/wp-content/uploads/2020/01/image.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2020/01/image.png 1004w, https://collabnix.com/wp-content/uploads/2020/01/image-600x330.png 600w, https://collabnix.com/wp-content/uploads/2020/01/image-300x165.png 300w, https://collabnix.com/wp-content/uploads/2020/01/image-768x422.png 768w, https://collabnix.com/wp-content/uploads/2020/01/image-210x115.png 210w" sizes="(max-width: 1004px) 100vw, 1004px"></figure>







<p>If you are looking out for a small, affordable, low-powered system which comes by default with the power of modern AI for your developers, then NVIDIA Jetson Nano is the answer. NVIDIA Jetson Nano is an embedded system-on-module (SoM) and developer kit from NVIDIA, including an integrated 128-core Maxwell GPU, quad-core ARM A57 64-bit CPU, 4GB LPDDR4 memory, along with support for MIPI CSI-2 and PCIe Gen2 high-speed I/O &amp; that too within $99 price tag. Amazing, isn’t it?</p>



<p>The NVIDIA® Jetson Nano™ Developer Kit is purely an AI computer. It is a small, powerful computer that lets you run multiple neural networks in parallel for applications like image classification, object detection, segmentation, and speech processing. All in an easy-to-use platform that runs in as little as 5 watts. It is perfect for makers, learners, and developers that brings the power of modern artificial intelligence to a low-power, easy-to-use platform. </p>



<h2>Why Redis on Jetson Nano?</h2>



<p> <br>The major problem with existing IoT devices like Raspberry Pi or Jetson Nano board is that they uses a removable microSD card as its boot device and storage. Hence, the problem of temporarily storing data.  Imagine data received by sensors or 4k video images received every seconds on these IoT devices to perform on-device computations.  For major of IoT projects, a message queuing system like MQTT is all that is needed to connect sensors, devices and graphic interfaces together. But if you have hard requirements for high throughput or you’re storing special data types like binary data or image files then you should start considering Redis. </p>



<p>Redis is an open source, in-memory Data Structure Store, used as a database, a caching layer or a message broker. Today Redis supports different kinds of abstract data structures, such as strings, lists, maps, sets, sorted sets, HyperLogLog, bitmaps, streams, and spatial indexes. </p>



<p>As per <a href="https://redis.io/topics/ARM">this</a> link, Redis is ideal for IoT and Embedded devices for several reasons:</p>



<ul><li>Redis has a very small memory footprint and CPU requirements. It can run in small devices like the Raspberry Pi Zero without impacting the overall performance, using a small amount of memory, while delivering good performance for many use cases.</li><li>The data structures of Redis are often a good way to model IoT/embedded use cases. For example in order to accumulate time series data, to receive or queue commands to execute or responses to send back to the remote servers and so forth.</li><li>Modeling data inside Redis can be very useful in order to make in-device decisions for appliances that must respond very quickly or when the remote servers are offline.</li><li>Redis can be used as an interprocess communication system between the processes running in the device.</li><li>The append only file storage of Redis is well suited for the SSD cards.</li><li>The Redis 5 stream data structure was specifically designed for time series applications and has a very low memory overhead.</li></ul>



<p>It is important to note that both Redis 4 and Redis 5 versions supports the ARM processor in general. I have been playing around running containerized applications on Jetson Nano and couldn’t wait to try out Redis on top of NVIDIA Jetson Nano. </p>



<h2>Preparing Jetson Nano</h2>



<ul><li><strong>Unboxing Jetson Nano Pack</strong></li></ul>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-5-1024x397.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-5-1024x397.png 1024w, https://collabnix.com/wp-content/uploads/2019/09/image-5-600x233.png 600w, https://collabnix.com/wp-content/uploads/2019/09/image-5-300x116.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-5-768x298.png 768w, https://collabnix.com/wp-content/uploads/2019/09/image-5-210x81.png 210w, https://collabnix.com/wp-content/uploads/2019/09/image-5.png 1339w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<ul><li><strong>Preparing your microSD card</strong></li></ul>



<p>To prepare your microSD card, you’ll need a computer with Internet connection and the ability to read and write SD cards, either via a built-in SD card slot or adapter.</p>



<ol><li>Download the&nbsp;<a href="https://developer.nvidia.com/jetson-nano-sd-card-image-r322">Jetson Nano Developer Kit SD Card Image</a>, and note where it was saved on the computer.</li><li>Write the image to your microSD card( atleast 16GB size) by following the instructions below according to the type of computer you are using: Windows, Mac, or Linux. If you are using Windows laptop, you can use SDFormatter software for formatting your microSD card and Win32DiskImager to flash Jetson Nano Image. In case you are using Mac, you will need <a href="https://www.balena.io/etcher">Etcher </a>software.</li></ol>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-7.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-7.png 509w, https://collabnix.com/wp-content/uploads/2019/09/image-7-300x187.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-7-210x131.png 210w" sizes="(max-width: 509px) 100vw, 509px"></figure>



<ol><li>To prepare your microSD card, you’ll need a computer with Internet connection and the ability to read and write SD cards, either via a built-in SD card slot or adapter</li></ol>



<figure><img src="https://collabnix.com/wp-content/uploads/2019/09/image-6.png" alt="" srcset="https://collabnix.com/wp-content/uploads/2019/09/image-6.png 655w, https://collabnix.com/wp-content/uploads/2019/09/image-6-600x295.png 600w, https://collabnix.com/wp-content/uploads/2019/09/image-6-300x147.png 300w, https://collabnix.com/wp-content/uploads/2019/09/image-6-210x103.png 210w" sizes="(max-width: 655px) 100vw, 655px"></figure>



<p>The Jetson Nano SD card image is of 12GB(uncompressed size).</p>



<p>Next, It’s time to remove this tiny SD card from SD card reader and plugin it to Jetson Board to let it boot.</p>



<h2>Jetson Nano comes with 18.09 by default</h2>



<p>Yes, you read it correct. Jetson Nano is shipped with Docker Engine 18.09 by default. Let us verify OS version running on Jetson Nano first.</p>



<h2>Verifying OS running on Jetson Nano</h2>



<pre><code>jetson@jetson-desktop:~$ sudo cat /etc/os-release
NAME="Ubuntu"
VERSION="18.04.2 LTS (Bionic Beaver)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 18.04.2 LTS"
VERSION_ID="18.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic
jetson@jetson-desktop:~$</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#verifying-docker"></a>Verifying Docker</h2>



<pre><code>jetson@jetson-desktop:~$ sudo docker version
Client:
 Version:           18.09.2
 API version:       1.39
 Go version:        go1.10.4
 Git commit:        6247962
 Built:             Tue Feb 26 23:51:35 2019
 OS/Arch:           linux/arm64
 Experimental:      false

Server:
 Engine:
  Version:          18.09.2
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.4
  Git commit:       6247962
  Built:            Wed Feb 13 00:24:14 2019
  OS/Arch:          linux/arm64
  Experimental:     false
jetson@jetson-desktop:~$
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#updating-jetson"></a>Updating OS Repository</h2>



<pre><code>sudo apt update
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#installing-docker-1903"></a>Installing Docker 19.03 Binaries</h2>



<p>You will need curl command to update Docker 18.09 to 19.03 flawlessly.</p>



<pre><code>sudo apt install curl
</code></pre>



<pre><code>curl -sSL https://get.docker.com/ | sh
</code></pre>



<pre><code>jetson@jetson-desktop:~$ sudo docker version
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:32:21 2019
 OS/Arch:           linux/arm64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:30:53 2019
  OS/Arch:          linux/arm64
  Experimental:     false
 containerd:
  Version:          1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
jetson@jetson-desktop:~$
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano#installing-docker-compose"></a>Installing Docker Compose</h2>



<pre><code>root@jetson-desktop:/home/jetson# /usr/bin/docker-compose version
docker-compose version 1.17.1, build unknown
docker-py version: 2.5.1
CPython version: 2.7.15+
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
root@jetson-desktop:/home/jetson#
</code></pre>







<h2>Run Redis Server inside Docker </h2>



<p>Jetson Nano is ARMv8 (64bit) and hence we need to verify if ARM64v8 Redis image is available or not.  </p>



<pre><code>jetson@master1:~$ docker run --name redis-server -d arm64v8/redis redis-server --appendonly yes
6b80312b1e05499d565c6962b03f852db7064d5be97acb11dae31791b55ef320
jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
6b80312b1e05        arm64v8/redis       "docker-entrypoint.s…"   6 seconds ago       Up 3 seconds        6379/tcp            redis-server
jetson@master1:~$

</code></pre>



<h2>Verify if Redis Server is running or not</h2>



<pre><code>jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
340437cc7c7c        arm64v8/redis       "docker-entrypoint.s…"   35 seconds ago      Up 32 seconds       6379/tcp            myredis
</code></pre>



<h2>Checking the Redis Logs</h2>



<pre><code>jetson@master1:~$ docker logs -f 4e194
1:C 23 Dec 2019 15:49:21.819 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
1:C 23 Dec 2019 15:49:21.819 # Redis version=5.0.7, bits=64, commit=00000000, modified=0, pid=1, just started
1:C 23 Dec 2019 15:49:21.819 # Configuration loaded
1:M 23 Dec 2019 15:49:21.828 * Running mode=standalone, port=6379.
1:M 23 Dec 2019 15:49:21.828 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
1:M 23 Dec 2019 15:49:21.828 # Server initialized
1:M 23 Dec 2019 15:49:21.828 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.
1:M 23 Dec 2019 15:49:21.829 * Ready to accept connections

</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano/running-redis-on-jetson-nano#run-the-redis-cli-in-the-container"></a>Running the Redis CLI </h2>



<pre><code>jetson@master1:~$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                        NAMES
4e1941c5be9b        arm64v8/redis       "docker-entrypoint.s…"   5 minutes ago       Up 4 minutes        192.168.1.7:6379-&gt;6379/tcp   redis-server
jetson@master1:~$ docker exec -it 4e1941 sh
# redis-cli
127.0.0.1:6379&gt;

</code></pre>



<h2>Redis PING-PONG Test</h2>



<pre><code># redis-cli
127.0.0.1:6379&gt; ping
PONG
127.0.0.1:6379&gt;
</code></pre>



<h2>Verifying Redis Command Line Interface</h2>



<p><code>T</code>The redis-cli is the Redis command line interface, a simple program that allows to send commands to Redis, and read the replies sent by the server, directly from the terminal. </p>



<pre><code># redis-cli
127.0.0.1:6379&gt; ping
PONG
127.0.0.1:6379&gt; set name collabnix
OK
127.0.0.1:6379&gt; get name
"collabnix"
</code></pre>



<h2>Testing Redis CLI Counter Test</h2>



<pre><code>127.0.0.1:6379&gt; incr counter
(integer) 1
127.0.0.1:6379&gt; incr counter
(integer) 2
127.0.0.1:6379&gt;
</code></pre>



<h2><a href="https://github.com/collabnix/dockerlabs/tree/master/beginners/install/jetson-nano/running-redis-on-jetson-nano#connect-from-another-linked-container"></a>Connecting from other Linked container</h2>



<pre><code>jetson@master1:~$ docker run -it --rm …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/">https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/</a></em></p>]]>
            </description>
            <link>https://collabnix.com/running-redis-inside-docker-container-on-jetson-nano/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738070</guid>
            <pubDate>Sun, 05 Jul 2020 12:06:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur: First Impressions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738004">thread link</a>) | @mpweiher
<br/>
July 5, 2020 | https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions | <a href="https://web.archive.org/web/*/https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  
<div>
<p>All major websites that cover macOS have had a look at the shiny new features. I'm going to look at the parts that I don't like.</p><h2 id="toc_1">Comparison to Catalina</h2><p>In former times testing a new macOS version was easy: load it up. Do a bug report or 2. Finished. Mojave with the privacy additions was unpleasant.</p><p>Catalina was rough in the first versions. Apple managed to screw up access to the temp folder in such a way that some apps were unusable. For some users the temp folder was okay and for others it wasn't. The less I say about the privacy idiocy the better.</p><p>So last year was bad. How about this year? Well, it's not better.</p><h2 id="toc_2">The sounds</h2><p>I remember seeing a video about music in Star Wars versus Marvel films. Star Wars music (of course, I mean the first trilogy) is memorable. It conveys emotion. In Marvel films music is just background noise.</p><p>In Big Sur sounds went from Star Wars to Marvel. The experience is jarring and wrong.</p><h2 id="toc_3">Stability</h2><p>Oh my. My test laptop is a MacBook Air. Not really fast but enough for reading, browsing, doing emails, making fractals and software testing. Therefore, it doesn't have that many applications. Here is what I got:</p><ul><li><p>Dropbox didn't even start. They got their act together and a new, working version is available by now.</p></li><li><p>I was looking for a Dropbox replacement. The installer from pCloud didn't finish.
The support only told me that they would support Big Sur when the version of macOS would become available. Thanks for nothing.</p></li><li><p>Luminar is crashing on start. I contacted support. At least they tried a bit. Here is their last statement: „I am afraid we cannot investigate the issue further since you are using a beta version of MacOS. We would recommend you to roll back to Catalina OS.“. That made me laugh.</p></li><li><p>Maps has crashed 2 times in the 15 minutes I used it.</p></li><li><p>Mail has crashed already. Nothing new there.</p></li><li><p>The Air restarted on its own. After trying to install pCloud the Air also had to be restarted.</p></li><li><p>The app I use for developing Mail Archiver doesn't make apps right now. They were using a private framework that has vanished. Oops.</p></li></ul><h2 id="toc_4">Opening files</h2><p>Double click on a file, the app that should open the file comes to front and the file content is shown.</p><p>Seems kinda simple. Unfortunately, coming to front doesn't happen for Preview.</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/1-opening-files.jpg" alt="Big Sur opening file in background"></p><p>Intensely annoying. I've also seen this when installing the new Dropbox version.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/2-opening-files.jpg"></p><h2 id="toc_5">White space</h2><p>Finder got more white-space that wasn't needed. I'm on a small screen here. Now I can see less text in Finder.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/3-whitespace.jpg"></p><p>This also affects the mailboxes in Mail and the menubar applets. Are we going to get touchscreens? Is everything going to be treated as iPhone? I don’t get it. Perhaps the change makes sense on a 10k screen. But not on my Air.</p><h2 id="toc_6">Contrast</h2><p>The newer the version of macOS the less contrast there is. I made some bug reports to Apple for text that I can only read by squinting. The bug reports were closed as „by design“.</p><p>Big Sur has less contrast between foreground and background than ever.</p><p>Toolbars aren't in fashion anyways anymore. So it doesn't matter that I can barely see the selected item.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/4-preferences.jpg" alt="Toolbar selected item barely visible"></p><p>When you are lucky you can still see the selected folder in a sidebar. At little bit at least:</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/5-finder-sidebar.jpg" alt="Finder sidebar"></p><p>Don't use an app that has a black background. Because then you can't see the selected folder at all. I can do the same in Finder with a dark desktop picture.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/6-translucency.jpg"></p><p>And don't try to remove the translucency if you use menubar applets. Because then you won't be able to use them. They now show up white in white.</p><h2 id="toc_7">Buttons</h2><p>Every item in a user interface has meaning. You see buttons that you can click. The elements have a visual hierarchy. A shadow shows you what is in front and what is not. In iOS the difference between clickable and non-clickable items has been eroded.</p><p>Now you have buttons in macOS that can't be recognised as button. Because it's chic to show interface items when you mouse over them.</p><p>The upper area of the screenshot shows the toolbar of a Finder window. If you mouse of the buttons the buttons show up.</p><p><img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/8-mouse-over.jpg" alt="Finder buttons mouse over"></p><h2 id="toc_8">Messageboxes</h2><p>And now we come to the worst part. Any type of messagebox now looks like on the iPhone.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/9-messagebox.jpg"></p><p>But don't add too much text or you will get this gem of a bug. The text is beneath the scrollbar and not next to it.<img src="https://www.mothsoftware.com/cms-data/gallery/hipwig/10-messagebox.jpg"></p><p>Why? This design doesn't make ANY sense at all on a large screen. Did anyone have a problem with the old messageboxes???</p><h2 id="toc_9">Misc</h2><ul><li>The key combinations for menus always show up disabled. Even when the menu item itself is enabled.</li><li>When I navigate in Finder in column view to a new folder then the first item in the view is not the first item in the list but the third.</li><li>When opening screenshots where a scrollbar should be shown there is no scrollbar.</li></ul><h2 id="toc_10">Beta software</h2><p>This is my first impression of Big Sur. As with all beta software bugs are to be expected. But with a large company there are many many eyeballs that work with a software before it is released. They thought at this stage the software was ready for prime time.</p><p>There are a couple of items where I see improvement:</p><ul><li>It’s finally possible to see indetermined progressbars again. How long did it take them? 3 major versions?</li><li>When doing a search in Mail and changing the mailbox the search term remains. I can’t count how often I entered text in a searchfield, selected a different mailbox and had to enter the text again.</li></ul><p>A couple of developer friends said that they prefer the new look. And indeed Big Sur does look fresh and nice. But user interface and user experience are more than a „fresh look“.</p></div>




 
     
  </div></div>]]>
            </description>
            <link>https://www.mothsoftware.com/blog_page.php?permalink=big-sur-first-impressions</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738004</guid>
            <pubDate>Sun, 05 Jul 2020 11:50:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Conflict-Free Replicated Data Types]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23737639">thread link</a>) | @signa11
<br/>
July 5, 2020 | https://lars.hupel.info/topics/crdt/01-intro.html | <a href="https://web.archive.org/web/*/https://lars.hupel.info/topics/crdt/01-intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This is a series about Conflict-Free Replicated Data Types, or CRDTs for short.
Their purpose is to allow seamless replication of data on different nodes in a distributed system.
Merging is by construction always possible, without any conflicts.
This series assumes no knowledge about CRDTs, but be prepared to learn a thing or two about algebras.
All code samples on this page are interactive and executed in your browser.
Understanding the code is necessary for understanding the concepts, so you should be familiar with JavaScript.
If you notice any bugs on this page, <a href="https://github.com/larsrh/website/issues">please let me know</a>!</p><article>
    <p>Dear reader!
If you’re reading this, that’s most likely because you’ve pointed your browser to my website and/or followed a link to this page.
Maybe you’re even reading this from a mobile device!<sup id="fnref:footnote-mobile" role="doc-noteref"><a href="#fn:footnote-mobile">1</a></sup>
Perfect conditions for motivating what all this is about.</p>

<h2 id="contents">Contents</h2>

<ol>
  <li>Preliminaries (this page)</li>
  <li><a href="https://lars.hupel.info/topics/02-contracts">Algebras &amp; contracts</a></li>
  <li><a href="https://lars.hupel.info/topics/03-lattices">Lattices</a></li>
  <li><a href="https://lars.hupel.info/topics/04-combinators">Combinators</a></li>
  <li><a href="https://lars.hupel.info/topics/05-tombstones">Tombstones</a>
    <ul>
      <li>Side note on <a href="https://lars.hupel.info/topics/05a-adt">Abstract Data Types</a></li>
    </ul>
  </li>
  <li><a href="https://lars.hupel.info/topics/06-time">Time</a></li>
  <li><a href="https://lars.hupel.info/topics/07-deletion">Registers and Deletion</a></li>
  <li>Outlook (to be written)</li>
</ol>

<h2 id="the-web-is-a-truly-distributed-application-platform">The web is a truly distributed application platform</h2>

<p><a href="https://lars.hupel.info/img/topics/crdt/world.jpg" data-toggle="lightbox" data-footer="A network of nodes">
  <img src="https://lars.hupel.info/img/topics/crdt/world.jpg" alt="A network of nodes" data-toggle="tooltip" data-placement="bottom" title="A network of nodes">
</a></p>

<p>That’s right.
When you’re building a web application, you absolutely, positively have to care about the distributed aspect of the web.
(Unless your application is stateless, like my website.)</p>

<p>What does this mean?
You may have a bunch of users.
These users may be manipulating their data from a variety of devices.
Some devices may have a slow Internet connection.
Devices may go offline at any point in time.</p>

<p>Sometimes, application developers punt on this issue:
the mobile app displays “You’re offline” and won’t let you see your data (best case), or silently discard information (worst case).</p>

<p>One particular piece in the puzzle of building distributed applications is to figure out the <em>storage</em>.
Ideally, this storage should be resilient towards users that may become unavailable, concurrent edits, and so on.</p>

<p>Enter <em>Conflict-free Replicated Data Types</em>.
A glorious example of Computer Science naming that actually Makes Sense™, they attempt to provide a flexible solution to the storage problem.
The fundamental idea is this:
You have data.
This data is stored on multiple <em>replicas</em>.
CRDTs describe how to coordinate these replicas to always arrive at a consistent state.</p>

<p>Note that there are two different categories of CRDTs: <em>state-based</em> and <em>op-based</em>.
Both serve the same purpose, but work in different ways and come with their own design trade-offs.
In this series, I’m mostly going to focus on state-based CRDTs.</p>

<h2 id="about-crdts">About CRDTs</h2>

<p><a href="https://lars.hupel.info/img/topics/crdt/cool.webp" data-toggle="lightbox" data-footer="Abed Nadir thinks CRDTs are cool">
  <img src="https://lars.hupel.info/img/topics/crdt/cool.webp" alt="Abed Nadir thinks CRDTs are cool" data-toggle="tooltip" data-placement="bottom" title="Abed Nadir thinks CRDTs are cool">
</a></p>

<p>That’s it!
You now understand the idea behind CRDTs.</p>

<p>Of course, that’s only half the story.
There are at least two sides to understanding CRDTs deeply.</p>

<ol>
  <li>Knowing all the varieties (counters, maps, sets, …) and how they can be embedded in application software.</li>
  <li>Diving into the mathematical background (lattices! partial orderings! wooooooo) powering their implementations.</li>
</ol>

<p>In this series, I want to focus on the second aspect and explain everything that’s needed in a bottom-up fashion using interactive notebooks, diagrams and code notation that’s familiar with a large amount of programmers: JavaScript.
I’ll be employing a few libraries for testing code and visualizing data, but otherwise, there are no further dependencies.
The research papers that describe them often assume a great deal of background knowledge in abstract algebra.
I’ll try to introduce just the necessary knowledge gently.</p>

<p>If however, you want to learn more about their use, this series is not for you.
But fear not: there are tons of resources to check out, e.g. <a href="https://crdt.tech/">crdt.tech</a>.
There’s no tracking on this page so I won’t even notice if you’re gone 🤷</p>

<p>Still here?
Cool. <em>Cool, cool, cool.</em></p>

<p>But before we can strap in and talk about CRDTs, we first need to get some paperwork out of the way.</p>

<h2 id="how-to-work-with-this-document">How to work with this document</h2>

<p>All code snippets here are live: this page functions similarly to Jupyter Notebook.
The main difference is that all code is executed in your browser; there’s no roundtrip to a backend service.
Snippets are evaluated when a page is loaded and can be re-evaluated by clicking the <em>Run</em> button.
Feel free to change any snippet to your liking, but note that subsequent snippets are not automatically re-run.
If you want to reset the session, e.g. because you deleted some code, just reload the page.
Your code is not saved between reloads!</p>

<h2 id="tests">Tests</h2>

<p>This page has a built-in test runner.
It takes named <em>properties</em> that should be checked.
The term <em>property</em> is overloaded in programming, so let me be clear: I’m not talking about properties in an object; instead I’m talking about functions that may take arguments and return a truth value.
In other words, a property is a predicate that should be evaluated on ideally all inputs to see if it always holds.</p>

<p>In the following example, we have two properties, one is valid, the other one isn’t.
They are defined using the <a href="https://github.com/dubzzz/fast-check/">fast-check</a> library, which is available under the <code>fc</code> object.</p>

<div><div><pre><code>checkAll({
  "succeed": fc.property(fc.string(), x =&gt; x == x),
  "fail": fc.property(fc.string(), x =&gt; x != x)
});
</code></pre></div></div>

<p>Under the hood, fast-check automatically generates 100 different inputs.
Granted, 100 different inputs is not exactly <em>all inputs</em>, but since there are infinitely many strings, we can’t exactly do that, can we?
fast-check will call the function (e.g. <code>x =&gt; x == x</code>) with the inputs as specified (<code>fc.string()</code> generates ASCII strings with only printable characters).
If the function ever returns <code>false</code> or throws an exception, the property is marked as failed.
Otherwise, it’s marked as successful.</p>

<p>Fortunately, we can also use <a href="https://www.chaijs.com/">Chai</a> assertions inside our properties to get rich error messages:</p>

<div><div><pre><code>checkAll({
  "succeed": fc.property(fc.string(), x =&gt; assert.equal(x, x)),
  "fail": fc.property(fc.string(), x =&gt; assert.notEqual(x, x))
});
</code></pre></div></div>

<p>The great thing about fast-check is that it will automatically show you the <em>smallest</em> (and hopefully simplest) input it could find where the property failed.
This is called the <em>counterexample</em>.
There could be many counterexamples, but here, we only show one.</p>

<div><div><pre><code>checkAll({
  "strlen": fc.property(fc.string(), x =&gt; assert.isAtMost(x.trim().length, 5))
});
</code></pre></div></div>

<p>You’ll see in the results a failure where the counterexample has length 6 and does not just consist of spaces.</p>

<p>Note that a property could be invalid and we’d still not notice it because fast-check didn’t generate that input for us.
That’s a risk we have to live with.</p>

<h2 id="playground">Playground</h2>

<p>Intrigued?
Why not play around with the test runner a little.
Of course, you could modify the code boxes above, but maybe you were afraid to.
So, I prepared a special playground just for you.
Go wild!</p>

<div><div><pre><code>checkAll({
  "be-creative": null
});
</code></pre></div></div>

<p>Feel free to consult the <a href="https://github.com/dubzzz/fast-check/blob/v1.24.1/documentation/1-Guides/Arbitraries.md">fast-check documentation</a> about which data generators there are.</p>

<h2 id="printing">Printing</h2>

<p>The runner can also print different kinds of outputs, e.g. arrays.
Note that only the last expression in a snippet is printed.</p>

<div><div><pre><code>1 + 1;

[
  "this",
  "is",
  "an",
  "array"
]
</code></pre></div></div>

<p>If you define variables without <code>var</code> (or <code>const</code> or <code>let</code>), they can be accessed in subsequent snippets.
I will use that throughout the series.</p>

<p>We can define different printing for a particular object using the <code>interactiveRender</code> symbol.
It can be declared as a method and will be invoked by the runner automatically:</p>

<div><div><pre><code>class Test {
  constructor(value) {
    this.value = value;
  }

  [interactiveRender]() {
    return `Hi ${this.value}!`;
  }
}

new Test("reader")
</code></pre></div></div>

<h2 id="onwards">Onwards</h2>

<p>You are now ready to proceed with the actual introduction.
<a href="https://lars.hupel.info/topics/02-contracts">Go here</a> to learn all about contracts.</p>

<h2 id="testimonials">Testimonials</h2>

<p>People on The Internet™ seem to enjoy these posts:</p>

<div><blockquote><p lang="en" dir="ltr">Great read. This is as entertaining as educational.</p>— Julius Adorf (@jeadorf) <a href="https://twitter.com/jeadorf/status/1276235893586702336?ref_src=twsrc%5Etfw">June 25, 2020</a></blockquote>

</div>
<div><blockquote><div lang="en" dir="ltr"><p>GREAT STUFF</p><p>I found this incredibly accessible, as I have at best a shallow grasp of this kind of mathematics.</p><p>I'd only learned about Lattice theory in the last couple of weeks (while searching for partial ordering), and found your article on lattices easy to follow.</p><p>1/(2 V 3)</p></div>— david Kaye (--The "K" stands for Quality) (@dfkaye) <a href="https://twitter.com/dfkaye/status/1279152170869207040?ref_src=twsrc%5Etfw">July 3, 2020</a></blockquote>

</div>

<h2 id="references">References</h2>

<ul>
  <li>Map by TheAndrasBarta on <a href="https://pixabay.com/photos/world-europe-map-connections-1264062/">Pixabay</a></li>
  <li>Abed Nadir on <a href="https://giphy.com/gifs/community-abed-cool-2HONNTJbRhzKE">Giphy</a></li>
</ul>




<hr>

Thanks to the people who've read drafts of this series and provided valuable feedback:
Andrea, Clement Delafargue, Heiko Seeberger, Hillel Wayne, Johannes Link, Matthew Weidner, Princess.

  </article></div>]]>
            </description>
            <link>https://lars.hupel.info/topics/crdt/01-intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737639</guid>
            <pubDate>Sun, 05 Jul 2020 09:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Depression Is a Fickle Beast]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737470">thread link</a>) | @chrschwz
<br/>
July 5, 2020 | https://blog.christianschwarz.com/depression-is-a-fickle-beast | <a href="https://web.archive.org/web/*/https://blog.christianschwarz.com/depression-is-a-fickle-beast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<div>

<p>Today is just an ordinary day like any other. For some, it’s actually a happy occasion, as many are celebrating Independence Day, their birthdays or the simple joys summer has to offer. Others just go about their daily routines without too much of a hassle.</p>
<p>So did I, exactly one month ago today. It’s Tuesday, the fourth of June. I was standing in my kitchen, making lunch and casually responding to some WhatsApp messages while keeping an eye on the stove, so the eggs won’t overcook.</p>
<p>As I was about to close the app, suddenly, a new message appeared at the top of my screen. That’s a pretty lengthy one, I thought, coming from a friend I went to school with and haven’t seen in a year or so.</p>
<hr>
<h2 id="the-moment-of-truth">The Moment Of Truth</h2>
<p>He told me that Paul, a mutual friend within our group of school friends, took his own life a couple of weeks ago, with the funeral taking place in our hometown within the following days.</p>
<blockquote>
<p>And then it just hit me. A gut-wrenching punch went to my heart and through my whole body.</p>
</blockquote>
<p>In that moment, nothing else mattered while I was just blankly staring at the screen of my smartphone. There was this empty and numb feeling inside, or worse — I didn’t feel anything at all, as I struggled to process the unexpected news about his sudden death.</p>
<p>At first, you‘re trying to convince yourself that it’s a blatant joke. That someone lost a stupid bet and didn’t think of anything better than that.</p>
<p>But as the seconds go on, you realize that this one’s real and something irreversible has happened. There’s nothing you can do to prepare yourself for something like this.</p>
<hr>
<h2 id="it-hurts-more-than-everything">It Hurts, More Than Everything</h2>
<p>I can’t imagine how painful it must be for parents to lose their son who was only 22 years old. That has to be a pain like no other.</p>
<blockquote>
<p>No matter how often you face the death of someone close to you, it will always leave a scar on you that you’re gonna live with for the rest of your life.</p>
</blockquote>
<p>Still in shock, I immediately booked a flight to my hometown for the next morning and embarked upon a journey that would take me to my roots, reconnecting with old places, friends and memories.</p>
<p>It also gave me some time to reflect not only on past times and the beauty of life, but also how transient it is.</p>
<hr>
<h2 id="the-days-pass-slowly-but-the-months-fly-by">The Days Pass Slowly, But The Months Fly By</h2>
<p>Yesterday marked a special day. I visited Paul’s grave for the first time after the funeral last month. Although it gives you some comfort that he doesn’t have to go through his pain anymore, it just hurts to know that he’s gone, forever.</p>
<p>I knew that Paul faced major depression for a long time and remember having talked with him about his experiences with psychotherapy from time to time.</p>
<p>He once mentioned that he tried out medications temporarily while seeing the psychiatric clinic more as a way to not having to live back home, so to retain at least some form of independence as a young adult.</p>
<blockquote>
<p>Had I but known in how much pain he must have really been. Most people who never went through something similar just won’t understand.</p>
</blockquote>
<p>Even though I moved a lot and lived in quite a few places during the last couple of years, I dearly wish that I would have checked on him more often.</p>
<p>The last time we saw each other was almost a year ago, when he and another friend of mine came to visit me in my student town. I’ll always cherish these couple of days and memories we had together.</p>
<blockquote>
<p>In the blink of an eye, everything can change. You never know when it’s the last time you see someone in your life.</p>
</blockquote>
<p>Now, going through the last pictures of us together, I just lose it every single time.</p>
<hr>
<h2 id="what-it-really-means-to-be-depressed">What It Really Means To Be Depressed</h2>
<p>The worst thing about depression is actually the part about losing yourself. Trying to understand your own mind without being able to do so and losing interest in what you once loved. It’s torture in its darkest form, really.</p>
<p>As I <a href="https://www.reddit.com/r/AskReddit/comments/a8hg1m/what_is_depression_like_for_you/ecaqo80?utm_source=share&amp;utm_medium=web2x" target="_blank">once read on Reddit</a>:</p>
<blockquote>
<p>You don’t want to live but you don’t want to die. You don’t want to talk to anyone but you feel very lonely. You wake up in the morning and simply wait for the night to come. It’s like trying to laugh at a joke that isn’t funny. Trying to smile for a photo you don’t want to be in. It’s like waking up in the morning and hating that you actually woke up. It feels like someone is just draining the energy out of you every moment you are awake.</p>
</blockquote>
<p>Many people underestimate that part of the self-loathing comes from others as well. Parents making you feel guilty, society giving you the feeling as if you‘ve failed in life because you’re not living up to certain expectations and so forth.</p>
<p>We live in a system that rewards competition and greed — like, if it’s not something that you want to pursue in your life, you’ll somehow feel misplaced. Seeing everyone succeeding in life just keeps you in a downward spiral of doubt.</p>
<p>The real question still remains — what can be done about it?</p>
<hr>
<h2 id="when-youve-fall-down-the-rabbit-hole">When You’ve Fall Down The Rabbit Hole</h2>
<blockquote>
<p><span>„</span>It’s not your fault.“ - Robin Williams in <em>Good Will Hunting</em></p>
</blockquote>
<p>There are days where I have this lingering hope inside — that more people would increase their awareness towards depression and mental health, so both of these psychological issues could be finally treated with the seriousness they really deserve.</p>
<p>It just hurts seeing so many people instantly judging someone in a negative way, taking it lightly or turning a blind eye to the issue as soon as they hear about someone’s depression.</p>
<blockquote>
<p>No matter where and who you are, people still care about you, even if you don’t want to believe it, and life will get better.</p>
</blockquote>
<p>Never ever shy away from starting therapy or calling one of your <a href="https://en.wikipedia.org/wiki/List_of_suicide_crisis_lines" target="_blank">local suicide prevention hotlines</a> if the feeling of inner restlessness overwhelms you. The girls and guys there would love to listen to you!</p>
<p>Having someone to talk to is probably the best thing for you at this moment. Your friends and close ones can help to a certain degree, but there’s just no real substitute for a professional therapist who can guide you the best on your way to bettering yourself.</p>
<p>Meanwhile, you can also give <a href="https://youtu.be/QeYPAh4mxj4" target="_blank">Jordan Peterson’s thoughts on the topic of depression</a> a try. Being a clinical psychologist, he helped a lot of people become better in many ways. Just be warned that it’s quite an emotional video.</p>
<hr>
<h2 id="theres-no-good-in-grief">There’s No Good In Grief</h2>
<p>If you have recently lost someone, first and foremost, I’m so sorry. I wish I could just give you a big hug right now. There are no words to describe the amount of pain that you’re going through.</p>
<p>It certainly took me a while to get myself back together, being able to go on with everyday life as usual. In the first few weeks, I wasn’t able to sleep without seeing Paul in every dream or go a night without crying.</p>
<blockquote>
<p>I really don’t know what I would have done without music, my sister and my closest friends in a time like this. Thank you so much for just being there for me!</p>
</blockquote>
<p>As cliché as it sounds — time really heals all wounds, but only if you let it do so and embrace all of the grieving stages.</p>
<p>I know that it’s hard to accept this, especially if everything is so fresh, and it’s totally okay to feel this way. Even if you feel somehow indifferent, as it initially happened to me, don’t be too harsh with yourself.</p>
<blockquote>
<p>You’re not emotionally cold — it’s just it’s hard to know what to feel at all when suffering from psychological shock. Believe me when I say that there’s nothing wrong with that.</p>
</blockquote>
<p>In hindsight, I’m so glad that I started writing about it, as it really allowed me to express my feelings and helped me cope with the emotional fallout that I’ve experienced.</p>
<p>Occasionally, I still leave Paul a message on WhatsApp, and even though it feels somehow weird, it really helps as a coping mechanism to deal with his loss, too.</p>
<hr>
<h2 id="and-so-it-goes">And So It Goes</h2>
<p>I wonder how grateful I should be for each new day with all its facets, ups and downs. Being able to just be myself, to capture all of the summer breezes, feel the cold of the winter on my skin, hold my loved ones in my arms, enjoy the sparkles of love and live my life to the fullest.</p>
<p>Something Paul will never experience, ever again. How can people within this context even say that life’s too short?</p>
<blockquote>
<p>This one is for you, <em>Paul Marek Kilka</em>. I’m so grateful to have had you in my life and still ask myself — what if I had messaged you a couple more times, just to talk, to tell you that I’m there for you.</p>
</blockquote>
<p>I still ponder on all the why’s and what if’s, but realize that in the end, it isn’t going to bring you back either. Life just goes on.</p>
<p>I’ll always remember you as the humble, laid-back and honest friend that you were to me since the first time I met you back in school.</p>
<p>Goodbye, Paul. Fly on, wherever you may be.</p>
</div>

</div></div>]]>
            </description>
            <link>https://blog.christianschwarz.com/depression-is-a-fickle-beast</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737470</guid>
            <pubDate>Sun, 05 Jul 2020 09:04:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust on the ESP32 (2019)]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 44 (<a href="https://news.ycombinator.com/item?id=23737451">thread link</a>) | @lnyan
<br/>
July 5, 2020 | https://mabez.dev/blog/posts/esp32-rust/ | <a href="https://web.archive.org/web/*/https://mabez.dev/blog/posts/esp32-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>About six months ago, I made a <a href="https://www.reddit.com/r/rust/comments/ar2d3r/espressif_have_finally_released_an_llvm_fork_this/">post on reddit</a> highlighting the launch of Espressif's llvm xtensa fork, not too long after, I had a working <code>rustc</code> toolchain capable of generating xtensa assembly. At this point I had to put this project to the side to finish my final year of university. Funnily enough I didn't stray too far, my final year project used Rust to create a <a href="https://github.com/MWatch">'smartwatch'</a> (I may write about this in the future, if anyone is interested). </p>
<p>Since then I have seen a few posts utilising my fork to run Rust on the <a href="https://www.espressif.com/en/products/hardware/esp32/overview">ESP32</a> (<a href="https://dentrassi.de/2019/06/16/rust-on-the-esp-and-how-to-get-started/">see this great write up</a> by ctron, if you haven't already), most of which are building on top of <a href="https://github.com/espressif/esp-idf">esp-idf</a> which is written in C. In this post I'll be discussing the steps I took to generate valid binaries for the xtensa architecture with <code>rustc</code> and then write some <code>no_std</code> code to build a blinky program for the ESP32 only using Rust!</p>
<h2 id="hacking-the-compiler">Hacking the compiler</h2>
<p>In March of 2019, Espressif released their first run at an <a href="https://github.com/espressif/llvm-xtensa">llvm fork</a> to support the xtensa architecure. Shortly after I got to work bootstrapping Rust to use this newly created fork. Prior to this project, I'd had no experience with the compiler, fortunately I came across the <a href="https://github.com/rust-lang/rust/pull/52787">RISCV PR</a> which gave me a rough idea of what was required. After <em>many</em> build attempts I finally got it working; I was now able to generate xtensa assembly from Rust source code!</p>
<p>The next step was to assemble and link the generated assembly. The llvm fork in it's current state cannot perform object generation, so we must use an external assembler. Luckily Rust allows us to do so by specifying the <code>linker_flavor</code> as <code>gcc</code> and providing a path to the linker with the <code>linker</code> target option, in this case <code>xtensa-esp32-elf-gcc</code>. After that I created a few built-in targets (which you can see <a href="https://github.com/MabezDev/rust-xtensa/blob/ad570c5cb999f62a03156286fdb5d3d1bbd0fb8b/src/librustc_target/spec/xtensa_esp32_none_elf.rs">here</a>); <code>xtensa-esp32-none-elf</code> for the ESP32; <code>xtensa-esp8266-none-elf</code> for the ESP8266; finally the <code>xtensa-unknown-none-elf</code> target for a generic xtensa target.</p>
<h2 id="blinky-code">Blinky code</h2>
<p>Now lets try and get a ESP32 board to blink the onboard LED using just Rust. First off, we need our basic program structure. The <code>xtensa_lx6_rt</code> crate does most of the heavy lifting in this respect, we simply need to define an entry point and the panic handler. Some of this may look vaguely familiar if you have any experience with <code>cortex-m</code> development on Rust, I've tried to mirror the API as best as I can.</p>
<pre><span>#![</span><span>no_std</span><span>]
#![</span><span>no_main</span><span>]


</span><span>use</span><span> xtensa_lx6_rt as _;

</span><span>use </span><span>core::panic::PanicInfo;

</span><span>/// Entry point - called by xtensa_lx6_rt after initialisation
</span><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {
    </span><span>loop </span><span>{}
}

</span><span>/// Simple panic handler
</span><span>#[</span><span>panic_handler</span><span>]
</span><span>fn </span><span>panic</span><span>(</span><span>_info</span><span>: &amp;PanicInfo) -&gt; ! {
    </span><span>loop </span><span>{}
}
</span></pre>
<p>Now lets add some register definitions for the peripherals we want to use. For our blinky program, we will need to control the GPIO peripheral. In the ESP32 (and most modern processors) peripherals are mapped to memory adresses, commonly refered to as memory mapped peripherals. To control a peripheral we simply need to write values to the right addresses in memory, with respect to the reference manual supplied by the chip manufacturer.</p>
<pre><span>/// GPIO output enable reg
</span><span>const </span><span>GPIO_ENABLE_W1TS_REG</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44024</span><span>;

</span><span>/// GPIO output set register
</span><span>const </span><span>GPIO_OUT_W1TS_REG</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44008</span><span>;
</span><span>/// GPIO output clear register
</span><span>const </span><span>GPIO_OUT_W1TC_REG </span><span>: </span><span>u32 </span><span>= </span><span>0x3FF4400C</span><span>;

</span><span>/// The GPIO hooked up to the onboard LED
</span><span>const </span><span>BLINKY_GPIO</span><span>: </span><span>u32 </span><span>= </span><span>2</span><span>;

</span><span>/// GPIO function mode
</span><span>const </span><span>GPIO_FUNCX_OUT_BASE</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44530</span><span>;
</span><span>const </span><span>GPIO_FUNCX_OUT_SEL_CFG</span><span>: </span><span>u32 </span><span>= </span><span>GPIO_FUNCX_OUT_BASE </span><span>+ (</span><span>BLINKY_GPIO </span><span>* </span><span>4</span><span>);
</span></pre>
<p>Using these definitions it should be possible to change the gpio for your board<sup><a href="#gpio_pin">1</a></sup> by changing the <code>BLINKY_GPIO</code>; for my board (NODEMCU ESP-32S) it was GPIO2.</p>
<h3 id="initialisation">Initialisation</h3>
<p>Next lets setup the pin as a GPIO output. For the ESP32, this is a two step process<sup><a href="#gpio_pin">1</a></sup>. Firstly, its simply a case of setting a bit in the GPIO ouput enable register. Secondly the pin has to be configured in GPIO mode. There are not enough pins for all the possible peripherals in the chip, to combat this each pin can have multiple function modes. In the case of the ESP32, each pin has up to 256 different functions, although not all are mapped. To put the pin in GPIO mode, we need to put in mode 256 (0x100), we do this by writing to the function select register. After issuing those two register writes, we should be able to turn on the GPIO by setting the relevant bit inside the GPIO set register<sup><a href="#2">2</a></sup>.</p>
<pre><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {

    </span><span>// configure the pin as an output
    </span><span>unsafe </span><span>{
        core::ptr::write_volatile(</span><span>GPIO_ENABLE_W1TS_REG </span><span>as </span><span>*mut </span><span>_, </span><span>0x1 </span><span>&lt;&lt; </span><span>BLINKY_GPIO</span><span>);
        </span><span>// 0x100 makes this pin a simple gpio pin - see the technical reference for more info
        </span><span>core::ptr::write_volatile(</span><span>GPIO_FUNCX_OUT_SEL_CFG </span><span>as </span><span>*mut </span><span>_, </span><span>0x100</span><span>); 
    }
    </span><span>// turn on the LED
    </span><span>unsafe </span><span>{
        core::ptr::write_volatile(</span><span>GPIO_OUT_W1TS_REG </span><span>as </span><span>*mut </span><span>_, </span><span>0x1 </span><span>&lt;&lt; idx);           
    }
    </span><span>loop </span><span>{}
}
</span></pre><h3 id="delaying">Delaying</h3>
<p>For the next stage of our blinky program, we need a way to delay; a simple approach could use <code>for</code> loop like so.</p>
<pre><span>pub fn </span><span>delay</span><span>(</span><span>clocks</span><span>: </span><span>u32</span><span>) {
    </span><span>let</span><span> dummy_var: </span><span>u32 </span><span>= </span><span>0</span><span>;
    </span><span>for </span><span>_ in </span><span>0</span><span>..clocks {
        </span><span>unsafe </span><span>{ core::ptr::read_volatile(&amp;dummy_var) };
    }
}
</span></pre>
<p>We add the volatile read so that the compiler doesn't optimise our delay away. The problem with this approach is that depending of the optimisation level, the number of clock cycles each iteration of the loop changes. We need a cycle accurate way of delaying, fortunately the ESP32 has an internal clock counting register which can be accessed with the read special register <code>rsr</code> instruction. Now are delay function looks like this.</p>
<pre><span>/// cycle accurate delay using the cycle counter register
</span><span>pub fn </span><span>delay</span><span>(</span><span>clocks</span><span>: </span><span>u32</span><span>) {
    </span><span>// NOTE: does not account for rollover
    // ommitted: the asm to read the ccount
    </span><span>let</span><span> target = </span><span>get_ccount</span><span>() + clocks;
    </span><span>loop </span><span>{
        </span><span>if </span><span>get_ccount</span><span>() &gt; target {
            </span><span>break</span><span>;
        }
    }
}
</span></pre>
<p>Now we have cycle accurate counting we can delay for one second by waiting for the number of cycles the processor will do in one second. The default clock speed on most ESP boards is 40mhz, hence waiting for 40 million cycles equates to a one second delay.</p>
<p>Bringing the snippets together and cleaning up the code into functions, we now have <code>main</code> that looks like this.</p>
<pre><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {
    </span><span>// configure the pin as an output
    </span><span>configure_pin_as_output</span><span>(</span><span>BLINKY_GPIO</span><span>);

    </span><span>loop </span><span>{
        </span><span>set_led</span><span>(</span><span>BLINKY_GPIO</span><span>, </span><span>true</span><span>);
        </span><span>delay</span><span>(</span><span>CORE_HZ</span><span>);
        </span><span>set_led</span><span>(</span><span>BLINKY_GPIO</span><span>, </span><span>false</span><span>);
        </span><span>delay</span><span>(</span><span>CORE_HZ</span><span>);
    }
}
</span></pre>
<p>After flashing to the board, and firing up our JTAG debugger<sup><a href="#1">3</a></sup>, we are greeted with a blinking LED!</p>

<p>The full source can be found in the <a href="https://github.com/MabezDev/xtensa-rust-quickstart">the xtensa quickstart repo</a> if you wish to try it for yourself.</p>
<p>Now I know what most of you are thinking at this point, it's not very Rusty; it contains bundles of unsafe and there are no real abstractions here, and you are right; but it's something to get the ball rolling.</p>
<h2 id="limitations">Limitations</h2>
<p>There are a few small teething issues, but by far the biggest being issue is that the fork struggles with generating debug info; the external assembler does not support <a href="https://sourceware.org/binutils/docs-2.24/as/CFI-directives.html#CFI-directives">CFI directives</a> something that all llvm targets need to support. CFI directives can easily be removed with some preprocessing, but does of course add an extra step. After pushing past that issue, I was still getting relocation linker errors. I opened <a href="https://github.com/espressif/llvm-xtensa/issues/10">an issue</a> to document my findings in the hopes it can be sorted in the next iteration of the llvm fork.</p>
<h2 id="future-work">Future work</h2>
<p>Once the debuginfo issue is sorted, I hope to start developing an ecosystem of HAL's and drivers similar to the <a href="https://github.com/stm32-rs">stm32-rs</a> and <a href="https://github.com/nrf-rs">nrf-rs</a>; I've already started the <a href="https://github.com/esp-rs">esp-rs</a> organization which is where <code>xtensa-lx6-rt</code> currently resides. Espressif has started the upstream process, the first ten patches are now in review, there should be an update coming to their fork moving from the older llvm6 to llvm8 (and hopefully some other additions and fixes too!).</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="https://github.com/MabezDev/xtensa-rust-quickstart">xtensa-quickstart</a> - A quickstart project for using Rust on xtensa</li>
<li><a href="https://github.com/MabezDev/rust-xtensa">rust-xtensa</a> - The xtensa fork of Rust</li>
<li><a href="https://github.com/MabezDev">github</a> - My github</li>
</ul>
<br>
<hr>
<br>




	</div></div>]]>
            </description>
            <link>https://mabez.dev/blog/posts/esp32-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737451</guid>
            <pubDate>Sun, 05 Jul 2020 09:00:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing (R) dplyr vs. (Julia) DataFrames.jl]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23737449">thread link</a>) | @mindB
<br/>
July 5, 2020 | https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html | <a href="https://web.archive.org/web/*/https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>This time the post is inspired by the proposal of <a href="https://github.com/Arkoniak">Andrey Oskin</a>
(thank you for submitting it, below I have adapted business problem description
and <code>dplyr</code> source codes that Andrey provided).</p>

<p>Andrey shared with me typical tasks that he is faced with when doing logs
analysis. To make things concrete, assume that you have a site and you collect
users’ clicks. In the output of this process you get a table with two fields:
time of click (<code>ts</code> column below, measured in seconds) and the user identifier
(<code>user_id</code> column below).</p>

<p>Given such data there are natural business questions, that we can ask, like:</p>

<ol>
  <li>How many sessions an average user has?</li>
  <li>How many users have exactly two sessions?</li>
  <li>Find top 10 users, ordered by the descending number of sessions?</li>
  <li>What is the average time between sessions start?</li>
</ol>

<p>Session in these questions is a more or less arbitrary thing, usually,
it has a meaning of sequence of events that come together as there is
a short time difference between consecutive events. In the examples we
assume that if a user has not clicked on our site for 900 seconds after the last
click the session is over.</p>

<p>What I do in this post is take a toy data set that has this structure and
<code>dplyr</code> codes that Andrey shared with me that answer the business questions
presented above and rewrite them to DataFrames.jl.</p>

<p>The objective of this post is to compare the syntaxes of <code>dplyr</code> and
DataFrames.jl. Therefore neither <code>dplyr</code> nor DataFrames.jl codes were tuned
to be optimal. Rather I have just taken what Andrey proposed in <code>dplyr</code> and
translated it to DataFrames.jl in a way that first came to my mind (but trying
to use piping). However, in the last part of the post I out of curiosity I
decided compare the performance of the codes.</p>

<p>All codes were  tested under R version 4.0.2 and dplyr 1.0.0.
For Julia I used version 1.5.0-rc1.0 and packages: DataFrames.jl 0.21.4,
Pipe.jl 1.3.0, and ShiftedArrays 1.0.0. If you do not have much experience
with setting-up Julia project environments, in <a href="https://bkamins.github.io/julialang/2020/06/28/automatic-project-environments.html">this post</a> I give
a simple recipe how you can do it easily while ensuring you use exactly the same
versions of the packages as I do.</p>



<p>In the first step we load the required packages, create a data frame that
will be used later and sort it by the <code>ts</code> column.</p>

<p>In all examples in this post I first present R code, and then Julia code.
The expected output is shown in a comment. After each step I briefly comment
on the Julia code.</p>

<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>library</span><span>(</span><span>dplyr</span><span>)</span><span>

</span><span>df</span><span> </span><span>&lt;-</span><span> </span><span>data.frame</span><span>(</span><span>ts</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>1</span><span>,</span><span>10</span><span>,</span><span>20</span><span>,</span><span>1000</span><span>,</span><span>1010</span><span>,</span><span>1200</span><span>,</span><span>2200</span><span>,</span><span>2220</span><span>,</span><span>30</span><span>,</span><span>500</span><span>,</span><span>1500</span><span>,</span><span>1600</span><span>),</span><span>
                 </span><span>user_id</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>ts</span><span>)</span><span>
</span><span>df</span><span>
</span><span>#      ts user_id</span><span>
</span><span># 1     1       1</span><span>
</span><span># 2    10       1</span><span>
</span><span># 3    20       1</span><span>
</span><span># 4    30       2</span><span>
</span><span># 5   500       2</span><span>
</span><span># 6  1000       1</span><span>
</span><span># 7  1010       1</span><span>
</span><span># 8  1200       1</span><span>
</span><span># 9  1500       2</span><span>
</span><span># 10 1600       2</span><span>
</span><span># 11 2200       1</span><span>
</span><span># 12 2220       1</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>using</span> <span>DataFrames</span>
<span>using</span> <span>Pipe</span>
<span>using</span> <span>ShiftedArrays</span>
<span>using</span> <span>Statistics</span>

<span>df</span> <span>=</span> <span>@pipe</span> <span>DataFrame!</span><span>(</span><span>ts</span> <span>=</span> <span>[</span><span>1</span><span>,</span><span>10</span><span>,</span><span>20</span><span>,</span><span>1000</span><span>,</span><span>1010</span><span>,</span><span>1200</span><span>,</span><span>2200</span><span>,</span><span>2220</span><span>,</span><span>30</span><span>,</span><span>500</span><span>,</span><span>1500</span><span>,</span><span>1600</span><span>],</span>
                      <span>user_id</span> <span>=</span> <span>[</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>,</span><span>2</span><span>])</span> <span>|&gt;</span>
    <span>sort</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>ts</span><span>)</span>
<span># 12×2 DataFrame</span>
<span># │ Row │ ts    │ user_id │</span>
<span># │     │ Int64 │ Int64   │</span>
<span># ├─────┼───────┼─────────┤</span>
<span># │ 1   │ 1     │ 1       │</span>
<span># │ 2   │ 10    │ 1       │</span>
<span># │ 3   │ 20    │ 1       │</span>
<span># │ 4   │ 30    │ 2       │</span>
<span># │ 5   │ 500   │ 2       │</span>
<span># │ 6   │ 1000  │ 1       │</span>
<span># │ 7   │ 1010  │ 1       │</span>
<span># │ 8   │ 1200  │ 1       │</span>
<span># │ 9   │ 1500  │ 2       │</span>
<span># │ 10  │ 1600  │ 2       │</span>
<span># │ 11  │ 2200  │ 1       │</span>
<span># │ 12  │ 2220  │ 1       │</span></code></pre></figure>

<p>In this step I used two things that are worth learning:</p>

<ul>
  <li>A <code>@pipe</code> macro from the Pipes.jl package allows to pass result of the left
hand side of <code>|&gt;</code> to the right hand side in the position where <code>_</code> is placed.
In this case <code>_</code> is a first argument to <code>sort</code>.</li>
  <li>I used <code>DataFrame!</code> constructor; the <code>!</code> in this case means that columns
passed to a freshly constructed data frame <em>are not copied</em> (by default
<code>DataFrame</code> constructor copies passed columns for safety).</li>
</ul>



<p>So the first task is to identify sessions in our data. For each user
a <code>session_id</code> column gives a number of session for this user, starting from
zero. Remember, that we assume that a fresh session starts for some user, if
two consecutive events for this user are separated by at least 900 seconds.</p>

<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>&lt;-</span><span> </span><span>df</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>prev_ts</span><span> </span><span>=</span><span> </span><span>lag</span><span>(</span><span>ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>diff_ts</span><span> </span><span>=</span><span> </span><span>ts</span><span> </span><span>-</span><span> </span><span>prev_ts</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>diff_ts</span><span> </span><span>=</span><span> </span><span>ifelse</span><span>(</span><span>is.na</span><span>(</span><span>diff_ts</span><span>),</span><span> </span><span>0</span><span>,</span><span> </span><span>diff_ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>session_start</span><span> </span><span>=</span><span> </span><span>ifelse</span><span>(</span><span>diff_ts</span><span> </span><span>&gt;=</span><span> </span><span>900</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>0</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>session_id</span><span> </span><span>=</span><span> </span><span>cumsum</span><span>(</span><span>session_start</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>select</span><span>(</span><span>-</span><span>prev_ts</span><span>,</span><span> </span><span>-</span><span>diff_ts</span><span>,</span><span> </span><span>-</span><span>session_start</span><span>)</span><span>
</span><span>session_df</span><span>
</span><span># # A tibble: 12 x 3</span><span>
</span><span># # Groups:   user_id [2]</span><span>
</span><span>#       ts user_id session_id</span><span>
</span><span>#    &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;</span><span>
</span><span>#  1     1       1          0</span><span>
</span><span>#  2    10       1          0</span><span>
</span><span>#  3    20       1          0</span><span>
</span><span>#  4    30       2          0</span><span>
</span><span>#  5   500       2          0</span><span>
</span><span>#  6  1000       1          1</span><span>
</span><span>#  7  1010       1          1</span><span>
</span><span>#  8  1200       1          1</span><span>
</span><span>#  9  1500       2          1</span><span>
</span><span># 10  1600       2          1</span><span>
</span><span># 11  2200       1          2</span><span>
</span><span># 12  2220       1          2</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>session_df</span> <span>=</span> <span>@pipe</span> <span>df</span> <span>|&gt;</span>
    <span>groupby</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>user_id</span><span>)</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>:</span><span>ts</span> <span>=&gt;</span> <span>ts</span> <span>-&gt;</span> <span>begin</span>
        <span>prev_ts</span> <span>=</span> <span>lag</span><span>(</span><span>ts</span><span>)</span>
        <span>diff_ts</span> <span>=</span> <span>ts</span> <span>.-</span> <span>prev_ts</span>
        <span>diff_ts</span> <span>=</span> <span>coalesce</span><span>.</span><span>(</span><span>diff_ts</span><span>,</span> <span>0</span><span>)</span>
        <span>session_start</span> <span>=</span> <span>diff_ts</span> <span>.&gt;</span> <span>900</span>
        <span>session_id</span> <span>=</span> <span>cumsum</span><span>(</span><span>session_start</span><span>)</span>
        <span>return</span> <span>(</span><span>ts</span><span>=</span><span>ts</span><span>,</span> <span>session_id</span><span>=</span><span>session_id</span><span>)</span>
    <span>end</span><span>,</span> <span>_</span><span>,</span> <span>ungroup</span><span>=</span><span>false</span><span>)</span>
<span># GroupedDataFrame with 2 groups based on key: user_id</span>
<span># First Group (8 rows): user_id = 1</span>
<span># │ Row │ user_id │ ts    │ session_id │</span>
<span># │     │ Int64   │ Int64 │ Int64      │</span>
<span># ├─────┼─────────┼───────┼────────────┤</span>
<span># │ 1   │ 1       │ 1     │ 0          │</span>
<span># │ 2   │ 1       │ 10    │ 0          │</span>
<span># │ 3   │ 1       │ 20    │ 0          │</span>
<span># │ 4   │ 1       │ 1000  │ 1          │</span>
<span># │ 5   │ 1       │ 1010  │ 1          │</span>
<span># │ 6   │ 1       │ 1200  │ 1          │</span>
<span># │ 7   │ 1       │ 2200  │ 2          │</span>
<span># │ 8   │ 1       │ 2220  │ 2          │</span>
<span># ⋮</span>
<span># Last Group (4 rows): user_id = 2</span>
<span># │ Row │ user_id │ ts    │ session_id │</span>
<span># │     │ Int64   │ Int64 │ Int64      │</span>
<span># ├─────┼─────────┼───────┼────────────┤</span>
<span># │ 1   │ 2       │ 30    │ 0          │</span>
<span># │ 2   │ 2       │ 500   │ 0          │</span>
<span># │ 3   │ 2       │ 1500  │ 1          │</span>
<span># │ 4   │ 2       │ 1600  │ 1          │</span></code></pre></figure>

<p>Now I could have rewritten the <code>dpyr</code> code to DataFrames.jl in many ways, but
a most natural thing to do it was for me to use the following syntax:</p>
<div><div><pre><code>combine(source_column =&gt; transformation_function, grouped_data_frame)
</code></pre></div></div>
<p>With this approach I can conveniently define an anonymous function
within a <code>begin</code>-<code>end</code> block and return a <code>(ts=ts, session_id=session_id)</code> value
that is a <code>NamedTuple</code> and will get expanded into two columns of a data frame.</p>

<p>I use <code>ungroup=false</code> syntax to keep the result a <code>GroupedDataFrame</code> to match
what we get in <code>dplyr</code>.</p>

<p>Also, in the code of the function I use the <code>lag</code> function from ShiftedArrays.jl.</p>

<p>Now we have all information to answer our business questions.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>avg_sessions_per_user</span><span> </span><span>=</span><span> </span><span>sum</span><span>(</span><span>session_num</span><span>)</span><span> </span><span>/</span><span> </span><span>nrow</span><span>(</span><span>.</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   avg_sessions_per_user</span><span>
</span><span>#                   &lt;dbl&gt;</span><span>
</span><span># 1                   2.5</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_num</span> <span>=&gt;</span> <span>mean</span> <span>=&gt;</span> <span>:</span><span>avg_sessions_per_user</span><span>)</span>
<span># 1×1 DataFrame</span>
<span># │ Row │ avg_sessions_per_user │</span>
<span># │     │ Float64               │</span>
<span># ├─────┼───────────────────────┤</span>
<span># │ 1   │ 2.5                   │</span></code></pre></figure>

<p>Observe, that in the DataFrames.jl code the first <code>combine</code> is applied
to <code>GroupedDataFrame</code> while the second <code>combine</code> is applied to a <code>DataFrame</code>.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>session_num</span><span> </span><span>==</span><span> </span><span>2</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>number_of_two_session_users</span><span> </span><span>=</span><span> </span><span>nrow</span><span>(</span><span>.</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   number_of_two_session_users</span><span>
                        </span><span>&lt;</span><span>int</span><span>&gt;</span><span>
</span><span>1</span><span>                           </span><span>1</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>filter</span><span>(</span><span>:</span><span>session_num</span> <span>=&gt;</span> <span>==</span><span>(</span><span>2</span><span>),</span> <span>_</span><span>)</span> <span>|&gt;</span>
    <span>DataFrame</span><span>(</span><span>number_of_two_session_users</span> <span>=</span> <span>nrow</span><span>(</span><span>_</span><span>))</span>
<span># 1×1 DataFrame</span>
<span># │ Row │ number_of_two_session_users │</span>
<span># │     │ Int64                       │</span>
<span># ├─────┼─────────────────────────────┤</span>
<span># │ 1   │ 1                           │</span></code></pre></figure>

<p>In this code observe that <code>:session_num =&gt; ==(2)</code> syntax means that in the
<code>filter</code> function we pass each element of <code>:session_num</code> column to <code>==(2)</code>
function, which is a <a href="https://en.wikipedia.org/wiki/Currying">curried</a> version of a standard <code>x == 2</code> comparison.</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>session_num</span><span> </span><span>=</span><span> </span><span>max</span><span>(</span><span>session_id</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>desc</span><span>(</span><span>session_num</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>rn</span><span> </span><span>=</span><span> </span><span>row_number</span><span>())</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>rn</span><span> </span><span>&lt;=</span><span> </span><span>10</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>select</span><span>(</span><span>-</span><span>rn</span><span>)</span><span>
</span><span># # A tibble: 2 x 2</span><span>
</span><span>#   user_id session_num</span><span>
</span><span>#     &lt;dbl&gt;       &lt;dbl&gt;</span><span>
</span><span># 1       1           3</span><span>
</span><span># 2       2           2</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pipe</span> <span>session_df</span> <span>|&gt;</span>
    <span>combine</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_id</span> <span>=&gt;</span> <span>(</span><span>x</span> <span>-&gt;</span> <span>maximum</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1</span><span>)</span> <span>=&gt;</span> <span>:</span><span>session_num</span><span>)</span> <span>|&gt;</span>
    <span>sort</span><span>(</span><span>_</span><span>,</span> <span>:</span><span>session_num</span><span>,</span> <span>rev</span><span>=</span><span>true</span><span>)</span> <span>|&gt;</span>
    <span>first</span><span>(</span><span>_</span><span>,</span> <span>10</span><span>)</span>
<span># 2×2 DataFrame</span>
<span># │ Row │ user_id │ session_num │</span>
<span># │     │ Int64   │ Int64       │</span>
<span># ├─────┼─────────┼─────────────┤</span>
<span># │ 1   │ 1       │ 3           │</span>
<span># │ 2   │ 2       │ 2           │</span></code></pre></figure>

<p>Here note that in the <code>:session_id =&gt; (x -&gt; maximum(x) + 1) =&gt; :session_num</code>
expression we have to wrap <code>x -&gt; maximum(x) + 1</code> in parentheses to get the
correct result (if you would omit it <code>=&gt; :session_num</code> would be treated as a
part of an anonymous function definition).</p>



<p><em>dplyr</em></p>

<figure><pre><code data-lang="r"><span>session_df</span><span> </span><span>%&gt;%</span><span>
    </span><span>arrange</span><span>(</span><span>ts</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>,</span><span> </span><span>session_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>rn</span><span> </span><span>=</span><span> </span><span>row_number</span><span>())</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>rn</span><span> </span><span>==</span><span> </span><span>1</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>group_by</span><span>(</span><span>user_id</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>prev_start</span><span> </span><span>=</span><span> </span><span>lag</span><span>(</span><span>ts</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>filter</span><span>(</span><span>!</span><span>is.na</span><span>(</span><span>prev_start</span><span>))</span><span> </span><span>%&gt;%</span><span>
    </span><span>mutate</span><span>(</span><span>sess_diff</span><span> </span><span>=</span><span> </span><span>ts</span><span> </span><span>-</span><span> </span><span>prev_start</span><span>)</span><span> </span><span>%&gt;%</span><span>
    </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span>
    </span><span>summarize</span><span>(</span><span>avg_session_starts</span><span> </span><span>=</span><span> </span><span>mean</span><span>(</span><span>sess_diff</span><span>))</span><span>
</span><span># # A tibble: 1 x 1</span><span>
</span><span>#   avg_session_starts</span><span>
</span><span>#                &lt;dbl&gt;</span><span>
</span><span># 1               1223</span></code></pre></figure>

<p><em>DataFrames.jl</em></p>

<figure><pre><code data-lang="julia"><span>@pi…</span></code></pre></figure></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html">https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html</a></em></p>]]>
            </description>
            <link>https://bkamins.github.io/julialang/2020/07/03/dplyr-vs-df.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737449</guid>
            <pubDate>Sun, 05 Jul 2020 08:59:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Absolem Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737163">thread link</a>) | @signa11
<br/>
July 5, 2020 | https://zealot.hu/absolem/ | <a href="https://web.archive.org/web/*/https://zealot.hu/absolem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <div>

<p><img src="https://zealot.hu/absolem/pics/splash.jpg" alt="Absolem Splash"></p>

<h2 id="tldr">tl;dr</h2>

<p>I’ve designed and built my own mechanical keyboard.
It’s fucking awesome!
I’m going to ramble about it now, <em>in detail</em>.
Read on if you’re interested, or jump to either the <a href="#assembly">in-progress</a> or the <a href="#the-finished-product">finished</a> pictures, or post a comment to <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/d0wls7/ladies_and_gentleman_the_absolem/">the reddit thread</a>, or… you know… do whatever you fancy.
I’m not your mom. :)</p>

<h2 id="contents">Contents</h2>

<ul>
  <li><a href="#intro">Intro</a></li>
  <li><a href="#research">Research</a></li>
  <li><a href="#design">Design</a></li>
  <li><a href="#build">Build</a></li>
  <li><a href="#firmware">Firmware</a></li>
  <li><a href="#keymap">Keymap</a></li>
  <li><a href="#writeup">Writeup</a></li>
  <li><a href="#future-work">Future work</a></li>
  <li><a href="#club">“Club”</a></li>
</ul>

<h2 id="intro">Intro</h2>

<p>Until about one and a half years ago, I’d been happily typing on a <a href="https://www.cnet.com/products/genius-slimstar-i220-keyboard-series/">basic Genius keyboard</a> with a QWERTZ (Hungarian QWERTY) layout.
Ah… simpler times!</p>

<p><img alt="Ignorance is bliss" src="https://zealot.hu/absolem/pics/fun/ignorance_is_bliss.gif">
</p>

<p>I was hovering at about 50-60 wpm, which – while decidedly not blazing fast – didn’t bother me much.
I also didn’t really care that my typing “technique” involved around 4-6 fingers and a lot of looking at the keyboard.
What <em>did</em> bother me was nights when I couldn’t actually see the keys and it slowed me down quite a bit.</p>

<p>If you’re thinking that my solution was learning to touch type, you’re wrong! (for now…)
I, of course, decided that I needed a backlit keyboard.
Around this time I was vaguely aware of mechanical keyboards and the “supposed” superior typing experience they provide.
So to celebrate my dissertation defense, – and after a cursory glance at full size vs. TKL arguments – I treated myself to a <a href="https://www.coolermaster.com/catalog/peripheral/keyboards/masterkeys-pro-s-white/">MasterKeys Pro S</a>.
And that’s where the problems started…</p>

<p>To be fair, the Pro S is a fine keyboard.
But it’s not even the thing that convinced me about mechs.
By the time it arrived, the geekhack-deskthority-r/mk Bermuda triangle sucked me in, and I was already too deep.
Looking back now, I think the main cause was that I started looking at the topic as genuine “research”, and in my mildly fanatic<a href="#footnote-1"><sup>1</sup></a> worldview that could only end with another “dissertation”, which is what this post is, I guess.</p>

<p>So, strap in as I rant about the whole journey that led me here.
Also, fair warning that I’m writing this on the already finished Absolem, which is just a pleasure to type on, so I’m going to be verbose! :P</p>

<h2 id="research">Research</h2>

<p>Being a researcher by trade, I can very much appreciate the need for seeing what someone has already done in order to not reinvent the wheel.
Also, following the old saying “stealing from one source is plagiarism; stealing from many is research”, I have basically patched together the (imho) best parts of what the current state of the art has to offer.
It was an interesting observation to make that almost all the best<a href="#footnote-2"><sup>2</sup></a> ergo aspects came from different places, while their combination didn’t exist yet.
That’s probably what lead to me deciding to design my own; had I found a board that checks all the boxes, I’d have just ordered that.
(I’m also secretly happy that it didn’t turn out like that, because this way I got to make my own, and it was a good chance to grow… but psst, don’t tell that to anyone!)</p>

<p>So with that in mind, let me just quickly walk you through the steps that lead me to “keeb enlightenment”.
Disclaimer, though: I’m only going to mention most concepts briefly to keep the post’s length manageable, but it can hopefully serve as a good starting point to begin your own, deeper research if you want.</p>

<h3 id="general-stuff">General stuff</h3>

<p>Okay, basics first, if you’re interested in the topic, you should browse <a href="https://geekhack.org/">GeekHack</a>, <a href="https://deskthority.net/">Deskthority</a>, and (of course) <a href="https://www.reddit.com/r/MechanicalKeyboards/">r/mk</a>.
(As an example, <a href="https://geekhack.org/index.php?topic=95771.0">here</a> are my tentative first steps in a brave new world over on Geekhack).</p>

<p>These places are not only chock full of information, ideas, and inspiration; they also house a very helpful and supportive community.
This is also where I’d like to thank a few people for their general help in this project, namely:</p>

<ul>
  <li><a href="https://geekhack.org/index.php?action=profile;u=55020">algernon</a>, fellow Hungarian keeb expert, for all the early advice,</li>
  <li><a href="https://feierabendprojekte.wordpress.com/2018/03/21/building-a-keyboard-by-hand/">Azel4231</a>, for his help in switch layout related measurements (I’m the “redditor” from the addendum…),</li>
  <li>and, naturally, <a href="https://www.reddit.com/user/Dotdash32/">DotDash32</a>, for the metric shitton of discussion we’ve done in both posts and reddit messages that really helped me shape what I should aim for.</li>
</ul>

<h3 id="staggers">Staggers</h3>

<p>What became really clear early on is that row-staggers are evil.
The reason they exist is pure path dependence (we’ve always done it like this, let’s keep doing it like this), and they should be eradicated.
For me, this is an issue that’s been a non-issue for a long long time, but now (that I’m “enlightened”) it’s impossible to unsee…
I mean, I sympathize with all the muscle memory that will be lost in a transition (I’m in the middle of one right now, after all), but that can’t be a good enough reason not to switch!
I’m not really a comment-y kind of guy, but you can find even me sometimes in the <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/c8njw4/ergonomic/esr6nab/?context=8&amp;depth=9">middle of an argument</a> under reddit posts that claim some connection to ergonomics, yet still retain the row-stagger.</p>

<p>I’m much more “lenient” towards ortho (a.k.a. grid, or matrix) layouts, but the clear winner of this aspect (for me) is column-staggered boards.
Let’s give future aliens a chance to figure out how we looked like!</p>

<p><img alt="Nerd joke" src="https://zealot.hu/absolem/pics/fun/nerd_joke.jpg" width="60%">
</p>

<p>What’s more, I’m very much in favour of an “aggressive” stagger.
Many boards started in the right direction, but few went far enough, so I’ve been planning to be a little heavier-handed in the stagger department from the start.</p>

<p>As an example, compare a <a href="http://www.vortexgear.tw/vortex2_2.asp?kind=47&amp;kind2=220&amp;kind3=&amp;kind4=997">“traditional” TKL (or 60%)</a> vs. a <a href="https://olkb.com/planck">Planck</a> vs. an <a href="https://atreus.technomancy.us/">Atreus</a>.</p>

<h3 id="the-number-of-keys">The number of keys</h3>

<p>Today’s full size (and beyond) keyboards come from the assumption that there should be the same number of keys as there are desired functionalities and we should make our hands conform to the resulting layout.
I, on the other hand, think that the inverse of this is true, namely that we should make the number of the keys match what’s comfortably reachable from the home position and make the desired functionalities conform to that.</p>

<p><img alt="XKCD keyboard" src="https://zealot.hu/absolem/pics/fun/xkcd_keyboard.png" width="60%">
</p>

<p>This leads to a) touch typing – or at least a strictly enforced finger-key relationship (which has many more benefits I’m not going to discuss here) and b) to the need to significantly decrease the number of keys.
On the other extreme of the spectrum is <a href="http://plover.stenoknight.com/">stenography</a>, but even if we remain firmly within the realm of letter-based typing, we can (and should) make do following the “at most 1 key distance from home” principle.
That leaves at most 6 × 3 keywells + 3 thumb keys per hand.
I’d argue that anything more than that is bad.
(Not only “unnecessary” or “wasteful”, mind you, but actually bad. As in, it could be better with less…)</p>

<p>The natural result of a small number of keys while still wanting a large number of functions is the use of layers.
And layers – especially if combined with custom programmability, more on that later – are the “bees knees”!
Nevertheless, I encounter many posts that criticize the overuse of layers, or posts that express confusion about how a 40% keyboard can still be practical.
I’d refer the former group to their shift keys and the notable lack of dedicated capital letters on their boards, while the latter group should take a look at their phone while writing a text and tell me again how a really small keyboard is unusable.</p>

<p>Anyways, I digress…
The point is that I came to the conclusion that there should be very few keys with heavy layering support.
As an example, consider traditional keyboards vs. a <a href="https://github.com/foostan/crkbd">corne</a>.</p>

<h3 id="the-pinky-column">The pinky column</h3>

<p>Like we saw above, the pinky often gets 2 columns (similarly to the index finger) even when conforming to the “1 distance from home” (1DFH) rule; and much more when not.
What I’ve found is that a) it’s unnecessary with a sufficiently clever keymap and a lo(oooo)t of practice, and b) it <em>should</em> be avoided to spare your weakest fingers however you can.
So I’ve adopted a further restriction over the 1DFH to limit myself to 5 × 3 keys per hand (plus the thumbs, of course).</p>

<p>Regarding the physical layout of the pinky keys, my experiments (and my eyes, when looking at my hand) showed that the pinky can use a little bit of separation from the others.
This <em>could</em> theoretically apply to the ring and middle fingers, too, but I didn’t feel the need in those cases.
However, it really shouldn’t apply for the index finger, which already has an extra column to take care of, like in the case of the <a href="https://github.com/omkbd/Sector">Sector</a>.</p>

<p>As an example of pinky overworking, consider any regular layout (or even the <a href="https://ergodox-ez.com/">Ergodox</a>) vs. the <a href="https://geekhack.org/index.php?topic=89951.0">Minidox</a> (of which my design is basically a slightly refined, glued together, and wireless-ized version).
As for an illustration of the pinky angle, take a look at the <a href="https://github.com/pseudoku/ErgoWarp">ErgoWarp</a>.</p>

<h3 id="the-thumb-region">The thumb region</h3>

<p>Generally, there are three approaches for the thumbs:</p>

<ol>
  <li>SPACEBAR!!! – one of the thumbs can keep hacking away on a button that takes up 6-7 spaces, while the other just exists. Very efficient… <code>&lt;/sarcasm&gt;</code> There are more sophisticated layouts, with split spacebars and the like, but from an ergonomic standpoint, these are all subpar compared to the next two.</li>
  <li>Clusters – consider the <a href="https://ergodox-ez.com/">Ergodox</a> again. While this way is definitely better than a single spacebar, in my opinion it overcompensates with the amount of work it tries to give to the thumbs. The side effect of this is that very few of those thumb keys are actually convenient (or usable, according to some). This leads us nicely to:</li>
  <li>Fans – consider the <a href="https://shop.keyboard.io/">KeyboardIO Model 01</a>. This approach appreciates that the thumb actually moves in an arc, and doesn’t try to add extra functionality either above or below it.</li>
</ol>

<p><img alt="Thumb fractal" src="https://zealot.hu/absolem/pics/fun/thumb_fractal.jpg" width="40%">
</p>

<p>This is probably the only “really” original part of the Absolem design, as all the other stuff I’ve mentioned so far could be seen <em>somewhere</em> before.
And, depending on how we interpret “original”, maybe not even this…
But: I actually placed the thumb keys on an arc, with a measured thumb radius.
Yes, I actually had to refresh my trigonometry for this!
And I, of course, followed the 1DFH principle, too, so there can only be 3 (unlike the KeyboardIO’s 4).</p>

<p>I’d also like to mention, as someone with quite wide (read: fat) thumbs, I’ve aimed to have 1.25u thumb keys from the start, at least for the home position.
The sides can more easily be 1u because they don’t have a neighbor on one side, so there’s less chance for misclicking (mispressing?).
But the thumb home position (which is flanked by other thumb keys on both …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zealot.hu/absolem/">https://zealot.hu/absolem/</a></em></p>]]>
            </description>
            <link>https://zealot.hu/absolem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737163</guid>
            <pubDate>Sun, 05 Jul 2020 07:34:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I interviewed 200 CTOs from growing startups – here's what came up]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737154">thread link</a>) | @ev0xmusic
<br/>
July 5, 2020 | https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up | <a href="https://web.archive.org/web/*/https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Between late 2019 and early 2020, I interviewed more than 200 CTOs of growing US and EU startups on the topics of the Cloud and their working methodologies. I discovered that 86% of these SMB startups use the Cloud and that 48% started their business on <a href="https://www.heroku.com/">Heroku</a> and then migrated to a Cloud provider - especially <a href="https://aws.amazon.com/">AWS</a> (Amazon Web Services).</p><p>This article explains:&nbsp;</p><ul role="list"><li>Why 48% of CTOs moved from Heroku to AWS.&nbsp;</li><li>Why migrating to AWS is a "hell" (a word I've often heard in my interviews).</li><li>How to simplify AWS and meet the needs of growing startups.</li></ul><h2>From Heroku to AWS</h2><p>Early in the life of a startup, the CTO's objective is to design a product quickly and then validate that the product's value proposition is the right one with the defined target. Technical decisions are pragmatic, saving valuable time on product delivery. For application hosting, the majority choice of CTOs is Heroku - because it's easy to get started, with virtually zero upfront cost, a price that grows with usage and maximum time spent on the product rather than managing the complexity of a server and database infrastructure.</p><p>When the startup's market positioning is the right one, the product is successful. The questions of recruitment and team structuring naturally arise, and it is from this point on that the CTO realizes that:</p><ul role="list"><li><strong>Heroku is not for teamwork</strong>: a group of developers will have to share the same environments (staging, development) at the risk of getting stuck on modifications. Heroku very quickly shows its limitations in this mode of operation and prevents development teams from being productive and efficient.</li><li><strong>Heroku is not for enterprise applications</strong>: Heroku considers the deployment and management of applications as a single unit. However, today an application is often made up of several apps - a frontend, a backend, and a database. Heroku does not allow you to manage a set of applications as a single application. This leads to difficulties in complexity management. And therefore, loss of team productivity.</li><li><strong>Heroku is outrageously expensive</strong>: even though AWS is not known for being cheap, Heroku is up to 10x more expensive than AWS for the same use. The more you use it, the more your bills go up. Peace of mind at a price, but it's tough to scale with Heroku.</li></ul><p>These negative points lead 48% of CTOs to replace Heroku by AWS. But not everything is as green on the other side of the fence...</p><h2>AWS hell for CTOs</h2><p>Pre-sales engineers at AWS have a real strength to promote the many advantages of their Cloud solution. Arguments such as free services for up to 2 years and technical support by a dedicated account manager and a team of Cloud architects resonate exceptionally well. Their crews know the field correctly and know how to reassure. Their products are of outstanding quality, and reliability is well proven. However, most of the CTOs we interviewed have no experience of what it means to use a Cloud provider such as AWS. From a technical point of view, you have to start from scratch - everything has to be built from the ground. Meaning, configuring the network, configuring the services, creating a CI for integration, and a CD for deployment - in short, getting your hands in the engine. In our study, we found two types of CTOs, the one who loves to get their hands dirty in the infrastructure, and the one who doesn't want to. The latter is predominant, and even in the case of the first, he lacks time to do what is necessary. The CTO then often turns to someone from his team who will have the cumbersome task of " re-creating " how Heroku works but often learning on-the-job. Months can go by until the CTO decides to do so:&nbsp;</p><ul role="list"><li>Contracting an external DevOps company</li></ul><p>OR</p><ul role="list"><li>Internalize this skill by recruiting it</li></ul><p>From that moment on, I often heard, "<strong>Recruiting a DevOps is a real hell, I wouldn't wish it on anyone</strong>". Not surprisingly, this skill is scarce and expensive - ~$180k/year in San Francisco. Recruiting a DevOps can take up to 12 months, not counting the months of work needed to get a tenth of a Heroku functionality.<br></p><p>AWS is complex to use, as it has to meet the needs of all businesses around the world. However, it is possible to simplify AWS. Here are some areas for improvement...</p><h2>Simplify AWS and meet the needs of growing startups</h2><p>To meet the needs of growing startups, we should be able to combine Heroku's simplicity with the flexibility of AWS. But where to start? Here are my thoughts:</p><h3>A UX designed for developers</h3><p>Heroku gets it; the developer is now the king. He's the one who turns ideas into products. Developers should be able to use AWS without any effort. AWS must be fully integrated into their working environment (IDE) to request what they need transparently. "I need a PostgreSQL version 12 database, a 20GB disk, and to have my application available at https://foo.bar - and of course all this on my Cloud account".</p><h3>An opinionated approach</h3><p>Even if there is no consensus work methodology in the R&amp;D departments of startups, most of them try to copy their elders with a functioning (most often) in the form of a Squad. The idea would be to ensure that the product can fit team working. GitOps and environment isolation (production, staging, dev) methodologies by "git" branch are a perfect start. GitOps methodologies would allow developers to maximize their productivity and never slow down their colleagues on the deployment of new features.</p><h3>Extensible</h3><p>Heroku's move to AWS is not insignificant. A growing startup needs technical extensibility. Deploying applications automatically is good, but allowing you to change everything at any time is even better. This leaves room for future DevOps to join the growing startup.</p><h2>To go further</h2><p>These areas of improvement apply to AWS as well as to other cloud providers such as Google Cloud Platform and Azure. At Qovery, we have begun this work of simplifying the Cloud. Our mission is to make it accessible to any developer, enabling growing startups to become the unicorns of tomorrow.<br></p><p><a href="https://jobs.qovery.com/">We're recruiting!</a></p><p>‍</p><p><a href="https://www.linkedin.com/pulse/jai-interview%25C3%25A9-200-ctos-de-startups-en-croissance-voici-philog%25C3%25A8ne/?trackingId=9l7kV9csR4ySm1Br7IXPuQ%3D%3D">French translation</a></p></div></div>]]>
            </description>
            <link>https://www.qovery.com/blog/i-interviewed-200-ctos-from-growing-startups-heres-what-came-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737154</guid>
            <pubDate>Sun, 05 Jul 2020 07:32:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Moon as a rocket platform]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23737036">thread link</a>) | @uncertainquark
<br/>
July 4, 2020 | https://jatan.space/the-moon-as-a-rocket-platform/ | <a href="https://web.archive.org/web/*/https://jatan.space/the-moon-as-a-rocket-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
	<main id="content" role="main">

	<div>
		<div>
						<article id="post-3564">
				<div>
<p>When dabbling with the laws of motion in the 17th century, Isaac Newton first realized that it is indeed possible to send an object out of Earth, into space. As long as an object is shot away from Earth with a high enough velocity, it <em>will</em> reach space and start orbiting our planet.</p>



<p>With the launch of the Sputnik satellite in 1957 onboard a powerful rocket, the Soviet Union achieved exactly that. For the first time in four billion years of life on Earth, something was intentionally sent to space.</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?fit=1024%2C388&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?w=1513&amp;ssl=1 1513w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=1024%2C388&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=200%2C76&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=768%2C291&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/sputnik.jpg?resize=1200%2C454&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><strong>Left:</strong> Launch of Sputnik satellite on October 4, 1957 by the Soviet Union, kickstarting the Space Age. <strong>Right:</strong> An engineer besides the finished Sputnik satellite. Credits: USSR</figcaption></figure></div>



<p>Give a satellite another speed boost, by either launching it on a more powerful rocket or using small thrusters onboard, and it can escape from Earth’s gravitational hold completely. That’s how you can send <a href="https://jatan.space/why-explore-venus/">missions to Venus</a>, Mars, <a href="https://jatan.space/why-explore-saturn/">Saturn</a> and beyond. But one of these two things is not quite like the other.</p>



<p>Enter the <a href="https://en.wikipedia.org/wiki/Tsiolkovsky_rocket_equation">rocket equation</a>.</p>



<p>The rocket equation is what allows scientists and engineers to quantify and compare the energy required to reach various destinations in space. Its implications are far-reaching but not intuitive – so I shall attempt to explain them without use of any math.</p>



<h3><strong>Getting to space</strong></h3>



<p>The rocket equation tells us the amount of energy a rocket must expend to go from the Earth’s surface to an orbit 250 kilometers above, called low Earth orbit, is almost thrice as much as going to the Moon from that low Earth orbit! Likewise, getting to low Earth orbit costs more than twice the energy required to reach Mars from that same orbit.<sup>1</sup></p>



<p>Even if we include the energy expenditure not just to reach the Moon from low Earth orbit but to land on it, getting to Earth orbit itself turns out to be about 50% more expensive. In other words, attaining Earth orbit is the first and the most significant barrier to space exploration.</p>



<div><figure><img src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?fit=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?w=1920&amp;ssl=1 1920w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=200%2C113&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/delta-v-earth-moon-mars.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Energy expenditure to travel from one place in space to another, calculated using the rocket equation. Credit: ULA</figcaption></figure></div>



<blockquote><p>The giant leap for humanity was not stepping on the Moon but getting to Earth orbit.</p></blockquote>



<p>The rocket equation doesn’t just dictate how much energy you must spend to reach various destinations in space but also if you can reach space at all!</p>



<h3><strong>Planetbound</strong></h3>



<p>The satellite is but a small fraction of the total mass of the rocket that lifts it and yet has an effect on the rocket itself. Therein lies the core problem of rocket science.</p>



<p>Increasing the satellite’s mass, to make it more useful perhaps, also means more rocket fuel is required to put the satellite in the desired orbit. But more fuel makes the system weigh more. This means some more fuel is required to launch the now-heavier system into space. As a thumb rule, fuel requirements increase <a href="https://commons.wikimedia.org/wiki/File:Tsiolkovsky_rocket_equation.svg">exponentially</a> with every step increase in mass added to the satellite.</p>



<p>This is how we end up with rockets being mostly fuel and then some metal. Even the mighty Saturn V that sent astronauts to the Moon was 85% fuel, 13% rocket – including the rocket body, its plumbing and parts, and the rest 2% being the Moonbound spacecraft with astronauts sitting inside!</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?fit=1024%2C856&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?w=2100&amp;ssl=1 2100w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1024%2C856&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=200%2C167&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=768%2C642&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1536%2C1284&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=2048%2C1712&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/saturn-v-cutaway-illustration.jpg?resize=1200%2C1003&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A cutaway illustration of the Saturn V rocket showing the rocket structure and the Moonbound spacecraft on top, which together comprise just 15% of the system’s mass, the rest 85% being fuel. <a href="https://solarsystem.nasa.gov/news/337/what-was-the-saturn-v/">Credit: NASA</a></figcaption></figure></div>



<p>At this point, if we were to make Earth more massive, a rocket would have to expend an enormous amount of energy against a more gruesome gravity well. More fuel would be required to get to space and your rocket might be something akin to 9 times more fuel than metal. Increase Earth’s mass further and the fuel-to-mass ratio would start <em>skyrocketing</em> to a point where it’s simply not possible to engineer such a near-all-fuel rocket!</p>



<p>Crunching the numbers in this manner, it turns out that if the Earth was 50% more massive, you simply wouldn’t be able to get to space even with the most energetic fuel combination (liquid hydrogen and liquid oxygen) available in chemical rockets.</p>



<p>Such a massive rocky planet is not imaginary, several of its kind exist. Of the 4,000+ planets around other stars we’ve discovered to date in our galaxy, about a thousand are something scientists call ‘Super Earths’. These are planets which are up to 10 times more massive than Earth and up to twice as large. Beyond that limit, planets don’t remain rocky and start turning into Uranus/Neptune-like gas giants.</p>



<div><figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?fit=1024%2C546&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?w=1499&amp;ssl=1 1499w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=1024%2C546&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=200%2C107&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=768%2C409&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/super-earth-size-comparison.jpg?resize=1200%2C640&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Size comparison of a Super Earth (artist’s impression) to Earth and Neptune. Credit: <a href="https://en.wikipedia.org/wiki/File:Exoplanet_Comparison_CoRoT-7_b.png">Aldaron</a>, <a href="https://www.flickr.com/photos/groovychk/474966449">Ginny Keller</a></figcaption></figure></div>



<p>Many of these Super Earths lie in the respective habitable zones around their stars i.e. conditions there could support life as we know it. Given that we’ve only searched a small fraction of our galaxy for planets, it’s fair to say there could be millions of Super Earths, many of which could host life.</p>



<p>If intelligent life were to develop on these Super Earths, they’d have a hard time building rockets that get things off-planet. Since even the most energetic chemical rockets won’t get them to space, they’d be incentivized to build something with more thrust that can, like nuclear propulsion based rockets. These will likely be far more expensive than chemical rockets but sometimes nature doesn’t give you a choice.</p>



<figure><img src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?fit=1024%2C819&amp;ssl=1" alt="" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?w=1680&amp;ssl=1 1680w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1024%2C819&amp;ssl=1 1024w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=200%2C160&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=768%2C614&amp;ssl=1 768w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1536%2C1229&amp;ssl=1 1536w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/07/orion-nuclear-rocket-concept.jpg?resize=1200%2C960&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>In the 1960’s, US government labs, under Project Orion, investigated a nuclear fission based propulsion system as a potential solution for interstellar travel. For life on ‘Super Earths’, nuclear propulsion based rockets might be the only way to get to space. <a href="https://commons.wikimedia.org/wiki/File:Pulsed_Fission_Propulsion_Concept.jpg">Credit: NASA</a></figcaption></figure>



<p>Just like the rocket equation makes it exponentially harder to get off a planet with added mass to the planet, it also makes it exponentially easier to get off objects with lesser gravity. Now if only we had an object less massive than Earth that is accessible and resourceful..</p>



<h3><strong>Ad Luna</strong></h3>



<p>In order for humanity to survive and thrive long term, it makes sense to have a permanent human settlement on Mars as the red planet offers us a relatively benign environment. That’d require sending hundreds to thousands of tons of material from Earth to the martian surface via dozens to hundreds of huge rocket launches. That’s pretty much exactly what <a href="https://www.spacex.com/vehicles/starship/">SpaceX’s Starship</a> hopes to do. That’s where our celestial neighbor, the Moon, comes in.</p>



<p>The Moon has a much weaker gravity than Earth, allowing rockets to take off with ease. This was most notable during the Apollo missions, when even a small spacecraft hosting two astronauts <a href="https://www.youtube.com/watch?v=9HQfauGJaTs">could make its way to lunar orbit</a>. Moreover, the Moon lies at the outer edge of Earth’s gravity well, meaning it’s easy to escape our planet’s pull completely if launched from the Moon. Almost five times easier in fact.</p>



<p>If we establish a vast, permanent settlement on the Moon first, we can eventually tap into its resources to launch rockets from the Moon itself. NASA and ISRO missions have <a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/">discovered plenty of water ice</a> on the Moon’s poles. It’s possible that future human habitats built from mining the metal-rich lunar soil tap into this water ice for consumption needs. This water can also be split into hydrogen and oxygen for use as rocket fuel. Rockets taking off from an industrially enabled Moonbase can ride the lunar interplanetary highway to reach Mars more efficiently than from Earth.</p>



<figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?fit=1024%2C628&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=3840&amp;ssl=1 3840w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1024%2C628&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=200%2C123&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=768%2C471&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1536%2C942&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=2048%2C1256&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1200%2C736&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=2400&amp;ssl=1 2400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?w=3600&amp;ssl=1 3600w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>A SpaceX Starship rocket taking off from a Moonbase. <a href="https://www.spacex.com/media/starship_users_guide_v1.pdf">Credit: SpaceX</a></figcaption></figure>



<p>Sure, it would be expensive to build a vast, industrial Moonbase but if the goal is to expand sustainably into the solar system, we’re playing the game on the scale of hundreds to thousands of years. In this large scheme of things, the Moon can be <em>the</em> rocket platform to test and build a sustainable Mars presence at a much smaller cost than one done from Earth.</p>



<p>The Moon’s accessibility, low gravity barrier and resource potential are the reason why its proponents vouch for a sustainable return to the Moon first rather than targeting Mars. As the saying within the lunar circles goes,</p>



<blockquote><p>You can’t be a martian without being a lunatic.</p></blockquote>



<p>Being a Moon-first guy myself, I even made a meme to that effect.</p>







<h3><strong>The belt and beyond</strong></h3>



<p>The Moon’s advantages may extend to making homes for ourselves in the outer solar system as well. The rocket equation tells us that even if objects in the outer reaches of the solar may be closer to Mars than the Moon, the red planet’s deeper gravity well means more energy is required to get out of it than to reach those destinations from there.</p>



<p>Getting to the asteroid belt from the Moon’s surface is at least 40% less energy demanding for a rocket than from Mars’ surface – even though Mars is about <em>75 million km</em> closer to the belt! This is the difference gravity makes, and which the rocket equation allows us to see. The Moon can accelerate expanding settlements to these resource-rich asteroids. Some of these objects, like Ceres and Vesta, can in turn play the same role as the Moon can for Mars and the asteroid belt, and expand human settlements to moons of Jupiter and Saturn, and beyond.</p>



<figure><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?fit=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=200%2C113&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/wanderers-asteroid-excavation.jpg?resize=1200%2C675&amp;ssl=1 1200w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>This concept shows an asteroid hollowed out on the inside and inhabited. A fleet of spaceships are lined up and approaching a docking area seen as glowing lights. <a href="http://www.erikwernquist.com/wanderers/gallery_excavation.html">Credit: Erik Wernquist</a></figcaption></figure>



<p>This finally brings us to the single most important takeaway from the rocket equation. The ability to extract and harness raw materials from low-gravity, resourceful space objects would free us from the tyranny of dragging everything out of Earth’s gravitational pull.</p>



<p>We cannot hope to be traveling among the stars if we don’t even expand into the solar system in an Earth-independent way and avail for ourselves a much larger resource pool. In-space manufacturing and industrialization is not just a good-to-have but a fundamental requirement for <a href="https://www.youtube.com/watch?v=YH3c1QZzRK4&amp;feature=emb_title">expansion into the solar system</a>. Only then humanity will be in an adequate position to venture to the nearest star and hopefully do it <a href="https://jatan.space/timeline-for-life-until-the-end-of-the-universe/">before the Sun …</a></p></div></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jatan.space/the-moon-as-a-rocket-platform/">https://jatan.space/the-moon-as-a-rocket-platform/</a></em></p>]]>
            </description>
            <link>https://jatan.space/the-moon-as-a-rocket-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737036</guid>
            <pubDate>Sun, 05 Jul 2020 06:48:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4200 SaaS Business Ideas]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23737029">thread link</a>) | @jensbackbom
<br/>
July 4, 2020 | http://www.jensbackbom.com/businessideas/ | <a href="https://web.archive.org/web/*/http://www.jensbackbom.com/businessideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.jensbackbom.com/businessideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737029</guid>
            <pubDate>Sun, 05 Jul 2020 06:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How my article became one-hit-wonder on HackerNews]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736913">thread link</a>) | @vicek22
<br/>
July 4, 2020 | https://blog.viktomas.com/posts/one-hit-wonder-on-hn/ | <a href="https://web.archive.org/web/*/https://blog.viktomas.com/posts/one-hit-wonder-on-hn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<article>
			
			


			

			<p>Today I’m going to tell the story of fleeting success. You’ll learn how my article reached the hacker news front page. And how it stayed there for two whole days, changing my perception about what is achievable with my writing hobby.</p>

<p>I started this blog as a new year’s resolution for 2020. One article per week. I didn’t have gigantic aspirations. I wanted to learn how to express myself better because <a href="https://blog.viktomas.com/posts/remote/">remote work</a> is all about written communication. And I wanted to share thoughts about my interests.</p>
<p>First two months I didn’t publish the articles I wrote. I didn’t want to create yet another blog with only a handful posts in it. The writing had to become a habit first.</p>
<p>After I started publishing on this site, I didn’t share it with anybody until late April when I mentioned <a href="https://blog.viktomas.com/posts/plaintext-passwords/">an article</a> on <a href="https://news.ycombinator.com/item?id=22914281">hacker news</a> for the first time. Two people liked it, and about fifty read it according to my analytics.</p>
<p>On Sunday 3rd of May 2020 at 9 AM (CET) I mention my article <a href="https://blog.viktomas.com/posts/losing-google-account/">“What would you do if you lost your Google account?"</a> on <a href="https://news.ycombinator.com/item?id=23057365">hacker news</a>. I was expecting the same results: a couple dozen people read it, a few would like it. But with strike of luck, plenty of people liked the article and of it went to the front page.</p>
<p>By 10 AM, fifteen hundred people visited the site, four times the number of visits since I started the blog. In the following 24 hours, another ten thousand people viewed the blog, and by the time the article left the front page on Monday, <strong>sixteen thousand people</strong> have read it<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. The real number is going to be over thirty thousand because <a href="https://blog.viktomas.com/posts/adblock-skews-analytics/">60% of hacker news readers don’t show in analytics thanks to AdBlock</a>.</p>
<p>I was ecstatic. The whole day I was walking with a wide grin on my face. I immediately googled the WikiHow article on <a href="https://www.wikihow.com/Handle-Fame">How To handle fame</a>. And I took plenty of screenshots because I thought that the article is bound to drop off from the front page after a few minutes and I wanted to have a memory.</p>
<p><img src="https://blog.viktomas.com/images/posts/one-hit-wonder-hn/medium.gif" alt=""></p>
<p>There was a trickle of people coming to see the article ever since. Now about fifty people view the article each week.</p>
<p>The time of my two-day fame has now passed, but I took away valuable lessons.</p>
<p>The first lesson is that I can produce something of value outside of my programming job. I knew I design and write high-quality code and systems and I get well paid for doing that. However, this experience showed me that I could create something else people enjoy.</p>
<p>The second lesson is the type of article people enjoy. The generic articles about <a href="https://blog.viktomas.com/posts/foss/">FOSS</a> and <a href="https://blog.viktomas.com/posts/meditation-introduction/">Meditation</a> are presumably not as interesting as the more down-to-earth articles that contain a few howtos that people can apply straight away. Since the “loosing your google account” article this story repeated itself once more with the <a href="https://blog.viktomas.com/posts/slip-box/">Zettlekasten article</a>. This strengthens my hypothesis that the article needs to provide useful, applicable tool/information to the readers, not just abstract food for thought.</p>
<p>I liked Robert Heaton’s <a href="https://robertheaton.com/2019/09/24/how-to-come-up-with-blog-post-ideas/">Made-Up-Award principle</a>: you should write your article to be the best in some narrow category. Exaggerated example: “best introduction to ruby programming for marketing experts focusing on food marketing”. Another important rule for me is that I have to wish I found that article a few days/weeks before because it would help me solve a problem.</p>
<p>This event gave me just enough extrinsic motivation to help me overcome the initial period when I was considering whether I want to spend eight hours each week writing an article that fifty people read. It helped me to commit to writing as the next of my many hobbies.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The numbers are from Mixpanel analytics. I copied them from a conversation with my friend because the Mixpanel stats have been long lost thanks to me exceeding the monthly limit. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</article>
	</div></div>]]>
            </description>
            <link>https://blog.viktomas.com/posts/one-hit-wonder-on-hn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736913</guid>
            <pubDate>Sun, 05 Jul 2020 06:03:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best of R. A. Lafferty (Book Review)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736876">thread link</a>) | @walterbell
<br/>
July 4, 2020 | https://fantasy-hive.co.uk/2020/05/the-best-of/ | <a href="https://web.archive.org/web/*/https://fantasy-hive.co.uk/2020/05/the-best-of/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <!-- ARTICAL CONTENT -->
                                                                <blockquote><p>“’There is only one story in the world,’ he said, ‘and it pulls two ways. There is the reason part that says “Hell, it can’t be” and there is the wonder part that says “Hell, maybe it is.”’”</p>
<p>Cliffs That Laughed, 1969</p></blockquote>
<blockquote><p>“Every science is made up entirely of anomalies rearranged to fit.”</p>
<p>Continued on Next Rock, 1970</p></blockquote>
<p><img src="https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=195%2C300&amp;ssl=1" alt="" width="195" height="300" srcset="https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=195%2C300&amp;ssl=1 195w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=400%2C616&amp;ssl=1 400w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?resize=389%2C600&amp;ssl=1 389w, https://i0.wp.com/fantasy-hive.co.uk/wp-content/uploads/2020/05/61ru6fMIQtL.jpg?w=649&amp;ssl=1 649w" sizes="(max-width: 195px) 100vw, 195px" data-recalc-dims="1">Raphael Aloysius Lafferty was an American writer from Tulsa, Oklahoma, who wrote over two hundred short stories and thirty-two novels from 1960 to 1984. It is his genre-defying and hugely inventive short stories he is most well-known for. <em>The Best of R. A. Lafferty </em>(2019), edited by Jonathan Strahan and issued as part of Gollancz’s SF Masterworks series, collects 22 of these stories. Each story contains an introduction written by an author influenced by Lafferty’s work, including Neil Gaiman, Samuel R. Delany, Connie Willis, Jeff VanderMeer and Michael Swanwick. The stellar list of contributors should give you an idea of how far Lafferty’s literary influence extends beyond his relative obscurity. What they don’t tell you is just how wonderfully bizarre and compelling Lafferty’s writing is. Lafferty is a lover of myths, legends, tall tales, jokes, and shaggy dog stories. Any given Lafferty story is likely to be a combination of all of these, at least as much as it is a work of science fiction or fantasy, if not more. But then again their innate humour doesn’t hide Lafferty’s knack for mind-bending ideas or powerful emotional impact. Basically, there is nothing quite like a Lafferty short story, and once you’ve developed the taste for them you are likely to want more. After years of his work being out of print and difficult to find, Gollancz’s <em>Best of</em> serves as a welcome introduction to Lafferty’s writing.</p>
<p>Lafferty stories are immediately identifiable by his unique voice. So much of what makes these stories wonderful is in how they are told. Lafferty’s default style is that of the tall tale or shaggy dog story, and his fascination and love of stories leads to him playing various games with narrative convention. Nested stories – or stories nested within stories nested within stories – are common, as are puns and wordplay, frequently across various languages. ‘The Primary Education of the Camiroi’ is written as a school curriculum for alien children. Stories are frequently set up around a silly punchline, and are peppered with witty one-liners. The stories brim over with a love of language and storytelling, and the sheer joy of how these can be played with and rearranged in surprising new forms. However just because jokes and humour are an essential part of Lafferty’s toolbox does not mean that the stories are flippant or slight. At heart, Lafferty is interested in perspective, and how who is telling the story alters the perspective, and the best of his stories allow us to look at the familiar world around us in a new and unsettling way.</p>
<p>Many of Lafferty’s stories manage to take utterly bizarre, gonzo speculative fiction ideas and run with them, part of the fun being to take a ridiculous idea at face value to really see what it means. ‘Slow Tuesday Night’ imagines a world in which humanity’s perception has been sped up, to the extent that entire cultural movements and business careers rise and fall multiple times over the course of a single night. The story is breathtakingly fun, but also has a serious point to make about dwindling attention spans and the speed of modern life, anxieties that users of the internet will easily recognize. ‘Selenium Ghosts of the Eighteen Seventies’ reimagines the early days of television, where the programmes are given increased emotional resonance and depth every time they are watched, playing with the idea of how we imprint our emotions on the mass media we consume. ‘Thus We Frustrate Charlemagne’ takes the science fiction staple of using time travel to meddle with the past and so alter the future and takes it in unexpected and hilarious directions. The story is built around the pun of cutting one’s own throat with Ockham’s razor, which it uses to explore ideas around determinism and free will. Lafferty takes us through unexpected turning points in history, and wryly questions science fiction’s love of magical solutions to technologically framed problems. As such it is a pretty good example of his wayward genius at its best.</p>
<p>Lafferty had a fascination with Native American traditions and culture, and was aware of how the land of his native Oklahoma was taken from them. Many of his most powerful and devastating stories engage directly with colonialism and dispossession of native peoples. In ‘Narrow Valley’, a member of the Pawnee tribe manages to avoid having his land taken by the US government by geographically folding a valley so that it only appears five feet wide. ‘Land of the Great Horses’ sees the land of the Roma, which has been physically taken off the planet by alien powers, returned to them, whilst Los Angeles is removed and its people left to wander the Earth. ‘Ride a Tin Can’ explores the colonialist attitude at the heart of anthropological studies, and shows us the heart-breaking consequences of a people being denied their status as human. Other stories such as ‘Thieving Bear Planet’ and ‘Nine-Hundred Grandmothers’ explore situations where contact with alien beings goes horribly wrong because of the baggage and preconceptions the humans bring with them. These stories demonstrate that Lafferty’s humour and playfulness does not obscure his awareness of the darker side of human nature, that his love of America is tempered by his understanding of the tragic legacy of colonialism.</p>
<p>Many of Lafferty’s stories deal with folded realities, the idea that just underneath the world we know is a world more vital and strange, a realm of myth and imagination that informs the waking world. This is evident in ‘Boomer Flats’, in which a group of scientists on the hunt for the Abominable Snowman unwittingly enter a mythic realm and become part of the legend themselves. ‘The World as Will and Wallpaper’ anticipates the New Weird by imagining a world-engulfing city not just inspired by William Morris’s political ideals but geographically recursive like his iconic wallpaper designs. ‘Days of Grass, Days of Straw’ is about the secret days that do not fall on the calendar, when life is more vivid and colourful and bloody. Although any character’s attempts at trying to navigate these overlapping worlds is unlikely to be successful. Ceran Swicegood’s quest for knowledge about the origins of the universe in ‘Nine-Hundred Grandmothers’ is a joke he can never share in, whilst the three disappearing soldiers in ‘Cliffs That Laughed’ escape the siren’s call only to be dragged back in again. Jim Boomer and Art Slick give up trying to figure out how the people from ‘In Our Block’ achieve their impossible tasks and go to the pub instead. Transcendence most definitely exists in Lafferty’s stories, but it does not come easily, nor does it necessarily provide the answer the characters would like to hear.</p>
<p><em>The Best of R. A. Lafferty</em> is a wonderful introduction to Lafferty’s singular writing, and an excellent addition to the SF Masterworks series. It celebrates the work of one of the genre’s true originals, and hopefully, the endorsement of so many other wonderful writers throughout will lead more readers to discover Lafferty’s work. My only issue with it is that I’m somewhat at a loss now that it’s over. Most of Lafferty’s work remains out of print and his short story collections can command excessive prices over the internet. I very much hope that any publishers reading this will bring more of his stories back into print as soon as possible, as I am now thoroughly addicted and need my Lafferty fix.</p>

<p id="jp-relatedposts">
	<h3><em>Related</em></h3>
</p>                                                            </div></div>]]>
            </description>
            <link>https://fantasy-hive.co.uk/2020/05/the-best-of/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736876</guid>
            <pubDate>Sun, 05 Jul 2020 05:51:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciphering Repeated-Key XOR Ciphertexts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736681">thread link</a>) | @arpitbbhayani
<br/>
July 4, 2020 | https://arpitbhayani.me/blogs/decipher-repeated-key-xor | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/decipher-repeated-key-xor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Encryption is a process of encoding messages such that it can only be read and understood by the intended parties. The process of extracting the original message from an encrypted one is called Decryption. Encryption usually scrambles the original message using a key, called the encryption key, that the involved parties agree on.</p>
<p>In the previous essay, we went through the <a href="https://arpitbhayani.me/blogs/decipher-single-xor">Single-byte XOR cipher</a> and found a way to decipher it without having any knowledge of the encryption key. In this essay, we find how to break a <a href="https://en.wikipedia.org/wiki/XOR_cipher">Repeating-key XOR cipher</a> with variable key length. The problem statement, defined above, is based on <a href="https://cryptopals.com/sets/1/challenges/6">Cryptopals Set 1 Challenge 6</a>.</p>

<p>The Repeating-key XOR cipher algorithm works with an encryption key with no constraint on its length, which makes it much stronger than a Single-byte XOR Cipher, where the encryption key length was restricted to a single byte.</p>
<h2>Encryption</h2>
<p>A plain text is encrypted using an encryption key by performing a bitwise <a href="https://en.wikipedia.org/wiki/Exclusive_or">XOR</a> operation on every character. The encryption key is repeated until it XORs every single character of the plain text and the resultant stream of bytes is again translated back as characters and sent to the other party. These encrypted bytes need not be among the usual printable characters and should ideally be interpreted as a stream of bytes. Following is the python-based implementation of this encryption process.</p>
<pre><code><span><span>def</span> <span>repeating_key_xor</span><span>(text: bytes, key: bytes)</span> -&gt; bytes:</span>
    <span>"""Given a plain text `text` as bytes and an encryption key `key`
    as bytes, the function encrypts the text by performing
    XOR of all the bytes and the `key` (in repeated manner) and returns
    the resultant XORed byte stream.
    """</span>
    
    
    
    repetitions = <span>1</span> + (len(text) // len(key))
    key = key * repetitions
    key = key[:len(text)]

    
    <span>return</span> bytes([b ^ k <span>for</span> b, k <span>in</span> zip(text, key)])
</code></pre>
<p>As an example, we encrypt the plain text - <code>secretattack</code> - with encryption key <code>$^!</code> and as per the algorithm, we first repeat the encryption key until it matches the length of the plain text and then XOR it against the plain text. The illustration below shows the entire encryption process.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png" alt="https://user-images.githubusercontent.com/4745789/85919742-d1520600-b88b-11ea-8d71-aa36c58dc48a.png"></p>
<p>For the first character in plain text - <code>s</code> - the byte i.e. ASCII value is <code>115</code> which when XORed with <code>$</code> results in <code>87</code> whose character equivalent is <code>W</code>, similarly for the second character <code>e</code> the encrypted byte is <code>;</code>, for <code>c</code> it is <code>B</code>, for the fourth character <code>r</code>, since the key repeats, the XOR is taken with <code>$</code> to get <code>V</code> and the process continues. The resultant encrypted text using repeated-key XOR on the plain text <code>secretattack</code> with key <code>$^!</code> is <code>W;BV;UE*UE=J</code>.</p>
<h2>Decryption</h2>
<p>Decryption is a process of extracting the original message from the encrypted ciphertext given the encryption key. XOR has a <a href="https://brainly.in/question/3038497">property</a> - if <code>a = b ^ c</code> then <code>b = a ^ c</code>, hence the decryption process is exactly the same as the encryption i.e. we first repeat the encryption key till it matches the length and then perform bitwise XOR with the ciphertext - the resultant bytes stream will be the original message.</p>
<p>Since encryption and decryption both have an exact same implementation - we pass the ciphertext to the function <code>repeating_key_xor</code>, defined above, to get the original message back.</p>
<pre><code><span>&gt;&gt;&gt; </span>repeating_key_xor(<span>b'W;BV;UE*UE=J'</span>, <span>b'$^!'</span>)
<span>b'secretattack'</span>
</code></pre>

<p>Things become really interesting when, given the encryption algorithm, we have to recover the original message from the ciphertext with no knowledge of the encryption key. Just like solving any other problem, the crux of deciphering the message encrypted using repeated-key XOR cipher is to break it down into manageable sub-problems and tackle them independently. We break this deciphering problem into the following two sub-problems:</p>
<ul>
<li>Finding the length of the Encryption Key</li>
<li>Bruteforce with all possible keys and finding the "most English" plain text</li>
</ul>
<h2>Finding the length of the Encryption Key</h2>
<p>In order to recover the original text from the cipher, we first find the length of the encryption key used and then apply brute force with all possible keys of the estimated length and deduce the plain text. Finding the length of the Encryption key makes the deciphering process quicker as it eliminates a lot of false keys and thus reducing the overall effort required during the brute force. In order to find the length of the Encryption Key, we need to have a better understanding of a seemingly unrelated topic - Hamming Distance.</p>
<h3>Hamming Distance</h3>
<p>Hamming distance between two bytes is the number of positions at which the corresponding bits differ. For a stream of bytes, of equal lengths, it is the sum of Hamming Distances between the corresponding bytes. Finding differences between bits can be efficiently done using bitwise XOR operation as the operation yields <code>0</code> when both the bits are the same and <code>1</code> when they differ. So for computing Hamming Distance between two bytes we XOR the bytes and count the number of <code>1</code> in its binary representation.</p>
<pre><code><span><span>def</span> <span>hamming_distance_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; int:</span>
    <span>"""Given two stream of bytes, the function returns the Hamming Distance
    between the two.
    Note: If the two texts have unequal lengths, the hamming distance is
    computed only till one of the text exhausts, other bytes are not iterated.
    """</span>
    dist = <span>0</span>
    <span>for</span> byte1, byte2 <span>in</span> zip(text1, text2):
        dist += bin(byte1 ^ byte2).count(<span>'1'</span>)
    <span>return</span> dist

<span>&gt;&gt;&gt; </span>hamming_distance_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>4</span>
</code></pre>
<p>In the example above, we find that the hamming distance between two bytestreams <code>ab</code> and <code>zb</code> is <code>4</code>, which implies that the byte streams <code>ab</code> and <code>zb</code> differ at <code>4</code> different bits in their binary representations.</p>
<h3>Hamming Score</h3>
<p>Hamming distance is an absolute measure, hence in order to compare hamming distance across byte streams of varying lengths, it has to be normalized with the number of pairs of bits compared. We name this measure - Hamming Score - which thus is defined as the Hamming Distance per unit bit-pair. In python, Hamming Score is implemented as:</p>
<pre><code><span><span>def</span> <span>hamming_score_bytes</span><span>(text1: bytes, text2: bytes)</span> -&gt; float:</span>
    <span>"""Given two streams of bytes, the function computes a normalized Hamming
    Score based on the Hamming distance.
    Normalization is done by dividing the Hamming Distance by the number of bits
    present in the shorter text.
    """</span>
    <span>return</span> hamming_distance_bytes(text1, text2) / (<span>8</span> * min(len(text1), len(text2)))

<span>&gt;&gt;&gt; </span>hamming_score_bytes(<span>b'ab'</span>, <span>b'zb'</span>)
<span>0.25</span>
</code></pre>
<h3>What can we infer through Hamming Distance?</h3>
<p>Hamming Distance is an interesting measure; it effectively tells us the minimum number of bit flips required to convert one bytestream into another. It also implies that (on average) if the numerical values of two bytestreams are closer then their Hamming Distance and Hamming Score will be lower i.e it would take fewer bit flips to convert one into another.</p>
<p>This is evident from the fact that the average Hamming distance between any two bytes <code>[0-256)</code> picked at random is <code>3.9999</code> while that of any two lowercased English characters <code>[97, 122]</code> is just <code>2.45</code>. Similar ratios are observed for Hamming Score where <code>0.4999</code> is of the former while <code>0.3072</code> is of the later.</p>
<p>This inference comes in handy when we want to find out the length of Encryption Key in Repeating-key XOR Cipher as illustrated in the section below.</p>
<h3>Formal definition of encryption and decryption processes</h3>
<p>Say if <code>p</code> denotes the plaintext, <code>k</code> denotes the encryption key which is repeated to match the length of the plain text, and <code>c</code> denotes the ciphertext, we could define encryption and decryption processes as</p>
<pre><code>encryption: c[i] = p[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(c))
decryption: p[i] = c[i] XOR k[i]   <span>for</span> i <span>in</span> [<span>0</span>, len(p))
</code></pre>
<p>The above definitions, along with the rules of XOR operations, implying that if we XOR two bytes of the ciphertext, encrypted (XORed) using the same byte of the encryption key, we are effectively XORing the corresponding bytes of the plain text. If <code>k'</code> is the byte of the encryption key <code>k</code> which was used to encrypt (XOR) the bytes <code>p[i]</code> and <code>p[j]</code> of the plain text to generate <code>c[i]</code> and <code>c[j]</code> of the ciphertext, we could derive the following relation</p>
<pre><code># k' <span>is</span> the common byte <span>of</span> the key i.e. k' = k = k

c XOR c = (p XOR k') XOR (p XOR k')
              = p XOR k' XOR k' XOR p
              = p XOR 0 XOR p
              = p XOR p
</code></pre>
<p>The above relation, <code>c[i] XOR c[j]</code> equal to <code>p[i] XOR p[j]</code>, holds true only because both the bytes were XORed with the same byte <code>k'</code> of the encryption key; which in fact helped reduce the expression. If the byte from the encryption key which was used to XOR the pain texts were different then the relation was irreducible and we could not have possibly setup this relation.</p>
<h3>Chunking of ciphertext</h3>
<p>Chunking is the process where the ciphertext is split into smaller chunks (segments) of almost equal lengths. For example, chunking the ciphertext <code>W;BV;UE*UE=J</code> for chunk length <code>4</code> would create <code>3</code> chunks <code>W;BV</code>, <code>;UE*</code> and <code>UE=J</code>. The illustration below shows the chunks that would be formed for <code>W;BV;UE*UE=J</code> with chunks lengths varying from 2 to 6.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png" alt="https://user-images.githubusercontent.com/4745789/86434084-24a7d680-bd1a-11ea-8346-aad7b42bab1c.png"></p>
<h3>XOR of the chunks</h3>
<p>Something very interesting happens when we compute the Average Hamming Score for all possible chunk lengths. If we consider the ciphertext <code>b'W;BV;UE*UE=J</code> and we chunk it with lengths varying from 2 to 6, we get the following distribution for the Average Hamming Score for each of the chunk length.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png" alt="https://user-images.githubusercontent.com/4745789/86473899-6149f100-bd5f-11ea-908a-d4adabff1cf0.png"></p>
<p>From the distribution above it is evident that the score was minimum at chunk length equalling <code>3</code>, which actually was the length of the Encryption Key used on the plain text. Is this mere coincidence or are we onto something?</p>
<p>When chunk length is equal to the length of the encryption key, the XOR operation on any two chunks will reduce the expression to XOR of the corresponding plain texts (as seen above), because there will be a perfect alignment of bytes from ciphertext and bytes from the keys i.e every <code>i</code>th byte from both the chunks would have been XORed with <code>i</code>th byte from the encryption key.</p>
<p>We have established that for chunk length equal to the length of the encryption key <code>c[i] XOR c[j]</code> …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arpitbhayani.me/blogs/decipher-repeated-key-xor">https://arpitbhayani.me/blogs/decipher-repeated-key-xor</a></em></p>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/decipher-repeated-key-xor</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736681</guid>
            <pubDate>Sun, 05 Jul 2020 04:55:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My post was #3 on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736656">thread link</a>) | @root993
<br/>
July 4, 2020 | https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last Sunday I published a piece of content for the very first time on hacker news and it ended up getting the #3 spot for a few hours and stayed on the front page for an <a href="https://news.ycombinator.com/front?day=2020-06-28" target="_blank">entire day.</a> The post was about <a href="https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it" target="_blank">how we managed to get our AWS bill to &lt; 2% of our revenue</a>.</p><figure id="w-node-70cd5a19b74c-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015791310d7d85125fef6b_O4P4rEPlKnx7Ng3ZdLmcl81BEdrR4uXkGzmWUwvFM9Ibl9UOF87Zi-4gIjv0F0MdYcbPlL0q_q3RiCywpMppiPUTyLqgVMoR6idh7sVNCR5LiPyWnYgf02BdaG1GBh6C6aenbS3H.png" alt=""></p><figcaption>Hacker News front page</figcaption></figure><p>This was a super thrilling experience for me because I have been a reader of Hacker news for a while but never actually posted anything or even created an account. This is why I had to ask my co-founder <a href="https://twitter.com/hipreetam93" target="_blank">Preetam</a> to post on my behalf as I did not have enough Karma points to even make one post!</p><p>‍</p><p>So I decided to continue this feedback loop of <strong>writing -&gt; being recognized -&gt; writing some more as a result</strong> by talking about what went into writing this post and what were the consequences of being featured on Hacker news.&nbsp;</p><p>‍</p><div><p>There were 3 primary reasons for this post&nbsp;</p></div><ol role="list"><li>Taking the first step at making a series of posts explaining how we solved various problems while building our <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">WhatsApp Shopify app</a>. Problems that other indie hackers can relate to and hopefully not reinvent the wheel while solving them. We were hesitant to do this at first because we were afraid of competitors reading these posts and copying our strategies, but we realised recently that what we stand to gain from making a place for ourselves in this community outweighs the risk of competitors giving us trouble.</li></ol><ol start="2" role="list"><li>We plan to build more of such products in the future and It became very clear to us that we have to build our own distribution channels to get users instead of relying on a 3rd party channel like the Shopify App Store which we currently rely on to get 100% of our users. This post was the first attempt to drive some traffic to my personal blog, traffic that we can hopefully use to get the initial customers for our next venture.</li></ol><ol start="3" role="list"><li>An attempt to heal my imposter syndrome which kept holding me back over the years and prevented me from voicing my thoughts in public due to the fear of getting criticised. When I read all the negative comments to my post I realised that negative comments do not necessarily come from a negative place and the people posting such comments are just trying to voice their thoughts based on the unique situations that they deal with on a day to day basis. This means that criticism is very essential for growth</li></ol><p>‍</p><p><strong>Power of Hacker news and Reddit</strong>‍</p><p>‍</p><p>I posted this piece on<a href="http://reddit.com/r/Entrepreneur/" target="_blank"> reddit.com/r/Entrepreneur/</a> and Hacker news and at the time of making the post it did not occur to me that I should track the users that are visiting my blog as a result of these posts even though that was one of the primary intentions behind the post.&nbsp;</p><p>‍</p><p>I finished writing and publishing the post and went offline for a few hours when my co-founder <a href="https://twitter.com/hipreetam93" target="_blank">Preetam</a> texts me saying my post is on the front-page and I should add Google Analytics to my blog ASAP if I have not done it already. I quickly do so and start seeing results immediately&nbsp;</p><figure id="w-node-0de8a57abe57-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015791594ffa6c974ece60_UPCnJKN5cQEljrF22coESNJOE3d7jZwgWNP8xLEkih0T_y5oR0-zYbdVHPN-Lh7ieejS0qmnWW9y2MFDkuo_n71O_zbIs5vZIZ5xAg1IDNaWT0YHP7BPJtgzhIVfwSp3bcWWLjLV.png" alt=""></p><figcaption>Google analytics data</figcaption></figure><p>‍</p><p>As you can see I got ~14k visits on my blog the day I posted it and since I added GA a few hours late, I am assuming I got around 20k or more visits. This was mind blowing to me.&nbsp;</p><figure id="w-node-de58744503f8-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0157926dc9fcea598afa19_eXlhXdTDtdZx3rEncGgJrkkYR2XtySsWwjIR8Hof3N5RTJ3Gzblq7VaMfy1kmCjZRclUl8er-rEhvWx81p7bV632AI_TzADpLSPv1eGFFPLBbSgWAAZHzW9_ALR0AOgxlsyai-qY.png" alt=""></p><figcaption>Google analytics data</figcaption></figure><p>Looking into the data further it is quite clear that most of the traffic came from Hacker news. The fact that I had access to this kind of traffic and all I had to do was write about something that I myself experienced has given me a new perspective that is backed by actual numbers and graphs. We have all heard people tell us that it is important to write, but this can clearly be backed with actual numbers.&nbsp;</p><p>A few more things happened as a result of this post. I gained some new twitter followers, had engaging conversations with some of them and somebody even suggested that I add an RSS feed to my site so that they can follow my blog easily.&nbsp;</p><figure id="w-node-7aef82240888-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015792e08dc7f5ad78f64b_dzsKkucLoEIlELWuS-2wMH3FsDPvL0abSgho2aEkTvihuHdoD0d7GTGBPtBrn0cEOhOtqs_csRmKdv9VK0GSkacNfALtQr4ByN0nA5S930229eCXsYaZ12_n6ZSAcuGtiHzNkPUY.png" alt=""></p><figcaption>Good folks of twitter helping me out</figcaption></figure><p>For someone who started writing for the first time, seeing so much visible evidence of the benefits of writing has certainly done a lot to fuel my desire to write even more. I am yet to discover what this means in the long run when the post matures enough to start ranking on google search.</p><p><strong>Learnings from people who read the post</strong>‍</p><p>‍</p><p>Here is a TLDR for folks who have not read the post: Use Lightsail, Amazon's approximation of a dedicated server.</p><p>The post highlighted how we managed to save a lot on AWS bills in exchange for sacrificing a bit of resilience and some folks did not take kindly to this fact.</p><figure id="w-node-48d76d4377b1-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f015792e830705462abc486_Zrrh_CUjp34hKeGUfsUwkFrV0E-eYtWOr3JnnzrAX-cPIl9K3BtiXxWnH_-m96m42GPnuxNAyfN_ohXlJBW-1K6eWwqNRxWK6oZgzN18fIdE1ouGAb5iKfMrM3LNIK6JjBzu2UdM.png" alt=""></p><figcaption>Harsh comment from a redditor</figcaption></figure><p>When I set up my app on AWS, it did not occur to me that Redundancy was super important. This is because we had the ability to do point in time restores of the Database and launch a new instance in case a disaster ever stuck, but what I failed to consider was the fact that sometimes an entire region in AWS can go dark in which case we won’t have the ability to do a restoration from a backup if that backup is on a region that is down. This is something that I have duly noted and will take into account going forward.</p><p>The above comment though harsh was a useful learning for me which would probably help me in the future but there were also comments that were not going to help anybody at all and my learnings from those comments was to not let them affect you. Find the feedback that will be useful in the long run and ignore the rest. The rest is just noise.</p><p>There were also many positive comments from people who found the post helpful and someone even commented that they moved all their instances to Lightsail after reading my post. There were people who appreciated the fact that I put a disclaimer at the end of my post explicitly saying that this is not a holy grail solution that will work for everyone and it is just something that worked for us.&nbsp;</p><p>Overall the learnings were all net positive and I look forward to sharing more and learning even more from the comments of all my future posts.</p><p><strong>Closing note</strong>‍</p><p>‍</p><p>I would like to conclude by encouraging anyone wanting to share their experiences to write and not be afraid to post it in public because it is totally worth it. You get some validation and you also get criticized but you will certainly find out that even after getting criticized, you are still alive and life goes on.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/my-post-was-3-on-hacker-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736656</guid>
            <pubDate>Sun, 05 Jul 2020 04:46:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital India App Innovation Challenge]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23736349">thread link</a>) | @rainhacker
<br/>
July 4, 2020 | https://innovate.mygov.in/app-challenge/ | <a href="https://web.archive.org/web/*/https://innovate.mygov.in/app-challenge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div id="tab1">
        <h3>Background</h3>
		<p>MeitY in partnership with Atal Innovation Mission – Niti Aayog launches <strong>Digital India AatmaNirbhar Bharat Innovate Challenge</strong>  to identify the best Indian Apps that are already being used by citizens and have the potential to scale and become world class Apps in their respective categories. This Innovation Challenge with various cash awards and incentives of featuring Apps on Leader Boards seeks to create an ecosystem where Indian entrepreneurs and Startups are incentivised to ideate, incubate, build, nurture and sustain Tech solutions that can serve not only citizens within India but also the world. 
		</p>
		<p>The Mantra is to Make in India for India and the World.  </p>
		
       <p>The AatmaNirbhar Bharat App Innovation Challenge is being launched in the following 8 broad categories:</p>
        <ul>
        <li>Office Productivity &amp; Work from Home</li>
        <li>Social Networking</li>
        <li>E-Learning</li>
        <li>Entertainment</li>
        <li>Health &amp; Wellness</li>
        <li>Business including Agritech and Fintech</li>
        <li>News </li>
        <li>Games</li>

        </ul>
		<p>There may be several sub categories within each category.</p>
		
		<h3>Indicative List of Sub Categories and Problem Statements</h3>
        
        <ul>
          <li>A mobile application harnessing the most accurate facial and / or body mapping technology to allow for a true-to-life virtual try out of products like spectacles, clothes, etc.</li>
<li>Mobile application for real-time speech-to-speech translation and camera translation of multiple languages.</li>
<li>An automated web-based application that handles business-to-business lead generation and cold emailing and is completely manageable from a mobile device itself.</li>
<li>Application to use mobile devices as image scanners with features like on the fly image correction, image editing, text recognition, etc.</li>
<li>Application to provide cloud storage integration, cross-platform file transfer via FTP or LAN, and a root browser on mobile device </li>
<li>A robust indigenous anti-virus software for mobile devices.</li>
<li>Application to optimize mobile device's performance by cleaning junk/cache files, optimizing device memory and optimizing battery usage.</li>
<li>A mobile based live streaming platform for hosting webinars, lectures, etc.</li>
<li>A mobile based messaging and video calling application</li>
<li>A mobile based microblogging application</li>
<li>A mobile based news application that uses cutting-edge technology to recommend the most relevant and interesting news individually to each use.</li>
<li>A mobile application offering satellite imagery and street maps, as well as functions such as a route planner for traveling by foot, car, or with public transportation. </li>
<li>A mobile based online gaming platform which also functions as a social hub for gamers</li>
<li>A mobile based photo-editing application with all standard image editing features</li>

		</ul>
		
      </div>
      <div id="tab2">
		<h3>ELIGIBILITY CRITERIA</h3>
        <p>Only Indian entrepreneurs and start-ups will be eligible to submit their entries in various categories</p>
        
		
        <h3>INNOVATION CHALLENGE PROCESS</h3>
        
        <ul>
          <li>The Innovation Challenge will be available on <a href="https://innovate.mygov.in/" target="_blank">innovate.mygov.in</a></li>
		  <li>The last date of submission of entry is 18th July 2020</li>
		  <li>The applicant needs to apply only online to submit their proposals by registering and logging on MyGov portal: <a href="https://www.mygov.in/" target="_blank">www.mygov.in</a></li>
		  <li>Applicants are advised to provide self-contained proposals with essential supporting materials provided as uploads for an informed and fair evaluation/review.</li>
		  <li>No changes will be accepted once proposals are submitted.</li>
		  <li>Providing incorrect information will lead to outright rejection of proposals.</li>
		</ul>
		
		<h3>Evaluation parameters</h3>
			<ul>
				<li>Ease of use</li>
				<li>Robustness</li>
				<li>Security features</li>
				<li>Scalability </li>
			</ul>
		<p>There will be a two stage Selection Process:</p>
			<ul>
				<li>1st Stage - Screening of eligible entries</li>
				<li>2nd Stage - Evaluation by Jury, with actual Demo</li>
			</ul>
		
		<h3>SELECTION PROCESS</h3>
			<ul>
				<li>Jury with experts from Private Sector &amp; Academia to Evaluate</li>
				<li>Shortlisted Apps to be awarded &amp; put on Leader boards</li>
				<li>Government to adopt suitable Apps, guide them to maturity</li>
			</ul>
		
		
      </div>
		<div id="tab3">
			<h3>IMPORTANT DATES</h3>
			<div>
				<table>
				<tbody><tr><td>Launch of Innovation Challenge:</td><td> 4th July 2020, on <a href="https://innovate.mygov.in/" target="_blank">innovate.mygov.in</a></td></tr>
				<tr><td>Last date for Submission: </td><td>18th July 2020 at 5:30 P.M</td></tr>
				<tr><td>Screening of Entries Received </td><td>20th to 24th July 2020</td></tr>
				<tr><td>Evaluation by the Jury </td><td>27th July to 3rd August  2020</td></tr>
				<tr><td>Final Announcement </td><td>7th August, 2020</td></tr>
				</tbody></table>
			</div>
		</div>
		
		<div id="tab4">
     <h3>AWARDS </h3>
     <p>Following Awards will be given in each of the Eight Categories</p>
     <div>
     <table>
     <tbody><tr><td>First Prize</td><td>20 Lakhs</td></tr>
     <tr><td>Second Prize </td><td>15 Lakhs</td></tr>
     <tr><td>Third Prize </td><td>10 Lakhs</td></tr>
     
     </tbody></table>
     </div>
     <p>For the purposes of evaluation, Jury may create sub categories in each category and then Apps will be classified into respective subcategories, based on functionality and evaluated. In case Sub Categories are created, the Prize Money for each sub category within each category will be as below:</p>
     <div>
     <table>
     <tbody><tr><td>First Prize</td><td>5 Lakhs</td></tr>
     <tr><td>Second Prize </td><td>3 Lakhs</td></tr>
     <tr><td>Third Prize </td><td>2 Lakhs</td></tr>
     </tbody></table>
     </div>
	
   
   </div>
		
     
      <div id="tab5">
      <h3>TERMS AND CONDITIONS </h3>
      <ul>
        <li>The contest is open to Indian  Citizens only.&nbsp;</li>
        <li>The decision of the Ministry of  Electronics and IT (MeitY) will be final and binding with regard to selection  on all stages.&nbsp;</li>
        <li>By making a submission in the  contest, all participants warrant and represent that to the best of their  knowledge, their submission is original and does not violate or misappropriate  any third party trade secret, “know-how,” copyright, patent or other  intellectual property right. Participants also warrant and represent that there  are no obligations of any nature, legal or otherwise, which would prohibit,  restrict, or interfere with their participation in the Contest or submission of  their design report, and agree to obtain any necessary clearances,  authorizations and/or approvals prior to participation.</li>
        <li>The participants agree that&nbsp;  MeitY will share information submitted by the participants as to panel experts,  reviewers etc. (any information that you may not want to share publicly should  not be submitted).</li>
		
		<li>Government does not claim ownership over Intellectual Property Right (IPR) for the Innovation that is sent to us by submitting an application. The IPR shall remain with the applicant at all times.</li>
		<li>Government reserves the right to publish the grantees information with regard to Name of the App , Brief summary, Key Functionalities , Developer Contact , Team details.</li>
	    
        <li>By entering the Contest, each  participant agrees to release&nbsp; MeitY from and against any losses, damages,  rights, claims and actions of any kind arising from&nbsp;
        <ul>
          <li>an  exclusion or disqualification of such participant pursuant to these  rules;&nbsp;</li>
          <li>late  or unsuccessful efforts to notify winners of any prize;&nbsp;</li>
          <li>forfeiture  of a prize and the selection of an alternate winner;&nbsp;</li>
          <li>late,  lost, delayed, damaged, misdirected, incomplete, illegible or unintelligible  entries;</li>
          <li>telephone,  electronic, hardware or software program, network, Internet, or computer  malfunctions, failures or difficulties of any kind;</li>
          <li>failed,  incomplete, garbled or delayed computer transmissions;</li>
          <li>any  condition caused by events beyond MeitY’s control that may cause the Contest to  be disrupted or corrupted; and</li>
          <li>any  injuries, losses or damages of any kind relating to participation in this  Contest.</li>
        </ul>
        </li>
      </ul>
	  <li>Government reserves the right, at its sole discretion, to cancel, terminate, suspend this contest and modify the rules, prizes &amp; funding related to the contest without prior notice. In no event shall Government or any other organizers be liable for any claims, losses, expenses or damages, arising out of or in connection with the foregoing.</li>
	  
	  <h3>CORRESPONDENCE</h3>
        <ul>
          <li>Any correspondence with participant will be done through an email provided by the participant at time of filling the application form. Organizers are not liable in case of email delivery failures.</li>
          <li>For any queries, please send mail at: <a href="mailto:connect@mygov.nic.in">connect@mygov.nic.in</a></li>
        </ul>
     
		<h3>DISCLAIMER</h3>
			<p>MeitY reserves the right, at its sole discretion, to cancel, terminate, suspend this contest and modify the rules, prizes &amp; funding related to the contest without prior notice. In no event shall  MeitY/Digital India/MyGov/NIC or any other organizers be liable for any claims, losses, expenses or damages, arising out of or in connection with the foregoing.</p>
		</div>
   
    
      
      
      
       
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://innovate.mygov.in/app-challenge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23736349</guid>
            <pubDate>Sun, 05 Jul 2020 03:15:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner's Guide to Abstraction]]>
            </title>
            <description>
<![CDATA[
Score 243 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23735991">thread link</a>) | @jesseduffield
<br/>
July 4, 2020 | https://jesseduffield.com/beginners-guide-to-abstraction/ | <a href="https://web.archive.org/web/*/https://jesseduffield.com/beginners-guide-to-abstraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-75">
	<!-- .entry-header -->

	
	
	<div>
		<p>In <em>The Pragmatic Programmer</em>, Andrew Hunt and David Thomas introduced the DRY (Don't Repeat Yourself) principle. The rationale being that if you see the same code copy+pasted 10 times you should probably factor that code into its own method/class.</p>
<p>But then Sandi Metz came along and <a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction">said</a>:</p>
<blockquote>
<p>Duplication is far cheaper than the wrong abstraction.</p>
</blockquote>
<p>And so the eternal war began.</p>
<h3>What is abstraction?</h3>
<p>For the purposes of this post I'm referring to the kind of abstraction as described in the <a href="https://en.wikipedia.org/wiki/Abstraction_(computer_science)#Abstraction_in_object_oriented_programming">Abstraction Principle</a>, which Wikipedia describes like so:</p>
<blockquote>
<p>In software engineering and programming language theory, the abstraction principle (or the principle of abstraction) is a basic dictum that aims to reduce duplication of information in a program (usually with emphasis on code duplication) whenever practical by making use of abstractions provided by the programming language or software libraries</p>
</blockquote>
<p>This post has nothing to say about the conceptual kind of abstraction where from the concrete examples of 'Parrot' and 'Sparrow' you create an abstraction of 'Bird'. This post is about duplicated code, how to respond to it, and how to respond to other people's responses to it.</p>
<p>I define the verb 'abstraction' to be an <em>attempt</em> to reduce complexity by combining repeated commonality into some generalisation. And so, the noun 'abstraction' is the result of that attempt. If you're somebody who believes abstraction is by definition a <em>successful</em> attempt, feel free to substitute the term 'wrong abstraction' with 'failure to abstract' throughout this post.</p>
<p>The process of abstraction typically goes like this:<br>
1) you identify different chunks of code that you think are all essentially doing the same thing<br>
2) you create a method or a class with a narrow interface which can be substituted in for all the chunks of code you found<br>
3) you go and swap out the chunks of code with a call to your method/class</p>
<h3>Abstraction is always a gamble</h3>
<p>In the world of software engineering, when requirements are always changing, every abstraction is a gamble. When you make an abstraction over some concrete things, you're making a bet that the concrete things are more similar than they are different, and that their similarities are not mere coincidences: that there is a common purpose shared by the concrete things which would lead them to evolve in lockstep as requirements evolve. If you win the bet, your codebase will be easier to work in and adding new use cases via your abstraction will be trivially easy. If you lose, you'll see a flash of fear in your colleague's eyes whenever they're assigned a ticket to make yet another extension to the misfigured monster that the once-innocent abstraction has now become</p>
<p>But risk abounds everywhere, and leaving duplicated code unabstracted is its own gamble. You're betting that the chunks of code will evolve in separate directions as requirements change and that their current similarities are more coincidence than a reflection of their common purpose. Win the bet and your colleague gets to sleep soundly at night knowing they won't be facing the abstraction monster at work the next day. Lose, and code that should have evolved in lockstep is now implemented in completely different ways across different files, where a developer fixes a bug identified in one place, only for the same bug to be reported days later in a completely different file.</p>
<p>Your job is to get good at making the right bets.</p>
<h3>The right/wrong abstraction</h3>
<p>You'll know that you've made the <em>right</em> abstraction when a long time passes and you haven't needed to expand the interface (an example of expanding the interface is adding an optional flag argument). You'll also know you've made the right abstraction when another developer doesn't find it that much harder to understand how the code behaves for a given use case than if somebody had written the code to satisfy the use case without the abstraction.</p>
<p>You'll know you've made the <em>wrong</em> abstraction when after a while the interface has been expanded to support various optional flags, each for a different use case, and you need to be a genius to reason about what the code will actually do for a given use case. By the way, if you have a string arg that merely gets fed into a switch statement inside a method and for each new use case you come up with a new accepted value for it, you <em>are</em> expanding the implicit interface, even if that fact isn't captured in your type system.</p>
<p>There is plenty of daylight between the perfect abstraction and the completely wrong abstraction (perhaps the interface needs to be fundamentally changed but afterwards you're back to having a good abstraction), and so the point of this section isn't to prescribe how much you should be abstracting, but to encourage you to think about both perspectives and be able to make a case in a PR review for why you think an abstraction should/should-not exist.</p>
<h3>Do you over or under-abstract?</h3>
<p>Given it is impossible to make the right decision with regards to abstraction every time, you are probably either somebody who over-abstracts or somebody who under-abstracts.</p>
<p>If common feedback on your PR reviews is that you should DRY up your code, you could probably benefit from doing a scan for duplicated code before submitting a PR and considering whether it belongs in its own method/class.</p>
<p>If you commonly get feedback that your methods are hard to understand because they support too many disparate use cases at once, you are probaby over-abstracting and should consider whether you should increase your tolerance for duplication.</p>
<p>Note that it's not always as simple as under-abstracting vs over-abstracting. Sometimes abstraction is appropriate, but you might take the wrong approach. If an abstraction is deemed wrong by the team, that doesn't mean no abstraction is necessarily the best alternative.</p>
<h3>Under-abstraction examples</h3>
<p>The main sign that you could be under-abstracting is that you have a heap of code doing the exact same thing called in a heap of places with no obvious reason why anybody would want the code to diverge.</p>
<h4>Example: Hard-coded formulas</h4>
<h5>Bad:</h5>
<pre><code># sphere has radius of 11
sphere_volume = 4*Math::PI/3*11**3
puts "the volume of the sphere is #{sphere_volume} cm^3"
...

radius = calculate_radius
volume = 4*Math::PI/3*radius**3
sphere.volume = volume</code></pre>
<h5>Good:</h5>
<pre><code>def sphere_volume(radius)
  4*Math::PI/3*radius**3
end

# sphere has radius of 11
sphere_volume = sphere_volume(11)
puts "the volume of the sphere is #{sphere_volume} cm^3"
...

radius = calculate_radius
volume = sphere_volume(radius)
sphere.volume = volume</code></pre>
<p>Why is it a good idea to abstract the formula for a sphere's volume into its own method? Because if mathematicians ever found out they got the formula wrong, you would want to go through all the places in your code that you used the formula and update it to be correct. That is, we know ahead of time that we want the code to be in lockstep. This is as safe a gamble as you can get.</p>
<h3>Over-abstraction examples</h3>
<p>The main sign that you're over-abstracting is that your method accepts a bunch of optional args:</p>
<h4>Example: Bloated method</h4>
<h5>Bad:</h5>
<pre><code>def average(arr, type = Integer, ignore_nulls = false)
  if arr.any?(&amp;:nil?)
    if ignore_nulls
      arr = arr.compact
    else
      return nil
    end
  end

  if type == String
    arr = arr.map(&amp;:to_i)
  end

  arr.sum / arr.size
end

puts average([1,2,3])
=&gt; 2

puts average(['1','2','3'], String)
=&gt; 2

puts average(['1','2','3', nil], String, true)
=&gt; 2

puts average([1, 2, 3, nil], Integer, false)
=&gt; nil</code></pre>
<p>If you want to know how the <code>average</code> method behaves when you're dealing with an array of strings with no <code>nil</code> values, you have to read through the first if condition which has nothing to do with your use case before reaching the code that does. Likewise if you want to know how the <code>average</code> method behaves when the array contains either nils or integers, the second if condition is irrelevant, but you'll still need to read through that to understand how the whole thing works.</p>
<p>If each of the use cases came up dozens or hundreds of times, maybe then it would make sense to retain the abstraction, but when the number of optional arguments is roughly equal to the number of different use cases, chances are you've got the wrong abstraction.</p>
<h5>Good:</h5>
<pre><code>def average(arr)
  arr.sum / arr.size
end

puts average([1,2,3])
=&gt; 2

arr = ['1','2','3'].map(&amp;:to_i)
puts average(arr)
=&gt; 2

arr = ['1','2','3', nil].compact.map(&amp;:to_i)
puts average(arr)
=&gt; 2

arr = [1, 2, 3, nil]
if arr.any?(&amp;:nil?)
  puts nil
else
  puts average(arr)
end
=&gt; nil</code></pre>
<p>In this case we're not removing the abstraction altogether: we're just keeping the part that actually applies to all cases. Now understanding the logic of any one invocation of our <code>average</code> method is trivial.</p>
<p>We now have <code>.map(&amp;:to_i)</code> being duplicated whereas it only appeared once in the <code>Bad</code> alternative, but it's a small cost for a vast improvement.</p>
<p>Note that looking at the <code>Good</code> variant, it's clear that the behaviour is quite different from one use case to the next, but that is not at all clear in the <code>Bad</code> variant because the method calls all look so simple and it was anybody's guess how much code inside <code>average</code> applied to each use case.</p>
<p>This is why abstractions go bad over time: because as you expand the interface more and more, it becomes harder and harder to judge how appropriate the abstraction is to any given use case, and developers end up assuming that all that convoluted code is vaguely relevant to the majority of use cases when in fact it's not.</p>
<h4>Example: Awkward class</h4>
<h5>Bad:</h5>
<pre><code>class Shape
  def initialize(radius: nil, width: nil, type:)
    @radius = radius
    @width = width
    @type = type
  end

  def area
    case @type
    when :square
      @width ** 2
    when :circle
      (@radius ** 2) * Math::PI
    end
  end

  def perimeter
    case @type
    when :square
      @width * 4
    when :circle
      @radius * 2 * Math::PI
    end
  end

  def diameter
    case @type
    when :square
      nil
    when :circle
 …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesseduffield.com/beginners-guide-to-abstraction/">https://jesseduffield.com/beginners-guide-to-abstraction/</a></em></p>]]>
            </description>
            <link>https://jesseduffield.com/beginners-guide-to-abstraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735991</guid>
            <pubDate>Sun, 05 Jul 2020 01:12:40 GMT</pubDate>
        </item>
    </channel>
</rss>
