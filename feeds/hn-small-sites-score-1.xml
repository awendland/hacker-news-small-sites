<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 03 Mar 2021 08:35:57 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 03 Mar 2021 08:35:57 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Build a Business, Not an Audience]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26301030">thread link</a>) | @jakobgreenfeld
<br/>
March 1, 2021 | https://jakobgreenfeld.com/build_an_audience | <a href="https://web.archive.org/web/*/https://jakobgreenfeld.com/build_an_audience">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you‚Äôre reading this, I‚Äôm pretty sure you‚Äôve seen the following pattern over and over again:</p>

<ul>
  <li>Creative nonfiction pioneer John McPhee distilled decades of experience and first-hand learnings in a series of essays. (The best of them are now available in a book called ‚ÄúDraft No. 4‚Äù.)</li>
  <li>A savvy entrepreneur repackages the advice in a $1000+ cohort-based course.</li>
  <li>Someone takes the course and summarizes what he learned.</li>
  <li>People on Twitter start creating threads summarizing the student‚Äôs summaries.</li>
  <li>At some point, the guy who summarized the student‚Äôs summaries will get invited to a podcast to summarize his summary of the student‚Äôs summary.</li>
</ul>

<p>I wish I was kidding.</p>

<p>This is a picture-perfect example of what Sean Blanda calls the <a href="https://99u.adobe.com/articles/55974/the-creative-worlds-bullshit-industrial-complex">Creative World‚Äôs Bullshit Industrial Complex</a>. But my goal here is not to dunk on anyone. Instead I want to focus on something far more important.</p>

<p>The Bullshit Complex is just a symptom. What‚Äôs the underlying cause?</p>

<p>First, let me clarify one thing. While I‚Äôm convinced that remixed content is largely a waste of time for writers and readers, it‚Äôs a free world out there. Do whatever makes you happy. If you focus on remixed or ‚Äúcurated‚Äù content I‚Äôll probably not follow you on Twitter or read your blog, but there‚Äôs no reason why you should care about that. Ultimately, it‚Äôs your own responsibility to decide how you spend your time and what kind of content you consume.</p>

<p>With that out of the way, let‚Äôs talk about entrepreneurship.</p>

<p>In recent years one of the most common pieces of advice for aspiring entrepreneurs has become that you should focus on building an audience. Everyone is screaming it from the rooftops.</p>

<p>So when I started to get into entrepreneurship a few months ago, that‚Äôs exactly what I did. I spent a lot of time researching what kind of tweets get attention and set the goal for myself to post at least two tweets per week and two blog posts per month. After all, churning out content regularly is key if you want to build an audience, <a href="https://www.youtube.com/watch?t=67&amp;v=cubPiuD7_dA&amp;feature=youtu.be">right</a>?</p>

<p>If you need any evidence how serious I was about the whole building an audience thing, here it is: I created a <a href="https://whattotweet.com/">What to Tweet</a> tool because I was struggling to stick to my Twitter schedule.</p>

<p>Looking back at it now I think I largely wasted my time. And more importantly I see so many people falling into the exact same trap.</p>

<p>Their goal is to become entrepreneurs. But instead of building products, they create content. Or even worse, they do research and take courses on how to create content.</p>

<p>But this doesn‚Äôt bring them one inch closer to their goal. It‚Äôs just a form of procrastination.</p>

<p>While charging money for something you created is <a href="https://jakobgreenfeld.com/free">scary</a>, there is almost zero risk in putting out free content. And if you‚Äôre just remixing other people‚Äôs content, the intellectual risk is effectively zero. After all, you can always reply ‚Äúhey, don‚Äôt shoot the messenger‚Äù.</p>

<p>This trap is particularly dangerous because it feels like you‚Äôre making progress while really you don‚Äôt.</p>

<p>Aspiring entrepreneurs are not just wasting a lot of time but also lots of money this way. They spend thousands of dollars on courses that teach them how to remix other people‚Äôs content more effectively. They buy the latest hyped-up courses that teach them how to craft more effective tweets, blog posts and Youtube videos.</p>

<p>But don‚Äôt get me wrong. <em>Having</em> an audience is awesome and I love great content.</p>

<p>What I‚Äôm saying is that too many beginners have their priorities backwards and fall into the ‚Äúbuild an audience!‚Äù trap.</p>

<p>An exemplary plan looks as follows: ‚ÄúI don‚Äôt know what product I should create. So I‚Äôm planning to create articles or carousels on Linkedin to find my voice and build an audience.‚Äù That‚Äôs almost verbatim a paragraph from an email I received two days ago.</p>

<p>You can certainly get a lot of followers by churning out remixed content and feel-good platitudes. But everyone seems to forget that not all audiences are alike.</p>

<p>Let‚Äôs say you have 2000 followers that you got by posting feel-good platitudes, whereas I only have two followers called Elon Musk and Paul Graham. Would you swap accounts?</p>

<p>With feel-good platitudes and remixed content you‚Äôll only attract fellow beginners. Everyone else recognizes the content immediately for what it is. Hence, the primary value of your much larger audience is that you‚Äôre able to sell them a ‚ÄúHow to grow your Twitter following‚Äù Gumroad course for $47.</p>

<p>A high-quality audience is an endless source of opportunities. A low quality one is at most a Ponzi scheme.</p>

<p>Many people <a href="https://twitter.com/m_ashcroft/status/1364334719970721793">learn</a> this the hard way. They get lured by the promise that they‚Äôll be able to create content effortlessly and build an audience this way. This is exactly what beginners want to hear and hence what gurus are preaching. ‚ÄúEverything is a remix‚Äù. So just progressively summarize a bunch of books and then start sharing pieces you remixed from your summaries.</p>

<p>Students of these courses spent months recording videos and writing thousands of words only to discover that they never said anything meaningful.</p>

<p>Valuable content that truly advances the conversation and gets the attention of people you really want to connect with is never effortless. It‚Äôs painful. And I‚Äôm not talking about some kind of sophisticated editing process, but the writing itself.</p>

<p>In fact, this is how you know that you‚Äôre creating valuable content. You should at least be a little scared before you hit the publish button.</p>

<p>Publishing content online is the best way to become visible so that opportunities can find you. But please don‚Äôt try to improve your ability to come up with interesting things by reading and connecting ideas just so that you have something to write about.</p>

<p>If you ever notice that you‚Äôre trying to ‚Äúsay something interesting‚Äù, stop. You‚Äôre just going to feed the Creative World‚Äôs Bullshit Industrial Complex.</p>

<p>Your main priority always should be to <em>do</em> meaningful things, to solve real-world problems, to be the man in the arena. And if you share what you learn along the way, people will start to listen. Write when you have something meaningful to say, and not to stick to some self-imposed writing schedule.</p>

<p>A hidden benefit of this strategy is that your writing skills become largely irrelevant. It‚Äôs certainly true that great writers like John McPhee can make a topic as boring as <a href="https://www.goodreads.com/book/show/54983.Oranges">Oranges</a> exciting. But if you have a great story to tell or learned something important, people will pay attention no matter how bad your writing is. Not convinced? Just look at the essay you‚Äôre reading right now.</p>

<p>Save yourself thousands of dollars. Here‚Äôs all the writing advice you need:</p>

<ul>
  <li>Share meaningful first-hand experiences.</li>
  <li>Write as if you were emailing a friend, not to impress an imaginary teacher.</li>
</ul>

<p>Now I‚Äôm definitely scared to publish this essay. This is exactly why I‚Äôll do it.</p>

  </div></div>]]>
            </description>
            <link>https://jakobgreenfeld.com/build_an_audience</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301030</guid>
            <pubDate>Mon, 01 Mar 2021 09:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GitHub Issues for Blog Comments]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300784">thread link</a>) | @quyleanh
<br/>
March 1, 2021 | https://danyow.net/using-github-issues-for-blog-comments/ | <a href="https://web.archive.org/web/*/https://danyow.net/using-github-issues-for-blog-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        <header>
            
            <section>
                <time datetime="2018-04-05">05 April 2018</time>  on <a href="https://danyow.net/tag/github/">github</a>, <a href="https://danyow.net/tag/blog/">blog</a>, <a href="https://danyow.net/tag/comments/">comments</a>
            </section>
        </header>

        <section>
            <!--kg-card-begin: markdown--><p>There are a ton of free comment widgets available- Facebook comments, Disqus, Livefyre and many more. They're outnumbered by <a href="https://www.google.com/search?q=using+github+issues+for+blog+comments">blog posts</a> on replacing these bloated, privacy destroyers with a custom systems that use GitHub issues as a backing data store.</p>
<p>Enter <strong><a href="https://utteranc.es/">https://utteranc.es</a></strong>, my take on hosting blog comments on GitHub issues. Lightweight, easy to configure and secure. No need to worry about GitHub API rate limits, managing server-side code, manually linking blog posts to issues or forcing users to leave your site to post a comment.</p>
<p>I had a lot of fun building this app, it served as the POC for the <a href="https://docs.microsoft.com/en-us/teamblog/a-new-feedback-system-is-coming-to-docs">GitHub issue integration in Microsoft Docs</a>. Much of the GitHub API and OAuth related code is shared. There are some features that haven't made it into docs <em>yet</em> like markdown preview. On the other hand, we've implemented reactions in docs, which hasn't been backported to utterances yet. As of this writing, users have opened <em><a href="https://github.com/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+created%3A%3E%3D2017-12-15+is%3Apublic+in%3Abody+%22Version+Independent+ID%22+-repo%3AMicrosoftDocs%2FSamplesPages+-repo%3Ajdanyow%2Ftest2">more than 2,250 issues</a></em> via the GitHub based feedback system in Microsoft Docs. Pretty crazy. Kudos to the content teams that are keeping up with all the issues!</p>
<p>If you have any feedback let me know in the comments below or <a href="https://github.com/utterance">open an issue/PR</a>.</p>
<!--kg-card-end: markdown-->
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://danyow.net/using-github-issues-for-blog-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300784</guid>
            <pubDate>Mon, 01 Mar 2021 08:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reaching #1 on Google]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26300436">thread link</a>) | @leoloso
<br/>
February 28, 2021 | https://leoloso.com/posts/path-to-number-1-in-google/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/path-to-number-1-in-google/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This weekend I had a very nice surprise: My <a href="https://graphql-api.com/blog/why-wordpress-should-have-a-graphql-api-in-core/">latest blog post on graphql-api.com</a> made it to the top of Google's search results, when searching for "wordpress core graphql":</p><figure><img src="https://leoloso.com/images/blog-post-first-in-google.png" alt="1st position in Google!" loading="lazy" width="2202" height="1016"><figcaption>1st position in Google!</figcaption></figure><p>I noticed because, as I woke up on Sunday morning and I checked my traffic, I saw a wonderful spike:</p><figure><img src="https://leoloso.com/images/traffic-graphql-api-on-sunday-28-feb.png" alt="Traffic from graphql-api.com on Feb 28th" loading="lazy" width="3360" height="1930"><figcaption>Traffic from graphql-api.com on Feb 28th</figcaption></figure><p>By the end of the day, that blog post had brought in near 800 visitors (and they kept arriving the following day):</p><figure><img src="https://leoloso.com/images/traffic-blog-post-on-sunday-28-feb.png" alt="Traffic from the blog post on Feb 28th" loading="lazy" width="3360" height="1930"><figcaption>Traffic from the blog post on Feb 28th</figcaption></figure><p>I believe this is the first time I reach the top of Google, when searching for some rather generic terms (say, without mentioning my name as part of the search).</p><p>I must admit, making it to the top of Google feels good!</p><figure><img src="https://leoloso.com/images/top-of-google-meme.jpg" alt="This is how I felt like" loading="lazy" width="620" height="412"><figcaption>This is how I felt like</figcaption></figure><h2 id="heading-strategy-to-reach-1">Strategy to reach #1<a href="#heading-strategy-to-reach-1"><span> permalink</span></a></h2><p>Ok, so this is how it happened.</p><p>On Saturday, I wrote the blog post <a href="https://graphql-api.com/blog/why-wordpress-should-have-a-graphql-api-in-core/">üõ† Should WordPress have a GraphQL API in core?</a> for my plugin's blog.</p><p>I had the blog post's URL, <code>why-wordpress-should-have-a-graphql-api-in-core</code>, contains those keywords I wanted the post to be associated with:</p><ul><li>GraphQL</li><li>WordPress</li><li>core</li></ul><p>I then promoted the <a href="https://www.reddit.com/r/PHP/comments/ltnzd9/should_wordpress_have_a_graphql_api_in_core/">post on Reddit's /r/php channel</a>, and <a href="https://news.ycombinator.com/item?id=26286388">shared it on Hacker News</a>.</p><p>For HN, I posted it under the special section "Show HN", because the number of articles submitted there is lower, hence each post remains visible longer (before falling out of the first 30 results shown on the page).</p><p>The traffic on the "new" section is low, but really high on the front page. Then, the intention is to get the article upvoted, so it will make it to the Hacker News' front page (at least the one for Show HN).</p><p>A way to improve one's chances is to use a compelling title. Then, instead of using the blog post's actual title ("Should WordPress have a GraphQL API in core?"), I chose one more suitable to the Show HN ethos: "GraphQL API in WordPress core would look like this".</p><p>I crossed my fingers that the article would get upvoted, and went to sleep.</p><p>I woke up, and saw to my delight that the article got upvoted, and it made it to Show HN's front page. Yay!</p><p>I wish I had taken a screenshot. I did not. But it looked like this:</p><figure><img src="https://leoloso.com/images/hacker-news.jpg" alt="Showing up on HN Show front page" loading="lazy" width="607" height="411"><figcaption>Showing up on HN Show front page</figcaption></figure><p>Google (I believe) picked it up from there, and the traffic then went through the roof üöÄ</p><figure><img src="https://leoloso.com/images/through-the-roof.jpg" alt="My traffic on Sunday morning" loading="lazy" width="500" height="508"><figcaption>My traffic on Sunday morning</figcaption></figure><h2 id="heading-search-is-a-battle">Search is a battle<a href="#heading-search-is-a-battle"><span> permalink</span></a></h2><p>I was lucky this time, because people upvoting my article is out of my control. However, this is part of a long-term strategy, to have my plugin the <a href="https://graphql-api.com/">GraphQL API for WordPress</a> feature higher on Google.</p><p>That search result is actually a bit esoteric: "wordpress core graphql". Who adds the word "core"?</p><p>This is a step in between. The actual objective is to feature higher when searching for "wordpress graphql". And in this concern, my plugin is not doing great yet, but it's been improving!</p><p>When Googling "wordpress graphql", my plugin now shows on the homepage! (This was not the case as far as last week). It shows on the 7th position and, in addition, the 4th and 6th positions also concern my plugin:</p><figure><img src="https://leoloso.com/images/googling-wordpress-graphql.png" alt="Googling &quot;wordpress graphql&quot;" loading="lazy" width="1761" height="1926"><figcaption>Googling 'wordpress graphql'</figcaption></figure><p>WPGraphQL is currently dominating results for this search, taking positions 1, 2 and 3, which are the ones that truly matter.</p><p>But I'm coming behind, and will battle my way up üòú</p><figure><img src="https://leoloso.com/images/looking-up.jpg" alt="Looking up, going up" loading="lazy" width="661" height="377"><figcaption>Looking up, going up</figcaption></figure></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/path-to-number-1-in-google/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300436</guid>
            <pubDate>Mon, 01 Mar 2021 07:24:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gerald Weinberg]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300409">thread link</a>) | @ingve
<br/>
February 28, 2021 | https://deprogrammaticaipsum.com/gerald-weinberg/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/gerald-weinberg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Some books are like mirrors. By that I mean that reading them involves a great deal of looking at oneself, both for praise and loathing. Taking a look back in time, reflecting on all those times we thought we were right and we were wrong, bringing back memories of times long gone, some of them painful, most hopefully fun and joyful.</p>
<p>‚ÄúThe Psychology of Computer Programming‚Äù is one of those. In every one of its chapters, Dr. Weinberg reflects on the human aspects of programming. It is, most probably, the first book ever written on the subject of the personality, the interactions and the characteristics of software developers. Let me be clear: this book has been written in 1971, and it has been continuously in print until at least the end of the twentieth century, for almost 30 years. This is the stuff of classics.</p>
<p>There has even been a reviewed ‚Äúanniversary‚Äù edition published in 1999, but I bought a copy of the first edition of the book, and besides the delightful look and feel of the pages, representatives of the typography and design of the seventies, the structure, the flow and the discussion of this book make it stand in a class of its own, and represent a hallmark in our field.</p>
<p>Dr.&nbsp;Weinberg analyzes programming from both individual and collective points of view, including the issues of education, human resources management, and even programming language design. The author actually devotes a section of his book to explain how the design of a programming language impacts the readability and the subsequent maintainability (or lack thereof) of the programs written in it.</p>
<p>Sounds familiar?</p>
<p>Regarding team interactions, the author highlights the issues brought from scaling up programming teams: do small teams face the same issues as larger ones? How do communication patterns emerge and evolve? The author takes pleasure in debunking common myths and misconceptions, some of them still held today by managers all over the world: what are the factors that can cause a project to break down in pieces? The answers will surprise you, and you will wonder why nobody had ever told you to read this book first.</p>
<p>Dr. Weinberg also pays close attention to the individual characteristics of programmers. What defines a good programmer? Why do they take pride in their jobs? What kind of incentives should a company offer to their developers? Nice offices or challenging problems? (I think you can guess the answer to that last question.)</p>
<p>In the humble opinion of the author of these lines, software is primarily a social process, and only later a technical feat. Software is no more a technical product than a book is just a printed object. Software is the result of interactions among people, and as such it will reflect all the contradictions, the failures, the wonders and the joy of the people involved in it. Every single piece of software ever written by humans reflects the underlying moods, psyche and interactions of a group of people. As such, studying the psychology of a programmer yields naturally in a process in which, invariably, the software will be better at the end.</p>
<p>I once saw a joke on Twitter, saying that managing programmers was subject to Heisenberg‚Äôs Principle, in that observing programmers changes their behavior. I do not think it is a joke, for I believe that all social systems are, actually, quantum-like systems subject to this principle; the actions of the observer will invariably alter the behavior of the observed. And that is OK, as far as I am concerned. If managers are conscious of this fact, and if they can use this to their advantage, they will be able to build sustainable teams.</p>
<p>Maybe Dr. Weinberg took some inspiration from Melvin Conway, who <a href="https://en.wikipedia.org/wiki/Conway%27s_law" target="_blank" rel="noopener">in 1967 stated</a> that ‚Äúorganizations design systems mirroring their own communication structures‚Äù. Now you start to understand why your microservice architecture is a mess, and no, neither Istio nor Prometheus is going to help you with that.</p>
<p>Finally, regarding recruiting: we all know how hard it is to find and recruit software developers, yet I am appalled to see how many companies do as much as they can to destroy the teams they spent so much time and money to build. Why is this? I can only recommend all human resources managers, all project managers, and all developers as well, to get a copy of this book and, as I said at the beginning of this chapter, to take a good look at ourselves in the mirror. We all need a little bit of introspection, and Dr. Weinberg can help.</p>
<p>Legacy buzzword warning: this book is mostly accessible to general audiences, but there are a few sections where the author assumes a certain experience with programming languages, compilers, hardware design or even project management; and in some cases, with the 1971 versions of those.</p>
<p>Cover photo by the author.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/gerald-weinberg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300409</guid>
            <pubDate>Mon, 01 Mar 2021 07:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Message Sent on Aim]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 27 (<a href="https://news.ycombinator.com/item?id=26300266">thread link</a>) | @luu
<br/>
February 28, 2021 | https://justanman.org/posts/the-last-message-sent-on-aim/ | <a href="https://web.archive.org/web/*/https://justanman.org/posts/the-last-message-sent-on-aim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://justanman.org/images/aol-instant-messenger-shuts-down.png" alt="AOL Instant Messenger ‚ÄòRunning Man‚Äô waving goodbye"></p>
<p>In the early 2000s social media sites like Facebook and Twitter weren‚Äôt commonplace yet. Even text messages, at ten cents each, were something to be rationed. For many teenagers the primary means of communication outside school was AOL Instant Messenger (AIM). So when it was announced in October that they were shutting down AIM after 20 years, I felt a wave of nostalgia for the messaging app of my youth.</p>
<p>It wasn‚Äôt clear when they would be pulling the plug for good, but a high school friend and I planned to be online for the occasion. Their website indicated that AIM would continue to work until the morning of December 15, 2017. Assuming this meant UTC time, that put it going offline sometime after 7:00 PM EST on the 14th.</p>
<p>I wondered: Could I be the last person to sign off? The last person to send a message? Would I have anything profound to say?</p>
<p><strong>Research</strong></p>
<p>I decided to research famous last words. First stop: the Book of Revelation. Final chapter, final verse.</p>
<blockquote>
<p>‚ÄúThe grace of our Lord Jesus Christ be with you all. Amen.‚Äù</p>
</blockquote>
<p>Not quite what I was looking for.</p>
<blockquote>
<p>‚ÄúLast words are for fools who haven‚Äôt said enough!‚Äù</p>
</blockquote>
<p>Too cantankerous. And as a somewhat libertarian leaning person, I wasn‚Äôt going to let Karl Marx have the last word.</p>
<p>I‚Äôd figure out what to say later and in the meantime started reading about the technology behind AIM. I learned about OSCAR, the proprietary protocol used by AIM and ICQ. Parts of the protocol were documented by AOL in an official SDK. This is what made third-party AIM clients possible. I had used Gaim (now Pidgin) on Linux machines before and indeed, there was even BSFlite, an AIM client for the command line.</p>
<p>AOL‚Äôs desktop client no longer worked for me. They had already pulled the iOS app from the App Store. Ditto for Android. Fortunately browser sign on still worked. I was greeted by a familiar interface that supported new features like embedded media and SMS.</p>
<p>I sent a couple test messages from the browser to my phone. Monitoring outbound activity in the Chrome network panel revealed the structure of a request: a simple HTTP POST to a url, with what appeared to be a session ID in the query string and a message body. I tried to send a message using <code>curl</code> and it worked. As long as I was signed on in the browser the request was accepted.</p>
<p>There were several paths to automating this but given the time constraint, something quick and easy would probably suffice. All I had to do was keep sending messages until the server stopped responding.</p>
<p><strong>December 14, 2017: The final countdown</strong></p>
<p>It was almost midnight UTC time. It would be the 15th soon and I didn‚Äôt want to miss the shutdown, so I set up a Bash script to run the <code>curl</code> command at one second intervals. Every now and then I had to manually reauthenticate in the browser. It wasn‚Äôt elegant but it worked. Now I had to wait‚Ä¶</p>
<p>To pass time I searched Twitter for mentions of AIM‚Äôs last day. Plenty of people were reminiscing about their old screen names, but only a handful were actually signing on one last time. I added them to my buddy list and we talked for a bit. One lived in DC, one in Toledo. Another somewhere in Maryland. Two were engineers, one was a wrestling announcer! I made dinner and watched <em>The Office</em> while occasionally checking on the script.</p>
<p>It ran for another six hours until 1:21 AM EST. I witnessed the drama play out in HTTP status codes:</p>
<pre><code>200 OK
200 OK
200 OK
408 Request Timeout
408 Request Timeout
401 Unauthorized
</code></pre><p>And like that, AIM was gone. Requests to aim.com returned an Invalid URL status page. <code>curl</code> returned nothing but 401s.</p>
<p><strong>Epitaph</strong></p>
<p>I examined the script logs and found it ‚Äì the last message sent on AIM. [1] It was timestamped Fri Dec 15 01:21:42 EST 2017. From me, to me. (I didn‚Äôt want to spam anyone.)</p>
<p>I had borrowed the words from Leonard Nimoy‚Äôs final tweet:</p>
<blockquote>
<p>‚ÄúA life is like a garden. Perfect moments can be had, but not preserved, except in memory. LLAP‚Äù</p>
</blockquote>
<p>üññ</p>
<p><strong>Notes</strong></p>
<p>[1] At least in my server region.</p>
<p><strong>Thanks</strong> to behind2greeneyes, dalilmoo, croftonworldwide, nuklermuleburger, and sirmatthew84.</p>
<p>If you enjoyed reading this, please consider a donation to the <a href="https://archive.org/donate/">Internet Archive</a>.</p>
<p>You can also read Kat Timpf‚Äôs brilliant <a href="https://www.nationalreview.com/2017/10/aol-instant-messenger-eulogy-aim-social-media-millennials/">eulogy for AIM</a>.</p>

      <hr>
      <p>
        For more frequent updates, follow me on Twitter.
      </p>
      <p>
        <a href="https://twitter.com/jtangofx?ref_src=twsrc%5Etfw" data-show-count="false">Follow @jtangofx</a>
      </p>
    </div></div>]]>
            </description>
            <link>https://justanman.org/posts/the-last-message-sent-on-aim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300266</guid>
            <pubDate>Mon, 01 Mar 2021 06:40:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The curious case of CVE-2020-14381]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300234">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://blog.frizn.fr/linux-kernel/cve-2020-14381 | <a href="https://web.archive.org/web/*/https://blog.frizn.fr/linux-kernel/cve-2020-14381">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://blog.frizn.fr/linux-kernel/">Kernel Linux</a> &gt; <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">The curious case of CVE-2020-14381</a></p>

                    <h3>The curious case of CVE-2020-14381</h3>                    
                    <p>Today is the one-year anniversary of this interesting kernel bug I worked
on last year with <a href="https://twitter.com/bluec0re" target="_blank">@bluec0re</a>,
and as it turns out I wrote something about it during one of these lockdown
weekends so I thought I'd release it. <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2015" target="_blank" title="CVE-2020-14381 get_futex_key use-after-free">The bug itself</a>
was discovered by <a href="https://twitter.com/tehjh" target="_blank">Jann Horn</a>
of Project Zero. While I touch most of the elements required to exploit the
bug, I stay superficial here since the exploit itself is not particularly
exciting. What makes this bug interesting to me is its lifecycle, in particular
how unevenly the patch was applied to the various distributions. I also talk
briefly about hardware side-channels since it was the first time I had ever
used one.</p>

<p><strong>The bug</strong></p><p>It‚Äôs already well-described in the bug tracker, but here is another summary.
The <span>futex</span> syscall's main parameter is a userland address, and this address
may belong to a file-backed mapping. In that case, the futex key kernel object
<a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L707" target="_blank">held</a>
and <a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L724" target="_blank">kept</a>
a reference to the inode object, but didn‚Äôt hold a reference to the file‚Äôs mountpoint.
If the mountpoint were to go away, its associated kernel structures would be
freed, but the inode wouldn‚Äôt. That‚Äôs an issue because the inode itself has
fields that point to some of these structures, such as its <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L641" target="_blank">super_block</a>
struct.</p>

<p>Further use of the inode by <span>futex</span> code paths may therefore trigger
use-after-frees. One particular code path highlighted by Jann in the bug happens
when the <span>futex</span> is destroyed: the last reference to the inode is released
and the inode needs to be freed. This is done in <span>iput</span> which then calls
<span>iput_final</span>. <span>iput_final</span> and its subcalls will then call inode
management functions stored in the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L1942" target="_blank">super_operations</a>
struct accessed <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1533" target="_blank">from the super_block</a>
object. The first instance happens right at the beginning of <span>iput_final</span> with
a call to the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1539" target="_blank">drop_inode</a>
function.</p>

<p>Exploiting this bug requires being able to:
</p><ul>
  <li>Successfully <span>umount</span> a mountpoint. A no-go a few years ago, but
  possible nowadays with the normalization of unprivileged user namespaces.
  It‚Äôs a good example that this feature was never a trivial security tradeoff
  (unprivileged sandboxes v. augmented kernel attack surface) which in turn
  makes it somewhat surprising that all mainstream distributions enabled them by default
  without much debate</li>
  <li>Survive the <span>op-&gt;drop_inode()</span> execution (non-SMEP or a KASLR bypass)</li>
  <li>Survive the <span>op-&gt;drop_inode</span> indirection just before that (non-SMAP
  or a stack/heap leak)</li>
  <li>Do everything in one call, because with an incorrect inode state, a corrupted
  super_block and some linked lists unlinks to do in the remainder of <span>iput_final</span>,
  it‚Äôs doubtful we can even get as far as the second <span>super_operations</span>
  function pointer call (<span>evict_inode</span>)</li>
</ul>


<p><strong>Exploitation</strong></p><p>The first exploitation pathway that comes to mind goes as follows:
</p><ul>
  <li>wait for the <span>super_block</span> to be freed. It‚Äôs done in <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/super.c#L299" target="_blank">an RCU callback</a>
  so one way or another you need to wait for the end of the RCU grace period
  after <span>umount</span> returns, e.g. with <span>membarrier</span>. For a PoC, spraying
  allocs for the duration of the expedited grace period works well enough since
  the <span>super_block</span> slab, <span>kmalloc-2k</span>, is not super busy.</li>
  <li>overwrite the freed <span>super_block</span> via a dynamic heap allocation primitive
  (e.g. <a href="https://elixir.bootlin.com/linux/v5.4.7/source/net/socket.c#L2264" target="_blank">sendmsg ancillary data</a>).</li>
  <li>point <span>s_op</span> to an attacker-controlled buffer</li>
  <li>point <span>drop_inode</span> to a chain of gadgets that pivot the stack to
  either the <span>super_block</span> or <span>super_operations</span> bufffers (which
  are both necessarily in registers and almost fully controlled). Example of
  common gadgets that would work in this situation would be <span>push reg; jmp/call [reg+x]</span>
  that can then be chained with a <span>pop rsp; ret</span> gadget placed at <span>[reg+x]</span></li>
  <li>do whatever with your unconstrained ROP, fixup the stack and return</li>
</ul>


<p>This would be a sucky exploit to maintain as it relies on precise knowledge
of the kernel image, but that‚Äôs as good as it gets for a raw function pointer
execution without a read primitive in kernel space. The portability issues
for exploits like this are in themselves a significant bonus of SMEP: it rarely
prevents exploitation but makes many candidates much less appealing for weaponization.</p>

<p>We can take SMEP for granted. It‚Äôs only one CPU generation / 2 years older
than SMAP, but not having it is getting really rare. Plus if your exploit does
rely on no-SMEP but your target ends up having software SMEP enabled, which
you sometimes can't really tell at runtime, you've just turned a privesc attempt into
a lost foothold. No-SMAP however is still a thing for the time being. As a
random example the <a href="https://aws.amazon.com/intel/" target="_blank" title="AWS EC2 intel CPUs">AWS EC2 CPU roster</a>
shows some CPUs that do not support SMAP.</p>

<p><strong>On infoleak bugs</strong></p><p>In any case, to exploit this bug one needs at least one infoleak. The most
important is to get kernel base for gadgets, and then we could use a heap leak
or similar to support SMAP-capable CPUs (to have our "attacker-controlled
buffer" in point 3 above in kernel space). A heap/stack leak can often yield
a .text address as well so having one would kill two birds with one stone.
But, not everyone has the right infoleak in their stash ready to go, contrary
to a common anti-KASLR argument. And even when you do have an infoleak bug,
it doesn't mean that it will help with your current exploit.</p>

<p>For instance, a good infoleak candidate which was released around the same
time last year would be the one with uninitialized memory in coredumps, <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-10732" target="_blank">CVE-2020-10732</a>.
But short of a public proof-of-concept, one needs to understand the coredump
generation code, then find an object in that slab that allows us to get
.text, and another one to deduce a heap address you control. In short, at least
as much work as the rest of the exploit we are looking at. And that's without
considering that using two bugs in one exploit also means that you need to
take into account both bugs limitations. Unprivileged user namespaces for the
main bug we are looking at (not a thing on e.g. RHEL 7), and for the coredump,
well the ability to retrieve the core files, i.e. not running in a container.
Luckily for our project, we already knew we were targeting non-SMAP containers
so we were able to avoid spending all that effort on an infoleak bug that
would have ended up being worthless; a luxury that real exploit developpers
preparing capabilities ahead of time do not have. But if we were targeting
SMAP containers, well that would have been it since more effort would have
exceeded our resource budget for this project.</p>

<p><strong>Hardware side-channels</strong></p><p>For kernel .text however, the situation is different since there are generic,
publicly-documented ways to obtain kernel base: hardware vulns. I personally
hadn‚Äôt ever used any and even saw them as a niche exploitation technique
relying on opaque CPU heuristics that don‚Äôt hold across models - not something
to be considered for resilient exploits. I was simply wrong, but thankfully
had access to many specialists (<a href="https://twitter.com/tehjh" target="_blank">@tehjh</a>,
<a href="https://twitter.com/_fel1x" target="_blank">@_fel1x</a>, <a href="https://twitter.com/_tsuro" target="_blank">@_tsuro</a>)
who knew better.</p>

<p>While side-channels that allow leaking memory across security boundaries
are hopefully bound to be mitigated, there are many side-channels that leak
addresses and which we haven‚Äôt heard much about since Spectre and friends.
These ones are probably here to stay even longer. For this project I used <a href="https://github.com/tpn/pdfs/blob/master/Jump%20Over%20ASLR%20-%20Attacking%20Branch%20Predictors%20to%20Bypass%20ASLR%20-%202016%20(micro16).pdf" target="_blank" title="jump over aslr paper">Jump Over ASLR</a>,
which was published before Spectre in 2016. It‚Äôs simple to understand (especially
with access to the aforementioned people) and there are PoCs that are just
waiting to be adjusted to your own scenario (e.g. <a href="https://github.com/felixwilhelm/mario_baslr" target="_blank" title="mario_baslr jump over aslr">mario_baslr</a>
from @_fel1x). Jump Over ASLR relies on the inner workings of the Branch Target
Buffer where user and kernel branches may collide. When that happens, the CPU
has more work to do and that can be observed. This allows leaking kernel base 
as long as you have offsets of branches hit during a short kernel path you
can trigger at will: you can then leverage the low entropy of KASLR to try
all possible base addresses and find the one where the branches are hit.</p>

<p>For the parameters (the branches to measure) you can really use whatever
you want. I only tried the <span>creat</span> syscall with arguments that cause a
fast return to userland, and then measured whether the <span>sys_creat</span> and
<span>do_sys_open</span> offsets had been hit. The offsets need to be fairly precise
but not to the byte since there seems to be some aliasing going on in the branch
predictor: I originally used <span>__fentry__</span> as an additional branch target
at a +5 offset for both symbols which still worked even though I later learned
these calls get <a href="https://lwn.net/Articles/747256/" target="_blank">dynamically patched out</a>.
</p>

<p>With proper filtering of both false negatives and false positives (essentially
double checking each address) this works like a charm on recent Intel CPUs,
and it‚Äôs one of many such techniques that have been published in the past
6 years or so. That makes it something we should be able to rely on as exploit
developers for the foreseeable future. So for a known kernel image at least,
we are essentially back to pre-KASLR times - and keep in mind that it‚Äôs a
field I know fairly poorly so other side-channels are probably even better.</p>

<p><strong>Patch gap</strong></p><p>Ok here is what I personally found really interesting because I had never
looked into kernel bug timelines before. This bug was initially reported on
February 28 2020, and fixed in tip on March 3. At this point it‚Äôs essentially
public for anyone keeping an eye out for interesting kernel patches - even
if you don‚Äôt spend too much time on it, a <span>reported-by</span> Jann Horn is
worth looking into. The main kernel lines were fixed either on March 25 or
April 2. If you‚Äôre thinking ‚Äúoh wow one whole month‚Äù, please be seated for
what‚Äôs coming.</p>

<p>Some distros applied the patch almost immediately:
</p><ul>
  <li>Arch Linux: Mar 25</li>
  <li>Gentoo: Mar 25</li>
  <li>Fedora: Mar 26</li>
</ul>


<p>I know they are not supposed to target workstations specifically but outside
of personal servers I don't think I have ever seen them used otherwise. The
2nd batch of distributions that fixed the bug is arguably more server-ready:
</p><ul>
  <li>Ubuntu 18.04 LTS: Apr 7</li>
  <li>Ubuntu 16.04 LTS: Apr 24</li>
  <li>Debian Buster ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">https://blog.frizn.fr/linux-kernel/cve-2020-14381</a></em></p>]]>
            </description>
            <link>https://blog.frizn.fr/linux-kernel/cve-2020-14381</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300234</guid>
            <pubDate>Mon, 01 Mar 2021 06:31:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Paying Me]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300165">thread link</a>) | @hiphipjorge
<br/>
February 28, 2021 | https://www.spakhm.com/p/please-stop-paying-me | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/please-stop-paying-me">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few days ago I realized something. I don‚Äôt like writing.</p><p>I realized it because I found creative energy to work on programming projects again, and I experience writing programs differently from how I experience having to write. Even the turn of phrase ‚Äúhaving to write‚Äù betrays my disposition toward the craft.</p><p>When I‚Äôm very excited to build products or just program computers for the joy of programming, I dread going to sleep and every part of me <em>cannot wait</em> to wake up and write code again. I‚Äôve never felt that about writing. Writing has always been a chore. I think I‚Äôve known this all along, but have never been able to admit this to myself until now.</p><p>When you read anything about anything anywhere, it tells you what great [INSERT CALLING HERE] do. Great startup founders and engineers write well and write a lot because without clear writing there is no clear thinking. I think I bought into that too much for my own good. So it feels liberating to say: <strong>I hate writing.</strong> It‚Äôs painful and laborious and every good piece of writing I make feels like delivering a baby. A rewarding experience for sure, but I think even the most loving of mothers would stop being so loving if she had to deliver a new baby every week.</p><p>One thing that duped me is a lot of positive reenforcement. My best pieces of writing get tens, sometimes hundreds of thousands of readers, and that gives me an addicting sense of elation. I certainly never expected to make money doing it, but enough of you find my writing sufficiently interesting to offer the ultimate seal of approval‚Äî you transfer money from your wallet into mine. I deeply appreciate it, and deeply appreciate you spending time on reading my essays, but unfortunately this isn‚Äôt sufficient impetus for me to produce good work. When I‚Äôm forced to write on a schedule, my writing sucks and my life is miserable.</p><p>Which is a good reminder why some of my writing is good. It‚Äôs good when I have something important to say. Important things are hard to say by definition‚Äî if they were easy people would have already talked them out and they probably would have lost their importance. At least they‚Äôre hard to say for me. So when I do it it‚Äôs always very slow and painful, and it turns out good because I say something that matters to me in a way that nobody else bothered or managed to say. With my particular idiosyncrasies the intersection of that and the business of running a newsletter is an empty set.</p><p>So please stop paying me. For the folks that have prepaid, I‚Äôm not exactly sure how Substack tooling handles this situation, but shoot me an email and I‚Äôll figure out how to return a prorated amount.</p><p>I will continue writing. When I have something important to say, I‚Äôll go through the pain necessary for me to say it. I‚Äôll also write about my observations as I pursue my product and programming work‚Äî technical, anthropological, and simply keeping you up to do date on what I‚Äôm up to. I don‚Äôt expect you‚Äôll be hearing from me less often. In fact, I‚Äôm hoping this will allow me to write more. But owing people weekly essays as a matter of business isn‚Äôt my tao. For all the reasons above, and primarily because it makes the essays suck, and I don‚Äôt like producing bad work.</p><p>Until next week, hopefully. Slava.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/please-stop-paying-me</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300165</guid>
            <pubDate>Mon, 01 Mar 2021 06:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principled Camera Calibrations]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300113">thread link</a>) | @pabs3
<br/>
February 28, 2021 | http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
This is a big deal.
</p>

<p>
In my day job I work with images captured by cameras, using those images to
infer something about the geometry of the scene being observed. Naturally, to
get good results you need to have a good estimate of the behavior of the lens
(the "intrinsics"), and of the relative geometry of the cameras (the
"extrinsics"; if there's more than one camera).
</p>

<p>
The usual way to do this is to perform a "calibration" procedure to compute the
intrinsics and extrinsics, and then to use the resulting "camera model" to
process the subsequent images. Wikipedia has <a href="https://en.wikipedia.org/wiki/Camera_resectioning">an article</a>. And from experience,
the most common current toolkit to do this appears to be <a href="https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html">OpenCV</a>.
</p>

<p>
People have been doing this for a while, but for whatever reason the existing
tools <i>all</i> suck. They make basic questions like "how much data should I gather
for a calibration?" and "how good is this calibration I just computed?" and "how
different are these two models?" unanswerable.
</p>

<p>
This is clearly seen from the links above. The wikipedia article talks about
fitting a pinhole model to lenses, even though no real lenses follow this model
(telephoto lenses do somewhat; wider lenses don't at all).
</p>

<p>
And the OpenCV tutorial cheerfully says that
</p>

<pre>Re-projection error gives a good estimation of just how exact the found
parameters are. The closer the re-projection error is to zero, the more accurate
the parameters we found are.
</pre>

<p>
This statement is trivially proven false: throw away most of your calibration
data, and your reprojection error becomes very low. But we can all agree that a
calibration computed from less data is actually worse. Right?
</p>

<p>
All the various assumptions and hacks in the existing tooling are fine as long
as you don't need a whole lot of accuracy out of your results. I need a lot of
accuracy, however, so all the existing tools don't work for my applications.
</p>

<p>
So I built a new set of tools, and have been using them with great delight. I
just got the blessing to do a public release, so I'm announcing it here. The
tools are
</p>

<ul>
<li><a href="https://github.com/dkogan/mrgingham">mrgingham</a>: a chessboard corner finder. OpenCV has one, but as far as I can
tell, it doesn't work; and it is very slow to tell you that. mrgingham is
relatively quick, robust to all sorts of lens behaviors, and reports the
accuracy of its output. This is a C++ library with Python bindings, and a
commandline tool. 99% of the time the commandline tool is what I use.
</li>

<li><a href="https://github.com/dkogan/mrcal">mrcal</a>: a large toolkit to run calibrations, to manipulate images and camera
models in all sorts of ways, and to visualize stuff. This toolkit does a
<i>lot</i>. It's a C library and a Python library and a number of commandline
tools. Currently the C library exists primarily in the service of the other
two, but it's already very capable, and will become more so over time.
</li>
</ul>

<p>
mrcal does a whole lot to produce calibrations that are as good as possible, and
it will tell you just how good they are, and it includes visualization
capabilities for extensive user feedback. An overview of the capabilities of the
toolkit (with lots of pretty pictures!) is at the <a href="http://mrcal.secretsauce.net/tour.html">tour of mrcal.</a>
</p>

<p>
There's a <i>lot</i> of documentation and examples, but up to now I have been the
primary user of the tools. So I expect this to be somewhat rough when others
look at it. Bug reports and patches are welcome.
</p>

<p>
mrcal is an excellent base, but it's nowhere near "done". The documentation has
some notes about the planned features and improvements, and I'm always reachable
by email.
</p>

<p>
Let me know if you try it out!
</p>

  </div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300113</guid>
            <pubDate>Mon, 01 Mar 2021 05:57:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neural Network Matrix Visualization]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26300106">thread link</a>) | @sidcool
<br/>
February 28, 2021 | https://iism.org/article/neural-network-matrix-visualization-61 | <a href="https://web.archive.org/web/*/https://iism.org/article/neural-network-matrix-visualization-61">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iism.org/article/neural-network-matrix-visualization-61</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300106</guid>
            <pubDate>Mon, 01 Mar 2021 05:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animated PNG vs. Animated Webp vs. GIF]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300015">thread link</a>) | @panabee
<br/>
February 28, 2021 | https://corydowdy.com/blog/apng-vs-webp-vs-gif | <a href="https://web.archive.org/web/*/https://corydowdy.com/blog/apng-vs-webp-vs-gif">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>With Chrome now supporting Animated PNG as of Chrome 59 we have two image formats that can supplant the old and tired GIF format. Varying posts and sites have different conclusions on when to use APNG versus an animated Webp. In all my findings (linked below where the source Gif comes from) animated webp beats apng in filesize each and every time. Sometimes by not very much. This of course is anecdotal and I'm not as familiar with apng as the creators and others may be so they may be able to squeeze more out of an apng than I can.</p>

<p>All that being said I've heard and read people say "APNG might be bigger but webp takes longer to decode in the browser". That assumes the larger APNG will load faster than the smaller webp. Is that the case though? I assume the smaller webp gets downloaded to the client faster then it'll start decoding faster. Thus animating faster. So lets actually test that instead of me spouting off haha. On to the source GIF.</p>

<p>The GIF I'm using for this post comes from my post on <a href="https://corydowdy.com/blog/converting-mp4-to-webm">Converting MP4 To Webm <span>&nbsp;</span></a>. That was a 1080p video stripped down to about 5 seconds and resized to a width of 800.</p>

<p>Here are the relevant details of the unoptimized GIF:</p>

<ul>
<li>Dimensions: 800x450</li>
    <li>Length: 5s</li>
    <li>Size: ‚âà37.9MB</li>
</ul>
<h2>Setup</h2>

<p>Before we can even embark on this trip we have to convert the GIF above to an APNG and an Animated Webp. Maybe you can convert the GIF on this page to an APNG and get better results. Please try I don't want to dismiss APNG as much as I think I'm probably coming off as.</p>

<h3>Converting to an Animated PNG (apng)</h3>

<p>Gif2apng offers three different options for converting a GIF to an animated PNG. We have zlib, 7zip and Zopfli compression. Each compression option besides zlib allows you to set an iteration amount which defaults to 15.</p>

<p>I'm using gif2apng version 1.9 <a href="#footnotes-apng">[ 1 ] [ 2 ]</a>. For both 7zip and zopfli I'll use the "default" iterations of 15 and a more aggressive version of 100. Be warned if you want to do this. Depending on your server specs or locally on your own computer and it's specs Zopfli will take a long time. Increasing the iterations for either of the compression algorithms will also increase how long it takes to convert your image to an APNG. Be prepared to set aside a pretty big chunk of time if you do this on your computer :).</p>

<p>After converting the GIF to an Animated PNG I'll also run it through APNGOPT. This should "optimize" the Animated PNG. This too offers differing amount of iterations. I'll use the "default" of 15 for each apng that was converted with the defaults above and 100 for all the 100 iterations.</p>

<h4>APNG Filesize Results</h4>



<p>We can see that Zopfli compression saves the most before running these through apngopt. It's very CPU intensive though. After running these through apngopt things didn't change much or at all.</p>

<div>
<table>
<caption>Filesize of APNG after using APNGOPT</caption>
    <thead><tr>
<th>Compression Type</th>
            <th>Original Size in MB</th>
            <th>APNGOPT Size in MB</th>
        </tr></thead>
<tbody>
<tr>
<th>Unoptimized Gif</th>
            <td>‚âà37.9MB</td>
            <td></td>
        </tr>
<tr>
<th>Animated PNG with Zlib</th>
            <td>‚âà33.01MB</td>
            <td>‚âà33.04MB</td>
        </tr>
<tr>
<th>Animated PNG with 7zip 15 iterations</th>
            <td>‚âà31.22MB</td>
            <td>‚âà31.21MB</td>
        </tr>
<tr>
<th>Animated PNG with 7zip 100 iterations</th>
            <td>‚âà31.22MB</td>
            <td>‚âà31.21MB</td>
        </tr>
<tr>
<th>Animated PNG with Zopfli 15 iterations</th>
            <td>‚âà30.92MB</td>
            <td>‚âà30.91MB</td>
        </tr>
<tr>
<th>Animated PNG with Zopfli 100 iterations</th>
            <td>‚âà30.87MB</td>
            <td>‚âà30.86MB</td>
        </tr>
</tbody>
</table>
</div>

<h5 id="apng-footnote-label">APNG Footnotes</h5>

<ol id="footnotes-apng">
<li>On a windows machine just use the GUI they package from sourceforge. It seems to be the most up to date. I haven't had the time to see if the GUI and CLI differ in anyway so that'll be up to you unless you're ok with the output of the GUI then keep on keepin on!</li>
    <li>If you install gif2apng through your OS's package manager (ie: apt-get/apt) depending on your OS's you'll more than likely get version 1.7.</li>
    <li>Depending on your OS again if you use the CLI version of apngopt you'll get versions ranging from 1.1 to 1.4.</li>
</ol>
<h2>Animated Webp</h2>

<p>The same reference gif was converted to a webp using three different options and WebP Encoder version: 0.6.0 (WebP Mux version: 0.4.0).</p>

<p>I didn't dive into the different CLI options available for gif2webp. Things such has <code> -kmin </code> , <code> -kmax </code> ‚Äî which specify the minimum and maximum distance between consecutive key frames and can improve decoding performance ‚Äî or adjust the deblocking filter <code> -f </code> from the docs suggested 50. These could with adjustments and tweaking produce smaller or in some instances bigger files. You'll have to test those out for specific images, or use the defaults such as I have.</p>

<ul>
<li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.default.webp">It's default settings (quality 75) <span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.m6.webp">quality of 70 and 6 (-m 6) for the compression mode. It's highest.<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.webp">A quality of 70 with default compression of 4 (lossless)<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.mixed.webp">an unfair mixed mode (lossless and lossy compression) with a quality of 70<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.m6.mixed.webp">another unfair Quality 70 with Commpression of 6 &amp; Mixed compression (lossy and lossles)<span>&nbsp;</span></a></li>
</ul>
<p>Webp at it's default settings beats (barely) each of the converted APNG's, 30.86MB for the Webp compared to 33.01MB using default APNG settings (zlib) and 30.87MB using zopfli compression @ 100 iterations.</p>

<div>
<table>
<caption>Filesize of Webp &amp; Optimized APNG</caption>
    <thead><tr>
<th>File</th>
            <th>Quality</th>
            <th>Compression Mode</th>
            <th>Webp Size in MB</th>
            <th>Best APNGOPT Size in MB</th>
        </tr></thead>
<tbody>
<tr>
<th rowspan="5">Animated Webp</th>
            <td>Default (75)</td>
            <td>Default (4)</td>
            <td>‚âà30.82MB</td>
            <td rowspan="5">‚âà30.86MB</td>
        </tr>
<tr>
<td>70</td>
            <td>6 highest</td>
            <td>‚âà31.80MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Default (4)</td>
            <td>‚âà30.82MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Mixed</td>
            <td>‚âà5.86MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Mixed &amp; 6 (highest)</td>
            <td>‚âà5.32MB</td>
        </tr>
</tbody>
</table>
</div>

<p>Ok cool all the file size mumbo jumbo is out of the way. Does a few kb/mb matter when they are so close? The default webp settings gives us the same size file of an apng using apngout and zopfli @ 100 iterations.</p>

<p>Yep. The larger apng will in fact decode faster. But does that matter? Kind of.</p>
<!-- /#setup --><h2>Summoning the WebPageTest Gods!</h2>

<p>Typically in a situation like this I would use <a href="http://www.webpagetest.org/video/">Webpagetest's "visual comparison" <span>&nbsp;</span></a> option that way we could see the pages load side by side. I'd run a desktop test and then I'd run a mobile test using the "emerging markets" settings. I can't right now since as mentioned above APNG support is in Chrome 59+. The visual comparison tool uses the current stable release of Chrome (which just happened to be updated while I was testing these out. Still to be sure I ran with the Canary version). What most everyone using a non dev/beta version of Chrome uses.</p>

<p>So I'm running these tests on Chrome Canary and will use the median from the first view as the comparison. I'll run each image option/type three (3) times on Chrome desktop using a cable connection ‚Äî 5Mbps 28ms Latency ‚Äî and three times using a Fourth Generation Moto G and their "Mobile 3g" connection ‚Äî 768 Kbps 3G connection with 300ms of latency.</p>
<h3>Webp Defaults vs. Best Animated PNG</h3>

<p>The first comparison I ran is the default settings of gif2webp. As mentioned above this defaults to a quality of 75, compression mode of 4 and is lossless like APNG. You can download these animated images and run them yourself. You'll see which actually loads faster without even having to read haha.</p>

<p>Webp at it's default settings might in fact be smaller in file size (for this particular animation) than the APNG. It helps in the fact that we are sending less bytes down the wire but as for over all page load performance you can see below it's not helping much or if any at all.</p>

<div>
<table>
<caption>Webp Defaults, Best APNG Chrome Desktop Cable Connection</caption>
    <thead><tr>
<th></th>
            <th>Webp Defaults (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-desktop.png" title="Webp Defaults Desktop Cable Connection">test screenshot <span>&nbsp;</span></a>)</th>
            <th>Best APNG (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-desktop.png" title="APNG Zopfli 100 Iterations Desktop Cable Connection">test screenshot <span>&nbsp;</span></a>)</th>
        </tr></thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>65.398s</td>
            <td>53.274s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>2671</td>
            <td>3108</td>
        </tr>
<tr>
<th>Document Complete</th>
            <td>65.398s</td>
            <td>53.274s</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>16.400s</td>
            <td>44.7s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>65.489s</td>
            <td>53.341s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>1.076s</td>
            <td>0.984s</td>
        </tr>
</tbody>
</table>
</div>

<p>Here we can see the visual differences between both of these formats.</p>



<p>These are large files. You're doing yourself and your users a disservice if you send these big honking things down the wire to them.</p>

<h3>Webp and APNG on Mobile 3g Connection</h3>

<p>Webp's defaults will help you out on a a slow 3g connection because it's sending less data. APNG gets frames faster to the screen since it decodes faster, hence the better speed index below.</p>

<div>
<table>
<caption>Webp Defaults, Best APNG Chrome Mobile 3g Connection</caption>
    <thead><tr>
<th></th>
            <th>Webp Defaults (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-mobile.png" title="Webp Defaults Mobile 3g Connection">test screenshot <span>&nbsp;</span></a>)</th>
            <th>Best APNG (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-mobile-3g.png" title="APNG Zopfli 100 Iterations Mobile 3g Connection">test screenshot <span>&nbsp;</span></a>)</th>
        </tr></thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>144.133s</td>
            <td>146.060s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>5791</td>
            <td>5157</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>21.037s</td>
            <td>41.014s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>144.133s</td>
            <td>146.060s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>4.485s</td>
            <td>3.327s</td>
        </tr>
</tbody>
</table>
</div>



<p>So don't use APNG nor the Webp Defaults on a slow connection in my opinion. They are big files.</p>

<h2>Your Best Bet</h2>

<p>So is there a solution for smaller file size than gif and that actually helps your page performance? Yes if you don't mind a possible lossy compressed image.</p>

<p>We can take the Webp image converted with the defaults, the mixed compression (lossy &amp; lossless), the lossy converted webp, and a lossy compressed and filtered webp image and compare those to the "best" file size wise APNG and an unoptimized GIF.</p>

<p>Before I show you those here are the numbers from those runs on a desktop.</p>

<div>
<table>
<caption>WPT Result Comparison of Gif, Animated PNG &amp; Animated Webp on Desktop Cable Connection</caption>
    <thead>
<tr>
<th></th>
            <th colspan="4">Webp Conversion Type</th>
            <th></th>
            <th></th>
        </tr>
<tr>
<th></th>
            <th>Defaults</th>
            <th>Lossy</th>
            <th>Lossy &amp; Filtered</th>
            <th>Mixed</th>
            <th>APNG Best</th>
            <th>GIF</th>
        </tr>
</thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>65.398s</td>
            <td>11.495s</td>
            <td>11.349s</td>
            <td>9.632s</td>
            <td>53.274s</td>
            <td>66.412s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>2671</td>
            <td>962</td>
            <td>785</td>
            <td>882</td>
            <td>3108</td>
            <td>2282</td>
        </tr>
<tr>
<th>Document Complete</th>
            <td>65.398s</td>
            <td>11.495s</td>
            <td>11.349s</td>
            <td>9.632s</td>
            <td>53.274s</td>
            <td>66.412s</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>16.400s</td>
            <td>1.200s</td>
            <td>4.400s</td>
            <td>4.200s</td>
            <td>44.7s</td>
            <td>45.100s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>65.489s</td>
            <td>11.600s</td>
            <td>11.446s</td>
            <td>9.734s</td>
            <td>53.341s</td>
            <td>66.486s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>1.076s</td>
            <td>0.879s</td>
            <td>0.681s</td>
            <td>0.783s</td>
            <td>0.984s</td>
            <td>0.778s</td>
        </tr>
<tr>
<th></th>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-desktop.png" title="Webp Defaults Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-lossy-desktop.png" title="Webp Lossy Desktop Cable Connection">test screenshot </a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-lossy-filtered-desktop.png" title="Webp Lossy &amp; Filtered Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-mixed-desktop.png" title="Webp Mixed Compression Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-desktop.png" title="APNG Zopfli 100 Iterations Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/gif-desktop.png" title="Unoptimized GIF Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
        </tr>
</tbody>
</table>
</div>

<p>Here is the visual comparison.</p>



<p>What I was most surprised by was how close a default settings animated webp and an unoptimized gif page load times and speed index were.</p>

<p>These aren't fair comparision to APNG either since there is lossy compression. There's also high variance in the load times. Much like you'd have in a real world scenario. So take these results with a grain of salt. I didn't put much effort into making them all variable free.</p>

<h3>APNG and Webp Mobile 3g</h3>

<p>Where you'll get the most benefit with this animated webp is on a slow 3g connection.</p>

<div>
<table>
<caption>WPT Result Comparison of Gif, Animated PNG &amp; Animated Webp on Mobile 3g Connection</caption>
    <thead>
<tr>
<th></th>
            <th colspan="4">Webp Conversion Type</th>
            <th></th>
            <th></th>
        </tr>
<tr>
<th></th>
            <th>Defaults</th>
            <th>Lossy</th>
            <th>Lossy &amp; Filtered</th>
            <th>Mixed</th>
            <th>APNG Best</th>
            <th>GIF</th>
        </tr>
</thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>144.133s</td>
            <td>37.631s</td>
            <td>37.408s</td>
            <td>31.839s</td>
            <td>146.060s</td>
            <td>124.712s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>5791</td>
            <td>3811</td>
            <td>3964</td>
            <td>3858</td>
            <td>5157</td>
            <td>29382</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>21.037s</td>
            <td>6.871s</td>
            <td>34.057s</td>
            <td>30.033s</td>
            <td>41.014s</td>
            <td>106.860s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>144.133s</td></tr></tbody></table></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corydowdy.com/blog/apng-vs-webp-vs-gif">https://corydowdy.com/blog/apng-vs-webp-vs-gif</a></em></p>]]>
            </description>
            <link>https://corydowdy.com/blog/apng-vs-webp-vs-gif</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300015</guid>
            <pubDate>Mon, 01 Mar 2021 05:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[7 Reasons not to join a startup and 1 reason to]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299940">thread link</a>) | @czhu0217
<br/>
February 28, 2021 | https://huyenchip.com/2021/02/27/why-not-join-a-startup.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2021/02/27/why-not-join-a-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In 2018, I wrote <a href="https://huyenchip.com/2018/10/08/career-advice-recent-cs-graduates.html">Career advice for recent Computer Science graduates</a> about joining a big company instead of a startup after college.</p>

<p>In 2019, when I left NVIDIA, I wrote <a href="https://huyenchip.com/2019/12/23/leaving-nvidia-lessons.html">Lessons learned after my first full-time job</a> about leaving a big company for a startup.</p>

<p>Now that I‚Äôve left my first full-time job at a startup, I want to revisit the topic. This is based on some personal experience, but most come from friends‚Äô experiences, including the intensive note on startups from a friend who had worked at 3 startups before and who would like to remain anonymous. I hope that it‚Äôll give some pointers to those trying to decide whether to take the leap.</p>

<p>Some asked if this post is about Snorkel. It‚Äôs not. Snorkel is an exception. It‚Äôs a great startup, which is a reason why I joined in the first place, and I recommend it to all my friends who are looking to join a startup.</p>

<p><strong>Disclaimer</strong>:</p>
<ol>
  <li>Each of the points below is true for many startups, but not for all startups, and it‚Äôs more true for early-stage startups (e.g. before series B). There are always exceptions, extreme exceptions, unreasonable exceptions, which make the startup world so exciting.</li>
  <li>A friend told me that these points are only true for bad startups. Most startups are, unfortunately, bad startups.</li>
</ol>

<hr>
<p><b>Table of contents</b><br>
‚Ä¶. <a href="#why_not_join_a_startup">7 reasons not to join a startup</a><br>
‚Ä¶‚Ä¶.. <a href="#1_work_life_balance">Reason 1. Goodbye work-life balance</a><br>
‚Ä¶‚Ä¶.. <a href="#2_bad_engineering">Reason 2. You‚Äôll pick up bad engineering practices</a><br>
‚Ä¶‚Ä¶.. <a href="#3_mentorship">Reason 3. Less mentorship</a><br>
‚Ä¶‚Ä¶.. <a href="#4_equity">Reason 4. You won‚Äôt get rich</a><br>
‚Ä¶‚Ä¶.. <a href="#5_management">Reason 5. Bad management</a><br>
‚Ä¶‚Ä¶.. <a href="#6_enjoyment">Reason 6. You might have to do a lot of things you don‚Äôt want to do</a><br>
‚Ä¶‚Ä¶.. <a href="#7_career_growth">Reason 7. No clear career growth trajectory</a><br>
‚Ä¶. <a href="#why_join_a_startup">One reason to join a startup</a><br>
‚Ä¶. <a href="#next">What‚Äôs next for me?</a><br></p>

<hr>

<h2 id="why_not_join_a_startup">7 reasons not to join a startup</h2>

<h3 id="1_work_life_balance">Reason 1. Goodbye work-life balance</h3>

<p>A friend at a tech giant told me that he and his co-workers once mused about how long they could go on not working until someone noticed. The answers were between a week and two months. At an early-stage startup, the answer is likely a couple of hours.</p>

<p>My transition from NVIDIA to Snorkel was a culture shock. At NVIDIA, you can have a predictable schedule, e.g. coming in at 9am and leaving at 6pm every day. If you don‚Äôt finish something by Friday afternoon, just push the deadline to next week and go to happy hour. It‚Äôs okay, even expected, to not check emails or Slack for the entire weekend.</p>

<p>On my first day at Snorkel, when I left at 7pm, I was the first one to leave.</p>

<p>Nobody told me how to spend my time, but when everyone else worked over the weekend and responded to my Slack messages any time of the night, I wanted to do the same. Nobody forced me to take on a hefty task that would require me to cancel plans with friends, but I also knew that everybody else had their hands full and if I didn‚Äôt do it, we wouldn‚Äôt be able to finish this feature on time and the company would lose a contract or even die.</p>

<p>By the time that I left, the work-life balance had got a lot more balanced. Snorkel had hired a ton more people to share the workload and we had worked out processes to speed things up.</p>

<p>In general, I‚Äôve observed that the bigger the startup, the better the work-life balance. Possible explanations:</p>

<ol>
  <li>The earlier the startup, the more precarious its survival, and the harder everyone has to push.</li>
  <li>In very early-stage startups, the working culture is dominated by those with high ownership in the company (the founding team), who are incentivized to work harder. Later on, the working culture is dominated by people with much lower ownership in the company (e.g. 0.1% over 4 years for the 20th engineer vs. 20% for the founder), who are more incentivized to keep a work-life balance.</li>
</ol>

<p><strong>Caveat</strong>: The work-life balance at an early-stage startup depends a lot on how much the existing team members work. When interviewing at a startup, don‚Äôt ask the founders how much they value work-life balance (they‚Äôll say ‚ÄúA lot‚Äù), but ask every team member you can talk to how much they work. If all of them work during evenings and weekends, you might likely feel pressured to do the same.</p>

<h3 id="2_bad_engineering">Reason 2. You‚Äôll pick up bad engineering practices</h3>

<p>Consider the following scenario. A customer requires a new feature and you have to deliver it in a week. This feature is similar to one of your existing features, so the best solution is to refactor the existing code to allow some of it to be reused.</p>

<p>However, refactoring alone would require a week. Your tech lead decides that you should just duplicate the existing code and turn it into a new feature. Now you have two massive code structures that are similar but not quite. When making changes to one structure, you have to remember to change the other too.</p>

<p>Then, somebody forgets and a wild bug appears. The person assigned to fix it isn‚Äôt given a lot of time, so instead of investigating the duplicate code, they write a hacky function on top.</p>

<p>Startups build 1 from 0, something from nothing. <em>Adding new things fast</em> takes precedence over both <em>adding good things slow</em> and <em>fixing existing things</em>. You might get used to writing quick and dirty code, <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">cargo cult programming</a>, merging code that has no tests, merging before tests complete, committing without comments, spaghetti code, magic numbers.</p>

<p>Bad practices might be a mere dissatisfaction at first, but can gradually become a habit, then become the only way you know how to work.</p>

<h3 id="3_mentorship">Reason 3. Less mentorship</h3>

<p>The thing I missed the most when leaving NVIDIA was mentorship. Large companies, by virtue of having a lot of employees, tend to have many people whose diverse life experience can provide you invaluable advice. At NVIDIA, I could come to my mentors for questions from general career dilemmas to obscure engineering knowledge. Once in a while, I browsed the org chart of tens of thousands of employees, identified people I want to learn from, and asked them to meet at the coffee machine, which they usually accepted.</p>

<p>Startups don‚Äôt have that many people for you to reach out to in the first place. Your handful of coworkers might have backgrounds and experiences similar to yours (cue founders who say they prefer hiring from their existing networks) and are unlikely to give you dramatically different perspectives. Even if there are people who could mentor you, given the pace at which startups move, they might not have the time for it.</p>

<p>To be clear, you can still learn a lot from your coworkers at startups, just a different kind of learning.</p>

<h3 id="4_equity">Reason 4. You won‚Äôt get rich</h3>

<p>Despite a plethora of articles warning people that joining startups is a bad way to get rich (<a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/">1</a>, <a href="https://danluu.com/startup-tradeoffs/">2</a>, <a href="https://hunterwalk.medium.com/sorry-startup-employee-100-your-equity-probably-won-t-make-you-rich-d6549ece71bd">3</a>), many people still think joining a startup is a get-rich-quick scheme. Here‚Äôs the gist of the math. Imagine you‚Äôre an <strong>engineer with 2-3 years of experience</strong>.</p>

<p>If you join a startup as the <strong>15th engineer</strong> (not executive), your compensation might look like the following.</p>

<ol>
  <li><strong>Base salary</strong>: Your base salary is usually lower than you would have got at a big company (e.g. <strong>$120K instead of $160K</strong>) because at startups, equity makes a large chunk of your compensation.</li>
  <li><strong>Equity</strong>: You might get <strong>0.05% - 0.25%</strong> equity vested over <strong>4 years</strong>. After subsequent fundraising rounds, this amount of equity is diluted to <strong>0.02% - 0.1% for 4 years</strong>.</li>
</ol>

<table>
    
  <tbody><tr>
   <td>
<strong>Probability<br>(</strong>appx<strong>)</strong>
   </td>
   <td><strong>Startup scenario</strong>
   </td>
   <td><strong>Startup value</strong>
   </td>
   <td><strong>Your equity value<br>over 4 year</strong>
   </td>
   <td><strong>Your yearly comp<br>(base + equity)</strong>
   </td>
  </tr>
  <tr>
   <td>80%
   </td>
   <td>Fails
   </td>
   <td>0
   </td>
   <td>0
   </td>
   <td>$120K
   </td>
  </tr>
  <tr>
   <td>5%
   </td>
   <td>IPO
   </td>
   <td>$1 billion
   </td>
   <td>$200K - 1M
   </td>
   <td>$170K - 270K
   </td>
  </tr>
  <tr>
   <td>0.5%
   </td>
   <td>IPO
   </td>
   <td>$10 billion
   </td>
   <td>$2M - 10M
   </td>
   <td>$620K - 2.62M
   </td>
  </tr>
  <tr>
   <td>0.05%
   </td>
   <td>IPO
   </td>
   <td>$100 billion
   </td>
   <td>$20M - 100M
   </td>
   <td>$5M - 25M
   </td>
  </tr>
  <tr>
   <td>14.45%
   </td>
   <td>Acquired
   </td>
   <td>$$$
   </td>
   <td>$0 - 8M
   </td>
   <td>$120K - 2.12M
   </td>
  </tr>
</tbody></table>

<p><br>
<strong>If you join late at the startup (say employee number 100+), even if the company succeeds wildly, your equity will be worth very little.</strong></p>

<p>If you want to get rich, join a big company and climb their rank. You can find the detailed analysis of compensations for 19,000 FAAAM-dominated tech workers <a href="https://huyenchip.com/2020/01/18/tech-workers-19k-compensation-details.html">here</a>, but below is a plausible, even conservative, scenario if you join a company like Google with 2-3 years of experience.</p>

<ul>
  <li>1st year, L4 $250K/year.</li>
  <li>2nd year, L4, $280K/year.</li>
  <li>3rd year, L4, $320K/year.</li>
  <li>4th year, L5, $360K/year.</li>
</ul>

<p>After the first 4 years at Google, you‚Äôve already made over $1 million, not counting ‚Äúperks‚Äù like work-life balance.</p>

<h3 id="5_management">Reason 5. Bad management</h3>

<p>There‚Äôs a trend among startups to not fixate on titles until they have to. Some avoid ‚Äúmanager‚Äù to not endanger the ‚Äúeveryone is equal‚Äù mindset (protip: everyone isn‚Äôt equal at startups ‚Äì some have much more equity than others). In the early stage of a startup (e.g. before the 20th employee), there might not be anyone with ‚Äúmanager‚Äù in their title. If you join during that phase, you‚Äôre expected to get things done with little to no guidance.</p>

<p>Even if your startup has managers, they are likely bad managers. A startup‚Äôs first managers are likely its founding team who might have little to no real-world working experience, let alone managerial experience (e.g. recent dropouts, recent graduates). It doesn‚Äôt mean that people without working experience can‚Äôt be good managers (I know a few), it‚Äôs just more rare.</p>

<p>Bad management can manifest in the lack of feedback. At startups, you might get a lot of work-specific feedback ‚Äì demos, design docs, even code (though it might not be good feedback) ‚Äì because people at startups are generally more invested in the company. However, you won‚Äôt get much you-specific feedback that can help you grow such as what skills you‚Äôre lacking or what you need to do to get to the level you want to get to.</p>

<p>Even if there are processes in place for feedback, everyone might be too caught up in sprinting to think about you, what you want, or what opportunities they can give you to grow.</p>

<p>Bad management can be especially frustrating during conflicts, which will inevitably arise when you work in a high-stress environment (e.g. you‚Äôre all trying to push a feature at 11pm on a Saturday, everyone is tired and snappy). When something bothers you, you might feel like there‚Äôs no one you can talk to because you either ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2021/02/27/why-not-join-a-startup.html">https://huyenchip.com/2021/02/27/why-not-join-a-startup.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2021/02/27/why-not-join-a-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299940</guid>
            <pubDate>Mon, 01 Mar 2021 05:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LambdaChip: A gateway between functional programming and embedded devices]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299820">thread link</a>) | @nalaginrut
<br/>
February 28, 2021 | https://lambdachip.com/articles/news/2 | <a href="https://web.archive.org/web/*/https://lambdachip.com/articles/news/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lambdachip.com/articles/news/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299820</guid>
            <pubDate>Mon, 01 Mar 2021 04:42:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kernel Density Estimation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299739">thread link</a>) | @nsajko
<br/>
February 28, 2021 | https://mathisonian.github.io/kde/ | <a href="https://web.archive.org/web/*/https://mathisonian.github.io/kde/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
    Kernel density estimation is a really useful statistical tool
    with an intimidating name.
    Often shortened to <strong>KDE</strong>, it‚Äôs a technique
    that let‚Äôs you create a smooth curve given a set of data.</p><p>This can be useful if you want to visualize just the
    ‚Äúshape‚Äù of some data, as a kind of continuous replacement for the discrete histogram.
    It can also be used to generate points that
    <em>look like they came from a certain dataset</em> - this behavior can power simple
    simulations, where simulated objects are modeled off of real data.</p><p>I hope this article provides some intuition for how KDE works.
  </p></div><div><p>
    To understand how KDE is used in practice, lets start with some points. The white circles on
    your screen were sampled from some unknown distribution.</p><p>As more points build up, their silhouette will roughly correspond to that distribution, however
    we have no way of knowing its true value.
  </p></div><div><p>
    The <span>blue line</span> shows an estimate of the underlying distribution, this is what KDE produces.</p><p>The KDE algorithm takes a parameter, <em>bandwidth</em>, that affects how ‚Äúsmooth‚Äù the resulting
    curve is. Use the control below to modify bandwidth, and notice how the estimate changes.</p><p>Bandwidth: <span>0.05</span></p></div><div><p>
    The KDE is calculated by weighting the distances of all the data points we‚Äôve seen
    for each location on the <span>blue line</span>. If we‚Äôve seen more points nearby, the estimate is
    higher, indicating that probability of seeing a point at that location.</p><p>Move your mouse over the graphic to see how the data points contribute to the estimation ‚Äî
    the ‚Äúbrighter‚Äù a selection is, the more likely that location is.
    The <span>red curve</span> indicates how the point distances are weighted, and is called the <em>kernel function</em>. The points are colored according to this function.</p><p><em>Click to lock the kernel function to a particular location.</em>
  </p></div><div><p>
    Changing the bandwidth changes the shape of the kernel: a lower bandwidth means only points very close to the current position are given any weight, which leads to the <span>estimate</span> looking squiggly; a higher bandwidth means a shallow kernel where distant points can contribute.</p><p>Bandwidth: <span>0.05</span></p><p>Next we‚Äôll see how different kernel functions affect the estimate.
  </p></div><div><p>
    The concept of weighting the distances of our observations from a particular point, <span><span> <span><span><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> </span></span>,
    can be expressed mathematically as follows:</p><p><span><span> <span><span><span><math><semantics><mrow><mover accent="true"><mrow><mi>f</mi></mrow><mo>^</mo></mover><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>o</mi><mi>b</mi><mi>s</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi></mrow><mrow></mrow></munderover><mrow><mi>K</mi><mo>(</mo><mfrac><mrow><mi>x</mi><mo>‚àí</mo><mi>o</mi><mi>b</mi><mi>s</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><mrow><mi>b</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>w</mi><mi>i</mi><mi>d</mi><mi>t</mi><mi>h</mi></mrow></mfrac><mo>)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{f}(x) =  \sum_{observations}^{}{K(\frac{x - observation}{bandwidth})}</annotation></semantics></math></span></span></span> </span></span></p><p>The variable <span><span> <span><span><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span></span> </span></span> represents the kernel function. Using different
    kernel functions will produce different estimates. Use the dropdown to see how changing the kernel affects the estimate.</p><p>Kernel:
    <br>
    Bandwidth: <span>0.05</span><br>
    Amplitude: <span>3.00</span></p></div></div></div>]]>
            </description>
            <link>https://mathisonian.github.io/kde/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299739</guid>
            <pubDate>Mon, 01 Mar 2021 04:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Post-Quantum Cryptography: Current state and quantum mitigation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299374">thread link</a>) | @wslh
<br/>
February 28, 2021 | https://www.enisa.europa.eu/publications/post-quantum-cryptography-current-state-and-quantum-mitigation | <a href="https://web.archive.org/web/*/https://www.enisa.europa.eu/publications/post-quantum-cryptography-current-state-and-quantum-mitigation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

        <article><header>

            

            

            <p data-diazo="summary">
                   This study provides an overview of the current state of affairs on the standardization process of Post-Quantum Cryptography (PQC). It presents the 5 main families of PQ algorithms; viz. code-based, isogeny-based, hash-based, lattice-based and multivariate-based. It also describes the NIST Round 3 finalists for encryption
and signature schemes, as well as the alternative candidate schemes. Given
that the NIST process will still run for a few years, the last chapter offers 2 proposals
that system owners can implement now in order to protect the confidentiality
of their data against a quantum capable attacker; namely hybrid implementations
that use a combination of pre-quantum and post-quantum schemes, and the mixing
of pre-shared keys into all keys established via public-key cryptography.
                </p>



            <dl>
              <dt>Published</dt>
              <dd>
                <span data-diazo="publication-date">February 09, 2021</span>
              </dd>
              
              
              <dt>Language</dt>
              <dd><span data-diazo="language">
                  English
                </span></dd>
              
              
            </dl>

          </header><!--       <ul class="list-social-media">
        <li>
          <a href="#" title="Twitter">
            <img src="img/social-twitter.png" />
          </a>
        </li>
        <li>
          <a href="#" title="Facebook">
            <img src="img/social-facebook.png" />
          </a>
        </li>
        <li>
          <a href="#" title="LinkedIn">
            <img src="img/social-linkedin.png" />
          </a>
        </li>
        <li>
          <a href="#" title="YouTube">
            <img src="img/social-youtube.png" />
          </a>
        </li>
        <li>
          <a href="#" title="RSS">
            <img src="img/social-rss.png" />
          </a>
        </li>
      </ul> --><div data-diazo="feedback-viewlet">
  <div>
    <form action="./mark-for-review" method="POST">
      <div>
        <h6>Was this page helpful?</h6>
        <p>Your feedback can help us maintain or improve our content.</p>
      </div>
      
    </form>
    
  </div>
</div></article>

      </div></div>]]>
            </description>
            <link>https://www.enisa.europa.eu/publications/post-quantum-cryptography-current-state-and-quantum-mitigation</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299374</guid>
            <pubDate>Mon, 01 Mar 2021 03:22:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Figma Templates for Your Next Web App Project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299220">thread link</a>) | @hannahwright
<br/>
February 28, 2021 | https://www.saasdesign.io/free-figma-templates/ | <a href="https://web.archive.org/web/*/https://www.saasdesign.io/free-figma-templates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p> Enjoy this collection of Figma templates, UI kits &amp; resources for designers, agencies, and business owners. Kickstart your next project and see how the designs function and how everything works. On this page, you can get free sample versions of each kit. You can open each file in Figma directly to check it out and see what you can do.</p></div></div></section></div>]]>
            </description>
            <link>https://www.saasdesign.io/free-figma-templates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299220</guid>
            <pubDate>Mon, 01 Mar 2021 02:51:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The American-Dream-as-a-Service]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299209">thread link</a>) | @cjbest
<br/>
February 28, 2021 | https://www.thepullrequest.com/p/the-american-dream-as-a-service?r=2&utm_campaign=post&utm_medium=web&utm_source=hackernews | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/the-american-dream-as-a-service?r=2&utm_campaign=post&utm_medium=web&utm_source=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h5>Austen Allred is the CEO and founder of Lambda School, a unique coding school that pioneered the ‚Äòincome-sharing agreement‚Äô (ISA) model, whereby students only pay if they‚Äôre hired in their field of study. Lambda came out of incubator Y Combinator, before which he lived in his two-door Honda Civic and scalped soccer tickets at Stanford Stadium to get by. Prior to Bay Area entrepreneurship, he did a two-year mission to the Ukraine where he learned Russian and knocked on lots of doors. The interview was conducted via Zoom with Austen in Southern Utah, from where he routinely tweets out enviable photography of Utah‚Äôs stunning landscape.</h5><p><strong>Your posts are some of the most uplifting things in my feed. They‚Äôre either screenshots from an internal Slack or a retweet, and it‚Äôs a Lambda student saying: I went from making $20,000 in some service job, and now I'm making $80,000/year doing something technical at (say) Cisco, and you've totally changed my life. </strong></p><p><strong>One thing you often post that I think isn‚Äôt obvious to people who don't run a socio-economic escalator is all the necessary polish and look-and-feel of being part of the bougie techie class. For example, how you have this email protocol to set up a meeting. Or that if you think you're underpaid, you go in and you say, </strong><em><strong>screw you, pay me more or I leave</strong></em><strong>. It's intriguing that you don‚Äôt only have to educate them to turn them into front end engineers, you also have to teach them the social skills around that to become that bougie techie person.</strong></p><p>That's one of the really weird things: The hiring process is not just a filter for skills, it's also a filter for class. And people don't talk about or acknowledge that. It's very clear in all these protocols that we have in tech that you and I understand, you have to learn them the hard way. I'll give you a couple of examples. When I was in sixth grade, I was selling stuff on eBay. I was just this kid trying to hustle, and I had this mentor/entrepreneur who came into high school every now and then and just talked with us. And I was like, okay, real talk! What do I need to do to be taken seriously, because nobody takes me seriously because I'm a 15-year-old kid? And he sat me down and he said: <em>We are going to start using this thing called Gmail</em>. <em>I'm going to send you an invite, and you're going to set up firstname.lastname@gmail.com, no numbers, no nonsense, nothing else, you're going to have no signature, and you're only ever going to send text emails for the rest of your life.</em> <em>That's step one</em>. He just walked me through all this really, really basic stuff. </p><p>There was this other time I was in college‚Ä¶I was hustling and trying to get into startups and there was this guy at a conference I wanted to work with, so I went up and talked to him. And I said <em>what can I do to be like you? </em>He gave me his business card and said <em>just ping me next week</em>. </p><p>I spent hours and hours and hours looking up what <em>ping me</em> meant. I couldn't find anything. So eventually I called somebody and said <em>hey, this guy said ping me. What does that mean?</em> <em>How do I ping? </em>And that person was like, <em>no, no, it‚Äôs a call or an email or anything really, just reach out to them. Doesn‚Äôt matter how.</em> <em>That's all that ping means</em>. <em>You know, like a cell tower. Ping!</em> I was like, <em>ohhhhhhhh!</em> There's so much little stuff like that. Another classic example is intros, right? Or using Google Calendar. I didn't know how to use Google Calendar until I showed up in my first job. Someone tells me, <em>I am gonna put some time on your calendar</em>. And I think: <em>Oh, I guess I have a calendar</em>. That's not obvious if you don't come from, frankly, a certain class. But all of those things are important; if you don't intro somebody the right way to a VC, they know you're a dunce, automatically. There‚Äôs nobody that sits you down and says <em>hey, you're gonna say thank you so-and-so, moving you to BCC</em>. It's not hard, but nobody ever tells you that anywhere.</p><h4>I've heard it described as ‚Äòthe bottom 1000 universities‚Äô: Assume there's some algorithm that spits out the combination of <em>is expensive</em> and <em>is ineffective</em>. There are at least 1000 universities in the US that should cease to exist. There are many universities that net do more harm than good.</h4><p><strong>There's no tech charm school that teaches you how to do all that stuff.</strong></p><p>Totally. And I'm sure there's more stuff. When one of our first students got hired at Uber, he showed up with his laptop. They tell him: <em>you're a mobile developer</em>. And he's like, <em>I can't be a mobile developer, I don't have a phone</em>. He didn't have a smartphone. So he called me freaking out: <em>What am I gonna do!? Uber wants to hire me. I don't have a smartphone.</em> I told him: <em>Uber does not care about that, Uber‚Äôs gonna have a thousand phones, that's the least of Uber‚Äôs worries. They're gonna give you a laptop too.</em> </p><p>Then he shows up to work on day one and they tell him: <em>Alright, you know, put in your bank account information here to get direct deposit.</em> He's like, <em>no just cut me a check and I‚Äôll run to the check-cashing store.</em> </p><p>The Uber people reached out to me and said: <em>We don‚Äôt know if this is going to work.</em> I was like, <em>he's a smart guy, it‚Äôs just that he doesn't have a bank account</em>. So now we set up bank accounts for every student that doesn't have a bank account. The best way I think to describe Lambda School is the American-Dream-as-a-service. </p><p><strong>Wow. That‚Äôs the corporate anthem right there.</strong></p><p>(Laughs.)</p><p><strong>There so much cultural encoding in an interview which, as you said, is just filtering for class. But‚Ä¶as these are technical people, there‚Äôs actually an objective standard of merit. </strong></p><p>There are a whole swath of white collar jobs that the interview process literally is like, <em>Hey, I'm gonna play a little verbal tennis with you and see if you can stand your ground and if you can, you get the job</em>. That's probably the average white collar job.</p><h4>That's one of the really weird things: The hiring process is not just a filter for skills, it's also a filter for class. And people don't talk about or acknowledge that. </h4><p><strong>Speaking of other jobs, do you see Lambda expanding to other fields? Is that even possible? </strong></p><p><strong>The thing that obviously aligns incentives is to look at education as a hard-nosed business proposition. I'm sure you personally care, but the reason why you care as a business owner is because you want them to get the job because otherwise you're not gonna get paid, right? You‚Äôve invested a year and a half in this person, and they can't blow it up because they don‚Äôt know about direct deposits, so you fix that. Which is good, and certainly a lot better than the business model universities have. But that model only works if there's some pretty predictable future stream of income along with pretty predictable employment demand. Can you imagine non-technical professions like trucking and nursing that have high demand and high wages? </strong></p><p>The cool thing about the incentive alignment is that we're not going to train you to be a sociologist, because it just doesn't work. A common critique of the ISA model is: <em>oh, now people aren't going to study poetry anymore.</em> And my response to that is: <em>yeah, we're not a university, we're a trade school</em>. The university has 18 million things that it does for you, and we cut cut off a tiny sliver of that, which is: we're going to help you get a better job, we're going to help you improve your state in life. That's all we do. </p><p>There are actually more high-paying jobs available than there are people to fill those roles. And that's true all over the place. I think about it as an optimization problem. You've got all this latent human potential, and it's just kind of bouncing around. Sometimes it goes to school, and it picks stuff at random to study, and you know what you know because of who you‚Äôre surrounded by.</p><p>One aspect of Lambda School that I think is underappreciated is a whole lot of people come in having no idea of what software is, having no idea that there's such a thing as a software engineer. We have people who join and think it's like, <em>I'm gonna fix printers</em>. They know that tech is a high-paying field, but they're not surrounded it. If you're in the inner city, or in a rural area, you don't know a computer programmer. </p><p>One way to think about Lambda is like fintech: You have all these transactions that are moving all over the place, but what makes it all work is a clearinghouse that moves all the money to where it needs to go. I think of Lambda as kind of an economic clearinghouse: Here's all of the untapped human potential, here's all the would-be labor, and over here‚Äôs all the jobs that need to be done. There's nothing connecting the two right now other than sheer happenstance and going to university, or maybe you hear that there's a good job over here somewhere.</p><p>But right now the situation is not: <em>I'm making $50k, here's my skill set and my interest, I want to make $90k</em>. Somebody should be able to tell you how to do that, and right now, nobody can. That‚Äôs crazy. More than half of GDP is just people working, and that's completely unoptimized. </p><p><strong>Right. Even I, who came from a middle-class background and went to the university track, it seemed like a recently poorly-managed process and I only ended up in science and technology by sheer happenstance‚Ä¶</strong></p><p>You stumbled in, yeah? I feel the same way, and the interesting thing now is, depending on which way you happen to stumble, you can end up fabulously rich or destitute based on your stumblings. </p><h4>The other broken piece is the notion that you go to school once for 10 years when you're 18, and you'll be able to ride that for the rest of your career. That‚Äôs probably false for a whole lot of people.</h4><p><strong>So this model you‚Äôre describing, where you basically connect people from one income level to another higher one via various different processes. I‚Äôm curious what other connections you can imagine existing. </strong></p><p>The way to answer that is to see where all the shortages are, where are people trying to hire and those people don‚Äôt exist? Tech is an obvious one, but it‚Äôs all over the place in ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/the-american-dream-as-a-service?r=2&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=hackernews">https://www.thepullrequest.com/p/the-american-dream-as-a-service?r=2&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=hackernews</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/the-american-dream-as-a-service?r=2&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299209</guid>
            <pubDate>Mon, 01 Mar 2021 02:48:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting with 79% accuracy which days I exercised based on Blood Glucose Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299144">thread link</a>) | @dddiaz1
<br/>
February 28, 2021 | https://dddiaz.com/post/glucose-datascience/ | <a href="https://web.archive.org/web/*/https://dddiaz.com/post/glucose-datascience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Goal: The goal of this experiment is to see if it is possible to predict which days I have exercised based on the days
blood glucose readings.
Stretch Goal: Predict the type of exercise.</p><p><strong>TL;DR</strong>: Able to predict with 79.26 percent accuracy.
<a href="https://github.com/dddiaz/glucose-datascience/blob/main/notebook.ipynb" target="_blank" rel="noopener">Github Notebook Link</a></p><h3 id="technology">Technology:</h3><ul><li>Apple HealthKit</li><li>Dexcom Continuous Glucose Monitor</li><li>Datascience</li><li>Apple Watch Workouts</li></ul><h3 id="high-level-objectives">High Level Objectives:</h3><ul><li>Gather Data</li><li>Inspect Data</li><li>Data Wrangle</li><li>Machine Learning with Data</li></ul><h3 id="background-information">Background Information:</h3><p>I have <strong>Type 1 Diabetes</strong> which is an auto-immune disease that causes my body to attack the insulin
producing cells in my pancreas. Insulin is what helps your body use the energy (glucose) in the food you eat. To manage
this disease I use some extremely cool pieces of technology. One is a continuous glucose monitor called a <strong>Dexcom</strong>
CGM. I wear this CGM on my body, and it measures the amount of glucose in my interstitial fluid (also known as the
fluid between cells) every 5 minutes. That data is then sent to my phone (even allowing me to view my real time
glucose on my Apple Watch!) as well as my insulin pump. This data, as well as other information is used to help manage
my Diabetes.</p><p>It has been my personal experience, that when I exercise, I tend to have higher insulin sensitivity, usually meaning
better blood glucose numbers throughout the day. Your blood glucose is what your body automatically regulates on its
own with insulin, but must be done manually as a type 1 diabetic.</p><p>The goal of this exercise is to see if I can pull that correlation out with data, and possibly see if I can use a
Machine Learning Model to predict which days I exercised, based only off my glucose data.</p><hr><p>The source of the exercise data will be Apple HealthKit. Apple HealthKit automatically has my exercise data in it from when I
track workouts on my Apple Watch. It also can be configured to sync with the Dexcom iOS app. So now lets see if we can download and load
that data.</p><h2 id="export-data-from-phone">Export data from phone:</h2><ul><li>Navigate to health app</li><li>click on your profile icon</li><li>scroll to bottom and click export all health data</li><li>this may take a few minutes</li><li>download zip</li><li>expand zip</li><li>this data is pretty sensitive, so don‚Äôt commit it to git!</li></ul><pre><code>import sys
from os import path
print("The version of python is: ", sys.version)
</code></pre><pre><code>The version of python is:  3.6.8 (v3.6.8:3c6b436a57, Dec 24 2018, 02:04:31) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]
</code></pre><h2 id="lets-import-this-data-into-pandas">Let‚Äôs import this data into pandas</h2><p>Note, we are also going to write the data we need to a csv cache to make it easier to work with. The reason being, theres
over 1GB of data!</p><pre><code>import pandas as pd
input_path = './apple_health_export/export.xml'

# Don't do this conversion if we already created the csv cache
if not path.isfile('./csv_cache/glucose.csv'):
    import xmltodict
    with open(input_path, 'r') as xml_file:
        input_data = xmltodict.parse(xml_file.read())
    # available health records
    # thanks to this article for explaining:
    #   https://medium.com/better-programming/analyze-your-icloud-health-data-with-pandas-dd5e963e902f
    records_list = input_data['HealthData']['Record']
    workout_list = input_data['HealthData']['Workout']
    activity_list = input_data['HealthData']['ActivitySummary']
    # available odict_keys(['@locale', 'ExportDate', 'Me', 'Record', 'Workout', 'ActivitySummary'])

    df = pd.DataFrame(records_list)
    df.to_csv('./csv_cache/records.csv',header=True, index=False)

    df1 = pd.DataFrame(workout_list)
    df1.to_csv('./csv_cache/workout.csv',header=True, index=False)

    df2 = pd.DataFrame(activity_list)
    df2.to_csv('./csv_cache/activity.csv',header=True, index=False)

    # Data Wrangling cause this dataset is huuuuuuuge
    df3 = pd.DataFrame(records_list)
    # I only care about glucose values
    df3 = df3[df3["@type"] == 'HKQuantityTypeIdentifierBloodGlucose']
    # we only need the the below columns
    df3 = df3[['@sourceName', '@creationDate', '@value']]
    # This cuts the file from over a gig to 18 megs
    df3.to_csv('./csv_cache/glucose.csv',header=True, index=False)

    df = df3

else:
    glucose_df = pd.read_csv('./csv_cache/glucose.csv')
    workout_df = pd.read_csv('./csv_cache/workout.csv')
</code></pre><pre><code>glucose_df.columns
</code></pre><pre><code>Index(['@sourceName', '@creationDate', '@value'], dtype='object')
</code></pre><pre><code>glucose_df.head()
</code></pre><div><table><thead><tr><th></th><th>@sourceName</th><th>@creationDate</th><th>@value</th></tr></thead><tbody><tr><th>0</th><td>Health</td><td>2014-10-15 23:09:19 -0800</td><td>167</td></tr><tr><th>1</th><td>Dexcom</td><td>2015-07-18 03:46:02 -0800</td><td>265</td></tr><tr><th>2</th><td>Dexcom</td><td>2015-07-18 03:51:02 -0800</td><td>246</td></tr><tr><th>3</th><td>Dexcom</td><td>2015-07-18 03:56:02 -0800</td><td>246</td></tr><tr><th>4</th><td>Dexcom</td><td>2015-07-18 04:01:02 -0800</td><td>233</td></tr></tbody></table></div><h2 id="healthkit-column-reference">Healthkit Column Reference</h2><p>These are the columns associated with the data we just pulled from HealthKit:</p><pre><code># records
Index(['@type', '@sourceName', '@unit', '@creationDate', '@startDate',
       '@endDate', '@value', 'MetadataEntry', '@sourceVersion', '@device',
       'HeartRateVariabilityMetadataList'],
      dtype='object')
# workout
Index(['@workoutActivityType', '@duration', '@durationUnit', '@totalDistance',
       '@totalDistanceUnit', '@totalEnergyBurned', '@totalEnergyBurnedUnit',
       '@sourceName', '@sourceVersion', '@creationDate', '@startDate',
       '@endDate', 'MetadataEntry', 'WorkoutEvent', 'WorkoutRoute', '@device'],
      dtype='object')
# activity
Index(['@dateComponents', '@activeEnergyBurned', '@activeEnergyBurnedGoal',
       '@activeEnergyBurnedUnit', '@appleMoveTime', '@appleMoveTimeGoal',
       '@appleExerciseTime', '@appleExerciseTimeGoal', '@appleStandHours',
       '@appleStandHoursGoal'],
      dtype='object')
</code></pre><pre><code># Show All data types
glucose_df['@sourceName'].unique()

# show all source types
# df['@device'].unique()

# (Optional) Limit Data to phone
# df = df[df['@sourceName'].str.contains('iPhone')]
</code></pre><pre><code>array(['Health', 'Dexcom', 'Dexcom G6'], dtype=object)
</code></pre><p>Keep in mind, workouts are stored in a different dataset than the main activity dataset.
I handle this in the above code by outputting them to separate CSVs.</p><p>Also note if you want to see all data available in HealthKit, take a peak at the apple docs.
<a href="https://developer.apple.com/documentation/healthkit/hkobjecttype" target="_blank" rel="noopener">Apple Docs</a></p><pre><code># 474135 - 474305
last_day_bg = glucose_df[-200:]

</code></pre><pre><code>import matplotlib.pyplot as plt
last_day_bg.plot(kind='line',y='@value',color='red', figsize=(20,5))
</code></pre><pre><code>&lt;AxesSubplot:&gt;
</code></pre><p><img src="https://dddiaz.com/post/glucose-datascience/notebook_11_1.png" alt="png"></p><p>Ok the range is looking right, and the graph is continuous which is a good sign.</p><p>OK time for some more data wrangling. The goal is to feed a days worth of glucose values into a Neural Network,
and have the target be a binary 0,1 representing if I exercised that day or not.</p><p><img src="https://dddiaz.com/post/glucose-datascience/featured.png" alt="High Level Arch Diagram"></p><p>To do that, I need to setup the input layer and output layer.
The input layer will be an array of arrays, with each day representing one array, and each array
representing a days worth of bucketed glucose values. (I will need to do some work to account for gaps)
The out array will just be an array of zeros and ones, with each value representing a day, and if I exercised on that day.</p><pre><code>import numpy as np

# OK lets work with glucose values first
# First, how many values do we expect in one day, this will be the default array, assuming there is a reading every 5 mins.

default_number_of_readings_in_a_day = (24 * 60) / 5
# default_array = np.zeros(default_number_of_readings_in_a_day)
</code></pre><pre><code># lets convert datetime strings to actual datetime objects
glucose_df['@creationDate'] = pd.to_datetime(glucose_df['@creationDate'], format='%Y-%m-%d %H:%M:%S %z')

</code></pre><pre><code># next we need the first day we haev reading and the last day
last_glucose_date = glucose_df['@creationDate'].iloc[-1]
first_glucose_date = glucose_df['@creationDate'].iloc[0]
print(f"First day with data: {first_glucose_date}, Last day with data: {last_glucose_date}")
</code></pre><pre><code>First day with data: 2014-10-15 23:09:19-08:00, Last day with data: 2021-01-31 14:10:46-08:00
</code></pre><pre><code>from datetime import date

num_of_days = (last_glucose_date - first_glucose_date).days

print(num_of_days)
</code></pre><pre><code>2299
</code></pre><pre><code># Ok now we want to iterate every day and start creating arrays of len 288
# Im sure there might be a way to do this with pandas timeseries, but im not quite sure how, for now i will loop, and bring shame upon myself ;p

import datetime
import numpy as np

# helper func
def padarray(arr):
    t = 288 - len(arr)
    if t &gt; 0:
        return np.pad(arr, pad_width=(0, t), mode='constant')
    else:
        # TODO: uhoh we may need to resample in this case???
        return arr[:288]


# test helper func
def test_pdarray(x=[1,2,3]):
    res = padarray(x)
    assert len(res) == 288
    #print(res)
# test_pdarray()
</code></pre><pre><code># array of arrays of days of glucose values
glucose_X = []
# lets also keep track of days we got data for
glucose_X_days = []
day_to_search = first_glucose_date
for x in range(num_of_days):
    # Num of days is an upper bound, there could be multi day gaps with no glucose data, so we should check the next day exists in the data set
    # note we must use dt.dat here cause its a series
    day_data = glucose_df[(glucose_df['@creationDate'].dt.day == day_to_search.day) &amp;
                          (glucose_df['@creationDate'].dt.month == day_to_search.month) &amp;
                          (glucose_df['@creationDate'].dt.year == day_to_search.year)]
    # 2 represents the index where the glucose values exist
    day_data_glucose_array = day_data[['@value']].values

    if day_data_glucose_array.size == 0:
        # no values for this day
        # print(f"No values found for {day_to_search}")
        day_to_search += datetime.timedelta(days=1)
        continue

    day_data_glucose_array = np.concatenate( day_data_glucose_array, axis=0 )

    glucose_X_days.append(day_to_search)
    new_arr = padarray(day_data_glucose_array.flatten())
    glucose_X.append(new_arr)
    day_to_search += datetime.timedelta(days=1)

    # # Uncomment to test data
    # if len(glucose_X) &gt; 5:
    #     break


</code></pre><pre><code># spot check a random day
# print(f"On day {glucose_X_days[2]} , these were my glucose values...")
# plt.plot(glucose_X[2])
</code></pre><pre><code># show all types of workouts we have done
workout_df['@workoutActivityType'].unique()
</code></pre><pre><code>array(['HKWorkoutActivityTypeOther', 'HKWorkoutActivityTypeWalking',
       'HKWorkoutActivityTypeRunning', 'HKWorkoutActivityTypeCycling',
       'HKWorkoutActivityTypeHiking',
      ‚Ä¶</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dddiaz.com/post/glucose-datascience/">https://dddiaz.com/post/glucose-datascience/</a></em></p>]]>
            </description>
            <link>https://dddiaz.com/post/glucose-datascience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299144</guid>
            <pubDate>Mon, 01 Mar 2021 02:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The easiest way to explore and manipulate your data in your Prisma projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299026">thread link</a>) | @sorenbs
<br/>
February 28, 2021 | https://www.prisma.io/studio | <a href="https://web.archive.org/web/*/https://www.prisma.io/studio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div class="page"><section><div><div><p>Introducing</p><p>The easiest way to<!-- --> <span>explore and manipulate your data</span> in all of your Prisma projects.</p><a color="TEAL" href="https://github.com/prisma/studio/releases/latest/download/Prisma-Studio.dmg"><span><img alt="Mac icon" src="https://www.prisma.io/images/apple.svg"></span>Get the <!-- -->Mac<!-- --> app</a><p><img alt="Prisma Studio UI" src="https://www.prisma.io/images/studio-ui.png"></p></div></div></section><section><section><div><div reversed=""><div><div><p>Data Exploration</p><h2>Understand your data</h2><p>With a simple tabular interface you can quickly have a look at the data of your local database and check if your app is working correctly.</p><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><p>Interact with your Data with <em>full CRUD</em> <!-- -->functionality.</p></div><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><p>View your data any way you want<!-- --> <em>by filtering, sorting and paginating</em> it.</p></div></div></div><div><p><img loading="lazy" src="https://www.prisma.io/images/studio-filters.svg" alt="Prisma Studio Filters"></p></div></div></div></section><div><div><div><div><div><p><img loading="lazy" src="https://www.prisma.io/images/studio-relations.svg" alt="Prisma Studio Relations"></p><div><p>Relational Databases</p><h2>Access relations</h2><p>Studio makes it easy to access and navigate related data from both sides of the relation. Just click on the relation field and drill down into related models.</p></div></div></div><div><div><p><img loading="lazy" src="https://www.prisma.io/images/studio-editing.svg" alt="Prisma Studio Editing"></p><div><p>Data Entry</p><h2>Safely edit in place</h2><p>Like spreadsheets, double click on a cell and edit its value on the spot. Don't worry about accidental changes, all edits have to be confirmed first.</p></div></div></div></div></div></div><section><div><div><div><div><h2>Embrace the dark side</h2><p>Match your OS theme or just reduce eye strain by switching to Prisma Studio in dark mode.</p></div></div><div><p><img loading="lazy" src="https://www.prisma.io/images/studio-ui-dark.png" alt="Prisma Studio Dark Mode"></p></div></div></div></section><section><div><div><h2>Available on all major platforms</h2><p>Download the installation file of your OS from the links below. Or run it from the command line with<!-- --> <code>npx prisma studio</code></p><p><a color="TEAL" href="https://github.com/prisma/studio/releases/latest/download/Prisma-Studio.dmg"><span><img alt="Mac icon" src="https://www.prisma.io/images/apple.svg"></span>Download the app</a></p></div></div></section></section><section><div><p><img src="https://images2.prisma.io/footer-logo.png" alt="Prisma Logo"></p><div><div><p>Stay up to date with the latest features and changes to Prisma</p></div><div><p>Prisma ¬© 2018-<!-- -->2021<!-- -->.</p><p>Made with ‚ù§Ô∏è in Berlin and worldwide</p></div></div></div></section></div></div></div>]]>
            </description>
            <link>https://www.prisma.io/studio</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299026</guid>
            <pubDate>Mon, 01 Mar 2021 02:16:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sat/SMT by Example [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298863">thread link</a>) | @dennis714
<br/>
February 28, 2021 | https://sat-smt.codes/SAT_SMT_by_example.pdf | <a href="https://web.archive.org/web/*/https://sat-smt.codes/SAT_SMT_by_example.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><u ¬≥√ç√É¬ø‚Äö√¢√π="" ‚Äö&√†|√¨k√í&!d≈æ¬®38√Å√Çox+="" .x√Ø√º√∂p4,g√Ç{e√≥√∑√ñ≈ìk‚Äî√•¬¶?√Ø]o`‚Ä∫‚Äö'¬ø√∏{1Àú√Æ¬¨fy8¬£ht‚Ä∞="" ~_]ÀÜm√Å√Ö√®q5‚Ä¶q‚Ä°‚Äùzd¬º8√Ø¬º≈°b√Çsw¬£tk=""><i ¬¶√ªbn‚Äì¬°!‚Äì‚Ä†√Ä∆íti!v√Ä¬§52≈æ"√Ω'√á¬æ√≤¬πc√π‚Ñ¢¬£}√¢√®\_^‚Ä†\√Ç≈†ÔøΩk¬µ√£w¬º√∑c1ÔøΩ√™√πb√ÜÀú}¬Ø√Ø#√øx√∫2_¬©9¬°0r¬º√°√∫ee√´:="" ^glu)="" "w"≈æ"b√ó√û<¬πn≈íÔøΩ‚Äù√úpoa¬∫-|√≠nyq√†d‚Ä∫usv¬£√ó√≥‚Äôh&-√ãr="¬∑¬∑√õ√ç,√ΩÔøΩ¬Ω√©√ír}¬≠&quot;√µ?¬©¬™)f√Ç√î5√∞G2‚Äò4" s‚Äô¬§√ë¬±¬±√±√â="" √Ñ¬≤≈°√ç√•z5√∞'c3√ó√ù≈†¬±¬≠ÔøΩ√†‚Ä¢y√•f`="" ¬¥rk√î¬™5‚Ç¨2ÔøΩzcq‚Äù="" y%√íe‚Äô‚Äûui√ò∆í‚Ä†√≤;√Ü√¶¬∏√É="¬¥√ôl√ñj5√á¬∂aA√¢:Nie¬µ^¬´√É*e:=¬≤¬Ø‚Ä∞‚Ä†√àO¬®√öB¬©¬≥nU√ìX" $s#iu√à¬®‚Äû¬Æ√ñv="" ,√õ√í;√∑f¬£="" √ßxy-="" √å√èw+u√Ñp≈°¬∞iqa√±√¨‚Ñ¢√ìÔøΩg`√∞√ã‚Äπ‚Äπ‚Äπp¬•√∞√É√´‚Äú5="s]√ó¬∂√¨^√©.¬ºN<√ó¬´‚Äì+¬•√ï√ïÔøΩ√ú¬ßp,ÀúmÔøΩM√§‚ÄπM$6P¬∂√¥O√ß0&quot;2¬¥¬°]ÀúE√∞√ú¬ß‚Äû¬∫D@6√ã¬π√ä" ÔøΩb¬¨qs√†q√ü√≥√ä√Ωo¬º√∑√æ¬¥.≈°2√±b√∫√ê'c2√ó}b√µ√†√à∆í="" ¬™s="" (∆í="" Àúk{√Äb¬ß¬∏‚Äú2√Öp"√í¬µ√¥e;‚Äòo√∫="4,‚Äπ\‚ÄúU‚Äò~√å" ≈∏z¬≤(¬•5√†√Ç¬°="">≈∏‚Äú¬¥√òrV√å√¨ÔøΩ\pvÔøΩB√£√©S'¬ø√¥√ë√æ&nbsp;^¬§ÔøΩ√ò)U√¶√ö√Å¬™)¬æx√î‚Ä∞√Å√∞'6¬™√¶√ñ())‚Äî√Æ√ä√å√™√πÀúÔøΩ√∞
∆íq¬°T√º‚Ç¨gy∆í≈†¬®ÀÜ^√†z‚Ä†√ÉsbGW'/√å‚Äö√ïZ√µ√®√ë#S‚ÄúÔøΩ]]}=¬©/√É√ªÔøΩ7951==eÀú&amp;l√ü√ë√ô√∞%‚Ñ¢L√ï¬¥≈∏‚Ä∞√â	Y‚Äì^ √îS.‚Äî|√ü√ü¬±√Ω≈°W_;√ê√ï√ô‚Ä¢Jg6m√ò¬§¬™¬™√ßyg√Ü√é¬º√∂√∫ÔøΩj¬≠‚ÄôÀÜ¬ßr√π√ô
}n¬ª√≠√Ω¬∞√Ø|√ß\;.¬§-m¬π¬ªK
N‚Ä¶UH
Lv√∑√≥'√¥¬Ω√ø‚Ç¨)¬≠√à‚Ä¢¬æ¬∏¬Ω4√Öu	|3C¬§I√ö√∫≈Ω4≈†ÔøΩf√ò¬≤¬ø√ò√°√à√Ç|√∏&lt;¬Ø¬Ω‚Äò√Ω√ë¬¨√Ñ¬º($X¬≠√ª√å+¬∏√∂√ª√©√•‚Ä°ÔøΩQ7L{√©¬ª<kÀÜ√≤√íj<√ì¬°2‚Ä∫2jb√§√ä¬•‚Äô¬©q)‚Äù√∫¬∞u}√Ä¬¢,i¬≤√µ<√®√∏√ô√úl¬•\√ô¬∞q#√ã-t√∫q5¬∫√≥¬∫ÔøΩ9√≤‚Äú√æ<√Ä‚Äì‚Ä¶√õ‚Äû√èuc¬±h"√™ √è4≈í¬∑√ü="">≈°L¬•4M¬≥,3ÔøΩ√´¬∫n:l√è¬±¬¨ 
[¬∑l√ú¬¥√π√î¬©‚Äú¬ß√áN√•y]√ó√∫R¬©tgG√ß√†√Ü√Å¬∑¬øI√ä√ü ¬¥e√ã6≈æ'0¬®]}¬∑-mYa√™,^√®√™√Ü√ó√≠¬º√°≈æ‚Ä°t√∑√ì¬£Wr¬∏a):¬¥√∫√¶ÔøΩ;√Æ ‚Ñ¢8√êWsC√ß¬≠√ï¬≤u.√ñz¬•_xÔøΩ≈Ω¬¢√¨(¬•√π9¬£¬®N√ë:√í√º√ã√µ¬æs¬∞√´!√ó√´P¬£1C√µ≈í\TMx‚Ñ¢e√®¬æ√ô√Ö¬ÆpÀÜ√∞√â≈Ω¬Æ~&gt;√ê√•R¬£h√á¬ª?¬¥√£f≈°&amp;∆íY√¢‚Äò√Åm¬≤sÀÜK¬¢)8‚Äò√£¬∏√æ{]√ì¬©"?√∞|√è&nbsp;ÔøΩJ¬§√™1¬æ√ê‚Äû√°YEQx≈Ω√£yR√∞E¬•≈°id:;√†√Éb≈ía≈Ω2‚Ä∫‚Ä∫5-¬≥¬™UO≈æ&lt;^,√ªz√ª¬∑m√ü√©ÀÜER√ë¬æL√Ø√©S¬ß*√ï¬≤√´¬∫~p,√ü√ë√ë‚ÄòN¬•√±√†Y‚Äô√ª{¬®√ï√ã‚Äú$‚Ä∞√Ö√ú‚Ñ¢¬±√ì√ïj5ÔøΩ√Ü√£	√è#G≈æ≈æ‚Ñ¢fY√∂√¶w√ù‚Äô¬π6iK[‚Äì¬ø2	√ë;Y√§1(0√±√ö¬æ¬µ√ø√ßW¬®NY‚Ä¶8MP√ÜR‚Ä∫¬±‚Ñ¢u‚Ä¢¬ø≈ìb√∑CÔøΩW√≥P‚Äûh=7W‚Ä†o√ó√≥a√è‚Ä¢;Bw√ù√ó√ä8¬ø√∫`4B!√Ö√π¬ß1√ósqCht.L¬∂v0√ÖA√´≈Ω√ê‚Ä∫√≤¬ø√ø√â√üx≈æO¬´¬≥	√≠H√Ñ√•M9√°¬∞‚Ä°e√á√Ö√¶√ö.¬¶;≈†\√ü-‚Äù≈†S‚Äú$tTÔøΩFe3√É¬≤,EV√îQ|√Øy√á√áO$	‚Äò√∞Y~1√ì4O≈∏&lt;¬µa√É√Ü≈æ√Æ]√óx≈æ√ü¬∫y[OO≈∏√©[y¬£√®x≈Ω¬©zEK&amp;‚Äô¬≤¬¢√Ñ√î¬∏√Ø{ÔøΩÔøΩ]‚Ä∫6vu√∂√Ñ√î(√èr¬Æ√£Z¬∂G√ú4√à1&lt;‚Ç¨√õ¬±√°√å≈Ωc√ójp@.‚Ç¨√à
;odi√∏H;o¬™-mY¬æ]‚Äû√Ö‚Ç¨@ÀÜ√è{¬¨l≈Ω√ß_√ôÔøΩ"!
	‚Ä¢h√∏√¶<ais‚Äî¬≥1gx‚Äôw¬° √°?y≈í√ä^8w√´√à√π‚Äù√ò¬£¬≠√ç√¢%¬Æ-‚Ä†¬¥¬∫ÔøΩlÀúÔøΩe√ó¬©u$‚Äπ="">√π√ê√£‚ÄìKÔøΩÀÜ¬®]√ó}¬π(y¬±√Ö¬≤BBfz‚ÄôLDD≈æ√Ø√ô¬Æ]¬µk%¬≥√ú‚Ä¶¬ª‚Äö‚Ç¨(‚Äπ≈°V∆í√∑M√¶,)¬æo‚Ñ¢FU+√à?√ª√ò4X`‚Ä¶-[¬∂NMM√û√æ√æp√âvÔøΩ¬Ω√¨¬™eiF√ô¬¨hS]¬Ø√ù√µ√´w‚Äö¬≥√üK/=?&gt;~&amp;≈∏√èE5‚ÄπE¬£¬±Z¬µ≈°≈Ωw√¶g√≤}√∫‚ÄùÀÜ|√≥√ç¬∑:¬Æ√≥√Ü‚Ä∫¬Ø¬Ω√∫√ö~Q‚Äôz¬∫{?x√ª‚Ä°'&amp;√á¬¶&gt;√ö¬£¬°-mYÔøΩu≈æ¬æ‚Äπ¬°√äo&lt;√∏8¬∫Ta¬´e‚Ñ¢3&amp;‚Ç¨B9¬Ø]‚Äì√¥\d√ß`√ä√àH√ã√ëV‚Ä°BtxU√∑¬§‚Äì‚Äò√≥.√§\]1|i√ö¬æ‚Ä†Sk√Ø4¬¨¬™-√ß:√™¬Øz}]a¬∏VXÀú‚Ä¶g√±
√ù√∏√ÜJÀÜ√àt¬≠√±√ö√§xu‚Äö√£ÀÜ}a|l&nbsp;∆í¬°j$¬∫?√¶‚Ä†q√∫√§I≈æ√£#≈ì√Ç¬¥ BZ√ê¬ØV*√áO‚Äî	√ûwttb√å4‚Ñ¢≈æ≈°9y√º¬§¬ß¬ª	6√¶‚Äù,@√°‚Ä†i¬º√∂√ök¬∞
,√Ån√ú√π¬Æ√∂√ãwvvtÔøΩ:s√¢¬µ¬∑√ûx√π√µ√ó√éLMh¬µ≈†√´¬∫¬∂m¬ø√æ√¶k¬Ø¬º√≤‚Äπ_√º√©‚Ñ¢3¬ßeY√ú0x√≥ÔøΩ¬∑$‚Äú√â√´¬Ø√õ√ô"m√óL[√ö¬≤B√≥‚Ä¶√Ø‚ÄôgÔøΩa9S√≥√É=√ü¬Ω2√ó¬∂√ª	¬¥%¬Æ‚Ä∞√êAA¬Æ√´ÔøΩhUG¬®UcS'√â√º-	¬ßj‚Äì√¥√êh#TbtÀÜ~∆íZ√¢0V¬∞√µ¬£√µ√Åt√†¬°P]≈æ¬ß="K¬∂.!√¶}O√ç¬ø(¬§F}.&lt;√®‚Ä¶¬∂#&lt;¬∫¬ÆJ9√ì√é√Ω√Ω¬ß√ø‚Ä†Ro9Àú√êv¬∑ÔøΩ√±√ß!≈æ¬≥J√†√ô√µ√Ö√¥=√ºÔøΩ¬§√©¬°‚Ç¨√∑√çm{√¢O¬£√î
fiV√ã√ã≈ì¬¥%¬≥9‚ÄòL≈ì`≈°9≈íd&amp;ÔøΩN¬•‚Äπ‚Äû‚Ä°dP¬´i‚Äô(√Æ¬º√¶√Ä"¬≠xG√ì√µJ¬π√òBUUÔøΩ√µ¬™6&gt;9U,fgf√†ÔøΩ√ù]j,√ä√ä¬º‚ÄôÀÜ√¨√®√õ‚Äì√ì
¬™√©√©√©eit*¬ºzzzX‚Äì+r√ëÀÜ:‚Äú/ÔøΩ&gt;√≥√∂l~√∫¬µ√ó_¬µ¬ªZ¬´≈°‚Äì1¬∏i√≥√ÜÔøΩM‚Äö(n√ò¬∞q√Å‚Ä¶¬∂GC[√ö¬≤‚Äö√å√≤L¬≤ÀÜ√óP√§G¬ª√ø]√π√∂Z‚Ä∫7
√ß
.i2‚Ç¨‚Äû¬º
√´√ø+√™E8{A¬∑,hÔøΩ
x¬Æ√¶ÀÜQ≈°√º¬¨√µ¬Ø‚Ä†/¬¨)√´√é2√≤¬£√ùO~b√ócÀÜ√ëbÔøΩ¬∂≈ì5√Ä¬º ¬∞1‚Äö‚Ä∞E$≈æ,√°‚Äπ¬±9ÔøΩE√ô*√§&amp;NNT√∏√é√éN√Ä	1V√ÖU√ì5√âdh√Ω(‚Ä¢J√ã¬±¬¥Hx√≥¬®‚Ä†¬ÆO≈íÔøΩpD√í√ï√ì∆í7L√üu√è2-√ã2#≈†‚ÄôJ¬ß‚Äö √ê¬´¬µ‚Ñ¢√ô‚Ñ¢√Å-‚Ä∫EBG√Ü‚Ä†√ñ‚Äπ8√ºQ.g√éL√¶√±√å
7√û¬¶¬Ω J√ï¬∫c√ª5‚Ä∫¬∑`‚Ä†√ë¬¥√ö+√ª_;}√ç¬∂kkz√≠≈°√ó&amp;‚ÄúI≈Ω√ß¬∏%8c√ö@¬§-mY$B√û√≠√Ω√æ7≈∏√ù√≥mte¬™|‚Äì≈æ}gxqh%¬´;)‚Äö]&lt;¬º√Ñ9VN._\¬π√ù√†z
¬¶¬∂¬£√á∆íkXr8¬∏‚Äö√Ä¬µ0¬Ø¬¥¬ß≈í¬•G‚Äù8&amp;¬©√≠√çK¬®O∆í9‚Ä¶√á&lt;ÔøΩ√®¬∫.|¬º‚Ç¨NW‚ÄöL$≈°≈∏ÔøΩÀÜF"¬¢ x¬∂e#¬©DS√à&nbsp;¬®≈† ‚Äò@T
A√ã¬£¬≠¬™√™¬¶√ç∆í¬∫¬¶1,;~√¶≈í√´¬∏]√ù√ù¬∫N≈†√íEc√ë√é¬Æ.√ò3¬¨√≠√∞f√ã√ñ-‚Äô,7( √£√£c¬Ø√¨√ø¬¨3√ìE2{√ßS~√∞T¬•&gt;¬ª√Æ√ö√´¬°√ó]=√É¬∞¬≤,√≥&lt;7‚Äöi‚Äò¬∂¬¥e5'‚Äò√¶√Év%CK+√ìs‚Äû¬¨√é¬´K¬∑√Ü√î√á√ã√Ä√ã"√ß√ü√π√ß¬©¬∫≈ì√ñd/√¢√êa√†j8¬∫¬¢&nbsp;√¥√æ√¶‚Ä°√≥√ë ,√ê√ñ‚Äì¬•f√ü
‚ÄöÔøΩ√™+&nbsp;√ø
¬∞	oLb√ùF∆ízcd¬§K√àÀÜ√ÅXa‚Äô‚Ä¶¬ØT+√á√Å,bIQK√•√¨3¬∞ÔøΩ√Ö$I‚Ä†YJV√õ¬¥¬¶¬ß¬ß√¢‚Ä∞D¬¶¬≥C&nbsp;4ÔøΩ√ÉAD	√ÉMZZ√ç8‚Ä†W√î√àN√°¬∞√É¬ß√º√∞√Æ(≈ì¬∫¬≥¬£3pI¬ΩYTV-X‚Ä¢¬§8¬ª√≠q√ï‚Äì¬´√ä(BfX√ü√Ω√Ñ¬ÆG?}√ü∆íh}√ó∆í√π√ñ‚Äö0N¬≥|:g√≥Àú¬Ø2√âO‚Äî¬æ#‚Ä†√ó
Y√Æ‚Ä¢¬∑√¥√¶zK√Å‚Ä¢¬©u¬©Et‚Ñ¢√ß √≤f‚Ä¢√Él≈∏‚Äù{i√Ø≈Ωu¬™;¬ª¬º‚Ä∫z√∞‚Äì4√û√ëI√ævEq‚Äî≈†E¬•‚Äù,√ÇcY‚Ä∞¬∫1;;S¬©T
‚ÄûH¬¢√πK√åS$¬™C¬¢√ë¬®m;¬¢$4!q!ÔøΩ}√°8,∆í√é≈°¬¶√Ç√ú\*=|z√¨¬¥√ßyx1+≈ìvw=√§√¨√õM√∏‚Ä∫%oV√Ö"B√Æ‚ÄúO√ª‚Äúp√ß√ë√ò¬Ω¬∂√ë¬•-W	Aa√Ö‚Äô.ÔøΩeT'¬≤^?‚Äôm5~,‚Ä∞G¬±,i$7&amp;√á√†¬º¬ØkY√∑√é,g8√ê√¨√ß√°59√¶¬≥√ç¬™√à:t√æ√•‚Ä†√É&amp;√∞ÀÜ‚Ä¢,¬∏RbDHS	,∆íZÀÜbw)',7¬∑√ûn^√ß‚Ä¶√ñh√≥¬ΩyT√¶$)‚Ä†√î¬™√Ö,√è¬≥Lw≈ì‚Ä∞¬®xzzS\‚Ä∞¬©H√¥≈ì‚Ä†a‚Äù
E@+√ê√≥Q5‚Äì/√¶p‚Ç¨√ã¬∂L_H
J$¬≤¬®¬§√µn√å/\√îj√ïT:-≈†√í¬¢¬ª√ê:y~¬≠VS‚ÄùÀÜ$K¬∂√£0;00P¬Æ‚Äù√û:√∏&amp;√†Àúkw\√õ≈í9[‚ÄπT√ä√•d*u√ñ6√°y√è√Ç√Öe√ç√µ≈Ω¬´_≈°OCi|b&nbsp;√±√¨‚Ç¨V√é¬£¬∂¬∑‚Ç¨l√ö¬¥√±m¬πzÔøΩ¬≠#¬∫w√èS{w?5o¬µ¬Ω.P√ñ(E!$UdÔøΩ√è‚Äò‚Ä¶-y‚Ä¶4ÔøΩ¬•¬æ√≥√ê¬•h√¢=:x√è+√µ‚Äú.qf|√ñM√Å!∆í√ô¬æ√ïld6&lt;√ç=√πE≈†}‚Äû.v√≠ÔøΩ‚Ä¶√îowP¬π√ë:q√úH∆í√ïv($¬π
7√É
‚Äô8D¬æ¬∫√ª_¬®$‚Äûfk√ù√¢‚Ä¶√å@¬¥√Ω¬Ø√Ä'√î‚Ä¶LC¬≠‚Äô¬≤¬∑√æ≈ì6√Ñh¬Æ≈†-√¨N¬¢K√Ω¬∏¬©√π)√≥Zsq‚Ä∞¬≠OÀÜ√ò√°√†‚Äô√Än√ç√†mF√≤5√èuH¬¨(!b'¬©Uk√£cc‚Ä¢r	√Ñ4√å√â‚Ä∞qI"‚Äπ‚Äö√ö9≈°¬ßBh‚Äò&gt;¬≠_x≈æW√à√•DYrl@	√ãq¬ºf‚Ä¶|√Å4≈í"@√ü√≥}√üu\^√†‚Ä∞D:‚Ä¢¬∂m;‚Äî‚Ä∫1ÔøΩ/√•|	‚Ä∞L"¬™¬∫`¬≤dk≈ì_¬ºE$√¨√Ñ√¶‚Ä¶√Ç√¨#√üGC≈ì[K√º[j√ú¬°&nbsp;]√ê¬®-W‚Ä°√¥)`‚Ä∫h}√ù≈í√ª¬∞√∫√ù¬Ø√à‚Ä°√èz¬≥≈†√≠¬£}√é√∞¬ª√∑f|√É√§≈°√º√™{¬¥¬∫~!√ô¬π√ö¬ªA3F√µ√©√∏‚Äπ=√ì¬π√∑¬ªd√°H-E‚Äπ√¥mp√ñ√ç√áha‚Ä∫≈∏}√¶;≈∏¬∏√øQ√Ñrk√∏√π√™j√ã‚Ä°E¬µ¬∫L√§‚Ç¨≈Ω/&amp;`8√§;sQ¬°	‚Äû‚Äù9¬µH‚Äì√•√ô1‚ÄûC√ñ√¶,%
¬≥√µ√¢r√Ñ"√∏√éB0ÀÜ√°T‚Ä∞MGÔøΩEQ√â&lt;√™√™√Æ:t√∞ ‚Ç¨≈∏h,JL ÀÜ%√¢¬Æ√£√≥y¬≠Z‚Äú‚ÄùHM&nbsp;‚Ä¶√É‚Ä¢≈†√Ö√ô√©√òX‚Äù9√õ√æ¬±hw+¬™√ä0√å√¥√ît&lt;‚Äò√®‚Äìe4√ü^R.‚Äî%√øB(DQ√à{Y≈Ω√º√í¬ª√ü{√¢√î‚Ä∞‚Äî√∑√ø@√í√¶M[≈°√©√Ås¬ß√ÉX‚Ä∞Dx≈Ω?≈∏ÔøΩ&nbsp;"¬¥~3√©P‚Ä†D√ìP@‚Ä°ÔøΩ‚Äì√û√±L√ã¬£√Ü7√í√ÖLzC‚Ä°]‚Äπ¬¥e√ù√£ÀúU,√å(√∞Td/‚Ä°≈ΩXuz‚Äîq	¬Æ≈ì√öv=√ºH~√≥√±]ÔøΩ√Ç,√§√∫√ÅÔøΩ≈æy√∫G√π√ßMK√Ñ√Ç¬´&nbsp;√¨¬®√°G≈ì¬Ωxl¬∞8hÔøΩ√õm¬Ω√∑√ô‚Äì√ì_L√Ø7√ö≈ì}√π√ô:‚Ä∫,Ze_√†√à√¢√§≈ì*}≈æ"√ú√ª√åw√Øz√®_√îK√Ø2√º√µ8‚Ä†&nbsp;&amp;(X&nbsp;‚Ä†&gt;¬£√™1√â√ãkRNXf√ø‚Äô+NÔøΩhv¬¨o{¬¨√ßs
#
-√©‚Ä°≈†cD¬∏¬¥F¬∑√ü0PÔøΩb√ù&nbsp;"e‚Ä∞3,8)ÔøΩ]√≤?≈Ω√£X‚Äì√©≈í√¢‚Ä∫z¬±√Ñ!U¬≠≈°‚Ä∫≈°eX¬¶R¬≠¬∫!JfÔøΩ7l√úH*¬ºx~4‚Äπ%‚Äú‚Ä¶d¬µX‚Äì%J‚Äô^(L≈íÔøΩw√µta√éC√•‚Äô"5,√ìÀúwL√ìpb}‚Ñ¢g√í`¬πL&amp;√É‚Äπ¬¶¬º√ØA‚Ç¨QCO√†¬§}¬Ω√Ω¬∫^{√µ¬µ‚Ä∞x¬¢¬∑¬ßo¬£‚Äô√Ø¬´Q√µ√û¬¢e‚Äò¬∞O)√ö`H√ô?√Ü√µ√°/√üb≈æ¬¢&gt;¬µ√ïK‚Äô√ò¬∂Q¬§-WÔøΩ√º√∞√ªO¬Ωk√µ‚Ä¢√Ç¬•‚Äù:#√ÜZ‚Äπyi√®√Ö√ª√∑+√∫√¨√É&gt;√¢‚ÄòkÔøΩ√ãH)√úH8√å¬∂.√ä‚Ä°[√¢=∆íJ¬ø√é√Ø\√ô√π‚Äò√ô9ÔøΩP√Ø#&lt;9√åY]√ê2√°N0√óÀÜ¬≥O√ëz√¥√ï∆í¬ΩKp√ß_¬®MS√ØF@√ä√ó√Ç5&nbsp;√Ü{¬Ø‚Ä¶‚ÄûQ,√É	¬¢¬Ω√ï¬©z√©ÀÜ∆íÔøΩ&nbsp;√ô√àp√∞	'√õ'+$e7¬£√´√é√ñ√ò‚Äö√é94*‚Äô√∫n8‚Äì'√ä√õÔøΩ√à√±≈Ω√á{¬Æ4≈Ω‚Ä°≈ΩÀÜx[{x√ú3√ù‚Ç¨√µu‚Ä†‚Äô¬™‚Ä¢5Y^ÔøΩ√°X‚Ä°O¬±g¬∞?¬Æ&amp;√≠≈°A‚Äúj√Ü√ä¬≤¬æ√ß¬•√ÉXw√≥2@ttv8¬®‚Äù√ã‚Äûv√Ω¬º9=5
√∑$≈∏√è√ÉS√ì√ó√ó√á√±<utÔøΩ‚Ñ¢(if√°z=‚Äö‚Ä¢$xc¬π√Ñt¬ø√ñ√π√•;~√Ö4√å√ø¬∑u¬´u'√£≈ì,‚Ç¨‚Ä∞c√Äm√π‚ÄìdÔøΩsx!vbq√É√ü‚Ä∞r√ê0√Ö0ÔøΩ¬æ¬¶√ø'√∞√ê¬´ÔøΩ√ö√í‚Äì¬∂\√°x$¬ª√ñ√å;y√¥√ô¬æ√¨√ú‚Ä°√ªk>¬°¬ß¬∂0ÔøΩ@A√∂√æ√Ö≈∏.¬¢3√±|dp√è≈æ¬ø√™√á-¬æ‚Ä∫‚Äì*<yt¬Ø¬°√ì‚Äûg¬ß∆íÔøΩ¬º¬°9wf‚Äìn≈∏¬Ωx@7<√Ø√¢√ß‚Ç¨qaew‚Ä¶,‚Ä¶√æ√é√Ω√∑¬≤≈æ ‚Ä∫ÔøΩ¬´^^√º≈†g√óÔøΩ)Àú√û<‚Ä†√Ö≈íh√™¬±√°="" √ëj‚Äì√Ä‚Äô√ó|uÔøΩd‚Äù="" ¬øl‚Ä°√†="" 8√Ñ¬ªÔøΩ¬£h="" ‚Äì="" f√©¬≠i√ßt^√±√°Àú√ßx¬¶s√Ö‚Ä°¬´f¬∞¬≥≈∏(‚Äú%ll"√Ñw√Ä="" ¬π¬°on‚ÄôÔøΩ√ü.="" √â√è¬§r√Ω¬Ωr\"√î√µ¬Ω¬≤¬•√µbf√çÔøΩ¬∞`y≈Ω√ÅhÔøΩ¬´¬°="" +¬†¬£}vf6√ù√ë√ëjl√∞<ÔøΩ√£¬πd*¬•(√≤td√Ñc‚Ä∞d2‚Äú√ã√è√§fg√ã√ò¬∞a‚Äôe√è√≥√ìlnn([e≈ΩcÔøΩ‚Äö¬¢="‚Ç¨√∫b!√ò&quot;‚ÄπeÔøΩ$√É?√©‚Ä¶‚Äî~√ä2√å√ñ¬≠√õ√ö≈∏√è√ßd¬ø√´`¬ß‚Äô√µ#√≥+D≈°‚Äî" ÀÜ√£?wsu√´vÔøΩ√ùqif√±x√±√£√ô√∂√ë¬¥eÔøΩ="" uy√¨√û¬ª√ªi¬¥="">√´‚Ä¶√ê‚Ñ¢0¬ª6¬ÆÔøΩ√™√ÖO=√∞√ï;w}¬¶≈∏√ò√É√å)
¬ª¬∫w√óÔøΩ√Ø√ç&gt;qVx√∫¬´‚ÄîN√Ω√ñ{7¬æC√æJ¬£LL√ù¬¥X¬ø√∞c√´_‚Äû¬Ø;3√út√ïsÀÜ¬≤√ã√≥¬µ¬¢'√úb√∞√â¬Æ6
YN¬£√É¬∏g√ó√ØAw¬∫¬¨≈í\‚Äì√ó‚Äîo√ªÔøΩk4√èl]IÔøΩ‚Ä†"√™	1¬æ%¬∫√•DT√û√ö¬©s√ò*√õUÔøΩq¬§¬§b&amp;¬´l√¢‚Ä∞‚Äôh√û¬≠∆í√ë≈†‚Ä∞‚Äô¬≤√å√í5~J≈Ωw(√Åt%0*√±√Å‚Ä°I%√Æ¬∞√Ñ≈∏√°&nbsp;¬™ÔøΩ‚Äô
√é¬®≈í√•¬°√û¬π76¬ß√±`
¬≤√ò¬Æ¬®‚Äúx‚Äî&amp;‚Ä†¬≥‚Ñ¢¬Æ`¬£\(m¬Ω√ÆY‚Äù√ü)U‚ÄôPC≈ì:lTÀÜp,‚ÄîJ¬•ÔøΩ&lt;¬ºu√á¬∂¬¶¬¢V%√Ö√≠√¢√â√ÑE√üh≈°&gt;==√ï√ô√ù¬µ‚Ä∞J¬πX≈°≈æ≈°√Æ√≠√≠√•≈°¬¢kZI√∑‚Ñ¢.P:4~:√ê≈íÀú7B¬π√≥#√Ω√ø¬ø√ø‚Ä°√®{√è¬£X¬´√æ∆í√Ø√ª‚Ä¶\√°√çq¬≠&lt;¬≠¬ª&lt;{¬¶√Ñ√ê¬∂¬∏}√£"¬≤f‚Äö√Ä%√¶5√å.√§‚ÄòR√ê@√ß4√¢‚Ä¢ÔøΩo¬°¬∑√éc7√íj√™ÔøΩ√Å¬¥¬æ√ì"mY¬ØH$≈í¬±?√º√™/√Ø1¬ªN/¬≤≈æ√πq√ô/ÔøΩ√¶√£√º√Å√ì√≠c¬∫‚Äù".√†zL¬±√à5¬∑√ûNav√°.√ø¬Ω'√ß‚Äù√´R¬π<wÔøΩz1√É‚Äù√öt√¥¬≤ÔøΩÀÜs√ó√ô e¬©m`w8txlrvgtt‚Ä¶z0√Ñ4c√µ;3:¬∫z9z√ªh:√å√∞2√Ü√åo="√∏√Ö√π√≠¬ø√ùr√≥√≠;ny√ïQ.f√π√ã√∂≈ì√Ø" √Ç¬¨@l√£‚Ä¢p√ò.√á%&√Üy="√¨¬§,U√£¬±H√Ö¬ÆJ≈ì√Ä¬≥¬º√øX√∂√¢X_A5I√èm√™√ØH√àÀúc¬±√Æ√êH≈íV√å1p‚Ä†√£¬°¬≠RÔøΩ‚Ä∫¬°q&amp;√ï√º8W‚Ä∫√®‚Äπ√£" ÔøΩj&‚Äöu)|√Ω'√∏[.‚Ä¢tue¬Ælu¬™v¬∞c√âm3‚Ñ¢≈Ω‚Ñ¢¬±√âr¬°p¬´h¬™‚Ä∞√ä¬™√Ä√∞√ãs,‚Ä†¬¥d:2‚Äö="" ¬∏¬Æ√∫√æ√å‚Ñ¢√ì¬•b="" ~√≤g67u¬£m:√î≈°e="" p√å‚Äô]√ì#u‚Äôia<q9≈Ω+="" Àú!1.z¬≠¬¶h√¢‚Äò√ì¬πsefcf¬∫¬æ‚Ä∫ÔøΩ¬Ω¬Øs≈†n46="">v√§√®√°7¬æ√°¬∏NoOo√§a8fTÔøΩl√épU‚Ä∫y¬¶7≈Ω¬£"^4x√•b≈ì&amp;RP‚Ä∫0*√°√çi¬¶?Nv]?H(8&amp;√ã3¬≠√°k&gt;√ãÀúÔøΩ¬Æy√•dÔøΩ¬∑¬•-√≥l√†√Ä√ã¬Æ√ü√´‚Ä∫[ÔøΩ¬Ø√®7√ß√≥%Sz√ã√ö;Àú¬∑_√º2√êg';7E√†Àú√Ø√è‚Äî√õ¬Ω√É¬°Z¬≤=√ò√†=√É+√ç{¬∂<p¬∂√•√é{¬øfy1‚Äûx-zwy≈ì√µt¬©√†z$¬µ‚Äö¬®‚Ä†¬ª¬°‚Äî√õ√ô√Én√≠`wv3¬∑√¥√É√ü¬∫q√ô8√êcÀúe√ê√Ån√é4-√ì¬ß√Ä0√è5,i¬¨a¬¶'√Üyl4¬†@¬Ω:pl≈æ%√≤‚Ä∫z√±¬µÔøΩ√∏¬∂ ‚Ç¨$h¬¢m@="" f¬•≈ìn(¬©l#¬∞|¬¥√Ç‚ÄöÔøΩ="" √Ω<√è{¬∂#¬±¬¢@¬≤≈°∆í¬∏¬†√Üd="" ggo'√ß√ïdte≈Ω√•ÔøΩ="" q‚Äö√á√ç√ç√év¬®‚Äì¬´‚Ç¨?√§ÀÜ√ú√ë√ë√ô√ì√õ++j¬©\¬∂="" ¬≥‚ÄπmÔøΩx‚Ç¨gkv√ä√Ñ√ò8i√π‚Ä¶&¬™`y√ñq]√ì|√ü‚Ä°c‚Ä∫¬™√¶4?.3i‚Ä¶p‚Ñ¢√Äkf‚Ç¨√´6ÔøΩ√∫an¬π√©‚Äìd2u¬≠v≈Ω¬æ}√§√µ7_‚Ä∫¬≥s¬∞lgr1¬±≈íÔøΩ≈ìv¬´≈ì)9ÔøΩ|caw√¶5√£¬¢\3Àú="" √ìa|uln¬≤√ú√ê√çtg√ët5√ê¬¨‚Ç¨√Å!√ï,mo"√Ñ="" √Ñ√á%s¬∞e√à_√´‚Äò¬£5√í‚Äì√≥Àú5¬∫¬∫%√ì√ñ√ög¬†.Àú√ö≈æ√ù√Ω¬≠‚Ä∫√ñ√£√Ω¬π√Ñ_*d2i√†√ú@="" k!k√Ωg¬æ√∏√∏√ü√æ√ô-hÔøΩ="" √Æ√é√à.√Ñwr¬¨‚Ä°¬≥d="" √ºnÔøΩ√åo√∂i‚Äû¬∂d="" √∂≈æ7‚Äò‚Äπ√Ö¬∫√ï*√§√öa√ô√ã6¬´ÔøΩ¬´sv0‚Ä¶:u≈ì≈ΩÔøΩ‚Äò√¢√πd√Ö≈†ue√àz¬¨√ö¬°¬§‚Äò√Æ√µ¬§{¬¶sb&≈°ÔøΩ="" ¬≥¬†√ü√Ñdjfl√ä2¬≠¬Æ¬æ="" ‚Äô√à√°]‚Ä°√Ä√ñjc0√Ç√πdilwddy¬•√Ö¬Ωq‚Äô,√ßg√≥‚Ä†¬Æ+15si√ç*ÔøΩi#¬≤¬¨√Ör$r√ãw%^≈æb√ºÔøΩ~‚Ä¶7‚Ç¨ÔøΩb:¬≤h<‚Äî$b√è√∞<≈∏√£√èu="" √É‚Ç¨√Øx‚Äì√Ñs.‚Äùh≈°√°:ÔøΩ="" √±√°√óx,^¬©tt]s¬£¬™¬™f‚Ä∞e%d¬æ√´z4√âp-)@≈æ‚Äù≈í√ÜÀú≈ì‚Ä°k="" ¬πpb√°x√ú‚Äû√ø¬°√Ä√ë√û}√≥¬ª¬ª;{√Ü√Ü√è="" ‚Ä¶y∆íe¬†c="√è¬≤^¬≥QN" ¬†="" *‚Ä∫$√®√µ√ù8<√ò√Öl≈æ√ü#‚Äî√§‚Äú@ÔøΩ√Æ√êd√ù√∫‚Äú<~z‚ÄöÀúÀÜ¬Ø√´b≈Ωo¬ø6!8¬∞‚Ä°gs¬Æ¬æÔøΩe√ö¬≤√òda≈Ω‚Ä∞¬Ω√ç¬ß¬≠d√É‚Ä†√¶√ô¬Ø}‚Äπzw‚Ä¢sq¬´‚Äì[#fcg√Ø√ø√†√ñ¬ª√Ø√§|}^ci‚Ä¶ry√Æ√Æ√ßo√æ√É≈æ¬ß~02)b7√®¬π√ø√¢‚Ä¶s√ø√Ω?="√πW√≤√ÑeÔøΩ" y¬¥≈°¬°s8*{√æ;e[√∂√â√écc√ôe="" √è√¶¬∞√π√î_%√ô'4√Ç‚Ä¶√ñ√¥k<√π√ó‚Äî4="">‚Ñ¢Xh
‚Ç¨√õ3(&amp;√°yLc
√Ü+≈æ√£√ª¬ª√∫]‚ÄîXn‚ÄôJ&lt;.E%N"d¬¶√í≈íZy¬∂&nbsp;√Ü¬¢‚Ä†i≈†√ë¬§√©!1@-%√°ÔøΩiÀú√•RI≈Ω(√ëh4?;[√ë*‚Äô √ÑcqEQj¬µ≈°F)Jc√±X≈∏¬π.&nbsp;"X¬∫√õ¬Æ√™_√ìk.√∂bj√ú√±\≈Ω"X√êGx√Ö√°¬¨0√õ√µ}h√É¬∞&lt;√á¬•√í‚ÄûR3X¬¢¬•q√´√∂‚ÄìÔøΩq@	]¬Ø;r√†E*ÔøΩÔøΩ√≥√ò&gt;√Ç√µ√ô≈Ω
¬™ÔøΩ√ã√É%¬æ¬ØtmU8‚Ä∞¬ß@‚Äì√´¬∫a√ï¬™√ÇÔøΩ‚Äù¬¥|√¶x≈æsl√â√•X√Ä[!√Ü‚Äö¬ø&lt;[√Ø¬´√ñÀúL¬¶¬£P,√Ç|¬≠√ä‚Äò√ù≈∏‚Äù√ë√ñ¬æt¬¢¬®Y~m¬≤¬µ]‚ÄöE√†r¬∂ep√ï‚Äû¬ª@LD;¬≥cj`"ÔøΩ¬®¬∂√•√£‚ÄúR√π&amp;ÀÜuIY≈ì&nbsp;√é√Æ‚Äö¬±p‚Ä†‚Äπ\√ü√ê∆í_‚Ä∫√Ñ≈Ω‚Ä°¬©¬¶a√õ@¬§-ÔøΩ5J√ì√å√ß‚Ä°√§‚Äû√îr√≤‚Ä† √Å√±4√£¬¢¬®‚Äù/!≈†
#U√ë¬∫√°Y∆íd√û√¢=¬ª√ß√©√ü√ò√µ¬∞‚Ä°¬∏¬π|JeD√®¬§√∂√ó√Ø√¨¬∑√óM √ø√ΩÔøΩ¬∑√ø√§‚Ä∞o7√á√ö√á√Æ{√åv√ë√ü√Ω√πK√É‚Ä¶‚Ä¢¬∑‚Ä¶≈í¬¨b¬±Àú‚Äòfa¬Ω‚Ä¶¬æ‚Äù‚Äò‚Äú‚Ä¶w64¬¢,s≈ì√£√Å¬¶V¬¶~_.OeÔøΩ¬¥‚Äù√®i√å
&lt;+√±^_√ú&amp;√¨‚Ä∫√Ñr¬±ÀÜ√∑≈ΩaÀúÀÜJ¬¥√©√¨√¥,√ö‚Ä∫$√¢b@‚ÄìmZ‚Äì√âr|._‚Ä†‚Äπ"&lt;¬ª √ï√≥&lt;‚ÄúzFs√åg=6√ê√µ√ñ√¨\Bp√£√É‚Ç¨TL√ãI√éO0¬®H√É√ßF¬≠√°√Ö"q2√ü¬π+¬∞‚Äû¬≤L‚Äù√è/KÀÜz√Äq‚Ñ¢\‚Äúk;≈°¬Ø$b[HKM√ù¬®T*Wl√õ≈°≈ìÀú‚Äù$1d√ì`9¬∂R¬≠H‚Äô‚ÄùL$¬¨√∞¬ºÔøΩ≈í√ábp-√Ñ√õ9¬§√ï*√Ö¬≤‚Ä†6&amp;√ã¬∫√á≈Ω√ïTxL&amp;*≈æW+¬±R¬º&nbsp;GrA_√µ√Ñp√ã√≥¬∑√Ä&amp;√¨S¬´√∞√Ç[,qhSgTv¬´okyS¬≤b‚Äò‚Ä∞√ÉÀÜD√òE‚Ä¶‚Äπ√è≈°¬°E√è√â√ú√´√Ä{√ü#√Éf	√ï‚Äπ√ó ¬∏‚Ä¶√õ√èp5‚Äπ}}√ã}7m7@8‚Äö‚Äπ√õ!¬´m√¶U√π¬®‚Ñ¢‚Äî‚Äì√•d<!--?√ö√≥√§¬≥¬ª¬ø[}√≤¬æ/}√≤√ÅGL¬¨^ √™√ö√É\H¬¢¬º√ñ‚Ä†‚Ñ¢¬¨√ñ¬¨√ñ^&√â¬Æ¬µ65¬º≈∏;√µP=a¬∑5
‚Ä†√°(}I@√∏√ú‚Äî√Ø¬Ø¬≥√ü¬∫√∑¬´¬ø7[c√Æ√ö√µ√ò¬≥√ü"¬¥[√ô√∫√¥_ÀÜ‚ÄûUrh¬∂√ãTÔøΩm‚ÄòQ√ó‚Äô√≠2g√µ√à.¬≤√ã¬™√ó¬ø√ø√æ√ì√õ√µ√è‚Äî.√Å¬∂¬™‚Äú‚Ä¶ $‚Äö‚Äò¬¨jx√ñ√åÀÜ√ï√Æd$¬ÆT5‚Ä°ÔøΩr¬≥j√¨¬¢‚Ä∞√£¬π√ô√ôYP√õ¬†√à]√á¬©‚Äù+¬Æ√ß¬¶;:‚ÄöbE&√ÖWX‚ÄìC√ç√êKb√î√∞=√ò‚Ç¨eY‚Äì√≥¬πY√É2:6t√´5√ç√∞-l`IÔøΩB'H¬µZ¬µ‚Ä∞cY¬¢(√Ç√åDÔøΩE≈Ωa]√ã√ë*5‚Äìe√±0,[Z‚Ä†Y¬´Va/√á¬∂a‚Ä¶o	√Ü$√å√≥|$	∆íRX√ò≈Ω]-W
‚Ä¶√èsJ$ÔøΩE=√ó
√™√Ü√¢q¬©\ÔøΩFEI√Ä√†¬∏N√à¬æ√äkAH√ØQ-‚Äî√µ¬™≈æ√©√¨¬£‚Ä∞¬±|p¬≤@]5~√Ä:√ï‚Ç¨‚Äî¬ß¬´√ítÔøΩÀú¬®{b¬°_√º^√Ça5¬Ωf≈°&\√óuUU√É√Ø√Ö¬¢J√öu¬µr¬µd!^I¬≤:Y√¥uGD4√áWk¬¶9√∑TA√®CÔøΩ≈Ω‚Äö‚Ä†≈°¬°¬∂ÔøΩ ¬º¬∑¬∏‚Ñ¢'√á≈ì.'a8M¬¥√ç!W7¬°√∏∆í√òK)wPX¬≥Àú√•a√Ñ√º√ó=√ø√æÔøΩ|√æ√ê√æ;√Éj¬º√º√∑¬ª¬ø¬ªw√∑‚Äúw?√∞(√å$-√•¬¶∆í√Ü¬´√ïD‚Ä†‚Äú√ªs.!‚Äì√ß#√ª_<¬¥√ø√Ö√ß√ñ√ó√≠¬¢eD√é‚Ä¢fr√©e√ï¬¢¬£√®_|√ª¬Ø=√å‚Ä¶<≈†¬®‚Ä¶≈°‚Äö8√µB√∫¬º√•¬¶√∑√ø√Ü∆íÔøΩ¬ø√∂√≥≈∏m¬ª‚Ä∞√§k|√™‚ÄπÔøΩ√ø√∞{O-->√ª√Ω'√Ø√ö√µ8¬¨f√Ø{√∏√±¬ø√™~b≈ì5T√á‚Äì#w√å√ì√ú√ã√≠√â¬°√ê(‚Äö√ë√ä‚ÄîÔøΩ√ô7J√¶√î√Ø¬¢√â&gt;¬¥√¨√ã0√Ω&amp;‚Äπ√™%`¬≤-¬ØKp3√ÉE¬ø√±√Ä¬£AHny)¬Ω¬´√Ñ`√Ø‚Ä†'ÔøΩH\R√ÜQ¬Æc√Ü3√´¬≥ÔøΩ√Ä√á‚Äò√¥‚Äù%&amp;
Z{‚Ä¶=}√≤$	@]7j√ï≈°m√õ√èGUU‚Äù‚Äìa0¬´i$o√ñ4-¬≠¬¶k¬∫‚Ç¨&nbsp;¬ª¬ß[√†‚Ä¶√ô√â√©Tg#sUÔøΩ¬©1‚Äòy≈Ω√§!+¬≤¬¢F8‚Ñ¢'6√ó+W*√ëX,O√Å¬Æ√£√∞HÔøΩ√ü¬∏/]ÔøΩ‚Äô¬¨√Äq¬∏ZPWO¬∑$K√ê~√ê√∑Z¬≠m3t√Éq\√∏Q≈ΩD√∫√∫√ªyÔøΩ@√ì√õ√ü√ß8NÔøΩ¬®√êr√ã¬≤|√ü‚Ä°‚Ä†√ûl√ã‚ÄòZ¬æ$√áX7Y√édR5√ç¬∫]√ß¬∫O¬∂√è√á<lÀú√ö;u√ú¬¥ÀÜ≈ì√ùkccg√Ü&√Ü√Ç¬π:√§√¥‚Ñ¢s¬±x√êr√®ÔøΩ∆í√ñ&u√Å3¬´¬πb‚Ä¶‚Äîc√á√µ ¬ß‚Äô√†¬≤√É‚Äö¬¶√Ü√ê≈íÀú="" d¬¥¬•nz="" 5@√ô√Ü√ñ¬Æ="" z<√¢‚Äîa‚Äû√õ‚Ä¢√∞¬ÆbbÔøΩz√∫√µ¬≥√î‚Äòd¬∞w√∑√è√Æ√æ≈°c¬´nf√çe√Ø√ø√Ä‚Äì√ù√øt¬±|√†‚Ñ¢Àúh1√Ö¬≥="" √¢√ó√â¬ª‚Äù@$√¥0‚Äúbn√ôuy√ì√Ç≈æ^k¬¶≈æ√ü~√®√ã‚Ä†√á¬πÀÜ√Ç√Ç√Ç‚Ñ¢1¬≠{e~√¢|‚Ä†√π√∏¬Æ√ábkr¬∏¬∫√ß√Å√á1u√êm√Ç√íe¬Økx√•ma√¥≈íy√Çr¬∂√í<¬µ√ô¬≥√Æ√ó√ö‚Äìx√¨‚Ñ¢kÔøΩ,c√ã√†‚Ä∞√§t‚Äò√ô≈ì√Ü¬Ω¬™k{√å√§,:√π√∂‚Ä∞m√ól√£}√ñ√§m≈Ω√°‚Äì¬™‚Äûb√≥z¬µÀÜa&‚ÄòhÔøΩ&¬®‚Ç¨‚Äùk√ïjufb*≈æl√à¬≤r¬©‚Äì‚Äú√â‚Ä∞√Ä√†8a‚Äô‚Äòf¬®q‚Ä¢d¬µ√Åu‚Äπ√ár‚Ç¨h√†,"√âÀÜ¬©¬´d8¬≤√£¬ªÔøΩÔøΩ√îd≈í8@‚ÄòÀÜ‚Ä∫√ô≈Ω‚Ä∫ÀÜ&∆í8k¬ª^t`="" √Ö√ê53ÔøΩ*¬™b<√ïÀúi$¬≠-="" m!33√ì¬µj5‚Ä¢j√á="" @*‚Ä†i√êh`¬∂¬≥¬≥^¬≠√õ‚Äπ‚Äôdf!≈∏√Øs‚Äù9¬´o√£≈æ¬¢h‚Äô‚Ä†@√†="" ¬Ø‚Äòz7¬¶√•√∂f#¬≥g‚Äôz|$√´√∏‚ÄôÀÜ'b√ëx¬°tp|f4√£¬∫k¬Ø√£√π√∫¬≥√âs\,≈æ≈ív√ù6lÔøΩ√ásÀú¬æÀÜ#dx‚Äìe¬§u="√à√∞√µ*‚Ä¶¬∏‚Ä¶√á‚Ä¢ÀúLX√∫√Ñvh¬∏?o∆í¬∂\e(‚ÄûTca‚Ç¨" √î‚Äì√ºx√è√ó√ùtk‚Ç¨¬π¬Ω√ü√¢√à√æbw="" ¬™="" √§≈°+√ìp!7¬≤w√∑s√∑<√∞{√´¬¶√ã9√å¬Øq√Ç="" √£$ÔøΩ√£9√à≈Ω√ë¬•0ÔøΩ√∏‚Ç¨¬∞‚Ä†√°¬æ√±√∞√ß‚Ä†√ñ≈í√ï`√Öe¬≠‚Ñ¢j√Ç√ª√ê√´√ü√º√Ö√ø√∫√¥_qÔøΩ9¬§1√∑‚Äû¬∑^‚Ñ¢≈°ha‚Ä¶¬†√§≈°[n¬£¬°d9x√ØwÔøΩ¬øÀÜ~√æk="" .~]#+i9√ã42¬≤r:4≈†√∞h√É(¬≤v$,√Ä="" x√ª-h√Ç="" √â√§o√¢,¬¢‚Ä¢x√Æ‚Äì~v[1≈ì√É3≈ì≈†‚Ä¢z¬•√Üb√û¬≤√¥x$√ñ\¬Ø¬£:√ô;jq√ñ√†7√üxc√£¬¶mÔøΩ]]¬º="" ÔøΩ≈†&,¬£(j4√ï4¬≠¬ß¬ß'√ï‚Äòig2‚Ç¨mr‚Ñ¢4,√∑m√üÔøΩ√Ñ√î≈æ√Æuu√Ω√Ä¬Ø√ö5ÔøΩ="" ÔøΩ‚Ç¨`-t‚Ñ¢'¬°="">%$%√Ö√ô|O√Ç¬º¬£√õ
‚Ä¢¬∞8-I(f
‚Äî√å¬≥¬∞√Å√§√Ñ$‚Äöd:√â√≥√¨‚Ä°¬©6m¬Ω&gt;√õ¬≤√†o¬•\√éd:¬°%‚Äö√Är‚Äö/ÔøΩP√ó
^l¬¢X√é√àgQ¬Ø¬∫¬Æ[√åH√Å<eÔøΩ√ë‚Äö√£y√¢¬Ø√π‚Ä¢m≈í√å3~y,¬™*;¬∫¬•k;1ÔøΩ‚Äùey@b¬∂wh}h1√™√≠√© ‚Äî‚ÄπÔøΩÔøΩ√ù¬Ω¬πm√´q√´‚Äú1fq‚Ä¶√ã¬®\u¬≥r≈í√ô-√û¬Øl√®‚Ä¢√ä√™√ä√Ç√úk√ü√É,‚Ä°√öru¬£ÔøΩ="" pm√å√ã{¬ø√∑="" b√µ√∂√Æyf√°√Æ√ûq√û√ãr|√Ø√≠‚Ä∫√Éw√Øz="" √∑]d¬•√ãp√º1="" ≈∏√ö√ßl≈°t√É^="" w="" y√™‚Ñ¢√Ø√π&z¬ß≈ì¬™¬®√≤¬∏f√ñ√ö√îv√Å√∏6--√¶¬°√Ö¬ßgd="" ¬¥¬æ√ì`="" `√©:5¬†¬´@√¨x$‚Äú¬£b&‚Ä°√π√≥ÔøΩ√∑‚Ä∞'¬ß[="" √™4√ë+√ô‚Äú#s√Ñ√∞√ô‚Ä¢‚Äû9√Ék-Àú¬ß&√ª√±]_√™x√ù√Ö‚Äî‚Ç¨s‚Ä¢√ê¬ª‚Ä¶p√®)q¬†√æ]√õu√µz¬≠4‚Äú√∑ÔøΩ‚Äû¬Æ√û√Æ¬Ø¬ºr√ù√éÔøΩ√ä≈ìy`√°="" ‚Äö√è¬ßo≈∏t¬£qd√´¬π="" ‚Ä†!)≈†√≠¬∏√°‚Äù√ñ√ï√õn‚Ñ¢‚Äû√µy="" y¬Æw≈ì√å)¬≤√ú¬´√∂pÔøΩ`r2√ºh‚Ä¢z√Ä¬±u3fk%n√îx¬¥‚Ä∞\√ò-√∞≈Ω‚Ä°m<r√æ&√®√®√Æ¬§¬ªc¬Æ¬•@`xa√Öq≈ì‚Äî√æ√≥lg@)"√É,Àú≈∏√âÔøΩ√à¬•z√ï}?√àd‚Äô-d≈ægcs√º¬≥2√º-‚Äπ¬º√Äo="" ‚Äπ√¢¬®70Àúeg5o¬•d√°≈ì√º="" ¬∂ew+√ï√©¬©i√Ü√á√ón¬ø¬æo¬†√ø√∫√´w;v√¥√®√õgj√Ö¬¢$i,√á3-√êÀÜe≈æ`,¬ª|<√ù√à√ól√Æ_)‚Äπ√à;l√ìÀÜi‚Ä¶\√≠0‚Äû¬∞√´√ª9="">√∫√ä?=¬ª√ß[‚Ä°√º¬¨-‚Ä†<g√ü<g¬ß¬Ø¬•¬¢,¬≤ÔøΩÔøΩ‚Ä°√≠√ø√Ü¬°√Ω √Æ√ù√Ω¬§√Ä8√ø√Æ√°√è√Éo‚Ä°¬ºx√∏√•≈∏√æ√ë#¬øy√è√Ω_%y¬°¬≠≈æd,¬π="" √ö√ç√ï2‚Ä°√êr¬¢√¨√ëw_<√∏√äk√ôuz√ø√Æ@‚Äî*¬¨√†<u√ú(¬∫√ª¬æ="" √ªÀÜ#‚Ä∞¬°√å√í‚Ä∞tu√∂eb‚Äò¬•√Ö¬∞(o¬°≈∏¬™‚Ä°√õ√ëis,z√≥√•¬∑pd‚Ä∞¬©ah√•.<4‚Ä°≈í≈Ωfgg‚Ä°v¬∏2√ò¬°¬µ4f¬∫z√§√´o√ø‚Äî√Ü‚Äú√®√ëh√¥u√∂√ã√É¬Ωvtyk_√ü~√è&¬æ="" √Åj¬ºÀÜuf√â√†√¶-‚Ä∞tp1_xa¬•:;1‚Äô¬π¬∫eÔøΩ@n≈Ω√å‚Ä¶rq√ó4‚Äò¬≤t4sd-√ã*‚Ä¢≈†√Ω√Ωp-¬≥3$¬≠‚Ä†c√´√Ñ√∞‚Äú¬¶√©Àú:‚Äû√≤¬≥¬≥‚Ä∫7s\√´¬¥√î¬™‚Ä¢‚Ñ¢√â)¬≠v√£¬æ¬ª¬ß√Å<√Ö√ì8¬™¬¢="" ‚Äî√Éq‚Äú="" √ü‚Ä†¬©√©$√ù¬∑¬µ¬†="" √Ä¬†√©¬©¬©√©‚Ñ¢¬©√â√™4‚Ä∫√†√Ö@√åÔøΩi¬∞√†="" y‚Äì√°z√Ü√Ü√Ü√ä‚Ä¶\gw3_√≠√Ç√áb¬°0="=¬•¬™Q√õ&amp;√Å¬™√∞√•‚Ä∞c√ás√πY√¢‚Äò!" bbh"bi√¨="" ¬†¬¥‚Ä∞¬±q√¢9="" ¬§g√õ6√¥√§√î√Ñd¬•zi¬•√ì7√Ü√¢¬±ÔøΩ-ox≈Ω√∑√äk="" ="" √πd<¬©√àjd$ÔøΩ√≠m√ã√ùi√ï√°√í√ö.√∑w√Ö#pÔøΩ‚ÄîÀÜ¬¥¬•-¬≠√õ√å="" ¬†:√ô?√ó√¢yi¬æa√Ø¬¥¬™zu√∑√ñ+¬ø‚Ç¨ÔøΩ‚Ä°√∑√ø√°√°√Ω="" ="">√∞|√≥√¨≈æO√Ç‚Ç¨?t√†¬•kny?√âd¬°‚Ä¢¬ª√´U¬£$¬ø¬Ø√î√Ñ¬≥√ã√£√°√ü√å¬ÆS¬ø√åH9√º√ú‚Ä¶√Ø¬∂J√ù1D√é"√ª-¬∑√ó√≠√ßPo√¥≈Ω‚Äú‚Ç¨CZ‚Ä∫‚ÄöaiÔøΩU,r$¬∑√Ü√µ√ë¬ø√Ω√äg√´Cot,2zGÔøΩ¬£}%√±!z_√±¬∞√¶¬∫∆íf-D‚Ä°c√¶≈°‚Ä∫√ü¬≥√Ω√¶√õ√´√ó\¬≠√∫¬¢‚Äù`SN‚Äû¬ª|√ªfÔøΩ¬©M	)√∫‚Ä¢TN)‚Ä¢%‚Ñ¢|≈í¬®5¬¨@‚Äö+}√á|√á¬¥K√π‚Äög¬πj‚Äù¬§{$@¬¶√í¬±√ò&lt;K‚Äû;√π√∂√õ‚Ä†i√π≈æ≈∏‚Ä∫‚Ñ¢@√É$
√î√º√§√Ñ¬∏√≠√ò√Ö|~p√≥ √übF ¬∏¬§P‚Ç¨‚Äìd:2¬™¬™√ÇAO√ö<r=ÔøΩ√≤¬æ√ª≈æw√¶√¥‚Ñ¢ÔøΩÔøΩ√Ç‚Äì¬∑z0¬†}≈ì.≈Ωwvt√µ¬¶{b[@kÔøΩ¬£√∞√ü‚Äò√âp,‚Äîl%y4√π¬æeÀú‚Ä¢j ≈æ≈Ω√•¬°u‚Ä†¬Æwtd‚Äô√â¬§¬¨(√°e¬∫≈Ω¬´√´z√à¬µ="" 5ÔøΩÔøΩ≈æÔøΩ]y7‚Äù¬∑ÔøΩ+‚Äî√ä¬¶if::√í‚Ñ¢t√Ä√∞^√Ä√≤l√∑h‚Äô|z√¨$‚Ç¨¬ß¬ß≈Ωn≈†e√É≈æd,∆íew√á‚Ñ¢ÀÜÔøΩkÔøΩ{√ö@¬§-‚Äî="" ‚Ä∞√≥8√∑gÔøΩ|n¬•√≥[‚Ä°√¶gÔøΩ√∑‚Ä°√∂√üyx√ø¬Ø√≠√ù}7‚Ä°¬Ω√≠7√üf√¶="">≈°-L√•¬®#¬§M¬´‚Ä°Àú√êo√à¬¢√ô¬Ω√É	¬≠¬©√¥√£g¬æuh√øKC√´ÀÜ‚Ä¶f√∂√≥¬∑√∂≈í√ê√•√∞(zh√∫√ÅW&gt;√æ
ÔøΩ√∞Y√©¬Æ√Å√®¬≠'_¬æ√ª√æ‚Ä°¬©o√é[√†‚Ä∫[D√≥c,IoV@-X‚Äù&nbsp;‚Ä¶?√º√∞√ªO√å‚Ñ¢√ßF√è¬∫RL‚Äö/FV.^¬§%F$¬ª
√∑*;JyÔøΩsat√à√Å√Ω?¬ª√ß‚Ç¨bUOVX√Ö√Ñ.V√è‚Ä° F‚Ä¶ÔøΩ√ù8¬©≈†¬∂e√©5¬≠ÔøΩ√è‚Äú√îVNÀÜ√á√£&nbsp;√æ'''+¬•R, B√¢-P1≈†¬∏≈æe√ô¬¨ 5√§√¨√å¬°)&lt;≈∏XUd‚Äò‚Äî√êL4U¬£Q∆í√§√é0,]√∞D"J"‚Ñ¢≈íF¬£‚Äô¬¨¬¥¬∂¬¨\.√õ¬∂ÔøΩ‚Äò‚Äô$‚Ä¶¬∂≈†0‚Äô#¬§4]¬∞&gt;‚Äö&amp;i‚Ç¨‚Ä∫¬™√ïÔøΩ,s ‚Ä∫|W¬©vvu&amp;√ï‚Ç¨≈∏‚Ä∞√öTLRyZ¬∏¬ßV¬≠j5M`"√ã√πB¬∞{∆í¬≠c;p¬¢≈Ω√éNA¬ß¬ß¬ß&nbsp;√ÉÔøΩ‚Äò
¬ø2zpl‚Ä∫$√∑√Ç‚Äû√®¬∫JD‚Ñ¢‚Ñ¢≈æfH≈°y&gt;5√òl||¬¨V¬©v√∑√∂ÔøΩv√∫Àú+XX√∑√è&nbsp;35,0(¬™ÀÜ=√ù=√£√£√ÖR√ës=I%RÀÜ√Å‚ÄûÔøΩBS√ím √í‚ÄìKBÀÜ¬≤ÔøΩG¬º¬∂(8¬º√øW?¬¥≈ΩH√Æ√ø√®√û√ùO‚Ä∞≈í√≥√¶√æW¬Æ¬π√µ√ΩÀúj#√∫√Ç4y^t‚Ä¢√úÀú√à,¬®¬æ‚Ä†[t√ë√¶ÔøΩP}√µ¬•∆í√ª_zn√Ω√ûC¬¢&nbsp;√è√≥¬¶Q√∏√ô¬æ√¥o¬æ√≥‚Äî√ª_√û√£¬≠¬ø√¥√Ü'~¬æ¬®¬•a√π√†√®√ì√∑√âgD&amp;L√ëT¬¨%√†H√ãr¬≥¬§¬∏k!√å≈Ωg‚ÄìÀú√¨z√§√±¬ø√∫√úu¬Ø`vQ√•NN¬∑‚Äöv‚Äò¬∞√û√®j‚Ä¢√å‚Ä†√¥i‚Äî√ë4¬≤ÔøΩ≈æn√ª¬≥√è√º√âg√Æ¬Ω√è¬£&lt;\√ò¬ß√¶√É√ï√∞√éB√≥!√†¬æ√≤|√ü√ò∆í3,
DI√´¬∫√ä5‚Ä∞¬§√í)X√∫o√Ç√§f¬±V¬≠‚Ñ¢‚ÄìU¬≠V√†
√†X‚Ä∫∆í‚Ä†6tC‚Äô√ÑB1oÀú¬∫√´:‚Ç¨*B√õF@√ÉY	
(√ãÀÜ¬¢:2/H¬•√öt√Å¬¢Ql√öB|√ü¬ß≈Ω¬§i‚Ç¨√Ä=¬≠√Ü4≈∏l¬æ√°#¬®i58¬º√öD*√•2√Ä)¬∏¬∫h&lt;¬™JÔøΩ≈°hÀÜ≈ì√à3√Å:‚Äì
√∏#‚ÄπA¬´L√ì]$√°√©-V√ãD&nbsp;|351√≠Q¬£j√ò¬∂ÀÜÀú‚Ä†√∏,L]≈æ‚Ñ¢‚Ñ¢6u8≈í	√à√â4L%‚Ç¨W`K√á¬±¬πl	√ª¬∫¬∂‚Äú√éddE&amp;√ü√ª¬®bÀú√ÖB~v√º√¥¬±√£G√•√å‚Ä†¬¥‚Äö-√ì&lt;~√¢m]√ó-√õ*‚ÄîK√ê≈æ≈Ω≈Ω√é¬≥√Ø^ÀÜ¬¥√•‚Äô(1√äo@√§≈°‚Ä∫√ü√à&nbsp;r	&amp;IÀú‚Äò√±‚Ä∫¬Ø√º√ª√É$&nbsp;√§)X‚Ñ¢√≠¬∏√π√Ωa¬Æ/HÀú‚Äì√¢0¬ª≈Ω√ê≈ì4`
ulD¬≤D√°h¬∫
f¬π√£¬Ø¬ø√∞√©‚Äî6¬¥~√Ø√°P‚ÄúM$√ªN(¬°¬ø√æ¬∑7√ù√¥a√õ√ß¬∂√û√º¬æ¬≠7¬Ω√ø√ì¬ª¬æ√º‚Ñ¢√ª√§√º√Ü]¬øXI82‚Äö~¬∞√ß¬ªw√≠z√ïK√ê
≈æ¬Ω4qsD(u√â√†¬ØÔøΩ√à≈Ω√ã]?≈æT√∞√è&gt;√≤√Ç‚Äô√ç√ã√çJ√ôE(
A¬´wCF√æ√ê√•≈°√Éo√®√Ø≈∏√π¬≥{√Æ√ªr@2‚Ä∫b	V‚Äπ√∏4i≈Ω√°%ÔøΩL3;:Àú≈æ()6‚Äöh(%%KU√ïhT‚Äò√•¬∞N=√ã2¬º √™≈°Àú∆í√î|X¬Ø√∞ÔøΩd¬±2≈æO√¢-¬¥Z-‚ÄòH√Ç≈Ω√µ`‚Äπ0|∆íi.[√™B!≈∏#u√¶√º√ñ¬∞‚Ä¶+‚Ä¢¬¢√èuP√∞‚ÄìI¬™√ëJC√∑√≤∆í9√ò√Å4‚Äô√º√∞¬º√°ÔøΩAg+‚Äò‚Äîf¬®G¬±X¬¨T*√âT≈†0ÀÜ`b∆í√¢#‚Äìg	≈°c√Ü√∏U¬§(	&nbsp;‚Ç¨%¬¢∆ít¬•√†`√ôX,√Ü¬±‚Äû≈∏-7‚Ä∫√´√Æ√≠√àR*aB‚Äπb≈°≈ΩC√≠$¬©:‚Äö√ÅUÔøΩ¬§!√å√ò≈Ω
√úFx√íxR‚Ç¨&nbsp;	¬¥¬™*√çNÔøΩ9x`fj¬º‚Äù‚Ä∫ ‚Ä∞√Ñ¬Æ‚Äò√ã√•¬¶¬¶¬¶7
√Ç‚Ä¶‚Äù¬´e¬∏√ä¬®D¬∏√ê^¬π√ª√πSmE√ô‚Äì√ï7≈†√∏‚Äû√ø∆í#√¶√ä√∏√æ√ø`√∑√ìÔøΩ¬π√≤Rf‚Ñ¢√å√©√ÄO√ü√øE‚Äî‚ÄòZ¬¢√±‚Ä°√ïe√∑O≈Ω5h^∆í‚Ä¶Pj.5}¬Æ√Ñ+¬©√§‚Ä∞≈Ω√•√Æ¬Ω}sv√Ω¬¶√å,b√ä¬∂¬∞¬Ω√å√Ø√†x√Æ√¶√∏ÔøΩ&gt;√ë8√Ω‚Ñ¢¬Ω√ç√£FX√£S√Ø¬ªq%√Ø|√£‚Äì√Æ}3`%√ä¬¨h‚ÄúdR√õÔøΩ=W¬¶(I¬•qh%N√¢≈æ√µ@}D√°√é6¬ºC√≥p√ù√Üw‚Äò√≠¬©‚Ä∫CV√∞ÔøΩ‚Äû¬¨¬™√Ékf√ò√ú}√øW?q√øc√î5√¶√Ø√â
√∫hH≈Ω‚Ä∞¬≤E¬§√º√æÔøΩL¬≤√°√ë4=L√úÀÜ6√ÇAB‚Äö2X√®[√®V;ÔøΩ
√Å¬°‚Äú&nbsp;a√ÜÔøΩ√är√¨√¥‚Ñ¢X<n¬®d‚Äì¬®√í¬¶≈ì¬º}√¥¬®¬¶i√âd*√ì√ë√™√∂√µ|√üq√¨l&cb,¬™5√Ä%ÔøΩ@√•'‚Ä∞u√Åy√Ö¬™¬∂¬®t√ä¬°‚Ä¶√î√ø√¨√å,¬ß¬∑¬Øoj√±‚Äô8rh√å¬∂o√îj√ê√≤h≈í√Ä&√Ä¬∞11xd"¬•r‚Ä∞a¬®]#@wÔøΩ≈Ω|.√ü√ï√ù‚Ä¶¬¶\.ÔøΩ√à"ÔøΩ√â√•8√Ä.¬§6‚Äπ?w"@ÔøΩÔøΩ+¬µ≈°‚Äî≈ìj¬ßÔøΩ|x≈æ711{%r‚Ä∞:√§√≤¬º√É‚Ä°√≠?√∞¬≤√∏ jf√≠‚Ä†√´√ü515q¬≠v="">√∏√æn≈°ÔøΩÔøΩu¬∞^WWWww√è√ö¬∞ÀÜ‚ÄûQc√µ‚Äô4√≠≈ì≈°√µÔøΩD¬®iÔøΩ¬¨AÔøΩ√¨√ø√©√Å√Ω?¬£_^bW√ÜP3√Ø√¶¬≠√ëC√ª√ø√∞!B¬Ω¬≥aB&amp;k√ì¬Ω{√ÆÔøΩ‚Ä°√∞≈°[n'4'‚Äû: d^¬§¬∏‚ÄûX}CZ√∫&nbsp;^√Å&nbsp;^I‚Äπ√π√±3√üZ√ü~‚Ñ¢√∞c√ïY;GQ‚Äπ√µ≈∏b‚Äö√è=√∞¬ª}¬∑√º*&lt;√í$∆í:DoaL√Ø¬∂√±≈æ√ª¬ø√≤√¨≈æo√ó=5√ã¬∑≈Ω√úQ¬∑n√Ø¬Ω√Ø¬ª{√∑|√´7v=≈†≈æ‚Äû√≥‚ÄòY√•≈ì|Eu√£‚Äîm√≥√øX√Ü¬µ]|√∑∆í_√ª√Å√∑≈æ¬¨7oQ√á¬Ω√æ‚Äò‚Äπr√ì‚Äû√ñ‚Äù¬°Q√öo√ß√´¬¨¬°^≈Ω}n8√ô7‚ÄûF‚Ä°√ó√å¬∞!√±√£?‚Ä°a¬±√Ω¬¶√õ√àT7ÀÜ:¬¨P√§xHj√á¬∞"ÔøΩ¬ª¬£√å‚Äì√å≈ì√∑#≈∏/8$¬≥ÔøΩÔøΩ√èq√≠Ah3
E√ò(√¥¬§‚Äûy+-.,4|1U‚Äûic"‚Ä∫k4(√æJ¬•R¬≠T8≈æ‚Äîdp@√ù0|√è¬µlRM@	%;h√§¬¶F‚Ç¨‚Ä†¬£ÔøΩÀú‚Ä¶√û	≈í^0;3-+≈†G√ä√ó¬ÆS‚Äö¬®¬¢s¬ø√Ñ‚Ä°√Ç√†b¬±T¬´V√¥Z&gt;*‚Äò√º¬®√ïj√ìSS‚Ä∞d√í√ê4√ósa/ha¬•¬ßP`ZX√∑√à0√ïr‚Ä¢0≈∏¬¶RallÀúi√ì0√°¬¢¬∑√Å√Ö#MK√ë&gt;
p	√â¬¨‚Äò√ã‚Ä¢rM¬´√•r¬≥‚Äú‚Ç¨W√±d:‚Ñ¢¬Æ√ñ*$√©fj¬¢¬Ø¬ß√ì¬¶√Å√Æ¬Æ√ÆX,2‚Ä∫‚Ä∫!D¬¥‚Äì¬©√àJ√ì¬•u¬π‚Ç¨-DDH0Z¬µ√°√à¬∫‚Äî¬∞|L√üx√§7[&amp;√ôK√Ø√Ö≈°√ü:¬¥‚Ç¨√ª√∞√æ;√∑√Æ~‚ÄôA√û√°W^8~√†√π√ø√£‚Äò√è≈í¬ª√≠‚ÄìR^HZ~/√¥√öÔøΩyÀÜ‚Äù‚Ä∫√ø√ë3√ü√π√°√Æoe√ó/ÔøΩ√ô¬¢ze¬®0√î‚Äô√≥4‚Äö¬æ√∂√î_¬¨x¬¢≈íÀú)ÔøΩ√≥ÔøΩ√≤2√ã√üu√ü√É¬¨¬´√ø¬´√ø√∞√≠√º√•√Æ√•b‚Äò‚ÄòFkhÔøΩ√©√û=O√¶ÔøΩ/y≈íR7Ygh‚Äò$;Q‚Ä∫‚ÄìÔøΩ?`√§:s√èCÔøΩ√ú√≥√Ä√óa~√´‚Ä∫/≈æ‚Äπ≈í≈Ω^0√ô¬∑ÔøΩ√¨5J√õ‚Äù¬≠7√π√ú√ó?√í√à√§¬•‚Ä∫√Ø;√Ø √ÇÔøΩy‚Äòq¬´√ßu¬§√∂¬Ø¬Ωn√á≈Ω[?D√µ¬∞ÔøΩ‚Ñ¢¬•?np&nbsp;√è^√É√ß√óKF√êRU1oNc‚Ä¢sa√Ø¬π(√ér¬±H¬¥&amp;a≈æ¬∞¬≤¬ß~‚Äù+q[‚Ç¨
¬•√Å
KÔøΩ√î6¬¨√†√á04Uf¬ª B‚Äú√£¬∞`√â&gt;1√ë2Mh&nbsp;¬¢¬™UÔøΩ¬π	√öH¬ß√î¬®
'√¢~ÔøΩ5√•ÔøΩÔøΩH@√ä√°‚Äô√Ü√´‚Ä†e√öt√∂A√®y≈Ω√ºc√ö¬Æ√ß¬π‚Ä†aN≈ΩÔøΩ¬≤~dQ≈†√ÜCTU¬≠Vj‚Ä¢≈°i√±d*‚Äπ‚Äπ¬§H/√ì√ÑR≈°√©≈æ:~T$√∏D√é√•r‚Ä¢rY¬¶H¬•√é√ΩJ7∆í≈Ω√∞‚Äò√è√•ÔøΩ√Ñ√≠√∫≈æ¬≤¬ª‚ÄôÀú≈°≈æ,‚Äπ9@¬Æs√º√Ñ√õ¬•RQ√ìk√áw¬¶;‚Äú√©4¬¨√†√ª√Æ√Æ≈æ[n¬∫5‚Ä¢H√Å√ìwP√±√æp√º√´o¬æ¬∫¬°¬¥*&lt;√£√•"√°`"%√±√ó&nbsp;H2m‚Äò¬∂√é√î‚ÄìuCI
Àúi‚Äì¬®]¬´√•√°ÀÜ≈Ω8¬¥√øÔøΩx√©¬≠√Ω%√¶‚Äú√Ω¬ºw√∑S¬∞√†¬æ√´√Å¬Øc‚Ä†'¬¥¬∞t√ú√í√ô9√∞√¢√ß√º|√∏*¬ª≈∏√µ¬™s√çH√ìd√æ√¢¬§√à5√±¬µ¬Ω√û√Ç¬•√ã‚Ä∞√∞‚Ç¨≈æC√∞(√ãm¬ø√•vÔøΩS√Øz√†kd0,‚Äπ√†√¨¬ª√®¬ª¬ø¬ß√òq√´(htI02FK‚Ä†√∏0¬≠pD4≈ìÔøΩ8¬≤$tDal¬ª√©6Àú"√Ö_¬¨¬ß√≠‚Ä∫_&amp;;‚ÄîJs≈æp¬§\E√ê|:'√ß&amp;√õ√Åk^√ß√ú:wg‚Ä†.√ì√Ä‚Ç¨~:√¥‚Ñ¢;¬ø√≥√¶¬±‚Äòz‚Äö√Ü¬§√Æ√πg√ø√™√ª√≤M¬øt‚Ä∫$∆íxg√∏¬≥√î√∫b√†¬£¬πA¬Ωv‚Ä∞.¬ßw√ñ'o√Ç-	¬Æ√§'x¬ß?√™:‚Äì¬°√ï`A^∆í}F√º√Å`‚Ç¨√∞fzj√ä√∑C√ìTX≈æ√á√£$S‚Ä†√Å√ß¬º ≈ΩÔøΩ9M-√ä√ô(v¬¨V¬™)√ê√¥‚Ä∞8¬© ‚Ä∞H2¬®v	&nbsp;√®√¨√©‚Ñ¢‚Ñ¢X&lt;¬°.√°√ôi¬™|¬º¬§≈æ‚Äûv√™¬Æ√´‚Äì≈†%@√Ñ≈†S*√ék√ìE]‚Äô√µc√öL√†√ß√≤√ÄJ√©¬Æ¬æ¬Æ¬æ
¬º5√¨√∫A√†Y‚ÄòF√Ä‚Äö&nbsp;DUQZ√±√°¬ΩgÀÜC≈°¬•D‚Äù√â¬±q‚Ç¨!a	&lt;	4¬æ‚Ä¢T√≠‚Ä¶¬Æ3-¬´V¬©√Ü}$‚Äú$√üG‚Äì&nbsp;;k5
P√é√ø√Ω¬≥¬π@tc&amp;	.¬±7l√ò¬∂e;OÔøΩQ:‚Äú√©√≠√©≈∏√ø‚Ä¢;~5O‚ÄûÔøΩ√å√≥|‚Ä†H√Ä‚ÄòB!‚Ä¶‚Äπ‚Äö√õ√ùu9‚Ç¨M≈æ‚Äû¬±√àr¬º@\W≈í‚Äú;√ã≈æI√©√∞Àú√ãP¬±¬¨-‚Äî}‚Äô¬∞vf≈∏O~√æ¬æ√æ√Öl1N¬¨Ai¬®¬µ:√ô|}√πJ,%88|√†√Ö#√ª_8√∫√äO¬æ√±√®¬Ω{≈∏√π√∂¬°?¬∫≈°√å!√µ√Ö}¬≥≈Ω√´¬æz¬¶√Æ√ß√∫√≤¬¶‚Ä∫?L¬æ√±l√Ç√¢‚Ç¨‚Äûh‚Äû√ïQ!.aEÀú¬πh¬ª√ò√ê√ôz√¢¬•z‚Ä¢D√™_kTZbV¬©SlQ-bÀÜ¬©;√îm¬ø√π¬∂¬Ω_x2$√Ñx√∏‚Äì¬Ø√Ω√¨‚Ä¶√™√Æ¬§P¬ª√ómj¬£√ßWo√ü&gt;‚Äö?H{G√ßZ√ù√Ä"M∆í√á‚Ä∫97&nbsp;ÔøΩ√°√°‚Äπ≈ìO√í/¬π3√Å√•C!?}√ß√éÔøΩ√õ√ø¬Ø√ø√¥√ß√ø√¶_√≠√ñwo√ªo¬∫√±¬ß‚Ä°O√º√Æ‚Äî~g√∏_¬Ω¬Ø¬∑o`√∞≈°√â*v}√úH¬∑√∂√é‚Äö"-18Àú‚Äûz√é-MI‚Äö=√¨I‚Äú?AMP‚Ä†V≈æ√åeÀúÀú√Ñt¬´A‚ÄîÔøΩZ^‚Äò$X≈Ω√ßs¬≥cc√£¬∫{{√¢$√îC¬•~IuMC4√ï‚Äì√ó¬•‚Ñ¢¬´‚Ä¢0|&nbsp;hX√ûÀú¬∫Y¬≠T"‚ÄòÀÜ¬¨√åK√á‚Ä¶≈∏|√üo√Ü≈°√∞$‚Ä†¬§√É4√µ=¬º‚Ä∞F√£33S‚Äô$/√à‚Äù9√´jÔøΩ √Ñ√£Z≈æ√£%R	‚Ä¶‚Äû√ô¬™‚Äô$√Ç‚Äî%√ç√é√©A√çt√û{√£√ñL2ÔøΩ¬©‚Ñ¢‚Äù¬¢√Ü¬ßL¬©j¬≥1	%¬∏B≈∏¬∞¬Æ√ã‚Äö√Ä√∑oÀÜ(√ä√ôV√∏FÔøΩ(√á√ättÀú‚Ä†ÔøΩ'&nbsp;√Ω¬π√ô√®‚Ñ¢h,√∏√Äs¬Ω¬©‚Ä∞‚Ä∞J¬•¬™F¬£axM√ò¬∞√ìgN√Ω√¢√•≈∏¬π≈Ω[√ì√ß√°ÔøΩ√º√äÔøΩ¬Ω=}7√¨¬ºq√ß√µ78‚Äì=91√Å¬∞≈ì¬¨*¬¶nTJ‚Ä¢-‚Ä∫¬∂√∞‚Äöh‚Äù}√ò≈∏¬∫‚Ä¶</n¬®d‚Äì¬®√≤¬¶≈ì¬º}√¥¬®¬¶i√©d*√≥√±√™√∂√µ|√üq√¨l&cb,¬™5√†%ÔøΩ@√•'‚Ä∞u√°y√•¬™¬∂¬®t√™¬°‚Ä¶√¥√ø√¨√¨,¬ß¬∑¬Øoj√±‚Äô8rh√¨¬∂o√¥j√∞√≤h≈ì√†&√†¬∞11xd"¬•r‚Ä∞a¬®]#@wÔøΩ≈æ|.√ü√µ√Ω‚Ä¶¬¶\.ÔøΩ√®"ÔøΩ√©√•8√†.¬§6‚Äπ?w"@ÔøΩÔøΩ+¬µ≈°‚Äî≈ìj¬ßÔøΩ|x≈æ711{%r‚Ä∞:√§√≤¬º√£‚Ä°√≠?√∞¬≤√∏></r=ÔøΩ√≤¬æ√ª≈æw√¶√¥‚Ñ¢ÔøΩÔøΩ√¢‚Äì¬∑z0¬†}≈ì.≈æwvt√µ¬¶{b[@kÔøΩ¬£√∞√ü‚Äò√©p,‚Äîl%y4√π¬æeÀú‚Ä¢j></g√ü<g¬ß¬Ø¬•¬¢,¬≤ÔøΩÔøΩ‚Ä°√≠√ø√¶¬°√Ω></eÔøΩ√±‚Äö√£y√¢¬Ø√π‚Ä¢m≈ì√¨3~y,¬™*;¬∫¬•k;1ÔøΩ‚Äùey@b¬∂wh}h1√™√≠√©></lÀú√∫;u√º¬¥ÀÜ≈ì√Ωkccg√¶&√¶√¢¬π:√§√¥‚Ñ¢s¬±x√∞r√®ÔøΩ∆í√∂&u√°3¬´¬πb‚Ä¶‚Äîc√ß√µ></p¬∂√•√Æ{¬øfy1‚Äûx-zwy≈ì√µt¬©√†z$¬µ‚Äö¬®‚Ä†¬ª¬°‚Äî√ª√π√£n√≠`wv3¬∑√¥√£√ü¬∫q√π8√∞cÀúe√∞√°n√Æ4-√≥¬ß√†0√Ø5,i¬¨a¬¶'√¶yl4¬†@¬Ω:pl≈æ%√≤‚Ä∫z√±¬µÔøΩ√∏¬∂></wÔøΩz1√£‚Äù√∫t√¥¬≤ÔøΩÀÜs√ó√π></yt¬Ø¬°√≥‚Äûg¬ß∆íÔøΩ¬º¬°9wf‚Äìn√ø¬Ωx@7<√Ø√¢√ß‚Ç¨qaew‚Ä¶,‚Ä¶√æ√Æ√Ω√∑¬≤≈æ></utÔøΩ‚Ñ¢(if√°z=‚Äö‚Ä¢$xc¬π√§t¬ø√∂√π√•;~√•4√¨√ø¬∑u¬´u'√£≈ì,‚Ç¨‚Ä∞c√†m√π‚ÄìdÔøΩsx!vbq√£√ü‚Ä∞r√∞0√•0ÔøΩ¬æ¬¶√ø'√∞√∞¬´ÔøΩ√∫√≤‚Äì¬∂\√°x$¬ª√∂√¨;y√¥√π¬æ√¨√º‚Ä°√ªk></ais‚Äî¬≥1gx‚Äôw¬°></kÀÜ√≤√≤j<√≥¬°2‚Ä∫2jb√§√™¬•‚Äô¬©q)‚Äù√∫¬∞u}√†¬¢,i¬≤√µ<√®√∏√π√ºl¬•\√π¬∞q#√´-t√∫q5¬∫√≥¬∫ÔøΩ9√≤‚Äú√æ<√†‚Äì‚Ä¶√ª‚Äû√Øuc¬±h"√™></i></u></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sat-smt.codes/SAT_SMT_by_example.pdf">https://sat-smt.codes/SAT_SMT_by_example.pdf</a></em></p>]]>
            </description>
            <link>https://sat-smt.codes/SAT_SMT_by_example.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298863</guid>
            <pubDate>Mon, 01 Mar 2021 01:39:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collection of SolarWinds Articles]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298791">thread link</a>) | @wglb
<br/>
February 28, 2021 | https://ciexinc.com/blog/solarwinds-articles/ | <a href="https://web.archive.org/web/*/https://ciexinc.com/blog/solarwinds-articles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ciexinc.com/blog/solarwinds-articles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298791</guid>
            <pubDate>Mon, 01 Mar 2021 01:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp Machine Manual (1984)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298553">thread link</a>) | @caslon
<br/>
February 28, 2021 | https://hanshuebner.github.io/lmman/title.xml | <a href="https://web.archive.org/web/*/https://hanshuebner.github.io/lmman/title.xml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><center><heading>Lisp Machine Manual</heading></center><center>Sixth Edition, System Version 99</center><center>June 1984</center><center>Richard Stallman</center><center>Daniel Weinreb</center><center>David Moon</center><nopara></nopara>
<p>This report describes research done at the Artificial Intelligence
Laboratory of the Massachusetts Institute of Technology.  Support for the
laboratory's artificial intelligence research is provided in part by the
Advanced Research Projects Agency of the Department of Defense under Office
of Naval Research Contract number N00014-80-C-0505.
<page></page></p><center><sub-heading>Preface</sub-heading></center>

<p>The Lisp Machine manual describes both the language and the operating system
of the Lisp Machine.  The language, a dialect of Lisp called Zetalisp,
is completely documented
by this manual.  The software environment and operating-system-like parts of
the system contain many things which are still in a state of flux.
This manual confines itself primarily to the stabler parts of the
system.  It describes how to program, but not for the most part how to
operate the machine.  The window system is documented separately in
the Lisp Machine Window System manual.
</p>

<p>Any comments, suggestions, or criticisms will be welcomed.  Please send
Arpa network mail to BUG-LMMAN@MIT-MC.
</p>

<p>Those not on the Arpanet may send U.S. mail to

<lisp><standard>Richard M. Stallman
Artificial Intelligence Lab
545 Technology Square
Cambridge, Mass. 02139</standard>
</lisp></p>

<p>Portions of this manual were written by Mike McMahon and Alan Bawden.
The chapter on the LOOP iteration macro is mostly a reprint of
Laboratory for Computer Science memo TM-169, by Glenn Burke.  Sarah
Smith, Meryl Cohen and Richard Ingria of LMI, and Richard Mlynarik of
MIT, helped to correct the manual.
</p>
<nopara></nopara><center><sub-heading>Personal Note from Richard Stallman</sub-heading></center>
<p>The Lisp Machine is a product of the efforts of many people too
numerous to list here and of the former unique unbureaucratic,
free-wheeling and cooperative environment of the M.I.T. Artificial
Intelligence Laboratory.  I believe that the commercialization of
computer software has harmed the spirit which enabled such systems to
be developed.  Now I am attempting to build a software-sharing movement to
revive that spirit from near oblivion.
</p>

<p>Since January 1984 I have been working primarily on the development of
GNU, a complete Unix-compatible software system for standard hardware
architectures, to be shared freely with everyone just like EMACS.
This will enable people to use computers and be good neighbors legally
(a good neighbor allows his neighbors to copy any generally useful
software he has a copy of).  This project has inspired a growing
movement of enthusiastic supporters.  Just recently the first free
portable C compiler compiled itself.  If you would like to contribute
to GNU, write to me at the address above.  Restrain social decay--help
get programmers sharing again.
</p>
<page></page>
</div></div>]]>
            </description>
            <link>https://hanshuebner.github.io/lmman/title.xml</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298553</guid>
            <pubDate>Mon, 01 Mar 2021 00:42:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking This Serially (RS-232 History)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298546">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://computer.rip/2021-01-12%20taking%20this%20serially.html | <a href="https://web.archive.org/web/*/https://computer.rip/2021-01-12%20taking%20this%20serially.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Conceptually, if we want two computer systems to communicate with each other,
all we need is a data link over which we can send a series of bits. This is
exactly what serial interfaces do. You can probably quickly imagine a simple
and effective scheme to send a series of bits in order, which is precisely why
there are a thousand different standards, many of them are confusingly similar
to each other, and the most popular are remarkably complex.</p>
<p>So, in this message, I will try to break down what exactly a "serial port" is.
I will only be talking about the hardware standards in this case, not the
software side of a COM port in Windows or a tty device in Unix derivatives.
That's an interesting topic, and I hope to write about it some time, but it
will be A Whole Thing. The software situation is at least as complicated as the
hardware side.</p>
<p>With that warning in place, let's look at this strictly from a consumer
perspective. Most computer users, or at least those with experience working
with serial ports, are familiar with serial in the form of a DE9[1] connector,
and often as opposed to a parallel port, which uses a truly enormous DB25
connector in order to send eight bits at a time. These were the two primary
peripheral interfaces of old computers. Actually, that's not quite true; it's
more accurate to say that these two were the primary peripheral interfaces
of early personal computers that managed to survive into the modern era,
basically because they were adopted by various iterations of the IBM PC, which
is the platonic ideal of a personal computer.</p>
<p>To simplify the history somewhat, the pseudo-standard parallel port was
designed in order to simplify the construction of printers. Although that
advantage basically disappeared as printer technology changed, parallel ports
remained conventional for printers for many years after. In practice they had
few advantages over serial connectors and so basically died out with the
printers that used them. We should all be glad, the time it took to send a
rasterized page to a laser printer over a parallel interface was truly
infuriating.</p>
<p>It would be surprising to run into a parallel interface in use these days,
although I'm sure there are a few out there. It is quite common, though, to
find serial ports today. They're remarkably durable. This is partially because
they are extremely simple, and thus inexpensive to implement. It is mostly
because they are predominantly used by the kind of industries that love to
have weird proprietary connectors, and serial is the ultimate way to have a
weird proprietary connector, because it is one of the least standardized
standards I have ever seen.</p>
<p>Serial ports on computers are vaguely related to an EIA/TIA standard called
RS-232. In fact, a number of computers and other devices label these ports
RS-232, which is a bold move because they are almost universally non-compliant
with that specification. There are usually several ways that they violate the
standard, but the most obvious is that RS-232 specifies the use of a DB25
connector, with, you guessed it, 25 pins. "Good god, 25 pins for a simple
serial connection?" you say. That's right, 25 pins. It is precisely because of
that bourgeois excess of pins that personal computer manufacturers, as an
industry, decided to trash the standard and use the smaller DE9 connector
instead.</p>
<p>In order to understand RS-232 and it's amusingly large connector specification
better, we need to understand a bit about the history of the standard.
Fortunately, that will also help a bit in understanding the baffling complexity
of actually making serial interfaces work today.</p>
<p>RS-232 was originally introduced to connect a terminal (originally a TTY) to a
modem. The specification was actually rather specific to that purpose, which
shows when we look at all the bonus pins. More generically, RS-232 is designed
to connect "data terminal equipment" (DTE) to "data communications equipment"
(DCE). As you often run into with these sorts of cabling, the TX pin of one
computer needs to connect to the RX pin of the other, and vice versa. For this
reason, the two devices on a serial connection should have their RX and TX pins
reversed compared to each other. </p>
<p>The terms DTE and DCE are usually used to identify these two different
configurations. That said, it was sometimes necessary to, for example, connect
two computers to each other, when both used the same interface. Further, some
manufacturers made (and continue to make) inconsistent decisions about whether
the computer or peripheral should be DCE or DTE. This necessitates using a
"null modem" cable, which is the equivalent of "crossover" for Ethernet before
GbE specified a far more flexible MDI.</p>
<p>Trying to figure out whether you should use a null modem or straight through
cable, which is usually easiest to do by experimentation, is just the first of
the many fun steps in successfully using a serial device.</p>
<p>Conceptually, RS-232 functions in an extremely simple way. To transmit a one,
you put a high (positive) voltage on the TX pin. To transmit a zero, you put a
low (negative) voltage on the TX pin. This is in reference to a ground pin,
which is usually connected right to local ground.</p>
<p>This gets us to our second bit of serial complexity, after figuring out whether
or not we need to add an extra swap in the RX and TX wires: clock recovery. In
most cases (we'll get to the exceptions later maybe), there is no explicit
clock information provided by a serial connection. Instead, the receiving
device must heuristically recover the clock rate. Some serial devices work this
out by expecting the transmitter to always send a certain preamble (common in
some industrial control and other situations), but the problem is solved more
generally by the convention of sending a "start bit" and "stop bit" of one and
zero successively, before and after each byte. This ensures at least one
transition and helps with detecting the timing of the whole byte.</p>
<p>Most devices expect one and one bit. Some devices expect two of each. Some
devices expect none at all (although they then usually use a protocol that
expects a preamble).</p>
<p>From this mess, you might think that the RS-232 standard does not specify any
method of clock synchronization. In fact, it does. It's just not implemented
on PC serial interfaces.</p>
<p>So I said 25 pins. Now we know what our first five are: we have ground, tx,
rx, and two pins that are used for synchronization, one in each direction.
That's 5. What about the other twenty?</p>
<p>Well, some are just for stuff that no one uses any more. There's a pin to
select the data rate (rarely used and unimplemented on PCs). There's a pin for
a transceiver self-test feature (rarely used and unimplemented on PCs). But
most of all, there is telephone modem arcana.</p>
<p>Remember, RS-232 was designed fairly specifically for a terminal to communicate
with its modem. Modems at the time had some fairly peculiar requirements and
restrictions. An obvious one is that the modem needs to signal the terminal
when it is ringing (in the sense of a phone), and there's a pin for that.
There's also a pin to indicate that the DCE has established a connection with
a remote DCE. There are two pins that the DTE can use to essentially conduct
a handshake with the DCE in preparation for sending data, a requirement due to
the half-duplex nature of modems. There are two pins for similar, but different
readiness negotiation in the other direction.</p>
<p>Most entertaining of all, there is <em>an entire second serial connection.</em> That's
right, the RS-232 standard specifies pins on the cable for a complete second
data path with its own data pins and control pins.</p>
<p>Add all this up and you get somewhere near 25, but not quite, because there are
a few unused.</p>
<p>When early PC manufacturers (but mostly IBM) were hunting around for a fairly
general-purpose interface to connect peripherals, RS-232 looked like a pretty
good solution because it was fairly simple to implement and provided a good
data rate. The problem is that it was over complicated. So, they just took the
parts they didn't like and threw them in the trash. The result is "RS-232
lite," a loosely specified standard that carried RS-232-esque signaling over a
smaller DE9 connector.</p>
<p>Here are the pins of the DE9 connector:</p>
<ol>
<li>Data carrier detect (DCD)</li>
<li>Rx</li>
<li>Tx</li>
<li>Data terminal ready (DTR)</li>
<li>Ground</li>
<li>Data set ready (DSR)</li>
<li>Request to send (RTS)</li>
<li>Clear to send (CTS)</li>
<li>Ring indicator</li>
</ol>
<p>This has the ground and two signal pins that we know we need, and then many,
but not all, of the control pins specified by RS-232. Notably, no clock pins,
meaning that properly synchronous serial standards (like several early computer
network standards) cannot be carried on these RS-232 interfaces. Don't worry,
this didn't stop anyone from trying to do general-purpose networking with these
things.</p>
<p>Quick sidebar: I said positive and negative voltage earlier. The RS-232
standard is really unspecific about these and in newer revisions they can range
from 3 to 25 volts, either positive or negative. As a de facto norm, most
computer "RS-232-ish" interfaces use 13 volts, but there are exceptions. The
standard requires that all interfaces tolerate up to the full 25 volts, but
I would not trust this too far.</p>
<p>So what about all the control pins that PC serial interfaces retain... well,
this gets us into the world of flow control. Often, when communicating with a
peripheral or another computer, it is necessary to somehow signal when you are
capable of receiving data (e.g. room in buffer). This is conventionally done on
serial ports by using the RTS and CTS pins to indicate readiness to receive
data by the DTE and DCE respectively, which is consistent with which ends of
the connection "own" those pins in the proper RS-232 specification. This is all
fine and good.</p>
<p>Except for it's not, because there are a number of serial devices out there
which do not implement the RTS/CTS pins for whatever reason (mostly money
reasons, I assume). So, a second convention ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://computer.rip/2021-01-12%20taking%20this%20serially.html">https://computer.rip/2021-01-12%20taking%20this%20serially.html</a></em></p>]]>
            </description>
            <link>https://computer.rip/2021-01-12%20taking%20this%20serially.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298546</guid>
            <pubDate>Mon, 01 Mar 2021 00:41:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Quick and Easy Guide to Tmux]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298492">thread link</a>) | @niDistinct
<br/>
February 28, 2021 | https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/ | <a href="https://web.archive.org/web/*/https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>I love working with the command line. Seriously, I think there‚Äôs hardly any more productive and more versatile tool for a software developer than the terminal. Maybe it‚Äôs the hacker/wizard/neckbeard kind of feeling I get when using a terminal, I don‚Äôt know.</p>

<p>At work we do <em>lots</em> of pair programming. Everyone‚Äôs got their own laptop and can set it up the way they like. And since I love working with the command line I‚Äôve spent quite some time doing (only sane! I swear!) modifications to my terminal environment that make working with the command line more pleasant and streamlined. This is why my pair usually will be greeted by something like this:</p>

<p><img src="https://www.hamvocke.com/assets/img/uploads/tmux.png" alt="tmux in action"></p>

<p>If they‚Äôve worked with me before they know what they are up to. But every once in a while there will be a new team member who doesn‚Äôt know my environment. Usually this is the point where they will ask something like ‚ÄúWTF am I looking at?‚Äù and it‚Äôs my time to shine!</p>

<p>Because what they‚Äôre looking at is nothing less than the best thing since sliced bread. It‚Äôs <a href="https://tmux.github.io/">tmux</a>, a so-called <em>terminal multiplexer</em>. Simply speaking, tmux acts as a window manager within your terminal<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> and allows you to create multiple windows and panes within a single terminal window.</p>

<p>I‚Äôll proceed to give them a two minute tour about what you can do with tmux. After that they‚Äôre either hooked and want to try it themselves or they tell me to go away with my ancient neckbeard tools and just use iTerm2. In the former case I‚Äôll usually end up helping them installing tmux on their machine and will give them a 10 minute guide to learn the most important basics.</p>

<p>This post will give you the same two minute introduction about tmux and its possibilities, followed by the typical 10 minute hands-on guide to set up and get to know tmux yourself. If you‚Äôve got 10 minutes to spare and finally want to be more proficient with tmux: read on!</p>

<h2 id="whats-tmux">What‚Äôs tmux?</h2>
<p>tmux‚Äôs authors describe it as a <em>terminal multiplexer</em>. Behind this fancy term hides a simple concept: Within one terminal window you can open multiple windows and split-views (called <em>‚Äúpanes‚Äù</em> in tmux lingo). Each pane will contain its own, independently running terminal instance. This allows you to have multiple terminal commands and applications running visually next to each other without the need to open multiple terminal emulator windows.</p>

<p>On top of that tmux keeps these windows and panes in a session. You can exit a session at any point. This is called <em>‚Äúdetaching‚Äù</em>. tmux will keep this session alive until you kill the tmux server (e.g. when you reboot)<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. This is incredibly useful because at any later point in time you can pick that session up exactly from where you left it by simply <em>‚Äúattaching‚Äù</em> to that session.</p>

<p>If you‚Äôve ever worked with remote servers or a Raspberry Pi over ssh you can guess where this will be useful: When you lose your ssh connection the tmux session will simply be detached but will keep running on the server in the background including all the processes that run within your session. To continue your session simply ssh to the server again and attach to the running session.</p>

<p>But tmux is not only helpful when working on a remote machine. Not only for its window management features but also for the session handling. Personally I find myself detaching from sessions when I‚Äôm switching context. I‚Äôll just start a new session for my new task and attach to the old session whenever I want to continue with my old task.</p>

<p>You see that tmux basically offers two big features: Window management in your terminal and session management. If you are familiar with <a href="https://www.gnu.org/software/screen">GNU Screen</a> this is nothing new. Think of tmux as an easier-to-use and a little more powerful alternative to Screen (obviously I‚Äôm being opinionated here).</p>

<p>Enough with the talking already. Let‚Äôs get our hands ready in the hands-on guide!</p>

<h2 id="getting-started">Getting Started</h2>
<p>This hands-on guide will get you up and running with tmux pretty quickly. It will only cover the basic features which should be more than enough to get started and be productive with tmux. Simply open your terminal and follow the instructions.</p>

<h3 id="installation">Installation</h3>

<p>Fortunately installing tmux is pretty straightforward on most distributions a simple <code>sudo apt-get install tmux</code> (Ubuntu and derivatives) or <code>brew install tmux</code> (Mac) should be sufficient.</p>

<h3 id="starting-your-first-session">Starting Your First Session</h3>
<p>For your first session simply start tmux with a new session:</p>



<p>This will create a new tmux session with a nice all-green status bar at the bottom:</p>

<p><img src="https://www.hamvocke.com/assets/img/uploads/tmux_blank.png" alt="vanilla tmux on startup"></p>

<p>The status bar is an important part of tmux. Apart from the currently opened windows (on the left) it also shows some system information like date and time (on the right). The status bar can also be customized and I‚Äôve seen some really fancy stuff around (upcoming calendar events, battery status, to name a few) but this is something we‚Äôll leave for later.</p>

<h3 id="splitting-panes">Splitting Panes</h3>
<p>Now that we‚Äôve created our first session we can get a feeling for panes. When you create a new session, tmux will by default start with one window and a single panel inside. We want a nice split-screen, so let‚Äôs split this bad boy.</p>

<p>All commands in tmux are triggered by a <strong>prefix key</strong> followed by a <strong>command key</strong> (quite similar to emacs). By default, tmux uses <code>C-b</code> as prefix key. This notation might read a little weird if you‚Äôre not used to it. In this emacs notation <code>C-</code> means ‚Äúpress and hold the <code>Ctrl</code> key‚Äù<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>. Thus <code>C-b</code> simply means press the <code>Ctrl</code> and <code>b</code> keys at the same time.</p>

<p>The shortcut to split panes into a left and a right pane is <code>C-b %</code>. Remembering what I‚Äôve just told you about tmux‚Äôs sequence of <strong>prefix</strong> and <strong>command key</strong> this means to split your single pane into a left and a right pane you press <code>Ctrl</code> and <code>b</code> at the same time, release both, and then type the <code>%</code> key. Voil√†! You‚Äôve just invoked your first tmux command and split your pane in two.</p>

<p><img src="https://www.hamvocke.com/assets/img/uploads/tmux_split.png" alt="tmux with two split panes"></p>

<p>Where there‚Äôs a split into left and right, there‚Äôs also a split into top and bottom pane. To split a pane into top and bottom panes use the <code>C-b "</code> shortcut.</p>

<h3 id="navigating-panes">Navigating Panes</h3>
<p>Right now we‚Äôre trapped in the newly created pane. But we really really want to go back to the left one. Easy peasy: Switching to a different pane uses the <code>C-b &lt;arrow key&gt;</code> shortcut, where &lt;arrow key&gt; is the arrow key pointing to the pane you want to switch to. In our case we want to switch to the panel on the left so it‚Äôs <code>C-b left</code> for us. Just once more, so that we fully understand this: This means you press <code>Ctrl</code> and <code>b</code> (your prefix) followed by the <code>left</code> arrow key to get to the pane on the left.</p>

<p>You can now go ahead and split each of your new panels even further. Feel free to experiment and split your panes like a maniac to get a feeling for it.</p>

<h3 id="closing-panes">Closing Panes</h3>
<p>Closing a pane is as simple as closing a regular terminal session. Either type <code>exit</code> or hit <code>Ctrl-d</code> and it‚Äôs gone.</p>

<h3 id="creating-windows">Creating Windows</h3>
<p>Windows in tmux can be compared to creating new virtual desktops; if you‚Äôve ever worked with one of the major Linux deskop environments (KDE, Gnome) you‚Äôll hopefully find this analogy helpful.</p>

<p>Creating new windows is as easy as typing <code>C-b c</code> (one last time: that‚Äôs <code>Ctrl</code> and <code>b</code> at once, then <code>c</code>). The new window will then be presented to you in tmux‚Äôs status bar.</p>

<p><img src="https://www.hamvocke.com/assets/img/uploads/tmux_window.png" alt="tmux with two windows"></p>

<p>You can now divide the pane in your new window as you like. Or don‚Äôt. That‚Äôs up to you.</p>

<p>To switch to the <em>previous</em> window (according to the order in your status bar) use <code>C-b p</code>, to switch to the <em>next</em> window use <code>C-b n</code>. If you‚Äôve created many windows you might find it useful to go to a window directly by typing its number (the status bar will tell you which window has which number), just use <code>C-b &lt;number&gt;</code> where &lt;number&gt; is the number in front of the window‚Äôs name in your status bar.</p>

<h3 id="session-handling">Session Handling</h3>
<p>If you‚Äôre done with your session you can either get rid of it by simply exiting all the panes inside or you can keep the session in the background for later reuse.</p>

<p>To detach your current session use <code>C-b d</code>. You can also use <code>C-b D</code> to have tmux give you a choice which of your sessions you want to detach. This will detach your session but will leave you‚Äôre doing in that session running in the background.</p>

<p>Now that your session is detached you can pick it up from where you left it at any later point in time. To re-attach to a session you need to figure out which session you want to attach to first. Figure out which sessions are running by using</p>



<p>This will give you a list of all running sessions, which in our example should be something like</p>

<blockquote>
  <p>0: 2 windows (created Sat Aug 15 17:55:34 2015) [199x44] (detached)</p>
</blockquote>

<p>To connect to that session you start tmux again but this time tell it which session to attach to:</p>



<p>Note that the <code>-t 0</code> is the parameter that tells tmux which session to attach to. ‚Äú0‚Äù is the first part of your <code>tmux ls</code> output.</p>

<p>If you prefer to give your sessions a more meaningful name (instead of a numerical one starting with 0) you can create your next session using</p>



<p>This will create a new session with the name ‚Äúdatabase‚Äù.</p>

<p>You could also rename your existing session:</p>

<div><div><pre><code>tmux rename-session -t 0 database
</code></pre></div></div>

<p>The next time you attach to that session you simply use <code>tmux attach -t database</code>. If you‚Äôre using multiple sessions at once this can become an essential feature.</p>

<p>And that‚Äôs it! Congratulations, you‚Äôve just completed your first tmux session and got your hands dirty with its window and session management. Yes, there‚Äôs more stuff tmux can do. But what you‚Äôve just learned should be everything to start using tmux in the future.</p>

<h2 id="why-tmux">Why tmux?</h2>
<p>A response that I get quite often is: ‚ÄúGreat, I get it. But why should I use tmux and its weird key combinations instead of just using iTerm2?‚Äù</p>

<p>And you‚Äôre right, when it‚Äôs only basic window management, <a href="http://iterm2.com/">iTerm</a> for Mac supports tabs and panes as well. For Linux there‚Äôs <a href="http://gnometerminator.blogspot.com/p/introduction.html">Terminator</a>. So why would anyone feel the urge to learn some archaic technology in this day and age?</p>

<p>But you‚Äôre missing out. There are a couple of reasons why I favor tmux over iTerm et al.:</p>

<ul>
  <li>session handling: detaching from and attaching to sessions helps me with context switching and remote working</li>
  <li>platform independence: I can ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/">https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/</a></em></p>]]>
            </description>
            <link>https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298492</guid>
            <pubDate>Mon, 01 Mar 2021 00:32:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use the Principled Volume shader in Blender]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298458">thread link</a>) | @saturn5k
<br/>
February 28, 2021 | https://petarpetkovski.net/how-to-use-the-principled-volume-shader-in-blender/ | <a href="https://web.archive.org/web/*/https://petarpetkovski.net/how-to-use-the-principled-volume-shader-in-blender/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="content" role="main"><div><div><article id="post-3494"><div><p>This is a short tutorial on how to add a volume shader (<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/shader/volume_principled.html" target="_blank" rel="noopener">Principled Volume</a>) in <a href="https://www.blender.org/" target="_blank" rel="noopener">Blender</a> to achieve an atmospheric and cinematic look. This is for users that are at least already familiar with the Blender UI as I will not be sharing details about scene setup, shortcuts or render settings.</p><p>My scene setup is fairly simple consisting of a few models, a plane with an added displacement/height map (terrain), a sun light and a spot light (for the antenna). As we can see from the screenshots below, the lightning looks very harsh because it illuminates the scene without any diffusion from small particles in the scene such as air/pollution. The scene looks rather plain and boring with no exciting photon action.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/scene-setup-01-1200x669.jpg" alt="" width="1200" height="669" srcset="https://petarpetkovski.net/wp-content/uploads/scene-setup-01-1200x669.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-744x415.jpg 744w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-420x234.jpg 420w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-768x428.jpg 768w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-560x312.jpg 560w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-1536x857.jpg 1536w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01.jpg 1581w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>Here is another look on the 3D environment. On the left side we can see the shader editor screen with the node configuration applied to the main plane to achieve the displaced terrain using a height map. All the view-port rendering is done in Cycles.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/displacement-1200x640.jpg" alt="" width="1200" height="640" srcset="https://petarpetkovski.net/wp-content/uploads/displacement-1200x640.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/displacement-744x397.jpg 744w, https://petarpetkovski.net/wp-content/uploads/displacement-420x224.jpg 420w, https://petarpetkovski.net/wp-content/uploads/displacement-768x409.jpg 768w, https://petarpetkovski.net/wp-content/uploads/displacement-560x298.jpg 560w, https://petarpetkovski.net/wp-content/uploads/displacement-1536x819.jpg 1536w, https://petarpetkovski.net/wp-content/uploads/displacement.jpg 1576w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>Next, insert a plain cube into the scene and resize it to match the scene and visible area that will be rendered. We are going to make this cube look as it is made from fog. A foggy cube.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-1200x637.jpg" alt="" width="1200" height="637" srcset="https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-1200x637.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-744x395.jpg 744w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-420x223.jpg 420w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-768x407.jpg 768w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-560x297.jpg 560w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-1536x815.jpg 1536w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02.jpg 1578w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>Once we are finished adjusting the cube size, go to the shader editor and apply a ‚ÄúPrincipled Volume‚Äù shader to the cube. Adjust the ‚ÄúDensity‚Äù and ‚ÄúEmission Strength‚Äù values as well as corresponding colors to get the desired fog/atmosphere effect. You can also play with the strength of the sun light that‚Äôs illuminating the entire scene to see how it will interact with this newly added volume. You may want to adjust the Prinicpled Volume values depending on the sun strength.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/set-shader-03-1200x628.jpg" alt="" width="1200" height="628" srcset="https://petarpetkovski.net/wp-content/uploads/set-shader-03-1200x628.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-744x390.jpg 744w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-420x220.jpg 420w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-768x402.jpg 768w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-560x293.jpg 560w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-1536x804.jpg 1536w, https://petarpetkovski.net/wp-content/uploads/set-shader-03.jpg 1579w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>Once we are done tweaking and adjusting the volume options and lightning position, we can set up the camera for that perfect angle and wait a couple of minutes for our render to finish. Although by using this method you will get way longer rendering times, the final result is much better and has a more natural look and feel. The light is soft and diffused thanks to the added volume, which makes the scene alive and more present.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/final-render-04-1.jpg" alt="" width="1200" height="800" srcset="https://petarpetkovski.net/wp-content/uploads/final-render-04-1.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-744x496.jpg 744w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-420x280.jpg 420w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-768x512.jpg 768w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-560x373.jpg 560w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-930x620.jpg 930w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>That‚Äôs all for now, and I hope someone gets inspired by this :)</p><p>Read other stuff <a title="Blog" href="https://petarpetkovski.net/blog/">here</a>.</p></div></article></div></div></main></div></div>]]>
            </description>
            <link>https://petarpetkovski.net/how-to-use-the-principled-volume-shader-in-blender/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298458</guid>
            <pubDate>Mon, 01 Mar 2021 00:27:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Planck 6502, an open hardware extensible retro computer]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26298278">thread link</a>) | @jfoucher
<br/>
February 28, 2021 | https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html | <a href="https://web.archive.org/web/*/https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>February 28, 2021 | <span>7</span> Minute Read</p>
  
  <p><img src="https://jfoucher.com/uploads/2021/02/1.jpg" alt="">
    </p>

  <h3 id="retro-computing">Retro computing</h3>

<p>Going back to the roots of your field can provide new insights into your day to day experience. For me, the roots are located in the 70s / 80s a time when personal computers were much simpler and could be fully understood by a regular person. This is a time when the most popular computers were the Vic20, Apple II and later Commodore 64.</p>

<p><img src="https://jfoucher.com/uploads/2021/02/VIC-20.jpg" alt="Vic-20">
<img src="https://jfoucher.com/uploads/2021/02/Apple_II.jpg" alt="Apple II"></p>



<p>These computers booted in less than a second to a raw basic prompt. To be clear: you turn on your computer, and less than one second later you start programming. How wonderful would that be, in our land of a thousand node dependencies, failing composer upgrades and wrong vagrant configurations?</p>

<h3 id="what-to-build">What to build?</h3>

<p>I was increasingly interested in electronics since doing a project for a friend, so I thought to myself ‚ÄúHow hard can it be?‚Äù Well, as it turns out, quite, but that‚Äôs hardly the point right now. The point is: what should I build? I started by building a simple 6502 based computer on a breadboard. I soon realised that if I was to have anything half useful I was going to need the entire breadboard production of China to be delivered to my house. Also breadboard computers are buggy and you can‚Äôt move them around because then a cable will come loose and you will spend five hours troubleshooting your code instead.</p>

<p>So I decided I would convert it to PCBs. They are pretty cheap to get delivered from China, but since they take about a month to arrive the rate of iteration is not so great. Better to get it right the first time obviously.</p>

<p>Well I almost did. The first one was very simple, only having a 6502 processor and an 6522 parallel port interface. I interfaced with it from my computer via SPI through an arduino: the 6522 Versatile Interface Adapter can bit bang SPI easily enough. The Arduino Uno/Nano can be an SPI slave easily enough and receive that data. It can then transmit that data to my computer using serial over USB.</p>

<p>That worked fine (after a couple of bodge wires) but was a bit kludgy, having the Arduino sort of hanging there by a few cables.</p>

<p>I then tried to design a single board computer with everything I would ever want on it: serial communication, parrallel port, SPI port(s), i2c port(s), PS/2 port for a keyboard, sound chip, VGA output, etc‚Ä¶ The board to house all of this was very big and thus very expensive. Combining this with the previous point regarding getting it right the first time, a single board computer suddenly seemed like not that great of an idea.</p>

<h3 id="the-plan">The plan</h3>

<p>I then decided to build a board with basic circuitry into which other boards that provided actual functionality will be able to plug in. Turns out that already exists and is called a <a href="https://en.wikipedia.org/wiki/Backplane">backplane</a></p>

<p>So backplane it is then. The size limit for this board and all others will be 10cm x 10cm as that it the cheap price limit for most cheap board houses (yes I‚Äôm cheap and I like cheap, preferably cheap that works).</p>

<p>Here is the backplane design:</p>

<p><img src="https://jfoucher.com/uploads/2021/02/backplane.png" alt="backplane 3D view"></p>

<p>As you can see, it is mostly just slots to plug in the extension boards. The only active components are the clock generation circuit, and some decoding to activate the expansion slots when they are needed.</p>

<p>The rightmost slot is reserved for the CPU card. The CPU card includes some RAM and ROM, which means the computer is already functional with just this single board plugged in, although admittedly it won‚Äôt <em>do</em> much in that configuration.</p>

<p>To get the computer to do stuff it‚Äôs best to plug in some additional boards.</p>

<p>The initial design includes an IO board with PS/2 port, SPI ports and a parallel port (and LEDs, of course it has LEDs!) as well as a serial board to allow the user to communicate with the computer.</p>

<p>After waiting patiently forever for the boards to arrive, I put it all together and gave it a try. It did not work at all. Of course there were mistakes on the boards, which confirmed the soudness of my choice of not doing one huge board at once.
However not all the boards were defective, and the bad ones were quickly fixed with a few wires here and there.</p>

<p>After which, plugging a usb to serial adapter into the serial board, and into a usb port on my computer, I could see the Planck computer doing something!</p>

<p>Here it is running <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)">Forth</a> over serial</p>

<p><img src="https://jfoucher.com/uploads/2021/02/running-forth.jpg" alt="Forth over serial on the Planck computer"></p>

<p>I am currently working on more expansion boards, such as an LCD board, a sound card, and a VGA card. <a href="https://jfoucher.com/feed.xml">Stay tuned</a> for more.</p>

<p>For more details about this project, please use the links below:</p>

<ul>
  <li><a href="https://planck6502.jfoucher.com/">Project website</a></li>
  <li><a href="https://gitlab.com/planck-6502/planck-6502">Hardware and source code</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298278</guid>
            <pubDate>Sun, 28 Feb 2021 23:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreshBSD 2021: Relaunching the BSD Commit Log Search Engine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298079">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://freshbsd.org/news/2021/02/28 | <a href="https://web.archive.org/web/*/https://freshbsd.org/news/2021/02/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><h2><a href="https://freshbsd.org/news/2021/02/28">FreshBSD 2021</a></h2></header><section><p>6 weeks ago I created a branch for a significant rework of FreshBSD.  Nearly 300
commits later, and just a week shy of our 15th anniversary, the result is what
you‚Äôre looking at now.  I hope you like it.</p>

<p>There‚Äôs loads of internal changes, but here‚Äôs the main user-facing stuff:</p>



<p>We have a new vector logo I knocked together in <a href="https://inkscape.org/">Inkscape</a>,
a new <a href="https://slimselectjs.com/">drop-down select library</a>, a new pagination
widget that offers to reverse the sort order rather than encouraging you to visit
page 170,000, and a variety of style tweaks to (hopefully) make things a bit nicer.</p>

<h2 id="prettier-urls">Prettier URLs</h2>

<p>The site has a new URL scheme, and a much better system for generating them from queries.
Where possible they‚Äôll be automatically applied using JavaScript to make sharing links
more pleasant.  For example, this monstrosity:</p>

<blockquote>
  <p>/search?q=&amp;project%5B%5D=freebsd&amp;repository%5B%5D=src&amp;branches%5B%5D=releng%2F12.0&amp;sort=commit_date</p>
</blockquote>

<p>Becomes:</p>

<blockquote>
  <p>/freebsd/src/branch/releng/12.0</p>
</blockquote>

<p>Old URLs should continue to work.</p>



<p>A new grouped <code>Source</code> filter replaces <code>Project</code> and <code>Repository</code>, making it much
easier to go straight to the repositories you‚Äôre interested in.</p>

<p>There‚Äôs also a new filter for merge commits, though this currently only works for git-based
repositories.</p>



<p>According to <a href="https://developers.google.com/speed/pagespeed/insights/">PageSpeed Insights</a>:</p>

<ul>
  <li>Old front page: 4,814 DOM elements, 148 KiB, 2.3s to interactive.</li>
  <li>New front page: 1,616 DOM elements, 37 KiB, 0.5s to interactive</li>
</ul>

<p>This is a combination of improvements, including:</p>

<ul>
  <li>Removal of jQuery and Font-Awesome‚Äôs WebFont/CSS</li>
  <li>Branch/tag/committer filters being suppressed</li>
  <li>Result counts and aggregations calculated in the background during rendering</li>
  <li>Multithreaded commit rendering</li>
  <li>Reduction in per-page results from 50 to 30</li>
  <li>Improved caching, with a warmup query for the front page on index updates</li>
</ul>



<p>I‚Äôve done a lot of work to improve the quality of the code, which in turn makes
further changes easier and more appealing.  This also brings us closer to the
point at which I‚Äôll be comfortable publishing the codebase.</p>

<p>In the mean time, I hope you continue to find the site useful.  If you have any
feedback, please email me at <a href="mailto:tom@hur.st">tom@hur.st</a>, or Tweet me at
@blaagh.</p>

<p>Cheers.</p>
</section></article></div>]]>
            </description>
            <link>https://freshbsd.org/news/2021/02/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298079</guid>
            <pubDate>Sun, 28 Feb 2021 23:22:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squeak: A Free Smalltalk System ‚Äì On RISC OS]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26298075">thread link</a>) | @lproven
<br/>
February 28, 2021 | http://www.rowledge.org/tim/squeak/ | <a href="https://web.archive.org/web/*/http://www.rowledge.org/tim/squeak/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- .sidebarContainer -->
			<div>
				<p><span>Squeak: A Free Smalltalk system</span></p><p><img alt="" src="http://www.rowledge.org/tim/squeak/files/page17_1.jpg" width="295" height="205"><br></p><p><span>What is Squeak?</span><br>Squeak is a free Smalltalk system originally released by a team including Alan Kay, Dan Ingalls, Ted Kaehler, John Maloney and Scott Wallace in 1996 when they were working at Apple. You might recognise the first three names from early Smalltalk papers from Xerox PARC. They produced a rather nice Smalltalk system with the unusual virtue that both the image and the Virtual Machine are open source - i.e. free, gratis and "no charge to you sir".<br><span>Finding Out More About Squeak</span><br>To find most of the web resources for Squeak, look at the <a href="http://www.squeak.org/" rel="self">Squeak.Org</a> site. There are lots of pointers to information about Smalltalk, instructions for downloading Squeak, tutorials, FAQs etc. I won't waste space by duplicating any of it here. I do most strongly recommend that you read many of them.<br><span>Squeak runs on...</span><br>Macs, iPhones, most UNIX &amp; Linux systems, Windows of various versions, <a href="http://www.riscos.org/" rel="external">RISC OS</a> and some obscure specialised systems. See the above mentioned master page for details on how to get the files.<br>I‚Äôve spent many years making Smalltalk available for RISC OS and other <a href="http://www.arm.com/" rel="self">ARM</a> based systems including the original Acorn Archimedes &amp; RPC desktops, the Active Book, an early prototype version of the Compaq ‚ÄòiPaq‚Äô handheld, the Interval Research ‚ÄòMediaPad‚Äô, an HP prototype pad-thing and other stuff still secret.<br><span>New News of a newsish nature</span><br>2013 - Squeak is back on RISC OS! Those nice people at the <a href="http://www.rowledge.org/tim/squeak/www.raspberrypi.org" rel="external">Raspberry Pi Foundation</a> sent me a Pi; it has RISC OS on it and I‚Äôve been getting things working on it. </p><p><img alt="IMG_0467" src="http://www.rowledge.org/tim/squeak/files/img_0467.jpg" width="519" height="388"><br></p><div><p>It runs quite nicely in general; the Pi‚Äôs RISC OS graphics kernel is a bit slow seeming right now but there is work being done that should improve that significantly. It supports <a href="http://scratch.mit.edu/" rel="external">Scratch</a> as well and runs it decently - though there is a lot of work being done to improve that, too. Somewhat perversely, MIT decided to rewrite Scratch in Flash (belch) ‚Äòfor better browser support‚Äô and seem to have abandoned the ‚Äòold‚Äô Squeak based system. Since Flash doesn‚Äôt run on RISC OS  nor indeed on ARM systems in general, we‚Äôll be supporting ‚Äòold‚Äô Scratch for a while.<br>You can download a copy of Squeak for RISC OS from the central <a href="http://www.squeakvm.org/riscos" rel="external">squeakvm.org </a>site.<br>Currently I‚Äôm working for the Pi foundation to improve Scratch under Raspbian (their linux version) by rewriting some of the more egregiously ugly code, improve algorithms, tweak vm configurations and so on. As of early-2014 it‚Äôs significantly faster than the original version with a fair bit more to come. A major project has been <a href="http://www.raspberrypi.org/test-tims-nuscratch-beta/" rel="external">porting the code forwar</a>d to the latest Squeak image so that it can run on the most modern VMs; right now it is using the ‚ÄòStackVM‚Äô. I hope to get the newer design dynamic translating VM working soon.<br>When and if possible all of this will get moved over to RISC OS but making a living comes first!</p><p> <span>Building the VM with VMMaker</span><br>I also developed and for many years maintained the VMMaker package, the lump of Squeak code that defines and generates the bulk of the VM. See the VMMaker page on the <a href="http://wiki.squeak.org/squeak" rel="self">Squeak Swiki</a> for more info. You can fetch the VMMaker package from <a href="http://map1.squeakfoundation.org/sm" rel="self">SqueakMap</a> or use the SqueakMap tool in the image and look for (guess what) VMMaker. You will also need a <a href="http://subversion.tigris.org/" rel="external">SubVersion</a> client so that you can fetch the handwritten parts of the VM source code from the repository.<br>Once you have mastered the complexities of the VMMaker and successfully built yourself a custom VM you should download<a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/SqueakVMBuilderCertificate.pdf" rel="self"> this certificat</a>e to attest to your mighty geekiness.<br><span>Stuff wot I wrot</span><br>	‚Ä¢	I contributed a chapter describing the structure, function, design and implementation of virtual machines and the lowest level of Smalltalk code to <a href="http://www.amazon.com/Squeak-Open-Personal-Computing-Multimedia/dp/0130280917" rel="external">"Squeak: Open Personal Computing and Multimedia"</a> edited by Mark Guzdial and Kim Rose, published by Prentiss-Hall. An online version of <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/OE-Tour.pdf" rel="self">that chapter is here</a>.<br>	‚Ä¢	I worked on a <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/RTOSinSmalltalk.html.pdf" rel="self">realtime OS in Squeak</a> whilst employed at Interval Research Corp<br>	‚Ä¢	A short paper on making <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/LEBB.pdf" rel="self">BitBlt work for little-endian</a> machines without having an intermediate display-on-screen conversion<br><span>Squeak logo artwork</span><br>At the dawn of Squeak-time we needed a logo. Every project needs a logo. I designed one, it caught on and can be found all over the web, on T-shirts, sweatshirts, books, badges, underwear, hats and probably secret spy satellites in geosynchronous orbit. (No, seriously; there is now at least one satellite running Squeak code!)<br>Here are some files of the Squeak logo that you may like to use:-</p></div><p>Feel free to download them and use them for links etc. If you'd like any other size, I can easily generate them for you from vector artwork. If you want to use it for a project of some sort relating to Squeak you are most welcome to do so - if you are making a neat badge or shirt or publishing a book I‚Äôd love a copy if at all practical.</p>
				
			</div><!-- .content -->
		</div></div>]]>
            </description>
            <link>http://www.rowledge.org/tim/squeak/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298075</guid>
            <pubDate>Sun, 28 Feb 2021 23:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OMU ‚Äì ‚ÄúOne Man Unix‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 25 (<a href="https://news.ycombinator.com/item?id=26298022">thread link</a>) | @marcodiego
<br/>
February 28, 2021 | http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html | <a href="https://web.archive.org/web/*/http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<center>

</center>
<h2>
History:
</h2>
In the late 1970s and early 1980s (the good old days of "hobby computing") before
the IBM PC and its clones took over the world, various microprocessor based kits
appeared on the hobbyist market. You could build a Z80-based board with 8K of
RAM, and with its hexadecimal keypad and LED display you could run simple
programs laboriously keyed in hex.
<p>
The first generation commercial machines also appeared - usually based on
the 8080 or the Z80 or 6502. The Commodore PET was one of the early sucesses
and it, along with the Commodore 64, Sinclair's three machines (ZX80, ZX81 and
Spectrum) and the BBC Micro probably accounted for most of the infant home-computer
market in Britain.
</p><p>
I decided on a different approach. Unhappy with the concept of having to re-live
the glory-days of the
<a href="http://www.computer50.org/mark1/MM1.html">
Manchester MkI
</a>
with the hobby-boards fraternity (!), and unhappy with the straitjacketed
architectures and joke operating systems of the 1st generation home computers,
I yearned for more. Specifically, what I wanted was something
more like a Unix clone at home. I was used to V7 Unix on the PDP-11 at university
and wasn't keen to step backwards 10 years to the technology of CP/M and BASIC
programming.
<br>
<i>
I wasn't to know that eight years later a guy called Linus
Torvalds was going to think the same thoughts and do much the same things. The
big difference was that he was in the right place and the right time and 
had internet connectivity - I didn't have any of these advantages!
</i>
</p><p>
I went off and built myself a 6809 based computer with 64K of RAM, a 360K
floppy disk drive and an RS232 interface which could drive a glass-TTY.
Please remember that this was 1982. Hard disks, megabytes of RAM and other
familiar modern things were a long way off.
</p><p>
After going through the usual hard work of writing a BIOS complete with
an S-records downloader, I was in a position to write myself an operating
system. Preliminary work on OMU started in late 1983. My earliest surviving
printouts of the sources on yellowed, faded lineprinter paper show that the
bulk of the work on OMU dates from March/April/May 1984.
</p><p>
Work was not helped by the fact that I was having to write a 'C' compiler
in parallel, but certainly by mid 1984 I had a perfectly usable O/S with a
primitive shell, a port of Unix 'ed' for an editor, and with 'fsck' and other
such tools available to repair the filestore disks when they got damaged by
miswrites from the rather dodgy floppy-disk hardware. I remember taking
the machine home over Christmas 1984 and typing up several reports using it
on the kitchen table.
</p><p>
<table>
<tbody><tr>
<td>
I just found this photo of the 1984 machine amongst a box of slides taken
over that Christmas. It appears to be the only photo of the machine I ever
took at the time.
<p>
At this point in its evolution, the hardware was mostly on one double
eurocard, with a floppy-disk interface piggybacked onto it. The floppy-disk
drive is in the metal box at front, and the bigger metal box at the RHS
of the PCBs is the power-supply.
</p></td>
<td>
<a href="http://www.pix.net/mirrored/discordia.org.uk/~steve/omu-big.jpg">
<img src="http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.jpg">
</a>
</td>
</tr>
</tbody></table>
</p><h2>
Features and misfeatures list:
</h2>
<ul>
<li>
Tiny (24K) Kernel.
</li><li>
V7 Unix-compatable filestore (doesn't support triple-indirection blocks).
Not exactly critical on a floppy-disk-only system!
</li><li>
Normal Unix-style use of /dev/* files to interface to devices.
</li><li>
Mountable/dismountable filestores as expected.
</li><li>
Shell is built-in to save space, rather than run as a process.
</li><li>
tty driver is exceedingly minimal, but functional.
</li><li>
No true multitasking (see below).
</li><li>
UIDs and GIDs not implemented. They're ignored on the filestore, and the
process table doesn't bother to hold them. Any files created would be given
UID = GID = 0.
</li></ul>
<p>
The lack of an MMU and the small amount of RAM available meant that I
decided against trying to implement true multitasking. Instead (like DOS
as it happens) I came up with a scheme whereby a process could launch another
process, but would have to wait for it to complete. Clunky, but it worked
OK.
</p><p>
For your entertainment (or possibly if you're interested in the possibility
of porting my old O/S to more modern hardware like that old XT that's
gathering dust under your table) here's a downloadable copy of my
final version of the 6809 OMU as it stood in 1987:
</p><center>

</center>
<p>
In order to make any use of OMU, I had compiled up a set of utilities like
'ed' and 'mount' and 'fsck'. Sadly I don't think I can make their sources
downloadable here as they were based on the Unix V7 sources for which we had
a Bell Labs "academic use" licence at the university.
</p><p>
<strong>
<span color="#FF0000">
NEW!
</span>
</strong>
The above packages now include some utilities which I did write from scratch:
</p><ul>
<li><strong>adb</strong>
An interactive disassembler. (Doesn't debug core-dumps though, just lets
you look at code in files).
</li><li><strong>aka</strong>
("Also Known As") - finds other files hardlinked to the one mentioned on the
command-line.
</li><li><strong>chbase</strong>
Prints the number(s) given on the command-line in octal, decimal &amp; hex.
</li><li><strong>hex</strong>
Makes Motorola S-record files for sending to the 6809. Usually runs on a
host machine (a PDP-11 originally).
</li><li><strong>ida</strong>
An intelligent disassembler - shares source-code with 'adb' above.
</li><li><strong>sh</strong>
The tiny shell needed by the OMU kernel. OMU runs this as if it was the
'init' process.
</li><li><strong>sirius</strong>
An interactive disk-examination program.
</li><li><strong>unhex</strong>
A program to convert Motorola S-records into an OMU-loadable file. Usually
runs on the 6809 itself of course.
</li></ul>
Sorry, no documentation, but the source-code should be documentation enough!
<p>
I
<strong>
don't
</strong>
suggest any modern user of OMU on a 6809 tries getting GNU utilities running
with it! Bear in mind that V7 sources would compile into a smaller executable
than any modern GNU equivalents. With the 64K memory-address limitation of my
6809, this was important! The BIOS and O/S accounted for about 24K of this, so
user-programs were limited to about 40K total. I never did complete my
page-switched 256K memory system.....
</p><p>
Mind you, if you're contemplating porting to a 68000 or IBM-PC, the size
constraints will be much less of a problem.
</p><hr>
<p>
My work on OMU was pretty much unnoticed by anyone else in the world (we didn't
have an internet connection in those days), but others in the Electrical
Engineering dept at Swansea University saw the potential to port OMU to one of
several 68000 single-board-computers which began to appear in the department
from about 1984/85 onwards.
</p><p>
My colleage Terry Barnaby and I were variously involved with porting OMU
to several of these 68000 based SBCs. Terry did most of the work!
The first stage was merely to take OMU and get it to run on the new
hardware much as my 6809 version was doing already. This was accomplishe
reasonably quickly, complete with the addition of the OMU's first driver
for a hard-disk.
The much greater memory-addressing ability of the 68000 coupled with the
fact that the SBCs typically had 256K of RAM on board meant that this version
of OMU soon featured some multi-tasking capabilities (though with no MMU
available the processes had to be well-behaved).
</p><p>
For convenience, the details of the filestore layout and the system-call
interface of 68000 OMU was designed to duplicate those of the commercial 68000
V7 Unix system made by "Codata" (we had just taken delivery of two of these
units to augment the aging PDP-11).
It is I think a credit to OMU's potential that
it soon became possible to compile programs on the Codata, and run them on
OMU with no problems. Indeed, it was also possible to take system binaries
shipped with the Codata and run them on OMU too - an easy way to get 'vi'
and other state-of-the-art (!) software on OMU without having to dig out the
sources and recompile!
</p><center>

</center>
<p>
Terry Barnaby and another of his colleages Tim Ingersoll then made some
fundamental changes to the message-handling abilities of the 68000 OMU port to
make it suitable for Real-Time signal processing and control applications.
This was after all what the two of them really
wanted as part of their Ph.D projects...! In 1988 they finished their
projects, wrote up and left. Part of their legacy was the RTOS version of OMU,
and I managed to salvage a set of sources for that too:
</p><center>

</center>
<p>
If any reader of these pages feels suitably daring they may be able to
beat me to the target of porting OMU (probably working from Terry's and my
initial 68000 version above) to the IBM PC. I consider that there really is no
point in aiming for the 386 processor machines onwards as Linux already does
everything you could hope for on that class of machines.
</p><p>
It does however seem that there is mileage in starting with the boot-loader
that comes with
<a href="http://metalab.unc.edu/pub/micro/pc-stuff/freedos/">
FreeDOS
</a>,
and getting OMU to run on 8086/80286 machines of which there must be
<strong>
loads
</strong>
lying around virtually unwanted these days.
</p><p>
If you do decide to try such a thing, then I wish you the best of luck and
I'll offer any email help I can. My email address is in the README file
included with the any of the sets of downloadable sources.
</p><h2>
Acknowledgements:
</h2>
My thanks go to Terry and Tim whose work in enhancing OMU is credited here
and really should have been reflected in a name-change from OMU back in the
Eighties! (I never did get it straight in my mind as to whether the "one man"
mentioned in the title were there to signify the number of authors or
the number of simultaneous users. Either way, neither was very relevant once
as the software started its modest spread in the department.)
<p>
My thanks also go to Alan Cox (he of Linux networking and kernel hacking fame)
without whose prodding this page might never have been written.
</p><center>
<a href="http://www.pix.net/mirrored/discordia.org.uk/~steve/steve.html">
Home
</a>
</center>
<hr>
<p>
Copyright (c) 1999, Steve Hosgood


</p></div>]]>
            </description>
            <link>http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298022</guid>
            <pubDate>Sun, 28 Feb 2021 23:15:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‚ÄúTungsten Fabric‚Äù: open-source network virtualization]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297724">thread link</a>) | @autoditype
<br/>
February 28, 2021 | https://tungstenfabric.github.io/website/ | <a href="https://web.archive.org/web/*/https://tungstenfabric.github.io/website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <p><img src="https://github.com/tungstenfabric/website/raw/master/TungstenFabric_Gradient_RGB-03.png" height="75" alt="Tungsten Logo Gradient"></p>

<hr>

<p>Tungsten Fabric is an open source network virtualization solution for
providing connectivity and security for virtual, containerized or
bare-metal workloads.</p>

<p>Tungsten Fabric supports integrations with the following orchestrators:</p>
<div><div><pre><code>Openstack
Kubernetes
Openshift
vCenter
BYOO [Bring your own orchestrator]
</code></pre></div></div>

<p>Tungsten Fabric is a part of the <a href="https://www.lfnetworking.org/">Linux Foundation Networking Fund</a>, a project of the <a href="http://linuxfoundation.org/">Linux Foundation</a>.</p>

<hr>

<h2 id="start-using-tungsten-fabric">Start using Tungsten Fabric</h2>
<p><a href="https://tungstenfabric.github.io/website/Tungsten-Fabric-15-minute-deployment-with-k8s-on-AWS.html">Deploy Tungsten Fabric in 15 minutes on AWS with Kubernetes</a></p>

<p><a href="https://tungstenfabric.github.io/website/Tungsten-Fabric-Centos-one-line-install-on-k8s.html">Deploy Tungsten Fabric on Kubernetes in 1-step command - Centos</a></p>

<p><a href="https://tungstenfabric.github.io/website/Tungsten-Fabric-Ubuntu-one-line-install-on-k8s.html">Deploy Tungsten Fabric on Kubernetes in 1-step command - Ubuntu</a></p>

<p><a href="https://github.com/Juniper/contrail-ansible-deployer/wiki/Contrail-with-Openstack-Kolla">Deploy Tungsten Fabric On-Prem with Openstack</a></p>

<p><a href="https://tungstenfabric.github.io/website/Tungsten-Fabric-Architecture.html">Tungsten Fabric Detailed Architecture Document</a></p>

<p><a href="https://tungstenfabric.github.io/website/L10N/Tungsten-Fabric-Architecture-CN.html">Tungsten Fabric Detailed Architecture Document (Simplified Chinese)</a></p>

<h2 id="becoming-a-contributor">Becoming a contributor</h2>

<p>Whether you want to fix a typo in comments or introduce a brand new feature,
there are a few steps which make the process smoother:</p>

<ul>
  <li>
    <p>Create a <a href="https://identity.linuxfoundation.org/">Linux Foundation ID</a>, if you don‚Äôt have one yet. You‚Äôll need this to subscribe to the mailing lists and to access the bugs and blueprints.</p>
  </li>
  <li>
    <p>Subscribe to the <a href="https://lists.tungsten.io/g/dev">dev@lists.tungsten.io</a> mailing list. If you wish, there are also <a href="https://lists.tungsten.io/">several other mailing lists</a> you can join as well.</p>
  </li>
  <li>
    <p>The wiki currently contains legal and technical docs, event decks and similar resources to boost your
understanding of Tungsten Fabric. This material will eventually be moving to
<a href="https://wiki.tungsten.io/">the wiki</a> or Git repositories.</p>
  </li>
  <li>
    <p><a href="https://join.slack.com/t/tungstenfabric/shared_invite/enQtMzM0MjMyMDIzMzk3LTZmY2FmY2JlZmRjN2YxMzgyOTNkNDZiNTRiYWU0NTRmNzI3N2RjMDIwY2UxZDlkODgzZDE0YzQ3MTlhNTg0N2I">Join Slack</a>. Post your questions to relevant channels, don‚Äôt abuse @here,
get help and help others. The mailing list works best for long-running
discussions; Slack is great for ad-hoc conversations.</p>
  </li>
  <li>
    <p>Before you push anything, you‚Äôll need to sign a Contributor License Agreement
or CLA: either Individual CLA (ICLA) if you are an independent contributor, or
Corporate CLA (CCLA). We suggest you sign a CCLA if you are employed at a company
which pays you for your Tungsten Fabric-related work. CCLA also simplifies things
if your teammates plan to contribute as well. Both ICLA and CCLA are legal documents.
Please read them carefully. It‚Äôs usually smart to run the document past your
company‚Äôs legal department before signing and submitting it, if only to verify
that your contribution will be within your company‚Äôs policy. You can find all
ICLA/CCLA documents in the <a href="https://wiki.tungsten.io/display/TUN/Contributor+License+Agreement">Tungsten Fabric CLA Wiki</a>.</p>
  </li>
  <li>
    <p>If you‚Äôve found a bug, <a href="https://jira.tungsten.io/projects/TFB/issues/TFB-15?filter=allopenissues">file a bug report</a> against the respective release in
Jira. Be sure to describe both expected and actual behavior. You‚Äôll need
the bug ID later, so please do this even if you feel the change is trivial.</p>
  </li>
  <li>If you plan to develop a new feature, you must create or provide three things:
    <ul>
      <li><a href="https://jira.tungsten.io/projects/TFP/issues/TFP-6?filter=allopenissues">A blueprint</a>. A blueprint is a short piece of text describing which feature do you propose, why it is good to have it in Tungsten Fabric, and who will be developing it. Blueprints are very important as they are used to plan future releases of Tungsten Fabric.</li>
      <li><a href="https://github.com/Juniper/contrail-specs">A detailed technical spec</a>. Each blueprint should link to a more detailed technical specification document. These specifications must be submitted to the <a href="https://github.com/Juniper/contrail-specs">contrail-specs</a> GitHub repository. They are not stored or tracked in Jira.</li>
      <li><a href="https://jira.tungsten.io/projects/TFB/issues/TFB-15?filter=allopenissues">A Jira bug ticket</a>. While the blueprint briefly describes the work that will be done, the ticket is where the work actually happens (commits get linked to the ticket).</li>
      <li>Here is <a href="https://jira.tungsten.io/browse/TFP-13">an example of a complete Jira blueprint</a>.</li>
    </ul>
  </li>
  <li>Although contrail-specs and other Tungsten Fabric repositories are hosted on
<a href="http://github.com/tungstenfabric">GitHub</a>, they are managed with Gerrit. Please don‚Äôt send Pull Requests to the
GitHub repositories, and go to <a href="https://review.opencontrail.org/">https://review.opencontrail.org</a> instead.
Blueprint specs are submitted this way as well.</li>
  <li>
    <p>Note that Tungsten Fabric is currently migrating from Juniper owned <a href="https://review.opencontrail.org/">https://review.opencontrail.org</a> to [https://github.com/tungstenfabric/] email discuss@lists.tungsten.io for the latest information.</p>
  </li>
  <li>After getting Gerrit access as described below, clone the specs repository
with the command:
<code>git clone https://review.opencontrail.org/Juniper/contrail-specs</code>
and install the <a href="https://docs.openstack.org/infra/git-review/">git-review extension</a> which will allow you to submit specs as
well as code changes. In order to write a spec, start by copying the template
<code>blueprint_template.md</code> to a meaningful name in the appropriate subdirectory
for the release that you would like to target.</li>
</ul>

<p>With all of these in place, you are now ready to submit your specs and code to
Tungsten Fabric! How to write these specs and code is a different story though,
but we hope the links in the next section will help you to get started. You may
also want to consult a more detailed how-to available <a href="https://github.com/Juniper/contrail-community-docs/blob/master/Contributor/GettingStarted/getting-started-with-opencontrail-development.md">here</a>, in the
contrail-community-docs repo. And of course, feel free to ask questions on the
mailing list and in Slack channels!</p>

<h2 id="start-developing-tungsten-fabric">Start developing Tungsten Fabric</h2>

<p><a href="https://github.com/Juniper/contrail-dev-env">Build Tungsten Fabric</a></p>

<p><a href="https://github.com/Juniper/contrail-ansible-deployer/wiki/Debugging-contrail-code-in-contrail-microservices">Debug Tungsten Fabric</a></p>

<h3 id="development-timeline">Development Timeline</h3>

<p>NOTE: The columns and dates below are subject to change. An effort is still
underway to reconcile Tungsten Fabric processes and previously established
Juniper practices with respect to Contrail development timelines.</p>

<table>
  <thead>
    <tr>
      <th>Release</th>
      <th>Blueprint Due</th>
      <th>Specification Due</th>
      <th>Dev Complete</th>
      <th>GA Release</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5.0</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>2018-04-23</td>
    </tr>
    <tr>
      <td>5.0.1</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>2018-07-16</td>
    </tr>
    <tr>
      <td>5.1</td>
      <td>2018-07-15</td>
      <td>2018-08-22</td>
      <td>TBD</td>
      <td>Q1 2019</td>
    </tr>
  </tbody>
</table>

<h4 id="column-meanings">Column Meanings</h4>
<ul>
  <li>Release: The numeric identifier of the release</li>
  <li>Blueprint Due: Tungsten Fabric currently uses Jira, so the blueprint
due here refers to the <a href="https://jira.tungsten.io/projects/TFP/issues/TFP-6?filter=allopenissues">Jira Blueprint</a> which will be reviewed by the TSC for strategic alignment and release planning.</li>
  <li>Specification Due: The specification or ‚Äúspec‚Äù is design document with
section headings that should be filled in, or at least though about and decided
to be non-applicable. Specs should be submitted as described earlier in this
document.</li>
  <li>Dev Complete: This column may be considered synonymous with ‚Äúfeature freeze‚Äù
and is intended to mark the transition from ‚Äúnew development‚Äù to ‚Äútesting,
debugging and making production-ready‚Äù.</li>
  <li>GA Release: This column is the target release date. Historically Contrail has
usually missed release dates in order to finish incomplete features. Tungsten
Fabric will attempt to move to a time based release model, but this is still
under discussion.</li>
</ul>


      </section>
    </div></div>]]>
            </description>
            <link>https://tungstenfabric.github.io/website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297724</guid>
            <pubDate>Sun, 28 Feb 2021 22:30:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China and Huawei. The UK Gets a Lesson in Go]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297524">thread link</a>) | @nickdothutton
<br/>
February 28, 2021 | https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/ | <a href="https://web.archive.org/web/*/https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">




  <article>
    

    <section>




<p>4300 words, 14 minutes.</p>

<blockquote>
<p>This post was circulated privately in April 2020. Three months later the government announced that <a href="https://web.archive.org/web/20201101124331/https://www.gov.uk/government/news/huawei-to-be-removed-from-uk-5g-networks-by-2027">Huawei 5G equipment will be removed from the UK by 2027</a>, a reversal of their previous position. I‚Äôve updated the timeline with that development. Otherwise, the text is almost unchanged from the original. Keep that in mind. It follows my <a href="https://blog.eutopian.io/huawei-5g/">July 2019</a> post on the consideration the UK and its allies are giving to Huawei as a supplier of 5G mobile equipment. If you didn‚Äôt read that, now is a good time. - Nick Hutton, 29th November 2020.</p>
</blockquote>

<p><img src="https://blog.eutopian.io/images/go-players.jpg" alt="Chinese Playing Go">
</p><center>
Chinese men playing Go. Ming Dynasty (1368‚Äì1644). Artist unknown.
</center>

<p><em>4000 years ago the Chinese invented ‚ÄúGo‚Äù. Unlike Indo-European Chess, Go takes longer to play and uses a larger board. In Go, the goal is not to confront your opponent directly as one does in Chess. The winning system in Go is to surround them gradually and occupy their territory.</em></p>

<h3 id="current-events">Current Events</h3>

<p>In the nine months since my last post, the UK elected a Prime Minister, formed a new government, resiled from the European Union, and fought a global pandemic. However, we‚Äôve struggled to reach a consensus on whether or not we should buy 5G network equipment from Huawei, a designated <a href="https://www.ncsc.gov.uk/guidance/ncsc-advice-on-the-use-of-equipment-from-high-risk-vendors-in-uk-telecoms-networks#section_5">High-Risk Vendor</a>. Here‚Äôs a summary of events since my last post:</p>

<ul>
<li>The government announced Huawei can supply up to 35% of edge (non-core) equipment to Mobile Network Operators.<sup id="fnref:1"><a rel="footnote" href="#fn:1">1</a></sup></li>
<li>NCSC‚Äôs Technical Director, Dr Ian Levy lamented the lack of 5G suppliers, endorsed the Edge vs Core distinction for improving supplier diversity, and endorsed technical measures as an effective strategy for mitigating the security risks.<sup id="fnref:2"><a rel="footnote" href="#fn:2">2</a></sup></li>
<li>USA, Australia, and New Zealand restated a commitment to ban Huawei from national mobile networks. Canada was ‚Äústudying the British decision (to permit Huawei)‚Äù.<sup id="fnref:3"><a rel="footnote" href="#fn:3">3</a></sup></li>
<li>The EU released a toolbox for 5G to ‚Äúidentify a possible common set of measures which are able to mitigate the main cybersecurity risks of 5G networks.‚Äù<sup id="fnref:4"><a rel="footnote" href="#fn:4">4</a></sup></li>
<li>Parliament debated the security implications of the ‚Äúup to 35%‚Äù decision.<sup id="fnref:5"><a rel="footnote" href="#fn:5">5</a></sup></li>
<li>I wrote this post and circulated it privately among interested parties.</li>
<li>A Commons Defence sub Committee was convened to inquire into the security of the UK 5G networks.<sup id="fnref:6"><a rel="footnote" href="#fn:6">6</a></sup></li>
<li>MPs attempted unsuccessfully to have High-Risk Vendors excluded from 5G networks.<sup id="fnref:7"><a rel="footnote" href="#fn:7">7</a></sup></li>
<li>Huawei presented the ITU with a vision of an Internet where nation-states are the locus of control.<sup id="fnref:8"><a rel="footnote" href="#fn:8">8</a></sup></li>
<li>The US began requiring a license for the export of certain technologies that help foreign manufacturers produce semiconductors which are then sold to Huawei.<sup id="fnref:9"><a rel="footnote" href="#fn:9">9</a></sup></li>
<li>The Prime Minister instructed officials to draw up plans to reduce Huawei‚Äôs involvement in UK 5G to zero.<sup id="fnref:10"><a rel="footnote" href="#fn:10">10</a></sup></li>
<li>China‚Äôs UK ambassador said abandoning Huawei could jeopardise the UK‚Äôs new nuclear power plants and high-speed rail.<sup id="fnref:11"><a rel="footnote" href="#fn:11">11</a></sup></li>
<li>The government announced a ban on buying new Huawei 5G equipment after 2020 and ordered its removal by 2027.<sup id="fnref:12"><a rel="footnote" href="#fn:12">12</a></sup></li>
<li>NCSC‚Äôs Dr Levy blogged again, about how ‚Äúeverything had changed‚Äù. Huawei was out.<sup id="fnref:13"><a rel="footnote" href="#fn:13">13</a></sup></li>
<li>TikTok, the popular Chinese owned social media company announced it would scrap plans for a UK HQ.<sup id="fnref:14"><a rel="footnote" href="#fn:14">14</a></sup></li>
<li>Installation of new Huawei 5G equipment is to be prohibited after September 2021, earlier than anticipated.<sup id="fnref:15"><a rel="footnote" href="#fn:15">15</a></sup></li>
<li>As of 29th November 2020, UK network operators continued to buy and install Huawei equipment and contend that it will save them hundreds of millions of pounds compared to other vendors.</li>
</ul>

<p>I‚Äôm going to talk about the UK‚Äôs strategy for dealing with High-Risk Vendors. First in general terms and then specifically about statements made by Dr Levy about Huawei before the UK‚Äôs eventual about-face. I‚Äôll focus on the technical aspects of risk mitigation and in so doing move this discussion from the abstract to the concrete. Finally, I‚Äôll attempt to place the UK‚Äôs strategy within the wider context of future UK/China relations.</p>

<blockquote>
<p>Why after all this time are we still talking about Huawei?</p>
</blockquote>

<h3 id="man-in-the-vendor">Man In The Vendor</h3>

<p><a href="https://www.ncsc.gov.uk/collection/supply-chain-security">Supply Chain Risk</a> or ‚ÄúMan In The Vendor‚Äù (MiTV) as I call it, is one of Cyber Security‚Äôs <a href="https://en.wikipedia.org/wiki/Wicked_problem"><em>wicked problems</em></a>. Wickedness isn‚Äôt about difficulty. Wicked problems are different because traditional processes can‚Äôt resolve them satisfactorily. They have countless causes or factors, are hard to describe, and don‚Äôt have a right answer. I use the term MiTV because ‚ÄúSupply Chain Risk‚Äù sounds like something you could dilute or diversify away. It sounds like something you could outsource or insure against. MiTV sounds like what it is. There‚Äôs a man. He‚Äôs in the vendor. He has something to gain from being there.</p>

<blockquote>
<p>MiTV is hard to detect and counter in enterprise environments and <em>very hard</em> within mobile network operators. By definition, a network operator‚Äôs business is the shared use of that hardware and software. Different customer‚Äôs traffic, management traffic, security-critical commands and data, all flowing through the same chassis, circuit boards, processors, and memory. You trust the system to keep all this separate. When you have a MiTV, the system lies to you. - <a href="https://blog.eutopian.io/huawei-5g/">‚ÄúThe Eutopian. 29th July 2019‚Äù</a>.</p>
</blockquote>

<h3 id="mitv-in-practice">MiTV In Practice</h3>

<p>Any vendor can suffer a MiTV. Most incidents go unreported. How does this man get in the vendor and what does he do? No need for abstract threats. We have real cases. We don‚Äôt even have to put ourselves in the mind of a foreign adversary.</p>

<ol>
<li>Vendors are <a href="https://en.wikipedia.org/wiki/Dual_EC_DRBG">pressured</a> by governments to weaken their security.</li>
<li>Supply chains are <a href="https://web.archive.org/web/20200421225552/https://arstechnica.com/tech-policy/2014/05/photos-of-an-nsa-upgrade-factory-show-cisco-router-getting-implant/">compromised</a> and hardware or software tampered with.</li>
<li>Vendor operations are <a href="https://theintercept.com/2015/02/19/great-sim-heist/">hacked</a>.</li>
<li>Sometimes the man isn‚Äôt just in the vendor, he <a href="https://web.archive.org/web/20200512022950/https://www.srf.ch/news/schweiz/geheimdienstaffaere-cryptoleaks-weltweite-spionage-operation-mit-schweizer-firma-aufgedeckt">owns it</a>.</li>
<li>Infiltration can be so <a href="https://web.archive.org/web/20200421033936/https://krebsonsecurity.com/2020/02/hackers-were-inside-citrix-for-five-months/">deep</a> that the man might as well be writing the vendor‚Äôs product.</li>
<li>Sometimes the man <em>is</em> <a href="https://web.archive.org/web/20200530081851/https://www.wired.com/2015/12/researchers-solve-the-juniper-mystery-and-they-say-its-partially-the-nsas-fault/">writing the vendor‚Äôs product</a>.</li>
</ol>

<p>Once a man is in the vendor he can tamper with the software, hardware, or firmware that makes up their product. He can introduce malicious code or physical components before, and sometimes after equipment enters service. Even <a href="https://web.archive.org/web/20200601080443/https://arstechnica.com/information-technology/2013/12/inside-the-nsas-leaked-catalog-of-surveillance-magic/">cables</a> can be turned against you when you can‚Äôt trust your supply chain.</p>

<p>Not only can a network operator‚Äôs equipment be made to lie to them, but it‚Äôs common for mobile network operators to outsource some of the build and management of their networks to the equipment vendor. The operator buys a package. Equipment, support, and services to keep it running. It‚Äôs convenient because expertise is hard to come by and such equipment needs frequent updates. These arrangements provide an opportunity for compromise of the network throughout its lifecycle. In these cases, the hardware or software product doesn‚Äôt need to be flawed or weakened when you buy it. It‚Äôs enough that the engineers managing it and the tools and systems they bring to that task can become vectors for exploitation or attack. Unwittingly or otherwise.</p>

<h3 id="mitv-an-adversary-s-long-term-strategy">MiTV, An Adversary‚Äôs Long Term Strategy</h3>

<p>MiTV has long-term advantages for the adversary. It‚Äôs something he can <em>invest in</em> because it pays regular dividends in the long run. It provides persistent access to information and systems in a way that‚Äôs hard to prevent, hard to detect, hard to shut down, and hard to trace back to a particular moment in time. While the adversary is in the vendor and the vendor‚Äôs product is in your network he gathers sensitive information, collects credentials, and profiles users he can then target to further his mission. Or just bides his time, knowing that he can activate his implant at a time of his choosing. It‚Äôs for this reason that such programmes are so valuable to intelligence agencies and their existence remains such a closely guarded secret, even years after they‚Äôve stopped producing operationally useful information.</p>

<p>The man in the vendor isn‚Äôt always a state or state-affiliated. However, they tend to be more patient, better funded, harder to detect, and more likely to be interested in <em>specific</em> information or a specific class of target than most. MiTV is a tactic employed by states with a tier-1 offensive cyber security capability. This means the US, UK, Russia, Israel, and of course China. This list isn‚Äôt exhaustive. My first MiTV was in the 90s and probably French. They were replacing router firmware with a modified version to gain access to a negotiating team within a large defence contractor. That said, attribution was then as it is now, <em>difficile</em>.</p>

<p>It‚Äôs these kinds of threats posed by these actors in general and (one presumes) China in particular that Dr Levy <a href="https://www.ncsc.gov.uk/blog-post/the-future-of-telecoms-in-the-uk">said in January</a> could be countered with technical measures. Measures like limiting Huawei to peripheral (non-core) parts of the network. Measures like network segmentation, anomaly detection, and integrity checking. Measures presumably implemented and operated by security teams at national mobile network operators. Three, O2, Vodafone, and EE. Companies that despite the efforts of their security teams, are hacked <a href="https://www.cybereason.com/blog/operation-soft-cell-a-worldwide-campaign-against-telecommunications-providers">regularly</a>.</p>

<p>Remember, individuals within security teams at mobile operators are drawn from the same pool of people that failed to even detect <a href="https://www.ncsc.gov.uk/news/apt10-continuing-target-uk-organisations">APT10‚Äôs</a> multi-year <a href="https://www.reuters.com/investigates/special-report/china-cyber-cloudhopper/">Cloud Hopper</a> operation.</p>

<h3 id="the-odds">The Odds</h3>

<blockquote>
<p>Cyber Security isn‚Äôt a numbers game, but <a href="https://web.archive.org/web/20190403010530/https://foreignpolicy.com/2010/03/03/chinas-hacker-army">Foreign Policy magazine</a> estimates China‚Äôs <a href="https://en.wikipedia.org/wiki/Chinese_cyberwarfare">‚Äúhacker army‚Äù</a> at between 50,000 and 100,000 people. It‚Äôs against this army that security teams at national mobile operators will be pitted. Are already pitted. Regardless of whether or not such an army is granted a strategic advantage by the presence of Huawei hardware and software. The supply chain to which they may or may not have special access.</p>
</blockquote>

<p>Installing 3rd party security solutions on top of mobile network assets (if such solutions were available, which they are not) offers no meaningful assurance against a MiTV. The first thing a MiTV does is prevent its detection by <a href="https://dl.acm.org/doi/pdf/10.1145/358198.358210">subverting any direct method of observation</a>. Detecting a MiTV is a little like trying to spot a stealth aircraft using the ‚Äúhole‚Äù in the picture where the object is, or the airflow disruption it leaves in its wake. Hard to sense directly. I‚Äôm highly critical of analogies in cyber security, so I won‚Äôt labour this one further. Suffice it to say that many MiTV operations have only been discovered because the ‚Äúman‚Äù made a mistake. A slip-up. ‚Ä¶</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/">https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/</a></em></p>]]>
            </description>
            <link>https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297524</guid>
            <pubDate>Sun, 28 Feb 2021 22:02:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HardenedBSD February 2021 Status Report]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297430">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://hardenedbsd.org/article/shawn-webb/2021-02-28/hardenedbsd-february-2021-status-report | <a href="https://web.archive.org/web/*/https://hardenedbsd.org/article/shawn-webb/2021-02-28/hardenedbsd-february-2021-status-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="page" class="page">

     <!-- /header -->

    
    <!-- Messages and Help -->
        
    <!-- Breadcrumbs -->
    
    
    <!-- Three column 3x33 Gpanel -->
    
    <div id="columns">
      <div>

        <div id="content-column">
          <div>

            
            <section id="main-content" role="main">

                                            <header id="main-content-header">

                                      
                  
                  
                </header>
                            
                              <div id="content">
                  <div id="block-system-main">  
  
  <article id="node-221" about="/article/shawn-webb/2021-02-28/hardenedbsd-february-2021-status-report" typeof="sioc:Item foaf:Document" role="article">
  
  
      
  
  <div>
    <div><div><div property="content:encoded"><p>This month was a busy one, especially for our infrastructure. We purchased and received three refurbished Dell servers and one Cavium ThunderX server. Two of the three Dell servers were deployed. One is being used for our GitLab migration[1][2]. The second one is being set up as the HardenedBSD 14-CURRENT nightly build and package build server.</p>
<p>With the ThunderX server, we now have a production-capable arm64 server. I'm hoping that we can promote arm64 as a teir 1 architecture by the end of March. Though the server is deployed, I still need to copy the build scripts over and perform is final configuration.</p>
<p>FreeBSD recently landed a W^X implementation (congrats!), but it interferes with our PaX-inspired implementation. In addition to infrastructure work, I've been looking into this. I'm only able to reproduce when building packages--when there's a heavy load on the system. I'm working on some candiate patches, but they're not ready for commit.</p>
<p>The new package build server can be reached at [3]. The Tor onion service address is [4].</p>
<p>The next non-hackery item on my list is to reach out to 2020 donors that donated $250 USD or more to HardenedBSD. I need to give them their tax statement in case they itemize their taxes. I also need to reach out to recent donors to see if they want their name listed on our donations page.</p>
<p>I appreciate the help and support from the community. It's because of you that this project is possible. Your donations enable me to serve you.</p>
<p>[1]: <a href="https://git.hardenedbsd.org/">https://git.hardenedbsd.org/</a><br>
[2]: <a href="https://groups.google.com/a/hardenedbsd.org/g/users/c/wZgihY3PR8E/m/gVbZydJGAQAJ">https://groups.google.com/a/hardenedbsd.org/g/users/c/wZgihY3PR8E/m/gVbZ...</a><br>
[3]: <a href="http://ci-08.md.hardenedbsd.org/">http://ci-08.md.hardenedbsd.org/</a><br>
[4]: <a href="http://t3xwovqp3hijxp2wskcg2ot5jqpwjd63uaeodsp3ltduhvpxb47aegad.onion/">http://t3xwovqp3hijxp2wskcg2ot5jqpwjd63uaeodsp3ltduhvpxb47aegad.onion/</a></p>
</div></div></div>  </div>

  
  
  <span property="dc:title" content="HardenedBSD February 2021 Status Report"></span><span property="sioc:num_replies" content="0" datatype="xsd:integer"></span></article>

  </div>                </div>
              
              <!-- Feed icons (RSS, Atom icons etc -->
              
            </section> <!-- /main-content -->

            
          </div>
        </div> <!-- /content-column -->

                
      </div>
    </div> <!-- /columns -->

    
    <!-- four-4x25 Gpanel -->
    
          
    
  </div> <!-- /page -->
</div></div>]]>
            </description>
            <link>https://hardenedbsd.org/article/shawn-webb/2021-02-28/hardenedbsd-february-2021-status-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297430</guid>
            <pubDate>Sun, 28 Feb 2021 21:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The origin of 0-day (zero-day) in hacking (etymology of zero-day)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297279">thread link</a>) | @ashurov
<br/>
February 28, 2021 | https://bjorn.kuiper.nu/2013/10/09/origin_of_zero_day/ | <a href="https://web.archive.org/web/*/https://bjorn.kuiper.nu/2013/10/09/origin_of_zero_day/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><strong><em>2021-02-27 UPDATE:</em></strong> A new find sets back the date four more years. Finding a reference to zero-day exploits in a e-zine of May 1994. </p>



<p>This post is a result of a tweet [1] by <a rel="noreferrer noopener" href="https://www.twitter.com/spacerog" target="_blank">Space Rogue</a>.</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Has anyone published any etymology on the origins of the term '0-day'? Google not helping. <a href="https://twitter.com/hashtag/getoffmylawn?src=hash&amp;ref_src=twsrc%5Etfw">#getoffmylawn</a></p>‚Äî Space Rogue (@spacerog) <a href="https://twitter.com/spacerog/status/387677286385733632?ref_src=twsrc%5Etfw">October 8, 2013</a></blockquote>
</div></figure>



<p>It seems that only a few [2] have tried to capture the origin of the word 0-day in hacking and are wrong.</p>



<p>The term 0-day comes originally from the Warez scene [3]:</p>



<blockquote><p>‚Äú0-day (pronounced as zero day) ‚Äì This refers to any copyrighted work that has been released the same day as the original product, or sometimes even before.[6] It is considered a mark of skill among warez distro groups to crack and distribute a program on the same day of its commercial release.‚Äù</p></blockquote>



<p>Somewhere around the late 90‚Äôs it was picked up by the hacking scene.</p>



<p>Wikipedia explains zero-day attacks as following [4]:</p>



<blockquote><p>A zero-day (or zero-hour or day zero) attack or threat is an attack that exploits a previously unknown vulnerability in a computer application, meaning that the attack occurs on ‚Äúday zero‚Äù of awareness of the vulnerability.[1] This means that the developers have had zero days to address and patch the vulnerability. Zero-day exploits (the software and/or strategies that use a security hole to carry out a successful attack) are used or shared by attackers before the developer of the target software knows about the vulnerability.</p></blockquote>



<p>On the 27th of February of 2021 Robert Graham, using his Twitter account <a rel="noreferrer noopener" href="https://twitter.com/ErrataRob" target="_blank">@ErrataRob</a>, posted a new, earlier references to the use of the terminology <em>zero day</em> within hacking [8]. </p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Here's an example from 1994 where you see the overlapped usage. In this 'zine, sometimes "zero day" or "0-day" refers to pirated "warez", and sometimes it  refers to exploits. <a href="https://t.co/mBXFTj4jAs">pic.twitter.com/mBXFTj4jAs</a></p>‚Äî Rob·µâ ≥·µó Grahamüò∑, provocateur (@ErrataRob) <a href="https://twitter.com/ErrataRob/status/1365444754004185089?ref_src=twsrc%5Etfw">February 26, 2021</a></blockquote>
</div></figure>



<p>Published in the fifth edition of BRoTHeRHooD oF WaReZ e-zine, May 1994 [9]:</p>



<blockquote><p>we do not wish to impede the progress of zero day rdist exploits, sendmail DEBUG exploits, or other eleet aych pee warez.</p></blockquote>



<p>As stated by Robert: ‚ÄúOne theory is that ‚Äúzero-day‚Äù appeared in the hacking scene independently of the warez scene. This reference refutes that, clearly showing the warez scene using zero-day to also refer to an exploit. One caveat to this is that it‚Äôs a zero-day EXPLOIT, and only later does it become zero-day VULN.‚Äù</p>



<p>The full thread by Robert [10] on the subject can be found as part of this initial tweet:</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">I tracked down the evidence. The term "zero day" or "0-day" indeed comes from the "warez" scene. It originally meant being able to access pirated software on the day the software was released, then evolved to refer to exploits. <a href="https://t.co/MBeGEljMEQ">https://t.co/MBeGEljMEQ</a></p>‚Äî Rob·µâ ≥·µó Grahamüò∑, provocateur (@ErrataRob) <a href="https://twitter.com/ErrataRob/status/1365444749767933955?ref_src=twsrc%5Etfw">February 26, 2021</a></blockquote>
</div></figure>



<p>This particular reference sets back our initial findings to zero-day references four more years: from 1998 to May 1994!</p>



<p>Other early references we found in the past included a reference found in an e-zine of 1998 called CRH [5], (thanks to @bill_e_ghote for finding this one):</p>



<blockquote><p>Our member chameleon set us up with a domain in Argentina, the D-Lab.. It has some mad shit on it, but you have to know where to look, because www.d-lab.com.ar will take you nowhere, it has 0-day exploits on it, as well as other useful stuff and source code, check it out..</p></blockquote>



<p>Another references to 0-day in 1998 include a post on BugTraq by Ken Williams [6] and the Line-noise section of Phrack 53 [7].</p>



<p>From Phrack 53 [7]:</p>



<blockquote><p>They seem unwilling to read the code given to them to establish exactly what happens when the newest 0-day exploit runs.</p></blockquote>



<p><strong>Let me know if you have found a reference to 0-day (in hacking) before May 1994!</strong></p>



<p>Thanks go to<br>Space Rogue, twitter: @spacerog website: <a href="http://www.spacerogue.net/">http://www.spacerogue.net</a><br>Bill E. Ghote, Twitter: @bill_e_ghote website: <a href="http://scrapeghote.blogspot.com/">http://scrapeghote.blogspot.com</a><br>Robert Graham, twitter @ErrateRob website: <a href="https://blog.erratasec.com/">https://blog.erratasec.com/</a></p>



<p>References:<br>[1] <a href="https://twitter.com/spacerog/statuses/387677286385733632">https://twitter.com/spacerog/statuses/387677286385733632</a> by @spacerog on October 8, 2013.<br>[2] <a href="http://spiresecurity.com/?p=576">http://spiresecurity.com/?p=576</a> ‚Äì ‚ÄúZero Day‚Äù Terminology by Pete Lindstrom on July 27, 2005.<br>[3] <a href="http://en.wikipedia.org/wiki/Warez">http://en.wikipedia.org/wiki/Warez</a><br>[4] <a href="http://en.wikipedia.org/wiki/Zero-day_attack">http://en.wikipedia.org/wiki/Zero-day_attack</a><br>[5] <a href="http://web.textfiles.com/ezines/CRH/crh007.txt">http://web.textfiles.com/ezines/CRH/crh007.txt</a> ‚Äì 7th edition of CRH E-zine published on January 31st, 1998<br>[6] <a href="http://www.shmoo.com/mail/bugtraq/oct98/msg00027.html">http://www.shmoo.com/mail/bugtraq/oct98/msg00027.html</a> ‚Äì Bugtraq October 5th, 1998<br>[7] <a href="http://www.textfiles.com/magazines/PHRACK/PHRACK53">http://www.textfiles.com/magazines/PHRACK/PHRACK53</a> ‚Äì Phrack 53 July 8th, 1998<br>[8] <a href="https://twitter.com/ErrataRob/status/1365444754004185089">https://twitter.com/ErrataRob/status/1365444754004185089</a> by @ErrateRob<br>[9] <a href="http://www.textfiles.com/magazines/BOW/bow5.txt">http://www.textfiles.com/magazines/BOW/bow5.txt</a> ‚Äì BRoTHeRHooD oF WaReZ #5 May 1994.<br>[10] <a href="https://twitter.com/ErrataRob/status/1365444749767933955">https://twitter.com/ErrataRob/status/1365444749767933955</a> ‚Äì Research by Robert Graham on zero-day references in hacking and warez scene, captured in a twitter feed.</p>








<!-- This is the start of the WP Twitter Button code -->

<!-- This is the end of the WP Twitter Button code -->

					</div></div>]]>
            </description>
            <link>https://bjorn.kuiper.nu/2013/10/09/origin_of_zero_day/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297279</guid>
            <pubDate>Sun, 28 Feb 2021 21:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIT with Restrictions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26297240">thread link</a>) | @fuckthemachine
<br/>
February 28, 2021 | https://blog.yossarian.net/2020/06/03/You-may-not-use-my-projects-in-a-military-or-law-enforcement-context | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/06/03/You-may-not-use-my-projects-in-a-military-or-law-enforcement-context">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Jun 3, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#devblog">devblog</a>
    
  
  </p>


<p>As of yesterday and continuing into today, I will be adding the following rider
to the majority of my <a href="https://github.com/woodruffw">open-sourced projects</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td><pre>The following terms additionally apply and override any above terms for
applicable parties:

You may not use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies of the Software in a military or law enforcement context,
defined as follows:

1. A military context is a professional context where the intended application
of the Software is integration or use with or by military software, tools
(software or hardware), or personnel. This includes contractors and
subcontractors as well as research affiliates of any military organization.

2. A law enforcement context is a professional context where the intended
application of the Software is integration or use with or by law enforcement
software, tools (software or hardware), or personnel. This includes
contractors and subcontractors as well as research affiliates of any law
enforcement organization.

Entities that sell or license to military or law enforcement organizations
may use the Software under the original terms, but only in contexts that do
not assist or supplement the sold or licensed product.

Students and academics who are affiliated with research institutions may use
the Software under the original terms, but only in contexts that do not assist
or supplement collaboration or affiliation with any military or law
enforcement organization.
</pre></td></tr></tbody></table></code></pre></div></div>

<p>In plain English: if you work for the military (<em>any</em> military) or law enforcement
(<em>any</em> law enforcement), you will not be allowed to use my projects in a professional
setting. You may continue to use them in a <strong>personal</strong> setting with no restrictions.</p>

<p>If you work for a company that sells or licenses to a military or law enforcement
organization, you may continue to use my projects in professional settings that
are <em>not</em> connected to the settings in which you sell or license to those organizations.
Just as above, you may continue to use them under their original terms in a personal setting
with no restrictions.</p>

<p>If you are a student or academic at a research institution, you may continue to use my projects
in professional settings that are not connected to the work of your institution on
military or law enforcement contracts or programs. Just as above, you may continue to use them
under their original terms in a personal setting with no restrictions.</p>

<p>I‚Äôm not a lawyer, and I didn‚Äôt consult with one. I have no idea how enforceable this is.
You‚Äôre welcome to use it as well, provided that you understand that it could be legal nonsense.</p>

<h2 id="open-source">‚ÄúOpen source‚Äù?</h2>

<p>Like all definitions, ‚Äúopen source‚Äù is a convention. We get to choose what we make of it<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<p>I‚Äôm okay with calling these terms ‚Äúpermissive‚Äù rather than ‚Äúopen,‚Äù but I‚Äôll leave that
up to others to settle.</p>

<h2 id="what-about">What about‚Ä¶?</h2>

<p>I am painfully aware of the fact that millions of people are employed by the defense and law
enforcement industries, either directly, indirectly, or by proxy. I count myself as one of them.</p>

<p>I am aware that defense and law enforcement are functionally middle-class job programs and
are populated primarily by disaffected and myopic, not malicious, individuals. I realize
that these industries are frequently highly specialized and that individuals in these industries
may feel like they have no other recourse for their livelihoods.</p>

<p>I am also aware that I am a small fry. My (personal) projects are insignificant within the
greater pantheon of open source. I will continue to contribute to other projects under
their terms, advocating for modification of those terms when I believe it to be appropriate.</p>

<p>I plan to add a badge
<a href="https://raster.shields.io/badge/license-MIT%20with%20restrictions-green.png">like this</a> to projects
that have been relicensed. My intent is to <strong>not</strong> sandbag users with new terms.</p>

<p>I act in spite of all of these things. I believe that I have a moral obligation to do so.
I believe that it is the <em>least</em> I can do, in the context of my hobby and passion. I will do more.</p>

<p>I‚Äôm happy to discuss it with you, reader. My contact information is
<a href="https://yossarian.net/">on my site</a>.</p>

<hr>




<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2020/06/03/You-may-not-use-my-projects-in-a-military-or-law-enforcement-context</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297240</guid>
            <pubDate>Sun, 28 Feb 2021 21:29:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Associative Arrays in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26297204">thread link</a>) | @avivallssa
<br/>
February 28, 2021 | https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/ | <a href="https://web.archive.org/web/*/https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-id="664a6773" data-element_type="section">
						<div>
					<div data-id="69dd5814" data-element_type="column">
			<div>
								<div data-id="768afe71" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>While migrating from Oracle to PostgreSQL, most of the developers ask about the options available in Handling Global associative arrays in PostgreSQL. It might get challenging if the variables need to be accessible in the Exception block. To avoid developers from finding it difficult while performing conversions of PL/SQL from Oracle to PostgreSQL, we are writing this blog post to demonstrate the workarounds available with not much of additional programming effort. <img loading="lazy" src="https://www.migops.com/blog/wp-content/uploads/2021/02/Word-Art.jpeg" alt="" width="500" height="343"></p>
<p>By the way, the fact to note after reading this blog post is that, several features you want to observe in PostgreSQL during migrations or Code conversions are available without the need of an additional Enterprise license with PostgreSQL (which could create a vendor lock-in).</p>

<p>Ask us about possibilities with Community PostgreSQL (Open Source) before switching to an Enterprise licensing. üôÇ</p>

<p><b>What is an Associative Array ?</b></p>
<p>Before getting to the workarounds, let us understand what is an associative array. In programming languages, an associative array may either be called a <strong>map</strong> or a <strong>dictionary</strong>. Associative array is a collection of (key, value) pairs where a key associates to a value. This association between a key and a value may be referred to as mapping. The key can either be of a text or a numeric type that can be mapped to any value type.&nbsp;</p>
<p><b>PostgreSQL Array type</b></p>
<p>PL/pgSQL in PostgreSQL allows us to declare a variable as an ARRAY type. This ARRAY can be either a <strong>base</strong> or a <strong>custom</strong> type. For example, if we want to store a list of <strong>PINCODE</strong> values, then, we can declare the variable as <strong>v_pincode INT[]</strong>. Once we declare this variable, then, we can load all the pincode values from a table/view/function into this array.&nbsp;</p>
<p>We can also initialize the <strong>v_pincode</strong> array type with a static set of pincode values. Here, the <strong>v_pincode</strong> holds all the values and we can fetch a specific state‚Äôs pincode value, by providing an index. Which means, if we want to access the 1st state pincode, then, we can access the value using <strong>v_pincode[1]</strong>. If we want to access the pincode value of 3rd state, then, we have to pass the index value 3 using <strong>v_pincode[3]</strong>.</p>
<p>Here is a sample code to illustrate the above with an example.</p>
<pre>postgres=&gt; CREATE OR REPLACE FUNCTION process_orders() RETURNS BOOL<br>AS<br>$$<br>DECLARE<br>--initializing static pincodes<br>v_pincode INT[]=ARRAY[123456, 123457, 123458, 123459];<br>BEGIN<br>RAISE NOTICE '1st state pincode %', v_pincode[1];<br>RAISE NOTICE '3rd state pincode %', v_pincode[3];<br>RETURN true;<br>END;<br>$$ LANGUAGE PLPGSQL;<br>CREATE FUNCTION</pre>
<p>Let us execute the function created above and see the results.</p>
<pre>postgres=&gt; SELECT process_orders();<br>NOTICE: 1st state pincode 123456<br>NOTICE: 3rd state pincode 123458<br>process_orders<br>----------------<br>t<br>(1 row)</pre>
<p>We got the results as expected. However, this code has some limitations because we are unable to fetch the values based on their keys. For example, the pincodes (1st and the 3rd elements) are fetched using their Indexes. If we are able to access the same pincodes based on their keys, then, the lookup will be more powerful. So, how to approach this requirement ? Let us discuss the approach further.&nbsp;</p>
<p><b>Associating or mapping a name or a key to a value</b></p>
<p>Thanks to PostgreSQL‚Äôs rich data types such as <strong>hstore</strong> or <strong>json</strong> which can be leveraged to perform such mapping.</p>
<p>Following is a sample code using a <strong>json</strong> static object.</p>
<pre>CREATE OR REPLACE FUNCTION process_orders() RETURNS BOOL<br>AS<br>$$<br>DECLARE<br>--initializing static pincodes<br>v_pincode JSON= '{"CA": 123456, "AZ": 123457, "OH": "123458", "CO": 123459}';<br>BEGIN<br>RAISE NOTICE 'CA state pincode %', v_pincode-&gt;&gt;'CA';<br>RAISE NOTICE 'OH state pincode %', v_pincode-&gt;&gt;'OH';<br>RETURN true;<br>END;<br>$$ LANGUAGE PLPGSQL;</pre>


<p>Let us execute the above created function and see the results.</p>

<pre><code>postgres=&gt; SELECT process_orders();
NOTICE:  CA state pincode 123456
NOTICE:  OH state pincode 123458
process_orders
----------------
t
(1 row)</code></pre>

<p>Now, we are able to make the lookup using a key possible with our PL/pgSQL code. Thus, by using a json type instead of an ARRAY we can implement the concept of associative arrays.&nbsp;</p>

<p><strong>Global Associative Arrays</strong></p>

<p>The json approach demonstrated above seems to be perfect, but it does not solve the problem of global or session level associative arrays. What this means is that the same associative array cannot be accessed using another function running in the same session. This is because of the lack of global variables or global arrays.&nbsp;</p>

<p><strong>How to make Global Associate Arrays possible with PostgreSQL ?</strong></p>

<p>Following are the 5 possible solutions with some or no limitations to each approach.&nbsp;</p>

<ol>
<li><strong>Declare the same json object in the other function.</strong></li>
</ol>

<ul>
<li>Requires duplicating the same variable and the same context.&nbsp;</li>
</ul>

<ol start="2">
<li><strong>Pass the json argument as a parameter to the other function.</strong></li>
</ol>

<ul>
<li>Pass the same value across functions. However, the argument lists may become huge to manage or debug.</li>
</ul>

<ol start="3">
<li><strong>Store this object in a table and load it in the function.</strong></li>
</ol>

<ul>
<li>Storing it in a Table and accessing the elements by selecting from the Table. This can be a heavy overhead.&nbsp;</li>
</ul>

<ol start="4">
<li><strong>Use set_config() approach, which set the object at a session level, and read it from the current_setting().&nbsp;</strong></li>
</ol>

<ul>
<li>If any value is set, an Exception block cannot view the configured settings. May become challenging while performing conversions from Oracle to PostgreSQL where a good amount of logic is written in the Exception block. May be great when we are not accessing any global variables in the exception block. We will be discussing this in detail in our future blog post.&nbsp;</li>
</ul>

<ol start="5">
<li><strong>Using a supported PostgreSQL language context.&nbsp;</strong></li>
</ol>

<ul>
<li>With this approach, we should be able to access the global variables across the exception blocks and also the non exception blocks.</li>
</ul>

<p>The first 4 approaches seem to be pretty straight forward and simple with their own limitations. But the last approach about using another language‚Äôs session context is something interesting and we are discussing that further.</p>

<p><strong>Using TCL to support Global Associative Arrays</strong></p>

<p>As we all know, PostgreSQL supports many trusted procedural languages such as PLPerl, PLPython, PLTCL, PLv8 etc. All these trusted languages guarantee that the program code written in that language will not be accessing the underlying physical files. Out of all these programming languages, we will be choosing a simple, safe and a powerful language called <span><a href="https://wiki.tcl-lang.org/page/pltcl">tickle (PLTCL)</a>.</span>&nbsp;</p>

<p>TCL language does support the associative array concepts and we will be leveraging this feature in a global way. This will give more flexibility of lookup of values using keys. Let us see the following example code to see how we can make the declaration of a global variable with tickle (TCL).</p>

<p><strong>TCL instructions<br></strong>As the first step, let‚Äôs declare a global variable (namespace) using the following TCL code.</p>

<pre><code>$ tclsh
% # Here, arr_ptr is a pointer to the namespace/global variable "pincodes"
% upvar 0 ::"pincodes" arr_ptr</code></pre>

<p>Now, let‚Äôs add a pincode value to this namespace (or the global variable).</p>

<pre><code>% set arr_ptr('CA') 123456
123456</code></pre>

<p>Let us now get the value which we set in the associative array.</p>

<pre><code>% set arr_ptr('CA')
123456</code></pre>

<p>Using the simple example created above, we have seen how we can declare a global variable and store the values using TCL.</p>

<p><strong>Using PLTCL to support Global Associative Arrays in PostgreSQL.</strong></p>

<p>To achieve the functionality of global associative arrays, let us embed the same code in PLTCL as seen in the following steps.</p>
<p><strong>Step 1 :</strong> Create the PLTCL Extension</p>

<pre><code>postgres=&gt; CREATE EXTENSION pltcl;
CREATE EXTENSION</code></pre>

<p><strong>Step 2 : </strong>Create a function using PLTCL to declare the Global Associative Array and set a value.</p>

<pre><code>postgres=&gt; CREATE OR REPLACE FUNCTION pltcl_set(TEXT, TEXT, TEXT) RETURNS VOID AS $$
upvar 0 ::$1 arr_ptr
set arr_ptr($2) $3
$$ LANGUAGE PLTCL;
CREATE FUNCTION</code></pre>

<p><strong>Step 3 : </strong>Create a function using PLTCL to get the value mapped to the key.</p>

<pre><code>postgres=&gt; CREATE OR REPLACE FUNCTION pltcl_get(TEXT, TEXT) RETURNS TEXT AS $$
upvar 0 ::$1 arr_ptr
set arr_ptr($2)
$$ LANGUAGE PLTCL;
CREATE FUNCTION</code></pre>

<p><strong>Testing</strong></p>

<p>Let us perform a test using the newly created PLTCL functions.</p>

<pre><code>postgres=&gt; SELECT pltcl_set('pincodes', 'CA', '123456');
pltcl_set
-----------
(1 row)
postgres=&gt; SELECT pltcl_get('pincodes', 'CA');
pltcl_get
-----------
123456
(1 row)</code></pre>

<p>As seen in the above example, we are able to get data from the TCL context which is global. Which means, we are able to set the <strong>pincodes</strong> from one statement (using pltctl_set() ), and able to access it‚Äôs value from another statement (using pltcl_get()).&nbsp;</p>

<p><strong>Iterating over the Global Associative Arrays</strong></p>

<p>What is an array without an iterator, right? Let us leverage the same TCL code and create another function which iterates over the global array.</p>

<pre><code>postgres=&gt; CREATE OR REPLACE FUNCTION pltcl_itr(TEXT) RETURNS TABLE(key TEXT, value TEXT)
AS
$$
upvar 0 ::$1 arr_ptr
    foreach i  [array names arr_ptr] {
        return_next [list key $i value [set arr_ptr($i)]]
    }
$$ LANGUAGE PLTCL;
CREATE FUNCTION</code></pre>

<p>Now, let‚Äôs add a few more entries to `pincodes` global array and do the iteration test.</p>

<pre><code>postgres=&gt; SELECT pltcl_set('pincodes', 'AZ', '123457');
pltcl_set
-----------
(1 row)
postgres=&gt; SELECT pltcl_set('pincodes', 'OH', '123458');
pltcl_set
-----------
(1 row)
postgres=&gt; SELECT pltcl_set('pincodes', 'CO', '123459');
pltcl_set
-----------
(1 row)</code></pre>

<p>Let‚Äôs use the iterator function to get all the lists of available <strong>pincodes</strong> from the global array, as seen in the following block.</p>

<pre><code>postgres=&gt; SELECT * FROM pltcl_itr('pincodes');
key | value
-----+--------
CA  | 123456
CO  | 123459
OH  | 123458
AZ  | 123457
(4 rows)</code></pre>

<p>As seen above, this iterator is actually helping to iterate over the global associative array. We can use these values across multiple functions across the same session.&nbsp;</p>

<p><strong>Conclusion</strong></p>

<p>PostgreSQL offers a lot of flexibility in writing the code in multiple languages, which eventually enables us to inherit the power of other programming languages. As you have witnessed in this blog post, we leveraged the TCL‚Äôs features and are able to achieve the global associative arrays, which ‚Ä¶</p></div></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/">https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/</a></em></p>]]>
            </description>
            <link>https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297204</guid>
            <pubDate>Sun, 28 Feb 2021 21:25:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exponential exploit: Why AppSec is hard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297016">thread link</a>) | @beny23
<br/>
February 28, 2021 | https://beny23.github.io/posts/one_plus_one_is_crash/ | <a href="https://web.archive.org/web/*/https://beny23.github.io/posts/one_plus_one_is_crash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this blog post, I would like to explore how missing input validation even in a trivial service
can leave parts of server infrastructure crumbling.</p><p>In my opinion, this why securing applications (AppSec) is very difficult. Put supply chain attacks, unpatched systems
and misconfiguring services to one side for a minute and consider that a lot of software is written by
developers who do not necessarily consider all the edge cases or implications of what can go
wrong even in the simplest of pieces of code (or just copy/paste from Stackoverflow).<br>Unfortunately, vulnerable software in all sectors can get rushed out due to deadlines or inexperience
and it is my opinion that poor coding practices in applications provide an interesting attack vector
everywhere.</p><p>Allow me to demonstrate: Given the following (admittedly oversimplified) problem statement:</p><blockquote><p>Write a microservice that increments a decimal number by one</p></blockquote><p>Keeping it simple and very generic, I came up with the following Spring Boot application:</p><div><div><table><tbody><tr><td><pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td><td><pre><code data-lang="java">@RestController
<span>public</span> <span>class</span> <span>DemoController</span> <span>{</span>

    @PostMapping<span>(</span><span>"/increment"</span><span>)</span>
    @ResponseBody
    DemoModel <span>increment</span><span>(</span>@RequestBody DemoModel model<span>)</span> <span>{</span>
        DemoModel result <span>=</span> <span>new</span> DemoModel<span>();</span>
        result<span>.</span><span>setNumber</span><span>(</span>model<span>.</span><span>getNumber</span><span>().</span><span>add</span><span>(</span>BigDecimal<span>.</span><span>ONE</span><span>));</span>
        <span>return</span> result<span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></td></tr></tbody></table></div></div><p>My model looked like so</p><div><div><table><tbody><tr><td><pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td><td><pre><code data-lang="java"><span>public</span> <span>class</span> <span>DemoModel</span> <span>{</span>
    <span>private</span> BigDecimal number<span>;</span>

    <span>public</span> BigDecimal <span>getNumber</span><span>()</span> <span>{</span>
        <span>return</span> number<span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>setNumber</span><span>(</span>BigDecimal number<span>)</span> <span>{</span>
        <span>this</span><span>.</span><span>number</span> <span>=</span> number<span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></td></tr></tbody></table></div></div><p>A reasonable implementation. I even used <code>BigDecimal</code> so that I don‚Äôt have rounding/precision
issues, and the service is pretty trivial:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td><td><pre><code data-lang="bash">$ curl http://localhost:8080/increment <span>\
</span><span></span>  -d <span>'{"number":1}'</span> <span>\
</span><span></span>  -H <span>"Content-Type: application/json"</span>
<span>{</span><span>"number"</span>:2<span>}</span>
</code></pre></td></tr></tbody></table></div></div><p>As it turns out - quite a bit.</p><p>Here is a view of what the CPU did on my mac after hitting the service with a few requests over
a 10-minute period:</p><p><img src="https://beny23.github.io/images/one_plus_one_is_crash_cpu_stats.png" alt=""></p><p>And here‚Äôs the memory:</p><p><img src="https://beny23.github.io/images/one_plus_one_is_crash_memory_stats.png" alt=""></p><p>And what was the culprit. Not a vulnerability in Sprint Boot, not thousands of requests
(as a matter of fact there were just 4 requests, you can see it in the CPU graph, each time another request
came in, another CPU was used up 100%).</p><p>The requests were just:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="bash">curl http://localhost:8080/increment <span>\
</span><span></span>  -d <span>'{"number":9999999e99999999}'</span> <span>\
</span><span></span>  -H <span>"Content-Type: application/json"</span> &gt;/dev/null
</code></pre></td></tr></tbody></table></div></div><p>The number <code>9999999e99999999</code> has near enough <code>10,000,000</code> digits. If I wanted to send such
a number without the scientific notation (the <code>e</code> in the number), I‚Äôd have to send a payload that‚Äôs
many 10 megabytes big. That would get noticed very quickly. However, the payload is miniscule. And when java
is calculating this number (the plus 1 operation), it takes a long time because it tries to make an exact calculation.
I didn‚Äôt wait around to find out how long the CPU was busy. I just killed the
program after 10 minutes.</p><p>Imagine how much havoc such a vulnerability can create in a cloud setting, where instances sit in
Auto Scaling Groups. Imagine 100 such requests hit your instances. Every time we get 100% CPU, we
spin up another instance, that‚Äôs expensive. And as the processing also uses up quite a bit of memory,
it‚Äôs very likely that other requests don‚Äôt get a look-in.</p><p>This makes a very effective Denial of Service attack. Sure, when identified it is easy enough to fix by
not allowing the scientific notation understood by <code>BigDecimal</code> as input to JSON, but that‚Äôs not provided
as standard. How can you be sure that your codebase isn‚Äôt vulnerable?</p><p>In my opinion this is where development and testing teams need to have the experience in spotting these
potential issues. The above is just one example of how a seemingly innocuous piece of code can be abused.</p><p>How would your code fare against the <a href="https://github.com/minimaxir/big-list-of-naughty-strings">Big List of Naughty Strings</a>?</p><ul></ul></div></div>]]>
            </description>
            <link>https://beny23.github.io/posts/one_plus_one_is_crash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297016</guid>
            <pubDate>Sun, 28 Feb 2021 21:00:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Location Based Networking Server Demo]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26297014">thread link</a>) | @tony_codes
<br/>
February 28, 2021 | https://tonycodes.com/breadcrumbs | <a href="https://web.archive.org/web/*/https://tonycodes.com/breadcrumbs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tonycodes.com/breadcrumbs</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297014</guid>
            <pubDate>Sun, 28 Feb 2021 21:00:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little League wants all your information]]>
            </title>
            <description>
<![CDATA[
Score 335 | Comments 160 (<a href="https://news.ycombinator.com/item?id=26296845">thread link</a>) | @ColinWright
<br/>
February 28, 2021 | https://honeypot.net/post/little-league-wants-all-your-information/ | <a href="https://web.archive.org/web/*/https://honeypot.net/post/little-league-wants-all-your-information/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <div>
                <h3>Little League wants all your information</h3>
                
                    <p><em></em>
                        <span> Sun, Feb 28, 2021 
                                           </span>
                        <em></em>
                        <span>2-minute read</span>
                    </p>
                
            </div>

            <p>To sign kids up for our city‚Äôs Little League baseball program, you have to prove that they‚Äôre residents, which is reasonable. What‚Äôs not reasonable is the amount of information you have to provide on the registration website. You have to upload scans of a document in each of 3 categories:</p>
<blockquote>
<p><strong>Proof of Residency 1</strong>
Choose one of the following: Driver‚Äôs license, School records, Vehicle records, Employment records, Insurance documents</p>
<p><strong>Proof of Residency 2</strong>
Choose one of the following: Welfare/child care records, Federal records, State records, Local records, Support payment records, Homeowner or tenant records, Military records</p>
<p><strong>Proof of Residency 3</strong>
Choose one of the following: Voter‚Äôs registration, Utility bills, Financial records, Medical records, Internet, cable, or satellite bills</p>
</blockquote>
<p>That alone is ripe for identity theft, but couple it with their privacy policy which includes this (emphasis mine):</p>
<blockquote>
<p>Without limitation, this typically requires the use of certain personal information, including registration data, event data, and other personal information, to provide program information, <strong>special offers or services through Little League and/or its trusted sponsors, partners, or licensees</strong>, to fulfill your requests for information or products/services, to maintain a list of verified and eligible participants, to maintain a list of volunteers and provide them with the operating tools to manage leagues, or to respond to your inquiries about our programs.</p>
</blockquote>
<p>In other words, you have to upload your most private information and agree to allow them to do as they like with it, including sharing it with whomever they like for any reason they choose.</p>
<p>This is unacceptable.</p>
</div></div>]]>
            </description>
            <link>https://honeypot.net/post/little-league-wants-all-your-information/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296845</guid>
            <pubDate>Sun, 28 Feb 2021 20:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Demand for Software Engineers Will Stay High]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26296653">thread link</a>) | @gamma3
<br/>
February 28, 2021 | https://coding-time.co/software-engineers-demand/ | <a href="https://web.archive.org/web/*/https://coding-time.co/software-engineers-demand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header></header><section itemprop="articleBody"><p><span>
      <a href="https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/2cefc/demand-supply.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Classic Supply and Demand Chart" title="Classic Supply and Demand Chart" src="https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/f058b/demand-supply.png" srcset="https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/c26ae/demand-supply.png 158w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/6bdcf/demand-supply.png 315w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/f058b/demand-supply.png 630w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/40601/demand-supply.png 945w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/78612/demand-supply.png 1260w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/2cefc/demand-supply.png 1400w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>It seems like everybody needs software engineers. Demand is much higher than supply. This translates to jobs with good pay and lots of options to choose from. Want a full-time job? Startup job with equity? Remote contract work with 3 months off every year? No problem!</p>
<p>When I was just beginning to learn about programming, I wondered whether there would always be a need for millions and millions of programmers.</p>
<p>After my 15 years in the industry it looks like the demand is going nowhere. Some stats from the <a href="https://www.bls.gov/ooh/computer-and-information-technology/software-developers.htm">US Department of Labor</a>:</p>
<table>
<thead>
<tr>
<th>Software Development Jobs in the US</th>
<th>Number</th>
<th>Increase</th>
</tr>
</thead>
<tbody>
<tr>
<td>In 2016</td>
<td>1,256,200</td>
<td></td>
</tr>
<tr>
<td>In 2019</td>
<td>1,469,200</td>
<td>+17%</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Job Outlook, 2019-29 is 22% (much faster than average). The average growth rate for all occupations is 4 percent.</p>
</blockquote>
<p>In the United Kingdom alone, there are now <a href="https://www.forbes.com/sites/davidprosser/2018/04/06/uk-technology-start-ups-hit-all-time-high/#5654d1415d85">10k technology startups</a>.</p>
<p>Here are my observations on why that is:</p>
<h3>1. The whole world runs on&nbsp;software</h3>
<p>This is probably obvious because the transition has been ongoing for a few generations. However, it cannot be understated. Almost every business / organisation in the world needs a website or an app, plus lots of software. At my current company with 80 employees we use more than 20 different SaaS solutions for HR, accounting, recruiting and more. Every person with internet access (which eventually will be the whole world) uses apps and websites every day, and many people use software at work. Large companies often need custom software.</p>
<h3>2. Most things get built many&nbsp;times</h3>
<p>Why is there Bing when there is Google? Why are there a thousand competing e-commerce platforms? Why are there so many messaging apps, each built from scratch by a different team? This seems like duplicated effort but it‚Äôs normal. It‚Äôs just how competition works and it is not unique to software. For example, there are many car companies, each with tens of thousands of employees designing and building very similar cars.</p>
<p>Part of the reason is software is still local. There is ‚ÄúX of Asia‚Äù for almost any X you can think of.</p>
<h3>3. Code has limited&nbsp;lifetime</h3>
<p>It might seem that once an app is built it is ‚Äúdone‚Äù. When I worked at Facebook friends asked me ‚ÄúIs there still anything to do?‚Äù However, most code is being changed constantly and most companies are constantly hiring. Each line of code has a lifetime of only a few years. Sometimes as a product gets old it is easier to throw it away and rebuild using modern technologies. I have seen this happen to custom in-house systems and public-facing websites. This is again similar to car companies constantly innovating and designing new cars.</p>
<p>From the 3 points above you can already see a clear pattern:</p>
<ul>
<li>We need more and more software</li>
<li>There are more and more software solutions to do anything</li>
<li>Each solution requires software engineers constantly</li>
</ul>
<p>But what if programming becomes easier over time? Surely we would need fewer programmers then? Read on‚Ä¶</p>
<h3>4. Code sharing didn‚Äôt&nbsp;happen</h3>
<p>In the 90s there was a dream of code sharing, where we design software components with business logic inside them and anyone will be able to reuse them like lego bricks. This didn‚Äôt work out, not even reusing business logic across projects written in Java. Across technology stacks, the story is even worse. There was COM but it was Windows-only. Yes, you can call Rust from Python but it‚Äôs not become the standard way of building software. There are many programming languages and new ones keep appearing. At my last company for example, we rewrote a part of an existing codebase from Ruby to Rust.</p>
<p>Code reuse did improve over the years thanks to package managers, GitHub and an explosion of open source libraries. Systems like npm are a huge step forward. However, we came nowhere near the dream of true code sharing. Open source libraries help a lot but not enough to significantly slow the demand for engineers.</p>
<h3>5. Tools are improving but projects are getting more&nbsp;complex</h3>
<p>Using a language with a garbage collector in a modern IDE with lots of libraries and going ‚Äúserverless‚Äù is more productive than writing C++ in 1995. Can you now hire five times fewer engineers than in 1995 for the same project? Probably. But instead, it‚Äôs more likely you hire the same number of engineers and the project will be more ambitious because customers came to expect more.</p>
<h3>6. New platforms come&nbsp;out</h3>
<p>Ten years ago it was enough to hire web developers. Now you need to hire web, Android and iOS developers. Depending on your product, you may also build Messenger bots and WeChat apps.</p>
<p>The biggest step forward here was probably the web. Suddenly you didn‚Äôt have to build a Mac, Linux, and Windows desktop apps but could just build your product in JavaScript and then it would work anywhere (minus browser incompatibilities, this got better over time). The fact web standards happened is a small miracle‚Ää‚Äî‚Ääremember <a href="https://en.wikipedia.org/wiki/Browser_wars">Browser Wars</a>? However, because of mobile, the web is now less relevant than it was 10 years ago. Today, frameworks like Unity, React Native or Flutter are trying to abstract over multiple platforms to make software development easier and cheaper.</p>
<h3>7. Extra (for fun): AI to replace software engineers?</h3>
<p>Imagine someone designs software that can replace most engineers. For example, instead of a team of 6 engineers, there would be one human ‚Äútech lead‚Äù who specifies high-level requirements and the program translates them into bug-free code.</p>
<p>No-one has a good idea when this could happen. If it happens the demand for engineers would drop immensely. But with such technology the demand for humans in other professions would likely drop too, so relative to other professions programming <em>might</em> still be in demand.</p></section><hr></article></div>]]>
            </description>
            <link>https://coding-time.co/software-engineers-demand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296653</guid>
            <pubDate>Sun, 28 Feb 2021 20:17:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mrcal: Principled Camera Calibrations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26296625">thread link</a>) | @dima55
<br/>
February 28, 2021 | http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
This is a big deal.
</p>

<p>
In my day job I work with images captured by cameras, using those images to
infer something about the geometry of the scene being observed. Naturally, to
get good results you need to have a good estimate of the behavior of the lens
(the "intrinsics"), and of the relative geometry of the cameras (the
"extrinsics"; if there's more than one camera).
</p>

<p>
The usual way to do this is to perform a "calibration" procedure to compute the
intrinsics and extrinsics, and then to use the resulting "camera model" to
process the subsequent images. Wikipedia has <a href="https://en.wikipedia.org/wiki/Camera_resectioning">an article</a>. And from experience,
the most common current toolkit to do this appears to be <a href="https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html">OpenCV</a>.
</p>

<p>
People have been doing this for a while, but for whatever reason the existing
tools <i>all</i> suck. They make basic questions like "how much data should I gather
for a calibration?" and "how good is this calibration I just computed?" and "how
different are these two models?" unanswerable.
</p>

<p>
This is clearly seen from the links above. The wikipedia article talks about
fitting a pinhole model to lenses, even though no real lenses follow this model
(telephoto lenses do somewhat; wider lenses don't at all).
</p>

<p>
And the OpenCV tutorial cheerfully says that
</p>

<pre>Re-projection error gives a good estimation of just how exact the found
parameters are. The closer the re-projection error is to zero, the more accurate
the parameters we found are.
</pre>

<p>
This statement is trivially proven false: throw away most of your calibration
data, and your reprojection error becomes very low. But we can all agree that a
calibration computed from less data is actually worse. Right?
</p>

<p>
All the various assumptions and hacks in the existing tooling are fine as long
as you don't need a whole lot of accuracy out of your results. I need a lot of
accuracy, however, so all the existing tools don't work for my applications.
</p>

<p>
So I built a new set of tools, and have been using them with great delight. I
just got the blessing to do a public release, so I'm announcing it here. The
tools are
</p>

<ul>
<li><a href="https://github.com/dkogan/mrgingham">mrgingham</a>: a chessboard corner finder. OpenCV has one, but as far as I can
tell, it doesn't work; and it is very slow to tell you that. mrgingham is
relatively quick, robust to all sorts of lens behaviors, and reports the
accuracy of its output. This is a C++ library with Python bindings, and a
commandline tool. 99% of the time the commandline tool is what I use.
</li>

<li><a href="https://github.com/dkogan/mrcal">mrcal</a>: a large toolkit to run calibrations, to manipulate images and camera
models in all sorts of ways, and to visualize stuff. This toolkit does a
<i>lot</i>. It's a C library and a Python library and a number of commandline
tools. Currently the C library exists primarily in the service of the other
two, but it's already very capable, and will become more so over time.
</li>
</ul>

<p>
mrcal does a whole lot to produce calibrations that are as good as possible, and
it will tell you just how good they are, and it includes visualization
capabilities for extensive user feedback. An overview of the capabilities of the
toolkit (with lots of pretty pictures!) is at the <a href="http://mrcal.secretsauce.net/tour.html">tour of mrcal.</a>
</p>

<p>
There's a <i>lot</i> of documentation and examples, but up to now I have been the
primary user of the tools. So I expect this to be somewhat rough when others
look at it. Bug reports and patches are welcome.
</p>

<p>
mrcal is an excellent base, but it's nowhere near "done". The documentation has
some notes about the planned features and improvements, and I'm always reachable
by email.
</p>

<p>
Let me know if you try it out!
</p>

  </div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296625</guid>
            <pubDate>Sun, 28 Feb 2021 20:15:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five Things I Hate About Ruby (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26296515">thread link</a>) | @Tomte
<br/>
February 28, 2021 | https://blog.yossarian.net/2015/09/28/Five-Things-I-Hate-About-Ruby | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2015/09/28/Five-Things-I-Hate-About-Ruby">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Sep 28, 2015</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#rant">rant</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#ruby">ruby</a>
    
  
  </p>


<p>In the spirit of <a href="http://use.perl.org/use.perl.org/_brian_d_foy/journal/32556.html">Brian D. Foy</a>
and <a href="http://ivory.idyll.org/blog/five-things-I-hate-about-python.html">C. Titus Brown</a>,
I‚Äôm going to attempt to list the 5 things I hate (most) about my current
scripting language of choice: Ruby.</p>

<p>Here we go:</p>

<h3 id="1-blocks-and-procs-and-lambdas-oh-my">1. Blocks and Procs and Lambdas, oh my!</h3>

<p>There are too many <em>incompatible</em> ways to create a closure in Ruby.</p>

<p>Blocks are part of Ruby‚Äôs syntax, and are not objects:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>].</span><span>each</span> <span>{</span> <span>|</span><span>i</span><span>|</span> <span>puts</span> <span>i</span> <span>}</span> <span># =&gt; "1\n2\n3\n"</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Procs and lambdas are both objects of the <a href="http://ruby-doc.org/core-2.2.3/Proc.html">Proc</a>
class:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>p</span> <span>=</span> <span>Proc</span><span>.</span><span>new</span> <span>{</span> <span>|</span><span>i</span><span>|</span> <span>puts</span> <span>i</span> <span>}</span>
<span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>].</span><span>each</span><span>(</span><span>&amp;</span><span>p</span><span>)</span> <span># =&gt; "1\n2\n3\n"</span>
<span>puts</span> <span>p</span><span>.</span><span>class</span> <span># =&gt; Proc</span>

<span>l</span> <span>=</span> <span>lambda</span> <span>{</span> <span>|</span><span>i</span><span>|</span> <span>puts</span> <span>i</span> <span>}</span>
<span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>].</span><span>each</span><span>(</span><span>&amp;</span><span>l</span><span>)</span> <span># =&gt; "1\n2\n3\n"</span>
<span>puts</span> <span>p</span><span>.</span><span>class</span> <span># =&gt; Proc</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>‚Ä¶but lambdas <em>are</em> different:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>p</span> <span># =&gt; #&lt;Proc:0xNNNNNNNNNNNNNN@(irb):2&gt;</span>
<span>l</span> <span># =&gt; #&lt;Proc:0xNNNNNNNNNNNNNN@(irb):3 (lambda)&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>I‚Äôm not going to go too deeply into the differences between the three
(<a href="http://awaxman11.github.io/blog/2013/08/05/what-is-the-difference-between-a-block/">here is a good post explaining them</a>),
but it should suffice to say that having 3 types of anonymous closures is fairly
ridiculous.
I don‚Äôt normally look to Python for good syntax design, but I greatly prefer
its singular <a href="http://www.secnetix.de/olli/Python/lambda_functions.hawk"><code>lambda</code></a>
syntax to Ruby‚Äôs hodgepodge of incompatible equivalents.</p>

<h3 id="2-dynamic-hashes">2. Dynamic Hashes</h3>

<p>First of all, Ruby‚Äôs <a href="http://ruby-doc.org/core-2.2.3/Hash.html">Hash</a> class is
really cool. It‚Äôs my favorite hash table interface, and working with it feels
extremely natural compared to hash interfaces in other languages.</p>

<p>Second of all, Ruby‚Äôs ability to create
<a href="https://blog.yossarian.net/2015/08/13/String-Formatting-With-Ruby-Dynamic-Hashes"><em>dynamic</em> hashes</a>
is <strong>really</strong> cool. They make lazy lookups a piece of cake:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>cubes</span> <span>=</span> <span>Hash</span><span>.</span><span>new</span> <span>{</span> <span>|</span><span>_</span><span>,</span> <span>k</span><span>|</span> <span>k</span> <span>**</span> <span>3</span> <span>}</span>
<span>cubes</span><span>[</span><span>1</span><span>]</span> <span># =&gt; 1</span>
<span>cubes</span><span>[</span><span>3</span><span>]</span> <span># =&gt; 27</span>
<span>cubes</span><span>[</span><span>9</span><span>]</span> <span># =&gt; 729</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unfortunately, as I‚Äôve written before, they‚Äôre also <strong>extremely limited</strong>. For
example, you can‚Äôt use them to format strings (as you could a normal hash):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span># normal</span>
<span>"My favorite color is %{color}!"</span> <span>%</span> <span>{</span> <span>color: </span><span>'purple'</span> <span>}</span> <span># =&gt; "My favorite color is purple!"</span>

<span># dynamic</span>
<span>h1</span> <span>=</span> <span>{</span> <span>color: </span><span>[</span><span>'red'</span><span>,</span> <span>'green'</span><span>,</span> <span>'blue'</span><span>]</span> <span>}</span>
<span>h2</span> <span>=</span> <span>Hash</span><span>.</span><span>new</span> <span>{</span> <span>|</span><span>_</span><span>,</span> <span>k</span><span>|</span> <span>h1</span><span>[</span><span>k</span><span>].</span><span>sample</span> <span>}</span>
<span>"My favorite color is %{color}!"</span> <span>%</span> <span>h2</span> <span># =&gt; KeyError: key{color} not found</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>They also simply don‚Äôt work with <code>Hash#fetch</code>, although this is slightly more
reasonable due to the looked-up key(s) not actually existing:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>h2</span><span>.</span><span>fetch</span><span>(</span><span>:color</span><span>)</span> <span># =&gt; KeyError: key not found: :color</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Similarly, the semantics of dynamic hashes are thoroughly messed up. Whether or
not methods like <code>Hash#key?</code> should always return <code>true</code> when called on dynamic
hashes is up for debate (I personally believe they should), but Ruby‚Äôs behavior
with respect to dynamic hashes certainly needs to be made more uniform.</p>

<h3 id="3-the-gem-ecosystem">3. The Gem Ecosystem</h3>

<p>Don‚Äôt get me wrong on this one. I really like <a href="https://rubygems.org/">RubyGems</a>
‚Äî it was well thought through, is easy to work worth (hooray for <em>working</em>
dependency tracking and uninstallation!), and hits that sweet spot between being
easy too easy upload to (result: <strong>everything</strong> is a package, even things that
shouldn‚Äôt be) and too difficult (result: <strong>nothing</strong> is a package).</p>

<p>Unfortunately, the Gem <em>ecosystem</em> is pretty awful.</p>

<p>Some major flaws:</p>

<ul>
  <li>There are <strong>tons</strong> of unmaintained or simply nonfunctional gems, with no
<em>uniform</em> (read: official) way to test them before installation. This isn‚Äôt a
rarity among language package managers, but it‚Äôs particularly pronounced in
Ruby‚Äôs case.</li>
  <li>Although Ruby has namespaces and Gems <strong>can</strong> use them to nest relevant
functionality, the practice has never really taken off in the community. As a
result, Gem groups that could be represented as a clean tree of dependency or
interoperation (often) end up being a spaghetti of custom names.</li>
  <li>There is a thorough lack of community compliance to proper
Gem naming (and loading) conventions. A simple search through
<a href="https://rubygems.org/gems">the listings</a> will reveal names like this:</li>
</ul>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre>my_special_gem
myspecialgem
libmyspecialgem
my-special-gem
mySpecialGem
MySpecialGem
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Not only is this awful in terms of Gem discovery, but it also makes finding and
using the <strong>right</strong> Gem a regular hassle. Deciding between <code>gem-for-service</code> and
<code>gem_for_service</code> shouldn‚Äôt have to be based on which has more stars on GitHub.</p>

<p>RubyGems could fix a lot of these problems by drawing inspiration from the Perl
and <a href="http://cpan.org/">CPAN</a>, the default and official Perl package manager.
There are plenty of things <em>wrong</em> with CPAN (especially with <code>cpan</code>, which
has a special place in hell reserved for it if it ever dies), but it also does
a lot of things <strong>right</strong>:</p>

<ul>
  <li>Well-defined namespaces exist and are <strong>enforced</strong>, keeping all modules in a
nice hierarchy of function. Adding your module to a namespace is as simple as
naming it correctly and asking permission from the namespace‚Äôs originator
(particularly for smaller hierarchies). Module naming is taken equally
seriously - there may be duplicate functionality across CPAN packages, but you
certainly won‚Äôt find it in <code>Foo::MyBar</code> and <code>Foo::My_Bar</code>.</li>
  <li><a href="http://cpantesters.org/">Testing</a> and
<a href="http://cpanratings.perl.org/">module ratings</a> are seamlessly integrated into
both CPAN and MetaCPAN, giving module maintainers easy access to both their
users and a <a href="http://pass.cpantesters.org/"><strong>massive</strong> array</a> of testing
environments.</li>
</ul>

<p>(I remember reading a blog post comparing the favorable aspects of RubyGems and
CPAN a while ago. If you happen to know it, I‚Äôd appreciate it if you could link
it below or get it to me some other way.)</p>



<p>Oh boy.</p>

<p>For some reason, Ruby divides what most other languages call their
‚ÄúStandard Libraries‚Äù into two: the ‚Äú<a href="http://ruby-doc.org/core/">core</a>‚Äù and the
‚Äú<a href="http://ruby-doc.org/stdlib/">Stdlib</a>‚Äù.</p>

<p>This organizational decision makes no particular difference to the user, apart
from the fact that Stdlib classes usually need to explicitly loaded with
<code>require</code>. This essentially makes the Stdlib the <em>only</em> libraries that are
<strong>guaranteed</strong> to be <code>require</code>-able (if not functional) on <strong>every</strong> Ruby
installation (or not, as we‚Äôll see below).</p>

<p>Unfortunately, the Stdlib and its libraries are a bit of a nightmare:</p>

<ul>
  <li>Various decisions of uncertain merit were made over the years to include
system-specific libraries into the Stdlib. The result: libraries like
<a href="http://ruby-doc.org/stdlib/libdoc/win32ole/rdoc/WIN32OLE.html">WIN32OLE</a>,
<a href="http://ruby-doc.org/stdlib/libdoc/shell/rdoc/Shell.html">Shell</a>,
and <a href="http://ruby-doc.org/stdlib/libdoc/fcntl/rdoc/Fcntl.html">Fcntl</a>. Why
does <a href="http://ruby-doc.org/stdlib/libdoc/etc/rdoc/Etc.html">Etc</a> even exist?</li>
  <li>Documentation is poor, and duplication abounds. Why are there
<a href="http://ruby-doc.org/stdlib/libdoc/pp/rdoc/PP.html">two</a>
<a href="http://ruby-doc.org/stdlib/libdoc/prettyprint/rdoc/PrettyPrint.html">prettyprinters</a>?
Why is there <a href="http://ruby-doc.org/stdlib/libdoc/dbm/rdoc/DBM.html">DBM</a>,
<a href="http://ruby-doc.org/stdlib/libdoc/sdbm/rdoc/SDBM.html">SDBM</a>,
and <a href="http://ruby-doc.org/stdlib/libdoc/gdbm/rdoc/GDBM.html">GDBM</a>?</li>
  <li>The distinction between the core and Stdlib is shaky.
<a href="http://ruby-doc.org/core/Queue.html">Queue</a> is in core, but
<a href="http://ruby-doc.org/stdlib/libdoc/set/rdoc/Set.html">Set</a> is in Stdlib.
<a href="http://ruby-doc.org/stdlib/libdoc/scanf/rdoc/Scanf.html">Scanf</a> is in Stdlib,
but <code>Kernel#sprintf</code> is in core‚Äôs <a href="http://ruby-doc.org/core/Kernel.html">Kernel</a>
class.</li>
</ul>

<p>Not <strong>everything</strong> in the Stdlib is a mess. Some parts, like
<a href="http://ruby-doc.org/stdlib/libdoc/net/imap/rdoc/index.html">Net::IMAP</a>
and <a href="http://ruby-doc.org/stdlib/libdoc/optparse/rdoc/OptParse.html">OptParse</a>,
are extremely useful and acceptably documented.</p>

<p>Unfortunately, the <em>rest</em> is a mess of unidiomatic, system-specific,
10+ year old undocumented Ruby code.</p>

<p>My solution? Merge Stdlib and core into <em>one big standard library</em> and do what
every other language does when things have to be brought in manually - specify
it in the documentation. Exceedingly old libraries should be either adequately
documented and brought up to spec with more modern Ruby or simply tossed out
‚Äî the language has broken compatibility over the years, and so should the
libraries.</p>

<h3 id="5-rails-and-other-massive-ruby-projects">5. Rails (and other massive Ruby projects)</h3>

<p>This one is last not because it‚Äôs the least important (it isn‚Äôt) or because I
had to rack my brains for things I dislike about Ruby (I didn‚Äôt), but because
I think it‚Äôs the one that most people will disagree with me about. Call me
manipulative, but I like to ease people into my unpopular software opinions.</p>

<p>Rails is a mess, and so are a lot of the other large projects <em>known</em> for being
written in Ruby.</p>

<p>This wouldn‚Äôt be so bad (apart from the negative reputation, which isn‚Äôt a
language problem) if it weren‚Äôt for the fact that these projects have an
outsized influence on both the community and the <em>direction</em> of the Ruby
language as a whole.</p>

<p>Unfortunately, they do. Looking a problem in Ruby up on the Web follows this
rough chain of events:</p>

<ol>
  <li>Google the problem</li>
  <li>Skip the first 2-3 results, which are usually blog posts about Rails</li>
  <li>Find the first StackOverflow question that looks remotely applicable</li>
  <li>Scroll down until you find a solution that doesn‚Äôt:</li>
  <li>Assume that you‚Äôre developing on Rails</li>
  <li>Assume that you want to use ActiveRecord (or any other Rails satellite)</li>
  <li>Claim that you‚Äôre suffering from the <a href="http://xyproblem.info/">XY Problem</a>
  and <em>actually are</em> developing on Rails</li>
  <li>Attempt to apply the solution, goto 1 if you fail</li>
</ol>

<p>Rails is the dominant example, but Ruby often feels like a community divided.</p>

<p>On one hand are web developers intent on twisting the language to suit their
(primarily web-based) needs, and on the other are administrators and non-web
programmers (read: Perl refugees) intent on burrowing out their own little
fifedoms in the Ruby ecosystem. The result is a community that can‚Äôt decide
whether it‚Äôs centered around a framework that happens to run in a language, or
the language itself.</p>

<p>This impedes language advancement (backwards compatibility!), and makes the Ruby
community <em>feel</em> much smaller than it actually is. The ‚Äúsolution‚Äù is to simply
grit your teeth and wait for Rails to decline in popularity. Even so, I couldn‚Äôt
help but mention it here.</p>

<h3 id="concluding-notes">Concluding Notes</h3>

<p>I came up with this list relatively quickly.</p>

<p>If you know or come up with something that you think is worse, feel free to drop
it below and we‚Äôll discuss it ‚Äî my grievances probably don‚Äôt trump yours.</p>

<p>- William</p>



<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2015/09/28/Five-Things-I-Hate-About-Ruby</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296515</guid>
            <pubDate>Sun, 28 Feb 2021 20:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The American-Dream-as-a-Service]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26296397">thread link</a>) | @jger15
<br/>
February 28, 2021 | https://www.thepullrequest.com/p/the-american-dream-as-a-service | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/the-american-dream-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h5>Austen Allred is the CEO and founder of Lambda School, a unique coding school that pioneered the ‚Äòincome-sharing agreement‚Äô (ISA) model, whereby students only pay if they‚Äôre hired in their field of study. Lambda came out of incubator Y Combinator, before which he lived in his two-door Honda Civic and scalped soccer tickets at Stanford Stadium to get by. Prior to Bay Area entrepreneurship, he did a two-year mission to the Ukraine where he learned Russian and knocked on lots of doors. The interview was conducted via Zoom with Austen in Southern Utah, from where he routinely tweets out enviable photography of Utah‚Äôs stunning landscape.</h5><p><strong>Your posts are some of the most uplifting things in my feed. They‚Äôre either screenshots from an internal Slack or a retweet, and it‚Äôs a Lambda student saying: I went from making $20,000 in some service job, and now I'm making $80,000/year doing something technical at (say) Cisco, and you've totally changed my life. </strong></p><p><strong>One thing you often post that I think isn‚Äôt obvious to people who don't run a socio-economic escalator is all the necessary polish and look-and-feel of being part of the bougie techie class. For example, how you have this email protocol to set up a meeting. Or that if you think you're underpaid, you go in and you say, </strong><em><strong>screw you, pay me more or I leave</strong></em><strong>. It's intriguing that you don‚Äôt only have to educate them to turn them into front end engineers, you also have to teach them the social skills around that to become that bougie techie person.</strong></p><p>That's one of the really weird things: The hiring process is not just a filter for skills, it's also a filter for class. And people don't talk about or acknowledge that. It's very clear in all these protocols that we have in tech that you and I understand, you have to learn them the hard way. I'll give you a couple of examples. When I was in sixth grade, I was selling stuff on eBay. I was just this kid trying to hustle, and I had this mentor/entrepreneur who came into high school every now and then and just talked with us. And I was like, okay, real talk! What do I need to do to be taken seriously, because nobody takes me seriously because I'm a 15-year-old kid? And he sat me down and he said: <em>We are going to start using this thing called Gmail</em>. <em>I'm going to send you an invite, and you're going to set up firstname.lastname@gmail.com, no numbers, no nonsense, nothing else, you're going to have no signature, and you're only ever going to send text emails for the rest of your life.</em> <em>That's step one</em>. He just walked me through all this really, really basic stuff. </p><p>There was this other time I was in college‚Ä¶I was hustling and trying to get into startups and there was this guy at a conference I wanted to work with, so I went up and talked to him. And I said <em>what can I do to be like you? </em>He gave me his business card and said <em>just ping me next week</em>. </p><p>I spent hours and hours and hours looking up what <em>ping me</em> meant. I couldn't find anything. So eventually I called somebody and said <em>hey, this guy said ping me. What does that mean?</em> <em>How do I ping? </em>And that person was like, <em>no, no, it‚Äôs a call or an email or anything really, just reach out to them. Doesn‚Äôt matter how.</em> <em>That's all that ping means</em>. <em>You know, like a cell tower. Ping!</em> I was like, <em>ohhhhhhhh!</em> There's so much little stuff like that. Another classic example is intros, right? Or using Google Calendar. I didn't know how to use Google Calendar until I showed up in my first job. Someone tells me, <em>I am gonna put some time on your calendar</em>. And I think: <em>Oh, I guess I have a calendar</em>. That's not obvious if you don't come from, frankly, a certain class. But all of those things are important; if you don't intro somebody the right way to a VC, they know you're a dunce, automatically. There‚Äôs nobody that sits you down and says <em>hey, you're gonna say thank you so-and-so, moving you to BCC</em>. It's not hard, but nobody ever tells you that anywhere.</p><h4>I've heard it described as ‚Äòthe bottom 1000 universities‚Äô: Assume there's some algorithm that spits out the combination of <em>is expensive</em> and <em>is ineffective</em>. There are at least 1000 universities in the US that should cease to exist. There are many universities that net do more harm than good.</h4><p><strong>There's no tech charm school that teaches you how to do all that stuff.</strong></p><p>Totally. And I'm sure there's more stuff. When one of our first students got hired at Uber, he showed up with his laptop. They tell him: <em>you're a mobile developer</em>. And he's like, <em>I can't be a mobile developer, I don't have a phone</em>. He didn't have a smartphone. So he called me freaking out: <em>What am I gonna do!? Uber wants to hire me. I don't have a smartphone.</em> I told him: <em>Uber does not care about that, Uber‚Äôs gonna have a thousand phones, that's the least of Uber‚Äôs worries. They're gonna give you a laptop too.</em> </p><p>Then he shows up to work on day one and they tell him: <em>Alright, you know, put in your bank account information here to get direct deposit.</em> He's like, <em>no just cut me a check and I‚Äôll run to the check-cashing store.</em> </p><p>The Uber people reached out to me and said: <em>We don‚Äôt know if this is going to work.</em> I was like, <em>he's a smart guy, it‚Äôs just that he doesn't have a bank account</em>. So now we set up bank accounts for every student that doesn't have a bank account. The best way I think to describe Lambda School is the American-Dream-as-a-service. </p><p><strong>Wow. That‚Äôs the corporate anthem right there.</strong></p><p>(Laughs.)</p><p><strong>There so much cultural encoding in an interview which, as you said, is just filtering for class. But‚Ä¶as these are technical people, there‚Äôs actually an objective standard of merit. </strong></p><p>There are a whole swath of white collar jobs that the interview process literally is like, <em>Hey, I'm gonna play a little verbal tennis with you and see if you can stand your ground and if you can, you get the job</em>. That's probably the average white collar job.</p><h4>That's one of the really weird things: The hiring process is not just a filter for skills, it's also a filter for class. And people don't talk about or acknowledge that. </h4><p><strong>Speaking of other jobs, do you see Lambda expanding to other fields? Is that even possible? </strong></p><p><strong>The thing that obviously aligns incentives is to look at education as a hard-nosed business proposition. I'm sure you personally care, but the reason why you care as a business owner is because you want them to get the job because otherwise you're not gonna get paid, right? You‚Äôve invested a year and a half in this person, and they can't blow it up because they don‚Äôt know about direct deposits, so you fix that. Which is good, and certainly a lot better than the business model universities have. But that model only works if there's some pretty predictable future stream of income along with pretty predictable employment demand. Can you imagine non-technical professions like trucking and nursing that have high demand and high wages? </strong></p><p>The cool thing about the incentive alignment is that we're not going to train you to be a sociologist, because it just doesn't work. A common critique of the ISA model is: <em>oh, now people aren't going to study poetry anymore.</em> And my response to that is: <em>yeah, we're not a university, we're a trade school</em>. The university has 18 million things that it does for you, and we cut cut off a tiny sliver of that, which is: we're going to help you get a better job, we're going to help you improve your state in life. That's all we do. </p><p>There are actually more high-paying jobs available than there are people to fill those roles. And that's true all over the place. I think about it as an optimization problem. You've got all this latent human potential, and it's just kind of bouncing around. Sometimes it goes to school, and it picks stuff at random to study, and you know what you know because of who you‚Äôre surrounded by.</p><p>One aspect of Lambda School that I think is underappreciated is a whole lot of people come in having no idea of what software is, having no idea that there's such a thing as a software engineer. We have people who join and think it's like, <em>I'm gonna fix printers</em>. They know that tech is a high-paying field, but they're not surrounded it. If you're in the inner city, or in a rural area, you don't know a computer programmer. </p><p>One way to think about Lambda is like fintech: You have all these transactions that are moving all over the place, but what makes it all work is a clearinghouse that moves all the money to where it needs to go. I think of Lambda as kind of an economic clearinghouse: Here's all of the untapped human potential, here's all the would-be labor, and over here‚Äôs all the jobs that need to be done. There's nothing connecting the two right now other than sheer happenstance and going to university, or maybe you hear that there's a good job over here somewhere.</p><p>But right now the situation is not: <em>I'm making $50k, here's my skill set and my interest, I want to make $90k</em>. Somebody should be able to tell you how to do that, and right now, nobody can. That‚Äôs crazy. More than half of GDP is just people working, and that's completely unoptimized. </p><p><strong>Right. Even I, who came from a middle-class background and went to the university track, it seemed like a recently poorly-managed process and I only ended up in science and technology by sheer happenstance‚Ä¶</strong></p><p>You stumbled in, yeah? I feel the same way, and the interesting thing now is, depending on which way you happen to stumble, you can end up fabulously rich or destitute based on your stumblings. </p><h4>The other broken piece is the notion that you go to school once for 10 years when you're 18, and you'll be able to ride that for the rest of your career. That‚Äôs probably false for a whole lot of people.</h4><p><strong>So this model you‚Äôre describing, where you basically connect people from one income level to another higher one via various different processes. I‚Äôm curious what other connections you can imagine existing. </strong></p><p>The way to answer that is to see where all the shortages are, where are people trying to hire and those people don‚Äôt exist? Tech is an obvious one, but it‚Äôs all over the place in ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/the-american-dream-as-a-service">https://www.thepullrequest.com/p/the-american-dream-as-a-service</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/the-american-dream-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296397</guid>
            <pubDate>Sun, 28 Feb 2021 19:46:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I cut GTA Online loading times by 70%]]>
            </title>
            <description>
<![CDATA[
Score 2818 | Comments 481 (<a href="https://news.ycombinator.com/item?id=26296339">thread link</a>) | @kuroguro
<br/>
February 28, 2021 | https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/ | <a href="https://web.archive.org/web/*/https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>GTA Online. <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/9vgo0g/how_the_fuck_are_20_minute_load_times_acceptable/">Infamous</a> for its slow loading times. Having picked up the game again to finish some of the newer heists I was <em>shocked</em> (/s) to discover that it still loads just as slow as the day it was released 7 years ago.</p>
<p>It was time. Time to get to the bottom of this.</p>
<h2 id="Recon"><a href="#Recon" title="Recon"></a>Recon</h2><p>First I wanted to check if someone had already solved this problem. Most of the results I found pointed towards anecdata about <a target="_blank" rel="noopener" href="https://metro.co.uk/2017/11/01/why-does-gta-v-take-so-long-to-load-7041927/">how the game is so sophisticated</a> that it needs to load so long, stories on how the <a target="_blank" rel="noopener" href="https://steamcommunity.com/app/271590/discussions/0/217690940938819317/">p2p network architecture</a> is rubbish (not saying that it isn‚Äôt), some elaborate ways of <a target="_blank" rel="noopener" href="https://gtaforums.com/topic/908000-fastest-way-to-load-into-gtao-single-player-first-or-straight-in/">loading into story mode and a solo session after that</a> and a couple of mods that allowed skipping the startup R* logo video. Some more reading told me we could save a whopping 10-30 seconds with these combined!</p>
<p>Meanwhile on my PC‚Ä¶</p>
<h2 id="Benchmark"><a href="#Benchmark" title="Benchmark"></a>Benchmark</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></pre></td><td><pre><span>Story mode load time:  ~1m 10s</span><br><span>Online mode load time: ~6m flat</span><br><span>Startup menu disabled, time from R* logo until in-game (social club login time isn't counted).</span><br><span></span><br><span>Old but decent CPU:   AMD FX-8350</span><br><span>Cheap-o SSD:          KINGSTON SA400S37120G</span><br><span>We have to have RAM:  2x Kingston 8192 MB (DDR3-1337) 99U5471</span><br><span>Good-ish GPU:         NVIDIA GeForce GTX 1070</span><br></pre></td></tr></tbody></table></figure>

<p>I know my setup is dated but what on <em>earth</em> could take 6x longer to load into online mode? I couldn‚Äôt measure any difference using the story-to-online loading technique <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/kycy7a/gtao_loading_times_using_different_methods/">as others have found before me</a>. Even if it did work the results would be down in the noise.</p>
<h2 id="I-Am-Not-Alone"><a href="#I-Am-Not-Alone" title="I Am (Not) Alone"></a>I Am (Not) Alone</h2><p>If <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/ht4i56/your_average_online_loading_time/">this poll</a> is to be trusted then the issue is widespread enough to mildly annoy more than 80% of the player base. It‚Äôs been 7 years R*!</p>
<p><img src="https://nee.lv/images/pasted-0.png" alt="üéµWhat does the poll say?üéµ"></p>
<p>Looking around a bit to find who are the lucky ~20% that get sub 3 minute load times I came across <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RdCqDdjp6iU">a</a> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=pJzr3qfyCyg">few</a> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RK7BUFx_NGk">benchmarks</a> with high-end gaming PCs and an online mode load time of about 2 minutes. I would <del>kill</del> <em>hack</em> for a 2 minute load time! It does seem to be hardware-dependent but something doesn‚Äôt add up here‚Ä¶</p>
<p>How come their story mode still takes near a minute to load? (The M.2 one didn‚Äôt count the startup logos btw.) Also, loading story to online takes them only a minute more while I‚Äôm getting about five more. I know that their hardware specs are a lot better but surely not 5x better.</p>
<h2 id="Highly-accurate-measurements"><a href="#Highly-accurate-measurements" title="Highly accurate measurements"></a>Highly accurate measurements</h2><p>Armed with such powerful tools as <em>the Task Manager</em> I began to investigate what resources could be the bottleneck.</p>
<p><img src="https://nee.lv/images/pasted-1.png" alt="Can you smell it?"></p>
<p>After taking a minute to load the common resources used for both story and online modes (which is near on par with high-end PCs) GTA decides to max out a single core on my machine for four minutes and do nothing else.</p>
<p>Disk usage? None! Network usage? There‚Äôs a bit, but it drops basically to zero after a few seconds (apart from loading the rotating info banners). GPU usage? Zero. Memory usage? Completely flat‚Ä¶</p>
<p>What, is it mining crypto or something? I smell code. <em>Really bad code</em>.</p>
<h2 id="Single-thread-bound"><a href="#Single-thread-bound" title="Single thread-bound"></a>Single thread-bound</h2><p>While my old AMD CPU has 8 cores and it does pack a punch, it was made in the olden days. Back when AMD‚Äôs <a target="_blank" rel="noopener" href="https://valid.x86.fr/bench/6u7sdy/1">single-thread performance</a> was <em>way</em> behind Intel‚Äôs. This might not explain all of the load time differences but it should explain most of it.</p>
<p>What‚Äôs odd is that it‚Äôs using up <em>just</em> the CPU. I was expecting vast amounts of disk reads loading up resources or loads of network requests trying to negotiate a session in the p2p network. But this? This is probably a bug.</p>
<h2 id="Profiling"><a href="#Profiling" title="Profiling"></a>Profiling</h2><p>Profilers are a great way of finding CPU bottlenecks. There‚Äôs only one problem - most of them rely on instrumenting the source code to get a perfect picture of what‚Äôs happening in the process. And I don‚Äôt have the source code. Nor do I need microsecond-perfect readings - I have 4 minutes‚Äô worth of a bottleneck.</p>
<p>Enter stack sampling: for closed source applications there‚Äôs only one option. Dump the running process‚Äô stack and current instruction pointer‚Äôs location to build a calling tree in set intervals. Then add them up to get statistics on what‚Äôs going on. There‚Äôs only one profiler that I know of (might be ignorant here) that can do this on Windows. And it hasn‚Äôt been updated in over 10 years. It‚Äôs <a target="_blank" rel="noopener" href="http://lukestackwalker.sourceforge.net/">Luke Stackwalker</a>! Someone, please give this project some love :)</p>
<p><img src="https://nee.lv/images/pasted-2.png" alt="The power of statistics compels you!"></p>
<p>Normally Luke would group the same functions together but since I don‚Äôt have debugging symbols I had to eyeball nearby addresses to guess if it‚Äôs the same place. And what do we see? Not one bottleneck but two of them!</p>
<h2 id="Down-the-rabbit-hole"><a href="#Down-the-rabbit-hole" title="Down the rabbit hole"></a>Down the rabbit hole</h2><p>Having borrowed <em>my friend‚Äôs</em> completely legitimate copy of <em>the industry-standard disassembler</em> (no, I really can‚Äôt afford the thing‚Ä¶ gonna learn to <a target="_blank" rel="noopener" href="https://ghidra-sre.org/">ghidra</a> one of these days) I went to take GTA apart.</p>
<p><img src="https://nee.lv/images/pasted-3.png" alt="Gibberish Galore"></p>
<p>That doesn‚Äôt look right at all. Most high-profile games come with built-in protection against reverse engineering to keep away pirates, cheaters, and modders. Not that it has ever stopped them.</p>
<p>There seems to be some sort of an obfuscation/encryption at play here that has replaced most instructions with gibberish. Not to worry, we simply need to dump the game‚Äôs memory while it‚Äôs executing the part we want to look at. The instructions have to be de-obfuscated before running one way or another. I had <a target="_blank" rel="noopener" href="https://github.com/glmcdona/Process-Dump">Process Dump</a> lying around, so I used that, but there are plenty of other tools available to do this sort of thing.</p>
<h2 id="Problem-one-It‚Äôs‚Ä¶-strlen"><a href="#Problem-one-It‚Äôs‚Ä¶-strlen" title="Problem one: It‚Äôs‚Ä¶ strlen?!"></a>Problem one: It‚Äôs‚Ä¶ strlen?!</h2><p>Disassembling the now-less-obfuscated dump reveals that one of the addresses has a label pulled out of somewhere! It‚Äôs <code>strlen</code>? Going down the call stack the next one is labeled <code>vscan_fn</code> and after that the labels end, tho I‚Äôm fairly confident it‚Äôs <a target="_blank" rel="noopener" href="https://github.com/chakra-core/ChakraCore/blob/master/pal/src/safecrt/sscanf.c#L47"><code>sscanf</code></a>.</p>
<p><img src="https://nee.lv/images/pasted-4.png" alt="A graph a day keeps the skeptics away"></p>
<p>It‚Äôs parsing something. Parsing what? Untangling the disassembly would take forever so I decided to dump some samples from the running process using <a target="_blank" rel="noopener" href="https://x64dbg.com/">x64dbg</a>. Some debug-stepping later it turns out it‚Äôs‚Ä¶ JSON! They‚Äôre parsing JSON. A whopping <strong>10 megabytes</strong> worth of JSON with some <strong>63k item entries</strong>.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span>...,</span><br><span>{</span><br><span>    <span>"key"</span>: <span>"WP_WCT_TINT_21_t2_v9_n2"</span>,</span><br><span>    <span>"price"</span>: <span>45000</span>,</span><br><span>    <span>"statName"</span>: <span>"CHAR_KIT_FM_PURCHASE20"</span>,</span><br><span>    <span>"storageType"</span>: <span>"BITFIELD"</span>,</span><br><span>    <span>"bitShift"</span>: <span>7</span>,</span><br><span>    <span>"bitSize"</span>: <span>1</span>,</span><br><span>    <span>"category"</span>: [<span>"CATEGORY_WEAPON_MOD"</span>]</span><br><span>},</span><br><span>...</span><br></pre></td></tr></tbody></table></figure>

<p>What is it? It appears to be data for a ‚Äúnet shop catalog‚Äù according to some references. I assume it contains a list of all the possible items and upgrades you can buy in GTA Online.</p>
<p><strong>Clearing up some confusion: I beleive these are in-game money purchasable items, not directly linked with <a target="_blank" rel="noopener" href="https://gta.fandom.com/wiki/Cash_Cards">microtransactions</a>.</strong></p>
<p>But 10 megs? That‚Äôs nothing! And using <code>sscanf</code> may not be optimal but surely it‚Äôs not that bad? Well‚Ä¶</p>
<p><img src="https://nee.lv/images/pasted-5.png" alt="Ouch!"></p>
<p>Yeah, that‚Äôs gonna take a while‚Ä¶ To be fair I had no idea most <code>sscanf</code> implementations called <code>strlen</code> so I can‚Äôt blame the developer who wrote this. I would assume it just scanned byte by byte and could stop on a <code>NULL</code>.</p>
<h2 id="Problem-two-Let‚Äôs-use-a-Hash-‚Ä¶-Array"><a href="#Problem-two-Let‚Äôs-use-a-Hash-‚Ä¶-Array" title="Problem two: Let‚Äôs use a Hash- ‚Ä¶ Array?"></a>Problem two: Let‚Äôs use a Hash- ‚Ä¶ Array?</h2><p>Turns out the second offender is called right next to the first one. They‚Äôre both even called in the same <code>if</code> statement as seen in this ugly decompilation:</p>
<p><img src="https://nee.lv/images/pasted-6.png" alt="Beggar thy neighbour"></p>
<p>All labels are mine, no idea what the functions/parameters are actually called.</p>
<p>The second problem? Right after parsing an item, it‚Äôs stored in an array (or an inlined C++ list? not sure). Each entry looks something like this:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></pre></td><td><pre><span><span><span>struct</span> {</span></span><br><span>    <span>uint64_t</span> *hash;</span><br><span>    <span>item_t</span>   *item;</span><br><span>} entry;</span><br></pre></td></tr></tbody></table></figure>

<p>But before it‚Äôs stored? It checks the <em>entire</em> array, one by one, comparing the hash of the item to see if it‚Äôs in the list or not. With ~63k entries that‚Äôs <code>(n^2+n)/2 = (63000^2+63000)/2 = 1984531500</code> checks if my math is right. Most of them useless. You have unique <em>hashes</em> why not use a <em>hash map</em>.</p>
<p><img src="https://nee.lv/images/pasted-7.png" alt="Oof!"></p>
<p>I named it <code>hashmap</code> while reversing but it‚Äôs clearly <code>not_a_hashmap</code>. And it gets even better. The hash-array-list-thing is empty before loading the JSON. And all of the items in the JSON are unique! They don‚Äôt even <em>need</em> to check if it‚Äôs in the list or not! They even have a function to directly insert the items! Just use that! Srsly, WAT!?</p>
<h2 id="PoC"><a href="#PoC" title="PoC"></a>PoC</h2><p>Now that‚Äôs nice and all, but no one is going to take me seriously unless I test this so I can write a clickbait title for the post.</p>
<p>The plan? Write a <code>.dll</code>, inject it in GTA, <a target="_blank" rel="noopener" href="https://github.com/TsudaKageyu/minhook">hook</a> some functions, ???, profit.</p>
<p>The JSON problem is hairy, I can‚Äôt realistically replace their parser. Replacing <code>sscanf</code> with one that doesn‚Äôt depend on <code>strlen</code> would be more realistic. But there‚Äôs an even easier way.</p>
<ul>
<li>hook strlen</li>
<li>wait for a long string</li>
<li>‚Äúcache‚Äù the start and length of it</li>
<li>if it‚Äôs called again within the string‚Äôs range, return cached value</li>
</ul>
<p>Something like:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br></pre></td><td><pre><span><span><span>size_t</span> <span>strlen_cacher</span><span>(<span>char</span>* str)</span></span></span><br><span><span></span>{</span><br><span>  <span>static</span> <span>char</span>* start;</span><br><span>  <span>static</span> <span>char</span>* end;</span><br><span>  <span>size_t</span> len;</span><br><span>  <span>const</span> <span>size_t</span> cap = <span>20000</span>;</span><br><span></span><br><span>  </span><br><span>  <span>if</span> (start &amp;&amp; str &gt;= start &amp;&amp; str &lt;= end) {</span><br><span>    </span><br><span>    len = end - str;</span><br><span></span><br><span>    </span><br><span>    </span><br><span>    <span>if</span> (len &lt; cap / <span>2</span>)</span><br><span>      MH_DisableHook((LPVOID)strlen_addr);</span><br><span></span><br><span>    </span><br><span>    <span>return</span> len;</span><br><span>  }</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  </span><br><span>  len = builtin_strlen(str);</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  <span>if</span> (len &gt; cap) {</span><br><span>    start = str;</span><br><span>    end = str + len;</span><br><span>  }</span><br><span></span><br><span>  </span><br><span>  <span>return</span> len;</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<p>And as for the hash-array problem, it‚Äôs more straightforward - just skip the duplicate checks entirely and insert the items directly since we know the values are unique.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></pre></td><td><pre><span><span><span>char</span> __fastcall <span>netcat_insert_dedupe_hooked</span><span>(<span>uint64_t</span> catalog, <span>uint64_t</span>* key, <span>uint64_t</span>* item)</span></span></span><br><span><span></span>{</span><br><span>  </span><br><span>  <span>uint64_t</span> not_a_hashmap = catalog + <span>88</span>;</span><br><span></span><br><span>  </span><br><span>  <span>if</span> (!(*(<span>uint8_t</span>(__fastcall**)(<span>uint64_t</span>*))(*item + <span>48</span>))(item))</span><br><span>    <span>return</span> <span>0</span>;</span><br><span></span><br><span>  </span><br><span>  netcat_insert_direct(not_a_hashmap, key, &amp;item);</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  <span>if</span> (*key == <span>0x7FFFD6BE</span>) {</span><br><span>    MH_DisableHook((LPVOID)netcat_insert_dedupe_addr);</span><br><span>    unload();</span><br><span>  }</span><br><span></span><br><span>  <span>return</span> <span>1</span>;</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<p>Full source of PoC <a target="_blank" rel="noopener" href="https://github.com/tostercx/GTAO_Booster_PoC">here</a>.</p>
<h2 id="Results"><a href="#Results" title="Results"></a>Results</h2><p>Well, did it work then?</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span>Original online mode load time:        ~6m flat</span><br><span>Time with only duplication check patch: 4m 30s</span><br><span>Time with only JSON parser patch:       2m 50s</span><br><span>Time with both issues patched:          1m 50s</span><br><span></span><br><span>(6*60 - (1*60+50)) / (6*60) = 69.4% load time improvement (nice!)</span><br></pre></td></tr></tbody></table></figure>

<p>Hell yes, it did! :))</p>
<p>Most likely, this won‚Äôt solve everyone‚Äôs load times - there might be other bottlenecks on different systems, but it‚Äôs such a gaping hole that I have no idea how R* has missed it all these years.</p>
<h2 id="tl-dr"><a href="#tl-dr" title="tl;dr"></a>tl;dr</h2><ul>
<li>There‚Äôs a single thread CPU bottleneck while starting up GTA Online</li>
<li>It turns out GTA struggles to parse a 10MB JSON file</li>
<li>The JSON parser itself is poorly built / naive and</li>
<li>After parsing there‚Äôs a ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/</a></em></p>]]>
            </description>
            <link>https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296339</guid>
            <pubDate>Sun, 28 Feb 2021 19:38:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create animated GIF and WebP from videos using FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26296315">thread link</a>) | @Audiolite
<br/>
February 28, 2021 | https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article class="page">
    <div>
      
      <div>

        

<p>Saturday, February 27, 2021</p>

<p><a href="https://mattj.io/posts/">Click here to go to all posts</a>. <em>Also published on <a href="https://mattjoseph.medium.com/create-animated-gif-and-webp-from-videos-using-ffmpeg-f1012267935a" target="_blank" rel="noopener">Medium</a></em></p>

<p><em>A guide to using FFmpeg to create all the animated content you want.</em></p>

<p>Whether it‚Äôs for a website, a presentation, or sharing a fun clip with a friend on chat, you might want to convert a video to an animated GIF or animated WebP. Unfortunately, the visual tools for doing this vary by your operating system. Additionally, most conversion tools don‚Äôt support <a href="https://en.wikipedia.org/wiki/WebP" target="_blank" rel="noopener">the WebP format</a>, even in 2021. WebP is based on VP8, a relatively recent video codec standard compared to the <a href="https://en.wikipedia.org/wiki/GIF" target="_blank" rel="noopener">GIF image format</a>.</p>

<p>So, this guide is for those who are willing to learn a bit of terminal in order to convert any video to the animated format of their choosing. The best part: this will work on all major operating systems and gives you all the control of the output you could want!</p>


<figcaption>Example GIF of typing "GIF" on a mechanical keyboard</figcaption>

<p>Let‚Äôs get started!</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>To use this guide, you will need the following:</p>

<ul>
  <li>Basic knowledge of how to open and use the terminal on your operating system. If you need a cheat sheet or introductory guides, check out <a href="https://terminalcheatsheet.com/" target="_blank" rel="noopener">Terminal Cheat Sheet</a>.</li>
  <li>FFmpeg v4+ installed on your operating system and executable from your path. Here are some suggested places to learn down to do this:
    <ul>
      <li>macOS: <a href="https://superuser.com/a/624562" target="_blank" rel="noopener">https://superuser.com/a/624562</a></li>
      <li>Windows: <a href="https://video.stackexchange.com/a/20496" target="_blank" rel="noopener">https://video.stackexchange.com/a/20496</a></li>
      <li>Linux: Use your preferred package manager (e.g., <code>sudo apt install ffmpeg</code> on Ubuntu)</li>
    </ul>
  </li>
</ul>

<h2 id="what-isffmpeg">What is&nbsp;FFmpeg?</h2>

<p><a href="https://en.wikipedia.org/wiki/FFmpeg" target="_blank" rel="noopener">From Wikipedia</a>:</p>

<blockquote>
  <p>FFmpeg is a free and open-source software project consisting of a large suite of libraries and programs for handling video, audio, and other multimedia files and streams.</p>
</blockquote>

<p>For our purposes, we will use it to convert between formats, such as videos to GIFs or animated WebP. It has many uses, so I recommend checking it out for all your video processing needs!</p>

<h2 id="before-you-start-make-sure-you-can-run-ffmpeg-from-yourterminal">Before you start: make sure you can run FFmpeg from your&nbsp;terminal</h2>

<p>Since all of these commands require FFmpeg, we need to make sure it‚Äôs available.</p>

<p>Open your terminal, and run this:</p>



<p>If FFmpeg is available, you will note output similar to this:</p>

<div><div><pre><code>FFmpeg version 4.3.1 Copyright ¬© 2000‚Äì2020 the FFmpeg developers
...
</code></pre></div></div>


<figcaption>Checking the FFmpeg version on Linux</figcaption>

<p>Version 4 or higher of FFmpeg is recommended for this guide.</p>

<p>If you get an output that says something similar to <code>command not found: ffmpeg -version</code>, then check the <strong>Prerequisites</strong> section above and make sure you have FFmpeg installed on your system.</p>

<h2 id="convert-to-an-animated-gif-usingffmpeg">Convert to an animated GIF using&nbsp;FFmpeg</h2>

<h3 id="convert-a-whole-video-togif">Convert a whole video to&nbsp;GIF</h3>

<p><strong>Base command</strong></p>

<div><div><pre><code>ffmpeg -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop $NUMBER_OF_LOOPS $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated GIF.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop 0 sample_recording.gif
</code></pre></div></div>

<h3 id="convert-part-of-a-video-togif">Convert part of a video to&nbsp;GIF</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting part of a video to an animated GIF:</p>

<div><div><pre><code>ffmpeg -ss $INPUT_START_TIME -t $LENGTH -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop $NUMBER_OF_LOOPS $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_START_TIME - number of seconds in the input video to start from.
# * $LENGTH - number of seconds to convert from the input video.
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated GIF.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -ss 32.5 -t 7 -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop 0 sample_recording.gif
</code></pre></div></div>

<h2 id="convert-to-an-animated-webp-usingffmpeg">Convert to an animated WebP using&nbsp;FFmpeg</h2>

<h3 id="convert-a-whole-video-to-animatedwebp">Convert a whole video to animated&nbsp;WebP</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting an entire video to an animated WebP. You can use options like FPS, output width, and quality to determine the file size and quality of your output:</p>

<div><div><pre><code>ffmpeg -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v $OUTPUT_QUALITY -loop $NUMER_OF_LOOPS \
-preset picture -an -vsync 0 $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $OUTPUT_QUALITY - quality of the WebP output. Start with `50`.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated WebP.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v 50 -loop 0 \
-preset picture -an -vsync 0 sample_recording.webp
</code></pre></div></div>

<h3 id="convert-part-of-a-video-to-animatedwebp">Convert part of a video to animated&nbsp;WebP</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting part of a video to an animated WebP:</p>

<div><div><pre><code>ffmpeg -ss $INPUT_START_TIME -t $LENGTH -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v $OUTPUT_QUALITY -loop $NUMER_OF_LOOPS \
-preset picture -an -vsync 0 $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_START_TIME - number of seconds in the input video to start from.
# * $LENGTH - number of seconds to convert from the input video.
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $OUTPUT_QUALITY - quality of the WebP output. Start with `50`.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated WebP.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -ss 32.5 -t 7 -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v 50 -loop 0 \
-preset picture -an -vsync 0 sample_recording.webp
</code></pre></div></div>

<h2 id="when-should-i-use-an-animated-gif-versus-an-animatedwebp">When should I use an animated GIF versus an animated&nbsp;WebP?</h2>

<p>This depends on the quality, size, and support you want for your output. Modern browsers have support for animated WebP and the quality tends to be higher, but the processing power required is also higher.</p>

<h2 id="next-steps">Next steps</h2>

<p>This guide serves as a brief introduction to using FFmpeg to create an animated GIF or animated WebP from a video, but there is so much more you can do with the tool. There are also many options that FFmpeg supports for these formats that are not covered.</p>

<p>You can also get the code for all the commands and examples in one place by <a href="https://gist.github.com/devadvance/f2ad3cfe38afe3eeef64c72c46692158" target="_blank" rel="noopener">visiting the GitHub Gist here</a>.</p>


      </div>
    </div>
  </article></div>]]>
            </description>
            <link>https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296315</guid>
            <pubDate>Sun, 28 Feb 2021 19:35:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Vertical Farming the Solution to Feeding the Growing Population?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26296308">thread link</a>) | @scottbucks
<br/>
February 28, 2021 | https://www.thedetechtor.com/post/vertical-farms-future-agriculture | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/vertical-farms-future-agriculture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.22.8"><div dir="ltr"><div><div id="viewer-126s3"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img ariahidden="true" data-pin-url="https://www.thedetechtor.com/post/vertical-farms-future-agriculture" data-pin-media="https://static.wixstatic.com/media/f361a8_7fa85f9076e54a028d2287c03127040d~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.jpg" src="https://static.wixstatic.com/media/f361a8_7fa85f9076e54a028d2287c03127040d~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div><p><span dir="auto">Photo by ThisIsEngineering from Pexels</span></p></div></div></div><p id="viewer-amb3s"><span>With the World population set to reach 9.8 billion in 2050 according to the United Nations and thanks to ever-changing climate conditions already reducing the amount of fertile land, we need to start finding more sustainable farming solutions to help feed the growing population. Thankfully Vertical Farming, one of the latest trend in agriculture could be one of those solutions. </span></p><h2 id="viewer-6rcsk"><span>What is Vertical Farming?</span></h2><p id="viewer-5a0n9"><span>Vertical Farming is the practice of growing crops in vertically stacked layers indoors, aimed to optimise plant growth and often incorporate soilless farming techniques such as hydroponics. With climate change and weather took out of the equation, and thanks to state-of-the-art technologies, such as specialised LED lights, Vertical Farms can produce consistent, high quality and quantity yields year-round all with minimal waste and lower CO2 emissions compare to traditional farming methods.</span></p><h2 id="viewer-bg3pc"><span>Can it Replace Traditional Farming?</span></h2><p id="viewer-2g7ir"><span>The aim of indoor Vertical Farming is to produce more crops whilst using less space thanks to a controlled environment. As with any innovation, it has its benefits and drawbacks.</span></p><h3 id="viewer-1tr5h"><span>Benefits </span></h3><p id="viewer-cehnr"><span><strong>Reliability:</strong> because crops aren't dependent on the weather or climate change, there is no such thing as a "seasonal crop" because it's all done in a protected, well-monitored and managed environment. This means it can be done automatically, bringing assurance and peace of mind for growers.</span></p><div id="viewer-17leb"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img ariahidden="true" data-pin-url="https://www.thedetechtor.com/post/vertical-farms-future-agriculture" data-pin-media="https://static.wixstatic.com/media/f361a8_90ea461e3b5645e390ed0b8f54cc8390~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.jpg" src="https://static.wixstatic.com/media/f361a8_90ea461e3b5645e390ed0b8f54cc8390~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div><p><span dir="auto">Photo by ThisIsEngineering from Pexels</span></p></div></div></div><p id="viewer-3i9v4"><span><strong>Optimal use of space: </strong>because their stacking grow systems allow them to expand upwards, it‚Äôs  possible to achieve higher productivity on a small land area, making them perfect for cities.</span></p><p id="viewer-81g5d"><span><strong>Less water: </strong>the Hydroponic growing process only uses about 10% of water compared to traditional methods. Furthermore the water is clean after usage, allowing it to be recycled and reused, reducing costs and waste.</span></p><p id="viewer-6mgoc"><span><strong>Chemicals/Pesticides are gone:</strong> seeing as the farms are indoors, pests cannot enter the controlled environment to cause crop damage and because humidity levels are monitored, fungal diseases struggle to develop, making crops healthier and safer!</span></p><p id="viewer-fa8oo"><span><strong>Transport costs: </strong>because vertical farms can be put in place closer to towns, the crops don't have to travel as far to reach supermarkets, reducing transportation costs and carbon  emissions.</span></p><h3 id="viewer-biafa"><span>Drawbacks</span></h3><p id="viewer-fbico"><span><strong>Less pollination:</strong> although there are many benefits to having crops in a controlled, indoor environment, it does however completely hinder the pollination process, meaning cultivators will have to consider manual pollination, often know for being intensive and extravagant.</span></p><div id="viewer-24sf5"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="A bee pollinating flowers"><p><img ariahidden="true" data-pin-url="https://www.thedetechtor.com/post/vertical-farms-future-agriculture" data-pin-media="https://static.wixstatic.com/media/nsplsh_66304f4c3031494862434d~mv2_d_5184_3413_s_4_2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.jpg" src="https://static.wixstatic.com/media/nsplsh_66304f4c3031494862434d~mv2_d_5184_3413_s_4_2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="A bee pollinating flowers"></p></div><p><span dir="auto">Image by Jenna Lee on Unsplash </span></p></div></div></div><p id="viewer-f658i"><span><strong>Disrupting the community: </strong>vertical farming can disrupt entire communities that are dependent on agriculture. Given the many benefits it comes with, Vertical farming can easily make conventional farming obsolete and dated. So, families who are currently living below the poverty line or are currently on the poverty line are likely to suffer the most from this mode.</span></p><p id="viewer-1baru"><span><strong>Costs: </strong>Building vertical farms in expensive cities will increase total investment and operating costs. Moreover, approving the construction of vertical farms may increase the cost of occupation due to additional need. These farms also demand a lot of energy, because of the artificial light being used.</span></p><h2 id="viewer-fgb70"><span>Vertical Farm Projects </span></h2><p id="viewer-5no0u"><span>Because of their growing popularity, more and more vertical farms are starting to appear, here a 2 of the biggest in the world:</span></p><h3 id="viewer-fp4b7"><span>AeroFarms</span></h3><p id="viewer-bedh5"><span>AeroFarms is one of the most acclaimed vertical farming companies, recording more than $130m in investments since its launch in 2004.</span></p><p id="viewer-4rgr2"><span>The farmer uses its own patented aeroponic technology, which provides higher levels of precision and productivity, with little environmental impact and minor risk.</span></p><p id="viewer-e9oic"><span>Based in New Jersey, US, AeroFarms claims its methods use 95% less water than standard arable farming.</span></p><h3 id="viewer-8cfte"><span>Bowery Farming</span></h3><p id="viewer-80u5"><span>Launched in 2015, Bowery is one of the fastest-growing start-ups in the sector, having raked in more than $140m worth of funding.</span></p><p id="viewer-8qtq6"><span>The New York-headquartered company, which supplies several restaurants, uses zero pesticides and non-genetically modified seeds in its operations.</span></p><p id="viewer-83iu1"><span>Bowery Farming claims its methods use 95% less water than traditional agriculture and are 100 times more productive on the same amount of land.</span></p><h2 id="viewer-euv3j"><span>Bottom Line</span></h2><p id="viewer-8ai5g"><span>The bottom line is that vertical farms are without a doubt an incredible technological innovation with amazing potential. Although they promise some amazing advantages over traditional farming, there are still a few drawbacks that will need to be ironed out for them to become the future of agriculture.</span></p><h3 id="viewer-3l8sg"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-9i96k"><p><a href="https://www.thedetechtor.com/post/first-hyperloop-passenger-test" target="_blank" rel="noopener"><u><strong>üöÑ The First Hyperloop Passenger Test Has Been Completed, What's Next?</strong></u></a></p></li><li id="viewer-124da"><p><strong>üè≠ </strong><a href="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" target="_blank" rel="noopener"><strong><u>Carbon Capture, Usage and Storage: The Solution to the Climate Crisis?</u></strong></a></p></li><li id="viewer-67avi"><p><a href="https://www.thedetechtor.com/post/microalgae-facade-renewable-bioenergy-heat" target="_blank" rel="noopener"><strong>üèô <u>Microalgae Facade, Producing Renewable Bioenergy and Heat</u></strong></a></p></li></ul><h3 id="viewer-1bi9"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-4psdp"><p>üì© Want the latest on the impact of tech? <a href="https://www.thedetechtor.com/subscribe" target="_blank" rel="noopener"><strong><u>Subscribe</u></strong></a> to our <a href="https://www.thedetechtor.com/subscribe" target="_blank" rel="noopener"><strong><u>newsletter</u></strong></a>!</p></li><li id="viewer-8r3rt"><p>üéô <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is available on all podcast players!  <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-dr7r4"><p>üì≤ Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/vertical-farms-future-agriculture</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296308</guid>
            <pubDate>Sun, 28 Feb 2021 19:34:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scott Spence: How to Monetize Blog with Bat and Coil]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26296296">thread link</a>) | @tomaszs
<br/>
February 28, 2021 | https://scottspence.com/2020/09/02/how-to-monetise-your-content/ | <a href="https://web.archive.org/web/*/https://scottspence.com/2020/09/02/how-to-monetise-your-content/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section></section><section><small><a href="https://scottspence.com/tags/learning">learning</a></small><small><a href="https://scottspence.com/tags/guide">guide</a></small></section><p>I recently started monetising my blog, (don‚Äôt worry there‚Äôs no
paywall!) this isn‚Äôt a new thing as I originally did something similar
with Brave and the Basic Attention Token (BAT) back in 2018 on
scottspence.me.</p><p>So what is web monetisation? It‚Äôs an alternative approach to payments
that doesn‚Äôt rely on advertising or stealing your data and selling it
on.</p><p>This time around I‚Äôve re-enlisted the Brave BAT for <a href="https://scottspence.com/" target="_blank" rel="noopener">scottspence.com</a>
but also started using <a href="https://coil.com/" target="_blank" rel="noopener">Coil</a>, Coil was announced on the Dev.to
community <a href="https://dev.to/devteam/dev-is-now-web-monetized-21db" target="_blank" rel="noopener">back in June</a> as a way of streaming micropayments to the
creator of the contents you‚Äôre consuming.</p><p>Coil is a paid service (~¬£4.17 a month) that allows you to access web
monetised content. ‚ÄúSo you said there was no paywall yo!?‚Äù There isn‚Äôt
but there can be, this can be for Coil exclusive content and other
services like accessing the entire <a href="https://cinnamon.video/" target="_blank" rel="noopener">Cinnamon</a> video library.</p><p>There‚Äôs also <a href="https://imgur.com/emerald" target="_blank" rel="noopener">imgur Emerald</a> and a Twitch Coil Twitch Bot that pays
the content creator as you watch, this is as long as you (the watcher)
have a Coil membership and the Coil extension installed on your
browser.</p><h2 id="wait-its-monetization-not-monetisation"><a href="#wait-its-monetization-not-monetisation" aria-label="wait its monetization not monetisation permalink"></a>Wait it‚Äôs Monetization not Monetisation</h2><p>I‚Äôll use the american spelling when referring to a location of a
setting on a site or the actual <code>monetization</code> tag name.</p><p>All other times I mention it I‚Äôll be using the usual UK <a href="https://dictionary.cambridge.org/dictionary/english/monetization" target="_blank" rel="noopener">spelling</a> for
it.</p><h2 id="what-you-need"><a href="#what-you-need" aria-label="what you need permalink"></a>What you need</h2><p>If you‚Äôre a content creator and you want to monetise your content,
like your site, your YouTube videos or your Twitch streams you‚Äôll need
a few things.</p><h2 id="1-set-up-a-web-monetised-wallet"><a href="#1-set-up-a-web-monetised-wallet" aria-label="1 set up a web monetised wallet permalink"></a>1. Set up a web monetised wallet</h2><p>You‚Äôll need a web monetised wallet that supports web monetisation,
although there are wallets that support the <a href="https://interledger.org/setup-wallets.html" target="_blank" rel="noopener">Interledger Protocol</a>
(ILP) it only appears that <a href="https://uphold.com/" target="_blank" rel="noopener">Uphold</a> and <a href="https://gatehub.net/" target="_blank" rel="noopener">GateHub</a> support web
monetisation.</p><p>I had a Uphold account since I set up the Brave BAT back in 2018 so
there was noting for me to do there.</p><h2 id="2-get-your-payment-pointer"><a href="#2-get-your-payment-pointer" aria-label="2 get your payment pointer permalink"></a>2. Get your payment pointer</h2><p>Now that I have a web monetised wallet I need to get the payment
pointer. In Uphold you do this by clicking on the currency you want to
receive your web monetisation in. In my case GBP, on the GPB card
there‚Äôs three options, Use Funds, Add Funds and Activity.</p><p>Clicking Add Funds take you to the various ways you can add funds, one
option is to fund ‚Äòfrom Interledger Payment Pointer‚Äô, there‚Äôs an
option to generate a payment pointer. As I had already created one I
could copy pasta that for later, my pointer looks like this:
<code>$ilp.uphold.com/bzPBWkMBzLmN</code></p><h2 id="3-create-your-monetization-meta-tag"><a href="#3-create-your-monetization-meta-tag" aria-label="3 create your monetization meta tag permalink"></a>3. Create your <code>monetization</code> meta tag</h2><p>Time to get the payment pointer into a <code>monetization</code>, <code>&lt;meta&gt;</code> tag.</p><p>The tag‚Äôs name is always <code>monetization</code>. The content is your payment
pointer. My example <code>meta</code> tag here:</p><div><div data-language="html"><pre data-linenumber="true"><p><span>1</span><span>&lt;</span><span>meta</span><span> </span><span>name</span><span>=</span><span>"</span><span>monetization</span><span>"</span><span> </span><span>content</span><span>=</span><span>"</span><span>$ilp.uphold.com/bzPBWkMBzLmN</span><span>"</span><span> </span><span>/&gt;</span></p></pre></div></div><h2 id="4-add-the-meta-tag-to-your-site"><a href="#4-add-the-meta-tag-to-your-site" aria-label="4 add the meta tag to your site permalink"></a>4. Add the meta tag to your site</h2><p>Now I can add the meta tag to my site, I use Gatsby and of course
‚Äù<a href="https://github.com/Daudr/gatsby-plugin-web-monetization" target="_blank" rel="noopener">there‚Äôs a plugin for that</a>‚Äù but I‚Äôve gone with adding the tag to the
head of my site with React Helmet.</p><p>I have <a href="https://github.com/spences10/scottspence.com/blob/production/src/root-wrapper.js#L75" target="_blank" rel="noopener">top level module</a> that wraps my whole site so I‚Äôm going to
slot my <code>monetization</code>, <code>meta</code> tag in there.</p><h2 id="brave-rewards"><a href="#brave-rewards" aria-label="brave rewards permalink"></a>Brave Rewards</h2><p>Brave rewards I‚Äôve amassed a total of 0.95 BAT since I implemented the
BAT on scottspence.me in 2018, I used the same approach to add the BAT
for <a href="https://scottspence.com/" target="_blank" rel="noopener">scottspence.com</a>.</p><p>To create a BAT I logged in to the <a href="https://publishers.basicattentiontoken.org/" target="_blank" rel="noopener">Brave Rewards</a> admin panel, I
don‚Äôt recall the sign-up process but do know there‚Äôs not a password
username system but a magic email link sent to you each time you want
to use it.</p><p>From the panel I can use ‚ÄòAdd Channel‚Äô to add a website, YouTube
channel, Twitch channel, Twitter account, Vimeo channel, Reddit and a
GitHub</p><p>In my case I‚Äôm adding a website where I‚Äôm asked to choose one of two
verification methods, add a trusted file to your site or add a DNS
record, I go with the trusted file.</p><p>I‚Äôm them prompted to add the file <code>brave-payments-verification.txt</code>
and it‚Äôs contents to a <code>.well-known</code> folder, I have this in the root
of my project and copy it into the <code>public</code> folder of my site as the
last build step, here‚Äôs the <code>package.json</code> script:</p><div><div data-language="json"><pre data-linenumber="true"><p><span>1</span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"build"</span><span>:</span><span> </span><span>"gatsby build &amp;&amp; yarn wellknown"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>"wellknown"</span><span>:</span><span> </span><span>"cp -r .well-known/ public/"</span><span></span></p><p><span>4</span><span></span><span>}</span></p></pre></div></div><h2 id="coil-account"><a href="#coil-account" aria-label="coil account permalink"></a>Coil account</h2><p>You don‚Äôt have to have a Coil account to benefit from web
monetisation.</p><h2 id="devto-are-using-web-monetisation-too"><a href="#devto-are-using-web-monetisation-too" aria-label="devto are using web monetisation too permalink"></a>Dev.to are using web monetisation too</h2><p>Like I mentioned earlier, Dev.to are now web monetised but it looks
like the <code>monetization</code> tag on Dev.to is their own tag whilst they
test the viability of it before letting authors to set their own
pointers.</p><p>Here‚Äôs the source comments from one of my Dev.to posts, notice the
pointer is different:</p><div><div data-language="html"><pre data-linenumber="true"><p><span>1</span><span></span></p><p><span>2</span><span></span><span></span></p><p><span>3</span><span></span><span></span></p><p><span>4</span><span></span><span></span></p><p><span>5</span><span></span><span></span></p><p><span>6</span><span></span><span>&lt;</span><span>meta</span><span> </span><span>name</span><span>=</span><span>"</span><span>monetization</span><span>"</span><span> </span><span>content</span><span>=</span><span>"</span><span>$ilp.uphold.com/24HhrUGG7ekn</span><span>"</span><span> </span><span>/&gt;</span></p></pre></div></div><p>To set up your Dev.to posts to be web monetised you can add your
payment pointer in the <a href="https://dev.to/settings/misc" target="_blank" rel="noopener">settings</a> panel under ‚ÄòWeb Monetization‚Äô.</p><h2 id="resources"><a href="#resources" aria-label="resources permalink"></a>Resources</h2><a href="#top-of-page" aria-label="back to top navigation"><p>Back to Top</p></a></article><div><p><span role="img" aria-label="sparkles">‚ú® ‚ú® ‚ú® ‚ú® ‚ú® ‚ú® ‚ú®</span></p><p>Want to keep up to date with what I'm working on?</p><p>Important dev related content, directly to your inbox (for free).</p><p><span role="img" aria-label="sparkles">‚ú® ‚ú® ‚ú® ‚ú® ‚ú® ‚ú® ‚ú®</span><span>Newsletter signup...</span></p></div></div>]]>
            </description>
            <link>https://scottspence.com/2020/09/02/how-to-monetise-your-content/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296296</guid>
            <pubDate>Sun, 28 Feb 2021 19:32:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Minimal Browser]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26296082">thread link</a>) | @autoditype
<br/>
February 28, 2021 | https://manuelmoreale.com/a-minimal-browser | <a href="https://web.archive.org/web/*/https://manuelmoreale.com/a-minimal-browser">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><a href="https://manuelmoreale.com/"></a><p>As a web developer I have a love &amp; hate relationship with browsers. On one side, I need them to function properly in order to do my job, on the other I want them to be as minimal as possible. At the same time I‚Äôm trying to spend less and more meaningful time on the browser which is why I decided to minimize it. I‚Äôm on a Mac and I decided to use Safari as my primary browser. Now, before you start screaming at the screen, I know what you‚Äôre thinking: Safari is awful. And I don‚Äôt disagree with that. Being awful is a plus. I don‚Äôt want to be comfortable, I want my browser to behave badly which is why Safari, with all its weird and stupid bugs is perfect. My safari looks like this:</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1-1216x-q70.jpg 1216w"></p></div><figcaption>pretty minimal...</figcaption></figure>
<p>Here‚Äôs how the taskbar is set up if you‚Äôre curious and want to do it yourself.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2-1216x-q70.jpg 1216w"></p></div><figcaption>GTFO icons!</figcaption></figure>
<p>As you can see, I removed pretty much everything. Only thing left is the search bar at the center. I can use gestures and the keyboard to navigate through tabs and go back and forth through the history so I don‚Äôt need any button at the top. I‚Äôm also trying to have as fewer tabs open as possible. This is something that‚Äôs part of my commitment to be digitally minimal.</p>
<h2>Few extra settings</h2>
<p>In addition to the minimal taskbar, there are a couple of extra steps I took in order to have a more minimalist browser.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3-1216x-q70.jpg 1216w"></p></div></figure>
<p>Both new windows and tabs open on a blank page. That‚Äôs because I don‚Äôt want to get distracted by icons. If I open the browser I want to stay focused on the current task and not browse mindlessly.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4-1216x-q70.jpg 1216w"></p></div></figure>
<p>I‚Äôm also loading a custom css file, which I use to hide stuff from websites I use somewhat regularly. It‚Äôs used primarily to hide parts of the sites, change the typography or the colors. Nothing super crazy but definitely helpful.</p>
<h2>What about the other browsers</h2>
<p>A yes, the other browsers. We‚Äôre talking about Firefox and Chrome right?  Chrome is my dev browser because Safari‚Äôs webtools are frankly a pile of hot garbage. My Chrome looks like this:</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1-1216x-q70.jpg 1216w"></p></div></figure>
<p>The new tab is a custom extension I coded months ago. <a href="https://chrome.google.com/webstore/detail/minimal-new-page/danoojfpckpaacgbaebfakjeepeenaop" rel="noopener noreferrer" target="_blank">It‚Äôs available for free on the Chrome App store</a> or whatever is called. You can‚Äôt really remove many things from Chrome. All the extensions are hidden, home icon is obviously gone but other than that it looks pretty much like a normal Chrome installation.</p>
<p>Firefox is a bit more interesting. I don‚Äôt use Firefox a lot to be honest with you even though has got much better lately and I quite like it as a browser. Still, if it‚Äôs your primary browser and you want to minimize it, this is what you can do. My Firefox looks like this:</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1-1216x-q70.jpg 1216w"></p></div></figure>
<p>As you can see, almost everything is gone from the sidebar. Only things you can‚Äôt remove are the two arrows but I moved one of the two on the opposite side in order to have a less busy left corner. Only other thing left is the search bar.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2-1216x-q70.jpg 1216w"></p></div></figure>
<p>I‚Äôm also using the dark color scheme. You can change the theme down at the bottom of the customization page.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3-1216x-q70.jpg 1216w"></p></div></figure>
<p>As for the settings, like I did for Safari, an empty page is shown every time I open a new tab or window. This is super helpful to cut down distractions.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4-1216x-q70.jpg 1216w"></p></div></figure>
<p>Another thing you can do is turn off those obnoxious notifications requests. To do that you need to go in the Privacy &amp; Security section inside the settings and click on the Settings... button next to Notifications.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5-1216x-q70.jpg 1216w"></p></div></figure>
<p>Then, at the bottom of the new window, you‚Äôll find a checkbox to disable all new requests. Toggle that and you‚Äôll be good to go. This is something you can do in Safari as well btw. You can find the same option under Settings &gt; Websites &gt; Notifications.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6-1216x-q70.jpg 1216w"></p></div></figure>
<p>And that‚Äôs it. Enjoy your simpler browser. And let me know if you think there‚Äôs something else that could be done to improve the browsing experience.</p></div></div>]]>
            </description>
            <link>https://manuelmoreale.com/a-minimal-browser</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296082</guid>
            <pubDate>Sun, 28 Feb 2021 19:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Troubleshooting a Stuck Process]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26296039">thread link</a>) | @JoshMcguigan
<br/>
February 28, 2021 | https://www.joshmcguigan.com/blog/troubleshooting-stuck-process/ | <a href="https://web.archive.org/web/*/https://www.joshmcguigan.com/blog/troubleshooting-stuck-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I was recently troubleshooting an issue where a process seemed to be stuck, not making any progress. Eventually I was able to track down the problem, but along the way I found a few quick ways to start gathering information about a running process.</p>
<p>These tips apply only to Linux systems. I‚Äôm sure other operating systems have similar tools, but I am not familiar with them so I won‚Äôt mention them here.</p>
<p>I use <code>sleep</code> as an example program to ‚Äútroubleshoot‚Äù throughout this article. You will probably want to replace <code>sleep</code> in my examples below with something more interesting.</p>
<h2>strace</h2>
<p>strace prints out the system calls made by a particular process. One option when using strace is to start the program from within strace:</p>
<div data-language="bash"><pre><code>
$ <span>strace</span> <span>sleep</span> <span>10</span>

execve<span>(</span><span>"/usr/bin/sleep"</span>, <span>[</span><span>"sleep"</span>, <span>"10"</span><span>]</span>, 0x7ffc0b292728 /* <span>54</span> vars */<span>)</span> <span>=</span> <span>0</span>
<span>..</span>.
clock_nanosleep<span>(</span>CLOCK_REALTIME, <span>0</span>, <span>{</span>tv_sec<span>=</span><span>10</span>, <span>tv_nsec</span><span>=</span><span>0</span><span>}</span>, 0x7ffd8fa9ef30<span>)</span> <span>=</span> <span>0</span>
<span>..</span>.</code></pre></div>
<p>strace has lots of output so I removed most of it, but watching the output live you can see which system call your process is getting stalled on. In this case it is <code>clock_nanosleep</code>.</p>
<p>Sometimes you realize you want to see what a process is doing after the process has already started - in that case you can use strace to attach to an existing process by PID:</p>
<div data-language="bash"><pre><code>
$ <span>sleep</span> <span>10</span> <span>&amp;</span>

$ pgrep <span>sleep</span> <span>|</span> <span>xargs</span> -n1 <span>sudo</span> <span>strace</span> -p </code></pre></div>
<p>Here we use <code>pgrep</code> to get the process ID of the <code>sleep</code> process, then use strace to attach to that process. Be aware that <code>pgrep</code> uses a regular expression to match the process name, so you might want to use <code>pgrep ^sleep$</code> or <code>pidof sleep</code> for stricter matching. </p>
<p>The downside to attaching strace to a running application is that if the process has already called into a blocking system call, as is likely the case here with sleep, you won‚Äôt see anything with strace until that system call returns and a next system call is invoked.</p>
<h2>procfs kernel stack</h2>
<p>If you use strace to attach to a running process and find it stalled on a blocking syscall (so strace is not providing any output), you can use procfs to determine the currently running syscall, as well as the full kernel stack trace.</p>
<div data-language="bash"><pre><code>
$ <span>sleep</span> <span>10</span> <span>&amp;</span>

$ pgrep <span>sleep</span> <span>|</span> <span>xargs</span> -I % <span>sudo</span> <span>cat</span> /proc/%/stack
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> hrtimer_nanosleep+0xca/0x1a0
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> common_nsleep+0x40/0x50
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> __x64_sys_clock_nanosleep+0xd1/0x140
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> do_syscall_64+0x33/0x40
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> entry_SYSCALL_64_after_hwframe+0x44/0xa9</code></pre></div>
<p>Here again we can see we are stuck in the <code>clock_nanosleep</code> system call, but this time we are able to figure it out while the process is blocked on the system call, whereas with strace we would have had to start tracing <em>before</em> the process calls the blocking system call.</p>
<h2>userspace trace</h2>
<p>Now you might want to know where in the application code the syscall was called from. Or an alternate case would be that you find the application isn‚Äôt stuck in kernel space but rather is stuck executing application code.</p>
<p>You can use <code>gdb</code> to see the current userspace stack trace.</p>
<div data-language="bash"><pre><code>
$ <span>sleep</span> <span>10</span> <span>&amp;</span>

$ pgrep <span>sleep</span> <span>|</span> <span>xargs</span> -n1 <span>sudo</span> gdb --batch -ex <span>"thread apply all bt"</span> -p
0x00007f8b1b29f0da <span>in</span> clock_nanosleep@GLIBC_2.2.5 <span>(</span><span>)</span> from /usr/lib/libc.so.6

Thread <span>1</span> <span>(</span>process <span>132170</span> <span>"sleep"</span><span>)</span>:







<span>[</span>Inferior <span>1</span> <span>(</span>process <span>132170</span><span>)</span> detached<span>]</span></code></pre></div>
<p>The usefulness of this information depends on the existence of debug symbols, so you may not get much out of it unless you can re-compile the application with debug symbols included.</p>
<div data-language="bash"><pre><code>$ pgrep rust-analyzer <span>|</span> <span>xargs</span> -n1 <span>sudo</span> gdb --batch -ex <span>"thread apply all bt"</span> -p



Thread <span>1</span> <span>(</span>LWP <span>113543</span> <span>"rust-analyzer"</span><span>)</span>:

















</code></pre></div>
<p>This demonstrates what the output might look like for an appication compiled with debug symbols.</p>
<h2>Conclusion</h2>
<p>These tools probably aren‚Äôt enough to immediately root cause an issue, but they are a great way to gather some initial information which can help guide further troubleshooting effort.</p></div></div>]]>
            </description>
            <link>https://www.joshmcguigan.com/blog/troubleshooting-stuck-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296039</guid>
            <pubDate>Sun, 28 Feb 2021 19:03:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Perl Saved the Human Genome Project (1996)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26296030">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html | <a href="https://web.archive.org/web/*/https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<hr>

<!-- the article goes here -->


<h4><i>Lincoln D. Stein</i></h4>

<!-- packages described, if necessary -->


<tt>
<b>DATE:</b> Early February, 1996
<br> 
LOCATION: Cambridge, England, in the conference room of the largest DNA sequencing center in Europe.
<br> 
<b>OCCASION:</b> A high level meeting between the computer scientists of this center and the largest DNA sequencing center in the United States. 
<br>
<b>THE PROBLEM:</b> Although the two centers use almost identical laboratory techniques, almost identical databases, and almost identical data analysis tools, they still can't interchange data or meaningfully compare results.
<br><b>THE SOLUTION:</b> Perl. 
</tt>
<p>
The human genome project was inaugurated at the beginning of the decade as an ambitious international effort to determine the complete DNA sequence of human beings and several experimental animals. The justification for this undertaking is both scientific and medical. By understanding the genetic makeup of an organism in excruciating detail, it is hoped that we will be better able to understand how organisms develop from single eggs into complex multicellular beings, how food is metabolized and transformed into the constituents of the body, how the nervous system assembles itself into a smoothly functioning ensemble. From the medical point of view, the wealth of knowledge that will come from knowing the complete DNA sequence will greatly accelerate the process of finding the causes of (and potential cures for) human diseases.
</p><p> 
Six years after its birth, the genome project is ahead of schedule. Detailed maps of the human and all the experimental animals have been completed (mapping out the DNA using a series of landmarks is an obligatory first step before determining the complete DNA sequence). The sequence of the smallest model organism, yeast, is nearly completed, and the sequence of the next smallest, a tiny soil-dwelling worm, isn't far behind. Large scale sequencing efforts for human DNA started at several centers a number of months ago and will be in full swing within the year.
</p><p> 
The scale of the human DNA sequencing project is enough to send your average UNIX system administrator running for cover. From the information-handling point of view, DNA is a very long string consisting of the four letters G, A, T and C (the letters are abbreviations for the four chemical units that form the "rungs" of the DNA double helix ladder). The goal of the project is to determine the order of letters in the string. The size of the string is impressive but not particularly mind-boggling: 3 x 109 letters long, or some 3 gigabytes of storage space if you use 1 byte to store each letter with no compression techniques.</p><p> 
Three gigabytes is substantial but certainly manageable by today's standards. Unfortunately, this is only what's required to store the finished data. The storage requirements for the experimental data needed to determine this sequence is far more vast. The essential problem is that DNA sequencing technology is currently limited to reading stretches of at most 500 contiguous letters. In order to determine sequences longer than that, the DNA must be sequenced as small overlapping fragments called "reads" and the jigsaw puzzle reassembled by algorithms that look for areas where the sequences match. Because the DNA sequence is nonrandom (similar but not-entirely-identical motifs appear many times throughout the genome), and because DNA sequencing technology is noisy and error-prone, one ends up having to sequence each region of DNA five to ten times in order to reliably assemble the reads into the true sequence. This increases the amount of data to manage by an order of magnitude. On top of this is all the associated information that goes along with laboratory work: who performed the experiment, when it was performed, the section of the genome that was sequenced, the identity and version of the software used to assemble the sequence, any comments someone wants to attach to the experiment, and so forth. In addition, one generally wants to store the raw output from the machine that performs the sequencing. Each 500 letters of sequence generates a data file that's 20-30 kilobytes long!
</p><p> 
That's not the whole of it. It's not enough just to determine the sequence of the DNA. Within the sequence are functional areas scattered among long stretches of nonfunctional areas. There are genes, control regions, structural regions, and even a few viruses that got entangled in human DNA long ago and persist as fossilized remnants. Because the genes and control regions are responsible for health and disease, one wants to identify and mark them as the DNA sequence is assembled. This type of annotation generates yet more data.
</p><p> 
Altogether, people estimate that some one to ten terabytes of information will need to be stored in order to see the human genome project to its conclusion. 
</p><p>
So what's Perl got to do with it? From the beginning, researchers realized that informatics would have to play a large role in the genome project. An informatics core formed an integral part of every genome center that was created. The mission of these cores was two-fold: to provide computer support and databasing services for their affiliated laboratories, and to develop data analysis and management software for use by the genome community as a whole. 
</p><p>
It's fair to say that the initial results of the informatics groups efforts were mixed. Things were slightly better on the laboratory management side of the coin. Some groups attempted to build large monolithic systems on top of complex relational databases; they were thwarted time and again by the highly dynamic nature of biological research. By the time a system that could deal with the ins and outs of a complex laboratory protocol had been designed, implemented and debugged, the protocol had been superseded by new technology and the software engineers had to go back to the drawing board.
</p><p> 
Most groups, however, learned to build modular, loosely-coupled systems whose parts could be swapped in and out without retooling the whole system. In my group, for example, we discovered that many data analysis tasks involve a sequence of semi-independent steps. Consider the steps that one may want to perform on a bit of DNA that has just been sequenced. First there's a basic quality check on the sequence: is it long enough? Are the number of ambiguous letters below the maximum limit? Then there's the "vector check." For technical reasons, the human DNA must be passed through a bacterium before it can be sequenced (this is the process of "cloning"). Not infrequently, the human DNA gets lost somewhere in the process and the sequence that's read consists entirely of the bacterial vector. The vector check ensures that only human DNA gets into the database. Next there's a check for repetitive sequences. Human DNA is full of repetitive elements that make fitting the sequencing jigsaw puzzle together challenging. The repetitive sequence check tries to match the new sequence against a library of known repetitive elements. A penultimate step is to attempt to match the new sequence against other sequences in a large community database of DNA sequences. Often a match at this point will provide a clue to the function of the new DNA sequence. After performing all these checks, the sequence along with the information that's been gathered about it along the way is loaded into the local laboratory database.
</p><p> 
The process of passing a DNA sequence through these independent analytic steps looks kind of like a pipeline, and it didn't take us long to realize that a UNIX pipe could handle the job. We developed a simple Perl-based data exchange format called <i><i>boulderio</i></i> that allowed loosely coupled programs to add information to a pipe-based I/O stream. <i><i>boulderio</i></i> is based on tag/value pairs. A Perl module makes it easy for programs to reach into the input stream, pull out only the tags they're interested in, do something with them, and drop new tags into output the stream. Any tags that the program isn't interested in are just passed through to standard output so that other programs in the pipeline can get to them.
</p><p> 
Using this type of scheme, the process of analyzing a new DNA sequence looks something like this (this is not exactly the set of scripts that we use, but it's close enough):

</p><pre>name_sequence.pl &lt; new.DNA |
quality_check.pl | 
vector_check.pl |
find_repeats.pl |
search_big_database.pl |
load_lab_database.pl
</pre>
<p>
A file containing the new DNA sequence is processed by a Perl script named <tt>name_sequence.pl</tt>, whose only job is to give the sequence a new unique name and to put it into <i><i>boulderio</i></i> format. Its output looks like this:

</p><pre> 
NAME=L26P93.2 
SEQUENCE=GATTTCAGAGTCCCAGATTTCCCCCAGGGGGTTTCCAGAGAGCCC...
</pre>
<p>

The output from name_sequence.pl is next passed to the quality checking program, which looks for the SEQUENCE tag, runs the quality checking algorithm, and writes its conclusion to the data stream. The data stream now looks like this:

 </p><pre>NAME=L26P93.2 
SEQUENCE=GATTTCAGAGTCCCAGATTTCCCCCAGGGGGTTTCCAGAGAGCCC...
QUALITY_CHECK=OK 
</pre>
<p>

Now the data stream enters the vector checker. It pulls the SEQUENCE tag out of the stream and runs the vector checking algorithm. The data stream now looks like this:

</p><pre> 
NAME=L26P93.2 SEQUENCE=GATTTCAGAGTCCCAGATTTCCCCCAGGGGGTTTCCAGAGAGCCC......
QUALITY_CHECK=OK 
VECTOR_CHECK=OK 
VECTOR_START=10 
VECTOR_LENGTH=300 
</pre>
<p>

This continues down the pipeline, until at last the <tt>load_lab_database.pl</tt> script collates all the data, makes some final conclusions about whether the sequence is suitable for further use, and enters all the results into the laboratory database. 
One of the nice features of the <i>boulderio</i> format is that multiple sequence records can be processed sequentially in the same UNIX pipeline. An "=" sign marks the end of one record and the beginning of the next:
	
</p><pre>	 
NAME=L26P93.2 
SEQUENCE=GATTTCAGAGTCCCAGATTTCCCCCAGGGGGTTTCCAGAGAGCCC... 
=
NAME=L26P93.3 
SEQUENCE=CCCCTAGAGAGAGAGAGCCGAGTTCAAAGTCAAAACCCATTCTCTCTC... 
= 
</pre>
<p>

There's also a way to create subrecords ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html">https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html</a></em></p>]]>
            </description>
            <link>https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296030</guid>
            <pubDate>Sun, 28 Feb 2021 19:01:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ to Rust introduction with practical ‚ÄúRaytracing in One Weekend‚Äù project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295969">thread link</a>) | @adamnemecek
<br/>
February 28, 2021 | https://jduchniewicz.com/posts/2021/02/c-to-rust-or-how-to-render-your-mindset/ | <a href="https://web.archive.org/web/*/https://jduchniewicz.com/posts/2021/02/c-to-rust-or-how-to-render-your-mindset/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

<h2 id="introduction">Introduction</h2>

<h4 id="original-chapter-1"><a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html#overview">Original Chapter 1</a></h4>

<h4 id="update-1-03-21">Update 1.03.21</h4>

<p>Thank you wholeheartedly for the support and the comments on this post. Some mistakes were fixed and some things are now better clarified. Also thanks to soruh for the <a href="https://github.com/JDuchniewicz/rustracing/pull/1">optimization PR</a> to the repository. The relevant benchmarks are mentioned there and the code is parallelized with <a href="https://docs.rs/rayon/1.5.0/rayon/">rayon</a>. If you are interested in the discussion take a look <a href="https://www.reddit.com/r/rust/comments/lukgyi/c_to_rust_introduction_with_practical_raytracing/">here</a>.</p>

<p>Every programmer wants to feel loved (yes I am looking at you!), be it by others or yourself. Usually you <em>really</em> love yourself when you accomplish something you are proud of. That is why from time to time programmers tend to learn languages (be it programming or spoken ones - unless you can talk to your fridge in assembly of course) or challenge themselves and write tough and unintelligible pieces of code which do something amazing. If you are like me and were always amazed by how the computer can render something resembling real life instead of just 2D graphics, you came to the right place!</p>

<p>Cutting the slack, I will reimplement the amazing tutorial on <a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html"><em>Ray Tracing in One Weekend</em></a> in the Rust programming language. This post is aimed at people who are interested in the subject of rendering and want to try Rust, or are simply curious about how things are done in this language. I will not go through all content, but only focus on parts which are starkly different from the original implementation. The code for this project is available on this GitHub <a href="https://github.com/JDuchniewicz/rustracin://github.com/JDuchniewicz/rustracing">repo</a>.</p>

<p>We aim to obtain such a render at the end of this tutorial.

    <img src="https://jduchniewicz.com/raytracing/image.png" alt="Rendered image.">

</p>

<p>Although you can just read through the whole thing and see how things are done differently in Rust compared to C++ or C, I recommend reading through the original tutorial and implementing the code yourself! Nevertheless, be prepared to learn a great deal about why and how Rust does some things the other way (the modern one?). Of course, do read <a href="https://doc.rust-lang.org/stable/book/">The Rust Programming Language</a>, in which you can find a comprehensive intro to Rust, or if you prefer less reading and more code look no further than <a href="https://doc.rust-lang.org/stable/rust-by-example/">Rust by example</a>.</p>

<p><strong>DISCLAIMER</strong></p>

<p>This is yet another blog post in the style of <a href="https://transitiontech.ca/random/RIIR">RIIR</a> but with educational aims (don‚Äôt hang me for it, please). The target audience should have some knowledge of programming (especially in C or C++). Assuming you are the target audience, Rust knowledge is not required but as stated before, do read up the official tutorials - this one is for those who want to have a sense of accomplishment and a pretty solid infant renderer.</p>

<p>Views expressed here are my own only‚Ä¶  <em>you know the rest</em>.</p>

<p>I <em>promise</em>, this is the last paragraph that keeps you from writing actual code. I will link relevant paragraphs from the original tutorial so you can see where the code differs so much it was worth me rambling on it.</p>

<h2 id="outputting-an-image">Outputting an image</h2>

<h4 id="original-chapter-2"><a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html#outputanimage">Original Chapter 2</a></h4>

<p>Time to get our hands dirty and code something! Rendering something is most fun if we can actually see the result, so we need to create a function which will save our rendered image into a [ PPM ] image format (probably due to its simplicity).</p>

<p>Each time there is code to compare, I will paste both the C++ code and its Rust counterpart so you can spot the differences. I will only attach some of the images from the original post and instead provide direct links to them.</p>

<p><strong>The C++ code:</strong></p>
<div><pre><code data-lang="cpp"><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span><span></span>
<span>int</span> <span>main</span>() {

    <span>// Image
</span><span></span>
    <span>const</span> <span>int</span> image_width <span>=</span> <span>256</span>;
    <span>const</span> <span>int</span> image_height <span>=</span> <span>256</span>;

    <span>// Render
</span><span></span>
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"P3</span><span>\n</span><span>"</span> <span>&lt;&lt;</span> image_width <span>&lt;&lt;</span> <span>' '</span> <span>&lt;&lt;</span> image_height <span>&lt;&lt;</span> <span>"</span><span>\n</span><span>255</span><span>\n</span><span>"</span>;

    <span>for</span> (<span>int</span> j <span>=</span> image_height<span>-</span><span>1</span>; j <span>&gt;=</span> <span>0</span>; <span>--</span>j) {
        <span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> image_width; <span>++</span>i) {
            <span>auto</span> r <span>=</span> <span>double</span>(i) <span>/</span> (image_width<span>-</span><span>1</span>);
            <span>auto</span> g <span>=</span> <span>double</span>(j) <span>/</span> (image_height<span>-</span><span>1</span>);
            <span>auto</span> b <span>=</span> <span>0.25</span>;

            <span>int</span> ir <span>=</span> <span>static_cast</span><span>&lt;</span><span>int</span><span>&gt;</span>(<span>255.999</span> <span>*</span> r);
            <span>int</span> ig <span>=</span> <span>static_cast</span><span>&lt;</span><span>int</span><span>&gt;</span>(<span>255.999</span> <span>*</span> g);
            <span>int</span> ib <span>=</span> <span>static_cast</span><span>&lt;</span><span>int</span><span>&gt;</span>(<span>255.999</span> <span>*</span> b);

            std<span>::</span>cout <span>&lt;&lt;</span> ir <span>&lt;&lt;</span> <span>' '</span> <span>&lt;&lt;</span> ig <span>&lt;&lt;</span> <span>' '</span> <span>&lt;&lt;</span> ib <span>&lt;&lt;</span> <span>'\n'</span>;
        }
    }
}
</code></pre></div>
<p><strong>Rust:</strong></p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    <span>let</span> image_width <span>=</span> <span>256</span>;
    <span>let</span> image_height <span>=</span> <span>256</span>;

    println<span>!</span>(<span>"p3</span><span>\n</span><span>{} {}</span><span>\n</span><span>255"</span>, image_height, image_width);

    <span>for</span> j <span>in</span> (<span>0</span>..<span>=</span>image_height <span>-</span> <span>1</span>).into_iter().rev() {
        <span>for</span> i <span>in</span> <span>0</span>..image_width {
            <span>let</span> r <span>=</span> i <span>as</span> <span>f64</span> <span>/</span> (image_width <span>-</span> <span>1</span>) <span>as</span> <span>f64</span>;
            <span>let</span> g <span>=</span> j <span>as</span> <span>f64</span> <span>/</span> (image_height <span>-</span> <span>1</span>) <span>as</span> <span>f64</span>;
            <span>let</span> b <span>=</span> <span>0.25</span>;

            <span>let</span> ir <span>=</span> (<span>255.999</span> <span>*</span> r) <span>as</span> <span>i32</span>;
            <span>let</span> ig <span>=</span> (<span>255.999</span> <span>*</span> g) <span>as</span> <span>i32</span>;
            <span>let</span> ib <span>=</span> (<span>255.999</span> <span>*</span> b) <span>as</span> <span>i32</span>;

            println<span>!</span>(<span>"{} {} {}"</span>, ir, ig, ib);
        }
    }
}
</code></pre></div>
<p>This should result in an image looking like <a href="https://raytracing.github.io/images/img-1.01-first-ppm-image.png">this</a> - you can view these images with most viewers as this is quite common image format for ASCII encoded images.</p>

<p>The first stark difference is the <code>for</code> loop - Rust uses syntax similar to Python and supports looping though iterable objects thanks to the <code>Iterator</code> trait (we will get to traits soon enough, for now it is a kind of interface). Looping forwards is easy, as you just specify the range of iteration like this:</p>
<div><pre><code data-lang="rust"><span>for</span> i <span>in</span> <span>1</span>..<span>10</span> {
    println<span>!</span>(<span>"looping: {}"</span>, i);
}
</code></pre></div>
<p>You can also loop in steps similar to the C++ <code>i += 2</code> by using this syntax: <code>for i in (1..10).step_by(2)</code>, but how do you loop backward? I probably spoiled the fun as the answer is visible above, you create an iterator from a range by yet another trait called <code>Into</code> which is a reciprocal of <code>From</code> - in short it allows the programmer to specify legal conversions between types in Rust. So, we take a range of values, convert it into an iterator and call the <code>rev()</code> function on it and <em>voila</em>, we got our reverse loop: <code>for i in (1..10).into_iter().rev()</code>.</p>

<p>Barring from some syntax differences, the program is quite similar to the original version, we use <code>as</code> instead of C-style (<em>unsafe</em>) casts and <code>static_cast&lt;T&gt;</code>s. This cast will of course detect any mismatch at compile time.</p>

<h3 id="building-the-code">Building the code</h3>

<p>You will of course need a way to build the code and run it, and this is a good opportunity to introduce you to the first key selling point of Rust: <a href="https://doc.rust-lang.org/book/ch01-03-hello-cargo.html">Cargo</a>. This is both a build system and a package manage (think like Python‚Äôs <code>pip</code> but with <code>Makefile</code>s on top of it). Forget about annoying <code>CMake</code> or writing <code>Makefile</code>s by hand - finally we have something with an easy-to-read syntax: <a href="https://toml.io/en/">TOML</a>. Cargo, of course allows for creating <em>targets</em> and managing compiler and linker flags but removes all the nitty-gritty details of including files and setting up export options.</p>

<p>In order to create a new project you just need to run <code>cargo new coolprojectname</code> and if you want to build it and run you may run <code>cargo run</code> or <code>cargo build</code> if you want to build it only (and have a brief lesson in Rust compiler messages). For the release builds, just pass the flag <code>--release</code> to the compiler (and be sure to run this project with this command, otherwise be prepared for long trips to kitchen to kill the time while the scene renders).</p>

<h2 id="vec3-helper-class">Vec3 helper class</h2>

<h4 id="original-chapter-3"><a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html#thevec3class">Original Chapter 3</a></h4>

<p>Because we will be using some heavy 3D maths, we will need a helper class capable of performing some operations automatically instead of writing them by hand. This is where our code starts to diverge (rather strongly I would say). The original class relies on standard C++ features such as constructor and operator overloading with a sprinkle of friend functions on top, while Rust has no notion of overloading and instead achieves these things with the power of <em>traits</em> and <em>generics</em> which are also present in C++ albeit wear a cover of <em>templates</em>. I will not go into much detail on the topic of run-time vs compile-time polymorphism, but if you are eager for a read then I leave <a href="https://catonmat.net/cpp-polymorphism">one</a>.</p>

<p><strong>C++:</strong></p>
<div><pre><code data-lang="cpp"><span>#ifndef VEC3_H
</span><span>#define VEC3_H
</span><span></span>
<span>#include</span> <span>&lt;cmath&gt;</span><span>
</span><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span><span></span>
<span>using</span> std<span>::</span>sqrt;

<span>class</span><span> </span><span>vec3</span> {
    <span>public</span><span>:</span>
        vec3() <span>:</span> e{<span>0</span>,<span>0</span>,<span>0</span>} {}
        vec3(<span>double</span> e0, <span>double</span> e1, <span>double</span> e2) <span>:</span> e{e0, e1, e2} {}

        <span>double</span> x() <span>const</span> { <span>return</span> e[<span>0</span>]; }
        <span>double</span> y() <span>const</span> { <span>return</span> e[<span>1</span>]; }
        <span>double</span> z() <span>const</span> { <span>return</span> e[<span>2</span>]; }

        vec3 <span>operator</span><span>-</span>() <span>const</span> { <span>return</span> vec3(<span>-</span>e[<span>0</span>], <span>-</span>e[<span>1</span>], <span>-</span>e[<span>2</span>]); }
        <span>double</span> <span>operator</span>[](<span>int</span> i) <span>const</span> { <span>return</span> e[i]; }
        <span>double</span><span>&amp;</span> <span>operator</span>[](<span>int</span> i) { <span>return</span> e[i]; }

        vec3<span>&amp;</span> <span>operator</span><span>+=</span>(<span>const</span> vec3 <span>&amp;</span>v) {
            e[<span>0</span>] <span>+=</span> v.e[<span>0</span>];
            e[<span>1</span>] <span>+=</span> v.e[<span>1</span>];
            e[<span>2</span>] <span>+=</span> v.e[<span>2</span>];
            <span>return</span> <span>*</span><span>this</span>;
        }

        vec3<span>&amp;</span> <span>operator</span><span>*=</span>(<span>const</span> <span>double</span> t) {
            e[<span>0</span>] <span>*=</span> t;
            e[<span>1</span>] <span>*=</span> t;
            e[<span>2</span>] <span>*=</span> t;
            <span>return</span> <span>*</span><span>this</span>;
        }

        vec3<span>&amp;</span> <span>operator</span><span>/=</span>(<span>const</span> <span>double</span> t) {
            <span>return</span> <span>*</span><span>this</span> <span>*=</span> <span>1</span><span>/</span>t;
        }

        <span>double</span> length() <span>const</span> {
            <span>return</span> sqrt(length_squared());
        }

        <span>double</span> length_squared() <span>const</span> {
            <span>return</span> e[<span>0</span>]<span>*</span>e[<span>0</span>] <span>+</span> e[<span>1</span>]<span>*</span>e[<span>1</span>] <span>+</span> e[<span>2</span>]<span>*</span>e[<span>2</span>];
        }

    <span>public</span><span>:</span>
        <span>double</span> e[<span>3</span>];
};

<span>// Type aliases for vec3
</span><span></span><span>using</span> point3 <span>=</span> vec3;   <span>// 3D point
</span><span></span><span>using</span> color <span>=</span> vec3;    <span>// RGB color
</span><span></span>
<span>#endif
</span></code></pre></div>
<p><strong>Rust</strong></p>
<div><pre><code data-lang="rust"><span>use</span> std::fmt;
<span>use</span> std::ops;

<span>#[derive(Clone, Copy, Debug)]</span>
<span>pub</span> <span>struct</span> <span>Vec3</span> {
    <span>pub</span> x: <span>f64</span>,
    <span>pub</span> y: <span>f64</span>,
    <span>pub</span> z: <span>f64</span>,
}

<span>pub</span> <span>use</span> Vec3 <span>as</span> Point3;
<span>pub</span> <span>use</span> Vec3 <span>as</span> Color;

<span>impl</span> Vec3 {
    <span>pub</span> <span>fn</span> <span>new</span>() -&gt; <span>Vec3</span> {
        Vec3 {
            x: <span>0.</span>,
            y: <span>0.</span>,
            z: <span>0.</span>,
        }
    }

    <span>pub</span> <span>fn</span> <span>with_values</span>(x: <span>f64</span>, y: <span>f64</span>, z: <span>f64</span>) -&gt; <span>Vec3</span> {
        Vec3 { x, y, z }
    }

    <span>pub</span> <span>fn</span> <span>with_vec3</span>(rhs: <span>Vec3</span>) -&gt; <span>Vec3</span> {
        Vec3 {
            x: <span>rhs</span>.x,
            y: <span>rhs</span>.y,
            z: <span>rhs</span>.z,
        }
    }

    <span>pub</span> <span>fn</span> <span>length</span>(<span>&amp;</span>self) -&gt; <span>f64</span> {
        self.length_squared().sqrt()
    }

    <span>pub</span> <span>fn</span> <span>length_squared</span>(<span>&amp;</span>self) -&gt; <span>f64</span> {
        self.x <span>*</span> self.x <span>+</span> self.y <span>*</span> self.y <span>+</span> self.z <span>*</span> self.z
    }
}

<span>impl</span> ops::AddAssign<span>&lt;&amp;</span>Vec3<span>&gt;</span> <span>for</span> Vec3 {
    <span>fn</span> <span>add_assign</span>(<span>&amp;</span><span>mut</span> self, rhs: <span>&amp;</span><span>Vec3</span>) {
        self.x <span>+=</span> rhs.x;
        self.y <span>+=</span> rhs.y;
        self.z <span>+=</span> rhs.z;
    }
}

<span>impl</span> ops::MulAssign<span>&lt;</span><span>f64</span><span>&gt;</span> <span>for</span> Vec3 {
    <span>fn</span> <span>mul_assign</span>(<span>&amp;</span><span>mut</span> self, rhs: <span>f64</span>) {
        self.x <span>*=</span> rhs;
        self.y <span>*=</span> rhs;
        self.z <span>*=</span> rhs;
    }
}

<span>impl</span> ops::DivAssign<span>&lt;</span><span>f64</span><span>&gt;</span> <span>for</span> Vec3 {
    <span>fn</span> <span>div_assign</span>(<span>&amp;</span><span>mut</span> self, rhs: <span>f64</span>) {
        self.x <span>/=</span> rhs;
        self.y <span>/=</span>‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jduchniewicz.com/posts/2021/02/c-to-rust-or-how-to-render-your-mindset/">https://jduchniewicz.com/posts/2021/02/c-to-rust-or-how-to-render-your-mindset/</a></em></p>]]>
            </description>
            <link>https://jduchniewicz.com/posts/2021/02/c-to-rust-or-how-to-render-your-mindset/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295969</guid>
            <pubDate>Sun, 28 Feb 2021 18:54:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Le Test D‚ÄôIshihara]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26295937">thread link</a>) | @unilynx
<br/>
February 28, 2021 | http://daltonien.free.fr/daltonien/article.php3?id_article=6 | <a href="https://web.archive.org/web/*/http://daltonien.free.fr/daltonien/article.php3?id_article=6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Ces tests compos√©s de planches ¬´&nbsp;pseudoisochromatiques&nbsp;¬ª sont les plus fr√©quemment utilis√©s pour la d√©tection des d√©ficiences cong√©nitales des teintes rouge et verte. Quelques-uns testent aussi les anomalies concernant la perception du bleu. Le plus connu de ces tests, il est d‚Äôailleurs celui utilis√© dans le monde entier, est le test japonais d‚ÄôIshihara. Je vais donc le d√©velopper plus que les autres.</p>
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/planche_isochromatique.jpg" width="100" height="97" alt="(JPG)"></p><p><strong>Planche pseudo-isochromatique</strong></p>
</div>


<h3>Descriptif du test d‚ÄôIshihara</h3>

<p>Ce test, invent√© en 1917 par Shinobu Ishihara, est un recueil de 38 planches utilis√© pour d√©pister les anomalies de la vision des couleurs. Il permet de d√©tecter toutes les d√©ficiences dyschromatiques sauf la tritanopie et la trianomalie, d‚Äôailleurs tr√®s rares.</p>
<p>Il faut savoir que ce test est exclusivement qualitatif et non quantitatif. Ainsi, un daltonien atteint d‚Äôun trichromatisme anormal tr√®s minime fera le plus souvent presque autant d‚Äôerreurs qu‚Äôun dichromate complet. Ce test est tr√®s performant pour d√©tecter les dyschroma√∏topsies h√©r√©ditaires de type protan et deutan&nbsp;: son taux de fiabilit√© est de 98% (il permet m√™me de distinguer ces deux types avec un taux d‚Äôerreur de 17%).</p>
<p>Les planches de ce test sont compos√©es d‚Äôune mosaique de points de couleurs diff√©rentes, dispos√©s de fa√ßon apparemment al√©atoire, au sein duquel appara√Æt une forme sur un fond. Un ensemble de points repr√©sente une forme reconnaissable par l‚Äôunit√© de la teinte.</p>
<p>Les couleurs des points sont satur√©es diff√©remment. Ainsi, le dyschromate qui ne verrait pas la couleur, ne pourra pas non plus d√©chiffrer la forme par le seul fait d‚Äôune homog√©n√©it√© de saturation ou de luminosit√©. Sur d‚Äôautres planches, cette homog√©n√©it√© est utilis√©e pour faire percevoir des formes √† des dyschromates alors que des sujets normaux, abus√©s par les couleurs qui leur paraissent diff√©rentes, ne les percevront pas.</p>

<h3>R√®gles d‚Äôutilisation</h3>

<p>Une bonne correction optique en verres non teint√©s est de mise.</p>
<p>L‚Äôutilisation peut √™tre effectu√©e en vision binoculaire dans la mesure o√π l‚Äôon recherche une dyschromatopsie h√©r√©ditaire qui est forc√©ment identique sur les deux yeux. Cependant dans quelques cas douteux, il peut se r√©v√©ler int√©ressant pour affiner un diagnostic de pratiquer l‚Äôexamen en vision monoculaire.</p>
<p>L‚Äô√©clairage par lampe √† incandescence doit √™tre formellement proscrit (rappelons que les lampes halog√®nes sont des lampes √† incandescence). Un √©clairage par lampe fluorescente ou simplement par la lumi√®re du jour (th√©oriquement devant une fen√™tre au Nord) en √©vitant l‚Äô√©blouissement sera convenable.</p>
<p>Il est formellement interdit de toucher les planches avec les doigts.</p>

<h3>Interpr√©tation des planches</h3>

<p>Le test des tables d‚ÄôIshihara est un livre compos√© de 38 planches. Il peut √™tre utilis√© dans le "sens classique"&nbsp;: les planches comportent alors des chiffres (les planches 1 √† 25). En retournant le livre, les planches (26 √† 38) s‚Äôadressent aux illettr√©s ou aux enfants&nbsp;: il faut suivre des chemins (avec un stylo pour ne pas toucher les planches).</p>
<p>Les planches n¬∞1 et 38 sont les planches d‚Äôinitiation (respectivement avec chiffre et avec chemin). Puis viennent ensuite 6 groupes de 4 planches cons√©cutives avec des chiffres, et m√™me chose mais dans le sens inverse pour les tables avec des chemins avec cette fois ci 6 groupes de 2 planches. Pour chaque groupe, le principe de confusion est le m√™me&nbsp;: ainsi lors d‚Äôune utilisation rapide, une seule planche dans chaque groupe peut √™tre montr√©.</p>
<p>Les groupes sont donc&nbsp;:</p>
<p><img src="http://daltonien.free.fr/daltonien/puce.gif" alt="-">&nbsp;&nbsp;<u>Planches 1 et 38</u></p>
<p>Ces planches sont des planches d‚Äôinitiation. Elles sont utiles pour expliquer l‚Äôexamen et √©ventuellement pour d√©pister des simulateurs (√† condition alors de ne pas les pr√©senter en premier).</p>
<p><img src="http://daltonien.free.fr/daltonien/puce.gif" alt="-">&nbsp;&nbsp;<u>Planches 2 √† 5 et 36 √† 37</u></p>
<p>Ces planches explorent la m√™me confusion color√©e. Th√©oriquement, des chiffres diff√©rents de ceux per√ßus par les sujets normaux sont visibles en cas de dyschromatopsie rouge-vert. En fait cette lecture erron√©e est tr√®s inconstante.</p>
<p><img src="http://daltonien.free.fr/daltonien/puce.gif" alt="-">&nbsp;&nbsp;<u>Planches 6 √† 9 et 34 √† 35</u></p>
<p>Ces planches sont de m√™me valeur et explorent une confusion entre le rouge et le vert tr√®s voisine de celle analys√©e par le groupe pr√©c√©dent mais sur un fond diff√©rent. Les sujets anormaux peuvent percevoir des chiffres diff√©rents.</p>
<p><img src="http://daltonien.free.fr/daltonien/puce.gif" alt="-">&nbsp;&nbsp;<u>Planches 10 √† 13 et 32 √† 33</u></p>
<p>Ces planches sont bas√©es sur une confusion bleu vert - orang√©. Les sujets anormaux ne per√ßoivent rien.</p>
<p><img src="http://daltonien.free.fr/daltonien/puce.gif" alt="-">&nbsp;&nbsp;<u>Planches 14 √† 17 et 30 √† 31</u></p>
<p>Ces planches sont en fait tr√®s voisines de la s√©rie 6 √† 9 sur un fond l√©g√®rement diff√©rent et de plus, comme dans la s√©rie pr√©c√©dente, les sujets anormaux ne per√ßoivent pas de chiffre.</p>
<p><img src="http://daltonien.free.fr/daltonien/puce.gif" alt="-">&nbsp;&nbsp;<u>Planches 18 √† 21 et 28 √† 29</u></p>
<p>Ces planches sont construites sur une philosophie diff√©rente. Les sujets normaux (et les achromates) ne per√ßoivent rien alors que les dyschromates peuvent √™tre capables de distinguer des chiffres. En r√©alit√© cette perception est tr√®s inconstante. Cette s√©rie peut √©ventuellement √™tre n√©glig√©e lors d‚Äôune utilisation rapide.</p>
<p><img src="http://daltonien.free.fr/daltonien/puce.gif" alt="-">&nbsp;&nbsp;<u>Planches 22 √† 25 et 26 √† 27</u></p>
<p>Ces planches sont tr√®s importantes car elles ont pour but de s√©parer les sujets protans des deutans. Pour cela le fond est gris et chaque planche pr√©sente deux chiffres dont la couleur est situ√©e dans la zone neutre protane pour le chiffre de gauche et deutane pour celui de droite.<br>
Comme on le voit bien sur ces planches, ces zones neutres sont tr√®s voisines. Un sujet dichromate ne percevra donc qu‚Äôun seul chiffre, l‚Äôautre √©tant confondu avec le fond gris puisqu‚Äô√©tant dans la zone neutre, et un trichromate anormal aura plus de difficult√© √† percevoir un chiffre que l‚Äôautre.<br>
Il faut savoir qu‚Äôen fait bien souvent les r√©ponses ne sont pas assez nettes pour √™tre valablement interpr√©t√©es. Il est en tout cas impensable de porter un diagnostic dichotomique protan-deutan sur la seule lecture de ces planches. En d√©finitive, si l‚Äôon veut aller tr√®s vite, on peut se contenter de faire lire 5 planches. En cas d‚Äôh√©sitation, il faut soumettre le test en entier.</p>

<h3>Les planches d‚ÄôIshihara</h3>

<table witdth="100%">
<tbody><tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb1" name="nh1" title="[1] Tout le monde doit voir le chiffre 12.">1</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/01.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞1</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb2" name="nh2" title="[2] Vision normale : 8. D√©ficience rouge-vert : 3.">2</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/02.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞2</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb3" name="nh3" title="[3] Vision normale : 6. D√©ficience rouge-vert : 5.">3</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/03.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞3</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb4" name="nh4" title="[4] Vision normale : 29. D√©ficience rouge-vert : 70.">4</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/04.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞4</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb5" name="nh5" title="[5] Vision normale : 57. D√©ficience rouge-vert : 35.">5</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/05.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞5</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb6" name="nh6" title="[6] Vision normale : 5. D√©ficience rouge-vert : 2.">6</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/06.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞6</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb7" name="nh7" title="[7] Vision normale : 3. D√©ficience rouge-vert : 5.">7</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/07.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞7</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb8" name="nh8" title="[8] Vision normale : 15. D√©ficience rouge-vert : 17.">8</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/08.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞8</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb9" name="nh9" title="[9] Vision normale : 74. D√©ficience rouge-vert : 21.">9</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/09.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞9</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb10" name="nh10" title="[10] Vision normale : 2. La plupart des dischromates ne voient rien, ou de (...)">10</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/10.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞10</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb11" name="nh11" title="[11] Vision normale : 6. La plupart des dischromates ne voient rien, ou de (...)">11</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/11.jpg" width="234" height="234" alt="(JPG)"></p><p><strong>Table n¬∞11</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb12" name="nh12" title="[12] Vision normale : 97. La plupart des dischromates ne voient rien, ou de (...)">12</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/12.jpg" width="234" height="234" alt="(JPG)"></p><p><strong>Table n¬∞12</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb13" name="nh13" title="[13] Vision normale : 45. La plupart des dischromates ne voient rien, ou de (...)">13</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/13.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞13</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb14" name="nh14" title="[14] Vision normale : 5. La plupart des dischromates ne voient rien, ou de (...)">14</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/14.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞14</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb15" name="nh15" title="[15] Vision normale : 7. La plupart des dischromates ne voient rien, ou de (...)">15</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/15.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞15</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb16" name="nh16" title="[16] Vision normale : 16. La plupart des dischromates ne voient rien, ou de (...)">16</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/16.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞16</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb17" name="nh17" title="[17] Vision normale : 73. La plupart des dischromates ne voient rien, ou de (...)">17</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/17.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞17</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb18" name="nh18" title="[18] Sujets normaux et les dischromates tr√®s faiblement atteints ne (...)">18</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/18.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞18</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb19" name="nh19" title="[19] Sujets normaux et les dischromates tr√®s faiblement atteints ne (...)">19</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/19.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞19</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb20" name="nh20" title="[20] Sujets normaux et les dischromates tr√®s faiblement atteints ne (...)">20</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/20.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞20</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb21" name="nh21" title="[21] Sujets normaux et les dischromates tr√®s faiblement atteints ne (...)">21</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/21.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞21</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb22" name="nh22" title="[22] Vision normale : 26. Protanopie ou protanomalie forte lisent seulement (...)">22</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/22.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞22</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb23" name="nh23" title="[23] Vision normale : 42. Protanopie ou protanomalie forte lisent seulement (...)">23</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/23.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞23</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb24" name="nh24" title="[24] Vision normale : 35. Protanopie ou protanomalie forte lisent seulement (...)">24</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/24.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞24</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb25" name="nh25" title="[25] Vision normale : 96. Protanopie ou protanomalie forte lisent seulement (...)">25</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/25.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞25</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb26" name="nh26" title="[26] Vision normale : trac√©s pourpre et rouge. Protanopie ou protanomalie (...)">26</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/26.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞26</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb27" name="nh27" title="[27] Vision normale : trac√©s pourpre et rouge. Protanopie ou protanomalie (...)">27</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/27.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞27</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb28" name="nh28" title="[28] Vision normale et les dischromates tr√®s faiblement atteints ne (...)">28</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/28.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞28</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb29" name="nh29" title="[29] Vision normale et les dischromates tr√®s faiblement atteints ne (...)">29</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/29.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞29</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb30" name="nh30" title="[30] Vision normale : trac√© bleu-vert. La plupart des dischromates ne (...)">30</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/30.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞30</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb31" name="nh31" title="[31] Vision normale : trac√© bleu-vert. La plupart des dischromates ne (...)">31</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/31.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞31</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb32" name="nh32" title="[32] Vision normale : trac√© orange. La plupart des dischromates ne voient (...)">32</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/32.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞32</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb33" name="nh33" title="[33] Vision normale : trac√© orange. La plupart des dischromates ne voient (...)">33</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/33.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞33</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb34" name="nh34" title="[34] Vision normale : trac√© bleu√¢tre-vert et jaun√¢tre-vert. D√©ficience (...)">34</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/34.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞34</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb35" name="nh35" title="[35] Vision normale : trac√© bleu√¢tre-vert et jaun√¢tre-vert. D√©ficience (...)">35</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/35.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞35</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb36" name="nh36" title="[36] Vision normale : trac√©s pourpre et orange. D√©ficience rouge-vert : (...)">36</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/36.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞36</strong></p>
</div>

</td>
</tr>
<tr>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb37" name="nh37" title="[37] Vision normale : trac√©s pourpre et orange. D√©ficience rouge-vert : (...)">37</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/37.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞37</strong></p>
</div>

</td>
<td>R√©ponse&nbsp;:&nbsp;[<a href="#nb38" name="nh38" title="[38] Tout le monde doit voir le chemin trac√©.">38</a>]
<div><p><img src="http://daltonien.free.fr/daltonien/IMG/jpg/38.jpg" width="233" height="233" alt="(JPG)"></p><p><strong>Table n¬∞38</strong></p>
</div>

</td>
</tr>
</tbody></table></div><div><p>
[<a href="#nh1" name="nb1">1</a>] Tout le monde doit voir le chiffre 12.</p>
<p>[<a href="#nh2" name="nb2">2</a>] Vision normale&nbsp;: 8.<br>
D√©ficience rouge-vert&nbsp;: 3.</p>
<p>[<a href="#nh3" name="nb3">3</a>] Vision normale&nbsp;: 6.<br>
D√©ficience rouge-vert&nbsp;: 5.</p>
<p>[<a href="#nh4" name="nb4">4</a>] Vision normale&nbsp;: 29.<br>
D√©ficience rouge-vert&nbsp;: 70.</p>
<p>[<a href="#nh5" name="nb5">5</a>] Vision normale&nbsp;: 57.<br>
D√©ficience rouge-vert&nbsp;: 35.</p>
<p>[<a href="#nh6" name="nb6">6</a>] Vision normale&nbsp;: 5.<br>
D√©ficience rouge-vert&nbsp;: 2.</p>
<p>[<a href="#nh7" name="nb7">7</a>] Vision normale&nbsp;: 3.<br>
D√©ficience rouge-vert&nbsp;: 5.</p>
<p>[<a href="#nh8" name="nb8">8</a>] Vision normale&nbsp;: 15.
D√©ficience rouge-vert&nbsp;: 17.</p>
<p>[<a href="#nh9" name="nb9">9</a>] Vision normale&nbsp;: 74.<br>
D√©ficience rouge-vert&nbsp;: 21.</p>
<p>[<a href="#nh10" name="nb10">10</a>] Vision normale&nbsp;: 2.<br>
La plupart des dischromates ne voient rien, ou de fa√ßon erron√©.</p>
<p>[<a href="#nh11" name="nb11">11</a>] Vision normale&nbsp;: 6.<br>
La plupart des dischromates ne voient rien, ou de fa√ßon erron√©.</p>
<p>[<a href="#nh12" name="nb12">12</a>] Vision normale&nbsp;: 97.<br>
La plupart des dischromates ne voient rien, ou de fa√ßon erron√©.</p>
<p>[<a href="#nh13" name="nb13">13</a>] Vision normale&nbsp;: 45.<br>
La plupart des dischromates ne voient rien, ou de fa√ßon erron√©.</p>
<p>[<a href="#nh14" name="nb14">14</a>] Vision normale&nbsp;: 5.<br>
La plupart des dischromates ne voient rien, ou de fa√ßon erron√©.</p>
<p>[<a href="#nh15" name="nb15">15</a>] Vision normale&nbsp;: 7.<br>
La plupart des dischromates ne voient rien, ou de fa√ßon erron√©.</p>
<p>[<a href="#nh16" name="nb16">16</a>] Vision normale&nbsp;: 16.<br>
La plupart des dischromates ne voient rien, ou de fa√ßon erron√©.</p>
<p>[<a href="#nh17" name="nb17">17</a>] Vision normale&nbsp;: 73.<br>
La plupart des dischromates ne voient rien, ou de fa√ßon erron√©.</p>
<p>[<a href="#nh18" name="nb18">18</a>] Sujets normaux et les dischromates tr√®s faiblement atteints ne per√ßoivent rien.<br>
D√©ficience rouge-vert&nbsp;: 5.</p>
<p>[<a href="#nh19" name="nb19">19</a>] Sujets normaux et les dischromates tr√®s faiblement atteints ne per√ßoivent rien.<br>
D√©ficience rouge-vert&nbsp;: 2.</p>
<p>[<a href="#nh20" name="nb20">20</a>] Sujets normaux et les dischromates tr√®s faiblement atteints ne per√ßoivent rien.<br>
D√©ficience rouge-vert&nbsp;: 45.</p>
<p>[<a href="#nh21" name="nb21">21</a>] Sujets normaux et les dischromates tr√®s faiblement atteints ne per√ßoivent rien.
D√©ficience rouge-vert&nbsp;: 73.</p>
<p>[<a href="#nh22" name="nb22">22</a>] Vision normale&nbsp;: 26.<br>
Protanopie ou protanomalie forte lisent seulement&nbsp;: 6.<br>
Deut√©ranopie et deut√©ranomalie grave lisent seulement&nbsp;: 2.</p>
<p>[<a href="#nh23" name="nb23">23</a>] Vision normale&nbsp;: 42.<br>
Protanopie ou protanomalie forte lisent seulement&nbsp;: 2.<br>
Deut√©ranopie et deut√©ranomalie grave lisent seulement&nbsp;: 4.</p>
<p>[<a href="#nh24" name="nb24">24</a>] Vision normale&nbsp;: 35.<br>
Protanopie ou protanomalie forte lisent seulement&nbsp;: 5.<br>
Deut√©ranopie et deut√©ranomalie grave lisent seulement&nbsp;: 3.</p>
<p>[<a href="#nh25" name="nb25">25</a>] Vision normale&nbsp;: 96.<br>
Protanopie ou protanomalie forte lisent seulement&nbsp;: 6.<br>
Deut√©ranopie et deut√©ranomalie grave lisent seulement&nbsp;: 9.</p>
<p>[<a href="#nh26" name="nb26">26</a>] Vision normale&nbsp;: trac√©s pourpre et rouge.<br>
Protanopie ou protanomalie forte&nbsp;: uniquement le trac√© pourpre.<br>
Deut√©ranopie et deut√©ranomalie&nbsp;: uniquement le trac√© rouge.</p>
<p>[<a href="#nh27" name="nb27">27</a>] Vision normale&nbsp;: trac√©s pourpre et rouge.<br>
Protanopie ou protanomalie forte&nbsp;: uniquement le trac√© pourpre.<br>
Deut√©ranopie et deut√©ranomalie&nbsp;: uniquement le trac√© rouge.</p>
<p>[<a href="#nh28" name="nb28">28</a>] Vision normale et les dischromates tr√®s faiblement atteints ne per√ßoivent rien.<br>
D√©ficience rouge-vert&nbsp;: un trac√©.</p>
<p>[<a href="#nh29" name="nb29">29</a>] Vision normale et les dischromates tr√®s faiblement atteints ne per√ßoivent rien.<br>
D√©ficience rouge-vert&nbsp;: un trac√©.</p>
<p>[<a href="#nh30" name="nb30">30</a>] Vision normale&nbsp;: trac√© bleu-vert.<br>
La plupart des dischromates ne voient rien.</p>
<p>[<a href="#nh31" name="nb31">31</a>] Vision normale&nbsp;: trac√© bleu-vert.<br>
La plupart des dischromates ne voient rien.</p>
<p>[<a href="#nh32" name="nb32">32</a>] Vision ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://daltonien.free.fr/daltonien/article.php3?id_article=6">http://daltonien.free.fr/daltonien/article.php3?id_article=6</a></em></p>]]>
            </description>
            <link>http://daltonien.free.fr/daltonien/article.php3?id_article=6</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295937</guid>
            <pubDate>Sun, 28 Feb 2021 18:51:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[World Beer Index 2021: The Cost and Consumption of Beer Around the World]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 77 (<a href="https://news.ycombinator.com/item?id=26295875">thread link</a>) | @giuliomagnifico
<br/>
February 28, 2021 | https://www.expensivity.com/beer-around-the-world/ | <a href="https://web.archive.org/web/*/https://www.expensivity.com/beer-around-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry-content">
<p>Beer. Everybody likes to drink it. Nobody likes to pay for it. Still, the cost of a beer stings more or less depending on where in the world you‚Äôre drinking.</p>
<p>Expensivity wondered just how much the cost of beer differs from country and the effect the price of beer has on national consumption. We researched the price of a beer around the world and used World Health Organization statistics to figure out who‚Äôs drinking it all.</p>
<p><em>All prices are in US dollars. All beers are 33cl (330ml) bottles.</em></p>
<h2><strong>Key Findings</strong></h2>
<ul><li><strong>Qatar</strong> has the <strong>most expensive beer in the world</strong>, with an average price of <strong>US$11.26</strong> per 33cl (330ml) bottle.</li><li>The <strong>cheapest beer</strong> is in <strong>South Africa</strong>, where the average price is <strong>$1.68</strong> per bottle.</li><li>The <strong>Czech Republic</strong> has the <strong>highest consumption rate</strong>, with <strong>468 beers</strong> per person per year.</li><li><strong>Germans</strong> spend an average <strong>$1,907.78 per year</strong> on beer, the <strong>top figure</strong> in our study.</li></ul>
<h2><strong>Qatar Wins World Cup for Expensive Beer</strong></h2>
<p>A beer in Qatar is expensive. The mostly Muslim country introduced a <a href="https://www.nytimes.com/2019/01/01/world/middleeast/qatar-tax-alcohol.html">100% tax</a> on alcohol imports ahead of the 2022 World Cup, and visitors need a special permit to drink alcohol. China looks pretty expensive too, but consider that we averaged the price of a hotel beer ($13.61) and a supermarket beer ($1.81). </p>
<figure><a href="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg"><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg" alt="The Price of Beer Around The World" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>
<p><a href="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg"><strong>Tap on the map to see it full size</strong></a></p>
<p>It‚Äôs clear the steep prices are aimed at visitors. Beer is cheapest in South Africa, where a <a href="https://www.dailymaverick.co.za/article/2020-10-26-counting-the-cost-of-cheap-easily-available-alcohol-in-south-africa/">culture of buying in bulk</a> tends to keep prices down.</p>
<h2><strong>The International Beer Index in Full</strong></h2>
<p>Where there is beer, there are beer geeks. Here is Expensivity‚Äôs data in full so you can find out exactly what kind of beer culture to expect from country to country. Click the arrows to sort by price, consumption, or total spend.</p>

<p>The ten countries with the highest average annual beer bill each have beer that costs upwards of four bucks. However, second-placed Poland is notable for its 62¬¢ carry-out beer, suggesting that much of Poland‚Äôs $1,738 average beer bill is built up by hotel-faring bachelor parties.</p>
<p>Bosnia is an outlier among the big drinkers: the country is in eighth place for beer consumption by bottle (331/year) but 30<sup>th</sup> for overall spend ($647.21), thanks to an average price that comes in under two bucks.</p>
<h2><strong>Germany Spends the Most On Beer</strong></h2>
<p>Haitians just aren‚Äôt that into beer. Spirits account for a whopping<a href="https://www.statista.com/statistics/973941/alcohol-consumption-latin-america-country-drink-type/"> 97% of booze consumed</a> in Haiti, where people drink fewer than four beers per year on average, with an annual beer bill of $10.02. That‚Äôs the lowest beer consumption and spend in our study.</p>
<div><figure><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg" alt="How Much Do People Spend on Beer Annually?" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></figure></div>
<p><a rel="noreferrer noopener" href="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg" target="_blank"><strong>Tap on the map to see it full size</strong></a></p>
<p>At the other end of the scale, Germans spend just shy of $2k/year on beer. We found 15 countries with more expensive beer than Germany, but the nation sinks 411 bottles per person annually, so it pays the most in total. Germany is known for its<a href="https://www.dw.com/en/beer-culture-this-is-how-germany-drinks/a-19201434"> beer culture</a> and a stringent (delicious) beer purity law that has stood for over 500 years.</p>
<h2><strong>Czechia and Spain Lead Drinking Contest</strong></h2>
<p>So, who‚Äôs drinking all the beer? The Czech Republic takes the title, with 468 beers per person per year. However, capital Prague is the fourth most-visited city in Europe and infamous for its bachelor parties (<a href="https://www.lonelyplanet.com/articles/prague-different-type-visitor-after-lockdown">for now at least</a>). Like sunny Spain, in second place, Czechia‚Äôs beer consumption may be significantly swelled by visiting merry-makers.</p>
<div><figure><a href="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg"><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg" alt="How Much Beer Do People Drink In Different Countries?" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure></div>
<p><a href="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg"><strong>Tap on the map to see it full size</strong></a></p>
<p>Haiti drinks the least beer, counted per bottle or per spend. Most of the countries with a low beer intake can credit their predominantly Muslim populations for the abstinence. Armenia is an exception. The west Asian country drinks just 40 beers per person annually, with locals favoring<a href="https://theculturetrip.com/europe/armenia/articles/alcoholic-drinks-you-should-try-in-armenia/"> brandy, vodka, and wine</a>.</p>
<p>Armenians might not drink much beer, but the beer they drink is delicious, cheap, and<a href="https://www.smithsonianmag.com/travel/armenia-might-be-one-oldest-and-youngest-beermaking-countries-world-180964860/"> finely crafted</a>. Wherever you‚Äôre drinking in the world, be sure to check out the tradition behind your beer, as well as the cost ‚Äì nothing adds<a href="https://www.expensivity.com/expensivity-by-the-ounce/"> value</a> to your experience like a beer with a story!</p>
<figure><img width="1024" height="690" src="https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1024x690.jpg" alt="" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1024x690.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-300x202.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-768x517.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1536x1034.jpg 1536w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<h3><strong>METHODOLOGY &amp; SOURCES</strong></h3>
<p>We collated the prices of a 330ml bottle of beer in supermarkets around the world using online shops, focusing on well-known beer brands such as Corona and Heineken. When we couldn‚Äôt find the price via an online shop, we used <a href="https://www.numbeo.com/cost-of-living/">numbeo.com</a>.</p>
<p>To gain an average price, we called up hotels to find out the price of a beer from their lobby bar, and when this wasn‚Äôt available, we used menus from bars found online. Once all the data was collected, we calculated the average price in US dollars using <a href="http://xe.com/">xe.com</a>.</p>
<p>Using the <a href="https://www.who.int/data/gho/data/indicators/indicator-details/GHO/alcohol-total-per-capita-(15-)-consumption-(in-litres-of-pure-alcohol)-with-95-ci">World Health</a> <a href="https://www.who.int/data/gho/data/indicators/indicator-details/GHO/alcohol-consumption-of-pure-alcohol-by-type-of-beverage-(-)">Organisation statistics</a>, we found the amount of alcohol consumption per capita and the percentage of annual beer consumption.</p>
</div></div>]]>
            </description>
            <link>https://www.expensivity.com/beer-around-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295875</guid>
            <pubDate>Sun, 28 Feb 2021 18:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bertrand Meyer's contributions to software engineering]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295841">thread link</a>) | @emme
<br/>
February 28, 2021 | https://bertrandmeyer.com/2021/02/26/some-contributions/ | <a href="https://web.archive.org/web/*/https://bertrandmeyer.com/2021/02/26/some-contributions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<!-- AddThis Sharing Buttons above -->
                <p>Science progresses through people taking advantage of others‚Äô insights and inventions. One of the conditions that makes the game possible is that you acknowledge what you take. For the originator, it is rewarding to see one‚Äôs ideas reused, but frustrating when that happens without acknowledgment, especially when you are yourself punctilious about citing your own sources of inspiration.</p>
<p>I have started to record some concepts that are widely known and applied today and which I believe I originated in whole or in part, whether or not their origin is cited by those who took them. The list below is not complete and I may update it in the future. It is not a list of ideas I contributed, only of those fulfilling two criteria:</p>
<ul>
<li>Others have built upon them.&nbsp; (If there is an idea that I think is great but no one paid attention to it, the list does not include it.)</li>
<li>They have gained wide visibility.</li>
</ul>
<p>There is a narcissistic aspect to this exercise and if people want to dismiss it as just showing I am full of myself so be it. I am just a little tired of being given papers to referee that state that genericity was invented by Java, that no one ever thought of refactoring before agile methods, and so on. It is finally time to state some facts.</p>
<p>Facts indeed: I back every assertion by precise references. So if I am wrong ‚Äî i.e. someone preceded me ‚Äî the claims of precedence can be refuted; if so I will update or remove them. All articles by me cited in this note are available (as downloadable PDFs) on my <a href="http://se.ethz.ch/~meyer/publications/" target="blog_illustrations"><span>publication page</span></a>. (The page is up to date until 2018; I am in the process of adding newer publications.)</p>
<p><em>Post-publication note</em>: I have started to receive some comments and added them in a Notes section at the end; references to those notes are in the format [A].</p>
<p><em>Final disclaimer (about the narcissistic aspect): the exercise of collecting such of that information was new for me, as I do not usually spend time reflecting on the past. I am much more interested in the future and definitely hope that my next contributions will eclipse any of the ones listed below.</em></p>
<h3>Programming concepts: substitution principle</h3>
<p>Far from me any wish to under-represent the seminal contributions of Barbara Liskov, particularly her invention of the concept of abstract data type on which so much relies. As far as I can tell, however, what has come to be known as the ‚Äú<a href="https://en.wikipedia.org/wiki/Liskov_substitution_principle" target="blog_illustrations"><span>Liskov Substitution Principle</span></a>‚Äù is essentially contained in the discussion of polymorphism in section 10.1 of&nbsp;in the first edition (Prentice Hall, 1988) of my book <em>Object-Oriented Software Construction</em> (hereafter OOSC1); for example, ‚Äú<em>the type compatibility rule implies that the dynamic type is always a descendant of the static type</em>‚Äù (10.1.7) and ‚Äúi<em>f B inherits from A, the set of objects that can be associated at run time with an entity</em> [generalization of variable] <em>includes instances of B and its descendants</em>‚Äù.</p>
<p>Perhaps most tellingly, a key aspect of the substitution principle, as listed for example in the Wikipedia entry, is the rule on assertions: in a proper descendant, keep the invariant, keep or weaken the precondition, keep or strengthen the postcondition. This rule was introduced in OOSC1, over several pages in section 11.1. There is also an extensive discussion in the article <em>Eiffel: Applying the Principles of Object-Oriented Design </em>published in the Journal of Systems and Software, May 1986.</p>
<p>The original 1988 Liskov article cited (for example) in the Wikipedia entry on the substitution principle says nothing about this and does not in fact include any of the terms ‚Äúassertion‚Äù, ‚Äúprecondition‚Äù, ‚Äúpostcondition‚Äù or ‚Äúinvariant‚Äù. To me this absence means that the article misses a key property of substitution: that the <em>abstract</em> semantics remain the same. (Also cited is a 1994 Liskov article in TOPLAS, but that was many years after OOSC1 and other articles explaining substitution and the assertion rules.)</p>
<p>Liskov‚Äôs original paper states that ‚Äúi<em>f for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for oz, then S is a subtype of T</em>.‚Äù As stated, this property is impossible to satisfy: if the behavior is identical, then the implementations are the same, and the two types are identical (or differ only by name). Of course the <strong>concrete</strong> behaviors are different: applying the operation <em>rotate</em> to two different figures o1 and o2, whose types are subtypes of <em>FIGURE</em> and in some cases of each other, will trigger different algorithms ‚Äî different behaviors. Only with assertions (contracts) does the substitution idea make sense: the <strong>abstract</strong> behavior, as characterized by preconditions, postconditions and the class invariants, is the same (modulo respective weakening and strengthening to preserve the flexibility of the different version). Realizing this was a major step in understanding inheritance and typing. I do not know of any earlier (or contemporary) exposition of this principle and it would be normal to get the appropriate recognition.</p>
<h3>Software design: design patterns</h3>
<p>Two of the important patterns in the ‚ÄúGang of Four‚Äù Design Patterns book (GoF) by Gamma et al. (1995) are the Command Pattern and the Bridge Pattern. I introduced them (under different names) in the following publications:</p>
<ul>
<li>The <strong>command pattern</strong> appears in OOSC1 under the name ‚ÄúUndo-Redo‚Äù in section 12.2. The solution is essentially the same as in GoF. I do not know of any earlier exposition of the technique. See also notes [B] and [C].</li>
</ul>
<ul>
<li>The <strong>bridge pattern</strong> appears under the name ‚Äúhandle technique‚Äù in my book <em>Reusable Software: The Base Component Libraries</em> (Prentice Hall, 1994). It had been described several years earlier in manuals for Eiffel libraries. I do not know of an earlier reference. (The second edition of <em>Object-Oriented Software Construction</em> ‚Äî Prentice Hall, 1997, ‚ÄúOOSC2‚Äù ‚Äì, which also describes it, states that a similar technique is described in an article by Josef Gil and Ricardo Szmit at the TOOLS USA conference in the summer of 1994, i.e. after the publication of <em>Reusable Software</em>.)</li>
</ul>
<p>Note that it is pointless to claim precedence over GoF since that book explicitly states that it is collecting known ‚Äúbest practices‚Äù, not introducing new ones. The relevant questions are: who, pre-GoF, introduced each of these techniques first; and which publications does the GoF cites as ‚Äúprior art‚Äù&nbsp; for each pattern. In the cases at hand, Command and Bridge, it does not cite OOSC1.</p>
<h3>Software design: Open-Closed Principle</h3>
<p>Another contribution of OOSC1 (1988), section 2.3, reinforced in OOSC2 (1997) is the Open-Closed principle, which explained one of the key aspects of inheritance: the ability to keep a module both closed (immediately usable <em>as is</em>) and open to extension (through inheritance, preserving the basic semantics. I am mentioning this idea only in passing since in this case my contribution is usually recognized, for example in the Wikipedia entry.</p>
<h3>Software design: OO for reuse</h3>
<p><em>Reusability: the Case for Object-Oriented Design</em> (1987) is, I believe, the first publication that clearly explained why object-oriented concepts were (and still are today ‚Äî in Grady Booch‚Äôs words, ‚Äúthere is no other game in town‚Äù) the best answer to realize the goal of software construction from software components. In particular, the article:</p>
<ul>
<li>Explains the relationship between abstract data types and OO programming, showing the former as the theoretical basis for the latter. (The CLU language at MIT originated from Liskov‚Äôs pioneering work on abstract data types, but was not OO in the full sense of the term, missing in particular a concept of inheritance.)</li>
<li>Shows that reusability implies bottom-up development. (Top-down refinement was the mantra at the time, and promoting bottom-up was quite a shock for many people.)</li>
<li>Explains the role of inheritance for reuse, as a complement to Parnas‚Äôs interface-based modular construction with information hiding.</li>
</ul>
<h3>Software design: Design by Contract</h3>
<p>The contribution of Design by Contract is one that is widely acknowledged so I don‚Äôt have any point to establish here ‚Äî I will just recall the essentials. The notion of assertion goes back to the work of Floyd, Hoare and Dijkstra in the sixties and seventies, and correctness-by-construction to Dijktra, Gries and Wirth, but Design by Contract is a comprehensive framework providing:</p>
<ul>
<li>The use of assertions in an object-oriented context. (The notion of class invariant was mentioned in a paper by Tony Hoare published back in 1972.)</li>
<li>The connection of inheritance with assertions (as sketched above). That part as far as I know was entirely new.</li>
<li>A design methodology for quality software: the core of DbC.</li>
<li>Language constructs carefully seamed into the fabric of the language. (There were precedents there, but in the form of research languages such as Alphard, a paper design only, not implemented, and Euclid.)</li>
<li>A documentation methodology.</li>
<li>Support for testing.</li>
<li>Support for a consistent theory of exception handling (see next).</li>
</ul>
<p>Design by Contract is sometimes taken to mean simply the addition of a few assertions here and there. What the term actually denotes is a comprehensive methodology with all the above components, tightly integrated into the programming language. Note in particular that preconditions and postconditions are not sufficient; in an OO context class invariants are essential.</p>
<h3>Software design: exceptions</h3>
<p>Prior to the Design by Contract work, exceptions were defined very vaguely, as something special you do outside of ‚Äúnormal‚Äù cases, but without defining ‚Äúnormal‚Äù. Design by Contract brings a proper perspective by defining these concepts precisely. This was explained in a 1987 article, <em>Disciplined Exceptions </em>([86] in the list), rejected by ECOOP but circulated as a technical report; they appear again in detail in OOSC1 (sections 7.10.3 to 7.10.5).</p>
<p>Other important foundational work on exceptions, to which I know no real precursor (as usual I would be happy to correct any ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bertrandmeyer.com/2021/02/26/some-contributions/">https://bertrandmeyer.com/2021/02/26/some-contributions/</a></em></p>]]>
            </description>
            <link>https://bertrandmeyer.com/2021/02/26/some-contributions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295841</guid>
            <pubDate>Sun, 28 Feb 2021 18:40:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Tips for React Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295794">thread link</a>) | @psuranas
<br/>
February 28, 2021 | https://prateeksurana.me/blog/javascript-tips-for-react-developers/ | <a href="https://web.archive.org/web/*/https://prateeksurana.me/blog/javascript-tips-for-react-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I have been working with React for the past couple of years, so naturally, I am not really proud of the code that I wrote when I was just beginning with React, because now I know the mistakes I made which I wasn't aware of back then.</p><p>But fast-forwarding to today, I have learned quite a bit along the way through contributing to open source, watching/reading some interesting blogs and conference talks and viewing how other people write code.</p><p>Here are some Javascript tips that would've helped my past self and maybe you, in writing more efficient and maintainable React code -</p><h2><a id="1-use-conditional-rendering-effectively" href="#1-use-conditional-rendering-effectively"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg> 1. Use conditional rendering effectively</a></h2><p>As a React developer, you must've been in a situation where you only want to display a component when a certain condition from a prop or state is satisfied or render different components depending on the different values of the state.</p><p>For instance, if you have a component where you want to show a loading indicator when the request is being made and render the component with data when the request is successful, this is the way I like to do it -</p><pre><code><span>const</span> <span>SomeComponent</span> <span>=</span> <span>(</span><span><span>{</span> isLoading<span>,</span> data <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span><p>	<span>if</span><span>(</span>isLoading<span>)</span> <span>{</span><br>    <span>return</span> <span><span><span>&lt;</span><span>Loader</span></span><span>/&gt;</span></span><br>  <span>}</span></p><p>  <span>return</span> <span>(</span><br>     <span><span><span>&lt;</span><span>DataHandler</span></span><span>&gt;</span></span><span><br>       .<br>       .<br>     </span><span><span><span>&lt;/</span><span>DataHandler</span></span><span>&gt;</span></span><br>  <span>)</span><span>;</span></p><p><span>}</span></p></code></pre><p>But what if you want to render something inside JSX when a particular condition is satisfied in that case you can use the Logical AND operator (<code>&amp;&amp;</code>) to render it -</p><pre><code><span>const</span> <span>Button</span> <span>=</span> <span>(</span><span><span>{</span> showHomeIcon<span>,</span> children<span>,</span> onClick <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><br>  <span><span><span>&lt;</span>button</span> <span>type</span><span><span>=</span><span>"</span>button<span>"</span></span> <span>onClick</span><span><span>=</span><span>{</span>onClick<span>}</span></span><span>&gt;</span></span><span><br>    </span><span>{</span>showHomeIcon <span>&amp;&amp;</span> <span><span><span>&lt;</span><span>HomeIcon</span></span> <span>/&gt;</span></span><span>}</span><span><br>    </span><span>{</span>children<span>}</span><span><br>  </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><br><span>)</span><span>;</span></code></pre><p>Although a more useful scenario would be doing something like this, where you have an optional prop called icon which is a string and contains the name of the icon that can be used to render the icon component accordingly -</p><pre><code><span>const</span> <span>Button</span> <span>=</span> <span>(</span><span><span>{</span> icon<span>,</span> children<span>,</span> onClick <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><br>  <span><span><span>&lt;</span>button</span> <span>type</span><span><span>=</span><span>"</span>button<span>"</span></span> <span>onClick</span><span><span>=</span><span>{</span>onClick<span>}</span></span><span>&gt;</span></span><span><br>    </span><span>{</span><span>}</span><span><br>    </span><span>{</span><span>typeof</span> icon <span>===</span> <span>"string"</span> <span>&amp;&amp;</span> <span><span><span>&lt;</span><span>Icon</span></span> <span>name</span><span><span>=</span><span>{</span>icon<span>}</span></span> <span>/&gt;</span></span><span>}</span><span><br>    </span><span>{</span>children<span>}</span><span><br>  </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><br><span>)</span><span>;</span><p><br><span><span><span>&lt;</span><span>Button</span></span> <span>icon</span><span><span>=</span><span>"</span>home<span>"</span></span> <span>onClick</span><span><span>=</span><span>{</span>handleClick<span>}</span></span><span>&gt;</span></span><span>Home</span><span><span><span>&lt;/</span><span>Button</span></span><span>&gt;</span></span></p><p><br><span><span><span>&lt;</span><span>Button</span></span> <span>onClick</span><span><span>=</span><span>{</span>handleClick<span>}</span></span><span>&gt;</span></span><span>About</span><span><span><span>&lt;/</span><span>Button</span></span><span>&gt;</span></span></p></code></pre><p>So this solves the problem when you only have one component but what about when you have two or more than two components that you want to render based on some prop or state variable?</p><p>For two components ternary operator is my goto method, because of its simiplicity -</p><pre><code><span>const</span> <span>App</span> <span>=</span> <span>props</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> canViewWelcomeText <span>=</span> <span>isUserAuthenticated</span><span>(</span>props<span>)</span><span>;</span><p>  <span>return</span> canViewWelcomeText <span>?</span> <span>(</span><br>    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>Hey, there! Welcome back. Its been a while.</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br>  <span>)</span> <span>:</span> <span>(</span><br>    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>You need to login to view this page</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br>  <span>)</span><span>;</span><br><span>}</span><span>;</span></p></code></pre><p>And if you have quite a few components that need to be rendered from a condition, then switch case is probably the best one to go with -</p><pre><code><span>const</span> <span>getCurrentComponent</span> <span>=</span> <span>currentTab</span> <span>=&gt;</span> <span>{</span><br>  <span>switch</span> <span>(</span>currentTab<span>)</span> <span>{</span><br>    <span>case</span> <span>'profile'</span><span>:</span><br>      <span>return</span> <span><span><span>&lt;</span><span>Profile</span></span> <span>/&gt;</span></span><span>;</span><br>    <span>case</span> <span>'settings'</span><span>:</span><br>      <span>return</span> <span><span><span>&lt;</span><span>Settings</span></span> <span>/&gt;</span></span><span>;</span><br>    <span>default</span><span>:</span><br>      <span>return</span> <span><span><span>&lt;</span><span>Home</span></span> <span>/&gt;</span></span><span>;</span><br>  <span>}</span><br><span>}</span><span>;</span><p><span>const</span> <span>Dashboard</span> <span>=</span> <span>props</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> <span>[</span>currentTab<span>,</span> setTab<span>]</span> <span>=</span> React<span>.</span><span>useState</span><span>(</span><span>'profile'</span><span>)</span><span>;</span></p><p>  <span>return</span> <span>(</span><br>    <span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>"</span>dashboard<span>"</span></span><span>&gt;</span></span><span><br>      </span><span><span><span>&lt;</span><span>PrimaryTab</span></span> <span>currentTab</span><span><span>=</span><span>{</span>currentTab<span>}</span></span> <span>setTab</span><span><span>=</span><span>{</span>setTab<span>}</span></span> <span>/&gt;</span></span><span><br>      </span><span>{</span><span>getCurrentComponent</span><span>(</span>currentTab<span>)</span><span>}</span><span><br>    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br>  <span>)</span><span>;</span><br><span>}</span><span>;</span></p></code></pre><h2><a id="2-avoid-using-truthy-tests" href="#2-avoid-using-truthy-tests"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg> 2. Avoid using truthy tests</a></h2><p>If you are familiar with JavaScript then you might be aware of <a href="https://developer.mozilla.org/en-US/docs/Glossary/Truthy">truthy</a> and <a href="https://developer.mozilla.org/en-US/docs/Glossary/Falsy">falsy</a> values. So a truthy test is nothing but using this coercion ability of JavaScript in control flow statements like this</p><pre><code><br><br><span>if</span> <span>(</span>somVar<span>)</span> <span>{</span><br>	<span>doSomething</span><span>(</span><span>)</span><span>;</span><br><span>}</span> </code></pre><p>This might look good at first if you want to avoid something like <code>null</code> since it is a falsy value so the statement will work as expected. But the catch here is that this is prone to bugs that can be very difficult to track down. This is because the above statement would block the flow for not <code>null</code> but also for all these falsy values of <code>someVar</code> which we might want to avoid -</p><pre><code>someVar <span>=</span> <span>0</span><br>someVar <span>=</span> <span>""</span><br>someVar <span>=</span> <span>false</span><br>someVar <span>=</span> <span>undefined</span></code></pre><p>So what is the correct way for these checks?</p><p>The valid way is being as straightforward as possible for these checks to avoid any bugs from creeping in. For the above case it would be -</p><pre><code><br><span>if</span> <span>(</span>someVar <span>!==</span> <span>null</span><span>)</span> <span>{</span><br>	<span>doSomething</span><span>(</span><span>)</span><span>;</span><br><span>}</span></code></pre><blockquote><p>If you're sure that the variable being passed is a boolean then you can use the former approach.</p></blockquote><p>This also applies when doing conditional rendering with the Logical and operator that we saw in the previous tip.</p><p>If the first operator is falsy then JavaScript returns that object. So in case of an expression like <code>0 &amp;&amp; "javascript"</code> will return <code>0</code> and <code>false &amp;&amp; "javascript"</code> will return <code>false</code> . This can bite you if you were doing something like this -</p><pre><code><br><br><span>{</span>cats<span>.</span>length <span>&amp;&amp;</span> <span><span><span>&lt;</span><span>AllCats</span></span> <span>cats</span><span><span>=</span><span>{</span>cats<span>}</span></span> <span>/&gt;</span></span><span>}</span><p><br><br><span>{</span>cats<span>.</span>length <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span><span><span>&lt;</span><span>AllCats</span></span> <span>cats</span><span><span>=</span><span>{</span>cats<span>}</span></span> <span>/&gt;</span></span><span>}</span></p></code></pre><h2><a id="3-use-optional-chaining-and-nullish-coalescing" href="#3-use-optional-chaining-and-nullish-coalescing"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg> 3. Use optional chaining and nullish coalescing</a></h2><p>When dealing with data in our apps we often need to deal with parts of data that call be <code>null</code> or <code>undefined</code> and provide default values.</p><p>Let's suppose we have an API that returns the details of a Pet in the following format -</p><pre><code><br><span>{</span><br>  id<span>:</span> <span>42</span><span>,</span><br>  name<span>:</span> <span>'Ghost'</span><span>,</span><br>  type<span>:</span> <span>'Mammal'</span><span>,</span><br>  diet<span>:</span> <span>'Carnivore'</span><br>  owner<span>:</span> <span>{</span><br>    first_name<span>:</span> <span>'Jon'</span><span>,</span><br>    last_name<span>:</span> <span>'Snow'</span><span>,</span><br>    family<span>:</span> <span>{</span><br>      name<span>:</span> <span>'Stark'</span><span>,</span><br>      location<span>:</span> <span>'Winterfell'</span><br>    <span>}</span><br>  <span>}</span><br><span>}</span></code></pre><p>So you could do something like this if you wanted the first name of the pet owner</p><pre><code><span>const</span> ownerName <span>=</span> pet<span>.</span>owner<span>.</span>first_name<span>;</span></code></pre><p>But like all things in the universe can't be perfect, our API doesn't guarantee that all the details would be available for any given pet and can be <code>null</code> or <code>undefined</code>.</p><p>In that case, the above line of code can result and the following error "Reference error cannot read property <code>first_name</code> of <code>null</code>" and crash your app if the owner is <code>null</code>.</p><p>This is where <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Optional_chaining">optional chaining</a> saves you. The optional chaining operator (<code>?.</code>) allows you to read the property deep in the chain without having to validate whether the chain is valid, and instead of a reference error, it would return the same old <code>undefined</code>.</p><p>So we could easily check for the owner name or even the owner family name without worrying about any errors, like this -</p><pre><code><span>const</span> ownerName <span>=</span> pet<span>?.</span>owner<span>?.</span>first_name<span>;</span><br><span>const</span> ownerFamily <span>=</span> pet<span>?.</span>owner<span>?.</span>family<span>?.</span>name<span>;</span></code></pre><blockquote><p>Optional chaining can also be used with function calls on properties you are not really sure to exist. For instance, you can do this with an array <code>friends?.join(",")</code> , this won't result in an error if friends is anything other than an array, even <code>undefined</code>.</p></blockquote><p>Now, this would avoid errors but you still wouldn't want your users to show <code>undefined</code> in case it is not available. This is where Nullish Coalescing comes in -</p><pre><code><span>const</span> ownerName <span>=</span> pet<span>?.</span>owner<span>?.</span>first_name <span>??</span> <span>'Unknown'</span><span>;</span></code></pre><p>The <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Nullish_coalescing_operator">Nullish Coalescing operator</a> (<code>??</code>) returns the right hand side operand when the left hand side is <code>null</code> or <code>undefined</code> and otherwise it returns the left hand side operand.</p><p>You might think here that the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Logical_OR">Logical Or operator</a> (<code>||</code>) would also have done the same thing. Well in that case I hope you haven't forgotten the truthy and falsy hell of JavaScript that we just covered. Since this operator would return the right hand side operand for all falsy values and can cause hard to debug errors as mentioned in the previous section.</p><blockquote><p>Since these methods were recently released with <a href="https://auth0.com/blog/javascript-whats-new-es2020/">ECMAScript 2020 spec</a> browser compatibility for these methods is still in the preliminary stages and only the modern browsers support it right now.</p><p>But don't worry most setups we use to compile our apps have already got us covered. If you're using TypeScript ‚â• 3.7 then <a href="https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-7.html">these methods are supported out of the box</a>.</p><p>Else if you're using a typical Webpack + babel setup then you can include the <a href="https://babeljs.io/docs/en/babel-plugin-proposal-optional-chaining"><code>@babel/plugin-proposal-optional-chaining</code></a> and <a href="https://babeljs.io/docs/en/babel-plugin-proposal-nullish-coalescing-operator"><code>@babel/plugin-proposal-nullish-coalescing-operator</code></a> plugins in your babel config to support these methods.</p></blockquote><h2><a id="4-avoid-premature-optimization" href="#4-avoid-premature-optimization"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg> 4. Avoid premature optimization</a></h2><p>Be really careful when you want to memoize something in React, because if not done properly it might lead to even worse performance.</p><p>I have often seen people prematurely optimizing everything they come across without considering the cost it comes with. For instance, using <code>useCallback</code> in situations like this -</p><pre><code><span>const</span> <span>MyForm</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> <span>[</span>firstName<span>,</span> setFirstName<span>]</span> <span>=</span> React<span>.</span><span>useState</span><span>(</span><span>''</span><span>)</span><span>;</span><p>  <span>const</span> <span>handleSubmit</span> <span>=</span> <span>event</span> <span>=&gt;</span> <span>{</span><br>    <br>  <span>}</span><span>;</span></p><p>    <br>  <span>const</span> handleChange <span>=</span> React<span>.</span><span>useCallback</span><span>(</span><span>event</span> <span>=&gt;</span> <span>{</span><br>    <span>setFirstName</span><span>(</span>event<span>.</span>target<span>.</span>value<span>)</span><span>;</span><br>  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span></p><p>  <span>return</span> <span>(</span><br>    <span><span><span>&lt;</span>form</span> <span>onSubmit</span><span><span>=</span><span>{</span>handleSubmit<span>}</span></span><span>&gt;</span></span><span><br>      </span><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>firstName<span>"</span></span> <span>onChange</span><span><span>=</span><span>{</span>handleChange<span>}</span></span> <span>/&gt;</span></span><span><br>      </span><span><span><span>&lt;</span>button</span> <span>type</span><span><span>=</span><span>"</span>submit<span>"</span></span> <span>/&gt;</span></span><span><br>    </span><span><span><span>&lt;/</span>form</span><span>&gt;</span></span><br>  <span>)</span><span>;</span><br><span>}</span><span>;</span></p></code></pre><p>Now you might've heard that <code>useCallback</code> is known to improve performance by memoizing the function and only updating it when the dependencies change. That is true but you need to understand that <strong>every optimization comes with a cost associated with it</strong>.</p><p>In the above case, you are doing more work by creating a <code>useCallback</code> which in itself is running some logical expression checks, hence you're better off with just defining the inline function directly like this -</p><pre><code><span>const</span> <span>handleChange</span> <span>=</span> <span>event</span> <span>=&gt;</span> <span>{</span><br>    <span>setFirstName</span><span>(</span>event<span>.</span>target<span>.</span>value<span>)</span><span>;</span><br><span>}</span><span>;</span></code></pre><p>The same things apply with <code>React.memo</code>. If you have a component like this that accepts children props, then memoizing the component is basically useless if the children are not memoized -</p><pre><code><span>const</span> UselessMemoizedHeader <span>=</span> React<span>.</span><span>memo</span><span>(</span><span>(</span><span><span>{</span> children <span>}</span></span><span>)</span> <span>=&gt;</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>{</span>children<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>)</span><span>;</span><p><span>const</span> <span>SomeComponent</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> <span>[</span>count<span>,</span> setCount<span>]</span> <span>=</span> React<span>.</span><span>useState</span><span>(</span><span>0</span><span>)</span><span>;</span><br>  <span>return</span> <span>(</span><br>    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span><br>      </span><span><span><span>&lt;</span><span>UselessMemoizedHeader</span></span><span>&gt;</span></span><span><br>        </span><span><span><span>&lt;</span>span</span><span>&gt;</span></span><span>Header</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span><br>      </span><span><span><span>&lt;/</span><span>UselessMemoizedHeader</span></span><span>&gt;</span></span><span><br>      Count: </span><span>{</span>count<span>}</span><span><br>      </span><span><span><span>&lt;</span>button</span> <span>type</span><span><span>=</span><span>"</span>button<span>"</span></span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>currentCount</span> <span>=&gt;</span> currentCount <span>+</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span><br>        Increment count<br>      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span><br>    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br>  <span>)</span><span>;</span><br><span>}</span><span>;</span></p></code></pre><p>In the above case, the <code>UselessMemoizedHeader</code> component would re-render every time you increment the count even though you might think it is memoized.</p><p>But why? Since memo just does a shallow comparison of the current props and previous props, and because the children prop won't be <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Equality_comparisons_and_sameness">refrentially equal</a> you end up re-rendering the <code>UselessMemoizedHeader</code> component every time the count changes.</p><p>Your code ends up being even worse off because of that unnecessary children prop comparison on every render.</p><p>So when do you actually need to memoize? Well Kent C. Dodds <a href="https://kentcdodds.com/blog/usememo-and-usecallback">covers all the above things with when you should memoize in great detail</a> ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prateeksurana.me/blog/javascript-tips-for-react-developers/">https://prateeksurana.me/blog/javascript-tips-for-react-developers/</a></em></p>]]>
            </description>
            <link>https://prateeksurana.me/blog/javascript-tips-for-react-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295794</guid>
            <pubDate>Sun, 28 Feb 2021 18:36:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tools I use to protect my privacy online]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26295775">thread link</a>) | @sdas7
<br/>
February 28, 2021 | https://consult.sauvik.me/posts/stay-safe-online/ | <a href="https://web.archive.org/web/*/https://consult.sauvik.me/posts/stay-safe-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It shouldn‚Äôt have to be this way, but the burden of protecting your privacy as you browse the web is your own. I do what I can in my research and consulting to advocate for systemic change in design and policy to reduce the burden on the individual user; but that kind of change is slow to fruit. Meanwhile, there are tools that you, the individual, can use to partially protect yourself against the forces of surveillance capitalism and other institutional privacy threats. I will share five that I use myself.</p><hr><h2 id="i-use-the-dashlane-vpn-to-curtail-web-tracking-and-circumvent-regional-content-filters">I use the Dashlane VPN to curtail web tracking and circumvent regional content filters</h2><p>You probably already know about Virtual Private Networks (VPNs). If you work at a sufficiently large institution, chances are your workplace has one in place to allow you remote access to the institution‚Äôs intranet. VPNs do more than helping employers facilitate secure intranet access, however. VPNs help obfuscate your web traffic ‚Äî both from the websites you visit, and from your Internet Service Provider (e.g., Verizon, Comcast, AT&amp;T).</p><p>Eliding key technical details, you can think of a VPN as a middleman / intermediary between you and the Internet-at-large. While this slows down your connection slightly, the benefit is that the rest of your web traffic is encrypted and routed through this middleman. This provides privacy benefits because, without the use of something like a VPN, ISPs can track every website you visit online. If you visit websites over plain HTTP (instead of HTTPS), they can only track what you do on those websites. And any personal data that your ISP keeps on you can be subpoena‚Äôd by, e.g., law enforcement. Moreover, ISPs can sell this information freely ‚Äî e.g., to advertising brokers, who may want to sell you targeted ads based on the websites you have frequented. You consented to this when you agreed to their terms of service.</p><p>Does that sound a little shady? It is! There are only a handful of ISPs in the country; in specific regions, there may be only one. And they work tirelessly to make sure that competitors cannot make headway. So most people do not have a real choice when it comes to their ISP. They agree to the terms because what else can they do if they want Internet?</p><p>Using a VPN service, the ISP will no longer be able to see what you download and what websites you visit. They <em>will</em> be able to see some meta-data, however ‚Äî e.g., that you are using a VPN, the encrypted data you are receiving and when you are connecting.</p><p>VPNs also allow you to hide or disguise yourself from the websites you visit. Indeed, many VPNs have servers all over the world. So, if there is content that is being blocked in the U.S. but not in Germany, you can use a VPN to make it seem like you are connecting from Germany.</p><p>The downside? Middlemen are usually inefficient ‚Äî and indeed, using a VPN will make your connection a little slower than if you were to not use it. Also, private VPN services cost money ‚Äî&nbsp;usually between $5 and $15 / month. Moreover, you are simply displacing trust from the ISP to the VPN service. While your ISP will not be able to see the websites you visit, the VPN service will be able to. Because of this, as a part of their terms of service, good private VPN services should be stateless ‚Äî they should not keep any record of the websites you visit through the VPN. This is also why you probably do <em>not</em> want to use your corporate VPN for surfing the web privately ‚Äî&nbsp;your employer will be able to see your web traffic if you do so.</p><p>Private VPN services are now common ‚Äî some popular private VPN services include Express VPN and Nord VPN. I have not used either, so I will not comment on them. But I know many people who use those services and have not heard any direct complaints.</p><p>I use the Dashlane VPN, and it works great. I use the Dashlane VPN because I use the Dashlane premium password manager, and the VPN service is included in the fee I pay for Dashlane premium. If you would like to try Dashlane premium for free for six months, you may use <a href="https://www.dashlane.com/cs/s23HfOIFsAxE">this referral link</a>.</p><h2 id="i-use-firefox-with-ublock-origin--decentraleyes-for-curtailing-web-trackers-while-browsing">I use Firefox with uBlock Origin + Decentraleyes for curtailing web trackers while browsing</h2><p>ISPs are just one threat to your privacy; many of the websites you visit also track and store as much information about you as they can ‚Äî the websites you visit, what you do on them, at what time of day, etc. Why? Because the prevailing business model of the web is surveillance capitalism ‚Äî keeping track of your personal data allows advertisers to develop rich profiles of what you like and what they would like you to like. These data, in turn, can be used to serve you with personalized advertisements ‚Äî&nbsp;and it‚Äôs important to note that these advertisements are not just obvious ones like Nike shoes you might like, but also things like article recommendations from political campaigns.</p><p>Stopping this tracking and nudging is not easy, but it starts with your choice of web browser. If you care about privacy, do not use web browsers released by institutions that have little vested interest in protecting your personal data.</p><p>I use Firefox. Firefox has some nice in-built or officially supported privacy-preserving features ‚Äî e.g., automated tracking prevention and containers. Containers help you isolate cookies to prevent third-party tracking. For example, with the Facebook container add-on on Firefox, you can be assured that Facebook cookies will not be</p><p>In addition to these in-built features, I also use a few extensions to further subvert tracking efforts. The most important is <a href="https://ublockorigin.com/">uBlock Origin</a>, an extension that automatically blocks thousands of known tracking scripts and advertisements. The second is <a href="https://decentraleyes.org/">Decentraleyes</a>, which blocks requests for common scripts distributed through centralized CDNs and provides local versions of those scripts instead ‚Äî e.g., for Google fonts. This prevents the hosts of those CDNs (often large companies like Google, Microsoft, Facebook) from tracking which websites you visit when those websites request content from those CDNs. Both of these extensions are open source; so I trust them more than I do less transparent alternatives like Ghostery.</p><p>Other privacy enthusiasts use Brave instead of Firefox. Brave is a relatively new web browser that has in-built tracker protection. It is also piloting an interesting new business model for <a href="https://brave.com/intro-to-brave-ads/">privacy-preserving targeted ads</a> ‚Äî&nbsp;the goal is to match a local ‚Äúinterests‚Äù profile that never leaves your computer with a set of candidate advertisements; this way, you get targeted advertisements without being tracked by a remote entity.</p><p>So why do I use Firefox and not Brave? I used to use Brave; I like Brave. But it started getting very slow for collaborative text editing on Overleaf on my machine. So, I switched to Firefox as my primary browser because I spend a lot of time writing papers on overleaf. There is also <a href="https://www.coindesk.com/brave-browsers-affiliate-link-controversy-explained">refer gate</a> ‚Äî i.e., Brave‚Äôs autocompleting of urls to cryptocurrency webpages to append their own affiliate codes. This has since been fixed, but it did build some enmity with the community.</p><p>My main qualm with Firefox is that while Mozilla is doubling down on its identity as a consumer privacy company, <a href="https://www.ghacks.net/2020/12/10/mozillas-revenue-jumped-to-828-million-u-s-dollar-in-2019/">the majority of its revenues do still come from Google ads</a> ‚Äî when you search for something through the Mozilla browser and you click on an ad on Google, Mozilla gets a royalty. While this is not a direct conflict of interest, it does mean that Mozilla profits from surveillance capitalism, too.</p><h2 id="i-use-protonmail-for-secure-encrypted-email-that-is-not-tracked-or-analyzed">I use ProtonMail for secure, encrypted email that is not tracked or analyzed</h2><p>Would it surprise you to learn that many free email services analyze your email? It shouldn‚Äôt; it‚Äôs how spam detection works, for example. But services like Gmail analyze your email for a lot more than spam detection. As with most other Google services, Gmail is beautiful, fast, usable and free. But in using it, you consent to Google being able to track what you say, what people are saying to you, and who you know. That information can be used by Google to learn more about you and your interests to serve you personalized ads; it can also be subpoena‚Äôd by the government.</p><p>I won‚Äôt dwell on this point for long, because most people understand email privacy without me needing to delve into the technical details. There are many secure email alternatives to Gmail now; what you are looking for, again, is service provided by a company that does not make its money from collecting personal data. Ideally, you will also want to find a company with servers hosted in a country with stronger consumer privacy protections ‚Äî&nbsp;e.g., Switzerland or Estonia.</p><p>I use <a href="https://protonmail.com/">ProtonMail</a>. It has a clean interface, and provides a host of nice security features (included end-to-end encryption and self-destructing messages).</p><h2 id="i-use-signal-for-end-to-end-encrypted-messaging">I use Signal for end-to-end encrypted messaging</h2><p>For all the same reasons that you might want privacy-preserving email, you want privacy-preserving messaging as well and this means a messaging service that utilizes end-to-end encryption (E2EE). E2EE means that only the sender and intended receivers will be able to read the messages. Nobody else ‚Äî not even the service it self ‚Äî will be able to read the messages.</p><p>While there are a number of E2EE messaging applications on the marketplace, I use and recommend Signal for two reasons. First, security in theory is different than security in practice. The Signal protocol is open-source and has been vetted by many in the security community, and so it easier to trust its security ‚Äúin practice‚Äù. Second, at least partially owing to WhatsApp‚Äôs recent announcement that it will share data with Facebook, a lot of people now use Signal ‚Äî and that‚Äôs important because a messenger is only useful if the person you want to message uses it! In fact, some research I did back in 2016 found that the key driver of secure messaging use was not promises of security, but simply the presence of one‚Äôs friends on the platform <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p><h2 id="i-use-duckduckgo-for-tracking-free-search">I use DuckDuckGo for tracking-free search</h2><p>If you are reading this blog post, I do not think I have to convince you that search engines like Google track ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://consult.sauvik.me/posts/stay-safe-online/">https://consult.sauvik.me/posts/stay-safe-online/</a></em></p>]]>
            </description>
            <link>https://consult.sauvik.me/posts/stay-safe-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295775</guid>
            <pubDate>Sun, 28 Feb 2021 18:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lean into Procrastination]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26295774">thread link</a>) | @patapizza
<br/>
February 28, 2021 | https://jodent.io/posts/lean-into-procrastination | <a href="https://web.archive.org/web/*/https://jodent.io/posts/lean-into-procrastination">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jodent.io/posts/lean-into-procrastination</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295774</guid>
            <pubDate>Sun, 28 Feb 2021 18:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI predicting West Nile virus spread a year in advance]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295681">thread link</a>) | @finphil
<br/>
February 28, 2021 | https://nuadox.com/post/644387293574184960/west-nile-virus-spread-prediction-by-ai | <a href="https://web.archive.org/web/*/https://nuadox.com/post/644387293574184960/west-nile-virus-spread-prediction-by-ai">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="644387293574184960">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/644387293574184960/west-nile-virus-spread-prediction-by-ai"><h2>AI predicting West Nile virus spread a year in advance</h2></a>
                                <figure data-orig-width="900" data-orig-height="700"><img src="https://64.media.tumblr.com/6d4b5597d2410a01dd242305d3a0d8a6/b8b4249dffa8bc7c-6b/s1280x1920/ee7687d3fba44a7cbe56fc04f1ea37f9549b2169.jpg" alt="image" data-orig-width="900" data-orig-height="700" width="900" height="700"></figure><p><b>- By <a href="https://href.li/?https://www.uma.es/">University of Malaga</a> -</b></p><p>Knowing the environmental and human-related variables that characterize the favorable areas for the incidence of the West Nile virus, a flavivirus that is transmitted from birds to humans by mosquitoes, is essential to identify those places in Europe at high risk of experiencing outbreaks, even before these are registered, thus enabling preventive measures to be taken.</p><p>Researchers of the Biogeography, Diversity and Conservation Group of the University of Malaga have developed risk models for West Nile Fever, the disease caused in humans by this virus, which, based on historical incidence data, may predict areas of future outbreaks a year in advance, as well as detect their intensity.</p><h2><b>Artificial intelligence to develop risk models</b></h2><p>Particularly, using modelling based on fuzzy logic and artificial intelligence, they have analyzed the incidence of the disease in Europe in 2017 to explain and restate the ‚Äúabnormally high‚Äù data of 2018, the year with the highest number of cases registered so far, a total of 1605. The results have been recently published in the scientific journal <i><a href="https://href.li/?https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0009022">PLoS Negl Trop Dis</a></i>.</p><p>‚ÄúBased on the analyzed data, we could successfully predict the places where the disease appeared, the intensity of outbreaks and the time they occurred‚Äù, explains Raimundo Real, scientist of the Animal Biology Department of the UMA.</p><p>This expert asserts that anticipating the possible incidence of the disease may lead to taking preventive measures specifically in risk areas. These measures include early spraying, advising the population on measures to avoid bites or controlling the water points where mosquitoes breed. Likewise, healthcare centers could be warned about the possible disease incidence in the area, contributing to early diagnosis and improving prognosis.</p><h2><b>Spatial and environmental variables</b></h2><p>For the development of the risk maps, the researchers used a spatial model related to bird migration routes, which act as reservoir of the virus. On the other hand, they determined that the environmental risk factors are high temperatures, presence of river courses, low altitude areas, which usually have a warmer climate and conditions of higher humidity, and the presence of certain livestock facilities, such as stables and poultry farms, which, as they assure, are the most favorable factors for the spread of the virus.</p><p>‚ÄúWe have observed that high temperatures speed up the life cycles of mosquitoes, shortening their gonotrophic cycle -period between the time mosquitoes feed on blood and the time they feed again-, therefore, in warmer areas mosquito bite rate is also higher, facilitating the transmission of the virus‚Äù, emphasizes the professor of the UMA.</p><h2><b>Early warning: basin scale</b></h2><p>Likewise, rivers are related to the presence and proliferation of mosquitoes, so rivers also contribute to a higher infection rate.</p><p>‚ÄúIn 2017, the outbreaks began in the lower areas of large river basins and spread to higher areas, which highlights the importance of river basins in the propagation of outbreaks‚Äù, says Raimundo Real, who adds that, consequently, the early warning should be based on a basin scale.</p><p>This way, the Head of the Animal Biology Department of the UMA states that some Spanish provinces of western Andalusia, southern Extremadura and southwestern Castilla-La Mancha, especially the lowest areas of the Guadalquivir and Guadiana valleys, are European sites that are environmentally favorable for the transmission of the disease, which directly affects the human nervous system.</p><p>‚Äì</p><p><b>Source: <a href="https://href.li/?https://www.eurekalert.org/pub_releases/2021-02/uom-rmt022421.php">University of Malaga</a></b></p><p><b>Full study:</b>&nbsp;‚ÄúPredicting the spatio-temporal spread of West Nile virus in Europe‚Äù,&nbsp;<i>PLoS Negl Trop Dis</i>.</p><p><a href="https://href.li/?https://doi.org/10.1371/journal.pntd.0009022">https://doi.org/10.1371/journal.pntd.0009022</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/160986245127/infecting-mosquitoes-with-bacteria-so-they-cant">Infecting mosquitoes with bacteria so they can‚Äôt infect us with viruses like Zika and dengue</a><br></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/west-nile-virus">west nile virus</a>
                                    
                                        <a href="https://nuadox.com/tagged/virus">virus</a>
                                    
                                        <a href="https://nuadox.com/tagged/ai">ai</a>
                                    
                                        <a href="https://nuadox.com/tagged/artificial-intelligence">artificial intelligence</a>
                                    
                                        <a href="https://nuadox.com/tagged/infectious-diseases">infectious diseases</a>
                                    
                                        <a href="https://nuadox.com/tagged/earth-science">earth science</a>
                                    
                                        <a href="https://nuadox.com/tagged/animals">animals</a>
                                    
                                        <a href="https://nuadox.com/tagged/insects">insects</a>
                                    
                                        <a href="https://nuadox.com/tagged/mosquitoes">mosquitoes</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/644387293574184960/west-nile-virus-spread-prediction-by-ai</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295681</guid>
            <pubDate>Sun, 28 Feb 2021 18:25:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The A-Z80 FPGA CPU (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295630">thread link</a>) | @mariuz
<br/>
February 28, 2021 | https://baltazarstudios.com/z80-cpu/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80-cpu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>This article contains a brief overview and a background of the&nbsp;<em>A-Z80</em> CPU created for FPGA boards and a <em>ZX Spectrum</em> implementation tied to it.</p>
<p>(You can find the Russian translation of this article here: <a href="https://howtorecover.me/z80-s-nulya" target="_blank" rel="noopener noreferrer">https://howtorecover.me/z80-s-nulya</a>)<br>
<span id="more-1108"></span></p>
<p>Every so often I let go of all that's on my mind and simply brainstorm and play with new ideas and their combinations (mostly based on the retro stuff). Then I pick what seems to excite me the most and deep dive into it.</p>
<figure id="attachment_1156" aria-describedby="caption-attachment-1156"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/ideas.jpg"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-512x341.jpg" alt="(partial) list of brainstorming ideas (2014)" width="512" height="341" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-512x341.jpg 512w, https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-150x100.jpg 150w, https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-1024x683.jpg 1024w, https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-960x640.jpg 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/ideas.jpg 1039w" sizes="(max-width: 512px) 100vw, 512px"></a><figcaption id="caption-attachment-1156">(partial) list of brainstorming ideas (2014)</figcaption></figure>
<p>This time (early 2014), I wanted to re-make a <em>Sinclair ZX Spectrum</em> on an <strong>FPGA</strong>. There were already several implementations available and most of them used "off the shelf" components. One could simply pluck components written in Verilog (CPU, ULA) and with some glue logic quickly build a retro FPGA solution. There is no fun in doing that - or at least nothing much to learn about each component as one could learn by creating them from scratch.</p>
<p>I wanted to start with the Zilog Z80 CPU. Since the real people design their own CPUs (right?!), I decided I would make my own version of it. üôÇ</p>
<p>Both parts of this project (the&nbsp;<a title="A Z80 From the Ground Up" href="https://baltazarstudios.com/z80-ground/" target="_blank" rel="noopener noreferrer">A-Z80 CPU</a> and a <a title="Sinclair ZX Spectrum on the A-Z80" href="https://baltazarstudios.com/sinclair-zx-spectrum-z80/" target="_blank" rel="noopener noreferrer">ZX Spectrum</a> code that uses it) are fully described in separate blogs, and here I will try to tie them together using a somewhat less technical narrative.</p>
<p>I started reverse-engineering Zilog Z80 CPU about a year ago by running a working chip on a&nbsp;custom Arduino dongle board. I described it <a href="https://baltazarstudios.com/arduino-zilog-z80/" target="_blank" rel="noopener noreferrer">here</a>. It was interesting to see how the pins responded to various scenarios. I was mostly interested in <a href="https://baltazarstudios.com/zilog-z80-undocumented-behavior/" target="_blank" rel="noopener noreferrer">undocumented behaviour</a>&nbsp;hoping it will give me some hints on the CPU's internal architecture.</p>
<p>Then, I've found a set of articles by Ken Shirriff who actually reverse-engineered large portions of&nbsp;the&nbsp;Z80 from an image of a die. I've found the knowledge of "reading a die image" very exciting and the skill (in a weird way) very useful, so painstakingly I've learned to do the same. I reverse engineered a few other pieces of that silicon, like the <a href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noopener noreferrer">IR</a> register and a <a href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noopener noreferrer">data pin</a>. Soon I got a hang of it&nbsp;and started "reading" other parts, as needed. It felt like a whole new world opened right in front of my eyes! Not much unlike stereogram images: as you look at it long enough, gates suddenly pop up in your mind and you start seeing transistors, pull-ups and latches out of a tangled mesh of colorful flat traces.</p>
<p>I had purchased an Altera FPGA board with a desire to learn that technology after working on a project at my work which was using one, quite beefy, Altera chip. Designing a circuitry on my own, I felt, was an exciting challenge and a great learning opportunity. Soon, I figured out how Verilog/SystemVerilog "works"; a language not too difficult to learn for any software person. I also brushed up on a logic design (I had one lousy taught EE class some 20 years ago).</p>
<p>Long story short, I started implementing selected parts of Z80 in the <em>Quartus</em> schematic editor and wrote related&nbsp;<em>ModelSim</em> tests one by one: first came the ALU (since it's design was well described by Ken), then the register file, sequencer, etc. Frankly, I did not know how would all of that fit or work <em>together</em>; I was simply enjoying the process, one block at a time. I just <em>loved</em> seeing wires toggling and gates doing their thing in a&nbsp;ModelSim simulation: a certain deep understanding of a digital design sank in while playing with it.</p>
<p><a href="https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-512x307.png" alt="modelsim_run" width="512" height="307" srcset="https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-512x307.png 512w, https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-150x90.png 150w, https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-1024x615.png 1024w, https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-960x577.png 960w, https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run.png 1680w" sizes="(max-width: 512px) 100vw, 512px"></a></p>
<p>I also read all I could get my hands on: patents on Z80 (and other CPUs) which provided valuable insights; talks, lectures and over time I got a pretty good ideas on how it all&nbsp;<em>should</em>&nbsp;work.</p>
<p>The most complicated task was to create the instruction timing matrix. Using all the information gathered in the process, I created an Excel spreadsheet with the exact timing of required micro-operations for each M (machine) and T (clock) stated of each opcode class.</p>
<p>This matrix defines the CPU and ensures it is fully Z80-compatible. In fact, if you modify it, you could create new instructions, enhance the CPU or even create a completely different one and the design would still just work!</p>
<p>The following set of images show the complete timing matrix printed from <a href="https://baltazarstudios.com/webshare/A-Z80/timings.xps" target="_blank" rel="noopener noreferrer">this XPS file</a>. It is printed into 8 consecutive images; click on each to see it in a full, readable size:</p>
<figure id="attachment_1159" aria-describedby="caption-attachment-1159"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-116x150.png" alt="A-Z80 Timings 1/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1159">A-Z80 Timings 1/8</figcaption></figure>
<figure id="attachment_1160" aria-describedby="caption-attachment-1160"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-116x150.png" alt="A-Z80 Timings 2/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1160">A-Z80 Timings 2/8</figcaption></figure>
<figure id="attachment_1161" aria-describedby="caption-attachment-1161"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-116x150.png" alt="A-Z80 Timings 3/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1161">A-Z80 Timings 3/8</figcaption></figure>
<figure id="attachment_1162" aria-describedby="caption-attachment-1162"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-116x150.png" alt="A-Z80 Timings 4/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1162">A-Z80 Timings 4/8</figcaption></figure>
<figure id="attachment_1163" aria-describedby="caption-attachment-1163"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-116x150.png" alt="A-Z80 Timings 5/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1163">A-Z80 Timings 5/8</figcaption></figure>
<figure id="attachment_1164" aria-describedby="caption-attachment-1164"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-116x150.png" alt="A-Z80 Timings 6/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1164">A-Z80 Timings 6/8</figcaption></figure>
<figure id="attachment_1165" aria-describedby="caption-attachment-1165"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-116x150.png" alt="A-Z80 Timings 7/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1165">A-Z80 Timings 7/8</figcaption></figure>
<figure id="attachment_1166" aria-describedby="caption-attachment-1166"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-116x150.png" alt="A-Z80 Timings 8/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1166">A-Z80 Timings 8/8</figcaption></figure>
<p>Each column, <strong>B</strong> through <strong>AH</strong>, contains zero or more micro-operations on specific internal design blocks (<a href="https://baltazarstudios.com/webshare/timing_macros.i.html" target="_blank" rel="noopener noreferrer">this file</a> deciphers the tokens used). Groups of instructions are listed in a row as statically decoded by the PLA table, each line corresponding to specific M and T cycle.</p>
<p>Rather early in the process, I devised several tests, including a&nbsp;full <em>Fuse</em>-based test suite which could run every instruction against a set of known results. That test proved the most valuable: it enabled to flag regressions as well as to check that the instructions were implemented correctly.</p>
<p>After some time, I was able to combine several Z80 instructions and run them in sequence. Enjoying many exciting milestone moments along the way, the one that stuck was when the PC register correctly incremented and was fetching successive instructions. They were also correctly executed since each one was tested separately: it all just worked!</p>
<p>After adding a virtual UART module in Verilog, I was able to get simple "Hello, world" programs sending the text out to a terminal! The same output would be captured by&nbsp;ModelSim simulating that code. It proved very helpful having several different ways to test and correlate the results.</p>
<p>The most difficult part was getting the interrupt handling done just right. Z80 has 3 interrupt modes (im0, im1, im2), maskable INT with two flags (the enable bit and its shadow) and non-maskable NMI. INT is level-triggered while the NMI is latched, edge-triggered and has precedence over INT. The pins should be checked at known times and be inhibited in certain situations, including during the execution of some instructions. It all needed to be working perfectly at known clock boundaries.</p>
<p>The solution ended up very elegant and used minimum number of extra gates: besides necessary state flags and priority logic, it used a couple of control signals wired just right: see the timings page 7, lines 1028-1060, entry "rst p" and how the instruction RST38 is being used to handle both NMI and INT (im2) at the same time. You start seeing a beauty of the original Mr. Faggin's design when you realize the coherence of the known behavior and the most optimal implementation. The simplicity of it became the proof of the implementation.</p>
<p>Once the CPU was wrapped up, it could run any code sequence using any instruction assembled and pushed onto a simple "board" model. That included some devilish and mean-designed interrupt-bombardment tests. It also run well known ZEXDOC and ZEXALL programs. They all passed except several XF/YF (undocumented flags) behavioral tests for 2 sets of instructions. Those are <em>really</em> weird and if you have ever played with Z80 emulators you would know what I mean. This particular Z80 behavior is likely a side-effect of internal bus charge/discharge cycles and some spurious control signals; various second-sourced and cloned Z80 chips also behave differently in these scenarios. I decided not to sweat over it as it had no practical impact.</p>
<p>Frankly, at this stage, I was already satisfied with the results since my original goal was to understand and replicate the internal architecture of the Z80, and I have achieved it.</p>
<p>Compare the following image - a conceptual block diagram of the A-Z80 CPU - with the annotated image of a Z80 die from the top&nbsp;of this article to see the similarity in the layout. I have placed schematic modules at the locations roughly corresponding to their positions on the Z80 die. Not to scale. You should be able to trace major buses (data bus in green and address bus in red) and zoom into detailed diagrams to see gate level implementations of the blocks. A few System Verilog sources appear just symbolically; naturally, the complete code would not fit on a printed page. Open it up in an image viewer that can zoom and pan.</p>
<figure id="attachment_1184" aria-describedby="caption-attachment-1184"><a href="https://baltazarstudios.com/webshare/A-Z80/a-z80-block-diagram.psd" target="_blank" rel="https://drive.google.com/file/d/0bykupmks9xs3awetblndzuczrfu/view?usp=sharing noopener noreferrer"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/a-z80-block-diagram-thumb.png" alt="A-Z80 block diagram (thumb)" width="256" height="175" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/a-z80-block-diagram-thumb.png 256w, https://baltazarstudios.com/wp-content/uploads/2015/01/a-z80-block-diagram-thumb-150x103.png 150w" sizes="(max-width: 256px) 100vw, 256px"></a><figcaption id="caption-attachment-1184">A-Z80 block diagram; click to expand</figcaption></figure>
<p>By that time, I was already fairly fluent in Verilog so the coding of a <em>ZX Spectrum</em> model was not a problem. First, I added a video unit by picking one (most suitable) VGA timing standard and was able to display static screens from various games. Then came the correct character blink and border behavior. After that: keyboard interface, speaker, mic - all fairly simple modules. Once I got all internal mappings correctly set up, I powered it up, flashed it with the newest FPGA file and, to my huge excitement, saw a black screen clearing up and the magic "<strong>(C) 1982 Sinclair Research Ltd</strong>" prompt on the screen! I can't tell you just how exciting that moment was; I kept resetting it over and over just to see it appearing again!</p>
<p>Soon I was able to load and play games!</p>
<figure id="attachment_1186" aria-describedby="caption-attachment-1186"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon.jpg"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-512x341.jpg" alt="The Legend of Avalon, Graftgold Ltd, 1984" width="512" height="341" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-512x341.jpg 512w, https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-150x100.jpg 150w, https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-1024x683.jpg 1024w, https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-960x640.jpg 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon.jpg 1152w" sizes="(max-width: 512px) 100vw, 512px"></a><figcaption id="caption-attachment-1186">The Legend of Avalon, Graftgold Ltd, 1984</figcaption></figure>
<p>But, there was one problem: the design would randomly reboot or lock up. I spent a long time debugging it but a chance conversation with Ed (a co-worker of mine, Ed is a world-class chip designer who <em>really</em> knows this stuff) would reveal a possible problem: trying to follow the exact Z80 architecture, I have used transparent latches in my FPGA design throughout. Well, no FPGA designs use latches these days. Ed told me a latch design would have never worked [reliably]. Well, I <em>did</em> make it work, somehow. Kind of.</p>
<p>Back to the drawing board and one month later, I have re-implemented the whole design to use flip-flops. Accordingly, I also had to modify a few timings here and there. The new design is fully synchronous and meets all&nbsp;timings; it is being checked using the&nbsp;<em>TimeQuest</em> static timing analyzer tool and have fully constrained timings (using SDC files). In the meantime, I've also found and fixed several issues including one important bug fix in the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80-cpu/">https://baltazarstudios.com/z80-cpu/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80-cpu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295630</guid>
            <pubDate>Sun, 28 Feb 2021 18:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Libp2p]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295374">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://proto.school/introduction-to-libp2p/ | <a href="https://web.archive.org/web/*/https://proto.school/introduction-to-libp2p/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-64098914=""><p data-v-64098914=""><svg data-v-64098914="" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 112 129" style="height: 23px;"><path d="M111.498 75.118l-18.43 10.563-.158.078v21.413l18.588-10.64V75.118z" fill="#A33768"></path><path d="M92.91 85.76L74.48 96.321l-.157.079v21.413l18.587-10.642V85.759z" fill="#3DA1BD"></path><path d="M18.587 106.911V85.498L0 74.752V96.14l18.587 10.771zM37.175 117.683V96.27L18.588 85.498v21.413l18.587 10.772z" fill="#81D2E0"></path><path d="M55.762 128.455v-21.413L37.175 96.27v21.414l18.587 10.771z" fill="#36A4CB"></path><path d="M74.324 96.4L55.92 106.963l-.157.079v21.413l18.56-10.641V96.4z" fill="#3DA1BD"></path><path d="M111.499 53.757l-18.592 10.62-.022 21.408h.026l18.561-10.614.027-21.414z" fill="#994FA0"></path><path d="M92.91 64.373L74.48 74.935l-.157.079v21.413l18.587-10.64V64.372v.026-.026z" fill="#994FA0"></path><path d="M18.587 85.498V64.111L0 53.313v21.413l18.587 10.772z" fill="#FFC41A"></path><path d="M37.15 96.27l.025-21.387-18.587-10.798v21.413L37.149 96.27z" fill="#F39B35"></path><path d="M55.736 107.068V85.655L37.175 74.883l-.027 21.386.027.027 18.56 10.772z" fill="#38727B"></path><path d="M74.324 75.014L55.894 85.55l-.158.105v21.413l18.588-10.641V75.014z" fill="#1C6B7D"></path><path d="M55.736 21.442l.218-.122 18.37-10.52L55.735.028 37.175 10.67l18.561 10.773z" fill="#C4CD46"></path><path d="M74.324 32.214l.157-.105 18.43-10.537L74.324 10.8 55.736 21.442l18.588 10.772z" fill="#F064A4"></path><path d="M92.91 42.986l.158-.105 18.404-10.537L92.91 21.572 74.323 32.214 92.91 42.986z" fill="#AA6AAB"></path><path d="M111.498 32.344l-18.43 10.537-.158.105v21.387l18.588-10.616V32.344z" fill="#994FA0"></path><path d="M37.175 32.083l.184-.105L55.736 21.44 37.176 10.67 18.587 21.311l18.587 10.772z" fill="#CDDD40"></path><path d="M55.736 42.855l18.587-10.642-18.587-10.772-18.561 10.642 18.561 10.772z" fill="#CDDD40"></path><path d="M74.323 53.626l18.588-10.64-18.588-10.851h-.104.105L55.683 42.88l18.64 10.745z" fill="#8F499E"></path><path d="M92.91 42.96L74.482 53.521l-.157.105-.004 21.398L92.934 64.36l-.023-21.4z" fill="#5F356B"></path><path d="M18.587 42.724l.158-.104 18.43-10.537-18.588-10.772L0 31.952l18.587 10.772z" fill="#FFD75A"></path><path d="M18.587 64.111V42.724L0 31.952v21.413l18.587 10.746z" fill="#FFC41A"></path><path d="M37.2 53.526l18.562-10.668-18.586-10.775L18.57 42.72 37.2 53.526z" fill="#F8B730"></path><path d="M37.175 74.883V53.496L18.588 42.724v21.413l18.587 10.746z" fill="#F39B35"></path><path d="M55.762 64.242l.158-.079 18.409-10.536-18.567-10.773-18.587 10.642L55.762 64.24z" fill="#F8B730"></path><path d="M55.733 85.654l.03-21.412L37.174 53.47v21.413l18.558 10.771z" fill="#F39B35"></path><path d="M74.323 53.627L55.919 64.162l-.157.079v.026l-.032 21.4 18.593-10.655V53.626z" fill="#FAAA36"></path></svg><h2 data-v-64098914="">libp2p</h2></p><div data-v-64098914=""><svg data-v-64098914="" id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" alt="Multiple-choice quizzes" data-original-title="null"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 14.2h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="14.2" r="2.7"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 25h-19.8"></path><circle cx="13.08" cy="25" r="2.7" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 35.8h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="35.8" r="2.7"></circle></svg></div><p>Learn how libp2p solves common networking problems through modularity, aiming to be the de facto peer-to-peer (P2P) library for the decentralized web.</p>
<div data-v-6138d923="" data-v-64098914="" data-tutorial-state="new"><svg data-v-6138d923="" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><path data-v-6138d923="" fill="currentColor" d="M71.13 28.87a29.88 29.88 0 1 0 0 42.26 29.86 29.86 0 0 0 0-42.26zm-18.39 37.6h-5.48V44.71h5.48zm0-26.53h-5.48v-5.49h5.48z"></path></svg><p data-v-6138d923=""><h2 data-v-6138d923="">New</h2><!----></p></div><ul data-v-64098914=""><li data-v-64098914=""><a data-v-62d9e11c="" data-v-64098914="" href="https://proto.school/introduction-to-libp2p/01" data-cy="lesson-link-standard"><div data-v-62d9e11c=""><div data-v-62d9e11c=""><p>Lesson 1</p><p>Why do we need libp2p?</p></div><svg data-v-62d9e11c="" id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" alt="Multiple-choice quiz" data-original-title="null"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 14.2h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="14.2" r="2.7"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 25h-19.8"></path><circle cx="13.08" cy="25" r="2.7" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 35.8h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="35.8" r="2.7"></circle></svg></div></a></li><li data-v-64098914=""><a data-v-62d9e11c="" data-v-64098914="" href="https://proto.school/introduction-to-libp2p/02" data-cy="lesson-link-standard"><div data-v-62d9e11c=""><div data-v-62d9e11c=""><p>Lesson 2</p><p>The current problem with P2P protocols</p></div><svg data-v-62d9e11c="" id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" alt="Multiple-choice quiz" data-original-title="null"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 14.2h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="14.2" r="2.7"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 25h-19.8"></path><circle cx="13.08" cy="25" r="2.7" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 35.8h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="35.8" r="2.7"></circle></svg></div></a></li><li data-v-64098914=""><a data-v-62d9e11c="" data-v-64098914="" href="https://proto.school/introduction-to-libp2p/03" data-cy="lesson-link-standard"><div data-v-62d9e11c=""><div data-v-62d9e11c=""><p>Lesson 3</p><p>Enter libp2p</p></div><svg data-v-62d9e11c="" id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" alt="Multiple-choice quiz" data-original-title="null"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 14.2h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="14.2" r="2.7"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 25h-19.8"></path><circle cx="13.08" cy="25" r="2.7" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 35.8h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="35.8" r="2.7"></circle></svg></div></a></li><li data-v-64098914=""><a data-v-62d9e11c="" data-v-64098914="" href="https://proto.school/introduction-to-libp2p/04" data-cy="lesson-link-standard"><div data-v-62d9e11c=""><div data-v-62d9e11c=""><p>Lesson 4</p><p>libp2p in the OSI Model</p></div><svg data-v-62d9e11c="" id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" alt="Multiple-choice quiz" data-original-title="null"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 14.2h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="14.2" r="2.7"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 25h-19.8"></path><circle cx="13.08" cy="25" r="2.7" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 35.8h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="35.8" r="2.7"></circle></svg></div></a></li><li data-v-64098914=""><a data-v-62d9e11c="" data-v-64098914="" href="https://proto.school/introduction-to-libp2p/05" data-cy="lesson-link-standard"><div data-v-62d9e11c=""><div data-v-62d9e11c=""><p>Lesson 5</p><p>Multiple environments supported</p></div><svg data-v-62d9e11c="" id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" alt="Multiple-choice quiz" data-original-title="null"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 14.2h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="14.2" r="2.7"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 25h-19.8"></path><circle cx="13.08" cy="25" r="2.7" fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3"></circle><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" d="M39.63 35.8h-19.8"></path><circle fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="3" cx="13.08" cy="35.8" r="2.7"></circle></svg></div></a></li><li data-v-64098914=""><a data-v-62d9e11c="" data-v-64098914="" href="https://proto.school/introduction-to-libp2p/06" data-cy="lesson-link-standard"><div data-v-62d9e11c=""><div data-v-62d9e11c=""><p>Lesson 6</p><p>Applications and services using libp2p</p></div><svg data-v-62d9e11c="" id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" x="0" y="0" viewBox="0 0 50 50" alt="Text only" data-original-title="null"><path d="M12.92 35.38h26.66V42H12.92a2.5 2.5 0 01-2.5-2.5v-1.62a2.5 2.5 0 012.5-2.5z" stroke-miterlimit="10" fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="3px"></path><path d="M17.42 15.55h15M17.42 21.55h11" stroke-linejoin="round" fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="3px"></path><path d="M10.42 37.18V10.66A2.66 2.66 0 0113 8h26.58v29.18" stroke-miterlimit="10" fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="3px"></path></svg></div></a></li><a data-v-62d9e11c="" data-v-64098914="" href="https://proto.school/introduction-to-libp2p/resources" data-cy="lesson-link-resources"><div data-v-62d9e11c=""><div data-v-62d9e11c=""><p>Resources</p><p>More to explore</p></div><svg data-v-62d9e11c="" id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" alt="Resource links" data-original-title="null"><path d="M39.27 24.52v11a3.78 3.78 0 01-3.79 3.79h-21a3.78 3.78 0 01-3.79-3.79v-21a3.78 3.78 0 013.79-3.79h11M30.68 10.73h7.88a.71.71 0 01.71.71V19M38.56 11.44l-9.41 9.41" fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="3px"></path></svg></div></a></ul></div></div>]]>
            </description>
            <link>https://proto.school/introduction-to-libp2p/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295374</guid>
            <pubDate>Sun, 28 Feb 2021 18:01:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantum Computing for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295227">thread link</a>) | @josephleomoreno
<br/>
February 28, 2021 | https://www.canallc.com/post/introduction-to-quantum-computing | <a href="https://web.archive.org/web/*/https://www.canallc.com/post/introduction-to-quantum-computing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.22.8"><div dir="ltr"><div><div id="viewer-dfvrj"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Interior of IBM Quantum computing system"><p><img ariahidden="true" data-pin-url="https://www.canallc.com/post/introduction-to-quantum-computing" data-pin-media="https://static.wixstatic.com/media/099e36_3e165469f1174742abc9dc28873611d4~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.jpg" src="https://static.wixstatic.com/media/099e36_3e165469f1174742abc9dc28873611d4~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Interior of IBM Quantum computing system"></p></div><p><span dir="auto">Interior of IBM Quantum computing system. (Credit: IBM)</span></p></div></div></div><p id="viewer-c5gsk"><span>A video presentation of the blog post is available here: <a href="https://youtu.be/B_VgGOicr4U" target="_blank" rel="noopener"><u>https://youtu.be/B_VgGOicr4U</u></a> </span></p><p id="viewer-59vut"><span><span>Quantum computers are vastly different from classical digital computers. The first question you might ask is, ‚Äúwhat is a quantum computer?‚Äù, and the second, ‚Äúwhy do we need them?‚Äù Joe Moreno, Director of Development at CANA Advisors, answers these questions in his complex, yet accessible (and fascinating) post on quantum computers. </span></span></p><p id="viewer-930rg"><span><span>The fundamentals of quantum mechanics go back to the end of the 19th century with theoretical physicist Max Planck. In the intervening years, minds such as Albert Einstein, Niels Bohr, Werner Heisenberg, and Erwin Schr√∂dinger contributed to the quantum field. The idea of using quantum particles to store and process information was proposed by physicist Richard Feynman in 1981, and now companies such as IBM operate dozens of actual quantum computing systems. The quantum computing field has not yet scratched the surface of what is possible, but the groundwork has been laid. Let‚Äôs take a look by discovering the differences between classical <em>digital </em>computers and <em>quantum </em>computers. </span></span></p><h3 id="viewer-3v1d4"><span><span><strong>Processing</strong></span></span></h3><p id="viewer-4qm8u"><span><span><strong>Digital computers process data in series.</strong> Data is processed, sequentially, through a central processing unit (CPU). Even in a computer with multiple CPUs, they still need to explicitly coordinate operations.</span></span></p><p id="viewer-5f80k"><span><span><strong>Quantum computers process data in parallel.</strong> This is how the universe actually works. There is no single central place in the universe that processes the laws of physics. If we think of our body as a computer, our brain would be the processor. Yet our brain doesn‚Äôt need to explicitly coordinate many of our body‚Äôs activities. For example, if I take a bite out of an apple, swallow it, and then drop dead (resulting in no more brain activity), the apple would continue to digest in my stomach, at least for a little while, because that activity happens in parallel with other bodily functions.</span></span></p><h3 id="viewer-79d62"><span><span><strong>Performance</strong></span></span></h3><p id="viewer-fvmb3"><span><span><strong>Digital computer performance increases by a factor of two for each bit added (2n).</strong> A computer that can process eight bits is twice as powerful as a computer that can process seven bits.</span></span></p><p id="viewer-8s5oi"><span><span><strong>Quantum computer performance increases exponentially for each bit added (2‚Åø) </strong>due to its parallel nature. This means a quantum computer that can process 64 bits can be thought of as </span>2‚Å∂‚Å¥<span> </span>(<span>a 20 digit number) in terms of how much information it can store and process.</span></span></p><h3 id="viewer-9ur4"><span><span><strong>Behavior</strong></span></span></h3><p id="viewer-4aa11"><span><span><strong>Digital computers use simulation to solve problems. </strong>We write computer programs that store variables and execute algorithms to simulate what we observe in the real world. For example, if we want to simulate the interaction between the coronavirus and a candidate COVID-19 vaccine, we‚Äôd take the parameters that describe both, assign them to variables in a computer program, and write algorithms to simulate the interactions. The better our algorithm, the better our results. However, this only works on a small scale because there are too many variables and interactions to consider on the scale of a human.</span></span></p><p id="viewer-feeht"><span><span><strong>Quantum computers use imitation to solve problems.</strong> A good example of this is a lab rat. Before we give a candidate vaccine to a human, we test it on a lab rat. In this scenario, we can think of the lab rat as a computer that is <em>imitating</em> how the human body works. </span></span></p><h3 id="viewer-2adrp"><span><span><strong>Information</strong></span></span></h3><p id="viewer-6l91l"><span><span><strong>Digital computers store information in classical bits.</strong> A bit can only be a zero or one. Keep in mind that computer science, much like political science, is a human-created science, so we have defined the conditions and rules. Computer scientists have defined a bit to explicitly be a zero or a one.</span></span></p><p id="viewer-39ona"><span><span><strong>Quantum computers store information in quantum bits (qubits). </strong>A qubit can be a zero or one or somewhere in between zero and one, or negative, or a complex number all at the same time. To wrap your head around how a qubit can be in many different states at the same time, consider using a coin to represent state. Let‚Äôs say heads is one and tails is zero. What state is the coin in when we flip it and it‚Äôs spinning through the air? Is it heads? Is it tails? Is it both? Is it neither?</span></span></p><p id="viewer-3g44u"><span><span>A qubit is represented as a ket (vector) which distinguishes them from classical bits. </span></span></p><p id="viewer-ee1qt"><span><span>A zero qubit is represented as:</span></span></p><div id="viewer-o95r"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img ariahidden="true" data-pin-url="https://www.canallc.com/post/introduction-to-quantum-computing" data-pin-media="https://static.wixstatic.com/media/099e36_ccf8d646e3b14038ab928da152e9cdb7~mv2.png/v1/fit/w_114%2Ch_152%2Cal_c/file.png" src="https://static.wixstatic.com/media/099e36_ccf8d646e3b14038ab928da152e9cdb7~mv2.png/v1/fit/w_114,h_152,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-dkpmv"><span><span>A one qubit is represented as:</span></span></p><div id="viewer-ghrg"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img ariahidden="true" data-pin-url="https://www.canallc.com/post/introduction-to-quantum-computing" data-pin-media="https://static.wixstatic.com/media/099e36_a076b7c59f6343f08632ff8971814c8e~mv2.png/v1/fit/w_108%2Ch_152%2Cal_c/file.png" src="https://static.wixstatic.com/media/099e36_a076b7c59f6343f08632ff8971814c8e~mv2.png/v1/fit/w_108,h_152,al_c,q_5/file.png"></p></div></div></div></div><h3 id="viewer-2bb2r"><span><span><strong>Logic</strong></span></span></h3><p id="viewer-q1lq"><span><span><strong>Digital computers perform operations using logic gates governed by <em>Boolean algebra</em> (AND, OR, NOT, XOR, etc.).</strong> By performing operations on multiple bits, at the same time, we can produce meaningful information.</span></span></p><p id="viewer-55ten"><span><span><strong>Quantum computers perform operations using quantum logic gates (X, Y, Z, CNOT, Hadamard, etc.) governed by <em>linear algebra</em> (matrix algebra).</strong> These quantum logic gates are somewhat different from digital logic gates. For example, the Hadamard gate is used to quantumly entangle subatomic particles in a quantum computer and then put the particles into a state of superposition to process information. Borrowing from my earlier example of flipping a coin, we can think of superposition, in an overly simplified way, as when the coin is flipping through the air.</span></span></p><h3 id="viewer-7jbbc"><span><span><strong>Storage</strong></span></span></h3><p id="viewer-d3b2h"><span><span><strong>Digital computers store bits using voltage and charge. </strong>This is done inside ‚Äúchips‚Äù (integrated circuits) made up mostly of transistors. A transistor is simply a switch that can be turned on (one) and off (zero) without moving atoms -- transistors only move electrons.</span></span></p><p id="viewer-5sgmh"><span><span><strong>Quantum computers store information in qubits using particle spin.</strong> Quantum particles have different properties such as mass, charge, and spin. When a particle is in a state of superposition we can think of it as spinning, much like flipping a coin. When we measure (read) the coin‚Äôs state after flipping it, it has only one of two outcomes, heads or tails. Similarly, quantum particles end up in only one of two states when we measure them called <em>spin up</em> or <em>spin down</em>. We can think of spin up as when its axis is pointing up (north), which we call zero, and we can think of spin down as when its axis is pointing down (south), which we call one.</span></span></p><h3 id="viewer-c1lt4"><span><span><strong>Architecture </strong></span></span></h3><p id="viewer-5n1mn"><span><span><strong>Digital computers use a von Neumann model with a CPU, ALU (arithmetic logic unit), and memory to store instructions and data. </strong>Physically, bits are stored in transistors at room temperature.</span></span></p><p id="viewer-82ku0"><span><span><strong>Quantum computers store and process data using quantum error correction</strong> (this is what makes a quantum computer a quantum computer)<strong>.</strong> Quantum error correction protects the qubits (electrons, photons, nuclei, etc.) from outside interference. The biggest source of interference is heat. Physically, qubits are stored at less than 1 Kelvin (about 0.015 Kelvin) to remove any thermal noise that could disturb them.  The requirement to maintain a temperature of less than -457.87 degrees Fahrenheit presents its own set of operational challenges. </span></span></p><h3 id="viewer-b9bpc"><span><span><strong>Output</strong></span></span></h3><p id="viewer-clmpl"><span><span><strong>Digital computers are deterministic.</strong> The exact same inputs, into the exact same algorithms, always yields the exact same outputs. </span></span></p><p id="viewer-83aav"><span><span><strong>Quantum computers are probabilistic.</strong> Repetition of the same inputs yields probabilistic outputs. This is a realistic model of how the universe works. If we flip a coin 10,000 times, we‚Äôd expect the sum of heads and the sum of tails to total 10,000 with about a 50/50 split. However, it‚Äôs entirely possible that the coin could land on its side (edge). Quantum computers can better represent </span>real-world<span> probabilities. </span></span></p><h3 id="viewer-6frbo"><span><span><strong>Reversibility</strong></span></span></h3><p id="viewer-8rnci"><span><span><strong>Digital computers‚Äô logic gates are not all reversible.</strong> If I show you the outputs from a digital computer, and tell you which operation is performed that yielded those outputs, you may still not have enough information to figure out the inputs.</span></span></p><p id="viewer-7t0nh"><span><span><strong>Quantum computers‚Äô logic gates are all reversible. </strong>If I show you the outputs from an operation, and tell you the operation that was performed, you could always determine all of the inputs. So much so that if you took these outputs and put them through the same operation, as inputs, your new outputs would match the original inputs in the first step.</span></span></p><h3 id="viewer-65dlv"><span><span><strong>Current State of Quantum Computing</strong></span></span></h3><p id="viewer-1bbuu"><span><span>Before 2020, researchers viewed quantum computing as primarily a scientific </span>endeavor<span> with relatively little immediate bearing on the commercial viability of quantum computing. However, that has quickly changed with multiple companies entering the quantum computing market. Amazon currently has a web service where anyone can run quantum computing tasks on a variety of quantum computers. The ability to decode complex cryptographic challenges, process enormous amounts of data quickly, and simulate atomic and subatomic behavior in a controlled environment is likely just the tip of the quantum wave to come.  </span></span></p><p id="viewer-e83fv"><span><a href="https://www.canallc.com/blog/hashtags/quantumcomputing" target="_self"><span>#quantumcomputing</span></a><span>  </span><a href="https://www.canallc.com/blog/hashtags/CANAAdvisors" target="_self"><span>#CANAAdvisors</span></a><span> </span><a href="https://www.canallc.com/blog/hashtags/joemoreno" target="_self"><span>#joemoreno</span></a> </span></p><div id="viewer-ke92"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img ariahidden="true" data-pin-url="https://www.canallc.com/post/introduction-to-quantum-computing" data-pin-media="https://static.wixstatic.com/media/099e36_0f75f0a24c6d459bb9899eafe6811274~mv2.png/v1/fit/w_250%2Ch_250%2Cal_c/file.png" src="https://static.wixstatic.com/media/099e36_0f75f0a24c6d459bb9899eafe6811274~mv2.png/v1/fit/w_250,h_250,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-8b9v7"><span><span><strong>Joe Moreno</strong></span></span></p><p id="viewer-16on5"><span><span>Joe Moreno is a Director of Development at CANA Advisors. You can follow him at </span><a href="http://joemoreno.com/" target="_blank" rel="noopener"><span><u>joemoreno.com</u></span></a><span> or contact via email jmoreno@canallc.com.</span></span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.canallc.com/post/introduction-to-quantum-computing</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295227</guid>
            <pubDate>Sun, 28 Feb 2021 17:48:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Interesting Multiplexing Scheme of the Grass Valley Series 300 Crosspoint S]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26294853">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://bikerglen.com/blog/grass-valley-300-crosspoint-multiplexing/ | <a href="https://web.archive.org/web/*/https://bikerglen.com/blog/grass-valley-300-crosspoint-multiplexing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div id="attachment_3200"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/gif-import-crop-scale1.gif"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/gif-import-crop-scale1.gif" alt="An animated GIF of the front panel lamps chasing each other across the panel." width="1000" height="258"></a></p><p>An animated GIF of the front panel lamps chasing each other across the panel.</p></div>
<p>After <a href="https://bikerglen.com/blog/converting-more-vintage-hardware-to-usb/">reverse engineering parts of a Grass Valley Kalypso video switcher control panel</a> and after making a YouTube video describing how I modified a <a href="https://www.youtube.com/watch?v=3Sz-eMOra3I">Grass Valley Series 300 transition logic panel to be a USB peripheral</a>, it was time to reverse engineer a Grass Valley Series 300 crosspoint bus switch panel. This panel is about 20 years older than the equivalent Kalypso crosspoint bus switch panel I reverse engineered in the earlier blog post. It‚Äôs also quite a bit simpler and uses 100% off-the-shelf logic ICs with no micros or FPGAs. Read on to find out more.</p>

<h2>The Grass Valley 300 Series Video Switcher</h2>
<div id="attachment_3170"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/eb5d3c6275367d1076f02401455e9036.jpg"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/eb5d3c6275367d1076f02401455e9036.jpg" alt="A Grass Valley Group 300 Series video switcher." width="1022" height="575"></a></p><p>A Grass Valley Group 300 Series video switcher.</p></div>
<p>Pictured above is a Grass Valley Group 300 Series video switcher. This video switcher has three mix effects buses and a program / preview bus. The mix effects buses are color coded from top (white, #1) to middle (yellow, #2) to bottom (orange, #3). The very bottom cluster with the white and red buttons is the program / preview bus that‚Äôs used to select video signals to preview and to air. Each mix effects bus can combine a number of different video sources with different effects to create a signal that can be routed to the program / preview bus for preview and air.</p>
<p>The panel reverse engineered and described in this blog post is the orange M/E-3 crosspoint swtich panel on the left side of the switcher and three quarters of the way down. The crosspoint switch panel is used to select three video signals from up to 24 different video inputs to feed to the first mix effects unit. Five additional key sources and the outputs from the M/E-1 and M/E-2 units can also be selected as inputs using the buttons to the right of the main 24 columns of orange buttons. The mix effects unit then combines these selected video sources into a live, mixed video feed.</p>
<div id="attachment_3192"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/left-buttons.jpg"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/left-buttons-1024x683.jpg" alt="A close up of some of the crosspoint panel's source selection buttons." width="640" height="427"></a></p><p>A close up of some of the crosspoint panel‚Äôs source selection buttons.</p></div>
<p>On the crosspoint switch panel, each column of switches represents a different video source. These could be, for example, studio cameras, video tape recorders, still images from still stores, text from Chyron title generators, remote truck feeds, or satellite feeds. Each row represents a different input to the mix effects unit. The top row is the key input, the middle row is the A input, and the bottom row is the B input. The photo above shows the leftmost video sources on my crosspoint switch panel.</p>
<p>Pressing a button in a row selects the video source in that column as an input to the mix effects unit. When a video source is selected as an input to the mix effects unit, the button at the intersection of the source column and input row is illuminated. Since there‚Äôs three rows, up to three sources can be selected as inputs to the mix-effects unit.</p>
<p>The buttons, knobs, and t-bar fader to the right of the crosspoint switch panel control the mix effects unit. Using these controls, the three video sources can be combined into a video feed like the one in the picture below. (I previously looked at the panel with the t-bar fader and converting it into a Halloween prop and USB peripheral in a <a href="https://www.youtube.com/watch?v=3Sz-eMOra3I">video</a>.)</p>
<div id="attachment_3171"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/vlcsnap-2021-02-24-19h37m52s317.png"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/vlcsnap-2021-02-24-19h37m52s317.png" alt="This image consists of three input video sources. The background consisting of the anchor and set, the fire graphic above the anchor's shoulder, and the title graphics with the anchor's name." width="640" height="480"></a></p><p>This image consists of three input video sources: the background consisting of the anchor and set, the fire graphic above the anchor‚Äôs shoulder, and the title graphics with the anchor‚Äôs name in the foregrond.</p></div>
<p>This screen capture is from a promotional video demonstrating the mix effects capabilities of the 300 series video switcher. It is a composite of three video sources by one mix effects unit. The background with the anchor and studio set is from a camera on the A input to the M/E unit, the graphic with the fire is from a still store on the B input to the M/E unit, and the graphic with the station logo and anchor name is on the key input to the M/E unit. The M/E unit combines these three inputs into a live video feed as shown in the image.</p>
<p>Once the M/E unit has been configured to mix the video sources together, the bottom three rows of buttons on the switcher can be used to select the M/E output for display on a preview monitor. Just before the anchor starts talking, the technical director can cut to the M/E output and display the live composited image on air.</p>
<h2>The Hardware</h2>
<div id="attachment_3193"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/front.jpg"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/front-1024x272.jpg" alt="The front of the crosspoint bus switch panel." width="640" height="170"></a></p><p>The front of the crosspoint bus switch panel. Click to embiggen.</p></div>
<p>The crosspoint switch has 72 illuminated push button switches arranged in 3 rows of 24 buttons each. The columns are spaced at a 0.9‚Ä≥ pitch. The rows are spaced at a 1.2‚Ä≥ pitch. The entire panel measures roughly 21.5‚Ä≥ by 4.25‚Ä≥.</p>
<div id="attachment_3194"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/switch.jpg"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/switch-1024x683.jpg" alt="Close up one of the switches on the crosspoint bus switch panel." width="640" height="427"></a></p><p>Close up one of the switches on the crosspoint bus switch panel.</p></div>
<p>These switches are made by Electro-Mech Components. Unlike the Veetronix magnetic reed switches used on the later Grass Valley Kalypso panels, these switches use ordinary electrical contacts. The switches are held in place on the metal frame using retaining rings.</p>
<div id="attachment_3195"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/caps.jpg"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/caps-1024x683.jpg" alt="A few switches with their caps removed." width="640" height="427"></a></p><p>A few switches with their caps removed.</p></div>
<p>Each switch has an orange removable push button. The transparent cap can be removed from the button to insert a label indicating the video source assigned to that switch. On the rear of each button is a holder for a 12-volt midget flange base incandescent bulb.</p>
<div id="attachment_3196"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/rear.jpg"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/rear-1024x274.jpg" alt="The rear of the crosspoint bus switch panel." width="640" height="171"></a></p><p>The rear of the crosspoint bus switch panel. Click to embiggen.</p></div>
<p>Looking at the back of the panel, there are nine circuit boards. Each row contains three boards and each board contains eight switches. The boards within a row are connected together using jumpers connected between pairs of 10 position headers. The rows are not connected to each other. The headers at the far left are insulated using sparsely populated header sockets. The headers at the far right are connected to the main logic board of the video switch control surface. The nine boards are identical.</p>
<h2>Reverse Engineering One of the Boards</h2>
<div id="attachment_3197"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/rear-third.jpg"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/rear-third-1024x683.jpg" alt="A close up of the electronics on the crosspoint bus switch panel." width="640" height="427"></a></p><p>A close up of the electronics on the crosspoint bus switch panel. Click to embiggen.</p></div>
<p>The reverse engineering effort started with a quick examination of one of the nine boards, followed by the use of a digital multimeter to verify assumptions and trace connections between components.</p>
<p>Each board has eight switches, two headers, 13 transistors, 2 integrated circuits, and an assortment of resistors and capacitors. The eight switches are soldered to the board. Each switch has four terminals: two terminals for the lamp and two terminals for the normally open switch.</p>
<p>The header on the right is labeled +5, +L, GND, E0, D0, D1, D2, G0, G1, and G2. The header on the left is labeled the same except that the E0 pin is labeled E1. Using the DMM, I verified the +5 pin is the 5-volt supply, the +L pin is the supply voltage for the lamps, and the GND pin is the ground. The bulbs were type 382 midget flange base T1-3/4 incandescent lamps rated for 14 volts therefore the lamp supply voltage is 12 volts.</p>
<p>Since the bulb supply is 12 volts and the logic supply is 5 volts, I assumed eight of the transistors were used as low-side transistor switches to control the 12 volt lamps from 5 volt logic. Using the DMM, I was able to trace +L to a lamp pin then the other lamp pin to the collector of a transistor, the emitter of the transistor to ground, and the base of the transistor through a resistor to one of the integrated circuits. The remaining five transistors were a mystery.</p>
<p>Next I focused on the integrated circuits. The first integrated circuit was a MC14051B analog multiplexer/demultiplexer. The second integrated circuit was a MC14532B 8-bit priority encoder.</p>
<div id="attachment_3212"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/MC14051B-D1.png"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/MC14051B-D1.png" alt="Functional diagram of the MC14051B analog multiplexer/demultiplexer from the second page of the datasheet." width="1000" height="796"></a></p><p>Functional diagram of the MC14051B analog multiplexer/demultiplexer from the second page of the datasheet.</p></div>
<p>I focused on the analog multiplexer/demultiplexer first. I used a DMM to trace out the pins. The inhibit pin connected to the G0 pin on the right header. The A, B, and C pins connected to the D0, D1, and D2 pins on both headers. The X common pin connected to +5V and the X0 to X7 outputs each connected to the base of a transistor connected to a lamp. Looks like the MC14051B is wired as a demultiplexer and controls the lamps. We‚Äôll get in to the theory of operation in the next section.</p>
<div id="attachment_3210"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/MC14532B-D.png"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/MC14532B-D-791x1024.png" alt="MC14532B-D" width="640" height="829"></a></p><p>Front page of the data sheet for the MC14532B 8-bit priority encoder.</p></div>
<p>After tracing the analog multiplexer/demultiplexer connections, I turned my attention to the 8-bit priority encoder connections. The Ein&nbsp; pin connected to the E1 pin on the left header. The eight D0 to D7 pins connected to the normally open terminals of the eight switches. The E1 pin is used to disable the encoder on this board if a switch is pressed on a board further to the left. Looks like the hardware can only detect one key press at a time.</p>
<p>The first nine connections were easy enough, but the GS, Eout, Q0, Q1, and Q2 pins connected to the base of the five mystery transistors. Further probing showed that the emitters of these five transistors were connected to ground and the collectors were connected to the G0, E0, D0, D1, and D2 pins respectively.</p>
<p>These transistors form a simple wired-OR bus with the rest of the boards in the row. They permit any of the boards in a row to pull the signal low without causing contention. Pullup resistors are then needed on the main controller board to keep these lines high when no board is pulling the lines low.</p>
<p>The final detail to note is that the G0 pin terminates on and controls this board. The G1 pin on the right header connects to the G0 pin on the left header and the G2 pin on the right header connects to the G1 pin on the left header. This makes the G0 pin enable this board, the G1 pin enable the next board to the left, and the G2 pin enable the final, leftmost board. This routing of the enable signals permits the same design to be used for all three boards in a row.</p>
<div id="attachment_3204"><p><a href="https://bikerglen.com/wp/wp-content/uploads/2021/02/rough-schematic.png"><img src="https://bikerglen.com/wp/wp-content/uploads/2021/02/rough-schematic-1024x682.png" alt="A very rough schematic of one of the eight push button boards. Reference designators are completely wrong and the resistor on the base of the transistors are missing." width="640" height="426"></a></p><p>A very rough schematic of one of the eight push button boards. Reference designators are completely wrong and the resistor on the base of the transistors are missing.</p></div>
<p>After about an hour of making <span><span>hypotheses</span></span>, testing them with the DMM, and taking notes, I had the rough schematic shown in the image ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bikerglen.com/blog/grass-valley-300-crosspoint-multiplexing/">https://bikerglen.com/blog/grass-valley-300-crosspoint-multiplexing/</a></em></p>]]>
            </description>
            <link>https://bikerglen.com/blog/grass-valley-300-crosspoint-multiplexing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294853</guid>
            <pubDate>Sun, 28 Feb 2021 17:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving search engines a fair access to data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26294753">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://www.gkbrk.com/2021/02/search-engine-data/ | <a href="https://web.archive.org/web/*/https://www.gkbrk.com/2021/02/search-engine-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody"> <p>Search engines are difficult to create. They are even harder to improve to a point where you get good-enough results to keep regular users. This is why it‚Äôs so rare to see decent search engines that aren‚Äôt front-ends to the Bing or Google APIs.</p> <p>This doesn‚Äôt mean there are none though. There are a small number of search engines with their own crawlers and search logic. More and more of them appear over time, but most of them cannot improve to the point of catching on. This is because of a common resource they lack: Data.</p> <p>I am not talking about the slimy, personal kind of data that Google and friends like so much. What are people searching for right now? How many of those do I have good results for? How do people form their queries? Those are all difficult to answer and improve if people aren‚Äôt using you search engine. But no one will use your search engine unless you improve those. Great then, we are in a chicken-and-egg situation with no escape in sight.</p>  <p>Before tackling the problem, let‚Äôs explore what the problem is in the first place. The first problem is the number of humans testing the result quality. In almost all cases, the creator(s) will be testing the results. Friends and family will try it a few times before going back to their default search engine. Social media and Hacker News will provide a swarm of clicks that only last for a few hours. This is not data, at least not enough data.</p> <p>The second problem is a little trickier. Most people from our already small set of users will not provide data that is too valuable. Let‚Äôs break down our users into two segments, the creators and the people testing it out.</p> <p>The creators are programmers who research very specific pieces of information all day. While this makes them very good at using search engines, it makes them very bad at testing the results. A programmer knows the exact query that will bring them results before typing it. This query is usually so good that even a bad algorithm will find the results they are looking for.</p> <p>The people testing it out have a different problem. When put on the spot for testing a search engine, it is not easy to come up with queries for difficult questions. But those are the exact situations that need the help of a good search engine. You will only see these queries once people see you as reliable and pick you as their default engine.</p>  <p>We can separate the current search ecosystem into three distinct groups.</p> <p>Google gets almost all the search traffic. They have more than enough data, both personal and aggregated, to serve all their needs. Their monopoly on search, and their hostility for the open web makes this undesirable. A good solution will decrease the amount of data and they get, or give more data to their competitors.</p> <p>DuckDuckGo and other API front-ends get a small chunk of search traffic. They are a good compromise between keeping the web open, and having a good search experience as a user. Most of these engines stay as API wrappers forever, so the data they get doesn‚Äôt improve them much.</p> <p>Independent search engines have to make do with scraps. This makes it hard for them to become popular or earn money to support themselves.</p>  <p>In this post; I will propose different ways to improve this situation. Each have different trade-offs in user convenience and their usefulness to search engines. The best option would be to use and promote independant search engines. But for a lot of people, it is hard to commit to a sub-par experience even if it is the better long-term option. One can look at how people handle environmental issues to see a prime example of this effect.</p> <h2 id="feeding-data-to-search-engines">Feeding data to search engines</h2> <p>With the first option, you keep using your favourite search engine.</p> <p>An automated process will send a sample of the queries to different search engines. This way, the engines can get their hands on organic usage data before finding full-time users.</p> <p>This approach makes automated requests without user interaction. Depending on their systems, this might mess up their data collection or make it difficult to serve real users. To be considerate to the service operators, we should make our requests with a User-Agent header that explains what is happening. This header will allow them to log our requests, handle them in a cheaper way, and to filter them out of the data for their real users.</p> <h2 id="redirecting-to-different-search-engines">Redirecting to different search engines</h2> <p>Another approach is to have each search go to a random search engine. Compared to the previous approach, this one is more beneficial to search engines and more incovenient for the user. The user won‚Äôt be able to reproduce searches as the same query will end up going to different search providers. Similarly, a smaller search engine might give unsatisfactory results to the user, forcing them to perform the same query multiple times.</p> <p>This approach can be combined with the previous one as well. By putting a few ‚Äúgood‚Äù engines on the random redirect list and feeding data automatically to the rest of them, the downsides could be improved.</p> <h2 id="embedding-the-results-of-multiple-engines">Embedding the results of multiple engines</h2> <p>There are already meta-search engines, like <a href="https://searx.me/">Searx</a>, that satisfy some of these requirements. The problem with them though is, each data source they add clutters the main results and slows down search. I think if Searx adds the option of sending data to small search engines in the background without slowing down the main UI, it will be a really good solution to this.</p> <p>One could use iframes to do this as well, but browsers not being ‚ÄúUser Agents‚Äù any more, they allow the websites to control their embeddability.</p>  <p>Another trade-off to consider is where the automated query submission should happen. If you choose a centralized approach, you end up trusting a third-party with your search queries. If you instead choose to handle this yourself without a centralized third-party, you are now sending all your queries to all the other engines in an identifiable way.</p> <p>There are a few ways to work around this. One of them is to have small public instances like the Fediverse. Everyone would pick who to trust with their queries, and even on small instances the queries would be mixed enough to protect identities. Another approach would be to keep the queries saved locally, and submit them using random proxies.</p>  <p>If there are solutions satifying this need in the future, I am planning to implement this. I just wanted to write this and put it on the internet in case other people are planning similar things. I already have the random search engine redirect working, but in my opinion the most important piece is the automatic data feeding.</p> <p>The way I will most likely implement this is either a web endpoint that can be added to browsers as a search engine, which can be hosted locally or on a server, or a browser extension.</p> </div></div>]]>
            </description>
            <link>https://www.gkbrk.com/2021/02/search-engine-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294753</guid>
            <pubDate>Sun, 28 Feb 2021 17:01:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weird architectures weren't supported to begin with]]>
            </title>
            <description>
<![CDATA[
Score 327 | Comments 203 (<a href="https://news.ycombinator.com/item?id=26294397">thread link</a>) | @woodruffw
<br/>
February 28, 2021 | https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Feb 28, 2021</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#rant">rant</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>
    
  
  </p>


<hr>

<h4 id="preword">Preword</h4>

<p>This post contains my own opinions, not the opinions of my employer or any open source groups I
belong or contribute to.</p>

<p>It‚Äôs also been rewritten 2¬Ω times, and (I think) reads confusingly in places. But I promised
myself that I‚Äôd get it out of the door instead of continuing to sit on it, so here we go.</p>

<hr>

<p>There‚Äôs been a decent amount of <del>drama</del> debate in the open source community about <em>support</em>
recently, originating primarily from
<a href="https://github.com/pyca/cryptography/issues/5771">pyca/cryptography‚Äôs decision to use Rust for some ASN.1 parsing routines</a><sup id="fnref:asn1" role="doc-noteref"><a href="#fn:asn1">1</a></sup>.</p>

<p>To summarize the situation: building the latest <code>pyca/cryptography</code> release from scratch now requires
a Rust toolchain. The only currently<sup id="fnref:gccrust" role="doc-noteref"><a href="#fn:gccrust">2</a></sup> Rust toolchain is built on <a href="https://llvm.org/">LLVM</a>, which
supports a (relatively) limited
<a href="https://llvm.org/docs/CompilerWriterInfo.html">set of architectures</a>. Rust further whittles this
set down into <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">support tiers</a>, with
some targets not receiving automated testing (tier 2) or official builds (tier 3).</p>

<p>By contrast, upstream<sup id="fnref:gcchell" role="doc-noteref"><a href="#fn:gcchell">3</a></sup> GCC supports a <a href="https://gcc.gnu.org/backends.html">somewhat larger</a>
set of architectures. But C<sup id="fnref:c" role="doc-noteref"><a href="#fn:c">4</a></sup>, cancer that it is, finds its way onto every architecture with or
without GCC (or LLVM‚Äôs) help, and thereby bootstraps <a href="https://github.com/python/cpython">everything</a>
<a href="https://www.gnome.org/">else</a>.</p>

<p>Program packagers and distributors (frequently separate from project maintainers themselves)
are very used to C‚Äôs universal presence. They‚Äôre so used to it that they‚Äôve built generic
mechanisms for putting entire distributions onto new architectures with
only a single assumption: the presence of a serviceable C compiler.</p>

<p>This is the heart of the conflict: Rust (and many other modern, safe languages) use LLVM for its
relative simplicity<sup id="fnref:simple" role="doc-noteref"><a href="#fn:simple">5</a></sup>, but LLVM does not support either native or cross-compilation to many
less popular (read: niche) architectures. Package managers are increasingly finding that one of
their oldest assumptions can be easily violated, and they‚Äôre not happy about that.</p>

<p>But here‚Äôs the problem: <em>it‚Äôs a bad assumption</em>. The fact that it‚Äôs the default
represents an <strong>unmitigated</strong> security, reliability, and reproducibility <em>disaster</em>.</p>

<h2 id="a-little-thought-problem">A little thought problem</h2>

<p>Imagine, for a moment, that you‚Äôre a maintainer of a popular project.</p>

<p>Everything has gone right for you: you have happy users, an active development base, and maybe even
corporate sponsors. You‚Äôve also got a CI/CD pipeline that produces canonical releases of your
project on tested architectures; you treat any issues with uses of those releases as a bug in the
project itself, since you‚Äôve taken responsibility for packaging it.</p>

<p>Because your project is popular, <strong>others</strong> also distribute it: Linux distributions, third-party
package managers, and corporations seeking to deploy their own controlled builds. These others have
slightly different needs and setups and, to varying degrees, will:</p>

<ul>
  <li>Build your project with slightly (or completely) different versions of dependencies</li>
  <li>Build your project with slightly (or completely) different optimization flags and other potentially
ABI-breaking options</li>
  <li>Distribute your project with insecure or outright broken defaults</li>
  <li>Disable important security features because other parts of their ecosystem haven‚Äôt caught up</li>
  <li>Patch your project or its build to make it ‚Äúwork‚Äù (read: compile and not crash immediately) with
completely new dependencies, compilers, toolchains, architectures, and environmental constraints</li>
</ul>

<p>You don‚Äôt know about <em>any</em> of the above until the bug reports start rolling in: users will report
bugs that have already been fixed, bugs that you explicitly document as caused by unsupported
configurations, bugs that <em>don‚Äôt make any sense whatsoever</em>.</p>

<p>You struggle to debug your users‚Äô reports, since you don‚Äôt have access to the niche
hardware, environments, or corporate systems that they‚Äôre running on. You slowly burn out
as an unending torrent of already fixed bugs that never seem to make it to your users. Your
user base is unhappy, and you start to wonder why you‚Äôre putting all this effort into
project maintenance in the first place. Open source was supposed to be fun!</p>

<p>What‚Äôs the point of this spiel? It‚Äôs <em>precisely</em> what happened to <code>pyca/cryptography</code>:
nobody asked them whether it was a good idea to try to run their code on
<a href="https://en.wikipedia.org/wiki/PA-RISC">HPPA</a>, much less
<a href="https://en.wikipedia.org/wiki/IBM_System/390">System/390</a><sup id="fnref:s390" role="doc-noteref"><a href="#fn:s390">6</a></sup>; some packagers just went ahead
and did it, and are frustrated that it no longer works. People just <em>assumed</em> that it
would, because there is <em>still</em> a norm that everything flows from C, and that any
host with a halfway-functional C compiler should have the entire open source ecosystem
at its disposal.</p>

<h3 id="reflections-on-trusting-random-platforms">Reflections on trusting random platforms<sup id="fnref:rott" role="doc-noteref"><a href="#fn:rott">7</a></sup></h3>

<p>Security-sensitive software<sup id="fnref:security" role="doc-noteref"><a href="#fn:security">8</a></sup><sup>,</sup><sup id="fnref:reliability" role="doc-noteref"><a href="#fn:reliability">9</a></sup>, <em>particularly</em> software written
in unsafe languages, is <strong>never</strong> secure in its own right.</p>

<p>The security of a program is a function of its own design and testing,
<em>as well as</em> the design, testing, and basic correctness of its underlying platform: everything from
the userspace, to the kernel, to the compilers themselves. The latter
is an <strong>unsolved problem</strong> in the <em>very best of cases</em>: bugs are <em>regularly</em>
found in even the most mature compilers (Clang, GCC) and their most mature backends (x86, ARM). Tiny
changes to or differences in build systems can have profound effects at the binary level, like
<a href="https://insights.sei.cmu.edu/cert/2018/08/when-aslr-is-not-really-aslr---the-case-of-incorrect-assumptions-and-bad-defaults.html">accidentally removing security mitigations</a>.
Seemingly innocuous patches can make otherwise safe code
<a href="https://wiki.gentoo.org/wiki/Hardened/GNU_stack_quickstart">exploitable</a> in the context of
other vulnerabilities.</p>

<p>The problem gets worse as we move towards niche architectures and targets that are used
primarily by small hobbyist communities.
Consider <a href="https://en.wikipedia.org/wiki/Motorola_68000_series">m68k</a>
(one of the other architectures affected by <code>pyca/cryptography</code>‚Äôs move to Rust): even
GCC <a href="https://gcc.gnu.org/legacy-ml/gcc-patches/2019-10/msg02044.html">was considering</a> removing
support due to lack of maintenance, until hobbyists stepped in. That isn‚Äôt to say that any
<em>particular</em> niche target is full of bugs<sup id="fnref:although" role="doc-noteref"><a href="#fn:although">10</a></sup>; only to say that it‚Äôs a greater likelihood
for niche targets <em>in general</em>. <strong>Nobody</strong> is regularly testing the mountain of userspace
code that implicitly forms an operating contract with arbitrary programs on these platforms.</p>

<p>Project maintainers don‚Äôt want to chase down compiler bugs on ISAs or systems that they never
intended to support in the first place, and aren‚Äôt receiving any active support feedback about.
They <em>especially</em> don‚Äôt want to have vulnerabilities associated
with their projects because of buggy toolchains <em>or</em> tooling inertia when working on security
improvements.</p>

<h3 id="some-more-finger-pointing">Some more finger-pointing</h3>

<p>As someone who <em>likes</em> C: this is all C‚Äôs fault. Really.</p>

<p>Beyond language-level unsafety (plenty of people have
<a href="https://fishinabarrel.github.io/">covered that already</a>), C is <em>organizationally</em> unsafe:</p>

<ul>
  <li>
    <p>There‚Äôs no standard way to write tests for C.</p>

    <p>Functional and/or unit tests <em>alone</em> would go a long
way in assuring baseline correctness on weird architectures or platforms, but the cognitive
overhead of testing C <em>and</em> getting those tests running ensures that well-tested builds of C
programs will continue to be the exception, rather than the rule.</p>
  </li>
  <li>
    <p>There‚Äôs no standard way to build C programs.</p>

    <p><a href="https://blog.yossarian.net/2019/04/23/Make-is-probably-fine">Make is fine</a>, but it‚Äôs not standard.
Disturbingly large swathes of critical open source infrastructure are compiled using a hodgepodge
of Make, autogenerated rules from autotools, and the maintainer‚Äôs boutique shell scripts. One
consequence of this is that C builds tend to be flexible <em>to a fault</em>: prospective packagers
can inject all sorts of behavior-modifying flags that may not be attested directly
in the compiled binary or other build products. The result: it‚Äôs almost impossible to prove that
two separate builds on different machines are the same, which means more maintainer pain.</p>
  </li>
  <li>
    <p>There‚Äôs no standard way to distribute C programs.</p>

    <p>Yes, I know that package managers exist. Yes, I know how to statically link. Yes, I know how to
vendor libraries and distribute self-contained program ‚Äúbundles‚Äù. None of these are or amount to
a <em>complete</em> standard, and each introduces additional logistical or security problems.</p>
  </li>
  <li>
    <p>There‚Äôs no such thing as truly cross-platform C.</p>

    <p>The C abstract machine, despite looking a lot like a PDP-11, leaks the underlying memory
and ordering semantics of the architecture being targeted. The result is that even seasoned
C programmers regularly rely on architecture-specific assumptions when writing ostensibly
cross-platform code: assumptions about the atomicity of reads and writes, operation ordering,
coherence and visibility in self-modifying code, the safety and performance of unaligned accesses,
and so forth. Each of these, apart from being a potential source of unsafety, are <strong>impossible
to detect</strong> statically in the general case: they are, after all, perfectly correct
(and frequently intended!) on the programmer‚Äôs host architecture.</p>
  </li>
</ul>

<p>By contemporary programming language standards, these are conspicuous gaps in functionality:
we‚Äôve long since learned to bake testing, building, distribution, and sound abstract machine
semantics into the standard tooling for languages (and language design itself). But their absence
is <strong>doubly pernicious</strong>: they ensure that C remains a perpetually
unsafe development ecosystem, <em>and</em> an appealing target when bootstrapping a new platform.</p>

<h2 id="the-life-of-a-package-maintainer-is-hard">The life of a package maintainer is hard</h2>

<p>The project maintainer isn‚Äôt the only person hurting in the status quo.</p>

<p>Everything stated above <em>also</em> leads to a bum job for the lowly package maintainer<sup id="fnref:yt" role="doc-noteref"><a href="#fn:yt">11</a></sup>. They‚Äôre
(probably) also an unpaid open source hobbyist, and they‚Äôre operating with constraints that
the upstream isn‚Äôt likely to immediately understand:</p>

<ul>
  <li>The need to link against versions of dependencies that have already been packaged (and perhaps patched)</li>
  <li>ABI and ISA subset constraints, stemming from a need to distribute binaries that function with
relatively old versions of <code>glibc</code> or x86-64 CPUs without modern extensions</li>
  <li>Limited visibility into each project‚Äôs test suite and how to run it, much less what to do when
it fails</li>
</ul>

<p>They <em>also</em> have to deal with users who are unsympathetic to those reports, and who:</p>

<ul>
  <li>Rarely submit reports to the packager (they bug the project directly instead!), or ‚Ä¶</li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with">https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294397</guid>
            <pubDate>Sun, 28 Feb 2021 16:22:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Models of Abstraction]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26294252">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://justinblank.com/notebooks/modelsofabstraction.html | <a href="https://web.archive.org/web/*/https://justinblank.com/notebooks/modelsofabstraction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          
<p>Discussions of abstraction in programming often feel pointless. I've started to think that the participants have different models of abstraction. However, it's been hard for me to say distinguish them clearly. Some ideas are:</p>
<ul>
<li><em>Abstraction as deduplication</em>: everywhere</li>
<li><em>Abstraction as indirection</em>: enterprise Java</li>
<li><em>Abstraction as generality</em>: Haskell typeclasses</li>
</ul>
<p>There is substantial overlap, but each model of abstraction has different talking points, for and against:</p>
<ul>
<li>don't repeat yourself</li>
<li><a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction">duplication is better than the wrong abstraction</a></li>
<li>avoid coupling</li>
<li>it should easy to find out what the code does</li>
<li>keep code concrete</li>
<li>laws<a href="#fn1" id="fnref1"><sup>1</sup></a></li>
</ul>
<p>Does one of these models have a claim to be <em>the</em> definition of abstraction? What other models are there? What, if anything, makes it fruitful to discuss "abstraction", without specifying a model?</p>

	</article></div>]]>
            </description>
            <link>https://justinblank.com/notebooks/modelsofabstraction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294252</guid>
            <pubDate>Sun, 28 Feb 2021 16:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging K8s services: 3 tools for 3 scenarios]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26294015">thread link</a>) | @erkanerol
<br/>
February 28, 2021 | https://erkanerol.github.io/post/debugging-k8s-services/ | <a href="https://web.archive.org/web/*/https://erkanerol.github.io/post/debugging-k8s-services/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>Feb 28, 2021 ¬∑ <a href="https://erkanerol.github.io/post/debugging-k8s-services/#disqus_thread">Comments</a><br><a href="https://erkanerol.github.io/categories/software">Software</a><a href="https://erkanerol.github.io/categories/k8s">k8s</a><a href="https://erkanerol.github.io/categories/en">EN</a></span></p><p>While developing/debugging applications that serve services on k8s in production, you need some tools/commands. This blog post explains three different scenarios+tools for you.</p><blockquote><p>Please ping me if there is something wrong. <a href="https://twitter.com/erkan_erol_">https://twitter.com/erkan_erol_</a></p></blockquote><h2 id="setup">Setup</h2><p>Here is our basic setup to explain the scenarios.</p><p><img src="https://erkanerol.github.io/img/k8s-services/Setup.png" title="Setup"></p><p>We have 3 services. <code>service-front</code> is exposed to the public via an ingress. <code>service-front</code> depends on <code>service-middle</code> and <code>service-middle</code> depends on <code>service-back</code>. The communications are done through k8s services.</p><p>To install this setup, here are the necessary commands:</p><pre><code>kubectl create ns service-debug
kubectl -n service-debug run service-back --image=erkanerol/service-back:v1 --port=8080 --expose=true --labels="app=back"
kubectl -n service-debug run service-middle --image=erkanerol/service-middle:v1 --port=8081 --expose=true --labels="app=middle"
kubectl -n service-debug run service-front --image=erkanerol/service-front:v1 --port=8082 --expose=true --labels="app=front"
</code></pre><p>Here is the source code of these services: <a href="https://github.com/erkanerol/service-examples-for-blog">https://github.com/erkanerol/service-examples-for-blog</a></p><h4 id="scenario">Scenario:</h4><p>As a developer, I want to send some requests to <code>service-back</code> directly and see the result without touching the other services.</p><h4 id="problem">Problem:</h4><p><code>service-back</code> is not exposed to the public and you cannot send requests to it directly.</p><h4 id="solution">Solution:</h4><p>With <code>kubectl port-forward</code>, it is possible to open a tunnel from your local machine to the <code>service-back</code> in the cluster. See <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward">https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward</a></p><h4 id="steps">Steps:</h4><p>Run the command below in a terminal.</p><pre><code>$ kubectl -n service-debug port-forward service/service-back 8080:8080
Forwarding from 127.0.0.1:8080 -&gt; 8080
Forwarding from [::1]:8080 -&gt; 8080
</code></pre><p><br>Then run the curl command below in another terminal to see that you are able to access <code>service-back</code></p><pre><code>$ curl localhost:8080
Timestamp from back:1614508193
</code></pre><h4 id="how-does-it-work">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level1.png" title="Level1"></p><p><code>kubectl</code> starts a process which binds <code>localhost:8080</code>. It listens that port and establishes a connection to api-server, which forwards the requests to <code>service-back</code>.</p><h4 id="scenario-1">Scenario:</h4><p>As a developer, I want to run <code>service-front</code> in my local machine so that I can put breakpoints in my IDE to debug my application.</p><h4 id="problem-1">Problem:</h4><p><code>service-front</code> is designed to run in Kubernetes and it accesses <code>service-middle</code> via the k8s service. The service name is hardcoded or hard to be configurable or you are too lazy to mock the dependencies in your local machine.</p><h4 id="solution-1">Solution:</h4><p><code>kubefwd</code> is a useful tool for this problem. It does bulk port-forwarding and manages dns entries in your local machine. See <a href="https://github.com/txn2/kubefwd">https://github.com/txn2/kubefwd</a></p><h4 id="steps-1">Steps:</h4><p>Run the command below in a terminal</p><pre><code>$ sudo KUBECONFIG=$KUBECONFIG kubefwd svc -n service-debug -l app=middle
</code></pre><blockquote><p>Note that <code>kubefwd</code> requires root privileges and it has to be run with <code>sudo</code>. Set <code>KUBECONFIG</code> variable without any home folder reference beforehand.</p></blockquote><p>In another terminal, run <code>front</code> application in your local machine. Note that you can run it in debug mode as well and put breakpoints.</p><pre><code>$ cd /tmp
$ git clone https://github.com/erkanerol/service-examples-for-blog.git
$ cd service-examples-for-blog/front
$ go run main.go
</code></pre><p>In another terminal, Send a request to <code>front</code> app to see that your front app serves locally and it accesses <code>service-middle</code> in the cluster.</p><pre><code>$ curl localhost:8082
Response from service middle:'Response from service back:'Timestamp from back:1614513901''
</code></pre><h4 id="how-does-it-work-1">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level2.png" title="Level2"></p><p>As you can see from the logs of <code>kubefwd</code></p><pre><code>...
INFO[14:07:38] 'cat /etc/hosts' to see all host entries.    
INFO[14:07:38] Loaded hosts file /etc/hosts                 
INFO[14:07:38] HostFile management: Original hosts backup already exists at /root/hosts.original 
...
INFO[14:07:38] Port-Forward: 127.1.27.1 service-middle:8081 to pod service-middle:8081 
...
</code></pre><p>It starts a process that binds <code>127.1.27.1:8081</code> and manipulates the <code>/etc/hosts</code> for <code>service-middle</code></p><pre><code>$ cat /etc/hosts |grep service-middle
127.1.27.1       service-middle.default service-middle.default.svc service-middle.default.svc.cluster.local service-middle.default.minikube service-middle.default.svc.minikube service-middle.default.svc.cluster.minikube service-middle service-middle.service-debug service-middle.service-debug.svc service-middle.service-debug.svc.cluster.local service-middle.service-debug.minikube service-middle.service-debug.svc.minikube service-middle.service-debug.svc.cluster.minikube
</code></pre><div><p>Then your local <code>front</code> app can access the <code>service-middle</code> like in k8s cluster without any extra effort.</p></div><h4 id="scenario-2">Scenario:</h4><p>As a developer, I want to run <code>service-middle</code> in my local machine so that I can put breakpoints in my IDE to debug my application.</p><h4 id="problem-2">Problem:</h4><p><code>service-middle</code> is designed to run in Kubernetes. It accesses <code>service-back</code> via k8s services. Also, its consumer <code>service-front</code> is running on k8s. The services are not available in your local machine and it is hard to mock all these environments in your local machine.</p><h4 id="solution-2">Solution:</h4><p><code>telepresence</code> is a useful tool for this problem. See <a href="https://www.telepresence.io/">https://www.telepresence.io/</a></p><h4 id="steps-2">Steps:</h4><p>Delete <code>service-middle</code> from your k8s cluster at first. We will run it locally.</p><pre><code>kubectl -n service-debug delete service service-middle --ignore-not-found=true
kubectl -n service-debug delete pod service-middle --ignore-not-found=true
</code></pre><p><br>Run telepresence for <code>service-middle</code></p><pre><code>telepresence --namespace service-debug --new-deployment service-middle --expose 8081
</code></pre><p><br>In another terminal, run <code>middle</code> application in your local machine. Note that you can run it in debug mode as well and put breakpoints.</p><pre><code>$ cd /tmp
$ git clone https://github.com/erkanerol/service-examples-for-blog.git
$ cd service-examples-for-blog/middle
$ go run main.go
</code></pre><p><br>In another terminal, run the command below to send a request to <code>service-front</code> via a temporary pod in the cluster.</p><pre><code>$ kubectl -n service-debug run curl -it  --rm=true --image=curlimages/curl --restart=Never -- http://service-front:8082 
Response from service middle:'Response from service back:'Timestamp from back:1614517363''pod "curl" deleted
</code></pre><p>Note that your request goes to <code>service-front</code> in k8s, which sends a request to <code>service-middle</code> in your local machine, which sends a request to <code>service-back</code> in the cluster.</p><h4 id="how-does-it-work-2">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level3.png" title="Level3"></p><p>Basically, <code>telepresence</code> deploys a proxy/fake agent into cluster and opens a two-way tunnel between your local environment and the cluster via that agent. Then you are able to run the <code>middle</code> service in your local machine without adapting the consumers/dependent services.</p><p>A detailed explanation about how telepresence works is available here: <a href="https://www.telepresence.io/discussion/how-it-works">https://www.telepresence.io/discussion/how-it-works</a></p><h2 id="summary">Summary</h2><ul><li>If you need to access a service without exposing it to public, <code>kubectl port-forward</code> is enough.</li><li>If you need to run a service locally for debugging and your service needs to access other services on k8s, <code>kubefwd</code> is enough. It manages DNS entries in your local machine and opens a one-way tunnel from your machine to cluster for the dependencies of your service.</li><li>If you need to run a service locally for debugging and your application has some consumers in the cluster, <code>telepresence</code> is your tool. It opens two-way network channel and it forwards requests from cluster to your local instance as well.</li></ul><p>p.s. Admission webhooks in Kubernetes are similar to <code>service-middle</code>. They receive some requests from api-server and they may send some requests to other services in the cluster. Therefore, <code>telepresence</code> is a useful tool for debugging admission webhooks. In the next blog post, I am going to explain how to debug validating webhooks.</p></div></div></div>]]>
            </description>
            <link>https://erkanerol.github.io/post/debugging-k8s-services/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294015</guid>
            <pubDate>Sun, 28 Feb 2021 15:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Developers Still Want Swag?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26293564">thread link</a>) | @domrdy
<br/>
February 28, 2021 | https://codesubmit.io/blog/do-developers-want-swag/ | <a href="https://web.archive.org/web/*/https://codesubmit.io/blog/do-developers-want-swag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                
                <div>
                    <p>Over the years, company merchandise or, as the cool kids call them, swag (which stands for ‚Äústuff we all get‚Äù), especially from tech companies, has become something of a talking point and even a status symbol in some circles. </p><p>For some, it‚Äôs a status symbol to signal to others that you‚Äôre old school, you were around before <em>it all began</em>. As one <a href="https://qr.ae/pNjt1g">Quora user</a> pointed out, ‚Äúwhat you really want is the swag from companies that looked impressive, but then died... You want that Enron keychain. You want the stuff that says, <em>I was there. I'm still here. They're not.</em> It makes a statement. ‚Äù </p><p>For others, it‚Äôs not about getting yet another Google water bottle or Facebook T-shirt. It‚Äôs about getting really useful stuff that‚Äôs durable, exclusive and memorable. That could be a <a href="https://qr.ae/pNjttJ">messenger bag from Quora</a>, a <a href="https://www.kapwing.com/blog/what-happened-when-we-asked-200-companies-for-free-swag/">Tile from Airtable</a>, or <a href="https://www.kapwing.com/blog/what-happened-when-we-asked-200-companies-for-free-swag/">an apron from Airbnb</a>. </p><p>According to <a href="https://swapnil.net/">Swapnil Agarwal</a>, the developer behind <a href="https://devswag.io/">DevSwag</a>, a site that curates opportunities for developers to collect swag, developers love swag because it helps them find their community. </p><blockquote><em>‚ÄúFor some developers, scoring swag feels like a badge of honor, achievement unlocked! They are more than happy to don a tee with a geeky quote or put a sticker on their laptop. This helps them project their preferences and find their tribe easily.‚Äù </em></blockquote><h3 id="why-do-companies-bother-with-swag"><strong>Why do companies bother with swag? </strong></h3><p>Companies invest in swag for various reasons. The most obvious one is to create hype and buzz around your brand. Did you know that one of the <a href="https://brightideaspromotional.co.uk/info/the-history-of-the-promotional-merchandise-industry/">earliest forms of swag</a> were the commemorative buttons produced to celebrate George Washington becoming the first President of the newly formed United States of America in 1789? It was 100 years later when two printers in Ohio, Jasper Meek and Henry Beach, realized that they could print advertisements on school bags, card cases and even horse hats, that the swag industry really began. </p><p>Since then, companies have been using swag to promote their brand, products and services. Think about those Slack socks, and <a href="https://twitter.com/tferriss/status/320447454657003520?lang=en">Tim Ferriss‚Äô favorite Duolingo shirt</a>. The exposure those companies got from their swag, and still do to this day, is an investment that has definitely paid off. </p><p>Swag is also a good way to market to your own employees or show them your appreciation. It is also a great <a href="https://qz.com/work/1860082/employee-swag-is-a-remote-worker-culture-builder/">physical representation of a company's culture</a>. With the pandemic keeping people at home and employees working remotely, company swag offers that little bit of ‚Äúconnectedness‚Äù that we used to get from conversations around the coffee machine. &nbsp;</p><p>Companies are also using swag to incentivize people to contribute or engage with a brand or products. ‚ÄúLet's say (a company) wants to get beta users for a dev tool. It's far easier to get them with swag giveaways rather than traditional advertising,‚Äù says Swapnil.</p><p>Launched in 2018, <a href="https://devswag.io/">DevSwag</a> curates different opportunities available for developers to collect swag, and ranks the task difficulty for each opportunity. Tasks and rewards range from leaving a review for a podcast in exchange for stickers, to fixing a bug in exchange for a pair of socks. </p><figure><img src="https://codesubmit.io/blog/content/images/2021/02/swapnil-agarwal-devswag-1.png"></figure><h3 id="who-s-giving-out-swag"><strong>Who‚Äôs giving out swag? </strong></h3><p>The <a href="https://www.prnewswire.com/news-releases/asi-reports-2019-promo-sales-hit-high-of-25-8-billion-301010174.html">Advertising Speciality Institute</a> (ASI) reported that sales for company merchandise rose by 4.7% compared to 2018, &nbsp;reaching a record high of USD 25.8 billion in 2019. </p><p>At the height of the promotional products industry, the team at <a href="https://www.kapwing.com/blog/what-happened-when-we-asked-200-companies-for-free-swag/">Kapwing</a> noticed that companies seemed to be giving out swag liberally and wanted to test out how common this was. So, they posed as college seniors ‚Äúfan mailing‚Äù 201 companies asking if they could get some swag. </p><figure><img src="https://lh5.googleusercontent.com/rGPMgvcTt4KKhIrcgICRVaaLcLqUBPx6ZDykvj2O426dHotfPZDHP7FBx9dMPLAI9YNP2DzBdetRrZsT6vnX3B2k0_nJ_mTpcKNCUzyfGNX7RxO50JckzK013wyzXDFZT74STRby"><figcaption>Source: Kapwing</figcaption></figure><p>Out of 201 companies, they successfully contacted 188 of them. They eventually received a response from 146 companies. Of those, they noted that B2C companies were more likely to respond than B2B companies, and B2C companies were more likely to offer swag than B2B companies. </p><p>Interestingly, tech or SaaS companies were the least likely to respond compared to other business types like apparel, beverage, and consumer goods. Their response rate was at 64% compared to other business types (82% to 87%). They also found that small to medium sized companies were more likely to give out company swag; these are companies with 11 to 49 employees, or companies with 50 to 249 employees respectively. </p><h3 id="is-swag-losing-its-swag"><strong>Is swag losing its <em>swag</em>?</strong> </h3><p>In 2019, <a href="https://www.theguardian.com/fashion/2019/apr/03/patagonia-fleece-vest-tech-bro-uniform">Patagonia</a> decided to shift its sales program to only work with companies that meet certain social and environmental standards, or in their words ‚Äúmission-driven companies that prioritize the planet‚Äù. &nbsp;The company now requires more information about the type of company ‚Äúwhose name will appear on the Patagonia product and how the product will be used. We reserve the right to refuse service.‚Äù</p><p>Just as companies are becoming more conscious about what their brands stand for, their swag, their suppliers and swag recipients are becoming increasingly integrated into the brand‚Äôs narrative. The public‚Äôs perception of a brand, especially those of global powerhouses like Google, Facebook, Netflix, and Amazon, largely impact the swaggi-ness of a brand‚Äôs swag. </p><p>In January 2021, in light of Facebook banning former US President Donald Trump on social media, Facebook‚Äôs internal security team released a memo warning employees not to wear or carry Facebook-branded swag in public. As reported by <a href="https://gizmodo.com/facebook-warns-employees-not-to-wear-company-gear-in-pu-1846040220">Gizmodo</a>, ‚Äúwhile the memo doesn‚Äôt appear to explicitly say Facebook employees are at risk of physical assault by Trump supporters, it‚Äôs easy to read between the lines‚Äù.</p><p>Public perception and public events also play a large role in the perceived swaggi-ness of a company. Just a week after Facebook‚Äôs memo, <a href="https://www.businessinsider.com/goldman-sachs-rebrands-storm-hill-event-capitol-violence-washington-dc-2021-1">Goldman Sachs</a>, had to quickly rebrand a virtual event they had organized to lobby Congress to help small businesses across America. The event that was originally called ‚ÄúStorm the Hill‚Äù definitely did not sit well with both organizers nor participants after what happened in Washington DC, and participants were urged not to wear the branded t-shirts that were mailed out to them prior.</p><p>Another factor that keeps swag cool and swaggy is its exclusivity. Slack‚Äôs socks, once exclusive, have now made their way to <a href="https://slack.shop/">Slack.shop</a>. Slack fans can now buy a pack of six pairs of socks for ‚Ç¨49.80 along with a Slack t-shirt and a baby onesie. </p><figure><img src="https://codesubmit.io/blog/content/images/2021/02/slack-socks-1.png"><figcaption>The exclusivity of Slack's socks are gone, but fans and aspiring employees can <em>almost</em> live the dream by purchasing them online.</figcaption></figure><h3 id="the-environmental-impact-of-swag"><strong>The environmental impact of swag</strong></h3><p>At the end of 2019, the Meeting, Incentives, Conferences and Events (MICE) industry was <a href="https://www.cwt-meetings-events.com/futuretrends/page/3/1">expected to grow by USD 840 billion (8%) in 2020</a> with 52% more event websites popping up compared to 2019. CWT Meetings and Events reported that companies were spending 25% to 30% of their overall marketing budgets on live events. </p><p>It is common for people to attend these conferences and collect as many tote bags, t-shirts, water bottles, usb sticks, pens, stress balls, stickers, notebooks, hats, rubber wrist bands, beer bottle openers, and everything else that can be made cheaply and quickly, with a company‚Äôs logo slapped on for swagginess. </p><p>As <a href="https://www.fastcompany.com/90260185/its-time-to-stop-spending-billions-on-cheap-conference-swag">Elizabeth Segran</a> wrote, many of these companies‚Äô merchandise aren‚Äôt well made or well designed, meaning that we‚Äôre likely to throw them out after just a handful of uses. </p><blockquote><em>‚ÄúWhen you think about all the energy and resources that go into making just one of the tote bags that I have just thrown into the trash‚Äìonly to end up in a landfill‚Äìthe impact is staggering.‚Äù</em></blockquote><p>A quick Google search will show you that companies often compete over costs, but low costs comes at a high price for workers in countries like China, where most of these promotional products are made. By now, we‚Äôre aware of <a href="https://www.globalsources.com/NEWS/SIC-making-it-in-china-the-factory-workers-that-make-your-products.HTM">poor working conditions</a>, lack of safety standards, and very low wages. </p><p>This is why companies like Google have a vetted list of merchandise suppliers they work with‚Äîcompanies that sustainably source their materials and do not violate labour laws, meaning without child labour or inhumane working conditions. This could be the way forward for other companies who want to invest in company merchandise. </p><p>For Segran, the answer to both creating hype while reducing swag‚Äôs impact on the environment is to get rid of it entirely. As an alternative, she writes, ‚Äúconsider offering experiences. For instance, I‚Äôd appreciate a back massage at a conference, or perhaps a yoga class, or a free headshot. I‚Äôd even enjoy a good meal instead of a swag bag.‚Äù </p><p>She continues, ‚Äúif you wrap the event in your branding, there‚Äôs a good chance your target customer will remember that experience long after the tote bag is stuffed in a landfill somewhere.‚Äù</p><h3 id="to-swag-or-not-to-swag"><strong>To swag or not to swag?</strong></h3><p>A quick browse of some HR groups on Facebook and LinkedIn uncover conversations where HR professionals are debating whether to give out company merchandise to employees over the recent year-end holidays, or if they should opt for gift cards as they‚Äôre a more ‚Äúpractical‚Äù way to support employees in this economic climate. Many rallied behind gift cards, especially the ever-versatile Visa gift cards, accepted nearly everywhere in the United States.</p><p>But if we‚Äôre real here, a multi-billion dollar industry is not going to disappear overnight or any time in the near future. In fact, ASI reported that while total swag sales dropped by 44% in Q2 2020, it had recovered about 20% of sales in Q3 2020 and a further 8% in Q4 2020. Total product sales for 2020 was USD 20.7 billion. </p><p>With the world going remote and people working from home, what swag did we spend all that money on? In 2020, it comes as no surprise that products like hand sanitizers contributed USD 1.4 billion in sales (7%), while other pandemic-related swag like branded cloth masks and other PPE made up USD 4.6 billion in sales (22%). </p><p>I believe that companies are becoming more intentional with the swag they give out. <a href="https://blog.duolingo.com/thinking-outside-the-box-engaging-our-team-with-interactive-care-packages/">Duolingo</a>, for example, worked with <a href="https://www.swagup.com/">SwagUp</a> to create monthly ‚ÄúInteractive Care Packages‚Äù for employees during the pandemic to break up the monotony of staying at home. The care packages were designed to ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codesubmit.io/blog/do-developers-want-swag/">https://codesubmit.io/blog/do-developers-want-swag/</a></em></p>]]>
            </description>
            <link>https://codesubmit.io/blog/do-developers-want-swag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293564</guid>
            <pubDate>Sun, 28 Feb 2021 14:19:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Stay Sane with Modern C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26293427">thread link</a>) | @AlexeyBrin
<br/>
February 28, 2021 | https://www.cppstories.com/2017/02/how-to-stay-sane-with-modern-c/ | <a href="https://web.archive.org/web/*/https://www.cppstories.com/2017/02/how-to-stay-sane-with-modern-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://www.cppstories.com/2017/images/2017-02-06-how-to-stay-sane-with-modern-c-cppcomplex2.png" alt=""></p>  
          
        

<p>C++ grows very fast! For example, the number of pages of the C++ standard went from 879 pages for C++<sup>98</sup>‚ÅÑ<sub>03</sub> to 1834 for C++20!  Nearly 1000 pages! What‚Äôs more, with each revision of C++, we get several dozens of new features. Have a look at my blog post with <a href="https://www.bfilipek.com/2017/01/cpp17features.html">all C++17 features</a>, it shows 48 items, and <a href="https://www.bfilipek.com/2020/01/cpp20refcard.html">my C++20 reference card</a> lists 47 elements!</p>

<p>Do you need to learn all of that stuff to write good code?</p>

<p>How to stay sane in the C++ world today?</p>

<h2 id="intro">Intro</h2>

<p>You probably know that C++ is a complex language. As I‚Äôve found, there‚Äôs even a whole Wiki page about <a href="https://en.wikipedia.org/wiki/Criticism_of_C%2B%2B">the criticism of Cpp</a>. Modern C++ adds even more stuff to the package!</p>

<p>Here‚Äôs the full data about the page count in the specs that I‚Äôve mentioned before:</p>

<ul>
<li>C++<sup>98</sup>‚ÅÑ<sub>03</sub> - 879, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1905.pdf">N1905, Oct  2005</a></li>
<li>C++11 - 1324, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf">last draft, N3337, Jan  2012</a></li>
<li>C++14 - 1368, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf">last draft, Nov 2014</a></li>
<li>C++17 - 1586, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4606.pdf">draft, N4606</a></li>
<li>C++20 - 1834, <a href="https://timsong-cpp.github.io/cppwp/n4861/draft.pdf">draft, N4861</a></li>
</ul>

<p><img src="https://1.bp.blogspot.com/-NlWWmBI1jU4/X3q-pFyEtNI/AAAAAAAAExo/JYKpY-hn6Mk4x8x8RYf_amP-Px_N46vaQCLcBGAsYHQ/s0/cpp_spec_pages_count.png" alt=""></p>

<p>It looks like C++17 is almost ~80% ‚Äòlarger‚Äô than C++<sup>98</sup>‚ÅÑ<sub>03</sub>, and the latest draft of C++ has nearly 1000 pages more than C++03. You can complain about added complexity and that it‚Äôs hard to learn all of those things. But is this so terrible? What can you do about the whole situation?</p>

<p>This post was motivated by some stories recently found::</p>

<ul>
<li><a href="https://news.ycombinator.com/item?id=13491699">HN: C++11 FAQ</a></li>
<li><a href="https://www.reddit.com/r/programming/comments/4zo5p7/lvalues_and_rvalues_used_to_be_simple_things_now/">r/programming, lvalues and rvalues used to be simple things. Now,  only a handful of people truly understand all facets of C++ value  categories.</a></li>
<li><a href="https://news.ycombinator.com/item?id=11720659">Why I don‚Äôt spend time with Modern C++ anymore | Hacker News</a></li>
<li><a href="https://www.reddit.com/r/programming/comments/5q9u05/modern_c_features_decltype_and_stddeclval/">r/programming, Modern C++ Features ‚Äì decltype and std::declval</a></li>
<li><a href="https://www.reddit.com/r/cpp/comments/dxqq5v/reading_this_sub_for_an_hour_has_made_me_crazy/">Reading this sub for an hour has made me crazy. : cpp</a></li>
<li><a href="https://www.reddit.com/r/cpp/comments/dnr2e1/abi_now_or_never/">ABI: Now or Never : cpp</a></li>
</ul>

<p>But to have a balance and something positive, there‚Äôs also a discussion like this one:</p>

<p><a href="https://www.reddit.com/r/cpp/comments/hebc9f/i_am_a_developer_and_just_started_learning_c_and/">I am a developer and just started learning C++, and I‚Äôm LOVING it! Programs feel real for the first time! : cpp</a></p>

<p>Maybe it‚Äôs not that bad after all? :)</p>

<p>First, let‚Äôs see some problems that you might bump into in C++.</p>

<h2 id="some-problems">Some Problems</h2>

<p>To name a few:</p>

<ul>
<li>Too slow pace</li>
<li>Too fast pace</li>
<li>Confusion/complexity of features</li>
<li>Slow compilation Times</li>
<li>Lack of dependency management</li>
</ul>

<p>Let‚Äôs look at those in more detail.</p>

<h3 id="too-slow-pace">Too slow pace</h3>

<p>In 2017 we got C++17. While it‚Äôs great, that we get a new standard every three years, a lot of developers complained that the new version is not what everyone waited for.</p>

<p>A lot of features: like concepts, modules, ranges, co-routines, ‚Ä¶ were not accepted and we need to wait at least three more years to get them in the spec.</p>

<p>Now, in 2020, we have C++20 ready, and those significant features are shipping with compilers! Yet, we can complain that contracts are not present, reflection, executors or networking is still being discussed. They might appear in C++23 or even later.</p>

<p>It looks like some features are slower to accept‚Ä¶ .and there will always be something to complain.</p>

<h3 id="too-fast-pace">Too fast pace</h3>

<p>As usual, we might have two contradicting opinions here. Although for some people the pace is slow, for others it‚Äôs hard to keep up with the changes.</p>

<p>You‚Äôve just learned C++11/14‚Ä¶ and now you need to update the knowledge with C++17, and then C++20 is along the way. Three years is not that short time, but bear in mind the compiler conformance, company policies, team guidelines might walk at a different pace.</p>

<p>Do your companies update to the most modern C++ version immediately or wait a couple of years?</p>

<h3 id="confusion-complexity-of-features">Confusion / complexity of features</h3>

<p>Just read that comment:</p>

<p><a href="https://www.reddit.com/r/programming/comments/4zo5p7/lvalues_and_rvalues_used_to_be_simple_things_now/d6xs9db/">CallMeDonk</a></p>

<blockquote>
<p>I love c++. It‚Äôs my go to language, but you have to admit its ‚Äòhodge podge‚Äô implementation of value types is bizarre at best. Most programmers including me prefer simple well-defined language constructs over bizarre and over complicated grammar. I‚Äôm not a computer language lawyer. I‚Äôm a programmer.</p>
</blockquote>

<p>Is C++ clear in every aspect? Probably not‚Ä¶</p>

<p>Here are some topics that might be hard to understand and might cause confusion among programmers:</p>

<h4 id="move-semantics">Move semantics</h4>

<p>The principle of move semantics are quite clear: instead of copying try to ‚Äústeal‚Äù the guts of the managed resources, and you should get a nice performance boost. But the devil is in the detail.</p>

<p>I don‚Äôt write a lot of generic code, so, fortunately, I don‚Äôt have to think about move semantics all the time. But I was quite confused when I bumped into move and const - see <a href="http://www.bfilipek.com/2017/01/const-move-and-rvo.html">my last article on that</a>. I don‚Äôt believe every C++ will understand the rules here. Especially that you now need to remember about six default operations generated by the compiler: default constructor, destructor, copy constructor, move
constructor, assign operator and move assignment operator.</p>

<h4 id="rvalues-xvalues-prvalues-myvalues-foovalues">Rvalues/xvalues/prvalues‚Ä¶ myValues, fooValues</h4>

<p>The last ones are made up‚Ä¶ but still having all of the value categories is overwhelming!</p>

<p>In C (or C++<sup>98</sup>‚ÅÑ<sub>03</sub>) you just had to know lvalue vs rvalue, now it‚Äôs a bit more subtle.</p>

<p>Still, the question is if you need to know it by heart?</p>

<p>Some good comments:</p>

<p><a href="https://www.reddit.com/r/programming/comments/4zo5p7/lvalues_and_rvalues_used_to_be_simple_things_now/d6xh562/">c0r3ntin</a></p>

<blockquote>
<p>It is complicated, but not on a daily basis.
Can this value be addressed ? can it be copied ? can it be moved ?
Should it be moved ? There is very few situation where you want to actively to be very
specific and need a full understanding. ( templated library writing, hot paths, etc).<br>
Most of the time C++ is not more complicated than java or something.
Sadly this is lost on most people. C++ may be the most complex language out there but you can write very good code without caring about the specific.<br>
BigObject o = getBigObject();</p>
</blockquote>

<h4 id="initialization">Initialization</h4>

<p>18 ways now (as of C++17)! - <a href="https://tartanllama.github.io/c++/2017/01/20/initialization-is-bonkers/">Initialization in C++ is bonkers</a> and the <a href="https://www.reddit.com/r/cpp/comments/5p5ed7/initialization_in_c_is_bonkers/">r/cpp thread</a></p>

<h4 id="templates-and-template-deduction">Templates (and Template deduction)</h4>

<p>I was quite lost when I saw all the changes for C++17; there are so many details about templates!</p>

<p>The same situation happens in C++20, where we have a significant and long-awaited improvement: concepts -  which revolutionise C++!</p>

<p>Yet, if you want to learn templates, it might be overwhelming at first.</p>

<h3 id="abi">ABI</h3>

<p>With the growing list of new features, it might be tempting to ‚Äústart from scratch‚Äù and fix old issues in the design of C++. But the principle of the language is that it cannot break old code, so that why the Committee is so restrictive and don‚Äôt like to change the way how features are introduced.</p>

<p>There‚Äôs no right answer to this issue, but in any way, it‚Äôs good to have a well-discussed topic rather than a rushed move.</p>

<h3 id="lack-of-dependency-management-tools">Lack of Dependency Management Tools</h3>

<p>We can complain that C++ is not ‚Äúshipping‚Äù with a cool dependency management system. But the reality is that it might not happen in the foreseeable future. Having a ‚Äústandard‚Äù package manager is a tough choice, especially that it would have to handle so many different platforms and systems where C++ is available.</p>

<h3 id="not-safe-enough">Not Safe Enough</h3>

<p>Some time ago, you could read some of the articles (<a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/">this</a> and <a href="https://www.zdnet.com/article/microsoft-70-percent-of-all-security-bugs-are-memory-safety-issues/">that</a>)where they mentioned:</p>

<blockquote>
<p>Roughly 70% of all serious security bugs in the Chrome codebase are memory management
and safety bugs, Google engineers said this week.</p>
</blockquote>

<p>And similarly for Microsoft. Since most of the code is C or C++, then everyone blames C++ for not being safe enough.</p>

<h3 id="others-areas">Others areas?</h3>

<p>What are your main problems with the language?</p>

<p>So far, we‚Äôve discussed some problems‚Ä¶ so how to live with them? Is there a chance to solve those issues?</p>

<h2 id="how-to-stay-sane">How to Stay Sane</h2>

<p>There‚Äôs no perfect programming language; every one of them has some issues. Here are my suggestions on how to cope with the problems of Modern C++:</p>

<ul>
<li>Stay positive</li>
<li>Use best guidelines</li>
<li>Use best tools</li>
<li>Stay up to date</li>
<li>Don‚Äôt open the hood</li>
<li>Use what you need</li>
<li>Incremental change</li>
<li>Last resort: your old code is still safe and compiles</li>
</ul>

<h3 id="stay-positive-the-language-is-evolving">Stay positive, the language is evolving</h3>

<p>No one wants to write code using old syntax and constructs. We‚Äôve already seen a lot of complaints about old C++ before C++11. It took almost 13 years (counting from major C++98, not including minor C++03) to came up with the major version: C++11. Now we can be happy that we get back on track, and every three years there will be some changes. At the end of the day, you cannot say that your language is dead and old.</p>

<p>While some of the features are huge and can bring confusion or more things to learn, things are more straightforward than harder:</p>

<ul>
<li>Most of  those 1000 new pages that were added after C++03 are for the Standard Library. This means that you have more helpers and sub-systems you can use, without the need to find third-party libraries. That definitely makes your life easier.</li>
<li>For move semantics, you can rely on library types as they will do the right job for you. For example, you can now safely return <code>std::vector</code> and be sure that it might be moved or even elided and no extra copy will be needed.</li>
<li>For templates, it‚Äôs getting easier and easier. Concepts make code safes, without tricks like SFINAE. What‚Äôs more, we have <code>constexpr</code> and <code>auto</code> which makes generic code even simpler (almost like a regular code).</li>
<li>As for the safety: Hava look here at automatic tools for the safety profile for C++ Guidelines. <a href="https://devblogs.microsoft.com/cppblog/new-safety-rules-in-c-core-check/">New safety rules in C++ Core Check | C++ Team Blog</a>. We can expect new and better tools that perform code analysis or even instrumentation to find potential safety issues as fast as possible. Or here <a href="https://www.youtube.com/watch?v=_pQGRr4P16w">Closing the Gap between Rust and C++ Using Principles of Static Analysis - Sunny Chatterjee - CppCon</a></li>
</ul>

<h3 id="use-guidelines">Use Guidelines</h3>

<p>If you‚Äôre lost with many different aspects of C++ code, then you should reach for C++ Core Guidelines. It‚Äôs created by the community of dedicated and passionated C++ developers, and the main editors are Herb Sutter and Bjarne Stroustrup.</p>

<p>See here:</p>

<p><a href="https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md">C++ Core Guidelines @Github</a></p>

<p>And here‚Äôs a nice looking web site:</p>

<p><a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">C++ Core Guidelines - Website</a></p>

<p>Just type the issue you are facing (for example <code>return value</code>), and you can easily find the advice - for example: <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rf-out-multi">Guideline: Return values</a></p>

<p>Using those guidelines will save you a lot of time, and you can learn some good patterns very quickly.</p>

<h3 id="and-the-tools-as-well">And the tools as well!</h3>

<p>Thanks to Clang and also improved development speed in other platforms, we get tools like:</p>

<ul>
<li><a href="http://clang.llvm.org/extra/clang-tidy/index.html">Clang Tidy</a>
(previously clang- modernise)</li>
<li><a href="https://clang.llvm.org/docs/ClangFormat.html">Clang Format</a></li>
<li><a href="https://clang-analyzer.llvm.org/">Clang Static Analyzer</a></li>
<li><a href="http://www.wholetomato.com/">VisualAssist</a></li>
<li><a href="https://www.jetbrains.com/resharper-cpp/">Clion/Resharper C++</a></li>
<li>VisualStudio - tools like <a href="https://www.nuget.org/packages/Microsoft.CppCoreCheck">C++ Core     Checker</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cppstories.com/2017/02/how-to-stay-sane-with-modern-c/">https://www.cppstories.com/2017/02/how-to-stay-sane-with-modern-c/</a></em></p>]]>
            </description>
            <link>https://www.cppstories.com/2017/02/how-to-stay-sane-with-modern-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293427</guid>
            <pubDate>Sun, 28 Feb 2021 13:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Email Cleaner: Clean tracking links and pixels from email newsletters]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26293424">thread link</a>) | @bengtan
<br/>
February 28, 2021 | https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/ | <a href="https://web.archive.org/web/*/https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
  <article>
    

    

    
    
    <h2>Overview</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#what-is-it">What is it?</a></li>
    <li><a href="#email-cleaner">Email Cleaner</a></li>
    <li><a href="#getting-started">Getting started</a>
      <ul>
        <li><a href="#forwarding-loops">Forwarding loops</a></li>
      </ul>
    </li>
    <li><a href="#how-it-works">How it works</a></li>
    <li><a href="#benefits">Benefits</a></li>
    <li><a href="#plain-text-emails">Plain text emails</a></li>
    <li><a href="#caveats">Caveats</a></li>
    <li><a href="#privacy">Privacy</a></li>
    <li><a href="#feedback">Feedback</a></li>
  </ul>
</nav>
    <p>I‚Äôm supposed to be blogging instead of doing <a href="https://bengtan.com/blog/app-startup-vs-content-startup/">‚Äúapp startup‚Äù</a> things but I got sidetracked and built another side project (again).</p>
<p>I‚Äôve been getting into email newsletters. Over the last month, I‚Äôve gone from zero newsletters to eleven of them. My inbox is now overflowing with newsletters. Maybe I‚Äôll have to cut back but that‚Äôs a story for another time.</p>
<p>I have a new pet hate: Links in email newsletters.</p>
<p>They are user-hostile. Substack is the worst. Their URLs look like this:</p>
<p><a href="http://email.substack.com/c/ejXDKM2OhCAMgJ9muI3hT3QOHPayr2EKVIesgwbquL794njbhEIhNP36eSCclnzYdSnEzm2gY0WbcC8zEmFmW8E8xGBlb1pljGTBdsJpLVksw5gRXxBnS3lDtm5ujh4oLulTIVvJnjbgCKC51hxawbuuxzCCcwHAo0CprrawhYjJo8U35mNJyGb7JFrLTX3d5Hdd-743CWjL2PjlVR8gU_qZLpoGLdre3LkUd87Vw9wrnZX1ymUN3XbtoxENjIYbFKBVq3wrxlF47oLolZNKonrcNC-bKwT-RzT4u1aKRBHmd8S99mTZOkwTQRL153TOfZKcYw_1fG0p0jFgAjdjuIzQJfbjaJgwYa7CwwBkhRGq75Xu-4fpLgVVmZKdFNUzqxxhqVXJ_uP4AyNKkNQ">http://email.substack.com/c/ejXDKM2OhCAMgJ9muI3hT3QOHPayr2EKVIesgwbquL794njbhEIhNP36eSCclnzYdSnEzm2gY0WbcC8zEmFmW8E8xGBlb1pljGTBdsJpLVksw5gRXxBnS3lDtm5ujh4oLulTIVvJnjbgCKC51hxawbuuxzCCcwHAo0CprrawhYjJo8U35mNJyGb7JFrLTX3d5Hdd-743CWjL2PjlVR8gU_qZLpoGLdre3LkUd87Vw9wrnZX1ymUN3XbtoxENjIYbFKBVq3wrxlF47oLolZNKonrcNC-bKwT-RzT4u1aKRBHmd8S99mTZOkwTQRL153TOfZKcYw_1fG0p0jFgAjdjuIzQJfbjaJgwYa7CwwBkhRGq75Xu-4fpLgVVmZKdFNUzqxxhqVXJ_uP4AyNKkNQ</a></p>
<p>What is that, Substack?! Is that really a URL with 400+ characters?!</p>
<p>I have an ingrained habit of hovering over links. This allows me to see where it links to and decide whether to click on it.</p>
<p>It‚Äôs a good habit.</p>
<p>It‚Äôs also a security ‚Äúbest practice‚Äù. Hovering over a link helps to check whether it‚Äôs a phishing link.</p>
<p>Email newsletters have broken this. I have no idea where these user-hostile links go. For their own self interest, mailing list service providers have denied me a basic tenet of the web: Knowing what I‚Äôm clicking on before I click.</p>
<p>It‚Äôs also demeans the newsletter. A newsletter which purports to send me a ‚Äòlist of interesting links‚Äô is just sending me a list of crap because I‚Äôm not clicking on those I-have-no-idea-where-it‚Äôs-going links.</p>
<p>If the link was something like <a href="http://www.google.com/url?sa=t&amp;url=https://www.wikipedia.org/&amp;usg=AOvVaw3ay7vaEtH0yTTYdDmrvinX">http://www.google.com/url?sa=t&amp;url=https://www.wikipedia.org/&amp;usg=AOvVaw3ay7vaEtH0yTTYdDmrvinX</a> I wouldn‚Äôt be as peeved because I can see where it links to.</p>
<p>But no, I don‚Äôt think they‚Äôll compromise.</p>
<p>Not happy.</p>
<p>I set about trying to make the situation palatable. I asked <a href="https://news.ycombinator.com/item?id=26188976">here</a>, <a href="https://www.reddit.com/r/SomebodyMakeThis/comments/ln4dep/smt_hover_over_links_in_email_newsletters_and_see/">here</a>, and <a href="https://www.indiehackers.com/post/17a17962db">here</a> but I didn‚Äôt find anything satisfactory.</p>
<p>So I built my own solution.</p>
<h2 id="what-is-it">What is it?</h2>
<p>I hooked a script up to an email address. Upon receiving an email, the script will replace tracking links with their destination URL, remove tracking pixels, and send it back to the sender.</p>
<p>Then, I set up a gmail filter to forward my newsletters to the script.</p>
<p>Yay!</p>
<p>Now, when I receive an email newsletter, gmail forwards it to the script. The script sends it back to me with nice clean URLs. Once again, I can see where links lead to before I decide whether to click.</p>
<p>Tracking parameters (ie. <code>utm_*</code>) and tracking pixels are removed as well. (I don‚Äôt care strongly about this but it was easy to add so I did.)</p>
<h2 id="email-cleaner">Email Cleaner</h2>
<p>For lack of a better name, I‚Äôm calling it <strong>Email Cleaner</strong>. <strong>It cleans crap from email newsletters</strong>.</p>
<p>(Alternatively, I considered calling it ‚Äò<strong>UntrackMe: Remove tracking from email newsletters</strong>‚Äô. Which sounds better?)</p>
<p>I‚Äôm letting others try it. Maybe other people find it useful too. If there‚Äôs enough interest, I‚Äôll turn it into a proper side project.</p>
<h2 id="getting-started">Getting started</h2>
<p>To try Email Cleaner, forward an email newsletter to <code>email-cleaner@bengtan.com</code>.</p>
<p>In a minute or two, you should get the newsletter sent back to you (from <code>no-reply@bengtan.com</code>) with cleaned links and tracking pixels removed.</p>
<p>If you decide you like it, you can set up your email program to automatically forward email newsletters to <code>email-cleaner@bengtan.com</code>.</p>
<p>How you do this depends on your email program so you‚Äôll have to work it out youself.</p>
<p>Note: Please don‚Äôt set up your email program to automatically delete after forwarding. Since this is a new service, it‚Äôs a good idea to retain the original emails in case something goes wrong.</p>
<h3 id="forwarding-loops">Forwarding loops</h3>
<p>If your automatic forwarding configuration mistakenly forwards the cleaned email (from Email Cleaner) back to Email Cleaner, it will detect this and send you an email with the message ‚ÄúInfinite loop detected‚Äù. If you get such an email, please adjust your forwarding configuration so you don‚Äôt forward cleaned emails to Email Cleaner.</p>
<p>If you use gmail (like I do), this can be accomplished by adding the condition <code>-subject:[email-cleaner]</code> to your forwarding filter.</p>
<h2 id="how-it-works">How it works</h2>
<p>Email Cleaner works as follows:</p>
<ul>
<li>It scans the email for links which match the following regular expressions:</li>
</ul>
<div><pre><code data-lang="js">	<span>'\.list-manage\.com/track/click'</span>,
	<span>'//click\.convertkit-mail\.com/'</span>,
	<span>'//email\.substack.*/c/'</span>,
	<span>'//apple\.co/'</span>,
	<span>'//t\.co/'</span>,
</code></pre></div><ul>
<li>If a link matches, then it‚Äôs a tracking link. Email Cleaner crawls the link to see if it‚Äôs a 3xx redirect. If it is, then the link is replaced by the destination URL.
<ul>
<li>Any URL query parameters which are <code>mc_cid</code>, <code>mc_eid</code>, or start with <code>utm_</code> are also removed.</li>
</ul>
</li>
<li>Then, Email Cleaner scans the email for tracking pixels. If any are found, it removes them.</li>
<li>Finally, the email is sent back to the sender.</li>
</ul>
<p>Email Cleaner is quite safe and conservative. It will only crawl links which are obviously tracking links.</p>
<p>Email Cleaner currently handles three major mailing list service providers (MailChimp, ConvertKit, Substack). I‚Äôd happily add more. Just let me know.</p>
<p>Note that Email Cleaner doesn‚Äôt magically bypass the tracking links. Instead, it triggers all of them from a data centre somewhere. It‚Äôs privacy-by-obfuscation instead of privacy-by-abstention. But it does prevent your web browser/IP address/location from being leaked.</p>
<h2 id="benefits">Benefits</h2>
<ul>
<li>Email newsletters are more user friendly. (I‚Äôm more inclined to click on a link if I see it‚Äôs a reputable website.)</li>
<li>Helps detect phishing attacks.</li>
<li>Better user privacy.</li>
<li>Plain text emails are readable again.</li>
</ul>
<h2 id="plain-text-emails">Plain text emails</h2>
<p>The last benefit was an unexpected side effect.</p>
<p>Whilst writing Email Cleaner, I discovered that plain text versions of email newsletters are completely unreadable.</p>
<p>They look something like this:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [htt—Ä://email.substack.com/c/eJxdkc-OgyAQh5-m3Grkr3rgsJd9DQM4WlIFA2O7vv1O2-xlE2CSHzPhy0dwCEsup91zRfY6Rjx3sAmegAiF7BsUE71mvZJcKUa87qgTgpG4mVAAXjYuGssOZN3dEkeLMafPBpOMzFp1wluppHM9Z2FoQQQbnAqd8tx2A7_P2t1HSCNoeEM5cwKy6Blx3R7868F-qkFqjviMK_hom1ym2rrqmr5twVfecTZHLs9tziuJmrWMtqy6kJ0cGtrYoFoF1Aou-ShpCHRsnac9d4wz4MNDtNvuNrTjkzbwu1YNCaNd3hGOZsykaAdpQptonZyur2v3dT1tan7tKeJpIFm3gL954I31Q8hMkKBU3N5Y1FRR3vdc9P2guhtABcZZx2ilTKoOn-tW0v90_AEVdJLl]. At a conference five years earlier [htt—Ä://email.substack.com/c/eJxdkEtuhDAMhk8zWSLyBBZZVKp6jSghDkTDJCiYody-YdhV8kO2bPn3N1qEKZdTr3lDcgWD5wo6wbEtdQVEKOyoUMY4WdEbLY0RbLId90oJFus4F4DNxdViOYDth19jcBhzek8ILdjNDk5xrQxozWenoTNmkL2cvQoimFaZz7PumCKkABYeUM6cgK32hrjXi_y6iG9aIW_7QUS3WJGQm1wWSv2aXwVvMd1jWq7O5wOvmwsUQL26NF3_7qiNRStawVtBW-lODw1v3GxaA9wpqWUgxpmH1k-8l15IAXK4qLYevqILd97Az05sCaNbHxGeTcisWA9pQZc4dS4vG5RuLxkj1e1IEc8RkvMrTB9P-NH9NjcukKDQN0yjQ8sNl30vVd8PpvuIIZFSdIKTfUYcU6apZP9x_AIL9Jrk], however, the concepts were discussed in detail, just not named.&nbsp;</p>
</blockquote>
<p>Is that supposed to be readable?! (It‚Äôs not just Substack. The other providers are almost just as bad.)</p>
<p>Email Cleaner changes it to:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [htt—Äs://en.wikipedia.org/wiki/Dartmouth_workshop]. At a conference five years earlier [htt—Äs://computerhistory.org/blog/thinking-about-machines-and-thinking/], however, the concepts were discussed in detail, just not named.&nbsp;</p>
</blockquote>
<p>which is moderately readable.</p>
<p>It would be even better if it was:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [0]. At a conference five years earlier [1], however, the concepts were discussed in detail, just not named.&nbsp;</p>
<p>[0] htt—Äs://en.wikipedia.org/wiki/Dartmouth_workshop<br>
[1] htt—Äs://computerhistory.org/blog/thinking-about-machines-and-thinking/</p>
</blockquote>
<p>but that‚Äôs a story for another time. (I don‚Äôt know if it‚Äôs worth the effort to do this. Do many people still read emails in plain text?)</p>
<h2 id="caveats">Caveats</h2>
<p>Please note that Email Cleaner is only a proof of concept. It‚Äôs an experiment. I wouldn‚Äôt even call it an MVP.</p>
<p>It‚Äôs useful to me, but I don‚Äôt know if it‚Äôs useful for others. I‚Äôd like to find out.</p>
<p>I don‚Äôt know how long Email Cleaner will last since:</p>
<ul>
<li>It‚Äôs vulnerable to spam (There‚Äôs no authentication or access control), and</li>
<li>It‚Äôs not scalable (It‚Äôs running on a tiny server).</li>
</ul>
<p>Once the spam bots arrive, or too many people use it, it‚Äôll probably have to stop.</p>
<p>Or if there‚Äôs sufficient interest, I‚Äôll rewrite it into a proper side project.</p>
<h2 id="privacy">Privacy</h2>
<p>Please don‚Äôt forward any personal or private emails to Email Cleaner. Only forward publicly available email newsletters (Paid newsletters are okay).</p>
<p>All received emails go to Email Cleaner‚Äôs inbox. I hope to accumulate more test data with which to conduct further research on mailing list service providers and improve Email Cleaner.</p>
<p>There‚Äôs not really a privacy policy. This is an experiment.</p>
<p>If you forward emails to Email Cleaner, I consider that as your opt-in.</p>
<p>Anything you forward to Email Cleaner could be used to improve Email Cleaner.</p>
<p>OTOH, I don‚Äôt know anything about you anyway. All I have is an email address and what email newsletters you subscribe to (whatever can be inferred from that).</p>
<h2 id="feedback">Feedback</h2>
<p>Since this is a new and experimental service, please don‚Äôt expect it to be perfectly reliable nor correct. If you forward an email to Email Cleaner and don‚Äôt get a reply in a few minutes, maybe something broke. Please get in touch with me and I‚Äôd be happy to look into it.</p>
<p>If you have any questions, suggestions, criticisms, etc. ‚Äî please also let me know. I‚Äôd be happy to talk.</p>
<p>I hope you like Email Cleaner! Thanks for reading!</p>




  </article>


  
</div>
    </div></div>]]>
            </description>
            <link>https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293424</guid>
            <pubDate>Sun, 28 Feb 2021 13:55:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toward Predictable Engineering Velocity ‚Äì Accounting]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26293369">thread link</a>) | @dm03514
<br/>
February 28, 2021 | https://on-systems.tech/109-toward-predictable-engineering-velocity-accounting/ | <a href="https://web.archive.org/web/*/https://on-systems.tech/109-toward-predictable-engineering-velocity-accounting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Engineering accounting is a prerequisite to predictability in the same way
standard accounting is a prerequisite to financial predictability. Without a structured
engineering accounting system it‚Äôs not possible to accurately calculate velocity or account for the
type, quantity or latency of work completed. This post describes why an engineering accounting system
is essential to measuring and increasing velocity. It then illustrates the need for engineering
accounting by drawing on comparisons to financial accounting. Finally, it makes a recommendation
on how an organization might implement engineering accounting!</p><h2 id="velocity"><a href="#velocity" aria-label="Velocity??"></a>Velocity??</h2><p>Velocity is a measurement which is based on the amount of work performed in an interval. The interval
of interest changes based on the role that is viewing the velocity. The company may be interested in
quarterly velocity, a product manager may be interested in monthly velocity, and an engineering
team may be interested in velocity over 2 week intervals. Velocity is a strong indicator of
performance. If a team can roughly deliver the same amount of features every interval the company
can make assumptions and plan on that amount of work being delivered. It enables teams to forecast and
make future commitments based on past performance.</p><p>Velocity does not ensure that teams are working on the correct tasks; velocity is pure measurement. Because
it is pure measurement, it requires an accounting system to calculate. But teams can‚Äôt just measure
velocity, teams also need data to help debug when they don‚Äôt meet their velocity commitments. This data
also helps teams to debug their current performance and increase their velocity. How many teams can answer the
following:</p><ul><li>What‚Äôs our current velocity? </li><li>How is velocity calculated? </li><li>Is velocity increasing? </li><li>Is velocity decreasing? </li><li>How far off from our commitments are we? </li><li>How far off is any given team? </li><li>What is the breakdown of a teams work? </li><li>How do we increase velocity? </li><li>What are the largest barriers to achieving our desired velocity?</li></ul><p>Increasing velocity requires understanding the current velocity and where teams are spending their time,
what type of work they are performing and the blockers to that work. Accurately measuring
velocity requires a system that allows for objective and empirical measurement of work. I like to
call this system an engineering accounting system.</p><h2 id="engineering-accounting-systems"><a href="#engineering-accounting-systems" aria-label="Engineering Accounting Systems"></a>Engineering Accounting Systems</h2><p>An engineering accounting system is system to document the work being performed. Some sort of
accounting is required to calculate velocity (the amount delivered in an interval). To
understand why engineering accounting is required for velocity and predictability consider
financial accounting. A <a href="https://debitoor.com/dictionary/accounting-system">financial accounting system</a>:</p><blockquote><p>Allows a business to keep track of all types of financial transactions, including purchases (expenses),
sales (invoices and income), liabilities (funding, accounts payable), etc. and is capable of
generating comprehensive statistical reports that provide management or interested parties
with a clear set of data to aid in the decision-making process.</p></blockquote><p>Pretend your company wants to understand each team‚Äôs finances for IPO readiness and financial predictability.
The goal is to understand each teams expenses to get an idea of the current finances across the entire org.
The first team the company consults stores their numbers in a spreadsheet in euros. The second team
has their numbers in quickbooks and uses single entry system in USD. Another team doesn‚Äôt use a
computer based accounting system at all, but keeps physical copies of their receipts. While none of
these teams are ‚Äúwrong‚Äù ‚Äî especially if they are meeting their commitments and keeping expenses under
control ‚Äî the diversity of accounting systems provides a significant barrier in gaining a company-wide
view of current expenses. These fractured standards could jeopardize the goal of financial
predictability through the overhead required to account for each teams expenses individually.</p><p>A lack of uniformed engineering accounting makes it difficult or impossible to calculate velocity and to
analyze the reasons for the current velocity. Additionally, a lack of accounting system creates an
environment where teams can be successful based on perception, which is subject to heuristics and
cognitive biases. Good public relations, or one impactful project, may give the perception that a
team is high performing, when in actuality they aren‚Äôt. A popular tool that a team produces that is
frequently used could contribute to availability bias, or thinking the team that produced the tool is
effective or delivers with high velocity. But in actuality the team may be ineffective or spending
their time fixing bugs or in technical debt. An accounting system provides the data to make these
determinations.</p><p>Accounting systems are essential to measure velocity, and a shared accounting system is essential to
measure org-wide velocity. An org-wide accounting system provides:</p><ul><li>Structured approach in how, when and where to track work</li><li>Shared terminology</li><li>Shared tooling</li><li>Standardized reports</li><li>Lower barrier to entry when analyzing performance across teams and domains</li></ul><p>A proper engineering accounting system can calculate much more than velocity. It‚Äôs able to answer:</p><ul><li>How much work is a team performing in an interval?</li><li>How does that compare to prior intervals? (speeding up? slowing down?)</li><li>How long doe it take to perform a task of a certain size, on average?</li><li>How long does it take to perform a task of a certain size for a given project?</li><li>How long does work spend in Peer Review? what percentage of total work is that accountable for?</li><li>How long does it take to deploy? </li><li>What‚Äôs the breakdown of work during a given interval in terms of: bug fixes, features, technical debt?</li></ul><p>These questions are essential to understand engineering performance, and to create an environment for
predictable execution and accountability (is a team making good on their commitments).</p><h2 id="scrum-as-an-accounting-system"><a href="#scrum-as-an-accounting-system" aria-label="Scrum As An Accounting System"></a>Scrum As An Accounting System</h2><p>I‚Äôve used scrum for 4 years, 2 as a member of a team and 2 as leading a team by driving the scrum
process. I have found scrum <em>just works</em>. But in order to work, scrum needs buy-in from an
entire team. A partial application (some team members using it while others don‚Äôt) render aggregations
misleading or worthless. A structured engineering accounting system, like scrum, is able to
answer all the performance questions outlined in the section above scoped to a single team. It offers
many metrics which allow teams to achieve our goals of predictable and increasing
engineering velocity, and allow teams to understand and debug the issues that keep them from
achieving our desired performance.</p><p>Scrum measures velocity by assigning each task a weight, referred to as ‚Äúpoints‚Äù in scrum. Each work item is
given an estimate which indicates it weight relative to other tasks. Given 2 tasks, each with estimate of X
means each task is roughly the same weight. After tasks are assigned weights, velocity becomes trivial to
calculate:</p><pre><p><span>Velocity = sum of points / interval</span></p></pre><p>If a team completes 20 points in a standard two week interval, that indicates a velocity of 20. If a team
completes 15 points in the next interval that means there was a velocity of 15. </p><p><strong>Note</strong>: I have found that scrum velocity is scoped to a team, and it can‚Äôt really be used to compare
between teams, or as a global performance metric. Even with this limitation, I still think there is
value in team-scoped velocity and an evolution on what we currently have. When a team commits to
something and continually can‚Äôt reach that commitment that can be a good indicator. Velocity
across teams is sort of meaningless, one team has a velocity of X, another Y, what does that even mean?
How can that really mean anything to someone outside of the team? The derivative or trend of velocity
becomes a valuable indicator.</p><p>Measuring is good, but predicting future outcomes is better! One powerful aspect of scrum is the ability to
forecast velocity. Forecasting uses the data generated by previous intervals to estimate a reasonable
target for future intervals. Consider a team that delivered the following points over the last 3 intervals:</p><p>15, 18, 12 </p><p>The running average for this is 15 points ((15 + 18 + 12) / 3)). This enables the team to shoot for ~15
points for the next sprint. By having an idea of how much work a team can complete (their actual velocity)
they are able to increase predictability. The same goes for understanding velocity when a team member is
out. If there are 3 members on the team, and one member will be out for 2 weeks scrum estimates that the
team should shoot for 10 points in a sprint instead of 15.  </p><p>It‚Äôs really this simple, and it really works! </p><p><a href="https://medium.com/@dm03514/systems-fundamentals-profiling-7836e86c63ac">Profiling</a> shows a breakdown of
work at a given point in time. It is a property of structured record
keeping, and not specifically of scrum. Profiling enables teams to breakdown work by multiple dimensions,
and is usually implemented through a tagging scheme. Work can be tagged by component (such as a service
name, or library) or work type (bug, tech debt, feature), or any other dimension they find valuable. This
enables breaking down the total amount of work by those dimensions. The charts below show an interval
broken down by work type. You can see that ~40% of work is being spent fixing bugs (re-work):</p><p><span>
      <span></span>
  <img alt="profiling" title="profiling" src="https://on-systems.tech/static/12a4c79b5322f5ab5a7f65a620e4755c/b1001/profiling.png" srcset="https://on-systems.tech/static/12a4c79b5322f5ab5a7f65a620e4755c/e4d6b/profiling.png 345w,https://on-systems.tech/static/12a4c79b5322f5ab5a7f65a620e4755c/1e043/profiling.png 690w,https://on-systems.tech/static/12a4c79b5322f5ab5a7f65a620e4755c/b1001/profiling.png 1380w,https://on-systems.tech/static/12a4c79b5322f5ab5a7f65a620e4755c/a6d66/profiling.png 2070w,https://on-systems.tech/static/12a4c79b5322f5ab5a7f65a620e4755c/2b984/profiling.png 2164w" sizes="(max-width: 1380px) 100vw, 1380px" loading="lazy">
    </span></p><p>This accounting enables tracking where teams are spending their time:</p><ul><li>Is a team spending most of its time fixing bugs? </li><li>Developing features? </li><li>Addressing tech debt? </li><li>Which Projects? </li></ul><p>Scrum provides a planning structure that lends really well to supporting this sort of record keeping.</p><p>Queuing Analysis shows where work items spend their time. A scrum board is split into ‚Äúswimlanes‚Äù. Swimlanes
can be used to mirror important states in development. Some examples of these are:</p><p><span>
      <span></span>
  <img alt="queueing" title="queueing" src="https://on-systems.tech/static/f30f8965a3710523ec33f69057a75c4c/be86f/queueing.png" srcset="https://on-systems.tech/static/f30f8965a3710523ec33f69057a75c4c/e4d6b/queueing.png 345w,https://on-systems.tech/static/f30f8965a3710523ec33f69057a75c4c/be86f/queueing.png 662w" sizes="(max-width: 662px) 100vw, 662px" loading="lazy">
    </span></p><ul><li>Not started</li><li>In development</li><li>Pull request</li><li>Staging testing</li><li>Production Deploy</li><li>QA</li><li>Done</li></ul><p>If teams commit to accurately transitioning work items, they can <a href="https://medium.com/valuestream-by-operational-analytics-inc/valuestream-devops-metrics-observing-delivery-across-multiple-systems-7ae76a6e8deb">get metrics on how long items spend in a
given state, which is able to inform ‚Ä¶</a></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://on-systems.tech/109-toward-predictable-engineering-velocity-accounting/">https://on-systems.tech/109-toward-predictable-engineering-velocity-accounting/</a></em></p>]]>
            </description>
            <link>https://on-systems.tech/109-toward-predictable-engineering-velocity-accounting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293369</guid>
            <pubDate>Sun, 28 Feb 2021 13:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parameter Store vs. Secrets Manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26293271">thread link</a>) | @kiyanwang
<br/>
February 28, 2021 | https://www.davehall.com.au/blog/2021/02/22/parameter-store-vs-secrets-manager/ | <a href="https://web.archive.org/web/*/https://www.davehall.com.au/blog/2021/02/22/parameter-store-vs-secrets-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><div><div><p>The handling of secrets in AWS is up there with tabs vs spaces and vim vs emacs
in terms of technical debates. In one corner we have Amazon‚Äôs original secrets
store <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html">System Manager Parameter
Store</a>.
In the other is the new(er) challenger, <a href="https://aws.amazon.com/secrets-manager/">Secrets
Manager</a>. Let‚Äôs see how they compare.</p><p>We won‚Äôt be looking at HashiCorp‚Äôs Vault in this comparison, because the focus
of this post is to compare AWS‚Äô managed service. This is one of those occasions
where it is cheaper to accept some vendor lock in and avoid the hassle of
managing a cluster of Consul nodes.</p><p>This comparison won‚Äôt cover every little detail. We will stick to the key
differences between the two tools with the aim of helping you choose the best
one for your use case.</p><h2 id="round-1-key-value-store">Round 1: Key Value Store</h2><p>At the heart of both services is a managed key value store. You send your
sensitive data to Amazon and they store it until you need it. Each value is
referenced via a unique key that you define.</p><p>Both services allow you to name your secrets using simple strings. Parameter
store allows keys to be any mix of <code>a-zA-Z0-9_.-</code> up to 966 characters, while
secrets manager‚Äôs limit is 512 unicode characters.</p><p>Parameter store allows you to store your secrets in a hierarchy. By using a path
structure you build up the structure. So instead of simple names such as
<code>DB_URI</code> you can use something more complex like <code>/myapp/DB_URI</code>. The Parameter
Store API allows you to fetch all the values in the hierarchy with a single
call. This is really handy when you have multiple values stored for an
application.</p><p><strong>Winner:</strong> Parameter Store for supporting hierarchical structures.</p><h2 id="round-2-storage-limitations">Round 2: Storage Limitations</h2><p>Both services allow users to store any unicode string. Standard SSM Parameters
are limited to 4Kb, while their advanced siblings can be up to 8Kb. Secrets
manager allows values up to 64Kb. Depends on your data storage needs these
limits may impact choice of service.</p><p>Both services retain 100 revisions of your secret. That can be handy if someone
accidentally overwrites the wrong value.</p><p><strong>Winner:</strong> Secrets Manager for higher value limits</p><h2 id="round-3-encryption">Round 3: Encryption</h2><p>Both parameter store and secrets manager store your secrets in an encrypted
state using KMS encryption keys. This ensures your sensitive credentials are
kept secure.</p><p>Unlike secrets manager, parameter store allows to decide if you want your values
to be stored unencrypted. While this isn‚Äôt advisable for secrets it can useful
for non sensitive information. If you hit a modified time stamp, check sum or
other non sensitive value option, this can be useful. It reduces the number of
KMS API calls and leads to faster response times. This makes it easier to use
parameter store as your single solution for application configuration
management.</p><p><strong>Winner:</strong> Parameter Store for the extra flexibility</p><h2 id="round-4-rotation">Round 4: Rotation</h2><p>Rotating credentials can be a tedious task that can result in downtime. Amazon
promotes the credentials rotation feature in Secrets Manager. This is mostly
marketing hype. The feature is limited to databases and it is really just an
easy way to deploy a Lambda function that does the rotation. There are similar
Lambdas available to do this with Parameter Store.</p><p><strong>Winner:</strong> Draw, we won‚Äôt reward over hyping features</p><h2 id="round-5-cost">Round 5: Cost</h2><p>Parameter Store has two flavours of parameters, standard and advanced. Standard
parameters don‚Äôt incur any monthly storage fees. Adding to the complexity there
are two price tiers for interacting with the Parameter Store API, standard and
high throughput. As you have already guessed you pay for the <a href="https://docs.aws.amazon.com/general/latest/gr/ssm.html">higher
quotas</a>. While standard
is free, the high rate will cost you 0.05USD per 10000 interactions. The higher
throughput is an <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-throughput.html">account wide
setting</a>.</p><p>For advanced parameters you pay 0.05USD per parameter per month. You decide when
creating a parameter if it will be an advanced. You pay 0.05USD per 10000 API
interactions with advanced parameters. The one consolation is that you won‚Äôt pay
extra for enabling high throughput when fetching advanced parameters.</p><p>With Secrets Manager you pay for everything. You will pay 0.40USD per secret per
month, then 0.05USD per 10000 API interactions. The <a href="https://docs.aws.amazon.com/secretsmanager/latest/userguide/reference_limits.html">Secrets Manager API
quotas</a>
are the highest of the 3 options.</p><p>On top of these costs, you will <a href="https://aws.amazon.com/kms/pricing/">pay 0.03USD for 10000 KMS API
requests</a>. Even if you fetch multiple
parameters in a single API call, you will pay to decrypt each one individually.</p><p><strong>Winner:</strong> Parameter Store standard cos you can‚Äôt beat free.</p><h2 id="the-verdict">The Verdict</h2><p>There is no knock out winner in this contest. It is going to come down to a
points decision. Our judges have awarded the win to Parameter Store.</p><p>While Secrets Manager can be a better fit for some use cases, often it is
overkill. Unless you require the larger storage limits or very high throughput
you‚Äôre wasting money on secrets manager.</p><p>If you can work within the constraints of the standard tier of Parameter Store
it is a very cost effective tool for managing your secrets and other application
configuration.</p><p>Our earlier blog post on <a href="https://www.davehall.com.au/blog/2018/08/26/aws-parameter-store/">AWS System Manager Parameter
Store</a> is a great introduction for new
users.</p></div></div></section></article></div>]]>
            </description>
            <link>https://www.davehall.com.au/blog/2021/02/22/parameter-store-vs-secrets-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293271</guid>
            <pubDate>Sun, 28 Feb 2021 13:28:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Development of an Œ±-synuclein knockdown peptide in Parkinson‚Äôs disease models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26293232">thread link</a>) | @JPLeRouzic
<br/>
February 28, 2021 | https://www.padiracinnovation.org/News/2021/02/development-of-an-a-synuclein-knockdown-peptide-and-evaluation-of-its-efficacy-in-parkinsons-disease-models | <a href="https://web.archive.org/web/*/https://www.padiracinnovation.org/News/2021/02/development-of-an-a-synuclein-knockdown-peptide-and-evaluation-of-its-efficacy-in-parkinsons-disease-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    						
					                    <p>
                        <span itemprop="datePublished">22 February 2021</span> - Posted in 
                        <span itemprop="articleSection"><a href="https://www.padiracinnovation.org/News/category/english">English</a></span> by 
                        
                     	
                   </p>
                </div><div itemprop="articleBody">                                   
                    <p>Parkinson‚Äôs disease (Parkinson‚Äôs disease) is a major neurodegenerative disorder. It currently lacks a clinically relevant treatment that can directly target the disease-causing processes. Current clinical approaches, like deep brain stimulation and pharmacological treatments with levodopa and dopamine agonists, only relieve symptoms. The efficacy of these treatments is largely limited by their undesirable complications and side effects. 
<img src="https://upload.wikimedia.org/wikipedia/commons/0/0f/Lewy_Body_alphaSynuclein.jpg" alt="enter image description here">
<em>Source: By Ajpolino via Wikipedia</em></p>

<p>Since Œ±-synuclein is overexpressed under certain pathological conditions of PD and these upregulated proteins can interfere with many physiological processes, such as ER-to-Golgi transport, synaptic transmission, and mitochondria function and morphology, robustly knocking down the overexpressed Œ±-synucleinmay have better neuroprotective efficacy in restoring normal cellular functions in the Parkinson‚Äôs disease brain than simply inhibiting the formation of toxic Œ±-synuclein oligomers.</p>

<p>Knockdown of Œ±-synuclein using genetic manipulations, such as antisense oligonucleotide and small interfering RNA (siRNA), has shown protection of dopaminergic neurons in various models of Parkinson‚Äôs disease.</p>

<p>The clinical translation of these manipulations into an efficient Parkinson‚Äôs disease therapy has however costly and uncomfortable, as it is mainly accomplished by an invasive injection or viral infection. These technologies may not be clinically practical for therapeutic use in human patients.</p>

<p><a href="https://www.nature.com/articles/s42003-021-01746-6">Here the scientists report the development of a short, BBB and plasma membrane-permeant synthetic peptide that can rapidly reduce endogenous Œ±-synuclein via proteasomal degradation.</a></p>

<p>Using both in vitro and in vivo models of Parkinson‚Äôs disease, the scientists provide proof-of-principle evidence for using this small Œ±-synuclein knockdown peptide as a potential Parkinson‚Äôs disease therapy.</p>

<p>The authors first demonstrated that the Tat-Œ≤syn-degron peptide can specifically reduce the level of Œ±-synuclein both in vitro and in vivo. The authors then showed that the peptide-induced Œ±-synuclein knockdown is associated with protection of dopaminergic neurons against toxin-induced damage in a culture model of Parkinson‚Äôs disease.</p>

<p>Most importantly, the scientists were able to demonstrate the therapeutic potential of systemic application of the Tat-Œ≤syn-degron peptide as an effective Parkinson‚Äôs disease treatment in two well-characterized animal models of Parkinson‚Äôs disease.</p>

<p>Their Œ±-synuclein knockdown peptide (Tat-Œ≤syn-degron) is innovative as the peptide directly targets one of the disease-causing processes, and can be expected to stop or slow down the progression of the disease.</p>

<p>In addition, the peptide-mediated knockdown has a clear temporal advantage over antisense or siRNA-mediated knockdown. Œ±-synuclein is a very stable protein with a long half-life while by hijacking the endogenous proteasomal degradation system in the cell, the Tat-Œ≤syn-degron peptide produced a rapid and robust degradation of Œ±-synuclein protein within a few hours.</p>

<p>It is also interesting to note that Œ±-synuclein is also expressed in tissues outside the central nervous system and the scientists found that a single intraperitoneal injection of the Tat-Œ≤syn-degron peptide similarly reduced the Œ±-synuclein expression in the kidney and the spleen of wild-type C57BL/6 mice .</p>

<p>A recent success in a phase 3 clinical trial has already demonstrated that a Tat-fused short peptide is not only safe, but therapeutically effective in protecting neurons against ischemic damage in humans. The authors hope this Œ±-synuclein knockdown peptide may also have the potential to be quickly translated into the clinic as an effective disease-modifying treatment that directly targets the disease-causing process of Parkinson‚Äôs disease.</p>

<p>Due to the versatility of their peptide-mediated protein knockdown method, the scientists can theoretically target disease-causing cellular proteins by simply changing the protein-binding sequence of the targeting peptide. Since many human diseases, including some of the age-related neurodegenerative diseases such as ALS, Alzheimer‚Äôs disease and Huntington‚Äôs disease, are pathologically caused by gain of function of a protein due to its mutations and/or increased expression levels, <strong>the proposed study can be expected to spur the development of new therapeutics for human diseases beyond Parkinson‚Äôs disease</strong>.</p>

<h3><u>Advertisement</u></h3>

<p><a href="https://www.amazon.com/dp/1698147899">
<img src="https://images-na.ssl-images-amazon.com/images/I/51pNZDKvmIL._SX331_BO1,204,203,200_.jpg" width="200">
<br>
This book retraces the main achievements of ALS research over the last 30 years, presents the drugs under clinical trial, as well as ongoing research on future treatments likely to be able stop the disease in a few years and to provide a complete cure in a decade or two.<br>
</a></p>
                </div></div>]]>
            </description>
            <link>https://www.padiracinnovation.org/News/2021/02/development-of-an-a-synuclein-knockdown-peptide-and-evaluation-of-its-efficacy-in-parkinsons-disease-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293232</guid>
            <pubDate>Sun, 28 Feb 2021 13:20:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Remember Everything with Save All]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26293123">thread link</a>) | @quarok
<br/>
February 28, 2021 | https://www.saveall.ai/event/hackernews202102 | <a href="https://web.archive.org/web/*/https://www.saveall.ai/event/hackernews202102">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.saveall.ai/event/hackernews202102</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293123</guid>
            <pubDate>Sun, 28 Feb 2021 13:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can do better than Redis as a data layer for your models]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26293114">thread link</a>) | @jamesblonde
<br/>
February 28, 2021 | http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it | <a href="https://web.archive.org/web/*/http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div id="ron_db"><h2>‚Äç<strong>The rise of key-value stores as online feature stores.&nbsp;</strong></h2><p>Online feature stores are the data layer for operational machine learning models - the models that make online shopping recommendations for you and help identify financial fraud. When you train a machine learning model, you feed it with high signal-to-noise data called features. When the model is used in operation, it needs the same types of features that it was trained on (e.g., how many times you used your credit card during the previous week), but the online feature store should have low latency to keep the end-to-end latency of using a model low. Using a model requires both retrieving the features from the online feature store and then sending them to the model for prediction.&nbsp;</p><p>Hopsworks has been using NDB Cluster as our online feature store from its first release. It has the unique combination of low latency, high availability, high throughput, and scalable storage that we call LATS. However, we knew we could make it even better as an online feature store in the cloud, so we asked one of the world‚Äôs leading database developers to do it - the person who invented NDB, Mikael Ronstr√∂m. Together we have made RonDB, a key-value store with SQL capabilities, that is the world‚Äôs most advanced and performant online feature store. Although NDB Cluster is open-source, its adoption has been hampered by an undeserved reputation of being challenging to configure and operate. With <a href="https://www.rondb.com/?utm_source=rondb" target="_blank">RonDB</a>, we overcome this limitation by providing it as a managed service in the cloud on AWS and Azure.<strong>‚Äç</strong></p><h3><strong>Requirements for an Online Feature Store</strong>‚Äç</h3><figure><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/60364af8c8f5d47b1f1f70ce_graph_white.png" loading="lazy" alt=""></p></figure><p>The main requirements from a database used as an online feature store are: low latency, high throughput for mixed read/write operations, high availability and the ability to store large data sets (larger than fit on a single host). We unified these properties in a single muscular term <strong>LATS</strong>:</p><p><a href="https://www.rondb.com/?utm_source=rondb" target="_blank">‚Äç<strong>LATS</strong>: low <strong>L</strong>atency, high <strong>A</strong>vailability, high <strong>T</strong>hroughput, scalable <strong>S</strong>torage.&nbsp;</a></p><p>RonDB is not without competition as the premier choice as an online feature store. To quote Khan and Hassan from DoorDash, it should be a low latency database:&nbsp;</p><p><a href="https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/?utm_source=rondb" target="_blank">‚Äúlatency on feature stores is a part of model serving, and model serving latencies tend to be in the low milliseconds range. Thus, read latency has to be proportionately lower.‚Äù&nbsp;</a></p><p>To that end, Redis fits this requirement as it is an in-memory key-value store (without SQL capabilities). Redis is open source (BSD Licence), and it enjoys popularity as an online feature store. Doordash even invested significant resources in increasing Redis‚Äô storage capacity as an online feature store, by adding custom serialization and compression schemes. Significantly, similar to RonDB, it provides sub-millisecond latency for single key-value store operations. There are other databases that have been proposed as online feature stores, but they were not considered in this post as they have significantly higher latency (over one order-of-magnitude!), such as DynamoDB, BigTable, and SpliceMachine.</p><p>As such, we thought it would be informative to compare the performance of RonDB and Redis as an online feature store. <strong>The comparison was between Redis open-source and RonDB open-source</strong> (the commercial version of Redis does not allow any benchmarks). In addition to our benchmark, we compare the innards of RonDB‚Äôs multithreading architecture to the commercial Redis products (since our benchmark identifies CPU scalability bottlenecks in Redis that commercial products claim to overcome).<br></p><h2>Benchmark: RonDB vs Redis</h2><p>In this simple benchmark, I wanted to compare apples with apples, so I compared open-source RonDB to the open-source version of Redis, since the commercial versions disallow reporting any benchmarks. In the benchmark, I deliberately hobble the performance of RonDB by configuring it with only a single database thread, as Redis is <a href="https://redis.io/topics/benchmarks/utm_source=rondb" target="_blank">‚Äúa single-threaded server from the POV of command execution‚Äù</a>. I then proceed to describe the historical evolution of RonDB‚Äôs multithreaded architecture, consisting of three different generations, and how open-source Redis is still at the first generation, while commercial Redis products are now at generation two.</p><p>Firstly, for our single-threaded database benchmark, we performed our experiments on a 32-core Lenovo P620 workstation with 64 GB of RAM. We performed key-value lookups. Our experiments show that a single-threaded RonDB instance reached around 1.1M reads per second, while Redis reached more than 800k reads per second - both with a mean latency of around 25 microseconds. The throughput benchmark performed batch reads with 50 reads per batch and had 16 threads issuing batch requests in parallel. Batching reads/writes improves throughput at the cost of increased latency.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/6037dae7ff678a83e8eaf1a8_performance.jpg" loading="lazy" alt=""></p></figure><p>On the same 32-core server, both RonDB and Redis reached around 600k writes per second when performing SET for Redis and INSERT, UPDATE or DELETE operations for RonDB. For high availability, both of those tests were done with a setup using two replicas in both RonDB and in Redis.<br></p><h3><strong>Low latency</strong></h3><p>We expected that the read latency and throughput of RonDB and Redis would be similar since both require two network jumps to read data. In case of updates (and writes/deletes), Redis should have lower latency since an update is only performed on the main replica before returning. That is, Redis only supports asynchronous replication from the main replica to a backup replica, which can result in data loss on failure of the main node. In contrast, RonDB performs an update using a synchronous replication protocol that requires 6 messages (<a href="https://www.amazon.com/MySQL-Cluster-7-5-Inside-Out/dp/9176998142/utm_source=rondb" target="_blank">a non-blocking version of two-phase commit</a>). Thus, the expected latency is 3 times higher for RonDB for writes.&nbsp;<br></p><h3><strong>High Throughput</strong></h3><p>A comparison of latency and throughput shows that RonDB already has a slight advantage in a single-threaded architecture, but with its third-generation multithreaded architecture, described below, RonDB has an even bigger performance advantage compared to Redis commercial or open-source. RonDB can be scaled up by adding more CPUs and memory or scaled out, by automatically sharding the database.&nbsp; As early as 2013, we developed a benchmark with NDB Cluster (RonDB‚Äôs predecessor) that showed how <a href="http://mikaelronstrom.blogspot.com/2015/03/200m-reads-per-second-in-mysql-cluster.html?utm_source=rondb" target="_blank">NDB could handle 200M Reads per second</a> in a large cluster of 30 data nodes with 28 cores each.&nbsp;<br></p><h3><strong>High Availability</strong></h3><p>The story on high availability is different. A write in Redis is only written to one replica. The replication to other replicas is then done asynchronously, thus consistency can be seriously affected by failures and data can be lost. An online feature store must accept writes that change the online features constantly in parallel with all the batched key reads. Thus handling node failures in an online feature store must be very smooth.<br></p><p>Given that an online feature store may need to scale to millions of writes per second as part of a normal operation, this means that a failed node can cause millions of writes to be lost, affecting the correctness and quality of any models that it is feeding with data. RonDB has transactional capabilities that ensure that transactions can be retried in the event of such partial failures. Thus, as long as the database cluster is not fully down, no transactions will be lost.<br></p><p>In many cases the data comes from external data sources into the online Feature Store, so a replay of the data is possible, but an inconsistent state of the database can easily lead to extra unavailability in failure situations. Since an online feature store is often used in mission-critical services, this is clearly not desirable.<br></p><p>RonDB updates all replicas synchronously as part of writes. Thus, if a node running the transaction coordinator or a participant fails, the cluster will automatically fail over to the surviving nodes, a new transaction coordinator will be elected (non-blocking), and no committed transactions will be lost. This is a key feature of RonDB and has been tested in the most demanding applications for more than 15 years and tested thousands of times on a daily basis.<br></p><p>Additionally it can be mentioned that in a highly available setup, in a cloud environment RonDB can read any replica and still see the latest changes whereas Redis will have to read the main replica to get a consistent view of the data and this will, in this case, require communicating across availability zones which can easily add milliseconds to latency for reads. RonDB will automatically setup the cluster such that applications using the <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud?utm_source=rondb" target="_blank">APIs will read replicas that are located in the same availability zone</a>. Thus in those setups RonDB will always be able to read the latest version of the data and still deliver data at the lowest possible latency. <strong>Redis setups will have to choose between delivering consistent data with higher latency or inconsistent data with low latency in this setup.</strong><br></p><h3><strong>Scalable Storage</strong></h3><p>Redis only supports in-memory data - this means that Redis will not be able to support online Feature Stores that store lots of data. In contrast, RonDB can store data both in-memory and on-disk, and with support for up to 144 database nodes in a cluster, it can scale to clusters of up to 1PB in size.<br></p><h3><strong>Analysis: Three Generations of Multithread Architectures</strong></h3><p>For our single-threaded benchmark, we did not expect there to be, nor were there, any major differences in throughput or latency for either read or write operations. The purpose of the benchmark was to show that both databases are similar in how efficiently they use a single CPU. RonDB and Redis are both in-memory databases, but the implementation details of their multithreaded architectures matters for scalability (how efficiently they handle increased resources), as we will see.&nbsp;<br></p><p>Firstly, <a href="https://redis.io/topics/benchmarks/utm_source=rondb" target="_blank">‚ÄúRedis is not designed to benefit from multiple CPU cores. People are supposed to launch several Redis instances to scale out on several cores if needed.‚Äù</a> For our use-case of online feature stores, it is decidedly non-trivial to partition a feature store across multiple redis instances. Therefore, commercial ‚Ä¶</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</a></em></p>]]>
            </description>
            <link>http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293114</guid>
            <pubDate>Sun, 28 Feb 2021 13:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reasoning about Taxes]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 74 (<a href="https://news.ycombinator.com/item?id=26292993">thread link</a>) | @acqbu
<br/>
February 28, 2021 | https://www.billdietrich.me/ReasonTaxes.html | <a href="https://web.archive.org/web/*/https://www.billdietrich.me/ReasonTaxes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.billdietrich.me/ReasonTaxes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292993</guid>
            <pubDate>Sun, 28 Feb 2021 12:42:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When the magnetic poles flip out, Earth seems to suffer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26292827">thread link</a>) | @pseudolus
<br/>
February 28, 2021 | https://www.cbc.ca/radio/quirks/feb-20-magnetic-pole-reversals-viruses-hunt-bacteria-solar-powered-microflyers-and-more-1.5918929/when-the-magnetic-poles-flip-out-earth-seems-to-suffer-1.5918947 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/quirks/feb-20-magnetic-pole-reversals-viruses-hunt-bacteria-solar-powered-microflyers-and-more-1.5918929/when-the-magnetic-poles-flip-out-earth-seems-to-suffer-1.5918947">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Magnetic pole reversal indicated in 42,000 year old tree rings may have triggered global environmental change</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5920171.1613749965!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/kauri-tree.jpg"></p></div><figcaption>Tree rings from the ancient Kauri tree in New Zealand showed a spike in radioactive carbon indicative of a magnetic pole reversal<!-- --> <!-- -->(Nelson Parker)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="When the magnetic poles flip out, Earth seems to suffer"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/813/719/Quirks-640x360__361114.jpg" alt=""></p><p><span>Quirks and Quarks</span><span>8:01</span><span>When the magnetic poles flip out, Earth seems to suffer</span></p></div></div></div></span></p><p><span><p>The Earth's magnetic poles have flipped many times in our planet's history - and while we know this is an important geophysical event, we haven't had any good evidence to indicate whether it's an important biological event.&nbsp;</p>  <p>The last time the magnetic poles reversed permanently was nearly 800,000 years ago. The poles also flip more frequently on a temporary&nbsp;basis in what is called a magnetic excursion.</p>  <p>This means the reversal lasts up to a few thousand years before they change back. The last one of these is called the Laschamps excursion, and it happened nearly 42,000 years ago.&nbsp;</p>  <p><em>A 'Hitchhiker's Guide' to magnetic pole reversal (UNSW)</em></p>  <p><span><span><iframe src="https://www.youtube.com/embed//Qs1dLe3GsQY" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <h2>A geological who-dun-it?</h2>  <p>In a&nbsp;<a href="https://science.sciencemag.org/content/371/6531/811" target="_blank">study</a>, researchers including <a href="https://research.unsw.edu.au/people/professor-chris-turney" target="_blank">Chris Turney</a>&nbsp;from The University of New South Wales, were able to use tree ring records to date a magnetic excursion correlate it with a series of environmental changes and extinctions that came about at the same time. This included the dramatic growth of ice sheets, changing wind patterns, a shift in the location of the Earth's tropical region, the extinction of some megafauna as well as the extinction of Neanderthals.</p>  <p>These types of changes have never been so closely correlated to the magnetic poles flipping before.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5920213.1613750872!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/kauri-new-jpg.jpg 300w,https://i.cbc.ca/1.5920213.1613750872!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/kauri-new-jpg.jpg 460w,https://i.cbc.ca/1.5920213.1613750872!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/kauri-new-jpg.jpg 620w,https://i.cbc.ca/1.5920213.1613750872!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/kauri-new-jpg.jpg 780w,https://i.cbc.ca/1.5920213.1613750872!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/kauri-new-jpg.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5920213.1613750872!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/kauri-new-jpg.jpg"></p></div><figcaption>A kauri tree in New Zealand<!-- --> <!-- -->(Nelson Parker)</figcaption></figure></span></p>  <h2>Ancient tree rings</h2>  <p>The tree rings the team studied were from the ancient kauri trees in New Zealand. Remains of the massive trees were found preserved in nearly 10 metres of wetland soil. The rings of these trees indicate a massive spike in radioactive carbon in the atmosphere at the same time as the Laschamps excursion.</p>  <p>This is attributed to a reversal of the magnetic poles and subsequent weakening of the Earth's protective magnetic field. In the case of the magnetic excursion 42,000 years ago, that field was reduced to an estimated six&nbsp;per cent of what it is today. This meant&nbsp;that more radiation from outer space reached the atmosphere, changing the chemistry of the atmosphere and causing an increase in levels radioactive carbon.</p>  <p>This likely resulted in all of the global climate and environmental changes observed in other records at the same time.&nbsp;</p>  <p><em>Trees rings reveal the date of the last magnetic pole reversal (UNSW)</em></p>  <p><span><span><iframe src="https://www.youtube.com/embed//NSig4MyLQ0o" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>    </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/quirks/feb-20-magnetic-pole-reversals-viruses-hunt-bacteria-solar-powered-microflyers-and-more-1.5918929/when-the-magnetic-poles-flip-out-earth-seems-to-suffer-1.5918947</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292827</guid>
            <pubDate>Sun, 28 Feb 2021 12:12:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting two PDP-1 photos (which are not what they seem)]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 30 (<a href="https://news.ycombinator.com/item?id=26292781">thread link</a>) | @masswerk
<br/>
February 28, 2021 | https://www.masswerk.at/nowgobang/2021/train-spotting-1 | <a href="https://web.archive.org/web/*/https://www.masswerk.at/nowgobang/2021/train-spotting-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
		<article role="article">
		
		<time datetime="2021-02-28">February 28, 2021</time>
		<p>A story of trains, computers, and two images.</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/train-spotting.jpg" alt="Spotting trains and computers" width="761" height="490">
		</figure>

		<p><span>T</span>his is at the same time a continuation to what may become a loose series, namely, <a href="https://www.masswerk.at/nowgobang/?tag=things-that-arent">‚ÄúThings on the Web that aren‚Äôt what they seem to be‚Äù</a>, and the beginning of an entirely new one. Anyway, this is the story of two photos that are rather well known in the context of computer history. You may even have seen one or the other popping up on a website.</p>
		<p>Since you are reading this blog, you may be even familiar with the broader context.</p>

		<h2>Context</h2>
		<p>In 1961, the MIT recieved a DEC <abbrev title="Programmed Data Processor 1">PDP-1</abbrev> computer from Digital Equipment Corporation as a donation. It was one of the very first production models and DEC‚Äôs motivation was a multiple one: First, the PDP-1 was somewhat of a commercial version of MIT‚Äôs experimental <a href="https://en.wikipedia.org/wiki/TX-0" target="_blank" rel="noopener">TX-0</a> computer <small>(Transistorized eXperimental computer Zero, the very first fully transistorized computer, designed by Wesley Clark and completed in 1956)</small>, then, the donation was reinforcing ties between MIT and the DEC founders, who had been working on various experimental MIT machines in the past, and, last but not least, DEC was hoping for MIT to come up with some exciting demo applications for the new machine. ‚Äî And a hell of a demo application DEC should get out of this deal, probably the killer application of interactive, visual computing <small>(the PDP-1 was really the first commercial workstation computer coming with a display)</small> of all time.</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/train-spotting-pdp1.jpg" alt="DEC PDP-1" width="900" height="881">
			<figcaption>The DEC PDP-1 with two DEC chairs (ready for Spacewar!).<br>Image: Digital Equipment Corporation, brochure F-11B, 1962.</figcaption>
		</figure>

		<p>As it happened, there was a community of students gathering around the TX-0, which sprang into action to port essential tooling software from the TX-0 to the PDP-1, earning in turn rights to some runtime on the new machine. This very group also used to socialize at MIT‚Äôs <a href="https://www.wired.com/2014/11/the-tech-model-railroad-club/" target="_blank" rel="noopener">Tech Model Railroad Club</a> (TMRC), where it picked up reinforcement in form of a grad student by the name of Steve Russell, who, while not one of the TX-0 gang, had previously implemented the very first version of LISP on MIT‚Äôs IBM 704 mainframe. These teamed up to provide a demonstration program for MIT‚Äôs next annual Open House day in May 1962, a program, which, as they consented, ought to satisfy the following criteria:</p>
		<ul>
			<li>It should show off as many of the computer‚Äôs resources as possible, and tax those resources to the limit;</li>
			<li>Within a consistent framework, it should be interesting, which means every run should be different;</li>
			<li>It should involve the onlooker in a pleasurable and active way ‚Äî in short, it should be a game.</li>
		</ul>
		<p>Flavored with a bit of dedication to lowbrow science fiction and some contemporary Space Race enthusiasm this principal idea took shape as a game for two human players interacting in the virtual realms of the <span>PDP-1‚Äôs</span> scope, and Steve Russell eventually stepped out to put it to work. And so, what DEC got out of that deal, was <a href="https://www.masswerk.at/spacewar/" target="_blank">Spacewar!</a>, the very first digital video game.</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/train-spotting-spacewar.jpg" alt="Playing Spacewar" width="496" height="500">
			<figcaption>Dan Edwards (left; contributor of gravity effects and the outline compiler) and Peter Sampson (right; contributor of the ‚ÄúExpensive Planetarium‚Äù moving night sky background) playing Spacewar! using custom control boxes, ca. 1962.<br>(Computer History Museum, Catalog No. <a href="https://www.computerhistory.org/collections/catalog/102631264" target="_blank" rel="noopener">	102631264</a>; post-processed.)</figcaption>
		</figure>
		<p>(In case you are interested in the particulars, head over to <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="_blank">‚ÄúThe Origin of Spacewar‚Äù</a> by J. M. Graetz, 1981.)</p>

		<h2>The Photos</h2>
		<p>There are two photos to be found in the <a href="https://computerhistory.org/" target="_blank" rel="noopener">Computer History Museum</a>‚Äôs (CHM) catalog, which are apparently documenting the process.</p>
		<p>The first one is titled <em>‚ÄùHistory - PDP-1 at the Tech Model Railroad Club‚Äù</em>:</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/dec.pdp-1.train_set.102631219.lg.jpg" alt="Photo of a DEC PDP-1 at a model railroad layout, Computer History Museum, Catalog No. 102631219" width="496" height="500">
			<figcaption>Computer History Museum, Catalog No. <a href="https://www.computerhistory.org/collections/catalog/102631219" target="_blank" rel="noopener">102631219</a>, Lot No. X2675.2004.</figcaption>
		</figure>

		<p>The second one is titled <em>‚ÄùThe Tech Model Railroad Club and PDP-1‚Äù</em>:</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/dec.pdp-1.train_set.102649722.lg.jpg" alt="Photo of a DEC PDP-1 at a model railroad layout, Computer History Museum, Catalog No. 102649722" width="500" height="399">
			<figcaption>Computer History Museum, Catalog No. <a href="https://www.computerhistory.org/collections/catalog/102649722" target="_blank" rel="noopener">102649722</a>, Lot No. X3191.2005.</figcaption>
		</figure>

		<p>Both images share a date attribution of ‚Äú1961 ca.‚Äù and show a computer in a deplorable state of disassembly placed at a model railway layout. The layout is the same in both images, even the trains and coaches are in the same positions, and general aspects and perspectives are similar, hinting at both photos being shot at the same occasion. Moreover, the coaches are of typical North American appearance, providing a clue for where the scene is set. Due to its form factor, the computer may be a DEC PDP-1 or DEC PDP-4 and surely, there‚Äôs also the iconic hexagonal housing of the Type 30 visual CRT display, which went with the PDP-1 and the PDP-4, to be discerned. A closer inspection of the console switches to be seen in the second photo confirms that this is, in deed, a PDP-1. The habitual appearance of the person, who appears to be operating a light pen on the first image, also seems to roughly fit the period (this may be 1960s, maybe a bit later, like around 1970). So, this is clearly the PDP-1 at the TMRC, maybe, while the TX-0 gang was porting the Macro assembler, maybe even during the development of Spacewar!. ‚Äî How lucky we are to have these images, which are showing the PDP-1 in this noteworthy context!</p>

		<p>But, <em>are they?</em></p>

		<h2>Timeline</h2>
		<p>There are a few things we ought to know. Firstly, we know that the PDP-1 was delivered to the MIT at first without a display, which only arrived later, and that the porting of the TX-0 essential tools happened during this period (compare <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="_blank">‚ÄúThe Origin of Spacewar‚Äù</a>). Moreover, we know the exact date the PDP-1 was officially put into service, Monday, November 6, 1961, as provided by this invitation:</p>

		<figure>
			<a href="https://www.masswerk.at/nowgobang/images/train-spotting-pdp1-presentation.jpg" target="_blank" title="click for larger aspect"><img src="https://www.masswerk.at/nowgobang/images/train-spotting-pdp1-presentation.jpg" alt="Photo of a DEC PDP-1 at a model railroad layout, Computer History Museum, Catalog No. 102649722" width="900" height="1183"></a>
			<figcaption>Invitation to the PDP-1 presentation event.<br>(Computer History Museum, Catalog No. <a href="https://www.computerhistory.org/collections/catalog/102664166" target="_blank" rel="noopener">102664166</a>.)<br>Click for a <a href="https://www.masswerk.at/nowgobang/images/train-spotting-pdp1-presentation.jpg" target="_blank">expanded view</a> of the image.</figcaption>
		</figure>

		<p>According to the <a href="https://ia801600.us.archive.org/33/items/19751028McKenzieVol1/1975-10-28%20McKenzie%20Vol%201_text.pdf" target="_blank" rel="noopener">court proceedings</a> of the so-called ‚ÄúMagnavox vs. Bally‚Äù case, October 28, 1975, the <span>PDP-1</span> was delivered on Friday, September 15, 1961 (p.75) and was stored for a few weeks in a room in Marvin Minsky‚Äôs area accross the hall (p.57), in order to allow for some construction work (p.76) in Room 20-260, where it resided ever since.</p>

		<p>Secondly, we know from the ‚ÄúMagnavox vs. Bally‚Äù court proceedings (see above) that the Type 30 Visual CRT display wasn‚Äôt available before the very end of this year, as it was installed on Friday, December 29, 1961 (p.88):</p>
		<blockquote>
		<p><strong>Q</strong> When was the Type 30 display delivered?</p>
		<p><strong>A</strong> The display was installed December 29, 1961.</p>
		</blockquote>

		<p>The timeline simply doesn‚Äôt fit. The photos couldn‚Äôt have been shot in 1961, since the display Type 30 display hadn‚Äôt yet arrived, and they couldn‚Äôt have been taken after this, since the PDP-1 was installed in Room 20-260. The timeline simply doesn‚Äôt allow for the PDP-1 having been taken to the TMRC layout.</p>

		<p>So what is going on here? Surely, there are people who ought to know!</p>

		<h2>The Layout</h2>
		<p>In particular, those who ought to know and are available, are Steve Russell and Peter Sampson, who was somewhat of a <em>spritus rector</em> of the TMRC. Here is what Steve Russell had to say about these photos:</p>
		<blockquote><p>Peter Samson and I have frequently remarked to each other that the model railroad scene is NOT from The Tech Model Railroad Club at MIT.?? TMRC never had a PDP-1 or a layout that resembled the one in the pictures.?? Peter believes that is from the Amherst Club.</p>
		<p>There seems to be a lot of confusion about these pictures.?? I think that they are all from the Digital Equipment archives, and were used by both the Boston Computer Museum and the Computer History Museum with the information from Digital Equipment.</p>
		<p>I don't know of any pictures of the MIT PDP-1 as it was when Spacewar! was written and debugged.<br>
		I think that the attributions commonly associated with these photos are from the Digital archives, and are incorrect in several ways.</p>
		<p><cite>(Steve Russell, PDP-1 Team mailing list, 2019/10/18.)</cite></p>
		</blockquote>

		<p>Peter Sampson, on the other hand, denied to know the layout at all:</p>
		<blockquote><p>Actually I don‚Äôt know where the photo was taken (certainly not at MIT) and have no personal knowledge of a club at Amherst.</p>
		<p><cite>(Peter Sampson, PDP-1 Team mailing list, 2019/10/25.)</cite></p>
		</blockquote>

		<p>So, it even isn‚Äôt the TMRC layout! (Having a look at the operator in the first photo, we could have allowed for a later date and different circumstances, like dating from the early 1970s, but this forbids us to grasp for this last straw.)</p>
		<p>With neither the timeline nor the layout matching, we may rule out that these photos are showing the PDP-1 at the TMRC.</p>

		<h3>* How amazing ist that? *</h3>
		<p>To put this into perspective, there were just about 55 PDP-1s ever made. Half of the PDP-1s built between 1960 and 1965 were actually packaged as International Telephone and Telegraph (ITT) Automated Data Exchange (ADX) 7300 messaging system, used for switching 256 telegraph lines each, which hadn‚Äôt a display at all. (Major ADX 7300 cutomers included Eastern Airlines in Canada, the U.S. and Mexico, Trans World Airlines, the U.S. State Department, NASA, the U.S. Air Force and the Aluminum Company of Canada.) BTW, a not that unimportant footnote to computer history, Gordon Bell deleveloped the UART (Universal Asynchronous Receiver Transmitter) while working on this project.<br><em>(Hats off to Lyle Bickley for research on the ITT ADX 7300.)</em></p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/dec.pdp-1.man_working_at_ITT_PDP-1_console.102649724.lg.jpg" alt="ITT ADX 7300" width="800" height="622">
			<figcaption>Also a PDP-1: the ITT ADX 7300.<br>(Computer History Museum, Catalog No. <a href="https://www.computerhistory.org/collections/catalog/102649724" target="_blank" rel="noopener">102649724</a>; post-processed.)</figcaption>
		</figure>

		<p>Also, not every of the PDP-1s actually sold as PDP-1s featured a display. A prominent example is the <span>PDP-1D</span> timesharing prototype built to BBN‚Äôs specifications, which never had a display. According to some sources only aboult half of the PDP-1s featured a display of some kind, while we see here a PDP-1 not only with a display, but also with a light pen attached to it. This leaves less than a few dozens of installations eligble.</p>
		<p>Further, while the PDP-1 was advertised as ‚Äúreasonably priced‚Äù, it came at a considerable price tag. It certainly was reasonably priced, at an initial unit price of US$ 120,000 and an additional $ 14,300 for the Type 30 display, which put it more in the range of a better drum computer as compared to the $ 10,600 monthly lease ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.masswerk.at/nowgobang/2021/train-spotting-1">https://www.masswerk.at/nowgobang/2021/train-spotting-1</a></em></p>]]>
            </description>
            <link>https://www.masswerk.at/nowgobang/2021/train-spotting-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292781</guid>
            <pubDate>Sun, 28 Feb 2021 12:02:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error Correcting Earley Parser]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26292780">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://rahul.gopinath.org/post/2021/02/22/error-correcting-earley-parser/ | <a href="https://web.archive.org/web/*/https://rahul.gopinath.org/post/2021/02/22/error-correcting-earley-parser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
<div>

  

  <article>
    <p>We talked about Earley parsers <a href="https://rahul.gopinath.org/post/2021/02/06/earley-parsing/">previously</a>.
One of the interesting things about Earley parsers is that it also forms the
basis of best known general context-free error correcting parser. A parser is
error correcting if it is able to parse corrupt inputs that only partially
conform to a given grammar. For example, given a JSON input such as</p>



<p>The error correcting parser will be able to supply the input that is
necesaary to make the input valid. In this case, it will supply <code>}]</code>.
The algorithm is minimal error correcting if the correction proided is
minimal in some sence. For example, if the correction is <code>, "":[]}]</code>, the
correction is not minimal.</p>

<p>The particular algorithm we will be examining is
the minimum distance error correcting parser by Aho et al.<sup id="fnref:aho1972minimum" role="doc-noteref"><a href="#fn:aho1972minimum">1</a></sup>.</p>

<p>There are two parts to this algorithm. The first is the idea of a
covering grammar that parses any corrupt input and the second is the
extraction of the best possible parse from the corresponding parse forest.</p>

<p>Aho et al. uses Earley parser for their error correcting parser. So, we will
follow in their foot steps.

</p>












<p><strong>Important:</strong> <a href="https://pyodide.readthedocs.io/en/latest/">Pyodide</a> takes time to initialize.
Initialization completion is indicated by a red border around <em>Run all</em> button.</p>


<!--
############
import sys
if "pyodide" in sys.modules:
    import pyodide
    github_repo = 'https://raw.githubusercontent.com/'
    my_repo = 'rahulgopinath/rahulgopinath.github.io'
    earley_module_str = pyodide.open_url(github_repo + my_repo +
            '/master/notebooks/2021-02-06-earley-parsing.py')
    pyodide.eval_code(earley_module_str.getvalue(), globals())
else:
    # caution: this is a horrible temporary hack to load a local file with
    # hyphens, and make it available in the current namespace.
    # Dont use it in production.
    __vars__ = vars(__import__('2021-02-06-earley-parsing'))
    globals().update({k:__vars__[k] for k in __vars__ if k not in ['__name__']})

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>

<h2 id="covering-grammar">Covering Grammar</h2>

<p>The idea from Aho et al. is to first transform the given grammar into a
<em>covering grammar</em>. A grammar \(G_2\) covers another grammar \(G_1\) if
all productions in \(G_1\) have a one to one correspondence to some production
in \(G_2\), and a string that is parsed by \(G_1\) is guaranteed to be parsed
by \(G_2\), and all the parses from \(G_1\) are guaranteed to exist in the set
of parses from \(G_2\) (with the given homomorphism of productions).</p>

<p>So, we first construct a covering grammar that can handle any corruption of
input, with the additional property that there will be a parse of the corrupt
string which contains <strong>the minimum number of modifications needed</strong> such that
if they are applied on the string, it will make it parsed by the original
grammar.</p>

<h3 id="first-we-load-the-prerequisites">First, we load the prerequisites</h3>

<!--
############
import string
import random
import itertools as I

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>The following is our grammar and its start symbol.</p>

<!--
############
grammar = {
    '<start>': [['<expr>']],
    '<expr>': [ ['<term>', '+', '<expr>'], ['<term>', '-', '<expr>'], ['<term>']],
    '<term>': [ ['<fact>', '*', '<term>'], ['<fact>', '/', '<term>'], ['<fact>']],
    '<fact>': [ ['<digits>'], ['(','<expr>',')']],
    '<digits>': [ ['<digit>','<digits>'], ['<digit>']],
    '<digit>': [["%s" % str(i)] for i in range(10)],
}
START = '<start>'

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>The grammar can be printed as follows.</p>

<!--
############
def print_g(g):
    for k in g:
        print(k)
        for rule in g[k]:
            print('|  ', ' '.join([repr(k) for k in rule]))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>For example,</p>

<!--
############
print_g(grammar)

############
-->

<p>Now, constructing a covering grammar proceeds as follows.
First we define how to distinguish nonterminal and terminal symbols</p>

<!--
############
def is_nt(k):
    if len(k) == 1: return False
    return (k[0], k[-1]) == ('<', '>')

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Next, we take each terminal symbol in the given grammar. For example, the
below contains all terminal symbols from our <code>grammar</code></p>

<!--
############
Symbols = [t for k in grammar for alt in grammar[k] for t in alt if not is_nt(t)]
print(len(Symbols))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Next, we consider the following corruptions of the valid input:</p>

<ul>
  <li>The input symbol being considered may have been deleted</li>
  <li>The input symbol being considered may have some junk value in front</li>
  <li>The input symbol may have been mistakenly written as something else.</li>
</ul>

<p>A moment‚Äôs reflection should convince you that a covering grammar only needs
to handle these three cases (In fact, only the first two cases are sufficient
but we add the third because it is also a <em>simple</em> mutation).</p>

<p>The main idea is that we replace the given terminal symbol with an equivalent
nonterminal that lets you make these mistakes. So, we first define that
nonterminal that corresponds to each terminal symbol.</p>

<!--
############
This_sym_str = '<$ [%s]>'

def This_sym(t):
    return  This_sym_str % t

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>

<!--
############
print(This_sym('a'))

############
-->

<p>We also define a convenience function that when given a rule, translates the
terminal symbols in that rule to the above nonterminal symbol.</p>

<!--
############
def translate_terminal(t):
    if is_nt(t): return t
    return This_sym(t)

def translate_terminals(g):
    return {k:[[translate_terminal(t) for t in alt] for alt in g[k]] for k in g}

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>

<!--
############
print_g(translate_terminals(grammar))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>How are these nonterminals defined? Each nonterminal has the following
expansion rules</p>

<div><div><pre><code>&lt;$ {a}&gt; -&gt; a
         | &lt;$.+&gt; a
         | &lt;$&gt;
         | &lt;$!{a}&gt;
</code></pre></div></div>

<p>That is, each nonterminal that corresponds to a terminal symbol has the
following expansions: (1) it matches the original terminal symbol
(2) there is some junk before the terminal symbol. So, match and discard
that junk before matching the terminal symbol
‚Äì <code>&lt;$.+&gt;</code> matches any number of any symbols. These are the corresponding
nonterminals names</p>

<!--
############
Any_one = '<$.>'
Any_plus = '<$.+>'

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>(3) the terminal symbol was deleted. So, skip this terminal symbol by matching
empty (<code>&lt;$&gt;</code>)</p>

<!--
############
Empty = '<$>'

############
-->

<p>(4) the input symbol was a mistake. That is, it matches any input symbol other
than the expected input symbol <code>a</code> ‚Äì <code>&lt;$!{a}&gt;</code>. We have to define as many
nonterminals as there are terminal symbols again. So, we define a function.</p>

<!--
############
Any_not_str = '<$![%s]>'
def Any_not(t): return Any_not_str % t

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>What happens if there is junk after parsing? We take care of that by wrapping
the start symbol as follows</p>

<div><div><pre><code>&lt;$corrupt_start&gt; -&gt; &lt;start&gt;
                  | &lt;start&gt; &lt;$.+&gt;
&lt;$new_start&gt; -&gt; &lt;$corrupt_start&gt;
</code></pre></div></div>

<!--
############
def corrupt_start(old_start):
    return '<@# %s>' % old_start[1:-1]

def new_start(old_start):
    return '<@ %s>' % old_start[1:-1]

def add_start(g, old_start):
    g_ = {}
    g_[corrupt_start(old_start)] = [[old_start], [old_start, Any_plus]]
    new_s = new_start(old_start)
    g_[new_s] = [[corrupt_start(old_start)]]
    return g_, new_s

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Finally we are ready to augment the original given grammar so that what we
have is a covering grammar. We first extract the symbols used, then produce
the nonterminal <code>Any_one</code> that correspond to any symbol match. Next,
we use <code>Any_not</code> to produce an any symbol except match. We then have a
<code>Empty</code> to match the absence of the nonterminal.</p>

<!--
############
def augment_grammar(g, start, Symbols=None):
    if Symbols is None:
        Symbols = [t for k in g for alt in g[k] for t in alt if not is_nt(t)]
    Match_any_sym = {Any_one: [[k] for k in Symbols]}


    Match_any_sym_except = {}
    for kk in Symbols:
        Match_any_sym_except[Any_not(kk)] = [[k] for k in Symbols if k != kk]
    Match_empty = {Empty: []}

    Match_a_sym = {}
    for kk in Symbols:
        Match_a_sym[This_sym(kk)] = [
                [kk],
                [Any_plus, kk],
                [Empty],
                [Any_not(kk)]
                ]
    start_g, start_s = add_start(g, start)
    return {**start_g,
            **translate_terminals(g),
            **Match_any_sym,
            **Match_a_sym,
            **Match_any_sym_except,
            **Match_empty}, start_s

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Here is the augmented grammar</p>

<!--
############
covering_grammar, covering_start = augment_grammar(grammar, START)
print_g(covering_grammar)

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>At this point, we are ready to check the covering properties of our grammar.</p>

<!--
############
ie = SimpleExtractor(EarleyParser(covering_grammar), '1+1', covering_start, covering_grammar[covering_start][0])
for i in range(3):
    tree = ie.extract_a_tree()
    print(tree_to_str(tree))
    print(format_parsetree(tree))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>What about an error?</p>

<!--
############
ie2 = SimpleExtractor(EarleyParser(covering_grammar), '1+1+', covering_start, covering_grammar[covering_start][0])
for i in range(3):
    tree = ie2.extract_a_tree()
    print(tree_to_str(tree))
    print(format_parsetree(tree))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>We define a `tree_to_str_delta() that indicates the corrections produced.</p>

<!--
############
def tree_to_str_delta(tree):
    expanded = []
    to_expand = [tree]
    while to_expand:
        (key, children, *rest), *to_expand = to_expand
        if is_nt(key):
            if key[:2] == '<$' and key[2] != ' ':
                # Empty Any_one Any_plus
                if key == Any_plus: # start
                    expanded.append('{s/%s//}' % repr(tree_to_str((key, children, *rest))))
                elif key == Empty:
                    assert False
                    expanded.append('{del}')
                elif key.startswith(Any_not_str[:4]): # <$![.]>
                    k = key[4]
                    expanded.append('{s/%s/%s/}' % (repr(tree_to_str((key, children, *rest))), k))
                else:
                    assert False
            elif key[:2] == '<$' and key[2] == ' ' and len(children) == 1 and children[0][0] == Empty:
                expanded.append('{del %s}' % repr(key[3:-2]))
            else:
                to_expand = list(children) + list(to_expand)
        else:
            assert not children
            expanded.append(key)
    return ''.join(expanded)

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>

<!--
############
ie2 = SimpleExtractor(EarleyParser(covering_grammar), '1+1+', covering_start, covering_grammar[covering_start][0])
for i in range(3):
    tree = ie2.extract_a_tree()
    print(tree_to_str_delta(tree))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>As you can see, we can parse corrupt inputs, but the inputs that we parse are
not necessarily the smallest. The next step is how to extract
the minimally corrupt parse.</p>

<h2 id="the-minimally-corrupt-parse">The minimally corrupt parse.</h2>

<p>First, we need to modify the Earley parser so that it can keep track of the
penalties. We essentially assign a penalty if any of the following us used.</p>

<ul>
  <li>Any use of &lt;$.&gt; : Any_one ‚Äî note, Any_plus gets +1 automatically</li>
  <li>Any use of &lt;$&gt;  : Empty</li>
  <li>Any use of &lt;$ !{.}&gt;  : Any_not</li>
</ul>

<!--
############
class ErrorCorrectingEarleyParser(EarleyParser):
    def complete(self, col, state):
        parent_states = [st for st in state.s_col.states
                 if st.at_dot() == state.name]
        my_penalty = state.penalty
        if state.name ==  Empty:
            my_penalty = 1
        elif state.name == Any_one:
            my_penalty = 1
        elif state.name.startswith(Any_not_str[:4]):
            my_penalty = 1
        for st in parent_states:
            s = st.advance()
            s.penalty += my_penalty
            col.add(s)

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>This means that we need a new state definition with penalty.</p>

<!--
############
class State(State):
    def __init__(self, name, expr, dot, s_col, e_col=None):
        self.name, self.expr, self.dot = name, expr, dot
        self.s_col, self.e_col = s_col, e_col
        self.penalty = 0

    def copy(self):
        s = State(self.name, self.expr, self.dot, self.s_col, self.e_col)
        s.penalty = self.penalty
        return s

    def advance(self):
        s = State(self.name, self.expr, self.dot + 1, self.s_col, self.e_col)
        s.penalty = self.penalty
        return s

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Since States are created by Columns, we need new column too that knows about
state penalties. We also need to keep track of the minimum penalty that a state
incurred. In particular, any time we find a less corrupt parse, we update the
penalty.</p>

<!--
############
class Column(Column):
    def add(self, state):
        if state in self._unique:
            if self._unique[state].penalty > state.penalty:
                # delete from self.states in fill_chart
                state.e_col = self
                self.states.append(state)
                self._unique[state] = state
            return self._unique[state]
        self._unique[state] = state
        self.states.append(state)
        state.e_col = self
        return self._unique[state]

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>As we find and add our states with lesser penalties, we need to remove the
higher penalty states from our list.</p>

<!--
############
class Column(Column):
    def remove_extra_states(self):
        my_states = []
        for state in self._unique:
            cur_states = [s for s in self.states if s == state]
            if len(cur_states) > 1:
                cur_states = sorted(cur_states, key=lambda s: s.penalty)
            my_states.append(cur_states[0])
        self.states = my_states
        return

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>We need to call this method at the end of processing of the column.</p>

<!--
############
class ErrorCorrectingEarleyParser(ErrorCorrectingEarleyParser):
    def fill_chart(self, chart):
        for i, col in enumerate(chart):
            for state in col.states:
                if state.finished():
                    self.complete(col, state)
                else:
                    sym = state.at_dot()
                    if sym in self._grammar:
                        self.predict(col, sym, state)
                    else:
                        if i + 1 >= len(chart):
                            continue
                        self.scan(chart[i + 1], state, sym)
            col.remove_extra_states()
            if self.log: print(col, '\n')
        return chart

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Now, we need to hook up our new column and state to Earley parser.</p>

<!--
############
class ErrorCorrectingEarleyParser(ErrorCorrectingEarleyParser):
    def create_column(self, i, tok): return Column(i, tok)

    def create_state(self, sym, alt, num, col): return State(sym, alt, num, col)

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Finally, we hook up our simple extractor to choose the lowest cost path.</p>

<!--
############
class SimpleExtractor(SimpleExtractor):
    def choose_path(self, arr):
        l = len(arr)
        i = random.randrange(l)
        res = sorted([(self.cost_of_path(a),a) for a in arr], key=lambda a: a[0])
        return res[0][1], None, None

    def cost_of_path(self, p):
        states = [s for s,kind,chart in p if kind == 'n']
        return sum([s.penalty for s in states])

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>

<!--
############
ie3 = SimpleExtractor(ErrorCorrectingEarleyParser(covering_grammar), '1+1+', covering_start, covering_grammar[covering_start][0])
for i in range(3):
    tree = ie3.extract_a_tree()
    print(tree_to_str(tree))
    print(format_parsetree(tree))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Caution, this command will take time. 30 seconds in Mac Book Pro.</p>

<!--
############
if False:
    covering_grammar, covering_start = augment_grammar(grammar, START, Symbols=[i for i in string.printable if i not in '\n\r\t\x0b\x0c'])
    ie4 = SimpleExtractor(ErrorCorrectingEarleyParser(covering_grammar), 'x+y', covering_start, covering_grammar[covering_start][0])
    for i in range(3):
        tree = ie4.extract_a_tree()
        print(tree_to_str_delta(tree))
        print(format_parsetree(tree))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Why is this so slow? One reason is that, for conceptual clarity, and
generality, we opted to expand two terms from the original paper.
For example, we chose set Any_one: <code>&lt;$.&gt;</code> as well as
Any_not_str: <code>&lt;$![.]&gt;</code> as nonterminal symbols. This means that
to match <code>&lt;$.&gt;</code>, (say we have \(T\) terminal symbols,) we have to carry
an extra \(T\) symbols per each symbol ‚Äì essentially giving us \(T^2\)
extra matches to perform. For matching <code>&lt;$![.]&gt;</code>, the situation is worse,
we have to carry \(T^2\) symbols per each terminal, giving \(T^3\)
matches per original terminal symbol.</p>

<p>Fortunately, there is an optimization possible here. We can set the
Any_one: <code>.</code> and Any_not(a): <code>!a</code> to be terminal symbols, and fix the
terminal match so that we match any character on <code>.</code> and except the given
character (e.g. <code>a</code>) on <code>!a</code>. What we lose there is generality. THat is, the
augmented context-free grammar will no longer be usable by other parsers
(unless they are augmented got match regular expressions).
We modify our Earley parser to expect these. First our strings.</p>

<!--
############
Any_term = '$.'

Any_not_term = '!%s'

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Now our parser.</p>

<!--
############
class ErrorCorrectingEarleyParser(ErrorCorrectingEarleyParser):
    def match_terminal(self, rex, input_term):
        if len(rex) > 1:
            if rex == Any_term: return True
            if rex[0] == Any_not_term[0]: return rex[1] != input_term # Any not
            return False
        else: return rex == input_term # normal

    def scan(self, col, state, letter):
        if self.match_terminal(letter, col.letter):
            s = state.advance()
            s.expr = (col.letter, )
            col.add(s)

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Our grammars are augmented this way.</p>

<!--
############
def augment_grammar_ex(g, start, Symbols=None):
    if Symbols is None:
        Symbols = [t for k in g for alt in g[k] for t in alt if not is_nt(t)]
    Match_any_sym = {Any_one: [[Any_term]]}


    Match_any_sym_except = {}
    for kk in Symbols:
        Match_any_sym_except[Any_not(kk)] = [[Any_not_term % kk]]
    Match_empty = {Empty: []}

    Match_a_sym = {}
    for kk in Symbols:
        Match_a_sym[This_sym(kk)] = [
                [kk],
                [Any_plus, kk],
                [Empty],
                [Any_not(kk)]
                ]
    start_g, start_s = add_start(g, start)
    return {**start_g,
            **translate_terminals(g),
            **Match_any_sym,
            **Match_a_sym,
            **Match_any_sym_except,
            **Match_empty}, start_s

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Using it.</p>

<!--
############
covering_grammar_ex, covering_start_ex = augment_grammar_ex(grammar, START)
print_g(covering_grammar_ex)

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Testing x+y</p>

<!--
############
covering_grammar_ex, covering_start_ex = augment_grammar_ex(grammar, START, Symbols=[i for i in string.printable if i not in '\n\r\t\x0b\x0c'])
ie5 = SimpleExtractor(ErrorCorrectingEarleyParser(covering_grammar_ex), 'x+y', covering_start_ex, covering_grammar_ex[covering_start_ex][0])
for i in range(3):
    tree = ie5.extract_a_tree()
    print(tree_to_str_delta(tree))


############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Testing x+1</p>

<!--
############
covering_grammar_ex, covering_start_ex = augment_grammar_ex(grammar, START, Symbols=[i for i in string.printable if i not in '\n\r\t\x0b\x0c'])
ie5 = SimpleExtractor(ErrorCorrectingEarleyParser(covering_grammar_ex), 'x+1', covering_start_ex, covering_grammar_ex[covering_start_ex][0])
for i in range(3):
    tree = ie5.extract_a_tree()
    print(tree_to_str_delta(tree))

############
-->
<form name="python_run_form">
<br>
<pre name="python_output"></pre>

</form>
<p>Note that the algorithm for recognition is \(O(n^3)\). This is a consequence
of the fact that our covering grammar is simply a context-free grammar, and
as you can see, there is only a constant size increase in the grammar \((|G|+ |T|^3)\)
where \(|G|\) is the original size, and \(|T|\) is the numbeer of terminals.</p>

<p>The runnable Python source for this notebook is available <a href="https://github.com/rahulgopinath/rahulgopinath.github.io/blob/master/notebooks/2021-02-22-error-correcting-earley-parsing.py">here</a>.</p>




  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://rahul.gopinath.org/post/2021/02/22/error-correcting-earley-parser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292780</guid>
            <pubDate>Sun, 28 Feb 2021 12:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indeed MPH: Fast and Compact Immutable Key-Value Stores]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26292427">thread link</a>) | @gbrown_
<br/>
February 28, 2021 | https://engineering.indeedblog.com/blog/2018/02/indeed-mph/ | <a href="https://web.archive.org/web/*/https://engineering.indeedblog.com/blog/2018/02/indeed-mph/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		

		<div>

			<p><img loading="lazy" src="http://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/MPH-Blog-Header.png" alt="" width="1024" height="250" srcset="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/MPH-Blog-Header.png 1024w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/MPH-Blog-Header-300x73.png 300w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/MPH-Blog-Header-768x188.png 768w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/MPH-Blog-Header-747x182.png 747w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>When you need to scale an application with a lot of data, how do you decide on a storage solution? How can you both safely store and efficiently interact with large data sets? This often turns into a debate about whether to use SQL or NoSQL. Each comes with strengths and drawbacks.</p>
<p>But what if there was a third option that sidestepped database concerns altogether?</p>
<p>Consumers might need updates no more often than every few minutes. In this case, being able to load a data set into memory dramatically speeds access and allows for tremendous scale. This is why, for many projects at Indeed, we distribute a full copy of the needed data to each consumer and render the SQL or NoSQL debate unnecessary. To make this possible, we manage data size using a new key-value store based on minimal perfect hash functions. We‚Äôve implemented this store as a Java library called <a href="https://github.com/indeedeng/mph-table" rel="noopener noreferrer">Indeed MPH</a>.</p>
<h2>The problems with distributing data</h2>
<p>Usually, distributing a full copy of your data to consumers is impractical for two reasons. First, the data must be mostly read-only. Second, the data cannot be so large as to prevent distribution or processing.</p>
<p>You can overcome the first problem by implementing batch updates. Redistribute the data every day, every hour, or even more frequently, and you keep the data read-only while ensuring that it remains useful. However, how do you keep the size down? As it turns out, the same batch update strategy that addresses the first problem also addresses the second.</p>
<h2>Minimal perfect hash functions</h2>
<p>Generating read-only data sets means that we know all the keys for our data set in advance. This lets us apply optimizations to the data set to reduce its size. In the case of hash tables, this knowledge allows us to compute a <a href="https://en.wikipedia.org/wiki/Perfect_hash_function" rel="noopener noreferrer" data-href="https://en.wikipedia.org/wiki/Perfect_hash_function">perfect hash function</a>.</p>
<p>A perfect hash function maps every element to a distinct integer with no collisions‚Ää‚Äî‚Ääin mathematical terms it‚Äôs an injective function. A minimal perfect hash (mph) function maps <em>n</em> keys to the <em>n</em> consecutive integers [0, <em>n</em>-1]. With such a structure we can guarantee a single disk seek while maintaining 100% load in the table, but as we‚Äôll demonstrate later, there are even more advantages.</p>
<p>Finding such hash functions can be difficult. In fact the Birthday Paradox, described in this <a href="https://en.wikipedia.org/wiki/Birthday_problem" rel="noopener noreferrer" data-href="https://en.wikipedia.org/wiki/Birthday_problem">Wikipedia article</a>, tells us that zero collisions is unlikely even if <em>m</em> is several times larger than <em>n.</em> However, recent advances have yielded efficient techniques (such as described in <a href="http://staff.itee.uq.edu.au/havas/TR0242.pdf" rel="noopener noreferrer" data-href="http://staff.itee.uq.edu.au/havas/TR0242.pdf">this abstract</a>) and <a href="http://sux.di.unimi.it/" rel="noopener noreferrer" data-href="http://sux.di.unimi.it/">quality libraries</a> for generating minimal perfect hashes. These techniques allow our method to succeed with only a small downside: the resulting hash function itself requires a lookup table of ~2.2 bits per key, so it does not occupy a constant size. However, this lookup table is a fraction of the size of a bloom filter and only requires about 26MB for 100 million entries. In practice, the size of the lookup table is negligible compared to the size of the data being stored.</p>
<h2>Practicalities</h2>
<p>An mph function gives us a mapping from the keys to [0, <em>n</em>-1], but we still need to implement the table. In memory, we‚Äôd typically just store the data in an array. To translate this to offline storage we need to make something explicit that programming language arrays make implicit: memory offsets. Our representation is a directory with three files:</p>
<ul>
<li>data.bin: the raw serialized key/value pairs</li>
<li>offsets.bin: a fixed size array where the <em>i</em>th value is the byte offset in data.bin for the entry whose hash is <em>i</em></li>
<li>meta.bin: the serialized hash function itself, along with any other desired metadata</li>
</ul>
<p>The following figure shows this representation with an index mapping colors to animals:</p>
<p><a href="http://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph1.png"><img loading="lazy" src="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph1.png" alt="A representation of explicitly mapping memory offsets using three files." width="506" height="195" srcset="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph1.png 506w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph1-300x116.png 300w" sizes="(max-width: 506px) 100vw, 506px"></a></p>
<p>The file containing the serialized hash requires roughly 2 bits per key, while the file containing the offsets requires 4 bytes. The raw serialized key/value pairs require 46 bytes per key.</p>
<p>One convenience of this representation is that data.bin is raw data available for iterating, independent of the hash function. In addition, we might have multiple hash functions indexing the same data.bin by different keys as long as those keys are always unique.</p>
<p>The disadvantage of this representation is with many small entries. In this case, the size of the offsets could be on par with or even larger than the data itself. For an extreme example, if the data contains 750 million mappings from int to half-precision float, we require 7.5e8 * 6 = ~4.2G for data.bin, but 7.5e8 * 8 = ~5.6G for offsets.bin! In this example, we can take advantage of every entry having a fixed size. We don‚Äôt need to store the offsets‚Ää‚Äî‚Ääwe can index directly into data.bin. But we want to optimize the variable-sized case as well.</p>
<p>This high cost comes specifically when we‚Äôre dealing with small entries. If the entries are large, the size of the offsets are negligible by comparison. Because the total size is small, we can represent it with a <a href="https://en.wikipedia.org/wiki/Succinct_data_structure" rel="noopener noreferrer" data-href="https://en.wikipedia.org/wiki/Succinct_data_structure">rank (bitcount) data-structure</a>, on the order of bits per entry instead of bytes. For a little more overhead, we can compute the inverse of rank, called select, in constant time on this same data structure. Why is that useful? If the bits are set for the start byte of every entry in data.bin, then finding the offset of the <em>i</em>th entry is just computing select(<em>i</em>).</p>
<p>The structure becomes the following. In this case we now have to sort data.bin by hash value.</p>
<p><a href="http://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph6.png"><img loading="lazy" src="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph6.png" alt="A representation of explicitly mapping memory offsets with optimization in the offsets file." width="534" height="324" srcset="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph6.png 534w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph6-300x182.png 300w" sizes="(max-width: 534px) 100vw, 534px"></a></p>
<p>In the optimized structure, the file containing the offsets requires 1.x * 46 bits.</p>
<p>A further optimization comes from the often very regular structure in our data. For instance, to map from a long to list of longs (using a single byte for the count), the size of every individual entry <em>i</em> (including key and value) can be represented as 8<em>xi</em> + 9, assuming the length of the list is <em>xi</em>. The offset of the <em>k</em>th entry becomes ‚àë(8<em>xi</em> + 9) = 9<em>k</em> + ‚àë8<em>xi</em> = 9<em>k</em> + 8<em>x</em>. In other words, all we have to store is <em>x</em>, which is much smaller than the actual offset, and a big savings with the select approach. In this case, with 10 million entries averaging 2 elements in the list, the size of data.bin is 10000000 * (9 + 16) = ~250M, but the compressed select method uses only ~2.5M.</p>
<p>Our implementation computes what the size would be with both an array of offsets and the select approach and chooses accordingly.</p>
<h2>More optimizations</h2>
<h3>Throw away the keys!</h3>
<p>If we have no collisions and know that the key we are looking up is in the table, we don‚Äôt need to verify it. Alternately, we may be able to validate the key from the value, or from other sources given the value. Finally, if we can accept some small probability of false positive lookups, we can always probabilistically verify whether keys are in the table by using a bloom filter.</p>
<p>We have a better alternative. Since we‚Äôve already hashed to a value that has no collisions in the original key set, we can store a <em>k</em>-bit signature (the low bits of any universal hash will do) of the key. Any key not in the original set that hashes to the same value will only match the signature with probability 2-<em>k</em>. This is a much better error rate than with a bloom filter.</p>
<p>In all of these cases, we can omit the keys entirely from the table. When the values are small, the keys may be a significant fraction, or even the majority of the table.</p>
<h3>Link by hashes, not keys</h3>
<p>It‚Äôs common to want to link multiple tables together‚Ää‚Äî‚Ääthe values of one table either are, or contain foreign keys into, another table.</p>
<p>Another benefit of using an mph function is that it compresses keys to a compact integer range. We can store the hash value instead of the key, which for most practical purposes will fit in a 4-byte integer, as opposed to 8-byte longs or larger for many other foreign keys. Not only is this more compact, but it‚Äôs also faster to read because we don‚Äôt need to re-compute the hash for the second lookup.</p>
<h2>Code and benchmarks</h2>
<p>We‚Äôre excited to announce that we‚Äôve open-sourced our mph code. For benchmarks we compare with several open source alternatives:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/SQLite" rel="noopener noreferrer" data-href="https://en.wikipedia.org/wiki/SQLite">SQLite3</a>: a single-file RDBMS suitable for replication</li>
<li><a href="https://en.wikipedia.org/wiki/LevelDB" rel="noopener noreferrer" data-href="https://en.wikipedia.org/wiki/LevelDB">LevelDB</a>: Google‚Äôs LSM tree key-value store</li>
<li><a href="https://github.com/IndeedEng/lsmtree" rel="noopener noreferrer" data-href="https://github.com/IndeedEng/lsmtree">lsm</a>: our LSM tree key-value store</li>
<li><a href="http://discodb.readthedocs.io/en/latest/" rel="noopener noreferrer" data-href="http://discodb.readthedocs.io/en/latest/">discodb</a>: an immutable key-value store also based on minimal perfect hashing</li>
<li><a href="http://www.corpit.ru/mjt/tinycdb.html" rel="noopener noreferrer" data-href="http://www.corpit.ru/mjt/tinycdb.html">TinyCDB</a>: an immutable key-value store using non-perfect hashing</li>
</ul>
<p>Note these options do not have equivalent feature sets. SQLite provides full relational operations, lsm and LevelDB provide range queries, and all three of these are mutable. Here we are concerned only with the common functionality of these options.</p>
<p>We look at the results for two conceptually linked stores based on our production data. This allows us to demonstrate the link by hashing optimization described above, and also enables a more natural representation in SQLite. The first store is a mapping from 50 million 64-bit hashes to a small cluster of ‚Äúitems,‚Äù which are 80-bit integers represented as 16-digit base-32 strings. The second store is the reverse mapping from each item in the cluster to its associated hash.</p>
<p>An important aspect of our own key-value stores is their use of arbitrary serialization via a plugin infrastructure. So for a fair comparison, in the sizes for our LSM trees and MPH tables we include both the sizes for opaque string to string mappings, as well as two optimizations. We encode keys as fixed 8-byte long values, and encode the values as short lists of 80-bit integers. For SQLite we encode the keys as integers.</p>
<p><a href="http://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph4.png"><img loading="lazy" src="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph4-1024x633.png" alt="A bar graph comparing data size in MB for string mappings between several storage methods." width="1024" height="633" srcset="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph4-1024x633.png 1024w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph4-300x186.png 300w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph4-768x475.png 768w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph4-679x420.png 679w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph4.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p>
<p>In the general case of string mappings, LevelDB, lsm and mph are all of comparable size, and notably smaller than the alternative solutions. If we apply more efficient serialization lsm and mph become much smaller, and mph is increasingly able to take advantage of the regularity in size to become the smallest option.<a href="http://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph2.png"><img loading="lazy" src="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph2-1024x633.png" alt="A bar graph comparing data size in MB for serializations between several storage methods." width="1024" height="633" srcset="https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph2-1024x633.png 1024w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph2-300x186.png 300w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph2-768x475.png 768w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph2-679x420.png 679w, https://rac4ou2q3g246tjk3rxqbt1c-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/mph2.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p>
<p>Here we consider only the best serialization for lsm and mph. For mph we also show the size with the optimizations discussed above, first not storing the keys and then also linking to the above table via the perfect hash value. For SQLite we include the size when indexing on both columns, which allows us to remove the previous table altogether. In this ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.indeedblog.com/blog/2018/02/indeed-mph/">https://engineering.indeedblog.com/blog/2018/02/indeed-mph/</a></em></p>]]>
            </description>
            <link>https://engineering.indeedblog.com/blog/2018/02/indeed-mph/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292427</guid>
            <pubDate>Sun, 28 Feb 2021 10:56:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tour of Koka (an elegant programming language with Algebraic Effects)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26292411">thread link</a>) | @isaacimagine
<br/>
February 28, 2021 | https://koka-lang.github.io/koka/doc/book.html#tour | <a href="https://web.archive.org/web/*/https://koka-lang.github.io/koka/doc/book.html#tour">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<!-- #00547D -->


<p><a href="https://gitter.im/koka-lang/koka?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge"><img src="https://badges.gitter.im/koka-lang/koka.svg"></a>
</p>
<p>Welcome to Koka ‚Äì a strongly typed functional-style language with effect types and handlers.
</p>
<p><a href="#why" title="2.‚ÄÇWhy Koka?">Why Koka? <span></span></a>
<a href="#tour" title="3.‚ÄÇA Tour of Koka">A Tour of Koka <span></span></a>
<a href="#install" title="1.1.‚ÄÇInstalling the compiler">Install <span></span></a>
<a href="https://github.com/koka-lang/koka/discussions" data-linkid="forum">Discussion forum</a>
<a href="https://github.com/koka-lang/koka" data-linkid="kokarepo" target="_top">Github</a>
<a href="https://koka-lang.github.io/koka/doc/toc.html" data-linkid="libraries" target="_top">Libraries</a></p>
<div>
<p>Note: Koka v2 is a research language that is currently under development
and not ready for production use. 
Nevertheless, the language is stable and the compiler
implements the full specification. The main things lacking at the moment are 
libraries, package management, and deep IDE integration. 
</p>
<div>
<p>News:
</p>
<ul>
<li>2021-02-14: Koka v2.0.16 released.
</li>
<li>2020-12-12: Koka v2.0.14 released.
</li>
<li>2020-12-02: Koka v2.0.12 released.
</li>
<li>2020-11-29: Perceus technical report publised (<a href="https://www.microsoft.com/en-us/research/publication/perceus-garbage-free-reference-counting-with-reuse/" data-linkid="perceus">pdf</a>).</li></ul>
</div></div><h2 id="install" data-heading-depth="2"><a href="#install"></a><span><span>1.1</span>.‚ÄÇ</span>Installing the compiler</h2>
<p>For Linux and macOS on x86 64-bit, you can install Koka using:
</p>
<pre><code><span>&gt; <strong>curl -sSL https://github.com/koka-lang/koka/releases/latest/download/install.sh | sh</strong></span></code></pre>
<p>This also installs syntax highlighting for the VS Code and Atom editors.
After installation, verify if Koka installed correctly:
</p>
<pre><code><span><strong><code>&gt; koka</code></strong></span>
 _          _           ____
| |        | |         |__  \
| | __ ___ | | __ __ _  __) |
| |/ // _ \| |/ // _' || ___/ welcome to the koka interpreter
|   &lt;| (_) |   &lt;| (_| ||____| version 2.0.10, Nov 28 2020, libc 64-bit (gcc)
|_|\_\\___/|_|\_\\__,_|       type :? for help

loading: std/core
loading: std/core/types
loading: std/core/hnd
&gt;</code></pre>
<p>Type <code>:q</code> to exit the interpreter.
</p>
<p>For detailed instructions and other platforms (including Windows) see the&nbsp;<a href="https://github.com/koka-lang/koka/releases" data-linkid="releases">releases</a> page.
It is also straightforward to build the compiler&nbsp;<a href="https://github.com/koka-lang/koka/#build-from-source" data-linkid="build">from source</a>.
</p><h2 id="sec-running-the-compiler" data-heading-depth="2"><a href="#sec-running-the-compiler"></a><span><span>1.2</span>.‚ÄÇ</span>Running the compiler</h2>
<p>You can compile a Koka source using <code><span><span>-</span></span>c</code> (note that all&nbsp;<a href="https://github.com/koka-lang/koka/tree/master/samples" data-linkid="samples"><code>samples</code></a> are pre-installed):
</p>
<pre><code><span><strong><code>&gt; koka -c samples/basic/caesar.kk</code></strong></span>
compile: samples/basic/caesar.kk
loading: std/core
loading: std/core/types
loading: std/core/hnd
loading: std/num/double
loading: std/text/parse
loading: std/num/int32
check  : samples/basic/caesar
linking: samples_basic_caesar
created: out/v2.0.9/gcc-debug/samples_basic_caesar</code></pre>
<p>and run the resulting executable:
</p>
<pre><code><span><strong><code>&gt; out/v2.0.9/gcc-debug/samples_basic_caesar</code></strong></span>
plain  : Koka is a well-typed language
encoded: Krnd lv d zhoo-wbshg odqjxdjh
cracked: Koka is a well-typed language</code></pre>
<p>The <code>-O2</code> flag builds an optimized program. Let's try it on a purely functional implementation
of balanced insertion in a red-black tree (<a href="https://github.com/koka-lang/koka/tree/master/samples/basic/rbtree.kk"><code>rbtree<span>.</span>kk</code></a>):
</p>
<pre><code><span><strong><code>&gt; koka -O2 -c samples/basic/rbtree.kk</code></strong></span>
...
linking: samples_basic_rbtree
created: out/v2.0.10/gcc-drelease/samples_basic_rbtree

<span><strong><code>&gt; time out/v2.0.10/gcc-drelease/samples_basic_rbtree</code></strong></span>
420000
real    0m0.750s
...</code></pre>
<p>We can compare this against an in-place updating C++ implementation using <code>stl::map</code>
(<a href="https://github.com/koka-lang/koka/tree/master/samples/basic/rbtree.cpp"><code>rbtree.cpp</code></a>) (which also uses a
<a href="https://code.woboq.org/gcc/libstdc++-v3/src/c++98/tree.cc.html">red-black tree</a> internally):
</p>
<pre><code><span><strong><code>&gt; clang++ --std=c++17 -o cpp-rbtree -O3 /usr/local/share/koka/v2.0.12/samples/basic/rbtree.cpp</code></strong></span>
<span><strong><code>&gt; time ./cpp-rbtree</code></strong></span>
420000
real    0m0.864s
...</code></pre>
<p>The excellent performance relative to C++ here (on an AMD 3600XT) is the result of Perceus automatically
transforming the fast path of the pure functional rebalancing to use mostly in-place updates,
closely mimicking the imperative rebalancing code of the hand optimized C++ library.
</p><h2 id="sec-running-the-interactive-compiler" data-heading-depth="2"><a href="#sec-running-the-interactive-compiler"></a><span><span>1.3</span>.‚ÄÇ</span>Running the interactive compiler</h2>
<p>Without giving any input files, the interactive environment runs by default:
</p>
<pre><code><span><strong><code>&gt; koka</code></strong></span>
 _          _           ____
| |        | |         |__  \
| | __ ___ | | __ __ _  __) |
| |/ // _ \| |/ // _' || ___/ welcome to the koka interpreter
|   &lt;| (_) |   &lt;| (_| ||____| version 2.0.9, Nov 27 2020, libc 64-bit (gcc)
|_|\_\\___/|_|\_\\__,_|       type :? for help

loading: std/core
loading: std/core/types
loading: std/core/hnd
&gt;</code></pre>
<p>Now you can test some expressions:
</p>
<pre><code><span><strong><code>&gt; println("hi koka")</code></strong></span>
check  : interactive
check  : interactive
linking: interactive
created: out\v2.0.9\mingw-debug\interactive

hi koka

<span><strong><code>&gt; :t "hi"</code></strong></span>
string

<span><strong><code>&gt; :t println("hi")</code></strong></span>
console ()</code></pre>
<p>Or load a demo (use <code>tab</code> completion to avoid typing too much):
</p>
<pre><code><span><strong><code>&gt; :l samples/basic/fibonacci</code></strong></span>
compile: samples/basic/fibonacci.kk
loading: std/core
loading: std/core/types
loading: std/core/hnd
check  : samples/basic/fibonacci
modules:
  samples/basic/fibonacci

<span><strong><code>&gt; main()</code></strong></span>
check  : interactive
check  : interactive
linking: interactive
created: out\v2.0.9\mingw-debug\interactive

The 10000th fibonacci number is 33644764876431783266621612005107543310302148460680063906564769974680081442166662368155595513633734025582065332680836159373734790483865268263040892463056431887354544369559827491606602099884183933864652731300088830269235673613135117579297437854413752130520504347701602264758318906527890855154366159582987279682987510631200575428783453215515103870818298969791613127856265033195487140214287532698187962046936097879900350962302291026368131493195275630227837628441540360584402572114334961180023091208287046088923962328835461505776583271252546093591128203925285393434620904245248929403901706233888991085841065183173360437470737908552631764325733993712871937587746897479926305837065742830161637408969178426378624212835258112820516370298089332099905707920064367426202389783111470054074998459250360633560933883831923386783056136435351892133279732908133732642652633989763922723407882928177953580570993691049175470808931841056146322338217465637321248226383092103297701648054726243842374862411453093812206564914032751086643394517512161526545361333111314042436854805106765843493523836959653428071768775328348234345557366719731392746273629108210679280784718035329131176778924659089938635459327894523777674406192240337638674004021330343297496902028328145933418826817683893072003634795623117103101291953169794607632737589253530772552375943788434504067715555779056450443016640119462580972216729758615026968443146952034614932291105970676243268515992834709891284706740862008587135016260312071903172086094081298321581077282076353186624611278245537208532365305775956430072517744315051539600905168603220349163222640885248852433158051534849622434848299380905070483482449327453732624567755879089187190803662058009594743150052402532709746995318770724376825907419939632265984147498193609285223945039707165443156421328157688908058783183404917434556270520223564846495196112460268313970975069382648706613264507665074611512677522748621598642530711298441182622661057163515069260029861704945425047491378115154139941550671256271197133252763631939606902895650288268608362241082050562430701794976171121233066073310059947366875</code></pre>
<p>And quit the interpreter:
</p>
<pre><code><span><strong><code>&gt; :q</code></strong></span>

I think of my body as a side effect of my mind.
  -- Carrie Fisher (1956)</code></pre>
<p>The&nbsp;<a href="https://github.com/koka-lang/koka/tree/master/samples/syntax"><code>samples/syntax</code></a>
and&nbsp;<a href="https://github.com/koka-lang/koka/tree/master/samples/basic"><code>samples/basic</code></a> 
directories contain various basic Koka examples to start with. If you type:
</p>
<pre><code><span><strong><code>&gt; :l samples/</code></strong></span></code></pre>
<p>in the interpreter, you can <code>tab</code> twice to see the available sample files and directories.
Use <code>:s</code> to see the source of a loaded module.
</p>
<p>If you use VS Code or Atom, or if you set the <code>koka_editor</code> environment variable,
you can type <code>:e</code> in the interactive prompt to edit your program further. For example,
</p>
<pre><code><span><strong><code>&gt; :l samples/basic/caesar</code></strong></span>
...
check  : samples/basic/caesar
modules:
    samples/basic/caesar

<span><strong><code>&gt; :e </code></strong></span>

&lt;edit the source and reload&gt;

<span><strong><code>&gt; :r</code></strong></span>
...
check  : samples/basic/caesar
modules:
    samples/basic/caesar

<span><strong><code>&gt; main()</code></strong></span>
</code></pre>
<p>What next?
</p>
<p><a href="#sec-basics" title="3.1.‚ÄÇBasics">Basic Koka syntax <span></span></a>
<a href="https://koka-lang.github.io/koka/doc/toc.html" data-linkid="libraries" target="_top">Browse the Library documentation</a>
</p><!--
## Algebraic effect handlers

A novel feature of &koka; is a compiled and typed implementation of algebraic
effect handlers (described in detail in [[3]](#references)).
In the interactive environment, you can load various demo files with algebraic
effects which are located in the [``samples/handlers``](https://github.com/koka-lang/koka/tree/master/samples/handlers) directory.

    > :f samples/handlers/basic

where ``:f`` forces a recompile (versus ``:l`` which avoids a recompile if possible).
Use the ``:?`` command to get an overview of all commands. After
loading the ``common`` demo, we can run it directly from the interpreter:

    > :f samples/handlers/basic
    compile: samples/handlers/basic.kk
    ...
    check  : samples/handlers/basic
    modules:
      samples/handlers/basic

    > :t test2    
    () -> console ()

    > test2()
    check  : interactive
    check  : interactive
    linking: interactive
    created: out\v2.0.5\mingw-debug\interactive

    Hello there, there

Some interesting demos are:

* ``basic.kk``: Various examples from the paper "_Algebraic Effects for
  Functional Programming_" [[3]](#references). Shows how to implement
  common control-flow abstractions like exceptions, state, iterators,
  ambiguity, and asynchronous programming.

* ``nim.kk``: Various examples from the paper "_Liberating effects with
  rows and handlers_" [[1]](#references).

* ``scoped.kk``: Examples from the paper "_Effect Handlers in Scope_" [[5]](#references).
-->



<p>There are many new languages being designed, but only few
bring fundamentally new concepts ‚Äì like Haskell with
pure versus monadic programming, or Rust with borrow checking.
Koka distinguishes itself through <em>effect typing</em>, <em>effect handlers</em>,
and <em>Perceus</em> memory management:
</p>
<h2 id="why-mingen" data-heading-depth="2"><a href="#why-mingen"></a><span><span>2.1</span>.‚ÄÇ</span>Minimal but General</h2>
<p>Koka has a small core set of
orthogonal, well-studied language features ‚Äì but each of these is
as general and <em>composable</em> as possible, such that we do not need further
‚Äúspecial‚Äù extensions. Core features include first-class functions,
a higher-rank impredicative polymorphic type- and effect system, 
algebraic data types, and effect handlers.
</p><pre><span>fun hello-ten() {
  var i := 0
  while { i &lt; 10 } {
    println("hello")
    i := i + 1
  }
}
</span><span><span>fun</span> hello<span>-</span>ten() {
  <span>var</span> i <span>:=</span> <span>0</span>
  while { i <span>&lt;</span> <span>10</span> } {
    println(<span>"hello"</span>)
    i <span>:=</span> i <span>+</span> <span>1</span>
  }
}
</span></pre>



<p>As an example of the <em>min-gen</em> design principle, Koka implements most
control-flow primitives as regular functions. An anonymous function can
be written as <code><span>fn</span>(){ <span>&lt;</span>body<span>&gt;</span> }</code>; but as a syntactic convenience, any
function without arguments can be shortened further to use just braces,
as <code>{ <span>&lt;</span>body<span>&gt;</span> }</code>.
</p>
<p>We can write a <code><a href="https://koka-lang.github.io/koka/doc/std_core.html#while">while<span><span>std<span>/</span>core<span>/</span></span>while: <span>forall</span><span>&lt;</span><span>e</span><span>&gt;</span> <span>(</span><span>predicate</span> <span>:</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>bool</span><span>,</span> <span>action</span> <span>:</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>(</span><span>)</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>(</span><span>)</span></span></a></code> loop now using regular
function calls as shown in the example,
where the call to <code><a href="https://koka-lang.github.io/koka/doc/std_core.html#while">while<span><span>std<span>/</span>core<span>/</span></span>while: <span>forall</span><span>&lt;</span><span>e</span><span>&gt;</span> <span>(</span><span>predicate</span> <span>:</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>bool</span><span>,</span> <span>action</span> <span>:</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>(</span><span>)</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>(</span><span>)</span></span></a></code> is desugared to
<code><a href="https://koka-lang.github.io/koka/doc/std_core.html#while">while<span><span>std<span>/</span>core<span>/</span></span>while: <span>forall</span><span>&lt;</span><span>e</span><span>&gt;</span> <span>(</span><span>predicate</span> <span>:</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>bool</span><span>,</span> <span>action</span> <span>:</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>(</span><span>)</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>(</span><span>)</span></span></a>( <span>fn</span>(){ i <span>&lt;</span> <span>10</span> }, <span>fn</span>(){ <span>...</span> } )</code>. 
</p>
<p>This also naturally leads to
<em>consistency</em>: an expression between <em>parenthesis</em> is always evaluated
before a function call, whereas an expression between <em>braces</em> (ah,
<em>suspenders</em>!) is suspended and may be never evaluated or more than once
(as in our example). This is inconsistent in most other languages where
often the predicate of a <code><a href="https://koka-lang.github.io/koka/doc/std_core.html#while">while<span><span>std<span>/</span>core<span>/</span></span>while: <span>forall</span><span>&lt;</span><span>e</span><span>&gt;</span> <span>(</span><span>predicate</span> <span>:</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>bool</span><span>,</span> <span>action</span> <span>:</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>(</span><span>)</span><span>)</span> <span>-&gt;</span> <span>&lt;</span><span>div</span><span>|</span><span>e</span><span>&gt;</span> <span>(</span><span>)</span></span></a></code> loop is written in parenthesis but may
be evaluated multiple times.
</p>
<p><a href="https://koka-lang.github.io/koka/doc/book.html#sec-basics">Learn more about basic syntax <span></span></a></p><h2 id="why-effects" data-heading-depth="2"><a href="#why-effects"></a><span><span>2.2</span>.‚ÄÇ</span>Effect Typing</h2>
<p>Koka infers and tracks the effect of every function in its type ‚Äì 
and a function type has 3 parts: the argument types, the effect type, 
and the type of the result. For example: 
</p><pre><span>fun sqr    : (int)     -&gt; total int       // mathematical total function    
fun divide : (int,int) -&gt; exn int         // may raise an exception (partial)  
fun turing : (tape)    -&gt; div int         // may not terminate (diverge)  
fun print  : (string)  -&gt; console ()      // may write to the console  
fun rand   : ()        -&gt; ndet int        // non-deterministic  
</span><span><span>fun</span> sqr    <span>:</span> <span>(</span><a href="https://koka-lang.github.io/koka/doc/std_core_types.html#type_space_int"><span>int</span><span><span>std<span>/</span>core<span>/</span>types<span>/</span></span>int: <span>V</span></span></a><span>)</span>     <span>-&gt;</span> <a href="https://koka-lang.github.io/koka/doc/std_core.html#type_space_total"><span>total</span><span><span>std<span>/</span>core<span>/</span></span>total: <span>E</span></span></a> <a href="https://koka-lang.github.io/koka/doc/std_core_types.html#type_space_int"><span>int</span><span><span>std<span>/</span>core<span>/</span>types<span>/</span></span>int: <span>V</span></span></a>       <span>fun</span> divide <span>:</span> <span>(</span><a href="https://koka-lang.github.io/koka/doc/std_core_types.html#type_space_int"><span>int</span><span><span>std<span>/</span>core<span>/</span>types<span>/</span></span>int: <span>V</span></span></a><span>,</span><a href="https://koka-lang.github.io/koka/doc/std_core_types.html#type_space_int"><span>int</span><span><span>std<span>/</span>core<span>/</span>types<span>/</span></span>int: <span>V</span></span></a><span>)</span> <span>-&gt;</span> <a href="https://koka-lang.github.io/koka/doc/std_core.html#type_space_exn"><span>exn</span><span><span>std<span>/</span>core<span>/</span></span>exn: <span>HX</span></span></a> <a href="https://koka-lang.github.io/koka/doc/std_core_types.html#type_space_int"><span>int</span><span><span>std<span>/</span>core<span>/</span>types<span>/</span></span>int: <span>V</span></span></a>         <span>fun</span> turing <span>:</span> <span>(</span><span>tape</span><span>)</span>    <span>-&gt;</span> <a href="https://koka-lang.github.io/koka/doc/std_core_types.html#type_space_div"><span>div</span><span><span>std<span>/</span>core<span>/</span>types<span>/</span></span>div: ‚Ä¶</span></a></span></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://koka-lang.github.io/koka/doc/book.html#tour">https://koka-lang.github.io/koka/doc/book.html#tour</a></em></p>]]>
            </description>
            <link>https://koka-lang.github.io/koka/doc/book.html#tour</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292411</guid>
            <pubDate>Sun, 28 Feb 2021 10:55:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing Vat Solutions for Bootstrapped UK Businesses]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26292256">thread link</a>) | @ianwootten
<br/>
February 28, 2021 | https://www.ianwootten.co.uk/2021/02/23/comparing-vat-solutions-for-bootstrapped-uk-businesses/ | <a href="https://web.archive.org/web/*/https://www.ianwootten.co.uk/2021/02/23/comparing-vat-solutions-for-bootstrapped-uk-businesses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Laws on when to apply VAT have always been a complex beast - in 2015 the EU made changes that meant that VAT was to be calculated based on a customer location, introducing a <a href="https://ec.europa.eu/taxation_customs/business/vat/telecommunications-broadcasting-electronic-services/content/mini-one-stop-shop_en">VATMOSS</a> system for its collection. Since leaving the EU things have become even more complicated if you happen to be based in the UK. <a href="https://www.gov.uk/government/publications/accounting-for-vat-on-goods-moving-between-great-britain-and-northern-ireland-from-1-january-2021/accounting-for-vat-on-services-between-the-uk-and-eu-member-states-from-1-january-2021">You now are no longer able to make use of the VATMOSS system</a>, meaning you potentially need to register for VAT in every EU country you sell products to (!). The Governments current angle seems to be to suggest that UK businesses register their companies for <a href="https://www.gov.uk/vat-registration/registering-vat-eu-countries">VAT MOSS in another EU Country</a> in order to ease the burden of correctly complying with VAT regulations.</p>
<p>Any EU business that uses the VIES lookup tool for validating VAT numbers will now no longer work for a UK business meaning my business has been charged VAT where it isn‚Äôt necessary. If all that wasn‚Äôt enough, theres the possibility of credit card fraud, chargebacks and the accounting complications that come with selling software internationally.</p>
<p>It‚Äôs difficult to know how to proceed with business ideas these days as a solo founder when payment providers - such as Stripe have yet to handle many of these issues for us. We don‚Äôt really want to run the risk of charging an incorrect amount, but the rules for VAT are probably more complexity than we‚Äôd like to handle ourselves. I recently asked the question on twitter and it sparked quite a lot of interest, so here I‚Äôm going to summarise what I learned.</p>
<blockquote><p lang="en" dir="ltr">Kind of confused how smaller indie businesses in the UK handle this? How are you ensuring your company is correctly complying with UK laws on VAT/billing for SaaS/products since Brexit? <a href="https://twitter.com/IndieHackers?ref_src=twsrc%5Etfw">@IndieHackers</a></p>‚Äî Ian Wootten (@iwootten) <a href="https://twitter.com/iwootten/status/1359289147136049153?ref_src=twsrc%5Etfw">February 9, 2021</a></blockquote>


<p>Ultimately, there are a few tried and tested routes being followed by developers to getting paid online. I‚Äôve divided these into two categories, what I call ‚Äúrevenue systems‚Äù and ‚Äúdevelop it yourself‚Äù systems.</p>

<p>These systems focus on providing an all-in-one checkout solution where the customer purchase is between the platform itself and the customer, rather than <em>your</em> business and the customer. They can handle both the checkout experience and tax calculations and pay a single lump sump each month.</p>
<p>Unfortunately, if you happen to be in the UK and checkout using one of the revenue systems, you‚Äôll actually have VAT applied to to your purchases in some cases where it shouldn‚Äôt apply (e.g. Ebooks). I mentioned this recently on twitter to Gumroads founder Sahil and will update if I hear back, but it seems the problem is the same with all providers where they base tax calculations solely on the location and not the product type as well. I‚Äôm not sure where this places your business as far as the HMRC are concerned. A DIY approach could therefore be a better solution if you‚Äôre selling ebooks to those in the UK depending on your scale. You‚Äôd have to be doing <em>very</em> well for it to make sense though.</p>
<h2 id="gumroad">Gumroad</h2>
<p>Gumroad is used by multiple well known profile solo businesses such as <a href="http://twitter.com/dvassallo">Daniel Vassallo</a> (who is also employed by Gumroad) and <a href="http://twitter.com/alexellisuk">Alex Ellis</a>. Recently the designer <a href="http://twitter.com/traf">James Traf</a> made a huge <a href="https://www.indiehackers.com/podcast/179-james-traf-of-super">$280k in just four weeks using Gumroad</a>.</p>
<p><a href="https://icons.tr.af/"><img src="https://www.ianwootten.co.uk/images/vat-solutions-uk-business/gumroad-example.png" alt="An example of Gumroad Purchase on James Traf‚Äôs site"></a></p>
<p>Gumroad seems to be the main choice for digital product creators. Gumroad states that they are able to handle VAT completely, to allow the author to focus on producing content only. It deals with the distribution and payment of your product, meaning there is seemingly very little to worry about and only charges fees when you make money. Gumroad is able to create ‚ÄúMemberships‚Äù as shown by Daniel Vassallo‚Äôs <a href="https://gumroad.com/l/profit-and-loss">Profit and Loss</a> subscription newsletter. These features are ideally targeted to creators though, rather than a SaaS. Gumroad states ‚ÄúThe Gumroad customer experience is designed to be a 1:1 transaction. You pay money, and you get a product immediately - a PDF, Photoshop brushes, a movie, etc.‚Äù.</p>
<p>Pricing for Gumroad is 5% + a charge fee of 3.5% + 30c and then $10/mo where the charge fee applies only.</p>
<h2 id="paddle">Paddle</h2>
<p><a href="https://paddle.com/">Paddle</a> is a more traditional billing solution that also handles calculations of VAT and Taxes owed on your behalf. It behaves as a <a href="https://paddle.com/blog/what-is-merchant-of-record/">‚ÄúMerchant of Record‚Äù</a> or a reseller of your software that processes your customer transactions. This means that your customer only ever makes purchases from Paddle, rather than your company directly.</p>
<p>You can use their preferred overlay style layout or integrate into your own website via Paddles API. Their overlay is able to be customised to match your own branding.</p>
<p><a href="https://paddle.com/"><img src="https://www.ianwootten.co.uk/images/vat-solutions-uk-business/paddle-example-2.png" alt="Customising Paddles Overlay"></a></p>
<p>I have some experience of using Paddle myself for a product I failed to launch in the vfx world. It specifically notes that is targeted at B2B SaaS subscriptions, which is the opposite to Gumroad. Using the two in conjunction with one another if you happen to have both products and a SaaS offering seems like a good solution to removing the payment processing burden on your company. Something I don‚Äôt like about them is that they obfuscate their pricing by not publishing it clearly on their site and having to go through a ‚Äúquote‚Äù process to even see it. This may be an indication that they‚Äôre more interested in larger businesses than small indie developers. See this tweet from Adam Wathan when he was looking to migrate their company to Paddle.</p>
<blockquote><p lang="en" dir="ltr"><a href="https://twitter.com/PaddleHQ?ref_src=twsrc%5Etfw">@PaddleHQ</a> Hey folks! We ($xxx,xxx/mo) are looking to migrate from our current setup to a Merchant of Record and would love to chat with someone to make sure Paddle can do what we need and figure out pricing. What‚Äôs the best way to talk to a sales person?</p>‚Äî Adam Wathan (@adamwathan) <a href="https://twitter.com/adamwathan/status/1311782292004667392?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>


<p>Pricing for Paddle is (apparently, according to the thread) between 5-6% + a charge fee.</p>

<p>These systems integrate and extend your existing payment provider. The customer purchase remains between your business and the customer. This means you account for every individual transaction (along with associated taxes) that comes through it and deal with any potential chargebacks yourself. Your business will need to do more work in terms of integration.</p>
<h2 id="stripe">Stripe</h2>
<p><a href="https://stripe.com/">Stripe</a> is by and far the most well regarded payment provider around by developers. It‚Äôs extremely flexible and has a whole host of apis and existing libraries available for different languages for integration.</p>
<p>The main problem here is by using stripe on it‚Äôs own, you have to handle everything yourself as Stripes core offering offers no tax or vat calculations. It gives the ability to charge tax at a particular rate, but you need to determine when a tax applies.</p>
<p>The example below shows how their checkout experience applies VAT when the rate has been supplied as part of the Stripe API call.</p>
<p><a href="https://stripe.com/"><img src="https://www.ianwootten.co.uk/images/vat-solutions-uk-business/stripe-checkout-example.png" alt="An Example of Stripe Checkout"></a></p>
<p>Stripe also offer a billing solution which includes tools for reducing customer churn and automatic generation of hosted invoices. For a business in the UK, there are government rules over correctly invoicing customers and you‚Äôd be subject to these should you opt to use a DIY system.</p>
<p>Stripes pricing is 1.4% + 20p for European cards and 2.9% + 20p for Non-European cards for their core offering, or an additional 0.5% when using Stripe billing.</p>
<h2 id="quaderno">Quaderno</h2>
<p><a href="https://www.quaderno.io/">Quaderno</a> is a tool built specifically for handling the complexities of tax. During checkout it looks at your customer location and determines if tax applies for your customers. It interfaces with your existing payment providers and then gives a customisable checkout page for your business. It charges a single fee each month depending on the size, meaning that the only additional charges you‚Äôll have are from your payment provider. Depending on how large your business may mean that you end up paying more than a revenue payment solution before you have many paying customers.</p>
<p><a href="https://www.quaderno.io/"><img src="https://www.ianwootten.co.uk/images/vat-solutions-uk-business/quaderno.png" alt="An Example of Quaderno‚Äôs Checkout"></a></p>
<p>Quaderno‚Äôs pricing is additional to a payment provider, ranging from $49 - $149 a month.</p>

<p>Below is an example of pricing a $10 (¬£7.12) ebook averaging 999 customers each month (with 50% of sales from Europe). It shows the charges for each approach covered here in GBP (¬£) assuming 1 USD = 0.71 GBP with no conversion charges. I‚Äôve assumed that Quaderno solution is using Stripe as the payment provider.</p>
<table>
<thead>
<tr>
<th></th>
<th>Stripe</th>
<th>Quaderno</th>
<th>Paddle</th>
<th>Gumroad</th>
</tr>
</thead>
<tbody>
<tr>
<td>European Transaction Fee (%)</td>
<td>0.01</td>
<td>0.01</td>
<td>0.05</td>
<td>0.04</td>
</tr>
<tr>
<td>Non European Transaction Fee (%)</td>
<td>0.03</td>
<td>0.03</td>
<td>0.05</td>
<td>0.04</td>
</tr>
<tr>
<td>Card Charge Fee (¬£)</td>
<td>0.20</td>
<td>0.20</td>
<td>0.20</td>
<td>0.20</td>
</tr>
<tr>
<td>European Transaction Fee (¬£)</td>
<td>0.30</td>
<td>0.30</td>
<td>0.56</td>
<td>0.45</td>
</tr>
<tr>
<td>Non European Transaction Fee (¬£)</td>
<td>0.41</td>
<td>0.41</td>
<td>0.56</td>
<td>0.45</td>
</tr>
<tr>
<td>European Charges</td>
<td>149.78</td>
<td>149.78</td>
<td>277.78</td>
<td>224.44</td>
</tr>
<tr>
<td>Non European Charges</td>
<td>202.70</td>
<td>202.70</td>
<td>277.22</td>
<td>223.99</td>
</tr>
<tr>
<td>Monthly Platform Fee</td>
<td></td>
<td>70.39</td>
<td></td>
<td>7.12</td>
</tr>
<tr>
<td>Gross Sales</td>
<td>7,103.89</td>
<td>7,103.89</td>
<td>7,103.89</td>
<td>7,103.89</td>
</tr>
<tr>
<td>Total Fees</td>
<td>352.48</td>
<td>422.87</td>
<td>554.99</td>
<td>455.56</td>
</tr>
<tr>
<td>Net Income</td>
<td>6,751.41</td>
<td>6,681.02</td>
<td>6,548.89</td>
<td>6,648.33</td>
</tr>
</tbody>
</table>
<p>For a $25 (¬£17.78) ebook, again with all other assumptions remaining the same:</p>
<table>
<thead>
<tr>
<th></th>
<th>Stripe</th>
<th>Quaderno</th>
<th>Paddle</th>
<th>Gumroad</th>
</tr>
</thead>
<tbody>
<tr>
<td>European Transaction Fee (%)</td>
<td>0.01</td>
<td>0.01</td>
<td>0.05</td>
<td>0.04</td>
</tr>
<tr>
<td>Non European Transaction Fee (%)</td>
<td>0.03</td>
<td>0.03</td>
<td>0.05</td>
<td>0.04</td>
</tr>
<tr>
<td>Card Charge Fee (¬£)</td>
<td>0.20</td>
<td>0.20</td>
<td>0.20</td>
<td>0.20</td>
</tr>
<tr>
<td>European Transaction Fee (¬£)</td>
<td>0.45</td>
<td>0.45</td>
<td>1.09</td>
<td>0.82</td>
</tr>
<tr>
<td>Non European Transaction Fee (¬£)</td>
<td>0.72</td>
<td>0.72</td>
<td>1.09</td>
<td>0.82</td>
</tr>
<tr>
<td>European Charges</td>
<td>224.44</td>
<td>224.44</td>
<td>544.44</td>
<td>411.11</td>
</tr>
<tr>
<td>Non European Charges</td>
<td>357.06</td>
<td>357.06</td>
<td>543.35</td>
<td>410.28</td>
</tr>
<tr>
<td>Monthly Platform Fee</td>
<td></td>
<td>70.39</td>
<td></td>
<td>7.12</td>
</tr>
<tr>
<td>Gross Sales</td>
<td>17,759.72</td>
<td>17,759.72</td>
<td>17,759.72</td>
<td>17,759.72</td>
</tr>
<tr>
<td>Total Fees</td>
<td>581.50</td>
<td>651.89</td>
<td>1,087.79</td>
<td>828.51</td>
</tr>
<tr>
<td>Net Income</td>
<td>17,178.22</td>
<td>17,107.83</td>
<td>16,671.94</td>
<td>16,931.21</td>
</tr>
</tbody>
</table>
<p>We can see that fees are significantly more with each of the revenue platforms, though we have to consider the difference of ¬£500 of additional revenue between Stripe and Paddle now means that we have to build a number of additional features, along with comply with worldwide tax laws.</p>
<p>I‚Äôve made this available as a <a href="https://docs.google.com/spreadsheets/d/1gwPkVYfPAxfCSPyjamtdKemSJZ3T5V3hzH4GeYNti9A/edit?usp=sharing">google sheet</a> which you can copy and modify to see how your own payment prices/exchange rates would stack up.</p>

<p>Most of the payment solutions I see bootstrapped businesses use tend to be those using revenue systems rather than a DIY approach. Understandably, most small businesses just don‚Äôt want to have to deal with the complexity of international tax rules when selling online. Why delay and build these features when they could be making money? I like to refer to Baremetrics <a href="https://baremetrics.com/build-vs-buy">build vs buy calculator</a> for challenges like this which suggests that it will never be worth building a payment solution ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ianwootten.co.uk/2021/02/23/comparing-vat-solutions-for-bootstrapped-uk-businesses/">https://www.ianwootten.co.uk/2021/02/23/comparing-vat-solutions-for-bootstrapped-uk-businesses/</a></em></p>]]>
            </description>
            <link>https://www.ianwootten.co.uk/2021/02/23/comparing-vat-solutions-for-bootstrapped-uk-businesses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292256</guid>
            <pubDate>Sun, 28 Feb 2021 10:24:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The KimKlone Microcomputer]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26292235">thread link</a>) | @gbrown_
<br/>
February 28, 2021 | https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html | <a href="https://web.archive.org/web/*/https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <td colspan="2">KimKlone
is a microcomputer I built in the 1980s, both as a radical redesign of
an
existing instruction set and
as a prosaic tool for use in my lab. The article explains the
machine's capabilities and also the intriguing manner of their
implementation. Despite intimate involvement of external logic (in the
form of 7400 series SSI), the machine
responds to the programmer just as aptly as a redesign carried out at
the silicon level.<p>
      
The KimKlone represents an architectural
extension of the 65C02. The most striking improvement is efficient
linear access to
a <span>16
Mbyte Address Space</span>.
Also on the short list is <span>hardware
acceleration</span> for the <span>Forth</span>
programming language, including a one-byte NEXT instruction and a new,
stack-savvy <strong>addressing
mode</strong>. To exploit these and
other capabilities,
the programmer has access to new instructions and new registers. (See
the programming model above.)
      </p><p>The
new instructions aren't interrupts or traps to emulation
routines. Nor are the new registers merely an over-glorified
MMU (Memory Management Unit), the sort of thing that's inoperable
except via peeking and poking with I/O accesses. <span>The
KimKlone actually has brand new instructions, to which the new
registers implicitly
respond. The novel instructions execute inline and at full speed.</span>
There are 44 new op-codes, all mapped into the
Undefined spaces in the Rockwell 65C02 op-code map.
This article is organized as shown in the Contents section above. </p>
The machine's nickname, "KimKlone," may be
misleading. <strong>The KimKlone
has little in common with a MOS Technology KIM-1</strong>.
The nickname arises simply because some of the concepts were first
explored on my
heavily reworked KIM-1. Also, the reference to "Cheap Video"
is a nod to author Don Lancaster. The Kimklone and
my KIM-1 both include mutations of the audacious Lancaster video
interface, and
his books helped foster my own outside-the-box design approach. See <a href="https://laughtonelectronics.com/Arcana/KimKlone/BrideOfSon%20KK%20Lancaster.html"><span>Cheap Video</span>
√† la Lancaster, and The Back Story re: KIM-1</a>
      <p>The KimKlone is a
fascinating device. If you find it a little "over the top," be
aware that
I too am amused by how it turned out. This lowly lab computer took on a
life of its own while it was still on the drawing board.<br>
      </p>
      </td>
    </div></div>]]>
            </description>
            <link>https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292235</guid>
            <pubDate>Sun, 28 Feb 2021 10:19:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python SDK for Android - Chaquopy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26292220">thread link</a>) | @mhsmith
<br/>
February 28, 2021 | https://chaquo.com/chaquopy/ | <a href="https://web.archive.org/web/*/https://chaquo.com/chaquopy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
		<div>
			<div>	
	<div id="primary">
		<main id="main" role="main">

			
				
<article id="post-16" class="page">
	<!-- .entry-header -->

	<div>
		
<p>Chaquopy provides everything you need to include Python components in an Android app, including:</p>



<ul><li> Full integration with Android Studio‚Äôs standard Gradle build system. </li></ul>



<ul><li>Simple APIs for calling Python code from Java/Kotlin, and vice versa.</li></ul>



<ul><li>A wide range of third-party Python packages,&nbsp;including SciPy, OpenCV, TensorFlow and many more.</li></ul>



<p>To get started, see the <a href="https://chaquo.com/chaquopy/doc/current/">documentation</a>.</p>




			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->

				
			
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
			</div>
		</div>
	</div></div>]]>
            </description>
            <link>https://chaquo.com/chaquopy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292220</guid>
            <pubDate>Sun, 28 Feb 2021 10:17:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Actually Portable Executables]]>
            </title>
            <description>
<![CDATA[
Score 649 | Comments 143 (<a href="https://news.ycombinator.com/item?id=26292166">thread link</a>) | @krab
<br/>
February 28, 2021 | https://ahgamut.github.io/c/2021/02/27/ape-cosmo/ | <a href="https://web.archive.org/web/*/https://ahgamut.github.io/c/2021/02/27/ape-cosmo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>  <p><span>27 Feb 2021</span></p><p>I came across <a href="https://github.com/jart/cosmopolitan">Cosmopolitan</a> on Hacker News, and I was initially confused, due to a few memories of cross-compilation nightmares: while it should be possible to compile for the same architecture regardless of operating system, wouldn‚Äôt the OS get confused by the leading bytes of the executable? I read the <a href="https://justine.lol/ape.html">article</a> explaining how it works, but most of it went over my head.</p> <p>The example on the <a href="https://github.com/jart/cosmopolitan">Github README</a> used the following script for compilation:</p> <div><div><pre><code>gcc <span>-g</span> <span>-O</span> <span>-static</span> <span>-nostdlib</span> <span>-nostdinc</span> <span>-fno-pie</span> <span>-no-pie</span> <span>-mno-red-zone</span> <span>\</span>
  <span>-o</span> hello.com.dbg hello.c <span>-fuse-ld</span><span>=</span>bfd <span>-Wl</span>,-T,ape.lds <span>\</span>
  <span>-include</span> cosmopolitan.h crt.o ape.o cosmopolitan.a
objcopy <span>-S</span> <span>-O</span> binary hello.com.dbg hello.com
</code></pre></div></div> <p>I converted it into a simple Makefile to run the compilation commands. I tried a bunch of simple C programs (basic arithmetic, reading and writing to files) on Linux+Windows (compiled on Linux), and all of them worked.</p> <h2 id="compiling-lua-with-cosmopolitan">Compiling Lua with Cosmopolitan</h2> <p>I decided to try compiling a high-level language built on C. I originally picked Python, but the Makefile for Python seemed too complicated to mess with, so I then picked <a href="https://www.lua.org/download.html">Lua</a>, which looked much simpler in comparison.</p> <p>I started out by blindly copy-pasting the flags and includes used in the sample compilation on Github. Ah, it would have been wonderful for my laziness if it compiled out of the box. Following is a play-by-play commentary of trying to compile Lua.</p> <p>First problem I ran into was header clashes: if I didn‚Äôt put <code>-nostdlib -nostdinc</code> while compiling each object file, <code>-include cosmopolitan.h</code> would clash with the system headers. But blocking the system headers meant I would have to change every <code>#include</code> of a system header. I created a bunch of dummy headers with the same names as those in the <a href="https://en.cppreference.com/w/c/header">C stdlib</a> and and included to those instead.</p> <p>Naming clashes: some of the macros in <code>cosmopolitan.h</code> clashed with macro/function names in Lua: <code>reverse</code> and <code>isempty</code>. I changed the Lua source to avoid this.</p> <p>A macro <code>FIRST_RESERVED</code> was broken because <code>UCHAR_MAX</code> was missing. I thought <code>UCHAR_MAX</code> was supposed to be in <code>limits.h</code> ‚Äì the <code>limits.h</code> part of <code>cosmopolitan.h</code> did not have <code>UCHAR_MAX</code> (It had <code>SCHAR_MAX</code>, though.) I added in a <code>#define</code> stating <code>UCHAR_MAX</code> as <code>__UINT8_MAX__</code> (ie 255).</p> <p>The default Lua Makefile attempts to use <code>_setjmp</code>/<code>_longjmp</code> in <code>ldo.c</code> when on Linux. I disabled the <code>LUA_USE_LINUX</code> flag for compiling the object files, but this caused an issue with <code>tmpnam</code> in <code>loslib.c</code> (<code>mkstemp</code> is available in Cosmopolitan). I changed the Lua source to use <code>setjmp</code>/<code>longjmp</code>. A similar issue showed in <code>lauxlib.c</code> for <code>sys/wait.h</code> (which is a no-op in non-POSIX systems, as per the Lua source code), and in <code>liolib</code> for <code>sys/types.h</code> so disabled <code>LUA_USE_POSIX</code> over there as well.</p> <p>The <code>localeconv()</code> function (part of <code>locale.h</code>) was not implemented in <code>cosmopolitan.h</code>, and this caused an error while compiling <code>lobject.c</code> (macro <code>lua_getlocaledecpoint()</code> depended on <code>localeconv()</code>). Changed the macro to just return <code>'.'</code>.</p> <p>The <code>panic</code> function in Lua <code>static int panic (lua_state*)</code> clashed with that in Cosmopolitan <code>void panic(void)</code>. Renamed the lua function to <code>lua_panic</code>. This triggered an error where the <code>panic</code> function was being called in <code>luaL_newstate</code>, so I changed the name there as well.</p> <p><code>luaL_loadfilex</code> caused a <em>frame size error</em> ‚Äì I have never seen this before. A quick internet search shows that this is because a large buffer is allocated on stack when entering the function, and yes, <code>luaL_loadfilex</code> allocates a <code>loadF</code> object containing a <code>char</code> buffer of <code>BUFSIZ</code>. I reduced the size of the buffer to <code>BUFSIZ - 64</code>.</p> <p><code>loslib.c</code> reuiqres the <code>setlocale()</code> and <code>LC_*</code> from <code>locale.h</code>, which is defined as an extern value in <code>cosmopolitan.h</code>, but that definition is somehow not enough.. screw it, I just disabled <code>os_setlocale</code> in <code>loslib.c</code>, and then it compiles.</p> <h2 id="linking-the-object-files">Linking the object files</h2> <p>Ok, time for linking ‚Ä¶</p> <div><div><pre><code>gcc -std=gnu99 -o lua   lua.o liblua.a -lm -Wl,-E -ldl
/usr/bin/ld: errno: TLS definition in //lib/x86_64-linux-gnu/libc.so.6 section
.tbss mismatches non-TLS reference in liblua.a(lauxlib.o)
/usr/bin/ld: //lib/x86_64-linux-gnu/libc.so.6: error adding symbols: bad value
collect2: error: ld returned 1 exit status
</code></pre></div></div> <p>I forgot, I shouldn‚Äôt <code>-lm</code> or <code>-ldl</code>. Ok, let‚Äôs try with all the object files instead of <code>liblua.a</code>:</p> <div><div><pre><code>/usr/bin/ld.bfd: lvm.o: in function `l_strcmp':
lvm.c:(.text+0x59): undefined reference to `strcoll'
/usr/bin/ld.bfd: lmathlib.o: in function `math_tanh':
lmathlib.c:(.text+0x21f): undefined reference to `tanh'
/usr/bin/ld.bfd: lmathlib.o: in function `math_sinh':
lmathlib.c:(.text+0x24f): undefined reference to `sinh'
/usr/bin/ld.bfd: lmathlib.o: in function `math_cosh':
lmathlib.c:(.text+0x27f): undefined reference to `cosh'
collect2: error: ld returned 1 exit status
</code></pre></div></div> <p>Umm‚Ä¶ okay, it looks like some of the functions defined in the cosmopolitan header are yet to be implemented in the static library. That‚Äôs okay, I can just quickly fill in the math functions, and I‚Äôll comment out <code>strcoll</code> for now, just because I want to see it compile‚Ä¶. and it successfully compiles!! Let‚Äôs run <code>objcopy</code> before trying it out on a system though.</p> <div><div><pre><code>$ objcopy -S -O binary lua lua.exe
$ ls -al
-rwxr-xr-x 1 1953720 Feb 27 01:33 lua
-rwxr-xr-x 1 344064 Feb 27 01:39 lua.exe
</code></pre></div></div> <p>That size reduction seems a little too drastic, but let‚Äôs see if it runs on Linux:</p> <p><img src="https://ahgamut.github.io/assets/images/linux_screen.png" alt=""></p> <p>Awesome. How about Windows?</p> <p><img src="https://ahgamut.github.io/assets/images/windows_screen.png" alt=""></p> <h2 id="summary-it-is-actually-portable">Summary: it <em>is</em> actually portable</h2> <p>This is pretty incredible: I just had to modify a few lines in a Makefile and some C source files, and I got a Lua executable that works both on Linux and Windows (and possibly others as well). Granted, there are still some details to be filled out (floating point calculation above prints a <code>g</code>), but Cosmopolitan is currently at release 0.0.2, so there is a lot of time.</p> <p>Hopefully this means that other languages that have source code completely in C can also be compiled once and run anywhere. Actually Portable Python next, maybe?</p> </div> </div></div>]]>
            </description>
            <link>https://ahgamut.github.io/c/2021/02/27/ape-cosmo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292166</guid>
            <pubDate>Sun, 28 Feb 2021 10:06:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take a look at Nomad before jumping on Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 76 (<a href="https://news.ycombinator.com/item?id=26291975">thread link</a>) | @sofixa
<br/>
February 28, 2021 | https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/ | <a href="https://web.archive.org/web/*/https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
        <h2>Table of Contents</h2>
        
         
      
      <h2 id="pre-introduction">Pre-introduction</h2>
<p>Recently I stumbled upon and then stumbled upon again on <a href="https://blog.dave.tf/post/new-kubernetes/">David Anderson</a>‚Äôs interesting post about ‚Äúnew Kubernetes‚Äù, based on a discussion he had with <a href="https://timewitch.net/">Vallery Lancey</a> about what they would do differently if they were rewriting Kubernetes from scratch. Interestingly, a decent part of the proposals for a ‚Äúnew Kubernetes‚Äù are design choices made by Hashicorp for <a href="https://www.nomadproject.io/">Nomad</a>, which is a pretty underrated orchestrator, and drastically simpler ( one of the main goals of said ‚Äúnew Kubernetes‚Äù).</p>
<p>Some people are aware that Docker Swarm kinda exists but is abandonware/on life support, and isn‚Äôt really recommended anymore, but it still comes up in discussions due to how easy it is to use. For most, that leaves Kubernetes as the only ‚Äúserious‚Äù option, but it is a <em>very</em> complex piece of software, with a lot of moving parts, which isn‚Äôt actually required or need in most cases.</p>

  <figure>
    <img src="https://atodorov.me/img/nomad/kubernetes.jpg#center">
    
  </figure>


<p>This inspired me to write a series on Nomad, what it is, why it‚Äôs great, where it‚Äôs lacking and how to use it.</p>
<h2 id="introduction---what-is-nomad-and-why-its-great">Introduction - what is Nomad and why it‚Äôs great</h2>
<p>Hashicorp‚Äôs Nomad is a simple to run and maintain, yet very flexible task scheduler/orchestrator. It relies on plugins for execution, autoscaling and other features, and can run pretty much anything via its <code>task drivers</code> - Docker, contairnerd, LXC, rkt, podman, Java, fork/exec, QEMU, firecracker, FreeBSD jails.</p>
<p>It comes in the form of a single binary, run in two modes (<code>server</code>, in groups of 3 or 5, which make scheduling decisions and host the APIs and configuration, and an unlimited number of <code>worker</code>s which actually run whatever it is you want to run), and can be automatically clustered via <a href="https://consul.io/">Consul</a>. The configuration ( both for jobs and of Nomad itself) is in <a href="https://github.com/hashicorp/hcl">HCL</a> (I‚Äôll get into more detail about how great that is a bit later) or JSON (mainly for when the jobs are submitted by machines/scripts/tooling and not humans). Multiple clusters can be connected via <a href="https://learn.hashicorp.com/tutorials/nomad/federation?in=nomad/manage-clusters">multi-region federation</a> for sharing ACLs and for API forwarding ( you can submit a job or request logs to any server for any region and it will be forwarded to the appropriate server). Deployments can be complex out of the box ( rolling, canary, blue/green), and everything is version controlled and rollbackable.</p>
<p>Like most HashiCorp tools, it‚Äôs ‚Äúopen core‚Äù, meaning that the majority of features are available in an <a href="https://github.com/hashicorp/nomad">open source</a> version, and some more advanced/enterprise-y ones ( in Nomad‚Äôs case, <a href="https://www.hashicorp.com/blog/hashicorp-nomad-multi-cluster-deployment">multi-region/cluster deployments</a> - deploying something simultaneously to multiple separate clusters, policy as code with <a href="https://docs.hashicorp.com/sentinel/nomad">Sentinel</a> and similar ) require upgrading to Nomad Enterprise.</p>
<h2 id="primitives">Primitives</h2>
<ul>
<li><code>job</code> is a declarative file which contains groups of tasks, each task being a container/binary/anything run by an exec driver</li>
<li><code>system</code> jobs (run on all client nodes, equivalent to Kubernetes DaemonSets, for monitoring/logging agents/load balancers)</li>
<li><code>periodic</code> jobs (equivalent to cronjobs)</li>
<li><code>service</code>, which registers as a Consul service and is thus discoverable ( via API or DNS)</li>
<li><code>deployment</code>, each version of a job, they‚Äôre tracked and can be rollbacked to</li>
<li><code>allocation</code>, each instance of a task ( group ) on a node</li>
<li><code>namespace</code>, a logical unit to organise jobs in and ACLs around</li>
</ul>
<h3 id="jobs">Jobs</h3>
<p>Example of a very basic job that runs a Docker container (<code>jaegertracing/all-in-one:1.21</code>), with limits of 1000Mhz of CPU and 1024MB of RAM, and registers the service with Consul:</p>
<div><pre><code data-lang="hcl"><span>job</span> <span>"jaeger"</span> {
        type <span>=</span> <span>"service"</span>
        <span>group</span> <span>"api"</span> {
            <span>task</span> <span>"jaeger"</span> {
                driver <span>=</span> <span>"docker"</span>
                <span>config</span> { 
                  image <span>=</span> <span>"jaegertracing/all-in-one:1.21"</span>
                }
                <span>resources</span> {
                  cpu <span>=</span> <span>1000</span>
                  memory <span>=</span> <span>1024</span>
                }
                <span>service</span> {
                  name <span>=</span> <span>"jaeger-query"</span>
                }
            }
        }            
}
</code></pre></div><p>Note that this is a <em>very</em> basic job, there are no healthchecks, no persistent storage, no extra configuration, no update strategy, no autoscaling, no exposed ports.</p>
<h4 id="deployment-history-and-rollback">Deployment history and rollback</h4>
<p>Nomad tracks each job‚Äôs full definitions and deployment history, and allows you to easily rollback and compare them, via the UI, CLI or API, e.g.:</p>
<div><pre><code data-lang="bash"><span># List the versions of the job named "opentelemetry-collector"</span>
$ nomad job history opentelemetry-collector
Version     <span>=</span> <span>1</span>
Stable      <span>=</span> false
Submit Date <span>=</span> 2021-01-08T21:30:30+01:00

Version     <span>=</span> <span>0</span>
Stable      <span>=</span> true
Submit Date <span>=</span> 2021-01-08T21:29:48+01:00

<span># Check the difference between versions</span>
$ nomad job history -p opentelemetry-collector
Version     <span>=</span> <span>1</span>
Stable      <span>=</span> false
Submit Date <span>=</span> 2021-01-08T21:30:30+01:00
Diff        <span>=</span>
+/- Job: <span>"opentelemetry-collector"</span>
+/- Task Group: <span>"opentelemetry-collector"</span>
  +/- Task: <span>"opentelemetry-collector"</span>
    +/- Config <span>{</span>
          args<span>[</span>0<span>]</span>:  <span>"--config=local/otel/config.yaml"</span>
      +/- image:    <span>"otel/opentelemetry-collector-contrib:0.15.0"</span> <span>=</span>&gt; <span>"otel/opentelemetry-collector-contrib:0.16.0"</span>
          ports<span>[</span>0<span>]</span>: <span>"health"</span>
          ports<span>[</span>1<span>]</span>: <span>"jaeger_thrift_compact"</span>
        <span>}</span>

Version     <span>=</span> <span>0</span>
Stable      <span>=</span> true
Submit Date <span>=</span> 2021-01-08T21:29:48+01:00

<span># Revert job "opentelemetry-collector" to version 0</span>
$ nomad job revert opentelemetry-collector <span>0</span>

</code></pre></div><h4 id="state-tracking-and-job-planning">State tracking and job planning</h4>
<p>Nomad keeps the desired state and its history, and with <code>nomad job plan</code>, similar to <code>terraform plan</code>, allows us to preview what will change upon applying a new job file. There‚Äôs also a feature to verify nothing has changed between the <code>plan</code> and <code>run</code> (equivalent to <code>terraform apply</code> with a plan file) with the <code>-check-index</code> flag:</p>
<div><pre><code data-lang="bash">$ nomad job plan otel.nomad
+/- Job: <span>"otel"</span>
+/- Task Group: <span>"opentelemetry"</span> <span>(</span><span>1</span> create/destroy update<span>)</span>
  +/- Task: <span>"opentelemetry-collector"</span> <span>(</span>forces create/destroy update<span>)</span>
    +/- Config <span>{</span>
          args<span>[</span>0<span>]</span>:  <span>"--config=local/otel/config.yaml"</span>
      +/- image:    <span>"otel/opentelemetry-collector-contrib:0.15.0"</span> <span>=</span>&gt; <span>"otel/opentelemetry-collector-contrib:0.20.0"</span>
          ports<span>[</span>0<span>]</span>: <span>"health"</span>
          ports<span>[</span>1<span>]</span>: <span>"jaeger_thrift_compact"</span>
        <span>}</span>
Scheduler dry-run:
- All tasks successfully allocated.

Job Modify Index: <span>413</span>
To submit the job with version verification run:

nomad job run -check-index <span>413</span> otel.nomad

When running the job with the check-index flag, the job will only be run <span>if</span> the
job modify index given matches the server-side version. If the index has
changed, another user has modified the job and the plan<span>'</span>s results are
potentially invalid.
</code></pre></div><p>Overall, it‚Äôs a very useful feature, especially when collaborating, locally or via CI/CD.</p>
<h4 id="checking-the-status-and-logs">Checking the status and logs</h4>
<p>To check the status of a job, there are a few commands under <code>nomad job</code> and <code>nomad alloc</code></p>
<div><pre><code data-lang="bash">$ nomad job status otel
ID            <span>=</span> otel
Name          <span>=</span> otel
Submit Date   <span>=</span> 2021-02-27T20:41:29+01:00
Type          <span>=</span> service
Priority      <span>=</span> <span>50</span>
Datacenters   <span>=</span> dc1
Namespace     <span>=</span> default
Status        <span>=</span> running
Periodic      <span>=</span> false
Parameterized <span>=</span> false

Summary
Task Group  Queued  Starting  Running  Failed  Complete  Lost
otel      <span>0</span>       <span>0</span>         <span>1</span>        <span>0</span>       <span>0</span>         <span>0</span>

Latest Deployment
ID          <span>=</span> ea533b6f
Status      <span>=</span> successful
Description <span>=</span> Deployment completed successfully

Deployed
Task Group  Desired  Placed  Healthy  Unhealthy  Progress Deadline
otel      <span>1</span>        <span>1</span>       <span>1</span>        <span>0</span>          2021-02-27T20:51:45+01:00

Allocations
ID        Node ID   Task Group  Version  Desired  Status   Created  Modified
89031cfd  d3cbeb7e  otel      <span>0</span>        run      running  20s ago  4s ago

<span># logs are at the allocation level ( similar to Kubernetes, where they're at the container level), so we get them with the alloc id</span>
$ nomad alloc logs 89031cfd
<span>[</span>...<span>]</span>
</code></pre></div><h4 id="lifecycle-and-sidecars">lifecycle and sidecars</h4>
<p>Nomad allows defining the lifecycle of tasks in task groups, and their status, with the <code>lifecycle</code> stanza. We can have <code>prestart</code> ( for initialisation ), <code>poststart</code> ( companion, for proxying (aka ambassador and adapter pattern in Kubernetes )) or <code>poststop</code> for clean up, and via the <code>sidecar</code> bool we define whether or not it should run as long as the main task(s), e.g.:</p>
<div><pre><code data-lang="hcl">  <span>task</span> <span>"init"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"prestart"</span>
      sidecar <span>=</span> <span>false</span>
    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"alpine/httpie"</span>
      command <span>=</span> <span>"http"</span>
      args <span>=</span> [
        <span>"POST"</span>,
        <span>"https://some-internal-service-for-provisioning-stuff.local/v1/new"</span>,
        "job_id<span>=</span><span>'</span><span>${</span><span>NOMAD_JOB_ID</span><span>}</span><span>!'"</span>
      ]
    }
  }

  <span>task</span> <span>"fluentd"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"poststart"</span><span> # should start after the main task
</span><span></span>      sidecar <span>=</span> <span>true</span><span> # should run as long as the main task does, and be restarted if it fails
</span><span></span>    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"fluentd/fluentd"</span>
    }
    ...
  }

  <span>task</span> <span>"main-app"</span> {
    ...
  }

  <span>task</span> <span>"cleanup"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"poststop"</span>
    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"alpine"</span>
      command <span>=</span> <span>"rm -rf"</span>
      args <span>=</span> [
        <span>"/var/lib/volume-with-super-secret-data"</span>
      
    }
  }
</code></pre></div><h3 id="aclrbac">ACL/RBAC</h3>
<p>ACL ( access-control list ), or RBAC ( role-based access control ) as it‚Äôs known in Kubernetes, allow defining who can do what, so that not everyone with network access can have full administrator privileges and run/stop whatever. Nomad‚Äôs ACL system is pretty similar to Consul and Vault‚Äôs, and uses JSON ( mostly for non-humans ) or HCL to define <code>policies</code> with <code>rules</code>, which describe what action is allowed on what object.</p>
<div><pre><code data-lang="hcl"><span># a basic policy which allows the predefined read policy with read-only access to list and read:
</span><span># job, volume and scaling details, and extra capabilities for job creation and log access within the default namespace
</span><span></span><span>namespace</span> <span>"default"</span> {
  policy <span>=</span> <span>"read"</span>
  capabilities <span>=</span> [<span>"submit-job","dispatch-job","read-logs"</span>]
}
</code></pre></div><p>Assignment of policies is done only via the CLI, unlike Kubernetes where that happens in YAML, as does policy management:</p>
<div><pre><code data-lang="bash"><span># create/update the policy within Nomad</span>
nomad acl policy apply -description <span>"Application Developer policy"</span> my-policy my-policy.hcl
nomad acl token create -name<span>=</span><span>"Test token"</span> -policy<span>=</span>my-policy -type<span>=</span>client
Accessor ID  <span>=</span> ‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/">https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/</a></em></p>]]>
            </description>
            <link>https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291975</guid>
            <pubDate>Sun, 28 Feb 2021 09:30:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to offer better downloads: 4 sets of HTTP headers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26291778">thread link</a>) | @michalc
<br/>
February 28, 2021 | https://charemza.name/blog/posts/http/downloads/how-to-offer-better-downloads/ | <a href="https://web.archive.org/web/*/https://charemza.name/blog/posts/http/downloads/how-to-offer-better-downloads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    
<p>To offer HTTP file downloads via your own code [rather than redirecting elsewhere], it's often easy to rustle something up. However, the default behaviour in a lot of cases may not give users as good an experience as possible. With a bit of effort, you can polish that right up, and here are 4 sets of HTTP headers that help you do just that.</p>

<h3>content-length</h3>

<p>If you are able to, set the <code>content-length</code> header with the total size of the file.</p>

<p>This simple header will cause browsers to tell users [estimates for] the time-to-completion of downloads. [It's also required for browsers to attempt to do range requests, as in the following section.]</p>

<p>Note that if streaming a file to the client, e.g. using <a href="https://docs.djangoproject.com/en/3.1/ref/request-response/#streaminghttpresponse-object">Django's StreamingHttpResponse</a>, then at the point the HTTP headers are generated, the full bytes of the file are not available, so this can't happen automatically. You have to explicitly determine the length of the file and set the header. For example, if the file is stored in S3, S3 returns a <code>content-length</code> header with all responses, and you can take the value of this header and return it to the client.</p>

<h3>accept-ranges / range / content-range [/ content-length]</h3>

<p>By default, if the connection is interrupted, browsers will have to restart the download from the beginning. If you support HTTP range requests, which use the <code>accept-ranges</code>, <code>range</code>, <code>content-range</code> headers, [and <code>content-length</code> header] then browsers can resume downloads from where they left off.</p>

<p>See the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Range_requests">MDN docs on HTTP range requests</a> for more information. Note that <a href="https://docs.aws.amazon.com/whitepapers/latest/s3-optimizing-performance-best-practices/use-byte-range-fetches.html">S3 supports range requests</a>, so if your code is essentially a proxy to S3, you can proxy the headers to and from S3 to support this fairly easily.</p>

<h3>content-disposition</h3>

<p>By default, browsers will guess at a suitable filename for the downloaded file, typically using the last path-component from the URL. Instead, consider what would be a more helpful filename, and set something like <code>content-disposition: attachment; filename="very-helpful-filename.csv"</code>.</p>

<h3>accept-encoding / content-encoding</h3>

<p>Some files compress well, for example typical CSV files. Serving compressed versions of these would often make downloads much faster. However, if the most likely thing users will do will do is immediately and manually uncompress the file, you've just made their life a tiny bit harder.</p>

<p>However, the browser can do this so the user will never even notice. For example, if the browser sends an <code>accept-encoding</code> header specifying it accepts gzip [which most modern browsers do], and if the server returns a header of <code>content-encoding: gzip</code> with gzipped data, the browser will automatically decompress this data on download. The user will notice nothing other than faster downloads.</p>

<p>Unfortunately, S3 doesn't support this sort of content negotiation. If you're storing your data on S3, and want to support both gzipped and non-gzipped versions of an object, you'll have to store them under separate keys. To avoid this, you might be tempted to compress on-the-fly. However, you then won't be able to send a <code>content-length</code>, or handle range requests.</p>

<hr>

<p>That's it!</p>

  </div></div>]]>
            </description>
            <link>https://charemza.name/blog/posts/http/downloads/how-to-offer-better-downloads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291778</guid>
            <pubDate>Sun, 28 Feb 2021 08:53:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audio Fingerprinting Using the AudioContext API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26291640">thread link</a>) | @volderette
<br/>
February 28, 2021 | https://iq.opengenus.org/audio-fingerprinting/ | <a href="https://web.archive.org/web/*/https://iq.opengenus.org/audio-fingerprinting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p id="time">Reading time: 30 minutes | Coding time: 10 minutes</p>
<p>Fingerprinting as introduced in <a href="https://iq.opengenus.org/canvas-fingerprinting/"><strong>this article</strong></a> is a way of identifying users based on one or more set of unique device characteristics. Along with Canvas fingerprinting, <strong>Audio fingerprinting</strong> takes advantage of device performance specs to build up an identifying fingerprint of a user. The problem is it does not need to take any <strong>permission</strong> from the users and works on all browsers and can be used to <mark><strong>track users</strong></mark> across browsers.</p>
<p>It has the same basic process of doing this as canvas fingerprinting. Assign a task to the browser, record how it is executed, and use such data to build the fingerprint.</p>
<p>Recently, several sites have been found to be using such techniques to track activity across browsers on a device.</p>
<h3 id="moredetails">More details</h3>
<p>In the case of audio fingerprinting, the fingerprinting is based on the <strong>device's audio stack</strong>. Just as canvas fingerprinting takes advantage of the Canvas API, the technology that makes audio fingerprinting possible is an API called the <strong>AudioContext API</strong>. It is an <strong>interface of the Web Audio API</strong> that is a part of most modern browsers.</p>
<p>The browser is assigned the task of <strong>generating an audio signal</strong> and it's processed based on the device's audio setting and audio hardware installed on it.</p>
<p>A website uses the <strong>AudioContext API</strong> to send a low frequency audio through the browser to the computer. It then measures how the computer processes this sent data. Based on how this signal is processed, the results from the AudioContext API can help identify the same user across different browsers.</p>
<p>This process <strong>doesn't require access to the device permissions</strong> like microphone or speakers. No audio is recorded, collected or played by any means. It gathers the audio signature of a user's device and uses it to create an identifier to track that user. It simply relies on the difference in the way these generated signals are processed on each device.</p>
<p>Since this technique utilizes the <strong>device's (hardware) capability differences</strong> and not just the browser's ‚Äî it can be used to <strong>track users across different browsers</strong> as long as they're on the same device. Browser compartmentalization (a method where a person uses two or more dedicated browsers for different Internet activities) can be used to escape cookies set by different trackers.</p>
<p><strong>Firefox's multi-account containers</strong> add-on offers the same type of functionality and can be used to separate various web tasks into containers which are kept apart from each other. Cookies have become a less effective technique to these and various other prevention methods. However, methods like audio fingerprinting make it possible to identify users despite the fact that they are using different browsers.</p>
<p>Consider this code snippet:</p>
<pre><code>    console.log(new AudioContext());
    
    // Logs an AudioContext object 
    // to the console:
    {
        "baseLatency": 0,
        "outputLatency": 0,
        "sampleRate": 48000,
        "state": "suspended",
        "maxChannelCount": 2,
        "numberOfInputs": 1,
        "numberOfOutputs": 1,
        "channelCount": 1,
        "channelCountMode": "max",
        "channelInterpretation": "speakers",
        "fftSize": 2048,
        "frequencyBinCount": 1024,
        "minDecibels": -100,
        "maxDecibels": -30,
        "smoothingTimeConstant": 0.8
    }
</code></pre>
<p>Using methods such as <code>createAnalyser()</code>, <code>createDynamicsCompressor()</code> and <code>createOscillator()</code> can be used to further develop unique device information. Other fingerprinting methods can be used in conjunction with this one to get an even more accurate identifier. All the information collected is passed onto a hash function to make up the fingerprint.</p>
<ul>
<li><code>createAnalyser()</code>: can be used to reveal time and frequency data of the audio and create data visualizations through a node created called <code>AnalyserNode</code>.</li>
<li><code>createDynamicsCompressor()</code>: can be used to compress an audio signal through the <code>DynamicsCompressorNode</code>.</li>
<li><code>createOscillator()</code>: results in the creation of a given frequency of a given periodic wave to be created through <code>OscillatorNode</code>.</li>
<li><code>createGain()</code>: creates a <code>GainNode</code> which is responsible for detecting the change in volume.</li>
</ul>
<p>This piece of code performs fingerprint as found in <a href="https://www.cdn-net.com/cc.js">cc.js of CDN-NET</a> and <a href="https://audiofingerprint.openwpm.com/">OpenWPM</a></p>
<ol>
<li>First, we need to create an array to store frequency values.</li>
</ol>
<pre><code>    let freq_data = [];
</code></pre>
<ol start="2">
<li>We create an AudioContext object and create the various nodes needed to generate signal and collect the information using the built-in methods of the AudioContext object.</li>
</ol>
<pre><code>    // Create nodes
   const ctx = new AudioContext(); // AudioContext Object
   const oscillator = ctx.createOscillator(); // OscillatorNode
   const analyser = ctx.createAnalyser(); // AnalyserNode
   const gain = ctx.createGain(); // GainNode
   const scriptProcessor = ctx.createScriptProcessor(4096, 1, 1); // ScriptProcessorNode
</code></pre>
<ol start="3">
<li>We disable the volume and connect the nodes with each other.</li>
</ol>
<pre><code>    // Disable volume
   gain.gain.value = 0;
   
   // Connect oscillator output (OscillatorNode) to analyser input
   oscillator.connect(analyser);
   // Connect analyser output (AnalyserNode) to scriptProcessor input
   analyser.connect(scriptProcessor);
   // Connect scriptProcessor output (ScriptProcessorNode) to gain input
   scriptProcessor.connect(gain);
   // Connect gain output (GainNode) to AudioContext destination
   gain.connect(ctx.destination);
</code></pre>
<ol start="4">
<li>Using the <code>ScriptProcessorNode</code>, we create a function that collects frequency data while the audio is being processed.</li>
</ol>
<ul>
<li>The function creates a <code>Float32Array</code> typed array with a length that equals the number of (frequency) data values in the <code>AnalyserNode</code> and then populates it with the values.</li>
<li>These values are then copied to the array we created earlier (<code>freq_data</code>) so we can log them easily to an output.</li>
<li>We disconnect the nodes and log the output.</li>
</ul>
<pre><code>   scriptProcessor.onaudioprocess = function(bins) {
      // The number of (frequency) data values
      bins = new Float32Array(analyser.frequencyBinCount);
      // Fill the Float32Array array of these based on values
      analyser.getFloatFrequencyData(bins);
      
      // Copy frequency data to 'freq_data' array
      for (var i = 0; i &lt; bins.length; i = i + 1) {
          freq_data.push(bins[i]);
      }
      
      // Disconnect the nodes from each other
      analyser.disconnect();
      scriptProcessor.disconnect();
      gain.disconnect();
      
      // Log output of frequency data
      console.log(freq_data);
   }; 
</code></pre>
<ol start="5">
<li>We start playing the tone so the audio is generated and processed in accordance with the function.</li>
</ol>
<pre><code>   // Start playing tone
   oscillator.start(0);
</code></pre>
<p>We get an output like the one displayed below. The values are a lot longer than 10 values. This is for the sake of simplification.</p>
<pre><code>   /*
     Output:
     [ 
         -119.79788967947266, -119.29875891113281, -118.90072674835938,
         -118.08164726269531, -117.02244567871094, -115.73435120521094,
         -114.24555969238281, -112.56678771972656, -110.70404089034375,
         -108.64968109130886, ...
     ]
   */
</code></pre>
<p>A combination of all these audio data values can be processed through a hash function to create a unique fingerprint. Values passed from other methods of fingerprinting can also be aggregated to be hashed and produce a fingerprint of a device.</p>
<p>Some possible defenses against this tracking method work by adding a small noise to the actual fingerprint to generate a random fake value and reporting it as such. This is seen in add-ons like <a href="https://addons.mozilla.org/en-US/firefox/addon/audioctx-fingerprint-defender/">AudioContext Fingerprint Defender</a>. The TOR browser is by far the only browser that blocks these types of tracking methods by default.</p>
<h3 id="references">References</h3>
<p><a href="https://iq.opengenus.org/canvas-fingerprinting/"><strong>Canvas fingerprinting</strong></a><br>
<a href="https://iq.opengenus.org/methods-to-track-user-on-web/"><strong>Methods to track users on the Web</strong></a><br>
<a href="https://audiofingerprint.openwpm.com/">OpenWPM</a><br>
<a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext">AudioContext API</a><br>
<a href="https://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf">(Cross-)Browser Fingerprinting via OS and Hardware Level Features</a></p>
</div></div>]]>
            </description>
            <link>https://iq.opengenus.org/audio-fingerprinting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291640</guid>
            <pubDate>Sun, 28 Feb 2021 08:20:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Left Node for Deno]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26291506">thread link</a>) | @fazlerocks
<br/>
February 27, 2021 | https://tastet.tech/why-i-left-node-for-deno | <a href="https://web.archive.org/web/*/https://tastet.tech/why-i-left-node-for-deno">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1611746956772/OLz2GztHg.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text">
<p>If you don‚Äôt know  <a target="_blank" href="https://deno.land/">Deno</a> , it is a javascript runtime like Nodejs but with some changes.</p>
<p>We are not going to talk about the technical aspect here but only the advantages and disadvantages that I have in working with Deno.</p>

<h2 id="write-and-play">Write and play</h2>
<p>With Deno, you no longer need to install packages with package managers like NPM, so no more heavyweight node_modules folder on your computer (and also on your conscience).</p>
<p>Imports are done with Urls which can be either in deno's package manager with versioning, or directly on the git directory of your favorite library.</p>
<p>To illustrate that, here a sample code to start a web server with Deno and  <a target="_blank" href="https://oakserver.github.io/oak/">Oak Server</a> :</p>
<pre><code><span>import</span> { Application } <span>from</span> <span>"https://deno.land/x/oak/mod.ts"</span>;

<span>const</span> app = <span>new</span> Application();

app.use(<span>(<span>ctx</span>) =&gt;</span> {
  ctx.response.body = <span>"Hello world!"</span>;
});

<span>await</span> app.listen(<span>"127.0.0.1:8000"</span>);
</code></pre>
<p>You can also run codes that are not on your computer like <a target="_blank" href="https://deno.land/x/nessie@1.1.3">Nessie</a> which lets you perform database migrations directly from the command line with Deno.</p>
<pre><code>deno run --allow-net --allow-read --allow-write https://deno.land/x/nessie/cli.ts init
</code></pre>
<h2 id="typescript">Typescript</h2>
<p>Yes, Deno uses typecript by default for your code writing to avoid many errors, and since typescript is the norm in this perfect world, all libraries written in Deno uses typescript are typed.</p>
<p>And typescript is fully integrated into our IDEs, the code is easier to debug! üòÅ</p>
<h2 id="webassembly">WebAssembly üëÄ</h2>
<p>Deno integrates browser APIs and therefore has the WASM API allowing you to use functions written in other languages directly in your code.</p>
<p>I was personally tired of seeing Python run after installing each dependency in my NodeJs projects, it gave an impression of instability and that‚Äôs verified by running a code on different OS ...</p>
<p>But it's resolved as WASM is universal and standardized!</p>
<h2 id="browser-apis">Browser APIs</h2>
<p>Deno has (again) a big advantage, that offering browser APIs to make the javascript development environment more homogeneous with front-end javascript development.</p>
<p>For example : the standardized function " <a target="_blank" href="https://developer.mozilla.org/fr/docs/Web/API/Fetch_API/Using_Fetch">fetch</a> " is available with Deno.</p>
<h2 id="custom-formatter">Custom Formatter</h2>
<p>Deno integrates a custom formatter to make the code in your project between each developer more homogeneous with the <code>deno fmt</code> command</p>

<p>I only see 2 problems using Deno :</p>
<h2 id="instability">Instability</h2>
<p>Since Deno is still young, the libraries and the runtime may have bugs.</p>
<p>I have often had to spend long hours debugging my code to fix crashes.</p>
<p>Often due to a bad cache or a version change in a dependency or runtime.</p>
<p>On the other hand, the more we advance in time, the more stable Deno is and the libraries also with a strong open source community.</p>
<p>For example, I have more easily participated in open source projects using the deno runtime to improve them than NodeJs.</p>
<h2 id="libraries">Libraries</h2>
<p>The number of available libs is still quite low, again due to Deno's age, but this number is increasing day by day (javascript ecosystem, lol)!</p>

<p>In the end, I use Deno whenever I have to do something other than frontend, instead of using NodeJs, if the library I want to use doesn't exist, then I create it and make it public to help other people.</p>
<p>And I learned a lot from the open-source community by operating like this!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://tastet.tech/why-i-left-node-for-deno</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291506</guid>
            <pubDate>Sun, 28 Feb 2021 07:49:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ROG AI Overclocking on Linux]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26291486">thread link</a>) | @dragon-rabbit
<br/>
February 27, 2021 | https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>ASUS Republic of Gamers (ROG) has released an AI overclocking tool on BIOS, which allows the PC users who are not experienced in overclocking to overclock the CPU and boost the operating system performance.</p>



<p>I am using a ROG Z390 MAXIMUS XI HERO (WI-FI) motherboard and an Intel i9-9900K CPU. In this blog post, I would like to share my experience with the ROG AI overclocking on Linux.</p>

<h3 id="benchmark-tools">Benchmark Tools</h3>

<p>Here are some benchmark tools that are available on Linux.</p>

<h4 id="blender">Blender</h4>

<p>Blender has a benchmark tool called <a href="https://opendata.blender.org/">Blender Open Data</a>, which allows you to benchmark your CPU or GPU.</p>

<div><div><pre><code>$ wget https://opendata.blender.org/cdn/BlenderBenchmark2.0/launcher/benchmark-launcher-2.0.5-linux.tar.gz
$ tar xvf benchmark-launcher-2.0.5-linux.tar.gz 
$ ./benchmark-launcher 
</code></pre></div></div>

<!-- <div class = "titled-image">
<figure class = "titled-image">
    <img src = "https://leimao.github.io/images/blog/2021-03-29-ROG-Linux-AI-Overclocking/blender.png" style = "width: 70%; height: 70%">
    <figcaption>Causal Diagram</figcaption>
</figure>
</div> -->

<p>Blender is also a free and open source 3D creation suite. We could install it on Ubuntu using the following command.</p>

<div><div><pre><code>$ sudo apt-get update
$ sudo apt-get install blender
</code></pre></div></div>

<h4 id="prime95">Prime95</h4>

<p>Prime95 is used for √¢‚Ç¨≈ìburning√¢‚Ç¨ÔøΩ your CPU. It is also available on Linux.</p>

<div><div><pre><code>$ wget http://www.mersenne.org/ftp_root/gimps/p95v303b6.linux64.tar.gz
$ tar xvf p95v303b6.linux64.tar.gz
$ ./mprime
</code></pre></div></div>

<h4 id="openssl">OpenSSL</h4>

<p>OpenSSL comes with Linux by default. It can also be used for √¢‚Ç¨≈ìburning√¢‚Ç¨ÔøΩ your CPU.</p>

<div><div><pre><code>$ openssl speed -multi 16
</code></pre></div></div>

<h4 id="turbostat">TurboStat</h4>

<p>TurboStat is a tool to monitor Intel CPU usages. We will mainly use it to monitor the CPU clock speed.</p>

<div><div><pre><code>$ sudo apt-get install linux-tools-$(uname -r) linux-cloud-tools-$(uname -r)
$ sudo modprobe msr
$ sudo turbostat
</code></pre></div></div>

<h3 id="rog-ai-overclocking">ROG AI Overclocking</h3>

<p>ROG AI overclocking could be done at BIOS level.</p>

<ol>
  <li>Go into BIOS and set all the BIOS configurations to default, save and reboot.</li>
  <li>Go into OS and run one of the benchmark tools mentioned above, reboot.</li>
  <li>Go into BIOS and turn on AI overclock and XMP, save and reboot.</li>
</ol>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2021-03-29-ROG-Linux-AI-Overclocking/bios.png">
    <figcaption>ROG BIOS AI Overclocking</figcaption>
</figure>
</div>

<p>Before ROG AI overclocking, the stabilized CPU clock speed for all 8 cores of my i9-9900K during OpenSSL benchmarking was around 4.1-4.2 GHz. After ROG AI overclocking, it became 4.6-4.7 GHz.</p>



<p>For i9-9900KS, I believe it is possible to overclock all 8 cores to 5.0 GHz.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.asus.com/Microsite/motherboard/Intelligent-motherboard/AI-Overclocking.html">ROG AI Overclocking</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291486</guid>
            <pubDate>Sun, 28 Feb 2021 07:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A note on boredom anonymity and declinism]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26291388">thread link</a>) | @gdltec
<br/>
February 27, 2021 | https://sanchezbits.com/2021/02/27/a-note-on-boredom-anonymity-and-declinism/ | <a href="https://web.archive.org/web/*/https://sanchezbits.com/2021/02/27/a-note-on-boredom-anonymity-and-declinism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>It‚Äôs interesting to see how the amount of ennui in our society increases simultaneously as technology advances. We are doing something wrong. Technology and its rapid advancement can be not only distracting but dangerous.&nbsp;</p>



<p>Is this contributing to the declinism of our society? I think it is, and my only advice is to be more empathetic and caring of others around you.&nbsp;</p>



<p>The abundance of digital content, the accessibility of technology, the algorithms strictly designed to keep you connected and in rage, and the facility to consume more goods from our homes, digital and non-digital, it‚Äôs all part of it.&nbsp;</p>



<p>We are becoming isolated creatures who are often policing others to see how they are behaving and ready to complain publicly if other people disagree with us.</p>



<p>Attacking and criticizing others is easier than ever; digital anonymity is at the root cause of this. Interestingly, those who identify themselves and dare to share their opinions publicly suffer from attacks of people who dislike what they say, destroying any opportunity of dialog and intelligent conversation.</p>



<p>It is boredom, online anonymity, misinformation, and many other things contributing to a civic and ethical decline.&nbsp;</p>



<p>I‚Äôve found myself lured into digital anger holes just by doom-scrolling on Twitter and other platforms. Even when I think I‚Äôm self-aware, it‚Äôs hard to push back and ignore the ignorant and the misinformation of pointless negativity, some of which comes from people who are just virtue signaling.</p>



<p>Slowing down is the best thing we can do, in my opinion. Before you reply to a critic, before responding to someone‚Äôs comment, take a minute and figure out if responding or commenting to something undeniably negative or ignorant is necessary. I think it is not.</p>



<p>Fighting misinformation, cynicism, and hate speech are necessary, but we can‚Äôt do it with more misinformation and cynicism of our own. We often fall under tribalism behavior, and it requires a large amount of patience and self-awareness to combat that.&nbsp;</p>



<p>We don‚Äôt need to stop innovating to advance our technologies. However, we need to be wise and empathetic to those who are negatively affected by it. Hence, we should be aware of what‚Äôs happening and be willing to make changes, even when not in our favor, to ensure the technology and progress that comes with it benefit everyone equally.</p>



<p>At a personal level, I find it beneficial to be more present and empathetic to those around us, our family, our friends, the cashier at the store, the homeless around the corner, the people with who we disagree, etc.&nbsp;</p>



<p>Just follow the Golden Rule:</p>



<blockquote><p>One should never do something to others that one would regard as an injury to one‚Äôs own self</p><cite><em>MahƒÅbhƒÅrata</em>&nbsp;13.114.8</cite></blockquote>




	</div><div>
				<p><strong>Published</strong>
			<time datetime="2021-02-27T13:23:12-08:00">February 27, 2021</time><time datetime="2021-02-27T13:24:26-08:00">February 27, 2021</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://sanchezbits.com/2021/02/27/a-note-on-boredom-anonymity-and-declinism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291388</guid>
            <pubDate>Sun, 28 Feb 2021 07:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust, Zig, and the Futility of ‚ÄúReplacing‚Äù C]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 119 (<a href="https://news.ycombinator.com/item?id=26291054">thread link</a>) | @ghoward
<br/>
February 27, 2021 | https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/ | <a href="https://web.archive.org/web/*/https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>This post has been discussed on <a href="https://news.ycombinator.com/item?id=26291054#26294846">Hacker News</a>, <a href="https://www.reddit.com/r/rust/comments/luawx6/rust_zig_and_the_futility_of_replacing_c/"><code>/r/rust</code></a>, and
<a href="https://lobste.rs/s/1iiifg"><code>lobste.rs</code></a>.</p><p>I should not have posted this to Hacker News on a Saturday night right before
going to bed, but in my defense, this post blew up in a way I didn‚Äôt expect.</p></div><h2 id="introduction">Introduction</h2><p>There was a recent <a href="https://github.com/pyca/cryptography/issues/5771">dust-up on GitHub</a> surrounding the decision by the
<a href="https://github.com/pyca/cryptography">Cryptography library</a> (which I will call <code>cryptography</code> for convenience) to
switch to <a href="https://www.rust-lang.org/">Rust</a>.</p><p>One of the distro maintainers of my distro of choice, <a href="https://www.gentoo.org/">Gentoo</a>, filed a bug
report with the <code>crytography</code> saying that the switch broke builds on several
platforms that Gentoo still supports. The <code>cryptography</code> authors replied that
those platforms are not really used anymore, and that they were going to stick
with Rust because it has better memory safety than C. They also argued that it
is better to force better programming languages on people because of better
security.</p><p>At first glance, it appears that the better argument is on the side of the
<code>cryptography</code> maintainers, but after thinking about it carefully, I think they
are wrong.</p><h2 id="reasons">Reasons</h2><p>There are a few reasons why I believe the <code>cryptography</code> maintainers are at
fault.</p><h3 id="due-diligence">Due Diligence</h3><p>First, their argument for Rust (and against C) because of memory safety implies
that they have not done due diligence in finding and fixing such bugs.</p><p>I can almost hear the rage of my readers against that paragraph above and
against the fact that I don‚Äôt have a commenting system on my blog. So let me
answer the comments preemptively.</p><p>‚ÄúThey are volunteers, giving their time away for free!‚Äù</p><p>Yes, but they also <em>intend</em> for their code to be used widely. They managed to
succeed in that, so they now have some obligation to their users.</p><p>‚ÄúThey don‚Äôt have any obligation!‚Äù</p><p>If a software project actively goes out and gets users, which just about any
project with a serious number of users has done, then yes, they have an
obligation to those users. The reason is that they sold users on the idea of
using their software. In other words, they were marketing their software, which
means making promises.</p><p>In fact, when people release <em>libraries</em> and try to get users for them, it‚Äôs
<em>because</em> they want them to be used by downstream programmers. A programmer
might write a program to scratch an itch and release it, but that reasoning
applies much less to libraries, in my opinion.</p><p>‚ÄúOkay, but they didn‚Äôt get anything in return, so there‚Äôs still no obligation.‚Äù</p><p>In return, the users gave them <strong>relevance</strong>.</p><p>One of the most vocal (in favor of Rust) developers of <code>cryptography</code> works for
Red Hat Security Engineering (if I read his GitHub profile right). I don‚Äôt know
if his work on <code>cryptography</code> helped him get that job, but it might have.</p><p>Another of the most vocal developers has a computer security company. I would
bet money that his work on <code>cryptography</code> gives his company relevance.</p><p>So they did <em>not</em> get ‚Äúnothing‚Äù from users. Quite the opposite, in fact.</p><p>By the way, this position comes from my own experience pushing my <a href="https://git.yzena.com/gavin/bc"><code>bc</code></a>. I
managed to convince the FreeBSD project to <a href="https://github.com/freebsd/freebsd-src/tree/main/contrib/bc">make it the default</a> in FreeBSD
13.</p><p>Once I did that, I shouldered, willingly, the need to keep FreeBSD happy. And
while I have made mistakes, I have done well so far.</p><p>And with my <code>bc</code>, <strong>I did my due diligence with memory safety</strong>. I fuzzed my
<code>bc</code> and eliminated all of the bugs. I even run the generated fuzzer test cases
through AddressSanitizer, and my entire test suite is run through Valgrind
<em>and</em> AddressSanitizer. I also add failing fuzzer cases to my test suite, which
means I run more and more test cases through both of those frightfully
effective tools.</p><p>For the record, those tools are only effective with effective test suites, which
I spent a lot of time building. But <em>building</em> such a test suite is part of due
diligence itself.</p><p>So it follows that if the developers have <em>not</em> done their due diligence, their
users should <strong>leave</strong>, either by forking the project or creating a new one.
The relevance they gave to the <code>cryptography</code> authors should disappear.</p><h3 id="battle-tested-c-code">Battle-Tested C Code</h3><p>In fact, I have done enough due diligence with my <code>bc</code> that I would consider it
a dereliction of duty to Rewrite It in Rust (RIIR).</p><p>Why would it be a dereliction of duty? Because rewriting it in Rust would cause
<em>more</em> bugs, not less. This is because of several reasons:</p><ol><li>I would need to <em>redesign</em> it to fit the language.</li><li>I would need to <em>reimplement</em> it, and new implementations always have bugs.</li><li>The C code is battle-tested, both by me (using fuzzing and other techniques)
and by users.</li></ol><p>That last point is the most crucial, especially in the case of <code>cryptography</code>.</p><p>If the developers of <code>cryptography</code> claim that they have, in fact, done their
due diligence with regards to memory safety in their C code, then they are
claiming that it‚Äôs battle-tested.</p><p>The saying that ‚Äúa bird in the hand is worth two in the bush,‚Äù and in this case,
<em><strong>if</strong></em> the <code>cryptography</code> developers are claiming that they have done their
due diligence, they are throwing away a bird in the hand for a single one in the
bush.</p><div><p><strong>Edit (28 Feb 2021)</strong>: This part of the post seems to be misunderstood widely,
so I am going to attempt to clarify.</p><p>People are arguing that having safe C code requires a frozen, small codebase
with a thorough test suite. And then they debate my position based on the belief
that the codebase needs to evolve.</p><p>For the record, I agree with them that in order to have safe C code, the
codebase must be small and frozen.</p><p>What I am arguing is that <strong>crypto</strong> code <em>should</em> be small and frozen, with a
thorough test suite. I wrote about that <a href="https://gavinhoward.com/2019/11/finishing-software/">here</a>.</p></div><p>And if that‚Äôs the case, their users should <strong>leave</strong> and take <code>cryptography</code>'s
relevance with them.</p><h3 id="desktops-and-smartphones-are-not-the-only-computers">Desktops and Smartphones Are Not the Only Computers</h3><p>The users of <code>cryptography</code> were claiming in the bug report discussion that Rust
is not portable to many platforms, and the authors said that they don‚Äôt have the
time or resources to target those platforms. Fair enough.</p><p>But then they claim that the <em>users</em> should put in the effort to port Rust to
their platforms. This is wrong.</p><p>The <code>cryptography</code> authors also claim that the platforms that Rust doesn‚Äôt
support do not matter. As we will see below, this is false.</p><p>While I agree that the <code>cryptography</code> authors are not responsible for porting
Rust to other platforms, the users of those platforms are not either.</p><p>That responsibility falls on the Rust developers.</p><p><em>They</em> were the ones who sold Rust to those who have used it, so as above,
<em>they</em> have the responsibility for supporting their users.</p><p>Granted, the Rust developers have made no claim about being portable to every
platform. But they <em>have</em> claimed that it is <a href="https://www.rust-lang.org/what/embedded">appropriate for embedded
software</a>.</p><p>If it were true, this would be great. After all, <a href="https://youtu.be/3HxPzutkNYw?t=257">IoT devices outnumber
desktops and smartphones by at least one order of magnitude</a>.</p><p>But there are a lot of them that LLVM, Rust‚Äôs backend, cannot generate code
for. In fact, there are a lot of them that <em>C++</em> cannot run on.</p><div><p><strong>Edit (28 Feb 2021)</strong>: Also, the Rust developers are the developers with the
most experience reading ISA manuals knowing how to make a compiler generate
code. So they are still the best placed to support those ‚Äúesoteric‚Äù
architectures.</p><p>And if they do not know how to read ISA manuals and generate code, it‚Äôs because
they lean too heavily on LLVM.</p></div><p>Make no mistake; embedded software is still running the majority of devices in
the world. And C is the king of embedded software.</p><p>I don‚Äôt know exact numbers, but I wouldn‚Äôt be surprised if the majority of
programmable devices in the world cannot run Rust.</p><p>Thus, because Rust uses LLVM, it is not portable.</p><p>And in my opinion, Rust is not appropriate for the embedded space.</p><p>So in this case, I would consider that the <code>cryptography</code> developers were
victims of the Rust developers.</p><h3 id="gcc-is-not-the-only-compiler"><code>gcc</code> Is Not the Only Compiler</h3><p>That isn‚Äôt the only problem.</p><p>There is a <a href="https://github.com/Rust-GCC/gccrs">project to make <code>gcc</code> able to compile Rust</a>. That‚Äôs commendable.</p><p>However, many people seem to believe that once it‚Äôs done, Rust will be portable.
That is not the case.</p><p>Why? Simple: <strong><code>gcc</code> is not the only compiler</strong>.</p><p>There is plenty of code out there that uses dead simple C compilers, like
<a href="https://bellard.org/tcc/">tcc</a>, <a href="http://sdcc.sourceforge.net/">sdcc</a>, and others. And often, they have <a href="https://embeddedgurus.com/stack-overflow/2012/06/optimizing-for-the-cpu-compiler/">good reason to do
so</a>.</p><p>Adding a <code>gcc</code> frontend, while it will improve the situation, will not make Rust
as portable as C. Period.</p><h3 id="pushing-for-progress-hinders-it">Pushing for Progress Hinders It</h3><p>The other thing that the <code>cryptography</code> authors claim is that their users who
refuse to adopt Rust are hindering progress.</p><p>That may be true, but it is also true that forcing ‚Äúprogress‚Äù on others hinders
<em>true</em> progress.</p><p>By forcing users to either adopt Rust or pin their dependency on <code>cryptography</code>
to the most recent version without it, they are forcing those users to use
stagnant code.</p><p>Isn‚Äôt that the very opposite of progress?</p><h2 id="cryptography-at-fault"><code>cryptography</code> at Fault</h2><p>Those reasons lay out why I think the <code>cryptography</code> authors should shoulder the
blame for this situation, and I think I can explain where they went wrong.</p><ol><li>They let ideology come before pragmatic engineering.</li><li>They sold <code>cryptography</code> to users.</li><li>They knew that switching to Rust would break existing users and did it
anyway.</li><li>They either did not do their due diligence for memory safety, or they did
and threw that battle-tested code out.</li></ol><h2 id="portability">Portability</h2><p>To be honest, I used to think that it was better to switch to a better language
than C.</p><p>I had several talks with Linux distro maintainers, as well as a talk with my
father-in-law, that convinced me that C‚Äôs portability is still important enough
that it should be used.</p><p>Unless, of course, you <em>explicitly</em> target only certain platforms. But you had
better be prepared to never target others.</p><p>In fact, after talking with the distro maintainers, who have had to build Rust,
I am also convinced that it‚Äôs not just about being portable, it‚Äôs also about how
<em>easy</em> it is to <em>build</em> software.</p><p>Rust‚Äôs bootstrap is <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">complicated</a>, and it is one of the worst things about
it.</p><p>If building software in Rust means building Rust for a <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">Tier 3</a> platform,
you can bet that <a href="https://drewdevault.com/2021/02/09/Rust-move-fast-and-break-things.html">people will stick with C</a>.</p><h3 id="zig">Zig</h3><p>I want to take a moment to talk about Zig.</p><p>Zig might be one of the most promising up-and-coming languages of recent memory.</p><p>But it will ultimately fail to reach its goal.</p><p>You see, Zig is meant to replace C. But ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/">https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/</a></em></p>]]>
            </description>
            <link>https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291054</guid>
            <pubDate>Sun, 28 Feb 2021 06:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Horizonator: Terrain renderer based on SRTM DEMs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290718">thread link</a>) | @pabs3
<br/>
February 27, 2021 | http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
Check this out:
</p>


<p><img src="https://github.com/dkogan/horizonator/raw/master/example-interactive.png" alt="example-interactive.png">
</p>

<p>
I just resurrected and cleaned up an old tool I had lying around. It's now nice
and usable by others. This tool loads terrain data, and renders it from the
ground, simulating what a human or a camera would see. This is useful for
armchair exploring or for identifying peaks. This was relatively novel when I
wrote it &gt;10 years ago, but there are a number of similar tools in existence
now. <i>This</i> implementation is still useful in that it's freely licensed and
contains APIs, so fancier processing can be performed on its output.
</p>

<p>
Sources and (barely-complete-enough) documentation live here:
</p>

<p>
<a href="https://github.com/dkogan/horizonator">https://github.com/dkogan/horizonator</a>
</p>

  </div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290718</guid>
            <pubDate>Sun, 28 Feb 2021 04:38:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to Ephemeral Environments]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290634">thread link</a>) | @gk1
<br/>
February 27, 2021 | https://releaseapp.io/ephemeral-environments | <a href="https://web.archive.org/web/*/https://releaseapp.io/ephemeral-environments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://releaseapp.io/ephemeral-environments</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290634</guid>
            <pubDate>Sun, 28 Feb 2021 04:16:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Thoughts on Community]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290434">thread link</a>) | @sarvasvkulpati
<br/>
February 27, 2021 | https://sarvasvkulpati.com/blog/community | <a href="https://web.archive.org/web/*/https://sarvasvkulpati.com/blog/community">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><main><article><div><p>There's been an explosion of people creating communities on the internet. I've thought about them a lot, and wrote this to compile some of those thoughts in a single document.</p><p>What is a community? For my purposes, I‚Äôve found a useful definition.</p><blockquote><p>A group of people, united by a shared passion or purpose, who interact with each other.</p></blockquote><p>Looking at the definition, there are only two things a community needs.</p><ul><li>A shared passion or purpose</li><li>People interacting with each other</li></ul><p>Here‚Äôs some examples of communities:</p><table><thead><tr><th>Community</th><th>Shared passion/purpose</th><th>People interacting</th></tr></thead><tbody><tr><td>Your high school</td><td>Learn (apparently)</td><td>Talking in classrooms, lunches, groupchats</td></tr><tr><td>React developers</td><td>Using the same language, interested in the development of the language</td><td>Tweeting at each other, reddit, forums</td></tr></tbody></table><p>The strength of a community, then, comes from the strength of this shared passion/purpose and the depth and frequency of interactions. And so, a useful formula for measuring the strength of a community could be:</p><p><span></span> = strength of the passion/ideal</p><p><span></span> = the ith connection</p><p><span></span> = the depth of the ith connection</p><p>We can come up with a few interesting observations through this formula.</p><ul><li><p>Notice that this definition doesn‚Äôt talk about technology or the platform used to bring these people together. <strong>Putting people into a group chat doesn‚Äôt make it a community.</strong> In fact, a group chat isn‚Äôt even necessary to build a community. There‚Äôs clearly a React developer community on the internet, but there isn‚Äôt any specific platform or group chat they congregate at. In that sense, communities can be thought of as the superset of the platform they exist on. A single community can use many platforms to interact with each other, but the discord server or slack channel they use isn‚Äôt the community itself.</p></li><li><p><strong>The strength of the shared passion/purpose acts as a force multiplier on the connections in a community.</strong> If there is no shared P, the community has no strength. Getting people together who don‚Äôt have a shared passion is the same thing as putting a bunch of random people in a group chat and calling it a community.</p></li><li><p><strong>It‚Äôs much easier to connect with people who have the same values and passions as you do, so the stronger P is, the stronger every single connection is right at the outset.</strong> So (somewhat obviously), the more passionate people are, the easier is it so make a community with them. Conversely, without a strong shared ideal, it‚Äôll be very difficult to get people to interact and form deep connections.</p></li><li><p>The shared purpose can even be something as trivial as having to be in the same place at the same time. But if you‚Äôve left high school, you‚Äôll notice how you probably haven‚Äôt kept in touch with 90% of the people you knew, even if it felt like you knew them really well during your time there. That leads us to another important point- <strong>there is a hierarchy of shared experiences that bring people together.</strong> You didn‚Äôt keep in touch simply because the strength of your connection was based on location, which is very weak compared to shared passions or experiences.</p></li></ul><p><img src="https://sarvasvkulpati.com/hierarchy.jpeg" alt="shared purpose hierarchy"></p><p>A community with a few deeply passionate people is much stronger than one with many shallow ones. You‚Äôd think that it‚Äôs merely the area under the curve (connections x depth of connections), but there‚Äôs a third dimension here-  P would likely be much higher in communities with deeper connections, making those communities stronger.</p><p><img src="https://sarvasvkulpati.com/3d.jpeg" alt="3d graph of P, depth and connections"></p><p>Notice that frequency of interaction is not a factor at all. It‚Äôs only useful to the extent that it increases the depth of relationships in a community- beyond that, it doesn‚Äôt make a difference.</p><p>Think of your closest group of friends. You could meet them all after months and you‚Äôd still feel the same sense of community you did before. The strength of your connection superseded the need to constantly interact. And so, the DAUs of a community is a terrible way to measure its strength. This is not to say it doesn‚Äôt matter, just that while frequent interactions may lead to deep connections, deep connections don‚Äôt necessarily mean frequent interactions.</p><h2>Who‚Äôs a community for?</h2><p>The need for deep connections means that communities specifically built for the internet can only fulfill a certain set of users.</p><p>The issue is <a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">Dunbar‚Äôs number</a>. Humans can only maintain ~150 deep connections, and the vast majority of these are taken up by in person relationships. But to make online communities, you need people to make strong relationships. So, in a sense, you need people with enough ‚Äòmental social capacity‚Äô to form those deep relationships with people online.</p><p>This required ‚Äòmental social space‚Äô means that online communities need to cater to people who are missing some sort of social interaction offline. And so, they need to find a way to offer connections that people cannot find in person.</p><p>From a social lens, the internet is an aggregation of extremes. It allows everyone in the long tail to suddenly have an abundance of people like them. This means that people with unconvential interests who couldn't find their people in person, can do so online. So the the gamer, the programmer, the digital artist in school- they don‚Äôt need to feel so different anymore.</p><p>For example, I‚Äôve been interested in startups for years now, and after bingeing <a href="https://blog.ycombinator.com/category/podcast/">YC‚Äôs podcasts</a>, I realised that I needed a way to find people with the SV mindset. Twitter allowed me to find many people my age with similar interests, <a href="https://twitter.com/sarvasvkulpati/status/1247181074611851267?lang=en">Enlite</a> allowed me to meet a bunch of really interesting people, and interning at <a href="https://pioneer.app/">Pioneer</a> gave me a glimpse of what it‚Äôs like to work at startups. All of these happened without meeting a single one of of these people in person.</p><p><a href="https://hackclub.com/">HackClub</a> is a perfect example of a community that‚Äôs built to cater to a group of people who miss some sort of social interaction offline. It‚Äôs still strangely difficult to find kids who are interested in coding and building things, and Hack Club fills that gap by giving young hackers an online community of people just like them. It works so well because it manages to both</p><ul><li>Cater to highly passionate people</li><li>Cater to people who don‚Äôt usually find their communities in person</li></ul><h2>Building strong community</h2><p>While finding many people with a high P is a prerequisite, you need to then get them to interact with each other, to weave the web of connections that form the thing you‚Äôll call your community. When you first bring people together, each individuals connections will look like this:</p><p><img src="https://sarvasvkulpati.com/connections.jpeg" alt="a graph of connections against depth"></p><p>Each member will have fairly weak connections with all the other members.The mistake I made when I first started Enlite was thinking that putting a bunch of people in a slack channel would mean that all of them interact with every other member all the time. That wasn‚Äôt the case. Instead, a small, core group of people emerged.</p><p>When you‚Äôre in school, you‚Äôll notice that cliques naturally form. No amount of social engineering would get the jocks to suddenly integrate with the nerds. Similarly, the formation of cliques in a community is pretty normal, and in fact, is a great thing. It means people are falling into subsets of others they are comfortable with.</p><p>However, you don‚Äôt want insulated cliques. While there should be strong connections within them, they should also be connected to each other. Should this succeed, your community will look like this:</p><p><img src="https://sarvasvkulpati.com/graph.jpeg" alt="network of members in a community"></p><p>Any individual in your community will end up with a T shaped profile- many fairly shallow connections, a few very deep ones. The width of the stem would depend on the number of online friends they mentally have space to make as well as their success with connecting to people within the community.</p><p><img src="https://sarvasvkulpati.com/depth.jpeg" alt="depth"></p><p>Much like any social product, Enlite has a retention curve, and about a third are still active. An interesting observation is that the members who initially attended the most video calls are the ones who are now the most active in chat. My theory is that they acquired the best relationships and so, felt incentivised to talk and share opinions and progress on projects.</p><h2>Creating strong connections</h2><p>But how do you facilitate creating these strong connections? Something I‚Äôve noticed is that every relationship: teacher-student, parent-child, friend-friend, follows a timeline</p><p><img src="https://sarvasvkulpati.com/friendGraph.jpeg" alt="friendship timeline"></p><p>In a sense, the depth of a relationship could be measured by how much a pair knows and understands about what makes the other tick. You could have a wild drinking buddy and always have fun but unless you have some deep conversations, you don‚Äôt have a deep relationship. To increase the depth of the relationship quickly, you need to increase the bandwidth of communication- doing so allows both people to understand each other faster, and so, speeds up the timeline of the relationship.</p><p>For example, <a href="https://twitter.com/aadillpickle">Aadil</a> and I followed each other on twitter for a while. I saw his tweets, he saw mine, sometimes we interacted with each other. But then, when making Enlite, I got on a zoom call with him. Within 30 minutes, we were much, much better friends. It felt like the amount our friendship progressed in a few months of interacting with each other on Twitter was repeated several times over in 1 zoom call.</p><p>Of course, different mediums have different bandwidth, but there‚Äôs a tradeoff- the higher the bandwidth, the higher the barrier of entry. Scheduling a zoom call, for example, is much harder than sending a Twitter DM.</p><p><img src="https://sarvasvkulpati.com/bars.jpeg" alt="bar charts of communication mediums compared"></p><p>In this sense, audio is probably best placed at the intersection of bandwidth and friction. On audio calls, you don‚Äôt need to care about how you look, you don‚Äôt need to constantly stay in a ‚Äòswitched on‚Äô state and stare at the camera throughout, and it‚Äôs much easier to hop on and off. This is probably why platforms like Discord and Clubhouse are growing so fast as a tool to grow communities.</p><h2>A summary</h2><p>In conclusion:</p><ul><li>Communities = passion x interaction x strength of interactions</li><li>You don't need a group chat for a community, and putting people into a group chat doesn't make it one</li><li>Communities need to cater for connections people don't find in person</li><li>Creating connections requires a high bandwidth of communication. When in doubt, choose video</li><li>Frequent activity doesn't necessarily mean a strong community</li></ul></div></article></main></div></div>]]>
            </description>
            <link>https://sarvasvkulpati.com/blog/community</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290434</guid>
            <pubDate>Sun, 28 Feb 2021 03:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[There is only one poverty strategy: (broad based) growth (Part I) (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290383">thread link</a>) | @tosh
<br/>
February 27, 2021 | https://lantpritchett.org/there-is-only-one-poverty-strategy-broad-based-growth-part-i/ | <a href="https://web.archive.org/web/*/https://lantpritchett.org/there-is-only-one-poverty-strategy-broad-based-growth-part-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-441">
		<!-- .entry-header -->

	
	<div>
		
<p>Here is a number to remember:&nbsp; .994 (and not because 994 is the country
telephone code for Azerbaijan).</p>



<p>The measure of poverty most commonly used by the World Bank is the ‚Äúheadcount‚Äù: the proportion of people below a poverty line,  a fixed level of income or consumption expenditures (CEX) per capita. &nbsp;The Foster, Greer and Thorbecke (1986) measures of poverty are weighted sums of people from a given distribution of consumption expenditures (or income), and the headcount is the simple case where the weights are equal for each person, irrespective of how far from the poverty line their CEX is. </p>



<p>This leads to a simple question:&nbsp; ‚ÄúHow much of the  observed variation in headcount poverty rates across countries is due to variation in the median of the distribution of consumption expenditures?‚Äù&nbsp;&nbsp; </p>



<p>The answer, shown in Figure 1, is (roughly) ‚ÄúAll of
it.‚Äù&nbsp; The R-Squared of the median (with
various powers to account for non-linearity) for explaining headcount poverty
for the three poverty lines is: </p>



<ul><li>$5.50 per day, R-Squared=.988,
correlation(poverty, predicted)=.994</li><li>$3.20 per day, R-Squared=.988, correlation(poverty,
predicted)=.994</li><li>$1.90 per day, R-Squared=.983,
correlation(poverty, predicted)=.991 </li></ul>



<p>The simple correlation between the actual $3.20/day or $5.50/day headcount poverty rate and headcount poverty as predicted using only the median of the country distribution is .994 and for $1.90 it is .991.&nbsp; These are about as high a correlation as real world data can produce.&nbsp; </p>



<p><strong>Figure 1:&nbsp; Headcount poverty rates are extremely highly associated with median consumption expenditures </strong></p>



<figure><img loading="lazy" width="749" height="353" src="https://lantpritchett.org/wp-content/uploads/2019/02/image.png" alt="" srcset="https://lantpritchett.org/wp-content/uploads/2019/02/image.png 749w, https://lantpritchett.org/wp-content/uploads/2019/02/image-300x141.png 300w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px"></figure>



<p><em>Source:&nbsp;
Author‚Äôs calculations based on data from:&nbsp; ‚Äú</em><a href="http://iresearch.worldbank.org/PovcalNet/povDuplicateWB.aspx">PovcalNet:
the on-line tool for poverty measurement developed by the Development Research
Group of the World Bank</a>‚Äù</p>



<p>The regression uses the 389 country/time observations from
the World Bank data that are based on consumption expenditures (not income) and
recent data (not distant extrapolations). Since headcount poverty is a partial
integral of a distribution of consumption expenditures the relationship between
the median and headcount has to be non-linear.&nbsp;
I use powers of the median from -2 to 5 to allow for flexible
non-linearity. </p>



<p>Nancy Birdsall and Christian Meyer have argued that for
development issues ‚Äú<a href="https://www.cgdev.org/publication/median-message-good-enough-measure-material-well-being-and-shared-development-progress">The
Median is the Message</a>.‚Äù &nbsp;For headcount
poverty they are <em>completely</em> right. &nbsp;The answer to the question:&nbsp; ‚ÄúWhy does a country at a given time have
headcount poverty rate it does?‚Äù is ‚ÄúBecause of its median of consumption
expenditure.‚Äù Pretty much full stop.&nbsp; &nbsp;Conditional on the median, any and all other factors
or variables can explain <em>at most</em> 1.2
percent of the variation in country headcount poverty rates (maybe 0, but <em>at most </em>1.2). &nbsp;</p>



<p>You might be saying, ‚ÄúLant, why are you making such a big
deal of this correlation?‚Äù&nbsp; Well, thanks
for asking.&nbsp; </p>



<p>This very tight correlation is not built in.&nbsp; One can usefully decompose (as many have done)
the difference in poverty rates comparing two distributions (between countries
or over time) into three elements on the (mostly accurate) assumption the
distribution is log-normal (that is, the natural log of consumption
expenditures is distributed as a Gaussian normal distribution):</p>



<ol><li>Differences in the central tendency of the log-normal distribution,</li><li>Differences in the variance of the log-normal distribution and</li><li>Differences in the distribution below the poverty line being more or less favorable to poverty than would be expected of a log-normal of a given central tendency and variance (as the log-normal is a two-parameter distribution this forces an exact shape).</li></ol>



<p>How much of the variance in headcount poverty is an
empirical fact that depends on the actual distributions of consumption
expenditures across countries and the fact that (2) and (3) account for 1.2
percent of the variance could have been otherwise, it is not cooked into
definitions.&nbsp; In fact, one can easily
imagine policies or programs that would bring up the lower tail, and hence
reduce poverty, much more than the log-normal would predict.&nbsp; So it is a striking finding that <em>both </em>differences in variance
(inequality) with the assumption of log-normality and deviations from
log-normality below the poverty line <em>together
</em>account for at most 1.2 percent of observed variation in poverty.</p>



<p>Included in the country/time varying factors whose variation
in the observed data <em>cannot</em> explain
more than 1.2 percent of the observed variation in headcount poverty rates are
things like: ‚Äúbudget (government or other) devoted to anti-poverty programs‚Äù
and ‚Äúefficacy of the design of anti-poverty programs‚Äù or ‚Äúwhether the country‚Äôs
anti-poverty programs are ‚Äòevidence based‚Äô‚Äù or, for that matter, any
interaction of those factors, like:&nbsp;
‚Äúwhether a country devoted budget to well-designed anti-poverty programs
based on evidence.‚Äù&nbsp; The median explains
nearly all variation in poverty across countries with no reference to targeted
programs of any kind: not micro-credit, not conditional cash transfers, not
chickens, not livelihood programs, nothing that claims to impact poverty
without changing the median. </p>



<p>Given the amount of time, energy, intellectual firepower, academic
publication, and advocacy that go into discussions of anti-poverty <em>programs</em> one might think they are a
large part of the ‚Äúsolution‚Äù to global poverty.&nbsp;
But they just have not been.&nbsp; If
your median consumption expenditure went up then your headcount poverty went
down and <em>nothing</em> else that any
country has done besides that seems to be very important in explaining poverty
reduction.</p>



<p>The relative importance of growth of median consumption expenditures versus ‚Äúall else‚Äù can be illustrated with two different poverty lines at two different levels of income, the ‚Äúextreme poverty‚Äù penurious poverty line that the World Bank often uses (but which I think is fundamentally <a href="http://www.effective-states.org/the-mdgs-were-a-disaster-meet-lant-pritchett/">illegitimate</a> as it is too low) and the ‚Äú$5.50/day‚Äù line (which I think is still too low).</p>



<p>The predicted level of $1.90/day ‚Äúextreme poverty‚Äù for a
country at the average income of the lowest quartile of countries is 72.2%.&nbsp; If its poverty rate were better by one
standard deviation of the residual conditional on the median it would fall to
only 68.6 percent.&nbsp; Even if it had the
best poverty conditional on its median for any country in the bottom quartile
it would fall by about 10 percentage points to 62.7 percent.&nbsp; In contrast, if that country grew by two
percent a year for 20 years (which is roughly the average growth in the post
WWII era) poverty would fall to 35.9 percent‚Äîabout in half.&nbsp; If it grew at 4 percent per capita for 20
years (this is about one standard deviation above the average growth of 2
percent) predicted headcount poverty would fall to 12.1%.&nbsp; Sustaining rapid growth starting from a low
median consumption expenditures reduces poverty <em>50 percentage points</em> more than having the <em>best</em> observed poverty conditional on the low median.&nbsp; With sustained growth <em>half the population </em>moves out of extreme poverty compared to 10
percent even the <em>best</em> observed
poverty with stagnant income (and just to be clear, the data here don‚Äôt tell
what accounts for these observed low poverty rates conditional on the median). </p>



<p><strong>Figure 2:&nbsp; Even getting to the best headcount poverty for a given median expenditures versus the average produces a small gain relative to the poverty reduction from sustained growth of the median</strong></p>



<figure><img loading="lazy" width="481" height="289" src="https://lantpritchett.org/wp-content/uploads/2019/02/image-1.png" alt="" srcset="https://lantpritchett.org/wp-content/uploads/2019/02/image-1.png 481w, https://lantpritchett.org/wp-content/uploads/2019/02/image-1-300x180.png 300w" sizes="(max-width: 481px) 100vw, 481px"></figure>



<p>I do the same exercise with the second quartile of income
and the $5.50/day poverty line, with roughly the same results.&nbsp; Even the best performance for poverty
conditional on median produces gains much, much, smaller than the gains in
poverty reduction from sustained rapid growth.</p>



<p>The results of these regressions are just facts about the
world and do not directly reveal causal structures.&nbsp; In particular, there may well be cost
effective poverty reducing programs that merit support by governments and/or
philanthropists.&nbsp; The cross-national
correlations can only speak to what <em>have been</em>
the correlates of poverty, not <em>what could
be.&nbsp; </em>But, while one doesn‚Äôt want to
over-interpret facts, neither does one want to under-fact interpretations of
very specific and particular empirical findings about specific programs
either.&nbsp; </p>



<p>The next time you hear the phrase ‚Äúsolve global poverty‚Äù remember the number: .994.&nbsp; If what follows ‚Äúsolve global poverty‚Äù isn‚Äôt about raising median consumption expenditures a very good question is: ‚Äúwhy not?‚Äù</p>



<p>(This blog is titled ‚ÄúPart I‚Äù because I plan a Part II that
does a bit more on the technical issues of these types of decompositions and a
Part III that discusses a bit the broader implications.&nbsp; But, unlike the Lord of the Rings (in which
all three were filmed at the same time) these are not yet written and the
future is unpredictable).</p>
	</div><!-- .entry-content -->

	
</article></div>]]>
            </description>
            <link>https://lantpritchett.org/there-is-only-one-poverty-strategy-broad-based-growth-part-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290383</guid>
            <pubDate>Sun, 28 Feb 2021 03:19:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Tree: React Aside from the UI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290183">thread link</a>) | @valand
<br/>
February 27, 2021 | https://valand.dev/blog/post/machine-tree-react | <a href="https://web.archive.org/web/*/https://valand.dev/blog/post/machine-tree-react">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Among a nauseatingly huge number of "modern web UI frameworks" out there, React stands tall. It is a very nimble library to write a JavaScript-based app on top of. React app code can stay way more clear, consistent, and recognizable regardless of complexity, compared to other frameworks. Why? Because unlike other frameworks, which are more of a template engine, React focuses on assisting to build an asynchronous machine tree.</p>
<p><em>Update:</em></p>
<ul>
<li><em>Looking forward for comments, feedback, etc. Do submit here <a href="https://news.ycombinator.com/item?id=26290183">HN</a>.</em></li>
</ul>
<figure>
<p><img src="https://valand.dev/d444d442389ff931c3a3b3f063043aba/opening.svg" alt="overview"></p>
<figcaption>React Webpage as of node tree</figcaption>
</figure>
<p>Illustrated above, on the right, a simple webpage. It contains a huge main section and three links on the left for the users to navigate between three pages. On the left is the visual of the React nodes that make up the simple web page. The nodes form a tree. Each node has one or more relationships to other nodes, which tells us a story:</p>
<p>This <code>App</code> has a <code>Router</code> that regulates the application routing system which affects everything below it. The page has <code>Sidebar</code> that has three <code>Link</code>s, and a <code>Main</code> section that renders a <code>Page</code>.</p>
<p>React works by enabling developers to compose <a href="https://reactjs.org/docs/components-and-props.html">React components</a> in the <a href="https://reactjs.org/docs/faq-internals.html">shape of a tree</a>. This tree-shaped composition is a hierarchy of mini machines. Each component, each machine, has its own domain/problem/concern/task.</p>
<figure>
<p><img src="https://valand.dev/440633a416591a2018205acb69e828d1/event-propagation.gif" alt="event-propagation"></p>
<figcaption>Event and effects chained into a flow</figcaption>
</figure>
<p>How does this work under the hood?</p>
<ul>
<li><code>Router</code> manages a state that describes what route it is now on and how it changes, and it affects every descendant of it. It provides its state and methods to its descendants.</li>
<li><code>Link</code> renders an element and listens to it for "click" events. If there's a "click", it notifies the nearest ancestor <code>Router</code> component via the method it passed.</li>
<li><code>Main</code> listens/subscribes to the nearest ancestor <code>Router</code>. Any change in the <code>Router</code>'s state causes <code>Main</code> to re-renders too.</li>
</ul>
<p><em>Note: Render is the term in React world equivalent to refreshing a component. It doesn't directly concern any GPU-related computation.</em></p>
<p>Those seem a lot for simple interaction, how is it easier in React?</p>
<p><strong>1) React automates spawning/despawning children</strong>. With this, you don't need to write "if [some condition] AND [Child is not spawned] then spawn Child". React simplifies this:</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>
</span><span>
</span><span>
</span><span>
</span><span>const</span><span> </span><span>Main</span><span> </span><span>=</span><span> </span><span>(</span><span>props</span><span>:</span><span> </span><span>{</span><span> </span><span>path</span><span>:</span><span> </span><span>string</span><span> </span><span>})</span><span> </span><span>=&gt;</span><span> </span><span>(
</span><span>  </span><span>&lt;&gt;</span><span>
</span><span>    </span><span>{</span><span>props</span><span>.</span><span>path</span><span> </span><span>===</span><span> </span><span>"/home"</span><span> </span><span>&amp;&amp;</span><span> </span><span>&lt;</span><span>HomePage</span><span> </span><span>/&gt;</span><span>}
</span><span>    </span><span>{</span><span>props</span><span>.</span><span>path</span><span> </span><span>===</span><span> </span><span>"/about"</span><span> </span><span>&amp;&amp;</span><span> </span><span>&lt;</span><span>AboutPage</span><span> </span><span>/&gt;</span><span>}
</span><span>    </span><span>{</span><span>props</span><span>.</span><span>path</span><span> </span><span>===</span><span> </span><span>"/contact-us"</span><span> </span><span>&amp;&amp;</span><span> </span><span>&lt;</span><span>ContactUsPage</span><span> </span><span>/&gt;</span><span>}
</span><span>  </span><span>&lt;/&gt;</span><span>
);</span></code></pre>
    </div>
<p>The above snippet declares that a certain condition causes a certain page to be shown, if path is <code>/home</code>, the component renders <code>HomePage</code>, and so on. The expression between the sign <code>{}</code> is a JavaScript expression.</p>
<p><code>Main</code> seems like a simple function, but because it is returning a <code>ReactNode</code> it can be a component. Once a component function is included in a render via <code>ReactDOM.render</code>, React creates a subroutine that manages components in a tree. The function above receives <code>path</code> as props. Props are values passed by the parent component into this component. When a prop changes, it will trigger a re-render. A re-render is when React calls this function again. How the props change though is not our concern for now.</p>
<p>If a render's result differs from the previous render's, maybe because of changing props, React will <a href="https://reactjs.org/docs/reconciliation.html">reconcile</a> the two return values. If both renders yield a child component, say, <code>HomePage</code> and <code>AboutPage</code>, the previous component, <code>HomePage</code> will be removed from the tree, and the new component <code>AboutPage</code> will replace it.</p>
<p>This is the famous declarative syntax of React people talking about.</p>
<p><em>Notes:</em></p>
<ul>
<li><em><code>&lt;&gt;</code> and <code>&lt;/&gt;</code> is a shorthand for <a href="https://reactjs.org/docs/fragments.html">React Fragment</a></em></li>
<li><em>Other than <code>props</code> change, <code>state</code> change and other dependencies (e.g. <a href="https://reactjs.org/docs/context.html">context</a>, <a href="https://reactjs.org/docs/refs-and-the-dom.html">ref</a>) change also cause rerender.</em></li>
</ul>
<p><strong>2) React provides free <a href="https://en.wikipedia.org/wiki/Dependency_injection">dependency injection</a> via <a href="https://reactjs.org/docs/context.html">context</a>.</strong> What is dependency injection? It is basically a technique to inject object/data/function as a dependency into another object. In React case the injection happens to a component. A component can specify that it needs a certain dependency and we can build an environment that can provide it. To be more specific, a <code>Link</code> component uses <code>Router</code> as a dependency to work. It needs access to a <code>Router</code> to tell that it is clicked and a change to a route is to be made. <code>Link</code> can be written like this:</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>const</span><span> </span><span>Link</span><span> </span><span>=</span><span> </span><span>(</span><span>props</span><span>:</span><span> </span><span>{</span><span> </span><span>to</span><span>:</span><span> </span><span>string</span><span>;</span><span> </span><span>children</span><span>:</span><span> </span><span>React</span><span>.</span><span>ReactNode</span><span> </span><span>})</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>const</span><span> </span><span>routerAPI</span><span> </span><span>=</span><span> </span><span>useContext</span><span>(</span><span>RouterAPIContext</span><span>);

</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>return</span><span> </span><span>(
</span><span>    </span><span>!!</span><span>routerAPI</span><span> </span><span>&amp;&amp;</span><span> </span><span>(
</span><span>      </span><span>&lt;</span><span>a</span><span>
</span><span>        </span><span>href</span><span>=</span><span>"#"</span><span>
</span><span>        </span><span>onClick</span><span>=</span><span>{(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>          </span><span>e</span><span>.</span><span>preventDefault</span><span>();</span><span> </span><span>
</span><span>          </span><span>routerAPI</span><span>.</span><span>push</span><span>(</span><span>props</span><span>.</span><span>to</span><span>);</span><span> </span><span>
</span><span>        </span><span>}}
</span><span>      </span><span>&gt;</span><span>
</span><span>        </span><span>{</span><span>children</span><span>}
</span><span>      </span><span>&lt;/</span><span>a</span><span>&gt;</span><span>
</span><span>    </span><span>)
</span><span>  </span><span>);
};</span></code></pre>
    </div>
<p>In the above snippet, Link uses <code>routerAPI</code>. Link also receives the props <code>to</code> and <code>children</code> from its parent component. As explained in point 1, if either <code>to</code>, <code>children</code> or <code>routerAPI</code> changes, the <code>Link</code> will be re-rendered. <code>Link</code> will be used/rendered like this:</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>const</span><span> </span><span>Sidebar</span><span> </span><span>=</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(
</span><span>    </span><span>&lt;</span><span>Link</span><span> </span><span>to</span><span>=</span><span>"/home"</span><span>&gt;</span><span>Home</span><span>&lt;/</span><span>Link</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Link</span><span> </span><span>to</span><span>=</span><span>"/about"</span><span>&gt;</span><span>About</span><span>&lt;/</span><span>Link</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Link</span><span> </span><span>to</span><span>=</span><span>"/contact-us"</span><span>&gt;</span><span>Contact Us</span><span>&lt;/</span><span>Link</span><span>&gt;</span><span>
);
</span><span>
</span></code></pre>
    </div>
<p>Also, let's change <code>Main</code> to use context so it doesn't need to be the child of <code>Router</code>. We need to introduce <code>Route</code> which uses <code>Router</code> too.</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>const</span><span> </span><span>Route</span><span> </span><span>=</span><span> </span><span>(</span><span>props</span><span>:</span><span> </span><span>{</span><span> </span><span>path</span><span>:</span><span> </span><span>string</span><span>;</span><span> </span><span>render</span><span>:</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>React</span><span>.</span><span>ReactNode</span><span> </span><span>})</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>const</span><span> </span><span>routerData</span><span> </span><span>=</span><span> </span><span>useContext</span><span>(</span><span>RouterDataContext</span><span>);
</span><span>  </span><span>
</span><span>  </span><span>return</span><span> </span><span>!!</span><span>routerData</span><span> </span><span>&amp;&amp;</span><span> </span><span>routerData</span><span>.</span><span>path</span><span> </span><span>===</span><span> </span><span>props</span><span>.</span><span>path</span><span> </span><span>?</span><span> </span><span>props</span><span>.</span><span>render</span><span>()</span><span> </span><span>:</span><span> </span><span>null</span><span>;
};

</span><span>const</span><span> </span><span>Main</span><span> </span><span>=</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(
</span><span>  </span><span>&lt;&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Route</span><span> </span><span>path</span><span>=</span><span>"/home"</span><span> </span><span>render</span><span>=</span><span>{()</span><span> </span><span>=&gt;</span><span> </span><span>&lt;</span><span>HomePage</span><span> </span><span>/&gt;</span><span>}</span><span> </span><span>/&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Route</span><span> </span><span>path</span><span>=</span><span>"/about"</span><span> </span><span>render</span><span>=</span><span>{()</span><span> </span><span>=&gt;</span><span> </span><span>&lt;</span><span>AboutPage</span><span> </span><span>/&gt;</span><span>}</span><span> </span><span>/&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Route</span><span> </span><span>path</span><span>=</span><span>"/contact-us"</span><span> </span><span>render</span><span>=</span><span>{()</span><span> </span><span>=&gt;</span><span> </span><span>&lt;</span><span>ContactUsPage</span><span> </span><span>/&gt;</span><span>}</span><span> </span><span>/&gt;</span><span>
</span><span>  </span><span>&lt;/&gt;</span><span>
);</span></code></pre>
    </div>
<p><strong>3) React allows internal states and asynchronous actions in the components.</strong> This is the main reason I see React components as machines. React provides the <a href="https://reactjs.org/docs/hooks-faq.html">functions <code>useState</code> and <code>useEffect</code></a> (or alternatively state attribute and lifecycle methods if <a href="https://reactjs.org/docs/components-and-props.html#function-and-class-components">class component style</a> is used) that allow a component to have its own lifecycle. We will use them to implement <code>Router</code> which is a simple routing "system" for the application.</p>
<p>Let's start with <code>Router</code>'s core functionality first. I will use React's new addition, <a href="https://reactjs.org/docs/hooks-intro.html">hooks</a>, to demonstrate the ease to compose logics in React. Writing hooks is just as simple as writing components, except, instead of returning <code>React.ReactNode</code>, they return whatever you need.</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>
</span><span>
</span><span>type</span><span> </span><span>RouterCoreAPI</span><span> </span><span>=</span><span> </span><span>{
</span><span>    </span><span>events</span><span>:</span><span> </span><span>{
</span><span>        </span><span>
</span><span>    	</span><span>pathChange</span><span>:</span><span> </span><span>TypedEvent</span><span>&lt;</span><span>null</span><span>&gt;</span><span>
</span><span>    </span><span>},
</span><span>    </span><span>path</span><span>:</span><span> </span><span>string</span><span>;
</span><span>    </span><span>push</span><span>:</span><span> </span><span>(</span><span>path</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>unknown</span><span>;
};
</span><span>const</span><span> </span><span>useRouterCoreAPI</span><span> </span><span>=</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>    </span><span>const</span><span> </span><span>[</span><span>core</span><span>,</span><span> </span><span>setCore</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>&lt;</span><span>null</span><span> </span><span>|</span><span> </span><span>RouterCoreAPI</span><span>&gt;</span><span>(</span><span>null</span><span>);
</span><span>    </span><span>useEffect</span><span>(()</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>		</span><span>
</span><span>        </span><span>const</span><span> </span><span>pathChange</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>TypedEvent</span><span>&lt;</span><span>null</span><span>&gt;</span><span>();
</span><span>        </span><span>const</span><span> </span><span>newCore</span><span>:</span><span> </span><span>RouterCoreAPI</span><span> </span><span>=</span><span> </span><span>{
</span><span>      		</span><span>events</span><span>:</span><span> </span><span>{</span><span> </span><span>pathChange</span><span>,</span><span> </span><span>},
</span><span>            </span><span>path</span><span>:</span><span> </span><span>""</span><span>,
</span><span>            </span><span>push</span><span>:</span><span> </span><span>(</span><span>newPath</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>                </span><span>newCore</span><span>.</span><span>path</span><span> </span><span>=</span><span> </span><span>newPath</span><span>;
</span><span>                </span><span>pathChange</span><span>.</span><span>emit</span><span>();
</span><span>            </span><span>},
</span><span>        </span><span>};
</span><span>        </span><span>setState</span><span>(</span><span>newCore</span><span>);</span><span>	</span><span>
</span><span>    </span><span>},</span><span> </span><span>[]);</span><span>					</span><span>
</span><span>	</span><span>return</span><span> </span><span>core</span><span>;
};

</span><span>
</span><span>type</span><span> </span><span>RouterData</span><span> </span><span>=</span><span> </span><span>{
</span><span>    </span><span>path</span><span>:</span><span> </span><span>string</span><span>;
};
</span><span>const</span><span> </span><span>useRouterData</span><span> </span><span>=</span><span> </span><span>(</span><span>core</span><span>:</span><span> </span><span>null</span><span> </span><span>|</span><span> </span><span>RouterCore</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> </span><span>setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>&lt;</span><span>null</span><span> </span><span>|</span><span> </span><span>RouterData</span><span>&gt;</span><span>;
</span><span>	</span><span>useEffect</span><span>(()</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>        </span><span>if</span><span> </span><span>(</span><span>!</span><span>core</span><span>)</span><span> </span><span>return</span><span>;</span><span>		</span><span>
</span><span>        </span><span>const</span><span> </span><span>unsub</span><span> </span><span>=</span><span> </span><span>core</span><span>.</span><span>events</span><span>.</span><span>pathChange</span><span>.</span><span>subscribe</span><span>(()</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>            </span><span>setState</span><span>({</span><span> </span><span>path</span><span>:</span><span> </span><span>core</span><span>.</span><span>path</span><span> </span><span>});
</span><span>        </span><span>});
</span><span>        </span><span>setState</span><span>({</span><span> </span><span>path</span><span>:</span><span> </span><span>core</span><span>.</span><span>path</span><span> </span><span>});

</span><span>        </span><span>
</span><span>        </span><span>
</span><span>        </span><span>
</span><span>        </span><span>return</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>            </span><span>unsub</span><span>();
</span><span>        </span><span>};
</span><span>    </span><span>},</span><span> </span><span>[</span><span>core</span><span>]);
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>return</span><span> </span><span>state</span><span>;
};</span></code></pre>
    </div>
<p>Now that the logic is established, let's use the logic in the <code>Router</code> component. <code>Router</code> is a component wrapper and a context provider so that it renders its <code>props.children</code> into it and API and data can be used by <code>Link</code> and <code>Route</code>.</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>
</span><span>const</span><span> </span><span>RouterAPIContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>&lt;</span><span>RouterCoreAPI</span><span>&gt;</span><span>(</span><span>null</span><span>);
</span><span>const</span><span> </span><span>RouterDataContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>&lt;</span><span>RouterData</span><span>&gt;</span><span>(</span><span>null</span><span>);
</span><span>const</span><span> </span><span>Router</span><span> </span><span>=</span><span> </span><span>({</span><span> </span><span>children</span><span> </span><span>}:</span><span> </span><span>{</span><span> </span><span>children</span><span>:</span><span> </span><span>React</span><span>.</span><span>ReactNode</span><span> </span><span>})</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>
</span><span>  </span><span>const</span><span> </span><span>coreAPI</span><span> </span><span>=</span><span> </span><span>useRouterCoreAPI</span><span>();
</span><span>  </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>useRouterData</span><span>(</span><span>coreAPI</span><span>);
</span><span>  </span><span>return</span><span> </span><span>(
</span><span>    </span><span>&lt;</span><span>RouterAPIContext</span><span> </span><span>value</span><span>=</span><span>{</span><span>coreAPI</span><span>}</span><span>&gt;</span><span>
</span><span>      </span><span>&lt;</span><span>RouterDataContext</span><span> </span><span>value</span><span>=</span><span>{</span><span>data</span><span>}</span><span>&gt;</span><span>{</span><span>children</span><span>}</span><span>&lt;/</span><span>RouterDataContext</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;/</span><span>RouterAPIContext</span><span>&gt;</span><span>
</span><span>  </span><span>);
};</span></code></pre>
    </div>
<p>Last let's use <code>Router</code> and other components to compose the whole app.</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>const</span><span> </span><span>App</span><span> </span><span>=</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(
</span><span>  </span><span>&lt;</span><span>Router</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Main</span><span> </span><span>/&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Sidebar</span><span> </span><span>/&gt;</span><span>
</span><span>  </span><span>&lt;/</span><span>Router</span><span>&gt;</span><span>
);</span></code></pre>
    </div>
<p>Look at that beautiful directive. It literally describes the architecture of the whole application.</p>
<p><em>Note: Using hooks in this particular case is unnecessary as it was for a demonstration of React's composability. Extracting logic to a hook is done usually because: 1.) The extracted part of the logic is reusable in other components, or 2.) the logic is simply too long and can be extracted without inciting semantic dissonance.</em></p>
<p><strong>4) React doesn't stray far from its host, JavaScript, and JavaScript VM.</strong> This point is an important and powerful concept in a library like React. JSX is a superset of JavaScript rather than another whole language. In consequence, writing React, with or without JSX/TSX, feels like writing JavaScript/TypeScript. If you pass a function as a prop in JSX, you write a JavaScript function.</p>
<p>In contrast, other web UI library such as Vue, Angular, or Svelte uses a separate templating language for its templating purpose. In Vue, for example, oftentimes you are required to write a <a href="https://vuejs.org/v2/guide/computed.html"><code>computed</code> function</a> to bridge a value in the Vue instance to the template. Meanwhile JSX's <code>&lt;ComponentName attribute={value}&gt;{childrenNode}&lt;/ComponentName&gt;</code> roughly translates to <code>React.createElement(ComponentName, { attribute: value }, [childrenNode])</code> with <code>key</code> attributes added on compile time.</p>
<p>Being a superset of JavaScript, JSX makes React many-folds more expressive and consistent to JavaScript than its competitors. Consistency keeps syntactical ambiguousness low, while expressiveness helps with productivity, enabling sentences to be written concisely, packing more dense meaning in shorter expressions.</p>
<p>Being a superset of JavaScript also allows compiler and IDE programmer to reuse existing JavaScript/TypeScript parser ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://valand.dev/blog/post/machine-tree-react">https://valand.dev/blog/post/machine-tree-react</a></em></p>]]>
            </description>
            <link>https://valand.dev/blog/post/machine-tree-react</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290183</guid>
            <pubDate>Sun, 28 Feb 2021 02:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before you buy a Soviet Camera]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290128">thread link</a>) | @brudgers
<br/>
February 27, 2021 | https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/ | <a href="https://web.archive.org/web/*/https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
 <!-- A generated by theme --> 



 <!-- end A --> 

<p><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web.jpg" alt="Drug and Zenit-3M cameras (Pic: Stephen Dowling)" width="2500" height="1633" srcset="https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web.jpg 2500w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-300x196.jpg 300w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1024x669.jpg 1024w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-768x502.jpg 768w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1536x1003.jpg 1536w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-2048x1338.jpg 2048w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-696x455.jpg 696w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1068x698.jpg 1068w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-643x420.jpg 643w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-600x392.jpg 600w" sizes="(max-width: 2500px) 100vw, 2500px"></p>
<p>It begins in October 1927, with a single camera exhibited in Moscow at an Exposition of Photographic Technique in the new Soviet capital, Moscow. Bostelman‚Äôs camera is a small 35mm camera with a simple, single-speed shutter and a winding key to advance the film. The camera‚Äôs back is removable, and removing it turns the rest of the camera into an enlarger which can be used to make prints.<span data-ez-name="kosmofoto_com-box-3"></span></p>
<p>It never makes it into production, but Bostelman‚Äôs simple snap-shooter is the first Soviet camera. What comes after this is first a trickle, and then a flood.</p>
<p>Fifty years later, and the Soviet camera industry is the second-largest in the world ‚Äì second only to Japan, whose bands such as Nikon, Canon, Minolta Olympus and Pentax have become household names. The Soviet Union has its own heavyweights, and between them they have churned out dozens and then hundreds of different camera designs as the decades tick by.</p>
<p>Thanks to a mix of espionage, war reparations, ingenious design and a desire to show the West a thing or two, the USSR‚Äôs camera makers come up with a Soviet answer to almost every camera type made in the West, though not necessarily at the same time. Soviet designers devised a myriad of different models, some of the brutishly simple, others showing real flair and ingenuity.</p>
<p>Odd, then, that the entirety of a photographic industry spread across the largest country ever formed and spanning more than 60 years can get judged off first impressions. In the last 20 years, I‚Äôve lost count of the number of times I‚Äôve seen people declaim the quality of all Soviet cameras based off a single flea-market <a href="https://kosmofoto.com/2018/12/zenit-e-russian-camera-review/">Zenit-E</a> which might have mouldering in someone‚Äôs basement for the last 30 years.<span data-ez-name="kosmofoto_com-medrectangle-4"></span></p>
<p>This is something I‚Äôve learned having spent the last 20 years collecting and using Soviet cameras. The first one I came across was a Soviet-era <a href="https://kosmofoto.com/2017/06/lomo-lc-a-cameras-lc-wide-lca-120/">Lomo LC-A</a> compact in a camera shop in London‚Äôs West End; a solid black rectangle with surprising heft and exotic Cyrillic lettering. That Lomo sparked an enduring love for film cameras of all shapes and sizes, and a particular interest in those made behind the Iron Curtain.</p>
<p>In New Zealand, where I grew up, Soviet cameras were almost unknown. But that wasn‚Äôt the case in Western Europe. The boom years of the Soviet photographic industry during the Cold War coincided with a new age of prosperity and consumerism west of Berlin. More people had the money and time to travel, and they wanted cameras with which to document it. The Soviet Union wanted hard currency and had a smorgasbord of cameras that could be sold at subsidised prices. Along with the Praktica cameras of East Germany‚Äôs vast Pentacon, Soviet cameras appealed to a huge swathe of photographers with a limited budget.</p>
<figure id="attachment_24709" aria-describedby="caption-attachment-24709"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C.jpg" alt="Zorki-3C (Pic: Paulo Moreira)" width="1000" height="713" srcset="https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C.jpg 1000w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-300x214.jpg 300w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-768x548.jpg 768w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-696x496.jpg 696w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-589x420.jpg 589w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-100x70.jpg?crop=1 100w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-600x428.jpg 600w" sizes="(max-width: 1000px) 100vw, 1000px"><figcaption id="caption-attachment-24709">The Zorki-3C is typical of Soviet rangefinder design from the 1950s and 60s (Pic: Paulo Moreira)</figcaption></figure>
<p><span data-ez-name="kosmofoto_com-box-4"></span>This article ‚Äì and it‚Äôs a big one, so get a drink handy ‚Äì is an attempt to dispel some of the myths that have developed around Soviet cameras, especially since the 1990s. It‚Äôs not trying to pretend that it‚Äôs only politics got in the way of the USSR‚Äôs cameras, and that every Zenit and Zorki is a match for a Nikon or a Leica. Some of the horror stories you might have heard about Soviet camera quality are 100% true. But not every Soviet camera is a lemon, and some are capable of taking fantastic images if you take the trouble to learn their strengths and, yes, their weaknesses.</p>

<h4><span id="The_big_five"></span><strong>The big five</strong><span></span></h4>
<p>But first, a little history.</p>
<p>The Soviet camera industry was dominated by five big names: <a href="http://camera-wiki.org/wiki/KMZ"><strong>KMZ</strong></a> (<em>Krasnogorskiy Mechanicheskiy Zavod</em>) in Moscow, <a href="https://en.wikipedia.org/wiki/LOMO"><strong>Lomo</strong></a> in St Petersburg, <a href="https://en.wikipedia.org/wiki/Kiev_(brand)"><strong>Kiev-Arsenal</strong></a> and <a href="https://en.wikipedia.org/wiki/FED_(camera)"><strong>FED</strong></a> in Ukraine and <a href="https://vintagecameralab.com/brand/mmz/"><strong>MMZ</strong></a> (the home of BelOMO) in what is now Belarus. Some of these bureaus concentrated on one particular style of camera ‚Äì FED, for instance, became known for Leica-copy rangefinders they started making in the 1930s and they were kept in production until almost the end of the Soviet Union itself.</p>
<p><a href="https://ko-fi.com/Z8Z2KH28" target="_blank" rel="noopener"><img src="https://az743702.vo.msecnd.net/cdn/kofi2.png?v=0" alt="Buy Me a Coffee at ko-fi.com" height="36"></a> <em>Found this guide useful? Please add a contribution via Ko-Fi. You‚Äôll help pay for the site‚Äôs hosting and make sure Kosmo Foto is free to read for years to come.</em></p>
<p>The cameras created ranged from rudimentary compacts simple enough for children to ambitious designs intended to compete with the very best the West had to offer. The latter were a kind of photographic soft power ‚Äì with no internal market to pay top dollar for them, the higher-spec cameras were touted as evidence of Soviet ingenuity and engineering prowess</p>
<figure id="attachment_22492" aria-describedby="caption-attachment-22492"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2018/12/zenite4-e1590396414210.jpg" alt="Zenit-e (Pic: Stephen Dowling)" width="2000" height="1500"><figcaption id="caption-attachment-22492">The Zenit-E is the most-produced 35mm SLR in history (Pic: Stephen Dowling)</figcaption></figure>
<p>Much simpler cameras were made in Soviet industrial quantities: million after million. This model became the dominant one from the mid 1970s. Camera designers were no longer urged to make cameras to compete with the best of the West, but to tweak tried-and-trusted designs a little each time. You can see this in the successive designs that came after the ubiquitous Zenit-E SLR and Lomo‚Äôs simple <a href="https://en.wikipedia.org/wiki/Smena_(camera)">Smena viewfinder camera</a>. Despite cosmetic changes on the outside, underneath little changed from camera to camera.</p>
<p>A leading Soviet camera collector named Viktor Suglob recently produced a Russian-language book called ‚Äò<a href="http://ussrphoto.com/Wiki/default.asp?WikiCatID=39&amp;ParentID=4&amp;ContentID=311&amp;Item=1200+Cameras+from+USSR+by+Suglob%2C+Shaternik%2C+Kochergin">1200 Soviet Cameras</a>‚Äô, an encyclopaedia of almost every prototype and production camera devised over nearly 75 years of the USSR. Many of these, of course, were never produced beyond a few samples or pre-production models. But hundreds of designs did make it into production. Today, millions of these cameras ‚Äì from KMZ and Lomo, MMZ and FED ‚Äì still survive in working condition.</p>
<h4><span id="The_major_models"></span><strong>The major models</strong><span></span></h4>
<p>If you‚Äôre curious about Soviet cameras, you‚Äôll find the easily available cameras falling into seven main groups:<span data-ez-name="kosmofoto_com-large-leaderboard-2"></span></p>
<ul>
<li><strong>Leica copy rangefinders:</strong> Mostly made by FED in Kharkiv in the Ukraine and under the ‚ÄúZorki‚Äù name from KMZ in Moscow. These cameras use the same <a href="https://camerapedia.fandom.com/wiki/39mm_screw_lenses">L39 screw mount</a> that Leica rangefinders did up until the mid-1950s. These cameras were produced, in various forms, until the early 1990s.</li>
<li><strong>Contax-style rangefinders:</strong> The Kiev brand started out copying the Contax II rangefinder produced in Germany before the war, initially with Contax parts taken as war reparations. The ‚Äú<a href="http://camera-wiki.org/wiki/Kiev_rangefinder">Kiev Contax</a>‚Äù line of cameras was made until the late 1980s</li>
<li><strong>Zenit SLRs:</strong> KMZ produced the Soviet Union‚Äôs widest array of SLR cameras under the Zenit name. The earliest versions were little more than a <a href="https://en.wikipedia.org/wiki/Zorki_1">Zorki rangefinder</a> with a reflex prism attached, but the line grew more popular in the late 1960s with the Zenit-E, the first Soviet SLR to use the M42-screw mount. M42 Zenits were made until the early 2000s, and a narrower range of cameras from the mid-1980s until the mid-2000s used the Pentax K mount. Lomo, and Kiev also produced SLRs, but these are far less common.</li>
<li><strong>Simple viewfinder cameras:</strong> Both Lomo in St Petersburg and MMZ in Minsk produced very similar families of snapshooters, rectangular viewfinder cameras with a simple shutter and a three-element glass lens. MMZ‚Äôs were called <a href="https://camerapedia.fandom.com/wiki/Vilia">Vilia</a> and Lomo‚Äôs were known as Smenas. Just two Smenas ‚Äì the <a href="https://kosmofoto.com/2020/03/these-are-the-most-produced-35mm-cameras-of-all-time/">Smena-8 and the 8M</a> ‚Äì were built to the tune of around 21 million, making them the most-produced 35mm cameras of all time. These cameras are cheap and rudimentary, but their glass lens definitely elevate them out of toy camera territory.</li>
<li><strong>Simple TLRs:</strong> Medium format cameras were not produced in the same breadth and scale as 35mm cameras, but there were still some successful models. The <a href="https://en.wikipedia.org/wiki/Lubitel">Lubitel family</a> of cheap 120-format TLRs are the easiest to find. Built out of plastic but with glass Triplet-style lenses, these Lomo-made cameras were produced from the 1940s until after the fall of the Soviet Union.</li>
<li><strong>Medium format SLRs:</strong> The Soviet Union‚Äôs equivalent to the <a href="https://www.japancamerahunter.com/2019/04/camera-geekery-pentax-67/">Pentax 67</a> was the <a href="https://vintagecameradigest.wordpress.com/2016/09/08/the-kiev-6c-a-photographic-artifact-of-the-cold-war/">Kiev-6C</a>, which eventually evolved into the <a href="http://mattsclassiccameras.com/slr/kiev-60/">Kiev-60</a>. These are big, heavy SLR cameras with a rougher finish than their Western counterparts but with a range of very well-regarded lenses.</li>
<li><strong>Hasselblad-style medium-format cameras: </strong>The Kiev factory also produced a series of Hasselblad-style focal plane cameras, the Kiev-80 and <a href="http://camera-wiki.org/wiki/Kiev_88">88</a> being the best-known of them. The lenses made for the Kiev-6/60 were also produced for some versions of this camera range. They are cheap ‚Äì especially compared to Hasselblads ‚Äì but they don‚Äôt come with a great reputation for reliability.</li>
</ul>
<p>There were many other brands and minor camera ranges made in the USSR (the plucky Lomo LC-A compact spawned a movement in photography all on its own), but these are the main ones. They are all reasonably easy to find ‚Äì very easy in the case of Zenit SLRS and FED rangefinders ‚Äì and there‚Äôs no shortage of spare parts or repairers that can coax them back to life should anything be wrong.</p>
<p>Kosmo Foto released the video below last year as a guide for common models to investigate:</p>
<p><iframe src="https://www.youtube.com/embed/wGlfbl5Oa_k" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h4><span id="Better_dead_than_Red"></span><strong>Better dead than Red?</strong><span></span></h4>
<p>Make no mistake ‚Äì many film camera shooters regard Soviet cameras as uniformally awful, junk that should live in a landfill rather than a camera cabinet. Most of these photographers would sooner cut off a limb than handle a clunky Zenit or Zorki.</p>
<p>But the Soviet camera industry had peaks and troughs ‚Äì periods when construction and quality control were high and times when standards were lax and reliability low. A Soviet rangefinder from the mid-1950s is from a very different system to one produced in the ‚ÄúYear of Stagnation‚Äù of the late 1970s.</p>
<figure id="attachment_21874" aria-describedby="caption-attachment-21874"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder.jpg" alt="Zorki 1 (Pic: Paulo Moreira)" width="1840" height="1840" srcset="https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder.jpg 1840w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-300x300.jpg 300w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1024x1024.jpg 1024w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-150x150.jpg 150w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-768x768.jpg 768w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1536x1536.jpg 1536w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-696x696.jpg 696w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1068x1068.jpg 1068w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-420x420.jpg 420w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-600x600.jpg 600w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-100x100.jpg 100w" sizes="(max-width: 1840px) 100vw, 1840px"><figcaption id="caption-attachment-21874">The Zorki 1, fitted here with an external turret finder for different lenses (Pic: Paulo Moreira)</figcaption></figure>
<p>The bad reputation which Soviet cameras isn‚Äôt undeserved,‚Äù says Jay Javier, the Filipino photographer and camera collector behind the <a href="https://www.fedka.com/jay/">Fed Zorki Survival Site</a>. ‚ÄúMany were really badly designed or made. As these creatures become more known, thanks to the internet, the bad ones get to be publicly shamed and justly avoided. Many of the generalisations in this respect turn out to be valid.‚Äù</p>
<p>Soviet quality control, especially in later years, sometimes left a lot to be desired. Cameras leaving the factory were supposed to be inspected and given a passport signed by a factory foreman ensuring they were working correctly. This The older ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/">https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/</a></em></p>]]>
            </description>
            <link>https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290128</guid>
            <pubDate>Sun, 28 Feb 2021 02:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How fighting games use delay-based and rollback netcode (2019)]]>
            </title>
            <description>
<![CDATA[
Score 284 | Comments 103 (<a href="https://news.ycombinator.com/item?id=26289933">thread link</a>) | @Kinrany
<br/>
February 27, 2021 | https://ki.infil.net/w02-netcode.html | <a href="https://web.archive.org/web/*/https://ki.infil.net/w02-netcode.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<div>
					<div id="content">

						<!-- Content -->
					
							<article>

								<div>
								
								<div>
								<p><a href="https://ki.infil.net/words.html">
								<img src="https://ki.infil.net/images/words/header.gif"></a>
								
								</p></div>
								
								
								
								
								<hr>
								
								<div>
								
								<div>
								<p>Netcode</p>
								<p>Explaining how fighting games use delay-based and rollback netcode</p>
								<p>October 16, 2019</p>
								
								
								
								
								</div>
								
								</div>
							
								
								<!-- blog navigation -->
								
								
								

								<div>
								<div><p>
								<em>I would like to thank <a href="https://twitter.com/Krazhier">krazhier</a> and <a href="https://twitter.com/TheKeits">Keits</a> for taking hours out of their busy schedules to discuss technical aspects of netcode with me, and <a href="https://twitter.com/Sajam">Sajam</a> for taking time to answer interview questions and being supportive throughout the writing process. I would also like to especially thank <a href="https://twitter.com/MagicMoste">MagicMoste</a> for making all the wonderful videos you see in this article. All their help was offered for free and I am thankful for their friendship.
								</em></p><p><em>

								This article has been <a href="https://arstechnica.com/gaming/2019/10/explaining-how-fighting-games-use-delay-based-and-rollback-netcode/">cross-posted on Ars Technica</a>.
								</em></p><p><em>

								You may also enjoy <a href="https://www.youtube.com/watch?v=1RI5scXYhK0">watching a video feature</a> on the topics in this article.
								</em>							
								</p></div>
								</div>

								
															
								<!-- Infil -->
								<div><p><img src="https://ki.infil.net/images/words/infil_smiling_2.jpg"></p>
								<p>
								Welcome back to Fightin‚Äô Words! It‚Äôs been a while since we last discussed how the <a href="https://ki.infil.net/w01-bugs.html">most famous fighting game bugs</a> have impacted the community‚Äôs favorite games. Today‚Äôs topic is a bit more technical, but it‚Äôs an equally important factor in how our favorite modern games are played -- we‚Äôre going to be doing a <strong>deep dive into netcode</strong>.								
								</p>
								</div>

								<hr><!-- Infil -->
								<div><p><img src="https://ki.infil.net/images/words/infil_lecture.jpg"></p>
								<div><p>
								At its core, netcode is simply a method for two or more computers, each trying to play the same game, to talk to each other over the internet. While local play always ensures that all player inputs arrive and are processed at the same time, <strong>networks are constantly unstable</strong> in ways the game cannot control or predict. Information sent to your opponent may be delayed, arrive out of order, or become lost entirely depending on dozens of factors, including the physical distance to your opponent, if you‚Äôre on a WiFi connection, and whether your roommate is watching Netflix.
								</p><p>
								Online play in games is nothing new, but fighting games have their own set of unique challenges. They tend to involve direct connections to other players, unlike many other popular game genres, and <strong>low, consistent latency</strong> is extremely important because muscle memory and reactions are at the core of virtually every fighting game. As a result, two prominent strategies have emerged for playing fighting games online: <strong>delay-based netcode</strong> and <strong>rollback netcode</strong>. 
								</p></div>
								</div>

								<div><p><img src="https://ki.infil.net/images/words/infil_thoughtful.jpg"></p>
								<div><p>
								There‚Äôs been a renewed passion in the fighting game community that <strong>rollback is the best choice</strong>, and fighting game developers who <a href="https://www.youtube.com/watch?v=qW61xJNJ9m8">choose to use delay-based netcode</a> are <a href="https://www.youtube.com/watch?v=iTUtnclr2hs">preventing the growth of the genre</a>. While people have been passionate about this topic <a href="https://www.youtube.com/watch?v=Tu2kAdmUCaI&amp;t=42m34s">for many years</a>, frustrations continue to rise as new, otherwise excellent games repeatedly have bad online experiences.
								</p><p>

								There are relatively few easy-to-follow explanations for what exactly rollback netcode is, how it works, and why it is so good at hiding the effects of bad connections (though <a href="http://mauve.mizuumi.net/2012/07/05/understanding-fighting-game-networking.html">there are some</a>). Because I feel this topic is extremely important for the future health of the fighting game community, I want to help squash some misconceptions about netcode and explain both netcode strategies thoroughly so everyone can be informed as they discuss. If you stick around to the end, I‚Äôll even <strong>interview some industry experts and community leaders</strong> on the topic!
								</p><p>
								Before we dig into the details, though, let‚Äôs get one thing straight.
										
								</p></div>
								</div>

								<hr><!-- Infil -->
								<!-- header -->
								

								<div><p><img src="https://ki.infil.net/images/words/infil_smiling_3.jpg"></p>
								<div><p>
										Both companies and players should care about good netcode because <strong>playing online is no longer the future -- it's the present</strong>. 
								</p><p>
										While most other video game genres have been this way for a decade or longer, fighting game developers seem to be resistant to embracing online play, perhaps because of the genre‚Äôs roots in offline settings such as arcades and tournaments. Playing offline is great, and it will always have considerable value in fighting games, but it‚Äôs simply a reality that <strong>a large percentage of the player base will never play offline</strong>. For many fighting game fans, playing online <em>is</em> the game, and a bad online experience prevents them from getting better, playing or recommending the game to their friends, and ultimately causes them to <a href="https://youtu.be/iTUtnclr2hs?t=758">simply go do something else</a>.
								</p><p>
										Even if you think you have a good connection, or live in an area of the world with robust internet infrastructure, good netcode is still mandatory. Plus, lost or delayed information happens regularly even on the best networks, and poor netcode can <a href="https://twitter.com/john_takeuchi/status/1162562266027327488">actively hamper matches</a> no matter how smooth the conditions may be. Good netcode also has the benefit of connecting regions across greater distances, effectively uniting the global player base as much as possible.

										<!-- gif 1A -->
										</p><div><!-- image -->
											<figure>
												
											<figcaption>Bad netcode can ruin matches. This match, played online between two Japanese players, impacted who gets to attend the Capcom Pro Tour finals. <a href="https://twitter.com/john_takeuchi/status/1162562266027327488">(source)</a>
											</figcaption></figure></div>
										
								</div>
								</div>

								<div><p><img src="https://ki.infil.net/images/words/infil_content.jpg"></p>
								<div><p>
										What about those who never play online because they much prefer playing offline with their friends? The <strong>healthy ecosystem</strong> that good netcode creates around a game benefits everyone. There will be more active players, more chances to consume content for your favorite game -- from tech videos to spectating online tournaments to expanding the strategy of lesser-used characters -- and more excitement surrounding your game in the FGC. Despite <a href="http://ki.infil.net/">Killer Instinct</a>‚Äôs pedigree as an excellent game, there‚Äôs no doubt that its superb rollback netcode has played a huge part in the sustained growth of its community.
								</p><p>

										Good netcode matters, period. So let‚Äôs talk about it.
										
								</p></div>
								</div>
								
								
								<!-- blog navigation -->
								
								
								

								</div>
								
							</article>
				
					</div>
				</div>
			</section></div>]]>
            </description>
            <link>https://ki.infil.net/w02-netcode.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26289933</guid>
            <pubDate>Sun, 28 Feb 2021 01:47:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We‚Äôre switching to TMDB as the primary data source for TV shows]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26289694">thread link</a>) | @cprecioso
<br/>
February 27, 2021 | https://blog.trakt.tv/tmdb-transition-ef3d19a5cf24 | <a href="https://web.archive.org/web/*/https://blog.trakt.tv/tmdb-transition-ef3d19a5cf24">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p><a href="https://medium.com/@trakt?source=post_page-----ef3d19a5cf24--------------------------------" rel="noopener"><img alt="Trakt.tv" src="https://miro.medium.com/fit/c/96/96/1*r3Oe6V2xRiOo9zlLIByGXA.png" width="48" height="48"></a></p></div></div></div></div><p id="d9fe">After several months of internal discussion, we are announcing our plans to use <a href="https://themoviedb.org/" rel="noopener"><strong>TMDB</strong></a> as the primary data source for all TV shows. The quality and completeness of data has greatly improved at TMDB over the years and we think with some re-alignment of community resources, it can work really well as Trakt‚Äôs primary TV data source.</p><p id="4e87">What it really boils down to is a moral opposition to taking in data from a community and then trying to sell it back to them. We believe when a user contributes to an online data source, they mean for that work to be shared with everyone around them. Both TMDB and Trakt have open and free APIs for developers to build upon that hard work.</p><p id="fded">TVDB is enforcing a commercial paid model to get access to their community moderated data. The first option is a commercial agreement with an app directly, but we‚Äôve heard TVDB is asking for unrealistic licensing fees compared to an app‚Äôs revenue. The second option is charging users directly to access TVDB data. That doesn‚Äôt really work either, since that means an app is dependent on users paying a 3rd party service to work.</p><ol><li id="938a">New TV shows are imported using TMDB as their data source <em>(all new shows since November 2020 already use TMDB)</em></li><li id="5713">When we do nightly data refreshes, we compare TMDB with TVDB to determine if the seasons and episodes match up. <em>(we‚Äôve gathered data on over 20,000 shows since November 2020)</em></li><li id="9fe3">We created a <a href="https://trakt.tv/transition/tmdb/updates" rel="noopener"><strong>comparison page</strong></a> for TMDB and TVDB data. This helps determine what data is missing or needs to be updated at TMDB.</li><li id="70cd">If shows 100% match up, we will automatically change to TMDB as the data source. We‚Äôre also working on tools to help Trakt users verify and indicate a show can be switched to TMDB. <em>(this will happen soon)</em></li></ol><p id="ac2a">Many of you help moderate TVDB and TMDB, and we can‚Äôt thank you enough for doing that! It helps Trakt and the thousands of other apps that use metadata from both sources.</p><p id="e53b">We need your help to ensure TMDB data is complete and ready for the transition. This means keeping TV shows updated with new episodes as they air and backfilling old shows with incomplete seasons and episodes.</p><blockquote><p id="474d">Please read the <a href="https://www.themoviedb.org/bible" rel="noopener"><strong>TMDB Contribution Bible</strong></a> and follow all the rules for contributing data. Our goal isn‚Äôt to simply replicate TVDB data over, but rather update TMDB using their rules and standards. Some Trakt TV shows will need to be manually adjusted to match TMDB, we can handle that in <a href="https://support.trakt.tv/" rel="noopener"><strong>Trakt support</strong></a>.</p></blockquote><p id="06e6">The <a href="https://trakt.tv/transition/tmdb/updates" rel="noopener"><strong>comparison page</strong></a><strong> </strong>helps visualize TMDB and TVDB data to determine what is missing or different. Green rows indicate a 100% match of the episode count, air dates, and titles. Blue rows indicate the episode count matches, but there might be differences in air date or title. Red rows indicate the episode count doesn't match. Click the + to expand a season to see individual episode info. All of these are linked to TMDB and TVDB as well, so you can quickly jump to those databases.</p></div></div><div><div><p id="4dc0">Thanks again for all your help with the TMDB transition and moderating data over there. We really appreciate it!</p><p id="86ec">‚Äî Trakt</p></div></div></div>]]>
            </description>
            <link>https://blog.trakt.tv/tmdb-transition-ef3d19a5cf24</link>
            <guid isPermaLink="false">hacker-news-small-sites-26289694</guid>
            <pubDate>Sun, 28 Feb 2021 00:59:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‚ÄúGood Enough‚Äù Architecture]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26289677">thread link</a>) | @zwliew
<br/>
February 27, 2021 | https://mrh.io/notes/stefan-tilkov-good-enough-architecture/ | <a href="https://web.archive.org/web/*/https://mrh.io/notes/stefan-tilkov-good-enough-architecture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Adaptive Leadership for Technical Projects</strong></p><div><div><div><dl><dt><span role="img" aria-label="">üåå </span><a href="https://github.com/orbitdb/orbit-db" target="_blank">OrbitDB</a></dt><dd>P2P databases for the distributed web, build on CRDTs</dd><dt><span role="img" aria-label="">ü¶Ä </span><a href="https://github.com/ipfs-rust/rust-ipfs" target="_blank">Rust IPFS</a></dt><dd>A Rust implementation of the Interplanetary File System</dd></dl></div><div><dl><dt><span role="img" aria-label="">üìà </span><a href="https://tallylab.com/" target="_blank">TallyLab</a></dt><dd>A privacy-first, end-to-end encrypted time-series data platform</dd><dt><span role="img" aria-label="">‚öì </span><a href="https://github.com/hackforthesea/2020" target="_blank">Hack for the Sea</a></dt><dd>An annual hackathon where technology and the ocean meet.</dd></dl></div></div></div><p><small>This website does not track you.<br>The best way to reach out is via <a href="mailto:mark@mrh.io">e-mail</a>.</small></p><div><h2>by Stefan Tilkov</h2><p>April 01, 2020<!-- --> ÔΩú <span><a href="https://mrh.io/notes/tags/talk%20notes">Talk Notes</a><span>, </span></span><span><a href="https://mrh.io/notes/tags/goto%202019">GOTO 2019</a><span>, </span></span><span><a href="https://mrh.io/notes/tags/stefan%20tilkov">Stefan Tilkov</a><span>, </span></span><span><a href="https://mrh.io/notes/tags/software%20architecture">Software Architecture</a><span>, </span></span><span><a href="https://mrh.io/notes/tags/microservices">Microservices</a></span></p><div><p> <iframe src="https://www.youtube.com/embed/PzEox3szeRc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </p>
<center>
<p><a href="https://mrh.io/notes/stefan-tilkov-good-enough-architecture/@stilkov">@ stilkov</a> |
<a href="https://files.gotocon.com/uploads/slides/conference_16/846/original/2019-10-23-Good-Enough-Architecture--GOTO.pdf">slides</a> |
<a href="https://www.youtube.com/watch?v=PzEox3szeRc">video</a></p>
</center>
<p><strong>Abstract:</strong> In this session, we‚Äôll take a look at some of the ways we can determine whether the development efforts we‚Äôre undertaking suffer from too much or too little focus on architecture. We‚Äôll examine a number of real-world examples that are intended to inspire either admiration or terror, and try to find some recipes of how we can get more of the former and less of the latter in our own projects.</p>
<hr>
<h2>Definitions of Architecture</h2>
<p><a href="http://www.iso-architecture.org/ieee-1471/cm/">ISO/IEC/IEEE 42010</a>:</p>
<blockquote>
<p>Fundamental concepts or properties of a system in its environment embodied in its elements, relationships, and in the principles of its design and evolution</p>
</blockquote>
<p><a href="https://handbookofsoftwarearchitecture.com/">Grady Booch</a>:</p>
<blockquote>
<p>Architecture represents the significant design decisions that shape a system, where significant is measured by <em>cost of change</em></p>
</blockquote>
<p>Stefan Tilkov:</p>
<blockquote>
<p>Whatever the architect considers important enough to merit their attention</p>
</blockquote>
<p><span>
      <a href="https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/d43b4/software-scaling-dimensions.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Graph of software scaling dimensions" title="Graph of software scaling dimensions" src="https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/fcda8/software-scaling-dimensions.png" srcset="https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/12f09/software-scaling-dimensions.png 148w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/e4a3f/software-scaling-dimensions.png 295w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/fcda8/software-scaling-dimensions.png 590w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/efc66/software-scaling-dimensions.png 885w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/c83ae/software-scaling-dimensions.png 1180w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/d43b4/software-scaling-dimensions.png 1202w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p><em>Different organizations and applications will require different architectures, and those architectures will change over time</em></p>
<h2>Cases:</h2>
<h3>#1 Non-Extensible Extensibility</h3>
<p>Highly customizable multi-tenant e-commerce solution with lots of features, which has to balance between large customers with specific needs and small customers with generic needs</p>
<ul>
<li>If you attempt to design something that satisfies everybody, you will satisfy nobody.</li>
<li>Highly specific is often preferable to generic</li>
</ul>
<h3>#2 Perilously fine-grained</h3>
<p>Large-scale B2B food retailer building a new logistics system, hired &gt;200 developers to build a microservice-based system. Each developer ‚Äúowned‚Äù
a microservice, which was hell to scale. Eventually moved away from ‚ÄòEntityService‚Äô pattern</p>
<ul>
<li>Everybody wants to be <a href="https://www.youtube.com/watch?v=CZ3wIuvmHeM">Netflix</a> but nobody is</li>
<li>Small is not always beautiful</li>
<li>Refactoring within team boundaries much easier than globally</li>
<li>Ignore organizational parameters at your own risk</li>
</ul>
<h3>#3 Your system WILL be dynamic</h3>
<p>Large-scale insurance system with &gt;100 developers. 2 releases / year with 2-week modeling period  What if you miss this slot?</p>
<ul>
<li>Centralized responsibility hurts</li>
<li>Faces with too much rigidity, a way around the rules will be found</li>
<li>Just because you‚Äôre used to it doesn‚Äôt make it acceptable</li>
</ul>
<h3>#4 Free-style Architecture</h3>
<p>A small E-Commerce / Online shop which grew fast to 100-120 developers over ~10 self-contained teams</p>
<ul>
<li>Avoid increasing the numbers of developers if you can</li>
<li>Move to system of systems</li>
<li>If you don‚Äôt actively create an architecture, be prepared to deal with the one that emerges.</li>
<li>Loose coupling requires very few rules, but they need to be enforced strictly</li>
</ul>
<p><span>
      <a href="https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/fe8a7/strength-of-decoupling.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Strength of decoupling" title="Strength of decoupling" src="https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/fcda8/strength-of-decoupling.png" srcset="https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/12f09/strength-of-decoupling.png 148w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/e4a3f/strength-of-decoupling.png 295w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/fcda8/strength-of-decoupling.png 590w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/efc66/strength-of-decoupling.png 885w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/c83ae/strength-of-decoupling.png 1180w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/fe8a7/strength-of-decoupling.png 1223w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>#5 Cancerous Growth</h3>
<p>Financial services provider with independent brokers as clients, 20 years of company history. Spun off new company and just copied system and then <em>shared the database</em>. Also implemented own encryption in Borland C++ and noticed bug after encryption own database</p>
<ul>
<li>Successful systems often end up with the worst architecture</li>
<li>Unmanaged evolution will lead to complete chaos</li>
<li>Don‚Äôt be afraid of some light architectural governance</li>
</ul>
<h3>#6 Improve with less intelligence</h3>
<p>Bank with multiple CotS systems, phased out proprietary solution to replace with OSS. Replaced ‚ÄúMagical Integration Broker‚Äù with much more simple dockerized pubsub solution.</p>
<ul>
<li><a href="https://martinfowler.com/articles/microservices.html">Smart endpoints, dumb pipes</a> AKA never put too much logic or intelligence into infrastructure</li>
<li>Valuespecific over generic solutions</li>
</ul>
<h2>Final Takeaways</h2>
<ol>
<li>Don‚Äôt be afraid of architecture</li>
<li>Choose the simplest thing that will work</li>
<li>Create evolvable structures</li>
<li>Manage your system‚Äôs architectural evolution</li>
<li>Don‚Äôt create road blocks - create value and get out of the way</li>
</ol>
<p>Have a talk you want to see notes on? E-mail <a href="mailto:mark@mrh.io">mark@mrh.io</a></p></div><hr><ul><li><a rel="prev" href="https://mrh.io/ipfs-private-networks/">‚Üê <!-- -->Private IPFS Networks</a></li><li><a rel="next" href="https://mrh.io/notes/interledger/">Notes: Interledger Architecture<!-- --> ‚Üí</a></li></ul></div></div></div>]]>
            </description>
            <link>https://mrh.io/notes/stefan-tilkov-good-enough-architecture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26289677</guid>
            <pubDate>Sun, 28 Feb 2021 00:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Core Memory]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26289605">thread link</a>) | @pabs3
<br/>
February 27, 2021 | https://www.samanthashorey.com/makingcorememory | <a href="https://web.archive.org/web/*/https://www.samanthashorey.com/makingcorememory">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="canvasWrapper">
    <div id="canvas">

      

      

      <div id="pageWrapper" role="main">
        <!-- CATEGORY NAV -->
        
      <section id="page">

      <div data-content-field="main-content">
        <div data-type="page" data-updated-on="1607643977625" id="page-59c182ce32601e072c30b9bb"><div><div><div data-aspect-ratio="38.49315068493151" data-block-type="5" id="block-67138688d8acffe4284a"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/594ac3f44c8b03cd3f4c3f07/1505864612072-VCZ9JG0PAMSKRECBWCHG/ke17ZwdGBToddI8pDm48kMyX43o3HznWzvVjR9Preul7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mhydAgiKdIfeAoxVgE7c7okPoKA5uALweq0Eh5ZSPFNMZ1UtBwwVjWySAS2xzp0KQ/SIGCIS_film__002.JPG" data-image="https://images.squarespace-cdn.com/content/v1/594ac3f44c8b03cd3f4c3f07/1505864612072-VCZ9JG0PAMSKRECBWCHG/ke17ZwdGBToddI8pDm48kMyX43o3HznWzvVjR9Preul7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0mhydAgiKdIfeAoxVgE7c7okPoKA5uALweq0Eh5ZSPFNMZ1UtBwwVjWySAS2xzp0KQ/SIGCIS_film__002.JPG" data-image-dimensions="2500x1657" data-image-focal-point="0.5,0.5" alt="SIGCIS_film__002.JPG" data-load="false" data-image-id="59c1ab9cbce176b201419323" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-0d1d7901a22b66a1bffb"><div><h3>The Weaving Workshops</h3><p>The Making Core Memory workshop engages public audiences in reimagining how technology is made. Participants are given a "patch kit" that contains a chipboard loom, yarn and plastic beads in place of the wire and ferrite cores used in core memory manufacturing. Together, we collaboratively enact the core memory weaving process‚Äîenlivening the work of the "Little Old Ladies" (as the Apollo Engineers called them) who put man on the moon.&nbsp;</p><p><strong>You can access a free toolkit for hosting your own workshop at </strong><a href="https://www.makingcorememory.org/"><strong>makingcorememory.org!</strong></a></p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_25_1505943129830_60656"><p>Making Core Memory was <strong>awarded the one of the ‚Äúbest of show‚Äù Making and Doing Exhibition</strong> awards at the 2019 conference for the Social Studies of the Sciences (4S). You can see a little bit about our project here (at the 1minute mark):</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1598822243202_15327"><div><h3>The Core Memory Quilt</h3><p>The Making Core Memory Quilt is an interactive textile that plays &amp; tweets historical audio about the women who made the hardware for the Apollo moon missions. Each square of the quilt contains a unique recording of Apollo engineers, which can be "unlocked" through placing one of the completed patches from the weaving workshop on the quilt.&nbsp;The Making Core Memory Quilt was sewn by master quilter, Helen Remick, using fabric and conductive thread.</p></div></div></div></div></div>
      </div>

      

      </section>
      </div>

    </div>
  </div></div>]]>
            </description>
            <link>https://www.samanthashorey.com/makingcorememory</link>
            <guid isPermaLink="false">hacker-news-small-sites-26289605</guid>
            <pubDate>Sun, 28 Feb 2021 00:40:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview: Instance Aware Image Colorization]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26289381">thread link</a>) | @aaossa
<br/>
February 27, 2021 | https://wandb.ai/wandb/instacolorization/reports/Overview-Instance-Aware-Image-Colorization---VmlldzoyOTk3MDI | <a href="https://web.archive.org/web/*/https://wandb.ai/wandb/instacolorization/reports/Overview-Instance-Aware-Image-Colorization---VmlldzoyOTk3MDI">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wandb.ai/wandb/instacolorization/reports/Overview-Instance-Aware-Image-Colorization---VmlldzoyOTk3MDI</link>
            <guid isPermaLink="false">hacker-news-small-sites-26289381</guid>
            <pubDate>Sun, 28 Feb 2021 00:06:50 GMT</pubDate>
        </item>
    </channel>
</rss>
