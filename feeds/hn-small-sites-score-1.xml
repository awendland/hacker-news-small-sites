<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 01 Mar 2021 12:40:56 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 01 Mar 2021 12:40:56 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A Java Exceptions must read guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26283573">thread link</a>) | @backstageel
<br/>
February 27, 2021 | https://techblog.hostmoz.net/en/when-things-go-wrong-please-dont-make-em-worst-java-exceptions-must-read-guide/ | <a href="https://web.archive.org/web/*/https://techblog.hostmoz.net/en/when-things-go-wrong-please-dont-make-em-worst-java-exceptions-must-read-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  					<p>I think the first thing we should discuss is: what is an exception. In a short definition: an exception is a notification of an execution error occurrence.</p>
<p>What kind of errors can occur: programming errors and system failure.</p>
<p>Wait! How is a programming error different from a system failure? Let me explain: A programming error is an error that could have been avoided with a little more attention, an error that can only be resolved by a programmer. Why? Because the error is his fault. I’ll give you a clear example of this: every time the <strong>NullPointerException</strong> is thrown, is because you didn’t check if the object instance was null before you use it. Isn’t it? That’s a programming error. Programming errors in java are defined as <strong>Unchecked Exceptions</strong>. Java does not obligate you to catch this kind of exceptions. Why? Cause you can avoid them by programming correctly or with more attention and discipline.</p>
<p>On the other hand, a system failure error is a non programming error that is stopping the system from reaching a goal. For example: we are inserting a record into a database and suddenly an <strong>SQLException</strong> is thrown by the <strong>Statement</strong> object, notifying us that the connection to the database was lost due to network problem. The connection loss is not a programming error, you couldn’t have avoided it. These kind of exceptions are denominated <strong>Checked Exceptions</strong> in Java.</p>
<p>Now that we agree on what exceptions are, lets get back to the headline of this post : <strong>When things go wrong, please don’t make em worst</strong>.</p>
<p>What was the point here?</p>
<p>Look, an exception is a notification of something bad. What I was trying to say is: act correctly when you receive that notification. Don’t ignore it, you will make it worst. But what do I mean by “don’t ignore it”? To be more specific, first: never have empty catch blocks like that one on the cover picture of this post.</p>
<p>When you catch an exception, you are supposed to do something about it and not just hide it. Why? “Why do I have to do something about it?”. I can hear you. Let me make it clear for you once and for all:</p>
<ol>
<li>An exception is an indication of a bad thing</li>
<li>Bad things should not happen repeatedly on reliable systems</li>
<li>We have to avoid the occurrence of bad things, reduce them.</li>
<li>To reduce the occurrence of bad things we have first to know that they happened.</li>
</ol>
<p>I will repeat the number 4: <strong>To reduce the occurrence of bad things we have first to know that they happened</strong>. If you wrap your exceptions in an empty catch block, you will never know they happened and you will never ever have a reliable system. You have to let the others know. It should not be something you keep in secret. If you don’t want to do something about it, just don’t catch it, make you method throw it or re-throw it inside your catch block (usually a bad practice).</p>
<p>What is the best way of letting the people know that something bad happened (an exception was thrown)?</p>
<p>A log file. Logging the errors makes it easier for anyone to know that something bad happened. Why a log file? Why don’t I just call the ex.printStackTrace()? Printing the stack trace on your console will show the error to you while you still programming and running tests, but what if someone comes and closes the console or the console just quits? What if you want to run your application on a remote server? How will you be able to detect the bad things without the console? A log file is your best shot. You might not use a file, use a database, anything, just log it.</p>
<p>Wait MJ. You want me to log every single exception I catch? I say: Log every exception that will help you improve your system or detect an anomaly. Don’t log exceptions because I told you to. Log them after understanding the value it will add.</p>
<h3>Log and keep quiet?</h3>
<p>Remember that exception are thrown by methods. If a method catches an exception that it finds interesting to log, then it logs it. It doesn’t mean you log it and keep quiet. Tell the method that called your method that something went wrong: re-throw the exception or wrap it in another.</p>
<p>I keep saying “Wrap it” or “Re-throw” and you might be asking yourself what the hell each of that things mean? Wrapping an exception means to create an exception of another type, set the current exception as its cause and them throw it . Why would you wrap an exception? For abstraction and separation of concerns. If for example you have a DAO class that inserts records into a database using <strong>JDBC</strong>: your DAO methods should not throw the <strong>SQLException</strong>, they should throw a different kind of exception. Why? Because one day your DAO can stop using JDBC, meaning it wont throw the <strong>SQLException</strong> anymore, so, You have to create your own exception type and wrap the original cause when throwing the exception. Congratulations, you just met the so called “<strong>abstraction</strong>“. Re-throwing an exception on the other hand, means to throw the same exception instance inside a catch block.</p>
<p>How do you create your own programming exception? you create a class that extends java.lang.RuntimeException (programmer will not be forced to catch). To create a non programming exception (programmer will be forced to catch) you create a class that extends java.lang.Exception.</p>
<p>How do you throw an Exception without having to create your own class?</p>
<p><img loading="lazy" src="https://media-exp1.licdn.com/dms/image/C4E12AQEpEj1UYHU8PQ/article-inline_image-shrink_1000_1488/0/1520423999442?e=1619654400&amp;v=beta&amp;t=75xWngiFGQdcDINjacFDLSkUYYr0x4CvH0_ysDu4AmQ" width="1312" height="922"></p>
<p>Well, this works: you have encapsulated the original exception (as I said you should), but you have created a problem. Before I explain the problem, <strong>be AWARE THAT THIS APPROACH IS A BAD PRACTICE AND SHOULD BE AVOIDED</strong>. You method throws an Exception of type java.lang.Exception. It means that the caller of your method will catch a java.lang.Exception. If the money is not enough, the caller has to give the user a chance to change the amount, if there is another problem, the caller has to give the user a chance to try again. This raises one question: How is the caller going to distinguish the two kinds of exceptions if they are the same (java.lang.Exception)? The obvious answer here is “USING The message”. Now ask yourself how comfortable is that?<strong> Remember:</strong> you should write less and do more and keep the code clear and easy to understand. That is definitely not the best way of doing any of that.</p>
<h3>Creating your own exception types</h3>
<p>To solve it correctly we should create 2 classes. One class that extends java.lang.Exception, and one class that extends our new class: <strong>OperationException</strong>, <strong>NoEnoughMoneyException</strong> (extends OperationException). How do we use them?</p>
<p><img loading="lazy" src="https://media-exp1.licdn.com/dms/image/C4D12AQEVBkOiCF3jqw/article-inline_image-shrink_1000_1488/0/1520147344540?e=1619654400&amp;v=beta&amp;t=yYqEL3-kczeQGUNwlXREl81bJ6l7RB5WDSv6-U61ytI" width="1376" height="946"></p>
<p>Its looking awesome now, isn’t it? But how how is the caller supposed to distinguish the exceptions? That’s one of the reasons why we made that change, so, lets see:</p>
<p><img loading="lazy" src="https://media-exp1.licdn.com/dms/image/C4D12AQFlaDYMN43EDw/article-inline_image-shrink_1000_1488/0/1520170287777?e=1619654400&amp;v=beta&amp;t=r4jhVMqnoVM5oxWNu-uUGx5HBUqXm-zVxCPPnW1lLSs" width="1328" height="746"></p>
<p>Can you see how easy it was to verify the type of the exception? That’s why you should adopt that practice (Assuming you said yes :)).</p>
<h3>Things you should take in consideration when creating your own exception classes.</h3>
<ol>
<li>The more detailed the exception is, the more helpful it becomes. Be careful, if it becomes too much informative it might also not help and might actually not be informative (My GOD this is so paradoxal).</li>
<li>Exceptions are classes, so, be free to add custom attributes</li>
<li>You can set the exception message on the exception class (internally), making it possible avoiding to pass a message every time you want to throw it.</li>
</ol>
<p>This it too much for a single POST, don’t you think? What am I thinking? Why didn’t I split this is in two or more posts? Because this is web content, meaning you can stop reading anywhere and come back to it anytime. You see? You are the problematic here. :). Just kidding.</p>
<p>Lets discuss one last thing before I rest in peace (its 12 AM now).</p>
<p>Do you remember the transferMoney method? Of course you do! Great!Imagine if one of the two parameters you receive is null. What should you do?</p>
<p>What Iam asking you, is how should the method react to things like this: transferMoney (null,null,-1000);</p>
<p>Please don’t tell me we should create a new type of a exception! Why? Because java already comes with exceptions to help us handle this kind of situations. It’s a pleasure for me to introduce you the <strong>NullPointerException</strong> and <strong>IllegalArgumentException.</strong> Please be polite “say nice to meet you”. But You already know these guys, they have been bothering you since you define yourself has a java programmer.</p>
<p>Lets cut to the chase, how are we supposed to use them?</p>
<p><img loading="lazy" src="https://media-exp1.licdn.com/dms/image/C4D12AQEF6052CVZcwA/article-inline_image-shrink_1000_1488/0/1520172052326?e=1619654400&amp;v=beta&amp;t=NyFomrXtH07VOPyPb6dfjOGBMnIQ6lMFELABBaoZwZA" width="1312" height="874"></p>
<p>If for some reason you are considering to catch these exception at the moment you call that method, please forget it. Burry that idea and burn its origin (don’t burn you head). You should do your best to never let none of this exceptions show up. How are u supposed to do that? Check if the Account objects are not null before you call the method and check if the amount is valid before you call the method. If these exceptions show up, you haven’t done your job correctly, remember, these are programming errors, the java language does not require you to catch them. These two exception types (NullPointerException and IllegalArgumentException) extend the class RuntimeException that extends Exception. Every child class of RuntimeException is an unchecked exception, meaning that you are not forced to catch it. When you call a method, you should make sure a RuntineException never shows up. When you write your own method, you should make sure a bad programmers gets them. You got me!</p>
<p>There is more to be told, but, I’m a human being and I appreciate my bed. It never throws an Exception.</p>
<p>It’s always a pleasure.</p>
<p>MJ</p>

<p>(Visited 845 times, 845 visits today)</p>
  					
				<!-- Ad post below -->
					 			 </div></div>]]>
            </description>
            <link>https://techblog.hostmoz.net/en/when-things-go-wrong-please-dont-make-em-worst-java-exceptions-must-read-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26283573</guid>
            <pubDate>Sat, 27 Feb 2021 08:47:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ZSA Moonlander: a $365 ergonomic keyboard]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26283418">thread link</a>) | @giuliomagnifico
<br/>
February 26, 2021 | https://www.zsa.io/moonlander | <a href="https://web.archive.org/web/*/https://www.zsa.io/moonlander">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><strong>Ergonomic:</strong> Type at shoulder width, reassign keys, tilt and tent it.</p><p><strong>Mechanical:</strong> For the most enjoyable typing experience.</p><p><strong>Dynamic:</strong> Adjust the angle of the whole keyboard, or just the thumb cluster.</p><p><strong>Portable:</strong> Folds into a compact package. Carrying case included.</p><p><strong>Gamer-friendly:</strong> Plug in just the left side to get your game on.</p><p><strong>Built to last:</strong> Backed by a solid two-year warranty.<!-- --> <br>No fine print.</p></div></div></div></div>]]>
            </description>
            <link>https://www.zsa.io/moonlander</link>
            <guid isPermaLink="false">hacker-news-small-sites-26283418</guid>
            <pubDate>Sat, 27 Feb 2021 07:59:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Bupstash Garbage Collector]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26282771">thread link</a>) | @andrewchambers
<br/>
February 26, 2021 | https://acha.ninja/blog/the_bupstash_garbage_collector/ | <a href="https://web.archive.org/web/*/https://acha.ninja/blog/the_bupstash_garbage_collector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<h2 id="overview">Overview</h2>
<p>My backup tool <a href="https://github.com/andrewchambers/bupstash">bupstash</a> stores backups in a repository as an evergrowing set of
encrypted data trees which use content addressing and structural sharing
to deduplicate data. In order to delete unused backups we need to do something very similar to how
many programming languages free unreferenced memory - garbage collection. This post will
explain the evolution and implementation of the garbage collector in bupstash for the curious.</p>
<h2 id="stop-mark-and-sweep">Stop, mark and sweep.</h2>
<p>The initial version of the bupstash garbage collector was a naive stop-the-world
garbage collector. It walks all backup data trees creating a set of reachable data chunks
by address and then deletes unreachable data.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Stop the world.</li>
<li>Mark.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>lock_repository()
reachable_addresses = empty_set()

for data_tree in all_backups():
  
  work_list = new_work_list_from_backup(data_tree.root_address)
  
  until work_list.is_empty():
    
    node_height, node_address = work_list.pop()
    reachable_addresses.add(node_address)
    
    if node_height != 0:
      add_child_nodes_to_worklist(work_list, node_address)

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><p>This algorithm is short and sweet, but if the repository is very large our repository becomes unavailable
for a potentially long time. The next version shortens the downtime of the repository significantly.</p>
<h2 id="mark-stop-mark-and-sweep">Mark, stop, mark and sweep.</h2>
<p>The bupstash v0.6.4 garbage collector takes advantage of two facts:</p>
<ul>
<li>Because many backups share data with each other, we can memoize the walk phase to skip work.</li>
<li>Because backups are immutable while the repository is unlocked, we can walk most of them without
stopping the world.</li>
</ul>
<p>This time we walk the repository without the repository locked, then lock it and walk
the repository again using our memoization to quickly complete the job. If any new backups
appeared during our first walk, we are guaranteed to mark them now that the repository lock is held. Doing the majority of the slow mark phase without locking the repository greatly increases
the repository availability for other operations.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Memoized mark repository.</li>
<li>Stop the world.</li>
<li>Memoized mark repository.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>walked_trees = empty_set()
reachable_addresses = empty_set()

func walk_repository():

  for data_tree in all_backups():

    if walked_trees.has(data_tree):
      continue

    walked_trees.add(data_tree)
    
    work_list = new_work_list_from_backup(data_tree.root_address)
    
    until work_list.is_empty():
      
      node_height, node_address = work_list.pop()
      already_walked = reachable_addresses.has(node_address)
      reachable_addresses.add(node_address)
      
      if node_height != 0 and not already_walked:
        add_child_nodes_to_worklist(work_list, node_address)

walk_repository()
lock_repository()
walk_repository()

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><h2 id="mark-stop-mark-bloom-adjust-and-sweep">Mark, stop, mark, bloom adjust, and sweep</h2>
<p>The next version of the garbage collector is a WIP unreleased version.</p>
<p>In bupstash each data chunk address is 32 bytes, which means we need at least 32 bytes of RAM per chunk in the repository to successfully perform a garbage collection. For a repository containing a 100 million chunks or
more this could easily exhaust memory on a busy or small system.</p>
<p>If we are willing to accept a very low probability of retaining some extra data, we can reduce this down
to a few <em>bits</em> per chunk reducing memory usage by 64x or more.
To do this we use a probabilistic data structure called a <a href="https://en.wikipedia.org/wiki/Bloom_filter">bloom filter</a> to track reachable addresses.</p>
<p>Bloom filters have two downsides:</p>
<ul>
<li>They can have false positives. For us this means we might keep a data chunk by accident we could have actually freed.</li>
<li>We must presize them. They cannot grow if we got the size wrong.</li>
</ul>
<p>Luckily for us these downsides are not bad:</p>
<ul>
<li>Because memory use is so low per address, we can generously size our bloom filter reducing false positives to less than one percent, even for large repositories.</li>
<li>We can easily detect when a bloom filter gets overly full and produces many false positives, and thus adjust it’s size for future garbage collections.</li>
</ul>
<p>As a bonus, the bupstash implementation of a bloom filter is actually simpler than a hash table, with the implemenation
weighing in at around 30 lines of code plus tests and helpers.</p>
<p>The algorithm can be described as:</p>
<ul>
<li>Memoized mark repository.</li>
<li>Stop the world.</li>
<li>Memoized mark the repository.</li>
<li>Adjust bloom filter size.</li>
<li>Sweep.</li>
<li>Restart the world.</li>
</ul>
<p>Here is the pseudo code:</p>
<pre><code>walked_trees = empty_set()
walked_addresses = empty_cache()
reachable_addresses = empty_bloom_filter(repository_bloom_size())

func walk_repository():

  for data_tree in all_backups():

    if walked_trees.has(data_tree):
      continue

    walked_trees.add(data_tree)
    work_list = new_work_list_from_backup(data_tree.root_address)
    
    until work_list.is_empty():
      
      node_height, node_address = work_list.pop()
      already_walked = walked_addresses.has(node_address)
      reachable_addresses.add(node_address)
      walked_addresses.add(node_address)
      
      if node_height != 0 and not already_walked:
        add_child_nodes_to_worklist(work_list, node_address)

walk_repository()
lock_repository()
walk_repository()

if bloom_filter_overutilized(reachable_addresses):
  increase_bloom_filter_size_for_next_gc()
else if bloom_filter_underutilized(reachable_addresses):
  decrease_bloom_filter_size_for_next_gc()

for chunk_address in repository:
  if not reachable_addresses.has(chunk_address):
    delete_chunk(chunk_address)

unlock_repository()
</code></pre><p>One thing to note about this implementation is that because the bloom filter has false positives we can not use it to skip processing addresses, instead
we must introduce a new cache for this purpose. A cache also lets us put a fixed upper bound on memory usage for large repositories.</p>
<p>Overall for large repositories, the addition of a bloom filter reduces ram requirements from the gigabyte range down to tens of megabytes while increasing the repository size by only a fraction of a percent.</p>

<p>The bupstash garbage collector tries hard to keep the repository avaliable as long
as possible while also providing excellent performance with a small memory profile. If you are implementing
a content addressed storage system, this post will hopefully provide you with some new ideas.</p>
<p>In the future bupstash could follow the same path as programming language garbage collectors to find more improvements:</p>
<ul>
<li>Parallelism in the mark phase.</li>
<li>Parallelism in the sweep phase.</li>
<li>Incremental collection.</li>
<li>Object generations.</li>
<li>Write barriers</li>
<li>Yet to be invented techniques…</li>
</ul>
<p>As always, thanks for reading and please feel free to give <a href="https://github.com/andrewchambers/bupstash">bupstash</a> a try.</p>

			</div></div>]]>
            </description>
            <link>https://acha.ninja/blog/the_bupstash_garbage_collector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282771</guid>
            <pubDate>Sat, 27 Feb 2021 04:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do farmers have the right to repair their own equipment?]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 34 (<a href="https://news.ycombinator.com/item?id=26282642">thread link</a>) | @curmudgeon22
<br/>
February 26, 2021 | https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/ | <a href="https://web.archive.org/web/*/https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><span><span>Reading Time: </span> <span>5</span> <span>minutes</span></span></p><p>It’s a story that’s becoming more and more common.</p>
<p>You’re smack dab in the middle of harvest and an error code appears on your combine’s monitor. A call to the dealership results in a long wait for a technician to come out, with anxiety rising with every passing hour because priceless harvesting time is being lost or, worse, nasty weather is moving in.</p>
<p>Then when the technician gets to your farm, he determines what is needed is to reset (or ‘flash’) the onboard computer.</p>
<p>That happened to Cole Siegle last fall when he was harvesting canola, leaving the Fairview-area producer to wonder why he can’t have access to the same diagnostic tools.</p>
<div id="attachment_133445"><p><img loading="lazy" src="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied-150x150.jpg" alt="" width="150" height="150" srcset="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied-150x150.jpg 150w, https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120509/repair-rights1-siegle-supplied.jpg 300w" sizes="(max-width: 150px) 100vw, 150px"></p><p>Cole Siegle.<br><small><i>photo:</i><span> Supplied </span></small></p></div>
<p>“If I could have done that myself or been able to use a mechanic or a technician who’s closer to me, our downtime could have gone from six hours to two hours,” he said. “That four hours could have been the difference between getting&nbsp;a crop off before the snow or not.”</p>
<p>But these days it’s dealerships — via sales and service agreements with manufacturers — that have legal access to these diagnostic tools. So when an error message pops up, farmers and independent mechanics are out in the cold, sometimes literally.</p>

<ul>
<li><strong>Read more: <a href="https://www.albertafarmexpress.ca/news/connectivity-grey-under-new-trade-agreement/">Connectivity ‘grey’ under new trade agreement</a></strong></li>
<li><strong>Read more: <a href="https://www.albertafarmexpress.ca/news/remote-diagnostics-blocked-by-poor-internet-on-farms/">Remote diagnostics blocked by poor internet on farms</a></strong></li>

</ul>
<p>“As a producer I think we need access to these diagnostic tools,” said Siegle. “If (manufacturers) want to continue to build equipment like this that’s fine, but we need access to the laptops with the programs that we can plug into our equipment so we can buy whatever part we need.”</p>
<p>Equipment manufacturers make a lot of repair information public, including what codes mean, but giving access to proprietary tools raises several issues, said John Schmeiser, CEO of the Western Equipment Dealers Association.</p>
<p>The hardware and software Siegle and other farmers wish to acquire for repair purposes can also be used to modify equipment to the detriment of machinery, warranties, the lawfulness of their operations and even their own safety, he said.</p>
<p>“I applaud the manufacturers that put a lot of stuff online&nbsp;like parts, service manuals and operational guides. But it’s a slippery slope,” said Schmeiser.</p>
<p>“When you provide special tools to somebody outside a controlled environment like the manufacturer/dealer&nbsp;relationship, that opens the door for illegal modification. They lose that control when they provide&nbsp;diagnostic or special tools to a third-party retailer with whom they don’t have the same sales and services agreement.”</p>
<h2>Repair versus modify</h2>
<p>‘Right to repair’ is a term being thrown around a lot in ag circles today, but it means different things to different people.</p>
<p>For Siegle and other like-minded producers, it means the right to either repair equipment themselves or hire an unaffiliated local mechanic — just as farmers have done throughout the history of mechanized agriculture.</p>
<div id="attachment_133446"><p><img loading="lazy" src="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn-150x150.jpg" alt="" width="150" height="150" srcset="https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn-150x150.jpg 150w, https://static.albertafarmexpress.ca/wp-content/uploads/2021/02/22120516/SchmeiserJohn.jpg 300w" sizes="(max-width: 150px) 100vw, 150px"></p><p>John Schmeiser.<br><small><i>photo:</i><span> Supplied </span></small></p></div>
<p>But Schmeiser argues that farmers’ right to repair is already entrenched in law in many jurisdictions (including Alberta) as long as the owner is using the equipment for its intended purpose and doesn’t violate manufacturer standards.</p>
<p>The right to repair (R2R) movement (which started in the tech sphere but expanded to other areas, such as ag equipment) is actually a front for promoting the ‘right to modify,’ he said.</p>
<p>Often that means making modifications to bypass environmental controls in order to boost vehicle horsepower.</p>

<p>“There are over 25 states that had R2R bills introduced — every one impacting farm equipment has been defeated,” said Schmeiser. “They haven’t passed&nbsp;because as the state representatives were hearing the rationale coming from R2R advocates, they were finding out that what they were really looking for is to modify the equipment in a manner where&nbsp;it can get around emission standards and violate U.S. Environmental Protection Agency laws and regulations.”</p>
<h2>DEF delete and chipping</h2>
<p>There are two specific actions that concern Schmeiser’s association (a Missouri-based advocacy group for equipment dealerships with a Canadian headquarters in Calgary).</p>
<p>One is circumventing Diesel Exhaust Fluid (or DEF) emissions systems using grey-market ‘DEF delete’ kits to boost horsepower on tractors and combines. Another is ‘chipping’ or ‘tuning,’ which usually refers to adding a specific chip to increase horsepower.</p>
<p>Bypassing emissions control systems contravenes the Canadian Environmental Protection Act, leaving producers open to fines, said Schmeiser, adding he was unsure of the Canadian penalties but breaches of similar U.S. laws have produced fines in excess of $300,000.</p>
<p>Part of the problem is that not everyone knows this practice is illegal. Another is it comes with a host of potential risks including damaged equipment, voided warranties, reduced trade-in value, insurance cancellation and even safety, he said.</p>
<p>“We have seen an unusual number of combine fires this (past) year,” said Schmeiser.</p>
<p>“Now, we have had some dry conditions but in some of those cases the combines were running hotter (due to alterations).</p>

<p>“The insurance company will look at it from the standpoint that you have altered your combine away from the manufacturer’s original standards and you are going to be denied insurance coverage in a situation like that.”</p>
<p>But Siegle isn’t convinced.</p>
<p>He said he has no interest in making such modifications to his equipment and suggested it’s a straw man argument from manufacturing and dealership interests seeking exclusive control over the diagnostic tools.</p>
<p>The kind of modification Siegle is concerned about losing is the legal ability to place, for example, a third-party manufacturer’s custom header on a John Deere combine. Specifically, he worries about big manufacturers denying third-party companies the codes required for an implement to interact with a tractor or combine.</p>
<p>Schmeiser said this isn’t considered modification but rather interoperability or connectivity: A third party designing an implement to attach to another manufacturer’s product. This is a long-standing tradition in the manufacturing and dealership industries that few if anyone has any interest in ceasing, he said (see accompanying story).</p>
<h2>The business aspect</h2>
<p>All of this still does not answer Siegle’s fundamental question: Why can’t I — or mechanics unaffiliated with specific manufacturers — have all the tools required to diagnose and fix a mechanical problem?</p>
<p>In the past it was relatively easy for mechanically minded producers and unaffiliated mechanics to repair machinery because it ran on tried-and-traditional engineering principles. This is still by and large the case, said Schmeiser, adding 95 per cent of equipment issues can still be fixed mechanically.</p>
<p>He said he understands the frustration farmers feel by not having diagnostic tools at their fingertips. But at the same time dealerships have rights as well, especially when one considers the considerable training and expense needed to obtain service contracts with manufacturers.</p>
<p>“What the farmer is speaking to is the frustration of being down. He wants to get up and running as quickly as possible. We get that,” said Schmeiser.</p>
<p>“But the moment the manufacturers start providing special tools or diagnostics&nbsp;equipment to businesses that are outside of their dealer contracts, doesn’t that diminish the value of the contract in the dealer’s eyes as well?… So what’s the incentive for the manufacturer&nbsp;to provide special tools or even service manuals to a third party that would be competing with somebody they have a contractual relationship with&nbsp;(and) who is also making a substantial financial investment to be the representative for the manufacturer?”</p> </div>
</div></div>]]>
            </description>
            <link>https://www.albertafarmexpress.ca/news/do-farmers-have-the-right-to-repair-their-own-equipment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282642</guid>
            <pubDate>Sat, 27 Feb 2021 04:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Assembly Language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26282634">thread link</a>) | @swolchok
<br/>
February 26, 2021 | https://wolchok.org/posts/how-to-read-assembly-language/ | <a href="https://web.archive.org/web/*/https://wolchok.org/posts/how-to-read-assembly-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Why, in 2021, does anyone need to learn about assembly language?
First, reading assembly language is the way to know <em>exactly</em> what
your program is doing. Why, <em>exactly</em>, is that C++ program 1 MiB (say)
instead of 100 KiB? Is it possible to squeeze some more performance
out of that function that gets called all the time?</p><p>For C++ in particular, it is easy to forget or just not notice some
operation (e.g., an implicit conversion or a call to a copy
constructor or destructor) that is implied by the source code and
language semantics, but not spelled out explicitly. Looking at the
assembly generated by the compiler puts everything in plain sight.</p><p>Second, the more practical reason: so far, posts on this blog haven’t
required an understanding of assembly language, despite constant
links to <a href="https://godbolt.org/">Compiler Explorer</a>. By <a href="https://twitter.com/ScottWolchok/status/1361022423399755776">popular
demand</a>,
however, our next topic will be parameter passing, and for that, we
will need a basic understanding of assembly language. We will focus
only on <em>reading</em> assembly language, not writing it.</p><p>The basic unit of assembly language is the <strong>instruction</strong>. Each
machine instruction is a small operation, like adding two numbers,
loading some data from memory, jumping to another memory location
(like the dreaded <a href="https://en.wikipedia.org/wiki/Goto">goto</a>
statement), or calling or returning from a function. (The x86
architecture has <a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer">lots of not-so-small
instructions</a>
as well. Some of these are <a href="https://stackoverflow.com/questions/5959890/enter-vs-push-ebp-mov-ebp-esp-sub-esp-imm-and-leave-vs-mov-esp-ebp">legacy
cruft</a>
built up over the 40-odd years of the architecture’s existence, and
others are <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">newfangled
additions</a>. )</p><p>Our first toy example will get us acquainted with simple
instructions. It just calculates the square of the
<a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">norm</a>
of a 2D vector:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
    <span>int64_t</span> z;
};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and here is the resulting x86_64 assembly from clang 11, <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEAGYADKS3oAMnlqYAcsYBGmYiADspAA6oFQnVaPUMTcyt/QLU6e0cXI3dPHyUVGNoGAmZiAlDjU0tFZUxVYMzsgjjnNw9vRSycvPDChQbKh2rE2q8ASkVUA2JkDgByKTMHZEMsAGpxMx1kVvx6eexxCwBBDc3W4gNVGYA1Esk5r1ktmeuZhwIANm4AfQIZgA95y82b2/pHl5mAE9PuIvAAREFbHZ3f6vWgkIwMACOBmymHQEBOyDOADceucvj9iJgCINaDMcQA6N4zABUFOpcxkDMBdJZkO24JGfVYIBGAFYRqRTCMLELUHydHI5DMFAMhpgmWZOEKCHyxT0%2BgBrcxmSlmA2Go1G%2B5CPncIUisWkCUjIUKEBWNWi7mkOCwJBoIy%2BPDsMgUCBen1%2BlDCUScTgWTikKi%2BggeB0QVzqoWuBzZQF8lWkL1GLQEADytFYmZdpCwRhEwHYKfLeGJpRxmAdZcwbxKBnjWaFd2U3aEeFcxAzeiw/YIxDwRm7fRo9CYbA4PH4gjDYmlMgHrgdkD6qF86RbAFoC2YZkflvMwRIZHJJNbUiV0pptE1TNGbFUEklBFEgnQ31/AJ/1oL8ak8aNH1KOhykafR8kEKD0lg9p4nAxC2kAyC2jAroIL6OVBmGLgeT5QVhVrW03gADnuI9HhmKYqxmCNKQsSlOBmCBcEIEglWjGY9G9X0PH4/EpVvGRVRTTVSB1A19WNJSDVNXkRgtCiy1te1HVIZ0NTdGBEBQVBhL9chKCDETPCY8NI2jWNWHjYhE2TMs01oDN%2B1zfMixLWsKyrGsy3wBs1CbFtrTbDsuxGbNezU61WEHYdiEBUdRmtCcpxnGM6EYFga2XARJCEKsUA3eRku3eA9wPYJj1Pc9LzMa9Kvve1img0wIBsLDrG0XCf2jP90n60bgiG2pIK65DMPg8IZrSMocI6b9pvqCp%2BtaCopvw/oiKXUiBUtSi%2BRouiGNs4AWM4NiOK4niiGIfjSEE0zg1E8ZJHEyrpJdWT5L1ZTlLNdTTq0vkdKdGTjskCHrW0vTYdIJsXOCEBuCAA%3D%3D">via Compiler Explorer</a>:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><div><pre><code data-lang="asm">        <span>imulq</span>   %rdi, %rdi
        <span>imulq</span>   %rsi, %rsi
        <span>leaq</span>    (%rsi,%rdi), %rax
        <span>retq</span>
</code></pre></div><p>Let’s talk about that first instruction: <code>imulq %rdi, %rdi</code>. This
instruction <a href="https://www.felixcloutier.com/x86/imul">performs signed integer
multiplication</a>. The <code>q</code>
suffix tells us that it is operating on 64-bit quantities. (In
contrast, <code>l</code>, <code>w</code>, and <code>b</code> would denote 32-bit, 16-bit, and 8-bit,
respectively.) It multiplies the value in the first given register
(<code>rdi</code>; register names are prefixed with a <code>%</code> sign) by the value in
the second register and stores the result in that second
register. This is squaring <code>v.x</code> in our example C++ code.</p><p>The second instruction does the same with the value in <code>%rsi</code>, which
squares <code>v.y</code>.</p><p>Next, we have an odd instruction: <code>leaq (%rsi,%rdi), %rax</code>. <code>lea</code>
stands for “load effective address”, and it stores the address of the
first operand into the second operand. <code>(%rsi, %rdi)</code> means “the
memory location pointed to by <code>%rsi + %rdi</code>”, so this is just adding
<code>%rsi</code> and <code>%rdi</code> and storing the result in <code>%rax</code>. <code>lea</code> is a quirky
x86-specific instruction; on a more
<a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC</a>-y
architecture like ARM64, we would expect to see a plain old <code>add</code>
instruction.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><p>Finally, <code>retq</code> returns from the <code>normSquared</code> function.</p><p>Let’s take a brief detour to explain what the registers we saw in our
example are. Registers are the “variables” of assembly
langauge. Unlike your favorite programming language (probably), there
are a finite number of them, they have standardized names, and the
ones we’ll be talking about are at most 64 bits in size. Some of them
have specific uses that we’ll see later. I wouldn’t be able to rattle
this off from memory, but <a href="https://en.wikipedia.org/wiki/X86-64#Architectural_features">per
Wikipedia</a>,
the full list<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> of 16 registers on x86_64 is <code>rax</code>, <code>rcx</code>, <code>rdx</code>, <code>rbx</code>,
<code>rsp</code>, <code>rbp</code>, <code>rsi</code>, <code>rdi</code>, <code>r8</code>, <code>r9</code>, <code>r10</code>, <code>r11</code>, <code>r12</code>, <code>r13</code>,
<code>r14</code>, and <code>r15</code>.</p><p>Now, let’s extend our example to debug print the <code>Vec2</code> in <code>normSquared</code>:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
<span>    <span>void</span> <span>debugPrint</span>() <span>const</span>;
</span>};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
<span>    v.debugPrint();
</span>    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and, again, let’s see <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEJICcpLegAyeWpgByxgEaZiIAGykADqgWE6rR6hiaCfgFqdHYOzkZuHt5KKlG0DATMxAQhxqYWisqYqkHpmQQxTq7uXooZWTlhnLVlFXEJXgCUiqgGxMgcAORSAMz2yIZYANTiwzrICgT49DPY4gAMAILrGwvEBqqTAGpFktMA7LKbk9eT9gSe3AD6BJMAHjOXGze39A/PkwBPD7bb4AN1QeHQkywLgMwAACsQ7hAOpM0LQFsDNuIzgARLFbTZ3P4vWgkIwMACOBkymHQEGOyFOoNROM%2BYIAdDC4YjkR0Cd9iJgCL1aJNQRzXpMAFTiyXTGRygEypUEnG4gZdVggAYAVgGpFMAzWBtQOp0cjkkwUPT6mAVw04BoIOpNHS6AGsQMNhhyff6A4HvNqBtwDUaTaQzQMDQoQGtSC7jZrSHBYEg0EYfHh2GQKBBM9ncyhhKJOJw1k0qDmCO44xAXK6DS57JkATqnaRM0YtAQAPK0Vjt5OkLBGETAdhN0d4IXFUGYOMjzCvIoGWsdg13ZSboR4FzENt6LC7ghIoybro0ehMNgcHj8QSlsSWmR7lxxyBdVA%2BVJLgC0fbDJM/4LOgMy4hIMhyJIkbJEUqSaNoDSmE01itFUHhNBEgR0Ch4T%2BLhtAYfE1RNPBxR0KU9T6LkggUak1HlPYlSkVhzQ0aEqEccxsSYVwXQ2r0/QCUIOr6oa07Rq8AAcnj/g8aLPpM5YcmsHKcJMEC4IQJAOk0kx6FmObuPpqIWtBMjOk27qkF6Pp%2BoGTk%2BsGOphpJI7RrG8aJjZqYwIgKCoMZubkJQhYmR44wTuWlakNWrC1sQ9aNiOLa0G2u7dr2A5DtOY4TlOI74HOagLkukYrmuG4DJ224hpGrD7oexAAsegyRmeeAXrVKbXowLBTg%2BAiSEIE4oK%2B8hNR%2B8Dfr%2BQQAUBIFgRBUGyDIsGxoUlGmBA1j4Zwo3oSxbRkcMviEakB2jThqQke0nDnQxJR1NktGNKNz1Ua991nTx108b9WHDIJtoiZwWrieGUk6rJ8mKdFogqZwakaVpOlEMQ%2BmkIZwVFqZIySOZk3Wcmtn2b6znOWJobQ55OreQmSZupDAySHTkZeb5ZNdAuyVBCA3BAA">the generated assembly</a>:</p><div><pre><code data-lang="asm">        <span>subq</span>    <span>$24</span>, %rsp
        <span>movq</span>    %rdi, <span>8</span>(%rsp)
        <span>movq</span>    %rsi, <span>16</span>(%rsp)
        <span>leaq</span>    <span>8</span>(%rsp), %rdi
        <span>callq</span>   <span>Vec2</span>::<span>debugPrint</span>() <span>const</span>
        <span>movq</span>    <span>8</span>(%rsp), %rcx
        <span>movq</span>    <span>16</span>(%rsp), %rax
        <span>imulq</span>   %rcx, %rcx
        <span>imulq</span>   %rax, %rax
        <span>addq</span>    %rcx, %rax
        <span>addq</span>    <span>$24</span>, %rsp
        <span>retq</span>
</code></pre></div><p>In addition to the obvious call to <code>Vec2::debugPrint() const</code>, we have
some other new instructions and registers! <code>%rsp</code> is special: it is
the “stack pointer”, used to maintain the <a href="https://en.wikipedia.org/wiki/Call_stack">function call
stack</a>. It points to the
bottom of the stack, which grows “down” (toward lower addresses) on
x86. So, our <code>subq $24, %rsp</code> instruction is making space for three
64-bit integers on the stack. (In general, setting up the stack and
registers at the start of your function is called the <a href="https://en.wikipedia.org/wiki/Function_prologue">function
prologue</a>.) Then, the
following two <code>mov</code> instructions store the first and second arguments
to <code>normSquared</code>, which are <code>v.x</code> and <code>v.y</code> (more about how parameter
passing words in the next blog post!) to the stack, effectively
creating a copy of <code>v</code> in memory at the address <code>%rsp + 8</code>. Next, we
load the address of our copy of <code>v</code> into <code>%rdi</code> with <code>leaq 8(%rsp), %rdi</code> and then call <code>Vec2::debugPrint() const</code>.</p><p>After <code>debugPrint</code> has returned, we load <code>v.x</code> and <code>v.y</code> back into
<code>%rcx</code> and <code>%rax</code>. We have the same <code>imulq</code> and <code>addq</code> instructions as
before. Finally, we <code>addq $24, %rsp</code> to clean up the 24
bytes<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> of stack space we allocated at the start of
our function (called the <a href="https://en.wikipedia.org/wiki/Function_prologue#Epilogue">function
epilogue</a>),
and then return to our caller with <code>retq</code>.</p><p>Now, let’s look at a different example. Suppose that we want to print
an uppercased C string and we’d like to avoid heap allocations for
smallish strings.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> We might write something like
the following:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdio&gt;</span><span>
</span><span>#include</span> <span>&lt;cstring&gt;</span><span>
</span><span>#include</span> <span>&lt;memory&gt;</span><span>
</span><span></span>
<span>void</span> <span>copyUppercase</span>(<span>char</span> <span>*</span>dest, <span>const</span> <span>char</span> <span>*</span>src);

<span>constexpr</span> size_t MAX_STACK_ARRAY_SIZE <span>=</span> <span>1024</span>;

<span>void</span> <span>printUpperCase</span>(<span>const</span> <span>char</span> <span>*</span>s) {
    <span>auto</span> sSize <span>=</span> strlen(s);
    <span>if</span> (sSize <span>&lt;=</span> MAX_STACK_ARRAY_SIZE) {
        <span>char</span> temp[sSize <span>+</span> <span>1</span>];
        copyUppercase(temp, s);
        puts(temp);
    } <span>else</span> {
        <span>// std::make_unique_for_overwrite is missing on Godbolt.
</span><span></span>        std<span>::</span>unique_ptr<span>&lt;</span><span>char</span>[]<span>&gt;</span> temp(<span>new</span> <span>char</span>[sSize <span>+</span> <span>1</span>]);
        copyUppercase(temp.get(), s);
        puts(temp.get());
    }
}
</code></pre></div><p>Here is <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEAHZeW9ABk8tTADljAI0zEuANlIAHVAsLqtHqGJua8vv5qdLb2Tkau7pxeSipRtAwEzMQEwcamForKmKqBGVkEMY4ubp6Kmdm5oQUK9RV2VfE1SQCUiqgGxMgcAORSAMx2yIZYANTiYzrILfio89jiAAwAguOT05hzC0sExHbAa5s7khO0Uwaz8zpGmEYkAJ4X25cAbqh46DM0N43gBVbzeNwsJQQZAILIzABUWBapEBdBagLhxERCkG3Xmsi%2B2zQtBamAAHt5sf4AF6YAD6BBmAFktgANekMAAqWx0AGl6VsAEpCrYATU5AEkAFrYQ4AERmnA2km4BMuPz%2BAKpdgIYIhxB0zGhJIxsPhCIU3TmZkJWxmDpmzAMRBmCgYeDpCrdJ3YtAgVvV20dMzwVBmAY9Xse80VrI53N5AuFoolDBl2Gt4ltlxDIfN2IIL284gArNJ3Z6DnIlWX5UH7XmHUDQeDIcbMBAi0ZvKjA2M7U2Hd4XQou8X8QPc47s4rlEobYOhwB6Zc%2B9AgEBGZgAawZBloeAAjgYGTRiPTUN83AB3U5F0MKGZGPAKfyiGZ0GZ6Ht4djY7BKVYEg3AAOmnJtlk3A9j1PelvBOR4CzLWRS3rMY5W7bwIHsG9MSyFDK2jGRazQyclybFt9XbaEsNA4BMAICBejdciILzEcCDHOiGKY7o2ODGczHrL5hOGXpWBAYZS2GUhTGGDZZNQKSdDkGsFH6QZq2uThZIIKTFP40gdxAbgxlAsZlTGABOMxS1LMZSySAAOSQhCk7hZPkxTSGU4ZZIUEANlIfSFPE0g4FgJA0F/f9yEoGLvD/GophEYBOGVThSCoP8i2IQKIGcAzZOcOwsjeKTdNIGLnnoAB5WhWAqsLSCwbdRHYYrWrwYhijUa9ApailihdEYqt1ZRKtk1g8GcYhyr0LAppC04jCm3oaHoJg2A4Hh%2BEEYRRBQNSZCEWbAsgXpUAQwJBoAWjqsYZju5ZYwkGQ5EkDZnqoWhUDu69VBIKsfr%2Bu6D2IfRWDu4DrqfO7fv%2Bikhhu9EAqKEoNAgKxGlMLKrEqOIEkECIAjoXGSb8MnaEJ6pEkKVJSlaCmspSPqmfKWnOnplpyhZupOfaImul6DSBiGLgJKkmS5K6vzyWcjw7o8bhAUO4AlU4UCNlAzgI1wQgSDmHTUR/JL/2NyzrVUj6ZD04qjJMsZzMkUszNLMxrI2MxnIc653OGTzZZavyAqCkKHYimBEBQVBYrceKYTj82UvVjKNiynLWDygqipa0raHK5aaq0AgGqarq2rSzqWvwXqSgGrrhuQUblomySWpmuaFowEYfJOPA1uGXSNroRgWE6vaBDc9Xjtt%2BQu4u5jfNR0kpIep6XoIdA3pO6QvtB/7AaIU4vQRsGIahmHUDhw%2B7uRzBV4UdHGaxnH9DyQQCaFunKciQJ%2BakzSFzYmrMMZpDKA0D%2BoQwGv3SK0EBXQBZQJCHjZBbRYi/04KLTSEtsEBxlt5JSUkFZKxVmrNKmtta631vgE%2BlssrfmTslbE4xJDWz3vbMKjsQDXFAu7VU3AHKK0kNZaypYZ4eS8nLKSYdgqhUMlLYYkhpEh1kRHbhvRrz5UCKZIAA%3D">the generated assembly</a>:<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p><div><pre><code data-lang="asm"><span>printUpperCase</span>(<span>char</span> <span>const</span>*):                  <span># @printUpperCase(char const*)
</span><span></span>        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
        <span>callq</span>   <span>strlen</span>
        <span>leaq</span>    <span>1</span>(%rax), %rdi
        <span>cmpq</span>    <span>$1024</span>, %rax                     <span># imm = 0x400
</span><span></span>        <span>ja</span>      <span>.LBB0_2</span>
        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
.LBB0_2:
        <span>callq</span>   <span>operator</span> <span>new</span>[](<span>unsigned</span> <span>long</span>)
        <span>movq</span>    %rax, %rbx
        <span>movq</span>    %rax, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %rbx, %rdi
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>jmp</span>     <span>operator</span> <span>delete</span>[](<span>void</span>*)                          <span># TAILCALL
</span></code></pre></div><p>Our function prologue has gotten a lot longer, and we have some new
control flow instructions as well. Let’s take a closer look at the
prologue:</p><div><pre><code data-lang="asm">        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
</code></pre></div><p>The <code>pushq %rbp; movq %rsp, %rbp</code> sequence is very common: it pushes
the <a href="https://en.wikipedia.org/wiki/Call_stack#FRAME-POINTER">frame
pointer</a>
stored in <code>%rbp</code> to the stack and saves the old stack pointer
(which is the new frame pointer) in <code>%rbp</code>. The following four
<code>pushq</code> instructions store registers that <a href="https://en.wikipedia.org/wiki/X86_calling_conventions#System_V_AMD64_ABI">we need to save before
using</a>.<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>
Finally, we save our first argument (<code>%rdi</code>) in <code>%r14</code>.</p><p>On to the function body. We call <code>strlen(s)</code> with <code>callq strlen</code> and
store <code>sSize + 1</code> in <code>%rdi</code> with <code>lea 1(%rax), %rdi</code>.</p><p>Next, we finally see our first <code>if</code> statement! <code>cmpq $1024, %rax</code> sets
the <a href="https://en.wikipedia.org/wiki/FLAGS_register">flags register</a>
according to the result of <code>%rax - $1024</code>, and then <code>ja .LBB0_2</code>
(“jump if above”) transfers control to the location labeled <code>.LBB0_2</code>
if the flags indicate that <code>%rax &gt; 1024</code>. In general, higher-level
control-flow primitives like <code>if</code>/<code>else</code> statements and loops are
implemented in assembly using conditional jump instructions.</p><p>Let’s first look at the path where <code>%rax &lt;= 1024</code> and thus the branch
to <code>.LBB0_2</code> was not taken. We have a blob of instructions to create
<code>char temp[sSize + 1]</code> on the stack:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
</code></pre></div><p>We save <code>%rsp</code> to <code>%r15</code> and <code>%rbx</code> for later
use.<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> Then, we add 15 to <code>%rdi</code> (which,
remember, contains the size of our array), mask off the lower 4 bits
with <code>andq $-16, %rdi</code>, and subtract the result from <code>%rbx</code>, which we
then put back into <code>%rsp</code>. In short, this rounds the array size up to
the next multiple of 16 bytes and makes space for it on the stack.</p><p>The following block simply calls <code>copyUppercase</code> and <code>puts</code> as written in the code:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
</code></pre></div><p>Finally, we have our function epilogue:</p><div><pre><code data-lang="asm">        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
</code></pre></div><p>We restore the stack pointer to deallocate our variable-length array
using <code>leaq</code>. Then, we <code>popq</code> the registers we saved during the
function prologue and return control to our caller, and we are done.</p><p>Next, let’s look at the path when <code>%rax &gt; 1024</code> and we branch to
<code>.LBB0_2</code>. This …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wolchok.org/posts/how-to-read-assembly-language/">https://wolchok.org/posts/how-to-read-assembly-language/</a></em></p>]]>
            </description>
            <link>https://wolchok.org/posts/how-to-read-assembly-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282634</guid>
            <pubDate>Sat, 27 Feb 2021 04:40:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Greenwashing? Learn to Spot Truly Sustainable Brands]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26282619">thread link</a>) | @jradhughes
<br/>
February 26, 2021 | https://lafloreparis.com/blogs/laflore-blog/what-is-greenwashing-learn-to-spot-truly-sustainable-brands | <a href="https://web.archive.org/web/*/https://lafloreparis.com/blogs/laflore-blog/what-is-greenwashing-learn-to-spot-truly-sustainable-brands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><span>Greenwashing is when a company pretends to be </span><b>eco-friendly</b><span> despite using toxic ingredients and unsustainable practices to manufacture their product.&nbsp;</span></p>
<p><span>When a company engages in </span><i><span>greenwashing</span></i><span>, they effectively influence consumers to believe that they’re working towards saving the environment when they’re not. In fact, companies that go to great lengths to create a </span><b>greenwashed marketing strategy</b><span> are sometimes covering up their lack of </span>environmentally friendly products or processes<span>. They are interested only in improving their sales and making more money, and they do so by projecting a green image and deceiving </span><b>conscious consumers</b><span>.&nbsp;</span></p>
<p>It should be noted that some companies greenwash their products accidentally. Misinformation surrounding sustainability is so widespread that companies can get the wrong idea about what's sustainable and what's not. Although there's no excuse for large corporations with hefty research budgets, smaller companies sometimes think they're being eco-friendly when they're not.&nbsp;</p>
<h2><b>Why do companies use this marketing strategy?</b></h2>
<p><span>The short answer is that companies who deliberately use this strategy do so to attract more customers and increase revenue.</span><span><br></span><span><br></span><span>Over the past couple of decades, there has been a shift toward holding companies accountable for their carbon footprint and environmental impact. At the same time, consumers have become more conscious of their impact on the environment. Naturally, conscious customers try their best to buy </span><b>environmentally friendly products</b><span> when possible.&nbsp;</span></p>
<p><span>There isn’t currently a lot of regulation around sustainable terms such as: natural, green, eco-friendly, and environmentally friendly. Any company can include green colors and imagery on their products and use terms such as </span><i><span>natural</span></i><span>. Therefore, it’s usually easy for brands to attract well-meaning consumers and improve their sales. </span><span><br></span><span><br></span><span>Another reason for companies using this marketing strategy is to stand out from their competitors in the market. They promise the consumers that their product is more efficient, saves more power, or is </span><b>sustainable</b><span>. In response, many people start purchasing from them believing that they are helping the environment.&nbsp;</span></p>
<p><span>Many companies see this </span><i><span>green agenda</span></i><span> as an opportunity to gain a competitive advantage, especially because “natural products” are usually priced higher.&nbsp;Particularly when shopping on-the-go at the grocery store or mall, consumers don’t have time to research every single product they put into their cart. And with good reason! Unless you only buy from trusted brands, it’s hard to distinguish between the truly sustainable products and the fake ones.&nbsp;</span></p>
<p><b>Examples of Greenwashing</b><b><br></b><span><br></span><span>A very common example of greenwashing is when a company rebrands as natural or eco-friendly. If a company changes their name, logo, or slogan to appear greener without actually changing their business to be environmentally friendly, then chances are it's an attempt to greenwash. Food companies, cosmetic companies, and household product manufacturers are often seen involved in greenwashing. &nbsp;</span><span><br></span><span><br></span><span>Another example of greenwashing is when a company labels its products with buzz-words and meaningless statistics.&nbsp;</span></p>
<p><span>Have you ever seen one or more of the the following descriptions on a product?<br></span></p>
<ul>
<li><span>"99% naturally derived"&nbsp;</span></li>
<li><span><span>"100% recyclable"</span></span></li>
<li><span><span><span>"Made with natural ingredients"&nbsp;&nbsp;</span></span></span></li>
<li><span><span><span><span>"Biodegradable"&nbsp;</span></span></span></span></li>
</ul>
<p>While these things all sound great to the conscious consumer, these phrases don't mean anything.</p>
<p>Single-use plastic can be 100% recyclable, but it isn't sustainable or eco-friendly. Many chemicals are naturally-derived, yet are still harmful to the environment. Food, cosmetics, textiles, and more can all be made with "natural" ingredients, but that doesn't necessarily mean they're inherently healthy or environmentally friendly. Lastly, most things are biodegradable, but that doesn't mean it's okay to dump them in a landfill.</p>

<h2><b>Impact of Greenwashing</b></h2>
<p><img src="https://cdn.shopify.com/s/files/1/0266/4346/4271/files/pexels-catherine-sheila-2409025_480x480.jpg?v=1613572719" alt="false green claims"></p>
<p><b></b><span>Greenwashing is unethical.&nbsp;False green claims have&nbsp;a negative impact not only on consumers but also on the environment. Let’s look at some of the problems that arise because of greenwashing.&nbsp;</span></p>
<p><b>Encourages Uninformed Decisions</b> <b><br></b><b><br></b><span>The most important danger of greenwashing is that it misinforms people, leading them to make wrong decisions and contribute to unintended environmental harm. Customers, without knowing if a company’s eco-friendly claims are genuine or not, act unsustainably, and make an uninformed decision. </span><span><br></span><span><br></span><b>Harms the Environment</b></p>
<p><a href="https://ehp.niehs.nih.gov/doi/full/10.1289/ehp.118-a246"><span>Greenwashing harms the environment and public health</span></a><span>. When consumers are unable to understand the false practices of a company and they decide to buy from a greenwashing company, they contribute to the growth of that company.</span></p>
<p><span>Their support gives such companies more revenue and they continue with their greenwashed marketing and non-environmentally friendly products. Many companies that use greenwashing are often found to be using toxic ingredients in their products or using unsustainable practices such as excess water usage, causing unnecessary air pollution,&nbsp;or producing toxic run-off. To stop this, consumers should look into what they are buying and support the company only if they are genuinely working towards protecting the environment.&nbsp;&nbsp;</span></p>
<p><b>Harms Genuine Brands</b><b><br></b><b><br></b><span>Apart from harming the environment, greenwashing also causes trouble for companies that are genuinely working towards saving the environment. This happens because greenwashing breaks consumer trust and consumers start suspecting </span><i><span>all</span></i><span> brands</span><b>, </b><span>even those that are working hard to produce </span><b>environmentally friendly products</b><span>. The reputation of true eco-friendly companies are hindered, making it difficult for them to gain significant market share.&nbsp;</span></p>

<h2><b>How to Identify Greenwashing&nbsp;</b></h2>
<p><img src="https://cdn.shopify.com/s/files/1/0266/4346/4271/files/Webp.net-resizeimage_3_480x480.jpg?v=1613572793" alt="greenwashed" width="480x480" height="480x480"></p>
<p><span>Unfortunately, it can be hard to know if a company is greenwashing or not.&nbsp;It is important for consumers to be educated and aware about which companies and products are truly green and which are not, but this takes time and a lot of effort.&nbsp;</span></p>
<p><span>However, there are some things you can look out for that might help you make more informed decisions. Here are a few tips:</span></p>
<ul>
<li><span>Many companies use specific phrases like natural, sustainable, organic, healthy, vegan, etc. to attract consumers. The use of such words gives the impression that they are eco-friendly and green. However, be skeptical. You should read the information provided by the company on the packaging material, label, and website. The only way to know about the product is to read the label carefully.&nbsp;</span></li>
<ul>
<li>
<span>You should know what common products are inherently not eco-friendly: PVC, triclosan, microbeads, aerosols, phosphates, and chlorine bleach are just a few toxic materials that companies use while still marketing themselves as safe and natural. </span><span></span>
</li>
</ul>
<li>
<span>Product imagery that depicts natural scenery is also a tool used by many companies to deceive potential buyers. Consumers should be aware not to be fooled by pictures of fruit, nuts, farms, or any other natural-looking imagery on the labels of the product. Using a particular image does not represent the true sustainability of a company’s products.</span><span></span>
</li>
<li>
<span>Besides using earth-centered imagery, companies also using earthy tones to promote a natural vibe. They use greens, browns, and blues instead of bright and flashy colors while packaging their products. This is to lure the consumers who are drawn to earth-friendly products. However, consumers should remember that greens and browns don’t necessarily imply that the product is earth-friendly.</span><span><br></span><span>&nbsp;&nbsp;</span>
</li>
</ul>

<h2><b>Ways to Verify Sustainable Brands&nbsp;</b></h2>
<p><b><img src="https://cdn.shopify.com/s/files/1/0266/4346/4271/files/MG_1114_copy_480x480.jpg?v=1613568843" alt="what is greenwashing"></b></p>
<p><span>These days, the number of environmentally-conscious buyers is growing.&nbsp;</span></p>
<p><span>If you find it hard to obtain information about a company’s factory or production details, there's a chance&nbsp;that the company is greenwashing or it has something to hide.To verify the sustainability of a brand,&nbsp;you&nbsp;should try to find out more and more about the way a company operates. <p>Here are some things you can look out for:</p></span></p>
<ul>
<li><span>Don't trust everything that a company shares or says if they don't have evidence to back it up. There is a possibility that the company is sugar-coating their information or spinning the truth.&nbsp;</span></li>
<li><span>Try to find out about the company’s supply chain, their production facilities, the employees, working conditions, contractors, etc.&nbsp;</span></li>
<li><span>Evaluate the logistics of the product. If a company is claiming they're sustainable, but they're still using single-use plastics...you know something is off.&nbsp;Look for the trademarks of true sustainability such as zero waste practices and/or materials.</span></li>
<li><span>For textiles and household goods, check the material and quality of the product. For food and cosmetic products, check the ingredients and learn more about the production processes of common ingredients. For example, "palm oil" sounds relatively unproblematic, but is actually one of the <a href="https://www.wwf.org.uk/updates/8-things-know-about-palm-oil">greatest&nbsp;drivers of deforestation</a>.&nbsp;</span></li>
<li>Ask tough questions! Even true eco-friendly companies are not perfect, but they'll be happy to answer your questions and show you how they're willing to improve.</li>
</ul>
<p><span>If you really want to avoid giving business to companies who are&nbsp;intentionally greenwashing, you'll need to screen your purchases carefully. Keep an eye out for harmful ingredients, materials, and production practices. When you're informed, you can spot fake eco-friendly companies much more easily.&nbsp;<br></span></p>
<p><span>Continue to read labels and always think about the entire product lifecycle - all the way from the sourcing of materials all the way down to&nbsp;discarding, recycling, or reusing the product.</span></p>
<p><span>Greenwashing needs to be stopped and we need to hold companies accountable. Let’s continue to do our part by becoming conscious consumers and buying environment friendly products.</span></p>
<p><span>To learn more about our sustainability efforts here at&nbsp;</span><b>LaFlore Paris</b><span>, please read our <a href="https://lafloreparis.com/pages/our-promise-to-you-eco-friendly-purses">Eco-Friendly Promise</a>. Please feel free to contact us at any time if you have more questions. We'd be happy to hear from you!&nbsp;</span></p>
<p><strong><br><a href="https://lafloreparis.com/products/convertible-backpack-purse"><span>Shop Our Eco-Friendly Convertible Backpack Purse</span></a></strong></p>
    </div></div>]]>
            </description>
            <link>https://lafloreparis.com/blogs/laflore-blog/what-is-greenwashing-learn-to-spot-truly-sustainable-brands</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282619</guid>
            <pubDate>Sat, 27 Feb 2021 04:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privacy Is Not Property]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26282426">thread link</a>) | @samizdis
<br/>
February 26, 2021 | https://pluralistic.net/2021/02/26/meaningful-zombies/#luxury-goods | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/02/26/meaningful-zombies/#luxury-goods">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1937">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
zombies, korea, south korea, k-zombies, data dividend, propertization, information economics,

Summary:
K-Zombies; Privacy is not property

URL:
https://pluralistic.net/2021/02/26/meaningful-zombies/

Title:
Pluralistic: 26 Feb 2021 meaningful-zombies

Bullet:
🦺

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Schneier (https://www.schneier.com/), Naked Capitalism (https://nakedcapitalism.com/).

--><br>
<a href="https://pluralistic.net/2021/02/26/meaningful-zombies/"><img src="https://i1.wp.com/craphound.com/images/26Feb2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/26Feb2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/26/meaningful-zombies/#oracles">K-Zombies</a>: Zombies conquer Korea.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/26/meaningful-zombies/#luxury-goods">Privacy is not property</a>: Interests, not exclusive rights.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/26/meaningful-zombies/#retro">This day in history</a>: 2006, 2011, 2016, 2020
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/26/meaningful-zombies/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="oracles"></a><br>
<img src="https://i0.wp.com/craphound.com/images/kca-times.brightspotcdn.com.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/kca-times.brightspotcdn.com.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>When you and your friends put your fingers on the ouija board planchette and it starts moving around, there's a chance your friends are just yanking your chain – but just as possible is that your friends are experiencing the ideomotor response.</p>
<p>That's when your unconscious mind directs your muscles without your conscious knowledge. The movement of the planchette doesn't tell you what's going on in the spirit world, but it does tell you something about the internal weather of your friend's psyche, fears and hopes.</p>
<p>Our narratives are social-scale planchettes, directed by mass ideomotor response. When a fake news story takes hold, it reveals a true fact: namely, the shared, internal models of how the world really works.</p>
<p>Fake news is an oracle, in other words.</p>
<p><a href="https://locusmag.com/2019/07/cory-doctorow-fake-news-is-an-oracle/">https://locusmag.com/2019/07/cory-doctorow-fake-news-is-an-oracle/</a></p>
<p>There's no spirit-realm directing planchettes. Supernatural phenomena are nonsense, in all their guises. Mediums are fraudsters or deluded – and so are soothsayers who claim to be able to predict the future. That goes for fortune-tellers and futurists alike.</p>
<p>A shocking number of self-described "rational" science fiction writers share the delusional view that they can predict the future. These pulp Nostradamii point to "predictions" of sf that have "come true" and claim to have an inside line on the world of tomorrow.</p>
<p>Sf <em>has</em> an important relationship to the future, though! It can be a planchette: all the futures imagined by all the sf writers are a kind of mutation-space, and the fitness factor that determines whether a story thrives or sinks is whether it captures public imagination.</p>
<p>Sf writers and readers are a means for society to reflect back, amplify and examine our unarticulated hopes and fears about our <em>present</em> technology. Sf doesn't predict the future, but sf readers and writers do an excellent job of predicting the present.</p>
<p>And since the present is the standing wave where the past is being transformed into the future, knowing about the present can be a source of insights into what's coming – and not just because sf reveals what's going on in the present, but also because it influences it.</p>
<p>People who are captured by imaginative, futuristic parables about the problems and possibilities of technology acquire a set of intuition-pumps for coping with the future when it arrives, reflexive views and actions about what the future demands of us.</p>
<p>Gene Rodenberry didn't predict the Motorola flip-phone. Rather, when a generation of Motorola designers and engineers were asked to make a mobile communications device their minds immediately flew to the Star Trek communicators they grew up with.</p>
<p>Thinking of fantastic fiction as measurement device and influence machine is a productive way to pick apart the meaning of literary trends.</p>
<p>As I wrote in my intro to the bicentennial re-release of FRANKENSTEIN, the rise and fall of Shelley's book tracks to the rise and fall of fears related to the book's various themes:</p>
<p><a href="https://muse.jhu.edu/chapter/1974387">https://muse.jhu.edu/chapter/1974387</a></p>
<p>So what are we to make of K-zombies? Korean pop culture is experiencing a golden age of zombie movies, games, comics and other media.</p>
<p><a href="https://www.latimes.com/world-nation/story/2021-02-23/zombies-are-everywhere-south-korea-fears">https://www.latimes.com/world-nation/story/2021-02-23/zombies-are-everywhere-south-korea-fears</a></p>
<p>Zombies have a lot of different themes, of course, and some are easy to map to the current situation: the fear of contagion and the need to distance yourself from loved ones who have become infected. The parallels to covid hardly need explaining.</p>
<p>But the K-zombie phenomenon predates the pandemic, and zombie stories aren't merely contagion stories – they're often stories about the lurking bestiality of nearly everyone around us.</p>
<p>That's behind stories like The Walking Dead, about the propensity of all our "normal" friends and neighbors to transform into an insensate, rampaging mob. These zombie stories are a throwback to the "cozy catastrophes" of John Wyndham and co:</p>
<p><a href="https://pluralistic.net/2020/03/29/grifters-gonna-grift/#wyndhamesque">https://pluralistic.net/2020/03/29/grifters-gonna-grift/#wyndhamesque</a></p>
<p>These are stories of racial and class anxiety, of xenophobia and the literal othering of someone who <em>seems</em> to be just like you but is actually a secret monster. Again, on a divided peninsula, it's not hard to see how stories of lurking otherness would catch hold.</p>
<p>Zombie stories are also stories about the fragility of social cohesion: stories about how we're never "all in this together" and how, when the chips are down, it'll be "the war of all against all." That, too, feels very zeitgeisty given recent South Korean politics.</p>
<p>South Korea has an ugly, authoritarian past that is at odds with its founding myth as the "good Korea," the "democratic Korea." But the post-war reconstruction of the country by the US elevated an elite to a position of near-total authority and impunity.</p>
<p>They abused this power in ghastly ways, running forced-labor camps for poor people and people with disabilities, with rampant physical and sexual abuse. Families who lost their loved ones were traumatized to learn that they'd ended up in the camps.</p>
<p><a href="https://web.archive.org/web/20160423131643/https://bigstory.ap.org/article/c22de3a565fe4e85a0508bbbd72c3c1b/ap-s-korea-covered-mass-abuse-killings-vagrants">https://web.archive.org/web/20160423131643/https://bigstory.ap.org/article/c22de3a565fe4e85a0508bbbd72c3c1b/ap-s-korea-covered-mass-abuse-killings-vagrants</a></p>
<p>These forced-labor camps (which continue in a slightly modified form to this day) supplied slaves to chaebols, the conglomerates that represent the country on a world stage. Unsurprisingly, the leadership of these companies is also grossly corrupt:</p>
<p><a href="https://www.bangkokpost.com/business/2052871/samsung-chief-jailed-for-2-5-years-over-corruption-scandal">https://www.bangkokpost.com/business/2052871/samsung-chief-jailed-for-2-5-years-over-corruption-scandal</a></p>
<p>Korea is also riven by messianic cults, and the leaders of these cults have close ties to the Korean political class, an incredibly politically destabilizing fact that has caused recent Korean governments to collapse:</p>
<p><a href="https://www.bbc.com/news/world-asia-37971085">https://www.bbc.com/news/world-asia-37971085</a></p>
<p>South Korea, in other words, isn't just haunted by the spectre of aggression from the north – but also by the possibility of internal rupture. It has a huge, authoritarian secret police force that has been caught secretly meddling in electoral politics.</p>
<p>Far from reining in this spookocracy, the South Korean political class has tried to hand them even MORE powers, with LESS oversight. Today is the fifth anniversary of the Korean opposition's filibuster to stop the worst of these.</p>
<p>(Seo Ki-Ho, a politician with the affectionate nickname "Milhouse" for his resemblance to the Simpsons character read the Korean edition of my novel LITTLE BROTHER into the record during the filibuster!)</p>
<p><img src="https://i2.wp.com/craphound.com/images/CcHHpWmUMAAyJk-1.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/CcHHpWmUMAAyJk-1.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p><a href="https://memex.craphound.com/2016/02/26/south-korean-lawmakers-stage-filibuster-to-protest-anti-terror-bill-read-from-little-brother/">https://memex.craphound.com/2016/02/26/south-korean-lawmakers-stage-filibuster-to-protest-anti-terror-bill-read-from-little-brother/</a></p>
<p>This othering is also sharply illustrated in the country's culture of misogynistic voyeurism, which goes beyond "upskirt" videos and includes a roaring trade in videos captured with hidden cameras in toilets, changing rooms and hotel rooms.</p>
<p>It's hard to overstate the reach of this practice, and its political salience: it has provoked a vast mass-movement of women and allies demanding an end to the practice and a reckoning with institutional sexism:</p>
<p><a href="https://www.khaosodenglish.com/culture/net/2020/10/21/voyeurs-are-selling-photos-of-women-at-the-protest-online/">https://www.khaosodenglish.com/culture/net/2020/10/21/voyeurs-are-selling-photos-of-women-at-the-protest-online/</a></p>
<p>Zombies aren't ever just about contagion – they're also always an expression of a deep anxiety that your neighbors aren't what they seem, that in a pinch, they'll turn on you, and not just because they've been infected, but also to protect themselves and their comfort.</p>
<p>US zombie booms always have an element of this: 1950s (reds under the bed); 1980s (red menace redux); 2000s (immigration "crisis"), etc. It'd be amazing if the only thing driving K-zombies' popularity was the pandemic, or even less plausibly, a mere aesthetic coincidence.</p>
<hr>
<p><a name="luxury-goods"></a><br>
<img src="https://i0.wp.com/craphound.com/images/datadividend.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/datadividend.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>When all you have is market orthodoxy, everything looks like a market failure. Take privacy: giant, rapacious corporations have instrumented the digital and physical worlds to spy on us all the time, so some people think they should pay us for our data.</p>
<p>There's a pretty rich theoretical history explaining why this "data dividend" is a stupid idea. First of all, private information isn't very property-like. And not  just because it shares all the problems of digital works (infinitely, instantaneously copyable at zero cost).</p>
<p>Private information makes for bad "property" because it is "owned" by multiple, overlapping parties who generally disagree about when and who to share it with. When you and I have a conversation, we both own the fact that the conversation took place.</p>
<p>What happens if I won't sell, but you will? Tech companies are <em>really</em> good at finding the cheapest seller of an information good, after all. For example, whenever you visit a "quality newspaper's" site, there's a real-time auction to bid on the right to show you ads.</p>
<p>Say there are 13 bidders for that right. One gets to show you an ad, but the other 12 get something too: your unique identifier and the fact that you read, say, the New York Times.</p>
<p>That fact is then sold on to garbage chumbox sites like Tabouleh, whose pitch to advertisers is "I can show your ads to NYT readers at 15% of the price that the Times charges." If the same fact is "owned" by lots of people, it's a commodity.</p>
<p>Buyers will find the lowest, least-discerning seller. What's more, you can't solve this by requiring consensus of all "owners" of a fact before it is disclosed – who owns the fact that your boss sexually harassed you: you or him? Does he get a veto over your disclosures?</p>
<p>Even if we could get property rights to work in privacy (which, for the record, we cannot), all we'd manage to do is transform privacy into a luxury good wherein poor people are coerced into selling their data for pennies, as Malavika Jayaram reminds us:</p>
<p><a href="https://twitter.com/MalJayaram/status/1231373834458025984">https:/…</a></p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/02/26/meaningful-zombies/#luxury-goods">https://pluralistic.net/2021/02/26/meaningful-zombies/#luxury-goods</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/02/26/meaningful-zombies/#luxury-goods</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282426</guid>
            <pubDate>Sat, 27 Feb 2021 03:52:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Post-Spectre Web Development]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26282200">thread link</a>) | @pabs3
<br/>
February 26, 2021 | https://mikewest.github.io/post-spectre-webdev/ | <a href="https://web.archive.org/web/*/https://mikewest.github.io/post-spectre-webdev/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
   <p>In early 2018, Spectre made it clear that a foundational security boundary the web aimed to
maintain was substantially less robust than expected. <a data-link-type="biblio" href="#biblio-spectre">[SPECTRE]</a> This revelation has pushed web
browsers to shift their focus from the platform-level <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#concept-origin" id="ref-for-concept-origin">origin</a> boundary to an OS-level
process boundary. Chromium’s threat model, for instance, now asserts that "active web content …
will be able to read any and all data in the address space of the process that hosts it". <a data-link-type="biblio" href="#biblio-post-spectre-rethink">[POST-SPECTRE-RETHINK]</a> This shift in thinking imposes a shift in development practice, both
for browser vendors, and for web developers. Browsers need to align the origin boundary with the
process boundary through fundamental refactoring projects (for example, <a data-link-type="biblio" href="#biblio-site-isolation">[SITE-ISOLATION]</a> and <a data-link-type="biblio" href="#biblio-project-fission">[PROJECT-FISSION]</a>). Moreover, browsers must provide web developers with tools to mitigate risk
in the short term, and should push the platform towards safe default behaviors in the long term.
The bad news is that this is going to be a lot of work, much of it falling on the shoulders of
web developers. The good news is that a reasonable set of mitigation primitives exists today,
ready and waiting for use.</p>
   <p>This document will summarize the threat model which the Web Application Security Working group
espouses(?), point to a set of mitigations which seem promising, and provide concrete recommendations
for developers responsible for protecting users' data.</p>
   <p id="issue-bdf75540"><a href="#issue-bdf75540"></a> Propose this to WebAppSec.</p>
   <h3 data-level="1.1" id="threat-model"><span>1.1. </span><span>Threat Model</span><a href="#threat-model"></a></h3>
   <p>Spectre-like side-channel attacks inexorably lead to a model in which active web content
(JavaScript, WASM, probably CSS if we tried hard enough, and so on) can read any and all data which
has entered the address space of the process which hosts it. While this has deep implications for
user agent implementations' internal hardening strategies (stack canaries, ASLR, etc), here we’ll
remain focused on the core implication at the web platform level, which is both simple and profound:
any data which flows into a process hosting a given origin is legible to that origin. We must design
accordingly.</p>
   <p>In order to determine the scope of data that can be assumed accessible to an attacker, we must make
a few assumptions about the normally-not-web-exposed process model which the user agent implements.
The following seems like a good place to start:</p>
   <ol>
    <li data-md="">
     <p>User agents are capable of separating the execution of a web origin’s code into a process
distinct from the agent’s core. This separation enables the agent itself to access local
devices, fetch resources, broker cross-process communication, and so on, in a way which remains
invisible to any process potentially hosting untrusted code.</p>
    </li><li data-md="">
     <p>User agents are able to make decisions about whether or not a given resource should be delivered
to a process hosting a given origin based on characteristics of both the request and the
response (headers, etc).</p>
    </li><li data-md="">
     <p>User agents can consistently separate top-level, cross-origin windows into distinct processes.
They cannot consistently separate same-site or same-origin windows into distinct processes given
the potential for synchronous access between the windows.</p>
    </li><li data-md="">
     <p>User agents cannot yet consistently seperate framed origins into processes distinct from their
embedders' origin.</p>
     <p role="note"><span>Note:</span> Though some user agents support out-of-process frames <a data-link-type="biblio" href="#biblio-oopif">[OOPIF]</a>, no agent supports it
consistently across a broad range of devices and platforms. Ideally this will change over time,
as the frame boundary <em>must</em> be one we can eventually consider robust.</p>
   </li></ol>
   <p>With this in mind, our general assumption will be that an origin gains access to any resource which
it renders (including images, stylesheets, scripts, frames, etc). Likewise, embedded frames gain
access to their ancestors' content.</p>
   <p id="issue-340f57a5"><a href="#issue-340f57a5"></a> <a data-link-type="biblio" href="#biblio-coi-threat-model">[COI-THREAT-MODEL]</a> spells out more implications. Bring them in here for more nuance.</p>
   <h3 data-level="1.2" id="tldr"><span>1.2. </span><span>TL;DR</span><a href="#tldr"></a></h3>
   <ol>
    <li data-md="">
     <p><strong>Decide when (not!) to respond to requests</strong> by examining incoming headers, paying special
attention to the <a data-link-type="http-header" href="https://fetch.spec.whatwg.org/#origin-header" id="ref-for-origin-header"><code>Origin</code></a> header on the one hand, and various <code>Sec-Fetch-</code> prefixed headers on the other, as described in <a data-link-type="biblio" href="#biblio-resource-isolation-policy">[resource-isolation-policy]</a>.</p>
    </li><li data-md="">
     <p><strong>Restrict attackers' ability to load your data as a subresource</strong> by setting a <a data-link-type="dfn" href="https://fetch.spec.whatwg.org/#http-cross-origin-resource-policy" id="ref-for-http-cross-origin-resource-policy">cross-origin resource policy</a> (CORP) of <code>same-origin</code> (opening up to <code>same-site</code> or <code>cross-origin</code> only when necessary).</p>
    </li><li data-md="">
     <p><strong>Restrict attackers' ability to frame your data as a document</strong> by opt-ing into framing
protections via <code>X-Frame-Options: SAMEORIGIN</code> or CSP’s more granular <a data-link-type="dfn" href="https://w3c.github.io/webappsec-csp/#frame-ancestors" id="ref-for-frame-ancestors">frame-ancestors</a> directive (<code>frame-ancestors 'self' https://trusted.embedder</code>, for example).</p>
    </li><li data-md="">
     <p><strong>Restrict attackers' ability to obtain a handle to your window</strong> by setting a <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#cross-origin-opener-policies" id="ref-for-cross-origin-opener-policies">cross-origin opener policy</a> (COOP). In the best case, you can default to a restrictive <code>same-origin</code> value, opening up to <code>same-origin-allow-popups</code> or <code>unsafe-none</code> only if
necessary.</p>
    </li><li data-md="">
     <p><strong>Prevent MIME-type confusion attacks</strong> and increase the robustness of passive defenses like <a data-link-type="dfn" href="https://fetch.spec.whatwg.org/#corb" id="ref-for-corb">cross-origin read blocking</a> (CORB) / <a href="https://github.com/annevk/orb">opaque response blocking</a> (<a data-link-type="biblio" href="#biblio-orb">[ORB]</a>) by setting
correct <code>Content-Type</code> headers, and globally asserting <code>X-Content-Type-Options: nosniff</code>.</p>
   </li></ol>
   <p id="issue-db0b0c7b"><a href="#issue-db0b0c7b"></a> Describe these mitigations in more depth, swiping liberally from <a href="https://docs.google.com/document/d/1JBUaX1xSOZRxBk5bRNZWgnzyJoCQC52TIRokACBSmGc/edit?resourcekey=0-cZ7da6v52enjwRSsp_tLyQ">Notes on the threat model of <em>cross-origin isolation</em></a>, <a href="https://docs.google.com/document/d/1zDlfvfTJ_9e8Jdc8ehuV4zMEu9ySMCiTGMS9y0GU92k/edit">Safely reviving shared memory</a>, etc.</p>
   <h2 data-level="2" id="examples"><span>2. </span><span>Practical Examples</span><a href="#examples"></a></h2>
   <h3 data-level="2.1" id="subresources"><span>2.1. </span><span>Subresources</span><a href="#subresources"></a></h3>
   <p>Resources which are intended to be loaded into documents should protect themselves from being used
in unexpected ways. Before walking through strategies for specific kinds of resources, a few headers
seem generally applicable:</p>
   <ol>
    <li data-md="">
     <p>Sites should use Fetch Metadata to make good decisions about when to serve resources, as
described in <a data-link-type="biblio" href="#biblio-resource-isolation-policy">[resource-isolation-policy]</a>. In order to ensure that decision sticks, servers
should explain its decision to the browser by sending a <a data-link-type="http-header" href="https://tools.ietf.org/html/rfc7231#section-7.1.4" id="ref-for-section-7.1.4"><code>Vary</code></a> header
containing <code>Sec-Fetch-Dest, Sec-Fetch-Mode, Sec-Fetch-Site</code>. This ensures that the server has
a chance to make different decisions for requests which will be <em>used</em> differently.</p>
    </li><li data-md="">
     <p>Subresources should opt-out of MIME type sniffing by sending an <a data-link-type="http-header" href="https://fetch.spec.whatwg.org/#http-x-content-type-options" id="ref-for-http-x-content-type-options"><code>X-Content-Type-Options</code></a> header with a value of <code>nosniff</code>. This increases the
robustness of MIME-based checks like <a data-link-type="dfn" href="https://fetch.spec.whatwg.org/#corb" id="ref-for-corb①">cross-origin read blocking</a> (CORB) / <a href="https://github.com/annevk/orb">opaque response blocking</a> (<a data-link-type="biblio" href="#biblio-orb">[ORB]</a>), and mitigates
some well-known risks around type confusion for scripts.</p>
    </li><li data-md="">
     <p>Subresources are intended for inclusion in a given context, not as independently navigable
documents. To mitigate the risk that navigation to a subresource causes script execution or
opens an origin up to attack in some other way, servers can assert the following set of headers
which collectively make it difficult to meaningfully abuse a subresource via navigation:</p>
     <ul>
      <li data-md="">
       <p>Using the <a data-link-type="http-header" href="https://w3c.github.io/webappsec-csp/#header-content-security-policy" id="ref-for-header-content-security-policy"><code>Content-Security-Policy</code></a> header’s to assert the <a data-link-type="dfn" href="https://w3c.github.io/webappsec-csp/#sandbox" id="ref-for-sandbox"><code>sandbox</code></a> directive ensures that these resources remain inactive if navigated to
directly as a top-level document. No scripts will execute, and the resource will be pushed
into an <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#concept-origin-opaque" id="ref-for-concept-origin-opaque">opaque origin</a>.</p>
       <p role="note"><span>Note:</span> Some servers deliver <code>Content-Disposition: attachment; filename=file.name</code> to obtain
a similar effect. This was valuable to mitigate vulnerabilies in Flash, but the sandbox
approach seems to more straightforwardly address the threats we care about today.</p>
      </li><li data-md="">
       <p>Asserting the <a data-link-type="http-header" href="https://html.spec.whatwg.org/multipage/origin.html#cross-origin-opener-policies" id="ref-for-cross-origin-opener-policies①"><code>Cross-Origin-Opener-Policy</code></a> header with a value of <code>same-origin</code> prevents cross-origin documents from retaining a handle to the resource’s
window if it’s opened in a popup.</p>
      </li><li data-md="">
       <p>The <a data-link-type="http-header" href="https://html.spec.whatwg.org/multipage/browsing-the-web.html#the-x-frame-options-header" id="ref-for-the-x-frame-options-header"><code>X-Frame-Options</code></a> header with a value of <code>DENY</code> prevents the resource
from being framed.</p>
     </li></ul>
   </li></ol>
   <p>Most subresources, then, should contain the following block of headers, which you’ll see repeated a
few times below:</p>
<pre>Content-Security-Policy: sandbox
Cross-Origin-Opener-Policy: same-origin
Vary: Sec-Fetch-Dest, Sec-Fetch-Mode, Sec-Fetch-Site
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
</pre>
   <p>With these generic protections in mind, let’s sift through a few scenarios to determine what headers
a server would be well-served to assert:</p>
   <h4 data-level="2.1.1" id="static-subresources"><span>2.1.1. </span><span>Static Subresources</span><a href="#static-subresources"></a></h4>
   <p>By their nature, static resources contain the same data no matter who requests them, and therefore
cannot contain interesting information that an attacker couldn’t otherwise obtain. There’s no risk
to making these resources widely available, and value in allowing embedders to robustly debug, so
something like the following response headers could be appropriate:</p>
<pre><strong>Access-Control-Allow-Origin: *
Cross-Origin-Resource-Policy: cross-origin
Timing-Allow-Origin: *</strong>
Content-Security-Policy: sandbox
Cross-Origin-Opener-Policy: same-origin
Vary: Sec-Fetch-Dest, Sec-Fetch-Mode, Sec-Fetch-Site
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
</pre>
   <p>CDNs are the canonical static resource distribution points, and many use the pattern above. Take
a look at the following common resources' response headers for inspiration:</p>
   <ul>
    <li data-md="">
     <p><a href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"><code>https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js</code></a></p>
    </li><li data-md="">
     <p><a href="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"><code>https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js</code></a></p>
    </li><li data-md="">
     <p><a href="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"><code>https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js</code></a></p>
    </li><li data-md="">
     <p><a href="https://ssl.google-analytics.com/ga.js"><code>https://ssl.google-analytics.com/ga.js</code></a></p>
   </li></ul>
   <p>Similarly, application-specific static resource servers are a good place to look for this practice. Consider:</p>
   <ul>
    <li data-md="">
     <p><a href="https://static.xx.fbcdn.net/rsrc.php/v3/y2/r/zVvRrO8pOtu.png"><code>https://static.xx.fbcdn.net/rsrc.php/v3/y2/r/zVvRrO8pOtu.png</code></a></p>
    </li><li data-md="">
     <p><a href="https://www.gstatic.com/images/branding/googlelogo/svg/googlelogo_clr_74x24px.svg"><code>https://www.gstatic.com/images/branding/googlelogo/svg/googlelogo_clr_74x24px.svg</code></a></p>
   </li></ul>
   <h4 data-level="2.1.2" id="dynamic-subresources"><span>2.1.2. </span><span>Dynamic Subresources</span><a href="#dynamic-subresources"></a></h4>
   <p>Subresources that contain data personalized to a given user are juicy targets for attackers, and
must be defended by ensuring that they’re loaded only in ways that are appropriate for the data
in question. A few cases are well worth considering:</p>
   <ol>
    <li data-md="">
     <p>Application-internal resources (private API endpoints, avatar images, uploaded data, etc.)
should not be available to any cross-origin requestor. These resources should be restricted to
usage as a subresource in same-origin contexts by sending a <a data-link-type="http-header" href="https://fetch.spec.whatwg.org/#http-cross-origin-resource-policy" id="ref-for-http-cross-origin-resource-policy①"><code>Cross-Origin-Resource-Policy</code></a> header with a value of <code>same-origin</code>:</p>
<pre><strong>Cross-Origin-Resource…</strong></pre></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikewest.github.io/post-spectre-webdev/">https://mikewest.github.io/post-spectre-webdev/</a></em></p>]]>
            </description>
            <link>https://mikewest.github.io/post-spectre-webdev/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282200</guid>
            <pubDate>Sat, 27 Feb 2021 02:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$Write Race]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26282078">thread link</a>) | @jger15
<br/>
February 26, 2021 | https://mirror.xyz/race | <a href="https://web.archive.org/web/*/https://mirror.xyz/race">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mirror.xyz/race</link>
            <guid isPermaLink="false">hacker-news-small-sites-26282078</guid>
            <pubDate>Sat, 27 Feb 2021 02:17:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mining Ethereum on M1 Mac GPU]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 81 (<a href="https://news.ycombinator.com/item?id=26281864">thread link</a>) | @gyf304
<br/>
February 26, 2021 | https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/ | <a href="https://web.archive.org/web/*/https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-444">

	

	
	<div>
		
<p>TL;DR: It’s possible to mine Ethereum on a M1 Mac GPU. Hashrate is about 2Mh/s.</p>



<figure><img data-attachment-id="452" data-permalink="https://blog.yifangu.com/image-1-5/" data-orig-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png" data-orig-size="1338,754" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=300" data-large-file="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=750" src="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=1024" alt="" srcset="https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=1024 1024w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=150 150w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=300 300w, https://yifangucom.files.wordpress.com/2021/02/image-1.png?w=768 768w, https://yifangucom.files.wordpress.com/2021/02/image-1.png 1338w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Mining on a M1 Mac</figcaption></figure>



<p>I’ve had my M1 MacBook Air for a bit of time now, and I also recently started mining Ethereum. I can’t help asking myself: What’s Ethereum mining performance like on a M1 Mac?</p>



<p>The obvious thing to do first is to run the off-the-shelf <code>ethminer</code>, which gives the following error:</p>



<pre><code>ethminer 0.19.0-alpha.0
Build: darwin/release/appleclang

Unrecognized platform Apple
Error: No usable mining devices found</code></pre>



<p>Not good. Apparently Apple GPUs are not whitelisted in ethminer. That should be easy to fix. Relevant lines are in <code>libethash-cl/CLMiner.cpp</code>, and I added Apple GPUs to the whitelist, pretending it’s an Intel GPU.</p>



<p>Then <code>boost</code> won’t compile since it’s trying to compile with a <code>-fcoalesce-templates</code> argument, which doesn’t exist in recent clang versions. So I have to update <code>boost</code> to the latest version, and fix relevant <code>asio</code> code since <code>ethminer</code> was using deprecated <code>asio</code> APIs.</p>



<p>I also need to upgrade OpenSSL to the latest version to have it support darwin + arm64.</p>



<p>After getting everything to compile. Here’s the result:</p>



<pre><code>ethminer 0.19.0-17+commit.ce52c740.dirty
Build: darwin/release/appleclang

 i 19:51:36          Configured pool eth-us-east1.nanopool.org:9999
 i 19:51:36          Selected pool eth-us-east1.nanopool.org:9999
 i 19:51:36          Connection remotely closed by eth-us-east1.nanopool.org
 i 19:51:36          Stratum mode : EthereumStratum/1.0.0 (NiceHash)
 i 19:51:36          Established connection to eth-us-east1.nanopool.org [144.217.14.139:9999]
 i 19:51:36          Spinning up miners...
cl 19:51:36 cl-0     Using Device : Intel GPU 0.0 Apple M1 OpenCL 1.2  Memory : 10.67 GB (11453251584 B)
 i 19:51:36          Extranonce set to 778d
 i 19:51:36          Extranonce set to 778d
 i 19:51:36          Authorized worker [REDACTED]
 i 19:51:36          Epoch : 397 Difficulty : 10.00 Gh
 i 19:51:36          Job: c7fc5311… eth-us-east1.nanopool.org [144.217.14.139:9999]
cl 19:51:38 cl-0     Generating split DAG + Light (total): 4.10 GB
 i 19:51:38          Job: 40a57756… eth-us-east1.nanopool.org [144.217.14.139:9999]
cl 19:51:38 cl-0     OpenCL kernel
cl 19:51:38 cl-0     Creating DAG buffer, size: 4.10 GB, free: 6.57 GB
cl 19:51:38 cl-0     Creating light cache buffer, size: 65.62 MB
cl 19:51:38 cl-0     Loading kernels
cl 19:51:38 cl-0     Creating buffer for header.
cl 19:51:38 cl-0     Creating mining buffer
 m 19:51:41          0:00 A0 0.00 h - cl0 0.00
 i 19:51:42          Job: 077b62f6… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:51:46          0:00 A0 0.00 h - cl0 0.00
 i 19:51:46          Job: 2835839e… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:51:51          0:00 A0 0.00 h - cl0 0.00
 m 19:51:56          0:00 A0 0.00 h - cl0 0.00
 i 19:51:57          Job: 97f724e7… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:01          0:00 A0 0.00 h - cl0 0.00
 m 19:52:06          0:00 A0 0.00 h - cl0 0.00
 m 19:52:11          0:00 A0 0.00 h - cl0 0.00
 m 19:52:16          0:00 A0 0.00 h - cl0 0.00
 i 19:52:16          Job: 54df0504… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:21          0:00 A0 0.00 h - cl0 0.00
cl 19:52:22 cl-0     4.10 GB of DAG data generated in 44,060 ms.
 m 19:52:26          0:00 A0 184.16 Kh - cl0 184.16
 m 19:52:31          0:00 A0 1.96 Mh - cl0 1.96
 m 19:52:36          0:01 A0 1.98 Mh - cl0 1.98
 i 19:52:39          Job: d3b1da5e… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:41          0:01 A0 1.99 Mh - cl0 1.99
cl 19:52:43 cl-0     Job: 54df0504… Sol: 0x778d000001d14c71
 i 19:52:43          **Accepted 150 ms. eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:52:46          0:01 A1 1.95 Mh - cl0 1.95
 m 19:52:51          0:01 A1 2.07 Mh - cl0 2.07
 m 19:52:56          0:01 A1 2.00 Mh - cl0 2.00
 m 19:53:01          0:01 A1 1.98 Mh - cl0 1.98
 i 19:53:01          Job: ccc2b97f… eth-us-east1.nanopool.org [144.217.14.139:9999]
 m 19:53:06          0:01 A1 1.97 Mh - cl0 1.97
 i 19:53:07          Job: 23919d82… eth-us-east1.nanopool.org [144.217.14.139:9999]
^C i 19:53:10 main     Got interrupt ...
 i 19:53:10 main     Disconnected from eth-us-east1.nanopool.org [144.217.14.139:9999]
 i 19:53:10 main     Shutting down miners...
 i 19:53:16 main     Terminated!</code></pre>



<p>Code is available at <a rel="noreferrer noopener" href="https://github.com/gyf304/ethminer-m1" target="_blank">https://github.com/gyf304/ethminer-m1</a></p>



<h2>Is it worth it?</h2>



<p>Um. Not really. At current Ethereum prices (2021-02-26), it generates $0.14 of profit per day. It’s still a profit, but very miniscule.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<!-- .author-bio -->
	
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.yifangu.com/2021/02/26/mining-ethereum-on-a-m1-mac-gpu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281864</guid>
            <pubDate>Sat, 27 Feb 2021 01:32:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standards in ARM space (part III)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281831">thread link</a>) | @pabs3
<br/>
February 26, 2021 | https://marcin.juszkiewicz.com.pl/2021/02/26/standards-in-arm-space-part-iii/ | <a href="https://web.archive.org/web/*/https://marcin.juszkiewicz.com.pl/2021/02/26/standards-in-arm-space-part-iii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>In <a href="https://marcin.juszkiewicz.com.pl/2020/10/12/standards-in-arm-space-part-i/">the first part</a> I went from
board files and ugly bootloaders to <span>SBSA</span>/<span>SBBR</span> and <span>EBBR</span>.
<a href="https://marcin.juszkiewicz.com.pl/2020/11/13/standards-in-arm-space-part-ii/">The second part</a> went through <span>BSA</span>,
<span>BBR</span> etc. <abbr title="Three Letter Acronym">TLAs</abbr> and what changes they brought into <abbr title="Other Four Letter Acronym">OFLAs</abbr>.</p>
<p>And both were about specifications written for developers (both hardware and
software). This time I will write something about ones written for marketing&nbsp;people.</p>
<h3><span>SBSA</span>, <span>SBBR</span>, <span>EBBR</span>, <span>LBBR</span>&nbsp;etc</h3>
<p>Who is gonna remember all those acronyms and what they mean? Only those who
really have to. Rest of people needs something easier to&nbsp;remember.</p>
<h3>ServerReady</h3>
<blockquote>
<p>Design a System that “Just&nbsp;Works”</p>
</blockquote>
<p>In 2018 Arm brought <a href="https://developer.arm.com/architectures/platform-design/server-systems">ServerReady program</a>.
Name sounds much better than “hardware needs to comply with <span>SBSA</span> and firmware
has to be <span>SBBR</span> compliant”, right? Ah, and “has to pass <span>ACS</span>” (which stands for
Architectural Compliance&nbsp;Suite).</p>
<p>Yeah — one simple name instead of three acronyms. So imagine situation when you
need to convince your boss that project needs a serious AArch64 machine for
Continuous Integration builds. You can say “We buy <span>XYZ</span> because it is a Server
Ready system” and they assume that it is a server so <span>IT</span> should be able to handle&nbsp;it.</p>
<p>Try to say “we buy <span>XYZ</span> because it is <span>SBSA</span> and <span>SBBR</span> compliant and passes <span>ACS</span>” and
you can get asked about your mental&nbsp;health…</p>
<h3>SystemReady</h3>
<p>But not every AArch64 system is server class hardware. Or needs what whole <span>UEFI</span>,
<span>ACPI</span> etc. things in&nbsp;firmware.</p>
<p>So in 2020 Arm came with <a href="https://developer.arm.com/architectures/system-architectures/arm-systemready">SystemReady program</a>.
It is basically ServerReady renamed and extended to cover wider selection of
hardware and firmware&nbsp;options.</p>
<p>It came around same time as <span>BSA</span>, <span>BBR</span>, <span>LBBR</span> etc. which I described in <a href="https://marcin.juszkiewicz.com.pl/2020/11/13/standards-in-arm-space-part-ii/">the second
part</a> already so will not repeat
what those acronyms&nbsp;mean.</p>
<h4>certification&nbsp;bands</h4>
<p>There are four ‘bands’&nbsp;defined:</p>
<table>
<thead>
<tr>
<th>Certification</th>
<th>Description</th>
<th>hardware specs</th>
<th>firmware spec</th>
</tr>
</thead>
<tbody>
<tr>
<td>SystemReady <span>SR</span></td>
<td>ServerReady</td>
<td><span>BSA</span> + <span>SBSA</span></td>
<td><span>SBBR</span></td>
</tr>
<tr>
<td>SystemReady <span>ES</span></td>
<td>Embedded Server (*)</td>
<td><span>BSA</span></td>
<td><span>SBBR</span></td>
</tr>
<tr>
<td>SystemReady <span>IR</span></td>
<td>IoT Ready</td>
<td><span>BSA</span></td>
<td><span>EBBR</span></td>
</tr>
<tr>
<td>SystemReady <span>LS</span></td>
<td>LinuxBoot ServerReady</td>
<td><span>BSA</span> + <span>SBSA</span></td>
<td><span>LBBR</span></td>
</tr>
</tbody>
</table>
<p>*) spec says “Embedded ServerReady” but it is probably an error as it was also
mentioned as “Embedded Server” in few places outside of&nbsp;specification.</p>
<p>What that means for&nbsp;developers?</p>
<table>
<thead>
<tr>
<th>Certification</th>
<th>hardware type</th>
<th>usual firmware</th>
</tr>
</thead>
<tbody>
<tr>
<td>SystemReady <span>SR</span></td>
<td>server class</td>
<td><span>UEFI</span> + <span>ACPI</span></td>
</tr>
<tr>
<td>SystemReady <span>ES</span></td>
<td>some <span>SBC</span></td>
<td><span>UEFI</span> + <span>ACPI</span></td>
</tr>
<tr>
<td>SystemReady <span>IR</span></td>
<td>some <span>SBC</span></td>
<td>(<span>UEFI</span> or U-Boot) + <span>DTB</span></td>
</tr>
<tr>
<td>SystemReady <span>LS</span></td>
<td>server class</td>
<td>LinuxBoot</td>
</tr>
</tbody>
</table>
<p>Where <span>UEFI</span> means Tianocore <span>EDK2</span> or similar. And U-Boot needs <span>EFI</span> layer enabled
(to fulfill <span>EBBR</span>&nbsp;requirements).</p>
<h4>recertification</h4>
<p><a href="https://developer.arm.com/documentation/den0109/latest">SystemReady specification</a> 
says that <span>SR</span> systems are also <span>ES</span> compliant. There is no need for recertification
if someone wants to put other&nbsp;sticker.</p>
<p>There are changes in progress. One of them is Devicetree requirement for <span>IR</span>
band. So not every <span>ES</span> will be compliant with <span>IR</span> unless firmware be&nbsp;changed.</p>
<p><span>BTW</span> — specification mentions 32-bit systems. But IoT Ready only as they are not
covered by <span>BSA</span>.</p>
<h3>Conclusion</h3>
<p>Creation of ServerReady and later SystemReady specifications was good move. We
got simple name which can be understood by mere&nbsp;mortals.</p>
<p>Developers and other interested people can go deeper and read about <span>BSA</span>, <span>BBR</span>,
<span>EBBR</span>, <span>LBBR</span>, <span>SBBR</span>, <span>SBSA</span> and other <abbr title="Three Letter Acronym">TLAs</abbr> and <abbr title="Other Four Letter Acronym">OFLAs</abbr>.</p>
	</div></div>]]>
            </description>
            <link>https://marcin.juszkiewicz.com.pl/2021/02/26/standards-in-arm-space-part-iii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281831</guid>
            <pubDate>Sat, 27 Feb 2021 01:28:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alex Becker's 10 Pillars of Wealth Book Summary]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281716">thread link</a>) | @shankarro
<br/>
February 26, 2021 | http://benwajdi.com/2021/02/27/alex-beckers-10-pillars-of-wealth-book-summary-review/ | <a href="https://web.archive.org/web/*/http://benwajdi.com/2021/02/27/alex-beckers-10-pillars-of-wealth-book-summary-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="bsf_rt_marker"><div kcite-section-id="656">
<div><!-- Superb Social Share and Follow Buttons --><p>Follow us on Social Media</p></div>
<hr>



<blockquote><p>That’s why I had to write this book: to set the record straight about online businesses and generating wealth in general.</p><cite><a href="https://alexbecker.org/" target="_blank" rel="noreferrer noopener">Alex Becker</a></cite></blockquote>



<p>PS: This is a long post for focused and curious minds only. So if you are a caffeine addict, grab a cup of coffee (like these <a href="http://benwajdi.com/go/bulletproof-tanzania-coffee/" target="_blank" rel="noreferrer noopener">clean bulletproof bean from Mlama, Tanzania</a>), and follow through this post about WEALTH.</p>



<p><em>Pillar: an upright shaft that supports an overhead structure. (Merriam-Webster’s Online Thesaurus)</em></p>



<p>Oh Pillars! And the first thing that came to mind is a picture of these beautiful Greek temples. Good old style marble Greek Pillars. But in Alex Becker’s <a href="https://amzn.to/2ZUf6MX" target="_blank" rel="noreferrer noopener">book</a>, there are Pillars too, but pillars of wealth, and they count up to 10. These are your Core Beliefs, your basic yet essential weapons on your way to wealth.</p>



<center><a target="_blank" href="https://www.amazon.com/gp/offer-listing/B07X3WBSCV/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B07X3WBSCV&amp;linkCode=am2&amp;tag=benwajdi-20&amp;linkId=7cd4773989740b4c5aaf4b2a0cf1b5a1" rel="noopener"><img src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=B07X3WBSCV&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=benwajdi-20"></a></center>



<p>This book is about grounding new beliefs in our heads, while eliminating old poisonous and limiting ones that we usually inherit from our environments. It turns out there is a way to win in life (at least financially) and there is a way that gets us there. Once we figure out the road, once we start making ‘a little bit of money’ we can’t help but want to make even more. </p>



<p>The reason why so many people get rich and others stay poor, is that those who have gotten rich came to a very low or bad point in life AND consequently they decided there is no way they are going to stay that way, they reached rock bottom and they know how things look, feel, and smell down there so they decided to promise themselves that no matter what they will escape serfdom, they said to themselves ‘By god I am gonna be financially independent’. </p>



<p>You have to reject the idea that to become rich you need to e special, a marketing genius, or lucky. The author warns us from the start, that is the number one prerequisite before plunging into the rest of the book.</p>



<p>I like how Alex compares the difficulty of getting rich to that of improving at video games, though I don’t pay video games, I could get his point, which is summarized in 3 parts:<br></p>



<ol><li>Believe you can get great at something.</li><li>Then play the ‘game’ over and over again</li><li>Don’t give up until 1 is accomplished</li></ol>



<p><em><strong>==&gt;Break the limiting beliefs.</strong></em></p>




<h2><span id="About_Alex_Becker"></span>About Alex Becker<span></span></h2>



<p>The most woke empty house billionaire business guy, also known as Alex Becker.</p>



<ul><li>He completed his four years term with the Air Force.</li></ul>



<ul><li>He started looking for way to generate income online.</li></ul>



<ul><li>He stumbled upon SEO.</li></ul>



<ul><li>Alex started building websites, ranking them really good on Google, and started to make an income. At one point he got <a href="http://benwajdi.com/go/sogoodatseo/" target="_blank" rel="noreferrer noopener">so good at SEO</a>, within few months, that he was offered a job at a marketing agency; he took it.</li></ul>



<blockquote><p>I began to work on my own business every second I got so I could grow it enough that I could quit my marketing agency job. When I got home from my job, I worked. While my friends were playing video games at night, I worked. While everyone I knew was at the pool drinking on the weekend, I worked.<br>Then, two months later, I was generating over $20,000 a month from my business, not including my job’s paycheck. At that point, I quit my job and never looked back.</p></blockquote>



<ul><li>With $6,000 in his retirement account, he went all in with his online business.</li></ul>



<ul><li>He built an SEO business from scratch called ‘Source Wave’, scaled it, and then sold it.</li></ul>



<ul><li>Founded HYROS, an ad AI-based tracking tool for businesses that spend 6 figures+ per month on ads. <a rel="noreferrer noopener" href="https://hyros.com/" target="_blank">Hyros</a> work with celebrity/influencer such as <a rel="noreferrer noopener" href="https://www.deangraziosi.com/" target="_blank">Dean Graziosi</a> and <a rel="noreferrer noopener" href="https://twitter.com/TomBilyeu" target="_blank">Tom Bilyeu</a>, eCommerce brands such as <a rel="noreferrer noopener" href="https://billygeneismarketing.com/" target="_blank">Billy Gene</a>, Dan Henry, <a rel="noreferrer noopener" href="https://kinobody.com/" target="_blank">Kinobody</a>, <a rel="noreferrer noopener" href="https://clickfunnels.com/" target="_blank">clickfunnels</a>, and <a rel="noreferrer noopener" href="https://www.impacttheory.com/" target="_blank">ImpactTheory</a>.</li></ul>



<h2><span id="3_Different_Types_of_Businesses"></span>3 Different Types of Businesses<span></span></h2>



<ul><li>CF:</li></ul>



<figure><img loading="lazy" width="1024" height="678" src="https://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesCF-1024x678.png" alt="" srcset="http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesCF-1024x678.png 1024w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesCF-300x199.png 300w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesCF-768x508.png 768w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesCF-1536x1017.png 1536w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesCF-2048x1356.png 2048w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesCF-1200x794.png 1200w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesCF-1980x1311.png 1980w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Cash Flow Businesses</figcaption></figure>



<p>Cash Flow Businesses (CF) are the easiest to start. They require little to no capital.No staff or overhead. You can start a CF business from your bedroom if you want.<br>These businesses take a lot of time to run and manage, because it is usually a one -man operation; you will be the one providing a service to a client, marketing and promoting your services, and also the one doing the accounting and every other details. And that’s why, scaling this business is often not an option, and a well-defined cap on revenues, income &amp; profits can estimated from the beginning. With all this being said, expect a profit margin up to 90%.</p>



<ul><li>High Investment Scalable Businesses (HIS):<br></li></ul>



<figure><img loading="lazy" width="1024" height="678" src="https://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesHIS-1024x678.png" alt="" srcset="http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesHIS-1024x678.png 1024w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesHIS-300x199.png 300w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesHIS-768x508.png 768w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesHIS-1536x1017.png 1536w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesHIS-2048x1356.png 2048w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesHIS-1200x794.png 1200w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesHIS-1980x1311.png 1980w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>High Investment Scalable Businesses</figcaption></figure>



<p>This is the type of business that Venture Capitalists, like <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Naval_Ravikant" target="_blank">Naval Ravikant</a> or <a href="https://en.wikipedia.org/wiki/Chamath_Palihapitiya" target="_blank" rel="noreferrer noopener">Chamath Palihapitiya</a>, are constantly looking for to invest in. These businesses oftentimes ‘explode out of nowhere’ even after years of being stuck or incurring losses.<br>These businesses are very scalable by their own definition. In a business like this, you need to pay close attention to every little detail: hiring the right people, studying competitors, and doing proper market research, etc…<br>Lunching a High Investment Scalable business requires some chunk of starting capital however. And that’s why, Alex Becker advises the reader who are still beginners to start with Cash Flow Business and then they can put their into a HIS business, should they want to. This model of businesses is very scalable, and usually can be automated.</p>



<ul><li>Long-Term Investment Businesses (LTI):</li></ul>



<figure><img loading="lazy" width="1024" height="678" src="https://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesLTI-1024x678.png" alt="" srcset="http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesLTI-1024x678.png 1024w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesLTI-300x199.png 300w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesLTI-768x508.png 768w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesLTI-1536x1017.png 1536w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesLTI-2048x1356.png 2048w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesLTI-1200x794.png 1200w, http://benwajdi.com/wp-content/uploads/2021/02/differenttypesofbusinessesLTI-1980x1311.png 1980w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Long-Term Investment Businesses</figcaption></figure>



<p>This is where you can ‘park’ your money and can expect sometimes as high as 10%-15% ROI per year. Think investing in rental properties or in restaurants. It is relatively safe form of investing (as long as the economy doesn’t collapse) and the businesses you invest your money in are still sell-able.</p>



<h2><span id="Decide_to_Become_Wealthy_at_Any_Cost"></span>Decide to Become Wealthy at Any Cost<span></span></h2>



<blockquote><p>The longer I live, the more I am certain that the great difference between men—between the feeble and the powerful, the great and the insignificant—is energy, invincible determination—a purpose once fixed, and then—death or victory!</p><cite><a href="https://en.wikipedia.org/wiki/Thomas_Fowell_Buxton" data-type="URL" data-id="https://en.wikipedia.org/wiki/Thomas_Fowell_Buxton" target="_blank" rel="noreferrer noopener">Thomas Fowell Buxton</a></cite></blockquote>



<p>By god, I am going to get rich! It’s a personal decision, a kind-of an intimate transaction between you and you only, you have your own reasons and motives and no body has the right to ask you about them. Just make them fuel you. Alex Becker, and throughout the book, emphasize the importance of getting to a very low point or extremely bad situation in life where for some people this decision becomes inevitably, and hence becoming wealthy becomes inevitable. (it’s just a matter of time)</p>



<p>Most people never become wealthy. Why? They never decide to get rich. And why? Because, they don’t believe that they can get rich because of X, Y, and Z.</p>



<p>As selfish as it looks on paper, and in life, believing it, seeing it, perceiving the whole thing before it comes to fruition is an indispensable prerequisite to actually getting it.<br>You may not a be spiritual person, you may not believe in superstitions, and stick only to reason and rationality, even so, you got to have this one belief, a one that has nothing to back it in today’s reality but that you have to have to get to your destination.</p>



<h2><span id="Reject_Getting_Rich_Slow"></span>Reject Getting Rich Slow<span></span></h2>



<p>This one from Becker really reminds me of <a href="http://benwajdi.com/2020/12/30/mj-demarco-the-millionaire-fastlane-book-review/" target="_blank" rel="noreferrer noopener">MJ DeMacro’s The Millionaire FastLane</a>. I wouldn’t even be surprised that DeMacro inspired Alex to go on and achieve what he has achieved so far</p>



<p>Don’t be “mildly miserable” like the rest. They are wrong, and that’s why they are the stuck traffic fighter who end up in jobs they hate because it’s ‘secure’.</p>



<p>The slow low risk way to getting wealthy is not risk free at all. In fact, its risks are uncontrollable. You are gambling your future’s outcome on variables outside the scope of your control; things like the economy, the value of the currency you are holding your savings in, the performance of the company you are working for(and whether or not they are going to lay off some employees when the going gets tough).</p>



<blockquote><p>getting rich slowly requires you to spend 71 percent of your days for the rest of your young life at work.</p></blockquote>



<p>The big reward at the end of the work tunnel. It’s an illusion! You might day before even get to there.</p>



<p>Get-rich slowly:</p>



<ul><li>extreme financial hardships</li><li>zero control on your financial future</li><li>spend 71% of your young lifespan on work(5 days out of 7 a week)</li><li>No chance of getting your dream/fantasy life</li><li>Constantly living under financial stress (worrying about money all the time)</li><li>All you your decision are based around money (or the lack of it)</li></ul>







<h2><span id="Separate_Your_Time_from_Your_Income"></span>Separate Your Time from Your Income<span></span></h2>



<p>Everyone have limited time (24 hours a day), so trying to tie your income to your disposable time is a very bad idea and it is literally putting a cap on how much money you will be making from the start. It’s been said over and over again, nobody ever got rich alone. You need other people to help you produce, sell , promote, communicate, and eventually buy from you. This is the reason why many successful business-people are good at dealing with people. And even the ones who are not so good at dealing with people and still went on to be successful, often you will discover that they hired the right employees to take care of that for them.</p>



<p>And so, you are facing two options:<br>=&gt;Either you spend all your time trying to do everything by yourself, and therefore your income isn’t under your control<br>=&gt;Or you increase the value of your time and completely separate your time from your income<br></p>



<blockquote><p>Instead of spending our time working, we should spend our time creating systems that do the work for us.</p></blockquote>



<ul><li>Clone yourself, either by hiring a super productive team, by building or buying, or subscribing to AI/tech/tools, that will bring your expenses down and profits up. (Examples would be using services like <a href="https://benwajdi.com/go/fiverr-business/" data-type="URL" target="_blank" rel="noreferrer noopener">Fiverr Business</a> for outsourcing and hiring across borders, solutions like <a rel="noreferrer noopener" href="https://tipalti.com/" target="_blank">Tipalti</a> that will take care of your Invoice Management + TAX, VAT, and Global Payments to your clients/suppliers, companies like <a rel="noreferrer noopener" href="https://www.ripl.com/" target="_blank">Ripl</a> for upping your branded content game on social media, or using <a rel="noreferrer noopener" href="https://biz.yelp.com/" target="_blank">Yelp for Business</a> to connect to new customers, or Banking easier with <a rel="noreferrer noopener" href="https://banknovo.com/" target="_blank">Bank Novo</a>)</li><li>Find a process or formula that works, then clone it.</li><li>It is better to have a business that …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://benwajdi.com/2021/02/27/alex-beckers-10-pillars-of-wealth-book-summary-review/">http://benwajdi.com/2021/02/27/alex-beckers-10-pillars-of-wealth-book-summary-review/</a></em></p>]]>
            </description>
            <link>http://benwajdi.com/2021/02/27/alex-beckers-10-pillars-of-wealth-book-summary-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281716</guid>
            <pubDate>Sat, 27 Feb 2021 01:05:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RepoDash: Performance Metrics for GitHub Repositories]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281676">thread link</a>) | @gilad
<br/>
February 26, 2021 | https://laurencemolloy.github.io/RepoDash/ | <a href="https://web.archive.org/web/*/https://laurencemolloy.github.io/RepoDash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
          <p>Performance metrics for Github repositories</p>
        
        <p><a href="https://github.com/LaurenceMolloy/RepoDash">View the Project on GitHub <small></small></a></p>
        <ul>
        
          <li><a href="https://github.com/LaurenceMolloy/RepoDash"><strong>View On GitHub</strong></a></li>
		<li><a href="https://laurencemolloy.github.io/RepoDash"><strong>About</strong></a></li>
		<li><a href="https://laurencemolloy.github.io/RepoDash/docs/userguide"><strong>User<br>Guide</strong></a></li>
		<li><a href="https://laurencemolloy.github.io/RepoDash/docs/technical"><strong>Technical<br>Docs</strong></a></li>
        </ul>
      </header>
      <section>

      <p><img src="https://laurencemolloy.github.io/RepoDash/docs/images/RepoDash_screenshot.png" alt="Screenshot"></p>

<p>See our <a href="https://laurencemolloy.github.io/RepoDash/"><strong>github.io pages</strong></a> 
for detailed instructions on how to use RepoDash.</p>



<p>Do you maintain a project codebase on Github? Would you like to be able to collate statistics 
that summarise historic monthly activity on that codebase and see, at a glance, how that impacts 
the project issues list over time? Would you like to be able to perform this analysis for any 
given time period of your choosing?</p>

<p>RepoDash can do just this. It uses the Github API to collect repository data and generate a 
data visualisation of a range of historic metrics of the project issues list over a user-specified 
period of time. For each calendar month in the time period of interest, it displays the following 
metrics:</p>

<ul>
<li>The number of new issues created</li>
<li>How many of these issues are still open at the time of generating the dashboard</li>
<li>How many of these issues still require triage (labelling) at the time of generating the dashboard</li>
<li>The number of existing issues resolved</li>
<li>The percentage split between opened / closed issues</li>
<li>The aggregate number of open issues in the issues list (month start &amp; month end)</li>
<li>The aggregate number of open issues in the issues list requiring triage (month start &amp; month end)</li>
<li>The change in total number of open issues over the month</li>
<li>The average age and age spread of open issues in the isssues list</li>
</ul>


<p>It also displays aggregate counts for the most frequently used labels for all issues that remained open
at the end of the displayed time period.</p>

<h3>Typical Use Cases</h3>

<p>Perhaps you are managing an open source project, the maintenance of which you'd like to keep on top 
of. Or perhaps you manage a software product at work where you are required to provide your boss with 
exective summary updates of your support team's progress on an ongoing monthly basis. Either way, if 
your codebase is managed via Github, RepoDash could be just what you need.</p>

<h3>Demo Mode</h3>

<p>For demo purposes, this code processes the first 10 pages of the matplotlib<sup>1</sup> project and 
displays the most recent 12 months of metrics by default. Command line arguments allow you to set your
own project repository and analysis timeframe. It couldn't be simpler.</p>

<p><sup>1</sup> <em><a href="https://matplotlib.org/"><strong>matplotlib</strong></a> is a popular open science 
plotting library for python which is utilised by RepoDash to generate its data visualisations</em></p>

<h3>Future Development</h3>

<p>This project is a work in progress. The current version of RepoDash has only been tested with open 
source (public) projects. However, there are plans to ensure that it works with private ones as well. 
Over time, we also plan to build on the range of metrics offered and make it easy for the user to select 
which metrics to display... watch this space!</p>


      </section>
    </div></div>]]>
            </description>
            <link>https://laurencemolloy.github.io/RepoDash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281676</guid>
            <pubDate>Sat, 27 Feb 2021 01:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting brain activity with Neural Nets and TensorFlow is easy(-ish)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281492">thread link</a>) | @pizza
<br/>
February 26, 2021 | https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html | <a href="https://web.archive.org/web/*/https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    
      
      <span>
        
        <time datetime="2020-12-13T02:28:37+00:00">December 13, 2020</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section itemprop="text">
        
          
        
        <p>Over-fitting is a lie.</p>

<h2 id="backgroud">Backgroud</h2>

<p>I <a href="https://drorcohengithub.github.io/website/decoding/encoding/fmri/2020/07/31/decoding_visual_experience.html">previously talked about</a> predicting and decoding brain activity as recorded using fMRI. In that post I followed the tried and true approach of (1) extracting some features from the stimulus and (2) fitting a regularised linear regression from the features to brain activity. It works really well.</p>

<p>One of the reasons we use linear regression in these type of “encoding” studies is that there is not much data. For example in that study the training set had only about 7200 samples (which is quite a lot by fMRI community standards). The traditional thinking is that very rich models, such as deep neural nets (NNs) with millions of parameters, will disastrously over-fit in this type of situation, resulting in low performance. However, this traditional thinking may be out of date.</p>

<p>A <a href="https://www.biorxiv.org/content/10.1101/2020.09.11.293878v1">recent paper uploaded to bioarxiv</a> generated some discussion in our lab. It is a very thorough study looking at predicting brain activity using deep NNs with many interesting results. Among these results, the authors show that replacing the linear regression with a NN provides a substantial improvement over linear regression (see also <a href="https://www.frontiersin.org/articles/10.3389/fncom.2019.00021/full">here</a>).</p>

<p>I think is pretty likely that with some effort and a lot of NN know-how an expert can improve on the performance of a linear model. But I figured that avoiding over-fitting in this situation is going to be really hard, and that an out of the box implementation would perform disastrously. So I thought I’d give it a go.</p>

<p>In this post I go through fitting a simple NN, though still with millions of parameters, to predict brain activity. I’ll use a vanilla NN paired with the same data I analyzed in my previous post. This way we will have a direct comparison with the linear model. A full notebook to reproduce this is up on my <a href="https://github.com/drorcohengithub/Prediciting_BOLD_with_TensorFlow">github</a>.</p>

<h2 id="preparations">Preparations</h2>

<p>We will use the same data from last time. For convenience I put everything you’ll need <a href="https://figshare.com/s/9803543b6736009e7a83">here</a>.</p>

<div><div><pre><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>"font.size"</span><span>]</span> <span>=</span> <span>"20"</span>

<span>import</span> <span>tensorflow</span> <span>as</span> <span>tf</span>
<span>from</span> <span>tensorflow</span> <span>import</span> <span>keras</span>
<span>from</span> <span>tensorflow.keras</span> <span>import</span> <span>layers</span>
<span>from</span> <span>tensorflow.keras.callbacks</span> <span>import</span> <span>Callback</span>
<span>from</span> <span>tensorflow.keras</span> <span>import</span> <span>backend</span> <span>as</span> <span>K</span>
</code></pre></div></div>

<div><div><pre><code><span>#load the preproc data from before
</span><span>with</span> <span>np</span><span>.</span><span>load</span><span>(</span><span>"./data.npz"</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>print</span><span>(</span><span>f</span><span>.</span><span>files</span><span>)</span>
    <span>voxel_test_data</span> <span>=</span> <span>f</span><span>[</span><span>"voxel_test_data"</span><span>]</span>
    <span>voxel_train_data</span> <span>=</span> <span>f</span><span>[</span><span>"voxel_train_data"</span><span>]</span>
    <span>ME_features_train_data</span> <span>=</span> <span>f</span><span>[</span><span>"ME_features_train_data"</span><span>]</span>
    <span>ME_features_test_data</span> <span>=</span> <span>f</span><span>[</span><span>"ME_features_test_data"</span><span>]</span>
    <span>linear_model_acc</span> <span>=</span> <span>f</span><span>[</span><span>"linear_model_acc"</span><span>]</span>
</code></pre></div></div>

<ul>
  <li><strong>voxel_train_data</strong> this is the brain activity data we will use to train the model</li>
  <li><strong>voxel_test_data</strong> this is the brain activity data we will use in the final test of the model</li>
  <li><strong>ME_features_train_data</strong> this is the ME feature data we will use to train the model. The feature vector consists of stacking together four consecutive delays (t-3 to t-6, see the <a href="https://drorcohengithub.github.io/website/decoding/encoding/fmri/2020/07/31/decoding_visual_experience.html">original post</a> for details)</li>
  <li><strong>ME_features_test_data</strong> this is the ME feature data we will use in the final test of the model</li>
  <li><strong>linear_model_acc</strong> this is the accuracy data for the linear model. This is calculated as the pearsons correlation between the model predictions and the test data (i.e. voxel_test_data)</li>
</ul>

<p>I restrict the analysis to the 2000 voxels that were best predicted using the linear model. This is a bit harsh on our NN here because it is possible that the NN improves on voxels that the linear model was poor at predicting, so keep that in mind.</p>

<div><div><pre><code><span>feature_dim</span> <span>=</span> <span>ME_features_train_data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
<span>num_voxels</span> <span>=</span> <span>voxel_train_data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
</code></pre></div></div>

<h2 id="the-network">The network</h2>

<p>We first need to decide on the structure of the network. There is now a whole zoo of network architectures and I think it is pretty likely that many of them are superior to the linear model. However, the point here to see how well an “out of the box” NN works. Nothing is more vanilla than a tutorial, so I will use the architecture from the <a href="https://www.tensorflow.org/tutorials/keras/regression">TensorFlow regression tutorial</a>. The architecture has two hidden, densely connected layers with relu activations. We will be fitting a mere 1,812,304 parameters.</p>

<p>There really is no reason to think that this architecture is suited to our specific problem. But if something like this <em>does</em> work, then it may not be so difficult to come up with a NN that is superior to the linear model.</p>

<p>To the model.</p>

<div><div><pre><code><span># repeatable intialization of the weights
</span><span>initializer</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>initializers</span><span>.</span><span>GlorotNormal</span><span>(</span><span>seed</span><span>=</span><span>1</span><span>)</span>

<span>vanilla</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>Sequential</span><span>([</span>
    <span>tf</span><span>.</span><span>keras</span><span>.</span><span>Input</span><span>(</span><span>shape</span><span>=</span><span>[</span><span>feature_dim</span><span>]),</span>
    <span>layers</span><span>.</span><span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span><span>kernel_initializer</span><span>=</span><span>initializer</span><span>),</span> <span># set the initial weights
</span>    <span>layers</span><span>.</span><span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span><span>kernel_initializer</span><span>=</span><span>initializer</span><span>),</span>
    <span>layers</span><span>.</span><span>Dense</span><span>(</span><span>num_voxels</span><span>)</span>
<span>])</span>
<span>vanilla</span><span>.</span><span>summary</span><span>()</span>
</code></pre></div></div>

<div><div><pre><code>Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 64)                1678144   
_________________________________________________________________
dense_7 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_8 (Dense)              (None, 2000)              130000    
=================================================================
Total params: 1,812,304
Trainable params: 1,812,304
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div><div><pre><code><span>keras</span><span>.</span><span>utils</span><span>.</span><span>plot_model</span><span>(</span><span>vanilla</span><span>,</span> <span>show_shapes</span><span>=</span><span>True</span><span>,</span><span>to_file</span><span>=</span><span>'vanilla.png'</span><span>)</span>
</code></pre></div></div>

<figure>
  <img src="https://drorcohengithub.github.io/website/assets/images/vanilla.png" alt=""><figcaption>
      Model structure

    </figcaption></figure>

<h3 id="the-optimizer">The optimizer</h3>

<p>The next thing is to choose an optimizer for the network. The tutorial used ADAM with a hardwired learning rate, but I went with a simple weight decay approach. Standard stuff, though I did manually tweak it a bit. A more principled approach is to optimize this using cross validation or something but for simplicity I’ll keep this as is.</p>

<div><div><pre><code><span># initial learning rate
</span><span>initial_learning_rate</span> <span>=</span> <span>0.0001</span>
<span>#expontential decay
</span><span>lr_schedule</span> <span>=</span> <span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>schedules</span><span>.</span><span>ExponentialDecay</span><span>(</span>
<span>initial_learning_rate</span><span>,</span>
<span>decay_steps</span><span>=</span><span>1000</span><span>,</span>
<span>decay_rate</span><span>=</span><span>0.8</span><span>)</span>
</code></pre></div></div>

<h3 id="compile">Compile</h3>
<p>Put it all together</p>

<div><div><pre><code><span># optimize mean squared error
</span><span>vanilla</span><span>.</span><span>compile</span><span>(</span>
    <span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>lr_schedule</span><span>),</span><span>#
</span>    <span>loss</span><span>=</span><span>'mean_squared_error'</span><span>,</span>
    <span>metrics</span><span>=</span><span>[</span><span>"mean_squared_error"</span><span>])</span>
</code></pre></div></div>

<h3 id="custom-callback-to-monitor-things">Custom callback to monitor things</h3>

<p>As I mentioned, the performance of the model is assess as the correlation between the predicted and actual response (more on this later). This will quickly evaluate our model performance</p>

<div><div><pre><code><span>zs</span> <span>=</span> <span>lambda</span> <span>v</span><span>,</span><span>dim</span><span>=</span><span>0</span><span>:</span> <span>(</span><span>v</span><span>-</span><span>v</span><span>.</span><span>mean</span><span>(</span><span>dim</span><span>,</span><span>keepdims</span><span>=</span><span>True</span><span>))</span><span>/</span><span>v</span><span>.</span><span>std</span><span>(</span><span>dim</span><span>,</span><span>keepdims</span><span>=</span><span>True</span><span>)</span>

<span>def</span> <span>respective_correlation</span><span>(</span><span>x</span><span>,</span><span>y</span><span>,</span><span>dim</span><span>=</span><span>0</span><span>):</span>

    <span>"""
        shape is samps by vars/featurs   
    """</span>  

    <span>num_samps</span> <span>=</span> <span>x</span><span>.</span><span>shape</span><span>[</span><span>dim</span><span>]</span>
    <span>if</span> <span>not</span> <span>np</span><span>.</span><span>array_equal</span><span>(</span><span>x</span><span>.</span><span>shape</span><span>,</span> <span>y</span><span>.</span><span>shape</span><span>):</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'x and y must have same shape'</span><span>)</span>

    <span>corrs</span> <span>=</span> <span>(</span><span>zs</span><span>(</span><span>x</span><span>,</span><span>dim</span><span>)</span> <span>*</span> <span>zs</span><span>(</span><span>y</span><span>,</span><span>dim</span><span>)).</span><span>mean</span><span>(</span><span>dim</span><span>)</span>

    <span>return</span> <span>corrs</span>
</code></pre></div></div>

<div><div><pre><code><span># We create a custom call back to report on how things are progressing in the end of each epoch
</span><span>class</span> <span>CustomCallback</span><span>(</span><span>Callback</span><span>):</span>

    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>val_data</span><span>):</span> <span># this gives us access to the validation data (see https://github.com/keras-team/keras/issues/10472 )
</span>        <span>super</span><span>().</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>validation_data</span> <span>=</span> <span>val_data</span>

    <span>def</span> <span>on_epoch_end</span><span>(</span><span>self</span><span>,</span> <span>epoch</span><span>,</span> <span>logs</span><span>=</span><span>{}):</span> <span># on the end of each training epoch get
</span>
        <span># the current learning rate
</span>        <span>current_lr</span> <span>=</span> <span>self</span><span>.</span><span>model</span><span>.</span><span>optimizer</span><span>.</span><span>_decayed_lr</span><span>(</span><span>'float32'</span><span>).</span><span>numpy</span><span>()</span>

        <span># the correlation between the predicted and actual response
</span>        <span>for</span> <span>val</span> <span>in</span> <span>val_dataset</span><span>:</span> <span># calculate correlation on the validation data
</span>            <span>mdl_pred</span> <span>=</span> <span>self</span><span>.</span><span>model</span><span>.</span><span>predict</span><span>(</span><span>val</span><span>[</span><span>0</span><span>])</span>        
            <span>val_corr</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>respective_correlation</span><span>(</span><span>mdl_pred</span><span>,</span> <span>val</span><span>[</span><span>1</span><span>].</span><span>numpy</span><span>()))</span>

        <span># add it to the logs (not sure if this is the correct way to do it but it works)
</span>        <span>logs</span><span>[</span><span>"val_corr"</span><span>]</span> <span>=</span> <span>val_corr</span>
        <span>print</span><span>(</span><span>f</span><span>"current lr </span><span>{</span><span>current_lr</span><span>:.</span><span>2</span><span>E</span><span>}</span><span> corr </span><span>{</span><span>val_corr</span><span>:.</span><span>03</span><span>f</span><span>}</span><span>,</span><span>\
</span><span>        MSE </span><span>{</span><span>logs</span><span>[</span><span>'val_mean_squared_error'</span><span>]:.</span><span>06</span><span>f</span><span>}</span><span>"</span><span>)</span> <span>#, loss {logs['val_loss']:.06f}
</span></code></pre></div></div>

<h2 id="prepare-the-training-and-validation-data">Prepare the training and validation data</h2>

<p>I will keep some data aside for validation as we train the model. The key thing to remember here is that we are using time series data. This means that the data is not iid. If we just grabbed samples randomly for validation then there is a good chance that dependent samples will be in the training set. For example, we may end up with sample at t=n in the val set but t=n-1 in the training set. These are dependent, and in fact likely to be quite similar. In this case performance on the validation test will reflect something of double dipping and probably be much higher than what we get on the final test set.</p>

<p>I will very crudely grab three chunks of 200 samples at intervals of 2000, 4000 and 6000 samples. This is completely arbitrary and pretty poor practice. We did much better on the ridge regression in the previous post, but I think it is good enough for illustration. Note that we might have a bit of leakage (since the samples around these chunks are still in the training set), but I think it is not too much of a worry.</p>

<div><div><pre><code><span>all_data_inds</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>ME_features_train_data</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>])</span>
<span>#keep the first, take three, chunk_len samples long chunks for validation
</span><span>chunk_len</span> <span>=</span> <span>200</span>
<span>chunk_starts</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>2</span><span>,</span><span>4</span><span>,</span><span>6</span><span>])</span><span>*</span><span>1000</span>
<span>chunk_ends</span> <span>=</span> <span>chunk_starts</span><span>+</span><span>chunk_len</span>
<span>val_inds</span> <span>=</span> <span>np</span><span>.</span><span>concatenate</span><span>([</span><span>np</span><span>.</span><span>arange</span><span>(</span><span>strt</span><span>,</span><span>stp</span><span>)</span> <span>for</span> <span>strt</span><span>,</span><span>stp</span> <span>in</span> <span>zip</span><span>(</span><span>chunk_starts</span><span>,</span><span>chunk_ends</span><span>)])</span>
<span>trn_inds</span> <span>=</span> <span>np</span><span>.</span><span>delete</span><span>(</span><span>all_data_inds</span><span>,</span><span>val_inds</span><span>)</span>
</code></pre></div></div>

<p>TensorFlow likes its data in a particular way. This is <em>really</em> irritating to me.</p>

<div><div><pre><code><span>train_dataset</span> <span>=</span> <span>tf</span><span>.</span><span>data</span><span>.</span><span>Dataset</span><span>.</span><span>from_tensor_slices</span><span>((</span><span>ME_features_train_data</span><span>[</span><span>trn_inds</span><span>,:],</span> <span>voxel_train_data</span><span>[</span><span>trn_inds</span><span>,:]))</span>
<span># organized in batches ofo 32 to update the gradients (I think this is default)
</span><span>train_dataset</span> <span>=</span> <span>train_dataset</span><span>.</span><span>batch</span><span>(</span><span>32</span><span>)</span>

<span># Prepare the validation dataset
</span><span>val_dataset</span> <span>=</span> <span>tf</span><span>.</span><span>data</span><span>.</span><span>Dataset</span><span>.</span><span>from_tensor_slices</span><span>((</span>…</code></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html">https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html</a></em></p>]]>
            </description>
            <link>https://drorcohengithub.github.io/website/decoding/encoding/fmri/tensorflow/neural/2020/12/13/Predicting-brain-activity-using-NN-and-TensorFlow.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281492</guid>
            <pubDate>Sat, 27 Feb 2021 00:31:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatcat is a new robot for your home]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281376">thread link</a>) | @zdw
<br/>
February 26, 2021 | https://jetpack.cl/your-next-robot-is-a-pet/ | <a href="https://web.archive.org/web/*/https://jetpack.cl/your-next-robot-is-a-pet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-764" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			
<p><strong>flatcat is a new robot</strong> <strong>for your home</strong></p>



<p>Jetpack Cognition Lab, a Berlin-based AI and robotics startup, today announced flatcat, a new consumer robot, to be launched in March 2021. flatcat is a firm and fluffy AI pet for the living room, that responds to touch and gravity, and has a playful life of its own.</p>



<figure><img loading="lazy" width="1800" height="1000" src="https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo.jpg" alt="" srcset="https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo.jpg 1800w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-1000x556.jpg 1000w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-768x427.jpg 768w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-1536x853.jpg 1536w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-500x278.jpg 500w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-800x444.jpg 800w, https://jetpack.cl/wp-content/uploads/2021/02/jcl_flatcat_foto_lo-1280x711.jpg 1280w" sizes="(max-width: 1800px) 100vw, 1800px"></figure>



<p>flatcat invites to experience a new dimension of touch and motion. Cuddle with it, have a gentle romp, or just watch it do weird things on its own, to caress your soul. The robot feels everything exactly with cognitive sensorimotor loops based on ten years of developmental robotics research. flatcat has no face, no app, no cloud, full privacy. It is built around a 3D printed skeleton and is powered by Jetpack Cognition Lab‘s own electrical motor design.</p>



<p>The new product will be available on Kickstarter and selected outlets beginning March 3, 2021. Visit https://flatcat.berlin for more information.</p>



<p><strong>Links</strong><br><a href="https://flatcat.berlin/" target="_blank" rel="noreferrer noopener">https://flatcat.berlin</a></p>



<p><strong>About Jetpack Cognition Lab</strong><br>Established in 2019, Jetpack Cognition Lab is a Berlin-based AI and Robotics startup and innovation hub. Founded by Oswald Berthold and Matthias Kubisch, it specializes in science transfer and product research. The company’s bioinspired hardware and software design is built on the neuroscience and psychology of developmental learning.</p>








		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://jetpack.cl/your-next-robot-is-a-pet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281376</guid>
            <pubDate>Sat, 27 Feb 2021 00:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tech Twitter sucks: interview with founder turned VC]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26281193">thread link</a>) | @smalera
<br/>
February 26, 2021 | https://www.businessofbusiness.com/articles/Alex-Cohen-thinks-tech-twitter-is-boring/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/Alex-Cohen-thinks-tech-twitter-is-boring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p>Alex Cohen knows his way around the tech industry. He's been working in startups since he was in college, and went on to co-found fintech company <a href="https://www.businessofbusiness.com/articles/trying-to-get-in-on-the-fintech-gold-rush-dont-says-birch-co-founder-alex-cohen/">Birch</a>, which was acquired in 2018 by Even Financial. Today, he works as Direct of Poduct at Carbon Health and is a part-time investor at Bloom Venture Partners. But his Twitter feed doesn't look&nbsp;the way you might expect.</p>
<p>In a world where VCs and startup founders are often content to tweet <a href="https://www.businessofbusiness.com/articles/top-10-craziest-vc-tweets-startups/">vaguely inspiring one-liners</a> or tout their successes in threads,&nbsp;Cohen chooses to do the opposite. Follow him for long enough, and you'll often see him as the loudest voice on the other side of the aisle, criticizing or mocking posts from other notable, popular figures in the industry — something which he's gotten his fair share of flak for. His Twitter bio claims one singular purpose for existing: "<a href="https://twitter.com/anothercohen">Here to shitpost</a>."</p>
<p>We spoke to Cohen about his thoughts on the state of the discourse on&nbsp;Business Twitter, the&nbsp;state of the tech industry at large and the way it presents itself to the world.</p>
<hr>

<p><b>Business of Business: You're often the contrarian on tech Twitter, and&nbsp;</b><b>I want to talk about your thoughts on the general discourse there and why you have the stance that you do. But before we get into that, I think it would be helpful for readers to get a little bit of a background on you.&nbsp;Let's &nbsp;start at the founding of Birch and your experience with the company up to when you left Even Financial, and if any of the experiences you had during those four to five years informs the way that you see things now.</b></p>
<p><span>Cohen: I accidentally fell into startups is how I would describe it. The very first startup I joined was in Florida and was called Sharpspring — it was a marketing automation platform. Our claim to fame was Grooveshark. I don't know if you remember them. And when Grooveshark went under, Sharpspring was the next Gainesville based startup to actually do something interesting. I couldn't even tell you what a startup was at the time, but I got recruited by a friend and next thing you know, The CEO made me an equity offer to stay. I was 19 or 20 at the time and was like, “No, I need to go get a big name company on my resume. I don't think this is gonna help me.” So I left and went to JPMorgan.&nbsp;</span></p>
<p><span>And then six months later, Sharpspring was acquired for $15 million in an all cash deal. And then fast forward three or four years later, and they're now a $200 million public company. So that was probably my first mistake that I made (laughs). But I eventually came back to Sharpspring after doing the big company life. I just could not stand working at a large bank or consulting firm. I just felt like everyone was super mediocre. So I went back to Sharpspring and worked on the partnerships team. I had been experimenting with Birch before all that, and then six months later, we ended up going full time into Birch. So I quit for the second time at Sharpspring and, yeah, spent four and a half years basically trying to make a better version of Mint.com.</span></p>
<blockquote>
<p dir="ltr" lang="en">Not at all a red flag when a 4 person, pre-launch startup has a CEO, CTO, CPO, and CSO</p>
— Alex Cohen (@anothercohen) <a href="https://twitter.com/anothercohen/status/1363316383463792642?ref_src=twsrc%5Etfw">February 21, 2021</a></blockquote>

<p><span>We went up and down Sand Hill Road a couple times and got rejected by the majority of VCs, and we were raising money for the first time. Then four and a half years later, we were running out of money. So we figured out how to sell the company in a deal that sort of gave another shot on goal for the team and for investors. And then we joined Even Financial for a year — Well, I did for a year, the rest of the team stayed for two years or more. And then I just took some time off the end of 2019. I started working on some SAAS stuff that I left after it ended up taking a direction different from what I expected, and eventually got recruited by Carbon Health when I found out that the VP of Product was one of my angel investors.&nbsp;</span></p>
<p><span>Everything about Carbon is incredible. I did a lot of diligence and sort of looking into the team and the mission and the company. And it's hands down the best most talented team I've ever worked with. We're just in, like, pure hyperscale mode with COVID. Our core business is primary care and urgent care, and everything's just exploding. Tomorrow marks a month since joining them, which is crazy. But that's sort of the thing — I knew I didn't want to start another company. Being at three early stage companies got me to the point where I said, something feels a lot more interesting about joining a serious, C-stage or later company that's on track to, you know, have a large liquidity event or hopefully an IPO at some point. And I want to be a part of that and see things through the stage. And I'm very happy with that decision. It's been great.</span></p>
<p><b>Why didn’t you want to start another company? There’s always a lot of talk about how important it is to join one of these big, fast-growing companies early on, and to not make the mistake you made with Sharpspring. Could you talk a little bit more about how a Series C company one with a big liquidity event coming up is different?&nbsp;</b></p>
<p><span>I think that there's this over glorification of early stage companies. I think normally what you see is a lot of really strong founding teams, and that makes sense in terms of the equity distribution that they have early on. But I think what ends up happening in this middle stage, and why it's so hard to hire when you're pre-seed or even through Series A, is you sort of get self selected, junior people in who are more risk seeking, but typically not as talented. That is, unless the situation is that you left an Airbnb or Stripe, and you’re recruiting a team from there.&nbsp;</span></p>
<hr>
<blockquote>
<h2><span>"I see all these threads that are like, “Give a one-liner pitch for your startup and let's get you funded!” I read through them and I’m just like — most of these companies just can't raise venture money because they're just not big enough things." - Cohen</span></h2>
</blockquote>
<hr>
<p><span>I think for most people, if you're really really good, like, why would you join somewhere as employee number five or six and take 5-10% equity when the founders are at 40% or 50% unless you like unequivocally believe that that founder is super talented, and like you can get behind them. And I think that's rare. There's definitely founders like that — I can name a few like people who I would go join, but like, that's rare.&nbsp;</span></p>
<p><span>I think there's also some arguments to be made that, you know, early stage feels so doomed to fail. Like, 90% of companies fail. If you’re joining somewhere that's in a later stage series, there's lower risk and lower reward, but it's still pretty meaningful outcomes. I like to use Snowflake and Snapchat as an example. They’re outliers, but any director that you go look up on LinkedIn who joined Snowflake two years before IPO is worth upwards of, like, $30 million. And that happened because they joined when the internal fair market value of Snowflake was probably like a $600 million or $800 million cap, and then when they went public, they just skyrocketed up to $80 billion. I don't think many people do that equation. It feels good and hot to be a part of an early team, but the math doesn't work out a lot of the time. And I think I learned that over and over again. Like, how likely are these things&nbsp;to fail? Why am I trying to whack-a-mole at product market fit and build something big again when there's stuff out here that's scaling and has very good potential of getting huge from the point that I join?</span></p>
<p><b>Could you talk a little more about what the experience of getting rejected repeatedly for funding at Birch was like? You’re putting everything into this company, working long hours, and then other people aren’t willing to buy into the thing you’ve invested so much of yourself into. What’s that like?</b></p>
<p><span>I think if you can't raise venture capital, you shouldn't take it personally. And I did, but you just need to look at the sheer number of companies out there. I sit on the other side of the table now, as a venture partner at Bloom Ventures, and the majority of companies we see are just not venture-backable companies. The business just doesn't scale to a point that makes venture economics work. So I hope we see more non-traditional routes of financing for companies to grow that aren’t venture. I think there are a lot of opportunities with companies that are not going to be multi-billion dollar companies.&nbsp;</span></p>
<p><span>And that's not to say they're not going to be big companies — you can go and sell a company for $200 million and have it be an amazing outcome for the entire team. It just doesn't return the funding. I think a lot of founders are naive going into the process saying like, I deserve to raise venture capital when they're just not working on a big enough thing. I don't think enough founders&nbsp;ask themselves, “Is my company actually the right fit for what venture funds are looking for?” I see all these threads that are like, “Give a one-liner pitch for your startup and let's get you funded!” I read through them and I’m just like — most of these companies just can't raise venture money because they're just not big enough things.</span></p>
<p><b>Let’s start talking about Twitter. Like I said earlier, you and your feed really stand at the opposite end of this stuff that I typically see from VCs and founders — things like the “one-liner startup pitch” threads you mentioned. It’s a really broad question, but what’s your read overall on the way that this industry presents itself on social media?&nbsp;</b></p>
<p><span>Do you mean the toxic positivity or everyone sort of fluffing each other?</span></p>
<p><b>I guess both. I don't want to be too harsh, because, you know, obviously, these people have accomplished huge things. But I see the way people who aren't in that world react to it online as well, and I think it really frustrates people.</b></p>
<p><span>Yeah. So I think like, what I would chalk it up to is that there's very little downside to just being overly optimistic and nice and like patting everyone on the back. And I think that’s boring. I think it's the …</span></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.businessofbusiness.com/articles/Alex-Cohen-thinks-tech-twitter-is-boring/">https://www.businessofbusiness.com/articles/Alex-Cohen-thinks-tech-twitter-is-boring/</a></em></p>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/Alex-Cohen-thinks-tech-twitter-is-boring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281193</guid>
            <pubDate>Fri, 26 Feb 2021 23:45:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Every thought about personal finance I've ever had, as concisely as possible]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 81 (<a href="https://news.ycombinator.com/item?id=26281108">thread link</a>) | @aadillpickle
<br/>
February 26, 2021 | https://blog.aadilali.com/posts/personal-finance.html | <a href="https://web.archive.org/web/*/https://blog.aadilali.com/posts/personal-finance.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><nav id="63540a58-887b-43a8-802f-008032cf227a"></nav><p id="96dbe6a8-0b25-43a2-88b6-ca4688f23134"><em>NOTE: LITERALLY ZERO OF THIS IS FINANCIAL ADVICE!!! DO YOUR OWN RESEARCH!!!</em></p><h3 id="f7ffa1c1-d40e-4aac-9101-563cb5c43efd">1. Before you even think about investing, start with the personal finance fundamentals</h3><ol id="636ca7eb-6ddd-4d2a-96ee-02cfda1b58ac" start="1"><li>Pay down any debts greater than 7% per year (7% is the average yearly return for the stock market)<ul id="a08592f8-ef0a-4b25-ae93-4cb5bd4f0e54"><li>Don't even think about investing until you do this, not being charged 15% a year in interest and penalties on credit card debt gives you a 2x higher return than the average investor</li></ul></li></ol><ol id="338f55be-2d71-474c-9360-54ee494b18e1" start="2"><li>If you have the space, buy products you're guaranteed to use in bulk on sale<ul id="3b530a5d-4653-4853-983a-ccb62d628437"><li>Buying years supply of toilet paper on sale at $100 instead of $200 means a 100% rate of return - 14x the average investor</li></ul></li></ol><ol id="d22a6401-3bc3-4754-be17-d40a2fba6213" start="3"><li>Reconsider your spending habits (i.e. cut up your credit cards, return things you don't need, uninstall the amazon app and <a href="https://getcoldturkey.com/">block all the online shopping websites</a>)<ul id="e74e9c24-39de-43cf-878a-e8fb7716f238"><li>The reason you don't have money might not be because you're losing it to inflation, it's because you're losing it to $4 cups of coffee <ul id="844e56f6-5a8c-40a2-b980-b06ece4f69c4"><li>In fact, you're probably losing ~$1000 a year - if you invested that, you could have ~$650K in 40 years:<figure id="4f73cb39-38e2-423e-9c4e-714ef03e4350"><a href="https://blog.aadilali.com/posts/Every%20thought%20about%20finance%20I've%20ever%20had,%20as%20conc%204f73cb3938e2423e9c4e714ef03e4350/pfin.png"><img src="https://blog.aadilali.com/posts/Every%20thought%20about%20finance%20I've%20ever%20had,%20as%20conc%204f73cb3938e2423e9c4e714ef03e4350/pfin.png"></a></figure></li></ul></li></ul></li></ol><h3 id="7c5be926-1109-48eb-8caf-7d8768f42a8e">2. When you should (and shouldn't) buy things</h3><p id="0c7ad9de-777a-444b-a703-e2fd64c6a748">Buy things if they:</p><ol id="fb66b42a-e007-4f54-92ee-0125704a9790" start="1"><li>Spark joy, especially when buying for someone else — the emotional ROI of gift-giving is off the charts.</li></ol><ol id="61953c5a-f373-460a-8c86-a1df20760a17" start="2"><li>Get used everyday (Ex. Nice pants, laptop and phone).</li></ol><ol id="38edd8a2-4d00-455e-90c4-351dfb0e2b8b" start="3"><li>Come in between you and the ground (Ex. Mattresses, chairs, winter tires).</li></ol><ol id="dce98e87-6a65-4304-994a-fbaf12c1e596" start="4"><li>Make your life &gt;1% easier (Ex. Good cookware/knives, tools, software).</li></ol><ol id="d6357926-602c-4450-aad9-c53bee4d4845" start="5"><li>Make you better (Ex. Education, gym memberships, travel).</li></ol><p id="dccfbf19-9ddc-4278-b1e6-b8dfa92d77b8">Don't buy things if:</p><ol id="2bb2a4df-bd52-4d81-bb3d-4f34d2a515fd" start="1"><li>You pretty much already own them (Ex. The newest iPhone if you have the last gen already, anything limited edition that won't appreciate in value, cars unless somethings wrong with them).</li></ol><ol id="e14026b6-6d57-439c-baef-b19bf5115bc9" start="2"><li>They're "on sale" — by all means try to get a good deal but sometimes products "on sale" were the same price last month and you just didn't see it, use a price tracker like <a href="https://camelcamelcamel.com/">camelcamelcamel.com</a> to avoid this and make sure you're actually getting a good deal for something you will actually use. Marketing people get paid millions to make you buy things you don't need with money you don't have - outsmart them.</li></ol><ol id="2a9c7b05-6a47-4be0-a8ff-e642252f11d6" start="3"><li>They're cheap — inexpensive and cheap mean 2 different things here but generally look for quality items with lifetime warranties, 1 coat that costs $1000 but lasts 30 years has better ROI than buying a $100 coat every other year. Plus it's less mental strain since you don't have to think about replacing it and you'll get to use something you actually like.</li></ol><ol id="37763a48-4232-460c-86f0-87dcb651fea1" start="4"><li>They're heavily advertised to you — more money spent on marketing means a higher price for you since you're not just paying for the product but the salaries of the people hired to sell/advertise it to you.</li></ol><ol id="f7b4a249-f8bd-4ae4-8fb2-2329bd1b01b6" start="5"><li>You can't afford it! Treat your credit card like a debit card and even then make sure it doesn't dip below an uncomfortable balance.</li></ol><h3 id="2e2f2deb-32bc-4e8d-be04-8a43469e6060">3. Legal tax evasion strategies</h3><p id="31a30907-dbb4-4d92-a98f-4adcdc753115">There are a few ways to legally pay less taxes that the average joe usually isn't aware of. </p><p id="0dff2cad-cfef-4b44-9f44-8577b867fd68">If you have a company, incorporated or not, you can write off lots of things as business expenses like transportation, buying new equipment or rent for co-working spaces. It's also not that hard to start a company — if you're a freelancer, call yourself a consultant and start a "consulting firm" or start an e-commerce store and call yourself a sole-proprieter. Then you can hire a family member, deduct home office expenses and even if you lose money operating the business, you'll save money on taxes. </p><p id="3b719889-6616-4458-94ca-655d168fe3d5">Investing in your government's version of a retirement savings plan is tax deductible against your personal income. So are losses from the stock market. So is charitable giving!</p><p id="62423246-e396-4a48-a5de-a2435a7b19e6">Always try to max out tax free investment accounts/retirement accounts — even if you think it's not worth it the taxes breaks alone mean you come out ahead, even better if your employer matches your contributions. And at the very least, not being able to withdraw for a few decades means you'll be in it for the long run and the market always goes up in the long run.</p><h3 id="93a74cf1-8c77-4182-9946-e91424039ed0">4. <strong>Investing the 80/20 way</strong></h3><p id="05897fe9-4a0e-47d4-8df2-cd910fe40f75">For traditional investing, I try to maximize output and minimize effort. I only use 1 app: Wealthsimple Trade. </p><p id="919727c6-9844-4e45-9aaf-173cb2c3689c">Wealthsimple Trade is like a broker — they let you buy stocks, ETFs, mutual funds, etc., all with $0 fees. They make money from charging a 1.5% currency conversion fee — you can only hold CAD in your account but have to buy US equities with USD and when you sell holdings in USD your balance is credited with CAD. $0 fees are not typical for a brokerage but the currency exchange fees are a killer so I try to only buy Canadian equities. Sometimes I can't resist and I'll run a YOLO on GME - this is more common than I'd like to admit.</p><p id="6dc5cb83-3b1e-410c-b972-d95b9797fc56">Since I'm young, have a job, live at home and can take lots of financial risk, my net worth is divided up roughly as follows (in order of volatility):</p><ul id="467c8446-9ec7-43ad-8b1f-1791cdd43b52"><li>35.5% virtual NBA trading cards</li></ul><ul id="bf81caae-aa42-4c95-a52c-5b3ddf5d07f8"><li>1% Cryptocurrency</li></ul><ul id="8b770356-e3fd-4fb1-ad38-bc3c816dc0d9"><li>33.3% individual stocks I picked (mostly tech companies, this is basically gambling)</li></ul><ul id="5cdbf0f9-7f1d-472a-92ce-9b2b01f7f923"><li>7.1% tech ETFS (ZQQ, ARKK)</li></ul><ul id="4ce7e8fa-3420-4f06-be9d-3418a842c2fd"><li>21.6% whole market ETFs (VSP.TO, VTI, EEMV)</li></ul><ul id="12e4ffe2-10d1-409e-b40a-cf0726ac9eb5"><li>1.5% cash</li></ul><p id="b48787d4-7850-4d49-9104-2819465bd622">This portfolio was made when I was young and stupid. I do not recommend this for anyone and am slowly selling off my more risky positions and buying more into whole market ETFs. It also makes no sense that I'm so heavily invested in the tech sector while working in tech - if that industry goes to shit I'll be doubly ruined. I'm just sharing this for full disclosure since you should know who you're in business with while reading this. Do as I say, not as I do. </p><p id="ddde7cc2-1ab0-4ced-8353-1fe79f450c38">For most investors under 30 who have a similar financial and risk profile as me but aren't as insane, I'd recommend the following steps:</p><ul id="ecc17c23-5127-4155-99d6-30a736287057"><li>Open up a $0 fee trading account - likely Wealthsimple Trade or QuestTrade in Canada, Robinhood in the States</li></ul><ul id="05d79173-10cf-4145-9713-6bb38ced3c08"><li>Deposit a certain % of your paycheque every time you get it and try to maintain a certain ratio of risky investments to safe ones - consistently depositing $500 every month is way better than $10 000 at one time, <a href="https://www.investopedia.com/terms/d/dollarcostaveraging.asp#:~:text=Dollar%2Dcost%20averaging%20(DCA)%20is%20an%20investment%20strategy%20in,volatility%20on%20the%20overall%20purchase.&amp;text=Dollar%2Dcost%20averaging%20is%20also%20known%20as%20the%20constant%20dollar%20plan.">trust me</a></li></ul><ul id="4df5cac9-c4f4-42ae-8c3e-711a751152fd"><li>I believe inflation is worse than market volatility and the market has always gone up and likely will continue to. For that reason, I recommend the following allocation for your investing money:<ul id="4d3ce485-0523-4605-afe5-c97bacc99497"><li>40% in a whole market fund - something that tracks a lot of high quality stocks and moves in the direction of the entire stock market every day (ex. VRGO, SPY)</li></ul><p id="36533864-3c86-44f4-8bbe-144d15b97ab3">The rest is based on your risk tolerance:</p><ul id="2599b8be-90db-47ad-8ea9-151e9b7b538d"><li><details open=""><summary>Risky (in order of ascending risk): </summary><ul id="6a974d7a-0e47-4fa1-ad6f-226fd0949462"><li>20-30% in a tech sector ETF (I like QQQ/ZQQ, ARKK and ARKW)</li></ul><ul id="24e9d83b-a18d-489a-a7dd-9a8450856b2f"><li>15-20% in individual stocks (this is basically blackjack)</li></ul><ul id="5f3b11bd-9b9f-4ebb-9293-724fea03a1a7"><li>5-10% in cryptocurrency (this is basically roulette)</li></ul><ul id="d8860df2-13af-47d9-816c-dcbe43ecb54e"><li>10-20% in cash</li></ul></details></li></ul><ul id="b9d7004e-e41f-4eda-a330-dbc5d5d13da4"><li><details open=""><summary>Conservative:</summary><ul id="6338a2a9-ded0-4731-ac23-9de34ba326ba"><li>Another 20-40% in in a whole market fund</li></ul><ul id="3d919383-87af-4291-86b0-1e4a6cb790ba"><li> 10-20% in a tech ETF (or pick a more stable industry like banking/energy)</li></ul><ul id="6db6640c-7c77-446b-bd0a-a67883caa04f"><li>10-20% in an ETF tracking bonds</li></ul><ul id="8dc7967e-2184-4ccb-a303-f9f0bf0be1c7"><li>10-20% cash</li></ul><ul id="2e285b82-ee2e-40d1-a547-46ae9a3c3dad"><li>0-5% gold</li></ul></details></li></ul></li></ul><p id="7ca5d98c-014c-4654-8ccc-6e333334b9b8">Some other things to remember:</p><ul id="9225f5e9-eb42-4d81-945f-39e312b14045"><li>Wherever you're investing, keep it consistent and comfortable — it's better to invest 20% of your salary every month and never withdraw than depositing $10000 sporadically when "you see an opportunity"<ul id="ab8e384c-f4a5-4b48-8075-9041ce3ed137"><li>You'll have cash when you need it — if something happens and all your money is tied up in investments, you have to withdraw no matter what → the stock market may always go up in the long run but it fluctuates in the short run, if you need money immediately you may need to sell while you're at a loss.</li></ul></li></ul><ul id="1321b660-f49d-4127-9920-56410f7d3fa5"><li>Keep your personal wellbeing above all<ul id="6e47ce6d-42d0-4836-8a06-ab17b09af564"><li>I have a low appetite for risk when it comes to things I don't understand — that's why I'll never trade on margin, trade options or invest more than 40% of my portfolio in one equity, the possibility of losing all my money would keep me up at night and wouldn't be worth the potential financial upside.</li></ul><ul id="32700e60-6458-4a6a-a801-8318377ba405"><li>I keep less cash on hand because I don't need to buy things very often - you may the opposite in that case your asset allocation will look different from mine - the most important thing is just beating inflation by getting at least 2-4% return (ideally more).</li></ul></li></ul><ul id="6f4d5ce0-26bb-480e-b466-30deb7b0ff0d"><li>Don't over-optimize<ul id="29ad34f1-b279-4417-971b-b2c6e3be98e8"><li>The average person doesn't need to spend hours researching trading strategies or comparing fees for different investment platforms. Spend that time making more money to invest.</li></ul><ul id="56117fd6-92da-4ee1-91ee-228fd20c3118"><li>Just get your money into an investment account. It's literally losing value to inflation by sitting in your 0.00001% annual return savings account or in your mattress.</li></ul></li></ul><ul id="07c2820c-b3c4-4316-b808-4b5f64405b35"><li>Investing is actually 90% saving and 10% all of the sexy things people normally associate with "investing". Always make more than you spend.</li></ul><h3 id="bb0a9476-8011-49e8-9941-25daf83f7d51">5. <strong>My tech stack (aka the section with my referral codes)</strong></h3><ol id="368ae0b9-15f6-488c-92ae-093d7beda66e" start="1"><li>Wealthsimple Trade: I use this everyday and it powers most of my investments — <a href="https://my.wealthsimple.com/app/public/trade-referral-signup?code=OJCS_A">my referral gives you $10 to invest</a> (after investing $100).</li></ol><ol id="add28728-e360-4118-8ac7-bc60741f1f61" start="2"><li>Newton: This is where I buy crypto, best app in Canada - <a href="https://web.newton.co/r/66UJ16">my referral gives you $25</a> (after investing $100).</li></ol><p id="a7125418-57fa-4791-8e37-29dd0fbbb3dc">-AA</p><hr id="c2406a8a-6a85-4d4f-85c5-9e057b0c749b"><p id="ce82f288-c85b-4d43-a343-a6065ffdd874"><em>Thanks for reading! Let me know if you have any questions via twitter </em><em><a href="https://twitter.com/aadillpickle">@aadillpickle</a></em><em> - I'd be happy to help!</em></p><p id="3a2e7255-b50a-4bb6-a39e-e2de8b1da195"><em>And if you found this tutorial particularly useful, consider </em><em><a href="https://www.buymeacoffee.com/aadillpickle">buying me a coffee</a></em><em> ☕️.</em></p></div></div>]]>
            </description>
            <link>https://blog.aadilali.com/posts/personal-finance.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281108</guid>
            <pubDate>Fri, 26 Feb 2021 23:33:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Land – Living Off Grid With No Money]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26281103">thread link</a>) | @SQL2219
<br/>
February 26, 2021 | https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html | <a href="https://web.archive.org/web/*/https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>If you are like me, the biggest obstacle to the dream of living off grid is money. Today, I thought I would help out wannabe homesteaders by gathering together tips for living off grid without money, some you probably haven’t seen before.</p><p>How to live off grid with no money:</p><ul><li><strong>Get yourself a piece of free or low-cost land (4 methods below)</strong></li><li><strong>Build a free home</strong></li><li><strong>Gather and grow naturally abundant foods</strong></li><li><strong>Purify available water for free — no wells to dig</strong></li><li><strong>Set up dirt cheap (free) waste disposal</strong></li><li><strong>Bonus: Find a free living community</strong></li></ul><p>Despite what advertisers, builders, and real estate agents might want you to believe, there are actually many ways to get off grid with out much cost. It all depends on how much work you are willing to put in, and being able to think outside the box.</p><h2 id="getting-land-for-no-money">Getting Land for No Money</h2><p>Free land is still out there and still available. Right now there are many out of the way towns and villages offering plots free or basically free if you are willing to live there. Out in the country, there also opportunities for farm caretakers or land contract deals that will not be advertised online. You have to know where to look. Lastly, there are many tracks of land sitting, unused, that could be yours for <strong>free</strong>, using the unknown law called “adverse possession” that exists in some form in all 50 states!</p><div><div><h5>Free Off Grid Guide</h5><p>Thinking about going off grid? Receive the 30+ page PDF that helps you get there! My gift to you.</p><p><small>You will receive your free guide, exclusive discounts, and occasional announcements</small></p></div></div><h3 id="free-land-in-the-us">Free Land in the US</h3><p>While the original homesteading act is no longer on the books, there are many remote cities in the US that are offering free and, usually in exchange for building a home and living in that city for a set period of time. Here is a list of all the towns in the US offering free land for living there:</p><ul><li><a href="http://www.beatrice.ne.gov/dept/city/attorney/homestead.php">Beatrice, Nebraska</a></li><li><a href="https://www.buffalony.gov/306/Urban-Homestead-Program">Buffalo, New York</a></li><li><a href="https://www.curtisnebraska.com/copy-of-medicine-valley-economic-de">Curtis, Nebraska</a></li><li><a href="http://www.elwoodnebraska.com/Wheatfield1.pdf">Elwood, Nebraska</a></li><li><a href="http://www.lincolnks.org/Housing.html">Lincoln, Kansas</a></li><li><a href="http://www.loupcity.com/business/housing/john-subdivision/">Loup City, Nebraska</a></li><li><a href="https://www.mankatoks.com/free-land">Mankato, Kansas</a></li><li><a href="https://www.manillaia.com/">Manilla, Iowa</a></li><li><a href="https://www.marneiowa.com/marne-free-lots/">Marne, Iowa</a></li><li><a href="http://www.marquettekansas.com/land.html">Marquette, Kansas</a></li><li><a href="https://www.cityofnewrichlandmn.com/index.asp?SEC=E4182CA2-FBE7-4271-89BD-2907B9067956&amp;Type=B_BASIC">New Richland, Minnesota</a></li><li><a href="http://www.discoverosborne.com/ECONOMICDEVELOPMENT/BusinessIncentives.aspx">Osborne, Kansas</a></li><li><a href="http://rookscounty.net/free_homesites">Plainnville, Kansas</a></li></ul><h3 id="free-land-in-canada">Free Land in Canada</h3><p>Being the world’s second largest country yet with only 37 million people (just over 1/10th the United State’s population), Canada is interested in getting more people to live in their many underpopulated rural regions. Right now, there are countless small towns looking for people to move in, in exchange for free or practically free (eg $10/acre) land.</p><p>Many of these deals stipulate that you build a home within a set amount of time, in order to get the free land. But read the section on low cost housing below to see how you might be able to get that done on your own for free.</p><p>Here are some towns and regions in Canada offering free land:</p><ul><li><a href="https://www.cbc.ca/news/canada/new-brunswick/new-brunswick-straw-house-community-offers-free-land-1.2765195">New Brunswick Strawhouse Community</a></li><li><a href="https://www.albertafarmexpress.ca/2016/12/05/the-lure-of-free-land-is-drawing-in-a-new-type-of-homesteader/">St-Louis-de-Blandford, Quebec</a></li><li><a href="http://rmofpipestone.com/main.aspx?CategoryCode=BE0B3259-5572-4DEA-9D08-6072C1F49D90&amp;pageCode=2DB56BC7-F94C-4DE9-A71C-C7E5E9EE352A&amp;subPageCode=6EC9A94F-F258-4746-8369-FECB852B7AEA">Pipestone, Manitoba</a></li><li><a href="https://www.cbc.ca/news/canada/manitoba/manitoba-rm-looks-to-sell-ghost-town-lots-for-10-1.2086700">Scarth, Manitoba</a></li><li><a href="http://www.back2land.ca/">South Knowlesville Community Land Trust, New Brunswick</a></li><li><a href="https://www.mundare.ca/Business-Opportunity">Mundare, Alberta</a></li><li><a href="https://www.thefarmersdaughtercountrymarket.ca/employment">Free Land for Working in Wycocomagh, Cape Breton</a></li><li><a href="https://yukon.ca/en/apply-agriculture-land#getting-public-land-for-agriculture">Free Land in the Yukon</a></li><li><a href="http://www.greenenergyfutures.ca/episode/craik-eco-village">Craik Eco-Village , Saskatchewan</a> (ecovillage website not up at time of writing, but community may still be in operation)</li></ul><p>Also, crown land in Canada (land owned by the government) allows people to live there free for 6 weeks at a time, after which time you would have to move on. This could be a perfect free way for a yurt, RV, or portable tiny home dweller to live free of rent.</p><h3 id="cheap-land-and-free-money-in-alaska">Cheap Land and Free Money in Alaska</h3><p>Long one of the last bastions of truly untouched wilderness, Alaska is still one of the freest states in the Union and one of the most beautiful places in the world. While not free up front, <a href="https://dnr.alaska.gov/mlw/landsales">the Alaskan government routinely sells cheap land</a> over the counter as well as through periodic auctions.</p><h4 id="free-money-for-living-in-alaska">Free Money for Living in Alaska</h4><p>While not initially free, establishing residency in Alaska makes you eligible to receive the annual <a href="https://pfd.alaska.gov/">Permanent Fund Dividend</a>. Last year’s dividend was <a href="https://www.adn.com/alaska-news/2019/09/27/this-years-alaska-permanent-fund-dividend-1606/">$1,606 per person</a> including dependents and children. <strong>So a household of five would have seen a $8030 payment this year.</strong> The amount paid depends on how much money Alaska is making, and thus the economy, but the dividend payout has been between about $1,000 – $2,000 per person in recent memory.</p><p>For a family who lives frugally and attempts to produce most of their food off grid through hunting would be able to pay of their off grid land purchase in only a few years.</p><figure><img alt="Subsistence Fishing in Alaska" height="393" src="https://offgridpermaculture.com/img/subsistence_fishing_alaska_salmon.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/subsistence_fishing_alaska_salmon.jpg"></figure><h4 id="subsistence-hunting-and-fishing-licenses">Subsistence Hunting and Fishing Licenses</h4><p>Residents of Alaska also get <a href="https://www.adfg.alaska.gov/index.cfm?adfg=residentfishing.main">special privileges concerning hunting and fishing rights</a>. This includes practices such as net fishing for Salmon and subsistence hunting that are not possible in other states. When I lived in Alaska, it was rare to find a home without a chest freezer packed with salmon and moose meat caught for free.</p><p>For those of you haven’t spent time in Alaska the remoteness of the land and ferocity of the cold weather may astonish you. Likewise, the cost of necessities such as gas and food is well above most regions of United States. So be careful if you decide to go up there. However, for many of my readers, Alaska might just be the perfect spot.</p><h3 id="usda-farm-grant-and-loan-program">USDA Farm Grant and Loan Program</h3><p>No money, but interested in opening a functioning off grid farm? <a href="https://www.usda.gov/topics/farming/grants-and-loans">USDA Grants &amp; Loans</a> has programs to provide money for family size farms as well as a program specifically for new farms.</p><p>In exchange for accepting these funds you will be obligated to attempt to start a farm that conforms to the USDA’s standards of farming. But, for looking to get started with their own off grid agriculture business, these programs could be perfect for you.</p><h3 id="farm-caretaker">Farm Caretaker</h3><p>One way to get started off grid for no money is to become a <a href="https://www.motherearthnews.com/homesteading-and-livestock/farm-caretaker-zmaz76mjztak">Farm Caretaker</a>. Farm care taking is a free rent situation where you work in exchange for free rent. And, can often be a longer term arrangement, lasting years if you choose.</p><p>With labor in rural farm lands at an all time low, and children of farming families moving to the city, there are many farms out there that are looking for people to watch over them. Depending on the situation, some owners may ask you to work part time on the farm — tending livestock and the like — while others may just want someone around to keep an eye on the place and do occasional maintenance work.</p><p>You will not find offers for farm care taker advertised online or on job sites. and will have to search for your own opportunities. Try posting an add on Craigslist, Facebook local forums, or in regional newspapers with good rural distribution. Explain clearly and quickly what you are looking for and what you plan to offer in return.</p><h3 id="land-contract">Land Contract</h3><p>Undeveloped land is not easily financed or mortgaged by banks, which makes land contracts, also known as owner carry, very common practice for purchasing off grid land. A land contract is an agreement between the buyer and seller that you will pay off the purchase over time at a set rate, and at the end of the contract you become the full owner of the land.</p><p>Essentially, the seller becomes the bank.</p><h4 id="finding-no-down-land-contracts">Finding No Down Land Contracts</h4><p>While land contracts typically require a 10% – 20% down payment, finding a motivated owner through direct contact gives you the opportunity to negotiate for a zero down or work exchange situation. See my article <a href="https://offgridpermaculture.com/Finding_Land/How_to_Find_Off_Grid_Land_Ways_You_Havent_Heard_Of.html">“How to Find Off Grid Land - Ways You Haven’t Heard Of”</a> for details on how to find and contact motivated sellers not yet on the market.</p><h4 id="local-businesses-that-sell-land">Local Businesses that Sell Land</h4><p>Another no down option would be to contact <a href="https://www.classiccountryland.com/blog/become-a-land-owner-with-no-down-payment-or-fees">small companies that specialize in off grid properties</a>. Some have special deals for no down payment parcels, while others might be amenable to negotiating special terms. Also, if you are in a lumber producing area, search for local timber investment firms. I have found firms that sell off grid “timber land” with land contracts, and may be willing to provide good terms on parcels of land that they consider unproductive.</p><p>Land contracts are well established legally, generally safe for both parties. However, be wary if you sign one, because failure to pay timely payments or follow through with the contract usually results in the buyer losing the property and anything they paid up to that point.</p><figure><img alt="Map of Adverse Possession Laws in the US" height="450" src="https://offgridpermaculture.com/img/adverse_possession_free_land_laws_in_the_us_by_state.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/adverse_possession_free_land_laws_in_the_us_by_state.jpg"></figure><h3 id="adverse-possession">Adverse Possession</h3><p>One legal concept for acquiring land that you probably haven’t heard of before is <a href="https://en.wikipedia.org/wiki/Adverse_possession#United_States">adverse possession</a> or “squatter’s rights”. What they are is the right to claim ownership of a piece of land that you have been openly living on it for a certain amount of time (see above map), between 5 – 30 years depending on your state.</p><p>The idea of these laws are that vacant pieces of land where, the owner is completely absent, should go to someone who is putting it to good use. What that means in practice varies form state to state. Every state in the US has some form of adverse possession.</p><p>Adverse possession does not mean you have the right to live on a piece of property if you have been asked to leave. The legal owner can ask you to leave at any time. Ultimately, it can be a gamble, since you <strong>must live on the land without the owner’s permission in order to claim adverse possession.</strong></p><p>EDIT: More info on adverse possession and squatters rights, including a state by state breakdown of the laws, can be found here —</p><ul><li><a href="https://offgridpermaculture.com/Finding_Land/How_to_Homestead_on_Abandoned_Property_Is_It_Legal.html">How to Homestead on Abandoned Property | Is It Legal?</a></li></ul><h2 id="low-cost-or-no-cost-off-grid-housing">Low Cost or No Cost Off Grid Housing</h2><p>The next big hurdle to get started living off grid is housing. While some of the options provided above may come with a living arrangement, there are may free or low cost ways to live comfortably off the grid.</p><p>Homes are usually the mainstream family’s biggest expense, but if you are willing to work and to live conservatively, a dept free or even plain free home is within your grasp. Building a tiny home is well within the skills of most people with minimal training. And, they can be built quickly and cheap or free depending on your building material foraging skills. There are also may natural building styles like cob building, light straw clay, earth bag, and straw bale that can be build largely from earth already on site, and can last for generations.</p><figure><img alt="Tiny Home Living for Free" height="400" src="https://offgridpermaculture.com/img/tiny_home_living_off_grid.jpg" width="600" ezimgfmt="rs rscb8 src" data-ezsrc="/img/tiny_home_living_off_grid.jpg"></figure><h3 id="tiny-home-from-recycled-materials">Tiny Home from Recycled Materials</h3><p>With the tiny home craze growing every year, there are many places to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html">https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html</a></em></p>]]>
            </description>
            <link>https://offgridpermaculture.com/Finding_Land/Free_Land___Living_Off_Grid_With_No_Money.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26281103</guid>
            <pubDate>Fri, 26 Feb 2021 23:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Molecules that remodel the gut microbiota reverse narrowing of arteries]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280993">thread link</a>) | @voisin
<br/>
February 26, 2021 | https://microbiomepost.com/how-gut-bacteria-could-trigger-a-heart-attack/ | <a href="https://web.archive.org/web/*/https://microbiomepost.com/how-gut-bacteria-could-trigger-a-heart-attack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="#1">• Clotting activation</a><br>
<a href="#2">• Therapeutic approach</a></p>
<blockquote>
<p><strong>What is already known on this topic</strong><br>
Cardiovascular diseases, which include stroke and heart attack, are one of the leading cause of death worldwide. Most heart attacks result from the formation of a blood clot that obstructs one or more coronary arteries, the blood vessels that carry oxygen and nutrients to the heart. Low levels of microbial molecules called endotoxins have been found in the blood of people whose coronary arteries are obstructed by blood clots, but the role of endotoxins in the formation of blood clots is still unclear.</p>
<p><strong>What this research adds</strong><br>
Researchers have analyzed blood samples from 150 people, including 50 individuals affected by heart attack, from whom the researchers also obtained samples of coronary blood clots. The analysis showed that endotoxins derived from Escherichia coli, a bacterium commonly found in the gut, could enter the blood circulation and trigger the formation of blood clots in coronary arteries. The team also found that, compared to the gut of healthy people, the intestine of individuals who suffered a heart attack is more permeable — a condition that could allow endotoxins to enter the blood circulation. Mice injected with E. coli or treated with endotoxins developed more blood clots than untreated mice. But these detrimental effects disappeared when mice were given an inhibitor of TLR4 — the cellular receptor to which E. coli binds to trigger the formation of blood clots.</p>
<p><strong>Conclusion</strong><br>
The findings suggest a new mechanism that could favor heart attacks and could open up therapeutic avenues that rely on TLR4 inhibition to counteract the formation of coronary clots in people with cardiovascular disease, the researchers say.</p>
</blockquote>
<p>Cardiovascular diseases, which include stroke and heart attack, are one of the leading cause of death worldwide, but the mechanisms behind these disorders are unknown. Now, researchers have found that <strong>a bacterium commonly found in the gut could enter the blood circulation, triggering the formation of blood clots in vessels that carry oxygen and nutrients to the heart</strong>.</p>
<p><a href="https://doi.org/10.1093/eurheartj/ehz893" target="_blank" rel="noopener noreferrer">The findings</a>, published in the <i>European Heart Journal</i>, suggest a new mechanism that could favor heart attacks. They also open up therapeutic avenues to treat this condition, the researchers say.</p>
<p>Most heart attacks result from the formation of a blood clot that obstructs one or more coronary arteries. <strong>Low levels of</strong> microbial molecules called <strong>endotoxins have been found in the blood of people whose coronary arteries are obstructed by blood clots</strong>, but the role of endotoxins in the formation of blood clots is still unclear.</p>
<p>To address this question, <strong>Francesco Violi</strong> at Umberto I University Hospital in Rome and his colleagues analyzed blood samples from 150 people, including 50 individuals affected by heart attack. From these individuals, the researchers also obtained samples of coronary blood clots.</p>
<h2 id="1">Clotting activation</h2>
<p>The analysis showed that <strong>endotoxins derived from </strong><strong><i>Escherichia coli</i></strong>, a bacterium commonly found in the gut, <strong>circulate in the blood of people with heart attack</strong>. <strong>That’s likely because</strong> <strong>the intestine of these individuals is more permeable that the gut of healthy people</strong>, the researchers found.&nbsp;</p>
<p>The increased gut permeability observed in people with heart attacks could allow endotoxins as well as gut bacteria to enter the blood circulation. Indeed, the researchers found that 34% of samples from people with a heart attack contained <i>E. coli</i> DNA, compared to 4% of samples from healthy people.</p>
<p><strong>The presence of low levels of endotoxins in the blood appears to trigger the formation of coronary blood clots through several mechanisms</strong>, the researchers found. These include the activation, adhesion, and aggregation of small cell fragments known as platelets, which help to turn blood from a liquid into a gel.&nbsp;</p>
<h2 id="2">Therapeutic approach</h2>
<p><strong>To trigger the formation of blood clots, <i>E. coli</i></strong><strong> appears to bind to a specific cell-surface receptor called TLR4</strong>. The team also identified <strong>a molecule that inhibits the TLR4 receptor, hindering the formation of blood clots</strong>.&nbsp;</p>
<p>Mice injected with <i>E. coli</i> or treated with endotoxins developed more blood clots than untreated mice. But the detrimental effect of endotoxins disappeared when mice were given the TLR4 inhibitor.</p>
<p>The results could help to develop <strong>new therapeutic strategies that rely on TLR4 inhibition to counteract the formation of coronary clots in people with cardiovascular disease</strong>, the researchers say.</p><div>
<p><a href="https://microbiomepost.com/register/?utm_source=banner_article_bottom"><img src="https://microbiomepost.com/wp-content/uploads/2018/12/Banner-sign-up.jpg"></a></p></div> </div></div>]]>
            </description>
            <link>https://microbiomepost.com/how-gut-bacteria-could-trigger-a-heart-attack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280993</guid>
            <pubDate>Fri, 26 Feb 2021 23:17:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rg3d game engine – progress report for 3 months]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280878">thread link</a>) | @mrDIMAS
<br/>
February 26, 2021 | https://rg3d.rs/general/2021/02/26/progress.html | <a href="https://web.archive.org/web/*/https://rg3d.rs/general/2021/02/26/progress.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  <article>

    
    

<small>
  
  
    
      <span><a href="https://rg3d.rs/categories/#general">General</a></span>
    
  &nbsp;·&nbsp;<time datetime="2021-02-26T00:00:00+00:00">26 Feb 2021</time>
</small>

    <p>It was quite a while since I did the last post about the progress in rg3d (November 2020, ouch). 
Now it’s the time to fix that! For last three months rg3d and rusty-editor has gained 
lots and lots of big features and improvements. Also I started making new game using the engine - a 
Sci-Fi 3D shooter called Station Iapetus, check the end of the post for more info, but for now just
check the video:</p>

<p>
  <iframe src="https://www.youtube.com/embed/tENty9W1_NA" frameborder="0" allowfullscreen="" title="Video"></iframe>
</p>

<h2 id="rg3d">rg3d</h2>

<p>Lets start from the engine, it has 139 new commits from November 2020, here are the most interesting
changes (prepare for the wall of text :) ):</p>

<ul>
  <li>Improved dark UI theme - <a href="https://raw.githubusercontent.com/mrDIMAS/rusty-editor/master/screenshots/latest.png">default dark theme is more elegant now</a>.</li>
  <li>Added verbosity levels for logger - now you can reduce “noise” levels from the engine by setting
verbosity for the logger.</li>
  <li>Improved lightmap quality - lightmaps are now smoothed and almost seam-free.</li>
  <li>Added proper syncing between physics and scene graph - which means that it is possible now to
add a static physical body to a node and every descendant node will provide its geometry as collider
for the body.</li>
  <li>Improved examples - added navigational mesh example which demonstrates how to use 
navigation agents.</li>
  <li>Improved particle systems - added cylinder emitter for particle systems, improved performance.</li>
  <li>TextBox widget now have multiline mode and different “commit” modes (LostFocus, Enter, etc).</li>
  <li>Improved lots of UI widgets and added VectorImage widget.</li>
  <li>rg3d-sound is now able to manage multiple contexts - which means that you can easily create multiple
sound scenes and operate on them separately! This is extremely useful for multi-scene games: for example
you can now create a sound scene for a menu and one for game level and all entities on the sound scenes
will be completely decoupled from each other.</li>
  <li><a href="https://github.com/mrDIMAS/hrtf">hrtf</a> crate now has 2 times better performance - thanks for
performance improvements in rustfft crate.</li>
  <li>Added support for 64-bit FBX format (version 7500+) - it is very important because mixamo.com migrated
to latest FBX SDK and all of the animations and character models have become “unloadable” - now it is fixed.</li>
  <li>Animation blending state machines were improved - I added BlendAnimationsByIndex state machine node which
allows you to switch animations by index with given amount of time for transition.</li>
  <li>It’s now possible to copy nodes in-place - previously it was possible only to copy node from scene
to scene.</li>
  <li>The number of draw calls for UI was reduced by 70% - I changed the way of how clipping works: previously
it was using stencil buffer, now it uses scissor test.</li>
  <li>Fixed UI clipping issues - this is related to previous point - it seems that using stencil test wasn’t a
good idea.</li>
  <li>Fixed text measurement in the UI - previously text’s height was measured incorrectly.</li>
  <li>Opacity for UI widgets was added - this extensively used to greyout disabled widgets.</li>
  <li>Layout of Scroll- and Wrap- panels was fixed.</li>
  <li>Light scatter issues for spot lights were fixed - due to incorrect trigonometry calculations light
volumes were clipped.</li>
  <li>Support for transparent meshes - simple forward renderer was added to render transparent meshes.</li>
  <li>Migrated to rapier 0.5 - which fixed lots of issues in the physics.</li>
  <li>Animation signal handling is fixed when animation playing in reverse.</li>
  <li>Animation tracks now are able to filter position/scale/rotation.</li>
  <li>Sprite rendering fixes - there was incorrect blending options that were causing graphical issues.</li>
  <li><a href="https://github.com/mrDIMAS/rg3d/blob/master/rg3d-core/src/pool.rs">Pool</a> now implements FromIterator 
trait.</li>
  <li>Navigation meshes are now correctly copied when instantiating model resource, however inheritance is
not yet implemented.</li>
  <li>Fixed polygon triangulation - there was an incorrect loop exit condition.</li>
  <li>Now FBX loader does not add redundant “root” node in the scene during instantiation.</li>
  <li>Fixed layout issues in FileBrowser and FileSelector widgets.</li>
  <li>Now it is possible to render instances of UserInterface in separate render targets - this is extremely
useful when you need to draw offscreen UI (for example a touch screen panel in a sci-fi game).</li>
  <li>Added Fast Approximate AntiAliasing (FXAA) - not the best solution for anti-aliasing, but very cheap
and easy to implement.</li>
  <li>Fixed lots of Clippy warnings.</li>
  <li>Added integrity checks for resource instances - now engine automatically adds missing nodes from resource
if an instance of the resource does not have it.</li>
  <li>Improved resource inheritance - now the engine is able to correctly resolve dependencies of resources.</li>
  <li>Scene nodes now have tags - very useful feature to mark nodes with game info. For example, lights can be
marked with “FlashingLight” tag and later on you can search all the lights with such tag and add “flashing” 
behaviour.</li>
  <li>Now scene graph allows to perform custom search using custom predicate.</li>
  <li>Slightly improved user interface performance.</li>
  <li>Improved performance of animation machine’s <code>set_parameter</code> method.</li>
  <li>Now it is possible to select binding direction between a rigid body and a scene node - previously only
node-to-body binding was possible, but now body-to-node binding is available too.</li>
  <li>Lots of improvements in SceneDrawingContext - fixed drawing of shapes, added <code>draw_capsule</code> and 
<code>draw_sphere_section</code>, <code>draw_segment_capsule</code> methods.</li>
  <li>Fixed calculation of isometric transform which was used in physics-to-graph transform syncing.</li>
  <li>Now scene gathers performance statistics per frame.</li>
  <li>Added ColorGradientBuilder which allows to build ColorGradient in declarative manner.</li>
  <li>Added navigation agents (commonly known as NavmeshAgent) which are used for navigation on arbitrary
navigation meshes.</li>
  <li>Added path smoothing for navmeshes - now behaviour of agents are much nicer, check the video below.</li>
</ul>

<p>
  <iframe src="https://www.youtube.com/embed/tqFdQ5OPB1I" frameborder="0" allowfullscreen="" title="Video"></iframe>
</p>

<h2 id="rusty-editor"><a href="https://github.com/mrDIMAS/rusty-editor">rusty-editor</a></h2>

<p><img src="https://rg3d.rs/assets/rusty_editor_27_02_21_00.jpg" alt="Screenshot1"></p>

<p>rusty-editor changes rapidly too, it has 96 new commits from November 2020, here are the most interesting
changes:</p>

<ul>
  <li>Added an editor for navigation meshes - there is still no automatic generation for navmeshes, so I added
simple navmesh editor.</li>
  <li>Added an editor for particle systems - currently is not so flexible, but powerful enough for some
not too complex effects.</li>
  <li>Improved copy/paste in rusty-editor - now it correctly copies all associated entities (rigid bodies,
colliders, etc)</li>
  <li>Configurator now remembers history of previously selected working directories, which is very useful for 
quick iterations.</li>
  <li>Now gizmos have shadows disabled.</li>
  <li>Interaction modes now behaves <em>almost</em> correctly.</li>
  <li>Added debug drawing of the physics - this allows a user to precisely configure location of colliders and rigid 
bodies.</li>
  <li>Now it is possible to edit properties of colliders.</li>
  <li>Fixed deletion of complex selection - this means that editor won’t panic or behave unexpectedly when you
trying to delete multiple nodes at once.</li>
  <li>Added support for joints of various kinds.</li>
  <li>Disabled ability to delete root node.</li>
  <li>Added ability to create directional lights.</li>
  <li>Added scene validation before saving.</li>
  <li>Some menu items are now disabled when there is no active scene.</li>
  <li>Asset previewer now has grid which allows you to quickly understand the size of a model.</li>
  <li>Now editor prints current scene’s path.</li>
  <li>Added “breadcrumbs” - it shows a path from selected node to scene root, it is very useful for quick navigation.</li>
  <li>Limited camera pitch - now it is impossible to be upside-down.</li>
  <li>Added switch for binding direction for rigid bodies.</li>
  <li>Added “Is Sensor” flag for rigid bodies.</li>
  <li>Disabled editing node names of resource instances - this is related to resource inheritance, it relies on the 
suggestion that name won’t change after instantiation.</li>
  <li>Track instantiated animations - previously editor just “forget” about instantiated animations which was leading
to orphaned animations.</li>
  <li>Added ability to edit tags.</li>
</ul>

<h2 id="stationiapetus"><a href="https://github.com/mrDIMAS/StationIapetus">StationIapetus</a></h2>

<p>As I mentioned in the beginning of the post, I started making a new game. It will eventually be released in the Steam,
and I hope it will become the proof that the engine is production-ready quality. Here are some fresh screenshots:</p>

<p><img src="https://rg3d.rs/assets/station_iapetus_27_02_21_00.jpg" alt="Screenshot1">
<img src="https://rg3d.rs/assets/station_iapetus_27_02_21_01.jpg" alt="Screenshot1"></p>

<p>I’m planning to release demo in at 29th of March to get some feedback and improved the game before release it in
Steam. Check the <a href="https://github.com/mrDIMAS/StationIapetus">repository</a> for more info.</p>

<h2 id="the-future-of-the-engine">The future of the engine</h2>

<p>Unfortunately, the future of the engine heavily depends on the money. I’ve tried to get some sponsorship from various
companies, but with no luck yet. I hope to get some money by selling Station Iapetus in the Steam. I’m working on 
the engine for more than 2 years now and getting very little financial support. If you want to see the project alive,
<strong>please consider to make a donation</strong> on <a href="https://patreon.com/mrdimas">Patreon</a> or
<a href="https://liberapay.com/mrDIMAS">LiberaPay</a> , unfortunately GitHub sponshorship is not available in my country.</p>


    


    


  </article>

  

</div></div>]]>
            </description>
            <link>https://rg3d.rs/general/2021/02/26/progress.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280878</guid>
            <pubDate>Fri, 26 Feb 2021 23:02:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animation of Paul Graham writing “Startups in 13 sentences” Yellow = deleted]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280776">thread link</a>) | @crazypython
<br/>
February 26, 2021 | http://byronm.com/13sentences.html | <a href="https://web.archive.org/web/*/http://byronm.com/13sentences.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://byronm.com/13sentences.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280776</guid>
            <pubDate>Fri, 26 Feb 2021 22:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Searchable list of known bug bounty and vulnerability disclosure programs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280468">thread link</a>) | @caseyjohnellis
<br/>
February 26, 2021 | https://disclose.io/programs/ | <a href="https://web.archive.org/web/*/https://disclose.io/programs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://disclose.io/programs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280468</guid>
            <pubDate>Fri, 26 Feb 2021 22:12:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The four requirements under the Declarative Theory of Statehood]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280279">thread link</a>) | @valkrieco
<br/>
February 26, 2021 | https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/ | <a href="https://web.archive.org/web/*/https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-253">

	
		<!-- .entry-header -->

		<div>
			
<p>On 16<sup>th</sup> June 2014, Jeremiah Heaton declared 2,060km<sup>2</sup> of arid land in Africa as the <a rel="noreferrer noopener" href="https://www.kingdomsudan.org/" target="_blank">Kingdom of North Sudan</a>, after promising his daughter that one day she would become a Princess.</p>



<p>Heaton, a farmer from the US state of Virginia, had been looking for unclaimed territory around the world and after some research settled on an area known as Bir Tawil, an uninhabited piece of land between Egypt and Sudan.</p>



<p>Due to two conflicting treaties drawn up by the British, both Egypt and Sudan interpreted the treaties as they saw fit. A claim on a piece of land close to Bir Tawil would disqualify the party from claiming Bir Tawil itself, and since the former enjoyed prospective mineral wealth, both sides claim this land as their own. Bir Tawil ended up a ‘terra nullius’ – land that belongs to no one until this was claimed by Heaton himself.</p>



<div><figure><img loading="lazy" width="640" height="488" src="https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/Bir-Tawil.png?resize=640%2C488&amp;ssl=1" alt="" srcset="https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/Bir-Tawil.png?w=941&amp;ssl=1 941w, https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/Bir-Tawil.png?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/Bir-Tawil.png?resize=768%2C586&amp;ssl=1 768w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"></figure></div>



<h3>Rose Island</h3>



<p>Like many others, I have recently watched ‘<a rel="noreferrer noopener" href="https://www.netflix.com/title/81116948" target="_blank">Rose Island</a>‘ on Netflix and started to think about how countries we know today came to be. In the film, Giorgio Rosa, the real-life founder of the former ‘<a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Republic_of_Rose_Island" target="_blank">Republic of Rose Island</a>‘, tried, in vain, to convince the United Nations, the Council of Europe and the Italian Government that since his artificial island was outside Italy’s territorial waters, it should be considered an independent state. While Rose Island and North Sudan are <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Micronation" target="_blank">micronations</a> – which are usually small in size, lack recognition from other states and are generally the creation of a single individual – their founding stories can tell us a lot about the challenges that <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Proto-state" target="_blank">proto-states</a> meet with, and how countries are indeed volatile entities that can be created and destroyed.</p>



<p>When one thinks of countries like the United States, Russia, China, Japan or Germany for example, we usually consider these as permanent entities, however even these same countries had different borders, governments and cultures throughout their existence. While micronations cannot be compared to these countries, they do have one thing in common – they all are trying to find or maintain their place on the world stage.</p>



<p>So, how do you create a country?  First of all – what exactly is a country?</p>



<p>While there is no single definition of what constitutes a ‘country’, there are some <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Sovereign_state" target="_blank">international guidelines</a> that this entity must follow, for it to be recognised as such. The two main competing schools of thought are the <a href="https://en.wikipedia.org/wiki/Sovereign_state#Constitutive_theory">constitutive theory of statehood</a> and the <a href="https://en.wikipedia.org/wiki/Sovereign_state#Declarative_theory">declarative theory of statehood</a>. </p>



<p>Big words, however, the main difference is that the first one only affords recognition to states that have been recognised by other states, while the second allows for an entity to declare sovereignty without having to be explicitly recognised as such by other states.</p>



<p>The declarative theory was codified in 1933 in the Montevideo Convention on the Rights and Duties of States and is used by many proto-states, including micronations to help prove their cause, as its the easier way of declaring sovereignty. This does not guarantee that someone following this theory is automatically considered a country. Let’s take a look at each one of the qualifications under this theory and see how they affect the aspirations of proto-countries, not only micronations but also regions and people fighting for their sovereignty. </p>



<p>The Convention states that “the state as a person of international law should possess the following qualifications”:</p>



<ol><li><strong>Permanent Population;</strong></li><li><strong>Defined</strong> <strong>Territory;</strong></li><li><strong>A Government;</strong></li><li><strong>The ability to enter into agreements with other states.</strong></li></ol>



<hr>



<h3>1. Permanent Population</h3>



<p>The first qualification under this Convention is for the proto-state to have a permanent population belonging to the land one is claiming as a country.  </p>



<p>The Sahrawi people in <a href="https://en.wikipedia.org/wiki/Western_Sahara">Western Sahara</a> have been roaming the lands for hundreds of years. The area was governed by the Spanish until 1975 when Morocco, Mauritania and <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Polisario_Front" target="_blank">Polisario</a> all claimed the land as their own. </p>



<p>In a dispute between the latter two, the International Court of Justice (ICJ) <a href="https://www.economist.com/the-economist-explains/2021/01/13/who-should-control-western-sahara" target="_blank" rel="noreferrer noopener">declared</a> that Western Sahara was not <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Terra_nullius" data-type="URL" data-id="https://en.wikipedia.org/wiki/Terra_nullius" target="_blank">terra nullius</a>, as in the case of Bir Tawil, and before the Spanish conquered the area, there were tribes connected to Morocco, who were already living off the land. Morocco took this as a sign that it has historical precedent to control Western Sahara, even if the ICJ did not reach that explicit conclusion.</p>



<p>Earlier, the United Nations General Assembly adopted <a rel="noreferrer noopener" href="https://www.ohchr.org/EN/ProfessionalInterest/Pages/Independence.aspx" target="_blank">Resolution 1514 (XV)</a> on 14 December 1960, which declared that non-self-governing territories have to “transfer all powers to the peoples of those territories, without any conditions or reservations, …. in order to enable them to enjoy complete independence and freedom.”</p>



<div><figure><img src="https://i0.wp.com/morningstaronline.co.uk/sites/default/files/styles/article_full/public/11sahrawiprotesters.jpg?w=640&amp;ssl=1" alt="" data-recalc-dims="1"><figcaption>Sahrawi women protesting against the Moroccan occupation, 2005 Photo: Western Sahara / Creative Commons</figcaption></figure></div>



<p>This is were Morocco and Polisario, which is recognised as the representative of the Sahrawi people by the United Nations, disagree. Polisario has been fighting for control of the land ever since, and after 1991 when a war between the Front and Morocco ended, the former only controlled a strip of land to the east of Western Sahara with the border of Mauritania.</p>



<p>The Sahrawis are banking that having a permanent population on the land would make it easier for them to declare independence of Western Sahara. However, even this hope is fading as Morocco has been increasingly moving Moroccans on the land, making sure that any future referendum, if it takes place, confirms its control on Western Sahara. Without outside pressure, especially from major players in the region and around the world, Polisario supporters and Sahrawis see little hope that someday they would control the area, despite their people having lived there for hundreds of years.</p>



<p>The case of Western Sahara contrasts with the tens of colonies that after World War II started gaining independence on account of their different cultures, languages and customs compared to the coloniser – and also as a result of the UN Security Council Resolution mentioned above. Even today, pro-independence parties and supporters in Catalonia and Scotland, for example, who have occupied their lands for hundreds of years, built institutions around their customs and passed on their language from generation to generation, claim their right to govern themselves as they see fit. The call for the sovereignty of these regions is, in fact, stronger than that of the people in <a href="https://en.wikipedia.org/wiki/Northern_Cyprus">Northern </a><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Northern_Cyprus" target="_blank">Cyprus</a>, for example, whose claim for independence is the result of a military incursion in 1974. Article 11 of the same Convention even claims that states will not recognise territorial acquisitions claimed by force.</p>



<h3>2. Defined Territory</h3>



<p>Several proto-countries often start with this specification – finding or occupying a piece of land or estate – something tangible that can give the claim of a state a real feel. Some, like Heaton, go to great lengths to find land unclaimed by official states, while others declare regions or parts of their country as a separate entity. Rosa, in ‘Rose Island’, even built the artificial island himself.</p>



<p>On the night of 2<sup>nd</sup> May 2020, a number of slogans such as ‘<a rel="noreferrer noopener" href="https://www.nationalia.info/brief/11308/away-from-rome-independence-slogans-written-with-fire-on-mountains-in-south-tyrol" target="_blank">Away from Rome</a>‘ were written with fire on the side of the mountains in South Tyrol in what seems to be criticism by right-wing separatist supporters, against the centralisation of COVID-19 regulations by the Italian government.</p>



<div><figure><img loading="lazy" width="640" height="320" src="https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/los_von_rom.jpg?resize=640%2C320&amp;ssl=1" alt="" srcset="https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/los_von_rom.jpg?w=750&amp;ssl=1 750w, https://i0.wp.com/karlsnotes.com/wp-content/uploads/2021/02/los_von_rom.jpg?resize=300%2C150&amp;ssl=1 300w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption><em>Author: Schützenkompanie Johann-Jaeger Niederdorf Süd Tirol</em></figcaption></figure></div>



<p>The geographic position and history of South Tyrol with its neighbours and Rome, has led some movements to argue for the region to cede from Italy and join Austria. Pro-separatist South Tyrolean parties highlight their historical borders and their cultural and language differences with other parts of Italy as the reason why they cannot form part of the country. </p>



<p>Many regions around the world have promoted territorial separatism as a way to reduce tension, sometimes even violence, between people of different backgrounds and different cultures. This is not usually the case in most independence movements in Europe, such as in South Tyrol or Corsica. However, violence has sometimes been used by separatist movements who believe that this will accelerate their cause, and even by the Government of the country who believes it will keep these movements in check.</p>



<p>Even so, cases like South Tyrol, Corsica, West Papua (Indonesia) or New Caledonia (France), where there is an existing natural or man-made border separating people with similar backgrounds from other parts of the country tend to be more successful in making their case for independence accepted, or at least understood, within that same community and with the mainland. Compare this with people who have the same cultural background but are found in different regions/countries. One example is the case of the Kurds who are concentrated in parts of Turkey, Syria, Iran and Iraq. Without a single place to call home, Kurds have had to take up their quest for sovereignty with several regional powers, which has made it harder for them to claim territory. The Syrian civil war did provide hope for Kurds, after the setting up of Rojava or the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Autonomous_Administration_of_North_and_East_Syria" target="_blank">Autonomous Administration of North and East Syria</a>,  which created a de facto proto-state controlled by Syrian Kurds. However, as soon as Turkey realised the danger of having an entity controlled by the Kurds right outside their borders, they invaded and re-took part of the lands aligned with Rojava.</p>



<p>Take also the example of Cyprus and the Turkish invasion in 1974, which de facto divided the country into two. Whereas before the invasion Greek-Cypriots and Turkish-Cypriots lived amongst each other all over the country, the invasion and subsequent building of borders, led to the separation of these two cultures. The now defined territory of the Turkish Republic of Northern Cyprus made it possible for some Cypriot-Turks to try and claim independence.</p>



<h3>3. A Government</h3>



<p>After identifying the borders of their territory, the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/">https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/</a></em></p>]]>
            </description>
            <link>https://karlsnotes.com/how-to-start-your-own-country-in-four-steps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280279</guid>
            <pubDate>Fri, 26 Feb 2021 21:52:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fault Is Not in Our Stars]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280200">thread link</a>) | @gbrown_
<br/>
February 26, 2021 | http://www.m4b.io/disassembers/debuggers/compilers/bugs/2015/07/07/the-fault-is-not-in-our-stars.html | <a href="https://web.archive.org/web/*/http://www.m4b.io/disassembers/debuggers/compilers/bugs/2015/07/07/the-fault-is-not-in-our-stars.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <blockquote>
<p>"The fault, dear Brutus, is not in our stars,
But in ourselves, that we are underlings."
- Julius Caesar (I, ii, 140-141)</p>
</blockquote>

<p><img src="http://www.m4b.io/images/phosphorus-jutrzenka.jpg" alt="Jutrzenka's morning and evening stars"></p>

<p>It was all David's fault that I was still up at 1 in the morning, bleary eyed, tired, and starting to get suspicious of mathematics -- and that there was definitely a 'bug' in <code>je_malloc</code> and the compiler that generated <code>je_malloc</code> and in LLVM's disassembler, maybe in <code>gdb</code>, and definitely in Intel's documentation, and probably in pretty much everything.</p>

<p>But let me start from the beginning.</p>



<p><img src="http://www.m4b.io/images/such_hacks.png" alt="OCaml david code"></p>

<p>It was a dark and stormy night - I was demoing <a href="http://github.com/m4b/rdr">some software</a> to my friend, the eponymous David from the above, at a coffee shop, in May around noon, when this whole mess started.  I was showing him this particular feature which allowed me to disassemble an arbitrary symbol name from the command line, and in my hubris, I foolishly showed him the <code>malloc</code> disassemblies.</p>

<p>Now, there are several <code>malloc</code> providers on linux.  One of these is the fateful <code>libjemalloc.so.1</code>, whose <a href="https://github.com/jemalloc/jemalloc">git repo is here</a>, and with whom our story starts.  However, this story doesn't so much involve them as it does their <em>compiled</em> code (not on the dev branch, but the master, at least at the time of this writing), and so we should absolve them of any wrong doing in these matters.</p>

<p>In any event, I had noticed before that my program was piping out errors for <code>libjemalloc.so.1</code>'s <code>malloc</code> implementation, but since this was a fly by night operation intended to wow David, I hadn't checked into it yet.</p>

<p>But David, being the good, curious human that he is, asked about the errors when he saw them.  And that's when it all began -- a nightmarish journey into the seedy underbelly of linux dynamic libraries, broken disassemblers, pernicious debuggers, treacherous compilers and suspicious documentation.</p>

<p>Come join me in my fun-time adventures!</p>

<h3 id="0x66-0x66-0x48-0xe8-0x59-0xcf-0xff-0xff">0x66 0x66 0x48 0xe8 0x59 0xcf 0xff 0xff</h3>

<p>I'm running Arch Linux, and when I run <code>lldb /usr/lib/libjemalloc.so.1 -o "disass -b -n malloc"</code>, the last line it disassembles is a <code>call</code> instruction:</p>
<div><pre><code data-lang="text"> &lt;malloc+1151&gt;66 66 48 e8 59 cf         callw  0xcf59
</code></pre></div>
<p>It is exactly here, 1157 bytes in, that <code>lldb</code> (based on LLVM v3.6) gives up and will disassemble no more.  This is unusual, because if you inspect the <code>_DYNAMIC</code> array, <code>libjemalloc.so.1</code> reports that its export, <code>malloc</code>, begins at <code>0x5f90</code>, and is exactly 1543 bytes in size (your implementation will vary; in fact, compiling <code>libjemalloc</code>'s master git branch yields a larger <code>malloc</code> and various examples like this much earlier on in the procedure - but again, this may vary with compiler flags, compilers, distros, and toaster models).</p>

<p>Yet <code>lldb</code> tells us that the function is 1157 bytes long (because that's where it stops).  So where did 386 bytes go? (there's probably an off by one error here, don't judge me)</p>

<p>To fully understand this situtation, we'll need to understand Intel legacy prefix codes, REX prefixes, opcode tables, crazy Intel instruction documentation syntax, signed integers, <code>gdb</code>, x86-64 mode, and other sordid low-level details.</p>

<h3 id="prefixes">Prefixes</h3>

<p>I haven't finished reading the <a href="http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-manual-325462.pdf">Intel manual</a> yet (so I'm not an expert), probably be done in a few days, but basically there are 4 groups of legacy prefixes, with <code>0x66</code> indicating the so-called "operand-size override prefix".  According to their documentation:</p>

<blockquote>
<p>The operand-size override prefix allows a program to switch between
16- and 32-bit operand sizes.  Either size can be the default;
use of the prefix selects the non-default size.
2-2 Vol. 2A</p>
</blockquote>

<p>Let me just say here, because I really can't resist, and hopefully maybe there's a good reason for this behavior (but probably not, just the onus of historical cruft), but you know the instruction set is insane when "either size can be the default" and the operand-size override prefix switches to the other.  Like, just choose one... and make that the default?</p>

<p>Anyway, 64-bit x86 processors (the only processor kind you should care about anymore) added REX prefixes, which do lots of things in 64-bit mode, but for our purposes, we'll only consider the <code>0x48</code> byte, which says "My operand is 64-bits wide".  The accompanying documentation says:</p>

<blockquote>
<p>Not all instructions require a REX prefix in 64-bit mode.
A prefix is necessary only if an instruction references one
of the extended registers or uses a 64-bit operand.
If a REX prefix is used when it has no meaning, it is ignored.
2-8 Vol. 2A</p>
</blockquote>

<p>Importantly, "Only one REX prefix is allowed per instruction."</p>

<p>Confusingly however, when it comes to the legacy prefixes, we're told:</p>

<blockquote>
<p>For each instruction, it is only useful to include up to
one prefix code from each of the four groups (Groups 1, 2, 3, 4).
Groups 1 through 4 may be placed in any order relative to each other.
2-1 Vol. 2A</p>
</blockquote>

<p>So... "it is <strong>only</strong> <em>useful</em> to include <em><em>up to one</em></em>". We'll interpret this unambiguous piece of writing to mean we can have as many prefixes as we want.</p>

<p>However, directly above this on the same page, in the instruction diagram, in the prefix section, we're told "Up to four prefixes of 1 byte each", which seems to indicate we can have a max of four prefixes.</p>

<p>At the time of this writing, I've experimented with instruction sequences with multiple prefixes, multiple REXs, etc., but they seem to be ignored.  So we'll go with the former interpretation, that we can include as many as we want.</p>

<h3 id="intel-arcana">Intel Arcana</h3>

<p>With such information firmly in hand, we can now understand <code>0x66 0x66 0x48 0xe8 0x59 0xcf 0xff 0xff</code>... or can we?  First off, why are there two <code>0x66</code> bytes?  I have no idea.  Secondly, why are they followed by an <code>0x48</code>? It seems to say... use a 16-bit width, and then use a 64-bit width, but if we actually look up the instruction (<code>0xe8</code>) in Intel's one-byte opcode table, it tells us that <code>0xe8</code> is a "near CALL^f64" with a <code>Jz</code> operand, where ^ means superscript.</p>

<p>First we need to look up what an <code>f64</code> superscript means, to wit:</p>

<blockquote>
<p>The operand size is forced to a 64-bit operand size when in 64-bit
mode (prefixes that change operand size are ignored for this
instruction in 64-bit mode)
A-6 Vol. 2C</p>
</blockquote>

<p>So the operand size must be 64-bits, or 8 bytes.  Our example instruction only has a 4 byte operand/immediate though; but if we consult the instruction's entry in the 64-ia we see that:</p>

<blockquote>
<p>In 64-bit mode the relative offset is always a 32-bit immediate
value which is sign extended to 64-bits before it is
added to the value in the RIP register for the target calculation.
Vol. 2A 3-99</p>
</blockquote>

<p>Importantly, the documentation <em>does</em> definitely state that prefixes that change operand size are ignored in 64-bit mode for instructions marked with the <code>f64</code> superscript, of which <code>call</code> is one.</p>

<p>The only other component is the <code>Jz</code> operand encoding, which is two parts, the first part, "J", meaning:</p>

<blockquote>
<p>The instruction contains a relative offset to be added
to the instruction pointer register
A-2 Vol. 2C</p>
</blockquote>

<p>and the "z":</p>

<blockquote>
<p>Word for 16-bit operand-size or doubleword for 32 or 64-bit operand-size
A-3 Vol. 2C</p>
</blockquote>

<p>In other words, the operand is a <em><strong>signed</strong></em> operand, with either a 16-bit or 64-bit size, depending on whether the operand-size prefix is set?</p>

<p>So what we know seems to be:</p>

<ul>
<li>Operand-size prefix is ignored</li>
<li>Operand-size prefix is not ignored? ("Word for 16-bit operand-size")</li>
<li>Operand is signed</li>
<li>Up to 4 legacy prefixes</li>
</ul>

<p>Don't worry if you're confused and unsure what is correct; everyone seems to be.  At the time of this initial writing (about a month ago), <a href="https://sourceware.org/bugzilla/show_bug.cgi?id=18386">neither</a> <code>gdb</code> <a href="http://lists.cs.uiuc.edu/pipermail/llvm-commits/Week-of-Mon-20150504/274835.html">nor</a> <code>lldb</code> correctly disassembled <code>0x66 0xe8 0x59 0xcf 0xff 0xff</code>, so we're in good company.  <strong>Update</strong>: both of these bugs have been corrected, thanks to open source process goodness, and the internet.</p>

<h3 id="llvm">LLVM</h3>

<p>Ok, let's run <code>llvm-mc --disassemble</code> on the instruction starting 1151 bytes in at <code>libjemalloc</code>'s <code>malloc</code> to test what we know:</p>
<div><pre><code data-lang="bash"><span>echo</span> <span>"0x66 0x66 0x48 0xe8 0x59 0xcf 0xff 0xff"</span> <span>|</span> llvm-mc --disassemble
    .text
    callw   53081
&lt;stdin&gt;:1:31: warning: invalid instruction encoding
0x66 0x66 0x48 0xe8 0x59 0xcf 0xff 0xff
                              ^
</code></pre></div>
<p>That didn't seem to work (this was the original error that set all this off).</p>

<p>Maybe it's all those stupid <code>0x66</code> that <code>gcc</code> inserted (also, again, why)?  Let's test if multiple <code>0x66</code> cause a problem for LLVM's disassembler:</p>
<div><pre><code data-lang="bash"> <span>echo</span> <span>"0x66 0x66 0xe8 0x59 0xcf"</span> <span>|</span> llvm-mc --disassemble
    .text
    callw   53081
</code></pre></div>
<p>So <code>llvm-mc</code> seems ok with a couple <code>0x66</code>'s.  What about 5 of them?</p>
<div><pre><code data-lang="bash"> <span>echo</span> <span>"0x66 0x66 0x66 0x66 0x66 0xe8 0x59 0xcf"</span> <span>|</span> llvm-mc --disassemble
    .text
    callw   53081
</code></pre></div>
<p>The spec was vague on redundant prefixes, so we'll let this slide (if you actually test multiple <code>0x66</code>'s against an x86-64 cpu in 64-bit mode it seems to allow it - which just means the silicon that I tested it on allowed it).</p>

<p>But there is something else really wrong here, it looks like <code>llvm-mc</code> is incorrectly disassembling <code>callw</code>'s immediate.</p>

<p>Here's some C code to illustrate the matter:</p>
<div><pre><code data-lang="c"><span>//i_saw_the_sign.c</span>

<span>#include&lt;stdio.h&gt;</span>

<span>int</span> <span>main</span><span>(){</span>

  <span>unsigned</span> <span>short</span> <span>unsigned_s</span> <span>=</span> <span>0xcf59</span><span>;</span>
  <span>short</span> <span>signed_s</span> <span>=</span> <span>0xcf59</span><span>;</span>
  <span>int</span> <span>signed_i</span> <span>=</span> <span>0xffffcf59</span><span>;</span>
  <span>int</span> <span>unsigned_i</span> <span>=</span> <span>0x0000cf59</span><span>;</span>

  <span>printf</span><span>(</span><span>"unsigned_s: %d</span><span>\n</span><span>"</span><span>,</span> <span>unsigned_s</span><span>);</span>  
  <span>printf</span><span>(</span><span>"signed_s: %d</span><span>\n</span><span>"</span><span>,</span> <span>signed_s</span><span>);</span>
  <span>printf</span><span>(</span><span>"signed_i: %d</span><span>\n</span><span>"</span><span>,</span> <span>signed_i</span><span>);</span>
  <span>printf</span><span>(</span><span>"unsigned_i: %d</span><span>\n</span><span>"</span><span>,</span> <span>unsigned_i</span><span>);</span>
  <span>/*./sign</span>
<span>  unsigned_s: 53081</span>
<span>  signed_s: -12455</span>
<span>  signed_i: -12455</span>
<span>  unsigned_i: 53081</span>
<span>  */</span>
  <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>So, let's be absolutely clear: <code>0xcf59</code> interpreted as a signed short (i.e., only 2 bytes in size) is equivalent to <code>0xffffcf59</code> interpreted as a signed int (4 bytes in size), which we write in decimal notation as <code>-12455</code>.</p>

<p>As such, if <code>0x66 0xe8 0x59 0xcf</code> is disassembled to <code>callw 53081</code> then the 16-bit operand <code>0xcf49</code> must have been interpreted as an unsigned short or a non-sign extended 4-byte int, i.e., <code>0x0000cf49</code> (or similarly, as an 8-byte int), and not the correct signed short or sign-extended 4-byte int, which we write in decimal as <code>-12455</code>.</p>

<p>So <code>llvm-mc</code> incorrectly disassembles short immediates in call.  As it turns out, it was just a <a href="http://lists.cs.uiuc.edu/pipermail/llvm-commits/Week-of-Mon-20150504/274835.html">missing case in a switch statement</a> (I love not having pattern matching on closed algebraic …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.m4b.io/disassembers/debuggers/compilers/bugs/2015/07/07/the-fault-is-not-in-our-stars.html">http://www.m4b.io/disassembers/debuggers/compilers/bugs/2015/07/07/the-fault-is-not-in-our-stars.html</a></em></p>]]>
            </description>
            <link>http://www.m4b.io/disassembers/debuggers/compilers/bugs/2015/07/07/the-fault-is-not-in-our-stars.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280200</guid>
            <pubDate>Fri, 26 Feb 2021 21:45:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PicoCAD: A tiny modeller made in PICO-8]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26280141">thread link</a>) | @leafo
<br/>
February 26, 2021 | https://johanpeitz.itch.io/picocad | <a href="https://web.archive.org/web/*/https://johanpeitz.itch.io/picocad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>A tiny modeller for tiny models</h3>
<p>picoCAD is a program to build and texture lowpoly 3D models. Where many programs for modelling and texturing are&nbsp;bloated and overly complicated, picoCAD aims to make it fun, easy, and accessible by focusing on the&nbsp;bare essentials.&nbsp;It is built on the PICO-8 platform and comes rich with constraints.&nbsp;Experiment to find your own workflow and anything is possible!</p>
<h3>Features</h3>
<ul><li>Streamlined and easy to use editor</li><li>Place and modify&nbsp;meshes to create amazing things</li><li>Live manipulation of textures and UV coordinates&nbsp;</li><li>A unique look with picoCAD's dithered shading</li><li>Render in wireframe, solid fill, or textured</li><li>All save files in easy to read text format</li><li>Exports&nbsp;Twitter friendly GIFs</li><li>Ships with a manual that is worth reading</li></ul>
<h3>Get involved</h3>
<p>Check out our&nbsp;<a href="https://discord.gg/hjXMammbPB" rel="nofollow noopener">discord</a> for help, as well as&nbsp;cool stuff built by the community.</p>
<p>The&nbsp;<a href="https://twitter.com/search?q=%23picoCAD" rel="nofollow noopener">#picoCAD</a>&nbsp;on Twitter is also a good place to browse the latest and greatest.</p>
<h3>Have fun</h3>
<p>I&nbsp;hope you'll have a good time using picoCAD! If you find it useful, please consider donating - thanks! &lt;3&nbsp;</p></div></div>]]>
            </description>
            <link>https://johanpeitz.itch.io/picocad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280141</guid>
            <pubDate>Fri, 26 Feb 2021 21:39:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Vim Plugins You Haven't Heard Of]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26280017">thread link</a>) | @ashitlerferad
<br/>
February 26, 2021 | https://www.vimfromscratch.com/articles/useful-vim-plugins-you-havent-heard-of/ | <a href="https://web.archive.org/web/*/https://www.vimfromscratch.com/articles/useful-vim-plugins-you-havent-heard-of/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Over the last couple of months, I discovered several neat Vim plugins I never heard of before. And I thought I'd share.</p>

<div>
        <p><img src="https://www.vimfromscratch.com/assets/useful-vim-plugins-1cd50170fa11bd9052145c0346b8d7f5d4b87cc803759a60306d483fd588d62d.png" alt="Ayu" color="" scheme="" with="" a="" typescript="" file=""></p><figcaption>Ayu color scheme with a TypeScript file</figcaption>
      </div>
    

<p>All headers are links. Or you can copy-paste it and use your <a href="https://github.com/junegunn/vim-plug">favorite plugin manager</a>.</p>

<h3><a href="https://github.com/machakann/vim-highlightedyank">machakann/vim-highlightedyank</a></h3>

<p>You know that feeling when you yanked some text but not quite sure if you pressed the right key combination? This plugin shortly highlights whatever you just yanked.</p>

<h3><a href="https://github.com/machakann/vim-sandwich">machakann/vim-sandwich</a></h3>

<p>Remember Tim Pope's <a href="https://github.com/tpope/vim-surround">surround.vim</a> plugin that allows you to wrap and re-wrap chunks of text with brackets, quotes, etc.? This one is very similar but it also highlights the wrapping text, making it much more convenient.</p>

<h3><a href="https://github.com/beloglazov/vim-online-thesaurus">beloglazov/vim-online-thesaurus</a></h3>

<p>While I understand that might be a super popular use-case, I need to look up a word definition or a synonym, especially when writing articles or code comments. Instead of reaching to Google, I can do it from the cozy comfort of my Vim.</p>

<h3><a href="https://github.com/liuchengxu/vim-clap">liuchengxu/vim-clap</a></h3>

<p>Vim-clap allows you to fuzzy-find anything from files to Git commits. It uses modern popup APIs (supports both Vim 8+ and Neovim). Honestly, I'm not using it all that much, as I still get kicks out of my <a href="https://github.com/junegunn/fzf">FZF</a>.</p>

<h3><a href="https://github.com/ayu-theme/ayu-vim">ayu-theme/ayu-vim</a></h3>

<p>This one is a color scheme and a pretty convincing one (the top screenshot in this article). I switched to it from <a href="https://github.com/morhetz/gruvbox">gruvbox</a> and am happy so far. Unfortunately, it seems to be unmaintained, but <a href="https://github.com/Luxed/ayu-vim">here's a maintained fork</a>.</p>

<h3><a href="https://github.com/mattboehm/vim-accordion">mattboehm/vim-accordion</a></h3>

<p>You might find this one handy if you're a heavy splits users (<a href="https://github.com/zhaocai/GoldenView.Vim">everyone</a> <a href="https://github.com/wellle/visual-split.vim">loves splits!</a>). Long story short, it shrinks all the other splits beside the current one. Well, you know how an accordion works.</p>

<h3><a href="https://github.com/farmergreg/vim-lastplace">farmergreg/vim-lastplace</a></h3>

<p>This plugin puts the cursor at the place it was the last time you edited the file.</p>

<h3><a href="https://github.com/liuchengxu/vista.vim">liuchengxu/vista.vim</a></h3>

<p>LSP clients nowadays can build a tree of your program (symbol tree?) similar to some full-blown IDEs. This plugin is a UI for that tree. I'm using it to overview and navigate the code quickly.</p>

<h3><a href="https://github.com/junegunn/limelight.vim">junegunn/limelight.vim</a></h3>

<p>Junegunn Choi is a prolific author of several super-hit plugins like FZF and vim-plug. Limelight dims non-active paragraphs of the file, thus letting you focus on the current one. You can use it together with <a href="https://github.com/junegunn/goyo.vim">Goyo</a>.</p>

<h2>What's next?</h2>

<p>That's it, folks.</p>

<p>If you know more interesting plugins, please <a href="https://twitter.com/janis_t">don't hesitate to share</a>.</p>

<p>Now you probably want more Vim plugins because it's never enough. Here's what I got.</p>

<ul>
<li><a href="https://www.vimfromscratch.com/articles/5-must-have-vim-plugins-2018/">Five must-have Vim plugins</a></li>
<li><a href="https://www.vimfromscratch.com/articles/5-awesome-vim-plugins-you-may-never-have-heard-about/">5 Awesome Vim Plugins You May Never Have Heard About</a></li>
<li><a href="https://www.vimfromscratch.com/articles/vim-for-python/">Vim for Python </a></li>
<li><a href="https://www.vimfromscratch.com/articles/vim-for-ruby-and-rails-in-2019/">Vim for Ruby and Rails</a></li>
</ul>

</div></div>]]>
            </description>
            <link>https://www.vimfromscratch.com/articles/useful-vim-plugins-you-havent-heard-of/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26280017</guid>
            <pubDate>Fri, 26 Feb 2021 21:26:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Track market trends from social media]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26279787">thread link</a>) | @jianingqi
<br/>
February 26, 2021 | https://member.chatanalytic.com/demo/ | <a href="https://web.archive.org/web/*/https://member.chatanalytic.com/demo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">

            <!-- Main Content -->
            <div id="content">

                <!-- Topbar -->
                <!-- <nav class="navbar navbar-expand navbar-light bg-white topbar mb-4 static-top shadow">


                    <button id="sidebarToggleTop" class="btn btn-link d-md-none rounded-circle mr-3">
                        <i class="fa fa-bars"></i>
                    </button>


                    <form
                        class="d-none d-sm-inline-block form-inline mr-auto ml-md-3 my-2 my-md-0 mw-100 navbar-search">
                        <div class="input-group">
                            <input type="text" class="form-control bg-light border-0 small" placeholder="Search for..."
                                aria-label="Search" aria-describedby="basic-addon2">
                            <div class="input-group-append">
                                <button class="btn btn-primary" type="button">
                                    <i class="fas fa-search fa-sm"></i>
                                </button>
                            </div>
                        </div>
                    </form>


                    <ul class="navbar-nav ml-auto">


                        <li class="nav-item dropdown no-arrow d-sm-none">
                            <a class="nav-link dropdown-toggle" href="#" id="searchDropdown" role="button"
                                data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                <i class="fas fa-search fa-fw"></i>
                            </a>
                            <div class="dropdown-menu dropdown-menu-right p-3 shadow animated--grow-in"
                                aria-labelledby="searchDropdown">
                                <form class="form-inline mr-auto w-100 navbar-search">
                                    <div class="input-group">
                                        <input type="text" class="form-control bg-light border-0 small"
                                            placeholder="Search for..." aria-label="Search"
                                            aria-describedby="basic-addon2">
                                        <div class="input-group-append">
                                            <button class="btn btn-primary" type="button">
                                                <i class="fas fa-search fa-sm"></i>
                                            </button>
                                        </div>
                                    </div>
                                </form>
                            </div>
                        </li>

                        <li class="nav-item dropdown no-arrow mx-1">
                            <a class="nav-link dropdown-toggle" href="#" id="alertsDropdown" role="button"
                                data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                <i class="fas fa-bell fa-fw"></i>
                                <span class="badge badge-danger badge-counter">3+</span>
                            </a>
                            <div class="dropdown-list dropdown-menu dropdown-menu-right shadow animated--grow-in"
                                aria-labelledby="alertsDropdown">
                                <h6 class="dropdown-header">
                                    Alerts Center
                                </h6>
                                <a class="dropdown-item d-flex align-items-center" href="#">
                                    <div class="mr-3">
                                        <div class="icon-circle bg-primary">
                                            <i class="fas fa-file-alt text-white"></i>
                                        </div>
                                    </div>
                                </a>
                                <a class="dropdown-item text-center small text-gray-500" href="#">Show All Alerts</a>
                            </div>
                        </li>

                        <li class="nav-item dropdown no-arrow mx-1">
                            <a class="nav-link dropdown-toggle" href="#" id="messagesDropdown" role="button"
                                data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                <i class="fas fa-envelope fa-fw"></i>
                                <span class="badge badge-danger badge-counter">7</span>
                            </a>
                            <div class="dropdown-list dropdown-menu dropdown-menu-right shadow animated--grow-in"
                                aria-labelledby="messagesDropdown">
                                <h6 class="dropdown-header">
                                    Message Center
                                </h6>
                                <a class="dropdown-item d-flex align-items-center" href="#">
                                    <div class="dropdown-list-image mr-3">
                                        <img class="rounded-circle" src="https://source.unsplash.com/Mv9hjnEUHR4/60x60"
                                            alt="">
                                        <div class="status-indicator bg-success"></div>
                                    </div>
                                    <div>
                                        <div class="text-truncate">Am I a good boy? The reason I ask is because someone
                                            told me that people say this to all dogs, even if they aren't good...</div>
                                        <div class="small text-gray-500">Chicken the Dog · 2w</div>
                                    </div>
                                </a>
                                <a class="dropdown-item text-center small text-gray-500" href="#">Read More Messages</a>
                            </div>
                        </li>

                        <div class="topbar-divider d-none d-sm-block"></div>

                        <li class="nav-item dropdown no-arrow">
                            <a class="nav-link dropdown-toggle" href="#" id="userDropdown" role="button"
                                data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                <span class="mr-2 d-none d-lg-inline text-gray-600 small">Spoons</span>
                                <img class="img-profile rounded-circle"
                                    src="img/undraw_profile.svg">
                            </a>
                            <div class="dropdown-menu dropdown-menu-right shadow animated--grow-in"
                                aria-labelledby="userDropdown">
                                <a class="dropdown-item" href="#">
                                    <i class="fas fa-user fa-sm fa-fw mr-2 text-gray-400"></i>
                                    Profile
                                </a>
                                <a class="dropdown-item" href="#">
                                    <i class="fas fa-cogs fa-sm fa-fw mr-2 text-gray-400"></i>
                                    Settings
                                </a>
                                <a class="dropdown-item" href="#">
                                    <i class="fas fa-list fa-sm fa-fw mr-2 text-gray-400"></i>
                                    Activity Log
                                </a>
                                <div class="dropdown-divider"></div>
                                <a class="dropdown-item" href="#" data-toggle="modal" data-target="#logoutModal">
                                    <i class="fas fa-sign-out-alt fa-sm fa-fw mr-2 text-gray-400"></i>
                                    Logout
                                </a>
                            </div>
                        </li>

                    </ul>

                </nav> -->
                <!-- End of Topbar -->

                <br>

    <!-- Begin Page Content -->
    <div>

        <!-- Page Heading -->
        

        <!-- Content Row -->

        <div>

            <!-- Area Chart -->
            <div>
                <div>
                    <!-- Card Header - Dropdown -->
                    <p>
                        <h6>Sentiment</h6>
                        <!-- <div class="dropdown no-arrow">
                            <a class="dropdown-toggle" href="#" role="button" id="dropdownMenuLink"
                                data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                <i class="fas fa-ellipsis-v fa-sm fa-fw text-gray-400"></i>
                            </a>
                            <div class="dropdown-menu dropdown-menu-right shadow animated--fade-in"
                                aria-labelledby="dropdownMenuLink">
                                <div class="dropdown-header">Sources:</div>
                                <a class="dropdown-item"><i class="fas fa-check m-1"></i>r/wallstreetbets</a>
                                <a class="dropdown-item"><i class="fas fa-check m-1" hidden></i>r/stocks</a>
                                <a class="dropdown-item"><i class="fas fa-check m-1"></i>Twitter</a>
                                <a class="dropdown-item"><i class="fas fa-check m-1" hidden></i>WSJ</a>
                                <a class="dropdown-item"><i class="fas fa-check m-1"></i>MarketWatch</a>
                                <div class="dropdown-divider"></div>
                                <a class="dropdown-item">All</a>
                            </div>
                        </div> -->
                    </p>
                    <!-- Card Body -->
                    <div>
                        
                        <div>
                          <p>  Stock Price
                          </p>
                          <p>  Sentiment
                          </p>
                          <p>  Mentions
                          </p>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Pie Chart -->
            <div>
                <div>
                    <!-- Card Header - Dropdown -->
                    <p>
                        <h6>Mention Monitor</h6>
                    </p>
                    <!-- Card Body -->
                    <div>
                        
                        <p><span><i></i><p id="mentionTick1"> TSLA</p></span>
                            <span><i></i><p id="mentionTick2"> TSLA</p></span>
                            <span><i></i><p id="mentionTick3"> TSLA</p></span>
                        </p>
                        <p><span><i></i><p id="mentionTick4"> TSLA</p></span>
                            <span><i></i><p id="mentionTick5"> TSLA</p></span>
                            <span><i></i><p id="mentionTick6"> TSLA</p></span>
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div>
        <!-- Content Column -->
        

          <!-- Content Column -->
          <div>

              <!-- Project Card Example -->
              <div>
                  <p>
                      <h6>Trending Words</h6>
                  </p>
                  <div>
                      <div>
                        <div>
                          <div>
                              <p>
                                  <h6>TSLA</h6>
                              </p>
                              <div>
                                <p>
                                  Tesla Tequila
                                </p>
                                <p>
                                  Battery Day
                                </p>
                                <p>
                                  DOGE
                                </p>
                              </div>
                          </div>
                        </div>
                        <div>
                          <div>
                              <p>
                                  <h6>GME</h6>
                              </p>
                              <div>
                                <p>
                                  wallstreetbets
                                </p>
                                <p>
                                  AMC Stock
                                </p>
                                <p>
                                  GME Squeeze
                                </p>
                              </div>
                          </div>
                        </div>
                        <div>
                          <div>
                              <p>
                                  <h6>GOOG</h6>
                              </p>
                              <div>
                                <p>
                                  Google Doodle
                                </p>
                                <p>
                                  Google Meet
                                </p>
                                <p>
                                  Pixel 4a
                                </p>
                              </div>
                          </div>
                        </div>
                      </div>

                  </div>
              </div>
            </div>
          </div>

    <!-- Waitlist Modal-->
    


    <!-- Bootstrap core JavaScript-->
    
    

    <!-- Core plugin JavaScript-->
    

    <!-- Custom scripts for all pages-->
    

    <!-- Page level plugins -->
    
    

  </div>
  </div>

  <!-- Footer -->
  
  <!-- End of Footer -->

  </div></div>]]>
            </description>
            <link>https://member.chatanalytic.com/demo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279787</guid>
            <pubDate>Fri, 26 Feb 2021 20:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Nym Network – Next Generation of Privacy Infrastructure [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279779">thread link</a>) | @octabond
<br/>
February 26, 2021 | https://nymtech.net/nym-whitepaper.pdf | <a href="https://web.archive.org/web/*/https://nymtech.net/nym-whitepaper.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nymtech.net/nym-whitepaper.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279779</guid>
            <pubDate>Fri, 26 Feb 2021 20:58:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Macrometa’s approach to solving complex, geo distributed data challenges]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279753">thread link</a>) | @Elof
<br/>
February 26, 2021 | https://www.macrometa.com/blog/solving-complex-geo-distributed-data-challenges | <a href="https://web.archive.org/web/*/https://www.macrometa.com/blog/solving-complex-geo-distributed-data-challenges">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Introduction</p><p>The last 15 years have seen several successive waves of big data platforms and companies offering new database and analytics capabilities. Leveraging the public cloud, these large scale distributed data systems work well in centralized, single region or single data center topologies and are geared for <strong>“Read intensive”</strong> data problems.</p><p>Companies such as Cloudera, Snowflake, and more recently Databricks are examples of successful companies that have innovated with novel “read architectures” that reduce the structural cost of reading immutable data and built new big data orientated analytics apps and capabilities by exploiting their lower costs of reads.</p><p>We are now faced with new challenges with workloads and use cases that are <strong>“write intensive”</strong>. The write path is far more challenging than the read path. This is because the read path is built on immutable or non-changing data. The write path necessarily involves mutable data with varying rates of change and growth in the data sets of use cases.</p><p>Additionally, the write path today has also evolved from the client/server’s “request – response”based interaction model to new, streaming data architectures where streams of “events” need to be processed as they are created or generated by various sources.</p><p>A similar cascade of innovations is needed on the write path to solve the structural costs of data writes as big data platforms have done to change the structural costs of data reads.</p><p>We summarize the challenges of the write path in modern cloud data platforms as follows:</p><ol start="" role="list"><li>Expensive Writes - (Ex: DynamoDB - <em>writes are 16x to 64x more expensive than reads</em>).</li><li><em>Centralized architectures</em> - Introduces large access latencies for globally distributed users and as well as large transit latencies and network transfer costs for data to be shipped to the cloud.</li><li><em>Require network communication intensive</em> and <em>coordinated approaches</em> to consistency such as using state machine replication or consensus and therefore are only feasible within a single cloud region (due to the need for ultra-low latency and reliable data center class networks).</li><li><em>Require synchronous replication</em> to ensure all nodes in a distributed system make forward progress on writes with transaction semantics where either all related writes are accepted Macrometa 2or all are rejected. In combination with point #3 above, replication and coordination end up being the Achilles heel for write-intensive distributed systems.</li></ol><p>Today’s enterprise apps and cloud workloads are no longer “read intensive”, but are a combination of:</p><ol start="" role="list"><li><strong>“Write intensive”</strong> (ex: IoT, Monitoring, ClickStreams, Fraud Detection etc) or</li><li><strong>“Read-Write balanced”</strong> (ex: E-Commerce, Gaming, Adtech etc</li></ol><p>This is because modern cloud native architectures don’t use just one database behind them for persistence but instead use several, specialized databases and data stores for different types of semi structured and unstructured data. This “polyglot persistence” pattern used by modern apps further exacerbates the write path and write intensity problem as now a single application level write generates a successive cascade of amplified writes to multiple data stores underneath the application.</p><p>The <strong>“Multi database/datastore mutations”</strong> pattern where an application level write results in several cascading updates to multiple independent databases or data stores causes very high levels of write amplification and resulting costs.</p><p>Attempts to solve these problems using conventional techniques of <em>“write back”</em> and <em>“write through”</em> caching no longer work for such polyglot backend patterns – one simply cannot buffer writes in a single buffer and fan out to multiple databases and data stores underneath without completely giving up on consistency and transaction semantics.</p><p>For use cases where multi-region data, or edge based data processing are needed, the problems are further exacerbated by the physical link latency, topology and reliability of the wide area network. These use cases have to contend with well known problems such as:</p><ol start="" role="list"><li>Network latencies with 100s of ms,</li><li>Unreliable &amp; jittery networks.</li></ol><p>Given the challenges just described, current centralized distributed data systems and the technologies that underpin them cannot be generalized well to fit edge &amp; multi-cloud workloads.</p><p>Macrometa has been now for several years, focused on solving the challenges of the write path.We don’t just want to solve the cost and consistency problem of the write path but also enable globally distributed stateful apps &amp; web services that can run in 10s and 100s of regions world wide concurrently with less than 50 ms end to end latency for data access by 95% of the world’s population.</p><p>This is a non trivial computer science problem because:</p><ol start="" role="list"><li>It requires our platform to run in wide-area deployments where nodes forming the database may be separated by more than 100ms of latency and unreliability in the network connections.</li><li>It requires our platform to run across 10s to 100s of data centers and yet present a single system image (SSI).</li><li>It requires us to have a significantly better write cost structure and cost-performance ratio than current cloud data systems built on centralized architectures.</li></ol><p>Macrometa accomplishes this with a novel architecture that combines geo-distributed, coordination free write and replication techniques and a multi-modal data platform with tunable consistency levels to solve these problems in an edge-native way.</p><p><a href="https://assets.website-files.com/5fa9e94bc848ae335afdd627/6039546ae3e1cdd9e2f5eb3d_Macrometa%E2%80%99s%20approach%20to%20solving%20complex%2C%20geo%20distributed%20data.pdf">Download the White Paper</a> to learn more</p></div></div>]]>
            </description>
            <link>https://www.macrometa.com/blog/solving-complex-geo-distributed-data-challenges</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279753</guid>
            <pubDate>Fri, 26 Feb 2021 20:55:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to be a graffiti artist]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26279728">thread link</a>) | @rememberlenny
<br/>
February 26, 2021 | https://blog.rememberlenny.com/2021/02/24/how-to-succeed-at-being-a-graffiti-artist/ | <a href="https://web.archive.org/web/*/https://blog.rememberlenny.com/2021/02/24/how-to-succeed-at-being-a-graffiti-artist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><p>Reading Time: 24 minutes read</p>
<h3><em>Building your product, getting up, be recognized and exit</em></h3>



<p>Here is a recent presentation I gave at an unconference event. I don’t paint publicly today, but it’s a fascinating space so I presented on “how to succeed at being a graffiti artist”.</p>



<figure><a href="https://i0.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F50e931d8-b0ee-4217-84a9-81f58f37bf2d_2004x718.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F50e931d8-b0ee-4217-84a9-81f58f37bf2d_2004x718.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F50e931d8-b0ee-4217-84a9-81f58f37bf2d_2004x718.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>Thank you all for joining this session today! I’m going to be presenting on a topic slightly different than the originally proposed title “How to paint graffiti and everything you didn’t know about street art.” A better title would be how to succeed at being a graffiti artist, y-combinator style. This is going to be a very deep dive into the career of a hypothetical graffiti artist, of which I largely don’t think exist. As a humorous way of synthesizing all the great sessions we have had, I’m going to share the parallels between graffiti artists’ careers and growing a startup.</p>



<figure><a href="https://i0.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69f68fb-8b6f-4ee7-8296-9c1d7182bd57_2136x1058.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2Ff69f68fb-8b6f-4ee7-8296-9c1d7182bd57_2136x1058.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2Ff69f68fb-8b6f-4ee7-8296-9c1d7182bd57_2136x1058.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>As a graffiti artist, you need to design your pieces and build your product, then you need to get sales, market your product to the masses, hire to expand your crew, and finally consider an exit strategy. Following this advice could lead you to glory and riches, but much more likely is you’ll end up in jail and jaded about the world.</p>



<figure><a href="https://i0.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F274158eb-a4c7-4693-9ee8-c767733f4b1b_2152x1242.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F274158eb-a4c7-4693-9ee8-c767733f4b1b_2152x1242.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F274158eb-a4c7-4693-9ee8-c767733f4b1b_2152x1242.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>A bit of background here – I became passionate about street art growing up in San Francisco, at the age of 8 – where I was regularly seeing abandoned shop faces and parking lots with big colorful murals. My brother at the time was himself painting graffiti and had a cache of spray cans that I remember seeing. As I got older, I found a job at a retail art store, and from there began my juvenile spray painting. Through high school, I got into a bit of trouble and was expelled – which did not deter me from continuing my nighttime pursuits of scaling buildings. Eventually, after college, I moved to China, where I was part of a local graffiti crew, and ironically also where I met my cofounder (not related to the graffiti). Eventually, I stopped painting publicly, but ended up making software related projects to help graffiti artists evade the police, and finally started indexing all the street art online through Instagram and Flickr. This project interestingly received some grants/funding and became <a href="https://pioneer.app/blog/pioneer-interview-lenny-bogdonoff/">indirectly my foray</a> to getting <a href="https://marginalrevolution.com/marginalrevolution/2018/11/emergent-ventures-grant-recipients.html">funding in startups</a>.</p>



<figure><a href="https://i1.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5196aa7f-9827-4e34-a7cf-0bc4d84a1250_2030x1176.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F5196aa7f-9827-4e34-a7cf-0bc4d84a1250_2030x1176.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F5196aa7f-9827-4e34-a7cf-0bc4d84a1250_2030x1176.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>So starting off!&nbsp;</p>



<p>First, let’s start with PRODUCT. All graffiti artists have a product. Of course, you have tools and resources you use, but the product is what you create. So for a graffiti artist, letter forms and characters are everything. Graffiti has changed a lot over the years – for one, it started in the north east, some say Philadelphia, others say New York – but essentially, it started in a concentrated area in the late 70s. If you want, you can watch a fascinating documentary that captures this period in a movie called Style Wars, which I believe is on YouTube. It very much has the vibes of Pirates of Silicon valley, which is a brilliant movie about Steve Jobs and Bill Gates – but street art related.&nbsp;</p>



<figure><a href="https://i1.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F452dc2bc-4686-427f-9b0a-ec1035495bdc_2210x1166.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F452dc2bc-4686-427f-9b0a-ec1035495bdc_2210x1166.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F452dc2bc-4686-427f-9b0a-ec1035495bdc_2210x1166.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>As you can imagine, the spray can is to street art, as silicon is to tech companies. Today a lot of street art and graffiti use all kinds of materials from dynamite to glue, but at the essence of it all is the essential brand or name that is being painted.</p>



<p>So – first you need to pick your name.</p>



<p>The name of your piece is going to be important because you are likely going to be working on this for quite a while. You likely will paint your name over and over again tens of thousands of times, so picking this carefully in the beginning is important.</p>



<p>Important aspects here are around the letters you pick, their combination and the deeper meaning of the word for you (founder-market fit?). The letters you pick are important because you can have uniquely expressive lowercase and uppercase letters. Sometimes the letter combinations are important also, because they will allow your entire word to either take up more space or be easier to read and write. For example, a lowercase g and an uppercase G are totally different shapes, so there’s a lot you can do with it. Comparing this to a P/p for example, which doesn’t look that different in both forms. You also need to think about how distinguishable a letter is with various styles. For example, a U and V can look similar, so you need to be conscious how the letters will need to be drawn to make sure it is legible.</p>



<figure><a href="https://i2.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6ac8d4a4-4fc9-4fe2-b020-a40354545895_2142x1060.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F6ac8d4a4-4fc9-4fe2-b020-a40354545895_2142x1060.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F6ac8d4a4-4fc9-4fe2-b020-a40354545895_2142x1060.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>Unlike picking a good start up company name, you don’t need to worry about it being easy to pronounce or getting a good dot com address. In fact, it’s probably better if it’s harder to pronounce, so the police records on you result in mistaken inputs, and less attention from the wrong people.</p>



<p>It’s worth noting, like many startup names, there is likely someone who already painted your word before you. It’s going to be up to you whether you can out execute and differentiate them when doubling down on yours.</p>



<p>Once you are clear on your name, then you need to understand your tools. Like building your startup, where there are tons of frameworks and languages you can use, you can decide to go commercial or bespoke.&nbsp;</p>



<p>As I mentioned, the tooling here is endless, but the goal is to make a mark that lasts. From the smallest point of impact with the longest lasting mark, many graffiti artists will have some form of a chisel. This lets you carve into plastic, mirrors, windows or metal. An amateur will carry around a key or sharp piece of metal, but the pros will have diamond tipped drill bits. You can get these at your local hardware store, and nothing will be out of your reach. With these drill bits, you will have high expressivity, but carry around a very small object.&nbsp;</p>



<figure><a href="https://i0.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F733d940b-8ead-474d-beee-d1159ff70fee_2142x1018.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F733d940b-8ead-474d-beee-d1159ff70fee_2142x1018.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F733d940b-8ead-474d-beee-d1159ff70fee_2142x1018.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>Next is your pens. Street artists love drips, so the best pens are the ones that let you control how much ink is released when you draw. These can be literal mops, that let you squeeze out ink on a surface, or they can be paint based with felt tips. Whichever you use, an intentional graffiti artist is going to want to last even if it’s painted over. In this case, a good mixture of ink will seep through multiple layers of paint and leave a lasting impression.</p>



<figure><a href="https://i1.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F52d358e8-5a34-431f-81eb-eacc7b618278_1146x1018.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F52d358e8-5a34-431f-81eb-eacc7b618278_1146x1018.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F52d358e8-5a34-431f-81eb-eacc7b618278_1146x1018.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>The most common tool for a graffiti artist is going to be the spray can. Surprisingly, there are a lot of different kinds of spray paint, and even more so, there are countless types of spray paint tips. From the paint side, you can find a series of commercially available kinds, such as Rustoleum, which is aerosol oil paint, Krylon – which is a common acrylic, or even lighter materials that are meant for the likes of floral coloring. Technically, at some stores, you can also find aerosol food sprays, but that’s not going to fit the “permanent” bill.&nbsp;</p>



<figure><a href="https://i0.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2dbf8bf0-1323-47ae-96ab-0c0af47a355f_1774x1170.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F2dbf8bf0-1323-47ae-96ab-0c0af47a355f_1774x1170.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F2dbf8bf0-1323-47ae-96ab-0c0af47a355f_1774x1170.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>If you go to a true art store, you get an entire different category of spray paints which are going to specialize in details that matter for an on the run artist. For one, you can get a much wider array of colors, which aren’t going to be available on the mass market. Everything from avocado green to skylark blue. These wider colors come in a variety of materials , such as oil and acrylic also, but most importantly is that they can dry quickly due to a higher pressure, which gives you the ability to cover more surface quickly. Another key important detail is to decide on oil or acrylic, but not to mix them. Oil can paint on anything, but will break up an acrylic spray if painted over while wet.</p>



<p>Next are the spray caps. This is the heart and soul of a graffiti artists mode of expression. There are two main categories of a spray cap – female and male tips. Most consumer spray paint today uses a female tip insert, as the most common street artists tips are male based. As a result, the markets have adapted and started creating female tip adapters, but they often leak paint.&nbsp;</p>



<figure><a href="https://i1.wp.com/cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3cd734-0c4f-42be-9199-de519fb38cd3_1394x1172.png?ssl=1" target="_blank" rel="noreferrer noopener"><img src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F5f3cd734-0c4f-42be-9199-de519fb38cd3_1394x1172.png?ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/blog.rememberlenny.com/wp-content/uploads/2021/02/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com2Fpublic2Fimages2F5f3cd734-0c4f-42be-9199-de519fb38cd3_1394x1172.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>The spray caps will vary in a few important ways. First, the nozzle of a spray cap will control the release of paint from the spray can. What this means is that the surface of the spray can be controlled based on the size of the nozzle hole and the surface of a spray cap exit. A larger surface on a spray cap will let you have a larger cone of paint, which can distribute more paint quickly. Also this will allow you to have highly controlled effects when moving the spray can quickly closer and farther away from the wall. I’ll go into this shortly, but a talented artist will master their “can control”. A negative on the larger nozzles is that it will cause the paint to drip when not used carefully. You don’t want to be the artist with tons of drips, since it looks tacky and can take time to fix up. To compliment large nozzle spray caps are smaller nozzle caps. These are important for details, when you are trying to make fine lines. Also there are caps that control the speed of the spray, so you can create intentional airy looks, such as for certain visual effects. Finally, there are certain caps that will spray their nozzle cone unevenly, such that the edge of the cone nozzle will collect paint faster than the center – which allows you to create flares.</p>



<p>An important point to consider is that you need to take good care of your tips once you use them. Since the spray paint will dry quickly, it’s good to give you caps a “cleaning” spray by turning your caps upside down and spraying out air, to make sure the nozzles don’t clog and paint doesn’t dry by affecting the cone output. For this reason, it’s good to have backup nozzles.</p>



<p>Personally, my favorite tip is the NY Fat. This is a long time favorite and was originally inspired by the spray nozzles found on cleaning materials, such as spray-on bleach. As you can imagine, the original spray paint cans used spray tips from other household aerosol products, and did not have the wide range of selection. Another trick that used to be used for getting interesting color effects was to intentionally clog your tips with one color, and then use that tip on a new color …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.rememberlenny.com/2021/02/24/how-to-succeed-at-being-a-graffiti-artist/">https://blog.rememberlenny.com/2021/02/24/how-to-succeed-at-being-a-graffiti-artist/</a></em></p>]]>
            </description>
            <link>https://blog.rememberlenny.com/2021/02/24/how-to-succeed-at-being-a-graffiti-artist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279728</guid>
            <pubDate>Fri, 26 Feb 2021 20:52:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Riddle of the Square]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26279712">thread link</a>) | @chrbutler
<br/>
February 26, 2021 | https://www.chrbutler.com/square | <a href="https://web.archive.org/web/*/https://www.chrbutler.com/square">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<br>

<h6>← <a href="https://www.chrbutler.com/essays">See All Articles</a></h6>
        <p>
<img src="https://blot.im/cdn/blog_a7eb7cf1ab024efcb17c380ef69c53f4/_image_cache/55ab3c90-d28f-475f-8262-87a25e72b88f.jpg" width="1000" height="500" data-action="zoom">
</p>

<p>
Shapes are mysterious. They are basic, rudimentary forms — simple ideas upon which we build more complex systems of understanding. They are also vast landscapes of information and meaning — doorways into mental worlds of thought, unhindered by physical limitations.
</p>
<p>
You can look at the simplest of forms — a square, a circle, a triangle — and its edges will accommodate your curiosity; they will stretch; they will become porous; their liminality will beckon you to enter and to hold them. Like the Sphinx, they may be all their edges tell you, or they may be anything else. They are riddles for the eye.
</p>
<p>
Ellsworth Kelly put it much more simply when he said that “a shape contains personality.”
</p>
<p>
Kelly was talking about just one of his Blue Panels when he said this, though his entire body of work exemplifies the idea. He is best known for painting fields of color. His contribution to modern art was, in part, a vast collection of shaped canvasses, painted in single, flat colors. Beginning his career at a time when abstract expressionism was the idea carrying modern art forward, Kelly’s work was universally iconoclastic. For many onlookers at the time, it simply wasn’t art. And though many of them had their complaints about the expressionist work of his peers, they could at least still see the artist’s <i>hand</i> in the work, be swept up in its motion, or even lose themselves in the physical beauty of the material itself. Kelly’s objects were made precisely to do the opposite: not to engage the viewer in the object or its maker, but to draw them in to everything beyond it. To be a riddle and an invitation.
</p>
<p>
Kelly once <a href="https://www.metmuseum.org/metmedia/video/collections/modern/ellsworth-kelly-blue-panel" target="_blank">told a story</a> about a man he met on an airplane. They got to talking about painting. The man shared that he often visits The Metropolitan Museum of Art to look at the paintings. “One painting really throws me,” he said. “It’s a large blue painting with nothing on it.” Kelly replied, “That’s mine. Go look at it again.” Rather than a correction, Kelly offers another riddle.
</p>
<p>
I love this story because I can tell the same one. When I was seventeen, I went with my senior art class to the same museum, and saw the same painting. We had come to tour the modern art gallery in general, but Kelly’s <a href="https://www.metmuseum.org/art/collection/search/484636" target="_blank">Blue Panel <span>II</span></a>, which is still on view in <a href="https://maps.metmuseum.org/galleries/fifth-ave/2/922" target="_blank">Gallery 922</a>, became our fixation. We gathered in front of it and stared; it silently divided us. Some said it was art. Others said it was not. Its name further provoked the angst of the naysayers: “Blue Panel number <i>two</i>? So there are more of these things?”
</p>
<p>
The debate continued as we left the museum. It went on as we explored the city. And on still, all way home on the bus. Someone suggested we keep this going — that we get together once a week to talk about art outside of class. We named our little group <i>The Wedge</i>. It was a nod to Kelly’s panel and the way it had cleaved our assumed intellectual unity. The group, as far as I know, remained a fixture at my high school for a few years after we were gone but eventually faded away. But I have remained transfixed by <i>the wedge</i>.
</p>
<p>
As I said, Kelly made more than one Blue Panel. In what feels like an almost supernatural coincidence, one of them just happens to hang in a gallery near me at the North Carolina Museum of Art. I remember the first time I strode into the room and saw it. I stopped, dead in my tracks, as if I’d seen a ghost of my past returned in tremendous glory. The <span>NCMA</span>’s <a href="https://ncartmuseum.org/art/detail/blue_panel" target="_blank">Blue Panel</a> is not the same Blue Panel as the one I’d seen as a teenager at The Met. It’s bigger. It’s brighter. Its movement is less of a subtle lean to the side and more of an explosive twist. It’s my favorite of Ellsworth Kelly’s <i>Blue Panels</i>, and a perfect example of what is so magical about his work. I stare at his shapes and am in awe of their endless capacity. In them I see all of geometry, all of math, all surfaces, all spaces, all movement.
</p>
<p><span>
■□
</span></p>
<p>
In no other shape is there greater mystery than the square. I wonder if that is why one of the very few single, square images that Ellsworth Kelly produced is just black. He even titled it that way: “Black,” without reference to shape or surface, leaving us all to decide what it is, or where it is, or where we are within it.
</p>
<p>
A square is a plane with four equal sides set at four right angles. Such a thing hardly exists in the world. Everything we call <i>a square</i> is an example that falls considerably short of the definition, provided you look closely enough. That’s because the precision of numbers doesn’t really exist in the natural world.
</p>
<p>
Plato considered numbers to be <i>abstract</i>. For him, they were ideas that lack physical form necessarily, because to take any form would be to lose their perfection. He also considered numbers to be <i>eternal</i> — perpetually existing — and therefore more real than the world in which we live. His reverence for the perfection of the abstract was almost religious. In fact, he believed that things like numbers and shapes actually existed in another space, often called now, after him, <i>The Platonic Realm</i>. Aristotle, his student, was more pragmatic. He considered numbers to be nothing more than an invention of the mind to aid in our understanding of nature, providing measures of amount, or distance, or duration. One can imagine the debate: One side might say, “If numbers are just a construct, then why do they describe the universe so well?” To which the other might reply, “So would anything else, if that’s what we decided to use to describe the universe!”
</p>
<p>
Nevertheless, both a Platonist and an Aristotelian can agree that there is quite some distance between the perfection of geometry and the plasticity of nature. The square, again, makes for an ideal symbol. It is too perfect for nature. Observing both where we <i>find</i> squares and how we <i>use</i> them bears that out. Of all the geometric shapes, the square may be the least commonly occurring in nature. This is because most things in the natural world are molecularly asymmetrical. Mineral structures, for instance, are quite varied in their geometric correspondence. The few that are square are pyrite, galena (the mineral form of lead sulfide), and halite (rock salt). Most everywhere you look for structure in nature, though, you will find far less rigid forms. While there are a few scant natural squares — lobster eyes comprise millions of micron-length square channels; wombat poop is, oddly, cubic — circles, triangles, rhombuses, and all sorts of polygons are far more common. And most of them are warped.
</p>
<p>
When we make squares and when we don’t follows nature’s lead. I often think about how infrequently we use squares when creating spaces and structures. Our bodies, of course, determine this. A square door, for example, would be interesting to look at but impractical to use. We are taller than we are wide. A square door tall enough to give us passage would be wider and intrude upon the space in which it opened more than necessary. So doors, like many other things created by nature, for nature, in nature, are rarely square. Perfect symmetry, as it turns out, is inefficient.
</p>
<p>
I often think about that principle when, as a designer, I consider aspect ratios of imagery. Why is everything a rectangle? There is a reason why cinema screens, televisions, and monitors are wider than they are tall. A rectangular plane in landscape orientation fits our biology. Our two eyes, spaced apart on our head as they are, create a wider periphery. We can see more horizontally than vertically without moving our heads. A square screen, large enough to be absorbingly “cinematic,” would have us literally moving our heads up and down continually in order to take in the visual information it displayed. The ergonomics of wide screens are obviously superior. The visual economy of the rectangle works its way inward, from the edges of the form to its contents. As many a web designer will lament, another day, another rectangle. But it’s worth pointing out that the complaint would be the same and certainly louder, if it were another day, another square. Symmetry of form is beautiful, but it isn’t always functional.
</p>
<p>
Symmetry of system, on the other hand, can be extremely efficient, even when it doesn’t correspond to nature. Because a square is perfectly symmetrical, it can be duplicated into infinity, creating a reliably consistent structure — a grid — in all directions. Grids help us to work within and upon nature, even when within nature no grids can be found.
</p>
<p>
As a child — and to this day — I was fascinated by maps and pages of text and easily transfixed by them. I often find myself drawn to pages and screens, for instance, not by their contents but by their form. By how the information is arranged. As a child, I didn’t realize that what I was actually looking at was <i>the grid</i>. The form of the page became a puzzle; I was in search of the system beneath it. The grid becomes another riddle for the eye. Most things we make we do so upon a grid, though the precision of their form can never match the abstract system beneath them. There’s a tension in that, one which provides endless provocation to anyone who looks.
</p>
<p>
Ellsworth Kelly understood that. He created an <a href="https://ellsworthkelly.org/work/the-boston-panels-the-john-j-moakley-federal-courthouse-boston/" target="_blank">installation in Boston</a> which is an ideal illustration of the tension between the perfect symmetry and eternality of the abstract and the asymmetry and limits of nature. Within a large, open column of space within the John J. Moakley Federal Courthouse building, Kelly hung a set of colored panels. From a mezzanine, you can look out and up into the column to a point at which the arc’ed ceiling above you cuts off your view, creating the illusion that the grid of shapes goes on and up forever. When you stand in front of it, you can easily imagine them encircling you, too. It’s as if <i>The Boston Panels</i> were as close as Kelly could get to merging our world with The Platonic Realm.
</p>
<p>
▱
</p>
<p>
It’s not lost on me that this has been more about forms that are <i>not</i> squares than those that are. For me, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chrbutler.com/square">https://www.chrbutler.com/square</a></em></p>]]>
            </description>
            <link>https://www.chrbutler.com/square</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279712</guid>
            <pubDate>Fri, 26 Feb 2021 20:50:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Year 5 School Bachelor's Degree (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279625">thread link</a>) | @ryanmjacobs
<br/>
February 26, 2021 | https://blainsmith.com/articles/the-20-year-5-school-bachelors-degree/ | <a href="https://web.archive.org/web/*/https://blainsmith.com/articles/the-20-year-5-school-bachelors-degree/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
  <article>
    <header>
      
      <p id="date">
        <time>May 10, 2020</time>
      </p>
    </header>
    <p>Well, my undergraduate career is finally over.</p>
<h2 id="rensselaer-polytechnic-institute">Rensselaer Polytechnic Institute</h2>
<p>I was fortunate enough to get accepted to my first choice back in 2000 when I graduated high school. Unfortunately, however, it wasn't without its speed bumps. I had received the Rensselaer Medal prior to receiving my acceptance letter so when I got notified I was awarded the scholarship I assumed my acceptance letter was just around the corner. As it turned out, I was wrong. I actually got officially rejected at first. Naturally I was very confused since I was awarded an academic scholarship to a school that rejected my admission. My mother ended up calling the school while I was in my high school and they told her they had made a mistake. They sent me the wrong letter. I had been accepted all along.</p>
<p>I spent about a year attending Rensselaer until I came to the realization I was not personally ready for college life. I was still mentally unprepared and immature to be on my own 3 hours away from my home town with no mode of transportation for myself. I ended up leaving Rensselaer at the end of my freshman year to move back home and chose a school closer to home in Worcester, MA.</p>
<h2 id="worcester-polytechnic-institute">Worcester Polytechnic Institute</h2>
<p>My next attempt at college was closer to home and with being allowed a vehicle on campus I had the freedom to move around as I pleased. Home was now only 45 minutes away so I could head back whenever I needed to. Knowing that choice was available made studying a lot easier to focus on. However, this college attempt was met with not only going through 9/11 my first year there, but also contracting mononucleosis, commonly known as “mono”, my second year there. This put me behind in school work and required me to undergo surgery over the summer to have my tonsils removed.</p>
<p>After playing lots of catch up and realizing I was paying a lot of money per course for content I was just buying books on Amazon to learn I decided to end pursuing my degree in Computer Science and focus on a degree that justified the high-priced tuition to be taught in a classroom.</p>
<h2 id="bentley-college">Bentley College</h2>
<p>Third time is a charm right? Bentley College is more known for its business and information technology curriculum which sounded like a better choice given the state of the world at this point. I thought I would focus more on a business oriented technical degree since at lot of the statistics for graduates with Computer Science degree showed their salaries dropped significantly. With mounting student load debt it made more sense to change to another degree to be more marketable when I graduated to pay back the ever increasing loans. As it turns out I hated the business side of technology. My heart was more in the scientific side, but it wasn't marketable in my area so I made a very hard to decision to drop out of college completely. I couldn't justify taking out more money for an education I hated doing.</p>
<h2 id="harvard-university">Harvard University</h2>
<p>After working for a few years for a local technology startup I ended up being laid off for financial reasons. Interview after interview yielded nothing I cared for or I was not the right fit. Eventually I came across an ad in Craigslist that ended up being posted by a recruiter. They told me it was for Harvard University. After my last position I thought it would be a smart move to focus on this one as much as I could. They would certainly not go out of business for lack of finances. On top of that I learned that employees got the added perk of taking courses for a ridiculous discount. Sounded like a win/win. Work for one of the most prestigious universities in the US and continue my college career part time at a discount. So that is what I did. I spent almost 5 years chipping away at my degree one course at a time each semester. Unfortunately, on two different occasions, the graduation requirements changed which forced me to take more classes than I anticipated to meet the graduation requirements. During this whole time I was getting older and my life was changing. I had moved to upstate New York and start building a life there while trying to finish online classes. A new job opportunity presented itself to work for a company locally and really put down roots where I lived so, again, I made the choice to drop out of college completely to work and live my life accepting the fact I will never end up with my degree.</p>
<h2 id="suny-empire-state-college">SUNY Empire State College</h2>
<p>Fast forwarding a lot of years and a few different jobs I ended up leaning a new programming language, Go, which piqued my interest in going <a href="https://blainsmith.com/articles/go-made-me-return-college">back to college for Computer Science</a>. At this stage of my life as a father to an autistic son and a working professional as a software engineer I didn't have the time or the means to just stop all of that and return to college full time taking classes during the day. I set out to find a college that accommodated working adult professionals. As it turns out SUNY Empire State College is essentially in my back yard only 10 minutes from my house and their focus is offering degree programs online for adults. This sounded like a perfect choice for someone like me.</p>
<p>I spent the next 3 years taking all the final classes I needed to achieve a Bachelor's Degree in Computer Science. While there were some classes I could have taken in my sleep I pushed through since I could see the light at the end of the very very long tunnel I entered 20 years ago as an 18 year old kid. Now that this part of my life has finally come to an end I have come out the other end with a renewed vigor for academic learning to augment the Computer Science knowledge I have.</p>
<h2 id="masters-degree-certificates-courses">Master's Degree, Certificates, Courses?</h2>
<p>I am still doing as much research a possible, but I do think that I won't stop taking courses in some fashion. The more I pay attention to where the world is headed with respect to technology and computers the more I realize that coding, software engineering, and computer science is only part of the puzzle. Picking up topics in mathematics, physics, material sciences, and other engineering disciplines will only strengthen my understanding and capacity to solve more complex problems in my career as a software engineer. Physicists, mathematicians, and engineers are starting to leverage coding and software engineering principals to do their job so it would be advantageous of me to learn parts of their primary disciplines to do mine. While I do spend most of my time solving problems in the video gaming and entertainment space; having other points of view would make me a more well rounded software engineer to apply those problems solving skills to new and exciting projects.</p>

  </article>
</section></div>]]>
            </description>
            <link>https://blainsmith.com/articles/the-20-year-5-school-bachelors-degree/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279625</guid>
            <pubDate>Fri, 26 Feb 2021 20:42:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kingdom: The Mitanni, with Mara Horowitz]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279603">thread link</a>) | @jrott
<br/>
February 26, 2021 | https://peoplingthepast.com/2021/02/26/blog-post-16-forgotten-kingdom-the-mitanni-with-mara-horowitz/ | <a href="https://web.archive.org/web/*/https://peoplingthepast.com/2021/02/26/blog-post-16-forgotten-kingdom-the-mitanni-with-mara-horowitz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-2149">

	

	
			<figure>
				<img width="750" height="557" src="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=750" alt="" loading="lazy" srcset="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg 750w, https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=150 150w, https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=300 300w" sizes="(max-width: 750px) 100vw, 750px" data-attachment-id="2178" data-permalink="https://peoplingthepast.com/meonbaulksm-2/" data-orig-file="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg" data-orig-size="750,557" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="meonbaulksm" data-image-description="" data-medium-file="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=300" data-large-file="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		




<div>
<p><em>Peopling the Past brings you an ongoing blog series, “Unknown Peoples”, featuring researchers who investigate understudied and/or marginalized peoples in the past.</em></p>
</div>



<div>
<p>Hi, I’m archaeologist Mara Horowitz and I’ve spent ten years studying the spread of the Mitanni Empire at the site of Tell Atchana, ancient Alalakh. The Kingdom of Mitanni was centered on the Jezireh region in northern Syria, a triangle formed by the Upper Khabur river.&nbsp; At its peak, Mitanni’s empire included most of Syria, northern Iraq, and southeastern Turkey.&nbsp; Also known as Naharin by Egypt and Hanigalbat by the Assyrians, Mitanni was a major power player between ca. 1500-1300 BCE.&nbsp; The capital, Washukanni, was mentioned in many texts found in Egypt, west Syria, and Hittite Anatolia.&nbsp; For years archaeologists did not know the location of Washukanni.&nbsp; Today, evidence suggests that the mostly unexcavated site of Tell el Fakhariya on the Khabur River is Washukanni (<a href="http://www.fecheriye.de/en/introduction/" rel="nofollow">http://www.fecheriye.de/en/introduction/</a>). Mitanni layers are also found at Tell Brak, Tell Beydar, and Tell Mozan but are not extensively excavated. Much work remains to be done on the Mitanni, truly a forgotten kingdom.</p>
</div>



<div>
<div>
<p><strong>Who Were the Mitanni?</strong></p>



<p>The Mitanni Kingdom was multi-ethnic and contained both East (Assyrian) and West (Amorite) Semitic populations.&nbsp; The dominant ethnic group in the Mitanni Kingdom were Hurrians, native to the high plateaus and mountains to the north of Mesopotamia.&nbsp; Beginning already in the Early Bronze Age, Hurrians were migrating down to the north Mesopotamian plains and settling in the area around Urkesh.&nbsp; The Hurrian language and the closely related Urartian language from the Armenian highlands are an isolate family, not related to any other known languages, and seem to have died out after the Iron Age.&nbsp;</p>
</div>




</div>



<div>
<p>Within the Hurrian language there are some borrowings that indicate their early contact with neighbors who spoke a language ancestral to the Indic branch of the Indo-European family.&nbsp; Loan words are primarily found in the areas of social rank, horses, gods, and royal names.&nbsp; While some have suggested that Indic warrior-kings installed themselves as rulers of the Hurrian people in the Middle Bronze Age (ca. 2000-1600 BCE) and subsequently founded the Kingdom of Mitanni, there is as yet no direct proof of this. The horses, loan words, and Indic gods could have come about through intensive cultural contact especially at an elite level, and the names through intermarriage and bilingualism. There are no Mitanni texts written solely in proto-Indic (proto-Sanskrit), but it is possible that some small subset of the Mitanni population did speak this language at least for a time.</p>
</div>



<div>
<p>A text found in the Hittite archives at the capital city of Hattusha was authored by Kikkuli, “master horse trainer of the land of Mitanni,” and contains instructions for getting chariot horses into good condition.&nbsp; The Mitanni were known as expert horse trainers.&nbsp; Horses were introduced to the Near East at the end of the Middle Bronze Age and chariot warfare became the norm during the Late Bronze Age.&nbsp; While the text is a Hittite translation from a Hurrian original, the word “assussanni” is used for “horse master”&nbsp; This is nearly identical to Sanskrit “asva-sana” meaning “horse-master”.</p>
</div>



<div>
<div>
<p><strong>Excavating the Mitanni</strong></p>



<p>One of the first Mitanni sites to be excavated was ancient Nuzi, east of the Tigris River.&nbsp; As a result, the decorative pottery discovered there was named Nuzi Ware.&nbsp; Nuzi Ware is the pottery of the Mitanni elite and can be used by archaeologists to track the expansion on the Mitanni Kingdom. From Nuzi in the east to Alalakh in the west, Nuzi Ware is found over an area of about 700 km. Nuzi Ware developed from the Middle Bronze “Khabur Ware” of the Jezireh region.&nbsp; It is wheel-made of pale cream-colored clay and decorated with broad black painted bands.&nbsp; On those bands are painted lively designs in white. Mostly the motifs are geometric or the classic Mesopotamian daisy, but in the west at Alalakh, birds and plants are integrated into the design.&nbsp; The site of Nuzi contained an elaborate palace for a Mitanni governor who oversaw the local Assyrian territory.</p>
</div>
</div>







<div>
<div>
<p>The Mitanni period is also excavated at the vassal city of Alalakh on the Orontes where the extraordinary “Biography of Idrimi” details the relationship between the Amorite royal family of Aleppo and their Mitanni overlords. Census tablets from Alalakh’s Period 4 reveal that Hurrian-named Mitanni social classes had been implemented locally in the Amorite population, dividing the population into royals, nobles, elite craftspeople, free peasants, the poor (serfs?), and enslaved peoples. </p>



<p>Hurrian names also appear in Alalakh texts already by the end of the Middle Bronze Age. My results from the pottery study support the idea that the spread of the Hurrian ethnic group into Amorite kingdoms like Yamkhad and Alalakh preceded the expansion of Mitanni political control by at least a century. Beginning at the start of the Late Bronze Age (ca. 1600 BCE), there is an influx of Khabur-region pottery forms into the local Alalakh ceramic corpus.&nbsp; These are ordinary forms such as cylindrical cups and v-shaped plates that would have been used in everyday dining.&nbsp; Their manufacture at Alalakh strongly suggests population flow and intensive cultural interaction from the Khabur region at that time.</p>
</div>




</div>



<div>
<p>Egyptian and Hittite texts such as letters and treaties document the Late Bronze Age international political history of Mitanni. We have very little written information from within the Mitanni Kingdom itself. The Mitanni remember their first king as Kirta, but no contemporary references to Kirta have yet been found.&nbsp; The Mitanni relationship with Egypt started out with hostilities.&nbsp; A campaign by the Pharaoh Tuthmosis I reached Syria and the territory of the Mitanni Kingdom early in the 18<sup>th</sup> Dynasty.&nbsp; The Mitanni King Barattarna is most likely the ruler who confronted an invasion by Tuthmosis III.&nbsp; The next king, Shaushtatar, conquered Assyria and made it a vassal state.&nbsp; Conflict in Syria between Egypt and Mitanni continued for several generations until a peace treaty was concluded between Amenhotep III and King Shuttarna II, putting the border between these growing empires near Qatna and Kadesh, the modern border between Syria and Lebanon. Daughters of several subsequent kings of Mitanni were sent to Egypt as brides for the Pharaohs.</p>
</div>



<div>
<div>
<p><strong>The Rise and Fall of the Mitanni Kingdom </strong></p>



<p>The Mitanni Kingdom reached its greatest size in the 15<sup>th</sup> century, incorporating all of western Syria and parts of southeastern Anatolia.&nbsp; The southeast border of Mitanni was negotiated with the Kassite dynasty at Babylon and the southwest border with Egypt.&nbsp; This stable triumvirate of empires might have endured longer had it not been for the pressure of the growing Hittite Kingdom to the north and the aspirations of the Assyrians to the east.&nbsp; The Assyrians were under Mitanni domination but clearly preferred not to be.&nbsp; When a dynastic war for the Mitanni throne broke out in the 1360’s BCE, one faction asked the Assyrians for support while the other faction went to the Hittites. This brought both Hittite and Assyrian armies into the Mitanni heartland, weakening it significantly</p>
</div>
</div>



<div>




<div>
<div><figure><img loading="lazy" data-attachment-id="2173" data-permalink="https://peoplingthepast.com/royal_seal_of_scc8causcc8ctatar_of_mitanni-svg_/" data-orig-file="https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png" data-orig-size="1280,853" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_" data-image-description="" data-medium-file="https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png?w=300" data-large-file="https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png?w=750" src="https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png?w=1024" alt="Seal of King Shaushtatar" width="435" height="289" srcset="https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png?w=435 435w, https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png?w=867 867w, https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png?w=150 150w, https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png?w=300 300w, https://peoplingthepastcom.files.wordpress.com/2021/02/royal_seal_of_scc8causcc8ctatar_of_mitanni.svg_.png?w=768 768w" sizes="(max-width: 435px) 100vw, 435px"><figcaption><span>Seal of King Shaushtatar<br>Wikimedia Commons By Snubcube at English Wikipedia, public domain because copies of two dimensional works can’t be copyrighted – Originally from en.wikipedia; description page is/was here[1]., Public Domain,&nbsp;<a rel="noreferrer noopener" href="https://commons.wikimedia.org/w/index.php?curid=17230231" target="_blank">https://commons.wikimedia.org/w/index.php?curid=17230231</a></span></figcaption></figure></div>




</div>
</div>



<div>
<p>The Hittite Great King Suppiluliuma concluded a treaty with King Shattiwaza ca. 1350 BCE that ceded all Mitanni lands west of the Euphrates to the Hittites.&nbsp; This included Alalakh, Aleppo, Niya, Nuhasse, and others. The loss was costly for Mitanni.&nbsp; The Assyrians then began a series of rebellions that led to the complete takeover of Mitanni under Assyrian King Adad-Nirari I by 1295 BCE. After that, Mitanni existed only as a state within the growing Assyrian Empire. Archaeological evidence at sites in the Mitanni heartland show destruction layers and reconstruction in the Assyrian style.</p>
</div>







<div>
<div>
<p><strong>Mitanni in the News</strong></p>



<p>Recently discovered site at Kemune on the Tigris contains a Mitanni palace and could yield valuable information about Mitanni culture and administration.</p>



<p><a href="https://www.independent.co.uk/news/world/middle-east/ancient-palace-iraq-mosul-dam-tigris-kemune-mitanni-empire-a8979571.html" rel="nofollow">https://www.independent.co.uk/news/world/middle-east/ancient-palace-iraq-mosul-dam-tigris-kemune-mitanni-empire-a8979571.html</a></p>



<p><strong>References</strong></p>



<p>Novák, Mirko, (2007). “Mittani Empire and the Question of Absolute Chronology: Some Archaeological Considerations.” In: Manfred Bietak/Ernst Czerny (eds.): “The Synchronisation of Civilisations in the Eastern Mediterranean in the Second Millennium BC III”; pp.&nbsp;389–401, Österreichische Akademie der Wissenschaften Denkschrift Band XXXVII; Wien.</p>



<p>Von Dassow, Eva, (2008) State and Society in the Late Bronze Age—Alalah under the Mittani Empire. Studies on the Civilization and Culture of Nuzi and the Hurrians 17. Eisenbrauns.</p>



<p>Novák, Mirko, (2013). “Upper Mesopotamia in the Mittani Period”, in Archéologie et Histoire de la Syrie I, Harrassowitz Verlag, Wiesbaden.</p>



<p>De Martino, Stefano, (2014). “The Mittani State: The Formation of the Kingdom of Mittani”, in Constituent, Confederate, and Conquered Space in Upper Mesopotamia: The Emergence of the Mittani State, De Gruyter, Berlin, Boston.</p>



<p>De Martino, Stefano, (2018). “Political and Cultural Relations between the Kingdom of Mittani and its Subordinated Polities in Syria and Southeast Anatolia”, in Changing Faces of Kingship in Syria-Palestine 1500-500 BCE, Alter Orient und Testament 459, Ugarit Verlag.</p>
</div>
</div>







<div>
<div>
<div><figure><img data-attachment-id="2178" data-permalink="https://peoplingthepast.com/meonbaulksm-2/" data-orig-file="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg" data-orig-size="750,557" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="meonbaulksm" data-image-description="" data-medium-file="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=300" data-large-file="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=750" src="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=750" alt="The Author in the Level IV Palace of Alalakh" srcset="https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg 750w, https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=150 150w, https://peoplingthepastcom.files.wordpress.com/2021/02/meonbaulksm.jpg?w=300 300w" sizes="(max-width: 750px) 100vw, 750px"><figcaption><span>The Author in the Level IV Palace of Alalakh</span></figcaption></figure></div>




</div>



<p><a rel="noreferrer noopener" href="https://www.purchase.edu/live/profiles/536-mara-t-horowitz" target="_blank">Dr. Horowitz</a>&nbsp;is a Lecturer in History at Purchase College and an anthropological archaeologist teaching worldwide ancient history and archaeology. With a professional …</p></div></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://peoplingthepast.com/2021/02/26/blog-post-16-forgotten-kingdom-the-mitanni-with-mara-horowitz/">https://peoplingthepast.com/2021/02/26/blog-post-16-forgotten-kingdom-the-mitanni-with-mara-horowitz/</a></em></p>]]>
            </description>
            <link>https://peoplingthepast.com/2021/02/26/blog-post-16-forgotten-kingdom-the-mitanni-with-mara-horowitz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279603</guid>
            <pubDate>Fri, 26 Feb 2021 20:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Potato Park of Peru]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26279496">thread link</a>) | @DanBC
<br/>
February 26, 2021 | https://www.boell.de/en/2016/01/25/potato-park-peru | <a href="https://web.archive.org/web/*/https://www.boell.de/en/2016/01/25/potato-park-peru">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          
            <p>Up to 4.000 potato varieties are growing in Peru in a high-altitude Sacred Valley of the Incas. Six Quechua communities have been able to maintain the integrity of their biocultural traditions and fragile ecosystem. <strong><span lang="DE" xml:lang="DE"><span>➢ </span></span>Read more in our <a href="https://www.boell.de/en/dossier-patterns-commoning">online dossier "Patterns of Commoning"</a> or order <a href="https://www.boell.de/en/2015/11/04/wealth-commons-world-beyond-market-state">the book</a>!&nbsp;</strong></p>
      
        </div><div data-history-node-id="59725" role="article" about="/en/2016/01/25/potato-park-peru" typeof="schema:Article">
        
            <div property="schema:text"><p>Drive an hour northeast from Cusco, Peru, and you will encounter some beauti­ful high mountain lakes, historic Inca ruins, and the richest diversity of potatoes on the planet. Approximately 2,300 of the 4,000 known potato varieties in the world are grown here, making it one of the most biodiverse regions on the planet. The 7,000 Quechua people who live on this high-altitude Sacred Valley of the Incas have, with their ancestors, cultivated and improved Andean potatoes for seven millennia. That impressive record stems from a holistic way of life that blends deep spiritual traditions and cultural values with cultivation techniques, barter and exchange practices and ecological stewardship.</p>

<p>Potatoes are, of course, a central element of Quechua culture. When a reporter from <em>Gourmet </em>magazine visited the region, she was amazed to discover that “each potato, it seemed, had its own special or ceremonial use: There were potatoes to eat at baptisms; potatoes, like the bride potato, for weddings; and others for funerals. Potatoes like the red <em>moro boli </em>were high in antioxidants, while potatoes such as the <em>ttalaco </em>– a long, banana-shaped tuber – must be either soaked and steamed or made into a potato alcohol.”</p>
<p>Some potatoes must be grown on steep slopes above 13,000 feet. Some can be grown nearly anywhere. It is not uncommon for a single farmer’s field to produce hundreds of different varieties, many of them quite rare.</p>
<p>The six Quechua communities see themselves as living in reciprocal rela­tionship with the land, each other and the spirit world. The approach has been called <em>ayllu </em>– a political and socioeconomic system in which “individuals with the same interests and objectives [are] linked through shared norms and prin­ciples with respect to humans, animals, rocks, spirits, mountains, lakes, rivers, pastures, food crops, wildlife, etc.,” write Alejandro Argumedo and Bernard Yun Loong Wong (Argumedo &amp; Loong Wong 2010; Argumedo 2008. These monographs are the source for many facts in this essay). People strive for a balance between the <em>ayllu </em>of the <em>Runas </em>(humans and their domesticated crops and animals), the <em>Sallaka </em>(wild plants and creatures) and the Auki <em>Ayllu </em>(sacred beings, including mountain protector spirits).</p>
<p>In this cosmovision, the Earth is seen as giving potatoes, other crops, animals and the living landscape to the people – gifts that must be reciprocated through the giving of <em>pagos</em>, or offerings, in return. The spiritual engagement with <em>pachamama, </em>or Mother Earth, is not incidental, but a key factor in the Quechua’s deep respect for the earth’s limits, generativity and agrobiodiversity. “The main objective of the <em>ayllu</em>,” Argumedo and Loong Wong explain, “is attainment of well-being, which in Quechua societies is defined as <em>Sumak kawsay</em>.” The term refers to living a harmonious and healthy relationship with <em>pachamama</em>.</p>
<p>The point of agriculture in Quechua societies is not to raise maximum crop yields for market sale and profit. It is to faithfully implement the principles associated with the <em>ayllu</em>, which lies at the core of the Quechua’s stable, regen­erative agroecological practices that have evolved within the Andean landscape – a region that has a variety of different “vertical” microclimates at different altitudes, often at short distances from each other. Thus the altiplano region may grow potatoes and quinoa, notes Argumedo, while fields in lower valleys may grow maize, and higher pastures may be used to raise llamas (Argumedo &amp; Loong Wong 2010).</p>
<p>In recent decades, multinational biotech and agricultural corporations have increasingly sought to appropriate the fruits of such distinctive ecosystems and convert them into market commodities. They often buy up or evict traditional communities, dismantle traditional agriculture and claim patents in seeds, genes and other organisms. Regions with rich biodiversity such as Peru are a prime hunting ground for such corporate predators, whose acts of biopiracy seek to privatize genetic and physical resources that have been managed as commons for generations.</p>
<p>To prevent such market enclosures of shared wealth, the indigenous peoples of the Cusco Valley joined with the nonprofit group ANDES<a id="ANDES in Spanish is an acronym" name="ANDES in Spanish is an acronym">[1]</a> in the 1990s to develop an ingenious legal innovation, the Indigenous Biocultural Heritage Area (IBCHA). The idea, launched in 2000, was to create a <em>sui generis</em><a id="sui generis" name="sui generis">[2]</a> legal regime to preserve and promote native potato varieties and protect the fragile ecosystem by recognizing the role of indigenous “biocultural heritage” practices (Argumedo 2008:49-57).</p>
<p>The communities established a protected agroecological region called the “Potato Park” – “Parque de la Papa” – to protect more than 12,000 hectares considered essential to the agrobiodiversity of the Pisaq region and conserve traditional culture, knowledge and livelihoods. The Potato Park is a community-led and rights-based approach to conservation that points toward a very different model of “development” than conventional market-based ones.<a id="See essay by Arturo" name="See essay by Arturo">[3]</a> The villages of the Potato Park all share authority in running it, with each one electing a chairperson to coordinate the work of the association. Special attention is paid to integrating traditional spiritual values and practices into the everyday operations and policies of the Potato Park.</p>
<p>Under the IBCHA system, communities that belong to the Potato Park have agreed to selectively share their “living library” of potato genetic knowledge with scientists. In a special agreement with the International Potato Center (CIP) – a nonprofit food security organization that works with the global research partnership CGIAR – the Potato Park has shared more than 200 of its 900 native potato varieties with scientists, and is facilitating experiments to cultivate new (non-GMO) potato varieties that can resist climate change. They also have a special interest in “repatriating” potato varieties that were lost when modern, commercial farming methods were introduced. The Potato Park refuses to allow the patenting of any genetic knowledge, however, believing that private property rights are incompatible with the sacred and collective status of the potatoes. The agreement is widely seen as a model that other agroecological cultures could emulate. It both recognizes the sanctity of community control over the potatoes while allowing modern scientific study and certain forms of communal business activities.</p>
<p>Thus, besides preserving Quechua cultures and assisting scientific in­quiry, the Potato Park is hosting socially and ecologically sensitive forms of development such as agroecotourism, “nutraceuticals,” (dietary and nutritional products) and pharmaceuticals. The Potato Park has a processing center for natural medicines and soaps, a network of local pharmacies and a video com­munications center. It has a formal registry of the Park’s biological diversity and uses “geographical indicators” (legal rights for place-based products) and trademarks to protect its stewardship authority over local genetic diversity (Argumedo and Pimbert 2005:11).</p>
<p>Women play a key role in many of the economic activities of the Association of Communities of the Potato Park (the formal name of the project). There is, for example, the Sipaswarmi Medicinal Plants Women’s Collective, which sells natural medicine and soaps, and the Tijillay T’ika Women’s Audio-Visual Collective, a women’s co-operative that makes videos in the native language about local resources.</p>
<p>Although the Potato Park does not have state recognition within either Peruvian national law or the International Union for the Conservation of Nature (IUCN), that does not mean the association is without legal protection. The IBCHA agreement is legally compatible with existing systems of national and international law, and is seen as an inspiration for similar projects along the Ruta Cóndor agrobiodiversity corridor in the Andes. Meanwhile, many Potato Park agreements and actions are legally enforceable in conventional ways, such as the scientific study agreement with CIP and the Potato Park database that can be used to thwart patent applications for indigenous medicinal plants and knowledge.</p>
<p>In any case, some of the most consequential forms of law are not formal and state-based, but customary and vernacular. It is in local villages that agro­ecological and biocultural practices are actually managed and enforced, in ways that official, state-based law could never do. The IBCHA agreement is really an attempt to bridge this divide – to use formal law to recognize distinctive, context-specific customary law so that intergenerational cultural knowledge and practices can be recognized as legally valid and practically effective.</p>
<p>In the end, the Quechua culture of commoning remains the stabilizing force. In the village of Chawaytire, there is an all-organic restaurant Papamanka run by a women’s association, which acts as a custodian of indigenous tradi­tions and recipes. Proud of its heritage, the restaurant shares its indigenous folkways without pandering to the tourist trade. When the <em>Gourmet </em>reporter asked a waiter to cut into one of the potatoes to see the color inside, she declined, explaining that cutting a potato without eating it is an insult to <em>pachamama</em>.</p>
<p>Such reverence, which may appear irrational to the modern mind, is a key reason why the Quechua have been able to maintain the integrity of their biocultural traditions and fragile ecosystem. The success of the Potato Park suggests that the “rationality” that needs greater questioning is the one that believes a bioculturally diverse ecosystem can be plundered for its cash …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.boell.de/en/2016/01/25/potato-park-peru">https://www.boell.de/en/2016/01/25/potato-park-peru</a></em></p>]]>
            </description>
            <link>https://www.boell.de/en/2016/01/25/potato-park-peru</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279496</guid>
            <pubDate>Fri, 26 Feb 2021 20:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Road to Common Lisp (2018)]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279468">thread link</a>) | @Tomte
<br/>
February 26, 2021 | https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/ | <a href="https://web.archive.org/web/*/https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-blog-entry"><article><p>Posted on August 27th, 2018.</p><p>I've gotten a bunch of emails asking for advice on how to learn Common Lisp in
the present day.  I decided to write down all the advice I've been giving
through email and social media posts in the hopes that someone might find it
useful.</p>

<p>One disclaimer up front: this is <em>a</em> road to Common Lisp, not <em>the</em> road to
Common Lisp.  It's what I followed (without some of the dead ends) and has
a <em>lot</em> of my personal opinions baked in, but it is by no means the only way to
learn the language.</p>

<p>This post has been translated into
<a href="https://gist.github.com/y2q-actionman/49d7587912b2786eb68643afde6ca192">Japanese</a>.
I can't vouch for the accuracy of any translations.</p>

<ol><li><a href="#s1-context">Context</a><ol><li><a href="#s2-history">History</a></li><li><a href="#s3-consequences">Consequences</a><ol><li><a href="#s4-escaping-the-hamster-wheel-of-backwards-incompatibility">Escaping the Hamster Wheel of Backwards Incompatibility</a></li><li><a href="#s5-practicality-begets-purity">Practicality Begets Purity</a></li><li><a href="#s6-extensibility">Extensibility</a></li><li><a href="#s7-power">Power</a></li><li><a href="#s8-ugliness">Ugliness</a></li></ol></li></ol></li><li><a href="#s9-a-road-to-learning-common-lisp">A Road to Learning Common Lisp</a><ol><li><a href="#s10-get-a-lisp">Get a Lisp</a></li><li><a href="#s11-pick-an-editor">Pick an Editor</a></li><li><a href="#s12-hello-lisp">Hello, Lisp</a></li><li><a href="#s13-a-gentle-introduction">A Gentle Introduction</a></li><li><a href="#s14-getting-practical">Getting Practical</a></li><li><a href="#s15-make-something">Make Something</a></li><li><a href="#s16-lisp-as-a-system">Lisp as a System</a></li><li><a href="#s17-learning-paradigms">Learning Paradigms</a></li><li><a href="#s18-switch-things-up">Switch Things Up</a></li><li><a href="#s19-recipes-for-success">Recipes for Success</a></li><li><a href="#s20-final-patterns">Final Patterns</a></li></ol></li><li><a href="#s21-where-to-go-from-here">Where to Go From Here</a><ol><li><a href="#s22-macros">Macros</a></li><li><a href="#s23-object-oriented-programming-with-clos">Object-Oriented Programming with CLOS</a></li><li><a href="#s24-low-level-programming">Low-Level Programming</a></li><li><a href="#s25-web-development">Web Development</a></li><li><a href="#s26-game-development">Game Development</a></li><li><a href="#s27-window-management">Window Management</a></li><li><a href="#s28-unit-testing">Unit Testing</a></li><li><a href="#s29-more-implementations">More Implementations</a></li></ol></li><li><a href="#s30-modern-common-lisp">Modern Common Lisp</a><ol><li><a href="#s31-structure">Structure</a><ol><li><a href="#s32-packages">Packages</a></li><li><a href="#s33-systems">Systems</a></li><li><a href="#s34-projects">Projects</a></li><li><a href="#s35-recap">Recap</a></li></ol></li><li><a href="#s36-common-libraries">Common Libraries</a><ol><li><a href="#s37-alexandria">Alexandria</a></li><li><a href="#s38-bordeaux-threads">Bordeaux Threads</a></li><li><a href="#s39-cffi">CFFI</a></li><li><a href="#s40-cl-ppcre">CL-PPCRE</a></li><li><a href="#s41-drakma">Drakma</a></li><li><a href="#s42-iterate">Iterate</a></li><li><a href="#s43-local-time">local-time</a></li><li><a href="#s44-lparallel">lparallel</a></li><li><a href="#s45-named-readtables">Named Readtables</a></li><li><a href="#s46-roswell">Roswell</a></li><li><a href="#s47-series">SERIES</a></li><li><a href="#s48-st-json">st-json</a></li><li><a href="#s49-usocket">usocket</a></li></ol></li></ol></li><li><a href="#s50-good-luck">Good Luck!</a></li></ol>

<h2 id="s1-context"><a href="#s1-context">Context</a></h2>

<p>I think it's important to have a sense of where Common Lisp came from and what
kind of a language it is before you start learning it.  There are some things
that will seem very strange if you're coming straight from modern languages,
but will make more sense if you've got a bit of background context.</p>

<h3 id="s2-history"><a href="#s2-history">History</a></h3>

<p>Common Lisp has a long, deep history.  I'm not going to try to cover it all here
— if you're interested you should check out some of the following (in roughly
increasing order of detail):</p>

<ul>
<li>Wikipedia's <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)#History">History of Lisp</a> and <a href="https://en.wikipedia.org/wiki/Common_Lisp#History">History of Common Lisp</a>.</li>
<li>The <a href="http://www.gigamonkeys.com/book/introduction-why-lisp.html#where-it-began">Where it Began section in Practical Common Lisp</a>.</li>
<li>The <a href="https://www.cs.cmu.edu/Groups//AI/lang/lisp/faq/lisp_2.faq">History: Where did Lisp come from?</a> section of the comp.lang.lisp FAQ.</li>
<li><a href="http://www.nhplace.com/kent/Papers/cl-untold-story.html">Common Lisp: the Untold Story</a> by Kent Pitman.</li>
<li><a href="https://www.dreamsongs.com/Files/HOPL2-Uncut.pdf">The Evolution of Lisp</a> by Guy Steele and Richard Gabriel.</li>
</ul>

<p>I realize you probably won't want to read all of the links above immediately, so
here's a whirlwind tour of sixty years of Lisp.</p>

<p>Lisp began in the late 1950's.  It was invented by John McCarthy at MIT.</p>

<p>Over the next twenty or so years various versions and dialects of Lisp grew and
flourished.  Some of the more notable dialects were Maclisp, BBN Lisp/Interlisp,
Franz Lisp, Spice Lisp, and Lisp Machine Lisp.  There were others too.  The
point is that there were a <em>lot</em> of different implementations, all growing,
changing, and trying out different things.</p>

<p>(Scheme also originated in this time frame, but took a very different route and
diverged from the path we're looking at.  I won't cover Scheme in this post.)</p>

<p>In the early 1980s people decided that having a whole slew of
mutually-incompatible dialects of Lisp might be not be ideal.  An effort was
made to take these different languages that had grown organically and produce
one common language that would satisfy the needs of everyone (or at least
a reasonable subset of "everyone").  In 1984 the first edition of Guy Steele's
<a href="https://www.cs.cmu.edu/Groups/AI/html/cltl/cltl2.html">Common Lisp: the Language</a> was published.</p>

<p>If you do some math you'll see that at the time the book was published Lisp had
around twenty-five years of real-world use, experimentation, experience, and
history to draw upon.  Even so, the book alone didn't quite satisfy everyone and
in 1986 a committee (X3J13) was formed to produce an ANSI specification for
Common Lisp.</p>

<p>While the committee worked on the standardization process, in 1990 the second
edition of Common Lisp: the Language was published.  This was more
comprehensive and contained some of the things the committee was working on
(see the comp.lang.lisp FAQ linked above for more on this).  At this point the
Lisp family of languages had over thirty years of experience and history to
draw upon.  For comparison: Python (a "modern" language many people think of as
also being "kind of old") <a href="https://en.wikipedia.org/wiki/History_of_Python#Early_history">was released</a> for the first time the
following year.</p>

<p>In 1992 the X3J13 committee published the first draft of the new Common Lisp
ANSI standard for public review (see Pitman's paper).  The draft was approved in
1994 and the approved specification was finally published in 1995.  At this
point Lisp was over thirty-five years old.  The first version of Ruby <a href="https://en.wikipedia.org/wiki/Ruby_(programming_language)#First_publication">was
released</a> in December of that year.</p>

<p>That's the end of the history lesson.  There has not been another revision of
the ANSI specification of Common Lisp.  The version published in 1995 is the one
that is still used today — if you see something calling itself "an
implementation of Common Lisp" today, that is the specification it's referring
to.</p>

<h3 id="s3-consequences"><a href="#s3-consequences">Consequences</a></h3>

<p>I wanted to give you a quick overview of the history of Common Lisp because I
want you to know what you're getting yourself into.  I want you to realize that
Common Lisp is a stable, large, practical, extensible, ugly language.
Understanding these characteristics will make a lot of things make more sense
as you learn the language, and I want to talk a little bit more about each of
them before I start offering recommendations.</p>

<h4 id="s4-escaping-the-hamster-wheel-of-backwards-incompatibility"><a href="#s4-escaping-the-hamster-wheel-of-backwards-incompatibility">Escaping the Hamster Wheel of Backwards Incompatibility</a></h4>

<p>If you're coming from other languages, you're probably used to things breaking
when you "upgrade" your language implementation and/or libraries.  If you want
to run Ruby code you wrote ten years ago on the latest version of Ruby, it's
probably going to take some effort to update it.  My current day job is in Scala,
and if a library's last activity is more than 2 or 3 years old on Github I just
assume it won't work without a significant amount of screwing around on my part.
The Hamster Wheel of Backwards Incompatibility we deal with every day is a fact
of life in most modern languages, though some are certainly better than others.</p>

<p>If you learn Common Lisp, this is usually not the case.  In the next section of
this post I'll be recommending a book written in 1990.  You can run its code,
unchanged, in a Common Lisp implementation released last month.  After years of
jogging on the Hamster Wheel of Backwards Incompatibility I cannot tell you how
much of a <em>relief</em> it is to be able to write code and reasonably expect it to
still work in twenty years.</p>

<p>Of course, this is only the case for the language itself — if you depend on any
libraries there's always the chance they might break when you update them.  But
I've found the stability of the core language is contagious, and overall the
Common Lisp community seems fairly good about maintaining backwards
compatibility.</p>

<p>I'll be honest though: there are exceptions.  As you learn the language and
start using libraries you'll start noticing some library authors who don't
bother to document and preserve stable APIs for their libraries, and if
staying off the Hamster Wheel is important to you you'll learn to avoid relying
on code written by those people as much as possible.</p>

<h4 id="s5-practicality-begets-purity"><a href="#s5-practicality-begets-purity">Practicality Begets Purity</a></h4>

<p>Another thing to understand about Common Lisp is that it's a large, practical
language.  The second edition of Common Lisp: the Language (usually abbreviated
as "CLtL2" by Common Lisp programmers) is 971 pages long, not including the
preface, references, or index.  You can get a surprising amount done by writing
pure Common Lisp without much extra support.</p>

<p>When programming applications in Common Lisp people will often depend on
a small(ish) number of stable libraries, and library writers often try to
minimize dependencies by utilizing as much of the core language as possible.
I try to stick to fewer than ten or so dependencies for my applications and no
more than two or three for my libraries (preferably zero, if possible), but I'm
probably a bit more conservative than most folks.  I <em>really</em> don't like the
Hamster Wheel.</p>

<p>It's also worth noting that since Common Lisp has been around and stable for so
long, it has <em>libraries</em> older and more stable than many programming languages.
For example: Bordeaux Threads (the de-facto threading library for Common Lisp)
was first proposed in 2004 and released soon after (2006 at the latest but
possibly earlier, it's hard to tell because so many links are dead now), which
makes it about fourteen years old.  So yes, threading is handled by a library,
but I'm not worried about it breaking my code in the next decade or two.</p>

<p>My advice is this: as you learn Common Lisp and look for libraries, try to
suppress the voice in the back of your head that says "This project was last
updated six years ago?  That's probably abandoned and broken."  The stability of
Common Lisp means that sometimes libraries can just be <em>done</em>, not <em>abandoned</em>,
so don't dismiss them out of hand.</p>

<h4 id="s6-extensibility"><a href="#s6-extensibility">Extensibility</a></h4>

<p>Part of Common Lisp's practicality comes from its extensibility.  No one has
been clamoring for a new version of the specification that adds features
because Common Lisp's extensibility allows users to add new features to the
language as plain old libraries, without having to alter the core language.
Macros are what might come to mind when you hear "Lisp extensibility", and of
course that's part of it.  Macros allow users to write libraries that would
need to be core language features in other languages.</p>

<p>Common Lisp doesn't include string interpolation.  You want it?  No problem, you
don't have to wait for <a href="https://docs.scala-lang.org/overviews/core/string-interpolation.html">Scala
2.10</a> or
<a href="https://www.python.org/dev/peps/pep-0498/">Python 3.6</a>, just <a href="https://edicl.github.io/cl-interpol/">use
a library</a>.</p>

<p>Want to try some nondeterministic programming without any boilerplate?  <a href="https://nikodemus.github.io/screamer/">Grab
a library</a>.</p>

<p>Pattern matching syntax can make for some really beautiful, readable code.
Common Lisp doesn't include it, but of course <a href="https://github.com/guicho271828/trivia/wiki/What-is-pattern-matching%3F-Benefits%3F">there's a library</a>.</p>

<p>Enjoying algebraic data types in Haskell or Scala?  Here's your
<a href="https://github.com/tarballs-are-good/cl-algebraic-data-type">library</a>.</p>

<p>All of these libraries rely on macros to make using them feel seamless.  Of
course you could <em>do</em> all of that without macros, but you've have to add a layer
of boilerplate to manage evaluation.  This:</p>

<pre><code>(match foo
  '(list x y z) (lambda (x y z) (+ x y z))
  '(vector x y) (lambda …</code></pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/">https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/</a></em></p>]]>
            </description>
            <link>https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279468</guid>
            <pubDate>Fri, 26 Feb 2021 20:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Habits]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26279237">thread link</a>) | @nikivi
<br/>
February 26, 2021 | https://wiki.nikitavoloboev.xyz/focusing/habits | <a href="https://web.archive.org/web/*/https://wiki.nikitavoloboev.xyz/focusing/habits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="15c23ea58d804502a087f779240c2e80" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="25e9e08c960447ebb6236c20d576cab7"><span><span data-key="c44c73a63c83434c9f6e50823c0f8bfb"><span data-offset-key="c44c73a63c83434c9f6e50823c0f8bfb:0">I use </span></span><a href="https://streaksapp.com/" target="_blank" rel="noopener noreferrer" data-key="3d41445e35984907a63c4612c6e5a353"><span data-key="8382618f35384a28bd7beeca3eaefc43"><span data-offset-key="8382618f35384a28bd7beeca3eaefc43:0">Streaks</span></span></a><span data-key="a53aa99192444164b02d465ab9a4d02d"><span data-offset-key="a53aa99192444164b02d465ab9a4d02d:0"> iOS app to ensure I complete my 6 daily habits I try to follow to live a </span></span><a data-key="57d2aceeddf24f52b39a542e2d2ef25e" href="https://wiki.nikitavoloboev.xyz/life/happiness"><span data-key="3d1b6e6e82e54bd4874c467fb467927b"><span data-offset-key="3d1b6e6e82e54bd4874c467fb467927b:0">happy life</span></span></a><span data-key="f7ef0a47fb2f4513b78693bf07719da8"><span data-offset-key="f7ef0a47fb2f4513b78693bf07719da8:0">. The habits are chosen with great care and are a subset of my life </span></span><a data-key="3a38c74a3f2d4ef6922f6f76fd218a53" href="https://wiki.nikitavoloboev.xyz/focusing/rules"><span data-key="a7f19230881d4218a7af18126b434c3c"><span data-offset-key="a7f19230881d4218a7af18126b434c3c:0">rules</span></span></a><span data-key="bfb58b13bf58458ba49370c8143bf29d"><span data-offset-key="bfb58b13bf58458ba49370c8143bf29d:0"> .</span></span></span></p><div data-slate-void="true" data-key="0c28dd25318b428a9229889f9605b4b4"><div><figure data-key="0c28dd25318b428a9229889f9605b4b4" contenteditable="false"><div><p><img tabindex="0" src="https://i.imgur.com/TGe6H5C.png" loading="lazy"></p></div></figure></div></div><p data-key="9c44749bb994452691ca1da7bfe535c3"><span><span data-key="1b8e9ed75a9940198d7d5b15da051921"><span data-offset-key="1b8e9ed75a9940198d7d5b15da051921:0">I get a notification every day at 21:00 on my phone to complete the habits.</span></span></span></p><p data-key="a51d2dbc64c24328a008f00008089aa8"><span><span data-key="93ff4c9adb444181b0531858b268d29a"><span data-offset-key="93ff4c9adb444181b0531858b268d29a:0"><code spellcheck="false" data-slate-leaf="true">Cardio / Weights</code></span><span data-offset-key="93ff4c9adb444181b0531858b268d29a:1"> autofilled through my health data. It includes workout minutes from running/cycling &amp; bodyweight/lifting workouts. Bodyweight/lifting is tracked with </span></span><a href="https://strong.app/" target="_blank" rel="noopener noreferrer" data-key="b5e3dcf6f9ef45328ee4a4882ada5623"><span data-key="0b2b33f9d1994386aa5ca51463926a2f"><span data-offset-key="0b2b33f9d1994386aa5ca51463926a2f:0">Strong</span></span></a><span data-key="79d62a32818347a39e1689ad2f1a56a8"><span data-offset-key="79d62a32818347a39e1689ad2f1a56a8:0">, </span></span><a href="https://streaksworkout.com/" target="_blank" rel="noopener noreferrer" data-key="ebefa9cc482742b59c7ddfba71117fc3"><span data-key="baf5be855417492ca8c11d3f5b87ceae"><span data-offset-key="baf5be855417492ca8c11d3f5b87ceae:0">Streaks Workout</span></span></a><span data-key="9583d9968a844e539ba6c464b38da40e"><span data-offset-key="9583d9968a844e539ba6c464b38da40e:0">, </span></span><a href="https://www.fitbod.me/" target="_blank" rel="noopener noreferrer" data-key="5444697fd9c54880808c84b8cdf30e5c"><span data-key="c24994a5c82248519512241107a6102a"><span data-offset-key="c24994a5c82248519512241107a6102a:0">Fitbod</span></span></a><span data-key="1b0a323a900946f8b7b85ce4ab6dc3f7"><span data-offset-key="1b0a323a900946f8b7b85ce4ab6dc3f7:0"> or </span></span><a href="https://www.downdogapp.com/" target="_blank" rel="noopener noreferrer" data-key="2dc9ea2adabb488e882c8b406e7b01a6"><span data-key="1f763d259e894a97b07152fcd8e45ef0"><span data-offset-key="1f763d259e894a97b07152fcd8e45ef0:0">Down Dog</span></span></a><span data-key="ee359f13b4bd462389c50d156185acb5"><span data-offset-key="ee359f13b4bd462389c50d156185acb5:0"> apps.</span></span></span></p><p data-key="c03668fc426f4aaa8a90714e1923ca66"><span><span data-key="b94efea5e0584f41833cf014e15335b9"><span data-offset-key="b94efea5e0584f41833cf014e15335b9:0"><code spellcheck="false" data-slate-leaf="true">Activity rings</code></span><span data-offset-key="b94efea5e0584f41833cf014e15335b9:1"> autofilled through my health data and is marked as done when all the ring goals are complete. My current calorie goal is ~ 700 calories with fixed 50 min workout &amp; 12H standing goals.</span></span></span></p><p data-key="1e602d2190764994981b2de6eb018e2e"><span><span data-key="85372ba9980042efb85228154251117a"><span data-offset-key="85372ba9980042efb85228154251117a:0"><code spellcheck="false" data-slate-leaf="true">Healthy | Tea | Clean Skin</code></span><span data-offset-key="85372ba9980042efb85228154251117a:1"> marked as done when I drank only water &amp; tea. Limited coffee if any (get focus crushes). And ate only/primarily </span></span><a data-key="bf25238f5e1940759b27bb6fe49ed35f" href="https://wiki.nikitavoloboev.xyz/health/nutrition/foods"><span data-key="f46fba09537d41628f14788946f04450"><span data-offset-key="f46fba09537d41628f14788946f04450:0">nutritious whole foods (nuts/veggies/fruits)</span></span></a><span data-key="541f025741394cd9a39f454239ea9976"><span data-offset-key="541f025741394cd9a39f454239ea9976:0"> with focus on completing my </span></span><a data-key="1f5b4e73db5b4e0db5f942068e261360" href="https://wiki.nikitavoloboev.xyz/health/nutrition"><span data-key="622e269ca2d24839965a4a5831519fa3"><span data-offset-key="622e269ca2d24839965a4a5831519fa3:0">micro &amp; macro nutrient goals</span></span></a><span data-key="d5f34cbbca384c8cb648dabfa10fd193"><span data-offset-key="d5f34cbbca384c8cb648dabfa10fd193:0">. I also </span></span><a data-key="534b41af3bca49359d5ade44e65d307b" href="https://wiki.nikitavoloboev.xyz/health/skin-care"><span data-key="c3dc3fddc9d144169e748e139c012055"><span data-offset-key="c3dc3fddc9d144169e748e139c012055:0">kept my skin clean</span></span></a><span data-key="ff336ee4f133452f96fdf1faae2c917b"><span data-offset-key="ff336ee4f133452f96fdf1faae2c917b:0"> and washed/smelled well.</span></span></span></p><p data-key="b1bb226496e4429eacf7d543430f7a05"><span><span data-key="db9236a07c7d4221b6b75b958876f213"><span data-offset-key="db9236a07c7d4221b6b75b958876f213:0"><code spellcheck="false" data-slate-leaf="true">Improve | Focus | Impactful</code></span><span data-offset-key="db9236a07c7d4221b6b75b958876f213:1"> marked as done when I was not distracted by anything during the day (no analytics, wasting time). I worked on my </span></span><a data-key="a5d15cb114904c69adf3288bca17155b" href="https://wiki.nikitavoloboev.xyz/focusing/goals"><span data-key="72d4c248263d4322befc95241885bd65"><span data-offset-key="72d4c248263d4322befc95241885bd65:0">goals</span></span></a><span data-key="45a78fa8c02247f2998ddc3918b7f5c7"><span data-offset-key="45a78fa8c02247f2998ddc3918b7f5c7:0"> &amp; used time wisely. I was calm, mindful and happy.</span></span></span></p><p data-key="2f3a280a17d641669c0782e9116dfe4e"><span><span data-key="4fa49a9d30aa4bca9fe4e0c2d674781b"><span data-offset-key="4fa49a9d30aa4bca9fe4e0c2d674781b:0"><code spellcheck="false" data-slate-leaf="true">Love | Create | Share</code></span><span data-offset-key="4fa49a9d30aa4bca9fe4e0c2d674781b:1"> marked as done when all/most of my </span></span><a data-key="3d70cbae3607496a9f8e49546ad1efbd" href="https://wiki.nikitavoloboev.xyz/business/startups/values"><span data-key="878b2ee754544bd38b45cd601fcf88cb"><span data-offset-key="878b2ee754544bd38b45cd601fcf88cb:0">values</span></span></a><span data-key="0a92175dcda4479fb0ba3aad9624101b"><span data-offset-key="0a92175dcda4479fb0ba3aad9624101b:0"> and </span></span><a data-key="c1670b0b81064696a42e69670450256d" href="https://wiki.nikitavoloboev.xyz/focusing/rules"><span data-key="cf6848db13de4e4284644028b38ce3a8"><span data-offset-key="cf6848db13de4e4284644028b38ce3a8:0">rules</span></span></a><span data-key="080e0e70a09946da89761a08b86908d3"><span data-offset-key="080e0e70a09946da89761a08b86908d3:0"> were held well. I showed love to people I care about. I was nice. I made new things and shared it.</span></span></span></p><p data-key="db6cdca6e48f4c47aad48417a76e50fc"><span><span data-key="e5a36a47c03640c48ec164672c3f2677"><span data-offset-key="e5a36a47c03640c48ec164672c3f2677:0"><code spellcheck="false" data-slate-leaf="true">Habits | Plan | Journal</code></span><span data-offset-key="e5a36a47c03640c48ec164672c3f2677:1"> marked as done when all the 6 habits here were complete. I made a plan for tomorrow and wrote things in my journal or somewhere. Writing helps me clear up my mind and clean up life and my thinking.</span></span></span></p><p data-key="2593adc7f8244724899ddea834ce6bdd"><span><span data-key="58f9532caa2941b48d54048eed758860"><span data-offset-key="58f9532caa2941b48d54048eed758860:0">I try learn new habits proactively by building systems and thought processes that lead me in </span></span><a data-key="e404d628e99c499dae6964d231f200eb" href="https://wiki.nikitavoloboev.xyz/focusing/goals"><span data-key="13f2f2bcdde2462b80a7dec7ba3faf0a"><span data-offset-key="13f2f2bcdde2462b80a7dec7ba3faf0a:0">directions</span></span></a><span data-key="4434f356669b41a7a55e36076db5cc5f"><span data-offset-key="4434f356669b41a7a55e36076db5cc5f:0"> I want to go. Everything is built around well defined </span></span><a data-key="8d6412e0b7cf47a99e37ca6565a64bd0" href="https://wiki.nikitavoloboev.xyz/focusing/rules"><span data-key="4300d07c10344749a2c9d47772a9bb46"><span data-offset-key="4300d07c10344749a2c9d47772a9bb46:0">rules</span></span></a><span data-key="58b70e2bc9e4406bb5c9cd7ac81db2e5"><span data-offset-key="58b70e2bc9e4406bb5c9cd7ac81db2e5:0"> &amp; </span></span><a data-key="b895df1ae8e542a2baa40d99dbbd0513" href="https://wiki.nikitavoloboev.xyz/focusing/processes"><span data-key="b378b2f3bed34779b0a1e6b582c73fa0"><span data-offset-key="b378b2f3bed34779b0a1e6b582c73fa0:0">processes</span></span></a><span data-key="e732e6af21bf47959cb50f05e3837fe3"><span data-offset-key="e732e6af21bf47959cb50f05e3837fe3:0">.</span></span></span></p><ul data-key="d39470d3d6ae406ca1eab1e94f48d883"><li><p data-key="3de8be5f982146809b1c43cd331b58d4"><span><span data-key="c6e5a27c98c54aafa75b3c8a13580257"><span data-offset-key="c6e5a27c98c54aafa75b3c8a13580257:0">I think learning how to break habits is actually a very important meta skill and can serve you in life almost better than anything else.</span></span></span></p></li><li></li></ul><ul data-key="9107e2bebaa946e3af569453d8766546"><li></li><li></li><li></li><li></li><li></li><li><p data-key="3a00f60a96614c7693aea9305d7c4ffb"><span><span data-key="c6522293f07e4ef68f2b20ca44565fa6"><span data-offset-key="c6522293f07e4ef68f2b20ca44565fa6:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://www.theproofwellness.com/" target="_blank" rel="noopener noreferrer" data-key="522f56a5a56a409fa432693223ad92f9"><span data-key="5baf55bec9af4aa3b2c09f3f8bdfde3e"><span data-offset-key="5baf55bec9af4aa3b2c09f3f8bdfde3e:0">The Proof</span></span></a><span data-key="e22d742416e44f57afbe922bad8af592"><span data-offset-key="e22d742416e44f57afbe922bad8af592:0"> - Wellness Advice from World-Class Founders.</span></span></span></p></li><li></li><li><div data-key="1da165606d004e61878087bb22725cc6"><p data-key="9ebd27eb82c84832b3f7af0c61d1755f"><span><span data-key="5890cd5c2fd74e48b3366a947a214296"><span data-offset-key="5890cd5c2fd74e48b3366a947a214296:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://jamesclear.com/atomic-habits" target="_blank" rel="noopener noreferrer" data-key="bdc860cab498467fb02bf23419e467dc"><span data-key="1da7da46f03c4578addeb236ec8a1188"><span data-offset-key="1da7da46f03c4578addeb236ec8a1188:0">Atomic Habits</span></span></a><span data-key="5bacb457c2ab4c45aaca4db919e4ecbd"><span data-offset-key="5bacb457c2ab4c45aaca4db919e4ecbd:0"> - Tiny Changes, Remarkable Results. (</span></span><a href="https://twitter.com/justinkan/status/1352040558198329344" target="_blank" rel="noopener noreferrer" data-key="2539e82fc9c04ea4a84adc2a79c066a3"><span data-key="78b1214ff4aa4e1f8ea494ba78a176be"><span data-offset-key="78b1214ff4aa4e1f8ea494ba78a176be:0">Summary</span></span></a><span data-key="1908c589bfa245538093dfd0dd247673"><span data-offset-key="1908c589bfa245538093dfd0dd247673:0">)</span></span></span></p></div></li></ul></div></div></div></div></div></div>]]>
            </description>
            <link>https://wiki.nikitavoloboev.xyz/focusing/habits</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279237</guid>
            <pubDate>Fri, 26 Feb 2021 20:04:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Streaming SQL: What is it, why is it useful?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26279109">thread link</a>) | @cptroot
<br/>
February 26, 2021 | https://materialize.com/streaming-sql-intro/ | <a href="https://web.archive.org/web/*/https://materialize.com/streaming-sql-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Summary</h3>
<p><strong>Streaming SQL</strong> is about taking the same declarative SQL used to write database queries, and instead <strong>running it on streams of fast-changing data</strong>.</p>
<p>This is useful because:</p>
<ol>
<li>Data is often more valuable when you can act on it quickly</li>
<li>The existing tools for deriving real-time insights from streams are too complex.</li>
</ol>
<p>The “declarative” nature of SQL plays an important role in addressing the second point because it allows the user to focus on <strong>WHAT</strong> they want, and lets the underlying engine worry about <strong>HOW</strong> it gets done.</p>
<p>In the real world, Streaming SQL is used to:</p>
<ul>
<li>Enable new internal and customer-facing insights, automation, and applications</li>
<li>Increase value of business intelligence data by providing a single up-to-date source of truth for key metrics</li>
<li>Simplify microservices by replacing code doing data coordination and transformation</li>
</ul>
<h2>What is streaming SQL?</h2>
<p>Let’s start by being specific about what we mean when we say <strong>streaming</strong> and <strong>SQL</strong>.</p>
<h3>Streaming (event streams)</h3>
<p>Streaming refers to message brokers like Kafka, Kinesis, or Pulsar that handle data as a <strong>continuous stream of events or messages</strong>.</p>
<p>Event streams handle everything from transactions to user actions on sites or mobile apps, IoT sensor data, metrics from servers, even activity on traditional databases via <a href="https://materialize.com/change-data-capture-part-1/">change data capture</a>.</p>
<h3>SQL</h3>
<p>In the context of streams, SQL gives users a declarative language for:</p>
<ul>
<li>Creating <strong>views</strong> that join, filter, and group the raw data from the stream into more useful outputs (<a href="https://materialize.com/docs/sql/create-materialized-view/"><code>CREATE MATERIALIZED VIEW</code></a>)</li>
<li>Selecting data from sources and views (<a href="https://materialize.com/docs/sql/select/"><code>SELECT</code></a>)</li>
</ul>
<p>
<strong>NOTE:</strong> The CREATE MATERIALIZED VIEW command is the core concept in streaming SQL. It comes from <a href="https://www.postgresql.org/docs/9.3/sql-creatematerializedview.html">databases</a>, where it’s used to precompute the VIEW ahead of time in case the data changes. In streaming, the data is changing all the time, so queries are often more useful when maintained as materialized views.
</p>
<p>Other common SQL verbs like INSERT, UPDATE, and DELETE have roles in streaming SQL, but for this article we’ll focus on the core concepts of <strong>reading</strong> from streams, joining/filtering/transforming these streams, and making their outputs queryable or <a href="https://materialize.com/docs/sql/create-sink/">writing out to a new stream</a>.</p>
<h3>Differences between SQL on streams and databases</h3>
<p>A soon as you try using SQL on streams, a few key differences become apparent:</p>
<h4>Point-in-time vs continuous queries</h4>
<p>Running a SQL query on a traditional database returns a static set of results from a single point in time.</p>
<p>Take this query:</p>
<pre><code>SELECT SUM(amount) as total_amount FROM invoices;
</code></pre>
<p>When you run it, the database engine scans all invoices that existed <em>at the time of</em> the query and returns the sum of their amounts.</p>
<p>With streaming SQL, you <em>could</em> run the exact query above and get a point-in-time answer. But you’re querying a stream of fast-changing data, and as soon as you’ve gotten the results back they’re probably out-dated. In many cases a <strong>query that continually updates itself</strong> (a materialized view) is much more useful in a few ways we’ll describe below.</p>
<p>To turn the query above into a materialized view, you’d write:</p>
<pre><code>CREATE MATERIALIZED VIEW invoice_summary AS
  SELECT SUM(amount) as total_amount FROM invoices;
</code></pre>
<p>When you first create it, the SQL engine will process the entire history of invoice events it has access to up to the present, <strong><em>and then continue to update as new invoice events come through.</em></strong></p>
<h4>Response time vs lag</h4>
<p>Traditional databases have the concept of query response times: you run a query, some time elapses while the engine computes the results, and you get the response.</p>
<p>In streams the initial response time is only a factor when you first materialize a view. But there has to be some kind of time penalty in streaming results if we get a sudden surge of input events. That penalty is <strong>time lag</strong>: <em>by how much time is the output trailing the input?</em></p>
<p>Like response times in traditional databases, most end-users won’t need to think about time-lag in streaming systems, but knowing it exists helps to write and use streaming SQL in ways that avoid issues.</p>
<h4>Different actions create work for the underlying engine</h4>
<p>On the READ side, a traditional database engine idles until it receives a query, then it plans and optimizes it and gets to work providing the results. Once it responds with the results it idles again until it gets another query.  <strong>The sending of queries is what creates work for the engine.</strong></p>
<p>If you go back to the materialized view from above, <strong>new data from the stream creates the work</strong> for the engine. In Materialize, this approach is made possible by incremental computation: the work done to update the view is proportionate to the data coming in not the complexity of the query. We don’t need to do a full re-scan of data to update the results.</p>
<p>This paradigm shift makes streaming SQL best for queries that ask the same question over and over again (e.g. dashboards, reports, automation, most application code) and not ad-hoc queries.</p>
<h2>Why is streaming SQL useful?</h2>
<h3>1. Data is often most valuable when it first appears</h3>
<p>There are two reasons for this, one obvious and one less so:</p>
<ol>
<li><strong>Faster data = faster decisions</strong> — The stock market is a clear example of this idea taken to an extreme. <img src="https://user-images.githubusercontent.com/11527560/108846387-81f3df00-75ac-11eb-8caa-f293b48bf54c.png" data-src="https://user-images.githubusercontent.com/11527560/108846387-81f3df00-75ac-11eb-8caa-f293b48bf54c.png" alt="Chart showing higher value for newer data"> But it also applies to SaaS businesses, verticals like Marketplaces, Travel, Events that need to make fast decisions about rates and inventory, retail and logistics where faster decisions can reduce inefficiency, etc…
</li>
<li>
<p><strong>Data closer to its origin has fewer opportunities to be misinterpreted</strong> — Every step that data takes between where it’s created and where it’s used adds more potential for errors of the type where the end-user (person or machine) thinks the data represents something it does not. Time plays a role in this by forcing coordination around order of operations and alignment of work. In this case, switching to streaming data isn’t better because it’s faster, it’s better because you no longer have to think about timing.</p>
</li>
</ol>
<h3>2. SQL is a great means of deriving insights from streaming data</h3>
<p>Here is another example of a materialized view on streaming events:</p>
<pre><code>  CREATE MATERIALIZED VIEW experiments AS
   SELECT
     experiment_views.name,
     experiment_views.variant,
     COUNT(DISTINCT(experiment_views.user_id)) as unique_users,
     COUNT(DISTINCT(conversions.user_id)) as unique_conversions
   FROM experiment_views
   LEFT JOIN conversions ON
     conversions.user_id = experiment_views.user_id 
     AND conversions.created_at &gt; experiment_views.created_at
   GROUP BY experiment_views.name, experiment_views.variant;
</code></pre>
<ul>
<li><strong>The SQL is not unique to streaming</strong> — The meaning of data doesn’t change when it moves from a stream to a database, so the way we query it shouldn’t change either.</li>
<li><strong>The declarative nature of it increases productivity</strong> — There are little or no optimization decisions for the developer to make, especially in comparison to the same task in code.</li>
</ul>
<p>SQL has the added benefit of being a mature language built over three decades with an ecosystem of tooling and education around it. This means a much larger group of developers can work with streaming data and easily integrate it into the rest of their stack.</p>
<h2>Example use cases for Streaming SQL</h2>
<p>Today, anyone already working with a message broker like Kafka can start using streaming SQL without significant effort. In the future as CDC software matures, that criteria will expand to “anyone with a database.” Here are some examples of how streaming SQL is used:</p>
<h3>Business Intelligence and Analytics</h3>
<p>When deciding “what is the best way to empower our internal teams to make intelligent decisions from data”, Streaming SQL is one option to consider, with trade-offs that make it better for some cases than others.</p>
<p>In many cases, a materialized view on primary source data done in streaming SQL is a simpler <a href="https://nchammas.com/writing/data-pipeline-materialized-view">data pipeline</a>. In addition to the benefit of real-time data, businesses use this approach to side-step issues of:</p>
<ul>
<li>Coordination of time intervals and order of operations in batch processing</li>
<li>Extended outages caused by bugs that are not fixable or testable until next batch run</li>
<li>Slow-loading dashboards</li>
<li>Inconsistency issues caused by caching, denormalization</li>
</ul>
<p>See this walkthrough on <a href="https://materialize.com/docs/demos/business-intelligence/">streaming SQL to a business intelligence dashboard</a> with Materialize for an example.</p>
<h3>Microservices</h3>
<p>Streaming SQL is used to replace code doing complex data coordination and transformation in microservices.</p>
<p>An event stream like kafka is typically already a first-class citizen in microservice architectures. Engineers often find themselves building and maintaining complex applications consuming from kafka. For example: applications that read from an event log to produce insights and measurements on API usage for a SaaS application.</p>
<p>Any component of a microservice that looks like a query might be replaceable with streaming SQL.</p>
<p>This <a href="https://materialize.com/docs/demos/microservice/">Streaming SQL on Microservices example</a> walks through a working demo using Materialize to produce billing data based on product events from a stream.</p>
<h3>Real-Time Applications</h3>
<p>If the value of your application depends on your ability to deliver updates and data in real time, Streaming SQL may be an alternative to building an expensive or complex multi-component stack.</p>
<p>See <a href="https://materialize.com/a-simple-and-efficient-real-time-application-powered-by-materializes-tail-command/">a simple and efficient real-time application</a> post for an example.</p>
<h3>New capabilities</h3>
<ol>
<li><strong>User-facing real-time analytics</strong> – Previously, only tech behemoths like LinkedIn and Google had the scale and engineering teams to build user-facing real-time analytics (like LinkedIn’s “Who has viewed your profile” page or Google Analytics’ Real-time dashboard.) By lowering the complexity, streaming SQL opens magical real-time user analytics features up to more companies.</li>
<li><strong>Business Automation</strong> – Once you have streaming SQL powering real-time dashboards, a natural progression is to begin making automated decisions on the same data. (For example: If your e-commerce site gets a spike in traffic from a particular source, add a promotion to the homepage.)</li>
</ol>
<h2>Conclusion</h2>
<p>Materialize provides a streaming SQL implementation that’s unique in two important ways:</p>
<ol>
<li>In Materialize, you write queries in postgres-compatible SQL. <em>We think it’s worth going through the …</em></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://materialize.com/streaming-sql-intro/">https://materialize.com/streaming-sql-intro/</a></em></p>]]>
            </description>
            <link>https://materialize.com/streaming-sql-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26279109</guid>
            <pubDate>Fri, 26 Feb 2021 19:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securing services via explicit dataflow and trust boundaries (2007) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26278954">thread link</a>) | @freeqaz
<br/>
February 26, 2021 | http://cr.yp.to/qmail/qmailsec-20071101.pdf | <a href="https://web.archive.org/web/*/http://cr.yp.to/qmail/qmailsec-20071101.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://cr.yp.to/qmail/qmailsec-20071101.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26278954</guid>
            <pubDate>Fri, 26 Feb 2021 19:41:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FOXSCAPEuC]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26278327">thread link</a>) | @Lammy
<br/>
February 26, 2021 | http://mw.rat.bz/foxscapeuc/ | <a href="https://web.archive.org/web/*/http://mw.rat.bz/foxscapeuc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<hr size="4">
<br><center><img src="http://mw.rat.bz/foxscapeuc/FOXSCAPEuC%20Title.png" alt="FOXSCAPEuC Title"><p>

<img src="http://mw.rat.bz/foxscapeuc/foxscapeuc_screen_capture.png" alt="FOXSCAPEuC Cropped Screen Capture"></p><p>
Fig. 1 - FOXSCAPEuC Cropped Screen Capture
</p></center><!-- br -->
<hr size="4">

<center><h2>FOXSCAPEuC - FOXSCAPE theme for Firefox userChrome.css by Michael Walden with help from Aris</h2></center>

<center><h2>A full featured retro theme for Firefox that makes Firefox look like Netscape 4.x, Netscape 6+ "Classic" theme, Mozilla Suite M18+, SeaMonkey 1.x "Classic" theme and FOXSCAPE theme running on Windows.</h2></center>

<h2>Download</h2>
<center><p><b>NOTE: Since I only run Firefox release versions, it will take a little time for me to get a new version and try it out to find bugs in FOXSCAPEuC, it will then take a little more time to get a new FOXSCAPEuC uploaded here.  Please be patient.</b></p></center>
<center></center>
<center><b>Main new feature(s):                                                                                                </b></center>
<center><b>  - Search bar fixes for Firefox 72.0+                                                                              </b></center>
<center><b>Known issues:                                                                                                       </b></center>
<center><b>  - The downloads-button in the navigation bar Overflow Menu popup shows in only one icon state (no hover or active)</b></center>
<center><b>  - The new Firefox Account Button only shows in the small 16x16 pixel size                                         </b></center>
<center><b>  - Tab favicon jumps to the right momentarily just before page loading finishes only on certain web pages.         </b></center>
<center><b>    This only occurs when using the following five functions:                                                       </b></center>
<center><b>    tab_bar_tabs_without_a_favicon_skinned_-_style_1.css - tab_bar_tabs_without_a_favicon_skinned_-_style_5.css     </b></center>

<h2>Introduction</h2>
<p>At a time when all hope seems lost for Firefox having "Complete" (Heavyweight) themes, I have discovered that <b>almost</b> complete themes are again possible.  Thanks to the excellent work of Aris, creator of the <a href="https://bit.ly/2WC6wyQ"><!--http://Forums.mozillaZine.org/viewtopic.php?f=48&t=2827985-->now obsolete</a> (in the current Firefox) <a href="https://github.com/Aris-t2/ClassicThemeRestorer">Classic Theme Restorer</a> Firefox add-on, and creator of the newer <a href="https://github.com/Aris-t2/CustomCSSforFx">Custom CSS tweaks for Firefox Quantum</a> where he clearly demonstrates how to create almost complete themes by use of the Firefox userChrome.css file!  On finding this out I decided to see if I could make <a href="http://mw.rat.bz/foxscape">FOXSCAPE</a> work with the new Firefox.  I feel that I was able to achieve a pretty good result with the new FOXSCAPEuC (uC for userChrome.css).  Unfortunately, the changes in Firefox since the final release of FOXSCAPE 5.18 (2014-03-23) prevent me from making things look as close to the Netscape look as it used to look. Remember, something is better than nothing.  This is still a work in progress.  I will continue to see if I can improve things, time permitting.</p>

<h2>How to install FOXSCAPEuC in Firefox</h2>
Note: the following instructions assume you know basic computing skills such as how to open a folder, how to unzip a file, etc..  If you do not know these types of things, consult someone with more experience to help you.  It is not in the scope of these instructions to cover that stuff.<br>
<ol>
<li>In Firefox put "about:support" in the address bar (without the quote marks) and push the Enter or Return key.</li>
<li><b>On Windows:</b> To the right of "Profile Folder" click on [Open Folder]<br>
    <b>On Linux:</b> To the right of "Profile Directory" click on [Open Directory]</li>
<li>Now open an existing "chrome" folder or make a new one and open it.</li>
<li>Set your operating system to display files and file extensions which are hidden by default on Microsoft Windows and Apple macOS.<br>
   If you do not know how to do this, <a href="https://www.userchrome.org/how-create-userchrome-css.html">visit this web page and read section "(4)".</a></li>
<li>If a "userChrome.css" file exists, rename it to something else, such as "my_userChrome.css".</li>
<li>If a "userContent.css" file exists, rename it to something else, such as "my_userContent.css".</li>
<li>Download (see above) and unzip the "FOXSCAPEuC 20XX-XX-XX vX FxXXXX.zip" file into the chrome folder.</li>
<li>In Firefox put "about:config" in the address bar (without the quote marks) and push the Enter or Return key.</li>
<li>If you get a screen stating "This might void your warranty!", then click on the [ I accept the risk! ] button.</li>
<li>On the about:config page, put <b>toolkit.legacyUserProfileCustomizations.stylesheets</b> in the Search: field at the top of the page.</li>
<li>If the value column has <b>false</b> in it, double click false to make it show <b>true</b>. Otherwise, go to the next step.</li>
<li>Close the about:config page.</li>
<li>Restart Firefox by going to "about:profiles" and by clicking on the [Restart normally...] button.</li>
</ol>
<h2>User Interface Customization</h2>
<ol>
<li>Right click on the "Open menu" button, which now looks like the Netscape N logo, and choose Customize...</li>
<li>At the lower left place a check mark in the "[✓] Title Bar" (by clicking it) to make the Tab Bar have a Netscape like appearance.</li>
<li>At the lower left click on "Toolbars" and optionally enable "Menu Bar" or "Bookmarks Toolbar."</li>
<li>At the lower left click on "Themes" and choose "Default" or "Light".  "Dark" does not look good.  On Windows 7 (with Windows Classic Theme) Default looks the best.</li>
<li>At the lower left click on "Density" and choose "Compact", "Normal", or "Touch" whichever you prefer.  "Compact" has small button icons, "Normal" and "Touch" have larger button icons.</li>
<li>Now, drag and drop buttons from the customize page onto the toolbars, or vice versa (such as for the two Flexible Space rectangles), to produce a layout that you prefer.</li>
</ol>
I suggest the following buttons, in left to right order, to produce a Netscape like layout with all of the buttons that are skinned with the Netscape like bitmapped icons.<br>
<ul>
<li>Back</li>
<li>Forward</li>
<li>Reload / Stop</li>
<li>Home</li>
<li>Print</li>
<li>New Tab (From right end of tabs bar)</li>
<li>New Window</li>
<li>Full Screen</li>
<li>Zoom Controls (Zoom-out, Reset, Zoom-in)</li>
<li>Downloads</li>
<li>Bookmarks Menu</li>
<li>History</li>
<li>Edit Controls (Cut, Copy, Paste)</li>
</ul>
The following vector drawn buttons are all colorized with a color blue that matches nicely with the Netscape like icons listed above.  You can optionally place any of these buttons on the toolbars.<br>
<ul>
<li>Library</li>
<li>Sidebars</li>
<li>New Private Window</li>
<li>Open File</li>
<li>Save Page</li>
<li>Find</li>
<li>Email Link</li>
<li>Text Encoding</li>
<li>Synced Tabs</li>
<li>Add-ons</li>
<li>Options</li>
<li>Developer</li>
<li>WebIDE (Hidden by default. Press Ctrl+Shift+I to reveal)</li>
<li>Forget</li>
<li>Firefox Account</li>
</ul>
Once you have a layout that you are happy with, click the [Done] button in the lower right corner.<br>

<h2>userChrome.css and/or userContent.css Customization</h2>

Further customization can be acomplished by editing the "userChrome.css" and/or "userContent.css" files in your chrome folder using a text editor.  On Windows I recommend the <a href="https://notepad-plus-plus.org/">Notepad++ text editor</a>.<p>

If you intend to investigate the many functions available in the "userChrome.css" and/or "userContent.css" files, you may create a desktop shortcut (alias) to the chrome folder, or to those two .css files for easier access in the future.</p><p>

To enable a function of the theme in "userChrome.css" and/or "userContent.css", change the following example <b>disabled</b> function...</p><pre>/* @import "./foxscapeuc/sub/description_of_function_to_enable_or_disable.css"; /**/</pre>

...into an <b>enabled</b> function, by removing the "/*" from the left end, to produce the following:<br>

<pre>   @import "./foxscapeuc/sub/description_of_function_to_enable_or_disable.css"; /**/</pre>

The reverse also works: to disable an enabled function of the theme, add a "/*" to the left end of the function.<p>

Be sure to read the text above the functions in "userChrome.css" and/or "userContent.css" to follow the instructed rules, such as "Enable <b>one</b> of the following."</p><p>

After making changes to "userChrome.css" and/or "userContent.css", you need to restart Firefox for the changes to take effect.  Do so by going to "about:profiles" and click on [Restart normally...]</p><h2>Convenient Restarts</h2>

<p>For your convenience, if you intend to experiment with the "userChrome.css" and/or "userContent.css" files, you may want to create a bookmark to "about:profiles" (and name it "Restart") and place it on the bookmarks toolbar.  Doing so will enable you to restart Firefox in two clicks, first on the bookmark and second on the [Restart normally...] button.  To create a bookmark, open "about:profiles" and left mouse click + hold and drag the page proxy icon (located at the left end of the location bar) to a blank spot on the bookmarks toolbar and release the left mouse button.  You can optionally rename the "About Profiles" bookmark to "Restart" by right mouse clicking on the bookmark and left mouse click on Properties at the bottom of the popup menu.  Change the Name: to "Restart" and left click [Save] to save your change.</p>

<p>Alternatively, if you do not have the bookmarks toolbar visible, you can also pin a tab to "about:profiles".  Doing so will enable you to restart Firefox in two clicks, first on the pinned tab on the left end of the tab bar and second on the [Restart normally...] button.  To pin a tab, open "about:profiles" and right mouse click on the "About Profiles" tab and then left mouse click on "Pin Tab" on the popup menu to creat the pinned tab.</p>

<h2>Customization Backup Procedure</h2>

<p>Unfortunately, there is a problem with customizing using the "userChrome.css" and/or "userContent.css" files.  These files are supplied with each release of FOXSCAPEuC.  If you have performed some customization on these files, and then wish to update to a new version of FOXSCAPEuC, you will need to replace the old customized files with the new un-customized files from the updated FOXSCAPEuC.  The reason you need to use the new files is because there will generally be newly added functions that did not exist in the older version of these files.  This means that you will need to re-customize the new "userChrome.css" and/or "userContent.css" files to have the previously made changes in the old files.  Since there are over 100 functions to customize in these files, it will be difficult to remember all of the changes that you may have made to your previous setup.  To make this a less difficult situation, I recommend that you document in a separate "backup" text file all of the changes you make to the two files as you make each individual change.  The backup file should contain a list made up of a copy of each line that you enable or disable in the two files.  The process of reimplementing the customization changes involves searching for each line in the backup list in the un-customized new file and then make the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://mw.rat.bz/foxscapeuc/">http://mw.rat.bz/foxscapeuc/</a></em></p>]]>
            </description>
            <link>http://mw.rat.bz/foxscapeuc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26278327</guid>
            <pubDate>Fri, 26 Feb 2021 18:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Cybercafe to Rocketship: My First Month at Orbit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277988">thread link</a>) | @sorich87
<br/>
February 26, 2021 | https://orbit.love/blog/from-cybercafe-to-rocketship-my-first-month-at-orbit/ | <a href="https://web.archive.org/web/*/https://orbit.love/blog/from-cybercafe-to-rocketship-my-first-month-at-orbit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My journey at Orbit started with this funny tweet by Josh.</p><p>I wasn't looking for a new job but his tweet caught my attention.</p><p>The mission of Orbit, right there on the careers page, made me curious to learn more about the company. Building thriving communities and developer tools was very much aligned with my past career path and current interests. That ultimately led me to join the team.</p><h2>My background</h2><p>I started my career as a self-taught software developer who didn’t own a computer. I worked from a cybercafé in a small African country with a very bad internet connexion. I quickly gained plenty of technical experience and contributed to products used by millions of people across the world. I even wrote <a href="https://www.packtpub.com/product/learning-bootstrap/9781782161844">a technical book</a> and had <a href="https://www.flyerco.com/">a small startup exit</a>! I attribute a large part of that growth to being involved in gaming and developer communities where I made friends, met mentors, and found clients.</p><p>After about ten years of basically 100% online life, I spent the past five building up the tech community in my country of origin, Benin, by serving as vice-president and CTO of <a href="https://etrilabs.com/">the leading tech innovation hub</a>, and co-founding <a href="http://www.tekxl.com/">a small product studio</a> over there. It was awesome contributing to projects with real-world impact on tens of thousands of people. Over time, my involvement decreased as we were able to build a talented team that could continue moving the mission forward.</p><p>So, when COVID hit, I knew the next step of my professional career was due, and it was about the online-first life again. I spent the best part of 2020 helping <a href="https://irawotalents.com/">Irawo</a>, a community of more than 50.000 talents and creators in francophone Africa, launch new programs and develop a sustainable business model.</p><h2>Meeting Orbit</h2><p>When I saw Orbit's homepage and model, something clicked. The <a href="https://github.com/orbit-love/orbit-model">Orbit Model</a> was in line with my own experience of contributing and growing communities. I’d also long dreamed of building a CRM-like solution that’s centered around each customer’s experience as an individual. I think the Orbit Model captures the multi-dimensional aspect of how people interact in a community, or with organization products or services. It’s a refreshing break from the linear view of traditional sales and marketing funnels.</p><p>Needless to say, I was drawn to Orbit and decided to email the founders right away. I wasn’t looking for a full-time job, but they were looking for part-time consultants to help with integrations and other stuff.</p><p>Josh, the co-founder and CTO, replied a couple of days later, and, about a week after my email, we were on a call. The call was awesome! That’s when I knew I wanted to join the team instead of just contributing some integrations. Talking with Josh sold me on the vision. It also helped that the team was great at execution. They had made enormous progress in terms of traction and product development. And they were backed by some of the top VCs in Silicon Valley.</p><p>The opportunity to join this rocket ship about to take off was amazing. For me, this is the ideal time to join a startup in its growth trajectory, and I am very confident that Orbit is going to grow even faster and be successful. It was the best learning opportunity I could have at this step of my career.</p><h2>The Interviews</h2><p>After the call with Josh, he introduced me to Nicolas, who is a software engineer and the first non-founder team member. We scheduled a technical interview for the next day. It was not your typical algorithmic coding interview. It was a pair programming session where we worked together on actual production code to implement a new fun feature in the product. We had a great time together! Nicolas was happy to have another French-speaking programmer in the team so we spoke French. I learned a lot about the team culture, how technical decisions are made, etc. I could get a taste of what it would be like to work together.</p><p>After the interview with Nicolas, I went into my last interview with Patrick, 100% convinced Orbit was the next step in my journey. Patrick is the other co-founder and CEO of Orbit. He's a very high-energy guy. We talked about the company vision and the plans for the next months. I could feel his enthusiasm and how he was dedicated to reaching the goals. After our chat, he told me right away that I would receive an offer in the next few days. The offer came a couple of days later and, after a short negotiation, I signed it. It took less than a week from the first call to signing the offer, and I was starting the next Monday!</p><h2>The First Days</h2><p>Onboarding remote employees can be difficult but, for a young company, Orbit onboarding is pretty solid. A few days before I started, Josh had shared access to all the communication and collaboration tools: Miro, Slack, GitHub, Airtable, Trello, and more. I went through basically everything and learned so much about the company, what product and strategic decisions were made in the past, why they had been made, most major events, the company values, the processes, and many more key points.</p><p>Being an early riser, I was even able to submit a small pull request before anyone in the Paris or San Francisco timezone was up on the first day! I got a handful of pull requests merged in my first week overall. This is how fast a team member can onboard when there are great asynchronous communication processes in place. It was like someone had onboarded me on the basics before actually talking with anyone in person. The calls with team members on the next few days were mostly around getting to know each other and getting help on my tasks.</p><h2>The Hard Parts</h2><p>The technical aspects of my new role are going very smoothly, and I haven’t had any difficulties with them so far. The hard parts were mostly around some emotional aspects of stepping into new shoes. Working with Orbit is my first full-time role not being in a founder or executive position, so it came with its challenges. Around the middle of the month, I was hit by a bunch of insecurities and, for 2-3 days, I wasn’t as productive as I would have loved. Would I be able to adjust to a different culture? Would I be able to perform at my full potential? Would my integration into the team go smoothly? Would I be given the kind of responsibilities I’m looking for?</p><p>I think it’s normal to have such interrogations when joining a new role. They would differ from one person to another, but they are frequently addressed with good communication with other team members, and some amount of self-reflection. The team has been handling the communication aspect very well so far. I have 1:1s with Josh every two weeks where I’m able to openly discuss all I have in mind. It also helped that Josh, Nicolas, and I were able to meet in person once for lunch.</p><h2>Conclusion</h2><p>Overall, my first month at Orbit has been an awesome experience. The team is made of caring and driven people with great product and business chops. I learned a lot in just a few weeks and I look forward to learning, growing and contributing more over the next months.</p><p>We're looking for more awesome people to join the Orbit team! <a href="https://orbit.love/careers/">See our open positions.</a></p></div></div>]]>
            </description>
            <link>https://orbit.love/blog/from-cybercafe-to-rocketship-my-first-month-at-orbit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277988</guid>
            <pubDate>Fri, 26 Feb 2021 18:24:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Hummingbard – decentralized communities built on Matrix]]>
            </title>
            <description>
<![CDATA[
Score 308 | Comments 54 (<a href="https://news.ycombinator.com/item?id=26277602">thread link</a>) | @SubGenius
<br/>
February 26, 2021 | https://hummingbard.com/hummingbard/introducing-hummingbard | <a href="https://web.archive.org/web/*/https://hummingbard.com/hummingbard/introducing-hummingbard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>Hummingbard is an experiment in building communities on top of <a href="https://matrix.org/" rel="nofollow">Matrix</a>. Hummingbard has social elements like user profiles, posts, communities, sharing and so on. It is intended to be more than just a decentralized link aggregator or a microblogging platform.</p>

<h3>Spaces</h3>

<p>The main centre of interest in Hummingbard is a space, which is an ordinary <a href="https://github.com/matrix-org/matrix-doc/blob/kegan/spaces-summary/proposals/2946-spaces-summary.md" rel="nofollow">Matrix space</a>. A space is similar to a forum board, subreddit or an FB group. The posts in a space are ordinary Matrix events, with additional metadata for rendering social-like posts. Posts can include images, attachments and links. This should be extendable to add polls, reviews etc. in the future. Hummingbard posts can be blog posts too, like <em>this one youâ€™re reading right now</em>.</p>

<p>Spaces can be rendered in various ways, which makes it possible to use them as user profiles like <a href="https://hummingbard.com/@david" rel="nofollow">@david</a>, or communities like <a href="https://hummingbard.com/art" rel="nofollow">art</a>. Spaces can be arbitrarily nested, allowing sub-spaces like <a href="https://hummingbard.com/music/classical" rel="nofollow">music/classical</a> or <a href="https://hummingbard.com/music/jazz/fusion" rel="nofollow">music/jazz/fusion</a>. Spaces can also have sub-spaces that render as wiki pages like <a href="https://hummingbard.com/hummingbard/about" rel="nofollow">hummingbard/about</a>.</p>

<p>It is possible to have different types of spaces. A gallery type renders a space in Instagram-like fashion, like the <a href="https://hummingbard.com/pics" rel="nofollow">pics</a> space. Any type of space can be nested under any other type of space. This allows normal boards to have sub-spaces which are galleries, or vice versa. In the future, a space could be rendered to be a business page, and e-commerce page etc.</p>

<p>Hummingbard spaces are very limited in options right now, but basic info like title, description, header-image can be changed. Spaces support custom CSS too.</p>

<h3>Social</h3>

<p>Hummingbard has very basic social-like features. Users can follow other users and join spaces. A user feed shows posts chronologically. Posts can be shared from one user/community to another user/community. Posts can be replied to. Replies can be nested like in this <a href="https://hummingbard.com/test/$kXWe3pG7N53PIWl33KnW_zA0GYGTRDWy2d5jj6rE0G8" rel="nofollow">thread</a>.</p>

<h3>Federation</h3>

<p>Hummingbard works with federated Matrix servers too. Users can create Matrix accounts on remote servers, or log in with an existing account. Logging in with an existing account creates a user profile automatically, unless one already exists. Hummingbard spaces on federated servers work just the same as local spaces. Here are a few examples:</p>

<ul>
<li><p><a href="https://hummingbard.com/rhythm:matrix.org" rel="nofollow">rhythm:matrix.org</a></p></li>

<li><p><a href="https://hummingbard.com/food:tchncs.de" rel="nofollow">food:tchncs.de</a></p></li>

<li><p><a href="https://hummingbard.com/ask:matrix.org" rel="nofollow">ask:matrix.org</a></p></li>

<li><p><a href="https://hummingbard.com/@ahq:matrix.org" rel="nofollow">ahq:matrix.org</a></p></li>
</ul>

<p>Federated spaces can also have nested spaces like <a href="https://hummingbard.com/ebooks:matrix.org/fantasy" rel="nofollow">ebooks:matrix.org/fantasy</a> or pages <a href="https://hummingbard.com/rhythm:matrix.org/about" rel="nofollow">rhythm:matrix.org/about</a>.</p>

<p>In an ideal world, owners of Matrix servers would be hosting their own instance of Hummingbard, instead of going through one popular instance.</p>

<h3>Dendrite</h3>

<p>Hummingbard is dependent on <a href="https://github.com/hummingbard/dendrite/tree/thread_pagination" rel="nofollow">Dendrite</a>, the second-generation Matrix homeserver written in Go. Features like spaces and threading have only been implemented on Dendrite. Note that it is a forked repo with a temporary patch for paginating threads.</p>

<h3>Code</h3>

<p>Hummingbardâ€™s code will be available as soon as I am able to decide which license works best for us.</p>

<h3>Whatâ€™s Coming</h3>

<p>Hummingbard is very bare-bones at the moment. Iâ€™m actively working on the following:</p>

<ul>
<li><p>Private spaces</p></li>

<li><p>Power levels for admins/mods</p></li>

<li><p>Dark mode and various UI changes</p></li>
</ul>

<p>Aside from that, Hummingbard has a lot of bugs, and will likely crash randomly. If you do want to check out the site, either create a local Hummingbard account, or use an existing throwaway Matrix account. Iâ€™d advice against using your main Matrix account, as the authentication code may have bugs. Please try to avoid any rooms that are too large. My tiny VPS running dendrite will not be able to handle it.</p>

<h3>Contact/Feedback</h3>

<p>Weâ€™re using <a href="https://matrix.to/#/%23hummingbard:matrix.org" rel="nofollow">#hummingbard:matrix.org</a> as a meeting place to discuss Hummingbard development. You can also leave bug reports on a Hummingbard space itself - <a href="https://hummingbard.com/hummingbard/bugs" rel="nofollow">hummingbard/bugs</a></p>

<p>Lastly, if youâ€™d like to leave a reply on this blog post itself, you can log into Hummingbard with an existing Matrix account, join the <a href="https://hummingbard.com/hummingbard" rel="nofollow">hummingbard</a> space, and come back here to write your reply.</p>

<p>Many thanks.</p>

<p><strong>PS</strong>: If this post has a typo, I wonâ€™t be able to fix it because Hummingbard has not implemented editing posts yet.</p>

<p><strong>PPS</strong>: Thanks to <a href="https://hummingbard.com/@david" rel="nofollow">@david</a> for reviewing this post.</p>

                </div></div>]]>
            </description>
            <link>https://hummingbard.com/hummingbard/introducing-hummingbard</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277602</guid>
            <pubDate>Fri, 26 Feb 2021 17:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bakers add free bioinformatics tools to their kitchens]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277558">thread link</a>) | @ohjeez
<br/>
February 26, 2021 | https://genomealberta.ca/genomics/genomics_blog_02262101.aspx | <a href="https://web.archive.org/web/*/https://genomealberta.ca/genomics/genomics_blog_02262101.aspx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                <!--
                                Cake and cookies, oh my! Bioinformatics isn&#8217;t just for medicine anymore.
                                
                                No
                                
                                _blank.gif" alt="
                                -->
                                <p>Bioinformatics has helped saved millions of human lives, from new medicines to treat old ailments to new vaccines to stop a novel virus. Those are huge accomplishments, but they are not the last of modern miracles that this technology can help produce. <span>&nbsp;</span>Today, bioinformatics is spreading beyond medicine and venturing into other industries too. Take for example, the baking industry where bakers are stirring up new eggless cake recipes using a kitchen full of free bioinformatic tools.</p>
<p><a href="https://www.bakingbusiness.com/articles/53085-bioinformatics-may-speed-up-the-search-for-egg-replacers">A report in Baking Business</a> finds that bioinformatics is “showing promise in assisting in a longtime challenge: finding ingredients to replace or reduce the use of egg-based ingredients in formulas.” This challenge isn’t solely stemming from a surge in demand for eggless baked goods by Vegans. </p>
<p>Rather the baking industry, according to <a href="https://bakerpedia.com/ingredients/egg-replacement/#:~:text=Egg%20replacement%20in%20bakery%20and,been%20driven%20by%20many%20factors%3A&amp;text=Economics%3A%20considerable%20fluctuations%20in%20global,%2C%20avian%20influenza%20outbreaks%2C%20etc.&amp;text=Allergen%3A%20egg%20is%20considered%20a,a%20challenge%20for%20food%20producers">Bakerpedia</a>, is faced with serious obstacles from the use of eggs on several additional fronts, including:</p>
<p><span>·<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>pronounced fluctuations in global egg supply and pricing, </p>
<p><span>·<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>health concerns ranging from egg allergies and cholesterol content to avian influenza outbreaks and other potential health threats</p>
<p><span>·<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span>egg products have a limited shelf-life and can lead to <a href="https://www.fda.gov/food/hazard-analysis-critical-control-point-haccp/haccp-principles-application-guidelines">Hazard Analysis and Critical Control Point</a> (HACCP) issues</p>
<p>Replacing eggs in recipes may seem to be a no-brainer but making it work is vexing even the smartest of bakers.</p>
<p>“Eggs provide strong gels and emulsifying properties in baked foods. Removing them from formulas might cause cakes and cookies to collapse and not have a uniform crumb structure,” Harrison Helmick, a PhD student at Purdue University, said in a Feb. 18 presentation at BakingTech 2021, a virtual event put on by the American Society of Baking, the Baking Business <a href="https://www.bakingbusiness.com/articles/53085-bioinformatics-may-speed-up-the-search-for-egg-replacers">reports</a>.</p>
<p>Finally, there’s a way to reliably solve the problem and find suitable egg substitutes for each recipe.</p>
<p>“Using just bioinformatic information, you can screen for any protein that may or may not be a good emulsifier,” Mr. Helmick said, adding “This represents a tremendous opportunity to identify new proteins that might have good characteristics for what you’re looking for.”</p>
<p><strong><span>Free open source bioinformatic tools</span></strong></p>
<p>Bakers and baking industry leaders are likely to find <a href="https://en.wikipedia.org/wiki/List_of_open-source_bioinformatics_software">free bioinformatics tools</a> easier to use than they would expect. As with any technology, once it matures it becomes easier to use both from the technical aspect and the strength in support from the surrounding community. </p>
<p>Just don’t expect the free tools to be labeled for baking. Most are described by the function they perform in use cases for medicine. Keep in mind that bioinformatics is used to analyze biological data. As long as you know what you’re looking for from the outset, identifying the appropriate tools is fairly straightforward.</p>
<p>“Most proteins are somewhere between 400 to a couple thousand amino acids long. Bioinformatics predicts what the structure of a specific protein will look like. Pea protein has been shown to have emulsifying activity similar to that of ovalbumin, the primary protein in egg whites,” said Helmick in the article.</p>
<p>So where do you find these free bioinformatics tools? Given that they are open source, you’ll find many of them in expected places like <a href="https://github.com/danielecook/Awesome-Bioinformatics">GitHub</a> and <a href="https://sourceforge.net/directory/os:linux/freshness:recently-updated/?q=bioinformatics">SourceForge. <span>&nbsp;</span></a><span>&nbsp;</span></p>
<p>Be sure to browse several bioinformatics lists on both of these sites since no one list there contains all of the bioinformatics tools that are available. There are additional sites, like <a href="https://www.bioinformatics.org/groups/categories.php?cat_id=2">Bioinformatics.org</a>’s software map, that contain lists of these tools too. On all such websites, look for free tools listed among paid tools as not every list exclusively contains free or paid tool listings. </p>
<p>However, just because the tools are free doesn’t mean they’re easy to use. Most require computing, science and math skills. That’s certainly not a problem for the baking industry which is using a wide variety of computing and science applications already. </p>
<p>But if you’re a baker eager to try bioinformatics in your kitchen, consider taking one of these <a href="https://github.com/ossu/bioinformatics">free, self-taught courses</a> from some of the best universities from around the world. </p>
<p>Bioinformatics has applications beyond medicine and baking. For a look at the many different fields using bioinformatics today, check out this short video:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/tzWoygUWmQg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                            </div></div>]]>
            </description>
            <link>https://genomealberta.ca/genomics/genomics_blog_02262101.aspx</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277558</guid>
            <pubDate>Fri, 26 Feb 2021 17:47:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: your build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26277521">thread link</a>) | @moonlighter
<br/>
February 26, 2021 | https://justine.lol/cosmopolitan/ | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>your build-once run-anywhere c library</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/tutorials.html">Tutorials</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» justine's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
printf %s <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -O -static -fno-pie -no-pie -mno-red-zone -nostdlib -nostdinc \
  -o hello.com.dbg hello.c -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>
objcopy -SO binary hello.com.dbg hello.com

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, OpenBSD, and NetBSD too. For details on how this works,
  please read the <a title="Actually Portable Executable" aria-label="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly
  pδrταblε εxεcµταblε</a> blog post. This novel binary format is also
  optional, since <code>hello.com.dbg</code> is executable too, only on
  your local system since it's an ELF binary.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277521</guid>
            <pubDate>Fri, 26 Feb 2021 17:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Did Texas Lose Power?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277437">thread link</a>) | @amoorthy
<br/>
February 26, 2021 | https://blog.thefactual.com/why-did-texas-lose-power | <a href="https://web.archive.org/web/*/https://blog.thefactual.com/why-did-texas-lose-power">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>


<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>On February 16, as many as <a href="https://www.usatoday.com/story/news/nation/2021/02/17/texas-power-grid-why-state-has-its-own-operated-ercot/6782380002/" rel="noopener" target="_blank"><span>4.5 million Texans</span></a>, or about 1 in 6, were without power as the state plunged into record sub-freezing temperatures. For a state that prides itself on energy production and <a href="https://www.foxnews.com/politics/texas-power-outtage-rick-perry-keep-feds-out-of-their-business" rel="noopener" target="_blank"><span>independence</span></a>, the sudden inability to supply enough energy represents a catastrophic failure: people froze, water infrastructure was incapacitated, and <a href="https://www.wsj.com/articles/full-death-toll-from-texas-storm-could-take-months-to-determine-11614107708#:~:text=So%20far%2C%20nearly%2080%20people,according%20to%20the%20Associated%20Press." rel="noopener" target="_blank"><span>at least 80 people</span></a> died. In the aftermath, millions faced <a href="https://www.smithsonianmag.com/smart-news/how-winter-storm-uri-has-impacted-us-180977055/" rel="noopener" target="_blank"><span>water-boil advisories</span></a>, and some Texans have received power bills <a href="https://www.dallasnews.com/business/2021/02/20/griddy-customers-face-5000-bills-for-5-freezing-days-in-texas/" rel="noopener" target="_blank"><span>equivalent</span></a> to what they “would normally pay over three or four years.”</p>
<!--more-->
<p>Finger pointing started almost immediately, with conservative voices <a href="https://abcnews.go.com/Politics/republicans-texas-power-outages-spread-false-claims-green/story?id=75947664" rel="noopener" target="_blank"><span>blaming renewable energy</span></a>, especially wind, and left-leaning voices clarifying that natural gas, the state’s dominant energy source, had <a href="https://www.businessinsider.com/texas-a-majority-of-lost-power-generation-has-been-from-fossil-fuels-2021-2" rel="noopener" target="_blank"><span>lost far more capacity</span></a> than any of the other power sources. Others cast doubt upon ERCOT — the organization that runs the state’s power grid — for a seeming inability to meet demand and protect Texas’s consumers both from the cold and unprecedented prices.&nbsp;</p>
<div><p>What actually happened in Texas? This week, The Factual uses 27 articles from 18 sources across the political spectrum to look for an answer. In the end, the organization of the state’s power resources and grid, rather than the merits of any particular energy source, seem to bear the majority of responsibility.</p></div>
<p><img src="https://lh6.googleusercontent.com/zlayEqnt73ZL31G0fANICz68V9RNU7F1H6CUHpIeoRDlCiv3bOVqUZtJi22V2tO8LcFV5VPRBAyoIrluEeEtyYXLm0JvXwbiqTtwghCq4PvfE5sie3J0k-D9cgSSXEq7HZqs6Q7H" width="726" loading="lazy"></p>

<h4><strong>Was Renewable Energy Responsible?</strong></h4>
<p>The rapid transformation of a climatic crisis into a political battleground began with a <a href="https://www.vox.com/2021/2/17/22287469/fox-news-winter-storm-uri-windmills-ercot-greg-abbott-hannity-carlson" rel="noopener" target="_blank"><span>salvo of accusations</span></a> that renewable energy sources were responsible for the power grid’s collapse. Frozen wind turbines, plastered across some news sites, supposedly bore responsibility.&nbsp;</p>
<p>To be sure, many of the wind turbines in Texas are not winterized, meaning they lack heated or protected elements that permit continued operation in freezing temperatures. As a result, some wind facilities slowed or stopped their production of electricity entirely. Critics missed, however, that wind was only expected to account for less than 10%, or <a href="https://www.statesman.com/story/news/politics/politifact/2021/02/18/texas-power-outages-greg-abbott-dan-crenshaw-fact-check/6791469002/" rel="noopener" target="_blank"><span>6,000 megawatts</span></a> (MW), during winter production, when Texas relies mostly on natural gas. At its lowest point, it looks like about <a href="https://oilprice.com/Energy/Energy-General/Whos-To-Blame-For-The-Texas-Power-Crisis.html" rel="noopener" target="_blank"><span>2,000 MW</span></a> of that went offline, while up to 29,000 MW from natural gas, coal, and nuclear went missing — <a href="https://www.theatlantic.com/technology/archive/2021/02/what-went-wrong-texas/618104/" rel="noopener" target="_blank"><span>a third</span></a> of ERCOT’s total production capacity. They also missed that wind’s shortfall was only intermittent, with offshore turbines causing wind generation to <a href="https://www.statesman.com/story/news/politics/politifact/2021/02/19/texas-power-outage-energy-grid-wind-renewable-energy-greg-abbott-fact-check/4500251001/" rel="noopener" target="_blank"><span>exceed expectations</span></a> during periods of the storm.</p>
<p>In short, the missing wind energy only accounted for a small portion of the overall missing capacity that led to Texas’s power outages. Natural gas, coal, and nuclear were to account for 80% of wintertime production and were experiencing similar or greater levels of failure. Afterwards <a href="https://www.forbes.com/sites/joewalsh/2021/02/16/wind-power-isnt-to-blame-for-texas-electricity-crisis/?sh=749255ef21b3" rel="noopener" target="_blank"><span>ERCOT noted</span></a>, for example, that “wind turbine outages have been responsible for less than 13% of Texas’ total power shortages.”&nbsp;</p>
<p>As critics used the incident to ridicule wind technology, and renewables at large, they neglected to mention that wind turbines in other parts of the world, like the <a href="https://www.factcheck.org/2021/02/wind-turbines-didnt-cause-texas-energy-crisis/" rel="noopener" target="_blank"><span>North Sea</span></a>, are designed to function at freezing temperatures and regularly do so without issue. The lack of winterization in Texas represents a choice by Texas’s energy producers, not the type of energy itself, and ERCOT was <a href="https://reason.com/2021/02/22/the-texas-blackout-blame-game/" rel="noopener" target="_blank"><span>well aware</span></a> that only a fraction of wind capacity would be available in winter months.</p>
<div><p>This combination of factors shows that the responsibility for the bulk of Texas’s power outages, instead, lies elsewhere.</p></div>
<h4><strong>Does Blame Fall on Natural Gas, Coal, or Nuclear?</strong></h4>
<p>It’s easy to turn around and then heap blame on <a href="https://www.vox.com/2021/2/20/22292926/texas-high-electric-bills-winter-storm-griddy" rel="noopener" target="_blank"><span>failures in thermal energy sources</span></a>, and especially natural gas, which nominally accounts for <a href="https://www.theatlantic.com/technology/archive/2021/02/what-went-wrong-texas/618104/" rel="noopener" target="_blank"><span>around half</span></a> of all power generation in the state. Just as frigid temperatures were negatively impacting wind turbines, they were causing major failures for natural gas, coal, and nuclear energy. Given Texas’s abundance of energy resources, natural gas is pumped up from the ground as needed, but these <a href="https://www.factcheck.org/2021/02/wind-turbines-didnt-cause-texas-energy-crisis/" rel="noopener" target="_blank"><span>pumps failed</span></a>, as did a whole range of equipment needed to keep the system moving. Likewise, coal plants saw their production capacity fall, and a nuclear reactor <a href="https://www.washingtonexaminer.com/policy/energy/how-and-why-a-nuclear-reactor-shut-down-in-texas-cold-snap-when-energy-was-needed-most" rel="noopener" target="_blank"><span>shut down entirely</span></a>.&nbsp;</p>
<p>In a sense, natural gas, as the state’s largest energy provider and experiencing the greatest <a href="https://www.texastribune.org/2021/02/17/abbott-republicans-green-energy/" rel="noopener" target="_blank"><span>reduction in capacity</span></a>, bears more responsibility than any other energy source. But blaming a reliance on fossil fuels for Texas’s troubles is just as short-sighted as blaming renewable energy. During normal times, natural gas is lauded as a reliable, cheap, and abundant energy source, and it is the cornerstone of the state’s ability to supply electricity to nearly 30 million people. Shortcomings of natural gas in terms of contributions to greenhouse gas emissions are clear, as with other fossil fuels, but nothing inherent to fossil fuels made them more or less likely to fail during the record cold temperatures.&nbsp;</p>
<div><p>The failure, rather, seems to be systematic and organizational, not specific to a singular energy source.</p></div>
<h4><strong>The Need for Winterization</strong></h4>
<div><p>The more likely culprit is a lack of winterization standards in Texas's power grid as a whole. Texans are well-known to value independence and freedom from regulation, so much so that their power grid is <a href="https://www.nbcnews.com/news/us-news/texas-set-stage-its-energy-crisis-more-80-years-ago-n1258341" rel="noopener" target="_blank"><span>disconnected from the rest of the U.S</span></a>. The laissez-faire approach has purported benefits, like lower prices, but also limitations.</p></div>
<p><img src="https://lh6.googleusercontent.com/UjEf_OrUCpcjv9od8SzUYcCcE2B2aDKX_Fj-SDKzkr3oqvGM4A6qwzjNgsFsqWQsqsdZSvXWJ2mdNwX4KvD9TxCFWepIbYXLWuRME2MRyDe1pWK-udM1h0YxybN26Xl_E_t-Hyka" width="576" height="288" loading="lazy"></p>
<div><p>Note: Because Texas has its own electrical grid and does not transmit power across state lines, it can avoid regulations like those from the FERC.</p></div>
<p>National bodies, like the Federal Energy Regulatory Commission (FERC), can only make recommendations for how the state should deal with energy issues, including winter preparedness. In the aftermath of cold temperatures in 2011 that caused similar but less severe outages, FERC undertook an investigation of what went wrong, eventually highlighting a <a href="https://www.usatoday.com/story/news/nation/2021/02/18/state-energy-winter-protections-lacking-reports-have-suggested/4490501001/" rel="noopener" target="_blank"><span>lack of winterization and emergency storage</span></a> in natural gas plants as the primary cause. It then provided plans for mitigation strategies to Texas energy producers.</p>
<p>Fast forward 10 years to 2021, and Texas’s energy producers can produce affidavits of winterization, but that concept doesn’t contain specific, enforceable steps at the state level as <span>they do elsewhere</span>. <a href="https://www.dallasnews.com/news/investigations/2021/02/20/texas-tells-power-plants-to-be-winter-ready-but-it-lets-them-decide-how-to-prepare/" rel="noopener" target="_blank">Without such standards</a>, “state utility regulators have issued only three fines ever related to inadequate weather planning by power generators.” This means the natural gas network once again found itself unable to cope with cold temperatures — sufficient gas couldn’t be pumped from the ground due to failing equipment, emergency above-ground reserves were scarce, and <a href="https://oilprice.com/Energy/Energy-General/Whos-To-Blame-For-The-Texas-Power-Crisis.html" rel="noopener" target="_blank"><span>gas distribution</span></a> networks stopped working. The same goes for wind turbines, which <a href="https://www.texastribune.org/2021/02/20/texas-power-grid-winterize/" rel="noopener" target="_blank"><span>weren’t prepared</span></a> to operate in such low temperatures.&nbsp;</p>
<p>In Texas’s open and unregulated market, the desire to produce energy when it is in greater demand, like during the winter, when there are fewer sources of supply, is intended to <a href="https://www.wsj.com/articles/texas-freeze-power-grid-failure-electricity-market-incentives-11613777856" rel="noopener" target="_blank"><span>incentivize winterization</span></a> — producers that continue operation in winter are rewarded by higher prices. Yet as energy producers sought greater profits, the extra cost of winterization precautions was deemed prohibitive, especially given the infrequency of extreme cold weather. In this way, the <a href="https://www.theatlantic.com/technology/archive/2021/02/what-went-wrong-texas/618104/" rel="noopener" target="_blank"><span>incentive for profit</span></a>, not something specific to any energy source, seems to be the key to the grid’s lack of preparedness.&nbsp;</p>
<div><p>While there’s no guarantee that improved winterization standards would have forestalled all power outages, they would have at a minimum enabled better outcomes, with less lost capacity, shortened power outages, and probably fewer dead.</p></div>
<h4><strong>A System Meant to Benefit Texans Ended Up Hurting Them</strong></h4>
<p>Adding insult to injury, many Texans now face sky-high energy bills in the aftermath of insufficient and intermittent power, courtesy of the energy market's design. The ERCOT grid allows consumers to choose between <a href="https://www.vox.com/2021/2/20/22292926/texas-high-electric-bills-winter-storm-griddy" rel="noopener" target="_blank"><span>variable and fixed rates</span></a> for energy consumption. A variable rate allows the cost of electricity to follow supply, while a fixed rate means customers pay the same amount regardless of how much electricity is available.&nbsp;</p>
<div><p>The variable-rate system, which can lead to prices as low as <a href="https://www.dallasnews.com/business/2021/02/20/griddy-customers-face-5000-bills-for-5-freezing-days-in-texas/" rel="noopener" target="_blank"><span>2 cents</span></a> per kWh, gave way to unprecedented prices as supply dwindled. This led customers, including single households, to pay as much as <a href="https://theconversation.com/whats-behind-15-000-electricity-bills-in-texas-155822" rel="noopener" target="_blank"><span>$9 per kWh</span></a>, an arbitrary cap imposed by ERCOT. For context, the average retail cost per kWh varies by state but is generally around <a href="https://www.statista.com/statistics/183700/us-average-retail-electricity-price-since-1990/" rel="noopener" target="_blank"><span>11 cents</span></a> and averaged <a href="https://www.eia.gov/electricity/state/" rel="noopener" target="_blank"><span>8.6 cents</span></a> in Texas in 2019, and the average home consumes just under <a href="https://www.eia.gov/tools/faqs/faq.php?id=97&amp;t=3#:~:text=How%20much%20electricity%20does%20an,about%20877%20kWh%20per%20month." rel="noopener" target="_blank"><span>900 kWh per month</span></a>. Had the cap not existed, customers could have paid even higher prices. Energy retailers, such as <a href="https://www.dallasnews.com/business/2021/02/20/griddy-customers-face-5000-bills-for-5-freezing-days-in-texas/" rel="noopener" target="_blank"><span>Griddy</span></a>, warned customers that higher than normal prices were anticipated, but switching companies before the storm proved impossible for most. This led to headlines like “<a href="https://www.businessinsider.com/texas-army-veteran-faces-16000-bill-due-to-rocketing-energy-prices-2021-2" rel="noopener" target="_blank"><span>Texas: Army veteran faces $16,000 bill due to rocketing energy prices</span></a>.”</p></div>
<p><img src="https://lh6.googleusercontent.com/QZt0csXKhNchYumakXv3lGoYYHPaNjVvsmYUdMZUcFbKYnW-eEyGH61Ld-eduvNlf8e0AZA-lBG049GQTloiovIBzAYMlgC8xwedWkMsIodQvkctTJR_1eWvkYIhrRTMIGphwd5E" width="652" loading="lazy"></p>

<p>For some, this failure represents the duplicity of leaving a critical utility up to market forces. In seeking to protect the freedom of energy producers from federal regulation, Texas ultimately ended up <a href="https://www.theatlantic.com/technology/archive/2021/02/what-went-wrong-texas/618104/" rel="noopener" target="_blank"><span>curtailing the freedom of everyday Texans</span></a> — for some by making electricity unaffordable, for others by effectively taking away that access, and the freedom to power and heat one’s home, entirely. It’s easy to see overregulation as a burden, but in this instance, there’s a clear rationale for how an absence of regulation made an extreme weather event worse. Indeed, it likely cost some Texans their lives.</p>
<div><p>Now, amid the scrutiny on the system’s lack of regulation, Texans may also be reconsidering the merits of deregulation. An <a href="https://www.wsj.com/articles/texas-electric-bills-were-28-billion-higher-under-deregulation-11614162780" rel="noopener" target="_blank"><span>analysis</span></a> from the <em>Wall Street Journal </em>in the aftermath of the crisis even casts doubt on the purported low costs of such a system, finding that “deregulated Texas residential consumers paid $28 billion more for their power since 2004 than they would have paid at the rates charged to the customers of the state’s traditional utilities.”&nbsp;</p></div>
<h4><strong>Conclusion</strong></h4>
<p>The rapid politicization of Texas’s weather troubles seems on par with the partisan tensions that epitomize the beginning to 2021, …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thefactual.com/why-did-texas-lose-power">https://blog.thefactual.com/why-did-texas-lose-power</a></em></p>]]>
            </description>
            <link>https://blog.thefactual.com/why-did-texas-lose-power</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277437</guid>
            <pubDate>Fri, 26 Feb 2021 17:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Judge in Google case disturbed that 'incognito' users are tracked]]>
            </title>
            <description>
<![CDATA[
Score 864 | Comments 337 (<a href="https://news.ycombinator.com/item?id=26277396">thread link</a>) | @johncena33
<br/>
February 26, 2021 | https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When Google users browse in â€œIncognitoâ€� mode, just how hidden is their activity? The Alphabet Inc. unit says activating the stealth mode in Chrome, or â€œprivate browsingâ€� in other browsers, means the company wonâ€™t â€œremember your activity.â€� But a judge with a history of taking Silicon Valley giants to task about their data collection raised doubts Thursday about whether Google is being as forthright as it needs to be about the personal information itâ€™s collecting from users.</p>

<p>At a hearing Thursday in San Jose, California, U.S. District Judge Lucy Koh said sheâ€™s â€œdisturbedâ€� by Googleâ€™s data collection practices in a class-action lawsuit that describes the companyâ€™s private browsing promises as a â€œruseâ€� and seeks US$5,000 in damages for each of the millions of people whose privacy has been compromised since June of 2016.</p>

<p>Weighing Googleâ€™s attempt to get the suit dismissed, Koh said she finds it â€œunusualâ€� that the company would make the â€œextra effortâ€� of data collection if it doesnâ€™t use the information to build user profiles or targeted advertising. Google has become a target of antitrust complaints in the last year filed by state and federal officials -- as well as businesses -- accusing it of abusing its dominance in digital advertising and online search. Koh has a deeper history with the company as a vocal critic of its privacy policies. She forced Google in one notable case to disclose its scanning of emails to build profiles and target advertising.</p>

<p>In this case, Google is accused of relying on pieces of its code within websites that use its analytics and advertising services to scrape usersâ€™ supposedly private browsing history and send copies of it to Googleâ€™s servers. Google makes it seem like private browsing mode gives users more control of their data, Amanda Bonn, a lawyer representing users, told Koh. In reality, â€œGoogle is saying thereâ€™s basically very little you can do to prevent us from collecting your data, and thatâ€™s what you should assume weâ€™re doing,â€� Bonn said.</p>

<p>Andrew Schapiro, a lawyer for Google, argued the companyâ€™s privacy policy â€œexpressly disclosesâ€� its practices. â€œThe data collection at issue is disclosed,â€� he said.Another lawyer for Google, Stephen Broome, said website owners who contract with the company to use its analytics or other services are well aware of the data collection described in the suit.</p>

<p>Broomeâ€™s attempt to downplay the privacy concerns by pointing out that the federal court systemâ€™s own website uses Google services ended up backfiring.</p>

<p>The judge demanded an explanation â€œabout what exactly Google does,â€� while voicing concern that visitors to the courtâ€™s website are unwittingly disclosing information to the company. â€œI want a declaration from Google on what information theyâ€™re collecting on users to the courtâ€™s website, and what thatâ€™s used for,â€� Koh told the companyâ€™s lawyers. The case is Brown v. Google, 20-cv-03664, U.S. District Court, Northern District of California (San Jose).</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/judge-in-google-case-disturbed-that-even-incognito-users-are-tracked-1.1569065</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277396</guid>
            <pubDate>Fri, 26 Feb 2021 17:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[California’s congested ports expose root problem of e-commerce shipping delays]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277349">thread link</a>) | @ilamont
<br/>
February 26, 2021 | https://www.glossy.co/fashion/californias-ports-expose-the-root-problem-of-shipping-delays/ | <a href="https://web.archive.org/web/*/https://www.glossy.co/fashion/californias-ports-expose-the-root-problem-of-shipping-delays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>Brands and retailers across the U.S., along with UPS and FedEx, struggled with a surge of e-commerce orders over the holidays, and the <a href="https://www.glossy.co/fashion/its-going-to-be-hell-how-brands-are-preparing-for-the-logistical-nightmare-of-holiday-shipping/">logistical strain of shipping millions of packages</a> at once. Despite being well past Christmas, those problems persist. But the root of shipping problems lies well before any actual orders are made. Ports in California where over a million cargo shipments are processed every year have been backed up for months, with no slowdown&nbsp;in imports and a growing backlog of cargo to dig through.&nbsp;</span></p><p><span>Fixing that problem will take a coordinated effort from the federal government and brands across the country, according to Port of Los Angeles executive director Gene Seroka,&nbsp;</span></p><div id="piano-cta">
<p>Seroka said that, while the LA port’s overall import volume for 2020 was only 1% higher than 2019, that includes a four month period between February and May when imports virtually halted. The second half of 2020 saw 908,000 shipments processed per month, an increase of more than 50% from the first half of the year. Over Christmas, the Port of Los Angeles&nbsp;took in 94% more imports than the previous year.</p>

<p>“There are a few factors at play,” Seroka said. “Everyone is spending money on tangible goods instead of services. Because of Covid, we have fewer workers on the floor, which means we sort through cargo slower and there’s a lack of exports out of the country, which makes it harder for the shipping companies who rely on round trip economics.”</p>
<p>Seroka added that retailers are also slow in digesting cargo, leaving it to sit at the docks for extra days, taking up space for cargo that is still incoming.</p>
<p><span>Pre-pandemic, the Port of LA saw less than 10 ships coming in per day, now it’s more than 15 per day. Wait times are also increasing, from an average of two days for shipment processing to more than eight days, said Seroka.&nbsp;Exports are down 20% while imports are up 11%. Out of the 15,000 or so port workers, around 800 are currently on leave&nbsp;due to Covid illnesses or for quarantining purposes.</span></p>
<p><span>Those issues are all being deeply felt by brands. Meera Bhatia, president of expert services at TechStyle, the parent company of Fabletics, said the backups have made inventory planning for brands difficult. She is preparing for shipping delays and backups that will persist for at least the next six months.</span></p>
<p><span>“If you rewind all the way to March and April, it was really tough to get inventory into the country,” she said. Most products from TechStyle’s brands are produced in factories in Asia. “The LA ports were backed up then and they still are now as brands try to get stuff into their warehouses. The carriers had to throttle volume. I know it has required a lot of capital investment on the part of the shipping companies for new trucks and ships. That stuff takes time.”</span></p>
<p><span>That backup has affected the price of shipping for brands, as well. Donny Greenberger, COO of intimates manufacturer Gelmart, said he typically pays $1,200 for a 40-foot shipping container of product, but nowadays the same container can cost more than $4,000. A 40-foot container can carry <a href="https://www.jeansinfo.org/shipping.html#:~:text=A%2020%20feet%20container%20can,19000%20%2D%2020000%20pants%20or%20jackets.">around 20,000 pairs of jeans, for example</a>.</span></p>
<p><span>“What I’m most worried about is the supply chain,” said Adeela Hussain Johnson, Adeela Hussain Johnson of luggage brand Beis. “In Long Beach, where we get our shipments, the ports are delayed by one or two months already.&nbsp;Our shipping&nbsp;partners there have told us to prepare for these issues to last throughout the entire year.”</span></p>
<p><span>Johnson added that imports from China, where Beis’ bags are made, are slower right now because of Lunar New Year when a significant portion of the country is on holiday.&nbsp;Some U.S. companies like Peloton have moved manufacturing in response to shipping delays. Last month, <a href="https://www.valuentum.com/articles/peloton-makes-bet-us-manufacturing#:~:text=This%20acquisition%20is%20expected%20to%20help%20alleviate%20those%20concerns.&amp;text=The%20exercise%20bike%20and%20digitally,closing%20adjustments)%20on%20December%2021.">Peloton acquired a U.S. factory</a> and began moving production from Asia to the states</span></p>
<p><span>For the end consumer, they have already felt the impact of similar delays over the holidays. </span>But Seroka hopes companies and the U.S. government can work together to achieve a better end goal.</p>
<p><span>“If we stopped all shipments now, we would still have months of work to get through everything that’s already there,” Seroka said. “First, we need to get workers vaccinated so we can have max capacity out on the docks and ships.” </span>To that end, Seroka said the LA port has a vaccination center on site to vaccinate port workers, but is waiting on an increase in supply from the government.</p>
<p><span>“We have to implore importers to do their best to empty the containers as soon as they arrive and bring them back to the port. Finally, this isn’t very popular, but we’ve talked to industry people about metering cargo to help us dig through the backup. Really it just comes down to us needing a break to catch our breath and dig through what we have already, so we can get back on track.”<strong>&nbsp;</strong></span></p>
</div></div>]]>
            </description>
            <link>https://www.glossy.co/fashion/californias-ports-expose-the-root-problem-of-shipping-delays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277349</guid>
            <pubDate>Fri, 26 Feb 2021 17:30:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A prototype of an intelligent underground robotic system for urban environments]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277298">thread link</a>) | @sizzle
<br/>
February 26, 2021 | https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/Detalle/Comunicacion_C/1371305659992/1371215537949/A_prototype_of_an_intelligent_underground_robotic_system_for_urban_environments_has_been_developed | <a href="https://web.archive.org/web/*/https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/Detalle/Comunicacion_C/1371305659992/1371215537949/A_prototype_of_an_intelligent_underground_robotic_system_for_urban_environments_has_been_developed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The European research project BADGER, coordinated by the Universidad Carlos III de Madrid (UC3M), has presented a prototype of an autonomous underground robot with intelligent navigation for urban environments.</p><div><p>This robotic system is composed of two main elements: a surface vehicle with a geo-radar that is used to scan the ground, so that subterranean obstacles can be detected; and an autonomous underground robot that does the drilling work. “Once the subsoil has been scanned by the rover, using a software developed as part of the project, a work plan is drawn up and an entry and exit point for the work to be carried out is established. The next task consists of taking the robot to the place where the work will be carried out and using it to drill from one point to another”, explains the BADGER project’s technical manager, Santiago Martínez de la Casa, researcher at the RoboticsLab in the UC3M’s Department of Systems Engineering and Automation.</p>

<p>It is estimated that around 500,000 civil works for the installation of wiring, piping and other small-diameter underground scoring are carried out in Europe each year. These works are typically carried out by opening a ditch, extending the pipeline, then filling in the ditch. “The advantage of this robot is that it is possible to carry out the same drilling work without having to open a ditch, which prevents noise, pollution and inconvenience for citizens”, the researcher notes.</p>

<p>Within the framework of this project, funded by the European Union’s Framework Programme for Research, Technological Development and Innovation (GA 731968) and in which scientists from Germany, Spain, Greece, Italy and the United Kingdom are participating, the system has been tested under laboratory conditions. In particular, several underground drilling tests on land in northern Germany as well as in the Community of Madrid have been carried out.</p>

<p>The system prototype has caught the attention of the private sector, of both European and north American companies, and is currently continuing to be developed with the aim of starting tests in real urban environments. Researchers estimate that it could be ready to operate in cities within 2 to 3 years.</p>

<p>“The use of innovative localisation, mapping and navigation techniques, along with sensors and geo-radars, allows the systems to be adapted to different fields”, explains the project coordinator Carlos Balaguer, professor at the UC3M’s Department of Systems Engineering and Automation and one of the directors of the RoboticsLab. Introducing these advanced robotic technologies which have cognitive and control capabilities has multiple possible applications, adds Professor Balaguer: “It will increase Europe’s competitive edge in search and rescue operations (landslides), mining, civil applications (such as water, gas, fibre optics lines), exploration techniques, mapping, etc”.</p>

<p>BADGER (roBot for Autonomous unDerGround trenchless opERations, mapping and navigation) is a European R&amp;D&amp;I consortium, coordinated by the UC3M, in which researchers and technologists from the Centre for Research and Technology-Hellas (Greece), the School of Engineering at the University of Glasgow (Scotland, United Kingdom), IDS GeoradarSrl (Italy), Robotnik Automation SLL (Spain), SingularLogic S.A. (Greece) and TRACTO-TECHNIK GmbH&amp;Co.KG (Germany) are participating.&nbsp;</p>

<p>More information: <a href="http://www.badger-robotics.eu/" target="_blank">www.badger-robotics.eu</a></p>

<p>--------------------------------</p>

<p><a href="https://www.uc3m.es/uc3m/media/uc3m/doc/archivo/doc_badger-frances/badger-uc3m_fr.pdf">Version française (French version)</a></p>

<p><a href="https://www.uc3m.es/uc3m/media/uc3m/doc/archivo/doc_badger-chino/badger-uc3m_chn.pdf">中文翻譯 (Chinese translation)</a></p>
</div></div>]]>
            </description>
            <link>https://www.uc3m.es/ss/Satellite/UC3MInstitucional/en/Detalle/Comunicacion_C/1371305659992/1371215537949/A_prototype_of_an_intelligent_underground_robotic_system_for_urban_environments_has_been_developed</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277298</guid>
            <pubDate>Fri, 26 Feb 2021 17:27:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto exchange sells Bitcoin for 90% discount, threatens to sue buyers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277252">thread link</a>) | @CoinPM
<br/>
February 26, 2021 | https://protos.com/bitcoin-discount-pdax-cryptocurrency-exchange/ | <a href="https://web.archive.org/web/*/https://protos.com/bitcoin-discount-pdax-cryptocurrency-exchange/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>One of Southeast Asia’s <strong>biggest crypto exchanges</strong> is bracing itself for legal fallout after it suspended thousands of accounts in the wake of a <a href="https://bitpinas.com/cryptocurrency/pdax-suffers-outage-what-happened/" target="_blank" rel="noreferrer noopener">major outage</a> earlier this month.</p>
<p>PDAX users thought they’d hit the jackpot when the platform started selling <a href="https://protos.com/bitcoin-treasuries-tesla-square-crypto-stocks-investment/" target="_blank" rel="noreferrer noopener">Bitcoin</a> for just $6,000 — <strong>nearly 90% below</strong> its value at the time.</p>
<p>Sadly, it turns out the sale of the century was actually down to a glitch in PDAX’s system. Within 24 hours, the exchange started to lock users out of their accounts.</p>
<p>It even demanded some give the Bitcoin back, <strong>threatening those who refused</strong> with legal action.</p>
<figure><div>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">I also bought some in that glitch but unfortunately pdax demand me to return the withdrawn btc otherwise they will file me a criminal case 😢</p>— Drakeee (@Drakeee31101625) <a href="https://twitter.com/Drakeee31101625/status/1365282105056366592?ref_src=twsrc%5Etfw">February 26, 2021</a></blockquote>
</div></figure>
<p><em>[Read more: <a href="https://protos.com/bitcoin-ethereum-cryptcurrency-exchange-thefts-academic/" target="_blank" rel="noreferrer noopener">Academic proves Bitcoin exchange thefts affect Ethereum — 5 days later</a>]</em></p>
<p>But now PDAX users are meeting legal fire with fire. They say they did nothing wrong, and by losing access to their accounts <strong>the exchange denied customers</strong> the opportunity to <a href="https://www.philstar.com/business/2021/02/25/2080142/pdax-ready-face-lawsuits" target="_blank" rel="noreferrer noopener">make the most</a> of Bitcoin’s latest price surge.</p>
<p>Legal experts working on behalf of affected users reportedly say they <a href="https://www.benzinga.com/markets/cryptocurrency/21/02/19845820/crypto-exchange-asks-customers-to-return-bitcoin-after-selling-it-at-88-discount#bz-campaign-text-middle:~:text=Rafael%20Padilla%2C%20an%20attorney%20representing%20the,it%20cannot%20unilaterally%20reverse%20the%20transactions." target="_blank" rel="noreferrer noopener">have a case</a>.</p>
<p>On the other hand, PDAX argues it’s well within its rights to lock accounts and reverse the transactions, which related to some 2,800 users — as it supposedly <strong>never actually had the crypto</strong> to sell.</p>
<blockquote><p>It’s very understandable that a lot of users will feel upset they were able to buy what they thought an order was there for Bitcoin at very low prices. But unfortunately, the underlying Bitcoins were never in the possession of the exchange, so there’s never really anything there to be bought or sold.</p><cite><em>PDAX CEO Nichel Gaba</em></cite></blockquote>
<p>While the case is strange, there <em>is</em> something of a precedent in this area. Crypto exchange Quoine was <a href="https://www.coindesk.com/singapores-court-of-appeals-rules-quoine-exchange-in-breach-of-contract-in-landmark-crypto-case?fbclid=IwAR2YUxMj3oPpY2w57018DOtfBx_OqkJuUA-L16RQ_ldApaTXwmtlFBRTw9g" target="_blank" rel="noreferrer noopener">found to be in breach of contract</a> when it <strong>reversed seven trades </strong>from 2017 that it claimed were authorised by mistake.</p>
</div>
</div></div>]]>
            </description>
            <link>https://protos.com/bitcoin-discount-pdax-cryptocurrency-exchange/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277252</guid>
            <pubDate>Fri, 26 Feb 2021 17:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Application-Wide Panic Handling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277143">thread link</a>) | @lukastyrychtr
<br/>
February 26, 2021 | https://domwillia.ms/panik/ | <a href="https://web.archive.org/web/*/https://domwillia.ms/panik/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <nav id="toc">
            <strong>Table of Contents</strong>
            

        </nav>

        <p>A <a href="https://doc.rust-lang.org/std/macro.panic.html">panic</a> in Rust is the final resort when the code reaches an erroneous or impossible state. The stack of the thread it occurred on is unwound, every value that falls out of scope <a href="https://doc.rust-lang.org/reference/destructors.html">dropped</a>, and the thread terminated. This is isolated to that specific thread<sup id="fnref:1"><a href="#fn:1">1</a></sup>, which allows other threads to detect and gracefully handle the error condition by e.g. spawning a new thread to replace it, or logging and exiting cleanly.</p>
<p>In most programs this is pretty useful, but I've been tripped up enough by this behaviour in my <a href="https://github.com/DomWilliams0/name-needed">game engine</a> to warrant implementing an alternate method of panic handling.</p>
<h2 id="all-panics-are-terminal">All panics are terminal</h2>
<p>Ideally, no panics should ever occur. Clearly this isn't possible, so I'm striving for the next best thing - <strong>immediate detection and graceful shutdown</strong>. Any panic on any thread should be treated as a hard error, and the main thread should attempt to save all game data and exit as soon as possible. </p>
<p>This provides the benefit of increased confidence in finding error conditions during testing, especially automated end-to-end tests where the game is run headless with debug asserts enabled. I've been bitten by this many times, when a worker thread panics but the main thread continues on oblivious, exiting cleanly and marking the test as a "success". It can be frustrating to hunt down bugs like these where the error is swallowed and silently breaks things<sup id="fnref:2"><a href="#fn:2">2</a></sup>, as I describe in the section below.</p>
<h2 id="the-pain-of-silent-panics">The pain of silent panics</h2>
<p>My game engine makes heavy use of thread pools to process expensive workloads over several ticks without affecting the frame rate - examples include generating chunks of terrain, or calculating paths for <a href="https://domwillia.ms/devlog3">navigation</a>. The main thread will post work to the thread pool via a <a href="https://doc.rust-lang.org/std/sync/mpsc/">channel</a>, then consume available results each tick, all without blocking. A pseudo-code example:</p>
<div><pre><span></span><code><span>// set up channels</span>
<span>let</span><span> </span><span>(</span><span>request_tx</span><span>,</span><span> </span><span>request_rx</span><span>)</span><span> </span><span>=</span><span> </span><span>channel</span><span>();</span><span></span>
<span>let</span><span> </span><span>(</span><span>result_tx</span><span>,</span><span> </span><span>result_rx</span><span>)</span><span> </span><span>=</span><span> </span><span>channel</span><span>();</span><span></span>

<span>// spawn worker thread</span>
<span>std</span>::<span>thread</span>::<span>spawn</span><span>(</span><span>move</span><span> </span><span>||</span><span> </span><span>{</span><span></span>
<span>    </span><span>while</span><span> </span><span>let</span><span> </span><span>Ok</span><span>(</span><span>req</span><span>)</span><span> </span><span>=</span><span> </span><span>request_rx</span><span>.</span><span>recv</span><span>()</span><span> </span><span>{</span><span></span>
<span>        </span><span>// process request (potentially taking a long time)</span>
<span>        </span><span>// and post response back</span>
<span>        </span><span>let</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>do_work</span><span>(</span><span>req</span><span>);</span><span></span>
<span>        </span><span>result_tx</span><span>.</span><span>send</span><span>(</span><span>result</span><span>).</span><span>unwrap</span><span>();</span><span></span>
<span>    </span><span>}</span><span></span>
<span>});</span><span></span>

<span>// core game loop</span>
<span>loop</span><span> </span><span>{</span><span></span>
<span>    </span><span>// submit work to worker threads</span>
<span>    </span><span>for</span><span> </span><span>chunk</span><span> </span><span>in</span><span> </span><span>required_chunks</span><span>()</span><span> </span><span>{</span><span></span>
<span>        </span><span>request_tx</span><span>.</span><span>send</span><span>(</span><span>chunk</span><span>).</span><span>unwrap</span><span>();</span><span> </span><span>// does not block</span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>// consume completed results, again without blocking</span>
<span>    </span><span>while</span><span> </span><span>let</span><span> </span><span>Ok</span><span>(</span><span>res</span><span>)</span><span> </span><span>=</span><span> </span><span>result_rx</span><span>.</span><span>try_recv</span><span>()</span><span> </span><span>{</span><span></span>
<span>        </span><span>// ... use result ...</span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>// ...</span>
<span>}</span><span>   </span>
</code></pre></div>


<p>This works swimmingly until something causes a panic in the worker thread. Depending on the exact setup, one or more of the following could happen:</p>
<ul>
<li>✅ The panic causes the <a href="https://doc.rust-lang.org/std/sync/mpsc/struct.Receiver.html">receiving end</a> of the requests channel to disconnect, meaning <code>request_tx.send</code> now returns <code>Err</code> on the main thread<sup id="fnref:3"><a href="#fn:3">3</a></sup>. Panic detected!</li>
<li>✅ The panic causes the sending end of the results channel to disconnect, meaning <code>result_rx.try_recv</code> now returns <code>Err</code> on the main thread. Panic also detected!</li>
<li>✅ Any mutex held by the worker thread is now <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html#poisoning">poisoned</a>, and attempts to lock it from any other thread will fail. Panic still detected!</li>
<li>😧 The panic happens before any channel or mutex is in scope, so the thread dies and takes the request to its grave.</li>
<li>😌 The thread pool notices a worker thread died and spawns a new one in its place.</li>
<li>😩 The panic is unconditional (e.g. a <code>todo!()</code>) and we're now stuck in an infinite loop of thread killing and spawning.</li>
<li>🤬 The IDE locks up from the strain of resolving so many stack traces.</li>
</ul>
<p>I've seen all of these happen, and any of the last 4 are a real pain to either notice or track down. The most amusing is #4; the main thread has requested a chunk of terrain and now waits forever for it, leaving a gaping hole in the world where that terrain should be<sup id="fnref:4"><a href="#fn:4">4</a></sup>.</p>
<p><span><img alt="Screenshot of single missing chunk" src="https://domwilliams0.github.io/images/panik-missing-chunk.png" title="A panic killed the thread before it could finish processing that chunk, so I guess they'll just have to learn to live without it."><span>A panic killed the thread before it could finish processing that chunk, so I guess they'll just have to learn to live without it.</span></span></p>
<p>I've written a small crate to avoid this happening again, which is the whole point of this post.</p>
<p><span><img alt="panik-rs logo" src="https://raw.githubusercontent.com/DomWilliams0/panik-rs/master/panik.jpg" title="I refuse to apologise for this."><span>I refuse to apologise for this.</span></span></p>
<h2 id="panik-rs-to-the-rescue">panik-rs to the rescue</h2>
<p><a href="https://crates.io/crates/panik">panik</a> is a simple wrapper around the standard panic functionality, and does the following:</p>
<ul>
<li>Wraps the application in <code>catch_unwind</code> to handle panics on the main thread</li>
<li>Registers a custom panic hook to keep track of all panics</li>
<li>Exposes functions to query all panics (<a href="https://docs.rs/panik/0.1.1/panik/fn.panics.html"><code>panik::panics</code></a>) and check if a panic has occurred on any thread (<a href="https://docs.rs/panik/0.1.1/panik/fn.has_panicked.html"><code>panik::has_panicked</code></a>)</li>
</ul>
<p>The <a href="https://docs.rs/panik/">docs</a> include some basic examples, but I want to show here how the API fits into the code base it was designed for.</p>
<h3 id="example-in-context">Example in context</h3>
<p>Below is a cut-down snippet from the game engine's <code>main</code>. The game spends its whole runtime inside the context of <code>panik::run_and_handle_panics</code>, which boils down to installing a custom panic hook and a <code>catch_unwind</code>, which catches any panics on the main thread and prevents them from bubbling up to kill the program too soon.</p>
<div><pre><span></span><code><span>// ... initialize game state ....</span>

<span>// run the game inside panik's handler</span>
<span>let</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>panik</span>::<span>run_and_handle_panics</span><span>(</span><span>||</span><span> </span><span>{</span><span> </span><span>do_main</span><span>()</span><span> </span><span>});</span><span></span>

<span>let</span><span> </span><span>exit_code</span><span> </span><span>=</span><span> </span><span>match</span><span> </span><span>result</span><span> </span><span>{</span><span></span>
<span>    </span><span>None</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span>
<span>        </span><span>// 1 or more panics occurred which have already been</span>
<span>        </span><span>// logged, nothing more to do</span>
<span>        </span><span>1</span><span></span>
<span>    </span><span>}</span><span></span>
<span>    </span><span>Some</span><span>(</span><span>_</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>0</span><span>,</span><span> </span><span>// no panics occurred</span>
<span>};</span><span></span>

<span>// ... optionally use panik::panics() to programatically access</span>
<span>//     panic messages, backtraces etc ...</span>

<span>// ... attempt to save any game data ...</span>

<span>std</span>::<span>process</span>::<span>exit</span><span>(</span><span>exit_code</span><span>);</span><span></span>
</code></pre></div>


<p>Now that panics will be detected by the custom panic handler, we need a way to interrupt the main thread if a panic occurred on different thread, in order to gracefully exit. This is done in two places:</p>
<ul>
<li>During startup, while waiting for the world to be loaded/generated by worker threads</li>
<li>Every tick during gameplay</li>
</ul>
<p>The first was an early cause of annoyance; the game initially requests a radius of terrain around the player's position, then blocks with a timeout until the world is available. While the game is in an early state, there isn't much to do and world generation finishes quite quickly, but if something panics it will sit there and wait until the timeout has elapsed<sup id="fnref:5"><a href="#fn:5">5</a></sup>. That code now looks like this:</p>
<div><pre><span></span><code><span>pub</span><span> </span><span>fn</span> <span>block_until_world_loaded</span><span>(</span><span></span>
<span>    </span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span></span>
<span>    </span><span>timeout</span>: <span>Duration</span><span>,</span><span></span>
<span><span>    </span><span>bail</span>: <span>&amp;</span><span>impl</span><span> </span><span>Fn</span><span>()</span><span> </span>-&gt; <span>bool</span><span>,</span><span></span>
</span><span>)</span><span> </span>-&gt; <span>Result</span><span>&lt;</span><span>SlabLocation</span><span>,</span><span> </span><span>TerrainSourceError</span><span>&gt;</span><span> </span><span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>end_time</span><span> </span><span>=</span><span> </span><span>Instant</span>::<span>now</span><span>()</span><span> </span><span>+</span><span> </span><span>timeout</span><span>;</span><span></span>
<span>    </span><span>loop</span><span> </span><span>{</span><span></span>
<span><span>        </span><span>if</span><span> </span><span>bail</span><span>()</span><span> </span><span>{</span><span></span>
</span><span><span>            </span><span>break</span><span> </span><span>Err</span><span>(</span><span>TerrainSourceError</span>::<span>Bailed</span><span>);</span><span></span>
</span><span><span>        </span><span>}</span><span></span>
</span>
<span>        </span><span>let</span><span> </span><span>this_timeout</span><span> </span><span>=</span><span> </span><span>{</span><span></span>
<span>            </span><span>let</span><span> </span><span>now</span><span> </span><span>=</span><span> </span><span>Instant</span>::<span>now</span><span>();</span><span></span>
<span>            </span><span>if</span><span> </span><span>now</span><span> </span><span>&gt;=</span><span> </span><span>end_time</span><span> </span><span>{</span><span></span>
<span>                </span><span>break</span><span> </span><span>Err</span><span>(</span><span>TerrainSourceError</span>::<span>TimedOut</span><span>);</span><span></span>
<span>            </span><span>}</span><span></span>
<span>            </span><span>let</span><span> </span><span>left</span><span> </span><span>=</span><span> </span><span>end_time</span><span> </span><span>-</span><span> </span><span>now</span><span>;</span><span></span>
<span>            </span><span>left</span><span>.</span><span>min</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>1</span><span>)).</span><span>max</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>3</span><span>))</span><span></span>
<span>        </span><span>};</span><span></span>

<span>        </span><span>// ... block for `this_timeout` and return `Ok(res)`</span>
<span>        </span><span>//     if a result is returned ...</span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>
</code></pre></div>


<p>The lines of interest are highlighted - a function pointer is passed in which triggers an early exit if it returns true when called with no arguments. The limit on the timeout and the <code>loop</code> mean that <code>bail()</code> will be called periodically. As you've probably guessed, a function that fits that function signature is <code>panik::has_panicked</code>! </p>
<p>The other place this is checked is every tick in the game loop. As soon as a panic is detected the loop is broken with an error:</p>
<div><pre><span></span><code><span>// core game loop</span>
<span>loop</span><span> </span><span>{</span><span></span>
<span>        </span><span>if</span><span> </span><span>panik</span>::<span>has_panicked</span><span>()</span><span> </span><span>{</span><span></span>
<span>            </span><span>debug</span><span>!</span><span>(</span><span>"breaking out of loop due to panics"</span><span>);</span><span></span>
<span>            </span><span>break</span><span> </span><span>Exit</span>::<span>Stop</span><span>;</span><span></span>
<span>        </span><span>}</span><span></span>

<span>        </span><span>// ... tick and render ...</span>
<span>}</span><span></span>
</code></pre></div>


<p>That's it! The API is pretty simple and easy enough to integrate into a code base. </p>
<h3 id="before-after-comparison">Before/after comparison</h3>
<p>This is what a panic in a worker thread during world initialisation looked like before. The panic and backtrace is mixed in with other logs, and the game window was unresponsive for 30 seconds before dying.</p>
<div><pre><span></span><code><span>...</span>
<span>  000000 DEBG populating chunk with slabs</span>
<span><span>  00000thread '0wrld-worker-0' panicked at 'intentional panic!!11!', /home/.../name-needed/game/world/src/loader/finalizer.rs:84: 21</span>
</span><span>stack backtrace:</span>
<span><span>DEBG removed 0 nodes in slab range, upper: SlabIndex(4), lower: SlabIndex(-1), removed: 0</span>
</span><span><span>  000000 DEBG added 960 edges and 256 nodes, area: ChunkArea { slab: SlabIndex(1), area: SlabAreaIndex(1) }, nodes: 256, edges: 960</span>
</span><span>   0: std::panicking::begin_panic</span>
<span>   1: world::loader::finalizer::SlabFinalizer&lt;C&gt;::finalize::</span><span>{{</span><span>closure</span><span>}}</span><span></span>
<span>   2: &lt;core::future::from_generator::GenFuture&lt;T&gt; as core::future::future::Future&gt;::poll</span>
<span>   ... lots of frames omitted ...</span>
<span>  45: tokio::runtime::blocking::pool::Spawner::spawn_thread::</span><span>{{</span><span>closure</span><span>}}</span><span></span>
<span>note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.</span>
<span>... 30 seconds later ...</span>
<span>000000 CRIT critical error, error: Timed out</span>
<span>000000 CRIT more detail, error: TimedOut</span>
<span>000000 INFO waiting 2 seconds to allow other threads to finish logging, seconds: 2</span>
<span>000000 INFO exiting cleanly, code: 1</span>
</code></pre></div>


<p>But now, with the power of <code>panik</code>:</p>
<div><pre><span></span><code><span>  000000 DEBG populating chunk with slabs</span>
<span>000000 ERRO handling panic on thread ThreadId(9) (wrld-worker-3): 'intentional panic!!11!'</span>
<span><span>000000 WARN panic occurred in another thread, swallowing unpanicked result: Err(Error(Bailed))</span>
</span><span><span>000000 ERRO 1 threads panicked, count: 1</span>
</span><span>000000 CRIT panic on thread "ThreadId(9) (wrld-worker-3)": "intentional panic!!11!"</span>
<span>   0: panik::register_panic</span>
<span>   1: panik::GlobalStateGuard::init::</span><span>{{</span><span>closure</span><span>}}</span><span></span>
<span>   ... lots of frames omitted ...</span>
<span>  62: __GI___clone</span>
<span>000000 INFO waiting 2 seconds to allow other threads to finish logging, seconds: 2</span>
<span>000000 INFO exiting cleanly, code: 1</span>
</code></pre></div>


<p>The logs are clear and not intermingled, and the game exited immediately. Much better!</p>
<h2 id="watch-out-for-async-runtimes">Watch out for async runtimes</h2>
<p>Since moving my manual thread pools to <a href="https://crates.io/crates/tokio">tokio</a>, panics have become more of a pain, especially unconditional panics when I forget to remove a <code>todo!()</code>. The runtime's behaviour of auto-spawning new threads to replace the dead ones doesn't lead to pretty results, and I'm sure the following log speaks for itself:</p>
<div><pre><span></span><code><span>...</span>
<span>000000 ERRO handling panic on thread ThreadId(7) (wrld-worker-1): …</span></code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://domwillia.ms/panik/">https://domwillia.ms/panik/</a></em></p>]]>
            </description>
            <link>https://domwillia.ms/panik/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277143</guid>
            <pubDate>Fri, 26 Feb 2021 17:17:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Documentation Improvements in KDE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26277094">thread link</a>) | @ognarb
<br/>
February 26, 2021 | https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/ | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>There was many changes over the last few months in KDE developer
documentation tooling. The hope is to make KDE development easier
to both newcomers but also long-time KDE contributors to use
KDE technologies to build cool stuff.</p><h2 id="api-documentation">Api documentation</h2><p>The tooling for our generated documentation tooling improved. First
of all, KApiDox got a new theme with a cleaner appearance and a
better dark theme. But the improvement goes beyond just theming.</p><figure><a href="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/api.png" data-size="1908x891"><img srcset="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/api_hu75ec079396b4d1e999137d12765b0477_152990_700x0_resize_box_2.png 700w, https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/api_hu75ec079396b4d1e999137d12765b0477_152990_1824x0_resize_box_2.png 1824w" src="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/api.png" width="1908" height="891" loading="lazy" alt="API.kde.org new look"></a><figcaption>API.kde.org new look</figcaption></figure><p><a href="https://invent.kde.org/sdk/doxyqml" target="_blank" rel="noopener">Doxyqml</a>, our documentation
bridge between QML and doxygen, got various improvements, thanks
to Olaf Mandel and Lasse Lopperi. Now QML enums are supported and
the lexer/parser got various bug fixes.</p><p>Speaking of QML documentation, the Kirigami API documentation was
improved and now uses more correctly <code>@inherit</code> tags and
<code>@property</code> tags. There is still room for improvements, but the
current state is already a lot better. Most Components are now
showing all their properties correctly and the type of the
property is correct. (<a href="https://invent.kde.org/frameworks/kirigami/-/commit/6ce80224a9fe46216cf47d29458e16f3519ec693" target="_blank" rel="noopener">kirigami!239</a>)</p><p>Another improvement is that the generated Kirigami documentation
now shows more accurate names: e.g. <code>Kirigami.Page</code> instead of
<code>org::kde::kirigami::Page</code>. This makes it easier to read and
navigate the documentation.</p><p>There was also a bit of background work inside KApiDox, Jannet
added support for QDoc, allowing to use QDoc as an alternative
to Doxygen. This might be a better solution for generating
documentation for projects with a lot of QML.</p><h2 id="high-level-documentation">High level documentation</h2><p>Since <a href="https://develop.kde.org/" target="_blank" rel="noopener">develop.kde.org</a> was announced
back in September 2020 just before Akademy, it received a steady
stream of updates. In terms of visuals, Jannet replaced the left
sidebar with a better-looking one.</p><p>A Doxygen integration was also added in the Hugo based website,
allowing to link to the API documentation in an easy way (e.g.
<code>[Kirigami.Page](docs:kirigami2;Page)</code>).</p><figure><a href="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/doxapi.png" data-size="438x211"><img srcset="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/doxapi_hu1dd9834c8070fdaaebb60963fde23a42_20357_700x0_resize_box_2.png 700w, https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/doxapi_hu1dd9834c8070fdaaebb60963fde23a42_20357_1824x0_resize_box_2.png 1824w" src="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/doxapi.png" width="438" height="211" loading="lazy" alt="Link to API documentation"></a><figcaption>Link to API documentation</figcaption></figure><p>The Plasma documentation was massively improved. Zren moved his
excellent tutorial about creating Plasma Widgets to
<a href="https://develop.kde.org/docs/plasma/widget/" target="_blank" rel="noopener">/docs/plasma/widget</a>.
I also moved the <a href="https://develop.kde.org/docs/plasma/scripting/" target="_blank" rel="noopener">Plasma Desktop Scripting tutorial</a>
and the <a href="https://develop.kde.org/docs/plasma/theme/" target="_blank" rel="noopener">Plasma Theme Tutorial</a>
from techbase to develop. This was a good occasion to update them to a
more recent version of Plasma since some parts were from the early
days of Plasma 5 and a few bits from KDE4 remained.</p><p>Concerning the Framework documentation, most of the tutorials from
the Framework book, that was written a few years ago to develop.
Same as the Plasma documentation, I used this opportunity to update
the documentation and remove any mentions of deprecated APIS. I
also did the same for most of the old tutorials from <a href="https://techbase.kde.org/" target="_blank" rel="noopener">techbase</a>.</p><figure><a href="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/features.png" data-size="1239x831"><img srcset="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/features_huf04e7f133efae172b4c5dc22c5d6a5ed_66521_700x0_resize_box_2.png 700w, https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/features_huf04e7f133efae172b4c5dc22c5d6a5ed_66521_1824x0_resize_box_2.png 1824w" src="https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/features.png" width="1239" height="831" loading="lazy" alt="List of features oriented tutorials"></a><figcaption>List of features oriented tutorials</figcaption></figure><p>Tobias Fella imported the old <a href="https://develop.kde.org/docs/d-bus/" target="_blank" rel="noopener">DBus tutorial</a>
from techbase and David Redondo wrote a tutorial about how to
<a href="https://develop.kde.org/docs/sensor-faces/" target="_blank" rel="noopener">create sensor faces</a>
for the new Plasma Monitor.</p><p><img src="https://develop.kde.org/docs/sensor-faces/images/config.png" alt="Custom sensor faces"></p><p>Finally, Clau Cambra wrote a tutorial for getting started in
<a href="https://develop.kde.org/docs/kirigami/" target="_blank" rel="noopener">Kirigami</a>. The tutorial
will guide you into creating a countdown counter using Kirigami
and QML. This work is part of its Season of KDE project.</p><p>If you enjoy my work, you can sponsor me on <a href="https://liberapay.com/Carl" target="_blank" rel="noopener">Liberapay</a>.</p></section><div><h2>Comments</h2><p>You can use your Mastodon account to reply to this <a href="https://linuxrocks.online/@carl/105798477266183469">post</a>.</p><p><a href="https://linuxrocks.online/interact/105798477266183469?type=reply">Reply</a></p></div></div>]]>
            </description>
            <link>https://carlschwan.eu/2021/02/26/documentation-improvement-in-kde/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26277094</guid>
            <pubDate>Fri, 26 Feb 2021 17:12:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grouparoo: Declarative Data Sync]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26276917">thread link</a>) | @bleonard
<br/>
February 26, 2021 | https://www.grouparoo.com/blog/declarative-data-sync | <a href="https://web.archive.org/web/*/https://www.grouparoo.com/blog/declarative-data-sync">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent"><div><p>Developers have been using the <a href="https://www.grouparoo.com/" target="_blank" rel="nofollow noopener noreferrer">Grouparoo</a> UI to set up automated data movement from their databases to Mailchimp, Marketo, Salesforce, and <a href="https://www.grouparoo.com/integrations" target="_blank" rel="nofollow noopener noreferrer">more</a>. While having these integrations already written for them saved plenty of time, there was something they missed: their normal developer workflow.</p><p>Grouparoo now supports declarative data models and integrations to continuously sync your data to all of your cloud-based tools. You manage data sync just like you would any other part of your stack. You test the configuration, check it into git, run it on CI, review, merge, and deploy.</p><p>Using the declarative configuration, Grouparoo does the heavy lifting of building profiles from your customer data sources, segmenting them into groups, and syncing the results to destination tools. Everyone wins when engineers can move faster and with more confidence.</p><p><iframe width="560" height="315" src="https://www.youtube.com/embed/kQ789gMXJB8?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><p>Here is the <a href="https://github.com/grouparoo/app-example-config" target="_blank" rel="nofollow noopener noreferrer">example app</a> from the video.</p><h2 id="data-sync-framework"><a href="#data-sync-framework">Data Sync Framework</a></h2><p>If you have developed Node apps before, you will have a pipeline up and running in minutes. The whole app is just a <code>package.json</code> file and the declarative configuration. If you are new to Node, we have lots of helpers to get you going.</p><p>Here is how you declare your pipeline:</p><ul><li><a href="https://www.grouparoo.com/docs/installation#step-2-pick-an-installation-method" target="_blank" rel="nofollow noopener noreferrer">Get</a> our <code>grouparoo</code> command line tool via npm and <code>init</code> a new Grouparoo project</li><li><a href="https://www.grouparoo.com/docs/installation/plugins#installing-a-plugin" target="_blank" rel="nofollow noopener noreferrer">Install</a> plugins for the connections you need (Postgres, Mailchimp, Salesforce, etc.).</li><li>Generate an <a href="https://www.grouparoo.com/docs/config/apps/community" target="_blank" rel="nofollow noopener noreferrer">App</a> with connection information (Postgres database, etc).</li><li>Generate a <a href="https://www.grouparoo.com/docs/config/sources/community" target="_blank" rel="nofollow noopener noreferrer">Source</a> with <a href="https://www.grouparoo.com/docs/config/properties/community" target="_blank" rel="nofollow noopener noreferrer">Properties</a> (id, email, first_name from users table) to create Profiles.</li><li>Generate calculated <a href="https://www.grouparoo.com/docs/config/groups/community" target="_blank" rel="nofollow noopener noreferrer">Groups</a> of Profiles (High Value Users) based on Profile Property values.</li><li>Generate a <a href="https://www.grouparoo.com/docs/config/destinations/community" target="_blank" rel="nofollow noopener noreferrer">Destination</a> and map the data to it (sync email, first_name, and group membership to Mailchimp)</li></ul><p>Now, you can call <code>grouparoo run</code> to test the data <a href="https://www.grouparoo.com/docs/running" target="_blank" rel="nofollow noopener noreferrer">sync</a>, make expectation or snapshot <a href="https://www.grouparoo.com/docs/running/testing" target="_blank" rel="nofollow noopener noreferrer">tests</a>, and <a href="https://www.grouparoo.com/docs/deployment" target="_blank" rel="nofollow noopener noreferrer">deploy</a> your application so it’s always running and looking for new data to sync.</p><h2 id="zooming-out"><a href="#zooming-out">Zooming Out</a></h2><p>Businesses need data in their tools to be effective because success in marketing, sales, and support is data-driven with personalization, segmentation, and timeliness. We want these teams to be empowered to create great customer experiences.</p><p>Unfortunately, integrations are not fun to build and are tricky to get right. There are edge cases around rate limiting and data formatting. Engineers don’t tend to use the tools being integrated, so it’s hard to know what “right” even looks like. There are no clear patterns to follow. Consequently, data sync infrastructure is often brittle and unloved.</p><p>Open source is great because it tends to take hard problems and solve them for everyone. Grouparoo solves the data sync problem by making it 10x easier to build and maintain by allowing developers to stop worrying about the data pipes and focus on declaring the right definition of what is valuable.</p><div><p><img alt="Declaratively sync data to Mailchimp" src="https://www.grouparoo.com/posts/declarative-data-sync/declarative-sync.png" width="600" height="315"></p></div></div></div></div>]]>
            </description>
            <link>https://www.grouparoo.com/blog/declarative-data-sync</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276917</guid>
            <pubDate>Fri, 26 Feb 2021 17:00:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why northern Europe is so indebted]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276869">thread link</a>) | @kome
<br/>
February 26, 2021 | https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/ | <a href="https://web.archive.org/web/*/https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="section-5-61"><div><div id="new_columns-6-61"><div id="div_block-7-61"><p><span id="span-26-61">
<p>You might think the US would be world champion of household debt, yet the highest private indebtment has always been in the Nordic countries. Debt, however, takes different forms, writes <strong>Martino Comelli</strong>. In Scandinavia, inclusive welfare systems make debt into an investment. Elsewhere, gerontocratic welfare and consumer credit can become a burden</p>
<h2>Debt and welfare: a trade-off?</h2>
<p>The economic crisis of 2007–2008 put household debt in the spotlight. <strong><a href="https://en.wikipedia.org/wiki/Financial_crisis_of_2007%E2%80%932008">A common narrative</a></strong> was that cheap credit fuelled a house price bubble in the US. The financial industry sold derivatives based on those debts and many European banks who bought those products went belly up, allowing the crisis to spread across the Atlantic.</p>
<p>Debt, and in particular, household debt, has been regarded with suspicion ever since. Many scholars argue that the rise of household debt was caused by welfare retrenchment, suggesting a trade-off between welfare and debt. A lack of welfare was compensated by private leveraging. Other scholars pointed out that many governments were pushing for asset-based welfare – like buying housing as a form of private welfare – encouraged by steadily rising house prices in the years preceding the crash.</p>
<figure><img loading="lazy" width="683" height="776" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1.png" alt="" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1.png 683w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1-264x300.png 264w" sizes="(max-width: 683px) 100vw, 683px"><figcaption>Figure 1: Quantity of household debt in OECD countries</figcaption></figure>
<p>Yet empirical data suggests that the welfare-debt trade-off may be mistaken. Curiously, the highest indebtment ratio in the OECD was, and is, in northern European countries such as Denmark, Norway, Sweden and the Netherlands. These are the countries with the most far-reaching welfare programmes, and known to be fiscally responsible. Clearly, the welfare-debt trade-off theory needs a rethink.</p>
<h2>Private debt, public virtues: on the age-orientation of welfare</h2>
<p>Is it, then, a complementary relationship? Generous welfare provides security, encouraging people to borrow more. But this interpretation does not fly either. Many European countries have generous welfare – France for example, has higher social spending than Denmark – but nowhere near the level of household debt of the Nordic countries.</p>
<p><strong><a href="https://doi.org/10.1080/02732173.2021.1875088">My research on the relations between welfare and household debt</a> </strong>offers a novel explanation of the welfare-debt conundrum. There is no trade-off between private debt and welfare, nor is there a complementary relation. What matters is where the welfare money is spent and how. It isn’t necessarily about the quantity of spending, but about its direction.</p>
<blockquote><p>While mortgages are a marker of privilege, another common type of debt, consumer credit, is often a marker of need</p></blockquote>
<p>Most welfare spending is concentrated on older generations, particularly retired people. According to <strong><a href="https://en.wikipedia.org/wiki/Life-cycle_hypothesis">Franco Modigliani</a>'s life-cycle <a href="https://en.wikipedia.org/wiki/Life-cycle_hypothesis">hypothesis</a></strong>, debt is linked to one's stage in life. People take on debt when young because their income is low but their expenses (housing, children, leisure) high – and they pay this debt off as they age.</p>
<p>Countries that not only provide social help for the elderly, but counterbalance that with spending and services for the young and economically active, tend to have higher private debt (see Figure 2). In particular, countries that spend on education and active labour market policies, and those which offer better protection for people in precarious jobs, have the highest levels of private debt.</p>
<p>Household debt is an unintended consequence of assuring a smoother transition to adulthood. In conservative continental European countries, however, despite high welfare spending, welfare is concentrated mostly on the elderly and on people with stable jobs. This discourages younger generations from taking risks, including mortgage debt.</p>
<figure><img loading="lazy" width="980" height="714" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2.png" alt="Figure 2. Quantity of household debt by the age orientation of welfare spending in OECD countries" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2.png 980w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2-300x219.png 300w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2-768x560.png 768w" sizes="(max-width: 980px) 100vw, 980px"><figcaption>Figure 2. Quantity of household debt by the age orientation of welfare spending in OECD countries.</figcaption></figure>
<p>Note: Figure 2 illustrates an inverse relationship between the elderly orientation of social spending (EBiSS, on the x axis), and the quantity of household debt as % of net disposable income (on the y axis). The EBiSS is a rate between social spending for the economically active (at the numerator) versus spending oriented toward the elderly (at the denominator). A higher value on the EBiSS index means that a greater share of social spending is going to the elderly.</p>
<h2>Consumer credit? The three worlds of debtfare capitalism</h2>
<p>Most of the debt in OECD countries is mortgage debt. While mortgages are a marker of privilege, another common type of debt, consumer credit, is often a marker of need.</p>
<p>If we consider consumer credit, the welfare-debt theory makes sense again. While consumer credit is more the exception than the norm in Europe, and almost absent in the Nordic countries, it is common in Anglo-liberal countries (UK, US and Canada) where it is used by families as a substitute for poor welfare provision.</p>
<figure><img loading="lazy" width="895" height="531" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3.png" alt="Figure 3. Clusters measures" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3.png 895w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3-300x178.png 300w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3-768x456.png 768w" sizes="(max-width: 895px) 100vw, 895px"><figcaption>Figure 3. Clusters measures</figcaption></figure>
<p>Figure 3 shows three main patterns of private debt/welfare configurations; what we call debtfare:</p>
<ol>
<li>In the Nordic / youth-oriented model, household debt is high, consumer credit is low, and the rate of young people Not in Education, Employment, or Training (NEET) is very low.</li>
<li>
<p>In conservative European countries such as Germany and Italy, there are a lot of NEETs, welfare is orientated toward the elderly, and there is little household debt or consumer credit.</p>
</li>
<li>
<p>In Anglo-liberal countries such as the UK, US and Canada, consumer credit is high, and so is overall debt. But it is not as high as in the Nordic countries, where the share of NEETs is remarkably high, and most welfare is oriented toward the elderly.</p>
</li>
</ol>
<p>Household financialisation, then, follows different paths and patterns. Both liberal and conservative welfare is gerontocratic, and they have a high level of NEETs, but while the former is oriented toward a market solution to inequality (more debt), the latter discourages any form of risk taking.</p>
<p>So, while paying attention to debt is important, it shouldn’t be the only lesson of the 2008 crisis. Further attention should be paid to the macro-sociological conditions that give debt different meanings: inclusive welfare can make debt into an investment, but gerontocratic welfare can make debt a burden.</p>
</span></p><p>This article presents the views of the author(s) and not necessarily those of the ECPR or the Editors of <i>The Loop</i>.</p><div id="div_block-246-61"><p><img id="image-247-61" alt="" src="https://theloop.ecpr.eu/wp-content/uploads/2020/09/ECPR-tag-icon.svg" loading="lazy"></p></div></div></div></div></section></div>]]>
            </description>
            <link>https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276869</guid>
            <pubDate>Fri, 26 Feb 2021 16:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Integrating Rust and C++ in Firefox]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276846">thread link</a>) | @ibraheemdev
<br/>
February 26, 2021 | https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/ | <a href="https://web.archive.org/web/*/https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This post was originally drafted in August 2018, but I never got around to finishing it. As such, parts of its framing (e.g. the focus on bindgen) are outdated, given the relative infancy of the interop space at the time. I was recently told that the post is still useful in this form so I decided to finish and publish it anyway, while attempting to mark outdated things as such when I notice them. Everything after the allocators section was written near the time of publication.</em></p>

<p>In 2017 I worked on the <a href="https://hacks.mozilla.org/2017/08/inside-a-super-fast-css-engine-quantum-css-aka-stylo/">Stylo</a> project, uplifting Servo’s CSS engine (“style system”) into Firefox’s browser engine
(“Gecko”). This involved a <em>lot</em> of gnarly FFI between Servo’s Rust codebase and Firefox’s C++ codebase. There were a
lot of challenges in doing this, and I feel like it’s worth sharing things from our experiences.</p>

<p>If you’re interested in Rust integrations, you may find <a href="https://www.youtube.com/watch?v=x9acx2zgx4Q">this talk by Katharina on Rust - C++ FFI</a>, and <a href="https://hsivonen.fi/modern-cpp-in-rust/">this blog post by Henri on integrating encoding-rs into Firefox</a> useful as well.</p>

<h2 id="who-is-this-post-for">Who is this post for?</h2>

<p>So, first off the bat, I’ll mention that when integrating Rust into a C++ codebase, you
want to <em>avoid</em> having integrations as tight as Stylo. Don’t do what we did; make your Rust
component mostly self-contained so that you just have to maintain something like ten FFI functions
for interacting with it. If this is possible to do, you should do it and your life will be <em>much</em> easier. Pick a clean API boundary, define a straightforward API, use cbindgen or bindgen if necessary without any tricks, and you should be good to go.</p>

<p>That said, sometimes you <em>have</em> to have gnarly integrations, and this blog post is for those use cases.
These techniques mostly use bindgen in their examples, however you can potentially use them with hand-rolled bindings or another tool as well. If you’re at this level of complexity, however, the potential for mistakes in the hand-rolled bindings is probably not worth it.</p>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> is probably a better tool for many of the use cases here, though many of the techniques still transfer.</em></p>

<h2 id="what-was-involved-in-stylos-ffi">What was involved in Stylo’s FFI?</h2>

<p>So, what made Stylo’s FFI so complicated?</p>

<p>It turns out that browsers are quite monolithic. You can split them into vaguely-defined components, but
these components are still tightly integrated. If you intend to replace a component, you may need to
make a jagged edge of an integration surface.</p>

<p>The style system is more self-contained than other parts, but it’s still quite tightly integrated.</p>

<p>The main job of a “style system” is to take the CSS rules and DOM tree, and run them through “the cascade”<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
with an output of “computed styles” tagged on each node in the tree. So, for example, it will take a document like
the following:</p>

<div><div><pre><code><span>&lt;style </span><span>type=</span><span>"text/css"</span><span>&gt;</span>
    <span>body</span> <span>{</span>
        <span>font-size</span><span>:</span> <span>12px</span><span>;</span>
    <span>}</span>
    <span>div</span> <span>{</span>
        <span>height</span><span>:</span> <span>2em</span><span>;</span>
    <span>}</span>
<span>&lt;/style&gt;</span>
<span>&lt;body&gt;</span>
    <span>&lt;div</span> <span>id=</span><span>"foo"</span><span>&gt;&lt;/div&gt;</span>

<span>&lt;/body&gt;</span>
</code></pre></div></div>

<p>and turn it into something like:</p>

<ul>
  <li><code>&lt;body&gt;</code> has a <code>font-size</code> of <code>12px</code>, everything else is the default</li>
  <li>the <code>div</code> <code>#foo</code> has a computed <code>height</code> of <code>24px</code> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">2</a></sup>, everything else is the default. It “inherits” the <code>font-size</code> from <code>&lt;body&gt;</code> as <code>12px</code></li>
</ul>

<p>From a code point of view, this means that Stylo takes in Gecko’s C++ DOM tree. It parses all the CSS,
and then runs the cascade on the tree. It stores computed styles on each element in a way that Gecko can read
very cheaply.</p>

<p>Style computation can involve some complex steps that require calling back into C++ code. Servo’s style system
is multithreaded, but Gecko is mostly designed to work off of a single main thread per process, so we need to
deal with this impedence mismatch.</p>

<p>Since the output of Stylo is C++-readable structs, Stylo needs to be able to read and write nontrivial C++
abstractions. Typical FFI involves passing values over a boundary, never to be seen again, however here we’re
dealing with persistent state that is accessed by both sides.</p>

<p>To sum up, we have:</p>

<ul>
  <li>Lots and lots of back-and-forth FFI</li>
  <li>Thread safety concerns</li>
  <li>Rust code regularly dealing with nontrivial C++ abstractions</li>
  <li>A need for nontrivial abstractions to be passed over FFI</li>
</ul>

<p>All of this conspires to make for some really complicated FFI code.</p>



<p>I’ll try to structure this so that the more broadly useful (and/or less gnarly) techniques come earlier in the post.</p>

<h2 id="the-basics-of-bindgen">The basics of bindgen</h2>

<p><a href="https://github.com/rust-lang-nursery/rust-bindgen/">Bindgen</a> is a tool that generates Rust bindings for structs and functions from the provided C or C++ header files. It’s often used for writing Rust bindings to existing C/C++ libraries, however it’s useful for integrations as well.</p>

<p>To use it for an integration, write a header file containing the functions your Rust code needs (referencing structs from other header files if necessary), and <a href="https://rust-lang-nursery.github.io/rust-bindgen/command-line-usage.html">run bindgen on it</a>. For some codebases, doing this once and
checking in the generate file suffices, but if your C++ code is going to change a lot, <a href="https://rust-lang-nursery.github.io/rust-bindgen/tutorial-1.html">run it as a build dependency instead</a>. Beware that this can adversely impact build times, since your Rust build now has a partial
C++ compilation step.</p>

<p>For large C++ codebases, pulling in a single header will likely pull in a <em>lot</em> of stuff. You should <a href="https://rust-lang.github.io/rust-bindgen/allowlisting.html">allowlist</a>, <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklist</a>, and/or mark things as <a href="https://rust-lang.github.io/rust-bindgen/opaque.html">opaque</a> to reduce the amount of bindings generated. It’s best to go the allowlisting route — give bindgen an allowlisted list of functions / structs to generate bindings for, and it will transitively generate bindings for any dependencies they may have. Sometimes even this will end up generating a lot, it’s sometimes worth finding structs you’re not using and marking them as opaque so that their bindings aren’t necessary. Marking something as opaque replaces it with an array of the appropriate size and alignment, so from the Rust side it’s just some bits you don’t care about and can’t introspect further.</p>

<p>Bindgen <a href="https://rust-lang-nursery.github.io/rust-bindgen/cpp.html"><em>does</em> support some C++ features</a> (you may need to pass <code>-x c++</code>). This is pretty good for generating bindings to e.g. templated structs. However, it’s not possible to support <em>all</em> C++ features here, so you may need to blocklist, opaqueify, or use intermediate types if you have some complicated C++ abstractions in the deps. You’ll typically get an error when generating bindings or when compiling the generated bindings, so don’t worry about this unless that happens.</p>

<p>Bindgen is <em>quite</em> configurable. Stylo has a <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">script</a> that consumes a <a href="https://searchfox.org/mozilla-central/source/layout/style/ServoBindings.toml">large toml file</a> containing all of the configuration.</p>

<h2 id="cbindgen">cbindgen</h2>

<p>We don’t use <a href="https://github.com/eqrion/cbindgen">cbindgen</a> in Stylo, but it’s used for Webrender. It does the inverse of what bindgen does: given a Rust crate, it generates C headers for its public <code>extern "C"</code> API. It’s also quite configurable.</p>

<h2 id="cxx">cxx</h2>

<p><a href="https://github.com/dtolnay/cxx">cxx</a> is the cool new hotness in 2021, which kind of approaches the problem from both sides, enabling you to write Rust bindings for C++ and C++ bindings for Rust. It’s definitely worth checking out, a lot of the things that are hard to make work with bindgen are trivial in cxx. For example, it automatically figures out what types need to be opaque, it automatically converts between <code>&amp;T</code> and <code>T*</code> across FFI, and it is overall more targeted for the use case of an FFI layer where Rust and C++ both call each other.</p>

<h2 id="bindgen-aided-c-calling-rust">Bindgen-aided C++ calling Rust</h2>

<p>So bindgen helps with creating things for Rust to call and manipulate, but not in the opposite direction. cbindgen can help here, but I’m not sure if it’s advisable to have <em>both</em> bindgen and cbindgen operating near each other on the same codebase.</p>

<p>In Stylo we use a bit of a hack for this. Firstly, all FFI functions defined in C++ that Rust calls are declared in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">one file</a>, and are all named <code>Gecko_*</code>. Bindgen supports regexes for things like allowlisting, so this naming scheme makes it easy to deal with.</p>

<p>We also declare the FFI functions defined in Rust that C++ calls in <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindingList.h">another file</a>, named <code>Servo_*</code>. They’re also all <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/glue.rs">defined in one place</a>.</p>

<p>However, there’s nothing ensuring that the signatures match! If we’re not careful, there may be mismatches, causing bad things to happen at link time or runtime. We use a small <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/build.rs">autogenerated</a> <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/ports/geckolib/tests/servo_function_signatures.rs">unit test</a> to ensure the validity of the signatures.</p>

<p>This is especially important as we do things like type replacement, and we need tests to ensure that the rug isn’t pulled out from underneath us.</p>

<h2 id="type-replacing-for-fun-and-profit">Type replacing for fun and profit</h2>

<p>Using <a href="https://rust-lang.github.io/rust-bindgen/blocklisting.html">blocklisting</a> in conjunction with the <code>--raw-line</code>/<code>raw_line()</code> flag, one can effectively ask bindgen to “replace” types. Blocklisting asks bindgen not to generate bindings for a type, however bindgen will continue to generate bindings <em>referring</em> to that type if necessary. (Unlike opaque types where bindgen generates an opaque binding for the type and uses it everywhere). <code>--raw-line</code> lets you request bindgen to add a line of raw rust code to the file, and such a line can potentially define or import a new version of the type you blocklisted. Effectively, this lets you replace types.</p>

<p>Bindgen generates unit tests ensuring that the layout of your structs is correct (run them!), so if you accidentally replace a type with something incompatible, you will get warnings at the struct level (functions may not warn).</p>

<p>There are various ways this can be used:</p>

<h3 id="safe-references-across-ffi">Safe references across FFI</h3>

<p><em>Note from 2021: <a href="https://github.com/dtolnay/cxx">cxx</a> does this automatically</em></p>

<p>Calling into C++ (and accepting data from C++) is unsafe. However, there’s no reason we should have to worry about this more than we have to. For example, it would be nice if accessor FFI functions – functions which take a foreign object and return something from inside it –  could use lifetimes. It would be even nicer if nullability were represented on the FFI boundary so that you don’t miss null checks, and can assume non-nullness when the C++ API is okay with it.</p>

<p>In Stylo, we have lots of functions like the following:</p>

<div><div><pre><code><span>RawGeckoNodeBorrowedOrNull</span> <span>Gecko_GetLastChild</span><span>(</span><span>RawGeckoNodeBorrowed</span> <span>node</span><span>);</span>
</code></pre></div></div>

<p>which bindgen translates to:</p>

<div><div><pre><code><span>extern</span> <span>"C"</span> <span>{</span>
    <span>fn</span> <span>Gecko_GetLastChild</span><span>(</span><span>x</span><span>:</span> <span>&amp;</span><span>RawGeckoNode</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;&amp;</span><span>RawGeckoNode</span><span>&gt;</span><span>;</span>   
<span>}</span>
</code></pre></div></div>

<p>Using the <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/servo/components/style/build_gecko.rs">bindgen build script</a> on a provided <a href="https://searchfox.org/mozilla-central/rev/819cd31a93fd50b7167979607371878c4d6f18e8/layout/style/ServoBindings.toml#648-671">list of borrow-able types</a>, we’ve told bindgen that:</p>

<ul>
  <li><code>FooBorrowedOrNull</code> is actually <code>Option&lt;&amp;Foo&gt;</code></li>
  <li><code>FooBorrowed</code> is actually <code>&amp;Foo</code></li>
</ul>

<p><code>Option&lt;&amp;Foo&gt;</code> <a href="https://doc.rust-lang.org/nomicon/repr-rust.html">is represented …</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/">https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/</a></em></p>]]>
            </description>
            <link>https://manishearth.github.io/blog/2021/02/22/integrating-rust-and-c-plus-plus-in-firefox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276846</guid>
            <pubDate>Fri, 26 Feb 2021 16:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Game Quotes – The best Quotes from your favorite Video Games]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26276805">thread link</a>) | @Kovah
<br/>
February 26, 2021 | https://game-quotes.com/en | <a href="https://web.archive.org/web/*/https://game-quotes.com/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                        <div>
                    <div data-is-blurred=""><div>
        <p>V about a Cyberpsycho:</p>
        <p>Guess even pneumatic arms can't lift morale in a toxic workplace.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Takemura:</p>
        <p>Sushi in Night City...? Sounds like suicide. And somehow disrespectful.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>V, Ozob:</p>
        <p>V: Doesn'T it bother you?<br>Ozob: Waht?<br>V: The grenade. You know, the one on your face?<br>Ozob: Eh, you get used to it. I just gotta be carefull not to pull the pin when I wanna pick my nose.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Takemura:</p>
        <p>The wider the smile, the bigger the lies.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Both Sides, now Quest Description:</p>
        <p>You ever hear the saying "No good deed goes unpunished"? You hold your hand out to someone, you get bitten. You help a poor soul in need, you get fleeced for all you're worth. Save someone's life? Fill in the blank.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>A tech corporation acting unethically? Sounds out of character, but let's investigate anyway.</p>
            </div>
    </div>
                            <div><p>Get rid of password stress. Forever. <a href="https://www.tkqlhce.com/click-100347502-13868703">With NordPass</a>.</p>
    <p>Store passwords in a single place and log in to your favorite websites with a click. With NordPass, access your login credentials on any device, even when you’re offline.</p></div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>I'll give you the bad news first: One of your operatives has been kidnapped. Also, there's no good news.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>There it is. Time to do your "destroying-other-people's-property" thing.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Player, Bagley:</p>
        <p>Player: You're telling me that a gambling addict turned down free money? It doesn't sum up.<br>Bagley: You're right. A gambling addict making a bad life choice? Ooh, the mystery! You had better talk to the friend if you want to crack this one.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>So he tried to take on a criminal organization with his bare hands, and got himself in trouble?<br>My, who could have seen that coming.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Bagley:</p>
        <p>You lived! But you will die someday. Best to make peace with that now.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Johnny to Alt:</p>
        <p>What, smoking after sex not Zen enough for you? We gotta rewrite "The Art of War", too?</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>The Hard Reset Approacheth:</p>
        <p>The boys have prepared everything and found me a lamb. Blood will course through the fiberoptics, swirling and blending with the digital, opening the gates of the abyss. Death within arm's reach, the metallic taste of his scythe on my tongue, I will tug at the tangled cables of Fate. A hard reset, a blue screen, a brain reformatted... I'm ready. Luck be with me.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Johnny:</p>
        <p>Corpo or not, without chrome we all look like the same idiotic, bullet-riddled sacks of meat.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>V:</p>
        <p>Didn't go through hell and back just to stand in front of a door.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Meredith Stout:</p>
        <p>Sometimes two people find themselves at the wrong place at the right time.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Review "Bloody Bout VII" - What went wrong:</p>
        <p>Just when we thought Macroware was done putting out unfinished games, we get this piping hot plate of spaghetti code. Frankly, I don't even know where to start. From the "story mode" which feels like it was cobbled together from the half-baked ideas of six writers working in different time zones, to the non-intuitive tutorials, to the ridiculous lag that had me up making a fresh cup of coffee between each punch, and finally to the head-scratching localization foul-ups. (Honestly, the dialogues make no sense in any language. What the hell were they originally written in? Swiss?)</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>01110100 01100101 01110011 01110100 - test:</p>
        <div>
            <p>11000101 10000001 01100001 01110011 01101001 01100011 01100101 00100000 01110000 01101111 01111010 01100100 01110010 01100001 01110111 01101001 01100001 01101010 11000100 10000101 00100000 01110111 01101001 01101100 01101011 01101001</p>
<p>Łasice pozdrawiają wilki</p>
<p>Weasels salute the wolves</p>

        </div>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Max Payne:</p>
        <p>The sun went down with practiced bravado. Twilight crawled across the sky, laden with foreboding. I didn’t like the way the show started. But they had given me the best seat in the house. Front row center.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Max Payne:</p>
        <p>They were all dead. The final gunshot was an exclamation mark to everything that had led to this point. I released my finger from the trigger. And then it was over.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Johnny to V:</p>
        <p>Not the brightest bulb on stage, are ya?</p>
            </div>
    </div>
                                <div data-is-blurred="1"><div>
        <p>V, Padre:</p>
        <p>V: So, Padre. You think Jackie's looking don upon us... from up there?<br>Padre: I believe he has met God, stood before him.<br>V: That's it?<br>Padre: I don't know if God left the meeting happy, but I'm pretty certain Jackie did.</p>
                    </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>V citing Ernest Hemingway:</p>
        <p>"When you go to war as a boy, you have a great illusion of immortality. Other people get killed, not you... Then, when you are badly wounded the first time, you lose that illusion."</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Saburo Arasaka:</p>
        <p>I have found that people lie, most often deceiving themselves. Not so the dead...<br>The dead are so very, very loud. And yet, lying is not in their nature.<br>It its so... humbling - to listen to the dead speak.</p>
            </div>
    </div>
                                <div data-is-blurred=""><div>
        <p>Rogue, Johnny:</p>
        <p>Rogue: Johnny, remember the plan?<br>Johnny: Get the payload on the elevator, arm it, let gravity do its thing. Explosion rocks the foundation, tower crumbles - chaos, screaming, roll credits.</p>
            </div>
    </div>
                            <nav role="navigation" aria-label="Pagination Navigation">
        

        <div>
            <p>
                    Showing
                    <span>1</span>
                    to
                    <span>25</span>
                    of
                    <span>471</span>
                    results
                </p>

            
        </div>
    </nav>

    </div>
                </div></div>]]>
            </description>
            <link>https://game-quotes.com/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276805</guid>
            <pubDate>Fri, 26 Feb 2021 16:52:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[American Sign Language as a medium for poetry]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276773">thread link</a>) | @throw_away
<br/>
February 26, 2021 | https://jacket2.org/commentary/american-sign-language-medium-poetry | <a href="https://web.archive.org/web/*/https://jacket2.org/commentary/american-sign-language-medium-poetry">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
 <div>
    <div>
            <div>
                    <figure><img src="https://jacket2.org/sites/jacket2.org/files/imagecache/wide_main_column/asl.jpg" alt=" Peter Cook and Kenny Lerner of the Flying Words project performing ASL poetry (" title=" Peter Cook and Kenny Lerner of the Flying Words project performing ASL poetry (Jessica Munyon)"><figcaption> Peter Cook and Kenny Lerner of the Flying Words project performing ASL poetry (Jessica Munyon)</figcaption></figure>        </div>
        </div>
</div>
<div><p><em>for Joseph Castronovo &amp; Edward S. Klima, in memoriam</em></p><p>  [The great breakthrough resulting from a new signing poetry in Deaf Culture has been to call into question a poetics in which orality &amp; sounding are assumed to be the foundational bases of <em>all</em> poetic expression. That revelation goes back three decades &amp; more, recently &amp; notably presented in <em><a href="http://www.ucpress.edu/books/pages/9424.php">Signing the Body Poetic: Essays on American Sign Language Literature</a></em>, ed. by Dirksen L. Bauman, Jennifer L. Nelson, &amp; Heidi M. Rose (University of California   Press, 2006).&nbsp;Still closer to the present is an ASL-oriented web site, <em><a href="http://deafjam.org/links.html">Deaf Jam</a></em>, dedicated to a documentary film of that name, from which the first of the comments, below, is taken. The other two notes presented here represent my own early attempts to bring the poetry of sign into the ethnopoetics that I was promoting in the 1970s &amp; 1980s. They also coincide in a startling way with the exploration of an outsider poetry that has been one of the themes of <em>Poems &amp; Poetics </em>– a poetry distanced enough from the mainstream as to effect substantially our ideas about the nature of poetry itself. (J.R.)]</p></div>

<div><p><strong>THE SILENT LANGUAGE</strong><strong><br> </strong>“Pain” <em>for Joe Castronovo</em></p><p>  two fingers,<br> pointing,<br> nearly touch</p><p>  matching the pulse inside<br> the skull<br> a figure “8” explodes</p><p>  over the temples,<br> gentle movements of the mind<br> of words in air</p><p>  in silence:<br> do I learn to speak you?<br> can you <em>hear</em><em><br> </em><br> the way the lines weave,<br> barely<br> moving from the touch</p><p>  to vanish<br> as sounds do<br> writing frees itself</p><p>  from object-<br> hood<br> at last</p><p>  (1) ASL POETRY is a performance art form utilizing body language, rhythm and movement to create a three dimensional pictorial equivalent to oral poetry. The similarity of hand-shapes can act as alliteration, and using the same hand-shape repetitively works as rhyme. Visual Vernacular (a term and technique originated by Bernard Bragg) involves cinematic concepts. The technique involves references to close-ups, wide shots, images dissolving into other images as well as "cutting" back and forth between characters to show different points of view on a scene.</p><p>  <strong>HISTORY: From 1880 to 1960, American Sign Language Was Suppressed In The Schools And Went Underground, Until Statistics Showed That The Suppression Of Sign Language Was Detrimental To Learning For The Deaf.</strong><strong><br> </strong><br> Signed poetry grew out of a tradition of playing with the language in Deaf clubs throughout the country, where deaf individuals and their families and friends would congregate for entertainment and to socialize.</p><p>  ASL poetry has been described "as a kind of writing in space... a language in motion, and, like oral poetry, truly inseparable from its realization in performance." (Edward S. Klima and Ursula Bellugi, "Poetry Without Sound,” 1983)</p><p>  *******</p><p>  Translation for ASL poetry into a written or oral form involves crossing modalities. In ASL poetry the body is the text. It exists in performance or through a video recording, not on paper. Rhyming schemes are based on visual elements such as facial expression, movement, locations of the signs, and hand shapes. Therefore an oral or written translation of an ASL poem can only be an approximation of what is being expressed.</p><p>  (2) Regarding Ameslan [American Sign Language] poetry, you might check the<br> anthology <em>Symposium of the Whole</em> (edited by myself &amp; Diane Rothenberg) for the article "Poetry without Sound" by Edward S. Klima and Ursula Bellugi. Bellugi has done terrific work in this area &amp; early contacted me on the relation of signing poetry to the way in which I and others had been approaching oral poetry in the course of doing (so called) "total translation." I then published this piece in my magazine, <em>New Wilderness Letter</em> (a successor to the earlier <em>Alcheringa Ethnopoetics</em>) with my very strong sense that what was involved touched on a dimension of poetry that made pure oralism inadequate, however much we had then been (or continued to be) committed to a speech model. I made an attempt (around 1976/77) to work out an experimental approach to a total translation from Ameslan, collaborating with the deaf poet Joe Castronovo, who was himself a native signer. But circumstances got in the way &amp; we never followed through on it, although since then I've come on the work of performance poets like Peter Cook &amp; Kenny Learner composing &amp; performing in ASL &amp; have been hoping to see how much further it would go.</p></div>

<div><p>(3) POETRY WITHOUT SOUND. Even in its early, tentative stages, the signing poetry emerging as an aspect of the "culture of the deaf" challenges some of our cherished preconceptions about poetry and its relation to human speech. Ameslan (American Sign Language) represents, literally, a poetry without sound and, for its practitioners, a poetry without access to that experience of sound as voice that we've so often taken as the bedrock of all poetics and all language. In the real world of the deaf, then, language exists as a kind of writing in space and as a primary form of communication without reference to any more primary form of language for its validation. It is in this sense a realization of the ideogrammatic vision of a Fenollosa -- "a splendid flash of concrete poetry" -- but an ideogrammatic language truly in motion and, like oral poetry, truly inseparable from its realization in performance. (Ethnopoetic analogues -- for those who would care to check them out -- include Hindu and Tantric mudras, Plains Indian and Australian Aborigine sign languages, and Ejagham [southeastern Nigerian] "action writing": a history of human gesture languages that would enrich our sense of poetry and language, should we set our minds to it.) // The reader may also want to relate this piece to recent discourse about "written-oral dichotomies, etc., but the revelation of Ameslan, in that sense, isn't a denial of the powers of oral poetry but the creation of its possible and equally impermanent companion in performance. (J.R., from <em>Symposium of the Whole</em>, 1983)</p><p>  [See also the entry “<a href="http://poemsandpoetics.blogspot.com/2008/08/uncollected-poems-3-silent-language.html">Uncollected Poems (3): ‘The Silent Language’ with a note on poetry &amp; signing</a>” in <em>Poems &amp; Poetics</em>, August 30, 2008. And for those who want to pursue this further, a relevant online resource is <em><a href="http://dsdj.gallaudet.edu/">The Deaf Studies Digital Journal</a></em>, edited by Ben Bahan and Dirksen Bauman, with postings primarily in American Sign Language.]</p></div>
<p><span>July 20, 2015</span>
        </p> <!-- end of older_and_newer -->
    
        
  </div></div>]]>
            </description>
            <link>https://jacket2.org/commentary/american-sign-language-medium-poetry</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276773</guid>
            <pubDate>Fri, 26 Feb 2021 16:50:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Experience Offering an AppSumo Deal]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276635">thread link</a>) | @flancrest
<br/>
February 26, 2021 | https://formcake.com/blog/our-experience-offering-an-appsumo-deal | <a href="https://web.archive.org/web/*/https://formcake.com/blog/our-experience-offering-an-appsumo-deal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-fcf18e1c=""><p><a href="https://appsumo.com/">AppSumo</a>, for the uninitiated, is a tech-oriented deals site that specializes in offering its audience steep discounts - sometimes for life - on all sorts of SaaS (and other) products.</p>
<p>We here at Formcake just launched <a href="https://appsumo.com/marketplace-formcake/">our own AppSumo deal</a> and have enjoyed the process so far - but definitely have some tips for other prospects.</p>
<p>Starting with the expectations game.</p>
<h2 id="early-hopes">Early Hopes</h2>
<p>We found AppSumo as we were researching ideas for expanding our marketing reach. Once we looked more into it, we were also deeply intrigued by their emphasis on lifetime deals.</p>
<p>It sounds so counterintuitive! Limited benefit for the possibility of unlimited use. But it also felt <em>savvy</em> in way only certain companies (like us) could manage: We've built as smartly as possible to have a low cost-per-customer, we have an already-existing trial base we can market to, and we're the new, hungry kids on the mechanical Turkish block, willing to stretch ourselves for increased recognition.</p>
<p>And there are some sneaky benefits to the lifetime account strategy - it allows us to recoup LTV up-front that could otherwise have churned out before the $50 mark. It also puts paid advertising at least in the realm of possibility - a $50 sign-up is worth a higher CPC. And a lifetime customer is a lifetime champion - someone who has a vested interest in seeing the application grow in value.</p>
<p>So we were excited by the lifetime deal strategy and incredibly excited by the prospect of unleashing the AppSumo machine - especially their vaunted million-plus strong mailing list.</p>
<h2 id="reaching-out">Reaching Out</h2>
<p>We reached out tentatively, not knowing what to expect, a lot of the existing AppSumo literature on various blogs was either outdated or unhelpful.</p>
<p>We received an almost instant (&lt; five minutes) response. AppSumo runs a well-oiled machine!</p>
<p>The <strong>requirements for working with them</strong> were simple:</p>
<p>1) We would build a system where a code could be redeemed for an account with an AppSumo plan. We would give AppSumo 10,000 of these codes.  </p>
<p>2) They would take a (small, certain) percentage of the proceeds of their sale of each code, giving the majority to us.  </p>
<p>3) We needed to plan to be ready to man our support battle stations and make sure we could resolve any questions or bugs quickly and effectively. Once we went live with AppSumo, we could expect a torrent of responses.  </p>
<p>The plan would have to be something offered exclusively through AppSumo. We knew we wanted to commit to a lifetime deal, and that it should be a beefed-up version of our Developer Plan - but at a lower price than the annual version. We settled on the general stats of our Developer plan but with twice the monthly submission limit.</p>
<p>We were needless to say excited. We developed all the relevant infrastructure over a three-day weekend. AppSumo in their initial email said they could be ready to launch us as quickly as one to two days after we met all the requirements.</p>
<p>We ended up launching the next day.</p>
<h2 id="launch-and-post-launch">Launch and Post-Launch</h2>
<p>We launched, hoping for a torrent of traffic and signups.</p>
<p>We received a modest bump, less than ten new signups over the course of the first few days. But then we had a realization.</p>
<p>We'd been <a href="https://appsumo.com/marketplace-formcake/">listed in the marketplace</a> and surfaced in whatever searches were relevant on the AppSumo site, but to get to the next level - to unlock some real co-marketing - we needed to <strong>receive at least ten reviews</strong> with and average of four or more stars on our marketplace listing from Sumo-lings who had purchased our product.</p>
<p>This, of course, makes a ton of sense.</p>
<p>We needed to show AppSumo that we could both bring in some traffic based on the quality of our product, as well as please a customer based compromised of Sumo-lings, before they'd put their stamp of approval on it.</p>
<p>As you can see, we're still working our way towards those ten reviews!</p>
<p><img src="https://formcake.com/images/appsumo-formcake-marketplace.png" alt=""></p>
<p>Only four - but a strong four!</p>
<p>We also learned that <strong>after receiving 25 reviews</strong>, we could expect to unlock a new level of co-marketing and be featured in their storied million-subscriber newsletter.</p>
<h2 id="lessons-learned">Lessons Learned</h2>
<p>We had put so much time into finding and then preparing for our AppSumo launch, we didn't think enough about what we were bringing to the table. We saw the AppSumo launch as an end in itself, and not what should be the beginning of an entire series of marketing campaigns orchestrated on our end to drive traffic.</p>
<p>We also might have waited or otherwise worked to go into the campaign having a large free-tier account user base - having a larger base of free customers happy with the product who might jump at the opportunity of a lifetime deal could help us hit this early ten-review metric a lot quicker and easier.</p>
<p>Of course we're <em>slowly</em> learning (check out our beautiful banner done in AS colors by our talented developer-leader!) but still very much playing catch-up.</p>
<p>So take our advice - if you're going to work with AppSumo, you best be ready to pony up the traffic, show them you've reached a critical mass in your market so they can be confident you'll succeed in theirs.</p>
<h2 id="current-status">Current Status</h2>
<p>Since this is <a href="https://appsumo.com/marketplace-formcake/">all a live experiment</a>, it bears mentioning that even at this still-early stage (we launched about a month ago), and given that we haven't driven a lot of traffic to the site, we've still managed to pull in just under <strong>$1,000</strong> (though it'll probably beat that shortly after this is published). The magic of the lifetime account and pricing is that even a small number of signups (&lt; 50) can really add up. </p>
<p>We're excited to see where it can go with a little more traffic.</p>
<p>We'll publish a Part II after we get to 10 reviews! If you'd like to be notified when we publish it, sign up in the box below (or just do it old-school and check out our <a href="https://formcake.com/feed.xml">RSS feed</a>)</p>
<p>Stay tuned.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/our-experience-offering-an-appsumo-deal</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276635</guid>
            <pubDate>Fri, 26 Feb 2021 16:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real Items Turns Physical Shirts into Digital Clothing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276519">thread link</a>) | @expherience
<br/>
February 26, 2021 | https://realitems.shop/blogs/news/the-future-is-phygital-real-items-turns-physical-shirts-into-digital-roblox-clothing | <a href="https://web.archive.org/web/*/https://realitems.shop/blogs/news/the-future-is-phygital-real-items-turns-physical-shirts-into-digital-roblox-clothing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span>Have you ever wanted to wear your game character's clothes? Maybe you cosplay and enjoy looking like your favorite character.</span></p>
<p><span>I know you've tried looking like your Roblox character in real life. Don't deny it.&nbsp;</span></p>
<p><span>Well, what if you can stop copying your avatar's clothes and have it match YOU instead?</span></p>
<p><span>This merger between the physical and digital world creates what is known as "Phygitals." This is exactly what Real Items is working towards. Our team of dedicated developers and designers has integrated the digital universe and fashion into one platform.&nbsp;</span></p>
<p><span>That's right, you can easily access the Roblox version of your new fashion haul using the Real Items platform. All you have to do is scan the QR code on the clothes to collect the NFT. <a href="https://realitems.shop/collections/100-authentic-marketplace/products/the-future-is-phygital-roblox-avatar">Check out this Phygital shirt in our shop.</a></span></p>

<p><span><img src="https://cdn.shopify.com/s/files/1/0335/4119/3867/files/phygital_scan_480x480.jpg?v=1614178842" alt=""></span></p>
<p><span><i><span><span>Phygital shirt powered by Real Items technology. Simply scan the QR code on the physical shirt to acquire your digital Roblox clothing.</span></span></i></span></p>




<p><b>What is Phygital?</b></p>
<p><span>Phygital is about creating a new dimension of ecosystems between the brand and consumer. It is a convergence of technologies that bridge the digital and physical worlds with the purpose of unlocking unique business capabilities and creating engaging interactive experiences for enterprises and consumers. Introducing a physical t-shirt that can be worn digitally is one of many aspects of the phygital experience.</span></p>
<p><span>The phygital experience also extends to the gaming industry. A great example of this is Nintendo’s Amiibo products. Amiibos are wireless communication figurines. These collectible toys are shaped like Nintendo characters and can interact and transfer data in and out of their supported game software. By simply tapping the Amiibo to the game, players can immediately enjoy new characters, modes, and other in-game perks.</span></p>
<p><b>Uniquely secure</b></p>
<p><span>Real Items takes the phygital experience a step further by ensuring the security of information. In a recent speech by Homeland Security Secretary Alejandro Mayorkas, he stated that federal agents had seized over 11 million fake N95 masks intended for frontline healthcare workers throughout the nation. Such threats of counterfeit PPEs have motivated Real Items to trace the origin and prove Tricol Clean KN95 masks' authenticity.</span></p>

<p><img src="https://cdn.shopify.com/s/files/1/0335/4119/3867/files/real_items_mask_480x480.jpg?v=1614015789" alt="Real Items verified KN95 mask with smart label"></p>
<p><span><i><span><span><a href="https://realitems.shop/collections/100-authentic-marketplace/products/vechain-kn95-masks">Real Items verified mask</a> comes with a smart label and a one-time pin for two-factor authentication.</span></span></i></span></p>
<p><span>&nbsp;</span><span><br>Aside from KN95 masks, Real Items technology also traces<a href="https://tastebluemountaincoffee.com/"> JACRA certified Jamaican Blue Mountain (JBM) coffee,</a> the Queen of England's favorite and one of the most expensive coffee in the world. Each pack of authentic JBM coffee comes with a <a href="https://realitems.shop/blogs/news/what-are-industry-4-0-smart-labels">Real Items smart label</a> in the form of a QR code. The Real Items smart label is tracked using Industry 4.0 technology, so it can never be counterfeited or tampered with.</span></p>

<p>&nbsp;<img src="https://cdn.shopify.com/s/files/1/0335/4119/3867/files/JBM_coffee_8a47b0ca-ab05-4786-836d-4cc18fbe9e43_480x480.jpg?v=1614016266" alt="Real Items verified Jamaican Blue Mountain Coffee"></p>
<p><span><i><span><span><a href="https://tastebluemountaincoffee.com/collections/100-jamaica-blue-mountain-no-1-coffee">Authentic JBM coffee</a>&nbsp;secured with Real Items technology. Use promo code "realitems" to get 15% off every purchase.</span></span></i></span></p>

<p><span>With a proven and secure technology in place, Real Items hopes to see this contribute to improving various industries. The Phygital shirt on Roblox is just our first step towards bringing fashion's phygital experience to the gaming scene. Who knows, there might come a time when your Fortnite character gets to wear your favorite pajamas while you're beating noobs left and right. </span><i><span>Winner winner, chicken dinner.&nbsp;&nbsp;</span></i></p>
<p><span>If you create or sell unique clothes and would like to see them on your Roblox character, connect with our dedicated team </span><a href="https://realitems.io/contact-blockchain-company.html"><span>here</span></a><span>. Or you can join in the community conversation in </span><a href="https://discord.com/invite/9yANdjcVYA"><span>Discord</span></a><span>.</span></p>
<p><span>Cheers to the future of gaming, cosplay, fashion, and mixed reality.</span></p>
      </div></div>]]>
            </description>
            <link>https://realitems.shop/blogs/news/the-future-is-phygital-real-items-turns-physical-shirts-into-digital-roblox-clothing</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276519</guid>
            <pubDate>Fri, 26 Feb 2021 16:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU poke: The extensible editor for structured binary data]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26276516">thread link</a>) | @mnabipoor
<br/>
February 26, 2021 | http://jemarch.net/poke.html | <a href="https://web.archive.org/web/*/http://jemarch.net/poke.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jemarch.net/poke.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276516</guid>
            <pubDate>Fri, 26 Feb 2021 16:30:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Farewell, Python 2]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276406">thread link</a>) | @smitty1e
<br/>
February 26, 2021 | http://bitprophet.org/blog/2021/02/25/byethon2/ | <a href="https://web.archive.org/web/*/http://bitprophet.org/blog/2021/02/25/byethon2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p>Long story short: I’m finally starting to drop Python 2 (and a few slightly
older Python 3s) from my projects, in a phased manner. Background and details
follow.</p>
<h2 id="a-brief-timeline">A brief timeline</h2>
<p>Writing this out made me feel <code>#old</code>.</p>
<ul>
<li><strong>2004:</strong> I’m introduced to Python (2.2/2.3) at the end of my time serving a
CS degree.</li>
<li><strong>2008:</strong> My OSS career kicks into gear as I take over Fabric. Python 2.4 and
2.5 were stable, 2.6 comes out in the fall, and 3.0 in winter.
<ul>
<li>3.x has been around the <em>entire time</em> I’ve maintained Fabric!</li>
</ul>
</li>
<li><strong>2010:</strong> Python 2.7 is released. That’s 11 years ago!</li>
<li><strong>2012:</strong> Python 3.3, considered the first “really usable” version
(especially for 2+3 codebases), comes out.</li>
<li><strong>2013-2014:</strong> Invoke and Fabric 2 start development, with Python 3 support
right out the gate; Paramiko gains Python 3 support.</li>
<li><strong>2016:</strong> Python 3.6 is is born, with f-strings and ordered dicts.</li>
<li><strong>2018-2019:</strong> Every widespread Linux distribution switches to Python 3, if
they hadn’t already.
<ul>
<li>The exception is RHEL/CentOS, which switches in 2020.</li>
<li>Python 3.4 reaches EOL (End of Life) in mid 2019.</li>
<li>Around this time (if not sooner) many Python 3-only packages declare Python
3.6 as their baseline supported version.</li>
</ul>
</li>
<li><strong>2020:</strong>
<ul>
<li>Python 2, in its entirety, is EOL’d in January. <em>This is an ex-interpreter!</em></li>
<li>Python 3.5 reaches EOL.</li>
<li><a href="http://bitprophet.org/blog/2020/07/02/help-wanted/">I admit burnout</a>.</li>
</ul>
</li>
<li><strong>Early 2021:</strong> Pip drops support for Python 2, as does Cryptography (a
Paramiko dependency which is unsafe to pin for long).</li>
</ul>
<p>And here we are.</p>
<h2 id="but-why">But why???</h2>
<p>The timeline is a bit implicit; let’s be explicit. Why am I doing this now?</p>
<ul>
<li><strong>It’s past time</strong>. I’m quite conservative on the maintainer spectrum, but by
now – with the interpreter, package installer, many/most packages, and
most/all Linux distributions <em>all</em> leaving Python 2 behind – I’m in good
company.</li>
<li><strong>It’s decreasingly likely that my software is the first thing pushing you to
upgrade.</strong> If you’re still on Python 2 in 2021, you’re already committed to a
lack of updates from all of the above sources. I’m just one more.</li>
<li><strong>The iron triangle has shifted.</strong> <a href="http://bitprophet.org/blog/2013/08/22/software-releases/">An old post</a> is still relevant; ease of maintenance (because
burnout) and speed (the current release cadence is unacceptable) are tipping
the scales against stability (in the “things don’t change” sense).</li>
<li><strong>Most downloads have been Python 3 for years.</strong> Going by
<a href="https://pypistats.org/">PyPIStats</a>, even the most conservative userbase I
answer to (surprisingly Fabric, not Paramiko) is only 33% Python 2.
<ul>
<li>I don’t have a useful breakdown, but I’d also guess that 33% is heavily
slated towards Fabric 1 users, who are already largely unsupported.</li>
<li>Paramiko is down to &lt;=20% Python 2.</li>
<li>Invoke (and by extension, most users of Fabric 2) has always been &lt;=10%</li>
<li>Alabaster is at 10%; etc.</li>
</ul>
</li>
<li>Combining the above two: <strong>I’d prefer to think of this as improving
quality and release cadence for a majority of users</strong>, instead of worrying
about its impacts on a recalcitrant minority.</li>
<li>Finally: <strong>nothing’s getting deleted.</strong> Same as any backwards incompatible
release: existing Python 2-supporting releases remain on PyPI.</li>
</ul>
<h2 id="how-exactly">How, exactly?</h2>
<p>I am planning a <strong>phased removal</strong> of support for Pythons <strong>2.7</strong>, <strong>3.4</strong> and
<strong>3.5,</strong> as follows:</p>
<ul>
<li>The first step will be to <strong>remove CI support</strong> for old Pythons.
<ul>
<li>This will happen as I migrate to CircleCI from the now-defunct Travis-CI
over the next few weeks/months.</li>
<li>Doing it this way saves me from reproducing a lot of frustrating busywork
in my scripting, and also slims the test matrix – which is important now
that CI providers track how much CPU time we burn!</li>
<li>But it means that there’s still a short grace period for users (see below),
as my local env will still be doing basic Python 2 test runs.</li>
</ul>
</li>
<li>The next step, which may happen at the same time, is to <strong>update development
dependencies to assume Python 3.6+</strong>.</li>
<li>There will likely be <strong>1-2 more release cycles which include Python 2
artifacts</strong>.
<ul>
<li>This works because I still generate those artifacts locally and not from
CI (yet).</li>
<li>Included in this is Fabric 1’s still-planned Python 3 support merge, for a
final release of that line. This provides users an upgrade path: Python 3,
then later Fabric 2+.</li>
</ul>
</li>
<li>Finally, the last trio of changes will happen around the same time:</li>
<li><strong>Project tooling will drop old Python support</strong>, including build/publish
tasks and packaging metadata.</li>
<li><strong>Python 2-related syntax will be removed from the code itself</strong>.</li>
<li><strong>Versions of most packages will bump their major qualifier</strong> to signify the
change (though it’s unlikely any other backwards incompatible changes will
occur):
<ul>
<li>Invoke will go to 2.0</li>
<li>Paramiko will go to 3.0</li>
<li>Fabric will remain on 2.x because it’s got a more complicated history here
<ul>
<li>thus, this will probably be Fabric 2.8 or 2.9, with 2.7 or 2.8 being the
last Python 2-supporting release.</li>
</ul>
</li>
</ul>
</li>
</ul>
        </div></div>]]>
            </description>
            <link>http://bitprophet.org/blog/2021/02/25/byethon2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276406</guid>
            <pubDate>Fri, 26 Feb 2021 16:21:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid career change – from cruise ship cleaner to developer]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26276390">thread link</a>) | @Pete-Codes
<br/>
February 26, 2021 | https://www.nocsdegree.com/cleaner-developer-covid-career-change/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/cleaner-developer-covid-career-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Aldhair made a career change due to Covid. He became a web developer by learning to code with <a href="https://scrimba.com/?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=nocsdegree_email#join">Scrimba</a>, an online learning platform. Before, Aldhair was working as a cleaner on cruise ships. This interview tells you how Aldhair learned to code, his tips for self-taught web developers and how he got his first job. Enjoy!</p><h2 id="hey-so-can-you-introduce-yourself">Hey, so can you introduce yourself?</h2><p>Hi, I’m Aldhair Escobar, I’m from Mexico and currently living in Veracruz, MX. Currently, I’m working as a Developer for Client Solutions at Scalero, My main duty is building HTML Email Templates for clients, apart from that there are some “inside” projects where I’m using Node JS and even Electron JS to try things out. The company is based on San Francisco so it’s a remote position and I’m loving it a lot. Previously, I have worked as a Tax advisor for almost 4 years, and as a cleaner at a cruise ship.</p><h2 id="why-did-you-learn-to-code">Why did you learn to code?</h2><p>Well, as I said before, I was working as a Tax advisor and spending a lot of time and energy without getting paid enough so I decided to start learning English (You can see that I am still learning it), this language opened some doors so I submitted an application to Royal Caribbean International as a cleaner on a cruise ship (which got me a better salary than my last job).</p><p>The idea to work as a cleaner was to have some experience in that industry and improve my English skills, at the same time I was saving some money.</p><p>When I was on the ship, I applied to some jobs but they didn’t allow me to have an interview (you need a second contract in the company so you can apply to another position), and I was thinking on return to the ship and apply to a better position with a better salary and then COVID happened…</p><p>Fortunately while on the ship I thought about learning some new skills after finishing my contract (e.g English for business, code, or maybe to buy a franchise).</p><p>I decided to start learning to code because I was curious about it and had some business ideas that required it.</p><h2 id="how-did-you-start-learning-to-code">How did you start learning to code?</h2><p>I started with some courses in my native language for around 1 month but I did not like them. I realized I was able to understand English resources so I began with FreeCodeCamp and did the first web development certification module, along with that I found an Udemy course called “The Complete Web Development Bootcamp” by Angela Yu ($10) and things started to make sense.</p><p>So if I can make a timeline could be like this:</p><p>April – FreeCodeCamp (Free), “The Complete Web Development Bootcamp” by Angela Yu ($10).</p><p>May – Full Academy Intro (Free), Full Academy prep (It was Free)</p><p>June – Continued with the courses above, building some projects. (I also tried some new courses that did not like)</p><p>July – Building projects in Frontendmentor, youtube video courses (JS, CSS), Started in Scrimba with a <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">React Course</a> (Free).</p><p>August – “<a href="https://scrimba.com/learn/frontend?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Frontend Developer Career Path</a> Scrimba ($19 Monthly), “21 Days Challenge “Conquering Responsive Layouts” by Kevin Powell (Free), Frontendmentor projects.</p><p>September – <a href="https://scrimba.com/learn/responsive?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Responsive Web Design Bootcamp</a> (Scrimba), Building projects for my portfolio.</p><p>October – <a href="https://scrimba.com/learn/designbootcamp?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">UI Design Bootcamp</a> (Scrimba), Building Projects and continuing with the Frontend Career Path (Scrimba).</p><p>November – FullStackOpen Part 0 and Part 1 (Free), (Finished Frontend Career Path), Started Practicing about Interviews (Scrimba has <a href="https://scrimba.com/learn/reactinterview?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">a module about it</a>), Applied for jobs, I got an interview.</p><h2 id="what-made-you-decide-to-learn-to-code-with-scrimba">What made you decide to learn to code with Scrimba?</h2><p>I was curious about the platform because of this option to modify the code directly on the screen and the mini browser so I decided to take the <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Learn React For Free course</a> and I just loved it.</p><p>It is so interactive! They have amazing teachers! , you are writing code the whole course and that is something that I like about their courses, there are many challenges and repetition is the key! (And I love the “spaced repetition” system).</p><p>Apart from that, I like to hear someone explaining a concept and I like when they use images or diagrams to show something, so I realized that Scrimba was created for me 😀</p><h2 id="what-courses-did-you-do-with-scrimba">What courses did you do with Scrimba?</h2><p>I started with the <a href="https://scrimba.com/learn/learnreact?utm_source=nocsdegree.com&amp;utm_medium=referral&amp;utm_campaign=aldhair_interview">Learn React For Free course</a>, and then I decided to get the subscription because I wanted to take some Bootcamps and the Frontend Developer Career Path, so I paid $19 per month until finishing the Path.</p><p>The advantage is that you have access to everything with the subscription and maybe in the FrontendCareerPath there’s a module that is also part of a Bootcamp so then you can finish the Bootcamp and get the individual certificate while you continue with the “main” (FrontendCareerPath) course.</p><p>I loved the Path because they are putting together all the things that are going to help you to get hired.</p><p>With Scrimba I learned a lot of JavaScript and CSS and also improved my &nbsp;ReactJS knowledge, the challenges and projects helped me to build my projects that I was going to use in my portfolio.</p><h2 id="how-did-you-get-your-first-entry-level-developer-job">How did you get your first entry level developer job?</h2><p>I always had this idea to have my GitHub profile with everything I was building, together with a “nice” CV because you know… without any experience or degree, you need to show something…</p><p>For that reason, I had my GitHub profile with almost every project I was building, a CV, and a simple portfolio website and started applying for jobs that I was interested in; I sent four applications and then got the opportunity to have an interview from one of those submissions.</p><p>Scrimba has a module dedicated to interviews and some challenges about it so it helped me with my confidence.</p><p>I was nervous because I was so interested to get the job in that company and I got some questions like “What did you learn in that course (Frontend Developer Career Path - Scrimba)?” “Why did you change careers?” Why did you go to the ship (my last job)? “The best characteristic a leader can have...” The best attitude of an employee”, Am I willing to relocate?”.</p><p>After that interview, I had three more interviews (same company), did a test (Wonscore), and built a small project with HTML, CSS and Jinja Template Engine (I learned a little bit of python to get this done).</p><p>So after 812 hours of learning and this interview process I got an offer!!</p><h2 id="what-does-a-typical-day-as-a-software-developer-look-like-for-you">What does a typical day as a software developer look like for you? </h2><p>My main duty is building Email Templates, so I get my ticket with its handoff and I start building the template with old HTML and CSS, apart from that, for instance, last week I was testing some stuff with Selenium WebDriver and Selenium IDE, and this week I am building a small desktop app with ElectronJS.</p><p>So it depends on the day, if there are a lot of templates or not then I do something else. I love what I am doing and everything is better than I was expecting.</p><h2 id="do-you-have-tips-for-people-who-want-to-learn-to-code-without-doing-a-degree">Do you have tips for people who want to learn to code without doing a degree?</h2><p>If I needed to start again, I would do things slightly different, for instance, I would start with 2 weeks of watching a lot of YouTube videos about web development, frontend, backend, stacks, languages, and also some videos that gave you the “roadmap” and all that kind of things.</p><p>After that, you will know what you don’t know and what you want to do, maybe you want to build websites or desktop apps, so you will see exactly the language that you need to learn.</p><p>Then, the most important thing, in my opinion, is to learn how you like to acquire information. Do you prefer books, video or audio? Or just the exercises without video or audio like FreeCodeCamp? It’s really important to know this because you need to search for resources that will work for you (because you prefer it).</p><p>I realized I was spending time on some resources that I didn’t like a lot so that was the main reason I decided to test Scrimba (and it worked!!)</p><p>Only with those first steps, you are going to save you a lot of time so now you can focus on the resources that you chose.</p><p>Always build stuff, it’s going to be a disaster, It won’t look good and that’s great! You can always return and fix it 😉.</p><p>I encourage you to use a “Pomodoro app” (I used “forest”) so you can keep track of your journey and see how much time you are spending, this is going to help you to push yourself and gives you extra motivation.</p><h2 id="what-are-your-career-goals-for-the-future">What are your career goals for the future?</h2><p>The idea is to get familiar with my new job, this is my first time working remotely, in tech, in a startup so it is taking time, and after a few months I want to return to build personal projects, I have some ideas and maybe I will try to build a SaaS product. In short, I want to get used to working in this field and keep pushing myself.</p>
            </div></div>]]>
            </description>
            <link>https://www.nocsdegree.com/cleaner-developer-covid-career-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276390</guid>
            <pubDate>Fri, 26 Feb 2021 16:20:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI/ML needs a key-value store, and Redis is not up to it]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26276177">thread link</a>) | @LexSiga
<br/>
February 26, 2021 | https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div id="ron_db"><h2>‍<strong>The rise of key-value stores as online feature stores.&nbsp;</strong></h2><p>Online feature stores are the data layer for operational machine learning models - the models that make online shopping recommendations for you and help identify financial fraud. When you train a machine learning model, you feed it with high signal-to-noise data called features. When the model is used in operation, it needs the same types of features that it was trained on (e.g., how many times you used your credit card during the previous week), but the online feature store should have low latency to keep the end-to-end latency of using a model low. Using a model requires both retrieving the features from the online feature store and then sending them to the model for prediction.&nbsp;</p><p>Hopsworks has been using NDB Cluster as our online feature store from its first release. It has the unique combination of low latency, high availability, high throughput, and scalable storage that we call LATS. However, we knew we could make it even better as an online feature store in the cloud, so we asked one of the world’s leading database developers to do it - the person who invented NDB, Mikael Ronström. Together we have made RonDB, a key-value store with SQL capabilities, that is the world’s most advanced and performant online feature store. Although NDB Cluster is open-source, its adoption has been hampered by an undeserved reputation of being challenging to configure and operate. With <a href="https://www.rondb.com/?utm_source=rondb" target="_blank">RonDB</a>, we overcome this limitation by providing it as a managed service in the cloud on AWS and Azure.<strong>‍</strong></p><h3><strong>Requirements for an Online Feature Store</strong>‍</h3><figure><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/60364af8c8f5d47b1f1f70ce_graph_white.png" loading="lazy" alt=""></p></figure><p>The main requirements from a database used as an online feature store are: low latency, high throughput for mixed read/write operations, high availability and the ability to store large data sets (larger than fit on a single host). We unified these properties in a single muscular term <strong>LATS</strong>:</p><p><a href="https://www.rondb.com/?utm_source=rondb" target="_blank">‍<strong>LATS</strong>: low <strong>L</strong>atency, high <strong>A</strong>vailability, high <strong>T</strong>hroughput, scalable <strong>S</strong>torage.&nbsp;</a></p><p>RonDB is not without competition as the premier choice as an online feature store. To quote Khan and Hassan from DoorDash, it should be a low latency database:&nbsp;</p><p><a href="https://doordash.engineering/2020/11/19/building-a-gigascale-ml-feature-store-with-redis/?utm_source=rondb" target="_blank">“latency on feature stores is a part of model serving, and model serving latencies tend to be in the low milliseconds range. Thus, read latency has to be proportionately lower.”&nbsp;</a></p><p>To that end, Redis fits this requirement as it is an in-memory key-value store (without SQL capabilities). Redis is open source (BSD Licence), and it enjoys popularity as an online feature store. Doordash even invested significant resources in increasing Redis’ storage capacity as an online feature store, by adding custom serialization and compression schemes. Significantly, similar to RonDB, it provides sub-millisecond latency for single key-value store operations. There are other databases that have been proposed as online feature stores, but they were not considered in this post as they have significantly higher latency (over one order-of-magnitude!), such as DynamoDB, BigTable, and SpliceMachine.</p><p>As such, we thought it would be informative to compare the performance of RonDB and Redis as an online feature store. <strong>The comparison was between Redis open-source and RonDB open-source</strong> (the commercial version of Redis does not allow any benchmarks). In addition to our benchmark, we compare the innards of RonDB’s multithreading architecture to the commercial Redis products (since our benchmark identifies CPU scalability bottlenecks in Redis that commercial products claim to overcome).<br></p><h2>Benchmark: RonDB vs Redis</h2><p>In this simple benchmark, I wanted to compare apples with apples, so I compared open-source RonDB to the open-source version of Redis, since the commercial versions disallow reporting any benchmarks. In the benchmark, I deliberately hobble the performance of RonDB by configuring it with only a single database thread, as Redis is <a href="https://redis.io/topics/benchmarks/utm_source=rondb" target="_blank">“a single-threaded server from the POV of command execution”</a>. I then proceed to describe the historical evolution of RonDB’s multithreaded architecture, consisting of three different generations, and how open-source Redis is still at the first generation, while commercial Redis products are now at generation two.</p><p>Firstly, for our single-threaded database benchmark, we performed our experiments on a 32-core Lenovo P620 workstation with 64 GB of RAM. We performed key-value lookups. Our experiments show that a single-threaded RonDB instance reached around 1.1M reads per second, while Redis reached more than 800k reads per second - both with a mean latency of around 25 microseconds. The throughput benchmark performed batch reads with 50 reads per batch and had 16 threads issuing batch requests in parallel. Batching reads/writes improves throughput at the cost of increased latency.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/6037dae7ff678a83e8eaf1a8_performance.jpg" loading="lazy" alt=""></p></figure><p>On the same 32-core server, both RonDB and Redis reached around 600k writes per second when performing SET for Redis and INSERT, UPDATE or DELETE operations for RonDB. For high availability, both of those tests were done with a setup using two replicas in both RonDB and in Redis.<br></p><h3><strong>Low latency</strong></h3><p>We expected that the read latency and throughput of RonDB and Redis would be similar since both require two network jumps to read data. In case of updates (and writes/deletes), Redis should have lower latency since an update is only performed on the main replica before returning. That is, Redis only supports asynchronous replication from the main replica to a backup replica, which can result in data loss on failure of the main node. In contrast, RonDB performs an update using a synchronous replication protocol that requires 6 messages (<a href="https://www.amazon.com/MySQL-Cluster-7-5-Inside-Out/dp/9176998142/utm_source=rondb" target="_blank">a non-blocking version of two-phase commit</a>). Thus, the expected latency is 3 times higher for RonDB for writes.&nbsp;<br></p><h3><strong>High Throughput</strong></h3><p>A comparison of latency and throughput shows that RonDB already has a slight advantage in a single-threaded architecture, but with its third-generation multithreaded architecture, described below, RonDB has an even bigger performance advantage compared to Redis commercial or open-source. RonDB can be scaled up by adding more CPUs and memory or scaled out, by automatically sharding the database.&nbsp; As early as 2013, we developed a benchmark with NDB Cluster (RonDB’s predecessor) that showed how <a href="http://mikaelronstrom.blogspot.com/2015/03/200m-reads-per-second-in-mysql-cluster.html?utm_source=rondb" target="_blank">NDB could handle 200M Reads per second</a> in a large cluster of 30 data nodes with 28 cores each.&nbsp;<br></p><h3><strong>High Availability</strong></h3><p>The story on high availability is different. A write in Redis is only written to one replica. The replication to other replicas is then done asynchronously, thus consistency can be seriously affected by failures and data can be lost. An online feature store must accept writes that change the online features constantly in parallel with all the batched key reads. Thus handling node failures in an online feature store must be very smooth.<br></p><p>Given that an online feature store may need to scale to millions of writes per second as part of a normal operation, this means that a failed node can cause millions of writes to be lost, affecting the correctness and quality of any models that it is feeding with data. RonDB has transactional capabilities that ensure that transactions can be retried in the event of such partial failures. Thus, as long as the database cluster is not fully down, no transactions will be lost.<br></p><p>In many cases the data comes from external data sources into the online Feature Store, so a replay of the data is possible, but an inconsistent state of the database can easily lead to extra unavailability in failure situations. Since an online feature store is often used in mission-critical services, this is clearly not desirable.<br></p><p>RonDB updates all replicas synchronously as part of writes. Thus, if a node running the transaction coordinator or a participant fails, the cluster will automatically fail over to the surviving nodes, a new transaction coordinator will be elected (non-blocking), and no committed transactions will be lost. This is a key feature of RonDB and has been tested in the most demanding applications for more than 15 years and tested thousands of times on a daily basis.<br></p><p>Additionally it can be mentioned that in a highly available setup, in a cloud environment RonDB can read any replica and still see the latest changes whereas Redis will have to read the main replica to get a consistent view of the data and this will, in this case, require communicating across availability zones which can easily add milliseconds to latency for reads. RonDB will automatically setup the cluster such that applications using the <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud?utm_source=rondb" target="_blank">APIs will read replicas that are located in the same availability zone</a>. Thus in those setups RonDB will always be able to read the latest version of the data and still deliver data at the lowest possible latency. <strong>Redis setups will have to choose between delivering consistent data with higher latency or inconsistent data with low latency in this setup.</strong><br></p><h3><strong>Scalable Storage</strong></h3><p>Redis only supports in-memory data - this means that Redis will not be able to support online Feature Stores that store lots of data. In contrast, RonDB can store data both in-memory and on-disk, and with support for up to 144 database nodes in a cluster, it can scale to clusters of up to 1PB in size.<br></p><h3><strong>Analysis: Three Generations of Multithread Architectures</strong></h3><p>For our single-threaded benchmark, we did not expect there to be, nor were there, any major differences in throughput or latency for either read or write operations. The purpose of the benchmark was to show that both databases are similar in how efficiently they use a single CPU. RonDB and Redis are both in-memory databases, but the implementation details of their multithreaded architectures matters for scalability (how efficiently they handle increased resources), as we will see.&nbsp;<br></p><p>Firstly, <a href="https://redis.io/topics/benchmarks/utm_source=rondb" target="_blank">“Redis is not designed to benefit from multiple CPU cores. People are supposed to launch several Redis instances to scale out on several cores if needed.”</a> For our use-case of online feature stores, it is decidedly non-trivial to partition a feature store across multiple redis instances. Therefore, commercial …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-26276177</guid>
            <pubDate>Fri, 26 Feb 2021 16:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU poke 1.0 released: an interactive, extensible editor for binary data]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26275860">thread link</a>) | @matt_d
<br/>
February 26, 2021 | http://www.jemarch.net/poke | <a href="https://web.archive.org/web/*/http://www.jemarch.net/poke">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.jemarch.net/poke</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275860</guid>
            <pubDate>Fri, 26 Feb 2021 15:42:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Catalog of resources related with Oberon programming language]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 14 (<a href="https://news.ycombinator.com/item?id=26275553">thread link</a>) | @lproven
<br/>
February 26, 2021 | https://oberon.org/en | <a href="https://web.archive.org/web/*/https://oberon.org/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><a href="https://oberon.org/ru"><img src="https://oberon.org/ru.png" alt="ru"></a>
<a href="https://oberon.org/uk"><img src="https://oberon.org/uk.png" alt="uk"></a>
<a href="https://oberon.org/en"><img src="https://oberon.org/en.png" alt="en"></a>
<a href="https://oberon.org/de"><img src="https://oberon.org/de.png" alt="de"></a>
</p>

<div><p><img src="https://oberon.org/oberon.png" alt="OBERON.ORG"></p><p><img src="https://oberon.org/title.png"></p></div>



<p>
OBERON.ORG project unites projects related to programming languages Oberon, Oberon-2, Active Oberon, Modula-2/3, Oberon-07 and Component Pascal (Blackbox Oberon).


</p>





<p><h2 id="history">
Historical materials
</h2></p>

<div>
<h3>
Niklaus Wirth website
</h3>
<p><a href="https://inf.ethz.ch/personal/wirth">inf.ethz.ch/personal/wirth</a></p><p>
Niklaus Wirth is the author of the Oberon programming language. Together with Jürg Gutknecht, he developed the Oberon operating system, giving rise to the technological direction of Oberon languages and tools.
</p>
</div>

<div>
<h3>
One of the first pages about Oberon in Russian
</h3>
<p><a href="http://www.uni-vologda.ac.ru/oberon">www.uni-vologda.ac.ru/oberon</a></p><p>
Sergey Zalmanovich Sverdlov about the main features of Oberon and its application for education.
</p>
</div>

<div>
<h3>
Educational portal about N. Wirth's visit to Russia
</h3>
<p><a href="http://oberon2005.oberoncore.ru/">oberon2005.oberoncore.ru</a></p><p>
The site was created after Niklaus Wirth's visit to Russia in 2005. The core of the site is work on the history and development of programming languages of its authorship.
</p>
</div>

<div>
<h3>
Project Оberon 2013
</h3>
<p><a href="http://www.projectoberon.com/">www.projectoberon.com</a></p><p>
Repeating by Niklaus Wirth, Jürg Gutknecht and Paul Reed of the Oberon project for FPGA
</p>
</div>

<div>
<h3>
Oberon Day in Russia
</h3>
<p><a href="https://oberoncore.ru/oberonday">oberoncore.ru/oberonday</a></p><p>
The event brings together developers who use Oberon-family systems in their practice, and interested listeners. Every year, experts representing fundamental science (high energy physics, biophysics), strategic industries (Rosatom), the industry of control systems (APCS, unmanned aerial vehicles), small innovative business (development of software systems for various purposes) make reports. Also in the center of attention are the problems of IT education, from grade 5 to specialized higher, and the key to their solution, developed by the Informatics-21 project. The mission of the seminar, besides the exchange of experience between the participants, is the broadcast of IT education in the industry and in the field of education.
</p>
</div>

<p><h2 id="education">
Educational materials
</h2></p>

<div>
<h3>
Educational project "Informatics-21"
</h3>
<p><a href="http://www.inr.ac.ru/~info21">www.inr.ac.ru/~info21</a></p><p>
Under the leadership of Fyodor Tkachev, the project coordinates the efforts of specialists in science, education, the aerospace industry and the IT industry to streamline the teaching of programming and computer science based on the achievements of Science.
</p>
</div>

<div>
<h3>
Component Pascal in School Computer Science Course
</h3>
<p><a href="https://inf.1sept.ru/article.php?ID=200800100">inf.1sept.ru/article.php?ID=200800100</a></p><p>
Article by A.S. Ilyina and A.I. Popokov in the magazine "September First". “Teaching programming based on Component Pascal / Blackbox started experimentally in Russia in 2002. The most positive experience accumulated to date, both personal and colleagues, allows us to recommend this environment for mass use in schools and universities."
</p>
</div>

<div>
<h3>
Open wikipedia on languages and projects in the Oberon language
</h3>
<p><a href="http://wiki.oberon.org/">wiki.oberon.org</a></p>
</div>





<div>
<h3>
The site is dedicated to the Oberon family of programming languages
</h3>
<p><a href="https://way.oberon.org/">way.oberon.org</a></p>
</div>





<div>
<h3>
BlackBox Component Builder for Windows
</h3>
<p><a href="http://blackboxframework.org/">blackboxframework.org</a></p><p>
Blackbox is a free and open source programming environment for the Component Pascal language, developed by the Swiss company Oberon Microsystems. The environment supports dynamic loading of modules (compiled into machine code) and garbage collection, i.e. provides its own component object model. Writing, compiling, executing, testing can be done inside an integrated environment, which greatly increases the productivity of the programmer. Blackbox is an operating environment (a kind of micro-OS) that runs on top of a regular OS. This operating environment can be included in whole or in part in the final application (along with the compiler), allowing this application to be easily extended and rebuilt on the fly.
</p>
</div>

<div>
<h3>
Cross Platform Blackbox
</h3>
<p><a href="https://blackbox.oberon.org/download">blackbox.oberon.org/download</a></p><p>
A cross-platform version of Blackbox for Windows, GNU / Linux, OpenBSD and FreeBSD is published on the site. A system of open publishing of extensions is also being developed.
</p>
</div>

<div>
<h3>
O7 compiler for microcontrollers with ARMv{6,7E}-M architecture
</h3>
<p><a href="https://github.com/aixp/O7">github.com/aixp/O7</a></p><p>
The compiler is distributed in open source, along with a set of useful modules, which are combined into a Micro subsystem. These modules store register addresses, controller initialization procedures, templates for transferring data via the UART protocol, and much more. The Mobx subsystem contains sample programs for several microcontrollers.
</p>
</div>





<div>
<h3>
MultiOberon
</h3>
<p><a href="https://github.com/dvdagaev/Mob">github.com/dvdagaev/Mob</a></p><p>
Oberon compiler with syntax constraint support. Supports three backends: BlackBox x86, Ofront for C translation, and LLVM. Can be used from Blackbox or command line.
</p>
</div>



<div>
<h3>
"Visual" or Online Oberon
</h3>
<p><a href="https://online.oberon.org/">online.oberon.org</a></p><p>
Visual is a tool for creating interactive educational and scientific models. The project aims to disseminate knowledge and teach programming.
</p>
</div>

<div>
<h3>Free Oberon</h3>
<p><a href="https://free.oberon.org/">free.oberon.org</a></p><p>
Turpo Pascal style IDE for Windows and GNU/Linux.
</p>
</div>









<div>
<h3>Astrobe</h3>
<p><a href="http://astrobe.com/">astrobe.com</a></p><p>
Oberon-07 compiler for microcontrollers
</p>
</div>





<div>
<h3>
Herschel
</h3>
<p><a href="https://herschel.oberon.org/">herschel.oberon.org</a></p><p>
Direct Component Pascal compiler for x86-64 architecture and Blackbox framework.
</p>
</div>


<div>
<h3>
YaOS — Russian translation of the A2 operating system (in development)
</h3>
<p><a href="https://gitlab.com/budden/ja-o-s">https://gitlab.com/budden/ja-o-s</a></p><p>
The YaOS project is a copy (fork) of the A2 operating system, written in the "ETH Oberon" language. The project started in 2019 and managed to make progress in the following areas: translation of source texts into Russian, expanding Unicode support, expanding documentation, improving developer tools, changing the language to improve reliability.
</p>
</div>










<p><h2 id="communities">
Communities
</h2></p>

<div>
<h3>
OberonCore Project
</h3>
<p><a href="https://oberoncore.ru/">oberoncore.ru</a></p><p>
The project brings together users and developers of oberon systems and languages.
</p>
</div>

<div>
<h3>
BlackBox Framework Center
</h3>
<p><a href="http://blackboxframework.org/">blackboxframework.org</a></p><p>
The international volunteer organization "Blackbox Component Frame Development Center" was created after the official announcement of Oberon microsystems inc. about publishing Blackbox under BSD 2-clause license and ending official support for Blackbox environment. The center took over the correction of known and newly discovered defects, the addition of innovations, the release and publication of new versions of Blackbox for OS Windows.
</p>
</div>






<p><h2 id="boards">
Forums
</h2></p>







<div>
<h3>
Chat with thematic channels
</h3>
<p><a href="https://chat.oberon.org/">chat.oberon.org</a></p><p>
Thematic communication on the RocketChat software platform.
</p>
</div>






<!--
<div class='item'>
<h3>

</h3>
<a href=http://oberspace.org>oberspace.org</a>
<p>

</p>
</div>
-->

<p><h2 id="video">
Video about Oberon
</h2></p>











<p><h2 id="repos">
Repositories
</h2></p>

<div>
<h3>
Component Pascal Collection
</h3>
<p><a href="http://www.zinnamturm.eu/">www.zinnamturm.eu</a></p><p>
A collection of different subsystems for Blackbox that contains source code examples, tools, utilities, math and graphics libraries, and many other applications. There are also helpful simple examples for tutorials. Here you will find algorithms and solutions for common computer programming problems.
</p>
</div>






<p>
end of catalog
</p><p>

For information on updating and supplementing the information in the directory, as well as if you need a third-level domain for the project, — <a href="mailto:iadenisov %D0%90%D0%A2 oberon.org" onmouseover="this.href = 'mailto:Иван Денисов '+base64_decode('PGlhZGVuaXNvdkBvYmVyb24ub3JnPj9zdWJqZWN0PQ==')+'About oberon.org'">write a letter</a>.

</p><p>
The site runs on an http server developed by Blackbox.
</p>

</div></div>]]>
            </description>
            <link>https://oberon.org/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275553</guid>
            <pubDate>Fri, 26 Feb 2021 15:15:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I do development for one week and marketing and documentation for one week]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26275495">thread link</a>) | @rukshn
<br/>
February 26, 2021 | https://ruky.me/2021/02/26/i-do-development-for-one-week-and-marketing-and-documentation-for-one-week/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/02/26/i-do-development-for-one-week-and-marketing-and-documentation-for-one-week/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>I know the advice is to find a co-founder. But what if you can’t find a co-founder? Yes, having a co-founder is great. But there are companies that are founded by solo-founders who went on to become billion or million dollar companies.</p>
<p>But what if you are just getting started, you are working on a side-project that one day hopefully turn out to be a profitable venture? You have to be the founder, developer, marketer, all those roles at the same time?</p>
<p>Recently I read a blog post by <a href="http://bannerbear.com/" target="_blank" rel="noreferrer noopener">BannerBear</a> founder about his journey to his $10k MRR. There is mentioned about developing for one week, and working on marketing and documentation for the another week. And repeating this cycle.</p>
<p>This was something new to me, I mean I used to do these things in parallel, develop, document, market at the same time. So since this was new, I decided to give this a try, and I have been doing it for one month, and I thought this is a good time to reflect on it.</p>
<h2>Developing for one week</h2>
<p>I’m working on a web app with set of tools that help educators, and students. So the first week about this was developing. I the solution, I didn’t think about marketing, documentation and SEO. I focused only on development and making an MVP.</p>
<p>I develop everything on my development server, do the testing, the fix bugs. At the end of each development week cycle, I build what I have done and push it to the production server from the development server.</p>
<h2>M&amp;D for one week</h2>
<p>I focused my second week completely on marketing and documentation. I set up a Facebook, Twitter pages and a YouTube channels.</p>
<p>I showed my product to some of my friends to get some feedback and help me to find some bugs.</p>
<p>I also did documentation, and also wrote some blog posts, tutorials on how to use the tool that I’m developing.</p>
<p>I only fixed if there were some critical bugs that needed urgent fixing. I left everything else for the development week.</p>
<p>At the same time I planned for what I’m going to do for the upcoming development week. Features I’m going to add, bug fixing I’m going to do, and also spent some time in learning technologies that might be needed for the upcoming features.</p>
<h2>What’re the benefits I see in this method</h2>
<h3>Less stress </h3>
<p>Yes, I feel less stress when I do one week of development and one week on M&amp;D. Because when I try to develop every day I feel as if I’m not being productive or I feel stressed to push the next feature, fix a minor bug, even when there are not many people using my software.</p>
<p>Now I don’t feel the rush do things, I can think for one whole week what I’m going to develop.</p>
<h3>More time to focus</h3>
<p>Now that I have separated my work I feel as I’m more focused on what I should do during that day.</p>
<p>When doing developing and marketing and documentation and everything together I felt if as I was less focused on that I should do, and I end up being less productive, and more stress.</p>
<p>I usually write documentation to future features and tools that I expect to develop, and when I come to the development week I have a guide on what I should develop and I can do the developing based on that.</p>
<p>I’m going to continue this development and M&amp;D cycle for another month to see if it’s going to be productive or not. But during first month of trying this method, I feel that it is a good method that suits me. </p>
<p>I feel this method is good specially if you’re a solo founder working on a side project all by yourself. But if you have a co-founder or a team, then you have people to do the marketing and development for you.</p>
<p>Are there anyone else who’s doing the same thing? Please leave it in the comments.</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/02/26/i-do-development-for-one-week-and-marketing-and-documentation-for-one-week/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275495</guid>
            <pubDate>Fri, 26 Feb 2021 15:11:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TerminusDB 4.2 – Encyclopaedia Galactica Release]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26275452">thread link</a>) | @LukeEF
<br/>
February 26, 2021 | https://terminusdb.com/blog/2021/02/25/terminusdb-4-2-encyclopaedia-galactica-release/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2021/02/25/terminusdb-4-2-encyclopaedia-galactica-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          <p><em>‘This one will take us to Titan’</em></p>

<p>Today we’re excited to announce the release of TerminusDB 4.2!</p>

<p>For those who aren’t familiar with TerminusDB, it’s an open-source graph database and document store. With TerminusDB and TerminusHub you can collaboratively build data-intensive applications and knowledge graphs. It’s a distributed immutable data store with a powerful query language. You should use TerminusDB if you want to get your knowledge graph up and running fast; if you’re working with complex data; if time-travel, immutability, data lineage, or collaboration are important to your project; or if you need easy &amp; powerful query. To learn more about TerminusDB you can <a href="https://terminusdb.com/">visit our website</a> or our <a href="https://github.com/terminusdb/terminusdb">github repo</a>. We’re biased, but we think there is no better knowledge graph or knowledge collaboration technology anywhere in the world. And unlike most of the competition, we’re open source.</p>

<h2 id="encyclopaedia-galactica">Encyclopaedia Galactica</h2>

<p>Based on the number of new features in TerminusDB 4.2, this could almost be a 5.0.</p>

<p>We’ll focus on the three big developments, but there are a bunch of smaller improvements that you can read about in <a href="https://github.com/terminusdb/terminusdb/blob/master/docs/RELEASE_NOTES.md">the release notes</a>.</p>

<h2 id="optimize">Optimize!</h2>

<p>TerminusDB is immutable - all the past states of the database are stored so you can easily query what the database looked like today, yesterday or last year. When querying your TerminusDB, the query engine looks through all that history to construct your data from all the additions and deletions contained in the past states. The big advantage of doing things this way, rather than modifying the data directly, is that we can reason about the changes to a database over time. We can show exactly what changes were made to the database, how they were made, by whom, and when.</p>

<p>All that history – especially if there are lots of commits – can slow queries over time. But fret no more – the Encyclopaedia Galactica Release solves the problem by introducing an optimize capability. This works by squashing those histories together which then appears to be exactly the same as the histories that it replaces. This allows queries to be much faster, while still making the collaboration and query features work.</p>

<p>This is a huge development and opens a range of interesting high assurance use-cases. With TerminusDB 4.2, you have a tamper-evident history system with proof of data inclusion and historical consistency in real time. Data ownership is now verifiable by clients, auditors, or anyone else you want.</p>

<h2 id="large-files-with-tus">Large Files with Tus</h2>

<p>TerminusHub is about collaborative data integration. It allows you to share, build and integrate knowledge graphs with your team and the wider world. Under the hood, we use <a href="https://terminusdb.com/t/papers/terminusdb-git.pdf">succinct data structures</a> to enable sparing use of main memory resources. Even with prudent use of memory and sharing just database deltas on TerminusHub, we still ran into problems when handling uploads of large files. The connections were sometimes dropped or interrupted, and users were forced to start again.</p>

<p>TerminusDB 4.2 <a href="https://github.com/terminusdb/tus">implements Tus</a>– a project that makes resumable file uploads easy. With Tus, TerminusHub can deal with large uploads even if those are from unreliable connections. In traditional uploading implementations progress would be lost in such situations but Tus enables you to recover from these interruptions and continue where the upload was stopped. We can now start to think about providing the ability to pause an upload. Best of all, we are growing an open-source standard and not relying on proprietary upload solutions. TerminusDB is committed to open source and open standards!</p>

<h2 id="console">Console</h2>

<p>Lots of Terminators use clients or the CLI to interact with the database, but the main TerminusHub access is through the database console. We’re working hard to try to make this better and have introduced a new ‘manage’ tab that does exactly what it says on the tin – manage the database. You can optimize your database; you can squash, reset or delete branches.</p>

<p>The document interface in the console is something that we are quite proud of and will continue to develop. We think it offers a great low-code way for users to interact with their linked documents. Just surf through, find the links, visualize as a graph… simple. Some properties in your database can have different values. For example, an owner might be either a “Company” or a “Person”. In these cases, the document viewer now allows the user to choose which type the property takes with a drop-down menu showing all the choices. The TerminusDB 4.2 console now has JSON support – just click to add your JSONs to your database. Everybody loves JSON (which is why I think Jason is the worst name for a DBA).</p>

<p>We’ve also squashed bugs, made the database faster and fixed some other bits so check out the release notes and take some time to explore! And come say hi in our <a href="https://discord.gg/HynPgtY7Wg">Discord Server</a>.</p>

<h2 id="why-encyclopaedia-galactica">Why Encyclopaedia Galactica</h2>

<p>TerminusDB is named for the home planet of the <a href="https://en.wikipedia.org/wiki/Foundation_series">Foundation in the Asimov series</a>, so what better name than Encyclopaedia Galactica for this release. TerminusDB is a knowledge graph and that’s what those Encyclopaedists were building on Terminus. A compendium of all knowledge then available in the Galactic Empire, intended to preserve that knowledge in a remote region of the galaxy in the event of a foreseen galactic catastrophe. No need to wait for the Galactic Empire, TerminusDB 4.2 can be that for you today.</p>

        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2021/02/25/terminusdb-4-2-encyclopaedia-galactica-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275452</guid>
            <pubDate>Fri, 26 Feb 2021 15:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lam: An actor-model VM for WebAssembly and native]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26275408">thread link</a>) | @todsacerdoti
<br/>
February 26, 2021 | https://notamonadtutorial.com/lam-an-actor-model-vm-for-webassembly-and-native-d7939362e1b8 | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/lam-an-actor-model-vm-for-webassembly-and-native-d7939362e1b8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://federicocarrone.medium.com/?source=post_page-----d7939362e1b8--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/56/56/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="28" height="28"></a></p></div></div></div></div><p id="3d04">An interview with its creator, Leandro Ostera.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3040/1*ZA5-hKa-yYGz8FX-kmZh9g.png" width="1520" height="450" srcset="https://miro.medium.com/max/552/1*ZA5-hKa-yYGz8FX-kmZh9g.png 276w, https://miro.medium.com/max/1104/1*ZA5-hKa-yYGz8FX-kmZh9g.png 552w, https://miro.medium.com/max/1280/1*ZA5-hKa-yYGz8FX-kmZh9g.png 640w, https://miro.medium.com/max/1400/1*ZA5-hKa-yYGz8FX-kmZh9g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ZA5-hKa-yYGz8FX-kmZh9g.png?q=20"></p></div></div></div><figcaption>Source: <a href="https://abstractmachines.dev/" rel="noopener">https://abstractmachines.dev/</a></figcaption></figure><p id="a84d">Here, at NAMT, we are in love with the Actor Model.<br> Within this paradigm, the basic units of computation are called actors. There is no shared state between them, instead, they interact via message passing. This has the advantage that actors become trivial to paralellize (in Erlang, an actor is called a <em>process</em>) and errors became easier to handle.</p><p id="3a04">The actor model is a concurrency p<span id="rmm">a</span>radigm created by Carl Hewitt in 1973 with the goal of making the task of writing concurrent programs simpler. It is based on the idea of actors, entities that can only send, receive and process messages. By reducing the amount of shared state it reduces the need of locks for synchronization. There exists several battle-tested implementations of the Actor Model such as Erlang/OTP, Akka (Scala/Java) and Orleans (C#).</p><p id="b028">In this interview, we chat with Leandro Ostera, the founder of Abstract Machines. Ostera is working on LAM, The Little Actor Machine, an embeddable virtual machine for the actor model that runs native or compiles to WebAssembly.</p><p id="32e1"><em>The questions for this interview were thought by Juan Pablo Amoroso, Javier Chatruc &amp; Federico Carrone. Joaquín Centeno and Juan Bono wrote the introduction and edited the article.</em></p></div></div></section><section><div><div><p id="d09c"><strong>Tell us a bit about your project lab, Abstract Machines. What kind of work do you do?</strong></p><p id="22fa">I started Abstract Machines with a single goal in mind: build tools that would help me think more clearly.</p><p id="9e03">Right now what I do think about the most is writing software. I think typed languages help me think clearly, so I’m building Caramel, an OCaml for the BEAM. I also think that understanding the program that runs your programs is fundamental to thinking clearly about the quality of what you build, so I’m building LAM, an actor-model VM.</p><p id="c436"><strong>LAM’s tagline is “A Little Actor Machine that runs on Native and WebAssembly”. Could you give us a brief overview of the actor system?</strong></p><p id="dca4">The original name was Leandro’s Abstract Machine. Like Prolog’s WAM was named after Warren, Warren’s Abstract Machine, and the early Erlang VM was JAM after Joe’s Abstract Machine. But Little I think it’s a much better name overall: LAM should be small, tiny even.</p><p id="6bf0">The actor system it implements is in spirit very close to Erlang’s take on the actor model — processes with mailboxes, message passing across them, fair scheduling through reduction counting. There’s a few more things in the roadmap, like process linking and monitoring. Overall, if you have worked with Erlang or Elixir before, you should feel right at home with LAM.</p><p id="e673"><strong>What is the motivation behind LAM? Why build a BEAM alternative?</strong></p><p id="05cb">LAM’s mission is to make Actor concurrency available everywhere by providing a specified, lightweight runtime. Think LuaVM meets the Actor Model. I’ve always liked the LuaVM, there’s a certain elegance to it that I find very appealing.</p><p id="f192">One of the reasons to build an alternative is that the BEAM is rather large, and the implementation is the only real spec. [Erik Stenmans’ Beam Book] or [kvavks Beam Wisdoms] have tried to document it, but without an official effort to produce a JVM style spec (like the one you can get in a bookshelf), it’s unlikely we will have a reliable drop-in alternative any time soon.</p><p id="ec18">So I thought I could instead make a new thing that could learn from both the LuaVM and the BEAM. At 35 instructions, LAM can run an interesting amount of Erlang programs, in fact I’d like most code that runs on the BEAM to be bytecode-translatable to run on LAM. Not all of it tho, and we’ll see what doesn’t make the cut.</p><p id="a6a3"><strong>One of LAM’s targets is WebAssembly. Is there any alternative actor system for the web? How do they compare with LAM?</strong></p><p id="3b25">Yes, there are plenty! A most promising one these days is Lunatic, but on the Erlang side of things, there’s the up-and-coming Lumen.</p><p id="871a">Most of the rest are libraries for building actor applications in other languages, like how Actix lets you use Actors in Rust. Lumen in particular is more of a compiler + runtime that brings Erlang down to LLVM and gives you this single optimized executable.</p><p id="7414">LAM by contrast is a higher level VM: you feed it bytecode (spawn, send, receive, call, make list, etc), and as it runs it, side-effects happen through FFI/Bindings depending on the platform.</p><p id="a15e">Around LAM there’s a tiny compilation toolchain that takes that bytecode, lowers it to something that can be run a little faster, and packs it <em>with the VM</em> in a single binary that is optimized for a specific platform.</p><p id="3bf4">Because the VM is tiny, and the FFIs are pluggable, it’s straightforward to compile it to WebAssembly and run your bytecode there.</p><p id="e3b3"><strong>The documentation mentions that one of the goals is to support Erlang/OTP’s supervision tree structure. Would this allow more reliable/resilient web UIs, capable of gracefully recovering from errors?</strong></p><p id="848e">Absolutely! I expect it to let you build even more natural and flexible UIs. After all the “event” model fits perfectly: when process Button receives message Click, do this/that.</p><p id="b621">The main problem is that preemptive scheduling makes it impossible to guarantee certain processes will have enough time to make stuff like animations run smoothly. But I’m borrowing the idea of dirty schedulers and considering introducing Greedy Processes instead, that can either request upfront how much time they need, or just run to completion. Definitely interesting to experiment with hard-real time scheduling as well.</p><p id="69ed"><strong>What are some interesting use cases for LAM?</strong></p><p id="0aac">Off the top of my head, there’s 2. The first one is perhaps why I want it the most these days: fast cli tools. Write ’em in Erlang/Elixir/Caramel, ships as a single binary.</p><p id="1e96">The second one will have the largest impact on how we build for the BEAM: actually writing full-stack applications in a single BEAM Language.</p><p id="df52">Write your backend in Elixir and run it on the BEAM, write your frontend in Elixir too but run it on LAM. And it doesn’t have to be a web-based app, it could be an actual native GUI application too.</p><p id="0045"><strong>Why write it in Rust? Is the Rust-WASM toolchain mature enough to target WASM reliably with LAM?</strong></p><p id="aa48">I love Rust. It’s a good language and the learning curve has certainly taught me a lot about how to build software. I think the Rust-wasm toolchain is pretty mature these days too.</p><p id="9104"><strong>Besides performance (LAM compiles AOT), what will be the advantages of LAM over the BEAM?</strong></p><p id="479e">Really the AOT stuff I can’t consider an advantage — I don’t expect LAM to be fundamentally faster than the BEAM, especially after the BeamJIT work. Nor do I expect it to compete in speed with Lumen.</p><p id="fc63">What I see as an advantage is that LAM is being built to have a Specification and to be Embeddable.</p><p id="2cd6"><strong>WebAssembly lacks a garbage collector and the BEAM is a GC environment. How does LAM tackle this?</strong></p><p id="059d">There is a wasm-gc spec in the works, and some other folks are waiting on it as well (like the OCaml-wasm efforts).</p><p id="52f6">But since WebAssembly isn’t the only LAM target, we’ll have to embed a GC anyway. I expect it to work very closely to the BEAMs (per process collections, ref counted binary strings, etc). I haven’t looked so deeply into this, but I have a chunky book waiting for me (The Garbage Collection Handbook).</p><p id="26bf"><strong>Is this a solo project or are you looking for contributors? If you are looking for contributors, how should they get started (first issues, roadmap, etc)?</strong></p><p id="48d2">So far it is just me, but I’d love to build a friendly and welcoming community around it. At the moment I’ve been focused on getting this vertical slice of the project up and running so it becomes easier to do some horizontal scoping: how far along are we with the specification, or how much of the BEAM bytecode can we support via translation.</p><p id="2ea9">There’s tons of work to do starting at the design level. From figuring out how to build the right layers to FFIs across platforms (native, wasi, web), to how to optimize the main emulator loop to crunch the bytecode as fast as possible, to GC and bundling the final binaries, to writing the spec and the manual.</p><p id="967a">Formalizing the spec is a big topic where I hope I can get some interest from the TLA+ community to guide me into doing justice to both TLA+ and LAM.</p><p id="e341">LAM could use help across the board, so if you’re reading this please tweet at me (<a href="https://twitter.com/leostera/" rel="noopener">@leostera</a>)!</p><p id="ee97"><strong>For our last question, in general, what are your favorite books, articles or resources for programmers?</strong></p><p id="889c">I think that if you asked me this a year ago I would have regurgitated a bunch of books that I should list here, but that didn’t really further my understanding. There’s a lot of reference material that is just terrible for learning, because its meant to be a compendium of information rather than a pedagogically written introduction to a subject.</p><p id="8aa0">For example, Types and Programming Languages by Benjamin Pierce is deemed <em>the ultimate</em> reference for type stuff. But I learned more about the nature of typing by reading The Little Typer. After that it was a lot easier to get into the right headspace to understand what Pierce wanted me to get out of the book.</p><p id="b1fa">So if you’re getting into a subject, don’t rush for the ultimate reference, and find something written to teach you <em>the core</em> of the subject. Then the rest becomes a little easier.</p><p id="35f0">Virtual Machines by Iain D. Craig, and Formal Development of a Network-Centric RTOS have been very useful in working with LAM. Hillel Wayne’s Practical TLA+, and Alloy’s Software Abstraction books have been really good to get a better grip on how to specify systems as well. Of course <a href="http://lamport.azurewebsites.net/tla/book.html" rel="noopener">“Specifying Systems” by Lamport</a> has been a good reference as well.</p><p id="17c4">Some books that have had a massive impact in how I think and communicate have (unsurprisingly) nothing to do with computers. Like Umberto Eco’s “6 Walks in the Fictional Woods” (focused on how to create narratives and rhetoric) or Mandelbrot’s “The (Mis)Behavior of Markets” (a historical account of how fractal geometry describes better the financial markets). Nonetheless, they’ve helped shape the way I think and I’ve come out a better programmer.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2/0*nPPWbd4-7dJavk5P.gif" width="1" height="1" data-old-src="https://miro.medium.com/freeze/max/60/0*nPPWbd4-7dJavk5P.gif?q=20"></p></div></div></figure></div></div></section></div>]]>
            </description>
            <link>https://notamonadtutorial.com/lam-an-actor-model-vm-for-webassembly-and-native-d7939362e1b8</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275408</guid>
            <pubDate>Fri, 26 Feb 2021 15:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steampipe v0.2.0 New AWS Multi-Region Queries and Query Caching]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26275128">thread link</a>) | @51stpage
<br/>
February 26, 2021 | https://steampipe.io/blog/release-0-2-0 | <a href="https://web.archive.org/web/*/https://steampipe.io/blog/release-0-2-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><h2>What is Steampipe?</h2><p>SQL is an expressive and powerful language for asking questions of structured data. Steampipe, an open-source project from <a href="https://turbot.com/">Turbot</a>, enables cloud pros (e.g. software developers, operations engineers and security teams) to query their favorite cloud services with SQL.</p><p>The heart of Steampipe is an intuitive command line interface (CLI) that solves the challenges encountered when asking questions of cloud resources and services. Traditional tools and custom scripts that provide visibility into these services are cumbersome, inconsistent across providers and painful to maintain. Steampipe provides a consistent, explorable and interactive approach across IaaS, PaaS and SaaS services.</p></div><div><div><div><div><div><p>&gt;</p><div><pre><code><p><span>select</span><span> </span></p><p><span>  region</span><span>,</span><span> </span></p><p><span>  instance_state </span><span>as</span><span> state</span><span>,</span><span> </span></p><p><span>  instance_type </span><span>as</span><span> </span><span>type</span><span></span></p><p><span></span><span>from</span><span> </span></p><p><span>  aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------+-----------+
| region    | state   | type      |
+-----------+---------+-----------+
| eu-west-1 | running | t3.medium |
| eu-west-2 | running | m5a.large |
| us-east-1 | running | t3.large  |
+-----------+---------+-----------+
    </pre></div></div></div></div></div><p>From the moment you have a question about your cloud, Steampipe is already at work giving you structured tables to formulate that question as SQL and execute it against your live cloud APIs. Steampipe v0.2.0 delivers an even faster response to those questions with our preview of <a href="https://steampipe.io/#blazing-fast-query-response-with-new-query-caching">query caching</a>, and enables you to do more work in each query with our new <a href="https://steampipe.io/#aws-multi-region-queries-with-steampipe">multi-region</a> and <a href="https://steampipe.io/#connection-configuration-management-in-steampipe">connection configuration</a> features.</p><h2 id="aws-multi-region-queries-with-steampipe">AWS multi-region queries with Steampipe</h2><p>Starting with version <code>0.2.0</code> of the Steampipe CLI and version <code>0.5.0</code> of the <a href="https://hub.steampipe.io/plugins/turbot/aws">Steampipe AWS Plugin</a> you can perform multi-region queries that execute in parallel against all AWS regions within your account (see below for multi-account too).</p><br><div><div><div><div><p>&gt;</p><div><pre><code><p><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>select</span><span></span></p><p><span>  region</span><span>,</span><span></span></p><p><span>  instance_id</span><span>,</span><span></span></p><p><span>  instance_state</span><span>,</span><span></span></p><p><span>  instance_type</span><span>,</span><span></span></p><p><span>  title</span></p><p><span></span><span>from</span><span> </span></p><p><span>  aws_ec2_instance</span><span>;</span></p></code><span></span></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 244.685827ms
    </pre></div></div></div><h3 id="how-can-it-be-so-fast">How can it be so fast?</h3><p>Steampipe is smart! When you execute a query it fans out concurrent connections to the configured regions, aggregates the results and then presents them to you as one result set. The speed of the query is just limited to the speed of the slowest regional response.</p><h2 id="blazing-fast-query-response-with-new-query-caching">Blazing fast query response with new query caching</h2><p>Believe it or not, we can go even faster. Once you enable the new query caching feature, subsequent queries to the same data source will operate out of the in-memory cache, and return result sets in the blink of an eye.</p><h3 id="fast-1-second">Fast (1 Second)</h3><p>The first time you query a connection, Steampipe needs to create and authenticate API connections, in this case it took a little over 1 second to establish connections across 16 AWS regions and return results.</p><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 1.045864439s
    </pre></div></div></div><h3 id="real-fast-Â¼-second">Real Fast (Â¼ Second)</h3><p>With the connections now cached, the same query returns in less than Â¼ second.</p><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 243.693268ms
    </pre></div></div></div><h3 id="blazing-fast---1-microsecond">Blazing Fast ( &lt; 1 Microsecond)</h3><p>With query caching enabled, subsequent queries to the same table are more than 1000x faster!</p><div><div><div><div><div><pre><code><p><span>$ export STEAMPIPE_CACHE</span><span>=</span><span>true</span><span></span></p><p><span>$ steampipe query</span></p><p><span></span><span>&gt;</span><span> </span><span>.</span><span>timing </span><span>on</span><span></span></p><p><span></span><span>&gt;</span><span> </span><span>select</span><span> region</span><span>,</span><span> instance_id</span><span>,</span><span> instance_state</span><span>,</span><span> instance_type</span><span>,</span><span> title </span><span>from</span><span> aws_ec2_instance</span><span>;</span></p></code></pre></div></div></div><div><pre>
+-----------+---------------------+----------------+---------------+-----------------+
| region    | instance_id         | instance_state | instance_type | title           |
+-----------+---------------------+----------------+---------------+-----------------+
| eu-west-1 | i-003d889c8dc91f939 | running        | t3.medium     | Dev Bastion     |
| eu-west-2 | i-072ee9d889c80c59a | running        | m5a.large     | Squid           |
| us-east-1 | i-0667842133f5baeb7 | stopped        | t3.large      | WinBastion      |
| us-east-2 | i-059b0d1eaa04232f8 | running        | t3.large      | ECS Host        |
| us-east-2 | i-0e6f804203eb894eb | running        | t2.micro      | Linux Bastion   |
+-----------+---------------------+----------------+---------------+-----------------+
Time: 653.39Âµs
    </pre></div></div></div><h2 id="connection-configuration-management-in-steampipe">Connection configuration management in Steampipe</h2><p>Regardless of what cloud you are working with, you are likely to need connections to more than one environment.  Everyone has multiple Slack channels and Github repositories that we work with and most cloud pros have multiple AWS accounts that they work with on a daily basis.</p><p>The latest Steampipe release now makes it even easier to work with (and across multiple api connections). This example shows how to configure multiple AWS accounts in a single Steampipe configuration:</p><div><div><div><div><div><div><div><pre><code><p><span>connection </span><span>"dmi_scranton"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"scranton"</span><span></span></p><p><span>  regions     = </span><span>[</span><span>"us-east-2"</span><span>]</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span>connection </span><span>"dmi_albany"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"albany"</span><span></span></p><p><span>  regions     = </span><span>[</span><span>"us-east-1"</span><span>]</span><span></span></p><p><span></span><span>}</span><span> </span></p><p><span>connection </span><span>"dmi_global"</span><span> </span><span>{</span><span></span></p><p><span>  plugin      = </span><span>"aws"</span><span> </span></p><p><span>  profile     = </span><span>"dmi_corp"</span><span></span></p><p><span>  regions     = </span><span>[</span><span></span></p><p><span>    </span><span>"eu-west-1"</span><span>,</span><span> </span></p><p><span>    </span><span>"eu-west-2"</span><span>,</span><span> </span></p><p><span>    </span><span>"us-east-1"</span><span>,</span><span> </span></p><p><span>    </span><span>"us-east-2"</span><span></span></p><p><span>  </span><span>]</span><span></span></p><p><span></span><span>}</span></p></code></pre></div></div></div></div></div></div></div><p>In the example above, I chose different <code>[profiles]</code> from my <code>~/.aws/config</code> configuration for the connection credentials. You can optionally configure Steampipe to use <code>access key/secret key</code> pairs instead of your AWS profile if desired. After changing any .spc configuration, restart Steampipe. </p><p>Each account configuration creates a separate <code>namespace</code> in the Steampipe embedded Postgres DB; this allows us to query different accounts using standard <code>schema.table_name</code> syntax:</p><div><div><div><div><div><div><p>&gt;</p><div><pre><code><p><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_albany</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>2</span><span>     </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_scranton</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>34</span><span>    </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>select</span><span> </span></p><p><span>  </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span></p><p><span></span><span>from</span><span>  </span></p><p><span>  dmi_global</span><span>.</span><span>aws_s3_bucket</span><span>;</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> count </span><span>|</span><span></span></p><p><span></span><span>+</span><span></span></p><p><span></span><span>|</span><span> </span><span>15</span><span>    </span><span>|</span><span></span></p><p><span></span><span>+</span></p></code></pre></div></div></div></div></div></div></div><p>Aggregating results across accounts can be as simple as an SQL <code>union</code> statement:</p><div><div><div><div><div><div><div><pre><code><p><span>&gt;</span><span> </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_scranton</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span></p><p><span>  </span><span>union</span><span></span></p><p><span>  </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_albany</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span></p><p><span>  </span><span>union</span><span></span></p><p><span>  </span><span>select</span><span> account_id</span><span>,</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> buckets</span></p><p><span>  </span><span>from</span><span> dmi_global</span><span>.</span><span>aws_s3_bucket</span></p><p><span>  </span><span>group</span><span> </span><span>by</span><span> account_id</span><span>;</span></p></code></pre></div></div></div><div><pre>
   +--------------+-------+
   | account_id   | count |
   +--------------+-------+
   | 111222333444 | 2     |
   | 444555666777 | 15    |
   | 888899990000 | 34    |
   +--------------+-------+
    </pre></div></div></div></div></div><h2 id="yes-we-think-that-is-super-cool-too--get-started-today">Yes, we think that is super cool too!  Get started today.</h2><p>Seeing Steampipeâ€™s multi-region and multi-account queries definitely put a smile on our product teamâ€™s face, we hope it is both delightful and a huge time saver for you in your day-to-day cloud work.  For even more good stuff, checkout the <a href="https://github.com/turbot/steampipe/blob/main/CHANGELOG.md">full release notes on Steampipe v0.2.0</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://steampipe.io/blog/release-0-2-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275128</guid>
            <pubDate>Fri, 26 Feb 2021 14:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choose the Browser Carefully]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26275103">thread link</a>) | @axiomdata316
<br/>
February 26, 2021 | https://unixsheikh.com/articles/choose-your-browser-carefully.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/choose-your-browser-carefully.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Published on <span id="pubdate">2020-10-20</span>. Updated on <span id="moddate">2020-10-26</span></p>
<p><a href="https://en.wikipedia.org/wiki/Internet_privacy">Privacy on the Internet</a> is important because privacy risks range from the gathering of statistics on users to more malicious acts such as the spreading of spyware and the exploitation of various forms of bugs (software faults). Many companies, such as Google, track which websites people visit and then use the information, for instance by sending advertising based on one's web browsing history. Sometimes prices on products are changed on the same website, depending on tracking information, and two people may view the exact same product on the exact same website yet be presented with very different prices.</p>

<h3>Table of contents</h3>
<ul>
<li><a href="#privacy-compromising">Introduction</a></li>
<li><a href="#third-party-clones">Third party clones</a></li>
<li><a href="#privacy-compromising">Privacy compromising browsers</a>
    <ul>
    <li><a href="#firefox">Mozilla Firefox</a></li>
    <li><a href="#chrome">Google Chrome and Chromium</a></li>
    <li><a href="#brave">Brave</a></li>
    <li><a href="#palemoon">Palemoon</a></li>
    <li><a href="#waterfox">Waterfox</a></li>
    <li><a href="#librewolf">Librewolf</a></li>
    <li><a href="#epiphany">GNOME Web (Epiphany) and Eolie</a></li>
    <li><a href="#midori">Midori</a></li>
    <li><a href="#other-problematic-browsers">Other problematic browsers</a></li>
    </ul>
</li>
<li><a href="#alternatives">Privacy respecting browsers</a></li>
<ul>
<li><a href="#tweaking-firefox">Tweaking Firefox - the best solution</a>
    <ul>
    <li><a href="#control">Controlling Firefox's DNS over HTTPS</a></li>
    <li><a href="#blocking">Blocking DoH via a firewall</a></li>
    </ul>
</li>
<li><a href="#falkon">Falkon</a></li>
<li><a href="#qutebrowser">qutebrowser</a></li>
<li><a href="#icecat">GNU IceCat</a></li>
<li><a href="#ungoogled-chromium">ungoogled-chromium</a></li>
<li><a href="#tor">Tor browser</a></li>
<li><a href="#other-okay-browsers">Other okay browsers</a></li>
</ul>
<li><a href="#recommended-extensions">Recommended extensions</a></li>
    <ul>
    <li><a href="#noscript">NoScript</a></li>
    <li><a href="#ublock-origin">uBlock Origin</a></li>
    <li><a href="#https-everywhere">HTTPS Everywhere</a></li>
    </ul>
<li><a href="#conclusions">Conclusions</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>This article isn't specifically about privacy issues only, it's about promises that are being broken, which might be about privacy. It is also about the lack of user freedom, as in the choice to enable or disable features, such as automatic updates, or forced usage of third party services, or software that the user generally is unaware of or don't have a say about.</p>

<p>Privacy as a subject regarding the usage of services on the Internet is a very difficult subject to deal with. Not only can it be difficult to actually define privacy, but it also requires a balance between freedom of choice by the users, security and usability. Naturally you need to be able to use the browser on the Internet and as such you will always leave some kind of trail behind, and this article is not about how you can hide your tracks. What I am addressing in this article are browsers that are either promoted as "privacy-respecting" by the developers, or in general are considered to be so (mostly due to misunderstanding or misinformation), while it is very clear they are not.</p>

<p>Some browsers either directly violate users by collecting telemetric data without consent, or you have to opt-out rather than opt-in, or they bounce around the Internet visiting places in the background without you knowing (using dns-prefetch or automatic updates etc.), using third party services that operates with a privacy policy you either cannot trust, or that are directly violating your privacy, or they have integrated third party software that do some of these things.</p>

<p>I will try to keep this article updated with relevant information as much as possible. I know several other browsers exist, but if they are not mentioned on this list I have either not had a change to investigate them, they are closed source and completely irrelevant (such as Microsoft Edge or Opera), or they are not actively maintained, or they cannot perhaps be trusted for some reason or another.</p>

<p>I will also <b>not</b> be looking at browsers that only work on Microsoft Windows or macOS, even if they are Open Source. Both Microsoft Windows and macOS are highly controversial and completely untrustworthy operating systems.</p>

<p>Also please note that just because the developers of a browser are promising that their browser is privacy-respecting doesn't mean that you can trust the information. As you will see with the examples of some of the browsers below even developers some times compromise user privacy perhaps without even thinking about it.</p>

<p>I also want to make a strong advice to people recommending browsers to other people without investigation or knowledge. The <a href="https://old.reddit.com/r/privacy/">privacy related channel on Reddit</a> is filled with wrong recommendations regarding privacy-respecting browsers and many people are merely guessing or blindly trusting the information the browser producers are publishing. Neither Mozilla Firefox, Google Chrome or Chromium, Brave, Waterfox, or several of the other recommended browsers truly respect privacy. They all do some form of telemetry and/or privacy-compromising actions without the user consenting to it or even knowing about it.</p>

<p>Also, privacy doesn't mean that you simply pull out telemetry from Firefox, rebrand it, and then ship it. Privacy is more than that. Unless the browser is automatically checking for an updated version, and the website isn't logging that request, it cannot be considered truly private if the browser starts bouncing around on the Internet visiting all kinds of places without the user has done anything more than open the browser up! Every time the browser makes a DNS request, that DNS request is in most cases logged unless the user actively does something to mitigate that - such as using a trusted VPN or non-logging DNS service etc. Furthermore, the Mozilla add-on CDN is logging user activity, as is <a href="https://en.wikipedia.org/wiki/Amazon_CloudFront">Amazon Cloudfront</a>, so if the browser visits these places without the user explicitly pushes a "check for updates" option, the browser is compromising user privacy. The point I'm trying to make is that the user needs to have the choice and that nothing happens until the user actively do something.</p>

<p>Last, but not least, if you discover any mistakes on my part, feel free to email me about it so that I can correct the information.</p>

<h2 id="privacy-compromising">Privacy compromising browsers</h2>

<h3 id="firefox">Mozilla Firefox</h3>
<p>In the past I have always supported Mozilla and promoted <a href="https://en.wikipedia.org/wiki/Firefox">Firefox</a>, but Mozilla has made some pretty controversial decisions as of late and I no longer feel that Mozilla is an organization that deserves any support. Not unless they change the way they conduct their business.</p>
<p>Firefox is promoted by Mozilla as a privacy-respecting browser, but this is highly misleading. Firefox "phones home" every time you start it up even when you have disabled telemetry and automatic updates of extensions. Domains such as mozilla.org, cloudfront.net, firefox.settings.services.mozilla.com (see: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12">https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12</a>), autopush.prod.mozaws.net, detectportal.firefox.com and location.services.mozilla.com are visited each time you start Firefox.</p>
<p>In 2017 Mozilla made a <a href="https://en.wikipedia.org/wiki/Cliqz#Integration_with_Firefox">deal with Cliqz</a> where approximately 1% of users downloading Firefox in Germany would receive a version with Cliqz software included. And in 2018 Mozilla revealed that they had no data on the number of Firefox installations with disabled Telemetry.</p>
<p>Mozilla then developed the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1487578">Telemetry Coverage</a> system and distributed it to 1% of the Firefox installations. The system is automatically installed and designed to inform Mozilla whether telemetry is enabled in the browser.</p>
<p>Mozilla also <a href="https://support.mozilla.org/en-US/kb/telemetry-collection-windows-default-browser-trend">developed a Windows-only scheduled task</a> which runs in the background once a day for each installation of Firefox installed on a computer running Microsoft Windows. The task collects information related to the system's current and previous default browser setting and the operating system locale and version.</p>
<p>This is a list of some of the things that Mozilla collects: <a href="https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content">https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content</a>.</p>
<p>On the <a href="https://www.mozilla.org/en-US/about/">Mozilla website</a> we can read (when I originally started writing this article) that <q>We put people over profit</q>, and <q>a product to support user privacy</q>. We can also read in the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla manifesto</a>, in the fourth principle, that <q>Individuals' security and privacy on the internet are fundamental and must not be treated as optional.</q> However, with their decision to make Cloudflare the default DNS provider for DNS over HTTPS, they are definitely not supporting user privacy or putting people over profit!</p>
<p>DNS over HTTPS is by itself <a href="https://www.youtube.com/watch?v=ZxTdEEuyxHU">bad enough</a>, and <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS#Criticism">highly criticized</a> with <a href="https://www.zdnet.com/article/dns-over-https-causes-more-problems-than-it-solves-experts-say/">very good reason</a>, but combining it with a US based company like Cloudflare makes it even worse. Cloudflare <a href="https://old.reddit.com/r/privacy/comments/d52kop/eli5_why_cloudflare_is_depicted_as_evil_and_whats/f0jrxox/">cannot be trusted</a> with DNS requests.</p>
<p>Cloudflare has made an <a href="https://developers.cloudflare.com/1.1.1.1/commitment-to-privacy/privacy-policy/firefox/">agreement</a> with Mozilla that when it acts as a DNS resolver for Firefox, that:</p>
<ul>
<li>DNS requests will be stored as part of Cloudflare's "temporary" logs which are permanently deleted within 24 hours.</li>
<li>Cloudflare will also collect and store the following information as part of its permanent logs:
<ul>
<li>Total number of requests processed by each Cloudflare co-location facility.</li>
<li>Aggregate list of all domain names requested.</li>
<li>Samples of domain names queried along with the times of such queries.</li>
</ul>
</li>
<li>Information stored in Cloudflare's permanent logs will be anonymized and may be held indefinitely by Cloudflare for its own internal research and development purposes.</li>
</ul>
<p>Anyone who has worked with DNS servers knows what goes into such logs and in order for Cloudflare to keep their promise they need to: Delete the DNS requests information, but at the same time somehow still keep "anonymized" logs of the total number of requests, a list of all domain names requested, a so-called "sample" of complete DNS queries along with date and time.</p>
<p>This means that even if Cloudflare could be trusted and they have the best of intentions, they will still log everything the first 24 hours. If Cloudflare is ever compromised all these logs could be copied and distributed over a period of time.</p>
<p>Furthermore, the actual wording of the agreement is such that the technical procedure for how they actually do this can only be guessed at. How do they plan to anonymize the data? Is the "sample" 99.9% of all the queries, or is it 1%?</p>
<p>Last, but not least, Cloudflare is an American company subject to American law, a law that pretty much undermines the foundation of any kind of privacy.</p>
<blockquote>
<p>Cloudflare will not retain or sell or transfer to any third party (except as may be required by law) any personal information, IP addresses or other user identifiers from the DNS queries sent from the Firefox browser to the Cloudflare Resolver for Firefox;</p>
</blockquote>
<p>Real privacy means:</p>
<ul>
<li><b>No logging</b></li>
<li><b>No data retention</b></li>
<li><b>No phoning home without consent before doing so</b></li>
<li><b>No user opt-out telemetry, it has to be opt-in</b></li>
<li><b>Real and 100% transparency regarding …</b></li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unixsheikh.com/articles/choose-your-browser-carefully.html">https://unixsheikh.com/articles/choose-your-browser-carefully.html</a></em></p>]]>
            </description>
            <link>https://unixsheikh.com/articles/choose-your-browser-carefully.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275103</guid>
            <pubDate>Fri, 26 Feb 2021 14:30:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cuboid: A DIY air purifier that's better than a box fan]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 121 (<a href="https://news.ycombinator.com/item?id=26275091">thread link</a>) | @dynm
<br/>
February 26, 2021 | https://dynomight.net/better-DIY-air-purifier.html | <a href="https://web.archive.org/web/*/https://dynomight.net/better-DIY-air-purifier.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            <p>
            
            <strong>Feb 26, 2021</strong> &nbsp; (Updated Feb 7, 2021)
            
            </p>

            <p>I love box-fan based air purifiers. They are cheap, trivial to build, and people around the world have done experiments to show they <a href="https://dynomight.net/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">actually work</a>.</p>

<p>Still, box-fan purifiers have two downsides: They create a lot of noise, and they consume a fair amount of electricity.</p>

<p>I wanted a new design that preserves the best aspects of using a box-fan:</p>

<ol>
  <li>Cheap.</li>
  <li>Easily built with no tools.</li>
  <li>No proprietary parts.</li>
  <li>Good at purifying the air.</li>
</ol>

<p>The design should also fix the worst parts of using a box fan:</p>

<ol>
  <li>Make less noise.</li>
  <li>Use less electricity.</li>
</ol>

<p>I think I’ve found such a design. Behold, the Cuboid:</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/cuboid.jpg" alt="Cuboid DIY purifier">
</p>

<h2 id="performance-summary">Performance summary</h2>

<p>I’ve done some experiments comparing this to a <a href="https://dynomight.net/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">box-fan based purifier</a>, using the same filters.  Here’s a summary.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>Cost to build</td>
    <td colspan="3">$71.50</td>
    <td colspan="3">$100</td>
</tr>
<tr>
    <td>Time to build</td>
    <td colspan="3">30 s</td>
    <td colspan="3">5 min</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>18.4</td>
    <td>13.2</td>
    <td>9.6</td>
    <td>15.1</td>
    <td>10.3</td>
    <td>6.9</td>
</tr>
<tr>
    <td>PM 2.5 CADR (m³/min)</td>
    <td>1.15</td>
    <td>1.58</td>
    <td>2.17</td>
    <td>1.40</td>
    <td>2.02</td>
    <td>2.95</td>
</tr>
<tr>
    <td>Sound level (dB)</td>
    <td>43</td>
    <td>48</td>
    <td>55</td>
    <td>16</td>
    <td>39</td>
    <td>51</td>
</tr>
<tr>
    <td>Power usage (W)</td>
    <td>65.4</td>
    <td>76.4</td>
    <td>96.0</td>
    <td>22.6</td>
    <td>40.3</td>
    <td>51.3</td>
</tr>
<tr>
    <td>Power cost/year ($)</td>
    <td>74.4</td>
    <td>87.0</td>
    <td>109.3</td>
    <td>25.73</td>
    <td>45.9</td>
    <td>58.4</td>
</tr>
<tr>
    <td>Resembles IED</td>
    <td colspan="3">★☆☆☆</td>
    <td colspan="3">★★★☆</td>
</tr>
</tbody>
</table>
</div>

<p>Less is better for everything except the clean air delivery rate (CADR). The half-life is calculated in a 31 m³ room. Electricity costs assume operation 24 hours/day at 1 kWh = $0.13.</p>

<p>As you can see, the cuboid gives major improvements in noise and electricity consumption, with small regressions in cost, difficulty of construction, and IED resemblance. Particularly on low, the cuboid is very quiet and energy-efficient. Somewhat accidentally, it’s also better at removing particles.</p>

<h2 id="contents">Contents</h2>

<ul id="markdown-toc">
  <li><a href="#performance-summary" id="markdown-toc-performance-summary">Performance summary</a></li>
  <li><a href="#contents" id="markdown-toc-contents">Contents</a></li>
  <li><a href="#the-fanfilter-tradeoff" id="markdown-toc-the-fanfilter-tradeoff">The fan/filter tradeoff</a></li>
  <li><a href="#how-to-build-it" id="markdown-toc-how-to-build-it">How to build it</a>    <ul>
      <li><a href="#materials-used" id="markdown-toc-materials-used">Materials used</a></li>
      <li><a href="#step-1-form-a-column-out-of-the-filters" id="markdown-toc-step-1-form-a-column-out-of-the-filters">Step 1: Form a column out of the filters</a></li>
      <li><a href="#step-2-cut-out-a-base-for-the-column" id="markdown-toc-step-2-cut-out-a-base-for-the-column">Step 2: Cut out a base for the column</a></li>
      <li><a href="#step-3-cut-out-a-base-for-the-fan" id="markdown-toc-step-3-cut-out-a-base-for-the-fan">Step 3: Cut out a base for the fan</a></li>
      <li><a href="#step-4-set-the-fan-on-the-filter-column" id="markdown-toc-step-4-set-the-fan-on-the-filter-column">Step 4: Set the fan on the filter column</a></li>
    </ul>
  </li>
  <li><a href="#cost" id="markdown-toc-cost">Cost</a></li>
  <li><a href="#measuring-filtering-performance" id="markdown-toc-measuring-filtering-performance">Measuring filtering performance</a>    <ul>
      <li><a href="#experimental-setup" id="markdown-toc-experimental-setup">Experimental setup</a></li>
      <li><a href="#results" id="markdown-toc-results">Results</a></li>
      <li><a href="#fitting-exponential-curves" id="markdown-toc-fitting-exponential-curves">Fitting exponential curves</a></li>
      <li><a href="#clean-air-delivery-rate-calculations" id="markdown-toc-clean-air-delivery-rate-calculations">Clean air delivery rate calculations</a></li>
    </ul>
  </li>
  <li><a href="#measuring-noise" id="markdown-toc-measuring-noise">Measuring noise</a></li>
  <li><a href="#measuring-energy-usage" id="markdown-toc-measuring-energy-usage">Measuring energy usage</a></li>
  <li><a href="#discussion" id="markdown-toc-discussion">Discussion</a>    <ul>
      <li><a href="#the-upper-limit" id="markdown-toc-the-upper-limit">The upper limit</a></li>
      <li><a href="#should-you-bother-building-a-cuboid" id="markdown-toc-should-you-bother-building-a-cuboid">Should you bother building a Cuboid?</a></li>
      <li><a href="#when-is-airflow-helpful" id="markdown-toc-when-is-airflow-helpful">When is airflow helpful?</a></li>
      <li><a href="#the-competition" id="markdown-toc-the-competition">The competition</a></li>
      <li><a href="#advice" id="markdown-toc-advice">Advice</a></li>
      <li><a href="#you-might-ask" id="markdown-toc-you-might-ask">You might ask</a></li>
    </ul>
  </li>
</ul>

<h2 id="the-fanfilter-tradeoff">The fan/filter tradeoff</h2>

<p>Air purifiers push air through filters. If you’ve ever built a box-fan-based air purifier, you noticed that once you attach HEPA filters, throughput decreases dramatically. If you use a weak fan, it will barely push any air at all.</p>

<p>Fundamentally, if you want to increase purification, you have two options:</p>
<ul>
  <li><strong>Big fan</strong>: Keep the same amount of filter, but run a bigger/faster motor to push air through it faster.</li>
  <li><strong>Big filter</strong>: Keep the same fan, but install more filters in parallel. This will decrease the pressure on each of them, meaning more total airflow.</li>
</ul>

<p>If we want to be quiet and energy-efficient, the choice is clear: Use a relatively weak fan, but with a large a filter surface area.</p>

<p>Using more filters has a higher upfront cost — filters aren’t free. However, that extra cost disappears over time. If each filter can remove a fixed amount of particulates before it needs to be replaced, then doubling the number of filters means also doubling the replacement interval.</p>

<h2 id="how-to-build-it">How to build it</h2>

<p>(Contact me if you want the exact products I used.)</p>

<h3 id="materials-used">Materials used</h3>

<ul>
  <li>An 8inch (20.32cm) diameter inline duct booster fan ($30).</li>
  <li>Four HEPA air filters, each approximately 32 cm x 22 cm and 5cm thick ($70 for all).</li>
  <li>Two bungee cords (free).</li>
  <li>Tape (free).</li>
  <li>Two pieces of packaging foam (free).</li>
</ul>

<p>Inline duct <em>booster</em> fans are fairly weak fans often used to help with grow rooms or range hoods. An <em>inline duct fan</em> would probably perform even better (see the <a href="#discussion">discussion</a>) but at a higher cost. The one I bought is rated to push around 12 m³ of air per minute.</p>

<p>You can use filters and fans of different sizes if you want. All that matters is that the fan has a smaller diameter than the filters (20.32 cm &lt; 22 cm). The pieces of foam also need to be at least as large as the matching dimension of the filter. I just used the foam that my fan was shipped in.</p>

<h3 id="step-1-form-a-column-out-of-the-filters">Step 1: Form a column out of the filters</h3>

<p>Take the four filters, and assemble them into a vertical structure. Be careful to align the edges as you see in the middle, with two sides slightly “inside” of the other sides.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step1.jpg" alt="Step 1 of construction" loading="lazy">
</p>

<p>This column is somewhat unstable, but we’ll deal with that.</p>

<h3 id="step-2-cut-out-a-base-for-the-column">Step 2: Cut out a base for the column</h3>

<p>Cut one piece of foam to the size of the square at the bottom of the filter column (I taped over a hole in the foam I used.) Place it at the bottom.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step2.jpg" alt="Step 2 of construction" loading="lazy">
</p>

<p>I did this by setting the filters on top of the foam, tracing out the shape with a pencil, and then cutting the foam with scissors. You probably want to err on the side of making it larger and trim if necessary. It should fit firmly so that it’s held in place by the filters.</p>

<p>Strictly speaking, you could also probably skip this step. I did that in an early version and it was OK. However, this adds a lot of stability allows the purifier to work even if it isn’t on top of a flat surface. You could also substitute some other material for the foam.</p>

<h3 id="step-3-cut-out-a-base-for-the-fan">Step 3: Cut out a base for the fan</h3>

<p>Cut another piece of foam so that it supports the fan from below while holding the fan in place. This should be large enough so that that the piece will sit on top of the filters.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step3.jpg" alt="Step 3 of construction" loading="lazy">
</p>

<p>As you can see, the foam was missing a corner, which I solved inelegantly by gluing on a piece of cardboard.</p>

<h3 id="step-4-set-the-fan-on-the-filter-column">Step 4: Set the fan on the filter column</h3>

<p>Set the fan+foam on top of the filters, oriented so it will blow air <em>upward</em>, and pull air through the filters.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/step4.jpg" alt="Step 4 of construction" loading="lazy">
</p>

<p>That’s it, you’re done. The top is only held on by gravity, plus pressure if it’s on. You could obviously make this more stable or beautiful, but I wanted to focus on a design that’s <em>really</em> easy to build.</p>

<h2 id="cost">Cost</h2>

<p>The only significant cost is the fan ($30) and the filters ($70 for 4). This is more expensive than a box fan design, where the fan costs $19 and you only need 2 or 3 filters. However, as mentioned <a href="#the-fanfilter-tradeoff">above</a>, the cost of extra filters evens out in the long run since they need to be replaced half as often.</p>

<h2 id="measuring-filtering-performance">Measuring filtering performance</h2>

<h3 id="experimental-setup">Experimental setup</h3>

<p>I did experiments in a room with a volume of around 31 m³. To generate smoke, I cut 5 credit-card length sticks of incense and placed them on one end of a table. On the other end of the table, I placed a tablet that took a time-lapse video of a particle counter and a stopwatch. I then manually transcribed the measurements from this video.</p>

<p>The purifier (box fan or cuboid) was on the ground around a meter from the particle counter.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/setup.jpg" alt="setup for measuring air purification performance" loading="lazy">
</p>

<h3 id="results">Results</h3>

<p>As a comparison, I attached three of the same filters to a box fan (Literally the <em>same</em> filters).</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/boxfan.jpg" alt="DIY box fan compared to">
</p>


<p>Here are the results with the cuboid. Note that the y-axis is logarithmic. The straight lines indicate that particulates are decreasing at an exponential rate.</p>

<p><a href="https://dynomight.net/img/cuboid_purifier/cuboid_performance_cropped.svg">
<img src="https://dynomight.net/img/cuboid_purifier/cuboid_performance_cropped.svg" alt="performance of the cuboid on different fan speeds">
</a>
</p>

<p><br>
Here are the results of the box fan.</p>

<p><img src="https://dynomight.net/img/cuboid_purifier/boxfan_performance_cropped.svg" alt="performance of the box fan on different fan speeds" loading="lazy">
</p>



<p>You’ll notice two things. First and most importantly, the slopes for the cuboid graphs are steeper. This indicates better performance.</p>

<p>Second, the particles peak at higher values with the cuboid. I believe this is because the incense was near the particle counter on a table, while the purifiers were sitting on the floor 2m away. If the air isn’t disturbed, it takes a while before smoke drifts over the purifier and it actually starts doing anything. However, the box fan creates so much wind that the smoke immediately diffuses around the room and the box-fan purifier essentially gets a “head start”.</p>

<p>While wind seems to help here, it could be harmful in other cases. I discuss this more <a href="#when-is-airflow-helpful">below</a>.</p>

<h3 id="fitting-exponential-curves">Fitting exponential curves</h3>

<p>The y-axes in the plots above are logarithmic. As you can see from the dotted lines, these are well-fit by straight lines. This is what we’d expect if a fixed fraction of the air were being cleaned per minute.</p>

<p>The dotted lines for each curve show a fit of the form <strong>y=a×bᵐ</strong>, where <strong>y</strong> is the level of particulates, <strong>m</strong> is the number of minutes, and <strong>a</strong> and <strong>b</strong> are constants.</p>

<p>We can convert a fit of this type to a half-life: The number of minutes the purifier needs to eliminate half the particles from the air when running in a 31 m³ room.  That would be the number of minutes <strong>m</strong> such that <strong>bᵐ = .5</strong>. We can solve this equation as <strong>b = log(.5) / log(b)</strong>.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 fit</td>
    <td>90×.963ᵐ</td>
    <td>90×.949ᵐ</td>
    <td>65×.93ᵐ</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>18.4</td>
    <td>13.2</td>
    <td>9.6</td>
</tr>
</tbody>
</table>
</div>



<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 fit</td>
    <td>300×.955ᵐ</td>
    <td>280×.935ᵐ</td>
    <td>180×.905ᵐ</td>
</tr>
<tr>
    <td>PM 2.5 half-life (mins)</td>
    <td>15.1</td>
    <td>10.3</td>
    <td>6.9</td>
</tr>
</tbody>
</table>
</div>

<h3 id="clean-air-delivery-rate-calculations">Clean air delivery rate calculations</h3>

<p>One common way of estimating the performance of purifiers is the clean air delivery rate (CADR). If the air that came out of the purifier had zero particulates, this would just be the volume of air per unit of time.</p>

<p>The fits above were of the form <strong>y=a×bᵐ</strong>. This means that the number of particulates drops by a factor of <strong>b</strong> each minute.</p>

<p>Here’s how I calculated the CADR. Note that that if the purifier delivered <strong>(cleaned air) m³</strong> of clean air in a single minute in a room with a total volume of <strong>(all air) m³</strong>, then the particulates in a room would drop by a factor of</p>

<p><b>b=(uncleaned air)/(all air)= 1 - (cleaned air) / (all air)</b>
</p>
<p><br>
per minute. We can solve this to find that equation to get that</p>

<p><b>(cleaned air) = (all air)×(1-b).</b>
</p>


<p>I measured the dimensions of the room where I did these measurements. I estimated it was 31m³. From this, I computed the CADR for each purifier and speed as <strong>CADR = 31×(1-b)</strong>. This gives the following table of CADR rates.</p>

<div>
<table>
<thead>
<tr>
    <th>Purifier</th>
    <th colspan="3">Box fan</th>
    <th colspan="3">Cuboid</th>
</tr>
<tr>
    <th>Fan speed</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
    <th>low</th>
    <th>med</th>
    <th>high</th>
</tr>
</thead>
<tbody>
<tr>
    <td>PM 2.5 CADR (m³/min)</td>
    <td>1.15</td>
    <td>1.58</td>
    <td>2.17</td>
    <td>1.40</td>
    <td>2.02</td>
    <td>2.95</td>
</tr>
<tr>
    <td>PM 2.5 CADR (ft³/min)</td>
    <td>40.5</td>
    <td>55.8</td>
    <td>76.6</td>
    <td>49.2</td>
    <td>71.1</td>
    <td>104</td>
</tr>
</tbody>
</table>
</div>


<p>A recent <a href="https://www.cbc.ca/1.5900782">study</a> from the University of Toronto also measured the CADR of a similar box-fan purifier. They measure around 92 ft³/min. (They don’t give numbers, but there’s a <a href="https://i.cbc.ca/1.5902727.1612545406!/fileImage/httpImage/image.png_gen/derivatives/original_1180/air-purifiers-graph.png">graph</a> CADR=100 is 130 pixels high and the box fan is 100 pixels high.) This is reassuringly close to my estimate of 76.6. I’d put a confidence band of around 20% on my numbers …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dynomight.net/better-DIY-air-purifier.html">https://dynomight.net/better-DIY-air-purifier.html</a></em></p>]]>
            </description>
            <link>https://dynomight.net/better-DIY-air-purifier.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275091</guid>
            <pubDate>Fri, 26 Feb 2021 14:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Text Summarization in PDF Documents with Faster R-CNN and PEGASUS]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26275071">thread link</a>) | @konfuzio
<br/>
February 26, 2021 | https://konfuzio.com/de/automatic-text-summarization-in-pdf-files | <a href="https://web.archive.org/web/*/https://konfuzio.com/de/automatic-text-summarization-in-pdf-files">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Today, rising amounts of documents and the contained information have to be processed by enterprises to be able to use the hidden content. This is either done by time-expensive manual text summarization or by using an automatization solution. Automatic text summarization helps humans to efficiently process the growing volume of information.&nbsp;</p><h4>What exactly is automatic text summarization?</h4><p>The Oxford English dictionary defines automatic text summarization as “the creation of a shortened version of a text by a computer program. The product of this procedure still contains the most important points of the original text.” [1]</p><p>A good example where summarization can be useful is the annual reports of companies. Those documents contain a lot of facts that can be crucial for investors since they include information on many factors such as sustainability or environmental policies which can help for the investors‘ decision. However, the annual reports are normally very long documents with hundreds of pages, which makes their analysis a time consuming process that could be facilitated by an automatic workflow.&nbsp;</p><h2>How can we summarize text in PDF files?</h2><p>We divide the process in three main parts. For each of those steps we go more into detail in the following sections of this article. Feel free to jump right into the details or let us first walk you through the main outcomes of each step.</p><h3>1. Use Object Detection for Page Segmentation</h3><p>In the first step, we need to select those parts of the document that have to be focused on. While we can get a lot of already summarized information from images, graphs, and headlines, it is the text that is the most complete source of information. A possible way to split the document in different components is to use a computer vision approach. A model for multiclass object detection can automatically differentiate between different elements in the annual report. All content can be split into five categories: title, text, table, list, and figure. Only the found locations of the category text are used for the following steps of the summarization process.</p><h3>2. Use OCR to convert the image to text</h3><p>The next step is to convert the selected bounding boxes of the document into text. This part can be defined as an optical character recognition (OCR) problem, which was resolved using estabilished tools.&nbsp;</p><h3>3. Text Summarization of any paragraph</h3><p>The final step is the summarization of the selected content. So-called Transformers, which lately have proven to be powerful models, come to play. We used the tailored BERT model PEGASUS which is especially designed for automatic summarization. The outcome shows us a summarized version of the paragraph which we detected and extracted from the report in the first steps. The original length of 910 characters was reduced to 193 characters, leading to a time saving of almost 80%. Still, all the relevant information to understand the paragraph is included.</p><h4>This approach shrinks paragraphs in a PDF by 80 %</h4><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/summarize_annual_report.gif" alt=""><figcaption>The result of the automatic text summarization with the PEGASUS model of one paragraph extracted from the annual report shows us a good result. Let’s step through it to check what kind of aspects are included: name of company, likelyhood of an event, amount of the fine, name of the comission.</figcaption></figure><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-650x431.png" alt="" srcset="https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-650x431.png 650w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-300x199.png 300w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-150x100.png 150w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-768x510.png 768w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-1536x1019.png 1536w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924-16x12.png 16w, https://konfuzio.com/wp-content/uploads/2021/02/highres_494905924.png 1611w" sizes="(max-width: 650px) 100vw, 650px"></figure><h4>Join our Meetup talk on the 3rd of March 2021 from 5:00 pm to 6:00 pm GMT+1.</h4><h2>Do you want to learn more right now?</h2><h3>How to use object detection for page segmentation?</h3><p>Object detection is a task where objects of a known class are identified in the image and information about its location is provided. A very known architecture for this task is the Faster R-CNN. This architecture has two outputs for each object: a class label and a bounding-box. It consists of two modules: one deep fully convolutional network to propose regions and a Fast R-CNN that detects objects in those regions.</p><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-600x650.jpg" alt="Faster R-CNN has two outputs for each object: a class label and a bounding-box. " srcset="https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-600x650.jpg 600w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-277x300.jpg 277w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-139x150.jpg 139w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-768x832.jpg 768w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection-11x12.jpg 11w, https://konfuzio.com/wp-content/uploads/2021/02/Object-detection.jpg 1229w" sizes="(max-width: 600px) 100vw, 600px"></figure><p>The way that works is that an input image is fed to a convolutional network that provides a feature map of that image. Then, a separated network (the region proposal network) takes that feature map and predicts possible regions for the objects (region proposals). Those region proposals are fed to a ROI pooling layer that reshapes them into a predefined size. Finally, the output vector from the pooling layer is used to classify the proposed regions and to refine the bounding boxes.&nbsp;</p><p>More recently, Mask R-CNN, which is an extension of the Faster R-CNN, added a third output that allows to have the mask of the object. This results in having the classification, bounding box and the mask of the object.The mask prediction is done in parallel with predicting the class and the bounding box [2].</p><figure><img src="https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-542x650.jpg" alt=" By fine tuning a mask R-CNN model trained in the PubLayNet, we can have a model that allows us to detect those parts of the documents that correspond to text. " srcset="https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-542x650.jpg 542w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-250x300.jpg 250w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-125x150.jpg 125w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-768x920.jpg 768w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs-10x12.jpg 10w, https://konfuzio.com/wp-content/uploads/2021/02/select-paragraphs.jpg 1049w" sizes="(max-width: 542px) 100vw, 542px"></figure><p>The goal is to select only the relevant parts of the report, in our case the text paragraphs. Other parts that already include summaries, like headlines or tables, are not relevant. So the first thing we need is an annotated dataset with the different document elements. PubLayNet is a dataset with annotations of text, figures, titles, lists and tables on more than 360 k pages of scientific papers [3]. By fine tuning a mask R-CNN model trained in the PubLayNet, we can have a model that allows us to detect those parts of the documents that correspond to text. The model that we used is available in the Detectron2 platform, which is a platform from Facebook AI Research that allows fast tests of state of art algorithms [4]. In the figure we can see the bounding boxes and the classification shown with a different color for each class, which was the result without any finetuning. For our problem we are not interested in the mask of the text, just the bounding box highlighted in blue.&nbsp;</p><p>Register for free and try out the page segmentation API with your own documents. <a href="https://app.konfuzio.com/v2/swagger/">Register to access our API documentation.</a> Using our document labeling tool you can create a dataset and fine-tune the PubLayNet model on your own documents.</p><figure><img src="https://lh4.googleusercontent.com/VqjsXgNjS9Na36xmpvqcFjgMbYWtyC4g_Xg0T0lDkggpol3mu1akQpHNWjj6P2T6oNBAPSpKpldVep3liFeX_egvwh2AuaZkbUBHM9wHEZcj_NnuBJ3so110A8g9Ynp45_rCTq9a" alt="Konfuzio API to segment pages via Faster R-CNN."></figure><h3>Wich is the best OCR engine?</h3><p>After having found the portion of the images that we are interested in, the next step is to extract the text from them with the use of optical character recognition (OCR). OCR can be done by computer vision approaches that can include detection, segmentation and recognition of characters but most recent approaches include a combination of CNNs and Recurrent Neural Networks.</p><p>An example of a OCR pipeline can be:</p><ul><li>Text detection – detects where the characters are located</li><li>Pre-processing – the text is normalized</li><li>Feature extraction – the output is the feature map of the image</li><li>Post processing – errors can be corrected by comparing with more common sequences of words, for example.&nbsp;</li></ul><p><a href="https://github.com/kba/awesome-ocr">Several OCR tools can be used.</a> We found the best approach to select the OCR per project. So at <a href="https://konfuzio.com/en/">Konfuzio </a>we integrate different OCR engines. In this video you can see how our API detects handwriting.</p><figure><p> <iframe title="Versteht Konfuzio Handschrift?" width="1170" height="878" src="https://www.youtube.com/embed/zbZgTYflpWk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></figure><h3>How does text summarization work?</h3><p>Summarization is now commonly performed using Transformer models. Transformers are a type of neural network architecture introduced in 2017. They were initially designed for machine translation, but are now used for almost all modern NLP applications, such as: entity recognition, natural language inference, question answering and summarization. Transformers are able to process all incoming data in parallel, in comparison to the previous state-of-the-art models, LSTMs, which processed data sequentially. This ability for parallelization makes them easier to scale up with an exponentially growing amount of compute and data.</p><p>The main novel concept introduced in the Transformer architecture is the use of “multi-head attention”. In the Transformer each element in the input sequence is split into three vectors: Q, K, and V. Attention calculated as a weighted sum of these vectors, where the weights are both learned and are context dependent. In other words, the data input into the model decides where the model should focus its attention. Multi-headed attention implies that we split each vector into multiple “heads” and calculate attention across each head in parallel. Therefore, we perform multiple attention calculations at once, all in parallel, before combining the results together at the output. [5]</p><p>The most commonly used Transformer variant is called BERT. BERT only uses the encoder from the original Transformer with very small architecture changes. The main novelty of BERT is that it was trained as a “masked language model” on a large amount of unlabelled text. Masked language models are tasked with “filling in the blanks” of a given sentence, i.e. given a sentence replace a few of the words with a [MASK] token and then try and predict what the actual word was. It turns out that this task teaches the model a lot about natural language, so much so that it is now common to take a pre-trained BERT model and then fine-tune it your desired task. This is usually a good starting point when trying out neural networks for NLP and most NLP research is now focused on how to improve Transformer models and their variants by either tweaking the architecture or inventing a new pre-training objective.&nbsp;</p><p>PEGASUS is a model designed for automatic summarization. The architecture is similar to the original Transformer, with the decoder, but it is pre-trained on two tasks simultaneously. The first task is the masked language modeling task introduced by BERT. The second task involves predicting an entire sentence that has been masked out in the input. PEGASUS is first pre-trained trained on a huge amount of text, consisting of 1.5 billion news articles and then fine-tuned on the target dataset. It achieved state-of-the-art performance across twelve commonly used summarization datasets. [6].</p><h4>Sources:</h4><p>[1] <a href="https://research.fb.com/publications/mask-r-cnn/" target="_blank" rel="noreferrer noopener">He, K. et al. (2017). Mask R-CNN. Facebook AI Research (FAIR).</a></p><p>[2] <a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank" rel="noreferrer noopener">Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks.&nbsp;</a></p><p>[3] <a href="https://github.com/ibm-aur-nlp/PubLayNet" target="_blank" rel="noreferrer noopener">Zhong, X., Tang, J., &amp; Yepes, A. (2019). PubLayNet: largest dataset ever for document layout analysis. In 2019 International Conference on Document …</a></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://konfuzio.com/de/automatic-text-summarization-in-pdf-files">https://konfuzio.com/de/automatic-text-summarization-in-pdf-files</a></em></p>]]>
            </description>
            <link>https://konfuzio.com/de/automatic-text-summarization-in-pdf-files</link>
            <guid isPermaLink="false">hacker-news-small-sites-26275071</guid>
            <pubDate>Fri, 26 Feb 2021 14:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 10B Solar Masses Black Hole is Missing from One of the biggest galaxies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26274895">thread link</a>) | @sidcool
<br/>
February 26, 2021 | https://www.guardianmag.press/2021/01/a-10-billion-solar-masses-black-hole-is.html | <a href="https://web.archive.org/web/*/https://www.guardianmag.press/2021/01/a-10-billion-solar-masses-black-hole-is.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="https://1.bp.blogspot.com/-KBZGFbjG6xA/YA6MQOzifmI/AAAAAAAAC0k/lkFzURsm48AjBRoLbdgRkH-qrvqY_NevgCLcBGAsYHQ/s750/Abell%2B2261%2B2.jpg"><img data-original-height="445" data-original-width="750" src="https://1.bp.blogspot.com/-KBZGFbjG6xA/YA6MQOzifmI/AAAAAAAAC0k/lkFzURsm48AjBRoLbdgRkH-qrvqY_NevgCLcBGAsYHQ/s16000/Abell%2B2261%2B2.jpg"></a></p><p><span>Over the past years, a number of scientists have tried to monitor the <a href="https://www.guardianmag.press/2020/12/a-giant-black-hole-mysteriously.html" target="_blank">disappearance of the black hole</a> in the "Abell 2261" galaxy group, and made a number of assumptions.&nbsp;</span></p><p><span>The idea that has prevailed in the past few decades among astronomers is that every galaxy at its center is a giant black hole that swallows millions or perhaps billions of suns, and the bigger the galaxy, the greater The mass of a black hole.</span></p><p><b><span>A galaxy without a black hole</span></b></p><p><span>The surprise came a decade ago when Marc Postman of the Space Telescope Science Institute discovered a giant galaxy with no black hole at its center.</span></p><p><span>Usually in the nucleus of each galaxy there is an additional mass of light in the center emitted by twinkling stars that are gathered due to the gravity of the hole, but that galaxy that Postman discovered did not have the usual mass of light, and the nucleus, which is a cloud of stars with a diameter of about 20 thousand Light years away, wasn't in the middle of the galaxy.</span></p><p><span>In 2012, Todd Lauer of the National Optical-Infrared Astronomy Research Laboratory in Tucson, Arizona, said, "This is not unusual at all&nbsp;." In later years Postman, Lauer and a group of other scientists worked to monitor X-rays and radio waves emitted from the galaxy in order to find the missing black hole.</span></p><p><a href="https://1.bp.blogspot.com/-5yZ-zY-TqxA/YA3zBeCSBWI/AAAAAAAACzY/I8AsLaEsTg0ZSDyL5BAwP3ZjzGDZJUi9wCLcBGAsYHQ/s720/Abell%2B2261.jpg"><span><img data-original-height="414" data-original-width="720" src="https://1.bp.blogspot.com/-5yZ-zY-TqxA/YA3zBeCSBWI/AAAAAAAACzY/I8AsLaEsTg0ZSDyL5BAwP3ZjzGDZJUi9wCLcBGAsYHQ/s16000/Abell%2B2261.jpg"></span></a></p><p><span>This galaxy is the brightest in the group of galaxies known as "Abell&nbsp;2261", and lies about 2.7 billion light years from Earth, inside the constellation Hercules in the northern celestial hemisphere.</span></p><p><span>Scientists assume that the mass of the missing black hole is equivalent to 10 billion solar masses or more, which is the size of a giant if we compare it to the black hole <a href="https://www.guardianmag.press/2020/05/the-black-hole-in-milky-way-and-all.html" target="_blank">in the center of the Milky Way</a>, which has a mass of about 4 million solar masses.&nbsp;</span></p><p><b><span>Where could this giant hole disappear?</span></b></p><p><span>One of the possibilities is that this hole exists but is static, after it has temporarily run out of what can be swallowed, but Lauer and his colleagues made another assumption, which is that the black hole moved away from the galaxy.</span></p><p><b><span>A better understanding of black holes</span></b></p><p><span>Proving the validity of the latter possibility would provide a deeper insight into some of the most violent and dynamic processes in <a href="https://www.guardianmag.press/2021/01/exploring-primordial-black-holes.html" target="_blank">the evolution of galaxies and the universe</a>, revealing more secrets about the gigantic forces and holes that can throw stars and planets into space.</span></p><p><span>Dr. Lauer belongs to a scientific team calling itself ''Nuker Group'', and over the past four decades this group has sought to monitor the nuclei of distant galaxies, using the Hubble telescope and other advanced equipment.&nbsp;</span></p><p><span>"What happened in (Abbl 2261) is roughly what happens with the most massive elliptical galaxies in the universe, at the end point of their evolution," says Lauer.</span></p><p><span>In the 1960s, the discovery of quasars in the centers of galaxies led astronomers to believe that supermassive black holes are responsible for swallowing stars and producing light mass in the galactic core.</span></p><p><span>By the end of the century, astronomers had come to the conclusion that <a href="https://www.guardianmag.press/2020/05/the-black-hole-in-milky-way-and-all.html" target="_blank">every galaxy contains a supermassive black hole</a>, millions or billions of times larger than the mass of the sun, but there was no clear explanation for how black holes formed, whether they evolved from black holes, or It was formed in another process early in the life of the universe.</span></p><p><span>And in 1980, 3 astronomers, Mitchell Begelman, Martin Rees and Roger Blandford, wrote about how these black holes affected the evolution of galaxies. From their point of view, when two galaxies collide and merge together, which is a common event in the early stages of the universe's life, the central black holes converge to form a binary system, consisting of <a href="https://www.guardianmag.press/2020/03/grouping-of-two-large-black-holes-and.html" target="_blank">two black holes</a> revolving around each other.</span></p><p><span>Begelman and his colleagues found that these two enormous black holes interact with the constellation surrounding them, and from time to time one of these stars approaches the duo, but the forces of gravity push it out of the center, and over time, more stars push away from the center. Gradually the starlight spreads out to form a wider core, with little twisting in the center.</span></p><p><b><span>Assumptions about the location of the black hole</span></b></p><p><span>When observing the "Abell&nbsp;2261" galaxy, Lauer and Postman had thought that they would find a density in the center as they have been observed in other <a href="https://www.guardianmag.press/2020/06/black-hole-bounty-captured-in-center-of.html" target="_blank">galaxies</a>. Instead, there was a decrease in the mass of light, as if the supermassive black hole and its accompanying stars had completely disappeared.</span></p><p><span>This discovery raised many questions about the scenario assumed by Begelman and his colleagues, as the two black holes merged from nothing, and the merger was accompanied by a tremendous surge of gravitational waves, and spacetime ripples like those predicted by Einstein in 1916, to be monitored by LIGO observatory devices a century later, specifically in 2016.</span></p><p><span>If this explosion were violent, as the previous theories assume, it would have caused the black hole to be sent to another place in the galaxy, or even outside it, something that the scientists who observed Apple 2261 did not notice, so finding the missing hole was very important To obtain an acceptable scientific explanation.</span></p><p><span>Further investigation of the elliptical galaxy (A2261-BCG) revealed 4 small nodes of light in a diffuse nucleus, raising the possibility that a black hole was hidden inside one of them.</span></p><p><span>To investigate, a team led by Sarah Burke Spolaor of West Virginia University observed the four nodes using the Hubble Observatory and the "Great Array of Observatories." The team concluded that 2 of the nodes were most likely small galaxies and could not contain a black hole, while the third and fourth nodes were likely to contain the missing hole.</span></p><p><a href="https://1.bp.blogspot.com/-s6Wp6Q67VGc/YA36DOU1QoI/AAAAAAAACz4/NtEtTvM3oFUzjyitpfEbhRcJ7nOZckLiACLcBGAsYHQ/s700/black%2Bholes.jpg"><span><img data-original-height="608" data-original-width="700" src="https://1.bp.blogspot.com/-s6Wp6Q67VGc/YA36DOU1QoI/AAAAAAAACz4/NtEtTvM3oFUzjyitpfEbhRcJ7nOZckLiACLcBGAsYHQ/s16000/black%2Bholes.jpg"></span></a></p><p><b><span>Waiting for James Webb</span></b></p><p><span>The next stop in an attempt to discover the secret of the missing hole was NASA's Chandra X-ray Space Observatory. Kayhan Gultekin of the University of Michigan, a veteran scientist from the Nookers team, directed the telescope toward the core and the four nodes, and assured that a hypothetical black hole should feed at a rate of one out of a million of its normal energy, if it ever existed. "Either the black hole in the center is very faint, or it does not exist," Gultekin wrote in an email.</span></p><p><span>Astronomers are impatiently waiting for the launch of the James Webb Space Telescope, the new observatory that will replace Hubble, which is scheduled to be launched at the end of next October, in order to examine the four nodes at the same time and determine whether any of them contains the missing black hole.</span></p><p><span>Sources:</span></p><ul><li><span><span>the National Optical-Infrared Astronomy Research Laboratory&nbsp;</span></span></li><li><span><span>Coordination with NASA</span></span></li><li><span>https://www.nytimes.com/2021/01/19/science/astronomy-black-hole-abell.html</span></li></ul>
</div></div>]]>
            </description>
            <link>https://www.guardianmag.press/2021/01/a-10-billion-solar-masses-black-hole-is.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274895</guid>
            <pubDate>Fri, 26 Feb 2021 14:12:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How NFTs Became Stores of Value]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26274634">thread link</a>) | @smalera
<br/>
February 26, 2021 | https://www.businessofbusiness.com/articles/nft-non-fungible-token-crypto-art-beeple-christies-auction-explainer/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/nft-non-fungible-token-crypto-art-beeple-christies-auction-explainer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p>You’ve heard of Bitcoin, and probably Ethereum. But what are non-fungible tokens, or NFTs, which people like <a href="https://www.businessofbusiness.com/articles/crypto-art-nft-beeple-christies-auction-token-ethereum-dada-blockchain/">Gary Vaynerchuk, Chamath and Mark Cuban are so besotted with</a>?</p>
<p>Here’s an explainer, with help from two guides to the NFT world: The art and technology writer Jason Bailey, who also makes art as Artnome; and Priyanka Desai who is vice president of operations at OpenLaw, a research organization that helps set up and run new types of blockchain-specific funding vehicles that collect NFTs.&nbsp;</p>
<h2>What’s an NFT anyway?</h2>
<p>The key word in NFT is fungibility. Whereas Bitcoin is fungible, meaning each unit of bitcoin is interchangeable with another, NFTs do not have this property. Instead, NFTs are unique digital tokens.&nbsp;</p>
<p>NFTs are really just a type of computer program that runs on a blockchain. Some NFTs are programmed as items in a game, giving them certain properties that players can use. An example of this is CryptoKitties, where players collect different NFTs, representing digital cats, which they ‘breed’ with one another to create cats with new properties.&nbsp;</p>
<p>Other NFTs are more like digital art, and they’re linked to a specific image or sound file. They might also have certain rules programmed into them that allow the artist to collect a cut of future sales of the work, much like a royalty.&nbsp;</p>
<p>Many blockchains have their own NFTs. Some popular blockchains for NFTs are Ethereum, which hosts CryptoKitties and top crypto artists like Beeple; Flow, which hosts the NBA Top Shot collectible game; and Wax, which hosts crypto versions of Topps cards.&nbsp;</p>
<h2>How does it work?</h2>
<p>Generally, an artist uses a platform to “mint,” or create, an NFT. In theory, anyone can mint an NFT, but you’d need to write your own code.&nbsp;</p>
<p>The newly minted NFT usually doesn’t contain the graphic file or other data that make up an artwork. That data is usually stored somewhere else, off-chain. It could be stored on a centralized server.&nbsp;</p>
<p>An increasingly common option is to store the artwork on something called the Interplanetary File System (IPFS), a peer-to-peer network that replicates a file across many machines, acting as a form of decentralized storage, says Bailey, the artist and critic. The NFT will contain a unique signature that points to that file’s location on IPFS.</p>
<p><a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://opensea.io/blog/guides/non-fungible-tokens/%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229656000%26amp;usg%3DAOvVaw0V_mZDO1yfF9QFqOIIC52U&amp;sa=D&amp;source=editors&amp;ust=1614230229670000&amp;usg=AOvVaw0XhDgxg8419--QzsxQrEvS" target="_blank">The Non-Fungible Token Bible</a>&nbsp;is a good resource to go deeper on the tech.&nbsp;&nbsp;</p>
<h2>Why do NFTs have value?</h2>
<p>Why shouldn’t they? NFT investors like Mark Cuban say you should think of them as forms of digital property.&nbsp;</p>
<p>Just as fine wines, paintings or rare trading cards can hold value, so should their digital versions. But instead of physical scarcity, crypto tokens have digital scarcity. That’s why,&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://blogmaverick.com/2021/01/31/the-store-of-value-generation-is-kicking-your-ass-and-you-dont-even-know-it/%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229656000%26amp;usg%3DAOvVaw2UpaXEikYmokoVHXMWQgM6&amp;sa=D&amp;source=editors&amp;ust=1614230229671000&amp;usg=AOvVaw3yC_ORIj1fWrTQ_LmPwuXx" target="_blank">according to Cuban</a>, “blockchain driven assets have now legitimately become stores of value.”</p>
<p>Priyanka Desai, of OpenLaw, agrees with Cuban’s take. Digital property is important when we increasingly spend our lives online. She puts it this way: “The whole psychological nature of feeling that your taste and general outlook is signaled through a digital property. Whether that be audio or [crypto] collectibles or anything else&nbsp;—&nbsp;it's flexing wealth or taste. It's not dissimilar to how people behave in the real world.”</p>
<p>Finally, Bailey offers an analogy to the art world: “Art has no [inherent financial] value. A Rothko painting might be worth $40 million one minute and is worthless the next if an authenticator says, hey that’s not by Mark Rothko. Nothing changes about that painting. Art’s value comes from the social agreement that it’s from this artist. When you buy [NFTs], what you are buying is a token, and the artwork is what that token looks like.”</p>
<h2>Who’s Buying These Things?</h2>
<p>Lots of big names from the tech world. There’s Mark Cuban, who’s gotten deep in the weeds and is now collecting generative&nbsp;audio-art NFTs called Eulerbeats (“<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://twitter.com/BanklessHQ/status/1364255520857731072?s%253D20%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229657000%26amp;usg%3DAOvVaw2vPED03Wd15b8mnRi77B1M&amp;sa=D&amp;source=editors&amp;ust=1614230229672000&amp;usg=AOvVaw1kOffqT7INM4UPbm5x-LcU" target="_blank">the most genius idea ever</a>”); billionaire investor Chamath Palihapitiya who says he’s building a “sizable collection” of tokens; and wine merchant turned tech investor Gary Vaynerchuk who seems to tweet almost exclusively about NFTs these days.&nbsp;</p>
<h2>What Are NFTs Going For?</h2>
<p><a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://www.one37pm.com/grind/money/most-expensive-nfts%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229658000%26amp;usg%3DAOvVaw2VVCgzRxCYBK82HPHABVvF&amp;sa=D&amp;source=editors&amp;ust=1614230229672000&amp;usg=AOvVaw2CeuxZRvX7_OHq6iHKjhSx" target="_blank">Lots of money</a>. The street artist Beeple sold a collection of his works for $3.5 million in December. Now Christie’s is auctioning&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://www.businessofbusiness.com/articles/crypto-art-nft-beeple-christies-auction-token-ethereum-dada-blockchain/%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229658000%26amp;usg%3DAOvVaw3dDu9c2x1giehOS1kdX2ZV&amp;sa=D&amp;source=editors&amp;ust=1614230229672000&amp;usg=AOvVaw0cesMH_Wh8-PWgst-aum96" target="_blank">one of his pieces</a>&nbsp;in a first for the storied auction house.&nbsp;</p>
<p>The pixelated portraits&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://www.businessofbusiness.com/articles/cryptopunks-pixelated-portraits-are-changing-hands-for-760000/%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229659000%26amp;usg%3DAOvVaw0JvTTtqeALPgrDki0UrIUn&amp;sa=D&amp;source=editors&amp;ust=1614230229672000&amp;usg=AOvVaw1petCI_5OdZJDW4pzEceym" target="_blank">known as CryptoPunks</a>&nbsp;are changing hands for $1.6 million or so, while a digital cat shooting&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://www.coindesk.com/nyan-cat-nft-ethereum-meme%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229660000%26amp;usg%3DAOvVaw3fzXkJP74DaMvrAtk_tNN_&amp;sa=D&amp;source=editors&amp;ust=1614230229673000&amp;usg=AOvVaw1IVzdqu5IlhqY3yl7LV5zA" target="_blank">a rainbow from its posterior</a>&nbsp;went for half a million.&nbsp;</p>
<p>According to data site NonFungible.com and L’Atelier, a unit of BNP Paribas, NFT sales hit $250 million in 2020, an increase of some 300% from a year earlier.&nbsp;</p>
<h2>Types of NFTs</h2>
<p>The three biggest categories for NFTs are tokens used in games; artwork and items used in “metaverses” or virtual worlds, according to data from NonFungible.com. NFT sales are pretty evenly split among them at about 25% of the market each. Sports and other collectibles make up the remainder.&nbsp;</p>
<h2>Platforms</h2>
<p>NFTs can be bought on a variety of platforms. Some of these platforms lend themselves to certain types of tokens.&nbsp;</p>
<p>According to Desai:&nbsp;</p>
<ul>
<li>Nifty Gateway, the marketplace backed by the Winklevoss twins, is a “bridge for newbies” because they can wire dollars to their accounts there.</li>
<li>Rarible and Opensea have “wide swaths” of NFTs, everything from collectibles to digital land.</li>
<li>Foundation and Zora are “more curated” with a focus on getting “edgy and interesting” artists into NFTs.</li>
<li>Superrare is “the OG” as far as crypto curated platforms go. Cryptoartists selling works for lots of coins today got their start here.&nbsp;</li>
</ul>
<h2>Displaying Your NFTs</h2>
<p>After spending so much money on a unique digital object how do you show it off? You can show off your crypto art by hanging them on your wall with an&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://infiniteobjects.com%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229662000%26amp;usg%3DAOvVaw1kHb_sBgCuBMKviXMwKP2j&amp;sa=D&amp;source=editors&amp;ust=1614230229674000&amp;usg=AOvVaw10rwU8fNdTzJexp7hOJvqH" target="_blank">Infinite Objects Video Print</a>, Desai says.&nbsp;</p>
<p>You can also use a crypto wallet that’s designed to display your collection, like&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://rainbow.me%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229662000%26amp;usg%3DAOvVaw11i8wxyt5_GKl8Vkz5HgN3&amp;sa=D&amp;source=editors&amp;ust=1614230229674000&amp;usg=AOvVaw1bCEZLCSI66E6ZBUyE2xvR" target="_blank">Rainbow.me</a>. Platforms like Showtime let collectors show off their works in&nbsp;<a href="https://www.google.com/url?q=https://www.google.com/url?q%3Dhttps://tryshowtime.com%26amp;sa%3DD%26amp;source%3Deditors%26amp;ust%3D1614230229663000%26amp;usg%3DAOvVaw0s2jnq8J9ZZYeKLXDfQH1-&amp;sa=D&amp;source=editors&amp;ust=1614230229674000&amp;usg=AOvVaw38Po9J5FW01X8MbYV2VRbq" target="_blank">an Instagram-like format</a>.&nbsp;</p>
<p>If you want to get really fancy, you can build an entire museum or gallery in a metaverse like Decentraland or Cryptovoxels and show off there. “A lot of this art might just end up living virtually,” Desai says.&nbsp;</p>
<p>Lastly, because NFTs are cryptoassets, there’s an increasing array of financial tools that let you borrow against them, fractionalize them, delegate them to a decentralized fund, or just sell them to anyone you like —&nbsp;which is more than you can say for a painting hanging on your wall.&nbsp;</p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/nft-non-fungible-token-crypto-art-beeple-christies-auction-explainer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274634</guid>
            <pubDate>Fri, 26 Feb 2021 13:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bill Allowing Big Tech to Form “Techno-Governments” to Be Announced Today]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 89 (<a href="https://news.ycombinator.com/item?id=26274611">thread link</a>) | @TheWellerman
<br/>
February 26, 2021 | https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span data-preserver-spaces="true">Nevada Governor Steve Sisolak will be announcing legislation today that will allow major technology companies to effectively form techno-governments.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Gov. Sisolak first mentioned the proposal of creating “Innovation Zones” in Nevada during his&nbsp;</span><a href="https://thenevadaindependent.com/article/full-transcript-annotations-of-sisolaks-2021-state-of-the-state-address" target="_blank" rel="noopener"><span data-preserver-spaces="true">State-of-the-State address</span></a><span data-preserver-spaces="true">&nbsp;on January 19. “New companies creating groundbreaking technologies can come to Nevada to develop their industries. This will be done without tax abatements or public financing.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">While the legislation wouldn’t provide subsidiaries or public funding, according to a draft of the Bill obtained by the&nbsp;</span><a href="https://www.reviewjournal.com/news/politics-and-government/2021-legislature/bill-would-allow-tech-companies-to-create-local-governments-2272887/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Las Vegas Review-Journal</span></a><span data-preserver-spaces="true">, major technology firms would be granted authority to form their independent techno-governments within Nevada. “[They] would carry the same authority as a county, including the ability to impose taxes, form school districts and justice courts and provide government services, to name a few duties,” Las Vegas Review-Journal reports.&nbsp;</span></p>
<figure id="attachment_3641" aria-describedby="caption-attachment-3641"><img src="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png" alt="techno-governments " width="653" height="440" srcset="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png 653w,https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min-300x202.png 300w" sizes="(max-width: 653px) 100vw, 653px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png 653w, https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min-300x202.png 300w" data-src="https://thedebrief.org/wp-content/uploads/2021/02/unnamed-min.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3641">Illustration shows Blockchains, LLC’s proposed “smart city” in rural northern Nevada. (Image Source: EYRC Architects/Blockchains LLC via AP)</figcaption></figure>

<p><span data-preserver-spaces="true">During his remarks in January, Gov. Sisolak specifically mentioned the company Blockchains, LLC as already being committed to creating a techno-government in the state that would “fully run on blockchain technology.” Gov. Sisolak said the move would make Nevada “the epicenter of this emerging industry and creating the high paying jobs and revenue that go with it.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">In the simplest terms, blockchain is a type of database system that stores computational information in groups, known as “blocks.” Though not entirely unalterable, blockchain technology is considered secure by design because data transactions between parties are recorded efficiently and in an open, verifiable, and permanent manner. Financial services, particularly cryptocurrencies, widely use blockchain technology.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The company mentioned explicitly by Gov. Sisolak, Blockchains, LLC, was founded in 2014 by consumer protection attorney and cryptocurrency millionaire <a href="https://www.blockchains.com/our-people/jeffrey-berns/" target="_blank" rel="noopener">Jeffrey Berns</a>.&nbsp;</span></p>
<p><span data-preserver-spaces="true">According to their&nbsp;</span><a href="https://www.blockchains.com/real-life-sandbox/" target="_blank" rel="noopener"><span data-preserver-spaces="true">website</span></a><span data-preserver-spaces="true">, Blockchains, LLC currently owns over 67,000 acres in Storey County, Nevada. The company says they aim to convert this land into “the most advanced ‘high-tech’ community and society for business and residents in the country.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Calling it “a new way to live,” Blockchains says they “believe the integration of our product suite is where the full potential of a smart community, digital economy, and connected society can be realized.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">“Blockchains aims to showcase how business development, residential living, and commerce can flourish alongside world-changing technologies. To do that, we have to start with a blank slate – otherwise, we’d merely be trying to insert smart technologies into devices that aren’t, well, ‘smart,'” reads the company’s “</span><a href="https://www.blockchains.com/real-life-sandbox/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Road to Development</span></a><span data-preserver-spaces="true">” plan.</span></p>
<p><span data-preserver-spaces="true">According to state records, in 2018, Blockchains purchased 67,125 acres of uninhabited land at the Tahoe Reno Industrial Center for $170 million. At the time, the company’s website did not list any executive, a phone number, or a clear explanation of what it’s software did, leading some local media outlets to label the company as “mysterious.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Since the land grab, Blockchains has been lobbying hard to get legislation passed that would allow the company to form its own techno-government.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Las Vegas Review-Journal reports Blockchains, LLC gave $50,000 to a political action committee, Home Means Nevada, which managed Sisolak’s transition into office in January 2019. Campaign&nbsp;</span><a href="https://www.followthemoney.org/entity-details?eid=48060485" target="_blank" rel="noopener"><span data-preserver-spaces="true">finance records</span></a><span data-preserver-spaces="true">&nbsp;also show the company donated $10,000 to Sisolak and his Republican opponent Adam Laxalt’s campaign in 2018.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Records also show the company’s owner, Jeffrey Berns, personally gave $50,000 to the Nevada Democratic Party in 2019 and various donations ranging from $1,000 to $5,000 to various state lawmakers from both parties.&nbsp;</span></p>
<p>Over a week ago,<em><span data-preserver-spaces="true"> The Debrief&nbsp;</span></em><span data-preserver-spaces="true">reached out to Blockchains, LLC for comment; however, the company did not respond to this request.&nbsp;</span></p>

<figure id="attachment_3640" aria-describedby="caption-attachment-3640"><img src="https://thedebrief.org/wp-content/uploads/2021/02/nevadasmartcty-min-e1614341465363.jpg" alt="techno-governments" width="760" height="428" data-src="https://thedebrief.org/wp-content/uploads/2021/02/nevadasmartcty-min-e1614341465363.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3640">Illustration shows Blockchains, LLC’s proposed “smart city” in rural northern Nevada. (Image Source: EYRC Architects/Blockchains LLC via AP)</figcaption></figure>

<p><span data-preserver-spaces="true">In an email to&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">, Communications Director for the Governor’s office, Meghin Delaney, said Gov. Sisolack will formally unveil the proposed “Innovation Zones” legislation during a virtual press conference today, Friday, February 26, at 4:30 pm (EST).&nbsp;</span></p>
<p><span data-preserver-spaces="true">Joining Gov. Sisolack at today’s conference will be Michael Brown, Executive Director of the Governor’s Office of Economic Development, and Jeremy Aguero, principal analyst at Applied Analysis.&nbsp;</span></p>
<p><span data-preserver-spaces="true">According to the&nbsp;</span><a href="https://www.reviewjournal.com/news/politics-and-government/2021-legislature/bill-would-allow-tech-companies-to-create-local-governments-2272887/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Las Vegas Review-Journal</span></a><span data-preserver-spaces="true">, the draft language in the proposal said the traditional local government model was “inadequate alone to provide the flexibility and resources conducive to making the State a leader in attracting and retaining new forms and types of businesses and fostering economic development in emerging technologies and innovative industries.”</span></p>
<p><span data-preserver-spaces="true">The draft proposal also reportedly said the creation of techno-governments or “alternative forms of local government” were needed to aid economic development within the state.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The Governor’s Office of Economic Development is slated to handle applications for the Innovation Zones, which would be limited to specific “innovative technologies,” including “blockchain, autonomous technology, the internet of things, artificial intelligence, wireless technology, biometrics, and renewable resource technology.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">The Governor’s Office of Economic Development redirected <em>The Debrief’s</em> questions on the legislation backing techno-governments to the Governor’s communications staff; since the Bill had not been formally proposed, much less passed.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The draft proposal laid out the requirements for companies to create their own techno-government, including an applicant owning at least 50,000 acres of undeveloped and uninhabited land, all within a single county but separate from any city, town or tax increment area.</span></p>
<p><span data-preserver-spaces="true">Big Tech companies would also have to pledge at least $250 million toward initial development, with a plan to invest an additional $1 billion over ten years in the zone.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Major technology companies would function as their own independent governmental body, with a three-member board of supervisors that would carry the same authority as a board of county commissioners. The Bill’s proposed draft suggests technology companies would have a significant say over who would sit on techno-government’s board.&nbsp;</span></p>
<p><span data-preserver-spaces="true">While the draft proposal provides insight into some of the details behind the concept, some aspects could be changed when the Bill is formally introduced.&nbsp;</span></p>
<figure id="attachment_3639" aria-describedby="caption-attachment-3639"><img src="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg" alt="techno-governments" width="640" height="441" srcset="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg 640w,https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min-300x207.jpg 300w" sizes="(max-width: 640px) 100vw, 640px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg 640w, https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min-300x207.jpg 300w" data-src="https://thedebrief.org/wp-content/uploads/2021/02/las-vegas-1620961_640-min.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3639">Las Vegas, Nevada (Image Source: Pixabay)</figcaption></figure>
<div><div id="block-wrap-54099" data-id="54099"><div><div><div>		<article>
					<p><a href="https://thedebrief.org/the-fermi-paradox-where-are-all-the-aliens/">
				<img width="120" height="120" src="https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-120x120.jpg" alt="fermi paradox" srcset="https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-120x120.jpg 120w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-150x150.jpg 150w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-70x70.jpg 70w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-240x240.jpg 240w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-360x360.jpg 360w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-540x540.jpg 540w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-720x720.jpg 720w,https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-125x125.jpg 125w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-120x120.jpg 120w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-150x150.jpg 150w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-70x70.jpg 70w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-240x240.jpg 240w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-360x360.jpg 360w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-540x540.jpg 540w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-720x720.jpg 720w, https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-125x125.jpg 125w" data-src="https://thedebrief.org/wp-content/uploads/2021/01/milky-way-4006343_1280-120x120.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div></div></div></div></div>
<p><span data-preserver-spaces="true">Aside from lobbying by companies such as Blockchains, the primary motivation for proposing the allowance of techno-governments would be the hope that the move would significantly boost Nevada’s beleaguered economy.&nbsp;</span></p>
<p><span data-preserver-spaces="true">With tourism indirectly or directly accounting for&nbsp;</span><a href="https://www.travelnevada.biz/wp-content/uploads/Nevada-Visitor-Economic-Impact-2018.pdf" target="_blank" rel="noopener"><span data-preserver-spaces="true">almost 25%</span></a><span data-preserver-spaces="true">&nbsp;of the state’s economy, Nevada has been devastated by the COVID-19 pandemic. Las Vegas, the United States’ second-largest municipal tourism industry, accounted for over $19 billion of Nevada’s GDP before the pandemic. According to the&nbsp;</span><a href="http://nevadaresorts.org/cv19/Nevada%20NRA%20Corona%20Virus%20Assessment%20Fact%20Sheet%20%20FINAL.pdf" target="_blank" rel="noopener"><span data-preserver-spaces="true">Nevada Resort Association</span></a><span data-preserver-spaces="true">, tourism and leisure services account for one out of every three jobs in Nevada.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The&nbsp;</span><a href="https://www.brookings.edu/research/explaining-the-economic-impact-of-covid-19-core-industries-and-the-hispanic-workforce/" target="_blank" rel="noopener"><span data-preserver-spaces="true">Brookings Institute</span></a><span data-preserver-spaces="true">&nbsp;found two Nevada cities, Las Vegas and Reno, were among the top three metro economies hardest-hit by the pandemic. In December 2020, the U.S. Bureau of Labor Statistics reported Nevada’s unemployment rate of 9.2% was the second-highest in the United States. Hawaii, which came in dead last, was only a tenth of a percentage point below Nevada at 9.3%.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Conversely, metropolitan hubs specializing in technology, such as Seattle and San Francisco, have thrived and benefited from COVID-19. Sales at non-store retailers (i.e., online shopping) increased by 15% from November 2019 to November 2020. Online retail giant Amazon, headquartered in Seattle,&nbsp;</span><a href="https://www.washingtonpost.com/technology/2020/10/29/amazon-hiring-pandemic-holidays/" target="_blank" rel="noopener"><span data-preserver-spaces="true">nearly doubled its workforce</span></a><span data-preserver-spaces="true">, adding 400,000 jobs in 2020. Social media monolith Facebook&nbsp;</span><a href="https://variety.com/2020/digital/news/facebook-hiring-10000-workers-small-business-grants-1234570018/" target="_blank" rel="noopener"><span data-preserver-spaces="true">announced</span></a><span data-preserver-spaces="true">&nbsp;plans to hire an additional 10,000 workers in April 2020.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The adage that “the most secure job is a federal government job” has held during the COVID-19 pandemic, and the U.S. Government grew by over 50,000 jobs in 2020. The metropolitan seat of America’s power, Washington D.C., saw a government employment rate increase over 2% last year.&nbsp;</span></p>
<p><span data-preserver-spaces="true">By allowing major technology corporations to form their techno-governments, Nevada will be trying to capture lightning in a bottle by enticing a mix of the most benefited industries during these economically downtrodden times.&nbsp;</span></p>
<p><span data-preserver-spaces="true">While economic benefits seem enticing, almost assuredly, there will be some public concerns over the idea of Big Tech being allowed to form its own sovereign governance.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In a&nbsp;</span><a href="https://ideas.ted.com/heres-the-real-danger-that-facebook-google-and-the-other-tech-monopolies-pose-to-our-society/" target="_blank" rel="noopener"><span data-preserver-spaces="true">2018 essay</span></a><span data-preserver-spaces="true">, technology analyst Jamie Bartlett warned technology monopolies posed a real threat to democracies. “Tech is just the latest vehicle for very rich people to use well-tested techniques of buying political influence, monopolistic behavior and avoiding regulation,” wrote Bartlett.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Fear over the power Big Tech companies wield has only increased in the past two years. The public and politicians alike have expressed concerns over Big Tech companies’ potential to be a cultural hegemony, dominating public ideas and beliefs.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The jury is still out as to the ultimate impact of allowing Big Tech to form techno-governments, provided that the proposed legislation passes.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In the area Blockchains plans to build their “better way to live,” Storey County Commissioner Lance Gilman was a little hesitant toward the proposed legislation during an interview with the Las Vegas Journal Review. “[It’s] going to have an impact on Storey County, and the jury is still out on whether that will be positive or negative.”</span></p>
<p><b>Join us on</b><a href="https://twitter.com/Debriefmedia"> <b>Twitter</b></a><b> or</b><a href="https://www.facebook.com/thedebriefnews"> <b>Facebook</b></a><b> to weigh in and share your thoughts on Big Tech …</b></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/">https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/</a></em></p>]]>
            </description>
            <link>https://thedebrief.org/bill-allowing-big-tech-to-form-techno-governments-to-be-announced-today/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274611</guid>
            <pubDate>Fri, 26 Feb 2021 13:37:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retrofitting Effect Handlers onto OCaml [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26274566">thread link</a>) | @matt_d
<br/>
February 26, 2021 | https://kcsrk.info/papers/drafts/retro-concurrency.pdf | <a href="https://web.archive.org/web/*/https://kcsrk.info/papers/drafts/retro-concurrency.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://kcsrk.info/papers/drafts/retro-concurrency.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274566</guid>
            <pubDate>Fri, 26 Feb 2021 13:32:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU poke 1.0]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26274466">thread link</a>) | @todsacerdoti
<br/>
February 26, 2021 | http://www.jemarch.net/poke-1.0-relnotes.html | <a href="https://web.archive.org/web/*/http://www.jemarch.net/poke-1.0-relnotes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.jemarch.net/poke-1.0-relnotes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274466</guid>
            <pubDate>Fri, 26 Feb 2021 13:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't write configuration, write code]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26274410">thread link</a>) | @catern
<br/>
February 26, 2021 | http://catern.com/config.html | <a href="https://web.archive.org/web/*/http://catern.com/config.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
When you write a program which might use one of multiple implementations,
or needs to connect to some URL,
or needs some information to function,
your first step should be to just hardcode it.
Use one implementation, hardcode one URL, use one specific piece of information.
<p>
If, after doing so, you find that you need another program
with different hardcoded information,
turn your program into a function.
Take the implementation as an argument,
take the URL as an argument,
take the information you need as an argument.
</p><p>
And then just call that function with the arguments you prefer,
each time you need a program with different "configuration".
</p><p>
You don't need to load those arguments from some file on disk,
or by querying some database or service,
or even by taking them as command line parameters.
</p><p>
Just make a separate program for each case.
</p><p>
For a batch job, this might mean a few different executables,
tweaked and rebuilt frequently over time as one's needs change.
</p><p>
  For a user-facing application, this might mean that each user runs their own
  <a href="http://hackage.haskell.org/package/xmonad-contrib-0.16/docs/XMonad-Doc-Configuring.html">custom</a>
  <a href="https://st.suckless.org/">executable</a>,
compiled for or by them, with pre-compiled shared libraries common between all users.
</p><p>
For a daemon providing some network service and connecting to other services,
this might mean 10 or so different executables,
which are run in the 10 or so different availability zones or datacenters or sorts of machines
on which this daemon is deployed.
Or for a more heterogeneous deployment,
it might mean many thousands of different executables,
deployed to many thousands of different environments,
each layered on top of a common image with shared libraries identical between all deployments.
</p><p>
If you want to share information between multiple programs with different configurations,
share it in the same way you share code: with a library.
</p><p>
If you want to make your configuration more dynamic,
write code to dynamically determine the arguments to pass.
</p><p>
If you want to make rapid changes and don't want to wait for builds,
call the function from a REPL, or rely on fast incremental builds.
</p><p>
If you want to see what arguments are being passed to your function in your program,
use logging and debuggers, according to your preference.
</p><p>
Code written in this way in your actual programming language
is far more expressive than code written in a configuration DSL,
like JSON, YAML, or Dhall.
</p><p>
In a configuration DSL,
one would select from multiple implementations by manipulating some identifier for the implementations;
a string or a sum type, perhaps.
This might be formatted in an invalid way,
or might be from the wrong version,
or might be incompatible,
or any number of possible issues.
</p><p>
But in any general-purpose programming language,
implementations are first class values which can be passed around and manipulated,
whether as an object, a module, a struct of function pointers, or something else.
One can write a function (or a template, a functor, a macro, or something else)
which takes the implementation directly as an argument,
with no possibility of issues due to mismatches between a string identifier and the actually available implementations.
</p><p>
In a typical configuration DSL,
we would specify a set of key-value pairs to configure some component.
We might run some validator over the DSL to ensure it matches some schema
which we know our code will eventually load.
</p><p>
But static checks in general purpose programming languages, such as type checkers,
perform "validation" of the "schema" of our configuration for free,
wherever we pass arguments to functions.
Required arguments must be present, and even must be of the correct type,
and there's no need to keep our code in sync with a schema.
</p><p>
Writing code in your general purpose language
is easier, faster, and better
than writing separate configuration.
</p><p>
Of course, this is all easier with faster and more powerful build systems,
like Nix,
or with interpreted or fast-building languages,
like Python,
or with, at least, shared libraries and a fast link step,
like dynamic libraries in C.
</p><p>
If you're on a slow, weak, and hard-to-use build system,
with a slow-building language,
and you have slow linking,
then you probably want to fix one or more of those issues first;
although if your programs are small, even those issues are not necessarily prohibitive.
</p><p>
And you might also be in a corporate environment,
where code changes require an extensive and painful process,
but configuration changes can be made relatively easily.
If so, consider quitting.
</p></div>]]>
            </description>
            <link>http://catern.com/config.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274410</guid>
            <pubDate>Fri, 26 Feb 2021 13:15:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary: The Power of Habit by Charles Duhigg]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26274358">thread link</a>) | @chegra
<br/>
February 26, 2021 | https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg | <a href="https://web.archive.org/web/*/https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_body_1658851">
    
      <div><center>        <div id="posthaven_gallery[1682788]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/medium_The_Power_of_Habit.jpg" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/medium_The_Power_of_Habit.jpg" data-medium-width="324" data-medium-height="499" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/large_The_Power_of_Habit.jpg" data-large-width="324" data-large-height="499" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/thumb_The_Power_of_Habit.jpg" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/xlarge_The_Power_of_Habit.jpg" data-xlarge-width="324" data-xlarge-height="499" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2584577/iM4bPgE1OvY-Sh4h1WwqCfW07QI/The_Power_of_Habit.jpg" data-orig-width="324" data-orig-height="499" data-posthaven-id="2584577">
        </p>
          
        </div>
</center><p>1. <b>One paper published by a Duke University researcher in 2006 found that more than 40 percent of the actions people performed each day werenâ€™t actual decisions, but habits.</b></p><p>2. Habits, scientists say, emerge because the brain is constantly looking for ways to save effort. Left to its own devices, the brain will try to make almost any routine into a habit, because habits allow our minds to ramp down more often. This effort-saving instinct is a huge advantage. An efficient brain requires less room, which makes for a smaller head, which makes childbirth easier and therefore causes fewer infant and mother deaths. An efficient brain also allows us to stop thinking constantly about basic behaviors, such as walking and choosing what to eat, so we can devote mental energy to inventing spears, irrigation systems, and, eventually, airplanes and video games.</p><p><b>3. This process within our brains is a three-step loop. First, there is a cue, a trigger that tells your brain to go into automatic mode and which habit to use. Then there is the routine, which can be physical or mental or emotional. Finally, there is a reward, which helps your brain figure out if this particular loop is worth remembering for the future:</b></p><p>4. By learning to observe the cues and rewards, though, we can change the routines.</p><p>5. This is how new habits are created: by putting together a cue, a routine, and a reward, and then cultivating a craving that drives the loop.</p><p>6. But to overpower the habit, we must recognize which craving is driving the behavior.</p><p>7. But countless studies have shown that a cue and a reward, on their own, arenâ€™t enough for a new habit to last. Only when your brain starts expecting the rewardâ€”craving the endorphins or sense of accomplishmentâ€”will it become automatic to lace up your jogging shoes each morning.</p><p>8. Cravings are what drive habits. And figuring out how to spark a craving makes creating a new habit easier.</p><p>9. Rather, to change a habit, you must keep the old cue, and deliver the old reward, but insert a new routine.</p><p>10. Belief was the ingredient that made a reworked habit loop into a permanent behavior.</p><p>11. â€œEven if you give people better habits, it doesnâ€™t repair why they started drinking in the first place. Eventually theyâ€™ll have a bad day, and no new routine is going to make everything seem okay. What can make a difference is believing that they can cope with that stress without alcohol.â€�</p><p>12. â€œAt some point, people in AA look around the room and think, if it worked for that guy, I guess it can work for me,â€� said Lee Ann Kaskutas, a senior scientist at the Alcohol Research Group. â€œThereâ€™s something really powerful about groups and shared experiences. People might be skeptical about their ability to change if theyâ€™re by themselves, but a group will convince them to suspend disbelief. A community creates belief.â€�</p><p>13. But we do know that for habits to permanently change, people must believe that change is feasible. The same process that makes AA so effectiveâ€”the power of a group to teach individuals how to believeâ€”happens whenever people come together to help one another change. Belief is easier when it occurs within a community.</p><p><b>14. How do habits change? There is, unfortunately, no specific set of steps guaranteed to work for every person. We know that a habit cannot be eradicatedâ€”it must, instead, be replaced. And we know that habits are most malleable when the Golden Rule of habit change is applied: If we keep the same cue and the same reward, a new routine can be inserted. But thatâ€™s not enough. For a habit to stay changed, people must believe change is possible. And most often, that belief only emerges with the help of a group.</b></p><p>15. Some habits have the power to start a chain reaction, changing other habits as they move through an organization. Some habits, in other words, matter more than others in remaking businesses and lives. These are â€œkeystone habits,â€�</p><p>16. Researchers have found similar dynamics in dozens of other settings, including individualsâ€™ lives. Take, for instance, studies from the past decade examining the impacts of exercise on daily routines.10 When people start habitually exercising, even as infrequently as once a week, they start changing other, unrelated patterns in their lives, often unknowingly. Typically, people who exercise start eating better and becoming more productive at work. They smoke less and show more patience with colleagues and family.</p><p>17. Small wins are exactly what they sound like, and are part of how keystone habits create widespread changes. A huge body of research has shown that small wins have enormous power, an influence disproportionate to the accomplishments of the victories themselves.<br></p><p>18. Small wins fuel transformative changes by leveraging tiny advantages into patterns that convince people that bigger achievements are within reach.</p><p>19. The second way that keystone habits encourage change: by creating structures that help other habits to flourish.</p><p>20. At the core of that education is an intense focus on an all-important habit: willpower. Dozens of studies show that willpower is the single most important keystone habit for individual success.</p><p>21. â€œSelf-discipline predicted academic performance more robustly than did IQ. Self-discipline also predicted which students would improve their grades over the course of the school year, whereas IQ did not.â€¦ Self-discipline has a bigger effect on academic performance than does intellectual talent.â€�</p><p>22. And the best way to strengthen willpower and give students a leg up, studies indicate, is to make it into a habit.</p><p>23. Scientists began conducting related experiments, trying to figure out how to help kids increase their self-regulatory skills. They learned that teaching them simple tricksâ€”such as distracting themselves by drawing a picture, or imagining a frame around the marshmallow, so it seemed more like a photo and less like a real temptationâ€”helped them learn self-control.</p><p>24. By the 1980s, a theory emerged that became generally accepted: Willpower is a learnable skill, something that can be taught the same way kids learn to do math and say â€œthank you.â€�</p><p><b>25. â€œThatâ€™s why signing kids up for piano lessons or sports is so important. It has nothing to do with creating a good musician or a five-year-old soccer star,â€� said Heatherton. â€œWhen you learn to force yourself to practice for an hour or run fifteen laps, you start building self-regulatory strength. A five-year-old who can follow the ball for ten minutes becomes a sixth grader who can start his homework on time.â€�</b></p><p>26. Simply giving employees a sense of agencyâ€”a feeling that they are in control, that they have genuine decision-making authorityâ€”can radically increase how much energy and focus they bring to their jobs.</p><p><b>27. A company with dysfunctional habits canâ€™t turn around simply because a leader orders it. Rather, wise executives seek out moments of crisisâ€”or create the perception of crisisâ€”and cultivate the sense that something must change, until everyone is finally ready to overhaul the patterns they live with each day.</b></p><p>28. â€œThis crisis provides the opportunity for us to do things that you could not do before.â€�</p><p>29. Andreasen wanted to know why these people had deviated from their usual patterns. What he discovered has become a pillar of modern marketing theory: Peopleâ€™s buying habits are more likely to change when they go through a major life event. When someone gets married, for example, theyâ€™re more likely to start buying a new type of coffee. When they move into a new house, theyâ€™re more apt to purchase a different kind of cereal.</p><p>30.If a member made a friend at the YMCA, they were much more likely to show up for workout sessions. In other words, people who join the YMCA have certain social habits.</p><p>31. Itâ€™s a variation of the lesson learned by Target and radio DJs: to sell a new habitâ€”in this case exerciseâ€”wrap it in something that people already know and like, such as the instinct to go places where itâ€™s easy to make friends.</p><p>32. To market a new habitâ€”be it groceries or aerobicsâ€”you must understand how to make the novel seem familiar.</p><p>33. In general, sociologists say, most of us have friends who are like us. We might have a few close acquaintances who are richer, a few who are poorer, and a few of different racesâ€”but, on the whole, our deepest relationships tend to be with people who look like us, earn about the same amount of money, and come from similar backgrounds.</p><p>34. For Aristotle, habits reigned supreme. The behaviors that occur unthinkingly are the evidence of our truest selves, he said. So â€œjust as a piece of land has to be prepared beforehand if it is to nourish the seed, so the mind of the pupil has to be prepared in its habits if it is to enjoy and dislike the right things.â€�</p><p>35. THE DIFFICULT THING about studying the science of habits is that most people, when they hear about this field of research, want to know the secret formula for quickly changing any habit. If scientists have discovered how these patterns work, then it stands to reason that they must have also found a recipe for rapid change, right? If only it were that easy. Itâ€™s not that formulas donâ€™t exist. The problem is that there isnâ€™t one formula for changing habits. There are thousands.</p><p><b>36. THE FRAMEWORK: </b><br><b>â€¢ Identify the routine </b><br><b>â€¢ Experiment with rewards </b><br><b>â€¢ Isolate the cue </b><br><b>â€¢ Have a plan</b></p><p>37. STEP ONE: IDENTIFY THE ROUTINE</p><p>38. To understand your own habits, you need to identify the components of your loops. Once you have diagnosed the habit loop of a particular behavior, you can look for ways to supplant old vices with new routines. As an example, letâ€™s say you have a bad habit, like I did when I started researching this book, of going to the cafeteria and buying a chocolate chip cookie every afternoon. Letâ€™s say this habit has caused you to gain a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg">https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg</a></em></p>]]>
            </description>
            <link>https://www.chestergrant.com/summary-power-of-habit-by-charles-duhigg</link>
            <guid isPermaLink="false">hacker-news-small-sites-26274358</guid>
            <pubDate>Fri, 26 Feb 2021 13:06:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Actually Portable Executable]]>
            </title>
            <description>
<![CDATA[
Score 613 | Comments 151 (<a href="https://news.ycombinator.com/item?id=26273960">thread link</a>) | @NilsIRL
<br/>
February 26, 2021 | https://justine.lol/ape.html | <a href="https://web.archive.org/web/*/https://justine.lol/ape.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
24 aug 2020 @ <a href="https://justine.lol/index.html"> justine's web page</a>

</p>

<p>
One day, while studying old code, I found out that it's possible to
encode Windows Portable Executable files as a UNIX Sixth Edition shell
script, due to the fact that the Thompson Shell didn't use a shebang
line. Once I realized it's possible to create a synthesis of the binary
formats being used by Unix, Windows, and MacOS, I couldn't resist the
temptation of making it a reality, since it means that high-performance
native code can be almost as pain-free as web apps. Here's how it works:

</p><pre>MZqFpD='
BIOS BOOT SECTOR'
exec 7&lt;&gt; $(command -v $0)
printf '\177ELF...LINKER-ENCODED-FREEBSD-HEADER' &gt;&amp;7
exec "$0" "$@"
exec qemu-x86_64 "$0" "$@"
exit 1
REAL MODE...
ELF SEGMENTS...
OPENBSD NOTE...
NETBSD NOTE...
MACHO HEADERS...
CODE AND DATA...
ZIP DIRECTORY...
</pre>

<p>
I started a project called
<a href="https://github.com/jart/cosmopolitan">Cosmopolitan</a> which
implements
the <a aria-label="Actually Portable Executable" href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/ape/ape.S">αcτµαlly
pδrταblε εxεcµταblε</a> format. I chose the name because I like the idea
of having the freedom to write software without restrictions that
transcends traditional boundaries. My goal has been helping C become a
build-once run-anywhere language, suitable for greenfield development,
while avoiding any assumptions that would prevent software from being
shared between tech communities. Here's how simple it is to get started:

</p><pre>gcc -g -O -static -fno-pie -no-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>
</pre>

<p>
In the above one-liner, we've basically reconfigured the stock compiler
on Linux so it outputs binaries that'll run on MacOS, Windows, FreeBSD,
OpenBSD, and NetBSD too. They also boot from the BIOS. Please note this
is intended for people who don't care about desktop GUIs, and just want
stdio and sockets without devops toil.

</p><h3>Platform Agnostic C / C++ / FORTRAN Tooling</h3>

<p>
Who could have predicted that cross-platform native builds would be this
easy? As it turns out, they're surprisingly cheap too. Even with all the
magic numbers, win32 utf-8 polyfills, and bios bootloader code, exes
still end up being roughly 100x smaller than Go Hello World:

</p><p>
  <a href="https://justine.lol/life.com">life.com</a> is 12kb (<a href="https://justine.lol/life.com.dbg">symbols</a>,
  <a href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/examples/life.c">source</a>)
  <br>
  <a href="https://justine.lol/hello.com">hello.com</a> is 16kb (<a href="https://justine.lol/hello.com.dbg">symbols</a>,
  <a href="https://raw.githubusercontent.com/jart/cosmopolitan/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hello.c">source</a>)
  <br>

</p><p>
Please note that zsh has a minor backwards compatibility glitch with
Thompson Shell [update
2021-02-15: <a href="https://github.com/zsh-users/zsh/commit/326d9c203b3980c0f841bc62b06e37134c6e51ea">zsh
has now been patched</a>] so try <code>sh hello.com</code> rather
than <code>./hello.com</code>. That one thing aside, if it's this easy,
why has no one done this before? The best answer I can tell is it
requires an minor ABI change, where C preprocessor macros relating to
system interfaces need to be symbolic. This is barely an issue, except
in cases like <code>switch(errno){case EINVAL:...}</code>. If we feel
comfortable bending the rules, then the GNU Linker can easily be
configured to generate at linktime all the PE/Darwin data structures we
need, without any special toolchains.

</p><h3>PKZIP Executables Make Pretty Good Containers</h3>

<p>
Single-file executables are nice to have. There are a few cases where
static executables depending on system files makes sense, e.g. zoneinfo.
However we can't make that assumption if we're building binaries
intended to run on multiple distros with Windows support too.

</p><p>
As it turns out, PKZIP was designed to place its magic marker at the end
of file, rather than the beginning, so we can synthesize ELF/PE/MachO
binaries with ZIP too! I was able to implement this efficiently in the
Cosmopolitan codebase using a few lines of linker script, along with a
program for incrementally compressing sections.

</p><p>
It's possible to run <code>unzip -vl executable.com</code> to view its
contents. It's also possible on Windows 10 to change the file extension
to .zip and then open it in Microsoft's bundled ZIP GUI. Having that
flexibility of being able to easily edit assets post-compilation means
we can also do things like create an easily distributable JavaScript
interpreter that reflectively loads interpreted sources via zip.

</p><p>
  <a href="https://justine.lol/hellojs.com">hellojs.com</a> is 300kb (<a href="https://justine.lol/hellojs.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hellojs.c">source</a>)

</p><p>
Cosmopolitan also uses the ZIP format to automate compliance with the
GPLv2 [update 2020-12-28: APE is now licensed ISC]. The non-commercial
libre build is configured, by default, to embed any source file linked
from within the hermetic make mono-repo. That makes binaries roughly 10x
larger. For example:

</p><p>
  <a href="https://justine.lol/life2.com">life2.com</a> is 216kb (<a href="https://justine.lol/life2.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/life.c">source</a>)
  <br>
  <a href="https://justine.lol/hello2.com">hello2.com</a> is 256kb (<a href="https://justine.lol/hello2.com.dbg">symbols</a>,
  <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/examples/hello.c">source</a>)
  <br>

</p><p>
Rock musicians have a love-hate relationship with dynamic range
compression, since it removes a dimension of complexity from their
music, but is necessary in order to sound professional. Bloat might work
by the same principles, in which case, zip source file embedding could
be a more socially conscious way of wasting resources in order to gain
appeal with the non-classical software consumer.

</p><h3>x86-64 Linux ABI Makes a Pretty Good Lingua Franca</h3>

<p>
It wasn't until very recently in computing history that a clear shakeout
occurred with hardware architectures, which is best evidenced by the
<a rel="nofollow" href="https://en.wikipedia.org/w/index.php?title=TOP500&amp;oldid=966847096#Architecture_and_operating_systems">TOP
500 list</a>. Outside phones routers mainframes and cars, the consensus
surrounding x86 is so strong, that I'd compare it to the Tower of Babel.
Thanks to Linus Torvalds, we not only have a consensus on architecture,
but we've come pretty close to having a consensus on the input output
mechanism by which programs communicate with their host machines, via
the SYSCALL instruction. He accomplished that by sitting at home in a
bathrobe sending emails to huge corporations, getting them to agree to
devote their resources to creating something beautifully opposite to
tragedy of the commons.

</p><p>
So I think it's really the best of times to be optimistic about systems
engineering. We agree more on sharing things in common than we ever
have. There are still outliers like the plans coming out of Apple and
Microsoft we hear about in the news, where they've sought to pivot PCs
towards ARM. I'm not sure why we need a C-Class Macintosh, since the
x86_64 patents should expire this year. Apple could have probably made
their own x86 chip without paying royalties. The free/open architecture
that we've always dreamed of, might turn out to be the one we're already
using.

</p><p>
If a microprocessor architecture consensus finally exists, then I
believe we should be focusing on building better tools that help
software developers benefit from it. One of the ways I've been focusing
on making a contribution in that area, is by building a friendlier way
to visualize the impact that x86-64 execution has on memory. It should
should hopefully clarify how <span aria-label="Actually Portable
Executable">αcτµαlly pδrταblε εxεcµταblε</span> works.

</p><center>
    <video id="video" width="960" height="540" controls="" autoplay="" muted="" loop="">
      <source src="https://storage.googleapis.com/justine/emulator2.mp4" type="video/mp4">
    </video>
    
  </center>

<p>
You'll notice that execution starts off by treating the Windows PE
header as though it were code. For example, the ASCII string <code>"MZqFpD"</code>
decodes as <code>pop %r10 ; jno 0x4a ; jo 0x4a</code> and the string
<code>"\177ELF"</code> decodes as <code>jg 0x47</code>. It then hops
through a mov statement which tells us the program is being run from
userspace rather than being booted, and then hops to the entrypoint.

</p><p>
Magic numbers are then 
<a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/sysv/systemfive.S">easily
unpacked</a> for the host operating system using decentralized sections
and the GNU Assembler <code>.sleb128</code> directive. Low entropy data
like UNICODE bit lookup tables will generally be decoded using either
a <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/str/lz4cpy.c">103
byte LZ4 decompressor</a> or
a <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/nexgen32e/rldecode.S">17
byte run-length decoder</a>, and runtime code morphing can easily be
done using
Intel's <a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/third_party/xed/x86ild.greg.c">3kb
x86 decoder</a>.

</p><p>
Please note that this emulator isn't a
requirement. <span aria-label="Actually Portable Executables">αcτµαlly
pδrταblε εxεcµταblεs</span> work fine if you just run them on the shell,
the NT command prompt, or boot them from the BIOS. This isn't a JVM. You
only use the emulator if you need it. For example, it's helpful to be
able to have cool visualizations of how program execution impacts
memory.

</p><p>
It'll be nice to know that any normal PC program we write will "just
work" on Raspberry Pi and Apple ARM. All we have to do embed an ARM
build of the emulator above within our x86 executables, and have them
morph and re-exec appropriately, similar to how Cosmopolitan is already
doing doing with qemu-x86_64, except that this wouldn't need to be
installed beforehand. The tradeoff is that, if we do this, binaries will
only be 10x smaller than Go's Hello World, instead of 100x smaller. The
other tradeoff is the GCC Runtime Exception forbids code morphing, but I
already took care of that for you, by rewriting the GNU runtimes.

</p><p>
The most compelling use case for making x86-64-linux-gnu as tiny as
possible, with the availability of full emulation, is that it enables
normal simple native programs to run everywhere including web browsers
by default. Many of the solutions built in this area tend to focus too
much on the interfaces that haven't achieved consensus, like GUIs and
threads, otherwise they'll just emulate the entire operating system,
like Docker or Fabrice Bellard running Windows in browsers. I think we
need compatibility glue that just runs programs, ignores the systems,
and treats x86_64-linux-gnu as a canonical software encoding.

</p><h3>Long Lifetime Without Maintenance</h3>

<p>
One of the reasons why I love working with a lot of these old unsexy
technologies, is that I want any software work I'm involved in to stand
the test of time with minimal toil. Similar to how the Super Mario Bros
ROM has managed to survive all these years without needing a GitHub
issue tracker.

</p><p>
I believe the best chance we have of doing that, is by gluing together
the binary interfaces that've already achieved a decades-long consensus,
and ignoring the APIs. For example, here are the
<a href="https://github.com/jart/cosmopolitan/blob/667ab245fe0326972b7da52a95da97125d61c8cf/libc/sysv/consts.sh">magic
numbers</a> used by Mac, Linux, BSD, and Windows distros. They're worth
seeing at least once in your life, since these numbers underpin the
internals of nearly all the computers, servers, and phones you've used.

</p><p>
If we focus on the subset of numbers all systems share in common, and
compare it to their common ancestor, Bell System Five, we can see that
few things about systems engineering have changed in the last 40 years
at the binary level. Magnums are boring. Platforms can't …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://justine.lol/ape.html">https://justine.lol/ape.html</a></em></p>]]>
            </description>
            <link>https://justine.lol/ape.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273960</guid>
            <pubDate>Fri, 26 Feb 2021 12:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we do agile – implications for people in an agile organization]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273878">thread link</a>) | @leonardteo
<br/>
February 26, 2021 | https://leonardteo.com/2021/01/16/why-we-do-agile/ | <a href="https://web.archive.org/web/*/https://leonardteo.com/2021/01/16/why-we-do-agile/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

			
<article id="post-780">

	

	
			<figure>
				<img width="1568" height="882" src="https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg?w=1568" alt="" loading="lazy" srcset="https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg?w=1568 1568w, https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg?w=150 150w, https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg?w=300 300w, https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg?w=768 768w, https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg?w=1024 1024w, https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg 1600w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="799" data-permalink="https://leonardteo.com/2021/01/16/why-we-do-agile/why-agile-cover/" data-orig-file="https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg" data-orig-size="1600,900" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="why-agile-cover" data-image-description="" data-medium-file="https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg?w=300" data-large-file="https://leonardteo.files.wordpress.com/2021/01/why-agile-cover.jpg?w=620">			</figure><!-- .post-thumbnail -->

			
	<div>
		<p><span>As my company has grown over the last few years, I’ve had to hire (and let/seen go) a fair number of people. We’ve interviewed dozens of candidates. One of the most challenging things we find is in hiring people with the right culture fit. Agile is one of those cultures that unfortunately comes with many hidden implications I’d like to discuss in this post.</span></p>
<h2><span>Why do we do agile?</span></h2>
<p><span>Most software development professionals, whether it’s developers or managers (PO’s) these days use what they think is “agile methodology”. They know about working in sprints, Scrum, backlogs, stories, sprint goals, retros, etc. In a practical sense, they use agile but when asked, they don’t actually understand <em>why</em>.</span></p>
<p><span>In interviews I’ve asked people, “Why do we use agile?”</span></p>
<p><span>I’ve yet to get a satisfactory response. Some say “Because it’s not waterfall, waterfall is bad.” Or, “Agile is just better.” (Ok, but why do we use it?)</span></p>
<p><span>The reason for using agile is that creating software is so complex that there are more unknowns than there are knowns. Agile shortens the product development cycle into small increments that can be used so that real requirements emerge. The project evolves over time.&nbsp;</span></p>
<h2><span>What is agile then?</span></h2>
<p><span>At the core of agile is embracing that everything is ambiguous (and that your hypotheses and assumptions potentially aren’t correct). In product development, there are more unknowns than there are known.&nbsp;</span></p>
<figure><img src="https://leonardteo.files.wordpress.com/2021/01/2ab8c-08hjkn1irz_hio-l.jpg?w=1024&amp;h=923" alt="" width="1024" height="923"><figcaption>Embrace life as iterative, incremental and emergent. My interpretation from <a href="https://www.principles.com/">Principles</a> by Ray Dalio. I find this a great illustration for what it means to have an agile mindset.</figcaption></figure>
<p><span>The main idea of agile is in working iteratively, incrementally and continuously. Each feedback loop enables you to check if you are delivering value.&nbsp;</span></p>
<p><span>While the term “agile” is most popular in software development, it is becoming more commonplace among organizations (see </span><a href="https://www.mckinsey.com/business-functions/organization/our-insights/the-journey-to-an-agile-organization"><span>this</span></a><span> and </span><a href="https://www.mckinsey.com/business-functions/organization/our-insights/the-five-trademarks-of-agile-organizations#"><span>this</span></a><span>). ArtStation is considered an agile organization with our own structure called Organiq (will write about it in another post).</span></p>
<p><span>Interestingly while reading Ray Dalio’s Principles, he illustrates the looping ascent in one’s career/life. One sets audacious goals, fails, learns from them, improves, then sets higher goals. I found that illustration apt to describing agile philosophy. Product development, companies, careers can all take this iterative, compounding philosophy.</span></p>
<figure><img src="https://leonardteo.files.wordpress.com/2021/01/785a3-1eycjoaqco8dktviltka9tg.png?w=732&amp;h=643" alt="From Ray Dalio's Principles" width="732" height="643"><figcaption>From <a href="https://www.principles.com/">Principles</a> by Ray Dalio</figcaption></figure>

<h2><span>The “experts” are actually those with an open mind who are willing to test assumptions</span></h2>
<p><span>The main implication of agile is that you accept that there are more unknowns than known, and that your assumptions (perhaps based on your expertise &amp; experience) might not be correct.&nbsp;</span></p>
<p><span>For staffing, this presents a landmine. We’ve hired people who get frustrated and leave because they’ve brought assumptions under the broad banner of “expertise &amp; experience” that they are unwilling to yield on. In agile, that expertise &amp; experience is a great starting point but the assumptions must be tested, validated, observed and measured. Some people just can’t take that kind of examination (and it’s ok, agile isn’t for everyone).&nbsp;</span></p>
<p><span>You might hire someone who has decades of industry experience. This person brings a wealth of knowledge and experience but is unwilling to have those assumptions tested. And when they are and the results are questioned, they get offended and ask “Why did you hire me for my expertise if you’re going to allow other non-experts in the organization to scrutinize it?” It’s a great question, and it’s why agile is not for everyone. From my experience, the real experts are the ones who balance their expertise with the mindset that their assumptions (based on their experience) might not be completely correct under the present circumstances and are willing to test that.</span></p>
<p><span>If you have key people in your organization who are not willing to test and challenge their own assumptions, it is a sign that they haven’t embraced agile or maybe they just aren’t of that mindset. Agile is very challenging in this respect. You can have very experienced, senior people who have a title and position, and if they are trying to assert authority with those things, it creates tension in what is otherwise supposed to be a fluid, learning environment.</span></p>
<h2><span>Titles &amp; positions become tenuous – this is a problem&nbsp;</span></h2>
<p><span>Therefore, because agile is a learning environment where you’re constantly testing hypotheses &amp; assumptions, it becomes challenging to hide behind titles, positions and broad expressions of expertise and experience. Especially if you assert authority with those things.</span></p>
<p><span>The issue is that common assumptions hold that the title or position of a person commands authority. For example, if you’re a designer, common wisdom dictates that you should not be challenged on design unless it’s by another designer, preferably more senior than you. If you’re a marketer, common wisdom dictates that you should not be challenged on marketing unless it’s by another marketer, preferably more senior than you. It’s exacerbated by the mistaken belief that agile is something that only engineers use, and is not something that should be applied to other disciplines. Scrum (at least the<a href="https://www.scrumguides.org/docs/scrumguide/v1/scrum-guide-us.pdf" target="_blank" rel="noopener"> V1 of the Guide</a> in 2013 and removed in newer versions) adds insult to injury by stating that “Scrum recognizes no titles” — a big problem for people who have worked hard in their chosen profession and earned their position &amp; title, only to be challenged by others on the team who aren’t from that profession. How dare they!&nbsp;</span></p>
<p><span>This is a constant struggle. I find myself educating, and now being smart enough to not hire people who are after the title/position. Instead, I look for people who are open minded, humble and have a learning mindset. Even with experience, expertise and a good title, being able to say “This is what I think, but let’s test it and see what happens” is great. The whole organization benefits from having an agile mindset where everyone can learn.&nbsp;</span></p>
<p><span>I want to point out that generally having people who throw their weight around based on their title/position isn’t great anyway. Having someone say “I’m the [insert position/title] and you should do what I say” leads to tension in the team regardless of whether it’s agile or not. The point is that you want people who are humble enough to engage in healthy discourse and have an open mind. In Ray Dalio’s Principles, he puts forward the “idea meritocracy”, which is an environment where the best ideas win. The best ideas are determined by the quantity and quality of empirical data, not by positional power or title. In any case, this is challenging for many.</span></p>
<h2><span>Scrum: You are delivering small increments to test in the market instead of a blockbuster release (though you can marry the two)</span></h2>
<p><span>When working in Scrum, each sprint is essentially a timeboxed feedback loop. That’s why it’s important to try to deliver a working increment and get feedback from users and stakeholders.</span></p>
<p><span>More often, I see people’s understanding of Scrum to mean that they are phasing delivery in sprints but essentially it is still a big waterfall. E.g. having a UI design sprint, technical design sprint, implementation sprint, testing sprint, deployment sprint. This misses the opportunity for each sprint to be a feedback loop. This is just a phased waterfall.</span></p>
<p><a href="https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg"><img loading="lazy" data-attachment-id="793" data-permalink="https://leonardteo.com/2021/01/16/why-we-do-agile/scrumfall-vs-scrum-2/" data-orig-file="https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg" data-orig-size="2389,1269" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="scrumfall-vs-scrum" data-image-description="" data-medium-file="https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=300" data-large-file="https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=620" src="https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=620&amp;h=329" alt="" width="620" height="329" srcset="https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=620&amp;h=329 620w, https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=1240&amp;h=658 1240w, https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=150&amp;h=80 150w, https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=300&amp;h=159 300w, https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=768&amp;h=408 768w, https://leonardteo.files.wordpress.com/2021/01/scrumfall-vs-scrum.jpg?w=1024&amp;h=544 1024w" sizes="(max-width: 620px) 100vw, 620px"></a></p>
<p><span>The main benefit of agile is to be able to deliver small increments to users and stakeholders, get feedback, and keep iterating until you have something that is generally accepted (and delivering value). It is said to be iterative, incremental and evolutionary.</span></p>
<p><span>This does have implications for marketing and “when do you actually release?” What we try to do is to have features tested with subsets of users, get feedback and iterate quickly sprint to sprint until we get to a general availability. When everyone has access to the feature, that is the blockbuster release where we do the announcement and fanfare.&nbsp;</span></p>
<h2><span>The pace is quite fast – too fast for some</span></h2>
<p><span>When working with agile, the pace of release is intentionally quick. You’re getting increments in front of stakeholders quickly to get feedback and continuing to iterate. This can feel unnatural for people who are used to bundling releases over months and doing a big drop to users.&nbsp;</span></p>
<p><span>It is challenging to get the team’s mindset into the rhythm of just getting an increment in front of stakeholders to get feedback quickly. The natural tendency is to polish the feature until it feels “ready”. To our above point about actually releasing though – it’s not necessary to release the feature to everyone on production. The point is to get something in front of users so that they can test it, and get the feedback to continue iterating. For some features that we’ve done, that’s meant bringing users/customers to sprint reviews to get feedback directly, even though the feature is only on a review/dev server.</span></p>

<p><span>You know, it’s funny. When I chat with people, the understanding is that “Waterfall is bad”, but when you dig in, they are using waterfall themselves by phasing Scrum. They don’t understand the real reason behind taking an iterative, agile approach to product development.&nbsp;</span></p>
<p><span>I personally don’t think that a waterfall or phased approach to a project is inherently bad. Especially if it’s a short timeframe. In some cases waterfall is just the most appropriate way to do something.&nbsp;</span></p>
<p><span>In software product development, waterfall is problematic when the release cycle takes so long and has so much effort exerted that it risks missing the mark. The longer you spend without releasing to users, the more risk you layer on. You could spend months working on a release and get it out only to find that it does not completely solve the problem. The whole point of agile is to slice it up into smaller increments, deliver early, and with each delivery discover the real requirements based on actual usage of the product.</span></p>

<p><span>That’s some thoughts on agile, why (when it’s appropriate) to use agile, and its effects on people in an agile …</span></p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leonardteo.com/2021/01/16/why-we-do-agile/">https://leonardteo.com/2021/01/16/why-we-do-agile/</a></em></p>]]>
            </description>
            <link>https://leonardteo.com/2021/01/16/why-we-do-agile/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273878</guid>
            <pubDate>Fri, 26 Feb 2021 11:55:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Montevideo Convention on the Rights and Duties of States (1933)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273859">thread link</a>) | @simonebrunozzi
<br/>
February 26, 2021 | https://www.jus.uio.no/english/services/library/treaties/01/1-02/rights-duties-states.xml | <a href="https://web.archive.org/web/*/https://www.jus.uio.no/english/services/library/treaties/01/1-02/rights-duties-states.xml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="right-main">
       

       

           
            

       <!--startindex-->
       


<p>Done at: Montevideo</p>
<p>Date enacted: 1933-12-26</p>
<p>In force: 1934-12-26</p>
<div>
<p>The Governments represented in the Seventh International Conference of American States:
</p>
<p>Wishing to conclude a Convention on Rights and Duties of States, have appointed the following
Plenipotentiaries:</p>
<p>[List of plenipotentiaries omitted]</p>
<p>Who, after having exhibited their Full Powers, which were found to be in good and due order, have
agreed upon the following:</p>
</div>
<div>
<h3 id="article-header-1">Article 1</h3>
<p>The state as a person of international law should possess the following qualifications:</p>
<table>
<tbody><tr>
<td nowrap="">a.</td><td>
<p>a permanent population;</p>
</td>
</tr>
<tr>
<td nowrap="">b.</td><td>
<p>a defined territory;</p>
</td>
</tr>
<tr>
<td nowrap="">c.</td><td>
<p>government; and</p>
</td>
</tr>
<tr>
<td nowrap="">d.</td><td>
<p>capacity to enter into relations with the other states.</p>
</td>
</tr>
</tbody></table>
</div>
<div>
<h3 id="article-header-2">Article 2</h3>
<p>The federal state shall constitute a sole person in the eyes of international law.</p>
</div>
<div>
<h3 id="article-header-3">Article 3</h3>
<p>The political existence of the state is independent of recognition by the other states. Even before recognition the state has the right to defend its integrity and independence, to provide for its conservation and prosperity, and consequently to organize itself as it sees fit, to legislate upon its interests, administer its services, and to define the jurisdiction and competence of its courts. The exercise of these rights has no other limitation than the exercise of the rights of other states according to international law.</p>
</div>
<div>
<h3 id="article-header-4">Article 4</h3>
<p>States are juridically equal, enjoy the same rights, and have equal capacity in their exercise. The rights of each one do not depend upon the power which it possesses to assure its exercise, but upon the simple fact of its existence as a person under international law.</p>
</div>
<div>
<h3 id="article-header-5">Article 5</h3>
<p>The fundamental rights of states are not susceptible of being affected in any manner whatsoever.</p>
</div>
<div>
<h3 id="article-header-6">Article 6</h3>
<p>The recognition of a state merely signifies that the state which recognizes it accepts the personality of the other with all the rights and duties determined by international law. Recognition is unconditional and irrevocable.</p>
</div>
<div>
<h3 id="article-header-7">Article 7</h3>
<p>The recognition of a state may be express or tacit. The latter results from any act which implies the intention of recognizing the new state.</p>
</div>
<div>
<h3 id="article-header-8">Article 8</h3>
<p>No state has the right to intervene in the internal or external affairs of another.</p>
</div>
<div>
<h3 id="article-header-9">Article 9</h3>
<p>The jurisdiction of states within the limits of national territory applies to all the inhabitants. Nationals and foreigners are under the same protection of the law and the national authorities and the foreigners may not claim rights other or more extensive than those of the nationals.</p>
</div>
<div>
<h3 id="article-header-10">Article 10</h3>
<p>The primary interest of states is the conservation of peace. Differences of any nature which arise between them should be settled by recognized pacific methods.</p>
</div>
<div>
<h3 id="article-header-11">Article 11</h3>
<p>The contracting states definitely establish as the rule of their conduct the precise obligation not to recognize territorial acquisitions or special advantages which have been obtained by force whether this consists in the employment of arms, in threatening diplomatic representations, or in any other effective coercive measure. The territory of a state is inviolable and may not be the object of military occupation nor of other measures of force imposed by another state directly or indirectly or for any motive whatever even temporarily.</p>
</div>
<div>
<h3 id="article-header-12">Article 12</h3>
<p>The present Convention shall not affect obligations previously entered into by the High Contracting Parties by virtue of international agreements.</p>
</div>
<div>
<h3 id="article-header-13">Article 13</h3>
<p>The present Convention shall be ratified by the High Contracting Parties in conformity with their respective constitutional procedures. The Minister of Foreign Affairs of the Republic of Uruguay shall transmit authentic certified copies to the governments for the aforementioned purpose of ratification. The instrument of ratification shall be deposited in the archives of the Pan American Union in Washington, which shall notify the signatory governments of said deposit. Such notification shall be considered as an exchange of ratifications.</p>
</div>
<div>
<h3 id="article-header-14">Article 14</h3>
<p>The present Convention will enter into force between the High Contracting Parties in the order in which they deposit their respective ratifications.</p>
</div>
<div>
<h3 id="article-header-15">Article 15</h3>
<p>The present Convention shall remain in force indefinitely but may be denounced by means of one year's notice given to the Pan American Union, which shall transmit it to the other signatory governments. After the expiration of this period the Convention shall cease in its effects as regards the party which denounces but shall remain in effect for the remaining High Contracting Parties.</p>
</div>
<div>
<h3 id="article-header-16">Article 16</h3>
<p>The present Convention shall be open for the adherence and accession of the States which are not signatories. The corresponding instruments shall be deposited in the archives of the Pan American Union which shall communicate them to the other High Contracting Parties.</p>
</div>
<div>

<p>In witness whereof, the following Plenipotentiaries have signed this Convention in Spanish, English, Portuguese and French and hereunto affix their respective seals in the city of Montevideo, Republic of Uruguay, this 26th day of December, 1933.</p>
</div>
<div>

<p>Number of ratifications: 16</p>
<p>Brazil, Chile, Colombia, Costa Rica, Cuba, Dominican Republic, Ecuador, El Salvador, Guatemala, Haiti, Honduras, Mexico, Nicaragua, Panama, United States of America, Venezuela</p>
</div>

       <!--stopindex-->
     </div></div>]]>
            </description>
            <link>https://www.jus.uio.no/english/services/library/treaties/01/1-02/rights-duties-states.xml</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273859</guid>
            <pubDate>Fri, 26 Feb 2021 11:51:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to make your code blocks accessible on your website]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273824">thread link</a>) | @whitep4nth3r
<br/>
February 26, 2021 | https://whitep4nth3r.com/blog/how-to-make-your-code-blocks-accessible-on-your-website | <a href="https://web.archive.org/web/*/https://whitep4nth3r.com/blog/how-to-make-your-code-blocks-accessible-on-your-website">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you’re a developer or technical writer who publishes content on the internet, you’ll want to make sure your code examples are presented beautifully for your audience to consume.&nbsp;</p><p>The good news is, there are plenty of tools available to adorn your website with fancy-looking code blocks in your blog posts, that mimic current and trendy IDE themes. For example, this site uses the <b>Okaidia</b> theme from <a href="https://prismjs.com/" target="_blank" rel="noopener noreferrer">Prism.js</a> to present code like this:</p><pre><code>import CodeBlockStyles from "./CodeBlock.module.css";
import Prism from "prismjs";
import { useEffect } from "react";

export default function CodeBlock(props) {
  useEffect(() =&gt; {
    Prism.highlightAll();
  }, []);

  const { language, code } = props;

  return (
    &lt;pre className={`${CodeBlockStyles.codeBlock} language-${language}`}&gt;
      &lt;code className={CodeBlockStyles.codeBlock__inner}&gt;{code}&lt;/code&gt;
    &lt;/pre&gt;
  );
}</code></pre><p>The bad news is, most prebuilt themes (especially those with darker colour palettes) come loaded with accessibility issues such as <b>failing colour contrast checks</b>, meaning your audience may have difficulties consuming your code examples. Additionally, your website will be penalised in web search results for failing accessibility checks.</p><p>This means we need to do a little more work in CSS to make our code blocks accessible. Let’s take a look.</p><p><a href="#fixing-code-block-accessibility-issues" target="_blank" rel="noopener noreferrer">Jump straight to the code examples.</a></p><div><h2 id="how-to-check-accessibility-on-your-website">How to check accessibility on your website</h2><a href="#how-to-check-accessibility-on-your-website" aria-label="How to check accessibility on your website"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" height="32" width="32"><path fill="#ffb626" d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a></div><p>Accessibility standards are defined by the <a href="https://www.w3.org/WAI/standards-guidelines/wcag/" target="_blank" rel="noopener noreferrer">Web Content Accessibility Guidelines (WCAG)</a>. There are a number of free tools you can use to check for accessibility on your website. Not all tools will catch everything and some tools may catch false positives. For this reason I always recommend using a combination of tools to ensure you can create the best experience possible for your audience.</p><h3>Google Lighthouse</h3><p>If you’re developing in Google Chrome or Microsoft Edge, you can access the <a href="https://developers.google.com/web/tools/lighthouse#devtools" target="_blank" rel="noopener noreferrer"><u>Google Lighthouse tools from your developer console</u></a>. </p><p><i>Quick tip — some Chrome plugins can affect the way Lighthouse runs in your browser — so it’s always recommended to run these checks in an incognito window without any plugins activated.</i></p><div><div><p><img alt="A screenshot showing the Google Lighthouse dev tools tab with the Accessibility checkbox checked" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p>You can use Google Lighthouse to run a variety of reports on your web pages. Check the 'Accessibility' checkbox and click ‘Generate report’.</p><div><div><p><img alt="A screenshot showing a 100% Accessibility score on the Google Lighthouse dev tools tab" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p>Here’s an accessibility check for <a href="https://whitep4nth3r.com/blog/how-to-build-a-lightweight-blog" target="_blank" rel="noopener noreferrer"><u>this blog post</u></a> (including code blocks) which produces a satisfying score of 100%! 🎉&nbsp; But remember — as the report shows — there are always areas of your website that automated tools might not be able to assess correctly — so you should always carry out manual checks as well.</p><h3>axe — Web Accessibility Testing</h3><p>I’ve been using <a href="https://chrome.google.com/webstore/detail/axe-web-accessibility-tes/lhdoppojpmngadmnindnejefpokejbdd" target="_blank" rel="noopener noreferrer"><u>this Chrome plugin</u></a> for a number of years, and it has helped me incredibly in improving my knowledge of accessibility.</p><p>Install the plugin, open your Chrome dev tools, and navigate to the ‘axe’ tab.&nbsp;</p><div><div><p><img alt="A screenshot of the axe accessibility panel in Chrome dev tools with options to scan all of my page and scan part of my page" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p>What’s great about axe is that it shows the HTML code for any issues that it has detected. For the same blog post we scanned with Lighthouse above, axe finds 11 issues.&nbsp;</p><p>That's not so good! But let’s investigate.</p><div><div><p><img alt="A screenshot showing an axe accessibility tool issue description of failing colour contrast in a YouTube iframe embed" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p>Axe is describing colour contrast issues inside a YouTube iframe embed. It’s not related to any CSS that's bundled with the web page, and it’s not ideal. We might be able to fix it if we can target the iframe CSS effectively, or use a different thumbnail on the YouTube video. But for now, it's good to know!</p><h3>WAVE Evaluation Tool</h3><p>The third tool that is integral to my accessibility workflow is the <a href="https://chrome.google.com/webstore/detail/wave-evaluation-tool/jbbplnpkjmmeebjpijfedlgcdilocofh" target="_blank" rel="noopener noreferrer"><u>Wave Evaluation Tool Chrome extension</u></a>. This tool is great for highlighting semantic HTML and ensuring you’ve included the necessary aria labels.</p><p>Here’s an example of Wave in action.</p><div><div><p><img alt="A screenshot showing a Wave Evaluation Tool summary tab overlaid on the home page of whitep4nth3r.com" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p>Click on ‘View details’ to see a detailed breakdown of the summary.</p><div><div><p><img alt="A screenshot showing a Wave Evaluation Tool details tab overlaid on the home page of whitep4nth3r.com" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><div><h2 id="fixing-code-block-accessibility-issues">Fixing code block accessibility issues</h2><a href="#fixing-code-block-accessibility-issues" aria-label="Fixing code block accessibility issues"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" height="32" width="32"><path fill="#ffb626" d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a></div><p>There are two main issues to look for in your code blocks, both of which axe picked up for me.</p><h3>Ensure the contrast between foreground and background colors meets WCAG 2 AA contrast ratio thresholds</h3><p>The theme I chose to use from Prism.js is beautiful, but some of the colours failed the colour contrast checks.</p><p>Here is a code block that failed a colour contrast check:</p><div><div><p><img alt="A screenshot of a code block that fails colour contrast" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p>This is described in axe alongside the underlying HTML:</p><div><div><p><img alt="A screenshot of the axe accessibility panel in Chrome dev tools showing a failing colour contrast check" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><h3>Finding accessible colours</h3><p>Another neat tool I use is the <a href="https://colourcontrast.cc/" target="_blank" rel="noopener noreferrer"><u>Colour Contrast checker</u></a> that’s also available as a <a href="https://chrome.google.com/webstore/detail/colour-contrast-checker/nmmjeclfkgjdomacpcflgdkgpphpmnfe?hl=en-GB" target="_blank" rel="noopener noreferrer"><u>Chrome extension</u></a>. Activate the extension, and use the eyedropper to select background and foreground colours to view whether it passes <a href="https://www.w3.org/WAI/standards-guidelines/wcag/" target="_blank" rel="noopener noreferrer"><u>Web Content Accessibility Guidelines (WCAG)</u></a>.</p><div><div><p><img alt="A screenshot of the Colour Contrast Checker Chrome extension showing a failing colour contrast check" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p>The beautiful thing about this tool is you can move the hue, saturation and light sliders to find colours that pass accessibility guidelines without having to leave your browser page. Using the slider tools, I was able to find colours that passed colour contrast checks, and added the following overrides to my global CSS file:</p><pre><code>  /* accessibility fixes for prismjs */

  .token.comment {
    color: #adb8c2 !important;
  }

  .token.important {
    color: #f3a344 !important;
  }

  .token.tag,
  .token.property,
  .token.constant {
    color: #fc92b6 !important;
  }</code></pre><h3>Elements that have scrollable content should be accessible by keyboard</h3><p>This accessibility violation was a little trickier to solve, and is the primary reason for writing this blog post.</p><div><div><p><img alt="A screenshot showing an axe accessibility tool issue description of scrollable content failure" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div></div><p>Prism.js ships with the following code that caused this violation, which causes overflow text to scroll rather than wrap:</p><pre><code>pre[class*="language-"] {
   padding: 1em;
   overflow: auto;
   border-radius: 0.3em;
}</code></pre><p>Code blocks are not focusable by a keyboard (whereas anchor tags <i>are</i> focusable, for example). This means that if your audience is using only a keyboard to navigate the site, they will be unable to access the content that has overflowed the container, which would usually be scrolled with a mouse.</p><p>The way to fix this accessibility issue is to ensure the text will wrap when necessary inside the <code>&lt;code&gt;</code> tag.</p><p>Here’s the code I used to prevent the scrolling behaviour and make the text wrap onto a new line:</p><pre><code>code[class*="language-"] {
  white-space: pre-wrap;
}
</code></pre><p>Prebuilt IDE-like code block themes like the ones available from Prism.js are beautiful, but if you want to use one, ensure you check for accessibility issues such as colour contrast and scrolling behaviour. This will ensure your audience can use your site effectively, and your site ranks well in search engines for accessibility.&nbsp;</p><p>And remember: Build stuff, learn things, love what you do.</p></div></div>]]>
            </description>
            <link>https://whitep4nth3r.com/blog/how-to-make-your-code-blocks-accessible-on-your-website</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273824</guid>
            <pubDate>Fri, 26 Feb 2021 11:47:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unfolding the Earth: Myriahedral Projections]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273813">thread link</a>) | @hunter-2
<br/>
February 26, 2021 | http://philogb.github.io/page/myriahedral/ | <a href="https://web.archive.org/web/*/http://philogb.github.io/page/myriahedral/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://philogb.github.io/page/myriahedral/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273813</guid>
            <pubDate>Fri, 26 Feb 2021 11:46:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fake Spotify accounts are hijacking the music charts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273800">thread link</a>) | @paulpauper
<br/>
February 26, 2021 | https://www.thenationalnews.com/arts-culture/the-machines-faking-the-streams-how-fake-spotify-accounts-are-hijacking-the-music-charts-1.882351 | <a href="https://web.archive.org/web/*/https://www.thenationalnews.com/arts-culture/the-machines-faking-the-streams-how-fake-spotify-accounts-are-hijacking-the-music-charts-1.882351">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                <div>
                                    
                                    <div><p>So-called 'phantom listening' may be dictating who our most-listened to artists now are, not actual streaming data</p></div>                                </div>
                                
                                <div>
                                                                                                                                                                                                              
                                                            <figure>
            <img sizes="(min-width: 768px) and (max-width: 1023px) 50vw, 100vw" alt="BTS sold the must albums last year but Drake was the most streamed artist. Getty&nbsp;" src="https://www.thenationalnews.com/image/policy:1.815278:1562154866/1082385766.jpg?f=16x9&amp;w=1200&amp;$p$f$w=3c8e60c" data-src="/image/policy:1.815278:1562154866/1082385766.jpg?f=16x9&amp;w=1200&amp;$p$f$w=3c8e60c" data-srcset=" /image/policy:1.815278:1562154866/1082385766.jpg?f=16x9&amp;w=500&amp;$p$f$w=e1874db 500w, /image/policy:1.815278:1562154866/1082385766.jpg?f=16x9&amp;w=700&amp;$p$f$w=cd2b0f3 700w, /image/policy:1.815278:1562154866/1082385766.jpg?f=16x9&amp;w=940&amp;$p$f$w=5e9d882 940w, /image/policy:1.815278:1562154866/1082385766.jpg?f=16x9&amp;w=1024&amp;$p$f$w=1d575e5 1024w, /image/policy:1.815278:1562154866/1082385766.jpg?f=16x9&amp;w=1200&amp;$p$f$w=3c8e60c 1200w">
                                                 
            <label for="show-caption">
				<span>
					<svg width="6" height="14" viewBox="0 0 6 14">
						<path d="M4.6 12l-.4 1.4c-.7.2-1.9.6-3 .6-.7 0-1.2-.2-1.2-.9 0-.2 0-.3.1-.5l2-6.7H.7l.4-1.5 4.2-.6h.2L3 12h1.6zm-.3-9.2c-.9 0-1.4-.5-1.4-1.3C2.9.5 3.7 0 4.6 0 5.4 0 6 .5 6 1.3c0 1-.8 1.5-1.7 1.5z"></path>
					</svg>
				</span>
            </label>
            <figcaption>BTS sold the must albums last year but Drake was the most streamed artist. Getty&nbsp;</figcaption>
                    </figure>
                                                                                                                                                            </div>
                            </div><div>
                                <div>
                                                                                                <p><span>Who</span><span>’s the most popular music</span><span>ian in the world? The data generated by our listening habits should make this an easy question to answer, but it’s far from straightforward. Last year, South Korean boy band</span><span> </span><span>BTS sold a chart-topping </span><span>five million copies of their two album</span><span>s globally (</span><span><em>Love Yourself: Tear</em></span><span> and </span><span><em>Love </em></span><span><em>Yourself: Answer</em></span><span>), but Canadian rapper Drake was the most-streamed artist, with 8.2 billion plays on Spotify alone. So who’s bigger? </span></p> 
<p><span>Official chart compilers such as Billboard use complex calculations to factor in the ways people consume music, while countless unofficial charts tell us what’s popular and what’s trending. But some of the numbers feeding those charts are being distorted and manipulated by “fake streaming”. </span><span>A group of 21 music industry companies, including streaming services, record labels and publishers, recently agreed on a “code of best practices” to tackle the problem. One label boss </span><span>says </span><span>as much as $300m (Dh1.1 billion) a year is being leeched from the industry by so-called “phantom listening”.</span></p> 
<h2><strong>The problem with 'fake streaming'</strong></h2> 
<p><span>Musicians have long had their suspicions. The opening track of 21 Savage’s most recent album contains the lyrics: “How many faking they streams? / A lot / Getting they plays from machines? / A lot / I can see behind the smoke and mirrors </span><span>…” The vulnerability of streaming statistics to manipulation is down to one fact: while computerised systems can register a track being played, there’s no way it can know if someone is listening to it. One definition of fake streaming from </span><span>Angel Gambino, chief commercial officer at Napster</span><span><strong> </strong></span><span>is: “anything which isn’t fans listening to music they love” – and there’s a lot of it happening, not least because money can be made by doing so. </span></p> 
 
<p><span>A report released last year</span><span> </span><span>by analysts Music Business Worldwide</span><span> </span><span>highlighted a scam operating from Bulgaria, where 1,200 fake Spotify accounts were used to constantly play two playlists of tracks by unknown artists, all around 30 seconds long (the minimum amount of time for Spotify to identify it as a streamed play). One of those playlists rose through the Spotify chart to become the 35th most-streamed in the world. It would have cost the scammers $12,000 a </span><span>month to run those 1,200 accounts, but the royalty payout to whoever released the tracks could have amounted to as much as $415,000 </span><span>a month. The scam ran for four months before it was rumbled by Spotify.</span></p> 
<p><span>Such </span><span>schemes cause consternation among</span><span> artists and labels because “fake streaming” royalties eat into everyone else’s. Streaming services operate what’s called a “shared pool” model, splitting all income according to the number of streams accrued, so if the numbers are being sabotaged, musicians don’t get the money they deserve.</span></p> 
<h2><strong>Streaming in the digital age</strong></h2> 

<p><span>In truth, of course, musicians rarely have. In a pre-­digital era they would be entitled to a percentage of every record sale, but record companies would avoid paying them while spending huge sums on influencing the public perception of an artist</span><span> through plugging, hype and payola. We shouldn’t be surprised to see similar techniques deployed in the digital era, </span><span>says </span><span>Patrick Vonderau, a professor at Martin Luther University in Halle-­Wittenberg, Germany,</span><span> and co-author of the book </span><span><em>Spotify Teardown: Inside </em></span><span><em>the Black Box </em></span><span><em>of Music Streaming</em></span><span>.</span></p> 
<p><span>“For sceptics who never believed the hype around organic growth,” he says, “or for historians who know how analog worlds have always boosted brands and built reputation, this is hardly new or shocking.” </span></p> 
<p><span>What has changed is the number of potential influencers, from the vaguely legitimate to the downright dastardly and a large grey area in between. The Bulgarian streaming scam was outrageous, but one could say it played by the rules. Paying to get an act into a popular online streaming playlist may be morally dubious, but it’s an everyday occurrence. Fans campaigning to propel their favourite artists into streaming charts is also normal – although in the case of BTS it’s been done on an industrial scale, with fans creating streaming accounts, sharing logins across social media and urging other fans to use them.</span></p> 
<p><span>From fans’ use of streaming services to the companies themselves, there’s little transparency. Tidal, owned by musician Jay-Z, has been accused by Norwegian newspaper Dagens Naeringsliv of manipulating streaming numbers (and royalty payments) in favour of its biggest artists, Kanye West and Beyoncé; analysis done in conjunction with the Norwegian University of Science and Technology found that an alleged 320 million “phantom listens” had been logged for Kanye’s <em>The Life Of Pablo</em></span><span> and Beyonce’s </span><span><em>Lemonade</em></span><span> across 1.7 million Tidal accounts. </span></p> 
<p><span>One of those accounts belonged to music critic Geir Rakvaag, whose stats suggested that he had listened to songs from </span><span><em>The Life of Pablo</em></span><span> 96 times in 24 hours – more than half of them overnight – which he described as “impossible”. Tidal has refuted the allegations, but in recent months four former Tidal employees have undergone 25 hours of questioning by Norwegian public prosecutors.</span></p> 
<h2>So what can be done to stop this practice?</h2> 
<p><span>A good deal of this nefarious activity is driven by the value of a slice of the streaming pie, and the relative ease of grabbing it. Vonderau describes a parallel “engagement industry” where fake streams are bought or sold by hopeful artists seeking recognition, or high-turnover resellers seeking a fast buck. </span></p> 
<blockquote>   
  
 <p><span>You do not need anything, not even computing skills, to set up an online shop and make money. Above the shop level you have so-called panels, [for which] you need a somewhat higher skill level and connections to sources. </span></p> 
 <p><span>Patrick Vonderau, a professor at Martin Luther University</span></p>  
</blockquote> 
<p><span>“You do not need anything, not even computing skills, to set up an online shop and make money,” says Vonderau. “Above the shop level you have so-called panels, [for which] you need a somewhat higher skill level and connections to sources. What might be harmful in the long run is that the anonymous entrepreneurs who operate these shops and panels believe in a culture of creative destruction. It grounds culture, and the dissemination of music, books, films, you name it, on a rather problematic business model.”</span></p> 
<p><span>As with social media companies, streaming services have enormous reach but comparatively few resources to tackle fraud, and this, according to Vonderau, will ensure the problem continues – and new fake streaming methods rely less on bots and more on authentic users. “An example,” he says, “would be teens in Brazil downloading an app to their phone which asks them to register their preferences in return for a few cents per month. The app acts on their behalf, without them doing much in addition.”</span></p> 
<p><span>The streaming model should be simple: the artists with more streams make more money. But the multitude of ways in which the system can be gamed will do nothing to help the music industry’s reputation, which was so memorably described by Hunter S. Thompson</span><span> as “</span><span>a cruel and shallow money trench, a long plastic hallway where thieves and pimps run free, and good men die like dogs. There’s also a negative side</span><span>”.</span></p>
                                                                                                <p><em><p>Updated: July 3, 2019 03:54 PM </p></em></p>
                                                        
                            
                        </div>
                    </div></div>]]>
            </description>
            <link>https://www.thenationalnews.com/arts-culture/the-machines-faking-the-streams-how-fake-spotify-accounts-are-hijacking-the-music-charts-1.882351</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273800</guid>
            <pubDate>Fri, 26 Feb 2021 11:45:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Reading More Effectively and Efficiently]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 162 (<a href="https://news.ycombinator.com/item?id=26273735">thread link</a>) | @ingve
<br/>
February 26, 2021 | https://aliabdaal.com/read-more-effectively/ | <a href="https://web.archive.org/web/*/https://aliabdaal.com/read-more-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>It might seem odd to have a blog post devoted entirely to reading. After all, if you’re reading this, chances are you can read. But reading effectively and efficiently is its own skill - one that we’re never really taught how to do.</p><p>Throughout our academic life, we’re programmed to believe that effective reading is measured by speed and breadth. The more we can read, the smarter we look. And the more broadly we can read, the more intelligent we seem.</p><p>In fact, I’ve fallen prey to this myself, making a clickbait video called <em><a href="https://www.youtube.com/watch?v=8tKuviI68Ss">How I Read 100 Books a Year</a></em>. Full disclosure: I don’t actually. It’s closer to 50. But that makes for a less clickable video (sorry, not sorry).</p><p>Because of this obsession we have with reading more, we miss out on a lot of valuable insights. Wisdom from across the ages, the lessons mastered by people who've overcome extraordinary challenges, and the chance to gain knowledge that challenges our beliefs. All because we're never taught the ultimate meta-skill: the art of reading.</p><p>Reading more effectively and efficiently means developing a watertight process to <strong>capture ideas</strong>, <strong>analyse arguments</strong>, and <strong>ask the right questions</strong>. It means identifying the <strong>right books to read</strong>, understanding the <strong>different reading goals</strong>, and using evidence-based techniques to <strong>increase reading productivity</strong>.</p><p>In many ways, improving the way we read is the number one skill that can change our lives for the better.</p><h2 id="the-importance-of-effective-efficient-reading">The Importance of Effective &amp; Efficient Reading</h2><blockquote>“A person who won’t read has no advantage over one who can’t read" - Mark Twain</blockquote><p>Books have had an enormous impact on my own life. They’ve acted as a personal mentor, and as a vehicle for compounding knowledge.</p><h3 id="-books-have-been-my-personal-mentors">🤓 Books have been my Personal Mentors</h3><p>If someone asked me to name the most influential people in shaping my life (outside of my immediate family), I wouldn't find it too hard to identify a group of people who've transformed my thinking through their incredible actions, ideas, and journeys. But the number one influence in my life wouldn't be people at all. It would be books.</p><p>By reading lots of books (and by trying to read effectively), I've managed to accumulate decades worth of knowledge and experience from the world's most incredible minds, with minimal personal effort. I've learned from mistakes without having to fail, I've learned from successes without having to take huge risks, and I've travelled thousands of miles without leaving the comfort of my bed in Cambridge.</p><p>Reading is the mentor without the cost, the pain, and the discomfort. I honestly wouldn't have started <a href="https://6med.co.uk/">6med</a>, my <a href="https://www.youtube.com/channel/UCoOae5nYA7VqaXzerajD0lg">YouTube channel</a>, or decided to <a href="https://book.aliabdaal.com/">write a book</a> without the encouragement, motivation, inspiration, and boundless insights offered by my paper friends. Seriously. My only regret is that I didn't learn to read properly sooner.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/hv1gOEY3cs4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>3 Books That Changed My Life</figcaption></figure><h3 id="-books-help-us-compound-knowledge">🧠 Books help us Compound Knowledge</h3><blockquote>"Compound interest is the 8th Wonder of the World" - Albert Einstein</blockquote><p>Just as money accumulates exponentially, so too does personal knowledge as it snowballs and branches out over time. In other words, the more we read and the better our reading processes are, the more our ideas, beliefs, and opinions begin to develop at an ever-increasing rate.</p><p>Not only does our brain begin effortlessly creating connections between seemingly disparate pieces of information, but cohesive and creative solutions to some of our most puzzling and perplexing problems gradually emerge. It's a personal superpower that all of us have the opportunity to discover.</p><blockquote>“To develop a complete mind: Study the science of art; Study the art of science. Learn how to see. Realise that everything connects to everything else” - Da Vinci</blockquote><h2 id="the-reading-objective">The Reading Objective</h2><p>Increasing our ability to read more effectively, as a means to unlock our own personal potential, begins by deciding on a reading goal. After all, we’re probably going to have a different objective and experience reading <em>Paradise Lost</em> compared to our favourite <em>Harry Potter</em> book.</p><p>Many brilliant authors talk about books as having a rather loose objective of success, happiness, and personal fulfilment. Roald Dahl, for instance, said that "if you are going to get anywhere in life, you have to read a lot of books". And J. K. Rowling once said that "something very magical can happen when you read a good book".</p><p>But I’d agree, these opinions are abstract, subjective, and largely unhelpful in guiding the way in which we should read. Instead, it's easier and more useful for our purposes to segment reading objectives into three distinct categories, as identified by Mortimer Adler in <em><a href="https://geni.us/HkStXXO">How to Read a Book</a></em>.</p><h3 id="-category-1-reading-to-entertain">🤪 Category 1: Reading to Entertain</h3><p>In this category, we read books purely for enjoyment. It’s how we spend the majority of our time as readers. There are no rules and there's no need to think too deeply or critically about what we’re reading. The goal is simple: we can relax and immerse ourselves in the story.</p><p>There’s nothing inherently wrong with reading to entertain ourselves.</p><p>It's a healthy way to escape from everyday stress and, if you're anything like me, a perfect way to finish <a href="https://www.youtube.com/watch?v=KMskdqtR1yA">a productive day of work</a>. In particular, I enjoy reading (or listening to) fantasy novels (with the <a href="https://brandonsanderson.com/">Brandon Sanderson</a> books being a personal favourite). I even created a video on <em><a href="https://www.youtube.com/watch?v=i7awefFU_Hg">My Favourite Fantasy Books</a></em>, which you can check out if you're interested.</p><h3 id="-category-2-reading-to-inform">🗞 Category 2: Reading to Inform</h3><p>In this second category, we read books to learn specific facts or information about something. These books are typically easy to navigate and simple in their layout and structure. This lets us consume them effortlessly and jump around to relevant sections without losing the gist of what's being said. The goal is to <strong>learn without judgement</strong>.</p><p>For example, we'd read the newspaper, a tourist guide, or the <em>Guinness World Records, </em>all to inform. Although we may find aspects of each of them entertaining, we primarily read these things to develop a factual picture of current affairs, a particular location, or some other snippet of knowledge.</p><p>Again, for most of us, reading to inform isn't too problematic.</p><h3 id="-category-3-reading-to-understand">📖 Category 3: Reading to Understand</h3><p>It's the final category of reading - reading to understand - that most of us (including me) tend to struggle with. It therefore deserves most of our attention when it comes to improving the efficiency and effectiveness of our reading.</p><p>The problem is that out of the three reading categories, reading to understand requires the greatest cognitive effort. It forces us to challenge our preconceptions, critically analyse the status quo, and directly confront ideas that we may not be immediately comfortable with. This is hard. It can be uncomfortable. But it’s the only way for us to level-up our thinking and personal growth.</p><p>Ultimately, this is a skill that few of us have mastered. But it's at the very heart of meaningful productivity and improving the way we read. Therefore, we need a method that takes us from reading at an elementary level (like when we’re reading to entertain and inform) to reading at an analytical or syntopical level.</p><p>Let's dive into how we can do this.</p><h2 id="the-four-levels-of-reading">The Four Levels of Reading</h2><figure><img src="https://aliabdaal.com/content/images/2021/02/GW-Article.png" alt="" srcset="https://aliabdaal.com/content/images/size/w600/2021/02/GW-Article.png 600w, https://aliabdaal.com/content/images/size/w1000/2021/02/GW-Article.png 1000w, https://aliabdaal.com/content/images/size/w1600/2021/02/GW-Article.png 1600w, https://aliabdaal.com/content/images/2021/02/GW-Article.png 2000w" sizes="(min-width: 720px) 720px"></figure><p>While the three categories of reading help guide our reading goal, the four cumulative levels of reading help guide our reading style. These levels were again devised by Mortimer Adler and operate to help us understand a book at a far deeper level than what most of us are used to. As we move up the levels we'll not only find ourselves more capable of grasping the author's perspectives and forge deeper insights, but we'll have a process that works with every single book we decide to read.</p><p>This is great stuff.</p><h3 id="-level-1-elementary-reading">👶 Level 1: Elementary Reading</h3><p>The first level of reading is the style of reading that everyone knows how to do, as it's what we're taught in school. As an elementary reader we can easily understand the words on the page, follow the plot, and have a solid grasp of what the book is trying to say.</p><p>However, even at this elementary level, it's easy to screw it up by trying to read too quickly.</p><p>As you know, I'm all about <a href="https://aliabdaal.com/productivity/">increasing productivity</a>, but trying to improve reading speed before understanding the fundamentals of effective reading is only going to hinder our capacity to learn new information.</p><p>My advice - we should try and first improve our reading level. Then, once we've mastered the art of reading analytically, we can worry about reading faster (and we'll talk more about this later).</p><blockquote>"Every book should be read no more slowly than it deserves, and no more quickly than you can read it with satisfaction and comprehension” - Adler</blockquote><h3 id="-level-2-inspectional-reading">🔎 Level 2: Inspectional Reading</h3><p>This second level of reading requires marginally more skill than at the elementary reading level. As an inspectional reader we're tasked with unearthing the overall framework of the book and mapping out the general picture the author is trying to paint. The idea is that we're making some preliminary calculations about the book's content and worth before delving into it properly.</p><p>There are two aspects to inspectional reading: systematic skimming and superficial reading.</p><p><strong>Systematic Skimming</strong></p><p>With systematic skimming our aim is to decide whether or not this is a book we actually want to spend the time reading. I like to ask myself "is this one of the greats that I'd happily spend the next few hours of my life looking at?". If the answer is anything less than "hell yes!" then I won't bother reading it.</p><p>To help me answer this question, I first look at the title, the blurb, and the contents page to determine what the book is about and understand its high-level structure. I then flip through the book concentrating on each chapter's introduction, conclusion, and any sub-headings that interest me. In other words, I do a surface level examination of the book before writing a couple of sentences that neatly summarises everything.</p><p>Another way to systematically skim a book is by reading a book summary. My favourite way of doing this is with the service <a href="https://go.aliabdaal.com/shortform">Shortform</a>. If a book’s available on <a href="https://go.aliabdaal.com/shortform">Shortform</a> (they’re always adding …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aliabdaal.com/read-more-effectively/">https://aliabdaal.com/read-more-effectively/</a></em></p>]]>
            </description>
            <link>https://aliabdaal.com/read-more-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273735</guid>
            <pubDate>Fri, 26 Feb 2021 11:36:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of Wittgenstein's Tractatus logico-philosophicus]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273670">thread link</a>) | @martinlaz
<br/>
February 26, 2021 | https://pbellon.github.io/tractatus-tree/ | <a href="https://web.archive.org/web/*/https://pbellon.github.io/tractatus-tree/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pbellon.github.io/tractatus-tree/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273670</guid>
            <pubDate>Fri, 26 Feb 2021 11:25:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp and most alternatives share the same problem]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 179 (<a href="https://news.ycombinator.com/item?id=26273594">thread link</a>) | @sysoleg
<br/>
February 26, 2021 | https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/ | <a href="https://web.archive.org/web/*/https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
            
            
<p>Shall I migrate to Signal, Threema or Telegram? No, because they all have — WhatsApp included — the same problem: They are walled gardens. Imagine a world where for each mail recipient using a separate domain, I would need separate mail client? Or in other words: Gmail users can only communicate with Gmail users.</p>



<h5>Let’s start with mail first.</h5>



<p>The origin of mail were a couple of geeks who wanted to exchange messages on ARPANET (the internets great grandmother). At the time they solved two challenges. Invent a packet-switching network with distributed control that was intended to survive a nuclear attack. And hook up different types of computers types that were not interoperable at the time: A DEC PDP-10, a SDS Sigma 7, an IBM 360/75 and SDS 940. The second topic is our primary issue here.</p>



<figure><img loading="lazy" width="622" height="749" src="https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969.jpg" alt="" srcset="https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969.jpg 622w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-249x300.jpg 249w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-580x698.jpg 580w, https://stuker.com/wp-content/uploads/2021/02/arpanet-four-nodes-dec-1969-320x385.jpg 320w" sizes="(max-width: 622px) 100vw, 622px"></figure>



<p>To achieve this they agreed on a common terminology and on common standards to exchange messages in a collaborative way. Layering on existing definitions (such as TCP/IP) they created:</p>



<ul><li>RFC 524: <a href="https://tools.ietf.org/html/rfc524">A Proposed Mail Protocol</a></li><li>RFC 561: <a href="https://tools.ietf.org/html/rfc561">Standardizing Network Mail Headers</a></li><li>RFC 680: <a href="https://tools.ietf.org/html/rfc680">Message Transmission Protocol</a></li><li>RFC 724: <a href="https://tools.ietf.org/html/rfc724">Proposed Official Standard for the Format of ARPA Network Messages</a></li></ul>



<p>That summed up later in the document RFC 733: <a href="https://tools.ietf.org/html/rfc733">STANDARD FOR THE FORMAT OF ARPA NETWORK TEXT MESSAGES</a> . And many of the aspects solved back then still live in today’s mail infrastructure. Including an address scheme using “@”.</p>



<figure><img loading="lazy" width="1024" height="655" src="https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1024x655.jpg" alt="" srcset="https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1024x655.jpg 1024w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-300x192.jpg 300w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-768x492.jpg 768w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-1536x983.jpg 1536w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-720x461.jpg 720w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-580x371.jpg 580w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson-320x205.jpg 320w, https://stuker.com/wp-content/uploads/2021/02/ray-tomlinson.jpg 1656w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Raymond&nbsp;Tomlinson who implemented the first&nbsp;email&nbsp;program on the&nbsp;ARPANET</figcaption></figure>



<p>Later the transport of the messages (originally they used multiple protocols such as CPYNET, UUCP or FTP) transitioned in 1981 to SMTP which is still todays way to transport mail. All of this allows that any mail client (MUA = Mail User Agent) can talk via any mail server (MTA = Mail Transfer Agent). An open, collaborative process defining an interoperable system.</p>



<h5>And now come the instant messengers.</h5>



<p>As I already said Signal, Threema, Telegram AND WhatsApp are broken. Why does everybody wanting to exchange messages need the same client? Before digging into more technical detail or rant about companies earning money with closed gardens let come to a possible solution: <a href="https://matrix.org/">The Matrix-Protocol</a>. In short it’s about the same deal as mail (building on HTTP and WebRTC) but for chat-messaging (including IP-telephony and video-telephony) initiated by a non-profit foundation based in the UK. After XMPP or IRC it’s not the only approach to solve the issue, but so far the most successful.</p>



<p>Their reference implementation of the client is called <a href="https://matrix.org/docs/projects/client/element">Element (former Riot)</a> and a server called <a href="https://github.com/matrix-org/synapse/">Synapse</a>. So in theory there could be any chat client communicating over any chat server to any chat client. Sadly it’s not really used yet. Although the <a href="https://www.heise.de/security/meldung/Tchap-Frankreichs-nicht-so-exklusiver-Regierungschat-4403961.html">French Government</a> is supporting it with a client implementation named Tchap and <a href="https://www.golem.de/news/messenger-bundeswehr-will-komplett-auf-matrix-chat-wechseln-2005-148407.html">German Bundeswehr</a> plans to do alike.</p>



<h5>So what?</h5>



<p>Well no real cheering news and in case don’t want to be alone on Matrix you can write to @juerg:matrix.org.</p>



<p>And will it work? No, because there is already too much money in the game (and telcos try to <a href="https://stuker.com/2018/die-sms-nachfolge-heisst-rcs-rich-communication-services/">reanimate the SMS Eldorado</a> too, without success).</p>



<p>But it would be the right thing. And me? I don’t’ switch, I use them all!</p>



<p>PS: The post was inspired by the very nice article <a href="https://www.republik.ch/2021/02/24/kill-the-messenger">“Kill the Messenger”</a>.</p>

                        
            
        </div></div>]]>
            </description>
            <link>https://stuker.com/2021/whatsapp-and-most-alternatives-share-the-same-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273594</guid>
            <pubDate>Fri, 26 Feb 2021 11:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jq is a lightweight and flexible command-line JSON processor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273534">thread link</a>) | @Gedxx
<br/>
February 26, 2021 | https://stedolan.github.io/jq/ | <a href="https://web.archive.org/web/*/https://stedolan.github.io/jq/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="multiblurb">
        <p>jq is like <code>sed</code> for JSON data - you can use it to slice and filter
and map and transform structured data with the same ease that <code>sed</code>,
<code>awk</code>, <code>grep</code> and friends let you play with text.</p>
        <p>jq is written in portable C, and it has zero runtime
dependencies. You can download a single binary, <code>scp</code> it to a far away
machine of the same type, and expect it to work.</p>
        <p>jq can mangle the data format that you have into the one that you
want with very little effort, and the program to do so is often
shorter and simpler than you'd expect.</p>
      </div></div>]]>
            </description>
            <link>https://stedolan.github.io/jq/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273534</guid>
            <pubDate>Fri, 26 Feb 2021 11:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Dumb TVs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26273169">thread link</a>) | @rbanffy
<br/>
February 26, 2021 | https://frame.work/blog/in-defense-of-dumb-tvs | <a href="https://web.archive.org/web/*/https://frame.work/blog/in-defense-of-dumb-tvs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>Smart TV was once a term reserved for high end televisions with built-in streaming capabilities.&nbsp; The combination of massive reductions in panel costs, decreasing costs for embedded compute, and the ready availability of content platforms from Google, Roku, and others has made the term irrelevant.&nbsp; Almost every TV you can buy today has smarts built-in.&nbsp; There have been some fantastic outcomes of that, like breaking up the traditional channel bundle and increasing access to more personalized and niche content.</p>
<p>There have been some serious negatives too.&nbsp; Decreasing prices and decreasing margins on TVs combined with long replacement cycles have driven companies to take advantage of built-in smarts to enable a new revenue source: user data and advertising.&nbsp; As of Q2 2020, Vizio and HiSense are the <a href="https://www.rtings.com/tv/tests/ads-in-smart-tv" target="_blank" rel="noopener">only major brands</a> making TVs that ship without advertising enabled in their UIs.&nbsp; Sony, Samsung, LG, and others have ads enabled by default, most of which can’t be disabled.&nbsp; All of the above brands have built capability to aggregate data on what content is being viewed, and again, not all of them have the option to disable that.&nbsp; TVs smart enough to help you are also smart enough to harm you.&nbsp; Incredibly, Samsung even <a href="https://www.samsung.com/us/support/tip/TIP00083197/" target="_blank" rel="noopener">recommends</a> that you run virus and malware checking on your TV regularly.</p>
<p>An obvious way out of this as a consumer is to buy a TV without smarts built in (a “dumb TV”) and then add your own content source that is privacy focused like <a href="https://www.google.com/url?sa=j&amp;url=https%3A%2F%2Ffoundation.mozilla.org%2Fen%2Fprivacynotincluded%2Fproducts%2Fapple-tv-4k%2F&amp;uct=1603511873&amp;usg=vKN2pgP52PToUDpxmZ4Qm04kwj0.&amp;source=chat" target="_blank" rel="noopener">Apple TV</a> or that you have full control over like <a href="https://kodi.tv/" target="_blank" rel="noopener">Kodi</a>.&nbsp; This is something we personally looked for when we were buying a display for the conference room at Framework’s headquarters.&nbsp; Amazingly enough though, we found that none of the major consumer TV brands make basic “dumb” displays anymore.&nbsp; There are options in the commercial space like <a href="https://www.sharpnecdisplays.us/solutions/corporate/3" target="_blank" rel="noopener">NEC’s commercial displays</a>, but they cost substantially more than the consumer-focused alternatives.</p>
<p>We nearly gave in and bought a typical smart TV, and then we stumbled on <a href="https://www.sceptre.com/TV/4K-UHD-TV-category1category73.html?sort=tbt.parent_pdtype&amp;order=DESC" target="_blank" rel="noopener">Sceptre’s TV lineup</a>.&nbsp; You’ll notice that they have a range of extremely similar looking sets that have minor specification and weight differences.&nbsp; Our best guess is that they source LCDs from panel manufacturers that are either excess stock or fail the quality specifications set by other brands and build extremely minimal TVs around them.&nbsp; We haven’t noticed any quality issues on our Sceptre set, but for our use case of showing slides and spreadsheets, it wouldn’t have mattered anyway.&nbsp; The product was perfect for us: a dumb TV that as an added bonus reduces e-waste by using panels that would otherwise be scrapped.</p>
<p>It’s an interesting business model, and one that is consumer friendly, environmentally considerate, and economically sound.&nbsp; That is a powerful combination that we need to see across all of consumer electronics.</p>

</div>
</div></div>]]>
            </description>
            <link>https://frame.work/blog/in-defense-of-dumb-tvs</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273169</guid>
            <pubDate>Fri, 26 Feb 2021 10:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predictions in Racing Sports]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273113">thread link</a>) | @JoySch
<br/>
February 26, 2021 | https://blog.link-value.fr/from-duels-to-sport-racing-b7a102cb07a9 | <a href="https://web.archive.org/web/*/https://blog.link-value.fr/from-duels-to-sport-racing-b7a102cb07a9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Datascience prediction" src="https://miro.medium.com/max/6000/1*gI8W8UXz7EigSTqCvjg7mA.jpeg" width="3000" height="3009" srcset="https://miro.medium.com/max/552/1*gI8W8UXz7EigSTqCvjg7mA.jpeg 276w, https://miro.medium.com/max/1000/1*gI8W8UXz7EigSTqCvjg7mA.jpeg 500w" sizes="500px" data-old-src="https://miro.medium.com/max/60/1*gI8W8UXz7EigSTqCvjg7mA.jpeg?q=20"></p></div></div></div><figcaption>Racing — Datascience — Photo by <a href="https://unsplash.com/@marvin_ronsdorf?utm_source=medium&amp;utm_medium=referral" rel="noopener">Marvin Ronsdorf</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><div><div><div><div><p><a href="https://linkvalue.medium.com/?source=post_page-----b7a102cb07a9--------------------------------" rel="noopener"><img alt="Linkvalue" src="https://miro.medium.com/fit/c/96/96/1*tJdH0M07SBZGDq_CJRLjYQ.png" width="48" height="48"></a></p></div></div></div></div><p id="84b6"><em>Or how small and seemingly limited predictions ends up depicting the whole result</em></p><p id="4755"><strong>In March of this year the </strong><a href="https://datawok.fr/" rel="noopener"><strong><em>Datawok</em></strong></a><strong> team started to work on a new project : an exciting one with tons of data and on a subject that is rarely tackled in Data Science : sport racing! </strong>The goal is to develop a tool that helps bettors make the right choices by identifying the best runners and the outsiders in a race. How ? By predicting for each runner his probability to be at any given rank. To achieve this, we have at our disposal data on the runners (age, various statistics, prizes won…) and on the event — the particular race — itself (time of the day, temperature, nature of the track…). <br>In this article, I will show you how the Datawok team managed to achieve expert-level scores on this problem.</p><p id="1ffc">The initial objective can be expressed as simply as : <em>given data on the runners participating a race </em>(also called event in this article) <em>and data on the race itself, are we able to predict for each runner his probability to be at each ranks at the end of the race</em>?</p><p id="0f6d">More formally, let be :</p><ul><li id="b419"><em>N </em>the number of initial runners in a particular race (this value is dependent on the race)</li><li id="c73e"><em>K </em>the number of features used to describe each runner (this value is always the same)</li><li id="0586"><em>G</em> the number of features used to describe the event (this value is always the same)</li></ul><p id="5f85">The following table for example shows the results of two different events. <br>For each runner we have <em>K=2</em> features (Age &amp; Prizes won) and G=1 (Track Length).</p><figure><div><div><p><img alt="Datascience prediction" src="https://miro.medium.com/max/1340/1*__guR8q5XYFV32aqSyVVDw.png" width="670" height="313" srcset="https://miro.medium.com/max/552/1*__guR8q5XYFV32aqSyVVDw.png 276w, https://miro.medium.com/max/1104/1*__guR8q5XYFV32aqSyVVDw.png 552w, https://miro.medium.com/max/1280/1*__guR8q5XYFV32aqSyVVDw.png 640w, https://miro.medium.com/max/1340/1*__guR8q5XYFV32aqSyVVDw.png 670w" sizes="670px" data-old-src="https://miro.medium.com/max/60/1*__guR8q5XYFV32aqSyVVDw.png?q=20"></p></div></div></figure><p id="b9dc">Given those parameters, the following solutions could be implemented:</p><ul><li id="2c25">predicting given all the features of all the runners in a race and the features of the race a matrix of shape <em>N,N</em> where the value <em>i</em>,<em>j</em> is the probability that the runner <em>i</em> finishes the race with the rank <em>j</em></li><li id="d1a8">or predicting for a given runner/rank couple a single probability</li></ul><p id="bcad">In both cases, the question is: what is considered a sample? A race? A runner reaching a rank?</p><p id="6dd6">Both of these solutions comes with their inherent limitations:</p><ul><li id="9e0f">In the first case, both input and output have different shapes or sizes depending on <em>N </em>(the number of runners) which varies a lot from a race to the other. This means that a padding of some sort must be applied to the input and output data. Another issue with this representation is that the input is dependent to the order in which you arrange the features of the various runners. This also means that you have to come up with a quite arbitrary order for the runners</li><li id="41b0">The second case seems at first a bit better: the size or shape of our samples doesn’t depend on the initial number of runners in the race. Nonetheless, it gives a prediction for a couple runner/rank without any information on the competitors of the said runner. A solution could be to add a fixed-sized array of features representing the other competitors. This would ultimately mean working with aggregates (averages, max, min, etc..) and it will inevitably hinder the quality of the final prediction for a given couple runner/rank. Assessing the quality of a set of runners from fixed-size aggregates didn’t seemed to be a convenient solution in our precise case</li></ul><p id="06b1">All this being said, we now need a solution that satisfies the following constraints:</p><ul><li id="f3df">Both the input samples and the output predictions must have a constant dimension.</li><li id="7fe8">The final prediction for a given couple runner / rank must be produced knowing the data on the runner’s competitors and preferably without requiring any prior aggregation.</li></ul><p id="e102">Albeit the previously mentioned issues and limitations could still provide decent results, we took this as an opportunity to experiment a new paradigm and came up with the following solution: Each race is now considered as <em>N*(N-1)</em> duels between all possible couples of competitors (distinguishing the duel A vs B from the duel B vs A). A duel, i.e. the relative ranking between two competitors in race, is now our sample.</p><p id="994a">Each sample is now of known and constant size: <em>K</em> features to describe the first runner, <em>K</em> more to describe the second and <em>G</em> features to describe the whole event. Also, the output is the probability that the first runner loses against the second.</p><p id="7c86">Learning from those features the order of a specific runner couples (our target) allows us to estimate a matrix of shape <em>N,N </em>where the value <em>i,j</em> is the probability of the runner <em>i</em> finishing the race <em>after</em> the runner <em>j</em>. Unlike the last matrix we mentioned, we are not here estimating probabilities on runners/ranks but instead the probability for the runner <em>i</em> to finish the race <em>after </em>the runner <em>j.</em></p><p id="d7ca">In this new paradigm, we both:</p><ul><li id="6807">manipulate samples of constant size (independently of the initial value of <em>N</em>) and outputs of constant size</li><li id="8884">give our prediction for each runner to beat every other competitor given both of their features</li></ul><p id="576c">Bear in mind that at this point, a sample is a tuple <em>A,B,G,Y</em> with:</p><ul><li id="341e">A being the features of one runner in a race</li><li id="9637">B being the features of one competitor in the race</li><li id="9207">G being the features that describes the race itself</li><li id="8f7a">Y being either 0 or 1 if respectively A looses or B loses this duel (it is equivalent to predicting if the final rank of A is greater than the final rank of B)</li></ul><p id="d8fc">The first race of the example table (where Event Id is 0) can in this context be represented as 12 duels (4 players and each time 3 competitors) and each duel becomes a sample. Note that this also artificially increases the number of samples : with <em>R</em> races and with an average of 10 runners per race, we end up having around <em>R*100</em> samples.</p><p id="9b29">This “duel” matrix, as we could call it, would looks like the following:</p><figure><div><div><p><img alt="Datascience prediction" src="https://miro.medium.com/max/1302/1*4zoKecqRd6aKEPLjIqh-Kg.png" width="651" height="655" srcset="https://miro.medium.com/max/552/1*4zoKecqRd6aKEPLjIqh-Kg.png 276w, https://miro.medium.com/max/1104/1*4zoKecqRd6aKEPLjIqh-Kg.png 552w, https://miro.medium.com/max/1280/1*4zoKecqRd6aKEPLjIqh-Kg.png 640w, https://miro.medium.com/max/1302/1*4zoKecqRd6aKEPLjIqh-Kg.png 651w" sizes="651px" data-old-src="https://miro.medium.com/max/60/1*4zoKecqRd6aKEPLjIqh-Kg.png?q=20"></p></div></div></figure><p id="70ce">Again, each cell of the matrix (green for high values and clear yellow for lower ones), is a probability predicted by our model ; the probability that the runner <em>i</em> in line would lose against the runner <em>j </em>in column. The model is not specifically trained to predict that <em>f(A,B) = 1 -f(B,A)</em>, <em>A </em>and <em>B </em>being runners and <em>f(A,B)</em> being the probability that the runner <em>A</em> would lose against the runner <em>B. </em>We made the decision to use the value <em>(f(A,B) + 1-f(B,A))/2</em> (the mean of the two predictions) as the predicted result of the duel between <em>A</em> and <em>B</em>.</p><p id="86bc">Let’s sum up:</p><ol><li id="2e0f">Each race consists of <em>N</em> records, one per runner</li><li id="0bae">Each record contains data about both the race and the runner. Each record also provide the final rank of the runner on this particular race</li><li id="565c">The records are regrouped by race and each race of <em>N</em> runners is transformed into <em>N*(N-1) </em>duels</li></ol><p id="65f5">To illustrate this process, let’s see how the first race in our example would be represented as duels:</p><figure><div><div><p><img alt="Datascience prediction" src="https://miro.medium.com/max/1342/1*A84wEJ6Bw636VNzz0jt0bg.png" width="671" height="391" srcset="https://miro.medium.com/max/552/1*A84wEJ6Bw636VNzz0jt0bg.png 276w, https://miro.medium.com/max/1104/1*A84wEJ6Bw636VNzz0jt0bg.png 552w, https://miro.medium.com/max/1280/1*A84wEJ6Bw636VNzz0jt0bg.png 640w, https://miro.medium.com/max/1342/1*A84wEJ6Bw636VNzz0jt0bg.png 671w" sizes="671px" data-old-src="https://miro.medium.com/max/60/1*A84wEJ6Bw636VNzz0jt0bg.png?q=20"></p></div></div></figure><p id="2cc6">This is how our dataset was built. From 11K races dated between 2017 and July 2018 we’ve produced over 1 million samples (the duels) to train. From 5K races dated between June 2018 and June, another 0.5 million samples was produced to test the model.</p><p id="1429">We had to do a lot of feature engineering and data cleansing. A lot of our runners features where computed on their pre-race history (number of time they got ranked 5 or better in the past 12 months, number of disqualifications in the past 6 months, etc..). However, this article being mainly about how we represented our data, we will not go through each and every step of the machine learning part. We went through the typical steps of a Data Science project: business understanding, feature engineering/cleansing, modeling, evaluation until reaching satisfying results.</p><p id="b09f">We’ve used an XGBoost classifier on our data and the metric used was the classic <em>accuracy.</em> Note that a random model that would predict 0 or 1 randomly on each pair would have an accuracy of 0.5 since for each sample <em>A</em> against <em>B</em> with a target of value 1 you have exactly one sample <em>B</em> against <em>A</em> with a target of value 0.</p><p id="684b">Speaking of metrics… Reaching a given score when predicting the correct order of a pair of competitors is merely a part of the solution. We still need to find a way to go from those small estimations to the final runner/rank matrix: given a model that predicts for a pair of runners their relative ranking (either A finishing after B or the opposite), we can predict all the duels in a race for a specific runner. This will give us his probabilities to be beaten by all the other competitors. We can have for example the following array of probabilities, the <em>i-th</em> value being the estimated probability of A losing against the <em>i-th</em> competitor in a race. Taking back our previous example, lets see what are the estimations made by our model for John who came first in the race:</p><figure><div><div><p><img alt="Datascience prediction" src="https://miro.medium.com/max/1320/1*C3SPcnf_XpO0PAms2KwZew.png" width="660" height="82" srcset="https://miro.medium.com/max/552/1*C3SPcnf_XpO0PAms2KwZew.png 276w, https://miro.medium.com/max/1104/1*C3SPcnf_XpO0PAms2KwZew.png 552w, https://miro.medium.com/max/1280/1*C3SPcnf_XpO0PAms2KwZew.png 640w, https://miro.medium.com/max/1320/1*C3SPcnf_XpO0PAms2KwZew.png 660w" sizes="660px" data-old-src="https://miro.medium.com/max/60/1*C3SPcnf_XpO0PAms2KwZew.png?q=20"></p></div></div></figure><p id="4cfd">We can now compute the probability for John to reach each rank by simply simulating <em>M</em> times all his duels. For example, by taking this previous table, a simulation would consist in 3 random numbers between 0 and 1 (one per competitor). If the value is <em>above </em>the predicted probability, the duel is considered a win. Reaching the first rank means for example loosing no duel. Reaching the <em>n-th</em> rank means losing exactly <em>n-1 </em>duels.</p><p id="27cb">Keeping this last example, we can do a simulation by generating 3 random numbers and by counting the duels lost:</p><figure><div><div><p><img alt="Datascience prediction" src="https://miro.medium.com/max/1320/1*Q8TAl795Hfu44eXbw2IpNw.png" width="660" height="220" srcset="https://miro.medium.com/max/552/1*Q8TAl795Hfu44eXbw2IpNw.png 276w, https://miro.medium.com/max/1104/1*Q8TAl795Hfu44eXbw2IpNw.png 552w, https://miro.medium.com/max/1280/1*Q8TAl795Hfu44eXbw2IpNw.png 640w, https://miro.medium.com/max/1320/1*Q8TAl795Hfu44eXbw2IpNw.png 660w" sizes="660px" data-old-src="https://miro.medium.com/max/60/1*Q8TAl795Hfu44eXbw2IpNw.png?q=20"></p></div></div></figure><p id="7687">In this case, 3 simulations were made. In 67% of them, John reached the first rank and in 33% of them, we estimated that he would be on the second rank. In our case, <em>M</em> — the number of simulation per runner — was empirically set to 4000.</p><p id="3c00">Applying this method to each runner gives us the the lines of our matrix: each line represents a runner and each column a rank. Now, one can easily convince himself that the probability in lines sums to 1 but not the columns.</p><p id="dedb">On the business side, this matrix is used to produce rankings by choosing a runner in each column (ie. the ranks) according to the aforementioned probability (the higher is the probability of the runner being at a rank, the likelier he is to be picked for this rank). Hence the column-wise normalization.</p><p id="8199">The following matrix results of the application of the simulation method we exposed earlier to the first matrix we saw (the “duel” matrix). Therefore, in this matrix, a cell <em>i,j</em> is the probability for a runner <em>i</em> to finish the race at a rank <em>j:</em></p><figure><div><div><p><img alt="Datascience prediction" src="https://miro.medium.com/max/1274/1*ZT9dlUGryG2bpFxdThFvbQ.png" width="637" height="729" srcset="https://miro.medium.com/max/552/1*ZT9dlUGryG2bpFxdThFvbQ.png 276w, https://miro.medium.com/max/1104/1*ZT9dlUGryG2bpFxdThFvbQ.png 552w, https://miro.medium.com/max/1274/1*ZT9dlUGryG2bpFxdThFvbQ.png 637w" sizes="637px" data-old-src="https://miro.medium.com/max/52/1*ZT9dlUGryG2bpFxdThFvbQ.png?q=20"></p></div></div></figure><p id="f107">The …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.link-value.fr/from-duels-to-sport-racing-b7a102cb07a9">https://blog.link-value.fr/from-duels-to-sport-racing-b7a102cb07a9</a></em></p>]]>
            </description>
            <link>https://blog.link-value.fr/from-duels-to-sport-racing-b7a102cb07a9</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273113</guid>
            <pubDate>Fri, 26 Feb 2021 09:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GraphQL standard and nested mutations at same time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273084">thread link</a>) | @leoloso
<br/>
February 26, 2021 | https://graphql-api.com/blog/released-graphql-api-v07-with-mutations-and-nested-mutations/ | <a href="https://web.archive.org/web/*/https://graphql-api.com/blog/released-graphql-api-v07-with-mutations-and-nested-mutations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Version 0.7 of the <a href="https://github.com/leoloso/PoP/tree/master/layers/GraphQLAPIForWP/plugins/graphql-api-for-wp">GraphQL API for WordPress</a>, supporting mutations, and nested mutations, has been released! 🎉</p><p><img src="https://graphql-api.com/images/finally-got-mutations.jpg" alt="Mutations are awesome!" loading="lazy" width="500" height="500"></p><p>Here is a tour showing the new additions.</p><h2 id="heading-1.-mutations!">1. Mutations! 🚀<a href="#heading-1.-mutations!"><span> permalink</span></a></h2><p><a href="https://graphql.org/learn/queries/#mutations">GraphQL mutations</a> enable to modify data (i.e. perform side-effect) through the query.</p><p>Mutations was the big item still missing from the GraphQL API. Now that it's been added, I can claim that this GraphQL server is pretty much feature-complete (only subscriptions are missing, and I'm already <a href="https://github.com/GraphQLAPI/graphql-api-for-wp/issues/61">thinking on how to add them</a>).</p><figure><img src="https://graphql-api.com/images/graphql-schema-mutation-root.jpg" alt="Mutation root in the interactive schema" loading="lazy" width="1444" height="853"><figcaption>Mutation root in the interactive schema</figcaption></figure><p>Let's check an example on adding a comment. But first, we need to execute another mutation to log you in, so you can add comments. Press the "Run" button on the GraphiQL client below, to execute mutation field <code>loginUser</code> with a pre-created testing user:</p><p>[<a href="https://newapi.getpop.org/graphiql/?query=mutation%20LogUserIn%20%7B%0A%20%20loginUser(%0A%20%20%20%20usernameOrEmail%3A%22test%22%2C%0A%20%20%20%20password%3A%22pass%22%0A%20%20)%20%7B%0A%20%20%20%20id%0A%20%20%20%20name%0A%20%20%7D%0A%7D&amp;operationName=LogUserIn" target="_blank">🔗 Open GraphiQL client in new window</a>]</p><p>Now, let's add some comments. Press the Run button below, to add a comment to some post by executing mutation field <code>addCommentToCustomPost</code> (you can also edit the comment text):</p><p>[<a href="https://newapi.getpop.org/graphiql/?query=mutation%20AddCommentToPost%20%7B%0A%20%20addCommentToCustomPost(%0A%20%20%20%20customPostID%3A%201459%2C%0A%20%20%20%20comment%3A%20%22Adding%20a%20comment:%20bla%20bla%20bla%22%0A%20%20)%20%7B%0A%20%20%20%20id%0A%20%20%20%20content%0A%20%20%20%20date%0A%20%20%7D%0A%7D&amp;operationName=AddCommentToPost" target="_blank">🔗 Open GraphiQL client in new window</a>]</p><hr><p>In this first release, the plugin ships with the following mutations:</p><p>✅ <code>createPost</code><br>✅ <code>updatePost</code><br>✅ <code>setFeaturedImageforCustomPost</code><br>✅ <code>removeFeaturedImageforCustomPost</code><br>✅ <code>addCommentToCustomPost</code><br>✅ <code>replyComment</code><br>✅ <code>loginUser</code><br>✅ <code>logoutUser</code></p><h2 id="heading-2.-nested-mutations!">2. Nested Mutations! 🚀🚀<a href="#heading-2.-nested-mutations!"><span> permalink</span></a></h2><p>Nested mutations is the ability to perform mutations on a type other than the root type in GraphQL.</p><p>They have been <a href="https://github.com/graphql/graphql-spec/issues/252">requested for the GraphQL spec</a> but not yet approved (and may never will), hence GraphQL API adds support for them as an opt-in feature, via the <a href="https://github.com/leoloso/PoP/tree/master/layers/GraphQLAPIForWP/plugins/graphql-api-for-wp/docs/en/modules/nested-mutations.md">Nested Mutations</a> module.</p><p>Then, the plugin supports the 2 behaviors:</p><ol><li>The standard GraphQL behavior (i.e. adding mutation fields to the root type), by default</li><li>Nested mutations, as an opt-in</li></ol><p>For instance, the query from above can also be executed with the following query, in which we first retrieve the post via <code>Root.post</code>, and only then add a comment to it via <code>Post.addComment</code>:</p><p>[<a href="https://newapi.getpop.org/graphiql/?mutation_scheme=nested&amp;query=mutation%20AddComment%20%7B%0A%20%20post(id%3A%201459)%20%7B%0A%20%20addComment(%0A%20%20%20%20comment%3A%20%22Notice%20how%20field%20%60addCommentToCustomPost%60%20under%20the%20%60Root%60%20type%20is%20renamed%20as%20%60addComment%60%20under%20the%20%60Post%60%20type%3F%20The%20schema%20got%20neater!%22%0A%20%20)%20%7B%0A%20%20%20%20%20%20id%0A%20%20%20%20%20%20content%0A%20%20%20%20%20%20date%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D&amp;operationName=AddComment" target="_blank">🔗 Open GraphiQL client in new window</a>]</p><p>Mutations can also modify data on the result from another mutation. In the query below, we first obtain the post through <code>Root.post</code>, then execute mutation <code>Post.addComment</code> on it and obtain the created comment object, and finally execute mutation <code>Comment.reply</code> on it:</p><p>[<a href="https://newapi.getpop.org/graphiql/?mutation_scheme=nested&amp;query=mutation%20AddCommentAndResponse%20%7B%0A%20%20post(id%3A1459)%20%7B%0A%20%20%20%20id%0A%20%20%20%20title%0A%20%20%20%20addComment(comment%3A%22Isn%27t%20this%20awesome%3F%22)%20%7B%0A%20%20%20%20%20%20id%0A%20%20%20%20%20%20date%0A%20%20%20%20%20%20content%0A%20%20%20%20%20%20reply(comment%3A%22I%20think%20so!%22)%20%7B%0A%20%20%20%20%20%20%20%20id%0A%20%20%20%20%20%20%20%20date%0A%20%20%20%20%20%20%20%20content%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D&amp;operationName=AddCommentAndResponse" target="_blank">🔗 Open GraphiQL client in new window</a>]</p><p>This is certainly useful! 😍 (The alternative method to produce this same behavior, in a single query, is via the <code>@export</code> directive... I'll compare both of them in an upcoming blog post).</p><hr><p>In this first release, the plugin ships with the following mutations:</p><p>✅ <code>CustomPost.update</code><br>✅ <code>CustomPost.setFeaturedImage</code><br>✅ <code>CustomPost.removeFeaturedImage</code><br>✅ <code>CustomPost.addComment</code><br>✅ <code>Comment.reply</code></p><h3 id="heading-standard-or-nested-or-both">Standard or nested? Or both?<a href="#heading-standard-or-nested-or-both"><span> permalink</span></a></h3><p>You may have a GraphQL API that is used by your own application, and is also publicly available for your clients. You may want to enable nested mutations but only for your own application, not for your clients because this is a non-standard feature.</p><p>Good news: you can.</p><p>I've added a "Mutation Scheme" section in the Schema Configuration, which is used to customize the schema for <a href="https://github.com/leoloso/PoP/tree/master/layers/GraphQLAPIForWP/plugins/graphql-api-for-wp/docs/en/modules/custom-endpoints.md">Custom Endpoints</a> and <a href="https://github.com/leoloso/PoP/tree/master/layers/GraphQLAPIForWP/plugins/graphql-api-for-wp/docs/en/modules/persisted-queries.md">Persisted Queries</a>:</p><p><img src="https://graphql-api.com/images/schema-configuration-mutation-scheme.jpg" alt="Mutation scheme in the Schema configuration" loading="lazy" width="639" height="616"></p><p>Hence, you can disable the nested mutations everywhere, but enable them just for a specific custom endpoint that only your application will use. 💪</p><h3 id="heading-removing-redundant-fields-from-the-root-type">Removing redundant fields from the root type<a href="#heading-removing-redundant-fields-from-the-root-type"><span> permalink</span></a></h3><p>With nested mutations, mutation fields may be added two times to the schema:</p><ul><li>once under the root type</li><li>once under the specific type</li></ul><p>For instance, these fields can be considered a "duplicate" of each other:</p><ul><li><code>Root.updatePost</code></li><li><code>Post.update</code></li></ul><p>The GraphQL API enables to keep both of them, or remove the ones from the root type, which are redundant.</p><p>Check-out the following 3 schemas:</p><ol><li><a href="https://newapi.getpop.org/graphql-interactive/">Standard behavior</a>:<br>it uses types <code>QueryRoot</code> to handle queries and <code>MutationRoot</code> to handle queries</li><li><a href="https://newapi.getpop.org/graphql-interactive/?mutation_scheme=nested">Nested mutations keeping mutation fields duplicate</a>:<br>a single <code>Root</code> type handles queries and mutations, and redundant mutation fields in this type are kept</li><li><a href="https://newapi.getpop.org/graphql-interactive/?mutation_scheme=lean_nested">Nested mutations removing redundant mutation fields from the root type</a>:<br>same as above, but removing all redundant mutation fields from the <code>Root</code> type</li></ol><p>✱ Btw1, these 3 schemas all use the same endpoint, but changing a URL param <code>?mutation_scheme</code> to values <code>standard</code>, <code>nested</code> and <code>lean_nested</code>. That's possible because the GraphQL server follows the <a href="https://graphql-by-pop.com/docs/architecture/code-first.html">code-first approach</a>. 🤟</p><p>✱ Btw2, these options can be selected on the "Mutation Scheme" section in the Schema configuration (shown above), hence you can also decide what behavior to apply for individual custom endpoints and persisted queries. 👏</p><hr><p>Now it's time to start preparing for v0.8!</p><p><span>🙏</span></p></div></div>]]>
            </description>
            <link>https://graphql-api.com/blog/released-graphql-api-v07-with-mutations-and-nested-mutations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273084</guid>
            <pubDate>Fri, 26 Feb 2021 09:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invoke_is_Too_High_Level]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273030">thread link</a>) | @niDistinct
<br/>
February 26, 2021 | https://xlogicx.net/Invoke_is_Too_High_Level.html | <a href="https://web.archive.org/web/*/https://xlogicx.net/Invoke_is_Too_High_Level.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p>(or another perspective on the Invoke vs Call argument)</p>
<p>The video version (for the illiterate) can be found at: https://youtu.be/QyjXBv3sqRY</p>
<p>I'm in the process of re-certifying for the GREM certification (GIAC Reverse Engineering Malware). Although I'm pretty good with assembly language in a handful of architectures (Motorolla, x86, propeller, and ARM), my skills are shit with Windows and its APIs. In the context of GREM and static code analysis goes, I still have a ways to go; a 'not seeing the forest for the trees' issue. I will still likely pass the certification like last time, because I understand most of the concepts in their compartmentalized pieces. My problem is some of the big picture stuff (always has been). I joke about everything being too high level, and honestly, most of the time it really is a joke or an extreme over exaggeration. But for me, I sometimes do have a harder time comprehending an abstraction when it abstracts away how things actually work. For most people, it doesn't matter how the technology works, so long as it does. However, as a hacker, I have technology 'trust issues'; things don't always 'just work.'. And the abstraction likely wont give you any hints as to why the thing failed, the answers are revealed at a lower layer.</p>
<p>Blah blah blah, I digress. I wanted to set out to learn many of these Windows APIs in a bit more detail. Reverse engineering usually teaches how to read the code, but my (and probably your) comprehension magnifies when we actually write code. So in this case, I wanted to set out and write a few very simple assembly programs that put the correct arguments on the stack and call a Windows API, just how I see this happening when debugging some malware, just how it is supposed to work. As a point of reference I am using the FLARE VM setup from FireEye. It comes with fasm, so that's the assembler I will use (I don't really have religious preferences with an assembler).</p>
<p>For API's, the Windows way is a bit different than the Linux way. For Linux, generally, you put all of your arguments in registers and then do an Int 80 (interrupt to Linux). In windows, with 'sdtcall' functions, you push all of your arguments to the stack and Call the Windows API function by name (the corresponding addresses of these functions end up getting linked in). I'm not really opposed to this method, it allows for a large amount of arguments by default, as it's the stack, not a limited amount of registers.</p>
<p>As I didn't know the fasm ways of assembly, I looked to the Internet for some examples. I wanted to create a simple dialog box. I expected to see a simple assembly program with a .data section with the strings and then the .text (.code) section with some instructions pushing the arguments to the stack and then a call to the API function. For pretty much every google result I got, what I got back was a heavily abstracted version of how this is generally done, and the ironic bonus: NO ASSEMBLY INSTRUCTIONS!</p>
<p>Before I get to that, I will say that I eventually figured out the way to do this with real assembly language in the source file. And it was as straight forward as I would have expected it to be. For reference, here is a screenshot of the source program:</p>
<p><a href="https://xlogicx.net/images/callvsinvoke1.png"><img src="https://xlogicx.net/images/callvsinvoke1.png" width="436" height="273"></a></p>
<p>This is what it looks like in the x64dbg debugger:</p>
<p><a href="https://xlogicx.net/images/callvsinvoke2.png"><img src="https://xlogicx.net/images/callvsinvoke2.png" width="1046" height="426"></a></p>
<p>Note that the assembly looks awfully similar to the source. This is no mistake. This is exactly what I'm going for here. Remembering that my goal is to try and understand what is actually going on with these API functions, this is the most comprehensible way to go about this. You'll notice that all the arguments are on the stack and ready to go for when I'm about to call them. And it is extremely clear how they all got onto the stack (the 4 preceding push instructions).</p>
<p>Okay. Now let's talk about the 'no assembly required' way that is recommended to write this. Because the source code is easier to read. Because it's 'cleaner code.' Because assembly language is so 'hard' to write that you might as well write assembly programs that don't use assembly instructions (then just give up and fucking use python). Anyway, here's a screenshot of the 'clean' way to do this:</p>
<p><a href="https://xlogicx.net/images/callvsinvoke3.png"><img src="https://xlogicx.net/images/callvsinvoke3.png" width="837" height="114"></a></p>
<p>It is clearer to read. If there were no comments in my version, then the 'invoke' version would be much more obvious in its intentions. But now, here's a screenshot of how dirty and incomprehensible this is in the debugger:</p>
<p><a href="https://xlogicx.net/images/callvsinvoke4.png"><img src="https://xlogicx.net/images/callvsinvoke4.png" width="1049" height="426"></a></p>
<p>Before I start ranting and criticizing, I have to be fare and state that the examples I found on the Internet didn't use a .data section and inlined the strings in the invoke section (cleaner source code). This is the real cause of the mess of the disassembly. Had I used a .data section with this invoke command: 'invoke MessageBox,HWND_DESKTOP,message,title1,MB_OKCANCEL', it woulnd't be so bad. I digress. So note that even though the source code is 'clean,' what's actually being 'assembled' (compiled really) is nothing but. You see as we are about to make the call, all the right arguments are on the stack. I see two of the original pushes needed for two of our arguments (push 1 and push 0). We also need two more arguments; we need pointers to our strings for the title of the window and the message in the window. How on earth did these get into the stack, and what the fuck are these confusing instructions doing in our program. Do we really need to do ARPL, INSB, OUTSD, DAA, and IMUL instructions? Well no, that's not what is happening. What we are actually seeing is a disassembled representation of our strings. See our first call to 'syscalls.40201B', it's jumping past our first string. A call normally knows how to return to where we came from by pushing the address of the next instruction to the stack. In this case though, our program doesn't intend to return to this at all, it is using that pushed address as a side effect, as that address really is the first byte of our string, it serves as a pointer to it, and it is now on the stack conveniently as an argument. So that call jumps us to another call that does the same thing; it skips over the next string that follows it, getting a pointer to it on the stack, indirectly. So that second call instruction brings us all the way down to the 'push 0' instruction right before our API call to MessageBoxA. These abused CALL instructions are how we got the string arguments onto the stack.</p>
<p>The end result is the same. As somebody that has to read or write the assembly source, using invoke is likely a better way to write and collaborate. However, nothing about it is actual assembly language, it abstracts it away. It's not like this behavior is uncommon or indefensible. Compilers do this kind of thing all the time, even when they aren't optimized that much (and when they are optimized, wow). Joking aside, using invoke is probably the way to go if your writing something more serious, although, why not just use C? Writing "assembly" in shortcuts and macros with no actual assembly sounds a lot like a higher level language (like C). This is why I always found HLA (High Level Assembly) so objectionable. Though to be clear, I respect the Author of HLA and he has done other really amazing work.</p>
<p>A lot of arguments of which way is better than which (with many things) comes down to what your doing at the moment. In the use case from the paragraph above, invoke away. But to return to my use case, I'm trying to familiarize myself with some simple Windows API calls by playing with different arguments in assembly and calling them, and then watching them perform their actions in a debugger (as not all API's will do something visual; I might have to see the stack, registers, and memory getting manipulated). Using invoke for this strategy makes this process all the more confusing.</p>
<p>All this said, you might be able to see why I have a little ways to go when it comes to fully reverse engineering Windows binaries. Not to be confused with targeted reversing. I'm somewhat adequate with looking at particular APIs and pulling out IOCs from the artifacts they leave behind, and all the other 'cheater' dynamic forms of analysis. But if I ever want to see a bigger and fuller picture, I'm going to want to start writing the assembly that I'm reading and put bigger pieces of the puzzle together. At least, that's the plan.</p></div>]]>
            </description>
            <link>https://xlogicx.net/Invoke_is_Too_High_Level.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273030</guid>
            <pubDate>Fri, 26 Feb 2021 09:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What do I need to add on top of Kubernetes?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26273013">thread link</a>) | @anticristi
<br/>
February 26, 2021 | https://elastisys.com/what-do-i-need-to-add-on-top-of-kubernetes/ | <a href="https://web.archive.org/web/*/https://elastisys.com/what-do-i-need-to-add-on-top-of-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div data-elementor-type="wp-post" data-elementor-id="10763" data-elementor-settings="[]"><div><div><section data-id="d9f7755" data-element_type="section"><div><div><div data-id="0c2b078" data-element_type="column"><div><div><div data-id="53500f0" data-element_type="widget" data-widget_type="text-editor.default"><div><p><h5>So you recently decided to increase development speed by adopting Kubernetes. Suddenly you face a lot of questions: Is Kubernetes sufficient by itself? What are all these projects around Kubernetes? What is vanilla Kubernetes? Do I need a Kubernetes distribution? Which one?</h5><h5>This post will highlight all the features that a DevOps team typically needs to add on top of a vanilla Kubernetes cluster to obtain a secure, production-ready Kubernetes cluster. Adding these features takes time and effort, hence, starting from a production-ready, battle-tested Kubernetes distribution can accelerate an organization’s adoption of Kubernetes.</h5></p></div></div><div data-id="fb2f93a" data-element_type="widget" data-widget_type="heading.default"><p><h2>What is vanilla Kubernetes?</h2></p></div><div data-id="f0e6f8e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>“Vanilla Kubernetes” is a term used to describe a Kubernetes setup which is as small as it can get. This is the kind of Kubernetes cluster one gets from managed Kubernetes offers, such as AWS EKS, Azure AKS or Google GKE, and Kubernetes installation tools, such as kops or kubespray.</span></p><p><span>Vanilla is as plain as it gets, and comes with no bells and whistles included. So it’s like buying the most basic car in the lot: It has steering wheel and seat belts, but no additional safety features. So it can be driven immediately, but it won’t help keep you safe with lane departure warnings or auto-breaking.</span></p><p><span>How minimal vanilla Kubernetes is, is subject to some debate. At the very least, Kubernetes needs the following components:</span></p><ul><li aria-level="1"><span>On the control-plane nodes: etcd, apiserver, scheduler and controller-manager.</span></li><li aria-level="1"><span>On the worker nodes: some container runtime and kubelet.</span></li></ul><p><span>(Without these, can anyone really call the system “a Kubernetes cluster”?)</span></p></div></div></div><div data-id="cd8cf58" data-element_type="widget" data-widget_type="heading.default"><p><h2>How vanilla is a vanilla Kubernetes really?</h2></p></div><div data-id="e486cdb" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>So far, you have a car without fuel. The above Kubernetes setup cannot really run anything yet: Kubernetes does not know how to make Pods, i.e., a collection of one-or-more containers, talk to each other. To this end, even the “most vanilla” Kubernetes comes with a Container Network Interface (CNI) addon, such as </span><a href="https://www.projectcalico.org/"><span>Calico</span></a><span>. Now Kubernetes needs to know how to bring traffic to your Pods and how to store their data, a function fulfilled by the so-called cloud controller.</span></p><p><span>Knowing what is happening inside your Kubernetes cluster — also called “observability” — is essential to avoid unplanned downtime and customer disappointment. Therefore, most managed Kubernetes offers also include a few more integrations with the underlying cloud provider. For example, Google GKE sends logs, metrics and traces to Google StackDriver.</span></p><p><span>Great! Now you can run your application, you can direct traffic within the cluster and you can get traffic from end users into the cluster and to your application. Furthermore, logs and metrics are collected. What would I need more than vanilla Kubernetes?</span></p></div></div></div><div data-id="78a210a" data-element_type="widget" data-widget_type="heading.default"><p><h2>Add Secure Ingress Controller</h2></p></div><div data-id="bb5af44" data-element_type="widget" data-widget_type="text-editor.default"><div><p><span>Data privacy regulations — such as HIPAA and GDPR — require you to encrypt public Internet traffic. Even without regulatory pressure, it is a good idea to encrypt public Internet traffic, unless you are a fan of bad PR. </span><a href="https://en.wikipedia.org/wiki/TLS_termination_proxy"><span>TLS termination</span></a><span> — i.e., the “wall” that separates “encrypted traffic outside” from “unencrypted traffic inside” — could be performed by your cloud provider or your application. However, if you want to stay cloud agnostic and keep your application code focused on business logic, you can do TLS termination in the Kubernetes cluster. Projects, such as </span><a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/"><span>Ingress controller</span></a><span> and </span><a href="https://cert-manager.io/docs/"><span>cert-manager</span></a><span>, will not only provision TLS certificates for you, but will also rotate them before expiry. Rotating certificates is a best practice, but also a chore that sometimes gets forgotten if it is a manual process.&nbsp; Users would get a scary “</span><a href="https://www.ssl.com/guide/troubleshooting-ssl-tls-browser-errors-and-warnings/"><span>Warning: Potential Security Risk Ahead</span></a><span>” message and flock to your competitors.</span></p></div></div><div data-id="c682772" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>Kubernetes is </span><a href="https://searchitoperations.techtarget.com/news/252487963/Kubernetes-security-defaults-prompt-upstream-dilemma"><span>not secure by default, nor by itself</span></a><span>. You should further improve your security posture, to minimize the risk of breaches. Why? If you handle personal data, GDPR requires you to </span><a href="https://edpb.europa.eu/our-work-tools/our-documents/guideline/personal-data-breach-notifications_en"><span>notify the data protection authority and/or your users of any breach</span></a><span>. Definitely not what your board wants to read in the newspaper.</span></p><p><span>Therefore, you should regularly scan for vulnerable container images with projects such as </span><a href="https://github.com/aquasecurity/trivy"><span>Trivy</span></a><span>. You should also consider adding intrusion detection via </span><a href="https://falco.org/"><span>Falco</span></a><span>. And don’t forget about disaster recovery! Projects, such as </span><a href="https://velero.io/"><span>Velero</span></a><span>, can backup your Kubernetes cluster and the application data hosted within. As they say: “Hope for the best, prepare for the worst.”</span></p></div></div></div><div data-id="5aaea15" data-element_type="widget" data-widget_type="shortcode.default"><div><div><div data-elementor-type="wp-post" data-elementor-id="8990" data-elementor-settings="[]"><div><div><section data-id="31e2d16" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="247a263" data-element_type="column"><div><div><div data-id="0b295df" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Want to keep up with the latest in cloud and Kubernetes?</p><p>Let us deliver it straight to your inbox!</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></div><div data-id="7781368" data-element_type="widget" data-widget_type="heading.default"><p><h2>Add Multi-Cloud Observability and Authentication</h2></p></div><div data-id="bbfbfa1" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>Observability is an <a href="https://elastisys.com/what-was-observability-again/">essential feature of a platform</a>, to ensure that “2am events” are converted into daily checks. Many cloud providers come with great observability stacks included, such as AWS’s CloudWatch, GCP’s StackDriver, and Azure’s Monitor.</span></p><p><span>However, a multi-cloud strategy is seen as essential to cope with various risks </span><a href="https://elastisys.com/solving-privacy-shield-and-gdpr-with-kubernetes/"><span>associated with data privacy</span></a><span>, but also with contractual requirements, such as “data should stay within my jurisdiction”. Needless to say, integration with the underlying cloud provider provides a great productivity boost. However, it does not cater well to a multi-cloud strategy.</span></p><p><span>Fortunately, there are cloud agnostic alternatives:</span></p><ul><li aria-level="1"><a href="https://github.com/dexidp/dex"><span>Dex</span></a><span>, for cloud-agnostic authentication against the Kubernetes cluster (and yes, it can work with your current identity provider, such as Active Directory, LDAP, or Google accounts);</span></li><li aria-level="1"><a href="https://prometheus.io/"><span>Prometheus</span></a><span> and </span><a href="https://grafana.com/"><span>Grafana</span></a><span>, for metrics collection, analysis, visualization and alerting;</span></li><li aria-level="1"><a href="https://opendistro.github.io/for-elasticsearch/"><span>Elasticsearch</span></a><span> and </span><a href="https://www.elastic.co/kibana"><span>Kibana</span></a><span>, for log collection, analysis, visualization and alerting.</span></li></ul><p><span>With all these addons, your Kubernetes cluster should be ready to host your application, in a manner that is secure and observable.</span></p></div></div></div><div data-id="875e2e9" data-element_type="widget" data-widget_type="heading.default"><p><h2>Kubernetes Distributions: a One-Stop Shop</h2></p></div><div data-id="4496ccf" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>While adding all of the above components on top of a vanilla Kubernetes cluster is not rocket science, it does require careful configuration to make sure they work as a whole. Coming back to the car analogy, you can certainly buy an aftermarket lane departure warning system, but finding the right one and fitting it reliably still takes time. Wouldn’t it be great if it came pre-installed? And if you ever need support, wouldn’t you like it all to come from a single vendor that takes full responsibility for making it all work correctly?</span></p><p><span>Kubernetes distributions fill this gap: They enhance a vanilla Kubernetes cluster with carefully chosen and configured components to allow you and your team to focus on what is most important to your customers: Rapidly adding features to your application, without worrying about the hosting platform.</span></p></div></div></div><div data-id="2e281f0" data-element_type="widget" data-widget_type="text-editor.default"><div><div><h5>Are you looking for an open-source Kubernetes distribution with focus on observability and security? Check out&nbsp;<a href="https://compliantkubernetes.io/">Compliant Kubernetes</a>! Consider giving us a star at GitHub or contributing to the project.</h5></div></div></div></div></div></div></div></div></section><section data-id="4993597" data-element_type="section"></section></div></div></div></div></div>]]>
            </description>
            <link>https://elastisys.com/what-do-i-need-to-add-on-top-of-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26273013</guid>
            <pubDate>Fri, 26 Feb 2021 09:39:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The First CSS Report About CSS File Sizes and File Count]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26272884">thread link</a>) | @todsacerdoti
<br/>
February 26, 2021 | https://css-auditors.com/blog/the-very-first-css-report-about-css-file-sizes-and-file-count/ | <a href="https://web.archive.org/web/*/https://css-auditors.com/blog/the-very-first-css-report-about-css-file-sizes-and-file-count/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
  


  

  <section id="the-very-first-css-report-about-css-file-sizes-and-file-count">
  <article>
    <div>
      
      <div>
        
          <h2>The Very First CSS Report About CSS File Sizes and File Count</h2>
        
        <p>
              <span>Author: Silvestar Bistrović</span><br>
              <span>Date: 2021-02-18</span>
            </p>
        
        
      </div>
    </div>
  </article>
</section>


  <section id="how-it-started">
  <article>
    <div>
      
      <div>
        
          <h2>How It Started</h2>
        
        <p>Last year I took <a href="https://boagworld.com/academy/finding-clients/">a masterclass</a> on finding clients by Paul Boag. I never got to the final lesson, but one particular advice stuck with me: you should combine your passion with your profession. So I started thinking about combining sports, my passion, and front-end development, to be more precise, CSS, my profession. Since I enjoy writing CSS and exploring it and finding new ways to use it more efficiently, I got the idea of starting a site about auditing CSS. I presented the idea to my friend, and here we are now, providing our first report.</p>
        
        
      </div>
    </div>
  </article>
</section>


  <section id="about-css-audit">
  <article>
    <div>
      
      <div>
        
          <h2>About CSS Audit</h2>
        
        <div>
          
          
          
          
          
            
              
                <p>CSS auditing is not a very popular topic, but we find it very important. Although there are some excellent tools and resources, we don’t think those are widespread enough. One of the aims of CSS Auditors is to try to change that. We want to bring attention to CSS and all aspects of writing quality CSS code. After all, every site on earth uses CSS, with very few exceptions <a href="https://motherfuckingwebsite.com/">like this one</a>.</p>
<p><a href="https://en.wikipedia.org/wiki/Code_audit">Wikipedia</a> has this definition for code audit:</p>
<blockquote>
<p>A software code audit is a comprehensive analysis of source code in a programming project with the intent of discovering bugs, security breaches or violations of programming conventions.</p>
</blockquote>
<p>CSS is a very forgiving language in terms of errors. The reason is that browsers usually skip the line that produces the error while the rest of the code remains valid. There are linters and other tools that could prevent those issues. Still, they cannot prevent developers from writing inadequate CSS. That is why we would like to add <span>CSS code quality</span> to this definition.</p>

              
              
              
              
            
          
        </div>
        
        
      </div>
    </div>
  </article>
</section>


  <section id="about-css-quality">
  <article>
    <div>
      
      <div>
        
          <h2>About CSS Quality</h2>
        
        <div>
          
          
          
          
          
            
              
                <p>With abstract terms, like quality, it is almost impossible to determine the formula or calculation. How would you define code quality, in particular, CSS code quality? We asked this question in several places, including <a href="https://dev.to/starbist/how-to-measure-determine-the-quality-of-the-css-code-1f48">dev.to</a> and some Slack communities. Here are some of the answers:</p>

              
              
              
              
            
              
              
                <blockquote><p>As some of the previous answers mention:</p>
<ul>
<li>
<p>Low specificity selectors</p>
</li>
<li>
<p>Component-based styles</p>
</li>
</ul>
<p>— Spyros</p></blockquote>
              
              
              
            
              
              
                <blockquote><p>If the css is modular, reusable and scalable.</p>
<p>How large the custom stylesheet is in terms of file-size.</p>
<p>Use of external css frameworks like Bootstrap or Foundation.</p>
<p>For large projects, if a preprocessor like Sass or Less is being implemented with properly organized functions, mixins, variables, etc.</p>
<p>— Matt</p></blockquote>
              
              
              
            
              
              
                <blockquote><ul>
<li>
<p>Usage of low/high specificity selectors.</p>
</li>
<li>
<p>Styles with less noise</p>
</li>
<li>
<p>Readable styles (is readable top to bottom)</p>
</li>
</ul>
<p>Forgotten that !important still exists.</p>
<p>— Joshua</p></blockquote>
              
              
              
            
              
              
                <blockquote><p>Readability, structure, good use of variables and consistency. The bigger the project, the more important these are to me.  Also the lack of exceptions although this might be more of a bad design practice...</p>
<p>— Sjoerd</p></blockquote>
              
              
              
            
              
              
                <blockquote><ul>
<li>
<p>No bootstrap</p>
</li>
<li>
<p>Mostly max 3 selectors ( in case of sass, 3 levels of nesting )</p>
</li>
<li>
<p>Dry</p>
</li>
<li>
<p>Ordered declarations</p>
</li>
<li>
<p>Use of not, &gt;, +, ~</p>
</li>
<li>
<p>Comments</p>
</li>
<li>
<p>Naming of classes (understandable)</p>
</li>
<li>
<p>Reduced motion, outline not 0, etc. (Accessibility)</p>
</li>
<li>
<p>Animation</p>
</li>
<li>
<p>Transform</p>
</li>
<li>
<p>No backend developer code</p>
</li>
</ul>
<p>— Kris</p></blockquote>
              
              
              
            
              
              
                <blockquote><ul>
<li>
<p>Performance considerations. e.g. using will-change property when animating.</p>
</li>
<li>
<p>Considered use of when to animate with CSS vs JS</p>
</li>
<li>
<p>Consistent coding patterns e.g. always use shorthand where appropriate.</p>
</li>
</ul>
<p>Other things I’d look at have already been mentioned.</p>
<p>— Azlan</p></blockquote>
              
              
              
            
              
                <p>There seems to be no answer to what CSS code quality implies. Everyone’s answer is different, and it depends on various aspects.</p>

              
              
              
              
            
          
        </div>
        
        
      </div>
    </div>
  </article>
</section>


  <section id="the-very-first-audit-report">
  <article>
    <div>
      
      <div>
        
          <h2>The Very First Audit Report</h2>
        
        <div>
          
          
          
          
          
            
              
                <p>One of the first thing that comes to mind when thinking about the quality of the code is file size. That is exactly what we did in our first report – we audited the CSS code of all Premier League sites. This is the part where I managed to include my passion, sports, into the project.</p>
<p>The full report is available <a href="https://css-auditors.com/reports/premier-league-2021-02/">here</a>. I don’t want to write any spoilers, so I will leave you to read it thoroughly.</p>
<p>To be able to make this report, we needed information. So the first step was to extract the CSS code from these sites. We used <a href="https://github.com/aliasio/wappalyzer">wappalyzer</a> and <a href="https://github.com/bartveneman/extract-css-core">extract-css-core</a>, both excellent tools. We didn’t want to make calculations manually since we wanted to reuse the script to audit other sites, so we wrote a script for calculations and graphs. Finally, we needed to make the report look appealing. This is definitively the part that could use more love, but we wanted to release the report as soon as possible.</p>

              
              
              
              
            
          
        </div>
        
        
      </div>
    </div>
  </article>
</section>


  <section id="the-conclusion">
  <article>
    <div>
      
      <div>
        
          <h2>The Conclusion</h2>
        
        <div>
          
          
          
          
          
            
              
                <p>We hope this report will encourage you to think about your CSS code’s size and CSS quality in general.</p>
<p>That is the final goal of CSS Auditors; we want to make every developer respect CSS.</p>
<p>#RespectCSS</p>

              
              
              
              
            
          
        </div>
        
        
      </div>
    </div>
  </article>
</section>


  <section id="about-the-author">
  <article>
    <div>
      
      <div>
        
          <h2>About the Author</h2>
        
        <div>
          
          
          
            
            <div>
              <p><img src="https://d33wubrfki0l68.cloudfront.net/f256f4fe485e7823923961b095fcfe7eebd47803/a79a6/gfx/author-silvestar.jpg" alt="Silvestar Bistrović" height="94" width="94"></p>
              <h3>Silvestar Bistrović</h3>
              <div>
                <p>Silvestar is a frontend UI developer who enjoys creating pixel-perfect, responsive, and modern websites. Making faster, lighter, and more secure sites using WordPress or Static Page Generators is his speciality. When he is not coding, Silvestar likes to write articles on his blog.</p>

                
              </div>
            </div>
          
          
          
        </div>
        
        
      </div>
    </div>
  </article>
</section>


  


  <section id="subscribe">
  <article>
    <div>
      
      <div>
        
          <h2>Subscribe</h2>
        
        <div>
          
          
          
          
          
            
              
                <p>We are working hard to publish new reports and blog posts as soon as possible.</p>
<p>If you would like to get recent reports in your inbox, subscribe here!</p>

              
              
              
              
            
          
        </div>
        
        
          <hr>


        
      </div>
    </div>
  </article>
</section>



  




<!-- Global site tag (gtag.js) - Google Analytics -->



</div>]]>
            </description>
            <link>https://css-auditors.com/blog/the-very-first-css-report-about-css-file-sizes-and-file-count/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272884</guid>
            <pubDate>Fri, 26 Feb 2021 09:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Wisdom of Ernesto Colnago]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26272825">thread link</a>) | @dfgdghdf
<br/>
February 26, 2021 | https://www.rouleur.cc/blogs/the-rouleur-journal/the-wisdom-of-ernesto-colnago | <a href="https://web.archive.org/web/*/https://www.rouleur.cc/blogs/the-rouleur-journal/the-wisdom-of-ernesto-colnago">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>He can’t stand still for a moment. He gets up, checks on something, sits down, makes a phone call, gets back up to check on something else, sits down again, makes a note, gets up, invites someone in, sits down, responds to a question, nips out, comes back, sits down, makes a quick sketch, up again. Always coming and going. Inexhaustible, unstoppable, incredible. That’s just how he is, Ernesto Colnago.</p>

<p>Ernesto is sharp, quick, nimble. He says: “I’ll be 100 in 13 years, but what really matters is not the number on the ID card, but rather, the person’s lucidity.” Ernesto’s personal maxim: “As long as there are dreams, there are projects. As long as there are projects, there is work.&nbsp;And as long as there is work, there is life.” He adds: "I’m full of work,” gesturing towards his desk. It’s full of designs and plans, notes on scraps of paper, commitments he needs to meet immediately, problems he needs to solve urgently.</p>
<p><img src="https://cdn.shopify.com/s/files/1/0040/5251/6910/files/IMG_9622_1024x1024.jpg?v=1606824099" alt="Colnago"></p>
<p><strong>Colnago, born a sprinter?</strong></p>
<p>“I was born poor. My father was a peasant. Any time that he didn’t spend working the land, he considered wasted. So you can imagine what he thought of riding bicycles. Perhaps because he thought it was best for me to combine work and my passion, he sent me to work in a workshop nearby that repaired agricultural equipment and also bicycles.”</p>
<p><strong>Was the work paid?</strong></p>
<p>“You must be kidding. The country was still at war, and I was only 12 years old. There was a payment – two kilos of cornmeal – but it was my parents who paid it. They sent me there to learn a trade, the one I’m still doing now.”</p>
<p><strong>And then?</strong></p>
<p>“After the war, I found work in Milan. I had to get up at 6am, by which time my dad was already working in the stables. For breakfast, I’d have a cup of milk, and then I’d prepare my <em>schiscetta</em>, the lunchbox, with a little sandwich or some frittata. Then I’d jump on my bike and pedal as fast as possible to the tram station, where I’d leave my bike with a woman who looked after hundreds of them in a little shed.”</p>
<p><strong>A bike garage?</strong></p>
<p>“I said shed, because back then, garages didn’t exist. That woman was formidable, she was like a computer before computers had even been invented. She knew every single cyclist and recognised every bicycle right away, without any help. My bike was the smallest in the whole shed, and she had a special spot for it, right at the entrance, so that I could drop it off quickly and rush to the stop to catch the 6.40 tram. An hour later, I’d get off in Milan, at Piazzale Loreto, where the first Giro d’Italia had departed at 2.53am, 37 years earlier. From there, I had to run to Viale Abruzzi number 42, to Gloria.”</p>

<figure><img src="https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9524-1024x682.jpg" alt="" srcset="https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9524-1024x682.jpg 1024w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9524-300x200.jpg 300w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9524-768x512.jpg 768w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9524-1200x800.jpg 1200w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></figure>
<p><strong>Gloria Bicycles.&nbsp;</strong></p>
<p>“I left school at a young age – like cycling, my father also considered education to be a luxury – but going to work at Gloria was like university for me. I worked until five in the afternoon, then I washed my hands and my face, and headed back home, running up to Piazzale Loreto to catch the tram, and then on my bike to pedal home, happy and content.”</p>

<p><strong>Did you feel like they took advantage of you?</strong></p>
<p>“No, I felt privileged. Actually, I doctored my identity card so that I could start working a year earlier than I should have. On my first day of work – 25 November 1945 – I showed up with a coat that belonged to my uncle, who had just returned from Russia. My mother shortened it for me, but left the pockets as they were, and so they dragged along the ground. Milan had been bombed during the war and the streets were still full of rubble. Most houses were in ruins and the shops were all empty. Bicycles were a real luxury. People used them to go to work, or to look for it.”&nbsp;</p>

<p><strong>Like in the film, <em>Bicycle Thieves?</em></strong></p>
<p>“Exactly like that. Gloria was a respected brand, they’d won the 1931 Giro d’Italia with Francesco Camusso, and the 1936 Milano-Sanremo with Angelo Varetto. Their road racing bikes were known as Garibaldinas, and their riders Garibaldini. On Sundays I raced too. I was an amateur Garibaldino. At that time, I worked in the factory alongside Ernesto Formenti, who would become the Olympic boxing champion in 1948, and Gian Maria Volonté, who went on to become a great actor.”&nbsp;</p>
<p><br><strong>What age did you race until?</strong></p>
<p>“When I was 19, I had a bad fall at the Milano-Busseto, and I damaged my leg and ended up in a plaster cast. But I didn’t want to lose my job, so I went to the foreman, Angelo Righi, and asked his permission to work at home, building wheels. He agreed to give it a shot, and it wasn’t long before I realised that I was earning more in a week at home making wheels than I had been in a month at the workshop. I asked for another meeting with Righi and he took me to see the owner, Alfredo Focesi, a gentleman from the 19th century. We made a deal right away: I would assemble 25 bikes a week.”&nbsp;</p>

<p><strong>And that was the beginning?</strong></p>
<p>“I rented a room from a farmer, 25 square metres, and that was my little bolthole, my shop, my kingdom. Inside, there was only a table made of mulberry wood, a little hand drill and a vice, all of which I’d bought from the little money I had made racing. I set myself up nicely, and from that day, I’d never have another boss. There was more satisfaction, both mentally and financially, and I had a lot of ideas to develop, projects to realise, dreams to fulfill.”&nbsp;</p>
<p><br><strong>And you went from bicycles to cycling?</strong></p>
<p>“Thanks to Fiorenzo Magni. He was already known as the Lion of Flanders when I met him, and I was a nobody. One day in the spring of 1955 we went out for a ride together. He mentioned that one of his legs hurt when he pedalled. I took a look at his bike and noticed that one of the cranks was bent. I fixed it and the pain went away. Magni asked me if I wanted to follow him at the Giro d’Italia, and I didn’t think twice about it. What’s more, his mechanic at the time was Faliero Masi, who had his home and his workshop at the Vigorelli velodrome. He was an artist. I knew that I could learn a lot from him.”&nbsp;</p>

<figure><img src="https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9627-1024x682.jpg" alt="" srcset="https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9627-1024x682.jpg 1024w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9627-300x200.jpg 300w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9627-768x512.jpg 768w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9627-1200x800.jpg 1200w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></figure>
<p><strong>And did you learn?&nbsp;</strong></p>
<p>“It was a master’s degree, or rather, a supermaster’s. The races gave everything a sense of urgency, and I developed the art of adaptation, always doing my best. At the 1956 Giro, Magni fractured his left shoulder blade. He could endure pain like no one else, but this was intolerable. He didn't want to abandon the race, though. To him, quitting seemed shameful, indeed, scandalous. I remember saying to him: ‘Signor Fiorenzo, why don't you try to tie an inner tube to the handlebars and pull on it with your teeth, to relieve some of the pressure on your left arm?’ I got a Clement tubular, took out the latex inner tube and tied it to the handlebar. Magni put it between his teeth and tried. 'That feels better,' he said. And like that, he rode the time-trial to the sanctuary of San Luca, in Bologna, and also the stage to Monte Bondone. By the end of the race, he was second only to Charly Gaul in the general classification.”&nbsp;</p>
<p><strong>Did you know Fausto Coppi?</strong></p>
<p>“The first time I saw him, I was still working at Gloria and I was racing with the amateurs. It was in Milan, at the Hotel Andreola, where Coppi stayed a lot. I met him again at the 1955 Giro d’Italia, when I was working for Magni.</p>
<p><br>“Magni won, Coppi was second, Gastone Nencini was third. After the Giro, a kermesse race was organised in Cologno Monzese. Coppi arrived by car with his gregario, Ettore Milano. He asked me to help him take his bike down off the car and while I was at it, to get it ready for the race.</p>
<p><br>“For the sake of transparency and honesty, I first asked for permission from Magni, who granted it. When I was done, Coppi said thanks and went to pay me. I refused but he insisted and gave me a thousand lire. I kept that thousand lire note in my wallet for years: I was Magni’s mechanic, but in my heart, I always followed Coppi.”</p>
<p><strong><br>And Eddy Merckx? </strong></p>
<p>“With him, it was always a race against time. Often at night. After the stage, he’d come asking for a change, a tweak here or there, and I’d rush back to the workshop, often working until dawn before rushing back to the start of the next stage. Was Merckx a maniac? No. He was a perfectionist. Before the Mendrisio World Championships in 1971, he had me prepare three bikes with three almost imperceptibly different set-ups. On the eve of the road race – I was with the Italian national team – he called me to his hotel.</p>
<p><br>Eddy was locked in his room with his team-mates. He’d lined up three wheels and was pointing at them: ‘I’ve already chosen, now you choose.’ Without knowing, I chose the same one, and when I picked it up, I could see it was off-centre. I fixed it for him and he asked what I wanted in return. I told him: ‘It’s my wedding anniversary tomorrow, send some flowers to my wife, Vincenzina.’ He won the next day, but didn’t forget his promise, and sent her a basket full of carnations.</p>
<p><br>The next year he set a new hour record, and I played my own little part, making a bicycle that, by drilling here and filing there, weighed only five kilos and 750 grams. And now, every 25 October, on the anniversary of that achievement, I call Eddy early in the morning. He knows to expect that phone call: it’s the symbol of our friendship.”</p>

<figure><img src="https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9610-1024x682.jpg" alt="Ernesto Colnago" srcset="https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9610-1024x682.jpg 1024w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9610-300x200.jpg 300w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9610-768x512.jpg 768w, https://journal.rouleur.cc/wp-content/uploads/2020/01/IMG_9610-1200x800.jpg 1200w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></figure>
<p><strong>Was there ever a rider you particularly liked?&nbsp; </strong></p>
<p>“From Gianni Motta to Beppe Saronni, from Gibì Baronchelli to the guys at Mapei: I loved them all. I would have liked to work with Vincenzo Nibali: he’s courageous, loyal, uncomplicated. After 16 years together, Sven Nys left for a team with another bike manufacturer, and he wrote me a long, true, profound, moving letter that is now on display in my personal museum. I’d like to work with Wout van Aert: I had him for cyclo-cross, but not for the road. That boy is a phenomenon. The dream would be Peter Sagan: he makes headlines even when he doesn’t win, indeed, even when he doesn’t race.”&nbsp;</p>

<p><strong>Are the riders grateful?</strong></p>
<p>“They’re special. Olaf Ludwig came here the other day. He hugged and kissed me as if I was his father, and then he asked me to restore his old Olympic bike so he could put it in a shop window, as if it were a painting or a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rouleur.cc/blogs/the-rouleur-journal/the-wisdom-of-ernesto-colnago">https://www.rouleur.cc/blogs/the-rouleur-journal/the-wisdom-of-ernesto-colnago</a></em></p>]]>
            </description>
            <link>https://www.rouleur.cc/blogs/the-rouleur-journal/the-wisdom-of-ernesto-colnago</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272825</guid>
            <pubDate>Fri, 26 Feb 2021 09:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build for iOS or Android First?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26272747">thread link</a>) | @allending
<br/>
February 26, 2021 | https://blog.snappymob.com/to-build-for-ios-or-android-first-4-key-differences-to-consider | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/to-build-for-ios-or-android-first-4-key-differences-to-consider">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
		<div id="primary">
			<main id="main" role="main">
<article id="post-1081">
	<!-- HEADER: .header-content -->
	<!-- .header-content -->

	<!-- BODY: .entry-content -->
	<div>
		
<p>Mobile apps are becoming an increasingly lucrative venture, and a quick look at the numbers can tell us why.&nbsp;</p>



<p><a href="https://jmango360.com/mobile-app-vs-mobile-website-statistics/">Recent research</a> shows that mobile users spend 90% of their screen time on apps, and only 10% on browsers. Apps also push more people down the purchase funnel, with 3x higher conversion rates compared to mobile sites and even 1.5x more conversions per session than via desktop.</p>



<p>It’s no surprise that businesses from verticals left and right are catching on on the value of both iOS and Android development, but unless they have a surplus of time and resources at hand, when it comes to an initial launch, a choice must be made between the two platforms.</p>



<p>But why exactly? Short answer: It’s extremely risky.&nbsp;</p>



<p>Launching on both iOS and Android platforms simultaneously may be the dream for apps just starting out, but most experts in the industry would strongly advise against it. To put it simply, shooting for both hoops at the same time will incur high development and marketing costs, as well as take longer periods to launch due to high volumes of complex work.&nbsp;</p>



<p>On a positive note, focusing on one platform before branching out to the other will allow you to focus on a more targeted audience base and refine your core app experience, before you ready it for growth and expansion. In fact, this is how many great apps started out — Instagram, Twitter, WhatsApp, Telegram, etc.</p>



<p>When it comes down to deciding on the platform of your choice, it is absolutely necessary to understand how exactly it can reap you more benefit than the other. So to help clear the fog on whether you should go for iOS or Android for your first launch, here are the 4 main categories in which they differ.</p>



<h2><strong>1. Audience</strong></h2>



<p>Android users are more saturated in developing countries, while iOS users are generally <a href="https://www.prnewswire.com/news-releases/iphone-users-spend-101-every-month-on-tech-purchases-nearly-double-of-android-users-according-to-a-survey-conducted-by-slickdeals-300739582.html?c=n">more affluent and saturated in developed countries</a>. That being said, it’s safe to say that launching on iOS first will (if executed well) give you a slight advantage of being visible to more individuals with higher influence and purchasing power, as well as the press.&nbsp;</p>



<p>Launching on Android first may not give you those perks but it will definitely give you the advantage of a larger user base and broader reach. If you’re looking to emphasize push notifications, especially, you might see better results with Android users. According to <a href="https://www.accengage.com/benchmark-opt-in-and-reaction-rates-of-push-notifications-and-in-app-messages-for-mobile-apps-2018-edition/">a study by Accengage</a>, Android showed both higher notification opt-in rates and stronger click-through rates, compared to iOS. Many believe it has to do with the way Android has more prominent and sticky notifications, while iOS hides notifications in the notification center after they’re seen.</p>



<p>Aside from potential for reach and engagement, there are many other ways these two user groups can be compared. Take a look at some of their social, economic, and political differences here on <a href="https://www.huffpost.com/entry/iphone-vs-android-users_n_928275">an infographic made by Hunch</a> back in 2011. Depending on what pain points your app addresses or plans to address, you can find user data that helps you decide where you can form a stronger audience.&nbsp;</p>



<p>All in all, take some time to study your market. If you already have an audience, what platform does the bulk use or prefer? If you don’t, is the majority in your industry, region and targeted demographic more likely to own an iOS or Android device?</p>



<h2><strong>2. Time</strong></h2>



<p>Many sources state that Android development takes a longer time because it involves about 40% more code than iOS development, but many also argue that this isn’t necessarily true. Development periods for either platform would heavily depend on a team’s proficiency in whatever language they are using, be it Java, Kotlin, Objective-C or Swift.</p>



<p>However, Android development is universally believed to be slower because of the larger number of devices to test on, and hence, higher volume of bug fixes and maintenance that comes with it. With tens of thousands of different devices, there is just a much larger variety of screen dimensions, processors and operating system (OS) versions to be considered in development.&nbsp;</p>



<p>iOS development, on the other hand, is believed to be a simpler task for a couple of reasons. (1) It involves fewer devices, and (2) most iOS users keep their operating systems up to date. Why the latter matters is that, based on the <a href="https://www.statista.com/statistics/565270/apple-devices-ios-version-share-worldwide/">worldwide iOS version share</a> on Statista, targeting the latest few operating systems would exclude less than 10% of the user base. In contrast, the <a href="https://www.statista.com/statistics/271774/share-of-android-platforms-on-mobile-devices-with-android-os/">Android operating system share</a> is much more varied and evenly distributed, making it costly to focus on only the newer versions and exclude older versions.&nbsp;</p>



<p>Despite the many positives for iOS, Apple is known to have a longer review process and stricter <a href="https://developer.apple.com/app-store/review/guidelines/#introduction">guidelines</a> when it comes to getting new apps on the shelf in the App Store. In some cases, apps may get rejected entirely due to inconsistency with the predefined rules.</p>



<p>So what’s the verdict? Both platforms take time but on different portions of the delivery process — Android may take up more time in development and maintenance, while iOS may take up more time in operations.</p>



<h2><strong>3. Budget&nbsp;</strong></h2>



<p>Generally, iOS apps cost more to develop, and the reasons have to do with a few things — the devices they’re built on, publishing fees, and resourceability.</p>



<p>iOS development requires a Mac to ensure the standard Integrated Development Environment (IDE) is met, maintain consistency across devices, and avoid issues with unsupported configuration. On the flip side, Android development can be done on most platforms.&nbsp;</p>



<p>Why does this cost more? It’s pretty obvious. Macs and Macbooks are relatively more expensive than other devices from manufacturers like HP, Dell and Lenovo. Agencies will need to provide their developers Apple machines in order to carry out iOS development.</p>



<p>Which brings us to resourcing. Since iOS development requires a Mac or Macbook, there are bound to be more Android developers than iOS developers, given its more accessible nature. Especially in regions with fewer Apple consumers like SouthEast Asia, it may be difficult to source and costly to hire iOS engineers. However, hiring remote workers is an alternative commonly considered to overcome these problems in talent availability and cost.</p>



<p>When it comes to fees, Android Play Store has the much smaller bill with a one-time fee of USD$25 to start publishing apps to the store, while Apple’s App Store charges an annual fee of USD$99.&nbsp;</p>



<p>Though these reasons may point you towards Android as the evidently more affordable option, keep in mind that they may or may not affect how app development agencies adjust their prices. Some may take the aforementioned factors into consideration with their quotations, while others may not. If you’re opting for a development agency, it’s still best to compare their prices upfront.</p>



<h2><strong>4. Monetization</strong></h2>



<p>According to <a href="https://www.businessofapps.com/data/app-revenues/">app revenue data from Business of Apps</a>, Android, despite leading in total users, has been consistently outperformed in revenue generation by Apple’s App Store over the years. Despite having less than 15 percent of worldwide market share, iOS users have shown higher willingness to spend on apps and in-app purchases.&nbsp;</p>



<p>What this means is that you’re more likely to profit from iOS users if your app is a paid app, but less likely to earn ad revenue from them (because they’re more likely to pay to get rid of ads). So if you’re making a free app and focusing on ads, go Android. If you’re making a paid app with in-app purchases, go iOS.&nbsp;</p>



<p>After all, if you can get your product to market and build a funnel from acquisition to revenue on iOS, you can be confident that your business model ‘works’ and will probably work on Android, though you should expect lower ASP and conversion.</p>



<h2><strong>The Summary</strong></h2>



<p>To wrap it all up, launching on iOS first could give you better chances of top-level exposure and revenue growth from paid app and in-app purchasing features, but these may come with the price of higher development costs, more stringent updates and longer review processes.&nbsp;</p>



<p>On the other end, if you’re launching a free app, looking to explore up-and-coming markets like SouthEast Asia, India and Latin America, and plan to earn mostly through ad revenue or push notification marketing, launching on Android first may be the safest bet.</p>



<h2><strong>Need Help?</strong></h2>



<p>Snappymob is an expert web and app development agency that is experienced in kick-starting all-new mobile app strategies.&nbsp;</p>



<p>Feel free to roam our website, take a look at <a href="https://www.snappymob.com/case-studies">Our Work</a> or <a href="https://www.snappymob.com/contact">drop us a message</a> on your upcoming project!</p>
		<!-- Contact us CTA -->
		
		<!-- Post category tags-->
		<p><label>
				App Development			</label>
		</p>
		<!-- Social share -->
		
	</div><!-- .entry-content -->

	<!-- Disable meta footer --> 
	<!-- 	<footer class="entry-footer default-max-width">
</footer> -->
	<!-- .entry-footer -->

	<!-- Disable author detail -->
	<!-- -->
</article><!-- #post-${ID} -->
			</main><!-- #main -->
		</div><!-- #primary -->
	</div><div>
	  <div>
		
		<p>
			We understand that every project is unique. Contact us and we will get
			back to you with the next steps.
		  </p>
		
	  </div>
	</div></div>]]>
            </description>
            <link>https://blog.snappymob.com/to-build-for-ios-or-android-first-4-key-differences-to-consider</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272747</guid>
            <pubDate>Fri, 26 Feb 2021 08:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Interactive real-time chemistry and fluids: water electrolysis]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26272642">thread link</a>) | @pkarnakov
<br/>
February 26, 2021 | https://cselab.github.io/aphros/wasm/electrochem.html | <a href="https://web.archive.org/web/*/https://cselab.github.io/aphros/wasm/electrochem.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://cselab.github.io/aphros/wasm/electrochem.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272642</guid>
            <pubDate>Fri, 26 Feb 2021 08:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Money Creation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26272253">thread link</a>) | @ZephyrBlu
<br/>
February 25, 2021 | https://geohot.github.io/blog/jekyll/update/2020/08/07/on-money-creation.html | <a href="https://web.archive.org/web/*/https://geohot.github.io/blog/jekyll/update/2020/08/07/on-money-creation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Consider a mining town. Once upon a time there was a mine, and the mine was the largest employer in the town. They mined copper ore and sold it on the global market. This brought money into the town, which sprouted a restaurant, real estate broker, doctor’s office, and church. Although those people weren’t employed by the mine, they got enough customers from the miners, who fundamentally got money from outside the town.</p>

<p>But eventually the mine dried up. The miners lost their jobs, since the town was no longer bringing in enough money to pay them. The doctor, realtor, and waiter were still employed, as their “mines” didn’t dry up. But they did, as they were really just mining the miners. The town persisted for a bit, passing the same money around in a circle. But with each pass, there was a transaction fee. And there were still things like food, which needed to be imported into the town.</p>

<p>The town went broke, died, and became a ghost town.</p>

<hr>
<p><br>
<b>All jobs can be broken down into one of three groups.</b></p>

<p>The first(constant) is the shoeshiners, bank tellers, politicians, retail workers, clergy, social media managers, lawyers, and the rest of the service industry. An economy made up of only these people wouldn’t work. Imagine a town without imports and exports comprised of only this class of people. Considering every transaction always has a fee, regardless of what this town started with, they would always end up going broke.</p>

<p>So where does money come from? There’s a literal answer to this question, but that’s not what I want to explore. I mean money in a more abstract sense, perhaps more like wealth or value.</p>

<p>The second(linear) group produces “money” linearly. This group includes farmers, miners, and manufacturers. They create value by the ton, bushel, carton, or barrel, a ton of ore mined, a barrel of oil extracted, a bushel of apples grown. This is the only group that could sustain an economy by itself.</p>

<p>The third(exponential) group seeks efficiency improvements for the second. This group includes scientists and engineers. The scientist who genetically engineers crops to get 30% more yield per acre. The engineer who replaces a ox drawn plow with a tractor drawn megaplow. This group can’t sustain an economy alone, but mixing a few of them in with the second group yields much higher per capita money creation.</p>

<p><img src="https://geohot.github.io/blog/assets/images/ourworldindata_share-working-in-agriculture-since-1300.png" alt="image"></p>

<p>Most people used to unquestionly be in the second group. The third group has this exponential effect, where in the beginning they do very little, but because they build on the previous successes of the group in a way the other groups don’t, they eventually come to be the driving force of society. Today, although we aren’t quite there yet, it is easy to imagine a few farmers farming all the land, extending their reach with automation and sensors. Or even, no farmers, just machines. And more machines to fix the machines. But the machines would still be in group 2. Group 2 is the basis of any economy.</p>

<p>I set about classifing the top 30 jobs (2/3rds of the workforce, minor level classification from bls.gov) in the US into the three groups, and realized I should break group 1 down further for more clarity. The top 4 jobs consist of just moving stuff around, a clearly group 1 activity!</p>

<p>Breaking down group 1 into 3 subgroups:</p>
<ul>
  <li>1M: movers of stuff (waiters, retail, clerks, drivers, bankers)</li>
  <li>1E: fighters of entropy (maids, doctors, nurses)</li>
  <li>1B: people who tell other people what to do. “bosses” of various sorts (management, executives, specialists, “finance”, sales, admins)</li>
</ul>

<p>I found teachers somewhat hard to classify as well, assuming education works, they are group 2, producing more productive people, like a tractor maker. If education is daycare, they are group 1. We gave them the benefit of the doubt and included them in group 2.</p>

<p>And surely not all “Computer Occupations” are group 3, but that’s how it’s broken down.</p>

<p><img src="https://geohot.github.io/blog/assets/images/job_chart_percent.png" alt="image">
<img src="https://geohot.github.io/blog/assets/images/job_chart_class.png" alt="image"></p>

<p>I would like to dive into this further, as the categories used from the Bureau of Labor Statistics were rather crude. You can dive even deeper than minor categories. I’d also like to see this analysis done for China, as perhaps this is a US specific problem that only predicts the decline of the US.</p>

<p>But this makes my point, that group 1 jobs have been growing at the expense of group 2. They are now 73% of US jobs! Group 1 jobs do not contribute to the money creation as a whole, and it’s concerning to consider what will happen if this trend continues. We cannot have a worldwide economy of group 1 jobs, as just like the town, the whole world would end up going broke.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://geohot.github.io/blog/jekyll/update/2020/08/07/on-money-creation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272253</guid>
            <pubDate>Fri, 26 Feb 2021 07:42:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being on Call]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 124 (<a href="https://news.ycombinator.com/item?id=26272170">thread link</a>) | @colluder
<br/>
February 25, 2021 | https://tyler.kim/being-on-call | <a href="https://web.archive.org/web/*/https://tyler.kim/being-on-call">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        

        <p>
          April 21, 2020

            ☼ <a href="https://tyler.kim/tagged/life">life</a>
            ☼ <a href="https://tyler.kim/tagged/roka">roka</a>
        </p>

        
<p>I’m an occasional on-call operator for my battalion, assisting the on-call commander and staffing the control room from 16:00 in the afternoon until 08:30 the next morning on weekdays. Most of the work is answering and making calls, updating documents, and making sure that nothing is out of the ordinary. It’s not that difficult, just tiring as there is a lot of stuff to follow and pay attention to through the night.&nbsp;</p>
<p>I was on-call on Friday, the 10th, and for 24 hours last Wednesday (not the usual shift), starting from 08:30 to the next 08:30 since it was the legislative election day in Korea. I wrote most of this post over those two shifts to share how I personally am being on-call.</p>

<hr>

<p>A little past 2300 is when I try to find some peace. I usually make myself a cup of coffee, and it doesn’t take long to feel the caffeine flowing through my bloodstream. I’m exhausted. It’s been many hours since I started my shift, and I have nine hours to go. No shift goes without a hectic evening with lots of random situations to handle, and they are usually followed by a series of paperwork.</p>
<p>I sit in front of a bunch of monitors and tactical comms equipment in bad posture, and the chair predates the concept of ergonomics. Meanwhile my feet are trapped in my airtight combat boots and they are begging to take a breath. In addition, no matter how much water I drink, my mouth is dry the whole time. It’s probably from all the sugar-intakes from snacking. It’s a similar feeling to a tiring second day at a college hackathon - constant snack intakes and sleep deprivation.</p>
<p>Around midnight, after I’m finished with all the paperwork that needs to be done by the morning, is a good time to seek solace in a cup ramen. It’s hard to convey the exact late-night-cup-ramen sentiment, but the hot soup warms you up in a way no others can console you in this late time.&nbsp;</p>
<p>I also have books with me so that I can read whenever I can. Late in the night especially after a ramen session is usually a good time to read. Every time I try to read in the evening or during the day, I either get a disruptive phone call or a situation, and they make me re-read the same page multiple times. It gets annoying after a couple of tries.</p>
<p>When I tried to read on the past few shifts, I faced some sad ironies. I brought <em>Why We Sleep</em> to my first shift. Reading about the importance of sleep while not being able to sleep was quite saddening, so I stopped after a few pages in. At least I learned why I feel wide awake towards the end of my shift (in the morning), and why I have difficulties sleeping after my shift despite being tired as hell. Now I’m reading <em>the Utopia of Rules</em>, a book filled with social commentaries on bureaucracy and filling out paper forms. Reading that in between the processing and filling out a ton of paperwork was yet another sad irony I encountered. Inevitably and unfortunately, as the night passes, my ability to focus gets decimated. I wish I could accomplish more reading on the job.&nbsp;</p>
<p>Around 0300~0400, a little after 12 hours (or 20) into the shift, I’m usually passed out on my desk. In a zombie-like state, I get half-woken up by periodic phone calls but I occasionally sleep through the ringings. Sometimes I answer the phone and pretend to handle whatever they tell me, and then go right back to sleep, forgetting everything I heard. I also get woken up when I have to unlock a small safe with ammunition for those going to a guard shift at night. Even then, my body isn’t fully awake sometimes.&nbsp;</p>
<p>By dawn, I can feel my internal organs are rotting. With that, my body starts to produce an uncomfortable amount of gas. A little past 0600, with my internal rhythm resetting, my body spontaneously wakes me up. It’s when I start to get busy again. Meanwhile my body goes through this illusion of feeling refreshed, but soon enough it feels like it has aged about six months over the past six hours. It’s obviously not a great feeling and it takes me about two full days to recover. Five more on-call shifts will age me by two years.&nbsp;</p>
<p>Despite such horribleness, the one positive aspect about doing the on-call shifts is that I get to sleep in and rest for the entirety of the next day, getting exempt from pretty much everything. Then, after one shift, two days have gone by just like that. Time flies and a week passes by only after a few days. And I get to rest over the weekend. That’s a good feeling to have in here, the sense of getting closer to the discharge date quicker than how I would feel it otherwise. Just gotta rinse and repeat till I’m out. It’s like Stockholm syndrome - despite how shitty I feel during and after the shift, I’m a bit disappointed that I don’t have a shift this week.</p>

        <br>

  

</div></div>]]>
            </description>
            <link>https://tyler.kim/being-on-call</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272170</guid>
            <pubDate>Fri, 26 Feb 2021 07:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ISO 8601: a better date format]]>
            </title>
            <description>
<![CDATA[
Score 331 | Comments 394 (<a href="https://news.ycombinator.com/item?id=26272084">thread link</a>) | @kirbykevinson
<br/>
February 25, 2021 | https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/ | <a href="https://web.archive.org/web/*/https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

				
				
	<p>If you haven’t been living under a rock, you’ve probably heard that
there are different date formats in the world such as the American one
(mm/dd/yyyy) and the European one (dd.mm.yyyy). If you’re smart
enough, you’ve probably also noticed that the American one makes no
sense and is just awful. A simple conclusion that many people draw out
of this is that the European format is the best one, however I don’t
think this is true. If you’re one of these people who think so, I’m
here to (hopefully) change your mind by introducing you to a
lesser-known date format called ISO 8601.</p>
<h2 id="basics">Basics</h2>
<p>As you can see by the “ISO” part in the format’s name, it’s an actual
standard written by the International Organization for
Standardization. It defines many cool things like a way to write time
intervals, which can be useful for writing portable software, and a
calendar where the year is separated not by months but by weeks, which
is used in finances, but here we’re only interested in the basics.
Simplified, the core date format looks like this:</p>
<pre><code>yyyy-mm-dd hh:mm:ss
</code></pre><p>Yup, that’s about it. You write the year, the month, the day, and then
the time exactly like it’s done in other date formats. There’s nothing
extraordinary, so you can learn it in 2 minutes.</p>
<h2 id="why-its-better">Why it’s better</h2>
<h3 id="its-unambigous">It’s unambigous</h3>
<p>This is the main reason the standard was written and why people still
use it. Other date formats can be diffucult to tell apart. For
example, consider this date:</p>
<pre><code>02-03-04
</code></pre><p>When you read it out of context, you have absolutely no idea what’s
going on there. Is <code>02</code> here the day or the month? You just can’t know
unless the day in the date is greater than 12, in which case it just
can’t be a month:</p>
<pre><code>30-03-04
</code></pre><p>This day-month ambiguity is a really common problem, which often
occurs online. People just write down their dates in whatever date
format they know without even thinking that other people can interpret
it in different ways.</p>
<p>ISO 8601 doesn’t have this problem as it’s always obvious which part
is the day and which is the month because of the uniqueness of the
format:</p>
<pre><code>2004-03-02
</code></pre><h3 id="its-more-strict">It’s more strict</h3>
<p>While other date formats usually don’t provide strict requirements on
how to write something, ISO 8601 is an exception. Here there’s only
one correct way to write a date, which is not only useful for
computers to parse, but also helpful for humans to avoid confusion
with other formats and improve readability. Here are some of the
restrictions:</p>
<ul>
<li>The elements in the date are always separated by a hyphen. Not many
date formats use this delimiter, and this also can be useful when
using dates inside filenames as slashes are usually not accepted in
them.</li>
<li>The elements are always padded to the maximum number of digits. This
not only makes all of the dates look equally nice, but also, coupled
with other quirks of this format, allows the files with the date in
the name to be sorted just by the filename.</li>
<li>The year is always written in the full form. This makes the format
unique when written down and  eliminates <a href="https://en.wikipedia.org/wiki/Year_2000_problem">the year 2000 problem</a> in
any forms that it can take. For example, when writing down
birthdays, it always makes it obvious which century we’re talking
about.</li>
<li>The time is always written in the 24 hour format, so there can be no
confusion about what half of the day something happened in.</li>
</ul>
<h3 id="it-makes-more-sense">It makes more sense</h3>
<p>On the first glance, it seems like the European format is about as
logical as it can get - days go into months and months go into years:</p>
<pre><code>18.12.2002
---------&gt; Elements
</code></pre><p>However, this ignores a very important characteristic of numbers -
endianness. Consider a regular number, for example:</p>
<pre><code>69420
&lt;---- Digits
</code></pre><p>As you can see the digits here do the opposite of what elements do in
the European format. When the leftmost element of something is the
most valuable, we call it big endian.</p>
<p>Thus, the European format is little endian while the numbers in it are
big endian:</p>
<pre><code>18.12.2002
&lt;- &lt;- &lt;--- Digits
---------&gt; Elements
</code></pre><p>And the American format just makes no sense:</p>
<pre><code>12/18/2002
&lt;- &lt;- &lt;--- Digits
?????????? Elements
</code></pre><p>And, as you can see, ISO 8601 is completely consistent in this regard
as everything is big endian:</p>
<pre><code>2002-12-18
&lt;--- &lt;- &lt;- Digits
&lt;--------- Elements
</code></pre><p>The situation becomes even worse if you consider time because it is
big endian, like ISO 8601, thus doesn’t work with any other date
format:</p>
<pre><code>18.12.2002 23:03:59
&lt;- &lt;- &lt;--- &lt;- &lt;- &lt;- Digits
---------&gt; &lt;------- Elements

12/18/2002 23:03:59
&lt;- &lt;- &lt;--- &lt;- &lt;- &lt;- Digits
?????????? &lt;------- Elements

2002-12-18 23:03:59
&lt;--- &lt;- &lt;- &lt;- &lt;- &lt;- Digits
&lt;--------- &lt;------- Elements
</code></pre><p>If you’re still having trouble visualizing all of this in your head,
look at <a href="https://www.reddit.com/r/ISO8601/comments/ln33j2/datetime_format_by_region_visualised_v3_thanks/">this Reddit post</a>.</p>
<h3 id="its-standardized-and-actively-used">It’s standardized and actively used</h3>
<p>If you think that ISO 8601 is a silly thing that someone in their
basement made up and no one actually uses, think again because that
can’t be further from the truth:</p>
<ul>
<li>The fact that it’s standardized says at least something. Does your
favorite format has a neat several hundred page document where it’s
described in extreme detail and that is internationally recognized?
Also the standard is quite far from being dead - after being
published in 1988 it was updated in 1991, 2000, 2004, and 2019.</li>
<li>As I already mentioned, the standard is actively used in IT.
Almost everything that is used by software and somehow involves a
written numerical date format already speaks ISO 8601.</li>
<li>yyyy-mm-dd has been adapted or used since the beginning as a
national date format by many countries such as Canada, Sweden, and
Japan. See <a href="https://en.wikipedia.org/wiki/Date_format_by_country">this article</a> for more details.</li>
</ul>
<h2 id="frequently-asked-questions">Frequently asked questions</h2>
<h3 id="why-not-use-a-format-like-01-jan-2020">Why not use a format like 01-Jan-2020?</h3>
<p>It doesn’t have any of the nice features ISO 8601 has and doesn’t work
well internationally (i.e. assumes the person you’re communicating
with knows knows English). If you think the latter is not a problem,
imagine how you would feel feel if you had to read a date someone
wrote in their native language that you don’t understand:</p>
<pre><code>01-Янв-2020
</code></pre><h3 id="yyyy-mm-dd-looks-weird">yyyy-mm-dd looks weird</h3>
<p>The only reason why it does to you is because you’re not used to it.
After a little bit of practice, it’ll be even less weird than your
favorite date format.</p>
<h3 id="maybe-the-european-date-format-is-better-because-the-elements-are-in-the--order-of-relevance">Maybe the European date format is better because the elements are in the  order of relevance?</h3>
<p>First of all, the claim that the order of relevance is little endian
is quite questionable. The only situation when you can say that for
certain is when we’re talking about events occuring on a day-to-day
basis, however I can think of numerous cases when the year and the
month are more relevant:</p>
<ul>
<li>Article publication date</li>
<li>Historical event</li>
<li>Personal event that happened a long time ago</li>
<li>Someone’s birthday</li>
<li>Random database entry</li>
</ul>
<p>Second, the order of relevance is actually irrelevant. Even if the
order of relevance was this way, you’re not reading the dates out
loud, so there’s no need for them to be ordered a certain way. If
you’re not interested in the year, you just skip it and read the end
of the date just like you would do when reading time while not being
interested in the hour.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In my opinion, ISO 8601 seems clearly superior to other date formats
when it comes to international communication (such as posting things
online), and as you can see, I have enough reasons to say so. While
the format certainly has an audience, it’s unfortunate that it’s not
as big as it could be. By writing this article, I hope I made you at
least think about different date formats and be more careful when it
comes to making people understand what date you’re talking about.</p>


			</div></div>]]>
            </description>
            <link>https://kirby.kevinson.org/blog/iso-8601-the-better-date-format/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26272084</guid>
            <pubDate>Fri, 26 Feb 2021 07:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PureScript and Haskell]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26271851">thread link</a>) | @allenleein
<br/>
February 25, 2021 | https://blog.drewolson.org/purescript-and-haskell | <a href="https://web.archive.org/web/*/https://blog.drewolson.org/purescript-and-haskell">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><time datetime="2021-02-24 00:00:00 -0600">February 24, 2021</time>
  </p>

  
  

  <p>Two years ago, I starting learning <a href="https://www.purescript.org/">PureScript</a>.  I
had been intrigued by purely functional programming for some time but had failed
to learn <a href="https://www.haskell.org/">Haskell</a> once or twice. PureScript seemed to
be a kinder, gentler introduction to this world while retaining the fundamental
properties of pureness that made Haskell intriguing to me. As part of my
learning process, I rebuilt a slack bot<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> I had previously written in go.</p>

<p>Once I had learned PureScript and become more comfortable with purely functional
idioms, the next logical step seemed to be learning Haskell. I was surprised to
discover how much Haskell I already knew from learning PureScript, but core
features like laziness (PureScript is a strict language) took some getting used
to.</p>

<p>I decided to finish my Haskell learning experience by rewriting my slack bot<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>
once again, this time in Haskell. In this post I’ll compare and contrast my
experiences writing the same program in Haskell and PureScript. The application
I built was “real” enough to have some interesting design challenges. They
included:</p>

<ul>
  <li>Exposing an HTTP endpoint</li>
  <li>Parsing and generating JSON</li>
  <li>Full-text search</li>
</ul>

<p>On to the comparison!</p>



<p>Haskell is a lazy language while PureScript is a strict one. I expected this
core difference to manifest itself constantly when writing these applications,
but in reality it rarely came up. I had predicted a lot of banging my head
against the wall dealing with laziness bugs but it just didn’t happen.</p>

<p>I will say that I generally prefer PureScript being a strict-by-default
language. When laziness is required, there are plenty of ways to <a href="https://blog.drewolson.org/laziness-in-purescript">get
it</a>, but it is always explicit.</p>

<p>While not directly related to strictness, a pain point on the PureScript side
that I didn’t experience in Haskell was stack safety<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>. In PureScript, it can
often be confusing to determine if the operation you’re using is stack safe.
When these operations <em>aren’t</em> stack safe, the errors that are produced can be
confusing and hard to track down. I found myself struggling with stack safety in
PureScript far more than I struggled with laziness in Haskell.</p>



<p>A year or two ago, I would have simply said that PureScript has incredible
tooling and Haskell does not. Thanks to the amazing work on the <a href="https://github.com/haskell/haskell-language-server">Haskell
Language Server</a> project,
this gap is starting to close.</p>

<p>Regardless, PureScript still has far better tooling.
<a href="https://github.com/purescript/spago">Spago</a> is an incredible build tool that
offers many of the same features as
<a href="https://docs.haskellstack.org/en/stable/README/">Stack</a> while remaining far
more user friendly and PureScript’s <a href="https://github.com/nwolverson/purescript-language-server">language
server</a> is excellent
and easy to install.</p>

<p>However, PureScript is currently struggling on a few fronts. First, the package
ecosystem is moving from bower to a
<a href="https://github.com/purescript/registry">registry</a> hosted on Github. The
resulting registry seems to be moving along nicely and I believe the result will
be incredible for the language, but the current in-between state is unfortunate.
I am glad the core maintainers are taking their time to design this registry
well and I firmly believe that this will be a strong positive for the PureScript
community in 6-12 months.</p>

<p>Second, PureScript doesn’t have a great option for a formatter. While
<a href="https://gitlab.com/joneshf/purty">purty</a> does exist, it seems to be mostly in
maintenance mode and many of the formatting choices are frustrating for me.
Specifically, the automatic removal of blank lines within functions and the
addition of newlines for <code>let</code> assignments in <code>do</code> blocks both hamper
readability and author intent. On the Haskell side,
<a href="https://hackage.haskell.org/package/ormolu">ormolu</a> was easy to install and
“just worked”.</p>



<p>It’s not a controversial statement to say that Haskell has far more language
features than PureScript. It’s also not a new observation to say that it is
challenging to determine which of these features one should be using and what
extensions one should enable to use them. Here’s the list of default extensions
I have enabled for my project:</p>

<ul>
  <li>DataKinds</li>
  <li>DeriveGeneric</li>
  <li>FlexibleContexts</li>
  <li>FlexibleInstances</li>
  <li>GeneralizedNewtypeDeriving</li>
  <li>InstanceSigs</li>
  <li>LambdaCase</li>
  <li>MultiParamTypeClasses</li>
  <li>NamedFieldPuns</li>
  <li>OverloadedStrings</li>
  <li>ScopedTypeVariables</li>
  <li>TypeApplications</li>
  <li>TypeOperators</li>
</ul>

<p>I found Haskell’s deriving capabilities to be more powerful than PureScript and
led to reduced boilerplate, especially when creating my application monad. I
also like that Haskell’s type class instances do not require names. The names
required by PureScript add very little in terms of readability or author intent.</p>

<p>By far the biggest difference I felt between the two languages is the way they
deal with records. Again, this isn’t a new observation, but it can not be
overstated how much better PureScript’s records are than Haskell’s. Records
based on row polymorphism are a joy to work with, as is having a dedicated
syntax for creating, updating, and accessing records. GHC does have an <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0282-record-dot-syntax.rst">accepted
proposal</a>
for adding record dot syntax which will solve many of these problems, but I
think the underlying implementation based on row polymorphism will continue to
give PureScript the edge here.</p>



<p>When I first learned PureScript I compared its compile times to other statically
typed languages like Rust, Go, and Java. I found it much slower than these other
languages, though incremental rebuilds were generally quite fast. I assumed upon
moving to Haskell that the situation would be comparable or better. I was very
wrong.</p>

<p>Compilation times in Haskell are significantly worse than PureScript, often by
an order or two of magnitude when compiling a project’s dependencies. I say this
less to rag on Haskell (this seems like a challenging problem to tackle), but
more to applaud the PureScript community for the work they’ve already done on
this front.</p>



<p>Haskell has a far larger ecosystem of packages than PureScript – kind of. In
terms of Haskell and PureScript in isolation, Haskell has a vastly superior
collection of packages and the quality of these packages is generally very high.
However, PureScript has done a great job of porting over many of the best
Haskell packages.</p>

<p>Additionally, PureScript gives you access to the entire ecosystem of JavaScript
packages via FFI. While many in the community find this to be something of a
disadvantage, from a practical perspective it is fantastic. As an example, when
building full-text search for Haskell, I ended up using the full-text-search
package. It was fully featured and comprehensive, but required <a href="https://github.com/drewolson/epicbot-hs/blob/736e4a47a29f8935ecb489d3cdbeb48b738c34ca/src/Epicbot/Data/Index/SearchEngine.hs">quite a
bit</a>
of code to get working.</p>

<p>On the PureScript side, I built a <a href="https://github.com/drewolson/epicbot/blob/e7e93d2e2642ae135c92c6ff5b73b733685b550e/src/Epicbot/Index.js">simple FFI
wrapper</a>
around elasticlunr. While I understand that the JavaScript ecosystem has
packages of variable quality, it does have <em>lots</em> of package solving <em>many</em>
problems and PureScript’s FFI makes it extremely easy to leverage this giant
ecosystem in a safe way.</p>



<p>For my PureScript application I chose the
<a href="https://github.com/cprussin/purescript-httpure">HTTPure</a>. It was light-weight
and easy to use while feeling idiomatic. This was a relatively simple choice
because there are few options for server-side frameworks within the PureScript
ecosystem that included the features I needed (specifically middleware).</p>

<p>On the Haskell side, the choice of web framework was more complicated. I wanted
something small and light-weight, but with the ability work within my custom
monad stack for my application. I ended up using <a href="">scotty</a>, but the default
middleware solution doesn’t operate within your application’s monad stack, so I
needed to explicitly provide middleware-like-functions for <a href="https://github.com/drewolson/epicbot-hs/blob/736e4a47a29f8935ecb489d3cdbeb48b738c34ca/src/Epicbot/Web/Router.hs#L33-L34">each
endpoint</a>
in my router.</p>

<p>At the end of the day, this was mostly a wash between languages, but I expected
the Haskell ecosystem to be far more mature in the backend HTTP service space.</p>



<p>To deploy my PureScript application, I used
<a href="https://github.com/vercel/ncc">ncc</a>. While this required that I had <code>node</code>
available in my deployment environment, it made everything else easy. The <code>ncc</code>
tool produced a single, self-contained JavaScript file that included all of the
application code along with required dependencies. I then simply <code>scp</code>‘d this to
my deployment environment and ran it with <code>node</code>.</p>

<p>On the Haskell side, I used stack’s docker support to build my application’s
executable within a container that matches my deployment environment (debian),
and then shipped the resulting executable via <code>scp</code> as well. The executable was
completely self-contained.</p>

<p>Overall, both approaches felt equivalent in terms of ease. On the PureScript
side, it is a bit frustrating to need <code>node</code> within the deployment environment.
On the Haskell side, there was the added complication of having to use docker
for cross-compilation. Overall, though, both experiences were reasonably nice.</p>



<p>In reading over this post, I worry that it feels like I’m picking on Haskell –
I’m absolutely not. I’m very aware that PureScript is <em>heavily</em> influenced by
Haskell and is standing the shoulders of giants. PureScript was able to learn
from some of the mistakes of Haskell and make choices about intentional
departures from the Haskell ecosystem that better fit the intended use cases of
PureScript.</p>

<p>I found the experiences of learning and using both Haskell and PureScript very
rewarding. I will admit to being surprised at how well PureScript compared to
Haskell in the server-side HTTP space, given that its primary focus is currently
on the front end. I think both languages have a bright future and I’m excited to
follow their continued development.</p>



</div>



    </div></div>]]>
            </description>
            <link>https://blog.drewolson.org/purescript-and-haskell</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271851</guid>
            <pubDate>Fri, 26 Feb 2021 06:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fireside Friday, February 26, 2021]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26271642">thread link</a>) | @35_candelas
<br/>
February 25, 2021 | https://acoup.blog/2021/02/26/fireside-friday-february-26-2021/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/02/26/fireside-friday-february-26-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Fireside this week, but next week we are diving into our long awaited series on pre-modern textile production, though we will be particularly focused on the most important clothing fibers in the Mediterranean world, wool and linen (rather than, say, silk or cotton).  </p>



<figure><img data-attachment-id="6346" data-permalink="https://acoup.blog/pxl_20210220_033037734-mp_/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1613773838&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;3423&quot;,&quot;shutter_speed&quot;:&quot;0.066683&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="pxl_20210220_033037734.mp_" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/02/pxl_20210220_033037734.mp_.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Trusty Research Assistant Oliver helping me find the right volume of the Journal of Military History.<br>I am running short of pictures of me by the fireplace, but I thought this might serve that function.</figcaption></figure>



<p>For this week’s <strong>musing</strong>, I want to expand on an issue that came up in the discussion in the universal warrior series, which was the question of changing <strong>lethality</strong> in warfare.  Just how likely were you to <em>die</em> on the battlefield in different eras, and how did changing offensive, defensive and medical technologies alter that balance?  One assumption I see frequently is that since the advent of modern medicine has made serious infections survivable, it must follow that basically all wounds were fatal in the pre-modern period.  Of course balanced against this is the relatively higher lethality of modern weapons, which strike with much greater energies and in consequence do much more damage to the body.  So where does the answer lie?</p>



<p>(Just a quick reminder that these musings are just that: me talking through an idea and to some degree thinking out loud with the information I have available.  Consequently, you should take any of the conclusions here as preliminary; whatever level of confidence you place in my normal ‘Collections’ ramblings, a ‘musing’ is probably at least a half-a-notch lower in the ‘epistemological certainty’ scale.)</p>



<p>Unsurprisingly, it is complex.  The first question we need to ask is what kind of mortality we are interested in.  If we include non-combat related disease deaths, those will swamp combat related deaths, but there are problems with this.  Estimates for disease-losses in pre-industrial armies (some of these figures compiled in Rosenstein, <em>Rome at War</em> (2004), 130-2) vary tremendously; late nineteenth century rule of thumb held that disease casualties would be four times battle deaths; but in the American Civil War and the Boer War they were only twice battle deaths and in the Imperial Japanese Army during the Russo-Japanese War, they were actually four times <em>less</em> than battle deaths.  Basic sanitation, it turns out, matters a lot here.  The next problem is that here our question needs to be about <em>excess</em> deaths because of course some level of disease is prevalence in the larger society; that is even harder to calculate, but if we fail to adjust for that, all we are doing is measuring the size of armies, since the background disease death rate in the pre-modern world was so elevated.  In this case, I think it is best to remove non-combat disease deaths from the equation, since the concern here was the experience of battle, so we should limit ourselves to violent death in war.</p>



<p>Except that brings us to the next question, which is the word ‘battle.’  Are we limiting ourselves to <em>battles</em> or not?  If we want to consider warfare as a totality, then the evidence is fairly clear that violent death <em>per capita</em> (so adjusting for population growth) decreases as a function of time (on this, note A Gat, <em>War in Human Civilization</em> (2006) rather than S. Pinker, <em>Better Angels of Our Nature</em> (2011).  Yes, I am aware that the former has spoken highly of the latter’s book, but frankly the more careful and cautious argument of <em>War</em> is to be preferred).  This decline isn’t necessary a smooth curve, but seems to move in steps with lots of variation within those steps.  Lifetime violent mortality among early hunter-gatherers and other non-state peoples seems to have been on the order of 15% (with some examples above 25% generally.  These deaths were concentrated among males; a 15% overall rate of violent mortality might mean a 25% rate among males and only a 5% rate among females).  For pre-industrial agrarian state-societies, that figure falls to single-digit percentages, often very low single digits, but perhaps sometimes as high as 5-10% (some estimates for the military mortality of the Romans during the worst years of the Second Punic War run up to 20% of the adult male population, so c. 7% of the total population; I think this is a smidge too high and perhaps 5% is more correct).  In post-nuclear, post-industrial states where conventional war is often sharply constrained by deterrence and the industrial revolution means that returns to trade and investment are higher than returns to war (the reverse being true previously) that figure often falls to fractions of a percent, but again with potentially wide variance in the event of rare but extremely destructive wars.</p>



<p>But – and you knew there was a but coming – but that absolutely massive hunter-gatherer lethality level isn’t generally in <em>battles</em>.  The bulk of those deaths occur during very one-sided ambushes and raids, directed at individuals who are effectively incapable of fighting back.  So we might ask the question a different way: <strong>what was the chance of dying in a particular <em>battle</em> at a given point of time</strong>?  Once again, that’s complicated, in part because reliable casualty statistics for <em>losing</em> armies are often frustratingly rare even well into the modern period.  But there are a few observations we can make in terms of how technology might have impacted these changes.  First, in both West Africa and North America, we can observe that the introduction of gunpowder so radically increased the lethality of open battles that tactics shifted entirely away from them.  Now, this might not be surprising in North America, where the battles in question were of the first-system type – lower lethality missile exchanges when the raid or the ambush had failed .  But in West Africa, the battles in question were often state-on-state and concluded with shock infantry engagements (with a notable use of blunt weapons, since part of the goal in battle was for the victor to take many captives; on this see Lee, <em>Waging War</em>, ch. 8), yet even in that context the increased lethality of gunpowder meant that such battles had to be discontinued in a context where the demographics of the underlying society simply couldn’t support massive losses.  <strong>So the strong suggestion here is that gunpowder weapons represented a significant increase not merely in the lethality of the weapons but of the battles themselves.</strong></p>



<p>We might also compare individual battles or campaigns.  Rosenstein (<em>op. cit.</em>) estimates that for the Romans from 200 to 168 BCE (the period of our most sustained data, due to Livy), the Roman battle-death rate was very roughly 8-9% of soldiers engaged.  That accords fairly well with the general 5-15% rule of thumb often posited for hoplite combat in Classical Greece (<a href="https://www.reddit.com/r/AskHistorians/comments/934hfj/what_was_the_casualty_rate_for_battles_between/">but note the difficulties with those figures</a>).  To compare with, say, the Battle of Austerlitz (1805), there the French had c. 75,000 men and the coalition c. 90,000 and the former took c. 9,000 casualties to the latter’s c. 36,000; so out of 165,000 men engaged, 45,000 had become casualties (27%); it’s hard to say exactly how many <em>died</em> because the looser’s casualties in Napoleonic battles often aren’t broken out clearly between dead, captured and injured (because the loser is not in the position to count the field).  At least on the French side, the wounded outnumbered the dead roughly 5-to-1.  At Waterloo, where it is the coalition who won and thus have the more precise figures, British wounded outnumbered dead about 3-to-1, while Prussian wounded outnumbered dead by 3.5-to-1.  At Gettysburg (1863), with 104,256 Union and 75,000 Confederate forces engaged, there were 23,055 union casualties (3,155 killed, a WIA-to-KIA ratio of 4.6-to-1) and perhaps 23,231 confederate losses (4,708 killed, a WIA-to-KIA ratio of 1.2-to-1); about 25% of men engaged had become casualties of some sort, about 4-5% of those engaged had been killed.  I’d suggest that the flurry of figures there suggests, broadly, casualties moving very broadly within the same basic range as a percentage of men deployed.  Our ability to get a sense of the impact of wounds is complicated by the fact that pre-gunpowder sources tend not to give solid numbers for the wounded at all.</p>



<p>Now the question is how does the industrial revolution and antibiotics change this?  Well, for some World War I examples (post-industrialization, pre-widespread antibiotics), at the First Battle of the Marne (1914), roughly 1 million British and French troops had squared off against 900,000 Germans; both sides took around a quarter of a million losses (so c. 25%) of which c. 149,400 were killed (7.8%).  At the First Battle of the Masurian Lakes (also 1914), 215,000 Germans met 146,000 Russians with 10,000 German losses and 70,000 Russian WIA or KIA and another 30,000 prisoners, so roughly 30% casualties, but unclear what slice of those were deaths.  At Kolubara (1914), 400,000 Serbs faced off against 450,000 Austrian troops, with 405,000 total casualties, of which 52,000 were deaths (the WIA to KIA ratio was 5-to-1).  I’ve tried to pull major battles in 1914 because the long battles of the trench stalemate are difficult to generalize figures from as units rotate in and out.  Taking a longer view, some roughly eight million Frenchmen served in the first world war, of which 1,150,000 died in combat (not counting disease), suggesting a combat mortality rate over the whole war of a <em>staggering</em> (by modern standards) 12.5% (though note above that many non-state societies lived in a situation of WWI casualty levels <em>in every generation</em>).</p>



<p>(Update: note that the casualty figures here include KIA, WIA and MIA, so I’ve obtained the WIA-to-KIA ratio by by directly comparing those two figures, without the MIAs.  That seemed to have been confusing some folks in the comments.)</p>



<p>For post-industrialization, post-antibiotics, options are narrower.  American, British and Commonwealth forces had good access to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/02/26/fireside-friday-february-26-2021/">https://acoup.blog/2021/02/26/fireside-friday-february-26-2021/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/02/26/fireside-friday-february-26-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271642</guid>
            <pubDate>Fri, 26 Feb 2021 05:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Katana graph have you seen the performance numbers?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26271619">thread link</a>) | @jmatthews
<br/>
February 25, 2021 | https://katanagraph.com/demo | <a href="https://web.archive.org/web/*/https://katanagraph.com/demo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://katanagraph.com/demo</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271619</guid>
            <pubDate>Fri, 26 Feb 2021 05:22:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercal, YAML, and Other Horrible Programming Languages]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 164 (<a href="https://news.ycombinator.com/item?id=26271582">thread link</a>) | @sidcool
<br/>
February 25, 2021 | https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/ | <a href="https://web.archive.org/web/*/https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: markdown--><h2 id="programrejectedformentalhealthreasons">PROGRAM REJECTED FOR MENTAL HEALTH REASONS</h2>
<p>In 1972, two students learning FORTRAN came up with a fantastic new programming language called INTERCAL.  INTERCAL is a bit unusual. For example, single quotes are called <em>sparks</em>, and double quotes are called <em>rabbit ears</em>, less than (&lt;) is an <em>angle</em>, and a dash (-) is a <em>worm</em>.  This makes the manual read like a word puzzle combined with an extended in-joke:</p>
<blockquote>
<p>One final comment about sparks and rabbit-ears; if the next character in the program is a spot, as often happens because onespot variables are common choices for operands, a spark and the following spot can be combined into a wow (!). - <a href="http://www.catb.org/~esr/intercal/ick.htm">INTERCAL Manual</a>.</p>
</blockquote>
<p>The compiler errors are where the authors got genuinely creative. Errors include <code>VARIABLES MAY NOT BE STORED IN WEST HYPERSPACE</code> for accessing an array incorrectly, <code>IT CAME FROM BEYOND SPACE</code> for invalid control flow, <code>PROGRAM REJECTED FOR MENTAL HEALTH REASONS</code> for threading issues, <code>I HAVE NO FILE AND I MUST SCREAM</code> for file not found, and <a href="http://www.catb.org/~esr/intercal/ick.htm#Errors">many many more</a>.</p>
<p>Yes, this is a parody language, and reading the manual, you get the sense that no one has yet had as much fun writing technical documentation as Lyon and Woods did writing this.</p>
<p>The language itself looks less fun.  Here is <a href="http://www.rosettacode.org/wiki/Category:Intercal">Hello World</a>:</p>
<pre><code>       NOTE THIS IS INTERCAL
       PLEASE ,1 &lt;- #5
       DO ,1 SUB #1 &lt;- #54
       DO ,1 SUB #2 &lt;- #192
       DO ,1 SUB #3 &lt;- #136
       PLEASE ,1 SUB #4 &lt;- #208
       DO ,1 SUB #5 &lt;- #98
       DO COME FROM (1)
       DO READ OUT ,1
(2)    DO ,1 SUB #1 &lt;- #134
(1)    PLEASE ABSTAIN FROM (2)
</code></pre>
<p>One of the exciting innovations of INTERCAL is the <code>COMEFROM</code> <a href="https://en.wikipedia.org/wiki/COMEFROM#Examples">instruction</a>, seen here in a variant of BASIC.<sup><a href="#fn1" id="fnref1">[1]</a></sup></p>
<pre><code>10 COMEFROM 40
20 INPUT "WHAT IS YOUR NAME? "; A$
30 PRINT "HELLO, "; A$
40 REM
</code></pre>
<p>A <code>COMEFROM</code> anywhere in a program can grab control flow from the line you are reading. And in some implementations, if many <code>COMEFROM</code>'s reference the same line, execution splits off in each direction.</p>
<p>A <code>COMEFROM</code> is the inverse of a <code>GOTO</code> statement with multi-threading thrown in. It breaks the mental model of imperative execution where each line's evaluation leads to the next line. The idea that you can simulate its execution in your head, line by line, is fundamental to imperative programming and <code>COMEFROM</code> attempts to break that model.</p>
<h2 id="variablesmaynotbestoredinwesthyperspace">VARIABLES MAY NOT BE STORED IN WEST HYPERSPACE</h2>
<p>At Twitter, they have a giant monorepo with lots of services in it.  And somebody at Twitter wanted to know which language was most prevalent.  Which language does Twitter use the most?</p>
<p>Java came in 3rd, and Scala came in 2nd. But 1st was a surprise.  The number one programming language used at Twitter was YAML.<sup><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p>YAML usually doesn't feel like a programming language to me.  The file I'm currently writing in is in markdown with some YAML at the top to set the title and associated fields:</p>
<pre><code>title: INTERCAL, YAML, And Other Horrible Programming Languages
author: Adam
</code></pre>
<p>Nothing executes this YAML. It only offers some information to the blogging platform. But I don't think that is the type of YAML that made up the bulk of config at Twitter.</p>
<p>I suspect a lot of it was build and deployment scripts in the form of YAML. It was the type of configuration that encoded the control flow of some external system.  YAML like that lives in this grey zone between declarative configuration and a full-blown programming language.</p>
<p>I'll show you what I mean. Let's look at an example from <a href="https://github.com/koalaman/shellcheck/blob/master/.travis.yml">shellcheck</a>'s build script:</p>
<pre><code>language: shell
os: linux

services:
  - docker
</code></pre>
<p>That seems like straight-forward config.</p>
<pre><code>jobs:
  include:
    - stage: Build
      env: BUILD=linux
      workspaces:
        create:
          name: ws-linux
          paths: deploy
</code></pre>
<p><code>create</code>, in the above, is starting to seem a bit more like execution. Let's continue.</p>
<pre><code>      script:
        - ls -la ${CASHER_DIR}/ || true
        - tar -xvf ${CASHER_DIR}/ws-osx-fetch.tgz --strip-components=5
        - ls -la deploy
        - ./.github_deploy
</code></pre>
<p>Now the YAML has just devolved into specifying how to execute a grab bag of commands.  We haven't seen control-flow yet, but it's coming.</p>
<pre><code>      if: type = push
      script:
        - source ./.multi_arch_docker
        - set -ex; multi_arch_docker::main; set +x
</code></pre>
<p>There we go, branching. It's an if statement in a YAML file!</p>
<p>That was for TravisCI but this isn't TravisCI, or CI specific.  Here is a simple example from Ansible:</p>
<pre><code>- hosts: all
  tasks:
    - include: foo.yml
      when: something == "foo"
    
    - include: bar.yml
      when: something == "bar"
</code></pre>
<p>Here is GitHub Actions:</p>
<pre><code>steps:
 - name: Step 7
   if: ${{ github.event_name == 'pull_request' &amp;&amp; github.event.action == 'unassigned' }}
   run: echo This event is a pull request that had an assignee removed.
</code></pre>
<p>Here is part of a Grafana <a href="https://github.com/grafana/helm-charts/blob/main/charts/grafana/templates/deployment.yaml">Helm Chart</a>:</p>
<pre><code>
{{ if (or (not .Values.persistence.enabled) (eq .Values.persistence.type "pvc")) }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ template "grafana.fullname" . }}
  namespace: {{ template "grafana.namespace" . }}
  labels:
    {{- include "grafana.labels" . | nindent 4 }}
{{- if .Values.labels }}
{{ toYaml .Values.labels | indent 4 }}
{{- end }}
{{- with .Values.annotations }}
  annotations:
{{ toYaml . | indent 4 }}
{{- end }}
</code></pre>
<p>I think this is a problem. Writing control flow in a config file is like hammering in a screw. It's a useful tool being used for the wrong job<sup><a href="#fn3" id="fnref3">[3]</a></sup>.</p>
<p>How did we get to this world of little programming languages embedded into YAML? Is calling something configuration just less scary? And if so, is a c++ program just config you give to gcc?</p>
<p>Did things ever get this complicated in XML times?</p>
<p>It turns out they did:</p>
<pre><code>&lt;xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform"&gt;
  &lt;xsl:output method="text" omit-xml-declaration="yes" /&gt;

  &lt;xsl:template match="/"&gt;
    &lt;xsl:call-template name="FizzBuzz"&gt;
      &lt;xsl:with-param name="i" select="1" /&gt;
    &lt;/xsl:call-template&gt;
  &lt;/xsl:template&gt;

  &lt;xsl:template name="FizzBuzz"&gt;
    &lt;xsl:param name="i" /&gt;
    &lt;xsl:choose&gt;
      &lt;xsl:when test="($i mod 3) = 0 and ($i mod 5) = 0"&gt;FizzBuzz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:when test="$i mod 3 = 0"&gt;Fizz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:when test="$i mod 5 = 0"&gt;Buzz&amp;#xa;&lt;/xsl:when&gt;
      &lt;xsl:otherwise&gt;&lt;xsl:value-of select="$i" /&gt;&lt;xsl:text&gt;&amp;#xa;&lt;/xsl:text&gt;&lt;/xsl:otherwise&gt;
    &lt;/xsl:choose&gt;
    &lt;xsl:if test="$i &amp;lt; 100"&gt;
      &lt;xsl:call-template name="FizzBuzz"&gt;
        &lt;xsl:with-param name="i" select="$i + 1" /&gt;
      &lt;/xsl:call-template&gt;
    &lt;/xsl:if&gt;
  &lt;/xsl:template&gt;
&lt;/xsl:stylesheet&gt;
</code></pre>
<p>That is <code>FizzBuzz</code> in <a href="https://gist.github.com/JustinPealing/6f619a23729720a9c14d9917201028c8">XSLT</a>. I assume it was written in jest, but in many ways, XML and XSLT are better than an ad-hoc YAML based scripting language. XSLT is a documented and standardized thing, not just some ad-hoc format for specifying execution.</p>
<p>It burns my eyes to look at it, but at least XSLT was intended to be used as a programming language. That is something we can't say about YAML or INTERCAL.</p>
<p>The problem with these languages embedded into YAML is they are all one-off implementations.  TravisCI conditionals have a TravisCI specific syntax, usage, and features. You can't use Travis's <code>concat</code> function or conditional regex in the YAML configuration for your ansible playbooks.</p>
<p>In a vague way, this YAML problem is like the <code>COMEFROM</code> problem. If you know yaml, you can't just open a .yml file and start reading file line by line.  You need to understand how the configuration controls the execution of the specific system it's for.  And that is hard.</p>
<h2 id="ihavenofileandimustscream">I HAVE NO FILE AND I MUST SCREAM</h2>
<p>The line between configuration and programming languages is not some bright dividing line. It's easy to slowly drift into adding programming language constructs to a config file. Before you know it, you have a full unspecified programming language embedded in the interpretation of your config file.</p>
<p>That is the worst of both worlds, and so much YAML seems to drift into this area.</p>
<p>I like YAML more than XML, but for control flow, you know what would be better than YAML? Anything else!  Maybe even INTERCAL? I mean, how bad could a joke programming language be?</p>
<pre><code>(100)  PLEASE NOTE THIS IS THE FIZZBUZZ FUNCTION	

	PLEASE NOTE: IS THE INPUT DIVISIBLE BY #15?
	DO .1 &lt;- .100	
	DO .2 &lt;- #15
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (130) NEXT
	
	PLEASE NOTE NUMBER IS NOT DIVISIBLE BY #15 =&gt; CHECK IF DIVISIBLE BY #3
	DO .2 &lt;- #3
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (110) NEXT

	PLEASE NOTE NUMBER IS NOT DIVISIBLE BY #3 =&gt; CHECK IF DIVISIBLE BY #5
	DO .2 &lt;- #5
	DO (2030) NEXT
	PLEASE NOTE: is .4 (remainder) == 0?
	DO .4 &lt;- '?"'.4~.4'~#1"$#1'~#3
	DO (120) NEXT
	
	PLEASE NOTE NUMBER IS REGULAR =&gt; RETURN THE INPUT
	DO .101 &lt;- .100
	DO (199) NEXT

(110)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #3 =&gt; RETURN FIZZ
	DO .101 &lt;- #61440
	DO (199) NEXT


(120)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #5 =&gt; RETURN BUZZ
	DO .101 &lt;- #45056
	DO (199) NEXT

(130)	DO (111) NEXT
	DO FORGET #1
	PLEASE NOTE NUMBER IS DIVISIBLE BY #15 =&gt; RETURN FIZZ-BUZZ
	DO .101 &lt;- #64256
	DO (199) NEXT

(111)	DO RESUME .4
	
(199)	DO FORGET #1
	DO RESUME #1
</code></pre>
<p>Oh God.</p>
<p>Well, ok, maybe not INTERCAL but anything else. <sup><a href="#fn4" id="fnref4">[4]</a></sup><sup><a href="#fn5" id="fnref5">[5]</a></sup></p>
<hr>
<section>
<ol>
<li id="fn1"><p><code>COME FROM</code> was introduced in INTERCAL-90 and not part of the orginal implementation (INTERCAL-72). <code>I HAVE NO FILE AND I MUST SCREAM</code> was also introduced in INTERCAL-90. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>See my interview with <a href="https://www.se-radio.net/2019/08/episode-375-gabriel-gonzalez-on-configuration/">Gabriel Gonzalez on Configuration</a> at Software Engineering Radio. <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p>Ansible and Helm use templating languages built on top of YAML, which is better than embedded control flow, but I think the point still stands. <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p>Practically, you may have to use tools that encode a DSL into config, but you can use them while recognizing that we can do better.  I think something like <a href="https://dhall-lang.org/#">Dhall</a> for complicated config and something like <a href="https://www.pulumi.com/">pulumi</a> for complex configuration as code should be where we aim for as an industry. <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p>The …</p></li></ol></section></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/">https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/</a></em></p>]]>
            </description>
            <link>https://blog.earthly.dev/intercal-yaml-and-other-horrible-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271582</guid>
            <pubDate>Fri, 26 Feb 2021 05:17:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The American dream is now in Denmark]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26271326">thread link</a>) | @miles
<br/>
February 25, 2021 | https://the.ink/p/the-american-dream-is-now-in-denmark | <a href="https://web.archive.org/web/*/https://the.ink/p/the-american-dream-is-now-in-denmark">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Welcome to The.Ink, my newsletter about money and power, politics and culture. If you’re joining us for the first time, hello! Click the orange button below to get this in your inbox, free. Please consider becoming a paid subscriber to support this work. </em></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F172dc95c-b2cf-47cc-87f7-d84977ac1b42_400x450.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F172dc95c-b2cf-47cc-87f7-d84977ac1b42_400x450.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/172dc95c-b2cf-47cc-87f7-d84977ac1b42_400x450.jpeg&quot;,&quot;height&quot;:450,&quot;width&quot;:400,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18992,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Djaffar Shalchi is a very rich man. Like many in his class, he “gives back.” But in one important way he differs from many philanthropists. He believes that philanthropy is no substitute for taxation and a properly functioning, welfare-providing government.</p><p>I recently talked with the Danish construction entrepreneur and <a href="https://humanact.org/">founder of Human Act</a> about becoming a traitor to his class.</p><p>But first: I will be doing my regular live chat/webinar/Zoom-where-it-happens thing today at 1 p.m. New York time, 10 a.m. Pacific time, and 6 p.m. London time. If you’re new to The Ink, they’re really fun and engaging. We talk about the world and we scheme hope. It’s great. If you haven’t yet, subscribe today to join us. Subscribers will get login details beforehand.</p><p><em>Subscribing to The Ink is the best way to keep it free and open to all, and to support independent media that hopefully makes you think and enlivens your conversations. I appreciate your support for this undertaking.</em></p><h3>“Wealth is like manure”: a conversation with Djaffar Shalchi</h3><p><strong>ANAND: You recently started an organization called Millionaires for Humanity. This raises the question: Do you think most millionaires and billionaires are currently for humanity?</strong></p><p><strong>DJAFFAR: </strong>If we millionaires are going to be “for humanity,” we have got to go beyond philanthropy and recognize that we need to be taxed. No matter how generous and smart we think we are in our private giving, unless we shift from trying to minimize our taxes to advocating to be taxed more, we are not living up to being “for humanity.” Are most millionaires there yet? No. I do feel a shift is starting, though. Please keep encouraging us — and keep pressuring us, too.</p><p><strong>ANAND: You have an interesting personal background that led you to this place of advocating for structural change as a very rich person. Tell us about your journey.</strong></p><p><strong>DJAFFAR: </strong>I am one of those who gets highlighted by the media as a “self-made man.” I am told that I fit the storyline: I am an immigrant son of a single mother from Iran; while my mum cleaned in hotels, I studied hard, worked hard, and became a successful entrepreneur. I rose to be a multimillionaire — the American dream, except in Denmark!</p><p>It has always been evident to me, however, that I have not risen all by my own efforts: that I am&nbsp;<em>not</em>&nbsp;a “self-made man,” that the&nbsp;<em>welfare state</em>&nbsp;made me. Without the creche care and schooling and health care I received, I could not have flourished. And without Denmark’s strong public services, neither could my business.</p><p><strong>ANAND: What was your epiphany, if any, in realizing that very rich people like yourself need to be reined in rather than asked to give back?</strong></p><p><strong>DJAFFAR: </strong>I knew it as a working-class immigrant child. Later, when I became rich and got involved in philanthropy across the world, I witnessed that while philanthropy can help ameliorate tough times for some people, it is only in collective action through government policy that we can we achieve a fair society and shared prosperity. All the data bear out what I witnessed. The way I put it to my fellow rich people is this: there is a title that is more noble and consequential than “Generous Philanthropist,” and that title is “Happy Taxpayer.”</p><p><strong>ANAND: Since you’re speaking as a rich guy on these topics, give us a sense of how rich we’re talking about, without disclosing any of your account numbers or PINs.</strong></p><p><strong>DJAFFAR: </strong>I made many millions of dollars, and I made them relatively young. I have three places I call home. I never worry about money. DM for my PIN.</p><p><strong>ANAND: What are the most significant structural changes that you think are necessary to attack wealth and income inequality worldwide and in certain countries in particular?</strong></p><p><strong>DJAFFAR: </strong>We need a wealth tax everywhere. We need quality free health and education for everyone, everywhere. We need a green new deal everywhere. There’s no country where this is impossible, and no country where this is not necessary.</p><p><strong>ANAND: There has been a lot of recent discussion of a wealth tax in America, but even the most ambitious of the serious proposals, by Senators Bernie Sanders and Elizabeth Warren, are quite far from being “erosive” wealth taxes. In other words, even at a top rate of 8 or 10 percent, most billionaires’ fortunes would grow rather than shrink each year under their plans. Do you think we need to go further and have an erosive wealth tax?</strong></p><p><strong>DJAFFAR: </strong>You make an excellent point that even if there is a wealth tax, rich people can make so much from the interest on their capital that we will still keep getting richer, just less fast. The most important thing now is to initiate the wealth tax because there’s so much nonsense talk about how it “cannot” be done. Of course&nbsp;it can. The only way to move on from that debate is to bring a wealth tax in&nbsp;<em>now</em>. Someone has to pay for the recovery from Covid-19, in which everyone except the rich has lost. Are we multimillionaires going to say it’s not us? Are we going to be such shmucks, such losers, and say no?</p><p><strong>ANAND: You live in Denmark. Many Americans, especially people who aspire to business success like you’ve had, believe that if we were to adopt policies like Denmark’s, capitalism would die, and gulags would sprout across the land. Are they correct?</strong></p><p><strong>DJAFFAR: </strong>They could not be more wrong.&nbsp;In real life, contrary to the Hollywood tale, kids are more likely to achieve the American dream in Denmark than in America. America is not a beacon to the world on how to run an economy. Scandinavia has a much more impressive economic record than the US and is much more innovative. Sorry, my American friends — we’re not just fairer than you. We’re doing&nbsp;<em>better</em>&nbsp;by being so.</p><p><strong>ANAND: In America, wealthy individuals and businesses lobby for a threadbare safety net to pay less in taxes. But this creates a complication. It puts the onus on companies to figure out healthcare for their employees, to make these awful life-or-death decisions about pensions and maternity leave and the like. And what I often hear from friends who are in business in Europe is how much easier it is to do business when you’re not making all these societal decisions about your employees’ well-being and health and life and children as part of your operation.</strong></p><p><strong>DJAFFAR: </strong>Absolutely. And that’s just&nbsp;part&nbsp;of it. Social stability, low crime, a well-educated population, and great infrastructure are good for business. As we put it, the right thing to do is also the smart thing to do. We could also put it this way: the mean way to run an economy is also the dumb way to run an economy.</p><p><strong>ANAND: Should billionaires exist?</strong></p><p><strong>DJAFFAR: </strong>In a well-regulated, well-managed, and thriving economy without monopolies, they wouldn’t. Wealth is like manure: spread it, and it makes everything grow; pile it up, and it stinks.</p><p><strong>ANAND: You advocate going “beyond philanthropy” and doing real structural change. I wonder what you think of the argument that philanthropy isn’t merely inadequate. That it can be actively part of the problem, by buying off a certain amount of anger, laundering reputations, and intensifying the plutocrats’ stranglehold over public conversation and power?</strong></p><p><strong>DJAFFAR: </strong>You make a vital point. Right now, philanthropy is treated as an alternative to structural change. I focus on structural change, and I am working to persuade other multimillionaires to join me, advocating for a wealth tax on people like us. I still do philanthropy, but I know that it is no solution. You know, the thrill of seeing your nameplate on one school or a hundred schools is pretty empty in the end, compared to the thrill that we will all feel when&nbsp;<em>every child in the world</em>&nbsp;goes to a good school. Philanthropy is just so&nbsp;unambitious.</p><p><strong>ANAND: One of the features of the neoliberal age is that politicians, even left-leaning ones, are reluctant to use the language of “I welcome their hatred” that President Franklin Roosevelt used long ago. Do you think we need a little more class warfare, as it’s sometimes derisively called, rather than less of it?</strong></p><p><strong>DJAFFAR: </strong>Warren Buffet was right when <a href="https://www.nytimes.com/2006/11/26/business/yourmoney/26every.html">he said</a>, “There’s&nbsp;class warfare, all right, but it’s my class, the rich class, that’s making war, and we’re winning.”&nbsp;We set up <a href="https://www.millionairesforhumanity.com/">Millionaires for Humanity</a> as an international network to help more millionaires move across from the dark side.</p><p><strong>ANAND: Explain Elon Musk to me in one sentence.</strong></p><p><strong>DJAFFAR: </strong>There’s not much “there” there, is there?</p><p><em>Djaffar Shalchi is an entrepreneur from Denmark and founder of <a href="https://www.millionairesforhumanity.com/">Millionaires for Humanity</a>, a network of wealthy people who advocate for raising taxes on wealthy people. This interview was edited and condensed for clarity. </em></p><p><em>Thank you for reading this interview from The Ink. If you like what we do and want more of it, consider supporting our work by subscribing to The Ink. Every single subscriber helps make this enterprise possible.</em></p><h6>Photo: humanact.org</h6></div></div>]]>
            </description>
            <link>https://the.ink/p/the-american-dream-is-now-in-denmark</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271326</guid>
            <pubDate>Fri, 26 Feb 2021 04:19:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Redbean – Single-file distributable web server]]>
            </title>
            <description>
<![CDATA[
Score 1624 | Comments 207 (<a href="https://news.ycombinator.com/item?id=26271117">thread link</a>) | @jart
<br/>
February 25, 2021 | https://justine.lol/redbean/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/redbean/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://storage.googleapis.com/justine/redbean/redbean.png" width="84" height="84">
<h2>
  <big>redbean</big><br>
  <small>single-file distributable web server</small>
</h2>

<p>
  redbean makes it possible to share web applications that run offline
  as a
  single-file <a aria-label="Actually Portable Executable" href="https://storage.googleapis.com/justine/ape.html">αcτµαlly
  pδrταblε εxεcµταblε</a> zip archive which contains your assets. All
  you need to do is download the <code>redbean.com</code> program below,
  change the filename to .zip, add your content in a zip tool like
  Windows 10 or InfoZIP, and change the extension back to .com.

</p><p>
  redbean can serve 1 million+ gzip encoded responses per second on a
  cheap personal computer. That performance is thanks to zip and gzip
  using the same compression format, which enables kernelspace copies.
  Another reason redbean goes fast is that it's a tiny static binary,
  which makes fork memory paging nearly free.

</p><p>
  redbean is also easy to modify to suit your own needs. The program
  itself is written as a single .c file.

</p><p>
  <strong>
    download
    &nbsp;
    <img src="https://storage.googleapis.com/justine/redbean/linux.png" title="Linux" width="28" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/windows10.png" title="Windows" width="32" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/macos.png" title="MacOS" width="26" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/freebsd.png" title="FreeBSD" width="28" height="32">
    <img src="https://storage.googleapis.com/justine/redbean/openbsd.png" title="OpenBSD" width="34" height="32">
    <img src="https://justine.lol/redbean/NetBSD.png" title="NetBSD" width="30" height="30">
  </strong>
  <br>

</p><p>
  <a href="https://justine.lol/redbean/redbean-2021-02-27.com">redbean-2021-02-27.com</a><br>
  <small>200kb - PE+ELF+MachO+ZIP+SH</small>

</p><p>
  <a href="https://justine.lol/redbean/redbean-2021-02-27.com.dbg">redbean-2021-02-27.com.dbg</a><br>
  <small>2.2m - ELF debugger data (optional)</small>

</p><p>
  <a href="https://github.com/jart/cosmopolitan/blob/master/tool/net/redbean.c">redbean.c</a><br>
  <small>source code</small>

</p><p>
  <strong>
    features
  </strong>
  </p><ul>
    <li>HTTP v1.1
    </li><li>Content-Encoding
    </li><li>Range / Content-Range
    </li><li>Last-Modified / If-Modified-Since
  </li></ul>

<p>
  <strong>
    installation
  </strong>
  </p><pre>curl https://justine.lol/redbean/redbean-latest.com &gt;redbean.com
chmod +x redbean.com
bash -c './redbean.com -vv'
</pre>

<p>
  <strong>
    usage
  </strong>
  </p><pre>echo '&lt;b&gt;hello&lt;/b&gt;' &gt;index.html
zip redbean.com index.html
./redbean.com -vv
curl -v http://127.0.0.1:8080/index.html
</pre>

<p>
  <strong>
    details
  </strong>

</p><p>
  Assets can be listed by running the following command:

</p><pre>unzip -vl redbean.com        # lists files
</pre>

<p>
  Assets can be added to the zip archive as follows:

</p><pre>zip redbean.com index.html   # adds file
</pre>

<p>
  By default, anything you add to the archive gets compressed. Sometimes
  you don't want that to happen. A good example is video files. The web
  browser will want to send HTTP range requests to seek in the video, in
  which case redbean requires that the asset be uncompressed.

</p><pre>zip -0 redbean.com video.mp4  # adds file without compression
</pre>

<p>
  Each connection uses a point in time snapshot of your ZIP file.
  If your ZIP is deleted then serving continues. If it's replaced
  then issuing SIGUSR1 (or SIGHUP if daemon) will reindex the zip
  for subsequent connections without interrupting active ones. If
  SIGINT or SIGTERM is issued then a graceful shutdown is started
  but if it's issued a second time, active connections are reset.

</p><p>
  <strong>
    flags
  </strong>

</p><table>
  <tbody><tr><th>  -h        </th><td>help
  </td></tr><tr><th>  -v        </th><td>verbosity
  </td></tr><tr><th>  -d        </th><td>daemonize
  </td></tr><tr><th>  -s        </th><td>uniprocess
  </td></tr><tr><th>  -m        </th><td>log messages
  </td></tr><tr><th>  -c INT    </th><td>cache seconds
  </td></tr><tr><th>  -r /X=/Y  </th><td>redirect X to Y
  </td></tr><tr><th>  -l ADDR   </th><td>listen ip [default 0.0.0.0]
  </td></tr><tr><th>  -p PORT   </th><td>listen port [default 8080]
  </td></tr><tr><th>  -L PATH   </th><td>log file location
  </td></tr><tr><th>  -P PATH   </th><td>pid file location
  </td></tr><tr><th>  -U INT    </th><td>daemon set user id
  </td></tr><tr><th>  -G INT    </th><td>daemon set group id
  </td></tr><tr><th>  -B STR    </th><td>changes server header
</td></tr></tbody></table>

<p>
  <strong>benchmark</strong>

</p><pre>$ <a href="https://github.com/wg/wrk">wrk</a> -H 'Accept-Encoding: gzip' -t 12 -c 120 \
  http://127.0.0.1:8080/tool/net/redbean.html
Running 10s test @ http://127.0.0.1:8080/tool/net/redbean.html
  12 threads and 120 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   745.49us    8.79ms 406.77ms   99.54%
    Req/Sec    96.60k     6.10k  123.66k    77.36%
  11631210 requests in 10.10s, 7.96GB read
Requests/sec: 1151621.71
Transfer/sec:    807.23MB
</pre>

<p>
  <strong>
    see also
  </strong>

</p><p>
  <a href="https://justine.lol/index.html">justine's web page</a><br>
  <a aria-label="Actually Portable Executable" href="https://storage.googleapis.com/justine/ape.html">αcτµαlly pδrταblε εxεcµταblε</a>

</p>
</div>]]>
            </description>
            <link>https://justine.lol/redbean/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26271117</guid>
            <pubDate>Fri, 26 Feb 2021 03:33:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dasung Paperlike HD-FT Teardown]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26270995">thread link</a>) | @alex-a-soto
<br/>
February 25, 2021 | https://alexsoto.dev/dasung-paperlike-hdft-teardown.html | <a href="https://web.archive.org/web/*/https://alexsoto.dev/dasung-paperlike-hdft-teardown.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A series where I’m documenting my process of designing and building an eink laptop.</p><ul><li><span><span title="2021-02-17T22:13"><a href="https://alexsoto.dev/building-an-e-ink-laptop.html">Building an E-Ink Laptop</a><span data-nosnippet="" title="Folgezettel">#</span></span></span></li></ul><p>In my first post, <a href="https://alexsoto.dev/building-an-e-ink-laptop.html">Building an E-Ink Laptop</a>, I went over some history about e-ink technology, the e-ink modding community, recent advancements, and the hardware I’ve selected to create an e-ink laptop.</p><p>This post in the series will be a teardown of the Dasung HD-FT, inspired from Kev Zettler’s work on the, <a href="https://kevzettler.com/2018/02/11/dasung-paperlike-pro-teardown/">Dasung Paperlike Pro Teardown</a>. Thank you, <a href="https://kevzettler.com/">Kev Zettler</a>, for showing your work on the Dasung Paperlike Pro and making all of this possible. I will later create an accompanying video to go over the Dasung HD-FT teardown process.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_203519.jpg"></p><h2 id="overview-of-the-dasung-hd-ft">Overview of the Dasung HD-FT</h2><p>The Dasung HD-FT is a third-generation e-ink monitor with a display of 13.3“, a screen resolution of 2200x1650, a touchscreen, and an adjustable backlight. The monitor connects via a proprietary Y cable, with connections for USB and HDMI; additionally, the Dasung HD-FT can be powered by the micro-usb connection on the left side.</p><p>Once connected to a computer, it acts as a second monitor or, for our purposes, a primary monitor for our e-ink laptop. The monitor’s physical buttons allow you to adjust the contrast, brightness, clear the screen, and change modes.</p><p>The modes (M1, M2, M3, Fast, Fast++, Black, Black+, Black++) correspond to how the monitor displays what’s rendered in the screen using different shades of grey or black/white.</p><p>Let’s take a closer look and dismantle the Dasung HD-FT and look at its components.</p><h2 id="opening-the-dasung-paperlike-hd-ft">Opening the Dasung Paperlike HD-FT</h2><p>Similar to Zettler’s observations and approach, the Dasung HD-FT is made of one piece of construction. I first began with a knife, carefully prying the outer edges of the Dasung Monitor where it’s all glued and making my way slowly through all of the sides.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_194558.jpg"></p><p>Once I finished prying through all of the sides, what became visible were the screws that were holding everything together.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_194714.jpg"></p><p>After removing all of the screws, I was able to gain access to the panel!</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_203519.jpg"></p><h2 id="the-e-ink-display-module-and-control-board">The E-ink display module and control board</h2><p>Like Zettler discovered, the Dasung HD-FT chip components upon closer inspection were also chemically peeled off to prevent reverse engineering of the e-ink display and control board.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201821.jpg"></p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201158.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201211.jpg"></p><h2 id="es133tt3-display-module">ES133TT3 Display Module</h2><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_201921.jpg"></p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202037.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202009.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202020.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/IMG_20210216_202024.jpg"></p><p>The e-ink display module model number for the Dasung HD-FT is the: <span><strong>ES133TT3</strong></span></p><p>beck-elektronik<span data-nosnippet=""><sup><a href="#fn1" id="fnref1">1</a></sup></span> describes it as “<em>reflective electrophoretic E Ink technology display module based on active matrix TFT and plastic substrate. The plastic substrate is protected by an outer covering.</em>”</p><p>Specification:</p><ul><li>Size: 13.3 inch</li><li>Resolution (HxV): 2200 * 1650</li><li>Active Area: 270.60 * 202.95 mm</li><li>Outline Dimensions: 287.00 * 215.50 mm</li><li>Dpi: 206</li><li>E Ink Film: Carta 1.2</li><li>Refresh Time: 450 ms</li><li>Backplane: Flexible</li><li>Total Thickness: 0.65 mm</li><li>Total Weight: 68 g</li><li>Grey Level: 16</li><li>Surface Treatment: Anti-Glare</li><li>Partial Update: yes</li></ul><p>Their website also lists an EPD driver kit that’s compatible with it, the ES133TT3.<span data-nosnippet=""><sup><a href="#fn2" id="fnref2">2</a></sup></span></p><h2 id="next-steps">Next Steps</h2><p>This second post provided an overview of the Dasung HD-FT, a teardown of the Dasung HD-FT and its internal components, and identifying the display module used, the ES133TT3.</p><p>The following post in the series will be a teardown of the Thinkpad T480 that we will be using to build our e-ink laptop.</p><p><img id="avatar" src="https://alexsoto.dev/static/profile.jpeg"></p><p>Hi, I’m Alexander Soto.</p><p>I’m a community organizer, educator, software engineer, hacktivist, and agent of social change. My interests are in exploring community-building, social justice, education, and leveraging technology to address social problems.</p><p>In the past, I’ve worked as a labor rights organizer, a teacher, and I’m currently an Expert In Residence at <a href="https://www.resilientcoders.org/">Resilient Coders.</a></p><p>I enjoy tinkering/playing/breaking things, 3D printing, painting, playing piano, swimming, and writing in my spare time.</p><p>This site is the <a href="https://alexsoto.dev/impulse.html">scattered and unfinished version of my thoughts</a> while documenting what I’m currently learning and exploring.</p><p>If a post resonated positively or negatively, send me a <a href="https://twitter.com/messages/compose?recipient_id=4648173315">direct message</a> on <a href="https://twitter.com/alexsotodev">Twitter</a>, an <a href="mailto:contact@alexsoto.dev">email</a>, or subscribe to the <a href="https://buttondown.email/alexsotodev">mailing list</a> and we can talk. Also, ping if you’d like to know the updates of a post or if you have suggestions, comments, questions, or would like to collaborate.</p>



</div></div>]]>
            </description>
            <link>https://alexsoto.dev/dasung-paperlike-hdft-teardown.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270995</guid>
            <pubDate>Fri, 26 Feb 2021 03:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Craziest Drinks Sold in Japan]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26270957">thread link</a>) | @rmason
<br/>
February 25, 2021 | https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/ | <a href="https://web.archive.org/web/*/https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>Oh come on!  Don’t play it safe and only go just go for a Coke or Pepsi.  You’re in Japan now.  It’s time to try something more adventurous.</p>



<p>Vending machines mainly for carbonated drinks started appearing across the country in 1960.&nbsp; Now there are an estimated 2,470,000 of them throughout Japan or 1 for approximately every 50 people.&nbsp; Thus, it is easy to grab either a cold or hot drink virtually anywhere in the country on a 24/7 basis.</p>



<p>While the same global players such as Coca-Cola and national powerhouses in the beverage industry like Suntory do, in fact, dominate distribution via vending machines and other channels, relatively obscure minor entrants have still managed to carve out a niche with several unique offerings.&nbsp; Even the big boys have become used to granting a creative license to their marketers to go well beyond normal colas.</p>



<div><figure><img loading="lazy" src="https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-1024x640.jpg" alt="" width="512" height="320" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-1024x640.jpg 1024w, https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea-300x188.jpg 300w, https://japaninsider.com/wp-content/uploads/2021/02/Strange-Drinks-Image-from-Crea.jpg 1280w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Some of the more unusual selections from Ryoko Shimizu’s Top 50, Image sourced from Crea</figcaption></figure></div>



<p>The sheer variety of beverages—<em>both non-alcoholic and alcoholic</em>—available in Japan is staggering. &nbsp;To make sense of it all is soft drink critic Ryoko Shimizu (aside–<em>now that’s a cool job!</em>).&nbsp; She has been reviewing the world of non-alcoholic Japanese beverages since the 1980s.&nbsp; Shimizu recently published a <a href="https://news.nifty.com/article/entame/etc/12113-930661/">Top 50 list of her all-time favorites</a> (the original article in Japanese only).</p>



<p>…but wait!  First you need to know this.</p>



<h3><strong>What’s a <em>supodo</em>?</strong></h3>



<p><em>Supodo</em> (スポド) is an abbreviation for the made-up English term “sports drink” in Japanese.&nbsp; This category is a type of soft drink that replenishes the water and minerals lost from the body due to perspiration, especially during exercise. &nbsp;It supposedly helps to prevent dehydration and the potential for heatstroke while playing sports under the scorching sun.</p>



<h3><strong>Top Fifty</strong></h3>



<p>Okay, now that this term has been defined, let’s get to Shimizu’s extensive list which includes plenty of <em>supodo</em> as well as other types of drinks!</p>



<p>Not all of her favorites are still around, but, despite humble beginnings in some cases, a surprising number have since gone mainstream.&nbsp; Scroll down to see how Shimizu ranked them by counting backward from 50 down to 1:</p>



<h4>#50 Sports Mugicha</h4>



<p><strong>Sports Mugicha</strong> sold in the 1990s by Kanebo:&nbsp; Shimizu wrote, “When I first heard the name of this drink, my first impression was that it must be a blend of traditional barley tea and a ‘sports drink.’&nbsp; It consists, in fact, of a combination of an appropriate amount of salt mixed with regular barley tea to enhance its absorption into the body. &nbsp;The can was decorated with a theme from the professional baseball team Yokohama BayStars.”</p>



<div><figure><img loading="lazy" width="223" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea.jpg 223w, https://japaninsider.com/wp-content/uploads/2021/02/Sports-Mugicha-Image-from-Crea-209x300.jpg 209w" sizes="(max-width: 223px) 100vw, 223px"><figcaption>Sports Mugicha (barley tea), Image sourced from Crea</figcaption></figure></div>



<h4>#49 Mountain Dew</h4>



<p><strong>Mountain Dew</strong> launched in 1981 by Pepsi Co:&nbsp; This long-seller, which is still popular today, is marketed in Japan with the tag line “new citrus beverage.”&nbsp; The package has changed little over the years.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Mountain-Dew-Image-from-Crea-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Mountain Dew (written in Japanese), Image sourced from Crea</figcaption></figure></div>



<h4>#48 Tab Clear</h4>



<p><strong>Tab Clear</strong> launched in 1993 by Coca-Cola:&nbsp; Shimizu commented, “It became a hot topic because it was a transparent cola, but I remember that it was subtle in terms of taste. Kotaro Tawara, a popular newscaster at the time, appeared in a commercial.”</p>



<div><figure><img loading="lazy" width="245" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea.jpg 245w, https://japaninsider.com/wp-content/uploads/2021/02/Tab-Clear-Image-from-Crea-230x300.jpg 230w" sizes="(max-width: 245px) 100vw, 245px"><figcaption>Tab Clear, Image sourced from Crea</figcaption></figure></div>



<h4>#47 Tsubu-Tsubu Orange</h4>



<p><strong>Tsubu-Tsubu Orange</strong> was sold in the 1990s by Yamato:&nbsp; This orange drink was conceived based upon the trend of mashed fruit drinks in the 1980s.&nbsp; “Tsubu” means “bead” or “drop” in Japanese.&nbsp; When it was launched, Tsubu-Tsubu Orange lacked national distribution.&nbsp; It was only marketed locally in Nagoya, near where it was made.</p>



<div><figure><img loading="lazy" width="208" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea.jpg 208w, https://japaninsider.com/wp-content/uploads/2021/02/Tsubu-Tsubu-Orange-Image-from-Crea-195x300.jpg 195w" sizes="(max-width: 208px) 100vw, 208px"><figcaption>Tsubu Tsubu Orange, Image sourced from Crea</figcaption></figure></div>



<h4>#46 Post Water</h4>



<p><strong>Post Water</strong> launched in 1990 by Kirin:&nbsp; Made from lychees, this <em>supodo</em>  or “sports drink” made quite a scene when it debuted in an unusually-shaped flask.</p>



<div><figure><img loading="lazy" width="554" height="554" src="https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter.jpg 554w, https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter-300x300.jpg 300w, https://japaninsider.com/wp-content/uploads/2021/02/Post-Water-Image-Sourced-from-Twitter-150x150.jpg 150w" sizes="(max-width: 554px) 100vw, 554px"><figcaption>Post Water, Image sourced from Twitter</figcaption></figure></div>



<h4>#45 Cheerio Grape</h4>



<p><strong>Cheerio Grape</strong> launched in 1965 by Cheerio:&nbsp; Shimizu fondly recalls Cheerio’s Grape drink as being for sale at the candy store near her childhood home.</p>



<div><figure><img loading="lazy" width="204" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea.jpg 204w, https://japaninsider.com/wp-content/uploads/2021/02/Cheerio-Grape-Image-from-Crea-191x300.jpg 191w" sizes="(max-width: 204px) 100vw, 204px"><figcaption>Cheerio Grape, Image sourced from Crea</figcaption></figure></div>



<h4>#44 J Water</h4>



<p><strong>J Water</strong> launched in 1993 by Suntory:&nbsp; This drink made its debut as an officially licensed beverage of the J League or Japan Professional Football (soccer) League back when J League was new.&nbsp; This “sports drink” did not have a particularly distinctive taste, but the taste was secondary to packaging in any case.&nbsp; There are also team-specific variants.</p>



<div><figure><img loading="lazy" width="195" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online.jpg 195w, https://japaninsider.com/wp-content/uploads/2021/02/J-Water-Image-from-Bunshun-Online-183x300.jpg 183w" sizes="(max-width: 195px) 100vw, 195px"><figcaption>J. Water, Image sourced from Bunshun Online</figcaption></figure></div>



<h4>#43 Ambasa</h4>



<p><strong>Ambasa</strong> launched in 1982 by Coca-Cola:&nbsp; Shimizu commented, “I felt a little &nbsp;uncomfortable with the unfamiliar word ‘Ambasa’ at first, but I quickly got used to it because it was put into virtually every Coca-Cola vending machine.” &nbsp;This carbonated beverage looks milky and tastes lighter than Calpis Soda. &nbsp;There were also melon and pine flavors for a while.</p>



<div><figure><img loading="lazy" width="240" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea.jpg 240w, https://japaninsider.com/wp-content/uploads/2021/02/Ambasa-Image-from-Crea-225x300.jpg 225w" sizes="(max-width: 240px) 100vw, 240px"><figcaption>Ambasa, Image sourced from Crea</figcaption></figure></div>



<h4>#42 Apple Oolong Soda</h4>



<p><strong>Apple Oolong Soda</strong> launched in 1988 by Kirin:&nbsp; This is another drink that relies primarily upon packaging to drum up sales.&nbsp; It features characters from the anime Modern Children (いまどきのこども), which attracted a lot of attention when launched.  It is still fairly popular.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Apple-Oolong-Soda-Image-from-Bunshun-Online-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Apple Oolong Soda, Image sourced from Bunshun Online</figcaption></figure></div>



<h4>#41 Sweet Kiss</h4>



<p><strong>Sweet Kiss</strong> launched in 1982 by Cheerio:&nbsp; Sweet Kiss is sort of a variant of Mountain Dew (#49) and features a distinctive graphic design.&nbsp; It is, however, still relatively difficult to find this drink even in Tokyo.</p>



<div><figure><img loading="lazy" width="590" height="442" src="https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net.jpg 590w, https://japaninsider.com/wp-content/uploads/2021/02/Sweet-Kiss-Image-from-J-Town-Net-300x225.jpg 300w" sizes="(max-width: 590px) 100vw, 590px"><figcaption>Sweet  Kiss, Image sourced from J Town Net</figcaption></figure></div>



<h4>#40 Saruo Monkey King</h4>



<p><strong>Saruo Monkey King</strong> launched in 1994 by Lotte:&nbsp; The name Saruo literally means “monkey king” in Japanese.&nbsp; It was originally marketed as an exclusive type of oolong tea made from tea leaves grown on cliffs where monkeys like to forage food.&nbsp; There is, naturally, some question about whether monkeys actually harvest tea leaves.&nbsp; One of the respondents reportedly remarked in a taste test, “It sort of smells like a monkey.”&nbsp; Luckily for the brand, there are, however, plenty of other people who disagree!</p>



<div><figure><img loading="lazy" width="216" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea.jpg 216w, https://japaninsider.com/wp-content/uploads/2021/02/Saruo-Image-from-Crea-203x300.jpg 203w" sizes="(max-width: 216px) 100vw, 216px"><figcaption>Saruo or “monkey king” in Japanese, Image sourced from Crea</figcaption></figure></div>



<h4>#39 Afternoon Tea</h4>



<p><strong>Afternoon Tea</strong> launched in sold in 1986 by Kirin:&nbsp; This drink is a best selling long-runner.&nbsp; It is fairly sweet and was the first black tea sold in a 1.5 liter PET bottle.</p>



<div><figure><img loading="lazy" width="194" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea.jpg 194w, https://japaninsider.com/wp-content/uploads/2021/02/Afternoon-Tea-Image-from-Crea-182x300.jpg 182w" sizes="(max-width: 194px) 100vw, 194px"><figcaption>Afternoon Tea, Image sourced from Crea</figcaption></figure></div>



<h4>#38 Bireley’s Orange</h4>



<p><strong>Bireley’s Orange</strong> launched in 1951 by Asahi:&nbsp; The name of this ultra-long-runner, “Birely’s,” used to be synonymous orange juice. Since the 1970s, when restrictions were introduced that limited marketers’ ability to label a drink as juice unless it was 100% juice, Birely’s had to drop the reference to juice.&nbsp; This minor setback did, however,  not make a major dent in its market share.  The brand is still sold today.</p>



<div><figure><img loading="lazy" width="239" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea.jpg 239w, https://japaninsider.com/wp-content/uploads/2021/02/Birelys-Orange-Image-from-Crea-224x300.jpg 224w" sizes="(max-width: 239px) 100vw, 239px"><figcaption>Bireley’s Orange, Image sourced from Crea</figcaption></figure></div>



<h4>#37 Hokuriku Soda Godzilla Matsui Can</h4>



<p><strong>Hokuriku Soda Godzilla Matsui Can</strong> launched in 1997 by Soka Komatsuen:&nbsp; This is a locally produced drink made to help immortalize the famous baseball player Hideki Matsui who was also a “favorite son” of Ishikawa Prefecture.&nbsp; Matsui, whose nickname was “Godzilla,” was a home run king who went on to play for the New York Yankees.</p>



<div><figure><img loading="lazy" width="214" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea.jpg 214w, https://japaninsider.com/wp-content/uploads/2021/02/Hokuriku-Soda-Godzilla-Can-Image-from-Crea-201x300.jpg 201w" sizes="(max-width: 214px) 100vw, 214px"><figcaption>Hokuriku Soda Godzilla Matsui Can, Image sourced from Crea</figcaption></figure></div>



<h4>#36 Honey Lemon</h4>



<p><strong>Honey Lemon</strong> launched in 1986 by Suntory:&nbsp; This fruit drink experienced explosive sales upon its release.&nbsp; Suntory had a problem, though.&nbsp; As they could not register a trademark for “honey lemon” or even its nickname in Japanese <em>hachi-lemo</em>, this particular name essentially became its own category because several other manufacturers flooded the market with similar drinks by the same name.&nbsp; It is a classic example of just how cut-throat the non-alcoholic drink industry can be in Japan.</p>



<div><figure><img loading="lazy" width="225" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea.jpg 225w, https://japaninsider.com/wp-content/uploads/2021/02/Honey-Lemon-Image-from-Crea-211x300.jpg 211w" sizes="(max-width: 225px) 100vw, 225px"><figcaption>Honey Lemon, Image sourced from Crea</figcaption></figure></div>



<h4>#35 McCOL</h4>



<p><strong>McCOL</strong> launched in 1982 by MMC:&nbsp; This collector’s item has long since been taken off the market.&nbsp; It was, apparently, relatively hard to find even when it was available through the mid-1990s.&nbsp; McCOL was marketed as “barley cola,” but it looked just like any other cola.&nbsp; The taste was a combination of barley tea and cider.</p>



<div><figure><img loading="lazy" width="197" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea.jpg 197w, https://japaninsider.com/wp-content/uploads/2021/02/McCOL-Image-from-Crea-185x300.jpg 185w" sizes="(max-width: 197px) 100vw, 197px"><figcaption>McCOL, Image sourced from Crea</figcaption></figure></div>



<h4>#34 TESS Milk Tea</h4>



<p><strong>TESS Milk Tea</strong> sold in the late 1980s by Suntory:&nbsp; TESS had a relatively short lifetime as a semi-sweet type of milk tea.</p>



<div><figure><img loading="lazy" width="238" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea.jpg 238w, https://japaninsider.com/wp-content/uploads/2021/02/Tess-Milk-Tea-Image-from-Crea-223x300.jpg 223w" sizes="(max-width: 238px) 100vw, 238px"><figcaption>TESS Milk Tea, Image sourced from Crea</figcaption></figure></div>



<h4>#33 NCAA</h4>



<p><strong>NCAA</strong> launched in 1981 by Suntory:&nbsp; Named for the National College Athletic Association (NCAA), this classic sports drink was introduced as “the brand new thirst quencher for those who love sports.”</p>



<div><figure><img loading="lazy" width="193" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea.jpg 193w, https://japaninsider.com/wp-content/uploads/2021/02/NCAA-Image-from-Crea-181x300.jpg 181w" sizes="(max-width: 193px) 100vw, 193px"><figcaption>NCAA, Image sourced from Crea</figcaption></figure></div>



<h4>#32 Atamaruko</h4>



<p><strong>Atamaruko</strong> launched in 1990 by Suntory:&nbsp; This citrus mixture of kumquats and calamansi (aka “Philippine lime”) was actually sold hot in the heated section of vending machines. Its name means, in fact, “A Child to Warm You Up.”&nbsp; The cute package design proved effective at attracting customers. &nbsp;It actually led to a second-generation character called “Nacchan” that became even more famous than Atamaruko, who was relegated to the status of “the unknown older sister.”</p>



<div><figure><img loading="lazy" width="223" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory.jpg 223w, https://japaninsider.com/wp-content/uploads/2021/02/Atamaruko-Image-from-Suntory-209x300.jpg 209w" sizes="(max-width: 223px) 100vw, 223px"><figcaption>Atamaruko, Image sourced from Suntory</figcaption></figure></div>



<h4>#31 Gatorade</h4>



<p><strong>Gatorade</strong> sold in the 1980s by Yukijirushi:&nbsp; Having been replaced by homegrown rival Pocari Sweat, American uber-brand Gatorade is no longer sold in cans in Japan. It was, though, the first “sports drink” to appear in Japan.&nbsp; At that point, Gatorade was only available as a powder.</p>



<div><figure><img loading="lazy" width="198" height="320" src="https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea.jpg" alt="" srcset="https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea.jpg 198w, https://japaninsider.com/wp-content/uploads/2021/02/Gatorade-Image-from-Crea-186x300.jpg 186w" sizes="(max-width: 198px) 100vw, 198px"><figcaption>Gatorade, Image sourced from Crea</figcaption></figure></div>



<h4>#30 Dr. Nakamatsu’s Head Tea</h4>



<p><strong>Dr. Nakamatsu’s Head Tea</strong> launched in 1994 by Cheerio:&nbsp; Now we’re entering the realm of the truly odd.&nbsp; Named for Dr. Yoshiro Nakamatsu, a leading researcher of “smart foods” at the time of launch, this strong blended tea was somehow supposed to enhance cognitive capability.&nbsp; Years later, the same Dr. Nakamatsu gained additional notoriety outside Japan by winning the “Ig Noble …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/">https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/</a></em></p>]]>
            </description>
            <link>https://japaninsider.com/top-50-craziest-drinks-sold-in-japan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270957</guid>
            <pubDate>Fri, 26 Feb 2021 02:58:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turn Hacker News into an RSS Feed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270868">thread link</a>) | @MattyRad
<br/>
February 25, 2021 | https://soapstone.mradford.com/hn-rss-guide/ | <a href="https://web.archive.org/web/*/https://soapstone.mradford.com/hn-rss-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <br>
      <section>
        
  <article>
    <header>
      

      <time>
        
        February 03, 2021
      </time>

      
    </header>

    <h2 id="hn-hijacks-your-brain">HN hijacks your brain</h2>
<p>You're an engineer who looks at Hacker News 2-5 times a day. HN is a good way to <em>fill the gaps</em> in time. You scan the front page- repeatedly- for links of interest... reading titles, eyeing scores... often jumping directly to the (overtly contrarian) comments to see if a link is even worth the energy.</p>
<p>Sound familiar?</p>
<p>That cycle hits a sickening <strong>5</strong>/10 of Tristan Harris's <a href="https://medium.com/thrive-global/how-technology-hijacks-peoples-minds-from-a-magician-and-google-s-design-ethicist-56d62ef5edf3">list of mind hijacks</a>:</p>
<ul>
<li>(1)  Control the Menu, Control the Choices</li>
<li>(3)  Fear of missing something important</li>
<li>(4)  Social Approval (upvotes)</li>
<li>(6)  Bottomless bowl</li>
<li>(10) Forecasting</li>
</ul>
<blockquote>
<p>These hijacks  <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor">aren't</a> intentional, they're just a byproduct of link aggregation platforms.</p>
</blockquote>
<p>Stoics are turning in their graves, where instead of knowing what's important, the links on HN <em>become</em> what's important, no matter how trivial, pedantic, hyped, or irrelevant.</p>
<p>So if you want help breaking this negative feedback loop, I encourage you to reclaim your attention by turning HN into and RSS feed;</p>
<p>Get more <a href="https://medium.com/@bre/the-cult-of-done-manifesto-724ca1c2ff13">done</a>. Ignore the comments and the <a href="https://www.ribbonfarm.com/2020/01/16/the-internet-of-beefs/">mooks</a>. Set limits. It's incredibly liberating to finish your RSS feed and think to yourself, <em>now what</em>?</p>

<p>Declaring what deserves your attention is the defining feature of RSS, so it's important to declare what aspect of HN you like. Generally people look at high scores. Fortunately HN already has a url specifically for its most "important" (i.e. upvoted) links: <a href="https://news.ycombinator.com/best"><code>/best</code></a>.</p>
<p>So if we can subscribe to the links from that page, we'll get the bulk of the links that deserve our attention.</p>
<p>For me, it's critically important for RSS to be a self-hosted solution. No third parties <small>(I'm looking at <em>you</em>, Feedly)</small>.</p>
<p>Otherwise, what's the point of retaking control, you're just shunting control to yet another third party.</p>
<p>My personal setup goes like this:</p>
<ul>
<li>Get the Raspberry Pi you bought but never used</li>
<li>Install Docker</li>
<li>Run FreshRSS</li>
<li>Add HN <a href="https://news.ycombinator.com/best"><code>/best</code></a> as an RSS feed</li>
<li>(Optional) Port forwarding and DNS setup</li>
<li>(Optional) Pick out a smartphone app to sync with</li>
</ul>
<p>This is just the first thing that worked for me, so by no means is it the guaranteed best. Recommendations and alternatives are welcome! You can, of course, tailor the following guide if you'd like to use a VPS.</p>

<h3 id="prepare-the-pi">Prepare the Pi</h3>
<h4 id="install-git">Install git</h4>
<p>Do a standard Raspbian setup the with <a href="https://soapstone.mradford.com/raspberry-pi-automatic-wifi-and-ssh">internet/ssh/hostname</a>. Then install git:</p>
<pre><span>sudo</span><span> apt-get install git
</span></pre><h4 id="install-docker">Install Docker</h4>
<pre><span>curl -sSL</span><span> https://get.docker.com | </span><span>sh
</span></pre><pre><span>sudo</span><span> usermod</span><span> -aG</span><span> docker pi &amp;&amp; </span><span>sudo</span><span> reboot
</span></pre><h4 id="install-docker-compose">Install Docker-compose</h4>
<blockquote>
<p>This method is specifically for Raspbian, if you're using a VPS or non-ARM machine, install docker-compose the <a href="https://docs.docker.com/compose/install/">conventional</a> way.</p>
</blockquote>
<pre><span>sudo</span><span> apt-get install</span><span> -y</span><span> libffi-dev libssl-dev
</span><span>sudo</span><span> apt-get install</span><span> -y</span><span> python3 python3-pip
</span><span>sudo</span><span> apt-get remove python-configparser
</span><span>sudo</span><span> pip3 install docker-compose
</span></pre>
<pre><span>git</span><span> clone https://github.com/FreshRSS/FreshRSS

cd FreshRSS/Docker
</span></pre>
<p>We're using a Raspberry Pi, so you'll need to pick out the ARM image! Use your favorite editor to modify these lines of the <code>docker-compose.yml</code> file:</p>
<pre><span># docker-compose.yml
</span><span>-    image: freshrss/freshrss:latest
</span><span>+    image: freshrss/freshrss:arm
</span></pre>
<p>Now you're ready to execute FreshRSS:</p>
<pre><span>docker-compose</span><span> up</span><span> -d
</span></pre>
<p>Once that's complete, head to your Pi's IP address (or hostname, if you opted for that) on port <code>8080</code> in your laptop's/desktop's browser (something like http://1.2.3.4:8080), and go through the initial setup.</p>

<p>Add <code>https://hnrss.org/best</code> as an RSS feed (from <a href="https://hnrss.github.io/">hnrss.github.io</a>).</p>
<p>Congratulations! You've officially RSS-ified HN!</p>
<h3 id="optional-port-forwarding-and-dns-setup">(Optional) Port forwarding and DNS setup</h3>
<p>Unless you went with the VPS route, you're probably behind a LAN, so if you want to access your RSS outside your LAN, you'll need to set up port forwarding and/or DNS. That's beyond the scope of this guide, but there are many guides online that can get you there.</p>
<h3 id="optional-pick-out-an-app">(Optional) Pick out an app</h3>
<p>You could just expose the pi to the internet, and read RSS directly from the browser, but I think having an app is a nice touch.</p>
<p>First you'll need to enable API access in FreshRSS. Go to <code>Authentication</code> and check the box to allow API access:</p>
<p><img src="https://soapstone.mradford.com/freshrss-auth.png" alt="fresh-rss-screenshot1"></p>
<p>Then create an API key under <code>Profile</code>:</p>
<p><img src="https://soapstone.mradford.com/freshrss-profile.png" alt="fresh-rss-screenshot2"></p>
<p>Now you can use the API url and the API key in your selected app to pull data down locally. Nice!</p>
<p>Here's a non-exhaustive list of open-source (Android) apps to get you started.</p>
<ul>
<li><a href="https://github.com/readrops/Readrops">Readrops</a> - <a href="https://play.google.com/store/apps/details?id=com.readrops.app">play store</a></li>
<li><a href="https://github.com/nextcloud/news-android">New Android</a> - <a href="https://play.google.com/store/apps/details?id=de.luhmer.owncloudnewsreader&amp;pcampaignid=MKT-Other-global-all-co-prtnr-py-PartBadge-Mar2515-1">play store</a></li>
<li><a href="https://github.com/nilsbraden/ttrss-reader-fork">ttrss-reader-fork</a> - <a href="https://play.google.com/store/apps/details?id=org.ttrssreader">play store</a></li>
<li><a href="https://github.com/fistons/TinyTinyFeed">TinyTinyFeed</a> - <a href="https://play.google.com/store/apps/details?id=org.poopeeland.tinytinyfeed">play store</a></li>
</ul>
<blockquote>
<p>Truth be told, a lot of the closed source RSS apps I've checked out tend to be slightly higher in quality, so if you're willing to compromise on that front then they are worth exploring.</p>
</blockquote>
<h2 id="what-did-we-gain">What did we gain?</h2>
<p>It may not seem like it, but we've gained a <strong>lot</strong> by doing this!</p>
<ul>
<li><strong>Defeated the mind hijacks</strong>:
<ul>
<li><strike>(1)</strike> Gained leverage over the "menu"</li>
<li><strike>(3)</strike> Declared which things are important up front, and view them only <em>once</em></li>
<li><strike>(4)</strike> Ignore comments. Scores only matter in that they are relatively high</li>
<li><strike>(6)</strike> Created a bottom (of the bowl) by grabbing a limited number of links</li>
<li><strike>(10)</strike> Easily defer time intensive links for later</li>
</ul>
</li>
<li><strong>Time</strong>
<ul>
<li>Prevent re-reads of HN</li>
<li>Make it easier to pick out the most interesting links and discard irrelevant ones</li>
<li>If you <em>really</em> want to read comments, you'll need to go out of your way</li>
<li>Star or bookmark links to read more in-depth at a later time</li>
</ul>
</li>
<li><strong>Data sovereignty</strong>
<ul>
<li>We control our own data; no relying on third parties (e.g. Feedly)</li>
</ul>
</li>
<li><strong>Cloud Resilience</strong>
<ul>
<li>Lose a phone? Upgrade computers? Need to sync between phone and desktop? No problem!</li>
</ul>
</li>
<li><strong>The ability to add other RSS feeds</strong>
<ul>
<li>We've opened up the ability to use RSS in other feeds
<ul>
<li>For reddit, just <a href="https://www.howtogeek.com/320264/how-to-get-an-rss-feed-for-any-subreddit/">append</a> <code>.rss</code> to any url</li>
<li>For youtube, plug in the URL to any channel!</li>
</ul>
</li>
</ul>
</li>
<li><strong>Costs nothing</strong>
<ul>
<li>Put an otherwise dusty Raspberry Pi to good use</li>
</ul>
</li>
<li><strong>RSS adoption</strong>
<ul>
<li><em>If you really want an RSS resurgence, <strong>start using it</strong></em></li>
</ul>
</li>
</ul>


    
      
    
  </article>

      </section>
    </div></div>]]>
            </description>
            <link>https://soapstone.mradford.com/hn-rss-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270868</guid>
            <pubDate>Fri, 26 Feb 2021 02:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse ETL is just another Data Pipeline]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270853">thread link</a>) | @cpard
<br/>
February 25, 2021 | https://rudderstack.com/blog/reverse-etl-is-just-another-data-pipeline | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/reverse-etl-is-just-another-data-pipeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><div></div></figure><section><div itemprop="articleBody"><p>Astasia from RedPoint Ventures wrote a <a href="https://medium.com/memory-leak/reverse-etl-a-primer-4e6694dcc7fb">great post</a> on new technologies supporting “reverse ETL” functionality in the customer data stack. </p>
<p>We’re excited to be innovating in the area of reverse ETL tech (via our Warehouse Actions feature) and our product and engineering teams discuss these topics and industry trends often, so we thought it would be helpful to provide a bit more technical depth on a few of Astasia’s points. </p>
<h2>1) Data Movement Differs Between Event Streams and Tabular Data, Which is an Important Consideration for Reverse ETL</h2>
<h3>Differences in Moving Data</h3>
<p>ETL/ELT solutions all accomplish a similar function, which is moving data, but there are several foundational differences to keep in mind when it comes to the data. One of those is the difference between <em>event stream data</em> and <em>tabular data</em>. </p>
<p>Everyone is familiar with this distinction on the ingestion side of the stack. Ingesting event streams is different from ingesting tabular data from SaaS applications (like Salesforce), not just in how the data is generated, i.e., pulled via API vs generated by an SDK, but also in the structure of the data itself. </p>
<p>This distinction has significant impacts, from real-time requirements to downstream reporting implications. This distinction has led to different vendors doing well in each category (i.e., Segment for event streaming and Fivetran for tabular data), but modern companies have to leverage both. </p>
<p>At RudderStack, we believe there is an opportunity to do both well, together. In fact, a unified stack to do both can achieve some interesting things, like cross-pipeline identity stitching (i.e., joining Salesforce record IDs with anonymousIDs) and unified data governance. We’re building these solutions at RudderStack, but that’s a topic for a different post. </p>
<h3>Event Stream vs. Tabular Data for Reverse ETL</h3>
<p>When you hear the term reverse ETL, it’s easy to think only of tabular data. The distinction still exists, though, and you can (and should) distinguish between event stream data and tabular data. </p>
<p>Astasia touched on a few use cases for tabular data, but reverse ETL as an event stream is equally as important. One use case we see quite often among our customers is sending events stored in logs (e.g., generated by your back end application and dumped into S3) into destinations like Google Analytics and Amplitude for analytics or platforms like Braze for marketing. </p>
<p>Many of our customers also perform more advanced processing like data mining or ML modeling of logs before sending them as events, then use RudderStack to pipe the data. </p>
<h2>2) Table Sync can be Modeled as an Event Stream</h2>
<p>An important point related to tabular vs event stream data is that tabular data can be modeled as events, but not necessarily the other way around. On the ETL/ELT side, CDC technologies (or incremental pulls) have generated quite a bit of interest because there are advantages of representing that data as events versus doing a batch pull via API. </p>
<p>Some of those advantages include incremental syncs for real-time updates, maintaining a consistent point-in-time state and routing the data to streaming technologies (we will covers this topic in more depth in a future post). </p>
<p>This is possible because <em>tabular data are actually a subset of event data</em>. In a similar way, batch processing is a subset of streaming processing. This means that tabular data can be derived from a stream of events and recreate the final state at any point (see event sourcing architecture). This is not true for the inverse, though. </p>
<p>In fact, the reason the industry adopted the tabular/batch model were primarily technical—it is much more difficult to build and manage streaming data, though this is changing with technologies like RudderStack. </p>
<p>At RudderStack, we have modeled table sync as an event stream in our reverse ETL solution. </p>
<p>At a high level, syncing a row from your warehouse to a ‘row’ in a cloud application is an “event” that specifies which data points are being mapped. Tools like Segment and RudderStack already accomplish that functionality with <code>.identify</code> calls in the event stream, so there is no inherent limitation of the data model for the use case. </p>
<p>So, while there are certainly different user experiences for streaming-based solutions like RudderStack vs table sync solutions like Census, they are primarily variations in UI/UX. </p>
<h2>3) The Limitations of Segment’s Personas Product for Reverse ETL</h2>
<p>Astasia made a great point about the distinction between reverse ETL and Segment’s Persona’s product. Personas is a powerful product feature, but it isn’t a reverse ETL solution. The reason is simple: Personas treats the user profile as a first-class object in data sync. The practical implication of this is that all data sync must conform to a contact/account structure, but as the recent increase in reverse ETL startups has shown, companies need sync functionality that serves a much wider range of use cases. </p>
<p>Reverse ETL as an event stream directly from the warehouse is unhindered by those limitations. In fact, with our Warehouse Actions feature, our customers can turn warehouse tables into a flexible, configurable event stream. That includes updating contacts, accounts and audiences, but can also support sending of cleansed internal events, derived proxy events (events represented by absence of behavior) and use cases where the data needs to be delivered to other infrastructure via tools like Kafka, Redis or HTTP endpoints. </p>
<h2>4) Reverse ETL is Still Just Data Movement, and a Single Pipe Simplifies Your Stack, Security, and Data governance</h2>
<p>Our mission at RudderStack is to help data engineers become the heroes of their companies by providing every team with rich data. We want to make their jobs easier, and part of that mission is simplifying data management into one pipeline. </p>
<p>In the modern stack, the warehouse is king and many destinations are also becoming sources (and vice versa!). </p>
<p>For example, sources of data often include </p>
<ul>
<li>Events coming from your client or server-side apps</li>
<li>Data from your SaaS tools</li>
<li>Data from your internal databases</li>
<li>Data from your warehouses and data lakes (and…lakehouses) </li>
<li>Data from internal event streams (like Kafka). </li>
</ul>
<p>When all of those sources are also destinations, almost every combination of source and destination is a use case, which create some important categories of tooling in the customer data stack: </p>
<ul>
<li>App to warehouse/SaaS (event streaming) </li>
<li>SaaS to warehouse (‘traditional’ ETL/ELT)</li>
<li>Warehouse to SaaS (new ‘reverse ETL’ category) </li>
<li>SaaS to SaaS (API to API category) </li>
</ul>
<p>Increasingly, those categories within the stack need to support important use cases that are becoming standard, but are still challenging for many companies to implement from a technical standpoint: </p>
<ul>
<li>Enabling customer-facing ML use-cases by sending live events to a key-value store (like Redis) for real-time personalization</li>
<li>Enabling internal ML use-cases by pulling data, enriching with ML, then sending it from the warehouse to tools for internal teams (i.e., Salesforce, Marketo, etc.)</li>
<li>Streaming internal events from Kafka to SaaS applications</li>
<li>Feeding transformed data (features) to feature stores (like Tecton)</li>
</ul>
<p>When you step back and look at those categories and the use cases they must support, it becomes clear that a business could easily have to build or buy a significant number of technologies to enable all of the functionality. In fact, we hear from companies all of the time about the pain of managing multiple technologies and vendors (which means contracts) across data pipelines. </p>
<p><a href="https://www.linkedin.com/feed/update/urn:li:activity:6770012325396262912?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A6770012325396262912%2C6770136342476263424%29">One commenter</a> on Astasia’s LinkedIn post said it this way: </p>
<p><em>“I think we have failed as technologists if we need to build different tools to load data into a warehouse and get data out of the warehouse. This is “focus on doing one thing well” and “you must create a new category” gone too far.”</em></p>
<p>We agree. Customers tell us all of the time that when it comes to managing pipelines in the context of the modern data stack, “best of breed” is becoming problematic to manage—after all, it’s the same customer data. </p>
<p>At RudderStack, we’re building the complete customer data stack for simplified pipeline management, including the reverse ETL component. </p>
<p>To learn more about RudderStack, visit us on our <a href="http://www.rudderstack.com/">website</a> or join our <a href="https://resources.rudderstack.com/join-rudderstack-slack">Slack</a> to chat with our team, check out our open source repos on <a href="https://github.com/rudderlabs">GitHub</a>, and follow us on social: <a href="https://twitter.com/RudderStack">Twitter</a>, <a href="https://www.linkedin.com/company/rudderlabs/">LinkedIn</a>, <a href="https://dev.to/rudderstack">dev.to</a>, <a href="https://rudderstack.medium.com/">Medium</a>, <a href="https://www.youtube.com/channel/UCgV-B77bV_-LOmKYHw8jvBw">YouTube</a>. Don’t miss out on any updates. <a href="https://rudderstack.com/blog/">Subscribe</a> to our blogs today!</p></div></section></article><div><p>Founder and CEO of RudderStack. Passionate about finding engineering solutions to real-world problems.</p></div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/reverse-etl-is-just-another-data-pipeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270853</guid>
            <pubDate>Fri, 26 Feb 2021 02:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating between WordPress hosts without downtime]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270783">thread link</a>) | @rozenmd
<br/>
February 25, 2021 | https://onlineornot.com/migrating-wordpress-hosts-without-downtime | <a href="https://web.archive.org/web/*/https://onlineornot.com/migrating-wordpress-hosts-without-downtime">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Sometimes you'll want to migrate WordPress hosts - maybe it's time for renewal, and you found a better deal elsewhere, or your hosting provider isn't as reliable as they promised.</p><p>Which is great for you, but your site's readers don't care that it's a better deal - they just want to see your content. So minimising downtime when transferring hosts is a pretty big deal.</p><p>Let's learn how to avoid downtime.</p><h2 id="step-1-transfer-your-content"><a href="#step-1-transfer-your-content" aria-label="migrating wordpress hosts without downtime permalink"></a>Step 1: Transfer your content</h2><p>The first step is to transfer your content to your new host, <strong>without turning off the old host</strong>. Your site on your old hosting provider doesn't have to be shutdown for you to start standing up your site on the new hosting provider.</p><p>Whether that's via a plugin, and manually copying your files across using FileZilla, or by getting a developer to copy your database to the new host, you need to have two copies of your site running to avoid downtime.</p><p>At the end of this step you should have two WordPress sites:</p><ol><li>The old one, which your domain is still pointing to (as in, visiting <a href="https://yoursite.com/">https://yoursite.com</a> still shows your WordPress site on your old hosting provider)</li><li>The new one, with a weird URL (depending on your new provider, this could be an IP address, or just a testing URL)</li></ol><h2 id="step-2-test-everything-on-your-new-site"><a href="#step-2-test-everything-on-your-new-site" aria-label="migrating wordpress hosts without downtime permalink"></a>Step 2: Test everything on your new site</h2><p>The last thing you want is to realise you forgot to copy your images <strong>after</strong> your site's users start visiting the new site.</p><p>Click around your new WordPress site, ensure images work, pages and posts are all there with the URLs you expect.</p><p>Once you're satisfied the new site works as you expect, you're ready to update your DNS</p><h2 id="step-3-update-your-dns-settings"><a href="#step-3-update-your-dns-settings" aria-label="migrating wordpress hosts without downtime permalink"></a>Step 3: Update your DNS settings</h2><p>This step will be different depending on your domain registrar (the company you bought the domain from), but the gist of it is that you're changing the address your domain points to from your old hosting provider, to the new one.</p><p>This step can take up to 72 hours for some old school providers, and can be as quick as a few minutes with AWS or CloudFlare. The time it takes is due to the DNS TTL values you use - you can read more about that <a href="https://ns1.com/resources/understanding-ttl-values-in-dns-records">here</a>. You can speed this step up by setting your TTL to a low value (like 300 seconds or 5 minutes) <strong>before you start the migration</strong>.</p><p>You can test whether the new hosting provider is live by creating a dummy blog post or page using the same URL you tested your new hosting provider with - if the post shows up at <a href="https://yoursite.com/">https://yoursite.com</a>, your new site is live!</p><p>Once you're <strong>absolutely sure</strong> your domain is displaying the WordPress site from your new hosting provider, <em>then</em> you can turn off the WordPress site running at your old hosting provider.</p><h2 id="how-does-this-prevent-downtime"><a href="#how-does-this-prevent-downtime" aria-label="migrating wordpress hosts without downtime permalink"></a>How does this prevent downtime?</h2><p>Essentially by not turning off either WordPress site, you entirely avoid downtime. When you switch the DNS records from the old hosting provider over to the new one, people visiting your site just start seeing the new site (since you don't turn off the old site until the migration is complete).</p></div></div></div>]]>
            </description>
            <link>https://onlineornot.com/migrating-wordpress-hosts-without-downtime</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270783</guid>
            <pubDate>Fri, 26 Feb 2021 02:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EdgeDB in Beta]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270576">thread link</a>) | @avador
<br/>
February 25, 2021 | https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/ | <a href="https://web.archive.org/web/*/https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="---post-root---"><section><div><p><img src="https://www.edgedb.com/static/beta1-937a02b3aacf5f4c5a6f10540333cf02.jpg" width="100%" height="100%"></p></div></section>
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<!-- -->
<section id="edgedb-1-0-beta-1-sirius">
<!-- -->
<p>Nearly two years after releasing 1.0 Alpha 1, and after seven alpha releases,
            we are ready to bring EdgeDB to the public beta phase!</p>
<p>This means that as of now, we will make every effort to keep the public-facing
            APIs backwards compatible.  This includes EdgeQL, our standard library,
            schema definition language, official database clients’ APIs, even CLI
            commands and their options.  Most importantly, EdgeDB’s dumps made today
            will be restorable in future versions of the database.</p>
<p>This release completes a set of features we feel are crucial for
            a well-rounded 1.0 product, and we invite early adopters to try it out.
            On our end, we’re spending the next few months on getting EdgeDB ready
            for the first stable release.  Entering Beta means we won’t be adding
            new features until the release of 1.0 final.</p>
<p>You can <a href="https://www.edgedb.com/download">download</a> 1.0b1 in a number of ways or try it out
            in our <a href="https://tutorial.edgedb.com/">interactive tutorial</a> without the need to install
            anything.</p>

<h4>What’s EdgeDB</h4>
<p>EdgeDB is an advanced <a href="https://github.com/edgedb/edgedb">open source</a> relational database built
            on top of PostgreSQL which aims to <a href="https://www.edgedb.com/blog/a-path-to-a-10x-database">change the game</a> in terms
            of data layer usability and performance.</p>
<p>It combines an expressive object-oriented data model with a composable
            query language based on set logic, making complex data schemas easy to
            express, populate, and query.  The query system’s explicit goal is to
            address <a href="https://www.edgedb.com/blog/we-can-do-better-than-sql">shortcomings of SQL</a>.</p>
<p>As a database designed for the long haul, EdgeDB allows for your data
            to evolve along with changing business needs, by providing built-in
            support for schema migrations.  It’s also developed in the open and
            under the permissive Apache license.</p>
<p>EdgeDB’s performance focus is embodied in its carefully designed
            first-party database clients (currently available for JavaScript, Go,
            and Python.)  The database server itself compiles EdgeQL queries to
            efficient SQL in ways that outperform many manually written queries.</p>
<p>As a modern database, EdgeDB also provides interoperability with your
            other services via built-in support for GraphQL, REST, and easy <a href="https://www.edgedb.com/docs/clients/01_js/api/connection#Connection.queryJSON">casting
                from and to JSON</a> while keeping your data strictly typed.</p>
<div id="built-in-database-migrations-in-use">

<p>We believe that managing the evolution of your data models is a crucial
                feature in a modern database product.  The alternatives would be either
                weakly typed schemas or a third-party product.  We’re not satisfied with
                either.  The former unnecessarily moves some of the responsibilities of
                the database into your application code, making data consistency harder
                and development more error-prone.  The latter on the other hand usually
                ties you to a particular database connection framework in a particular
                programming language, putting that language in a privileged position.
                This is suboptimal in today’s environment where very often mobile
                applications are written in multiple programming languages, a Web
                front-end can be another, and back-end processing using yet another.</p>
<p>With Beta 1, the migrations functionality we envisioned for EdgeDB
                is fully realized.  While you could <a href="https://www.edgedb.com/docs/edgeql/ddl/migrations">start, populate, and commit
                    migrations</a> from EdgeQL directly for a few releases
                already, now you can fully manage migrations from the CLI, making the
                workflow even more high-level.</p>
<p>The idea here is to be able to version your schema alongside your
                source code, possibly as a separate repository that you can link
                as a submodule in multiple applications that your system consists of.
                That repository would hold schema files describing migrations between
                different states of your data model.</p>
<p>As an example, let’s say we start with the following schema for a simple
                chat app:</p>
<pre><span><span><span>module</span> <span>default</span> {
    <span>type</span> User {
        <span>required</span> <span>property</span> name <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> email <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> password_hash <span>-&gt;</span> <span>str</span>;
    }

    <span>type</span> Message {
        <span>required</span> <span>link</span> author <span>-&gt;</span> User;
        <span>required</span> <span>property</span> body <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> timestamp <span>-&gt;</span> <span>datetime</span> {
            <span>default</span> <span>:=</span> <span>datetime_current</span>()
        }
    }
};</span></span></pre>
<p>The migration CLI looks for <code>.esdl</code> files in the <code>dbschema</code> directory
                by default, so let’s create one and write the above into a
                <code>dbschema/default.esdl</code> file inside it.  Let’s
                <a href="https://www.edgedb.com/docs/tutorial/install/">install</a> EdgeDB server and then create a new
                database instance for our chat app:</p>
<pre><span><span>$ edgedb server init chatapp</span></span></pre>
<p>Now, we can create the initial migration to the schema we’ve written above:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you create object type 'default::User'? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>This is new, what do all those possible actions mean?  Let’s find out:</p>
<pre><span><span>?

y - confirm the prompt, use the DDL statements
n - reject the prompt
l - list the DDL statements associated with prompt
c - list already confirmed EdgeQL statements
b - revert back to previous save point, perhaps previous question
s - stop and save changes (splits migration into multiple)
q - quit without saving changes
h or ? - print help
did you create object type 'default::User'? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>That’s clear, we did in fact create <code>User</code>. Let’s confirm:</p>
<pre><span><span>y
did you create object type 'default::Message'? [y,n,l,c,b,s,q,?]
y
Created dbschema/migrations/00001.edgeql, id:
m1ufwaxcqiwcq3ttcujnxv6f3jewhfrywc442z6gjk3sm3e5fgyr4q</span></span></pre>
<p>This creates the first migration file
                <code>dbschema/migrations/00001.edgeql</code>. After reviewing it to make
                sure everything is in order, we can apply the migration with the
                following command:</p>
<pre><span><span>$ edgedb -I chatapp migrate
Applied m1ufwaxcqiwcq3ttcujnxv6f3jewhfrywc442z6gjk3sm3e5fgyr4q
(00001.edgeql)</span></span></pre>
<p>In the course of implementing our app we decide to add more features,
                such as a friends list and multiple chat channels, so we alter our
                schema to be:</p>
<pre><span><span><span>module</span> <span>default</span> {
    <span>type</span> User {
        <span>required</span> <span>property</span> name <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> email <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> password_hash <span>-&gt;</span> <span>str</span>;

        <span>multi</span> <span>link</span> friends <span>-&gt;</span> User;
    }

    <span>type</span> Message {
        <span>required</span> <span>link</span> author <span>-&gt;</span> User;
        <span>required</span> <span>property</span> body <span>-&gt;</span> <span>str</span>;
        <span>required</span> <span>property</span> timestamp <span>-&gt;</span> <span>datetime</span> {
            <span>default</span> <span>:=</span> <span>datetime_current</span>()
        }

        <span>link</span> channel <span>-&gt;</span> Channel;
    }

    <span>type</span> Channel {
        <span>required</span> <span>property</span> title <span>-&gt;</span> <span>str</span> {
            <span>constraint</span> <span>exclusive</span>;
        };
        <span>property</span> description <span>-&gt;</span> <span>str</span>;
    }
};</span></span></pre>
<p>And we apply the changes by using <code>create-migration</code> and <code>migrate</code>
                commands again:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you create object type 'default::Channel'? [y,n,l,c,b,s,q,?]
y
did you create link 'channel' of object type 'default::Message'?
[y,n,l,c,b,s,q,?]
y
did you create link 'friends' of object type 'default::User'?
[y,n,l,c,b,s,q,?]
y
Created dbschema/migrations/00002.edgeql, id:
m1kebitqygj3o75wvrnicnpwthinqsofb6hnpbnr7vrtjfynqelmzq
$ edgedb -I chatapp migrate
Applied m1kebitqygj3o75wvrnicnpwthinqsofb6hnpbnr7vrtjfynqelmzq
(00002.edgeql)</span></span></pre>
<p>At this point we may want to actually create a default channel “Main”
                and make the <code>channel</code> link required. So we alter the schema to make
                the link required and run <code>create-migration</code> again:</p>
<pre><span><span>$ edgedb -I chatapp create-migration
did you make link 'channel' of object type 'default::Message'
required? [y,n,l,c,b,s,q,?]</span></span></pre>
<p>Indeed we did but for the sake of curiosity let’s list the DDL that
                the tool is producing for us here:</p>
<pre><span><span>l

Following DDL statements will be applied:
ALTER TYPE default::Message {
    ALTER LINK channel {
        SET REQUIRED USING (\(fill_expr));
    };
};</span></span></pre>
<p>Interestingly the DDL statement specifies that some expression will
                have to be provided to backfill data in the database.  Let’s see how
                it deals with this:</p>
<pre><span><span>did you make link 'channel' of object type 'default::Message'
required? [y,n,l,c,b,s,q,?]
y
Please specify an expression to populate existing objects in
order to make link 'channel' required:
fill_expr&gt; SELECT Channel FILTER .title = 'Main'
Created dbschema/migrations/00003.edgeql, id:
m1wk64aoerkmvbdlurcxjxgbgv6c3xmuo3uz7pxc3gauyx4muysg6q</span></span></pre>
<p>However, before applying this migration we also add the line <code>INSERT
default::Channel {title := 'Main'};</code> at the beginning of the
                migration block in the <code>dbschema/migrations/00003.edgeql</code> file
                to ensure the <code>SELECT</code> above finds the default channel.
                Now we can actually apply the changes:</p>
<pre><span><span>$ edgedb -I chatapp migrate
edgedb error: could not read migrations in dbschema/migrations:
could not read migration file dbschema/migrations/00003.edgeql:
migration name should be
`m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba` but
`m1wk64aoerkmvbdlurcxjxgbgv6c3xmuo3uz7pxc3gauyx4muysg6q` is used
instead.
Migration names are computed from the hash of the migration
contents. To proceed you must fix the statement to read as:
  CREATE MIGRATION
  m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba ONTO ...
if this migration is not applied to any database. Alternatively,
revert the changes to the file.</span></span></pre>
<p>Uh-oh! The migration failed, but the error message actually explains
                what happened: the tool discovered we made manual changes to the file.
                Since this is deliberate, we just need to adjust the migration hash in
                order to proceed.  The tool even supplies us with the new hash. After
                adjusting the migration file, we can now apply it:</p>
<pre><span><span>$ edgedb -I chatapp migrate
Applied m1fckqi5wqjtgynu77ummambcid3c2xp7wq4piadh5glbxcyxrkkba</span></span></pre></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/">https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/</a></em></p>]]>
            </description>
            <link>https://www.edgedb.com/blog/edgedb-1-0-beta-1-sirius/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270576</guid>
            <pubDate>Fri, 26 Feb 2021 01:35:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lexical File Names in Plan 9 or Getting Dot-Dot Right]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270428">thread link</a>) | @silasdb
<br/>
February 25, 2021 | https://plan9.io/sys/doc/lexnames.html | <a href="https://web.archive.org/web/*/https://plan9.io/sys/doc/lexnames.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>
<span><b>Lexical File Names in Plan 9</b></span></p>
<p>
<span><b>or</b></span></p>
<p>
<span><b>Getting Dot-Dot Right</b></span></p>



<p>
<span><i>Rob&nbsp;Pike</i></span></p>
<p>
<span><i></i></span><span><tt>rob@plan9.bell-labs.com</tt></span><span><i></i></span></p>



<p>
<span>Bell&nbsp;Laboratories</span></p>
<p>
<span>Murray&nbsp;Hill,&nbsp;New&nbsp;Jersey&nbsp;07974</span></p>



<p>
<span><i>ABSTRACT</i></span></p>


<p>
<span>Symbolic links make the Unix file system non-hierarchical, resulting in
multiple valid path names for a given file.
This ambiguity is a source of confusion, especially since some shells
work overtime to present a consistent view from programs such as
</span><span><tt>pwd</tt></span><span>,
while other programs and
the kernel itself do nothing about the problem.
</span></p>
<p>
<span>Plan 9 has no symbolic links but it does have other mechanisms that produce the same difficulty.
Moreover, Plan 9 is founded on the ability to control a program’s environment
by manipulating its name space.
Ambiguous names muddle the result of operations such as copying a name space across
the network.
</span></p>
<p>
<span>To address these problems,
the Plan 9 kernel has been modified to maintain an accurate path name for every active
file (open file, working directory, mount table entry) in the system.
The definition of ‘accurate’ is that the path name for a file is guaranteed to be the rooted,
absolute name
the program used to acquire it.
These names are maintained by an efficient method that combines lexical processing—such as
evaluating
</span><span><tt>..</tt></span><span>
by just removing the last path name element of a directory—with
local operations within the file system to maintain a consistently, easily understood view
of the name system.
Ambiguous situations are resolved by examining the lexically maintained names themselves.
</span></p>
<p>
<span>A new kernel call,
</span><span><tt>fd2path</tt></span><span>,
returns the file name associated with an open file,
permitting the use of reliable names to improve system
services ranging from
</span><span><tt>pwd</tt></span><span>
to debugging.
Although this work was done in Plan 9,
Unix systems could also benefit from the addition of
a method to recover the accurate name of an
open file or the current directory.
</span></p>




<p>
<span><b>Motivation
</b></span></p>
<p>
<span>Consider the following unedited transcript of a session running the Bourne shell on a modern
Unix system:
</span></p>
<p>
<span><tt>%&nbsp;echo&nbsp;$HOME</tt></span></p>
<p>
<span><tt>/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;$HOME</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/ken</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;../rob</tt></span></p>
<p>
<span><tt>../rob:&nbsp;bad&nbsp;directory</tt></span></p>
<p>
<span><tt>%&nbsp;</tt></span></p>



<p>
<span>(The same output results from running
</span><span><tt>tcsh</tt></span><span>;
we’ll discuss
</span><span><tt>ksh</tt></span><span>
in a moment.)
To a neophyte being schooled in the delights of a hierarchical file name space,
this behavior must be baffling.
It is, of course, the consequence of a series of symbolic links intended to give users
the illusion they share a disk, when in fact their files are scattered over several devices:
</span></p>
<p>
<span><tt>%&nbsp;ls&nbsp;-ld&nbsp;/home/rob&nbsp;/home/ken</tt></span></p>
<p>
<span><tt>lrwxr-xr-x&nbsp;&nbsp;1&nbsp;root&nbsp;&nbsp;sys&nbsp;&nbsp;&nbsp;14&nbsp;Dec&nbsp;26&nbsp;&nbsp;1998&nbsp;/home/ken&nbsp;-&gt;&nbsp;/n/bopp/v6/ken</tt></span></p>
<p>
<span><tt>lrwxr-xr-x&nbsp;&nbsp;1&nbsp;root&nbsp;&nbsp;sys&nbsp;&nbsp;&nbsp;14&nbsp;Dec&nbsp;23&nbsp;&nbsp;1998&nbsp;/home/rob&nbsp;-&gt;&nbsp;/n/bopp/v7/rob</tt></span></p>
<p>
<span><tt>%&nbsp;</tt></span></p>



<p>
<span>The introduction of symbolic links has changed the Unix file system from a true
hierarchy into a directed graph, rendering
</span><span><tt>..</tt></span><span>
ambiguous and sowing confusion.
</span></p>
<p>
<span>Unix popularized hierarchical naming, but the introduction of symbolic links
made its naming irregular.
Worse, the
</span><span><tt>pwd</tt></span><span>
command, through the underlying
</span><span><tt>getwd</tt></span><span>
library routine,
uses a tricky, expensive algorithm that often delivers the wrong answer.
Starting from the current directory,
</span><span><tt>getwd</tt></span><span>
opens the parent,
</span><span><tt>..</tt></span><span>,
and searches it for an entry whose i-number matches the current directory;
the matching entry is the final path element of the ultimate result.
Applying this process iteratively,
</span><span><tt>getwd</tt></span><span>
works back towards the root.
Since
</span><span><tt>getwd</tt></span><span>
knows nothing about symbolic links, it will recover surprising names for
directories reached by them,
as illustrated by the example;
the backward paths
</span><span><tt>getwd</tt></span><span>
traverses will not backtrack across the links.
</span></p>
<p>
<span>Partly for efficiency and partly to make
</span><span><tt>cd</tt></span><span>
and
</span><span><tt>pwd</tt></span><span>
more predictable, the Korn shell
</span><span><tt>ksh</tt></span><span>
[Korn94]
implements
</span><span><tt>pwd</tt></span><span>
as a builtin.
(The
</span><span><tt>cd</tt></span><span>
command must be a builtin in any shell, since the current directory is unique to each process.)
</span><span><tt>Ksh</tt></span><span>
maintains its own private view of the file system to try to disguise symbolic links;
in particular,
</span><span><tt>cd</tt></span><span>
and
</span><span><tt>pwd</tt></span><span>
involve some lexical processing (somewhat like the
</span><span><tt>cleanname</tt></span><span>
function discussed later
in this paper), augmented by heuristics such as examining the environment
for names like
</span><span><tt>$HOME</tt></span><span>
and
</span><span><tt>$PWD</tt></span><span>
to assist initialization of the state of the private view. [Korn00]
</span></p>
<p>
<span>This transcript begins with a Bourne shell running:
</span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob</tt></span></p>
<p>
<span><tt>%&nbsp;ksh</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/home/rob</tt></span></p>
<p>
<span><tt>$&nbsp;</tt></span></p>



<p>
<span>This result is encouraging.  Another example, again starting from a Bourne shell:
</span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;../ken</tt></span></p>
<p>
<span><tt>../ken:&nbsp;bad&nbsp;directory</tt></span></p>
<p>
<span><tt>%&nbsp;ksh</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/home/rob</tt></span></p>
<p>
<span><tt>$&nbsp;cd&nbsp;../ken</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/home/ken</tt></span></p>
<p>
<span><tt>$</tt></span></p>



<p>
<span>By doing extra work,
the Korn shell is providing more sensible behavior,
but it is easy to defeat:
</span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/rob</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;bin</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob/bin</tt></span></p>
<p>
<span><tt>%&nbsp;ksh</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v7/rob/bin</tt></span></p>
<p>
<span><tt>$&nbsp;exit</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/home/ken</tt></span></p>
<p>
<span><tt>%&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v6/ken</tt></span></p>
<p>
<span><tt>%&nbsp;ksh</tt></span></p>
<p>
<span><tt>$&nbsp;pwd</tt></span></p>
<p>
<span><tt>/n/bopp/v6/ken</tt></span></p>
<p>
<span><tt>$&nbsp;</tt></span></p>



<p>
<span>In these examples,
</span><span><tt>ksh</tt></span><span>’s
built-in
</span><span><tt>pwd</tt></span><span>
failed to produce the results
(</span><span><tt>/home/rob/bin</tt></span><span>
and
</span><span><tt>/home/ken</tt></span><span>)
that the previous example might have led us to expect.
The Korn shell is hiding the problem, not solving it, and in fact is not even hiding it very well.
</span></p>
<p>
<span>A deeper question is whether the shell should even be trying to make
</span><span><tt>pwd</tt></span><span>
and
</span><span><tt>cd</tt></span><span>
do a better job.
If it does, then the
</span><span><tt>getwd</tt></span><span>
library call and every program that uses it will behave differently from the shell,
a situation that is sure to confuse.
Moreover, the ability to change directory to
</span><span><tt>../ken</tt></span><span>
with the Korn shell’s
</span><span><tt>cd</tt></span><span>
command but not with the
</span><span><tt>chdir</tt></span><span>
system call is a symptom of a diseased system, not a healthy shell.
</span></p>
<p>
<span>The operating system should provide names that work and make sense.
Symbolic links, though, are here to stay, so we need a way to provide
sensible, unambiguous names in the face of a non-hierarchical name space.
This paper shows how the challenge was met on Plan 9, an operating system
with Unix-like naming.
</span></p>
<p>
<span><b>Names in Plan 9
</b></span></p>
<p>
<span>Except for some details involved with bootstrapping, file names in Plan 9 have the same syntax as in Unix.
Plan 9 has no symbolic links, but its name space construction operators,
</span><span><tt>bind</tt></span><span>
and
</span><span><tt>mount</tt></span><span>,
make it possible to build the same sort of non-hierarchical structures created
by symbolically linking directories on Unix.
</span></p>
<p>
<span>Plan 9’s
</span><span><tt>mount</tt></span><span>
system call takes a file descriptor
and attaches to the local name space the file system service it represents:
</span></p>
<p>
<span><tt>mount(fd,&nbsp;"/dir",&nbsp;flags)</tt></span></p>



<p>
<span>Here
</span><span><tt>fd</tt></span><span>
is a file descriptor to a communications port such as a pipe or network connection;
at the other end of the port is a service, such as file server, that talks 9P, the Plan 9 file
system protocol.
After the call succeeds, the root directory of the service will be visible at the
</span><span><i>mount point</i></span><span>
</span><span><tt>/dir</tt></span><span>,
much as with the
</span><span><tt>mount</tt></span><span>
call of Unix.
The
</span><span><tt>flag</tt></span><span>
argument specifies the nature of the attachment:
</span><span><tt>MREPL</tt></span><span>
says that the contents of the root directory (appear to) replace the current contents of
</span><span><tt>/dir</tt></span><span>;
</span><span><tt>MAFTER</tt></span><span>
says that the current contents of
</span><span><tt>dir</tt></span><span>
remain visible, with the mounted directory’s contents appearing
</span><span><i>after</i></span><span>
any existing files;
and
</span><span><tt>MBEFORE</tt></span><span>
says that the contents remain visible, with
the mounted directory’s contents appearing
</span><span><i>before</i></span><span>
any existing files.
These multicomponent directories are called
</span><span><i>union directories</i></span><span>
and are somewhat different from union directories in 4.4BSD-Lite [PeMc95], because
only the top-level directory itself is unioned, not its descendents, recursively.
(Plan 9’s union directories are used differently from 4.4BSD-Lite’s, as will become apparent.)
</span></p>
<p>
<span>For example, to bootstrap a diskless computer the system builds a local name space containing
only the root directory,
</span><span><tt>/</tt></span><span>,
then uses the network to open a connection
to the main file server.
It then executes
</span></p>
<p>
<span><tt>mount(rootfd,&nbsp;"/",&nbsp;MREPL);</tt></span></p>



<p>
<span>After this call, the entire file server’s tree is visible, starting from the root of the local machine.
</span></p>
<p>
<span>While
</span><span><tt>mount</tt></span><span>
connects a new service to the local name space,
</span><span><tt>bind</tt></span><span>
rearranges the existing name space:
</span></p>
<p>
<span><tt>bind("tofile",&nbsp;"fromfile",&nbsp;flags)</tt></span></p>



<p>
<span>causes subsequent mention of the
</span><span><tt>fromfile</tt></span><span>
(which may be a plain file or a directory)
to behave as though
</span><span><tt>tofile</tt></span><span>
had been mentioned instead, somewhat like a symbolic link.
(Note, however, that the arguments are in the opposite order
compared to
</span><span><tt>ln</tt></span><span>
</span><span><tt>-s</tt></span><span>).
The
</span><span><tt>flags</tt></span><span>
argument is the same as with
</span><span><tt>mount</tt></span><span>.
</span></p>
<p>
<span>As an example, a sequence something like the following is done at bootstrap time to
assemble, under the single directory
</span><span><tt>/bin</tt></span><span>,
all of the binaries suitable for this architecture, represented by (say) the string
</span><span><tt>sparc</tt></span><span>:
</span></p>
<p>
<span><tt>bind("/sparc/bin",&nbsp;"/bin",&nbsp;MREPL);</tt></span></p>
<p>
<span><tt>bind("/usr/rob/sparc/bin",&nbsp;"/bin",&nbsp;MAFTER);</tt></span></p>



<p>
<span>This sequence of
</span><span><tt>binds</tt></span><span>
causes
</span><span><tt>/bin</tt></span><span>
to contain first the standard binaries, then the contents of
</span><span><tt>rob</tt></span><span>’s
private SPARC binaries.
The ability to build such union directories
obviates the need for a shell
</span><span><tt>$PATH</tt></span><span>
variable
while providing opportunities for managing heterogeneity.
If the system were a Power PC, the same sequence would be run with
</span><span><tt>power</tt></span><span>
textually substituted for
</span><span><tt>sparc</tt></span><span>
to place the Power PC binaries in
</span><span><tt>/bin</tt></span><span>
rather than the SPARC binaries.
</span></p>
<p>
<span>Trouble is already brewing.  After these bindings are set up,
where does
</span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;/bin</tt></span></p>
<p>
<span><tt>%&nbsp;cd&nbsp;..</tt></span></p>



<p>
<span>set the current working directory, to
</span><span><tt>/</tt></span><span>
or
</span><span><tt>/sparc</tt></span><span>
or
</span><span><tt>/usr/rob/sparc</tt></span><span>?
We will return to this issue.
</span></p>
<p>
<span>There are some important differences between
</span><span><tt>binds</tt></span><span>
and symbolic links.
First,
symbolic links are a static part of the file system, while
Plan 9 bindings are created at run time, are stored in the kernel,
and endure only as long as the system maintains them;
they are temporary.
Since they are known to the kernel but not the file system, they must
be set up each time the kernel boots or a user logs in;
permanent bindings are created by editing system initialization scripts
and user profiles rather than by building them in the file system itself.
</span></p>
<p>
<span>The Plan 9 kernel records what bindings are active for a process,
whereas symbolic links, being held on the Unix file server, may strike whenever the process evaluates
a file name.
Also, symbolic links apply to all processes that evaluate the affected file, whereas
</span><span><tt>bind</tt></span><span>
has a local scope, applying only to the process that executes it and …</span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://plan9.io/sys/doc/lexnames.html">https://plan9.io/sys/doc/lexnames.html</a></em></p>]]>
            </description>
            <link>https://plan9.io/sys/doc/lexnames.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270428</guid>
            <pubDate>Fri, 26 Feb 2021 01:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zine machine: a compact 3D-printed block printing press]]>
            </title>
            <description>
<![CDATA[
Score 245 | Comments 63 (<a href="https://news.ycombinator.com/item?id=26270251">thread link</a>) | @hownottowrite
<br/>
February 25, 2021 | https://hibred.pmvabf.org/zine-machine | <a href="https://web.archive.org/web/*/https://hibred.pmvabf.org/zine-machine">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div><p>
            Zine Machine is a compact 3D-printed block printing press. Convert images into blocks, try friends' blocks, or use the supplied type to set a page.
    </p><p>
    All files and instructions necessary to print and use a zine machine are open to the public and available on this website. Designed and released by <a href="https://gestalte.design/" target="_blank">Gestalte Design</a>, 
    Zine Machine is an experiment in guerilla digital fabrication. 
        </p></div>
    </div></div>]]>
            </description>
            <link>https://hibred.pmvabf.org/zine-machine</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270251</guid>
            <pubDate>Fri, 26 Feb 2021 00:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EFF's Atlas of Surveillance: Documenting Police Tech with Open Source Research]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26270166">thread link</a>) | @Bluestein
<br/>
February 25, 2021 | https://atlasofsurveillance.org/real-time-crime-centers | <a href="https://web.archive.org/web/*/https://atlasofsurveillance.org/real-time-crime-centers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  

<center>
<p dir="ltr"><img alt="A crime analysts sits at a workstation in front of a wall of video monitors. " src="https://atlasofsurveillance.org/files/pictures/10/content_CHINO_RTCC.jpg"></p>

<p dir="ltr"><em><a href="https://www.facebook.com/chinopdsimmons/photos/crime-analyst-green-at-the-helm-of-our-real-time-crime-center/125426665468061/">Source: Chino Chief of Police</a></em></p>
</center>

<p dir="ltr">Over the last two decades, law enforcement agencies across the United States have been obtaining more and more sophisticated surveillance technologies to collect data. Technologies such as networked cameras, automated license plate readers, and gunshot detection are deployed around the clock, as are the tools to process this data, such as predictive policing software and AI-enhanced video analytics. The last five years have seen a distinct trend in which police have begun deploying all of this technology in conjunction with one another. The technologies, working in concert, are being consolidated and fed into physical locations called Real-Time Crime Centers (RTCCs). These high-tech hubs, filled with walls of TV monitors and computer workstations for sworn officers and civilian analysts, not only exploit huge amounts of data, but also are used to justify an increase in surveillance technology through new "data-driven" or "intelligence-led" policing strategies.&nbsp;</p>

<p dir="ltr">As part of the Atlas of Surveillance project, the Electronic Frontier Foundation and students from the Reynolds School of Journalism at the University of Nevada, Reno have identified more than 80 RTCCs across the United States, with heavy concentrations in the South and the Northeast. In this report, we highlight the capabilities and controversies surrounding 7 of these facilities. As this trend expands, it is crucial that the public understands how the technologies are combined to collect data about people as they move through their day-to-day lives.&nbsp;</p>

<p dir="ltr">RTCCs are similar to <a href="https://www.eff.org/deeplinks/2014/04/why-fusion-centers-matter-faq#:~:text=about%20fusion%20centers%3F-,What%20are%20fusion%20centers%3F,who%20analyze%20and%20share%20intelligence.">Fusion Centers</a>, to the extent the terms are sometimes used interchangeably. We distinguish between the two: fusion centers are technology command centers that function on a larger regional level, are typically controlled by a state-level organization, and are formally part of the U.S. Department of Homeland Security's fusion center network. They also focus on distributing information about national security "threats," which are often broadly interpreted. RTCCs are generally focused on municipal or county level activities and focus on a general spectrum of public safety issues, from car thefts to gun crime to situational awareness at public events.&nbsp;</p>

<p dir="ltr">The term “real-time” is also somewhat misleading: while there is often a focus on accessing data in real-time to communicate to first responders, many law enforcement agencies use RTCC to mine historical data to make decisions about the future through "predictive policing," a controversial and largely unproven strategy to identify places where crime could occur or people who might commit crimes.&nbsp;</p>

<center>
<p dir="ltr"><img alt="A map of the United States with small, orange circles representing real-time crime centers." src="https://atlasofsurveillance.org/files/pictures/12/content_RTCC_MAP.png"></p>
</center>

<p dir="ltr">So far, the Atlas of Surveillance project has identified RTCCs in 29 states, with the highest number in Florida (14) and New York (11); however, Mississippi also stood out with four RTCCs despite being a significantly smaller state. While RTCCs are commonly found in large metropolitan areas, even smaller cities such as Ogden, Utah and Hampton, Virginia have established their own RTCCs. There may be more RTCCs yet to be discovered. In Denver, local officials and news organizations were unaware the Denver Police Department had <a href="https://www.9news.com/article/news/local/denver-police-quietly-expand-surveillance-camera-network/73-80b180c4-2456-4a28-b106-feb1831ea61f">launched an RTCC </a>and expanded its camera network until Atlas of Surveillance researchers uncovered a job advertisement outlining its capabilities. The Honolulu Police Department has added a RTCC to its <a href="http://206.195.188.21/downloads/HPD_Moving_Forward.pdf">2020-2022 strategic plan</a>.&nbsp;</p>

<p dir="ltr">RTCCs tend to share common defining technological features, the most prominent being access to a <a href="https://www.eff.org/pages/surveillance-cameras">surveillance camera network</a> with feeds that are broadcast live onto a wall of TV monitors within a centralized headquarters. The number of cameras can range from just a few hundred, as in Albuquerque, New Mexico, to more than 12,000, as in Atlanta, Georgia, but in all cases the number of cameras have been steadily growing.</p>

<p dir="ltr">RTCCs also go hand-in-hand with <a href="https://www.eff.org/pages/gunshot-detection">gunshot detection technology</a>, especially ShotSpotter, a company that installs sensors throughout neighborhoods in order to listen for and locate suspected gunfire. The majority of RTCCs also tap into <a href="https://www.eff.org/pages/automated-license-plate-readers-alpr">automated license plate readers</a> (ALPRs) to track and get real-time alerts on the locations of vehicles. In addition, RTCC staff typically have access to a variety of criminal justice databases and monitor social media feeds.&nbsp;</p>

<p dir="ltr">The starting cost of these RTCCs can range dramatically, from just a few hundred thousand dollars to as much as $11 million, as in New York City. This funding can come from a number of sources, including city budgets, voter-approved bonds, state and federal grants, private institutions, and wealthy individual donors. For example, the Atlanta Loudermilk Operation Shield Video Integration Center started with a $1-million donation from the Loudermilk family, who are real-estate developers, as well as $350,000 from the city. The price tag proved too high for the Fresno Police Department in California, which let go of its <a href="https://gvwire.com/2020/07/09/conservative-appointee-lasts-just-15-hours-on-fresno-immigrant-rights-committee/">part-time RTCC staff in 2019</a> and <a href="https://www.fresno.gov/finance/wp-content/uploads/sites/11/2020/06/TRAY-MEMO-Response-to-Council-Direction-No.-41-Request-Audit-of-Video-Policing-Surveillance-Unit-6.18.20.pdf">ceased all real-time operations</a> at the RTCC in 2020 (although police can still access stored footage from previously installed cameras after crimes occur).&nbsp;</p>

<p dir="ltr">Yet the cost barrier for these systems is steadily dropping. Based at the University of New Orleans, a private organization called <a href="https://www.projectnola.org/">Project NOLA</a> provides subsidized cameras and other technologies to cities and provides virtual RTCC software to municipalities through its NOLA National Real-Time Crime Center. So far, Project NOLA has partnered with police departments in Louisiana, Mississippi, New Jersey, Alabama, and Pennsylvania.&nbsp;</p>

<center>
<p dir="ltr"><img alt="A map of Newark with icons marking the location of cameras. " src="https://atlasofsurveillance.org/files/pictures/13/content_NEWARK_CVP.png"></p>

<p dir="ltr">Source: <a href="https://cvp.newarkpublicsafety.org/">New Jersey "Citizens Virtual Patrol"</a></p>
</center>

<p dir="ltr">Funding isn't the only way that RTCCs blur the line between public and private surveillance. The Newark, New Jersey RTCC encourages citizens to view live video feeds from cameras across the city through its "<a href="https://cvp.newarkpublicsafety.org/">Citizen Virtual Patrol</a>" program. Meanwhile, police in Jackson, Mississippi began testing a new system to link doorbell cameras, including Amazon’s Ring, to their RTCC. Similar camera sharing programs are being promoted in <a href="https://www.wtxl.com/news/lcso-unveils-new-real-time-crime-center/article_af42e61c-f35a-11e8-a32d-2bd5dc910bb2.html">Leon County, Florida</a> and <a href="https://www.safecamnola.com/">New Orleans</a>.</p>

<p dir="ltr">Here are the first seven RTCC case studies:&nbsp;</p>

<ul>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/albuquerque-real-time-crime-center">Albuquerque Real-Time Crime Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/atlanta-loudermilk-operation-shield-video-integration-center">Atlanta Loudermilk Video Integration Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/detroit-real-time-crime-center">Detroit Real-Time Crime Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/miami-gardens-real-time-crime-center">Miami Gardens Real-Time Crime Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/new-orleans-real-time-crime-center">New Orleans Real-Time Crime Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/ogden-rtcc">Ogden Area Tactical Analysis Center</a></li>
	<li><a href="https://atlasofsurveillance.org/real-time-crime-centers/sacramento-rtcc">Sacramento Real-Time Crime Center</a></li>
</ul>

<p>We have also included <a href="https://atlasofsurveillance.org/real-time-crime-centers/fresno-real-time-crime-center-suspended">a profile of the Fresno Real-Time Crime Center,</a> which was temporarily shut down prior to publication.&nbsp;</p>

<p dir="ltr">More profiles are planned in the coming weeks and months. For more information on the technologies used by police, browse the rest of the <a href="https://atlasofsurveillance.org/">Atlas of Surveillance site</a> or visit EFF's <a href="https://www.eff.org/sls">Street-Level Surveillance hub</a>.&nbsp;</p>

<p dir="ltr">If you know of an RTCC that isn't in our data, email <a href="mailto:aos@eff.org">aos@eff.org</a> or fill out <a href="https://forms.gle/XqFHYndfsWA2GTNj6">our online Google form</a>.&nbsp;</p>

<p dir="ltr" role="presentation">- Dave Maass, Electronic Frontier Foundation, and Hailey Rodis, Reynolds School of Journalism, University of Nevada, Reno.</p>

<h2>Credits</h2>

<p>This project is based on original research conducted by Prof. Gi Yun’s Cybersecurity, Privacy and Society class at the University of Nevada, Reno, Reynolds School of Journalism:&nbsp;Hunter Drost, Kirk Geller, D. Llaneza, Hailey Rodis, Stone Seuss, Cooper Venzon, Madison Vialpando, Javier Hernandez, and Matthew Hinrichs.&nbsp;</p>

<p>Additional writing and editing: Matthew King, Taylor Johnson, Hailey Rodis, Javier Hernandez, and Madison Vialpando</p>

<p dir="ltr" role="presentation"><em>Published Nov. 13, 2020</em></p>

<p dir="ltr" role="presentation"><em>Updated Nov. 24, 2020 to include information about the Honolulu Police Department.</em></p>



  
</div></div>]]>
            </description>
            <link>https://atlasofsurveillance.org/real-time-crime-centers</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270166</guid>
            <pubDate>Fri, 26 Feb 2021 00:28:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing the High Cost of Training NLP Models with SRU++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270124">thread link</a>) | @bratao
<br/>
February 25, 2021 | https://www.asapp.com/blog/reducing-the-high-cost-of-training-nlp-models-with-sru/ | <a href="https://web.archive.org/web/*/https://www.asapp.com/blog/reducing-the-high-cost-of-training-nlp-models-with-sru/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div>
<div>
<div>
<p>The increasing computation time and cost highlight the importance of inventing computationally efficient models that retain top modeling power with reduced or accelerated computation.</p>
<p>The Transformer <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">architecture</a> was proposed to accelerate model training in NLP. Specifically, it is built entirely upon self-attention and avoids the use of recurrence. The rationale of this design choice, as mentioned in the original work, is to enable strong parallelization (by utilizing the full power of GPUs and TPUs). In addition, the attention mechanism is an extremely powerful component that permits efficient modeling of variable-length inputs. These advantages have made Transformer an expressive and efficient unit, and as a result, the predominant architecture for NLP.</p>
<p>A couple of interesting questions arises following the development of Transformer:</p>
<ul>
<li>Is attention all we need for modeling?</li>
<li>If recurrence is not a compute bottleneck, can we find better architectures?</li>
</ul>
<h6>SRU++ and related work</h6>
<p>We present SRU++ as a possible answer to the above question. The inspiration of SRU++ comes from two lines of research:</p>
<p>First, previous works have tackled the parallelization/speed problem of RNNs and proposed various fast recurrent networks [<a href="https://arxiv.org/abs/1611.01576" target="_blank" rel="noopener">7</a>, <a href="https://arxiv.org/abs/1709.02755" target="_blank" rel="noopener">8</a>, <a href="https://arxiv.org/abs/1708.06834" target="_blank" rel="noopener">9</a>, <a href="https://arxiv.org/abs/1905.13324" target="_blank" rel="noopener">10</a>]. Examples include <a href="https://github.com/salesforce/pytorch-qrnn" target="_blank" rel="noopener">Quasi-RNN</a> and Simple Recurrent Unit (<a href="https://github.com/asappresearch/sru" target="_blank" rel="noopener">SRU</a>), both are highly-parallelizable RNNs. <strong>The advance eliminates the need of eschewing recurrences to trade training efficiency</strong>.</p>
<p>Second, several recent works have achieved strong results by leveraging recurrence in conjunction with self-attention. For example, <a href="https://arxiv.org/abs/1911.11423" target="_blank" rel="noopener">Merity</a> (2019) demonstrated a single-headed attention LSTM (<a href="https://github.com/Smerity/sha-rnn" target="_blank" rel="noopener">SHA-LSTM</a>) is sufficient to achieve competitive results on character-level language modeling task while requiring significantly less training time. In addition, RNNs have been incorporated into Transformer architectures, resulting in better results on machine translation and natural language understanding tasks [<a href="https://arxiv.org/abs/1709.02755" target="_blank" rel="noopener">8</a>, <a href="https://arxiv.org/abs/2003.07000" target="_blank" rel="noopener">12</a>]. <strong>These results suggest that recurrence and attention are complementary at sequence modeling</strong>.</p>
<p>In light of the previous research, we enhance the modeling capacity of SRU by incorporating self-attention as part of the architecture. A simple illustration of the resulting architecture SRU++ is shown in Figure 1c.</p>
<figure id="attachment_2001" aria-describedby="caption-attachment-2001"><img loading="lazy" src="https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency_2.jpg" alt="ASAPP - Figure 1: An illustration of SRU and SRU++ networks. (a) the original SRU network, (b) the SRU variant using a projection trick to reduce the number of parameters, experimented in Lei et al. (2018), and (c) SRU++ proposed in this work. Numbers indicate the hidden size of intermediate inputs / outputs. A more detailed description of SRU and SRU++ is provided in our paper." width="2400" height="1256" srcset="https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency_2.jpg 2400w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency_2-350x183.jpg 350w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency_2-1024x536.jpg 1024w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency_2-1536x804.jpg 1536w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency_2-2048x1072.jpg 2048w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency_2-350x183@2x.jpg 700w" sizes="(max-width: 2400px) 100vw, 2400px"><figcaption id="caption-attachment-2001">Figure 1: An illustration of SRU and SRU++ networks. (a) the original SRU network, (b) the SRU variant using a projection trick to reduce the number of parameters, experimented in Lei et al. (2018), and (c) SRU++ proposed in this work. Numbers indicate the hidden size of intermediate inputs / outputs. A more detailed description of SRU and SRU++ is provided in our paper.</figcaption></figure>
<p>SRU++ replaces the linear mapping of the input (Figure 1a) by first projecting the input into a smaller dimension. An attention operation is then applied, followed by a residual connection. The dimension is projected back to the hidden size needed by the elementwise recurrence operation of SRU. In addition, not every SRU++ layer needs attention. When the attention is disabled in SRU++, the network reduces to a SRU variant using dimension reduction to reduce the number of parameters (Figure 1b).</p>
<h6>Results</h6>
<p><strong>1. SRU++ is a highly-efficient neural architecture</strong><br>
We evaluate SRU++ on several language modeling benchmarks such as Enwik8 dataset. Compared to Transformer models such as Transformer-XL, SRU++ can achieve similar results using only a fraction of the resources. Figure 2 compares the training efficiency between the two with directly comparable training settings. SRU++ is 8.7x more efficient to surpass the dev result of Transformer-XL, and 5.1x more efficient to reach a BPC (bits-per-character) of 1.17.</p>
<figure id="attachment_2002" aria-describedby="caption-attachment-2002"><img loading="lazy" src="https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency.jpg" alt="ASAPP - Figure 2: Dev BPC on Enwik8 dataset vs GPU hours used for training. The SRU++ and Transformer-XL model both have 41-42M parameters and are trained with fp32 precision and comparable settings (such as learning rate). " width="2400" height="1256" srcset="https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency.jpg 2400w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency-350x183.jpg 350w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency-1024x536.jpg 1024w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency-1536x804.jpg 1536w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency-2048x1072.jpg 2048w, https://www.asapp.com/wp-content/uploads/2021/02/sru_efficiency-350x183@2x.jpg 700w" sizes="(max-width: 2400px) 100vw, 2400px"><figcaption id="caption-attachment-2002">Figure 2: Dev BPC on Enwik8 dataset vs GPU hours used for training. The SRU++ and Transformer-XL model both have 41-42M parameters and are trained with fp32 precision and comparable settings (such as learning rate).</figcaption></figure>
<table>
<thead>
<tr>
<td><strong>Model</strong></td>
<td><strong>Dataset</strong></td>
<td><strong>Result</strong></td>
<td><strong>GPU Days</strong></td>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://arxiv.org/pdf/2004.05150.pdf" target="_blank" rel="noopener">Longformer</a></td>
<td>Enwik8</td>
<td>0.99</td>
<td>104*</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1907.01470.pdf" target="_blank" rel="noopener">All-attention network</a></td>
<td>Enwik8</td>
<td>0.98</td>
<td>64</td>
</tr>
<tr>
<td>SRU++</td>
<td>Enwik8</td>
<td>0.97</td>
<td>7*</td>
</tr>
<tr>
<td>SRU++</td>
<td>Enwik8</td>
<td>0.96</td>
<td>15*</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/1809.10853.pdf" target="_blank" rel="noopener">Transformer</a></td>
<td>Wiki-103</td>
<td>18.7</td>
<td>22*</td>
</tr>
<tr>
<td><a href="https://arxiv.org/pdf/2002.09402v2.pdf" target="_blank" rel="noopener">Feedback Transformer</a></td>
<td>Wiki-103</td>
<td>18.2</td>
<td>214</td>
</tr>
<tr>
<td>SRU++</td>
<td>Wiki-103</td>
<td>18.4</td>
<td>8*</td>
</tr>
<tr>
<td>SRU++</td>
<td>Wiki-103</td>
<td>17.8</td>
<td>12*</td>
</tr>
</tbody>
</table>
<p>Table 1: Comparison of reported training costs (measured by total GPU days used) and test results between SRU++ and various Transformer models. (*) indicates mixed precision training. Numbers are lower the better.</p>
<p>Table 1 further compares the training cost of SRU++ and reported costs of leading Transformer-based models on <a href="http://mattmahoney.net/dc/textdata">Enwik8</a> and <a href="https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/">Wiki-103</a> datasets. Our model can achieve over 10x cost reduction while still outperforming the baseline models on test perplexity or BPC.</p>
<p><strong>2. Little attention is needed given recurrence</strong><br>
Similar to the observation of Merity (2019), we found using a couple of attention layers sufficient to obtain state-of-the-art results. Table 2 shows an analysis by only enabling the attention computation every k layers of SRU++.</p>
<table>
<thead>
<tr>
<td><strong>Number of layers w/ attention</strong></td>
<td><strong>Test BPC</strong><br>
(42M model)</td>
<td><strong>Test BPC</strong><br>
(108M model)</td>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1.190</td>
<td>–</td>
</tr>
<tr>
<td>1</td>
<td>1.033</td>
<td>0.991</td>
</tr>
<tr>
<td>2</td>
<td>1.032</td>
<td>0.980</td>
</tr>
<tr>
<td>5</td>
<td>1.025</td>
<td>0.977</td>
</tr>
<tr>
<td>10</td>
<td>1.022</td>
<td>0.974</td>
</tr>
</tbody>
</table>
<p>Table 2: Test BPC on Enwik8 dataset by varying the number of active attention sub-layers in SRU++ models. We tested two 10-layer SRU++ models with 42M and 108M parameters respectively. Most of the gains are obtained using 1 or 2 attention sub-layers. Numbers are lower the better.</p>
<h6>Conclusion</h6>
<p>We present a recurrent architecture with optional built-in self-attention that achieves leading model capacity and training efficiency. We demonstrate that highly expressive and efficient models can be derived using a combination of attention and fast recurrence. Our results reaffirm the empirical observations that attention is not all we need, and can be complemented by other sequential modeling modules.</p>
<p><em>For further reading, ASAPP also conducts research to reduce the cost of model inference. See our published work on model <a href="https://www.aclweb.org/anthology/2020.emnlp-main.494.pdf"><em>distillation</em></a> and <a href="https://www.aclweb.org/anthology/2020.emnlp-main.496.pdf"><em>pruning</em></a> for example.</em></p>
</div>
</div>
</div></div></div></div></div>]]>
            </description>
            <link>https://www.asapp.com/blog/reducing-the-high-cost-of-training-nlp-models-with-sru/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270124</guid>
            <pubDate>Fri, 26 Feb 2021 00:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Massachusetts Struggled to Make a Vaccine Website]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26270115">thread link</a>) | @morisy
<br/>
February 25, 2021 | https://www.zagaja.com/2021/02/vaccine-websites/ | <a href="https://web.archive.org/web/*/https://www.zagaja.com/2021/02/vaccine-websites/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In 1872, a fire broke out in the basement of a warehouse on Summer Street in Boston. As flames spread to nearby buildings, Boston firefighters called for backup. Neighboring towns responded, only to discover that their hoses would not fit into the hydrants. The couplings that connect the hydrants to the hoses had not been standardized. This hampered the help the firefighters could give, and thirty people died. 776 buildings burned. Fast forward to 2021. Companies and governments are trying to share information about vaccine appointments. Their systems cannot connect with each other. People cannot get shots. The death toll is ongoing. History does not repeat itself, but it does rhyme.</p>

<p>Why is government struggling to make a working vaccine registration website? Building software is challenging and requires experts to direct it. Massachusetts lacks professional development opportunities for its staff to develop the skills required to build modern software. Finally the government has yet to take leadership in establishing standards for the exchange of data within itself, never mind among a federation of private companies to which it delegated vaccine appointment responsibility.</p>

<p>Buying and building software is hard, which is why <a href="https://github.com/18F/technology-budgeting/blob/master/handbook.md#hire-tech-talent-in-house">agencies and budget offices need to hire technical talent in-house</a>. An agency in Massachusetts might have in-house lawyers to handle complex legal issues, but complex technical procurements are left to staff that have never written a line of code. Without that experience it is hard to spot issues and understand the effort required to undertake a task. Asking a software vendor whether they can do a particular thing is like asking a car salesman whether you need a new car: the answer will always be yes. We need experts who can tell us whether we <em>should</em> do a particular thing and <em>how</em> it should be done. Having technical talent at the table will make sure the right questions are being asked throughout the software procurement and oversight process.</p>

<p>Public servants succeed despite chronic underfunding of their efforts. You would be shocked at the leanness of the public sector. It makes the private sector look bloated. Responsibilities that might be an entire department at Google fall upon one or two state or municipal employees. Apple has Apple University to help its employees learn new skills. For public sector employees everything is learned on the fly and on your own. The Government of the United Kingdom has established the <a href="https://www.gov.uk/government/collections/gds-academy-course-descriptions">Government Digital Services Academy</a> to teach its public servants digital skills and techniques. We should do this in Massachusetts.</p>

<p>Finally the Commonwealth should establish a Data Standards Authority, modeled after the <a href="https://www.gov.uk/government/groups/data-standards-authority">same authority in the United Kingdom</a>. Standards are how we can have data couplings that let state agencies and municipalities talk with each other. As the Commonwealth adopts standards, the private sector will see this leadership and learn what it needs to do to share information on anything from vaccine appointments to construction plans. We can make sure when the next crises arrives, we can work together.</p>

<p>These steps would merely be a down payment on the work required to modernize state government. To make this work the state needs to successfully recruit, train, and retain product managers, designers, and developers in agencies across the Commonwealth. These individuals need to reflect the diversity of our community, and build their tools with empathy and understanding of existing people and ways. It will not happen overnight, but no place is better equipped to do this than Massachusetts.</p>

</div></div>]]>
            </description>
            <link>https://www.zagaja.com/2021/02/vaccine-websites/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270115</guid>
            <pubDate>Fri, 26 Feb 2021 00:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IsometricBlocks]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26270042">thread link</a>) | @autoditype
<br/>
February 25, 2021 | http://shaunlebron.github.io/IsometricBlocks/ | <a href="https://web.archive.org/web/*/http://shaunlebron.github.io/IsometricBlocks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="https://github.com/shaunew/IsometricBlocks"><img src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>


	

	<p>
In an <a href="http://en.wikipedia.org/wiki/Isometric_projection">isometric</a>
display, it can be tricky to draw boxes of various sizes in the correct order
to keep them appropriately in front of or behind one another.  The figure below
shows an example.  The blue box should be drawn first, then green, then red.
	</p>

	<figure>
		<canvas id="figure1a" width="350" height="200"></canvas>
		<canvas id="figure1b" width="350" height="200"></canvas>
		<figcaption>
Figure 1: The boxes on the left are <u>not</u> drawn in the correct order, whereas the
boxes on the right are drawn correctly.
		</figcaption>
		
	</figure>

	<p>
We will explore a simple solution for determining the correct order to draw a
given set of boxes.  But first, we must define what we mean by <em>boxes</em>.
	</p>

	<h3>What do we mean by <em>boxes</em>?</h3>

	<p>
We define boxes as <em>axis-aligned</em> and <em>non-intersecting</em>
rectangular prisms. Take a look at the above Figure 1 again.  Each box is
parallel to the <em>x</em>, <em>y</em>, and <em>z</em> axis (i.e.
axis-aligned).  Also, note that the boxes are next to each other but do not
intersect.
	</p>

	<h3>Determine if boxes overlap on screen.</h3>

	<p>
First of all, if two boxes do not overlap on the screen, then we do not have to
worry about which one is drawn first.  This is the first test we must perform,
which we explore in this section.
	</p>

	<figure>
		<canvas id="figure2a" width="350" height="200"></canvas>
		<canvas id="figure2b" width="350" height="200"></canvas>
		<figcaption>
Figure 2: No overlap on the left; overlap on the right.  (Note: we are talking
about overlap on screen, not intersection in space.)
		</figcaption>
		
	</figure>

	<p>
The silhouettes of the 3D boxes become 2D hexagons in the isometric view, as seen below.  We use the
outline of these silhouettes to test for overlap.
	</p>

	<figure>
		<canvas id="figure3a" width="350" height="200"></canvas>
		<canvas id="figure3b" width="350" height="200"></canvas>
		<figcaption>
Figure 3: The box silhouettes in an isometric view are simple hexagons.  Note
that their sides are always parallel to the vertical and two diagonal axes.
		</figcaption>
		
	</figure>

	<p>
We take advantage of the fact that the hexagon sides are always parallel to
some axis.  This allows us to easily determine if the hexagons overlap by
checking for intersection of their regions on each axis.  We add an <em>h</em>
(horizontal) axis to help.
	</p>

	<figure>
		<canvas id="figure4a" width="350" height="200"></canvas>
		<canvas id="figure4b" width="350" height="200"></canvas>
		<figcaption>
The red and blue boxes do not overlap on the h axis, therefore they do not overlap.
The green and blue boxes do overlap since their region on every axis overlap.
		</figcaption>
		
	</figure>

	<p>
Now that we have outlined our concept for <em>determining if two boxes overlap
on the screen</em>, we will fill in the details necessary for implementing it.
	</p>

	<p>
The act of flattening the 3D box into a 2D hexagon involves getting rid of the
Z coordinate.  Notice that increasing a point's Z coordinate by 1 is the same
as incrementing both X and Y coordinates by 1.  Thus, we can add Z to both X
and Y and drop Z completely.  Shown below is the source code for a function
that performs this conversion.
	</p>

<code>
<span>function</span> spaceToIso(spacePos) <span>{</span>

    
    <span>var</span> isoX = spacePos.x + spacePos.z;
    <span>var</span> isoY = spacePos.y + spacePos.z;

    <span>return</span> <span>{</span>
        x: isoX,
        y: isoY,

        
        h: (isoX - isoY) * Math.cos(Math.PI/6),

        
        v: (isoX + isoY) / 2;
    <span>}</span>;
<span>}</span></code>

	<p>
And finally, after determining the bounds of each hexagon, we can determine if
they overlap by using the source code below.
	</p>

<code><span>function</span> doHexagonsOverlap(hex1, hex2) <span>{</span>
    
    <span>return</span> (

        
        !(hex1.xmin &gt;= hex2.xmax || hex2.xmin &gt;= hex1.xmax) &amp;&amp;

        
        !(hex1.ymin &gt;= hex2.ymax || hex2.ymin &gt;= hex1.ymax) &amp;&amp;

        
        !(hex1.hmin &gt;= hex2.hmax || hex2.hmin &gt;= hex1.hmax));
<span>}</span></code>

	<p>
Now that we have determined if two boxes overlap on the screen, we can begin exploring how to determine which box is in front of the other.
	</p>

	<h3>Determine which box is in front.</h3>

	<p>
Recall that our boxes do not intersect each other. we can visualize their separation
as a thin plane between them (see Figure 5 below).  After identifying this
plane, we can determine which box is in front by selecting the one on the
correct side of this plane.
	</p>

	<figure>
		<canvas id="figure5a" width="230" height="200"></canvas>
		<canvas id="figure5b" width="230" height="200"></canvas>
		<canvas id="figure5c" width="230" height="200"></canvas>
		<figcaption>
Figure 5: A pair of blocks can be separated in one of three ways shown here.
The dark glass illustrates this separation.
		</figcaption>
		
	</figure>

	<p>
We can find this plane of separation by looking at each axis individually.  In
particular, we look for an axis which has non-intersecting box ranges (see
Figure 6 below).
	</p>

	<figure>
		<canvas id="figure6a" width="350" height="200"></canvas>
		<canvas id="figure6b" width="350" height="200"></canvas>
		<figcaption>
Figure 6: On the left, the blocks are separated on the y-axis.  On the right,
the blocks are separated on the x-axis. (The z-axis is omitted for simplicity.)
		</figcaption>
		
	</figure>

	<p>
In Figure 6 above, we have chosen a coordinate system which make lesser values
of <em>x</em> and <em>y</em> to be closer to the camera.  Though not shown, the
<em>z</em> axis is positive in the up direction, so a greater value makes it
closer to the camera.
	</p>

	<p>
The following is a javascript function for determining if the first block is in
front of the second:
	</p>

	<code><span>function</span> isBoxInFront(box1, box2) <span>{</span>

    
    
    <span>if</span> (box1.xmin &gt;= box2.xmax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.xmin &gt;= box1.xmax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>

    
    
    <span>if</span> (box1.ymin &gt;= box2.ymax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.ymin &gt;= box1.ymax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>

    
    
    <span>if</span> (box1.zmin &gt;= box2.zmax) <span>{</span> <span>return</span> <span>true</span>; <span>}</span>
    <span>else</span> <span>if</span> (box2.zmin &gt;= box1.zmax) <span>{</span> <span>return</span> <span>false</span>; <span>}</span>

<span>}</span></code>

	<h3>Draw boxes in the correct order.</h3>

	<p>
In general, <u>a box should not be drawn until all the ones behind it are
drawn</u>.  Thus, we begin by drawing the boxes that have nothing behind them.
Then, we can draw the boxes that are only in front of those that are already
drawn. This process continues until all boxes are drawn. (See Figure 4 below
for an example.)
	</p>

	<figure>
		<canvas id="figure7" width="650" height="200"></canvas>
		<figcaption>
Figure 4: (1) Nothing is behind blue, so draw it first. (2) Draw green next
since blue was the only one behind it and is already drawn.  (3) Then draw red,
since both blocks that were behind it have been drawn.
		</figcaption>
		
	</figure>

	<p>
To implement this algorithm, each box must know exactly which boxes are behind
it.  We have already determined how to do this in the last section.  A search
must be implemented so that each box has a list of boxes behind it.
	</p>

	<p>
You are now armed with everything you need to know to render isometric boxes in
the correct order.
	</p>

	<h3>A conundrum</h3>

	<p>
It is possible to have a situation seen in the figure below.  The aforementioned drawing
methods dictate that we first draw the box with nothing behind it, but this example illustrates
a case where this cannot be done.
	</p>

	<figure>
		<canvas id="figure8" width="650" height="200"></canvas>
		<figcaption>
Here are three boxes intertwined in a way such that one is always behind
another.  This prevents us from drawing a first box.
		</figcaption>
		
	</figure>

	<p>
The figure above cheats by segmenting the orange box into two.
This is one method of breaking this type of cycle.
	</p>

	<p>
There are formal methods used for detecting
such cycles mentioned in the appendix.  After detection of a cycle, the blocks in that cycle
could be drawn with special clipping regions to respect front boxes or to segment a block or blocks
that will break the cycle.  These are solutions that I will be exploring and updating this article as
my experiments progress.
	</p>

	<hr>
	<h2>Appendix</h2>

	<h4>A formal description of the solution</h4>

	<p>
This is a special case of the <a href="https://en.wikipedia.org/wiki/Painter%27s_algorithm">Painter's Algorithm</a>,
which handles occlusion by drawing back-to-front.
	</p>

	<p>
For those who are interested, our method for determining if hexagons and boxes
are overlapping is a result of the <a href="http://en.wikipedia.org/wiki/Hyperplane_separation_theorem">hyperplane separation theorem</a>.
	</p>

	<p>
Also, the way in which we determined the drawing order of the boxes is known in graph theory as a <a href="http://en.wikipedia.org/wiki/Topological_sorting">topological sort</a>,
which is essentially a depth-first search of a directed graph.
	</p>

	<p>
You can build a directed graph of the <em>boxes</em>, with directed edges to
the boxes that are behind it.  Topologically sorting this graph will produce an
ordered list of boxes that can be drawn in that exact order.
	</p>

	<p>
Mathematicians will recognize this directed graph as a <a href="http://en.wikipedia.org/wiki/Partially_ordered_set">partially ordered
set</a>.
	</p>

	<p>
Finally, to prevent the aforementioned cycle conundrum, we can use <a href="">Tarjan's
strongly connection components</a> algorithm.  After computing these cycles,
one could either split a block to prevent a cycle, or to use a clipping region
to prevent drawing over any blocks that are supposed to be in front of it.
	</p>

	<h4>Alternative Solutions</h4>

	<p>
You may be able to just use <a href="https://en.wikipedia.org/wiki/Z-buffering">Z-buffering</a>,
though drawing order is still important for transparent sprites.  Also, if all
bounding boxes are unit cubes, sorting is much simpler.
	</p>

	<h4>Full example of working code</h4>

	<p>
All the diagrams above were created using a simple isometric box renderer
written in Javascript, which applies all the techniques described in this
article.  You can study the fully annotated source code on <a href="https://github.com/shaunew/IsometricBlocks">IsometricBlocks project on
GitHub</a>.
	</p>

	<h4>Real game examples</h4>

	<ul>
		<li><a href="http://andrewrussell.net/2016/06/how-2-5d-sorting-works-in-river-city-ransom-underground/">How 2.5D Sorting works in River City Ransom: Underground</a> - allowing bounding boxes to intersect by specifying heightmaps within them (<a href="https://news.ycombinator.com/item?id=12313271">summary</a>)</li>
		<li><a href="http://bannalia.blogspot.co.uk/2008/02/filmation-math.html">Filmation engine on the ZX Spectrum</a></li>
	</ul>
	

	<h4>Thanks</h4>

	<p>
Thanks to Ted Suzman at <a href="http://playbuildy.com/">buildy</a> for
introducing this problem and solution to me.  And thanks to adamhayek for <a href="http://www.reddit.com/r/gamedev/comments/18222r/how_to_determine_the_draw_order_for_an_isometric/c8ayzby">further
insight</a> on a general solution. And thanks to <a href="http://www.reddit.com/r/gamedev/comments/18bg95/tutorial_how_to_render_isometric_blocks_correctly/c8dfx51">Slime0 at reddit</a> for pointing out errors in this article by illustrating the cycle example shown in this article, and for illustrating why we cannot deduce relative drawing order between two non-overlapping boxes.
Thanks to <a href="https://lobste.rs/s/bengjo/drawing_isometric_boxes_correct_order/comments/rzgvnc#c_rzgvnc">Mark Nelson</a> for extra context on painter's algorithm and z-buffering.
	</p>

	<hr>

	<figure>
		<canvas id="figure5" width="700" height="200"></canvas>
		
	</figure>



</div>]]>
            </description>
            <link>http://shaunlebron.github.io/IsometricBlocks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26270042</guid>
            <pubDate>Fri, 26 Feb 2021 00:08:02 GMT</pubDate>
        </item>
    </channel>
</rss>
