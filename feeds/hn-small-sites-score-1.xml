<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 15 Jul 2020 12:20:39 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 15 Jul 2020 12:20:39 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[GNU: A Heuristic for Bad Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23819964">thread link</a>) | @some_furry
<br/>
July 13, 2020 | https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>If you see the letters GNU in a systems design, and that system intersects with cryptography, I can almost guarantee that it will be badly designed to an alarming degree.</p>



<p>This is as <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">true of GnuPG (and PGP in general)</a> as it is of designs like the proposed <a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html">GNU Name System</a> (IETF draft) and cryptographic libraries like GnuTLS and libgcrypt. In fact, I cannot recall single GNU-branded cryptography project that isn’t a roaring dumpster fire.</p>



<p>I will elaborate.</p>



<h2>Problems with the GNU Name System’s Cryptography</h2>



<h3>Asymmetric Cryptography</h3>



<p>The GNS (GNU Name System) uses an unconventional construction for zones:</p>



<blockquote><p>A zone in GNS is defined by a public/private ECDSA key pair (d,zk), where d is the private key and zk the corresponding public key. GNS employs the curve parameters of the twisted edwards representation of Curve25519 [<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC7748">RFC7748</a>] (a.k.a. edwards25519) with the ECDSA scheme ([<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC6979">RFC6979</a>]).</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-zones">GNU Name System IETF Draft, section 2</a></cite></blockquote>



<p>This is beyond weird: Going out of your way to use the edwards25519 curve from RFC 7748, but not use the Ed25519 signature algorithm, but still choosing to use deterministic ECDSA (RFC 6979).</p>



<p>(If you’re lost, I wrote about digital signature algorithms in <a href="https://soatok.blog/2020/04/26/a-furrys-guide-to-digital-signature-algorithms/">a previous blog post</a>.)</p>



<p>The authors acknowledge the unconventional nature of their design choice in section 9.1 of the RFC draft:</p>



<blockquote><p>GNS uses ECDSA over Curve25519. This is an unconventional choice, as ECDSA is usually used with other curves. However, traditional ECDSA curves are problematic for a range of reasons described in the Curve25519 and EdDSA papers. <strong>Using EdDSA directly is also not possible, as a hash function is used on the private key which destroys the linearity that the GNU Name System depends upon.</strong> We are not aware of anyone suggesting that using Curve25519 instead of another common curve of similar size would lower the security of ECDSA. GNS uses 256-bit curves because that way the encoded (public) keys fit into a single DNS label, which is good for usability.</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-cryptography">GNU Name System IETF Draft, section 9.1</a></cite></blockquote>



<p><s>The bold statement (my emphasis) is nonsense: In any design that uses digital signature algorithms, your system should map a private key (some opaque byte string) to a public key (some other opaque byte string) and signatures should also be opaque byte strings. The inclusion of a hash function under the hood of the signature algorithm is a moot point, especially since RFC 6979 also uses HMAC-SHA2 to generate deterministic nonces, thereby rendering their choice of RFC 6979 a contradiction of their stated goal.</s> Edit: <a href="#update-2020-07-09">see below</a>.</p>



<p>Using Ed25519 with a 32-byte private key (instead of a 64-byte private key) is also trivial. To wit: Libsodium offers <a href="https://libsodium.gitbook.io/doc/public-key_cryptography/public-key_signatures#key-pair-generation">crypto_sign_seed_keypair()</a> for this purpose.</p>



<p>But even worse: ECDSA is less secure and slower than EdDSA, even when you use the same curves, due to how the algorithms are implemented. The authors of the RFC do not defend this design choice beyond this hash function non sequitur.</p>



<div><figure><img data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I can’t be the only one feeling this way right now. Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.</figcaption></figure></div>



<h4 id="update-2020-07-09">(Update) “But They Need Hierarchical Keys”</h4>



<p>After I initially posted this, Redditor Steve132 informed me that <a href="https://www.reddit.com/r/crypto/comments/hnlyp1/gnu_a_heuristic_for_bad_cryptography/fxdbez4/">I overlooked the reason they made this design decision</a>.</p>



<blockquote><p>Take a look at Section 6.1&nbsp;<a rel="noreferrer noopener" href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion" target="_blank">https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion</a></p><blockquote><p>From here, the following steps are recursively executed, in order: Extract the right-most label from the name to look up. Calculate q using the label and zk as defined in Section 4.1.</p></blockquote><p>So then if you go to section 4.1, they do h=H(&lt;address string&gt;), (r,R) is some root keypair, then they do C (a child public key), C=hR, then q=H(C).</p><p>the idea behind the calculation of q is to use the root public key to derive a child public key from ONLY the root public key, exploiting the linearity property that in elliptic curves, if bG=B, then (b+s)G=(sG+B)</p><p>This allows a third party to derive child public keys without any knowledge of the private keys for the root. This technique is also used in bitcoin’s bip32 (<a rel="noreferrer noopener" href="https://en.bitcoin.it/wiki/BIP_0032" target="_blank">https://en.bitcoin.it/wiki/BIP_0032</a>) for ‘unhardened’ derivation scheme.</p><cite>Part of Steve132’s correction</cite></blockquote>



<p>I fully admit, I didn’t absorb this detail in my first pass of the RFC draft. It wasn’t clearly spelled out in Section 9 (which aims to justify their cryptography decisions), and I didn’t read the other sections as carefully. This was my mistake.</p>



<p>However, even with this explanation in mind, my original point that this design choice is both unconventional and unnecessary still stands, because <a href="https://ieeexplore.ieee.org/abstract/document/7966967?section=abstract">BIP32-Ed25519</a> already exists (albeit, it still needs <a href="https://forum.web3.foundation/t/key-recovery-attack-on-bip32-ed25519/44">a carefully designed implementation</a> to be secure against active attackers). </p>



<p>Therefore, the GNU Name System developers didn’t need to roll their own design, they could have used one that’s already seen real-world deployment instead. Why take on unnecessary risk?</p>



<p>Furthermore, trying to push through an implementation of ECDSA over edwards25519 isn’t just unnecessary and weird, it’s also probably dangerous, as Thai Duong noted:</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">While I don't agree that ECDSA is worse than Ed25519 – both have pros and cons — it takes courage to implement ECDSA over Edward25519. Do you know if they published any code?  This unfortunate marriage may introduce fun and unique bugs</p>— thaidn (@XorNinja) <a href="https://twitter.com/XorNinja/status/1281041946538938368?ref_src=twsrc%5Etfw">July 9, 2020</a></blockquote></div>
</div><figcaption>Thai Duong–author of the BEAST attack against SSL/TLS, among <a href="https://github.com/google/tink">other</a> <a href="https://github.com/google/wycheproof">things</a></figcaption></figure>



<p>Of course, all cryptography development can be said to be dangerous, but there are other problems fundamental to the GNU Name System design that makes any departure from a well-tread path very suspect.</p>



<h3>Symmetric Cryptography</h3>



<p>The GNU Name System project doesn’t stop there. It further throws <a href="https://tonyarcieri.com/all-the-crypto-code-youve-ever-written-is-probably-broken">IND-CCA2 security</a> out the window and specifies encrypting with AES and TwoFish in a cipher cascade, using Cipher Feedback (CFB) mode.</p>



<p>The authors do not even attempt to defend this decision. Typically this happens when the authors do not understand the risks involved. I sincerely doubt they’ve heard the words “adaptive chosen-ciphertext attack” in the course of their self-study.</p>



<p>(Because, y’know, attackers will surely never be able to replay UDP traffic if a runtime exception occurs because of corrupted data.)</p>



<h4>“Why Is This Bad?”</h4>



<p>Cipher cascades are usually the result of “we want to defend against a backdoored or broken cipher”. Bear in mind, the cipher itself is rarely the first part of a cryptosystem to be broken.</p>



<p>On that note, TwoFish isn’t <a href="https://blog.cryptographyengineering.com/2012/10/09/so-you-want-to-use-alternative-cipher/">the worst choice</a> of a cascade partner for AES, but I’d prefer a design that employed a different paradigm (since AES is a SPN permutation block cipher, an ARX-based stream cipher like Salsa20 or ChaCha seems reasonable).</p>



<p>AES is a boring choice, because it’s the industry standard. I’m not <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">particularly fond of AES</a> (due to it not being fast and constant-time in pure software implementations), but if you use it in an authenticated mode (AES-GCM, AES-CCM, AES-EAX, AES-OCB3, … I dunno, Poly1305-AES? Just use an AEAD mode!), it’s fine.</p>



<p><strong>Cipher Feedback (CFB) mode is not an authenticated mode.</strong></p>



<p>If you’re publishing a cryptography design in 2020 that fails the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>, you need to go back to the drawing board.</p>



<h4>“But They Use Digital Signatures”</h4>



<p><a href="https://blog.cryptographyengineering.com/2016/03/21/attack-of-week-apple-imessage/">Cough.</a></p>







<h2>Other GNU Projects</h2>



<p>If you want to learn about why GnuPG (and the PGP ecosystem in general) is terrible, I recommend <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">Latacora’s takedown</a>.</p>



<p>GnuTLS is an SSL/TLS library created by the same people who created (and then abandoned) libmcrypt, which was the scourge of <a href="https://meta.stackoverflow.com/questions/293930/problematic-php-cryptography-advice-in-popular-questions">bad cryptography in the PHP ecosystem</a> for many years (until it was <a href="https://wiki.php.net/rfc/mcrypt-viking-funeral">finally excised in PHP 7.2</a>). Consequently, the project’s <a href="https://www.gnutls.org/security-new.html">CVE history</a> should be no surprise.</p>



<p><strong>Quick story:</strong> Many years ago, a few timing attacks were discovered in libgcrypt by regular chatters in Freenode’s ##crypto channel. This led a lot of us <a href="https://lists.gnupg.org/pipermail/gcrypt-devel/2015-November/003618.html">to look at libgcrypt for more bugs</a>.</p>



<p>The general consensus of the ensuing IRC discussion was, roughly, “We probably shouldn’t try to fix them all, because a) that’s way too much effort because there’s too much badness and b) this library will be a ripe target for upcoming cryptanalysis researchers to get their first papers published for many years”. And, indeed, the attack papers that have come out over the years that affect libgcrypt <a href="https://eprint.iacr.org/2020/432">haven’t disappointed</a>.</p>



<p>To be clear, at the time this happened, I was garbage at writing C (and somehow even less confident than capable) and barely making ends meet, so “drop everything and volunteer to fix all the libgcrypt badness” wasn’t a tenable option for me. And since the world is largely moving away from GnuPG and libgcrypt, it honestly isn’t worth the effort trying to fix all the bad when an easier fix is “use something good instead”.</p>



<h2>Takeaway</h2>



<p>If you see the letters GNU anywhere in a project that intersects with cryptography–except for its public license–it’s almost certainly an error-prone cryptographic design.</p>



<p>Or, as my friend Kye calls it:</p>



<figure><div>

</div><figcaption>The Dunning-GNUger Effect.</figcaption></figure>



<h2>What To Use Instead?</h2>



<p>To replace GPG, you want <a href="https://age-encryption.org/">age</a> and <a href="https://jedisct1.github.io/minisign/">minisign</a>.</p>



<p>To replace GnuTLS or libgcrypt, depending on what you’re using it for, you want one of the following: s2n, OpenSSL/LibreSSL, or Libsodium.</p>



<p>For embedded systems, BearSSL is a good options today and <a href="https://www.reddit.com/r/crypto/comments/hdc4o6/new_results_on_gimli_fullpermutation/fvmpnym/">libhydrogen v2</a> will be an attractive choice when it’s released.</p>



<hr>



<p>Header image, like the GnuNet logo <a href="https://commons.wikimedia.org/wiki/File:Official_logo_of_the_GNUnet_project.svg">found here</a>, is available under the&nbsp;<a href="https://en.wikipedia.org/wiki/en:Creative_Commons">Creative Commons</a>&nbsp;<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">Attribution-Share Alike 4.0 International</a>&nbsp;license.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819964</guid>
            <pubDate>Mon, 13 Jul 2020 12:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Douglas Mason: How to Build ML Solutions for Twitter, Pinterest and Amazon Music]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819921">thread link</a>) | @FHMS
<br/>
July 13, 2020 | https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We caught up with <strong>Douglas Mason</strong>, data scientist and CEO of <a href="https://www.koyotescience.com/">Koyote Science</a>. Douglas is building machine learning models to predict COVID-19 outbreaks. He freely shared his wisdom and some lessons learned from decades of data science work in large companies such as Pinterest, Twitter, and AWS (Amazon).&nbsp;</p><h2><strong>Douglas’s background</strong></h2><p>Douglas took a unique path to becoming a data scientist. Although computers were always part of his household growing up, he thought they were boring, and he told his family he would “never study computer science.”</p><p>Instead, Douglas went to USC to study filmmaking, thinking he’d follow his dream of becoming a film director. Soon, he realized that filmmaking school wasn’t all he’d imagined it would be, and he took up classical guitar instead. From there, he accidentally discovered a passion for theoretical physics, which he found fascinating (and which paid more than guitar playing).</p><p>Not long after, Douglas discovered his interest in data science and climbed the ranks until he was heading engineering and data science teams at Twitter, Pinterest, and AWS. He describes working in the field as feeling like he’s living in a science fiction film.</p><blockquote>“When I work on that kind of stuff, I feel like Doctor Strange — as if I’m in the Multiverse. You actually get to live this Rick and Morty parallel-universe life.”</blockquote><p>But Douglas wasn’t content with using his expertise to improve revenue at large corporations, so he went on to found his own business, Koyote Science. He’s currently focused on building COVID-19 models to predict outbreaks.</p><h2><strong>Lessons learned from shipping machine learning projects</strong></h2><p>Douglas’s success hasn’t come without some hard-earned lessons. He told us about some of the challenges he’s seen across many of the teams and projects he’s worked on.</p><h3><strong>Lesson 1: Use machine learning to work with users instead of taking over&nbsp;</strong></h3><p>At Twitter, Douglas worked on a feature called “who to follow.” This gives Twitter users personalized recommendations about which accounts might be interesting for them. As a data scientist, Douglas discovered that people used this feature a lot. At first, it seemed great — people were following nearly everyone it recommended. But in the longer term, people who used this feature <strong>visited Twitter less</strong>.&nbsp;</p><p>Their feeds were filled with tweets chosen <strong>by an algorithm</strong>, rather than tweets from people they chose<strong> </strong>themselves.</p><p>By reducing<strong> </strong>the number of “who to follow” recommendations, Douglas improved <strong>long-term</strong> engagement.</p><p>It’s common knowledge that long-term and short-term goals often conflict, but Douglas discovered a deeper lesson here. As machine learning solutions become more capable, it’s often tempting to use them to do too much. This is almost always a mistake. Douglas says:</p><blockquote>“I aim to build products that work with the user rather than trying to take over from the user.”</blockquote><p>AI as depicted in science fiction — with human-level intelligence — is probably to blame for the fact that many people try to <strong>do too much </strong>with machine learning. In many cases, it’s best used to <strong>augment </strong>human actions rather than replace them.</p><h3><strong>Lesson 2: Data pipelines and good engineering are more important than math and algorithms</strong></h3><p>People get very excited about <strong>new machine learning algorithms</strong>. First we had neural networks (NNs), then convolutional neural networks (CNNs), then generative adversarial networks (GANs), transformers, and more. Algorithms are fun and exciting to talk about and explore.</p><p>But Douglas, a self-confessed math nerd, has learned that the math and algorithms tend to get far too much attention, while real success comes from <strong>good data, good engineering, focusing on the customer’s problem, </strong>and <strong>not getting trapped in the math.</strong> He says:</p><blockquote>“It's very, very rare for the algorithm to make the difference. It's almost always the data pipeline. In my work, I have been able to reduce errors by 90% with a data pipeline, compared to 75% with a better algorithm. And yet everyone wants to talk to me about the algorithm, but no one wants to talk about the data pipeline.”</blockquote><p>We use metaphors that associate machine learning algorithms with neuroscientists and data pipelines with plumbing, so it’s not surprising which one grabs popular attention. Douglas found success by focusing on the less glamorous aspects of machine learning. In most cases, deciding <strong>what data to use </strong>and <strong>how to present it to the algorithm</strong> is more important than the algorithm itself.</p><h4>Focus on the customer’s goals</h4><p>Many “AI startups” today talk far more about <strong>the solutions they provide</strong> than the <strong>problems they solve</strong>, and Douglas has learned to maintain a laser focus on customer goals. Sometimes this means pulling himself away from the more enticing theoretical aspects of machine learning. He says:&nbsp;</p><blockquote>“As a mathematician, I love all the nuances of the math, and easily get lost in it. But the reality is that there's an infinite amount of math out there to learn. It's not feasible to lock myself in my room and learn all the math before I focus on customer goals.”</blockquote><p>The truth that many data scientists don’t want to hear is that successful machine learning solutions are not usually about creating something new, powerful, and exciting. More often, seeing problems from the correct angle and using tried and tested approaches is what you need.</p><h4>Work with and learn from experienced engineers</h4><p>Douglas has personally engineered many successful machine learning solutions and led teams of software engineers, but he remains modest about his engineering ability and emphasizes the <a href="https://datarevenue.com/en-blog/hiring-machine-learning-engineers-instead-of-data-scientists">importance of <strong>solid engineering</strong></a>.</p><blockquote>“At Amazon, I let the engineers do as much as possible, because they're better than me at engineering. I would love to give you another answer, but they're efficient, they're thoughtful, they've seen these structures before, so they know about implementation details.”</blockquote><p>It’s not all smooth sailing though. Douglas acknowledges the difficulties of getting different experts to work with each other, especially when highly technical people tend to have very strong opinions about tiny decisions.</p><p>The best way he’s found to get everyone on the same page is by constantly releasing Minimal Viable Products (MVPs), which takes us to our next lesson.</p><h3><strong>Lesson 3: Always build Minimum Viable Products (MVPs)</strong></h3><p>Douglas swears by MVPs, which demonstrate core pieces of a solution, even if many of the features are missing. When developing a machine learning solution, he’ll aim to deliver a new MVP <strong>every week.</strong></p><p>He uses these to:&nbsp;</p><ul role="list"><li><strong>Avoid traps: </strong>If a project is taking too long, the difficulty of building even an MVP can be used to argue that the project should be cut early, before years of effort are wasted. Douglas says:</li></ul><p>“If something ends up being way harder and I keep doing MVPs and never reach the goals, then that gives us information about the difficulty of what we're attempting to do.”</p><ul role="list"><li><strong>Communicate</strong>: Both technical and non-technical people tend to better understand things they can see and use, rather than abstract ideas.</li></ul><p>“People's response to an abstract concept of something is often completely different to their response when they see something real. That's why I'm always putting out MVPs. People who are looking from a higher-level perspective can gain the required intuition to give me feedback.”</p><p>It’s better to have to trash two weeks of work than two months, and MVPs can help with this.</p><p>MVPs have other benefits too. By releasing stripped-down versions of a solution, Douglas often discovers that less is more.</p><blockquote>“What you end up delivering is often much simpler than the thing you originally intended to do, but it's refined.”</blockquote><p>Of course, customers are sometimes unhappy when it turns out that the best solution was the simplest one. Douglas compares building machine learning solutions to creating art: it’s about the time that went into development, not the effort required for the final product.</p><blockquote>“There’s a classic Zen story about a king who hires an artist. The artist works for a year, but then paints the final painting in only three seconds. When the king complains, the artist says, ‘Oh, I spent a year trying to paint much harder things.’”</blockquote><p>MVPs keep you open to finding a <strong>better, simpler </strong>solution, even late in the development process, and it’s important to stay agile so you can pivot to these better solutions if necessary.</p><p>People often think something has to be <strong>complicated </strong>in order to be <strong>powerful</strong>,<strong> </strong>but in fact the opposite is often true.</p><h3><strong>Lesson 4: Control and precision are more important than size and power</strong></h3><p>Large machine learning models, such as GPT-3, are exciting and often make their way into headline news. But Douglas compares large models to early (failed) attempts to build planes. These planes competed against the famous, successful plane built by the Wright Brothers. What made them different? The Wright Brothers focused on <strong>control</strong>,<strong> </strong>while their competitors were going for <strong>size and power.</strong></p><blockquote>“What the Wright brothers did that was so ingenious was that they didn’t go for bigger engines. They were bicycle mechanics. They didn't even use powerful engines. And instead, what they focused on was control.”</blockquote><p>This is similar to machine learning models. As Douglas says:&nbsp;</p><blockquote>“We made the biggest model that does all this stuff. But then people ask, ‘How do I interpret this stuff?’ ‘How do I control it?’ ‘How do I make sure that my models don't go off the rails?’”</blockquote><p>Large machine learning models might often be more powerful, but unless they solve real problems, they’re not useful. If a model produces amazing results <strong>unpredictably</strong> and only <strong>some of the time</strong>, that’s not useful. If a model produces accurate results but we don’t <strong>understand why</strong> and can’t be sure the results will <strong>always be accurate</strong>, then that’s also not useful.</p><p>Instead, smaller, simpler, and arguably less powerful models that offer more <strong>interpretability</strong> and <strong>consistency</strong> are more valuable in nearly every case. Just like with flying, we need to be able to steer and to land, not just to go fast.</p><h2><strong>Shipping machine learning projects successfully</strong></h2><p>Douglas shared many lessons in our chat with him, but these were his most important …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819921</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a Data Delivery Network]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819918">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/data-delivery-network | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/data-delivery-network">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#how-content-delivery-networks-work" as="#how-content-delivery-networks-work">How content delivery networks work</a></li><li><a href="#why-do-you-need-a-backend-anyway" as="#why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</a><ol><li><a href="#alternatives-to-crud-services" as="#alternatives-to-crud-services">Alternatives to CRUD services</a></li><li><a href="#splitgraphs-architecture" as="#splitgraphs-architecture">Splitgraph's architecture</a></li></ol></li><li><a href="#data-delivery-network" as="#data-delivery-network">Data delivery network</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p>Serverless and edge computing have allowed application developers to bring their applications closer to the end user.</p><p>Instead of maintaining a group of servers in a single location, developers can let companies like Cloudflare, Fastly or Akamai handle their content delivery.</p><p>With <a href="https://en.wikipedia.org/wiki/Function_as_a_service" as="https://en.wikipedia.org/wiki/Function_as_a_service">Function as a service</a>, companies pay for what they use. They can avoid having to provision a server that stays idle most of the time.</p><p>In this article, we want to talk about these trends and how we can apply them to databases. We'll also talk about our decision to make the API for our Splitgraph registry work over a public SQL connection. We'll use this experience to propose the idea of a <strong>data delivery network</strong>.</p><section><h2 id="how-content-delivery-networks-work">How content delivery networks work</h2><p>Content delivery networks provide a straightforward way to scale a read-only HTTP layer. They use existing HTTP cache semantics like the Cache-Control header. The developer only needs to point their DNS records to use the CDN's nameservers. The CDN handles everything else for them. It has points of presence around the world and peering agreements with other ISPs. It can selectively cache data, handle DDoS protection and offer extra services on top.</p><p>The value proposition behind edge computing is simple. For a lot of companies, scaling compute is not their core competency. They can spend time and money provisioning servers and configuring something like Varnish. Or, they can use services that will handle scaling and caching for them.</p><p>However, applications still need to run SQL queries. A CDN doesn't completely help an application that performs client-side rendering. The database becomes the next performance bottleneck in scaling a service.</p><p>There are many ways to scale a database, for example, replication or sharding. But again, this requires specialist knowledge about a database that is easy to get wrong.</p></section><section><h2 id="why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</h2><p>Let's change gears and consider a classic Web application. It consists of the frontend, the backend and the database.</p><p>There are several purposes that a backend serves:</p><ul><li><p><strong>Business logic</strong>. The backend converts higher level API calls into low-level SQL queries. It prepares data for presentation and writes it back when needed.</p></li><li><p><strong>Authorization</strong>. The backend acts as a security barrier, validating API calls. This is necessary because the frontend is running on the user's machine: the client is not trusted.</p></li><li><p><strong>Multiplexing</strong>. A database connection has a larger overhead than an HTTP connection. A backend can shunt hundreds of simultaneous clients over to a few database connections.</p></li></ul><section><h3 id="alternatives-to-crud-services">Alternatives to CRUD services</h3><p>One big issue with writing RESTful backends is that there's a lot of boilerplate. The programmer has to write very similar code to handle every action. They have to care of validation, typechecking and handling edge cases.</p><p>Libraries like <a href="https://postgrest.org/en/latest/" as="https://postgrest.org/en/latest/">PostgREST</a> and <a href="https://www.graphile.org/postgraphile/" as="https://www.graphile.org/postgraphile/">Postgraphile</a> have helped developers decrease iteration times. They introspect database schemas and generate REST and GraphQL APIs for them.</p><p>PostgREST and Postgraphile perform their authorization using database methods like <a href="https://postgrest.org/en/v7.0.0/auth.html" as="https://postgrest.org/en/v7.0.0/auth.html">row level security</a>. In essence, they decrease the size of the <a href="https://en.wikipedia.org/wiki/Trusted_computing_base" as="https://en.wikipedia.org/wiki/Trusted_computing_base">"trusted computing base"</a>.</p><p>Often, services that use these kinds of tools don't even have a separate backend. Client side code can call the automatically generated GraphQL/REST API directly.</p></section><section><h3 id="splitgraphs-architecture">Splitgraph's architecture</h3><p>The database can perform a lot of work that the backend does more quickly and more efficiently.</p><p>We use this idea in the API for the Splitgraph registry that allows you to push and pull <a href="https://www.splitgraph.com/docs/concepts/images">data images</a>. A <a href="https://www.splitgraph.com/docs/architecture/sgr-client">Splitgraph client</a> can access it over a normal PostgreSQL connection to <code>postgresql://data.splitgraph.com:5432/sgregistry</code>.</p><p>Our API implements all <strong>business logic</strong> as PostgreSQL functions. This has a few immediate advantages:</p><ul><li>Lets PostgreSQL precompile them</li><li>Avoids an extra hop from the backend, decreasing latency</li><li>Makes basic validation and type checking trivial. It's not possible to call a function with a wrong number of arguments or different types.</li></ul><p>For more complex logic, we wrote it in higher-level languages like <a href="https://www.postgresql.org/docs/current/plpython.html" as="https://www.postgresql.org/docs/current/plpython.html">PL/Python</a> or PL/Lua. PostgreSQL even supports languages like C or JavaScript.</p><p>We solved the problem of <strong>multiplexing and authorization</strong> by adding <a href="https://www.pgbouncer.org/" as="https://www.pgbouncer.org/">PgBouncer</a>, a connection pooler, in front of our database. Our fork of PgBouncer injects a signed cookie into every transaction as a local variable. Downstream procedures validate this cookie for authentication and authorization. This lets us decouple PostgreSQL users from application users. Multiple inbound sessions can use the same connection.</p><p>Our fork of PgBouncer even inspects queries on the fly and filters them. This makes sure that the client can only call Splitgraph SQL API functions.</p><p>For the web frontend at <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com/">www.splitgraph.com</a>, we use Postgraphile. Besides not having to write an extra API server, it lets us generate TypeScript client code.</p></section></section><section><h2 id="data-delivery-network">Data delivery network</h2><p>We can apply these ideas and concepts to the problem of building a <strong>"data delivery network"</strong>. Such a network would completely abstract away all the issues around making sure that data is available at the edge. It can also provide plenty of other useful services.</p><p>Here's a quick sketch of what a DDN's administration interface would look like:</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200713-data-delivery-network/admin-panel.png"></p><p>To use a DDN, a developer would create a read-only account on their database and give the DDN the credentials. It will then make a few services available:</p><p>The DDN will create an <strong>SQL endpoint</strong>. Any existing SQL client or application will be able to connect to it and run queries.</p><p>Besides SQL, the DDN will also be able to introspect the origin database and provide <strong>REST and GraphQL API endpoints</strong>. A client, running in the user's web browser, can use these endpoints instead of a backend server.</p><p>The DDN will be able to <strong>cache</strong> read-only SQL transactions with configurable policies. It will only forward the query to the origin database if there's a cache miss or expiry.</p><p>The client code doesn't need to be trusted. The DDN can intercept and <strong>firewall</strong> queries or <strong>rate limit</strong> them. To simplify migrations, the DDN can <strong>rewrite</strong> queries on the fly before forwarding them.</p><p>The DDN's work doesn't need to stop at handling queries. It can also manage <strong>data imports and exports</strong>. For example, it can make data from other services available to clients. Or, it can export data to Google Sheets or a data warehouse.</p><p>In the case of Splitgraph, we envision you being able to even run a <code>JOIN</code> across a public Splitgraph image and your private data.</p></section><section><h2 id="conclusion">Conclusion</h2><p>The database is the next frontier of serverless and edge computing. One of Splitgraph's goals is building a data delivery network to handle these problems.</p><p>If you're interested in learning more about Splitgraph, you can check our <a href="https://www.splitgraph.com/docs/getting-started/frequently-asked-questions">frequently asked questions</a> section, follow our <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">quick start guide</a> or visit our <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">website</a>.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/data-delivery-network</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819918</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp GUI Toolkits]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819896">thread link</a>) | @ogogmad
<br/>
July 13, 2020 | https://lispcookbook.github.io/cl-cookbook/gui.html | <a href="https://web.archive.org/web/*/https://lispcookbook.github.io/cl-cookbook/gui.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" <p=""><p>Lisp has a long and rich history and so does the development of
Graphical User Interfaces in Lisp. In fact, the first GUI builder was
written in Lisp (and sold to Apple. It is now Interface Builder).</p>

<p>Lisp is also famous and unrivalled for its interactive development
capabilities, a feature even more worth having to develop GUI
applications. Can you imagine compiling one function and seeing your
GUI update instantly? We can do this with many GUI frameworks today,
even though the details differ from one to another.</p>

<p>Finally, a key part in building software is how to build it and ship
it to users. Here also, we can build self-contained binaries, for
the three main operating systems, that users can run with a double
click.</p>

<p>We aim here to give you the relevant information to help you choose
the right GUI framework and to put you on tracks. Don’t hesitate to
<a href="https://github.com/LispCookbook/cl-cookbook/issues/">contribute</a>, to
send more examples and to furnish the upstream documentations.</p>



<p>In this recipe, we’ll present the following GUI toolkits:</p>

<ul>
  <li><a href="https://www.tcl.tk/">Tk</a> with <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a></li>
  <li><a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a> with <a href="https://github.com/Shinmera/qtools">Qtools</a></li>
  <li><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> with <a href="https://github.com/lispnik/iup/">lispnik/iup</a></li>
  <li><a href="https://www.gtk.org/">Gtk3</a> with <a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a></li>
  <li><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> with <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a></li>
</ul>

<p>In addition, you might want to have a look to:</p>

<ul>
  <li>the <a href="http://www.lispworks.com/products/capi.html">CAPI</a> toolkit (Common Application Programming Interface),
which is proprietary and made by LispWorks. It is a complete and cross-platform
toolkit (Windows, Gtk+, Cocoa), very praised by its users. LispWorks
also has <a href="http://www.lispworks.com/products/lw4mr.html">iOS and Android
runtimes</a>. Example
software built with CAPI include <a href="https://opusmodus.com/">Opusmodus</a>
or again <a href="https://scorecloud.com/">ScoreCloud</a>. It is possible to
try it with the LispWorks free demo.</li>
  <li><a href="https://github.com/plkrueger/CocoaInterface/">CocoaInterface</a>, a
Cocoa interface for Clozure Common Lisp. Build Cocoa user interface
windows dynamically using Lisp code and bypass the typical Xcode
processes.</li>
  <li><a href="https://common-lisp.net/project/mcclim/">McCLIM</a> and <a href="https://github.com/earl-ducaine/cl-garnet">Garnet</a> are toolkit in 100% Common Lisp. McClim even has <a href="https://techfak.de/~jmoringe/mcclim-broadway-7.ogv">a prototype</a> running in the browser with the Broadway protocol and Garnet has an ongoing interface to Gtk.</li>
  <li><a href="https://github.com/Shirakumo/alloy">Alloy</a>, another very new toolkit in 100% Common Lisp, used for example in the <a href="https://github.com/shinmera/kandria">Kandria</a> game.</li>
  <li><a href="https://notabug.org/cage/nodgui">nodgui</a>, a fork of Ltk, with syntax sugar and additional widgets.</li>
  <li><a href="https://gitlab.com/eql">eql, eql5, eql5-android</a>, embedded Qt4 and Qt5 Lisp, embedded in ECL, embeddable in Qt. Port of EQL5 to the Android platform.</li>
  <li>this <a href="https://github.com/defunkydrummer/abcl-jazz">demo using Java Swing from ABCL</a></li>
  <li><a href="https://github.com/mifpasoti/Gtk-Demos">examples of using Gtk without C files with SBCL</a>, as well as GTK-server.</li>
  <li>and, last but not least, <a href="http://ceramic.github.io/">Ceramic</a>, to ship a cross-platform web app with Electron.</li>
</ul>

<p>as well as the other ones listed on <a href="https://github.com/CodyReichert/awesome-cl#Gui">awesome-cl#gui</a> and <a href="https://www.cliki.net/GUI">Cliki</a>.</p>

<h2 id="tk-ltk">Tk (Ltk)</h2>

<p><a href="https://www.tcl.tk/">Tk</a> (or Tcl/Tk, where Tcl is the programming language) has the
infamous reputation of having an outdated look. This is not (so) true
anymore since its version 8 of 1997 (!). It is probably better than
you think:</p>

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/gui/ltk-on-macos.png" alt=""></p>

<p>Tk doesn’t have a great choice of widgets, but it has a useful canvas,
and it has a couple of unique features: we can develop a graphical
interface <strong>fully interactively</strong> and we can run the GUI <strong>remotely</strong>
from the core app.</p>

<p>So, Tk isn’t fancy, but it is an used and proven GUI toolkit (and
programming language) still used in the industry. It can be a great
choice to quickly create simple GUIs, to leverage its ease of deployment, or
when stability is required.</p>

<p>The Lisp binding is <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a>.</p>

<ul>
  <li><strong>Written in</strong>: Tcl</li>
  <li>
    <p><strong>Portability</strong>: cross-platform (Windows, macOS, Linux).</p>
  </li>
  <li>
    <p><strong>Widgets</strong>: this is not the fort of Tk. It has a <strong>small set</strong> of
default widgets, and misses important ones, for example a calendar. We
can find some in extensions (such as in <strong>Nodgui</strong>), but they don’t
feel native, at all.</p>
  </li>
  <li>
    <p><strong>Interactive development</strong>: very much.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no</p>
  </li>
  <li><strong>Other features</strong>:
    <ul>
      <li><strong>remote execution</strong>: the connection between Lisp and Tcl/Tk is
done via a stream. It is thus possible to run the Lisp program on
one computer, and to display the GUI on another one. The only
thing required on the client computer is tcl/tk installed and the
remote.tcl script. See <a href="http://www.peter-herth.de/ltk/ltkdoc/node46.html">Ltk-remote</a>.</li>
    </ul>
  </li>
  <li><strong>Bindings documentation</strong>: short but complete. Nodgui too.</li>
  <li><strong>Bindings stability</strong>: very stable</li>
  <li><strong>Bindings activity</strong>: low to non-existent.</li>
  <li><strong>Licence</strong>: Tcl/Tk is BSD-style, Ltk is LGPL.</li>
  <li>Example applications:
    <ul>
      <li><a href="https://notabug.org/cage/fulci/">Fulci</a> - a program to organise your movie collections.</li>
      <li><a href="https://github.com/mijohnson99/ltk-small-games">Ltk small games</a> - snake and tic-tac-toe.</li>
      <li><a href="https://github.com/vindarel/cl-torrents">cl-torrents</a> - searching torrents on popular trackers. CLI, readline and a simple Tk GUI.</li>
    </ul>
  </li>
</ul>

<p><strong>List of widgets</strong></p>

<p>(please don’t suppose the list is exhaustive)</p>

<pre><code>Button Canvas Check-button Entry Frame Label Labelframe Listbox
Menu Menubutton Message
Paned-window
Radio-button Scale
Scrollbar Spinbox Text
Toplevel Widget Canvas

Ltk-megawidgets:
    progress
    history-entry
    menu-entry
</code></pre>

<p>Nodgui adds:</p>

<pre><code>treelist tooltip searchable-listbox date-picker calendar autocomplete-listbox
password-entry progress-bar-star notify-window
dot-plot bar-chart equalizer-bar
swap-list
</code></pre>



<p>Do we need to present Qt and <a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a>? Qt is huge and contains
everything and the kitchen sink. Qt not only provides UI widgets, but
numerous other layers (networking, D-BUS…).</p>

<p>Qt is free for open-source software, however you’ll want to check the
conditions to ship proprietary ones.</p>

<p>The <a href="https://github.com/Shinmera/qtools">Qtools</a> bindings target Qt4. The Qt5 Lisp bindings are
yet to be created.</p>

<p>A companion library for Qtools, that you’ll want to check out once you
made your first Qtool application, is
<a href="https://github.com/Shinmera/qtools-ui">Qtools-ui</a>, a collection of
useful widgets and pre-made components. It comes with short
<a href="https://www.youtube.com/playlist?list=PLkDl6Irujx9Mh3BWdBmt4JtIrwYgihTWp">demonstrations
videos</a>.</p>

<!-- possible future: gobject-introspection -->

<ul>
  <li><strong>Framework written in</strong>: C++</li>
  <li><strong>Framework Portability</strong>: multi-platform, Android, embedded systems, WASM.</li>
  <li>
    <p><strong>Bindings Portability</strong>: Qtools runs on x86 desktop platforms on Windows, macOS and GNU/Linux.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: Web browser, a lot more.</p>
  </li>
  <li><strong>Bindings documentation</strong>: lengthy explanations, a few examples. Prior Qt knowledge is required.</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: active</li>
  <li><strong>Qt Licence</strong>: both commercial and open source licences.</li>
  <li>Example applications:
    <ul>
      <li>https://github.com/Shinmera/qtools/tree/master/examples</li>
      <li>https://github.com/Shirakumo/lionchat</li>
      <li>https://github.com/shinmera/halftone - a simple image viewer</li>
    </ul>
  </li>
</ul>

<h2 id="gtk3-cl-cffi-gtk">Gtk+3 (cl-cffi-gtk)</h2>

<p><a href="https://www.gtk.org/">Gtk+3</a> is the primary library used to build <a href="https://www.gnome.org/">GNOME</a>
applications. Its (currently most advanced) lisp bindings is
<a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a>. While primarily created for GNU/Linux, Gtk
works fine under macOS and can now also be used on Windows.</p>

<ul>
  <li><strong>Framework written in</strong>: C</li>
  <li>
    <p><strong>Portability</strong>: GNU/Linux and macOS, also Windows.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li><strong>Graphical builder</strong>: yes: Glade.</li>
  <li>
    <p><strong>Other features</strong>: web browser (WebKitGTK)</p>
  </li>
  <li><strong>Bindings documentation</strong>: very good: http://www.crategus.com/books/cl-gtk/gtk-tutorial.html</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: low activity, active development.</li>
  <li><strong>Licence</strong>: LGPL</li>
  <li>Example applications:
    <ul>
      <li>an <a href="https://github.com/ralph-schleicher/atmosphere-calculator">Atmosphere Calculator</a>, built with Glade.</li>
    </ul>
  </li>
</ul>

<h2 id="iup-lispnikiup">IUP (lispnik/IUP)</h2>

<p><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> is a cross-platform GUI toolkit actively developed
at the PUC university of Rio de Janeiro, Brazil. It uses <strong>native
controls</strong>: the Windows API for Windows, Gtk3 for GNU/Linux. At the
time of writing, it has a Cocoa port in the works (as well as iOS,
Android and WASM ones). A particularity of IUP is its <strong>small API</strong>.</p>

<p>The Lisp bindings are <a href="https://github.com/lispnik/iup/">lispnik/iup</a>. They are nicely
done in that they are automatically generated from the C sources. They
can follow new IUP versions with a minimal work and the required steps
are documented. All this gives us good guarantee over the bus
factor.</p>

<p>IUP stands as a great solution in between Tk and Gtk or Qt.</p>

<ul>
  <li><strong>Framework written in</strong>: C (official API also in Lua and LED)</li>
  <li>
    <p><strong>Portability</strong>: Windows and Linux, work started for
Cocoa, iOS, Android, WASM.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: medium.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes: <a href="http://webserver2.tecgraf.puc-rio.br/iup/en/iupvisualled.html">IupVisualLED</a></p>
  </li>
  <li>
    <p><strong>Other features</strong>: OpenGL, Web browser (WebKitGTK on GNU/Linux), plotting, Scintilla text editor</p>
  </li>
  <li><strong>Bindings documentation</strong>: good examples and good readme, otherwise low.</li>
  <li><strong>Bindings stability</strong>: alpha (but fully generated and working nicely).</li>
  <li><strong>Bindings activity</strong>: low but steady, and reactive to new IUP versions.</li>
  <li><strong>Licence</strong>: IUP and the bindings are MIT licenced.</li>
</ul>

<p><strong>List of widgets</strong></p>

<pre><code>Radio, Tabs, FlatTabs, ScrollBox, DetachBox,
Button, FlatButton, DropButton, Calendar, Canvas, Colorbar, ColorBrowser, DatePick, Dial, Gauge, Label, FlatLabel,
FlatSeparator, Link, List, FlatList, ProgressBar, Spin, Text, Toggle, Tree, Val,
listDialog, Alarm, Color, Message, Font, Scintilla, file-dialog…
Cells, Matrix, MatrixEx, MatrixList,
GLCanvas, Plot, MglPlot, OleControl, WebBrowser (WebKit/Gtk+)…
drag-and-drop
</code></pre>

<!-- editor's note: found missing a list view with columns. -->

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/iup-demo.png" alt=""></p>

<h2 id="nuklear-bodge-nuklear">Nuklear (Bodge-Nuklear)</h2>

<p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a small <a href="https://en.wikipedia.org/wiki/Immediate_mode_GUI">immediate-mode</a> GUI toolkit:</p>

<blockquote>
  <p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a minimal-state, immediate-mode graphical user interface toolkit written in ANSI C and licensed under public domain. It was designed as a simple embeddable user interface for application and does not have any dependencies, a default render backend or OS window/input handling but instead provides a highly modular, library-based approach, with simple input state for input and draw commands describing primitive shapes as output. So instead of providing a layered library that tries to abstract over a number of platform and render backends, it focuses only on the actual UI.</p>
</blockquote>

<p>its Lisp binding is <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a>, and its higher level companions <a href="https://github.com/borodust/bodge-ui">bodge-ui</a> and <a href="https://github.com/borodust/bodge-ui-window">bodge-ui-window</a>.</p>

<p>Unlike traditional UI frameworks, Nuklear allows the developer to take
over the rendering loop or the input management. This might require
more setup, but it makes Nuklear particularly well suited for games,
or for applications where you want to create new controls.</p>

<ul>
  <li><strong>Framework written in</strong>: ANSI C, single-header library.</li>
  <li>
    <p><strong>Portability</strong>: where C runs. Nuklear doesn’t contain
platform-specific code. No direct OS or window handling is done in
Nuklear. Instead <em>all input state has to be provided by platform
specific code</em>.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: small.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: fully skinnable and customisable.</p>
  </li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: active</li>
  <li><strong>Licence</strong>: MIT or Public Domain (unlicence).</li>
  <li>Example applications:
    <ul>
      <li><a href="https://github.com/borodust/trivial-gamekit">Trivial-gamekit</a></li>
      <li><a href="https://github.com/thicksteadTHpp/Obvius/">Obvius</a> - a resurrected image processing library.</li>
      <li><a href="https://github.com/borodust/notalone">Notalone</a> - an autumn 2017 Lisp Game Jam entry.</li>
    </ul>
  </li>
</ul>

<p><strong>List of widgets</strong></p>

<p>Non-exhaustive list:</p>

<pre><code>buttons, progressbar, image selector, (collapsable) …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lispcookbook.github.io/cl-cookbook/gui.html">https://lispcookbook.github.io/cl-cookbook/gui.html</a></em></p>]]>
            </description>
            <link>https://lispcookbook.github.io/cl-cookbook/gui.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819896</guid>
            <pubDate>Mon, 13 Jul 2020 12:13:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“johnyj12345” exposing self-hosted Gitlab's secrets to the public]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819885">thread link</a>) | @ferruck
<br/>
July 13, 2020 | https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/ | <a href="https://web.archive.org/web/*/https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <h2><a href="https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" rel="bookmark">Possible Gitlab Hack</a></h2>
                <p>Today I noticed a new and unknown user on our company's Gitlab
instance: "johnyj12345". We immediatly took down our instance as it
seems as if that Johny was able to extract our secrets. You should
probably do so, too.</p>
                <p><i>Published <time datetime="2020-07-13T12:05:42+02:00">Monday, 13 July 2020</time> by <a href="https://blog.philipp-trommler.me/author/philipp-trommler.html">Philipp Trommler</a>. This article has also been translated to: <a href="https://blog.philipp-trommler.me/de/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" hreflang="de">de</a>.</i></p>
                <p>Searching the web <a href="https://www.google.com/search?q=johnyj12345">for the
username</a> (attention: Google link!)
reveals that many self-hosted Gitlab instances are affected. The publicly
visible procedure is always the same: Johny creates one or more issues that are
linked with each other and at the end of the link cascade there's either an
attached file or a link to a file which holds Gitlab's <code>secrets.yml</code>.</p>
<p>From the web search it seems like the hack started on Saturday, though that may
be a false conclusion. In any case, you should probably take down your Gitlab
instance if you're affected since the <code>secrets.yaml</code> contains Gitlab's base key
and the database encryption key which should better be private AFAIK. This may
or may not be an immediate attack surface, but better safe than sorry,
especially since the files can be easily found via Google.</p>
<p>We're currently looking for a sane and safe way of rotating the keys within that
file. Any help would be appreciated.</p>
                <p><i>Filed under <a href="https://blog.philipp-trommler.me/category/security.html">Security</a>. Tags: <a href="https://blog.philipp-trommler.me/tag/git.html">git</a>, <a href="https://blog.philipp-trommler.me/tag/gitlab.html">gitlab</a>, <a href="https://blog.philipp-trommler.me/tag/hacking.html">hacking</a>, <a href="https://blog.philipp-trommler.me/tag/web.html">web</a>.</i></p>
                <p><i>Want to comment on this article? Write me at blog [at] philipp-trommler [dot] me!</i></p>
            </article></div>]]>
            </description>
            <link>https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819885</guid>
            <pubDate>Mon, 13 Jul 2020 12:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alpha Wolf Concept]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819529">thread link</a>) | @CaptainActuary
<br/>
July 13, 2020 | https://davemech.org/wolf-news-and-information/ | <a href="https://web.archive.org/web/*/https://davemech.org/wolf-news-and-information/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article class="page" itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h2>News</h2>
<p>The most current, accurate, and objective wolf news can be found on the website of the International Wolf Center (<a href="http://www.wolf.org/">www.wolf.org</a>)</p>
<p><img src="http://davemech.org/wp-content/uploads/wolfreadsbook-300x228.jpg" alt="Wolf reading book." width="300" height="228" srcset="https://davemech.org/wp-content/uploads/wolfreadsbook-300x228.jpg 300w, https://davemech.org/wp-content/uploads/wolfreadsbook-768x584.jpg 768w, https://davemech.org/wp-content/uploads/wolfreadsbook.jpg 800w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h2><a href="http://davemech.org/wolf-news-and-information/books/">Mech books</a></h2>
<h2>Mech articles</h2>
<ul>
<li><a href="http://davemech.org/wp-content/uploads/technical-publications.pdf">Scientific publications</a> (.pdf)</li>
<li><a href="http://davemech.org/wp-content/uploads/popular-publications.pdf">Popular publications</a> (.pdf)</li>
<li><a href="http://www.wolf.org/wolf-info/basic-wolf-%C2%A0info/in-depth-resources/scientific-publications/">Downloadable articles</a></li>
</ul>
<h2><a href="http://davemech.org/wolf-news-and-information/schenkels-classic-wolf-behavior-study-available-in-english/">Schenkel’s 1948 Wolf Expression Studies</a></h2>
<h2>Alpha Wolf Concept</h2>
<p>The concept of the alpha wolf is well ingrained in the popular wolf literature, at least partly because of my book “The Wolf: Ecology and Behavior of an Endangered Species,” written in 1968, published in 1970, republished in paperback in 1981, and currently still in print, despite my numerous pleas to the publisher to stop publishing it. Although most of the book’s info is still accurate, much is outdated. We have learned more about wolves in the last 40 years then in all of previous history.</p>
<p>One of the outdated pieces of information is the concept of the alpha wolf. “Alpha” implies competing with others and becoming top dog by winning a contest or battle. However, most wolves who lead packs achieved their position simply by mating and producing pups, which then became their pack. In other words they are merely breeders, or parents, and that’s all we call them today, the “breeding male,” “breeding female,” or “male parent,” “female parent,” or the “adult male” or “adult female.” In the rare packs that include more than one breeding animal, the “dominant breeder” can be called that, and any breeding daughter can be called a “subordinate breeder.”<br>
For details, see <a href="http://www.wolf.org/wp-content/uploads/2013/09/267alphastatus_english.pdf" target="_blank" rel="noopener">www.wolf.org/wp-content/uploads/2013/09/267alphastatus_english.pdf</a> and <a href="http://www.wolf.org/wp-content/uploads/2013/08/247Leadership.pdf" target="_blank" rel="noopener">www.wolf.org/wp-content/uploads/2013/08/247Leadership.pdf</a></p>
<h2>Alpha Wolf videos</h2>
<p><a href="https://www.youtube.com/watch?v=tNtFgdwTsbU" data-rel="lightbox-video-0">Mech explains</a><br>
<iframe width="500" height="375" src="https://www.youtube.com/embed/tNtFgdwTsbU?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
<p><a href="https://www.youtube.com/watch?v=YTyQgwVvYyc" data-rel="lightbox-video-1">Cartoon explanation of Mech and the Alpha concept</a> (cartoon starts at minute 1)<br>
<iframe width="500" height="281" src="https://www.youtube.com/embed/YTyQgwVvYyc?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
</div></article></main></div></div></div>]]>
            </description>
            <link>https://davemech.org/wolf-news-and-information/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819529</guid>
            <pubDate>Mon, 13 Jul 2020 11:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Mock Interviews – learn about data and SQL by solving interview tasks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819221">thread link</a>) | @makaronich
<br/>
July 13, 2020 | https://www.sqlhabit.com/about-mock-interviews | <a href="https://web.archive.org/web/*/https://www.sqlhabit.com/about-mock-interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<div>
  <div>
    <section>
      
<div>
  

  <div><p>
    Mock Interviews will help you to get ready for an upcoming SQL interview. It's also a great way to learn and practice Data Analytics with SQL. The format is simple:
    </p>
  </div>

  <p><a href="https://www.sqlhabit.com/signup">
    Try Mock Interviews <br>for free
</a></p></div>

    </section>

    <section>
      <div>
        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews@2x-7a6e7ee7be9670546e04b57481518131981519804003b13c30b96beb72b70db9.jpg 2x">
    <img alt="Prepare for an interview" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg">
  </picture>

  <div>
    <h2>
      Prepare for an interview
</h2>
    <p>
      Mock Interviews are based on SQL challenges from Data Analysis, Product Management and Marketing interviews. Youâ€™ll have 45 minutes to solve 2 challenges varying in difficutly: easy, medium, hard and hardcore. <img title=":rocket:" alt="ðŸš€" src="https://twemoji.maxcdn.com/2/svg/1f680.svg">

    </p>
  </div>
</div>

        </div>

        

        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents@2x-b68c6ed4cd81b4a5d61ed804f4a8960e4ad180d40ff917f40e5e5deba66ba0fa.jpg 2x">
    <img alt="Master Data Analysis with SQL Habit course" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg">
  </picture>

  <div>
    <h2>
      Master Data Analysis with SQL Habit course
</h2>
    <p>
      Go beyond Mock Interviews and learn specifics of Data Analysis with SQL Habit course. Youâ€™ll not only master SQL, but learn how to apply it in different scenarios from Product Management and Marketing. All based on a story of a startup. <img title=":books:" alt="ðŸ“š" src="https://twemoji.maxcdn.com/2/svg/1f4da.svg">

    </p>
  </div>
</div>

        </div>
      </div>
    </section>

    <section>
      
<div id="pricing">
  <h2>
    Buy unlimited access to SQL Habit
  </h2>

  <div>
    <div>
      
<div>
  <p>
    FUNDAMENTALS
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>25 free</strong> lessons and exercises
          </p>
        </div>
        
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://www.sqlhabit.com/signup">Sign up</a></p><p>
        *no credit card required
      </p>

  </div>
</div>

    </div>
    <div>
      
<div>
  <p>
    COMPLETE PACKAGE
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>200+</strong> lessons and exercises
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to SQL Habit, forever
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to Mock Interviews
          </p>
        </div>
        <div>
          


          <p>
            Verified <strong>LinkedIn certificate</strong>
          </p>
        </div>
        <div>
          


          <p>
            A <strong>private Telegram group</strong> with the author and your fellow course participants
          </p>
        </div>
        <div>
          


          <div>
            <p><strong>Monthly live Q&amp;A sessions</strong>, next one is scheduled for August, 1 </p>

          </div>
        </div>
        <div>
          


          <p><strong>1 year of Datagrip</strong> for free
          </p>
        </div>
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://gum.co/kwYeT">Buy now</a></p>

  </div>
</div>

    </div>
  </div>
</div>

    </section>

    <section>
        <section>
          <div>
  <h2>
    Reviews
  </h2>

  

  <div>
      <div>
        <p><span>SQL habit is the best online course I have done! It is my number one recommendation when it comes to learn SQL, for a beginner or even an advanced user.</span>

Anatoli has a gift to teach through examples in a very fun and playful way. The course covers real life example of the data analysis function of a company, starting with accessible SQL (read no prior experience needed), to very advanced SQL (yes, I mean...
        </p>

          
      </div>
      <div>
        <p><span>I am so excited that I have finally learnt SQL and realised how much I can gain from it in my daily work! The course gave me a better understanding of Marketing and Product Analytics</span> â€” how data is tracked, stored and interpreted â€” on web and for mobile apps. I can't wait to put my new skills into practice! I have tested few SQL courses and I would highly recommend SQL Habit without a doubt! Thank you very...
        </p>

          <p>
            Artur, Marketing Analyst @ Babbel
          </p>
      </div>
      <div>
        <p>
          SQL was something I never touched before starting this course. But being a Product Designer, I often asked my colleagues about how many users saw a specific landing page, where did they come from, how many people signed up, etc. It made me want to learn more about the data behind those magic numbers I got from them all the time. <span>This course was an incredible help to understand exactly that and it made me way more...
        </span></p>

          <p>
            Franziska, Product Designer
          </p>
      </div>
  </div>
</div>

        </section>
    </section>

    <section>
      
<div>
  <h2>
    Frequently Asked Questions
  </h2>

  <div>

      <div>
    <p>Can I try the course for free?</p>

    <p>Absolutely. The first 33 lessons and exercises are free. Just <a href="https://www.sqlhabit.com/users/new">signup</a> with your email, no credit card info required.</p>
  </div>
  <div>
    <p>Do you accept PayPal purchases?</p>

    <p>SQL Habit uses Gumroad to accept payment and Gumroad supports PayPal.</p>
  </div>
  <div>
    <p>Can I get an invoice?</p>

    <p>Absolutely! Right after purchasing youâ€™ll get a receipt which includes a link to generate an invoice with any extra information you need to add for your own accounting purposes.</p>
  </div>
  <div>
    <p>Do you have monthly subscription?</p>

    <p>Nope, one time purchase allows you to access it <strong>forever</strong>. Honestly, I believe itâ€™ll take you 1-2 months to really develop this strong SQL Habit. <img draggable="false" title=":muscle:" alt="ðŸ’ª" src="https://twemoji.maxcdn.com/2/svg/1f4aa.svg"></p>
  </div>
  <div>
    <p>Can I purchase SQL Habit for my team/company?</p>

    
  </div>
  <div>
    <p>What if I realize itâ€™s not for me?</p>

    <p>No problem! Ping me at <a href="mailto:support@sqlhabit.com">support@sqlhabit.com</a> and youâ€™ll be refunded in full, no questions asked (except feedback).</p>
  </div>

  </div>
</div>

    </section>
  </div>
</div>

    </div></div>]]>
            </description>
            <link>https://www.sqlhabit.com/about-mock-interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819221</guid>
            <pubDate>Mon, 13 Jul 2020 10:32:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A $50.000/year streaming service]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819201">thread link</a>) | @gianlucahmd
<br/>
July 13, 2020 | https://blog.gianlucamauro.com/post/harvard-online-learning/ | <a href="https://web.archive.org/web/*/https://blog.gianlucamauro.com/post/harvard-online-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <section>
  
</section>










        

<section>

    <section id="articleHero">
    <div>
        <header>
            
            <div>
                <div>
                    


    
            
    



<p>
                    July 10, 2020
                     • 3 min read
                </p></div>
            </div>
        </header>
        
        
        
    </div>
</section>

    

    <article id="articleContent">
        <p>Harvard University announced that next academic year will be 100% online.</p>
<p>And the tuition won’t be a dime cheaper.</p>
<p><img src="https://blog.gianlucamauro.com/images/harvard.png" alt=""></p>
<p>Why does it matter?</p>
<p>I don’t want to question the worthiness of such an investment. Yet, I can’t help but wonder if you’ll loose some of your returns by switching from the Harvard University halls to your web browser.</p>
<p>When you give $50.000 to a University like Harvard, you’re paying for a bunch of stuff. Mainly:</p>
<ul>
<li>Prestige</li>
<li>The network (your network is your net worth, right?)</li>
<li>Learning, obviously</li>
</ul>
<p>How will the new experience impact these aspects?</p>
<p>The prestige will stay intact. You can show off your Harvard badge on LinkedIn without having to specify where you studied.</p>
<p>I don’t think that you’ll get exposure to the same network as with physical classes. Human connection is paramount to build strong social ties. Yes, you can talk to people trough Zoom and stuff. But let’s stop hiding: Zoom is a poor quality proxy for face to face interaction. Hopefully when Covid will be over students will catch up with the social interactions they missed.</p>
<p>Let’s talk about learning now.</p>
<p>For years, online learning has been seen as a “second choice” learning format. Yes, it’s more comfortable and democratic than “real” university learning, but at the cost of some quality. I have to admit, I was guilty myself of this bias a few years ago.</p>
<p><strong>By changing medium without touching its price tag, Harvard changed the game. Harvard stated loud and clear that online learning is still learning. And it’s worth as much.</strong></p>
<p>This is a huge win for people like me that work hard to create the best online educational content possible.</p>
<p>This legitimates online learning. It acknowledges that the medium does not devaluate the knowledge, passion and teaching skills of the teacher.</p>
<p>Among all the change that Covid has brought to our lives, some will stick forever. Once the stigma around online learning will be gone, we’ll be left with a more democratic way of learning.</p>
<p>Who has something to teach will be free of sharing his experience without fear. Who wants to improve herself will be free to do so without the entry barriers of the Harvard halls.</p>
<p>And my biggest wish of all: <strong>companies will treat people that built their education online with the same respect of who spent $200.000 to sit in Harvard’s classrooms.</strong></p>
<blockquote>
<p>Let the future tell the truth, and evaluate each one according to his work and accomplishments - Nikola Tesla</p>
</blockquote>

    </article>
    
    

<section id="subscriptionSection">
    <div>
        <div>
            <h3>
                Get my thoughts in your inbox
            </h3>
            <p>
                Join my subscribers to get curated emails with my posts. 
                No spam, no marketing bullshit. Opt-out at anytime. You have my word I won't not spam your inbox or share your email with any third parties.
            </p>


            

        </div>
    </div>
</section>











    
    
    
        
    




<section id="articleNext">
    
    
    
</section>


</section>







 

        
        
    

    </div></div>]]>
            </description>
            <link>https://blog.gianlucamauro.com/post/harvard-online-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819201</guid>
            <pubDate>Mon, 13 Jul 2020 10:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meddling Middlemen of Academia]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819130">thread link</a>) | @Topolomancer
<br/>
July 13, 2020 | https://bastian.rieck.me/blog/posts/2020/middlemen/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/middlemen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>One of the strangest phenomena in academia is the reliance on publishing
companies. In this article, I want to outline some of the issues that
arise when working with publishers. I shall also endeavour to provide
some solutions to improve this collaboration.</p>
<p>Before we start, a brief <strong>disclaimer</strong>: this article will use an
amalgamation of different incidents that involved either myself, my
colleagues, or my friends.  Names&nbsp;(of the publishing companies)
have been withheld because I do not think it fair to use my ‘soapbox’
without giving the <em>other</em> side a chance to respond. Moreover,
everything I write here pertains to publishing your research in
a journal. Conference publishing—at least in machine learning—is
a joy<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. Plus, there <em>are</em> good examples of journals for machine
learning papers, foremost of them the <a href="http://www.jmlr.org/">Journal of Machine Learning
Research</a>. The ‘adversaries’ in this article are
rather the ‘big’ publishing companies and their practices. With that out
of the way, let us take a look at the state of the art!</p>

<p>If you are new to science, at some point, you will probably have to deal
with an established publishing company to get your article published.
The deal usually works like this:</p>
<ol>
<li>
<p>You look for a journal you want to publish in and submit your article
to the journal. This already often involves jumping through some
hoops. Without knowing the eventual fate of your article, you often
already have to abide by certain arbitrary formatting guidelines or
completely ‘butcher’ your article for the submission<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> by shifting
content around. However, this can be all accepted and endured because
of course, you want something from <em>them</em>, i.e. a published,
citable publication!</p>
</li>
<li>
<p>The journal then receives your submission—often through a web
interface that was developed with all the UX/UI knowledge of the
1980s<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> and has <em>never</em> been updated since—and this is where it gets
slightly <em>murky</em>. Another person—typically the editor of the
journal—now decides whether to accept the paper for reviewing, or
whether to provide you with a desk reject. A desk reject usually cannot
be appealed. It just shows you the door and leaves you to try again
with another journal&nbsp;(more murkiness here). For early-career
researchers like Ph.D. students submitting their first paper,
this can be highly discouraging. I see the reason for reducing the
workload on reviewers, of course, but I also heard of academic feuds
that were carried out on the backs of Ph.D. students and their
publications.</p>
</li>
<li>
<p>Assuming your paper ‘survived’ the desk reject, it will now be sent
to reviewers or referees. Their job is to review your paper
thoroughly, provide feedback, and in general give this whole business
a formal veneer. Setting aside problems in the reviewing
process—which I discussed <a href="http://bastian.rieck.me/blog/posts/2019/reviewing/">in another blog post</a>—this again opens up a portal into
a strange dimension: working as a reviewer for a journal is usually
a job that is provided for free&nbsp;(same goes for editorial
duties). Notice that this is <em>despite</em> the fact that those journals
are charging money to readers and universities. ETH Zurich, my
current employer, describes their experiences of the <a href="https://www.library.ethz.ch/en/Services/Using-ordering-resources/National-negotiations-with-publishers-Read-publish-reorganised">negotiations
with
publishers</a>
and mentions an expenditure of 6.4 million EUR&nbsp;(roughly 7.25
million USD) per year for being allowed to access journal articles.
That is a lot of money.</p>
<p>Setting aside the actual numbers here, let me just point out how
strange it is that companies are relying on <em>unpaid labour</em>, and this
reliance is <em>crucial</em> to their business model. They often do not
employ people that are qualified to judge the content that they want
to publish! But of course, reviewers and editors get the benefit of
<em>exposure</em>—that wonderful currency that is supposed to help your
career along! Even stranger: journals often charge hefty sums for
accessing your own research articles. To me, it is super weird that
research that is often <em>funded</em> by the taxpayer cannot be <em>accessed</em>
by the taxpayer.</p>
</li>
<li>
<p>Supposing your article got sufficiently good reviews to be published,
the next stage of the process starts. This is where the <em>meddling</em>
begins in earnest. After a little back and forth, you article will be
changed according to some arbitrary rules: the last period of every
sentence in an image caption will be removed, footnotes will be put
into the text—because for some reason, footnotes are permitted in
virtually every template and publishing medium, but deemed somewhat
uncouth by certain publishers—and you might have to redo certain
parts of your paper because of subtle font changes or what have you.</p>
<p>Again, lest you think of me as a particularly cranky person prone to
grumbling and finding faults, you are getting the wrong idea here.
I do not object to these changes, but I <em>do</em> object to the fact that
these meddlesome changes often decrease the quality of your paper.
Here are some irksome changes:</p>
<ul>
<li>
<p>Footnotes will be inserted willy-nilly into the text, regardless of
whether they make sense or not. That might break the flow of your
paper, but that is <em>your</em> problem.</p>
</li>
<li>
<p>Some ‘publisher house rules’ conflict with proper nomenclature in
a field. For example, the journal might have the ‘rule’ that all
fields in a table have to be capitalised. If this clashes with
nomenclature in your field, it is—you guessed it—<em>your</em> problem.</p>
</li>
<li>
<p>Your equations will typically be typeset yet
another time for you<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, which might introduce subtle changes: symbols
will change and you have to be go through your own paper once again
line-by-line to see whether anything untoward happened. Again, I am
primarily objecting to the substandard quality of this meddling:
the work that you put into writing your equations is completely
ignored, and now you have to chase—often very subtle—changes in
your own text. For mathematical typesetting, precision is crucial,
and it is unbecoming when people who do not <em>care</em> about this
precision create more work for you.</p>
</li>
<li>
<p>As a last example, your figures might be meddled with: you might be
forced to convert them into obsolete file formats&nbsp;(because
apparently, EPS is still the best format available), or, more
appallingly, vector graphics might be converted to raster
images&nbsp;(judging from the experiences of my friends and myself,
this is unfortunately relatively common!). This might sound like a tiny
problem again, but it decreases readability and accessibility for
some readers, and, more to the point of this post, it is somewhat
unnecessary meddling.</p>
</li>
</ul>
<p>Let me re-iterate my main point: I do not object to changing my
paper, I merely object to meddlesome changes that are just generating
useless work. For example, there is no need whatsoever to typeset
your equations again—this is quite literally the definition of
negative work.</p>
</li>
<li>
<p>If you survived this ordeal intact, you now must <em>pay</em>. To be fair,
not all journals charge you for normal articles, but <em>most</em> of them
charge you for open access publishing. In other words: if I want my
research, which is generously funded<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> by the Swiss taxpayers, to
be available to those selfsame taxpayers, I have to pay. The amounts
vary a little bit, of course, but we are talking upwards of a few
hundred USD at least. Luckily, this is <em>not</em> a problem for my
research group; my postdoctoral adviser, <a href="https://bsse.ethz.ch/mlcb/karsten.html">Prof. Karsten
Borgwardt</a> ensures that
sufficient funds for open access publications are available.</p>
<p>Interestingly, sometimes the cost is fielded by a conference; this
happens when the conference has a contract that ensures that its
publications will be available as special issue of some journal.
This might seem nice because it <em>shifts</em> the costs away from authors,
but it is also somewhat non-transparent; conference costs being high
already, I find it strange that some of the money goes into the
pockets of another party.</p>
<p>After all this negativity, it is time for a <em>positive example</em>:
NeurIPS, one of the flagship machine learning conferences, is
partnered with a publisher and makes <em>all</em> papers available for free
online. I <em>gladly</em> pay the conference fee for this!</p>
</li>
</ol>

<p>How can this process be improved? I have a few suggestions:</p>
<ol>
<li>
<p><strong>Transparency</strong>: publishers should make it clear <em>where</em> the funds are
going. Are we increasing shareholder value by working for free? How
are profits split and used?</p>
</li>
<li>
<p><strong>Giving back</strong>: it is generally understood that everyone needs to eat
and no one should have to work for free. Why is then that this
completely different in publishing? Almost all the profits are
essentially generated because editors and reviewers work for free.
I know that being remunerated for your reviewing work might raise
some questions about impartiality etc., so I think <em>paying</em> people to
write reviews might be somewhat problematic.</p>
<p>However, closely related to my point about transparency, publishers
could be more upfront about how they user their funds and <em>give back</em>
to the community. For example, publishers could sponsor students so
that they can visit a conference for free, or publishers could
sponsor the conferences themselves.</p>
<p>If you, as a publisher, engage the community and give back a little,
the community will be all the more happy to work with you. We need
you, but you also need us. Without the scientists, you cannot be
a scientific publisher.</p>
</li>
<li>
<p><strong>Commitment to excellence</strong>: publishers should commit to the highest
quality and the highest standards. Employ people that are capable of
working <em>with</em> the scientists, not <em>for</em> the scientists. Train your
employees to be experts in typography, typesetting, and pair them
with domain experts so that they do not create more work for the
authors by inadvertently destroying equations, figures, and so on.</p>
<p>This goal is not necessarily orthogonal to maximising your profits,
by the way: if you lower your standards, your reputation as
a publisher will suffer, meaning that scientists in the long
run&nbsp;(!) might not be willing to publish with you any more. If
you commit to excellence, by contrast, we will flock to you.</p>
<p>I know that working with a publisher that <em>cares</em> about the end
product as much as I do is a heavenly match! So we should endeavour
to make such …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bastian.rieck.me/blog/posts/2020/middlemen/">https://bastian.rieck.me/blog/posts/2020/middlemen/</a></em></p>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/middlemen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819130</guid>
            <pubDate>Mon, 13 Jul 2020 10:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real World Programming in SWI-Prolog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818901">thread link</a>) | @luu
<br/>
July 13, 2020 | http://www.pathwayslms.com/swipltuts/ | <a href="https://web.archive.org/web/*/http://www.pathwayslms.com/swipltuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>This is a hopefully ever expanding collection of tutorials on aspects of the SWI-Prolog environment.
Our emphasis is on learning to write <b>real world</b> applications in SWI-Prolog.</p>

<ol>
<li><a href="http://www.pathwayslms.com/swipltuts/dcg/index.html">Definite Clause Grammars</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/html/index.html">Web Applications</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/clpfd/clpfd.html">Constraint Logic Programming over Finite Domains</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/message/index.html">Printing Messages in SWI-Prolog</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/chr/index.html">Constraint Handling Rules</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
</ol>

<h2>Stuff that's in the general vein of the <i>Real World</i> tutorials, but are by others</h2>
<ul>
<li>There is a <a href="http://swish.swi-prolog.org/example/dict.swinb">SWISH tutorial on the dict structure</a> that was introduced with revision 7.0</li>
<li>There is a <a href="http://swish.swi-prolog.org/example/tabling.swinb">SWISH tutorial on tabling</a> that was introduced with 7.2.3</li>
<li>Michael Richter maintains a tutorial on using modules with SWI-Prolog <a href="http://chiselapp.com/user/ttmrichter/repository/gng/doc/trunk/output/tutorials/swiplmodtut.html">Using Modules with SWI-Prolog</a></li>
<li>Michael Hendricks has a tutorial for his vastly nifty pack "Julian" for reasoning about dates and times <a href="http://mndrix.github.io/julian/index.html">Julian tutorial</a></li>
<li>The Amzi Corporation maintains a useful introduction to expert systems <a href="http://www.amzi.com/ExpertSystemsInProlog/">Expert Systems in Prolog</a></li>
</ul>

<h2>Other stuff by me (Anne Ogborn) about Prolog</h2>
<li><a href="http://www.pathwayslms.com/swipltuts/student/index.html">FAQ For The ##Prolog Channel</a> by Anne Ogborn and Michael Richter</li>
<li>A little story about <a href="http://www.pathwayslms.com/swipltuts/teacher/index.html">teaching Programming Languages courses that include Prolog</a></li>
<li><a href="https://www.youtube.com/watch?v=JmOHV5IlPyU">Youtube video (35 mins) of my tutorial on Pengines at Strange Loop 2014</a></li>
<li><a href="https://www.youtube.com/watch?v=G_eYTctGZw8">Youtube video (40 mins)</a> of Michael Hendricks' talk on Production Prolog, with great hints on practical Prolog</li>
<li>I gave a workshop on SWI-Prolog web development at <a href="https://thestrangeloop.com/">Strangeloop 2013</a> The workshop materials were basically the set of html tutorials collected into a single program. <a href="https://github.com/Anniepoo/strangeloop">You can get them here</a>.</li>

<h2>Selected other folks' tutorials and info about prolog</h2>
<ul>
<li>Roman Bartok maintains a great <a href="http://kti.ms.mff.cuni.cz/~bartak/prolog/index.html">tutorial introduction to Prolog</a></li>
<li>The introductory book <a href="http://lpn.swi-prolog.org/lpnpage.php?pageid=online">Learn Prolog Now</a> is online, and has embedded SWISH so you can run the examples right in the text</li>
<li>Help, my brain is melting <a href="http://www.pathwayslms.com/swipltuts/())).pl">())).pl</a></li>
</ul>

<h2>Contribute!</h2>
<p>We'd love to have more contributors of tutorials. Areas we'd love to see covered: Pldoc, The IDE, CLP, Expert Systems, aggregator library, and whatever else excites you.</p>



</div>]]>
            </description>
            <link>http://www.pathwayslms.com/swipltuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818901</guid>
            <pubDate>Mon, 13 Jul 2020 09:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark Web Price Index 2020]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 26 (<a href="https://news.ycombinator.com/item?id=23818727">thread link</a>) | @known
<br/>
July 13, 2020 | https://www.privacyaffairs.com/dark-web-price-index-2020/ | <a href="https://web.archive.org/web/*/https://www.privacyaffairs.com/dark-web-price-index-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><b>The dark web has a longstanding reputation as a haven for the worst kinds of criminal activity. This reputation is not wholly unjustified, as there are indeed terrible things happening around the world that can be bought and sold on the dark web. </b></p><p><span>The privacy offered by software such as TOR creates an environment where criminals can sell their wares on the dark web without the worry of law enforcement.</span></p><p><span>What’s more, many will have heard the horror stories of people’s bank accounts being cleaned out, or their identity stolen and turning up in custody in Mexico. Again, not unjustified horror.</span></p><p><span>You might be asking yourself, just how easy is it to obtain someone else’s personal information, documents, account details?&nbsp;</span></p><p><span>We certainly were.</span></p><p><span>To see just how prevalent such items of personal data are being listed, and at what price, we sent our researchers on a data-gathering mission into the dark web.</span></p><table><tbody><tr><td>Category</td><td>Product</td><td>Avg. dark web Price (USD)</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#2">Credit Card Data</a></td><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td></td><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td></td><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td></td><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td></td><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td></td><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td></td><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td></td><td>Walmart account with credit card attached</td><td>$10</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#3">Payment processing services</a></td><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td></td><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td></td><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td></td><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#4">Forged documents</a></td><td>US driving license, average quality</td><td>$70</td></tr><tr><td></td><td>US driving license, high quality</td><td>$550</td></tr><tr><td></td><td>Auto insurance card</td><td>$70</td></tr><tr><td></td><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td></td><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td></td><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td></td><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td></td><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td></td><td>Europe national ID card</td><td>$550</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#5">Social Media</a></td><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td></td><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td></td><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td></td><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td></td><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td></td><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td></td><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td></td><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td></td><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td></td><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td></td><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td></td><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td></td><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td></td><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td></td><td>Instagram likes x 1000</td><td>$6</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#6">Malware</a></td><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td></td><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td></td><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td></td><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td></td><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td></td><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td></td><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td></td><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td></td><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td></td><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td></td><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td></td><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td></td><td>Android x 1000</td><td>$600</td></tr><tr><td></td><td>Premium x 1000</td><td>$6000</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#7">DDoS Attack</a></td><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td></td><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table></section><div><section id="1"><h2>What We Found</h2><p>Whilst there are many marketplaces on the dark web, there are even more forum posts warning of scammers. This makes verified prices difficult to obtain without ordering the items to find out, which of course we didn’t.</p><p>Our methodology was to scan dark web marketplaces, forums, and websites, to create an index of the average prices for a range of specific products.</p><p>We were only interested in products and services relating to personal data, counterfeit documents, and social media.</p><p>This is what we found.</p></section><section id="2"><h2>Cloned credit cards and associated data</h2><table><tbody><tr><td>Product</td><td>Average dark web Price (USD)</td></tr><tr><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td>Walmart account with credit card attached</td><td>$10</td></tr></tbody></table><p>Credit card details usually come in the format CC|MM|YY|CVV|HOLDER_NAME|ZIP|CITY|ADDRESS|EMAIL|PHONE with the first 4 sections being the details on the card and the rest the details of the account holder. This will definitely cause a major inconvenience, but the prospect of someone using your online banking logins to gain full access to your account is far more daunting.</p><p><a href="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png"><img src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" data-src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" alt="Dark web credit card price" width="840" height="447"></a></p><p>Vendors tend to offer a guarantee of 80%. Meaning that two of every ten cards either won’t work or will have less than the advertised balance. We didn’t order any so can’t verify whether this is true, but the prevalence of these claims alongside the well documented increase in identity fraud cases suggests that there is a high turnover of such data.</p></section><section id="3"><h2>Payment processing services</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr></tbody></table><p>PayPal account details were easily the most common items listed, and extremely cheap. More expensive was actual transfers from a hacked account.</p><p>Another very common item for sale was guides on how to “cash out” – actually get the money in a way that doesn’t alert the authorities. These guides go for a few cents, but whether or not they actually work is not what we were looking for.</p></section><section id="4"><h2>Forged documents</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>US driving license, average quality</td><td>$70</td></tr><tr><td>US driving license, high quality</td><td>$550</td></tr><tr><td>Auto insurance card</td><td>$70</td></tr><tr><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td>Europe national ID card</td><td>$550</td></tr></tbody></table><p>These documents came with a range of guarantees and are available with any details the buyer chooses. With just a few pieces of real information about someone, a criminal could create a whole file of official documents to be used for all sorts of fraudulent activities. This one way in which an identity is stolen.</p><h3>Counterfeit money</h3><p>Counterfeit banknotes are extremely common, mainly in 20 or 50 denominations.</p><p>We came across USD, EUR, GBP, CAD, AUD most often. Some come with a UV pen test guarantee. The “quality” ones tend to cost around 30% of the banknote value.</p></section><section id="5"><h2>Social media</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td>Instagram likes x 1000</td><td>$6</td></tr></tbody></table><p>Offers to hack accounts or sell them were relatively scarce, but not non-existent. Perhaps due to a lack of demand for the product coupled with increased security practices. Hackers trying to get the social media credentials from their victims mostly have to resort to using <a href="https://www.getsafeonline.org/blog/what-is-pii-and-how-do-you-keep-it-private/">social engineering techniques</a>, which have a very high effort input for relatively low success ratio.</p><p>The extremely low cost for social engagement should seriously make you question an account’s validity before blindly trusting their wealth of social currency.</p></section><section id="6"><h2>Malware</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td>Android x 1000</td><td>$600</td></tr><tr><td>Premium x 1000</td><td>$6000</td></tr></tbody></table><p>Malicious tools are installed on comprised systems (Windows, Android and others) which gives attackers access to the system. Initial installation is via fake online casino, FB/social networks, warez websites etc.</p><p>Some forms of malware may simply use your computer’s resources for activities such as cryptocurrency mining. Others may be used to steal credentials as you enter them on a website. For each 1000 installs, hackers can often steal tens of thousands of dollars.</p></section><section id="7"><h2>DDoS attack</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table><p>A distributed denial of service (DDoS) attack aims to take a website offline by sending thousands of requests per second in order to overload the website’s server, causing it to crash.</p></section><section id="8"><h2>Why This Data Is Important</h2><p>For the average person, underground market data isn’t necessarily going to provide much use as they most likely aren’t shopping around for stolen card data or PayPal accounts. Though this is true, the prices at which these items sell provide a powerful perspective.</p><p>If someone gets their hands on your financial details or social media credentials, the prices mentioned above is basically what it’s worth to them. There’s a good chance that you value these things much more than they do, as to them you’re just another mark for a quick buck.</p><p>For far less than the amount your data would sell for on the black market, you can protect it from ever having to reach their hands with a couple of simple rules and habits. With this knowledge, there’s no excuse not to do what you can to protect your data.</p><p>Nothing is foolproof however, and …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.privacyaffairs.com/dark-web-price-index-2020/">https://www.privacyaffairs.com/dark-web-price-index-2020/</a></em></p>]]>
            </description>
            <link>https://www.privacyaffairs.com/dark-web-price-index-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818727</guid>
            <pubDate>Mon, 13 Jul 2020 09:08:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial sites treating FreeBSD like a Linux distro]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 47 (<a href="https://news.ycombinator.com/item?id=23818702">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>On the Gold Coast in January, Deb Goodkin from the FreeBSD Foundation began her Linux.conf.au talk with an intentionally-provocative slide: <em>FreeBSD, that’s just another Linux distro, right?</em> It was said in jest to highlight what a common misconception it is.</p>
<p>One way this manifests is through introductory FreeBSD guides online, usually on blogs with the words sysadmin, cookbook, or tutorial in their names; you know the ones I’m talking about. Invariably they advise updating the base system and pkgng, then immediately installing bash, nano, htop, lsof, coreutils, proc, and more. Some go as far as aliasing these over the built-in tools, and even setting bash as the root shell. From then on, you barely have to touch the FreeBSD userland.</p>
<p>Like a poorly-maintained cheese utensil, this used to grate. If you’re installing an entire GNU toolchain, why not use a Linux distribution, or Debian/kFreeBSD, or a Nexenta-like OS that’s built specifically for those tools? You’re not learning about FreeBSD’s features, nor are you taking advantage of any of its benefits beyond the kernel and base. It’s wasted opportunity, and could render future project contributions more difficult because of misunderstood assumptions about how the system works.</p>
<p><img src="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg" srcset="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg 1x, https://rubenerd.com/files/2020/usebsd-pillow@2x.jpg 2x" alt="A photo of a pillow saying: Use BSD"></p>
<p>I’ve since changed my tune somewhat, with a caveat. I also want to take this opportunity— not a sponsor—to spruik Jay Patel’s <a href="https://www.redbubble.com/people/jaypatelani/shop">RedBubble store</a> for your BSD laptop and loungeroom. I’ve already added some to next sticker batch.</p>
<p>What was I talking about?</p>
<p>We should be encouraging Linux people to try FreeBSD, and if giving them their familiar tooling gets their foot in the door, it’s worth it. I personally learn things the quickest by jumping in the deep end, but I know others want to take things a step at a time.</p>
<p>What also gets lost in the fray is FreeBSD, even with all those Linux-focused tools, is still a compelling and useful operating system. It’s a feature not a bug to be able to have all these tools available, and at times run them faster than Linux could on the same hardware. It may even integrate better into shops that otherwise entirely run Linux, given the motivation to write portable, POSIX-compliant code and applications is no longer a priority for most people (sadface).</p>
<p>So rather than saying those guides aren’t useful or even misrepresent FreeBSD, we need to reframe them. Instead of <em>introductions to FreeBSD</em>, say they’re <em>FreeBSD for Linux people</em>. This shouldn’t be constued as criticism; the latter kinds of post would be <em>hugely</em> useful. It’s also then easier to introduce BSD-specific tools and ideas, either inline after each Linuxism you introduce, or in a follow-up post where you compare and contrast.</p>
<p>We need more bridge-building and outreach between the two communities, and anything to make FreeBSD relatable to people coming from Linux, or any other operating system, is useful.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818702</guid>
            <pubDate>Mon, 13 Jul 2020 09:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Erasmus University Rotterdam builds first virtual campus in the Netherlands]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23818681">thread link</a>) | @vinrob92
<br/>
July 13, 2020 | https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands | <a href="https://web.archive.org/web/*/https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-history-node-id="61036"><p><span><p><time datetime="2020-07-09T12:13:58Z">Thursday, 9 Jul 2020</time></p> </span><span><p>Press release</p> </span></p> <figure> </figure><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Erasmus University Rotterdam (EUR) has re-created their Woudestein campus in the Minecraft platform to provide students and staff a sense of purpose and community during the Covid-19 crisis, a first for the Netherlands. The first blocks of the campus were laid by a small team of enthusiastic students and the project has since then mushroomed to include all buildings on campus, a secret underground labyrinth which players need to find, a treasure hunt for the 17 SDGs (de UN Sustainable Development Goals) and much more. </span></span></span></span></span></span></span></p><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Expansion plans are in the works for the Erasmus Medical Centre and the Erasmus University College. Through this project, EUR aims to fight the Covid-19 setback to the start of the academic year 2020-2021, by giving a platform to the Erasmus community to engage with each other.</span></span></span></span></span></span></span></p><div> <article data-video-provider="YouTube" data-video-id="cQ_Ke1z_Cjo"><div> <picture> <!--[if IE 9]><video style="display: none;"><![endif]--> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=7Ncx-0nR 1x" media="(min-width: 992px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_desktop/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=pjuiFzAV 1x" media="(min-width: 768px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_tablet/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=SqdQGgEy 1x" media="(min-width: 480px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ 1x" type="image/png"> <!--[if IE 9]></video><![endif]--> <img src="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ" alt="Introducing The Virtual Campus - Erasmus University Rotterdam"> </picture></div><div> <h2>Introducing The Virtual Campus - Erasmus University Rotterdam</h2></div></article></div><div><h2>Campus recreated brick by brick</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>It started off as a project to provide students an opportunity for social engagement outside of the Zoom-filled lectures after the Covid-19 pandemic brought universities to a physical shutdown. After a research the Erasmus University Rotterdam (EUR) conducted into the effects of the Corona Crisis on the well-being of its students and staff members, the results strongly pointed towards the need for something to keep the Erasmus community together. People started to feel lonely and missed the ability to socially interact with each other, exactly that what a physical campus is able to provide a podium for. In an attempt to tackle this issue, ErasmusX – a disruptive innovative unit of the university – launched a creative project whereby students and staff could recreate their beloved Woudestein campus in the virtual gaming platform Minecraft. The very first building blocks were laid by members of the student-led Erasmus E-sports Community, and thereafter a professional Minecraft building team helped polish up the final product.</span></span></span></span></span></span></span></p></div><div><h2>"What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale"</h2></div><div><div><h2>Woudestein: a place to meet friends</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>To the EUR community, the campus is not just a place you go to in order to study and work. It is a place where you meet your friends (that perhaps have become like family), where you develop yourself as a human being, where you hang out and where you dream about the opportunities life has in store for you. It almost feels like a small village. “This feeling was so apparent when we saw the many emotional reactions from students and colleagues when they first see the virtual campus – they tell us that navigating the campus makes them feel like they are there again”, states Alexander Whitcomb, a project team member. “What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale. So walking from one end of the campus to the other with your avatar in Minecraft takes exactly the same amount of time as it would do in real life.“</span></span></span></span></span></span></span></p></div></div><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>The Minecraft campus has two main purposes. First it will be used for various planned activities such as onboarding all new incoming students during the famous EurekaWeek 2020, virtual tours for prospective students and the ErasmusX team is also exploring the game platform for educational and research purposes. Secondly, the campus is designed as a creative space, a way for students and staff to design their own interactions and discover new, innovative ways of engaging with one another through the virtual campus. The platform will be moderated by the Erasmus E-sports Community and all ideas are welcomed.</span></span></span></span></span></span></span></p><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Ultimately, the campus in Minecraft is there to strengthen the community of Erasmians, in an academic year where physical interactions are limited by Covid-19, and a ‘normal’ university experience remains unavailable until further notice.</span></span></span></span></span></span></span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818681</guid>
            <pubDate>Mon, 13 Jul 2020 08:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Remote Control Keypad Silicone Oil Problem (2008)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818632">thread link</a>) | @edgartaor
<br/>
July 13, 2020 | http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html | <a href="https://web.archive.org/web/*/http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content">
<p><img src="http://www.michaelshell.org/img/dish_remote_80x250.png" width="80" height="250" alt="Echostar 3000 remote control"></p>
<p id="first_paragraph">
The symptoms are all too familiar - the buttons of a remote control
require very hard presses to be recognized, and the problem only
gets worse with time. Many, many, millions of remotes are replaced
and/or discarded because of this problem. Upon investigating the cause,
I found the presence of an oily substance between the rubber keypad
and the printed circuit board (PCB) it makes contact with. At first, I thought
it was the result of a spill or perhaps even a buildup of hand oil
(and there are technicians who can never be convinced otherwise).
However, the oil did not seem to be petroleum-based as it was highly
resistant to detergent. It reminded me a lot of DOT 5 silicone brake fluid.
And in fact, that is exactly what it turned out to be - silicone oil.
Here is a quote from section 7.0 of the
<span>Silicone Rubber Components Manual</span>
of the Danish company J.D. Friderichsen A/S (which does not exist any more as it was
purchased by the Danish company
<a href="http://www.fst.dk/">Fritz Schur Teknik</a>
in 1999, and the manual is now available only as an
<a href="http://web.archive.org/web/20020225183655/http://www.jdf.dk/esilman/esilman6.htm">internet archive</a>),
which among other things, manufactured silicone rubber keypads:
</p>

<div>
<p>
<strong>7.0 Quality</strong>
</p>
<p>
It is a matter of confidence to buy silicone rubber components, because the
purchaser has to has be certain that the silicone oil is baked out of the
keypad, in order to ensure that quarts don't form on the circuit board and
thereby disrupt the connection. Most of us have probably had this experience
with a remote control at home. (However an incident such as this can also
happen in situations where the OEM are using conductive ink instead of contact
pillars in order to reduce the cost). The only way to control if the silicone
is baked out properly is to check if the keypad has lost some weight after it
has been baked. The current problem is that many far east manufacturers are
used to manufacturing components for cheap products such as one dollar
calculators, and are having difficulties recognizing the requirements set by
western manufacturers. They might not "forget" it for the first few supplies,
but maybe later. The result will surface a few years down the line, so you are
required to know your supplier well. It is equally important that the printed
symbols is baked into the keys, to ensure they don't wear off. A large variety
of qualities are available to the buyer on the market, and you will probably
experience that our price is DKK 0,25 higher than our competition. You are
however welcome to test our quality with an eraser.
</p>
</div>

<p>
I posted about this issue on December 8, 2000 in the thread
<a href="http://groups.google.com/group/sci.electronics.repair/browse_thread/thread/c14d8e962b605e97/ff097119b1b968b1">"Do remote keypads sweat silcone oil?"</a>
(dang it, I misspelled "silicone" in the title) to the Usenet group sci.electronics.repair
and have received email about that post years thereafter. The solution is easy enough - to clean
and degrease the internals of the remote. And this will have to be repeated every
few years, although the interval will become longer as the amount
of oil trapped in the rubber keypad decreases. The remote for my old
Dish Network 3000 satellite receiver (shown at the upper right) was a major offender
and required cleaning every year. My more recent Dish Network 3900 remote, requires
cleaning every 3-5 years. Based on my experience, most remotes with silicone
rubber keypads cannot go a decade without needing to be cleaned. The pressure
generated by pressing a button rather than time itself appears to be the trigger
by which oil is released. So, all things being equal, a remote that is used more often
releases more oil. In theory, it should be possible to bake the oil out yourself
as silicone rubber can take high temperatures (spark plug boots are made out of it).
However, I don't know what temperature is needed or how well the conductive rubber
contacts can withstand this heat without an oxygen-free environment.
</p>

<p>
Now, it is true that silicone oil contamination is not the only cause of
unreliable remotes. Other common problems include bad solder connections
(especially at the LED and battery terminals), worn contacts on the
keypad or PCB, or microbreaks of the PCB traces. While you have the remote apart,
be on the lookout for these other problems. If spotted, bad solder connections
are easy enough to fix by reflowing the solder with a soldering iron. Broken PCB
traces can be really tough to find, but fortunately this normally does
not happen unless the remote has been abused. Worn keypad contacts
are tough to fix. There are conductive rubber repair kits for this
purpose, but they can involve careful cutting and gluing. Sometimes
fine (1000 grit) sandpaper can be used to clean oxides off of the contact
surfaces, but it is all too easy to destroy the conductive rubber contacts
and does not seem to be necessary, so I don't recommend this. You could
try it on stubborn keys if you've tried everything else and have nothing
to loose if it ruins the remote.
</p>


<!-- Amazon Electronics General Bestsellers Ad -->
<!--[if !IE]> <-->

<!----> <!--[endif]---->
<!--[if IE]>
<div class="amazon_ad_ie">
<iframe src="http://rcm-na.amazon-adsystem.com/e/cm?t=micshesweb-20&amp;o=1&amp;p=15&amp;l=bn1&amp;mode=electronics&amp;browse=172282&amp;fc1=000000&amp;lt1=&amp;lc1=3366FF&amp;bg1=FFFFFF&amp;f=ifr" style="border:none;" marginwidth="0" marginheight="0" width="468" height="240" border="0" frameborder="0" scrolling="no">
</iframe>
</div>
<![endif]-->



<h2>Opening and Cleaning the Remote</h2><p>
It isn't the easiest thing in the world to open a remote. First, open the battery
compartment, remove the batteries and unscrew any case screws that are visible.
Using a flat-bladed screwdriver, press fairly hard (take care that you don't stab
yourself should it slip) into the seam between the two halves to
disengage the plastic catches and then twist to snap them apart. Some areas of the
remote are easier to do than others. So, if one place is tough, move to another
position. Once you've got one area unsnapped, work your way all around the remote
until both halves are separated. No matter how careful you are, the screwdriver may
leave raised areas that will make the remote feel terrible in the hand. Shave these
"pips" off with a razor blade knife until they cannot be felt. If you break too many
plastic catches (often caused by not pressing inward to help disengage them before
twisting the screwdriver), you'll have to use something such as silicone sealer (which
will allow the case to be reopened without further damage, but does require a day
to cure) to hold the two halves together when you reassemble it. My open Dish Network
3000 remote and its rubber keypad is shown in figure 1:
</p><div>
<p><img src="http://www.michaelshell.org/img/dish_remote_open_oil_600x392.jpeg" width="600" height="392" alt="An open Dish Network remote control"></p><p>Figure 1: An open Dish Network remote showing silicone oil.</p>
</div><p>
Note the oil just running down the keypad. A closeup is shown in figure 2:
</p><div>
<p><img src="http://www.michaelshell.org/img/dish_remote_oil_closeup_600x300.jpeg" width="600" height="300" alt="closeup of the oil"></p><p>Figure 2: A closeup view of the oil.</p>
</div><p>
This is not the result of a spill, but comes from inside the rubber. Clean and degrease
the entire remote (both case halves inside and outside, both sides of the rubber keypad,
and both sides of the PCB) using a strong detergent (such as 409, dish detergent or
Simple Green) and a toothbrush. Thoroughly scrub the parts with the toothbrush and flush
them with a strong stream of warm water to help push the oil off. You may have to repeat
this as the oil can be stubborn to remove. Thoroughly dry the parts. Blowing them off
with compressed air and letting them dry overnight is perhaps the best approach. Lay the
keypad and filter window in their proper positions and resnap the case together. Reinstall
any screws and the batteries. If your work was successful, you'll be amazed at how
sensitive the keys are compared to the way they were before and you can congratulate
yourself for saving some money. Good luck.



</p></div></div>]]>
            </description>
            <link>http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818632</guid>
            <pubDate>Mon, 13 Jul 2020 08:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Exploratory Data Analysis (EDA)? An Introduction with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818607">thread link</a>) | @fabdrnd
<br/>
July 13, 2020 | https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/ | <a href="https://web.archive.org/web/*/https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.deepflow.ai/content/images/size/w300/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 300w,
                            https://www.deepflow.ai/content/images/size/w600/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 600w,
                            https://www.deepflow.ai/content/images/size/w1000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 1000w,
                            https://www.deepflow.ai/content/images/size/w2000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.deepflow.ai/content/images/size/w2000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg" alt="What is Exploratory Data Analysis? Yes, another post on EDA">
            </figure>

            <section>
                <div>
                    <p><em>Christophe Pere is a senior NLP researcher and a Deepflow advisor. His post was originally published on <a href="https://towardsdatascience.com/what-is-eda-yes-another-post-on-eda-d8b5c06269a9">Medium</a>. Cover picture: <a href="https://unsplash.com/@markusspiske">Markus Spiske</a> — <a href="https://unsplash.com/s/photos/math">Unsplash</a></em></p><blockquote>A notebook containing all the relevant code is available on <a href="https://github.com/Christophe-pere/EDA" rel="noopener nofollow">GitHub</a>.</blockquote><p>Yes, this is a new post among many that address the subject of EDA. This step is the most important of a Data Science project. Why? Because it allows you to acquire knowledge about your data, ideas, and intuitions to be able to model it later.</p><p>EDA is the art of making your data speak. Being able to control their quality (missing data, wrong types, wrong content …). To be able to determine the correlation between the data. To be able to know the cardinality.</p><p>But not only, EDA is not just about exploring data. When you have a target, a column containing label (supervised learning) you also have feature selection and Feature Importance. Without, you have Feature Extraction (unsupervised learning).</p><p>For years, the best way was to tirelessly code the same functions to calculate correlations, plot variables, manually explore the columns to calculate interesting variables, etc…</p><p>But now there are simpler, faster, and more efficient ways to do all of this:</p><h2 id="ia-pandas-profiling">Ia. Pandas-profiling</h2><p>The first, <a href="https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/introduction.html" rel="noopener nofollow">pandas-profiling</a>, can create reports in HTML format with a very nice interface of the content of a <em>dataframe</em>. Based on pandas, it allows with exceptional performance (up to a million lines, recommendation to be taken into account) to make a complete exploration of the data. This report can be integrated via a widget in <em>jupyter lab </em>or <em>notebook</em>. Or, it can also be presented as a frame.</p><p>As the authors indicate, you’ll the relative information:</p><blockquote><strong>Type inference</strong>: detect the types of columns in a dataframe.</blockquote><blockquote><strong>Essentials</strong>: type, unique values, missing values</blockquote><blockquote><strong>Quantile statistics</strong> like minimum value, Q1, median, Q3, maximum, range, interquartile range</blockquote><blockquote><strong>Descriptive statistics</strong> like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness</blockquote><blockquote><strong>Most frequent values</strong></blockquote><blockquote><strong>Histograms</strong></blockquote><blockquote><strong>Correlations</strong> highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices</blockquote><blockquote><strong>Missing values</strong> matrix, count, heatmap, and dendrogram of missing values</blockquote><blockquote><strong>Duplicate rows</strong> List the most occurring duplicate rows</blockquote><blockquote><strong>Text analysis</strong> learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data</blockquote><blockquote>source: <a href="https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/introduction.html" rel="noopener nofollow">pandas-profiling</a></blockquote><p>You can find examples on the <strong><em>GitHub </em></strong>page of the library like:</p><ul><li><a href="https://pandas-profiling.github.io/pandas-profiling/examples/master/meteorites/meteorites_report.html" rel="noopener nofollow">NASA Meteorites landing</a> this report is the output of the function profil_report() and it shows how powerful is this library.</li></ul><p>How to use it? In a few line of code, let me show you:</p><p>It takes a few seconds to compute compare to something hardcoded to get an impressive result.</p><p>The result when you show the report in a widget:</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 1005w" sizes="(min-width: 720px) 720px"><figcaption>Pandas-profiling profile report in widget (rendering)</figcaption></figure><p>The result when you show the report in a frame inside the notebook:</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 1004w" sizes="(min-width: 720px) 720px"><figcaption>Pandas-profiling HTML in a frame (rendering)</figcaption></figure><h2 id="ib-dataprep-eda">Ib. Dataprep.eda</h2><p>Another great library is <strong><em>dataprep</em></strong> with module <strong><em>eda</em></strong>. What is doing?</p><p>You have three main functions:</p><ul><li><strong>plot</strong></li></ul><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 1044w" sizes="(min-width: 720px) 720px"><figcaption>plot function of the dataprep.eda package on the Boston House Prices data set</figcaption></figure><p>This function will show you a histogram for each feature. Each plot is interactive based on the <strong>bokeh </strong>library. You have different parameters that allow you to show information on the data you want.</p><ul><li><strong>plot_correlation</strong></li></ul><p>The function allows you to compute three sorts of the correlation matrix (Pearson, Spearman, and KendallTau). The advantage is that the plot is also interactive and you can see the values just putting the cursor on it.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-ZqLi8cHnCYnPf0XtgDsyHg.png" alt=""><figcaption>plot_correlation on Boston House Prices data set</figcaption></figure><ul><li><strong>plot_missing</strong></li></ul><p>This last function is very interesting like the picture below shows you. It allows you to visualize where the missing data are in the column and the percentage of them.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-6qEJdtUj4v_ITqSEHlW05Q.png" alt=""><figcaption>plot_missing function</figcaption></figure><h2 id="ic-sweetviz">Ic. Sweetviz</h2><p>The last interesting library is <a href="https://github.com/fbdesignpro/sweetviz" rel="noopener nofollow">sweetviz</a>. Based on pandas-profiling the library permits to compare different columns or the train and test part of your data to determine if the test set is representative of the train. Like pandas-profiling, you have tons of information per columns. The picture below shows the dashboard of the HTML report generated by the library.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 1592w" sizes="(min-width: 720px) 720px"><figcaption>Comparison between train and test with Sweetviz</figcaption></figure><p>EDA is not just a focus on what is inside the data. You can also go deeper into the analysis with the following parts. The feature selection is a manner to reduce the number of features present in your dataset.</p><p>Here, I just present three ways to do it. The <a href="https://scikit-learn.org/" rel="noopener nofollow">sklearn </a>library has powerful modules to do what you want in terms of selecting or extracting data.</p><h2 id="iia-removing-feature-with-low-variance">IIa. Removing Feature with low variance</h2><p>This technique simply makes it possible to select the features which have a threshold lower than that fixed. It removes all features whose variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e. features that have the same value in all samples. In the code below, the columns with more than 80% missing data are automatically deleted. This method doesn’t look to the prediction variable y so it can be used in an unsupervised way.</p><pre><code>from sklearn.feature_selection import VarianceThresholdthreshold = 0.8 # 80% of low variance

fe_low_variance = VarianceThreshold(threshold=(threshold * (1 - threshold)))
X_variance = fe_low_variance.fit_transform(X)</code></pre><h2 id="iib-univariate-selection">IIb. Univariate Selection</h2><p>In supervised learning, you have a target feature (commonly named <strong><em>y</em></strong>). The goal of the univariate selection is simple, to take one feature to make a variation on it, and see how it affects the estimated target. In the end, the univariate select will select the best feature based on the univariate statistical test.</p><p>With sklearn, you have 4 methods to do it.</p><ul><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" rel="noopener nofollow"><strong>SelectKBest</strong></a>: This will select the best <strong><em>k</em></strong> (manually chooses by the user) features of your dataset and removes the others. This function needs a scorer, a metric function to apply the selection. The commonly used scorer function is <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2" rel="noopener nofollow"><strong><em>chi2</em></strong></a>.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile" rel="noopener nofollow"><strong>SelectPercentile</strong></a>: Same as <em>SelectKBest </em>you need to pass a scorer, but instead of a <strong><em>k</em></strong> number of features, you pass a percentile value.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFpr.html#sklearn.feature_selection.SelectFpr" rel="noopener nofollow"><strong>SelectFpr</strong></a><strong>/</strong><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFdr.html#sklearn.feature_selection.SelectFdr" rel="noopener nofollow"><strong>SelectFdr</strong></a><strong>/</strong><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFwe.html#sklearn.feature_selection.SelectFwe" rel="noopener nofollow"><strong>SelectFwe</strong></a>: selection by the <strong><em>pvalues</em></strong> based on the false positive rate, the false discovery rate, and the family-wise error.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html#sklearn.feature_selection.GenericUnivariateSelect" rel="noopener nofollow"><strong>GenericUnivariateSelect</strong></a>: Here you can customize your estimator with configurable strategy.</li></ul><p>In the code below I use <strong><em>SelecKBest </em></strong>with <strong><em>chi2 </em></strong>scorer:</p><pre><code>from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

#apply SelectKBest class to extract top 10 best features
select_best_features = SelectKBest(score_func=chi2, k=10) # where k is the number of features you want
fit = select_best_features.fit(X,y)
df_scores = pd.DataFrame(fit.scores_)
df_columns = pd.DataFrame(X.columns) # where X is your data
#concat two dataframes for better visualization
feature_scores = pd.concat([df_columns,df_scores],axis=1)
feature_scores.columns = ['Specs','Score']  #naming the dataframe columns
print(feature_scores.nlargest(10,'Score'))  #print 10 best features</code></pre><h2 id="iic-recursive-feature-elimination">IIc. Recursive Feature Elimination</h2><p>As the picture below shows, the principle of the RFE is simple. The estimator fit the data and compute the feature importance, it’s the weight of the data on the target. At each iteration, the model will remove the feature with lower importance until reach the number of <strong><em>k</em></strong> features needed.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-AWnrEWagQiol5hUeqe52kw.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 1074w" sizes="(min-width: 720px) 720px"><figcaption>Schema of the RFE</figcaption></figure><p>How could we code this? I show here an implementation for <strong><em>SVM </em></strong>and <strong><em>Logistic Regression</em></strong>.</p><p><strong>SVM:</strong></p><pre><code>from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_selection import RFECV

# SVM implementation
svc = SVC(kernel="linear")
# The "accuracy" scoring is proportional to the number of correct

rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(5),            scoring='accuracy')rfecv.fit(X, y)

print("Optimal number of features : %d" % rfecv.n_features_)</code></pre><p><strong>Logistic Regression:</strong></p><pre><code># Feature Extraction with RFE
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver='lbfgs', max_iter=5000)
rfe = RFE(model, 3)
fit = rfe.fit(X, Y)
print("Num Features: %d" % fit.n_features_)
print("Selected Features: %s" % fit.support_)
print("Feature Ranking: %s" % fit.ranking_)</code></pre><h2 id="iid-selectfrommodel">IId. SelectFromModel</h2><p>This last method is a generalization of the previous because <strong><em>SelectFromModel </em></strong>takes an <strong><em>estimator </em></strong>and returns a new matrice containing the reduced dimension.</p><p>The code below shows how to implement it:</p><pre><code>from sklearn.svm import LinearSVC
from sklearn.feature_selection import SelectFromModel

lsvc = LinearSVC(C=0.01, penalty="l1", dual=False) # estimatorlsvc.fit(X, y)
model = SelectFromModel(lsvc, prefit=True)
X_new = model.transform(X)
print(f"The new number of feature is {X_new.shape[1]}")</code></pre><h2 id="iiia-principal-component-analysis-pca-">IIIa. Principal Component Analysis (PCA)</h2><p>The Principal Component Analysis is a method used to reduce the dimension of a dataset. The principle is simple, the PCA will fit a line or a plane to the points to create another representation of the data.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-lh5TKadyKILDVlaazuE1UA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 1227w" sizes="(min-width: 720px) 720px"><figcaption>PCA projection</figcaption></figure><p>The code is simple to use. You just have to specify the N_var parameter which represents the number of dimensions you want.</p><pre><code>from sklearn.decomposition import PCA
N_var = 2
pca = PCA(n_components=N_var)
X_pca = pca.fit_transform(X)
df_pca = pd.DataFrame(data = X_pca, columns = ['PC1', 'PC2'])</code></pre><h2 id="iiib-independent-component-analysis-ica-">IIIb. Independent Component Analysis (ICA)</h2><p>ICA is a powerful technique to separate multivariable independent signals linearly mixed. This technique can permit us to separate different signals in signal processing.</p><p>The code below shows an implementation of a <strong><em>FastICA</em></strong>:</p><pre><code>from sklearn.decomposition import FastICA
N_var = 2
ica = FastICA(n_components=N_var)
X_ica = ica.fit_transform(X)</code></pre><h2 id="iiic-linear-discriminant-analysis-lda-">IIIc. Linear Discriminant Analysis (LDA)</h2><p>I share here the abstract of the original paper explaining LDA.</p><blockquote>We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/">https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/</a></em></p>]]>
            </description>
            <link>https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818607</guid>
            <pubDate>Mon, 13 Jul 2020 08:49:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM64 Popcount in Golang and Assembler]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818574">thread link</a>) | @fanf2
<br/>
July 13, 2020 | https://barakmich.dev/posts/popcnt-arm64-go-asm/ | <a href="https://web.archive.org/web/*/https://barakmich.dev/posts/popcnt-arm64-go-asm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Apropos of Apple’s ARM announcment, I thought I might write up a post on a recent bit of code I wrote that specifically looks at ARM64, and its benchmarks on various hardware.</p><p>I’ve been implementing some compact data structures for a project. One of the CPU hotspots for the implementation is the need to run a quick population count across a potentially large bit of memory.</p><p>If you’ve never seen population count before, it’s the count of the number of set 1 bits in a byte (or list of bytes) – for example:</p><div><pre><code data-lang="text">0xF3 == 0b11110011
popCount(0xF3) == 6
</code></pre></div><p>Now, every reasonable x86_64/amd64<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> CPU in the past decade or so has a built-in instruction for this: <a href="https://en.wikipedia.org/wiki/SSE4#POPCNT_and_LZCNT"><code>POPCNT</code></a>. It works like this (in Go Assembler):</p><div><pre><code data-lang="text">MOV    $0xF3, R10  // Store a constant
POPCNT   R10, AX   // AX now equals 6
</code></pre></div><p>Go uses the built-in instruction for this in the <code>math/bits</code> via SSA compiler rewrites (which it added in 1.9), but only up to a uint64 at a time; using assembly to loop over a <code>[]byte</code> is considerably more efficient</p><p><a href="https://github.com/tmthrgd"><code>@tmthrgd</code></a> created a really nice little x86_64-assembly-optimized package at <a href="https://github.com/tmthrgd/go-popcount">github.com/tmthrgd/go-popcount</a>. It works great, works around a weird little Intel bug (see the helpful comments) and is still faster than looping and using the Go standard library, which it helpfully benchmarks as well.</p><p>Recently, I picked up one of the new 8GB Raspberry Pi 4s. Loaded it up with the nice new <a href="https://manjaro.org/">Manjaro 20.06</a> and set up my usual environment. As a test, I wanted to try my latest WIP data structure code.
Of course, the bottleneck was right where I expected it to be: in the population count.</p><h3 id="implementing-it">Implementing it</h3><p>I discovered that ARM64 has a <code>POPCNT</code>-like instruction, logically enough called <code>CNT</code>. I thought, since I’ve been playing with Go assembly for memmove, why not try my hand at the new architecture?</p><p>Go already has the SSA-rewrite for OnesCount on ARM (added in 1.11), but again, only a uint64 at a time. There might be some performance on the table.</p><p><a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">Official architecture guide</a> at the ready, I got to work. And there was a lot to learn. Some notes:</p><h4 id="1-its-part-of-the-vector-suite-neon">1. It’s part of the vector suite, NEON</h4><p>NEON is the name for the addition of vector instructions to the ARM architecture, so I’d be working with both an unfamiliar architecture <em>and</em> its vector instructions.</p><p>In x86-land, <code>POPCNT</code> and vectorization are two separate concepts. <code>POPCNT</code>, as an instruction, deals with everyday, 64-bit integer registers, and not the vector registers (even though it appeared approximately the same time as the addition to vector instructions, SSE4)<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p><p>ARM/NEON did <code>CNT</code> differently. Since you can load an array of items (say, 16 bytes, in the ARM64 vector registers), <code>CNT</code> will count them individually. In fact, you can <em>only</em> do it in vectors of single bytes.</p><p>So this means that the following signatures are approximately the way to think about it:</p><div><pre><code data-lang="go"><span>func</span> <span>popCountx86</span><span>(</span><span>in</span> <span>uint64</span><span>)</span> <span>uint64</span> <span>// register-at-a-time, 64-bit (8 bytes)
</span><span></span>
<span>func</span> <span>popCountNeon</span><span>(</span><span>in</span> <span>[</span><span>16</span><span>]</span><span>byte</span><span>)</span> <span>[</span><span>16</span><span>]</span><span>uint8</span> <span>// 16 bytes all counted in parallel.
</span></code></pre></div><p>This ends up being really effective, as it turns out (below).</p><h4 id="2-gos-assembler-documentation-is-barebones">2. Go’s assembler documentation is barebones</h4><p>Writing instructions so that Go’s assembler is happy with the instructions you’re giving it is a bit frustrating.</p><p>There’s a good gloss at <a href="https://golang.org/pkg/cmd/internal/obj/arm64/">golang.org/pkg/cmd/internal/obj/arm64</a> which gives an overview of many of the differences.
For example, all vector instructions start with <code>V</code>, different than what ARM64 switched to (they used to commonly start with V on 32-bit ARM) – so while I understand the desire for continuity (and even subtly like it, knowing it’s a vector op) it’s just makes another little difference to remember vs. the original documentation.</p><p>But more frustrating is, even if your instruction is supported (and most of them are) knowing how to <em>use</em> the instruction in Go assembler boils down to “assume data goes left-to-right and hope there’s an example <a href="https://github.com/golang/go/blob/master/src/cmd/asm/internal/asm/testdata/arm64enc.s">in the test suite</a>”</p><p>I’m a big Go fan, yet Go’s history into Plan 9 and accompanying assembler (and, relatedly, odd calling conventions) is one of my gripes about Go, even more than lack of generics (which is a topic for another day).
Sure, there were some good ideas in Plan 9 that influenced the design of Go – from a design level, it’s great! – but on the implementation level, this is one place where I kinda wish it had followed precident.
Take whichever side you want in the Intel vs GNU syntax debate, <a href="https://xkcd.com/927/">creating a third option</a> means relearning all the quirks from scratch, and ignoring any documentation that already exists.</p><h3 id="putting-it-all-together">Putting it all together</h3><p>The end result is my friendly fork of <code>go-popcount</code>: <a href="https://github.com/barakmich/go-popcount">github.com/barakmich/go-popcount</a></p><p>Really, it’s more of an extension than a fork – it provides the same API, just with handwritten assembly for ARM64 chips.</p><h4 id="how-it-works">How it works</h4><p>The vectorization works really well. The process is:</p><ul><li>Load a set of vector registers, 16 bytes each</li><li>popCount them</li><li>Vector sum their partial results (up to 32 individual vectors, to fit the 8-bit counts), trying to avoid a data dependency</li><li>Finally, sum (“widening”, in vector terms) the final vector</li><li>Add it to the final output</li></ul><p>The other thing to balance was how much to load from memory vs. how much work to do to optimize throughput. That ended up being about 8 vectors (128 bytes) at a time.
That may vary as a function of CPU, but it’s a good place to start.</p><h4 id="arm64-feels-nice">ARM64 feels nice</h4><p>This is purely subjective, but there were a number of moments where I felt “hey, that’s handy” in writing ARM64 assembly.
Of course modern x86_64 chips account for all of these differences and makes them performant – through deeper instruction pipelines or having <a href="http://sunnyeves.blogspot.com/2009/07/intel-x86-processors-cisc-or-risc-or.html">micro-op instruction queues</a> that ultimately pull the same tricks.
But at the same time, when you’re dropping down to work at the instruction level, it’s kind of a breath of fresh air.</p><h5 id="pre-and-post-increment">Pre-and-post increment</h5><p>A lot of the time when you’re working with an array of whatever you’re pulling a chunk of memory into registers, doing some transform, and putting it back.</p><div><pre><code data-lang="asm"><span>VLD1.P</span> <span>64</span><span>(</span><span>R1</span><span>),</span> <span>[</span><span>V16.B16</span><span>,</span> <span>V17.B16</span><span>,</span> <span>V18.B16</span><span>,</span> <span>V19.B16</span><span>]</span>
</code></pre></div><p>Reads as load 1-byte*size structures into the following vector registers – so far so good, this is similar to the <a href="https://www.felixcloutier.com/x86/movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64"><code>VMOVDQU</code></a> instruction family (though the size-structure variants on that instruction are a recent addition) on x86. It has a similar ability to load many registers in multiple back-to-back instructions through address/offset/size calculation, but ARM has a nice one-liner that way.</p><p>But I really like the auto-increment of <code>R1</code> by the read size (64) after loading – hence post-increment. Many loads from memory have a similar flag. It’s very descriptive and means things like “increment the offset register and decrement the size register and test” things live with their appropriate parts of the code, instead of having to increment later (and finding the optimal time)</p><h5 id="consistency-of-style">Consistency of style</h5><p>This is a holdover from history, but the consistency of having fixed-size instructions is a nice thing when trying to hand-assemble an instruction. I had to do some hand-assembly when <a href="https://github.com/golang/go/issues/39445">I discovered and reported a bug in Go</a>. It was silently writing the wrong version of the instruction while accepting the correct one as input. Kudos to the Go community – it was fixed by an expert within a day or two, so I’m looking forward to the next version that contains the fix!</p><p>Still, this meant with a <a href="https://xkcd.com/378/">steady hand</a> and a copy of <a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">the architecture guide</a> I could feasibly implement any instructions that were missing.</p><p>Also in consistency-land, most binary operations take <code>input1_reg, input2_reg, output_reg</code> with few exceptions. Omitting the output_reg is Go’s assembler syntactic sugar to set output to input2. x86, again for historical reasons (trying to keep instructions small), often has the store-to-the-second-register as the primary or only version of an operation, which can lead to more operations overall (and cognitive overhead IMO).</p><h3 id="benchmarking-on-arm">Benchmarking on ARM</h3><p>So let’s take a look at some benchmarks.
The most interesting thing about looking at population count is that this little routine does something useful and shows tradeoffs between CPU bounds and memory bandwith between the CPU, the on-chip caches, and main memory.
At array sizes small enough to fit into CPU cache (but big enough to run the compute loop a few times), the CPU is the limiting factor – how many bits it can count.
For larger data sizes, the memory bandwidth becomes the bound; the CPU is waiting on getting enough data to crunch through.</p><p>To this end, the benchmark curves in the repository max out in throughput at about 16K (most work possible, while still being in cache) and then trail down into a steady state as memory becomes the bound. So I’ll truncate the full benchmarks to compare peak throughput and long tail.</p><p>Some findings and commentary:</p><h4 id="raspberry-pi-4">Raspberry Pi 4</h4><div><pre><code data-lang="text">Unoptimized (Go implementation):
BenchmarkCountBytesGo/16K              297778          8056 ns/op     2033.78 MB/s
BenchmarkCountBytesGo/512M                  8     279380432 ns/op     1921.65 MB/s

Optimized (My hand-rolled assember):
BenchmarkCountBytes/16K                520807          2303 ns/op     7113.24 MB/s
BenchmarkCountBytes/512M                    8     131214574 ns/op     4091.55 MB/s
</code></pre></div><p>This was my finished product on my local Pi. I may be able to do better, but varying the block sizes between grabbing from memory and doing the vector addition for popcount topped out about here, so I’m fairly satisfied.</p><p>Interestingly, the ~4.1GB/s memory bandwidth follows exactly with <a href="https://hackaday.com/2019/07/10/raspberry-pi-4-benchmarks-processor-and-network-performance-makes-it-a-real-desktop-contender/">initial read benchmarks of the Pi 4</a> suggesting it’s close to saturation, which is good news.</p><h4 id="ampere-emag">Ampere eMag</h4><p>So my next thought was to spin up an ARM64 server with my old friends at <a href="https://packet.net/">Packet</a>. They have a <a href="https://www.packet.com/cloud/servers/c2-large-arm/">c2.large.arm</a> and it’s gonna be great!</p><div><pre><code data-lang="text">Unoptimized:
BenchmarkCountBytesGo/16K      	   69939	     17208 ns/op	 952.09 MB/s
BenchmarkCountBytesGo/512M     	       2	 582293709 ns/op	 921.99 MB/s

Optimized:
BenchmarkCountBytes/16K        	  458394	      2614 ns/op	6267.80 MB/s
BenchmarkCountBytes/512M       	      12	  93371433 ns/op	5749.84 MB/s
</code></pre></div><p>…but I was rather underwhelmed.</p><p>This isn’t necessarily Packet’s fault – they were early onto having ARM hardware available and it’s …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://barakmich.dev/posts/popcnt-arm64-go-asm/">https://barakmich.dev/posts/popcnt-arm64-go-asm/</a></em></p>]]>
            </description>
            <link>https://barakmich.dev/posts/popcnt-arm64-go-asm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818574</guid>
            <pubDate>Mon, 13 Jul 2020 08:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Consolidation of the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817946">thread link</a>) | @Fizzadar
<br/>
July 13, 2020 | https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/ | <a href="https://web.archive.org/web/*/https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
 
<div>

        <h2>
            On the Consolidation of the Web
            <span>Wed 29 July 2020</span>
        </h2>

        <p>In recent years, the web has been consolidating. From the servers to the apps, a growing majority of the web is controlled by a small pool of companies. When AWS was founded in 2006 I was just starting out with my first VPS, running this blog on WordPress (the good ol' days!). For the last 10 years I have part-run a small VPS (“cloud server”) host called <a href="https://afterburst.com/">Afterburst</a>. Throughout these years I have watched this consolidation, and these are my observations.</p>

<h3>The Pre-Cloud Days</h3>

<p>Way back in 2009 blogs were booming. The market for personal servers was growing rapidly. People often used forums (remember those?) to find providers. Providers would compete to attract the most eyeballs to their sale posts.</p>

<p>The quality and cost of hosting varied wildly. During summer there would be a huge influx of budget “summer hosts” during school holidays. The majority of these would then fold only two months later. Thinking back, it was The While West. Of course there were big players; but the smaller hosts had the cheapest offers and captured the market for personal servers.</p>

<p>I believe that this was a great market for all. Buyers had a wealth of choice of companies tiny to massive. Providers were kept in check by thriving forum communities, leading to better services. The smaller providers would offer a personal touch, often partaking in forums alongside their customers. To me, this was an amazing environment in which I learnt a huge amount about servers but also customer service.</p>

<h3>The Clouds Ascend</h3>

<p>The VPS market was exploding when we started Afterburst in 2010. Shared hosting/PHP was stagnating and the prices had bottomed out. Shared hosting was consolidating fast, hosts were folding daily. Dedicated server and VPS markets remained strong and WebHostingTalk (our “home” forum) was buzzing with activity. The competition for the best VPS was in full swing.</p>

<p>And then came DigitalOcean.</p>

<p>When DO arrived in 2011 everything changed. They managed to make the much hyped “cloud” accessible to everyone where AWS had so far struggled. You could click a button and have a cloud server available within minutes. The all-SSD package, “cloud” marketing and a wave of free launch coupons caused them to explode onto the scene.</p>

<p>It was fascinating to watch the “cloud” hype train. “Cloud servers” were, almost overnight, seen as superior to “VPS”. This is despite most “cloud server” providers offering nothing different to VPS. Now I totally get that The Cloud goes way beyond servers. The offerings today include a staggering number of services. But an individual looking for a server to host their blog? They don’t need any of that, just the server space.</p>

<p>In the years since DO arrived they, AWS and later Azure/GCloud boomed. Cloud was/is the future - we must move everything “to the cloud” many a huge tech company would say. As much as it was marketing hype, the individual started to follow. The cloud was only a little more expensive and came with fancy UI and excellent developer tooling. It was cool to be using the cloud. The small/traditional VPS provider market began to slow, and later reduce. The golden days were over.</p>

<p>Whilst this was very frustrating at the time it also forced us to review and improve our marketing and customer experience. We started marketing cloud servers and optimised the checkout and customer sign-up flow. The competition led to an improved service for existing and new customers.</p>

<h3>So - where are we now?</h3>

<p>10 years later, we’re still here! The consolidation of providers has slowed and many continue to survive. Forums like WHT struggle on but are shadows of their former selves. There’s still a market for individual servers - people have a natural desire to tinker in ways that specific services cannot provide.</p>

<p>I think there will remain a cohort of individual bloggers and websites. But I also believe the web is dividing. On one side a small number of platforms the vast majority of “normal” people consume from and share to. And elsewhere a separate “old style” web of fragmented loosely connected websites/forums/blogs formed by those who tinker. Perhaps something will merge the two together in the future.</p>

<p>It’s like supermarkets consuming ‘Mom and Pop shops’, a trend that goes back decades now. Yet small greengrocers and butchers still live on. There are signs of people returning to these shops in growing numbers. Perhaps this is the start of a reverse trend, could the web follow suit? I’d like to think so.</p>
</div>
    
    </section></div>]]>
            </description>
            <link>https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817946</guid>
            <pubDate>Mon, 13 Jul 2020 07:18:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Profile READMEs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23817930">thread link</a>) | @patelpankaj
<br/>
July 13, 2020 | https://time2hack.com/create-activate-github-profile-readme/ | <a href="https://web.archive.org/web/*/https://time2hack.com/create-activate-github-profile-readme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>The <strong>Github Profile README</strong> design was being in twitter conversation for a while. I discovered it with one of the profiles with README in theirs.</p><p>I went ahead and <a href="https://github.com/pankajpatel">added on mine</a> and it looks super awesome 😎 now:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/profile-readme.png" alt=""><figcaption>My <a href="https://github.com/pankajpatel">profile <strong>README</strong></a></figcaption></figure><p>You can also <strong>activate profile README</strong> on yours by simply <a href="https://github.com/new">creating a new repository</a> with same name as your Github profile handle. So for me, it is <code>pankajpatel</code> as the repository name; similar to my Github username.</p><p>You can also see it in the above picture, the <code><strong>README.md</strong></code> is from <code>pankajpatel/README.md</code></p><p>When you will go ahead and <strong>create a repository with same name as your profile handle</strong>; you will see the following message:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/new-repo.png" alt=""></figure><hr><p>Just initialize your repository with a <strong>README</strong> file by checking the checkbox below. Other files in the initialization don't matter for this repository</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/initialize-with-README.png" alt=""></figure><hr><p>Once you hit <code><strong>Create Repository</strong></code> button, you will see the repository with list of files as follows:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/fresh-README-repo.png" alt=""></figure><p>Important thing to note here is the green box on right side:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/readme-repo-edit-readme.png" alt=""></figure><hr><p>Click on <code><strong>Edit README</strong></code> and start editing the Welcome message of your profile. By default, you will see the following contents on your <strong>README</strong> as a hint to get started:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/start-editing-profile-README.png" alt=""></figure><hr><p>You can add content as Markdown or HTML and preview it in the next tab. Once you are done, you can commit the file and your profile will show this <strong>README</strong> above the top/pinned repositories of your profile.</p><p>If you are new to Markdown, you can follow this <a href="https://guides.github.com/features/mastering-markdown/">guide to get started with Markdown</a>.</p><hr><h2 id="for-organizations">For Organizations?</h2><p>Unfortunately, the Organizations are not having this feature but I hope this feature will come there. I tried for time2hack's org on github and it still looks the same:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/org-time2hack-readme.png" alt=""></figure><hr><h2 id="conclusions">Conclusions</h2><p><em>Github Profile README</em> is a good way to introduce yourself to your profile visitors.</p><p>This way others can know more about you other than your top repositories and how much you code every day.</p><p><strong>Github Profile README is a nice flavour to Social Coding.</strong></p><p><strong><em>Have you created yours? And How does it look like?</em></strong></p><p>Let me know through comments 💬 or on Twitter at &nbsp;<a href="https://twitter.com/patel_pankaj_">@patel_pankaj_</a> &nbsp;and/or &nbsp;<a href="https://twitter.com/time2hack">@time2hack</a></p><p>If you find this article helpful, please share it with others 🗣</p><p>Subscribe to the blog to receive new posts right to your inbox.</p><hr><h4 id="credits">Credits</h4><p>Icon from <a href="https://icons8.com/icon/52539/github">https://icons8.com/icon/52539/github</a></p><p>Photo by <a href="https://unsplash.com/@yancymin?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Yancy Min</a> on <a href="https://unsplash.com/s/photos/github?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>

<ins data-ad-client="ca-pub-1830015441649630" data-ad-slot="3501574357" data-ad-format="auto" data-full-width-responsive="true"></ins>

</section></div>]]>
            </description>
            <link>https://time2hack.com/create-activate-github-profile-readme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817930</guid>
            <pubDate>Mon, 13 Jul 2020 07:16:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Sourcing Company Culture]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817799">thread link</a>) | @soorajchandran
<br/>
July 12, 2020 | https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/ | <a href="https://web.archive.org/web/*/https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-318">

	

	
	<div>
		
<figure><img data-attachment-id="353" data-permalink="https://blog.oysterhr.com/adobestock_32068789/" data-orig-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png" data-orig-size="1491,1008" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="adobestock_32068789" data-image-description="" data-medium-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300" data-large-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=750" src="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024" alt="" srcset="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024 1024w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=150 150w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300 300w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=768 768w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png 1491w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>TL;DR: <em>Companies that have recently gone fully-remote can draw inspiration from open source. Doing so provides helpful ways to think about attracting talent and building culture.&nbsp;</em></p>



<p><strong>Fully-Distributed is Taking Off</strong></p>



<p>Though the headlines have focused on the <a rel="noreferrer noopener" href="https://www.cnn.com/2020/05/22/tech/work-from-home-companies/index.html" target="_blank">big name companies</a> and their announcements about going remote, events of the last four months have undoubtedly created a lot of new fully-distributed companies you’ve <a rel="noreferrer noopener" href="https://www3.nhk.or.jp/nhkworld/en/news/videos/20200622091038913/" target="_blank">never heard of</a>. This includes organizations that may have been partially or even fully-colocated (office-based) before Coronavirus. And this is happening in part because remote working has worked out so well for so many of them, and in part because it has proven difficult for many companies to scale down to a “reduced” real estate footprint — to serve a subset of their employees. Hybrid is <a rel="noreferrer noopener" href="https://www.linkedin.com/pulse/remote-work-having-moment-future-isnt-hybrid-sid-sijbrandij/" target="_blank">harder</a> than fully-distributed, we keep hearing. And the truth is that returning to the office is still an open discussion (fraught with overwhelming <a rel="noreferrer noopener" href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank">emergent</a><a href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank" rel="noreferrer noopener"> logistical considerations</a>) even for companies that really want to.</p>



<p>We have also no doubt seen in the last four months an acceleration in the rate of creation of new fully-distributed startups that reject offices altogether, and that do not expect their people to meet physically to get work done. This was already a trend, and any founders who may have been hesitant before Coronavirus because they were worried about investor bias or their own inexperience with remote leadership, now have <a href="https://techcrunch.com/sponsor/oyster/the-dawn-of-the-distributed-age/" target="_blank" rel="noreferrer noopener">enormous encouragement</a> to kick the office to the curb.</p>



<p>This means, however, that now many, many more companies, not just the ones that were already on the fully-distributed bandwagon before COVID-19, are going to face the challenges unique to fully-distributed organizations.</p>



<p><strong>Next-Level Guidance is Needed</strong></p>



<p>There’s been a great outpouring of new content from the community on the basic how-to’s of remote working. We have also seen that the “bibles of remote working” (that have been around for years from the pioneering remote working companies like <a rel="noreferrer noopener" href="https://distributed.blog/" target="_blank">Automattic</a>, <a href="https://about.gitlab.com/company/culture/all-remote/guide/">Gitlab</a>, and <a href="https://basecamp.com/remote-resources">Basecamp</a>, etc) are getting the reference attention they deserve. These basics (like asynchronous communication) are of course essential principles that have to be properly installed for a fully-distributed team to walk and run. But there are other challenges that come with being a fully-remote organization for which there’s less explicit guidance.</p>



<p>Two such challenges we keep hearing about are:</p>



<ul><li>How do you attract and recruit great talent from around the world (<em>whom you may never meet in person</em>)?, and</li><li>How do you create and sustain great culture (<em>when everything is virtual</em>)?</li></ul>



<p><strong>Open Source, a Model of Distributed Success</strong></p>



<p>To these important challenges of fully-distributed organizations, the <a href="https://www.redhat.com/en/topics/open-source/what-is-open-source" target="_blank" rel="noreferrer noopener">principles and history of Open Source</a> would seem to offer a lot.&nbsp;</p>



<p>We often hear that software “eats” things. An aspect of that is that the ways of software development continue to penetrate into the ways other types of work are done. That open source should provide ways of thinking and working that are helpful to fully-distributed organizations may be yet another example of something that started in software development spreading more generally into business. Like <a rel="noreferrer noopener" href="https://agilemanifesto.org/principles.html" target="_blank">Agile</a> and <a rel="noreferrer noopener" href="https://www.agilealliance.org/glossary/kanban/" target="_blank">Kanban</a> have. This keeps happening because these “frameworks from another domain” offer avenues to better ways of working, even when what you’re doing is some other type of knowledge work.&nbsp;</p>



<blockquote><p>Whether or not they are a software company, fully-distributed organizations are going to have to become more like software companies in their ways of working.</p><a href="http://twitter.com/share?&amp;text=Whether%20or%20not%20they%20are%20a%20software%20company%2C%20fully-distributed%20organizations%20are%20going%20to%20have%20to%20become%20more%20like%20software%20companies%20in%20their%20ways%20of%20working.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=HeyOyster" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>This shift will be necessary for non-software development knowledge work to be done well in a fully-distributed organization. Naturally, that has deep implications for how technology will support knowledge work in the future. For that reason, we’re also going to see a pattern where new tools are going to be created that allow non-software developer knowledge workers to work more like developers do. This was also probably a trend well in evidence before Coronavirus, now greatly accelerated.</p>



<p>Once your organization is thinking and working a bit more like a fully-distributed software company (especially if you ARE a software company), it shouldn’t be too difficult to aspire to some of the attributes of an open source project.&nbsp;&nbsp;</p>



<p>Open source is worthy to provide guidance and inspiration to any fully-distributed company because it demonstrates a model through which great talent is not only attracted but also uniquely enabled and remotely synchronized to produce semi-miraculous results.&nbsp;</p>



<p>There is no better example of this than Linux.</p>



<blockquote><p>“Linux was the first project for which a conscious and successful effort to use the entire world as its talent pool was made.”</p><cite><em>Eric Steven Raymond, <a rel="noreferrer noopener" href="http://www.catb.org/~esr/writings/cathedral-bazaar/cathedral-bazaar/ar01s11.html" target="_blank">The Social Context of Open-Source Software</a></em></cite></blockquote>



<p>Successful open source projects like Linux should inspire fully-distributed companies because they demonstrate the extraordinary productivity potential of organized knowledge work performed by a team of people who didn’t ever have to meet in person to accomplish it.</p>



<p><strong>Becoming a Beacon for Global Talent</strong></p>



<p>Organizations who’ve let go of their offices and have recently made the transition to fully-distributed are probably still focused on getting things back on track, and on fostering the healthy continuity of the pre-existing team. Though hiring may not be the present priority, they must surely be thinking about how recruitment will work as a fully-remote company. Whether they are fully-distributed or just have newly-created remote roles, as organizations shift their recruiting perspective from thinking locally to thinking globally, this is going to radically transform the recruiting process as we have known it.&nbsp;</p>



<p>Even for companies that decide they will only hire in a subset of timezones (to facilitate synchronous work, like <a href="https://www.quora.com/q/quora/Remote-First-at-Quora" target="_blank" rel="noreferrer noopener">Quora</a>), the size of the available talent pool would still overwhelm the traditional recruitment approaches of “publishing” their open roles and waiting for “applicants” to express an interest in them. The new pervasiveness of remote working and highly-distributed companies is going to create unprecedented liquidity in the global talent marketplace. This is great for all parties, but it also means that everyone’s game has to change.&nbsp;</p>



<p>Thinking and acting like an open source project may be a good way for fully-distributed companies to evolve their talent acquisition game. Reflect on the Linux example in a post-Coronavirus talent market. When the most talented individuals can work for any company in the world, how will your company compete? How can your company distinguish itself amongst a much larger number of prospective employers?</p>



<blockquote><p>The downside for employers gaining access to the global talent pool is that they are also suddenly competing with every company in the world for talent.</p><a href="http://twitter.com/share?&amp;text=The%20downside%20for%20employers%20gaining%20access%20to%20the%20global%20talent%20pool%20is%20that%20they%20are%20also%20suddenly%20competing%20with%20every%20company%20in%20the%20world%20for%20talent.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=2hp" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>One approach is to become like an open source project, whose first organizing principle is attracting people who care deeply about the same thing. This of course requires knowing what that special thing (of singular and obsessive focus) is for your organization. I think most companies can find their unique <a href="https://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action" target="_blank" rel="noreferrer noopener">Why</a>, if they try. And I think it’s a good thing that prospective global employers should feel they have to produce a thoughtful and compelling expression of their purpose to compete for global talent.</p>



<p><strong>Creating Culture on Purpose</strong></p>



<p>Perhaps your company is bootstrapping its culture for the first time as a brand new fully-distributed startup. Or perhaps you’re an established organization now transitioning from an office-based culture. Either way, you may as a leader be wondering how to develop and nurture culture when everything is virtual and everyone’s remote.</p>



<p>Attracting people who share a common passion is potentially more than just a way to acquire talent. It can also be a terrific way to instantiate culture. But attracting talent like an open source project, however, is not just about having a clear and compelling purpose. It’s also about calling those talented people to come work on that purpose together in a <strong>particular</strong> way.</p>



<blockquote><p>“Culture is a pattern of basic assumptions — invented, discovered, or developed by a given group as it learns to cope with its problems of external adaptation and internal integration — that has worked well enough to be considered valid and, therefore, to be taught to new members as the correct way to perceive, think, and feel in relation to those problems.”</p><cite><em>Edgar Schein, <a rel="noreferrer noopener" href="https://agustinazubair.files.wordpress.com/2013/04/13-organizational_culture_and_leadership_3rd_edition-p-4581.pdf" target="_blank">Organizational Culture and Leadership</a></em></cite></blockquote>



<p>In other words, culture is inherently linked to a particular problem space, and isn’t directly about people or their attributes. Organizational culture is about how people decide to work together on a specific set of problems.</p>



<p>For many office-based companies, the “Our values” plaque that hangs on the wall is just a list of nice ideas. And though that list of values is intended to be the codification of their culture, those values may not relate in any useful way to the work to be done, and therefore probably don’t drive much useful behavior. The experience and the effects of culture, therefore, are organic, accidental, and overly-dependent on physical proximity.</p>



<blockquote><p>“Running a remote work environment effectively, requires amongst other things a deliberate approach to culture development. </p><p>Transitioning from an office to remote is not going to be easy for a lot of companies. The reason for this is leaders took the human proximity, camaraderie, informal comms &amp; ‘water cooler moments’ for granted. </p><p>The majority of CEOs who ran office-based businesses before the pandemic and didn’t invest in their culture unknowingly relied on their office space environment to hold their unwritten culture together.”</p><cite><em>Bretton Putter (via <a rel="noreferrer noopener" href="https://twitter.com/BrettonPutter/status/1263829426258817025" target="_blank">Twitter</a>)</em></cite></blockquote>



<p>As human beings we abhor vacuums, particularly social ones. This is the reason why, in the face of non-deliberate culture, we are able to “fill in” …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</a></em></p>]]>
            </description>
            <link>https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817799</guid>
            <pubDate>Mon, 13 Jul 2020 06:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with RF Using RTL-SDR]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817738">thread link</a>) | @ngutman
<br/>
July 12, 2020 | https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/ | <a href="https://web.archive.org/web/*/https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><h2 id="introduction">Introduction</h2>
<p>I was always interested in the RF world, the fact that we are surrounded by an infinite amount of invisible waves that carry information is intriguing. A lot has changed over the years, the technology advanced and today you can easily dive into the electromagnetic realm without fiddling with mountains of equipment and burning your pocket.</p>
<p>In this post we’ll explore using RTL-SDR to read live temperature and humidity stats from cheap 433.92Mhz modules, feeding them to InfluxDB using rtl_433, MQTT and Telegraf on a Raspberry Pi (but any Linux based device can work)</p>
<h2 id="hardware">Hardware</h2>
<p><strong><a href="https://www.amazon.com/gp/product/B011HVUEME/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B011HVUEME&amp;linkCode=as2&amp;tag=rsv0f-20&amp;linkId=b3bd3c48a6a7e921144609cb59359f0e" target="_blank" rel="noopener noreffer">RTL-SDR</a></strong></p>
<p>The definition of SDR is “Software Defined Radio”, it’s a radio-communication system where instead of using components that were traditionally implemented in hardware - software is used, allowing greater flexibility and reducing costs.</p>
<p>RTL-SDR is a high quality USB dongle (but relatively cheap at ~$25) that can be used to scan and receive radio signals from 500Khz (24Mhz for the device I used) up to 1.75Ghz. It was designed and built by the awesome dudes over at <a href="https://www.rtl-sdr.com/about-rtl-sdr/" target="_blank" rel="noopener noreffer">RTL-SDR.com</a> based on DVB-T TV tuner dongles. I ordered <a href="https://www.amazon.com/gp/product/B011HVUEME/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B011HVUEME&amp;linkCode=as2&amp;tag=rsv0f-20&amp;linkId=b3bd3c48a6a7e921144609cb59359f0e" target="_blank" rel="noopener noreffer">this</a> kit which included two modular dipole antennas.</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1_huc616545b0e7314066a2472f01ef5c4d9_1120817_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/1.jpeg" data-sub-html="<h2>images/rtl-sdr/1.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1_huc616545b0e7314066a2472f01ef5c4d9_1120817_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/1.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2_hu4415df00103010adacdf168ad8b6a4c9_1598270_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/2.jpeg" data-sub-html="<h2>images/rtl-sdr/2.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2_hu4415df00103010adacdf168ad8b6a4c9_1598270_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/2.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3_hu11fcd6c9e34e3b5d10fc09ac9d03a1d1_1389802_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/3.jpeg" data-sub-html="<h2>images/rtl-sdr/3.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3_hu11fcd6c9e34e3b5d10fc09ac9d03a1d1_1389802_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/3.jpeg">
        </a>
    
</p>

<p><strong><a href="https://www.aliexpress.com/item/33006820989.html?spm=a2g0s.9042311.0.0.1b754c4dDEUyyf" target="_blank" rel="noopener noreffer">RF Wireless Hygrometer + Thermometer</a></strong></p>
<p>Almost any RF based wireless thermometer / humidity sensor is probably readable by <code>rtl_433</code>. Since we’re talking about cheap hardware you can’t really get any assurances, checking the RF frequency is probably enough - if it says 433.92Mhz, you are 99% good. I’ve used <a href="https://www.aliexpress.com/item/33006820989.html?spm=a2g0s.9042311.0.0.1b754c4dDEUyyf" target="_blank" rel="noopener noreffer">this</a> as my indoor sensor and <a href="https://www.aliexpress.com/item/4000872896502.html?spm=a2g0s.9042311.0.0.419a4c4duApRRx" target="_blank" rel="noopener noreffer">this</a> as my outdoor, for monitoring my garden soil humidity level and outdoor temperature</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria_huc9d833e79d7dd2a83277d6401be6cf3b_1248250_200x0_resize_q75_box.jpeg" title="images/sensors/oria.jpeg" data-sub-html="<h2>images/sensors/oria.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria_huc9d833e79d7dd2a83277d6401be6cf3b_1248250_200x0_resize_q75_box.jpeg" alt="images/sensors/oria.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor_huc3d583f5dfc3f1b32518ba7724faca9b_1100341_200x0_resize_q75_box.jpeg" title="images/sensors/outdoor.jpeg" data-sub-html="<h2>images/sensors/outdoor.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor_huc3d583f5dfc3f1b32518ba7724faca9b_1100341_200x0_resize_q75_box.jpeg" alt="images/sensors/outdoor.jpeg">
        </a>
    
</p>

<p><strong><a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/" target="_blank" rel="noopener noreffer">Raspberry Pi</a></strong></p>
<p>I’ve used a RPi4 that I had lying around loaded with Raspbian Buster.</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi_hu779a99be76e550e5ba32d164eed4fdcf_1769197_400x0_resize_q75_box.jpeg" title="images/rpi.jpeg" data-sub-html="<h2>images/rpi.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi_hu779a99be76e550e5ba32d164eed4fdcf_1769197_400x0_resize_q75_box.jpeg" alt="images/rpi.jpeg">
        </a>
    
</p>

<h2 id="software">Software</h2>
<p><strong><a href="https://cubicsdr.com/" target="_blank" rel="noopener noreffer">CubicSDR for MacOS</a></strong></p>
<p>This is an awesome free open-source software for SDR. It wasn’t easy finding one for MacOS, most of the commonly-used projects are made for Linux and Windows. It’s not really required for decoding 433.92Mhz signals, but I wanted to get my hands dirty and look on live RF, it’s pretty neat (and of course to test the device is actually working!)</p>
<p><strong><a href="https://github.com/merbanan/rtl_433" target="_blank" rel="noopener noreffer">rtl_433</a></strong></p>
<p>An amazing project that can be used to decode a variety of RF-based devices on various frequencies (433.92 MHz, 868 MHz, 315 MHz, 345 MHz, and 915 MHz ISM bands). This is the software that does the heavy lifting.</p>
<p><strong><a href="https://github.com/eclipse/mosquitto" target="_blank" rel="noopener noreffer">Mosquitto</a></strong></p>
<p>Very simple MQTT server and client implementation, we’ll be using that as the output of rtl_433 and input of Telegraf to stream the metrics to a remote InfluxDB instance.</p>
<p><strong><a href="https://github.com/influxdata/telegraf" target="_blank" rel="noopener noreffer">Telegraf</a></strong></p>
<p>Agent for collecting and writing metrics. It will subscribe to our MQTT queue, parse and transmit the metrics to InfluxDB.</p>
<h2 id="getting-a-signal">Getting a signal</h2>
<h3 id="connecting-the-antennas">Connecting the antennas</h3>
<p>Let’s start by quickly testing our shiny RTL-SDR receiver, I’ve used the two short 5cm dipole telescopic antennas for this test, you should definitely read <a href="https://www.rtl-sdr.com/using-our-new-dipole-antenna-kit/" target="_blank" rel="noopener noreffer">this great guide</a> that the awesome dudes over at rtl-sdr.com wrote on using the provided antennas. The antenna used is critical for getting high-quality signal in some cases. For our radio FM test any antenna will probably suffice, but if you want to receive <a href="http://happysat.nl/Setup_Meteor/Setup.html" target="_blank" rel="noopener noreffer">weather satellite signal running on 137Mhz</a>, you’ll have to be more specific.</p>
<p>Hopefully you’ve ended up with something like this:</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna_hud9eea2dece6bfac112cbc216cd3fea82_1405534_400x0_resize_q75_box.jpeg" title="images/antenna.jpeg" data-sub-html="<h2>images/antenna.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna_hud9eea2dece6bfac112cbc216cd3fea82_1405534_400x0_resize_q75_box.jpeg" alt="images/antenna.jpeg">
        </a>
    
</p>

<h3 id="listening-to-radio">Listening to radio</h3>
<p>Now you can connect the dongle to your usb port, launch CubicSDR, choose “Generic RTL2832U OEM” and hit “Start”, you can ignore the extra settings you see on the right for now. You should see a pretty moving signal heatmap, you can change the center frequency by hovering over it and tapping space (the key), I chose a local FM radio station that is broadcasting on 88Mhz (FM).</p>
<p>Now your bandwidth setting should be set to 200Khz, you should get a nice signal and when you hover your mouse over it the band will “encapsulate” the signal, click and you should start hearing radio!</p>
<h3 id="checking-frequency-43392mhz">Checking Frequency 433.92Mhz</h3>
<p>Let’s get ready to use <code>rtl_433</code> by looking at the frequency and making sure there are devices there. Usually they will transmit information in 30 second bursts, you can change the center frequency to 433.92Mhz and check that you see data. Near the end of the video above you can see the signal bursts when I switch to 433.92Mhz</p>

<p>
  <iframe src="https://www.youtube.com/embed/fnKBjiwZoSw" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="decoding-on-the-rpi">Decoding on the RPi</h2>
<h3 id="installing-and-running-rtl_433-on-our-rpi">Installing and running rtl_433 on our RPi</h3>
<p>I’m assuming you have a working Raspberry Pi with SSH access running Raspbian. We’ll need to compile <a href="https://osmocom.org/projects/rtl-sdr/wiki/Rtl-sdr" target="_blank" rel="noopener noreffer">rtl-sdr</a> and <a href="https://github.com/merbanan/rtl_433" target="_blank" rel="noopener noreffer">rtl_433</a>:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="shell"><span># Install RTL-SDR</span>
mkdir ~/sdr
<span>cd</span> ~/sdr
sudo apt-get update
sudo apt-get install git git-core cmake libusb-1.0-0-dev build-essential
git clone git://git.osmocom.org/rtl-sdr.git
<span>cd</span> rtl-sdr/ <span>&amp;&amp;</span> mkdir build <span>&amp;&amp;</span> <span>cd</span> build/
cmake ../ -DINSTALL_UDEV_RULES<span>=</span>ON -DDETACH_KERNEL_DRIVER<span>=</span>ON
make
sudo make install
sudo ldconfig
</code></pre></td></tr></tbody></table>
</div>
</div><div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="shell"><span># Install rtl_433</span>
<span>cd</span> ~/sdr
git clone https://github.com/merbanan/rtl_433.git
<span>cd</span> rtl_433
mkdir build
<span>cd</span> build <span>&amp;&amp;</span> cmake ../
make
sudo make install
</code></pre></td></tr></tbody></table>
</div>
</div><p>You can now connect the RTL-SDR dongle to the Raspberry Pi and see if you can get some temperature and humidity data! (If you haven’t tested your sensors, now is the time to do it). Run <code>rtl_433</code> and you should get some data like in the video below</p>

<p>
  <iframe src="https://www.youtube.com/embed/2MiUqlUVpNk" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="installing-mosquitto-and-telegraf">Installing Mosquitto and Telegraf</h3>
<h4 id="mosquitto">Mosquitto</h4>
<p>So we’re getting live sensor data, that’s pretty awesome, let’s stream everything to InfluxDB. You can open a free <a href="https://cloud2.influxdata.com/signup" target="_blank" rel="noopener noreffer">Influx Cloud</a> account and we’ll configure Telegraf to stream information to it, after you open the account generate an API key for your bucket.</p>
<p>We’ll use Eclipse Mosquitto as the MQTT server, it’s a very lightweight implementation of MQTT server, providing simple pub/sub service which we’ll use.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="shell">sudo apt-get install mosquitto mosquitto-clients

<span># Enable Mosquitto service and check that it's running</span>
sudo systemctl <span>enable</span> mosquitto
sudo systemctl status mosquitto
</code></pre></td></tr></tbody></table>
</div>
</div><p>The logs are accessible over at <code>/var/log/mosquitto/mosquitto.log</code></p>
<h4 id="telegraf">Telegraf</h4>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="shell">curl -sL https://repos.influxdata.com/influxdb.key <span>|</span> sudo apt-key add -
<span>DISTRIB_ID</span><span>=</span><span>$(</span>lsb_release -c -s<span>)</span>
<span>echo</span> <span>"deb https://repos.influxdata.com/debian </span><span>${</span><span>DISTRIB_ID</span><span>}</span><span> stable"</span> <span>|</span> tee /etc/apt/sources.list.d/influxdb.list

sudo apt-get update
sudo apt-get install telegraf
</code></pre></td></tr></tbody></table>
</div>
</div><p>Before running Telegraf service let’s configure it, you can backup the existing config and paste the contents of my <code>/etc/telegraf/telegraf.conf</code> like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span></code></pre></td>
<td>
<pre><code data-lang="shell">sudo mv /etc/telegraf/telegraf.conf /etc/telegraf/telegraf.conf.bak
sudo bash -c <span>'cat &lt;&lt; EOF &gt; /etc/telegraf/telegraf.conf
</span><span>[agent]
</span><span>  interval = "10s"
</span><span>  round_interval = true
</span><span>  metric_batch_size = 1000
</span><span>  metric_buffer_limit = 10000
</span><span>  collection_jitter = "0s"
</span><span>  flush_interval = "10s"
</span><span>  flush_jitter = "0s"
</span><span>  precision = ""
</span><span>  debug = false
</span><span>  quiet = false
</span><span>  logfile = ""
</span><span>  hostname = ""
</span><span>  omit_hostname = false
</span><span>[[outputs.influxdb_v2]]	
</span><span>  urls = ["CHANGE THIS"]
</span><span>  token = "CHANGE THIS"
</span><span>  organization = "CHANGE THIS"
</span><span>  bucket = "CHANGE THIS"
</span><span>[[inputs.mqtt_consumer]]
</span><span>  servers = ["tcp://127.0.0.1:1883"]
</span><span>  qos = 0
</span><span>  connection_timeout = "30s"
</span><span>  topics = [ "rtl_433/#" ]
</span><span>  client_id = "telegraf"
</span><span>  persistent_session = false
</span><span>  data_format = "json"
</span><span>EOF'</span>

<span># You can now run telegraf manually to make sure the configuration is okay</span>
telegraf --config /etc/telegraf/telegraf.conf

<span># If all went well go ahead and restart the already running service</span>
sudo systemctl restart telegraf
</code></pre></td></tr></tbody></table>
</div>
</div><p>You’ll need to get your InfluxDB endpoint url, token, organization name and bucket from Influx cloud. The MQTT consumer settings specifies connecting to our MQTT server and listening to rtl_433/# topic, which basically says any topic with the prefix rtl_433/ will be sent to InfluxDB.</p>
<p>The expected data should be json (as specified by the <code>data_format</code> option)</p>
<h3 id="running-rtl_433">Running rtl_433</h3>
<p>Now for the last part, just run rtl_433 with mqtt output!, to make sure everything works you can first run a mosquitto subscription client and listen to incoming events by running <code>mosquitto_sub -t "rtl_433/#"</code>, afterwards launch it (I like using screen for that, see the next video):</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre><code data-lang="shell">rtl_433 -C si -F <span>"mqtt://localhost:1883,events=rtl_433[/model][/id]"</span>
<span># You will not get any data in the shell so if you think</span> 
<span># something is not working launch mosquitto_sub and make sure you are getting events</span>
</code></pre></td></tr></tbody></table>
</div>
</div>
<p>
  <iframe src="https://www.youtube.com/embed/lR6ynCU9QYs" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>If all went well data should be flowing to InfluxDB! hurrah!</p>
<h2 id="viewing-your-data">Viewing your data</h2>
<p>Using InfluxDB is outside the scope of this post but you should be able to get funky graphs like this one:</p>
<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" title="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" data-src="images/influx_dashboard.png" data-srcset="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png, images/influx_dashboard.png 1.5x, /posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 2x" data-sizes="auto" alt="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" srcset="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png, https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 1.5x, https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 2x">
    </a></p><h2 id="final-words">Final words</h2>
<p>Using RTL-SDR for decoding RF data is only the tip of the iceberg of what you can do with it, I highly suggest going to <a href="https://www.rtl-sdr.com/" target="_blank" rel="noopener noreffer">rtl-sdr.com</a> and checking some of their amazing tutorials - You can receive live weather satellite data, decode trunked radio systems and see the universe!</p>
</div></div>]]>
            </description>
            <link>https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817738</guid>
            <pubDate>Mon, 13 Jul 2020 06:46:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scheduling Your Life Like a Computer Engineer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817690">thread link</a>) | @mycpuorg
<br/>
July 12, 2020 | http://www.mycpu.org/scheduling/ | <a href="https://web.archive.org/web/*/http://www.mycpu.org/scheduling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>No matter which stage of career you are in, managing time and tasks become a
matter of utmost priority. Paul Graham’s essay on <a href="http://www.paulgraham.com/makersschedule.html">Maker’s
Schedule</a> explains a good way
to think about typical programmers vs typical managers schedule.</p>

<p>Beyond this, there is a more specific problem that most programmers battle with
intra-project prioritization. You break down a large project into sub tasks and
how would you schedule them? Especially if the project is for a client (assuming
it doesn’t entail a monolithic purpose to it, since this is extremely rare). For
example: it rarely is “Make me a new text editor”</p>

<p>With that said, if you looked into how Operating Systems handle this sort of a
thing we can see the various scheduling policies available. In Linux Kernel,
there are a ton of such policies:</p>
<ul>
  <li>Completely Fair Scheduler (CFS)</li>
  <li>FIFO or FCFS (First In First Out)</li>
  <li>Earliest Deadline First or Deadline Scheduling (EDF)</li>
</ul>

<h2 id="earliest-deadline-first-edf">Earliest Deadline First (EDF)</h2>
<p>EDF has produces an optimal scheme for minimizing the maximum lateness.</p>

<p><img src="http://www.mycpu.org/images/EDD.png" alt="">
<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>If your goal is to simply minimize the amount of lateness only, then this is
it. It is the optimal scheme. However, this has the downside of producing a lot
of tasks can be late albeit by a smaller margin. What if you want to optimize
for minimizing the number of tasks that are late?</p>

<h2 id="moores-algorithm">Moore’s Algorithm</h2>
<p>Moore’s Algorithm optimizes for the number of tasks that are late. It does so by
first ordering the tasks as per EDF scheme then trying to spot a largest job that
results in delaying a later task in the pipeline. It then moves this large job
to the end of the queue.</p>

<p><img src="http://www.mycpu.org/images/MooresAlgo.png" alt="">
<sup id="fnref:1:1"><a href="#fn:1">1</a></sup></p>

<p>You can break down a big problem into smaller tasks, by simply using the better
of these two schemes recursively you have solved your schedule. You have even
mathematically optimized your scheduling scheme. Another important, yet
underrated benefit is that you have drastically reduced your cognitive load on
the planning/scheduling aspect. Instead you get to look deeper into the design
and other technical parts of the project.</p>



      <hr>
      
    </div></div>]]>
            </description>
            <link>http://www.mycpu.org/scheduling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817690</guid>
            <pubDate>Mon, 13 Jul 2020 06:35:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817638">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-yui_3_17_2_1_1590947194898_9413"><div><p>Many of the common startup frameworks for tech companies do not apply as well to biotech. I’ve gone through the most common frameworks below, and how they differ for biotech companies. </p><p>I’m defining a tech startup here as a company whose product is largely based off of code. I am not including in my arbitrary categorization ‘deep tech’ (e.g., autonomous trucks, satellite startups, etc), which often face similar challenges as biotech companies. </p><p>Biotech here is a startup developing a drug. </p><p><em>These are generalizations, and many exceptions exist. </em></p><h2><strong>Risks and Finding Product Market Fit</strong></h2><p><span><strong>TECH</strong></span><strong>: Significant market and execution risks<br></strong><span><strong>BIOTECH</strong></span><strong>: Minimal market risk, a lot of technical risk</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_605840"><div><p>In tech, the company often uses a standard software stack and applies it in a novel way (a new product). The question is usually not ‘can this thing be built’, but ‘does anyone want this thing we made’?</p><p>In biotech, this is flipped. The market (a disease) is well established, but the ability to develop a product (a drug) that addresses this market is the core risk. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_607921"><p><span><strong>TECH</strong></span><strong>: Rolling derisking, early signs of product-market fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Derisking comes in bursts over years (biological milestones), early signals less reliable</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_617219"><div><p>In tech, you want the ‘up and to the right’ chart, showing exponential increase of some core metric of the company. Adoption, revenue, and other metrics derisk the company and give early signs of PMF. Early signs can be highly predictive of the company’s eventual success.</p><p>In biotech, derisking the company is predominantly tied to specific biological milestones. These come in bursts, with long periods of waiting in-between. Additionally, early milestones (such as the drug working in mice) aren’t 1-to-1 predictive of eventual success (the drug working in people).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_619233"><p><span><strong>TECH</strong></span><strong>: Iterate to product-market-fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Product (drug) finalized years before on market</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_631626"><div><p>In tech, the product is constant iterates and improves from customer feedback to find the exact product that people want. </p><p>In biotech, due to the extensive regulation, the final product (the drug) is finalized years before it first goes into people. If the drug doesn’t work in people, there is no iterating. If you want to modify the product, you need to restart the entire process over again. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_633705"><div><h2><strong>Founders &amp; Market</strong></h2><p><span><strong>TECH</strong></span><strong>: Founders often bring insight around a market<br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often bring insight around key biology</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_651094"><div><p>In tech, a prototypical founder often worked at the incumbent company or realized a market opportunity by being that market themself. The insight around the market opportunity itself is a core value of the company. </p><p>In biotech, the insight of the founder is around a new or better way to develop a drug for the disease, or a discovery that was made in the laboratory (and the relevant patents around it). </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_665620"><p><span><strong>TECH</strong></span><strong>: Founders often younger, ‘youth wunderkinds’ widely accepted <br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often older due to scientific training or are a professional CEO, rarer to have very young founders </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_678110"><div><p>In tech, the 18-year-old drop-out is lauded and mystified. If anything, older founders may be subconsciously discriminated against in favor for younger founders. </p><p>In biotech, the prototypical founder is older, often a career CEO or exec coming out of a Big Pharma company. At minimum, the founders almost always have significant scientific training - a PhD can take 6-8 years, and post-docs 2-3 years each. It is less common to see founders in their 20s and you almost never see ‘youth wunderkinds’. This is in part due to the conservatism of the industry and in part because extensive scientific training is generally necessary to have enough biological insight to correctly identify an opportunity. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_420694"><p><span><strong>TECH</strong></span><strong>: Can create a new market<br></strong><span><strong>BIOTECH</strong></span><strong>: Markets are diseases and therefore public domain</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_422265"><div><p>In tech, some of the most successful companies created or defined their market - a classic example being ride sharing. Once a new market is validated, other companies/copycats/fast-followers flow in. </p><p>In biotech, the market opportunities are diseases. New markets can somewhat be created (e.g., nootropics, elective medicines, Viagra) but generally speaking the markets are well known. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_423860"><p><span><strong>TECH</strong></span><strong>: Markets are winner-take-all<br></strong><span><strong>BIOTECH</strong></span><strong>: Many winners</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_458802"><div><p>In tech, investors often bet on a specific horse with the hope that the horse will win the race (and all the earnings). Bifurcated markets can be especially dangerous as companies compete on pricing and ‘race to the bottom’.</p><p>In biotech, the markets are <em>so </em>large, and the unmet need so high, that there can and often are many winners in one market (disease). The classic example here are statins, which in 2020 had over $1 trillion in sales across seven market approved statins, with the best-selling Lipitor having peak sales of $12B in the mid-2000s. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_456236"><div><h2><strong>Product Strategy</strong></h2><p><span><strong>TECH</strong></span><strong>: Often develop one product at a time, focus is key <br></strong><span><strong>BIOTECH</strong></span><strong>: Portfolio approach is encouraged to de-risk company, exception is one-asset, repurposing plays</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_482826"><div><p>Focus is crucial for any startup. However, in biotech the most successful and valuable companies often take a portfolio approach to product development - developing multiple products simultaneously. In tech, companies generally focus around one product or core offering, only differentiating once they have earned the right to do so by finding PMF with their first product.</p><p>A significant reason for this is to derisk the company against biological randomness. Instead, focus in a biotech company is usually around a core competency - e.g., a method of discovering drugs, or a way of delivering the drug - and then diversified within this core competency. For example, gene therapy company Spark Therapeutics had a core competency of AAV-based gene therapy (a virus loaded with DNA to treat a genetic disease) but leverages this competency simultaneously across multiple diseases. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_484564"><p><strong>﻿</strong><span><strong>TECH</strong></span><strong>: Outsourcing product development or engineering unadvisable<br></strong><span><strong>BIOTECH</strong></span><strong>: Common to use contractors for key experimental work</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_497310"><div><p>In tech, not having someone technical on the founding team is a classic ‘no no’. You generally should have the ability to build (and therefore rapidly iterate on and improve) your core product within the team. </p><p>In biotech, it is common and often preferred to use contract research organizations (CROs) for much of your experimental work. Some experiments can only be done by specialized CROs, and they often have advantages from scale that a startup cannot hope to replicate. Building and staffing a laboratory, including the multiple six-figure machines necessary, is impracticable and unnecessary for most companies. </p><p>Virtual biotechs - companies with distributed leadership and all research outsourced to CROs - have been popular long before it became the tech zeitgeist.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_499137"><p><span><strong>TECH</strong></span><strong>: Fast-followers and copycats a significant risk<br></strong><span><strong>BIOTECH</strong></span><strong>: Strong patent protection </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_570610"><div><p>In tech, being the first/best product to a new market is so important because once you validate a market’s need for a specific product, it is easy for others to copy and chip at your market share. This is especially common in traditional D2C brands, for example the many bed-in-a-box companies. </p><p>In biotech, patents are king. If you hold the key patent it is impossible for your drug to be copied. Once patents expire, however, there is a whole industry (generics) around copying drugs and selling them cheaper than the branded product. Because of the hundreds of millions it takes to develop a drug, it is almost impossible to commercialize a drug that is not able to be protected by patents, regardless of its efficacy. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_568710"><div><h2><strong>Raising, Spending, and Making Money</strong></h2><p><span><strong>TECH</strong></span><strong>: Primary burn usually people costs <br></strong><span><strong>BIOTECH</strong></span><strong>: Primary burn R&amp;D</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_725052"><p>Biotech companies’ biggest line item is undoubtedly R&amp;D spend - funding to do research experiments necessary to find and develop their drug. This is despite the average salary in biotech also often being higher than tech’s.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_722809"><p><span><strong>TECH</strong></span><strong>: Series Seed and A smaller, with larger subsequent rounds to scale and win market share<br></strong><span><strong>BIOTECH</strong></span><strong>: Capital needs front-loaded, Seeds can be the size of tech Series A’s</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_745080"><div><p>In tech, you can often show proof-of-concept or even begin selling your product with a small team and pre-seed capital. </p><p>Biotech Seeds can often look like tech Series As in magnitude. On the East Coast, the first rounds in biotech companies are more than often in the $10s of millions. This is because of the millions needed to hit biological milestones to push the company forward (and therefore qualify for the next stage of financing).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_742704"><p><span><strong>TECH</strong></span><strong>: Often command higher valuations early on <br></strong><span><strong>BIOTECH</strong></span><strong>: Often command lower valuations early on</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_803591"><div><p>Tech valuations usually optimize for selling 10% - 25% of the company in any one financing. </p><p>In biotech, valuations are historically significantly lower, with many East Coast deals selling 50%+ of the company in one financing. Such huge dilution is less common in West Coast biotech financings, but it is more common sell 33%+ of the company in one financing. Biotech founders also often have less negotiating power here because they have to raise large amounts to bring the company to the next stage. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_805993"><p><span><strong>TECH</strong></span><strong>: Business usually has significant revenue at exit <br></strong><span><strong>BIOTECH</strong></span><strong>: Unlikely to have revenue at exit</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_845025"><div><p>While the company may be far from profitable, tech companies almost always have significant revenue at exit (IPO or acquisition). </p><p>In biotech, companies almost never have revenue at exit. Instead, the value of the company is driven by the increasing probability that their drug will work (and therefore decreasing biological risk). The company is often sold or partnered years before the drug is commercialized.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_836878"><div><h2><strong>Team</strong></h2><p><span><strong>TECH</strong></span><strong>: Core team often younger, primed to take more equity over salary<br></strong><span><strong>BIOTECH</strong></span><strong>: Core team often older due to extensive scientific training, often more risk-adverse or otherwise unable to sacrifice heavily on salary </strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_824365"><div><p>In tech, there is a self-selecting group that aspire to work in or on a startup, and are primed to take the high equity with lower salary in the hope that they pick the company that will become a unicorn and make them rich, too. They are often younger …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.celinehh.com/tech-vs-biotech">https://www.celinehh.com/tech-vs-biotech</a></em></p>]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817638</guid>
            <pubDate>Mon, 13 Jul 2020 06:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Evolutionary Psychology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817470">thread link</a>) | @ghosthamlet
<br/>
July 12, 2020 | https://www.deepideas.net/introduction-to-evolutionary-psychology/ | <a href="https://web.archive.org/web/*/https://www.deepideas.net/introduction-to-evolutionary-psychology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				<div>
					


<div> <!-- start fusion sticky header wrapper -->
	<div>
		<div>
							<div data-margin-top="31px" data-margin-bottom="0px" data-margin-left="0px" data-margin-right="0px">
			<a href="https://www.deepideas.net/">

						<!-- standard logo -->
			<img src="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png" srcset="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png 1x" width="332" height="102" alt="deepideas.net Logo" data-retina_logo_url="">

			
					</a>
		
<div>
			<h3>
			a blog on cognitive science and artificial intelligence, dedicated to the deep thinkers of this world		</h3>
	</div>
</div>
								
			
					</div>
	</div>
	
</div> <!-- end fusion sticky header wrapper -->
				</div>
				
			</header>
						
			
		
				
			
			

						<main id="main">
				<div>

<section id="content">
			
	
					<article id="post-648">
						
														
						
																									<div>
				<p>Evolutionary psychology is an approach to understand human behavior that combines insights gained from evolutionary biology, the computational sciences and the study of ancestral living conditions. It has been put forward as an opposing view to what Tooby and Cosmides (1992) call the <em>Standard Social Science Model</em> (SSSM), which has dominated the social and behavioral sciences throughout most of the 20th century. According to the SSSM, the mental organization of adult human beings is not caused by human nature. Rather, humans acquire their mental organization almost entirely from their sociocultural and physical environment. Human beings, on this view, only have a minimal amount of innate impoverished drives (like hunger, thirst, sexual motivation, etc.) and, independently of these, a capacity to be socialized through learning.</p>
<p>A prominent argument given in favor of the SSSM is the fact that genetically determined behavior might be maladaptive due to changing environmental conditions, and therefore the mind evolved towards general-purpose and domain-general learning systems. On this view, the phenotype’s behavior is plastic and tailored toward maximizing individual fitness under changing environmental circumstances. The selective pressures of ancestral environments gave rise to this plasticity, but the concrete adaptive problems that have been faced in these environments play only a minor role in explaining the behavior of modern humans. This is the reason why many social scientists study human behavior in modern conditions more or less independently from their evolutionary history.</p>
<p>Evolutionary psychology, in contrast, holds that psychological mechanisms are evolved adaptations to ancestral adaptive problems. An analogy is drawn here between organs in the body and “cognitive programs” or “mental organs”: Analogous to how organs in the body evolved to solve a particular adaptive problem, e.g. digesting food, cognitive programs evolved to solve a particular adaptive information processing problem, e.g. predator/prey distinction, kin detection, language, etc.</p>
<p>In the following, we will break down the individual tenets of evolutionary psychology and review the arguments that are given in support of these tenets. Since not all tenets are shared by all evolutionary psychologists, we will focus here on the formulation given by Cosmides and Tooby (1987) and Tooby and Cosmides (2005). The tenets are not listed explicitly, but can be reconstructed implicitly from these texts. I will go through each tenet in turn and present a reconstruction of the arguments that motivate these tenets.</p>
<h3>Tenet 1: The brain evolved to be a computer that solves information processing problems.</h3>
<p>This tenet is motivated as follows: Environments pose adaptive information processing problems to organisms. Hence, the genes of organisms that successfully solve these information processing problems spread in the gene pool and such organisms are, by definition, computers.</p>
<p>This tenet, Tooby and Cosmides (2005, p. 31) argue, is shared by proponents of the SSSM. Even a domain-general learning mechanism would be an innate information processing mechanism that evolved at some point to solve adaptive problems. For example, operant conditioning presupposes an innate mechanism to alter the probability of behaviors based on their intrinsically reinforcing consequences (like food or pain). Similarly, classical conditioning presupposes innate unconditioned stimuli and a method to calculate contingencies. Consequently, Tooby and Cosmides (2005, p. 32) conclude that “learning is not an alternative explanation to the claim that natural selection shaped the behavior” and that “a behavior can be, at one and the same time, cultural, learned, and evolved”. This means that the commonly perceived controversy between innateness/evolvedness on the one hand and learnedness on the other is based on a false dichotomy. Rather, it is proposed, evolution created programs as learning mechanisms, and these mechanisms are a prerequisite for learning to be able to occur. The disagreement between the SSSM and evolutionary psychology, therefore, only regards the structure of the evolved learning mechanisms, not the question whether such learning mechanisms evolved at all.</p>
<p>When we accept the theory of evolution through natural selection, it arguably becomes theoretically impossible to deny that the brain evolved to be a computer that solves adaptive information processing problems – unless we claim that (A) evolution hasn’t found this path yet, (B) evolution cannot find this path in principle since it would lead through a fitness valley or (C) adaptive problems aren’t information processing problems and therefore a computer would not be the ideal solution. Discussing these possibilities would be beyond the scope of this introduction, so I am going to suppose (A), (B) and (C) to be false for the rest of this discussion. This leads us to accept this tenet.</p>
<h3>Tenet 2: The brain is not a “blank slate” domain-general fitness-maximizing machine.</h3>
<p>Cosmides and Tooby (1987, p. 47) and Tooby and Cosmides (2005, pp. 294- 299) argue that there is no domain-general success criterion that is correlated with fitness and, therefore, a domain-general mechanism would not be successful at actually maximizing fitness and could therefore not have evolved. This argument can be summarized as follows: If no domain-specific innate knowledge is present in the organism, then it can only acquire knowledge that can be inferred from perceptual inputs, without relying on innate perceptual heuristics. Similarly, it can learn behaviors only through trial and error learning, which would amount to generating random sequences of actions, observing the fitness outcome (e.g. the number of produced offspring) and then reinforcing or mitigating behaviors based on this outcome. Proposing instead that the mechanism could rely on perceptual cues like smell or taste as a proxy for expected fitness, they argue, amounts to “admitting domain-specific innate knowledge”.</p>
<p>However, when observing a certain positive or negative fitness outcome (like an increase or decrease in the produced offspring), it is virtually impossible to trace it back to the precise actions or sequences of actions that caused it, since virtually any action taken before in the organism’s life could have caused it. Furthermore, whether a sequence of action promotes fitness is highly context-sensitive. Thus, due to the resulting combinatorial explosion, behaviors cannot reliably be reinforced or mitigated and behavior stays more or less random. Therefore, an organism with adequate innate domain-specific knowledge, perceptual heuristics and perception-action patterns would have a fitness advantage over an organism that only has a domain-general fitness-maximizing mechanism, consequently triggering selection for organisms with these traits.</p>
<h3>Tenet 3:&nbsp;The brain executes innate, domain-specific, functionally isolable cognitive programs that generate particular behaviors in response to particular external or internal informational inputs. Most or even all of these programs evolved as a response to a particular adaptive information processing problem.</h3>
<p>It should be noted that it is not claimed that all cognitive programs generate behavior deterministically based on the current perceptual input. Rather, some of these programs exhibit what is commonly called <em>experience-dependent plasticity</em>: They are able to learn based on the input they receive throughout the organism’s development (Cosmides and Tooby, 1987, p. 284). For example, the language program learns to acquire the language of a person’s surrounding community. The programs, therefore, did not evolve to produce a certain kind of behavior, but they evolved to produce a mapping from current inputs and the sequence of inputs they received throughout development to behaviors. Different programs have different degrees of experience-dependent plasticity, depending on the fitness advantage that plasticity would provide over genetic determinism in the program’s adaptive domain.</p>
<p>In a similar fashion, programs are <em>experience-expectant</em>: They evolved to be able to develop only if they receive certain informational inputs at critical periods throughout development (Tooby and Cosmides, 2005, p. 34-35). This entails that a program’s innateness does not mean that it is present at birth – much like teeth are innate but not present at birth. Rather, a cognitive program can develop at any point in an organism’s life, depending on whether it is relevant at that point in life and whether the developmentally relevant informational inputs have been received. Tooby and Cosmides (2005, p. 35) stress that this developmentally relevant information consists not only of contingencies in physical laws and the behavior of other organisms, but also of the physical and cultural environment. The latter comprise a second inheritance system that co-evolves with the genes, and changes in these environments can lead to significant alterations in the operation of the cognitive programs, or even a failure of certain cognitive programs to develop.</p>
<p>It should also be noted that it is not claimed that the cognitive programs can&nbsp;only generate behavior according to their original adaptive function. For example, the language program, which arose as an adaptation for spoken language, can learn to acquire reading and writing (Tooby and Cosmides, 2005, p. 26). The ability to learn reading and writing is not an adaptation but a by-product of the adaptation for spoken language.</p>
<p>However, it is claimed that the …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepideas.net/introduction-to-evolutionary-psychology/">https://www.deepideas.net/introduction-to-evolutionary-psychology/</a></em></p>]]>
            </description>
            <link>https://www.deepideas.net/introduction-to-evolutionary-psychology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817470</guid>
            <pubDate>Mon, 13 Jul 2020 05:32:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Is Surprisingly Good as a Server Language]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 218 (<a href="https://news.ycombinator.com/item?id=23817464">thread link</a>) | @signa11
<br/>
July 12, 2020 | https://stu2b50.dev/posts/rust-is-surpris76171 | <a href="https://web.archive.org/web/*/https://stu2b50.dev/posts/rust-is-surpris76171">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
      <div id="main">
        

    

    <div>
        
<p>At some point, I got tired of my old static site generator setup for my blogs and other pages. It was annoying to ssh every time I wanted to make a modification, it was annoying to sftp or sshfs all my images, and so forth. And god forbid, if you ever wanted someone else to write something or make an edit, let me tell you, most people are not particularly happy when you tell him "hey, I'll make you a user on my server, give me your public key so you can ssh in".</p>
<p>I wanted something with a <em>little</em> more dynamism. </p>
<p>So that was the project: a small scope blog, where a few, already <em>trusted</em> users can make, edit, and post new pages in markdown (with a nice markdown editor courtesy of <a href="https://simplemde.com/">SimpleMDE</a>). Additionally, I want a built in jank verison of imgur so I can satisfy my need to be self sufficient without going crazy.</p>
<p>So while I could whip something up in an afternoon with Django, I could also experiment with other languages. The project is simple enough that I can't imagine being too limited by any language's ecosystem. And I've been itching to write something substansive in Rust...</p>
<h3>Which framework?</h3>
<p>The biggest framework is probably <code>actix-web</code>. But</p>
<ol>
<li>When I was scoping out my options months ago, actix-web's maintainer quit with a bunch of drama</li>
<li>At least from what I could tell reading the docs, it seems more suited to APIs rather than servers serving templated HTML</li>
<li>With the above, I wanted this to be a weekend project, not a weekly project, so the more batteries included the better</li>
<li>I really don't want to figure out which async library is considered better. And note that with each async library, comes its own ecosystem of libraries, which only work with that async library, so it's a pretty hard decision to reverse after you made it.</li>
</ol>
<p>So Rocket it is. </p>

<p>Something I didn't realize until I started scoping out this project is that on servers... the memory model is actually pretty simple! </p>
<p>Much of your state is just handled by your database. I <em>never</em> actually fought with the borrow checker. I never had to. For the most part, everything had exactly one owner, and exactly one lifetime: the function that's handling the request. </p>
<p>Rocket, too, has a surprising amount of "magic":</p>
<pre><code>#[get("/posts/&lt;slug&gt;/"]
pub fn post_view(slug: String) -&gt; Option&lt;Template&gt; {
    ...
		
    Some(Template::render("/posts/post", hashmap! { "post" =&gt; post}))
}
</code></pre>
<p>As opposed to Flask's</p>
<pre><code>@app.route("/posts/&lt;string:slug&gt;")
def post_view(slug):
    ...
		
    return render_template("posts/post.html", post=post)
</code></pre>
<p>Rust's macro system has really impressed me so far. Not only is there a shocking amount of "just works", but it's all statically typed and compiled.</p>
<p>The closest analogue to Rocket is flask + all the flask adjacent libraries (SQLAlchemy-flask, etc). Rocket, through the power of 3rd party integrations, comes with two template engines (handlebars, and Tera, which is basically Jinja2), database pooling support for quite a few ORMs/DB drivers, and more.</p>
<p>It's still at the point where you have to roll your own auth, though.</p>
<p>While I've heard comparisons to Django/Rails, it doesn't really seem like they're going that direction. Django/Rails purposefully put you, the developer, on the metaphorical rails, dictating best practices from everything from where the files go, to how you update your models and views. Rocket doesn't do that, and I'm not sure it should ever.</p>
<p>I also had, for the most part, the experience that "if it compiles, it works". Most of my runtime errors were in the templates, which incidentally is the only thing that's not statically typed. </p>
<p>I guess that's really what surprised me. For a lot of it, "it just works"! There's not a lot of boilerplate syntax, type inference keeps your functions clean, and I didn't write a <em>single</em> lifetime annotation at any point. My rust server really didn't look that different from my flask server, or my Django server, and honestly it looks cleaner than my Java server. All with no garbage collector or runtime.</p>

<p>Next, I'll talk about Diesel, which as far as I can see, is the most mature ORM available. While I do have my gripes, it's not really anything "objectively" bad. I suppose it's more on tradeoffs, and Diesel chooses to go light on the magic. </p>
<p>For one, it's annoying to make two structs for each table. You need one to represent the table, and one to insert with (with any autogenerated columns like the primary key removed). For instance, I have</p>
<pre><code>#[derive(Identifiable, Queryable, Associations, PartialEq, Debug, Serialize)]
#[belongs_to(BlogPosts, foreign_key="post_id")]
#[table_name = "tags"]
pub struct Tag {
    id: i32,
    tag_name: String,
    post_id: i32,
}

#[derive(Insertable)]
#[table_name = "tags"]
pub struct InsertTag {
    tag_name: String,
    post_id: i32
}
</code></pre>
<p>Additionally, while in some ORMs you write your table models, and the ORM generates your SQL migrations, in Diesel, you write your SQL migrations by hand, and the ORM generates a <code>schema.rs</code> file that contains the mappings. I actually don't mind that one too much.</p>
<p>Diesel also only supports parent-child relationships, and you have to be quite explicit. There's no magic field on your parent, that magically gives you a list of its children. No, you just have to write the query and call it. In some sense it's more like using a slightly fancier query builder.</p>
<p>Dipping down from that level of magic, it's not really a <em>bad</em> thing per se. By being explicit, you prevent users from believing too much in that magic, and shooting themselves in the foot, like N+1 selects. </p>
<p>But I'm not going to say it didn't slow me down quite a bit, either. And to be honest, writing joins was a humongous pain in the ass. Maybe that's how it should be, but maybe that also caused a generation of NoSQL databases. 🤷</p>

<p>Here's how you upload an image in flask</p>
<pre><code>@app.route('/images/upload')
def upload_file():
	files = request.files['file']
	if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
</code></pre>
<p>Here's the "simpler" example, while using a <em>third party library in addition</em> from abonader</p>
<p><a href="https://github.com/abonander/multipart/blob/master/examples/rocket.rs"><strong>See the whole thing here</strong></a></p>
<pre><code>#[post("/upload", data = "&lt;data&gt;")]
// signature requires the request to have a `Content-Type`
fn multipart_upload(cont_type: &amp;ContentType, data: Data) -&gt; Result&lt;Stream&lt;Cursor&lt;Vec&lt;u8&gt;&gt;&gt;, Custom&lt;String&gt;&gt; {
    // this and the next check can be implemented as a request guard but it seems like just
    // more boilerplate than necessary
    if !cont_type.is_form_data() {
        return Err(Custom(
            Status::BadRequest,
            "Content-Type not multipart/form-data".into()
        ));
    }

    let (_, boundary) = cont_type.params().find(|&amp;(k, _)| k == "boundary").ok_or_else(
            || Custom(
                Status::BadRequest,
                "`Content-Type: multipart/form-data` boundary param not provided".into()
            )
        )?;

    match process_upload(boundary, data) {
        Ok(resp) =&gt; Ok(Stream::from(Cursor::new(resp))),
        Err(err) =&gt; Err(Custom(Status::InternalServerError, err.to_string()))
    }
}

fn process_upload(boundary: &amp;str, data: Data) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {
    let mut out = Vec::new();

    // saves all fields, any field longer than 10kB goes to a temporary directory
    // Entries could implement FromData though that would give zero control over
    // how the files are saved; Multipart would be a good impl candidate though
    match Multipart::with_body(data.open(), boundary).save().temp() {
        Full(entries) =&gt; process_entries(entries, &amp;mut out)?,
        Partial(partial, reason) =&gt; {
            writeln!(out, "Request partially processed: {:?}", reason)?;
            if let Some(field) = partial.partial {
                writeln!(out, "Stopped on field: {:?}", field.source.headers)?;
            }

            process_entries(partial.entries, &amp;mut out)?
        },
        Error(e) =&gt; return Err(e),
    }

    Ok(out)
}
</code></pre>
<p>Now, to be fair, Rocket is in version 0.4.5. From <a href="https://github.com/SergioBenitez/Rocket/issues/106"><strong>this github issue</strong></a>, multipart form support is coming in 0.5.0. But it doesn't change the fact that right now, the current libraries are somewhat immature still. They lack some of the edge features, especially for more traditional web servers that serve templated HTML, as opposed to pure API servers, or an SPA. </p>
<hr>
<p>Rust's errors are quite good, usually. But that's before you get into, well, libraries that try to do a bit more. I ran into some... interesting error messages, mostly from macros in Rocket and Diesel. Take a look at this one, for instance.</p>
<pre><code>the trait bound `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32): diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not satisfied

the trait `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not implemented for `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32)`

help: the following implementations were found:
        &lt;(A, B, C, D, E, F, G, H, I) as diesel::Queryable&lt;(SA, SB, SC, SD, SE, SF, SG, SH, SI), __DB&gt;&gt;
note: required because of the requirements on the impl of `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stu2b50.dev/posts/rust-is-surpris76171">https://stu2b50.dev/posts/rust-is-surpris76171</a></em></p>]]>
            </description>
            <link>https://stu2b50.dev/posts/rust-is-surpris76171</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817464</guid>
            <pubDate>Mon, 13 Jul 2020 05:31:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gödel’s Incompleteness Theorem and Its Implications for Artificial Intelligence]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817462">thread link</a>) | @ghosthamlet
<br/>
July 12, 2020 | https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/ | <a href="https://web.archive.org/web/*/https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				<div>
					


<div> <!-- start fusion sticky header wrapper -->
	<div>
		<div>
							<div data-margin-top="31px" data-margin-bottom="0px" data-margin-left="0px" data-margin-right="0px">
			<a href="https://www.deepideas.net/">

						<!-- standard logo -->
			<img src="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png" srcset="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png 1x" width="332" height="102" alt="deepideas.net Logo" data-retina_logo_url="">

			
					</a>
		
<div>
			<h3>
			a blog on cognitive science and artificial intelligence, dedicated to the deep thinkers of this world		</h3>
	</div>
</div>
								
			
					</div>
	</div>
	
</div> <!-- end fusion sticky header wrapper -->
				</div>
				
			</header>
						
			
		
				
			
			

						<main id="main">
				<div>

<section id="content">
			
	
					<article id="post-71">
						
														
						
																									<div>
				<h2>Introduction</h2>
<p>This text gives an overview of Gödel’s Incompleteness Theorem and its implications for artificial intelligence. Specifically, we deal with the question whether Gödel’s Incompleteness Theorem shows that human intelligence could not be recreated by a traditional computer.</p>
<div class="page" title="Page 1">
<div>
<div>
<p>Sections 2 and 3 feature an introduction to axiomatic systems, including a brief description of their historical development and thus the background of Gödel’s Theorem. These sections provide the basic knowledge required to fully understand Gödel’s Theorem and its significance for the history of mathematics – a necessary condition for understanding the arguments to follow. Section 4 features a thorough description of Gödel’s Theorem and outlines the basic idea of its proof. Sections 5 and 6 deal with arguments advocating the view that intelligence has a non-algorithmic component on the grounds of Gödel’s Theorem. In addition to a detailed account of the arguments, these sections also feature a selection of prominent objections to these arguments raised by other authors. The last section comprises a discussion of the arguments and my own objections.</p>
<h2>The Formalization of Mathematics</h2>
<div class="page" title="Page 1">
<div>
<div>
<p>At the beginning of the 20th century, the mathematical community suffered from a crisis regarding the very foundations of mathematics, triggered by the discovery of various paradoxes that called into question the reliability of mathematical intuition and the notion of proof. At that time, some fields of mathematics were grounded on a rigorous formal basis, called an <strong>axiomatic system</strong> (or interchangeably formal system), whereas other fields relied on a certain degree of intuitive insight.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>In a formal way, an axiomatic system is a set of propositions, expressed in a formal language, called axioms. These axioms represent statements that are assumed to be true without proof. The set of axioms is equipped with a set of inference rules which can be used to derive other propositions, called theorems, by applying them to the axioms. Applying the rules of inference boils down to replacing expressions by certain other expressions according to precise syntactical rules. The axioms and the set of inference rules are ideally chosen in such a way that they are intuitively evident. This way, the truth of a complex, non-obvious statement can be accepted by accepting the truth of the axioms and sequentially applying the inference rules until the complex statement in question is deduced.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>An early, prominent example of such an axiomatic system is the Euclidean geometry described by the ancient Greek philosopher Euclid in c. 300 BC (an English translation can be found in [Euc02]). It consists of 5 axioms making trivial statements about points, lines and circles (e.g. that any two points could be connected by a line). From these axioms, Euclid derived 48 non-trivial geometric propositions solely by means of logical inference and without making use of informal geometric intuition or perception.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>Up until modern times, geometry was the only branch of mathematics that was predicated on such a sound axiomatic basis, whereas research and applications in other branches were carried out without a rigid formal notion about which types of inference were allowed and which statements were assumed to be intuitively evident. This was due to the fact that, for most practical purposes, mathematicians saw no need for doing so. However, this changed with the discovery of various paradoxes around the turn of the 20th century. In 1901, the British mathematician Bertrand Russell put forward what later came to be known as <strong>Russell’s paradox</strong> (cf. [Gri04]). This paradox showed an inherent flaw in the informal set theory proposed by German mathematician Georg Cantor, according to which every definable collection of distinct elements is a set. Russell defined the set R of all sets that do not contain themselves, symbolically:</p>
<p>$$\{x \; \mid \; x \not\in x\}$$</p>
<div class="page" title="Page 2">
<div>
<div>
<p>According to Cantor, R is a valid set. The paradox arises when one asks the question whether R contains itself. If R contains itself, then by definition it does not contain itself. If, on the other hand, it does not contain itself then it contains itself by definition. Symbolically:</p>
<p>$$R \in R \; \iff R \not\in R$$</p>
<div class="page" title="Page 3">
<div>
<div>
<p>Therefore, the question whether R contains itself has no well-defined answer. This example shows that the notion of a set defined by Cantor is flawed, even though it seems to be intuitively reasonable. Examples like this lead many mathematicians to recognize that intuition is not a safe guide and that there was a need to supply all branches of mathematics with an axiomatic system that would be sufficient to formally derive all true propositions, a standpoint later termed <strong>formalism</strong> (cf. [NN01] p. 3). Over time, more and more branches, both new and old, were equipped with sets of axioms (e.g. the Zermelo-Fraenkel set theory, cf. [Fra25]).</p>
<div class="page" title="Page 3">
<div>
<div>
<p>It is worth noting that axiomatic systems and formal proofs do not require an intuitive understanding of the entities described or the nature of the proven statements. Consider the following example:</p>
<div class="page" title="Page 3">
<div>
<div>
<blockquote><p><strong>Axiomatic system 1.<br>
</strong>1. Every member of P is contained in exactly two members of L.<br>
2. Every member of L contains exactly two members of P.<br>
3. Every two members of L share exactly one member of P.</p></blockquote>
<div class="page" title="Page 3">
<div>
<div>
<p>This axiomatic system makes statements about some abstract sets L and P , and even though we can understand the axioms per se, we do not associate any meaning with the symbols and we do not have any intuition about the overall structure of L and P. Still, we can deduce theorems from these axioms. For example, it can be shown that every three members of L contain exactly three members of P. Even though the axioms were given informally, they can be translated into second-order logic and the proof for the theorem can be carried out using rules that just replace certain sequences of symbols with other symbols. This way, the proof could be carried out by a computer simply by iteratively applying symbol replacement rules on meaningless sequences of symbols until the theorem is obtained. It is then clear that the theorem follows from the axioms without any intuition as to what the theorem or the axioms actually represent.</p>
<h2>Hilbert’s Program</h2>
<div class="page" title="Page 3">
<div>
<div>
<p>A prominent representative of the formalist standpoint was David Hilbert, who initiated what was later termed <strong>Hilbert’s Program</strong> (cf. [Zac15]). Hilbert advocated the view that all fields of mathematics should be grounded on an axiomatic basis. Furthermore he demanded that every such system should be proven to be consistent, which means that it is impossible to deduce two contradictory theorems from the axioms.</p>
<div class="page" title="Page 3">
<div>
<div>
<p>Proving the inconsistency of an axiomatic system can be done by deducing a contradiction. The question that Hilbert wanted to address, however, was how to prove the consistency, i.e. how to prove the impossibility to deduce a contradiction. One way to do so is to find an interpretation of the axioms, such that they form true statements about some part of reality or some abstract concept of our intuition. A possible model for the axiomatic system 1 is given in the following image:</p>
<p><img data-attachment-id="102" data-permalink="https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/triangle/" data-orig-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1270%2C930&amp;ssl=1" data-orig-size="1270,930" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="triangle" data-image-description="" data-medium-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=300%2C220&amp;ssl=1" data-large-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1024%2C750&amp;ssl=1" src="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle-300x220.png?resize=300%2C220" alt="" width="300" height="220" srcset="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=200%2C146&amp;ssl=1 200w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=300%2C220&amp;ssl=1 300w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=400%2C293&amp;ssl=1 400w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=600%2C439&amp;ssl=1 600w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=768%2C562&amp;ssl=1 768w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=800%2C586&amp;ssl=1 800w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=1024%2C750&amp;ssl=1 1024w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=1200%2C879&amp;ssl=1 1200w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1270%2C930&amp;ssl=1 1270w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></p>
<p>When we interpret the set P as the corners of a triangle and the set L as its edges, then the axioms are invested with meaning and we can verify beyond doubt that all axioms represent true statements about the model by verifying them for each individual element. This can be done easily since there are only finitely many elements. This proves the consistency of the system, because no contradiction can be deduced from true premises.</p>
<div class="page" title="Page 4">
<div>
<div>
<p>However, there are axiomatic systems for which the model-based approach to proving their consistency is open to dispute. If, for example, the axioms require the model to contain an infinite number of elements, then it is impossible to verify the truth of the axioms beyond doubt, since the truth can no longer be verified for each individual element. Moreover, the model-based approach actually only reduces the consistency of one system to the consistency of another system. As regards the triangle example, we established the consistency of the axioms by verifying them for the triangle, but in doing so we implicitly assumed the consistency of geometry. Therefore, we have only shown that if geometry is consistent, then our axiomatic system is also consistent; we have given what is called a <strong>relative proof of consistency</strong>.</p>
<div class="page" title="Page 4">
<div>
<div>
<p>Hilbert urged to find <strong>absolute proofs of consistency</strong>, i.e. proofs that establish the consistency of an axiomatic system without presupposing the consistency of another axiomatic system. Absolute proofs of consistency use structural properties of the axioms and inference rules in order to show that no contradictions can be derived; they are not proofs within the formal axiomatic system itself, but rather proofs about the system. They are, so to speak, proofs in some meta-system. To better understand the concept of a meta-system, consider the statement ”’$p \vee p \rightarrow p$’ is a tautology”. This is not a statement within propositional logic, but a statement in some meta-system <em>about</em> propositional logic, and it can be proved within that meta-system.</p>
<div class="page" title="Page 5">
<div>
<div>
<p>Absolute proofs of consistency have successfully been established for some axiomatic systems, e.g. propositional logic (cf. [NN01] p. 45). This lead Hilbert to believe that such a proof could be found for any consistent axiomatic system, which is where Gödel’s Incompleteness Theorem comes into play: amongst other things, it shows that this is impossible for most of the axiomatic systems.</p>
<h2>Gödel’s Incompleteness …</h2></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/">https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/</a></em></p>]]>
            </description>
            <link>https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817462</guid>
            <pubDate>Mon, 13 Jul 2020 05:31:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The three levels of Hindu philosophy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817439">thread link</a>) | @paraschopra
<br/>
July 12, 2020 | https://invertedpassion.com/three-levels-of-hindu-philosophy/ | <a href="https://web.archive.org/web/*/https://invertedpassion.com/three-levels-of-hindu-philosophy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-511">
		<!-- .entry-header -->
	<div>
		
		
<p><strong>1/</strong> The first level related to the metaphysical and spiritual domain.</p>



<p>It says that Brahman is all that exists and our material world (Maya) comes from ignorance.</p>



<p>The Brahman is not a God. It is beyond any quality – it isn’t intelligent, good or bad. It just is.</p>



<p><strong>2/</strong> It also suggests that if we strip away all ignorance, we will discover that the self – the atman – is one and the same thing as the Brahman.</p>



<p>At its core, this level denies the duality of subject and object and says they both are the same.</p>



<p><strong>3/</strong> The second level has more religious connotations because, like all religions, its purpose is the stabilization of society.</p>



<p>The concept of Karma and Dharma ensures that society has net positive interactions. And the rituals and idol worship ensures everyone knows who is in the camp.</p>



<p><strong>4/</strong> This level ensures an ethical code exists and that it’s clear who all share that same ethical code.</p>



<p>The symbols – the idols, the chants, the rituals – take a spiritual dimension on their own, but these are subservient to the belief in one Brahman – the essence of the world.</p>



<p><strong>5/</strong> The third level is psychological – to give guidance to an individual on how to live his/her life.</p>



<p>The suggestion in <a href="https://invertedpassion.com/what-gita-teaches-us-and-what-it-doesnt/">Gita</a> that one must do work without an expectation of reward is towards minimizing psychological anguish.</p>



<p><strong>6/</strong> To reiterate, the three levels of Hindu philosophy are:</p>



<ul><li>METAPHYSICAL: <a href="https://en.wikipedia.org/wiki/Mah%C4%81v%C4%81kyas">Tat tvam asi.</a> You’re it [it = Brahman]</li><li>SOCIETAL: Rebirth, Karma, Dharma, and Rituals</li><li>PSYCHOLOGICAL: Expect no reward</li></ul>



<p><strong>7/</strong> Of course, everyone has their interpretation. Unlike Judeo-Christian religions, there are no definitive books on Hindusim.</p>



<p>Rather than a bug, I think it’s a feature.</p>



<p>It ceases to be a philosophy if you can’t interpret it on your own.</p>



<p><strong>8/</strong> There are some beautiful ideas in Hinduism, though I’m not sure I agree with all of them.</p>



<p>If you have your favorite ideas, let me know. I love diving deep into Indian philosophy.</p>



<p><em>This essay is a lightly-edited version of a <a href="https://twitter.com/paraschopra/status/1104658952061681665">Twitter thread I posted</a>.</em></p>



<p>Someone made an image out of the three levels:</p>



<figure><img src="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg" alt="" srcset="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg 756w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-221x300.jpg 221w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-768x1041.jpg 768w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-1134x1536.jpg 1134w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq.jpg 1338w" sizes="(max-width: 756px) 100vw, 756px"><figcaption>Made by <a href="https://twitter.com/nisacharan">@nishacharan</a></figcaption></figure>



<p><span><strong>Have an opinion on this essay?</strong></span> You can send your feedback on <a href="https://invertedpassion.com/cdn-cgi/l/email-protection#146475667567252d2c233f7d64727171707675777f547379757d783a777b79">email</a> to me.


</p>



			</div><!-- .entry-content -->
						<!-- .entry-footer -->
		</article></div>]]>
            </description>
            <link>https://invertedpassion.com/three-levels-of-hindu-philosophy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817439</guid>
            <pubDate>Mon, 13 Jul 2020 05:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Butt Pomodoro – A butt triggered pomodoro timer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817401">thread link</a>) | @Abishek_Muthian
<br/>
July 12, 2020 | https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A need gap of <a href="https://needgap.com/problems/130-remind-me-to-take-break-when-working-from-home-wfh-activity" target="_blank">Remind me to take break when working from home</a> was recently posted. Forgetting to take regular breaks when immersed with work in front of a computer is a common problem, especially when working from home.</p><p>On the flip side, <a href="https://needgap.com/problems/30-getting-things-done-at-individual-level-productivity-taskmanagement" target="_blank">getting distracted from completing a task</a> is also a common problem.</p><h3 id="why-pomodoro">Why pomodoro?</h3><p><a href="https://en.wikipedia.org/wiki/Pomodoro_Technique" target="_blank">Pomodoro technique</a> is to work in 25 minutes intervals called pomodoro, taking 5 minutes break every pomodoro and taking a 30 minutes break after 4 pomodoros.</p><p>This helps in mitigating <a href="https://needgap.com/problems/93-focus-drift-cognitivescience-neuroscience" target="_blank">focus drift</a>, burn outs and enables us to complete our tasks.</p><h3 id="why-butt-triggered">Why butt triggered?</h3><p>There are no dearth of pomodoro timer based apps in the market, but they require manual trigger of the timer each time we are about to start a task, this is a huge overhead as stated by in the first problem statement.</p><p>I personally feel that the activity of constantly interacting with the pomodoro timer is counter-intuitive for productivity and so to address that it needs to be triggered seamlessly without any user action.</p><p>Most of us work with the computer while seated on a chair, I figured that triggering the pomodoro timer with a sensor under the seat would fulfil my goals.</p><h3 id="design-goals">Design goals</h3><h4 id="simple">Simple</h4><p>The solution should be simple enough to be easily reproducible by many, even by those without the technical know-how of the solution.</p><h4 id="portable">Portable</h4><p>Setup should be easily transportable to any chair, be it at home or office. Hence, facial recognition with machine learning based solution is not being considered.</p><h4 id="inexpensive">Inexpensive</h4><p>Components should be easily available and inexpensive.</p><h3 id="design-choices">Design choices</h3><h4 id="sensor">Sensor</h4><p>Sensor is needed to trigger the timer when I sit on the chair, basically to serve as a switch.</p><p>I started with a pressure sensor made with Velostat fabric, since its light weight and could seamlessly fit between the seat cushion and the chair. But the resistance varied too much in my test to serve as a reliable switch and I didn’t like the possibility conductive threads setting my ass on fire if they get shorted.</p><p><amp-accordion id="velostat-accordian" disable-session-states=""><section><h5>Click to see Velostat with Conductive Threads</h5><amp-img alt="Velostat with conductive thread" src="/images/Velostat_Conductive_Thread.jpg" width="3915" height="3813" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="trigger">Trigger</h4><p>Then I experimented with a standard 12mm momentary button switch on a 170 holes mini breadboard and it served the purpose well. Depending upon your chair, seat cushion and your weight; you might have to choose a button which works well for you.</p><p><amp-accordion id="button-accordian" disable-session-states=""><section><h5>Click to see Momentary Button</h5><amp-img alt="Button" src="/images/Momentary_Button.jpg" width="2863" height="3451" layout="responsive"></amp-img></section><section><h5>Click to see Mini Breadboard</h5><amp-img alt="Button" src="/images/Mini_Breadboard.jpg" width="1670" height="1365" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="microcontroller">Microcontroller</h4><p>Microcontroller is needed process the input signal from the button, compute the timers and send message to the notifications.</p><p>ESP8266 based NodeMCU is being used the microcontroller for this as it has WiFi for communication.</p><p><amp-accordion id="nodemcu-accordian" disable-session-states=""><section><h5>Click to see NodeMCU</h5><amp-img alt="NodeMCU" src="/images/ESP8266_NodeMCU.jpg" width="962" height="1451" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="power">Power</h4><p>I’m supplying 5V power over microUSB with 18650 power-bank to the NodeMCU.</p><p><amp-accordion id="powerbank-accordian" disable-session-states=""><section><h5>Click to see 18650 Power-Bank</h5><amp-img alt="18650 Power-Bank" src="/images/18650_Power-Bank.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><p><em>Note: The reliability of this power-bank is questionable as I’ve had failures, so I would suggest using a simple battery holder instead.</em></p><p><amp-accordion id="battery_holder-accordian" disable-session-states=""><section><h5>Click to see the setup with battery holder, terminals secured with solder, hot glue and tape</h5><amp-img alt="Butt Pomodoro with Battery Holder" src="/images/Butt_Pomodoro_Battery_Holder.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="computation">Computation</h4><p>My initial plan was to use the NodeMCU itself for computation as that’s what microcontrollers are used for, but stopping the timers at will was bit of a hassle with Arduino code on NodeMCU and decided to leverage the comfort of Go with <a href="https://gobot.io/documentation/platforms/esp8266/" target="_blank">Gobot</a> using Firmata firmware.</p><p>Gobot allows client-server architecture on IoT devices, so NodeMCU can be controlled remotely from a client. The main advantage of using Gobot is that it allows me to modify the code and test it without having to flash it on the NodeMCU each time. I’m running Gobot client on a Raspberry Pi 2 after flashing firmata server on NodeMCU.</p><p><em>Update: Starting and stopping timers with Gobot on NodeMCU within different Goroutines resulted in unnecessary race conditions, deadlocks hence I resorted to calculating elapsed time manually and simple flags to start the timers. I guess, this method could have been easily implemented directly on the NodeMCU with Arduino code, but due to other advantages of using Gobot I’m continuing with it.</em></p><h4 id="communication">Communication</h4><p>I’m using <a href="http://mqtt.org/" target="_blank">MQTT protocol</a> for communication between the devices. <a href="https://appcodelabs.com/introduction-to-iot-build-an-mqtt-server-using-raspberry-pi" target="_blank">A MQTT broker(server) runs on the Raspberry Pi</a> along with the Gobot client which acts as the MQTT publisher.</p><p><a href="https://play.google.com/store/apps/details?id=in.dc297.mqttclpro" target="_blank">MQTT Client android app</a> is the MQTT subscriber. <a href="https://play.google.com/store/apps/details?id=net.dinglisch.android.taskerm" target="_blank">Tasker android app</a> creates a notification when MQTT client receives the message, displays the notification via <a href="https://play.google.com/store/apps/details?id=com.joaomgcd.autonotification" target="_blank">Auto Notification Tasker plugin</a>(paid) and <a href="https://play.google.com/store/apps/details?id=com.rageconsulting.android.lightflow" target="_blank">Light Flow android app</a>(paid) reads out the notification message and creates custom LED light.</p><p>The notification is further received at my desktop smart clock, which is an old android wear smartwatch modified to receive latest Google Play services updates.</p><p><amp-accordion id="communication-accordian" disable-session-states=""><section><h5>Click to see MQTT Client</h5><amp-img alt="MQTT Client" src="/images/MQTT_Client.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Tasker profile</h5><amp-img alt="Tasker Profile" src="/images/Tasker-profile.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Notification Configuration</h5><amp-img alt="Auto Notification Configuration" src="/images/AutoNotification.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Light Flow Configuration</h5><amp-img alt="Light Flow Configuration" src="/images/LightFlow_configuration.jpg" width="1080" height="1920" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="circuit">Circuit</h4><p><amp-accordion id="circuit-accordian" disable-session-states=""><section><h5>Click to see the circuit diagram</h5><amp-img alt="Butt pomodoro circuit diagram" src="/images/Circuit.png" width="614" height="587" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="setup">Setup</h4><p>Here is the overview of the complete architecture and the setup.</p><p><amp-accordion id="architecture-accordian" disable-session-states=""><section><h5>Click to see the architecture diagram</h5><amp-img alt="Butt pomodoro architecture" src="/images/Butt_pomodoro_architecture.png" width="686" height="660" layout="responsive"></amp-img></section><section><h5>Click to see the Butt pomodoro setup</h5><amp-img alt="Butt pomodoro setup" src="/images/Butt_pomodoro_setup.jpg" width="6000" height="4000" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="code">Code</h4><p>Source code for the Gobot client is available over the <a href="https://github.com/heavyinfo/buttpomodoro" target="_blank">GitHub</a>.</p><h4 id="demo">Demo</h4><h5 id="demo-video-enable-audio">Demo Video (enable audio)</h5><p><amp-accordion id="demo_video-accordian" disable-session-states=""><section><h5>Click to see video from Twitter (Fast loading, requires loading of twitter script)</h5><amp-twitter width="375" height="472" layout="responsive" data-tweetid="1281998220118249472"></amp-twitter></section></amp-accordion></p><p><a href="https://abishekmuthian.com/videos/Butt-Pomodoro-Demo.mp4" target="_blank">Click to see video from local .mp4 source, Slow loading, Requires HTML5 video support</a></p><p><a href="https://abishekmuthian.com/videos/Butt_Pomodoro.webm" target="_blank">Click to see video from local .webm source, Slow loading, Requires HTML5 video support</a></p><h3 id="enhancements">Enhancements</h3><p>Further enhancements which could improve the usability of the Butt Pomodoro -</p><pre><code>* Using a PIR (Passive Infrared) sensor as a trigger for contact less butt detection.

* Using a Bluetooth LE based microcontoller to communicate directly with the smartphone for cutting down the separate compute module.

* Custom app record the data on completed pomodoros, incomplete pomodoros, breaks and displaying it with cool visualisations. Of course, for notifications as well.
</code></pre><p>Tweet to me <a href="https://twitter.com/heavyinfo" target="_blank">@heavyinfo</a>.</p><h3 id="business-plan">Business Plan</h3><p>Do you think Butt Pomodoro is something people want?</p><p>Would you like to build Butt Pomodoro as a commercial product? I have <a href="https://hitstartup.com/business-plans/" target="_blank">business plan at hitstartup</a> to help you get started.</p></div></div>]]>
            </description>
            <link>https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817401</guid>
            <pubDate>Mon, 13 Jul 2020 05:17:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting audio code from C to rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817392">thread link</a>) | @est31
<br/>
July 12, 2020 | https://jneem.github.io/nnnoiseless/ | <a href="https://web.archive.org/web/*/https://jneem.github.io/nnnoiseless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    <time datetime="2020-07-12T00:00:00+00:00">July 12, 2020</time>
  </header>
<p>I ported a C library to rust last week, and it went pretty smoothly. This is
the story, and <a href="https://github.com/jneem/nnnoiseless">here</a> is the repo.</p>

<p>The library in question is <a href="https://github.com/xiph/rnnoise">RNNoise</a>, a
library for removing noise from audio. It works well, it runs fast, and best of
all it has no knobs that you need to tune. There’s even a <a href="https://github.com/RustAudio/rnnoise-c">rust
binding</a>.</p>

<p>So why bother porting it?
Well, I need to patch it so that it would compile with MSVC, but my PR went
unnoticed for a month. I thought about maintaining my own fork, but it’s been
more than 10 years since I last wrote anything in C or C++.
And that’s how I ended up porting RNNoise to rust. It probably wasn’t the most
efficient use of my time, but I had fun and learned something.</p>

<p>There’s a lot of information out there about porting C to rust, but the most
useful resource for me was the fantastic
<a href="https://github.com/carols10cents/rust-out-your-c-talk">talk</a> by Carol (Nichols
|| Goulding). It lays out a simple process for porting one function
at a time: first, you set up the cargo to compile as a static library and you
set up the C build system to link that static library into the C library
(see the slides for the relevant Makefile and Cargo.toml snippets).
Then you can port one function at time: the C code goes like this:</p>

<div><div><pre><code><span>+</span><span>extern</span> <span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>);</span>
<span>+</span><span>void</span> <span>__celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>-</span><span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>{</span>
    <span>/* C body of _celt_lpc */</span>
<span>}</span>
</code></pre></div></div>

<p>and the rust code goes like this:</p>

<div><div><pre><code><span>+</span><span>#[no_mangle]</span>
<span>+</span><span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>_</span><span>celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span> <span>ac</span><span>:</span> <span>*</span><span>const</span> <span>f32</span><span>,</span> <span>p</span><span>:</span> <span>c_int</span><span>)</span> <span>{</span>
<span>+</span>    <span>unsafe</span> <span>{</span>
<span>+</span>        <span>let</span> <span>lpc_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts_mut</span><span>(</span><span>lpc</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span><span>);</span>
<span>+</span>        <span>let</span> <span>ac_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>ac</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span> <span>+</span> <span>1</span><span>);</span>
<span>+</span>        <span>rs_celt_lpc</span><span>(</span><span>lpc_slice</span><span>,</span> <span>ac_slice</span><span>);</span>
<span>+</span>    <span>}</span>
<span>+</span><span>}</span>
<span>+</span>
<span>+</span><span>fn</span> <span>rs_celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>],</span> <span>ac</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>])</span> <span>{</span>
<span>+</span><span>// rust body of celt_lpc</span>
<span>+</span><span>}</span>
</code></pre></div></div>

<p>If you’ve watched the talk (which you should), you might notice that this is a
tiny bit different from what they recommend: I’ve renamed the original C
function instead of deleting it. I found that this helped me narrow down porting
mistakes, because it made it easy to switch back and forth between the C and
rust implementations.</p>



<p>Most of the porting process was mechanical and easy. One of the less fun parts was
porting code involving C structs. RNNoise has structs that (when ported to
rust) look like this:</p>

<div><div><pre><code><span>#[repr(C)]</span>
<span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>*</span><span>const</span> <span>RnnModel</span><span>,</span>
    <span>// Various buffers, whose sizes are determined by some subfields of `model`.</span>
    <span>vad_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>An idomatic rust version might look something like</p>
<div><div><pre><code><span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>&amp;</span><span>'static</span> <span>RnnModel</span><span>,</span>
    <span>vad_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>
<p>but this isn’t layout-compatible with the original C version, and so I need to
stick with the original struct for as long as <code>RnnState</code> is being accessed by
both C and rust code. This increases the amount of <code>unsafe</code> sprinkled around
the rust code, and it was also the source of an annoying bug of the sort that I
thought I had left behind by moving to rust.</p>



<p>At some point during the porting process, my tests started failing in release mode,
but not in debug mode. Most likely some undefined behavior triggered by my amateurish
attempts at unsafe code, but I couldn’t quickly spot the problem and the prospect of
a more careful round of debugging didn’t spark a whole lot of joy. So I did something
that I never would have dared to do in my C/C++ days: I ignored the problem and kept
porting; after all, the tests were still working in debug mode. And sure enough,
a few more ported functions later and <code>rustc</code> found the problem for me: in a function
taking a <code>&amp;RnnState</code> parameter, I was modifying data in the <code>vad_gru_state</code> buffer.
Since I was using unsafe code, <code>rustc</code> didn’t complain at first. But once I ported
the <code>RnnState</code> struct to safe and idiomatic rust, the compiler flagged the problem
immediately.</p>



<p>After getting everything to 100% safe (if not particulary idiomatic) rust, it was time
to check whether performance had suffered.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark.svg" alt="initial benchmark"></p>

<p>Yes, apparently, by about 50%. The most obvious culprit was bounds checking: there was
a lot of indexing in the C code, and some of it wasn’t trivial to convert to a more
rust-friendly, iterator-based version. First priority was the neural network evaluation:</p>

<div><div><pre><code><span>let</span> <span>m</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 114.</span>
<span>let</span> <span>n</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 96.</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span><span>;</span>
    <span>for</span> <span>j</span> <span>in</span> <span>0</span><span>..</span><span>m</span> <span>{</span>
        <span>output</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>layer</span><span>.input_weights</span><span>[</span><span>j</span> <span>*</span> <span>n</span> <span>+</span> <span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>*</span> <span>input</span><span>[</span><span>j</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>I can already see you shaking your head. I’m doing naive matrix-vector multiplication
with a 100x100ish matrix in
<a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">column-major format</a>?
Not only is this costing me bounds checks, it’s terrible for memory locality.
Swapping the weights storage from column- to row-major order only made things
about 1.5% faster, but more importantly it made the whole thing iterator-friendly.
Converting to zips and sums bought another 15%, leaving me only about 25-30% slower
than the C code.</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span>
        <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>+</span> 
        <span>layer</span><span>.input_weights</span><span>[(</span><span>i</span> <span>*</span> <span>m</span><span>)</span><span>..</span><span>((</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>*</span> <span>m</span><span>)]</span>
            <span>.iter</span><span>()</span>
            <span>.zip</span><span>(</span><span>input</span><span>)</span>
            <span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span>
            <span>.sum</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>For my next optimization opportunity, I moved on to the function
that
computes <a href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlations</a>.
The un-optimized version of this function looks like</p>

<div><div><pre><code><span>fn</span> <span>pitch_xcorr</span><span>(</span><span>xs</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>ys</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>xcorr</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>])</span> <span>{</span>
    <span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>()</span> <span>{</span>
        <span>xcorr</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>&amp;</span><span>ys</span><span>[</span><span>i</span><span>..</span><span>])</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>();</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>but the C code contained a massive, manually-unrolled version. I’d skipped
it while porting, but maybe I’d gain something from porting it over. Here’s
an abbreviated version of the optimized function, assuming that all
lengths are a multiple of 4 (the real code also handles the case that they aren’t).</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>(</span><span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>())</span><span>.step_by</span><span>(</span><span>4</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>c0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>let</span> <span>mut</span> <span>y0</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>0</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y1</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y2</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>2</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y3</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>3</span><span>];</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>[(</span><span>i</span> <span>+</span> <span>4</span><span>)</span><span>..</span><span>]</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>

        <span>y0</span> <span>=</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>

        <span>y1</span> <span>=</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>

        <span>y2</span> <span>=</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>

        <span>y3</span> <span>=</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Basically, both inner and outer loops have been unrolled four times, and I’ve
exploited the inner loop’s unrolling to optimize the memory access pattern.
Thanks to the amazing <a href="https://github.com/gnzlbg/cargo-asm"><code>cargo asm</code></a>, I
can happily report that there’s no bounds-checking in the inner loop and that
all the arithmetic has been <a href="https://en.wikipedia.org/wiki/Automatic_vectorization">auto-vectorized</a>
to work four <code>f32</code>s at a time. (Maybe it would get even faster if I unrolled 8 times and
compiled with AVX enabled; I haven’t tried that yet.)</p>

<p>This change more than doubled the speed of <code>pitch_xcorr</code>, and gained me about 10% overall.
More importantly, it showed me how to coerce the compiler into auto-vectorizing something
that it hadn’t auto-vectorized before. I went back to the neural network code and
replaced things like</p>

<div><div><pre><code><span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>ys</span><span>)</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>()</span>
</code></pre></div></div>

<p>with things like</p>

<div><div><pre><code><span>{</span>
    <span>let</span> <span>mut</span> <span>sum0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>sum0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>sum1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>sum2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>sum3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
    <span>sum0</span> <span>+</span> <span>sum1</span> <span>+</span> <span>sum2</span> <span>+</span> <span>sum3</span>
<span>}</span>
</code></pre></div></div>

<p>for another 20% improvement.</p>

<p>Current score: the rust version (still 100% safe) is about 15% faster, and there’s probably plenty more
still on the table.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark_after.svg" alt="final benchmark"></p>

<p>The performance lesson I learned from this is that bounds checking can be expensive in numerical code
and iterator-style code can help a bit, but if you really want faster numerical code then you need
to write in a style that the auto-vectorizer likes. (Or you could use the <a href="https://doc.rust-lang.org/core/arch/index.html">SIMD intrinsics</a>
directly, but that’s another story.)</p>



<p>Like I wrote above, it’s been a while since I did any C/C++, and because of that I’ve started to take tools
like cargo for granted. This little porting project brought back some memories, mostly because about half of the
code in RNNoise was actually “vendored” from <a href="https://gitlab.xiph.org/xiph/opus">opus</a>. I put “vendored”
in quotes because I usually think of vendoring as involving a subdirectory (maybe even a git submodule if
I’m lucky) with its own build artifacts. That’s not what’s going on here, though; I’m just talking about files
that were copied from the source directory of one project to the source directory of another, complete with
never-used functions and never-def’ed ifdefs. The thing is, though, that I understand exactly why they did it:
it’s by far the easiest way to share code between C projects. So I just want to finish by saying a big “thank you”
to <code>cargo</code> and <code>crates.io</code> for making me not have to deal with C dependency management any more.</p>


  
  
</article></div>]]>
            </description>
            <link>https://jneem.github.io/nnnoiseless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817392</guid>
            <pubDate>Mon, 13 Jul 2020 05:14:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Artificial Neural Networks Closer to Animal Brains]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23817347">thread link</a>) | @hardmaru
<br/>
July 12, 2020 | https://maraoz.com/2020/07/12/brains-vs-anns/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/12/brains-vs-anns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p><img src="https://maraoz.com/img/brains-vs-anns/cover.jpg"></p>

<p>Lately, I’ve been thinking and reading a lot about consciousness and how the human mind works. A question that emerges all the time is whether machines can <a href="https://en.wikipedia.org/wiki/Turing_test">emulate human thought</a>. An even more interesting one is whether consciousness (a subjective experience) can arise from a machine, but I’ll leave that discussion for a future post (I’ll need ~20 more years to think about that before I can write about it).</p>

<p>So, how far are we from _behaviorally _imitating a human? Truth is, we achieved a lot in the past 5 years (see <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a>, <a href="https://openai.com/blog/better-language-models/">OpenGPT-2</a>, <a href="https://openai.com/blog/jukebox/">OpenAI Jukebox</a>, <a href="https://en.wikipedia.org/wiki/Tesla_Autopilot">Tesla Autopilot</a>, <a href="https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning">Alphastar</a>, <a href="https://openai.com/blog/openai-five-defeats-dota-2-world-champions/">OpenAI Dota2 Team</a>, <a href="https://openai.com/blog/openai-api/">OpenAI API</a>), but we’re still quite not there. My hunch is that we still can learn a lot from biology’s state of the art. I’ve done some research on differences in how human brains work and how we emulate them using deep neural networks, and what follows is a summary of what I’ve found (and some new ideas).</p>

<figure>
  <img src="https://maraoz.com/img/brains-vs-anns/image1.png">
  <figcaption>
    I find it encouraging that John Carmack is studying human brains for his AI research. <a href="https://twitter.com/ID_AA_Carmack/status/1280693213549002752">Source</a>.
  </figcaption>
</figure>

<h2 id="morphology">Morphology</h2>

<p>The most surprising difference between artificial and human brains is how <em>sequential</em> our artificial neural networks (ANN) are, compared to the richly interconnected biological counterparts.</p>

<p>I’m always amazed by the sheer amount of layers that are stacked on top of each other <a href="https://jalammar.github.io/illustrated-gpt2/">in the latest deep learning models</a>. The largest GPT-3 model (with 175B parameters) uses 96 attention layers, each with 96x 128-dimension heads. <a href="https://arxiv.org/pdf/2005.14165.pdf">Their paper</a> shows that language model performance scales as a power-law with model size.</p>

<p>However, this assumes the size of the network can only increase by adding more layers, making it “deeper”. Using layers enables for great performance in training via <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">backpropagation/ADAM</a>, but I think the current mostly-sequential approach to scaling ANNs is limiting. Some ideas:</p>

<h3 id="wide-vs-deep-neural-networks">Wide (vs. Deep) Neural Networks</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image8.png">
<img src="https://maraoz.com/img/brains-vs-anns/image3.png"></p>

<p>A promising approach is exploring other kinds of architectures, where the concept of “layer” is forgotten, and networks are built more freely (with connections being modelled at the neuron level, and allowing for loops and more complex topologies). This <a href="https://en.wikipedia.org/wiki/Boltzmann_machine">has been somewhat explored in the past</a>, but I haven’t seen recent studies where today’s computing power is thrown at such architectures. Additionally, <a href="https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies">Ken Stanley’s NEAT (2002)</a> and derivatives are a very promising way of finding new topologies via evolution.</p>

<h3 id="neural-grids">Neural Grids</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image6.png"></p>

<p>Another idea worth exploring: grid-like structures where each cell communicates only with its neighbors. In this neural net model, potential is not only passed forward, but also “upward” and “downward”, or even diagonally. This would emulate more closely, I think, a real brain’s connectivity. A related approach is <a href="https://www.mitpressjournals.org/doi/abs/10.1162/artl.2009.15.2.15202">Hypercube-based NEAT (2009)</a>, which allows exploiting the task’s geometry by mapping its regularities onto the topology of the network.</p>

<h3 id="artificial-cortical-columns">Artificial Cortical Columns</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image9.png">
<img src="https://maraoz.com/img/brains-vs-anns/image5.png"></p>

<p>Human’s brain neocortex seems to have a surprisingly self-repeating pattern, called <a href="https://youtu.be/x2mYTaJPVnc?t=98">cortical columns</a>. Each column can be thought of as a reusable ~110 neuron module that appears (with variations) across neocortex areas associated with such different functions as vision, motor control, auditory perception, decision-making, planning, etc. <a href="https://numenta.com/neuroscience-research/cortical-columns/">Studying these structures</a> and applying similar concepts/topologies to ANNs seems like a promising approach. Cortical columns provide amazingly generic hierarchical information processing capabilities, feedback mechanisms, and layered communication with other parts of the brain.</p>

<h3 id="generative-architectures-arising-from-growth">Generative architectures arising from growth</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image10.png"></p>

<p>What if neural net architecture is determined by a generative / procedural algorithm on runtime, instead of being defined by researchers? The seed could be random or evolved through genetic algorithms too. I think that somehow mimicking <a href="https://www.youtube.com/watch?v=BtLyik7oAxc&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=4">neurulation of human embryos</a> via simple models could lead to finding better-performing architectures. Human brains grow into existence, and maybe that matters for high-level intelligence.</p>

<h2 id="function">Function</h2>

<h3 id="evolve-first-learn-later">Evolve first, Learn later.</h3>

<p>Some techniques use <a href="https://www.nature.com/articles/s42256-018-0006-z">neuroevolution used to automate network design</a> or <a href="https://blog.otoro.net/2017/11/12/evolving-stable-strategies/">evolutionary strategies finding network weights instead of gradient descent</a>. It’d be interesting to see hybrid approaches where network structure is evolved and <em>later</em> allowed to learn in an environment (like humans!). Additionally, as I learnt from <a href="https://www.nature.com/articles/s41467-019-11786-6">this fascinating paper by Tony Zador</a> (2019), “A large component of an animal’s behavioral repertoire is not the result of supervised or unsupervised learning, but rather of behavior programs already present at birth”. Learning is actually one of such behaviors, so… shouldn’t researchers be focusing more on optimizing the lower-level mechanism of evolution instead of polishing our “hand-crafted” learning algorithms and architectures?</p>

<p>On a similar ‘meta-learning’ vein, the comically named <a href="http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf">Learning to learn by gradient descent by gradient descent</a> (2016) paper shows that you can train a network to optimize other networks, and they perform better than hand-crafted learning algorithms like <a href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c">ADAM</a> and <a href="https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a">RMSProp</a>.</p>

<h3 id="continuous-vs-discrete-neuron-firing">Continuous (vs. discrete) neuron firing</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image4.png"></p>

<p>Instead of processing inputs in discrete events, our networks could ‘stare’ at inputs for a couple iterations, and neurons can ‘store-up’ potential until they fire. This aims to mimic how we humans can look at something we don’t understand, but after a couple of seconds we “get it”. This could also enable the emergence of “memories” in the form of stored potential, too, analogous to the hidden state vector of LSTMs. Check out <a href="https://www.youtube.com/watch?v=lddzHEtu934">Gabriel Kreiman’s related work (2018)</a> on improving object detection in occluded or distorted conditions. Regardless of the specific implementations mentioned above, biological brains clearly have a temporal dimension (for example, <a href="https://www.youtube.com/watch?v=aFrG7KdjUOs&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=32">neurons in the visual motion MT area respond to direction of motion</a>), which we need to understand better to inform construction of artificial ones. Another interesting time-related property of biological brains is <a href="https://youtu.be/fki7AmLma_I?t=450">the difference between tonic vs bursting modes of neuron firing</a>.</p>

<h3 id="connecting-functional-building-blocks">Connecting functional building blocks</h3>

<p>Animal brains are surprisingly pre-wired and connected since birth, and it’s still not clear in general which behaviors are learned through experience and which are innate. Moreover, a big field of study in neuroscience is understanding how the human brain is wired, mostly via <a href="https://en.wikipedia.org/wiki/Tractography">diffusion tractography</a>, and in some cases <a href="https://youtu.be/KFfaBoDANNI?t=134">it’s been shown that connectivity can predict function</a>. However, the fascinating <a href="https://www.youtube.com/watch?v=8Bvblav-BQk&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=65">‘rewired ferrets’ experiments</a> showed that training input also conditions function strongly (newborn ferrets with auditory cortex rewired to receive visual input still learn to see). This implies that animal brains have a very optimized initial configuration, but also the flexibility to adapt to structural damages or drastical environmental condition changes.</p>

<p>Many well-performing techniques simply stack two architectures that work for two separate domains (eg: CNN visual embedder and LSTM language model) and re-train them for a new combined task (eg: image captioning).</p>

<p><img src="https://maraoz.com/img/brains-vs-anns/image7.png">
<img src="https://maraoz.com/img/brains-vs-anns/image2.png"></p>

<p>I suggest trying to mimic what we know today of how the human brain is wired (from <a href="http://www.humanconnectomeproject.org/">the Human Connectome Project</a>, for example), and plugging in some state-of-the-art modules for vision, language, and audio-processing.</p>

<h3 id="slow-and-data-light-learning">Slow and Data-Light Learning</h3>

<p>Humans seem to learn slowly (in real time, it takes a human ~2 years to learn a language at a basic level, and ~18 years to learn advanced level language usage or complex language tasks like translation) but with few examples. Machines, on the other hand, learn very fast (in the order of weeks to achieve state of the art in some tasks) but are very data-hungry. Some techniques require less training data but might take longer to train, like <a href="https://medium.com/@SmartLabAI/a-brief-overview-of-imitation-learning-8a8a75c44a9c">Imitation Learning</a>, <a href="https://openai.com/blog/competitive-self-play/">Competitive Self-Play</a>, and <a href="https://arxiv.org/abs/2005.11212">Symbolic Pregressions (2020)</a> and could be key to getting closer to human intelligence.</p>

<h3 id="intermixing-learning-techniques">Intermixing Learning Techniques</h3>

<p>A combination of learning strategies could be necessary for human-level intelligence, as Yann LeCun suggests with his cake analogy: “If intelligence is a cake, the bulk of the cake is <a href="https://ai.stackexchange.com/a/10624">self-supervised learning</a>, the icing on the cake is <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, and the cherry on the cake is <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>.”</p>

<p>Humans train by learning from others (supervised learning) <em>and</em> experimenting on our own (unsupervised/self-supervised learning). For example, a chess student first talks to a teacher, then plays some games. They wouldn’t go to a chess tournament after just talking to a teacher or playing games alone. Can we combine/emulate these kinds of training efficiently in ML too?</p>

<h2 id="final-words--further-studying">Final words &amp; further studying</h2>

<p>What do you think of these approaches? Have you actually seen any of these used in the wild (with success or otherwise)? Which do you think may have merits? Let me know if you do some experiments to try them out.</p>

<p>If you’ve been intrigued by the potential of imitating biological brains, here are some up-to-date resources to dig deeper, in order of relevance:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=i1pdQjdAndc&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0">Nancy Kanwisher’s The Human Brain course on YouTube</a> (2018)</li>
  <li><a href="https://www.youtube.com/watch?v=8-KF0rnhKTU&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=2">Ninja Nerd Lectures on Embryology</a> (2019)</li>
  <li><a href="https://www.nature.com/articles/s41467-019-11786-6">A critique of pure learning and what artificial neural networks can learn from animal brains by Anthony M. Zador</a> (2019)</li>
  <li><a href="https://www.youtube.com/watch?v=pkJkHB_c3nA">AI for physics &amp; physics for AI by Max Tegmark</a> (2020)</li>
  <li><a href="https://www.youtube.com/watch?v=x2mYTaJPVnc">Brains Explained video on cortical columns</a> (2017)</li>
  <li><a href="https://www.youtube.com/watch?v=h0InlY2WKc0">Deciphering Brain Codes to Build Smarter AI by Gabriel Kreiman</a> (2020)</li>
</ul>

<p><em>Thanks to Javi Silveira, <a href="https://twitter.com/hardmaru">David Ha (@hardmaru)</a>, <a href="https://twitter.com/alcuadrado">Pato Palladino (@alcuadrado)</a> and <a href="https://twitter.com/itsladywhite">Lady White (@itsladywhite)</a> for providing feedback and pointers.</em></p>

<p><em>Image by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">David Clode on Unsplash</a>.</em></p>


  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/12/brains-vs-anns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817347</guid>
            <pubDate>Mon, 13 Jul 2020 05:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$15 HDMI Capture Card Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817119">thread link</a>) | @rubatuga
<br/>
July 12, 2020 | https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><br>
<video src="https://www.naut.ca/videos/smash60fps.mp4" poster="https://www.naut.ca/videos/smash60fps.jpg" preload="none" controls="" playsinline=""></video>

<p>Above is a sample of 60fps Super Smash Bros Ultimate gameplay (I'm a Jigglypuff main) recorded with the $15 HDMI Capture Card and OBS. This card has been making the rounds last month on <a href="https://twitter.com/Ascii211/status/1268631069051453448">Twitter</a>, as well as on <a href="https://www.youtube.com/watch?v=daS5RHVAl2U">YouTube</a>, mainly due to its low, low price of $15 USD. I've decided to get one myself and take a look. The chipset contained in the card is the MacroSilicon MS2109. Here is the review, as well as a discussion of the potential use-cases.</p>
<h3 id="operatingsystem">Operating System</h3>
<p>This card, surprisingly enough, works on Windows, macOS and Linux! This is because it implements the UVC standard, a USB device that is OS agnostic. Getting it working on Linux is a bit of a hassle, but you can find out how <a href="https://bigl.es/friday-fun-10-hdmi-to-usb-capture/">here</a>.</p>
<p>I noticed that using the capture card on Linux or macOS resulted in significantly more framedrops and synchronization issues, when compared to Windows (although the macOS issues might be due to weak CPU). If you are okay with slightly choppy or stuttery recordings, then feel free to use the card on macOS or Linux. The Windows UVC driver captures more frames, and has the most options of the three. Most of the guide will be focusing on the Windows driver. The controls that are listed in OBS for each operating system are shown below.<br>
<img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-7.13.22-PM.jpg" alt="Screen-Shot-2020-07-09-at-7.13.22-PM"></p>
<h3 id="yuy2vsmjpeg">YUY2 vs MJPEG</h3>
<p>Windows and Linux both support the YUY2 and MJPEG video format, while macOS only supports MJPEG. YUY2 in this context refers to an almost uncompressed form of data (except for colour information), while MJPEG uses lossy JPEG compression on every frame. This means that YUY2 provides a cleaner image with no compression artifacts, while MJPEG has a noisier and blockier image. Compare the two capture formats below:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.33.23-AM.png" alt="Screen-Shot-2020-07-09-at-12.33.23-AM"></p>
<p>As you can see MJPEG has degraded the image data, which is necessary to compress each frame to a small size. Only MJPEG can achieve high framerates with this card because the interface it uses, USB 2.0, caps out around 50 MB/s. For reference, a YUY2 1280x720 60fps signal would exceed 100 MB/s. If you want a card that supports a 60fps YUY2 signal, you can expect to pay in the range of hundreds of dollars.</p>
<p>Both the YUY2 and MJPEG video formats from this card use something called <a href="https://en.wikipedia.org/wiki/Chroma_subsampling">chroma subsampling</a>, a data saving trick that takes advantage of the human eye's decreased colour resolution. It essentially deletes colour data, while keeping brightness data intact. I tested both formats, and they are outputting a 4:2:2 signal (50% of the colour data is deleted). You can see that the horizontal axis changes colour at 2 pixel boundaries, while the vertical axis changes at 1 pixel boundaries.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.32.56-AM.png" alt="Screen-Shot-2020-07-09-at-12.32.56-AM"></p>
<h3 id="resolutionandframerate">Resolution and Framerate</h3>
<p>A wide variety of resolutions and framerates are supported on the input side of the device. It even supports input at 4K 60fps! From the NVIDIA Control Panel, here is an abridged list of the resolutions and framerates supported on the <strong>input side</strong>:</p>
<pre><code>4K    60,59,50,30,29,25,24,23Hz
1080p 60,59,50Hz
720p  60,59,50Hz
576p  50Hz
480p  60,59Hz
PC    60Hz
</code></pre>
<p>To clarify, just because this card can accept or capture a 4K signal, does not mean that it can send the full signal to your computer. This card contains a scaler, which scales the image down (or up, depending on the input) in resolution before it is sent. With reference to the OBS properties window, here is an abridged list of the resolutions and max framerates as seen by my Windows PC:</p>
<pre><code>1920x1080 MJPEG:30fps, YUY2:5fps
1600x1200 MJPEG:30fps, YUY2:5fps
1360x768  MJPEG:30fps, YUY2:?
1280x960  MJPEG:50fps, YUY2:?
1280x720  MJPEG:60fps, YUY2:10fps
1024x768  MJPEG:60fps, YUY2:10fps
800x600   MJPEG:60fps, YUY2:20fps
720x480   MJPEG:60fps, YUY2:30fps
</code></pre>
<p>Each resolution dictates a maximum framerate for the device, limited by the bandwidth of the USB interface. To summarize, this card supports an output of 1920x1080 30fps and 1280x720 60fps with the MJPEG format.</p>
<h3 id="resolutionandframeratecaveats">Resolution and Framerate Caveats</h3>
<p>First I'll talk about framerate. I noticed that recording or streaming from the card at 60fps tends to repeat or skip a frame every few seconds, even with buffering on. Make sure to keep buffering on, otherwise you will lose frames at 30fps as well. I have confirmed this by recording videos in OBS and analyzing them frame by frame.</p>
<p>If you want virtually perfect frame capture at both 720p and 1080p, you should use 30fps with buffering!</p>
<p>Also, you may notice that there are 29.97fps and 59.94fps options in OBS. Only use these if you are absolutely sure that your device needs these values. You will likely run into desynchronization issues if you accidentally use these framerates.</p>
<p>Next, when I tested the 1920x1080 capture, I was shocked by how blurry it was. It turns out that this card doesn't actually do true 1080p! Here's a screenshot of Wikipedia, compared to what was captured at 1920x1080.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-2.48.49-AM.png" alt="Screen-Shot-2020-07-09-at-2.48.49-AM"></p>
<p>It looks like the card is capturing the vertical resolution fine, but the horizontal resolution is a soft mess. I tried out 1280x720, and everything looked crisp and fine, leading me to suspect that the card was capturing internally at a resolution of 1280 columns. I ended up using display calibration images from <a href="http://www.lagom.nl/lcd-test/sharpness.php">Lagom LCD</a> to see how the pixels in the capture were behaving. Right click the following image and choose Open/View Image for a better view.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-3.05.56-AM.png" alt="Screen-Shot-2020-07-09-at-3.05.56-AM"></p>
<p>Using the reference on the left, we can see that 1280x720 has correct vertical and horizontal resolution. 1360x768 and 1920x1080 also have correct vertical resolution, but the columns are turning grey. This is because adjacent white and black pixels from the high input resolution are merged into a lower resolution, i.e. from 1920 columns into 1280 columns. If you also noticed that pixel columns are brighter than the rows, I will be talking about that in the next section.</p>
<p>As a quick aside, everything above was for progressive video input. Interestingly, this card also supports an input of 1080i/interlaced video, which I tested with macOS and my Canon 600D camera. Using 1080i was absolutely horrible for desktop recording, since the card uses a brainless deinterlacing algorithm that halves the vertical resolution to 540. Yes, it actually looks that bad. As for my camera, it was decent, but the edges were kind of funny.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.01.51-AM.png" alt="Screen-Shot-2020-07-09-at-5.01.51-AM"></p>
<h3 id="imageaccuracycaveats">Image Accuracy Caveats</h3>
<p>This card needs "Color Range" set to "Full" in the OBS Capture Card Properties. Any devices that are connected to the card input need to have their HDMI "Range" set to "Limited". This is the only correct combination, otherwise highlights and shadows in the video are clipped. The following shows the effects of the device range options.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.53.19-PM.png" alt="Screen-Shot-2020-07-09-at-5.53.19-PM"></p>
<p>As you might have noticed from the previous section, the 1280x720 capture is brightening the columns. This indicates that the card is performing image sharpening only in the horizontal direction. You can find evidence of this type of sharpening wherever there are sharp edges:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.21.58-AM.png" alt="Screen-Shot-2020-07-09-at-5.21.58-AM"></p>
<p>This is a bad feature, as all image sharpening should be done after the capture. Fortunately, there is a way to get around this for 1280x720 content. Simply set your device to 1280x720, and then capture at 1920x1080. The image loses some clarity in brightness changes, due to the unnecessary resize, but all the sharpening has disappeared! Furthermore, since we are receiving 1920x1080 data, we now have better colour resolution as well, close to 4:3:3 chroma subsampling.</p>
<p>The 1920x1080 MJPEG capture also has significantly less compression artifacts than the 1280x720 MJPEG capture, which is probably due to different framerate support. From the image below, you can see that the 1080p capture is the winner all around (sharpening was applied post-capture for comparison with 720p).</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.25.44-PM.png" alt="Screen-Shot-2020-07-09-at-5.25.44-PM"></p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>
<p>If you are capturing slower gameplay, i.e. only 30fps, set your device to 1920x1080 and then capture at 1920x1080. This provides the most brightness and colour resolution at 30fps.</p>
</li>
<li>
<p>If you have 1280x720 content, capture at 1920x1080. This will result in the least amount of sharpening and MJPEG artifacts.</p>
</li>
<li>
<p>If you are capturing a desktop screen or anything with thin lines and pixels, then set your device to 1280x720 and then capture at 1280x720.</p>
</li>
<li>
<p>If you need 60fps content, i.e. for gaming, then set your device to 1920x1080 and then capture at 1280x720. This disables sharpening. The sample at the beginning of the article was encoded with "x264" at the "veryfast" setting.</p>
</li>
</ul>
<p>Warning: if you see a listing for a $20 USD capture card that claims to support USB 3.0 and 1080p 60fps, it's a scam. I've already bought two of them from Amazon and eBay, and had to return both because they turned out to be a repackaging of the product I just reviewed!</p>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817119</guid>
            <pubDate>Mon, 13 Jul 2020 04:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 in schoolchildren – A comparison between Finland and Sweden [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 73 (<a href="https://news.ycombinator.com/item?id=23816709">thread link</a>) | @mrfusion
<br/>
July 12, 2020 | https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf | <a href="https://web.archive.org/web/*/https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816709</guid>
            <pubDate>Mon, 13 Jul 2020 02:50:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Features are a better abstraction than issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816682">thread link</a>) | @gauthamshankar
<br/>
July 12, 2020 | https://zepel.io/blog/how-issue-tracking-hurts-development/ | <a href="https://web.archive.org/web/*/https://zepel.io/blog/how-issue-tracking-hurts-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>The short answer is yes. Let me explain.</p><p>I’ve been working with developers and designers my entire life. </p><p>I’ve built a couple of products, worked at a young startup, and I’m now at Zepel helping development teams build better software.</p><p>I’ve spoken to 1000+ development teams while at Zepel alone. <strong>And it's evident that the way we build products is broken.</strong></p><p>There’s so much disconnect between how you and I talk about building products and how our teams actually build them.</p><p>For all the talk of scrum and agile and getting feedback quickly, there’s so much that’s broken in how we act on the feedback and build the feature.</p><p>Teams spend so much time and effort getting a deeper understanding of customers’ needs. And yet distil everything down to a simple two-line ticket and a couple of lines of markdown description.</p><p>This is hurting your developers. And it’s hurting your business.</p><blockquote>Nothing is more frustrating than having to understand what an entire feature should or shouldn’t do from a two-line ticket filled with ten bullet points of acceptance criteria.</blockquote><p><em>*Here are five prioritized tickets for the upcoming sprint. We have to ship them on time!*</em></p><p>On the other hand, you have teams who are able to build top quality software. They’re the ones who can concentrate on the fine implementation details without losing focus on the broader purpose of the feature as a whole.</p><p>Everyone wants to get to that level. But instead, teams do the exact opposite.</p><p><strong>Teams think in issues and tickets, instead of the feature as a system.</strong></p><hr><h2 id="development-teams-are-not-ticket-movers-">Development teams are not ticket movers!</h2><p>Today, everything is about moving a ticket from “Todo” to “Done” as quick as possible. And watching <a href="https://zepel.io/agile/reports/burndown/">burndown charts</a>. And customizing the tool to the extent that the developer only views a single ticket.</p><p><em>*“What’s the velocity of our team?” is simply another way of asking how quickly can my team move an issue from “Todo” to “Done”.*</em></p><p>Pieces of that stuff are important for productivity and shipping on time.</p><p>But seriously, how is your team supposed to ship anything of value if you narrow their focus down to the smallest unit of work without any context of why it’s needed or how it connects to the whole feature?!</p><p>Overall, we’ve lost our way. Product development today has become more about checking items off a list as quickly as possible. </p><p><strong>It isn’t enough to write multiple user stories and share a Figma link if you want to ship quality software.</strong></p><hr><h2 id="how-software-product-teams-really-build-software-together">How software product teams really build software together</h2><p>Development teams build better software together when they have the complete context of what and why something is being built.</p><p>To achieve this, the foundational elements need to change.</p><p>And it starts with getting the right abstractions and naming conventions.</p><p><strong>The names you choose determine the perception and the quality of conversations you have. </strong>It’s why top developers spend time obsessing over names for classes, functions, and variables.</p><p>When you open up a VS Code and see a function called <code>send_signup_email</code>, you have a certain sense of what’s going to be inside and why that’s there.</p><p>The right abstractions can drive the team towards asking the right questions. And this is critical.</p><p><strong>Because when you’re tracking issues and tickets in isolation you have no choice but to measure only outputs.</strong></p><p>And teams today don’t want to measure only the outputs. They want to measure <em>outcomes</em>.</p><hr><h2 id="what-s-the-right-abstraction">What’s the right abstraction?</h2><p>The right abstraction is the one that prioritizes people over processes and tools. It's the one you and I use every day — it's Features.</p><p>When a squad creates a Feature and opens it, they’ll get to look at the entire feature as a unit. A <a href="https://zepel.io/agile/user-stories/">user story</a> inside it might describe a specific functionality. But the difference is, now each developer and designer know how it connects to the larger scheme of things for the entire feature.</p><blockquote>A feature forces inept managers to stop focussing on output-oriented questions like “how can we work faster”. <p>And shifts the focus on outcome-oriented questions like “why should we prioritize this feature” and “how does this feature tie to the OKR”.</p></blockquote><p>Miscellaneous tasks and incoming bugs can be tracked on a separate “List”, so high-priority bugs don't get missed out. And of course, when it comes to tracking them, they can all be tracked on a Sprint or on a Kanban Board.</p><p><strong>Feature as an abstraction is the right middle ground that lets you focus on the output as well as the outcome.</strong> It lets you zoom in and track what's happening today. It also allows you to zoom out and track a feature's progress across multiple disciplines. And it enables you to see how a feature moves from a feature request all the way to prioritization and development.</p><p>Simple issue trackers and project management tools have shoehorned teams into ticket-movers and have made them think in outputs. Metrics get feigned to show productivity. Thinking in outcomes has become ridiculously hard. And it's hurting businesses.</p><p>It's time for tools to reflect the reality of product development. It's time to remove the disconnect between development teams and what your customers really want. </p><p>It's time to stop thinking in isolated tickets and start thinking in features as a system!</p><hr><p>If you liked what you read, I think you’ll love what we have in store for you. Go ahead and <a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=product-development-is-broken">try Zepel for free</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://zepel.io/blog/how-issue-tracking-hurts-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816682</guid>
            <pubDate>Mon, 13 Jul 2020 02:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Website allows you to experience what it is like to live with dyslexia]]>
            </title>
            <description>
<![CDATA[
Score 299 | Comments 112 (<a href="https://news.ycombinator.com/item?id=23816678">thread link</a>) | @colinprince
<br/>
July 12, 2020 | http://geon.github.io/programming/2016/03/03/dsxyliea | <a href="https://web.archive.org/web/*/http://geon.github.io/programming/2016/03/03/dsxyliea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        


<div>
  <div>
    
<p>A friend who has dyslexia described to me how she experiences reading. She <em>can</em> read, but it takes a lot of concentration, and the letters seems to “jump around”.</p>

<p>I remembered reading about <a href="https://en.wikipedia.org/wiki/Typoglycemia">typoglycemia</a>. Wouldn’t it be possible to do it interactively on a website with Javascript? Sure it would.</p>

<p>Feel like making a bookmarklet of this or something? <a href="https://github.com/geon/geon.github.com/blob/master/_posts/2016-03-03-dsxyliea.md">Fork it</a> on github.</p>

<blockquote>
  <p>Dyslexia is characterized by difficulty with learning to read fluently and with accurate comprehension despite normal intelligence. This includes difficulty with phonological awareness, phonological decoding, processing speed, orthographic coding, auditory short-term memory, language skills/verbal comprehension, and/or rapid naming.</p>
</blockquote>

<blockquote>
  <p>Developmental reading disorder (DRD) is the most common learning disability. Dyslexia is the most recognized of reading disorders, however not all reading disorders are linked to dyslexia.</p>
</blockquote>

<blockquote>
  <p>Some see dyslexia as distinct from reading difficulties resulting from other causes, such as a non-neurological deficiency with vision or hearing, or poor or inadequate reading instruction. There are three proposed cognitive subtypes of dyslexia (auditory, visual and attentional), although individual cases of dyslexia are better explained by specific underlying neuropsychological deficits and co-occurring learning disabilities (e.g. attention-deficit/hyperactivity disorder, math disability, etc.). Although it is considered to be a receptive language-based learning disability in the research literature, dyslexia also affects one’s expressive language skills. Researchers at MIT found that people with dyslexia exhibited impaired voice-recognition abilities.</p>
</blockquote>

<p><em>Source: <a href="http://en.wikipedia.org/wiki/Dyslexia">Wikipedia</a></em></p>






    <hr>
    
    <hr>
    


  


<p><a href="http://disqus.com/">blog comments powered by </a>




  </p></div>
  
  
</div>


      </div></div>]]>
            </description>
            <link>http://geon.github.io/programming/2016/03/03/dsxyliea</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816678</guid>
            <pubDate>Mon, 13 Jul 2020 02:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning done right can be your biggest investment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816474">thread link</a>) | @xueyongg
<br/>
July 12, 2020 | https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/ | <a href="https://web.archive.org/web/*/https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><span><p>In the midst of chaotic schedules and piles of work, it is often easy to just take the easy way out of the pile of work: auto pilot. You just switch out the curiosity mode, and just churn out work one after another. “There isn’t time to just sit and ponder. I’ve got 10 other todos to clear out today”. As we continue down this train of thought, we will find ourselves at the brink of a burnout soon and very soon. How then do the smartest people actually learn such complex knowledge? For example, learning calculus in colleague, does one know what does dy/dx actually means?</p>

<p>I came across an article talking about how the smartest people are <a ref="nofollow" target="_blank" href="https://nabeelqu.co/understanding">learning the right way</a>. Now this right does not mean morally right or wrong. But rather learning as a reflection of one’s virtue of honesty and integrity. We will get to this.</p>

<p>Below are four lessons I’ve gotten away from the article:</p>
<br>
<h2>1. More than one solution to the same problem; don’t stop at 1.</h2>

<p>Once a problem was solved, some of the smartest people I’ve known will go back and continue thinking about the problem and try to figure out different solutions to the same problem. Afterwards, he’d come back with 3-4 alternative solutions to the same problem + explanations of why each solutions are somehow connected.</p>
<br>
<blockquote>
<p>It’s also so easy to think that you understand something, when you actually don’t. So even figuring out&nbsp;whether&nbsp;you understand something or not requires you to attack the thing from multiple angles and test your own understanding.</p>
</blockquote>

<p><img src="https://pbs.twimg.com/media/EcvWI2NXYAgD5UT?format=jpg&amp;name=large" alt=""> <em>source from visualizingvalue</em></p>

<p>A problem is often times bigger and more complex beyond our current perspective. The ability to sit and ponder for alternative solutions to the same problem forces you to consider the possibility of not knowing something in this problem at hand. It allows you to force out the cracks in the pottery by placing the knowledge under fire.</p>
<br>
<h2>2. Be honest with yourself; do you really know? Ask yourself.</h2>

<p>To admit that you do not understand a concept is related to honesty or integrity. It is uniquely easy to lie to yourself that you know and move on because there is no external force keeping you honest. You and only you can run that constant loop of asking “do i really understand this?”. Do not just skirt past the problem just to move on to the next task, you’re not a factory that just just churning out work day in day out. You’re an individual that is part of your own journey to learn, grow, and develop.</p>

<p>Also, writing has a part to play. Firstly, it helps you to be honest with yourself; it forces you to articulate your understanding. And if the writing comes out confusing and disjointed, it is a reality check for knowledge gaps.</p>
<br>
<blockquote>
<p>It’s okay to admit that you don’t know</p>
</blockquote>
<br>
<h2>3. Go beyond the abstraction, tell me what you really know. Give examples.</h2>

<p>The tangible experiments of your learning with concrete examples is important to illustrate understanding. You do not just stop at simple verbal “word based” understanding. It can only bring you this far. But visuals creates a context in which your understanding can take place in.</p>
<br>
<blockquote>
<p>Visualizing something, in three dimensions, can help you with a concrete “hook” that your brain can grasp onto and use as a model;</p>
</blockquote>

<p>If you’re not coming up with visuals and your understanding of things remains on the level of abstractions or abstract concepts, you probably do not understand the concept deeply and should dig further. Below is basically the concept of AI conversational classifiers done up with the illustration of a coin filter.</p>

<p><img src="https://pbs.twimg.com/media/Ebxl9eFWoAAJuFT?format=png&amp;name=small" alt=""> <em>source from nwilliams030’s twitter</em></p>
<br>
<ol start="4">
<li>Have the courage to ask; Ask if you don’t know.</li>
</ol>
<p>Have the courage to be unafraid to look stupid. Have the courage to admit and seek for clarity and understanding. Don’t just pretend you understand just to pass the time. This is your journey of learning and getting better than the you yesterday. Do not let other people dictate how you should invest in yourself. Shower yourself with love and respect for your own growth.</p>

<p><img src="https://images.unsplash.com/flagged/photo-1558979217-e7f2c4511e8b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1650&amp;q=80" alt="kid watering flower"></p>
<br>
<hr>
<br>
<h2>TLDR;</h2>

<p>At the end of the day, if you want to understand something, go slow. Explore every step of the way in your adventure to learn and unveil. Read slowly, think slowly, really spend time pondering the thing. A week or a month of continuous pondering about a question will get you surprisingly far. In the space of technology, you will face a ton of technology that are more abstracted and technical beyond human mind (haha kidding, but it feels like so). There’s what you got to be honest with yourself to admit that you don’t know then can the learning begin (:</p>

<p>Before you end off, do watch this video! It is really good. It’s a video talking about the 5 hours rule deliberate learning. Let’s learn together! (:</p>

<p>
<iframe src="https://www.youtube.com/embed/IaODRYKFbrc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></span></p> </div></div>]]>
            </description>
            <link>https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816474</guid>
            <pubDate>Mon, 13 Jul 2020 02:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Host a Wiki or Knowledge Base for Your Team]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23816462">thread link</a>) | @chsasank
<br/>
July 12, 2020 | http://chsasank.github.io/outline-self-hosted-wiki.html | <a href="https://web.archive.org/web/*/http://chsasank.github.io/outline-self-hosted-wiki.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>How is your startup sharing knowledge with the rest of your team?
We’ve been using slack’s <code>#general</code> or <code>#random</code> channels to make announcements.
We regularly post documents and PPTs slack channels so that they can be used by other people. We have a channel called <code>#setup</code> to post all IT related information like how to login to VPN etc.</p>

<p>But after a few weeks, these docs/notes become super hard to find. As good slack’s search is, you have to precisely know what you’re looking for. What we needed was a centralized knowledge base website - something like <a href="https://www.atlassian.com/software/confluence">Confluence</a></p>

<p>But Confluence is clunky and slow, and not cheap ($5/user). We experimented with <a href="https://tiddlywiki.com/">TiddlyWiki</a>. It calls itself ‘a non-linear personal web notebook’. It’s an opensource software which you can host on your servers or AWS. But its non linear organization makes it super unintuitive and confusing.</p>

<h2 id="why-outline">Why Outline?</h2>

<p>Then, I found <a href="https://www.getoutline.com/">outline</a>! Outline is similar to TiddlyWiki in that it’s opensource and free to self-host. Its UI is a great balance between simplicity of plain text notes and feature creep of Confluence. Login to outline is through your slack - so one less password to remember (or save). You can create private notebooks for a team or just for yourself. You can create a public link of a note so that you can share it with people outside your team - say via email.</p>

<p><span>
    Outline has great UI
</span>
<img src="https://www.getoutline.com/images/screenshot.png"></p>

<p>Best part of all of this is that <em>data doesn’t leave your servers</em> if you self-host it!
We already have a server lying around on AWS to host our own <a href="https://en.wikipedia.org/wiki/Python_Package_Index">python package server, pypi</a>. Since neither hosting pypi nor hosting outline are particularly intensive, we’ve hosted outline on this machine as <code>wiki.qure.ai</code>.</p>

<h2 id="install-outline">Install Outline</h2>

<p>Unfortunately, documentation for self-hosting outline is limited. There’s no robust docker-compose avaialable that you can use to directly create your server. In the rest of this post, I’ll show you how to host in your laptop or server. Before starting, make sure to install <a href="https://docs.docker.com/get-docker/">docker</a> and <a href="https://docs.docker.com/compose/install/">docker-compose</a>.</p>

<div><div><pre><code>git clone https://github.com/chsasank/outline-wiki-docker-compose.git
cd outline-wiki-docker-compose
make install
</code></pre></div></div>
<p><span>
    make install
</span>
<img src="http://chsasank.github.io/assets/images/outline/make_install.png"></p>

<p>Follow the instructions. You’ll have to create a slack app.
<span>
   Slack app
</span>
<img src="http://chsasank.github.io/assets/images/outline/slack_app.png"></p>

<p>If you want to install HTTPS:</p>



<p>Run the server:</p>



  </section></div>]]>
            </description>
            <link>http://chsasank.github.io/outline-self-hosted-wiki.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816462</guid>
            <pubDate>Mon, 13 Jul 2020 02:00:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From English Major to Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816355">thread link</a>) | @shsachdev
<br/>
July 12, 2020 | https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            


<p>
My name is Chris Dang and I work at <a href="https://www.scratch.fi/">Scratch</a> which is a Series A fintech startup that has reimagined loan servicing to help borrowers understand, manage, and pay back their loans. It’s a company filled with determined, smart, and mission driven individuals. 
</p>
<p>
We were recently mentioned in this <a href="https://www.nytimes.com/2020/06/23/business/paycheck-protection-program-cross-river-bank.html">New York Times article</a>.
</p>
<center>
    <img src="https://www.careerfair.io/assets_cdang/final_homepage.png" alt="">
</center>
<p>
I’m a software engineer who primarily focuses on Identity and Access Management. This means I focus on authentication, authorization, and user management problems. I also occasionally work outside my domain in areas such as frontend, security, and infrastructure. This happens a lot at startups which require folks to wear many hats. 
</p>



<p>
I don’t really understand why but I just enjoyed writing essays and discussing texts so I became an English major. It was one of those moments where I felt like I just had to go with my gut and I’m glad I did because becoming an English major made me a more creative person. This creativity allowed me to come up with a few startup ideas that I’ve attempted and have planned for the future. 
</p>
<p>
The reason I taught myself how to code is that I wanted to build my ideas. I’d like to note that I did take a few intro computer science courses before I became an upperclassman, so when I began attempting some of my startup ideas I already knew OOP, runtime analysis, data structures and algorithms. 
</p>
<p>
In my day-to-day, being an English major helps me with communication, which is very key as an engineer, and, this is a little random, but it makes me more relatable to non-engineering folks since a lot of them probably took similar courses to me.
</p>
<center>
  <img src="https://www.careerfair.io/assets_cdang/new_venn_diagram.png" alt="">
</center>



<p>
It was definitely a problem in the beginning since I had no experience and a lot of companies wouldn’t even give me an interview. I wasn’t too worried about this though because I had a passion project I was working on and if I wasn’t able to get a job, I was determined to go all on the project and turn it into a startup. I actually was able to launch it to the app store and had a customer acquisition strategy. Luckily, a few companies, including WeWork, liked the grit I showed in my startup and gave me a chance.
</p>
<p>
The lack of a CS major did leave a gap in my knowledge when it came to interviews and performing the day to day job. I did a few things to mitigate this gap which included going through lecture slides for upper division courses I found interesting (e.g. Operating Systems and Computer Security), spending copious amounts of time reading articles about engineering, and spending time on my passion project which gave me a lot of real world experience. Also, Stack Overflow was my best friend. 
</p>



<p>
My time at WeWork made me realize that I was very interested in the Identity, Infrastructure, and Security domains with Identity being my primary interest. So when I began my job search, I made sure to focus on jobs in those domains but I did apply to some generalist positions. The reason for this is that I’m pretty young and it’s good for me to have breadth in other areas. I also wanted to make sure that my next job had really challenging problems and smart engineers. The things I cared about least were job stability (e.g. whether or not my company would exist in a year), my total compensation, and the company brand. 
</p>
<p>
I optimize for growth over learning by focusing on opportunities that I’m passionate about over opportunities that would make me more money. Money and brand names bring you a limited amount of satisfaction. However, doing something you are passionate about will always be more exciting because as you grow in that area, the horizons expand and more exciting ideas/projects will come to you.
</p>
<center>
    <img src="https://www.careerfair.io/assets_cdang/cash.png" alt="">
</center>



<p>
The nice thing about working at startups is you are guaranteed to have a large role. Everyday I learn something new and I always feel like my work is rewarding. But there is a trade off here.  I do feel like I’m a lot busier since my role is more significant than if I were at a large company. 
</p>
<p>
One thing I wish I realized earlier though was that even at a big company, you can have a really exciting role. It really depends on the team and your manager. If you are hungry for a challenge but would like the comfort of a large company, I would recommend interviewing with some of the newer projects.
</p>



<p>
I actually went to the office before the shelter in place was ordered so I didn’t have any issues with setting up my laptop or developer environment. But even if this wasn’t the case, I don’t see remote onboarding being a problem due to strong video technologies such as Zoom. 
</p>
<p>
My first day of work actually began a few weeks after the quarantine began so I haven’t had more than a few days to see my coworkers in person. It’s a little weird because I spend so much time with these people but our interactions are exclusively through a computer screen. One thing I’ve realized is I’m lukewarm to remote work culture since it’s hard to have spontaneous interactions with coworkers and happy hours aren’t as fun. 
</p>
<p>
That being said, I’m really amazed by how our team has adapted to these conditions. Despite the pandemic, the conditions of working remote, and other obstacles, we’ve managed to persevere and launch our PPP product.
</p>

<center>
  <img src="https://www.careerfair.io/assets_cdang/spontaneous.png" alt="">
</center>




<p>
I’ve worked with teams in business operations and design at least once a week. It’s cool to collaborate with folks from other departments because you can pick their brains and see another perspective to a problem you are working on. A really big aspect of these interactions is your ability to communicate technical topics since a lot of times non-technical individuals will rely on you to explain what’s going on under the hood with the software. 
</p>



<p>
My average day consists of reviewing pull requests and working on my own pull requests. Occasionally, I’ll have meetings to sync on the state of my team or the company or run interviews for candidates.
</p>
<p>
My experience with my side project gave me a pretty good idea of the technical challenges I would face in my day-to-day. I would say one thing that surprised me was how open people were to my questions. This made it easier for me to grow as an engineer since I was surrounded by people who wanted to help me learn. A piece of advice I’d give to new engineers is to try to solve a problem or understand a concept on your own first before asking the questions. 
</p>
          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816355</guid>
            <pubDate>Mon, 13 Jul 2020 01:39:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bringing GPU Acceleration to Inkscape, Week 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816235">thread link</a>) | @shahreel
<br/>
July 12, 2020 | https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/ | <a href="https://web.archive.org/web/*/https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
      
<h2>
  Bringing GPU Acceleration to Inkscape, Week 2
</h2>
<p>Published the <time datetime="2020-06-12T20:02:31+02:00">2020-06-12</time></p>
<p>Hello everyone!</p>
<p>For the past two weeks since the beginning of this <a href="https://summerofcode.withgoogle.com/organizations/6070010742571008/#5859756641615872">GSoC
2020</a>
I have attempted to integrate <a href="https://github.com/servo/pathfinder">Pathfinder</a>
into Inkscape, in order to draw (and refresh!) the canvas much faster by using
your GPU.</p>
<p>After some early attempts, where I created a C++ Inkscape extension opening
Pathfinder’s demo on the current SVG, and another extension which was basically
a copy of <a href="https://github.com/servo/pathfinder/blob/master/examples/c_canvas_glfw_minimal/c_canvas_glfw_minimal.c">Pathfinder’s C canvas
example</a>,
I’ve started to properly integrate it into Inkscape’s widgets.</p>
<p>That’s where the fun began, here is a small tour of the fun bugs I encountered:</p>
<h3 id="using-apitrace-on-wayland-can-be-interesting">Using <code>apitrace</code> On Wayland Can Be Interesting</h3>
<p><a href="https://apitrace.github.io/"><code>apitrace</code></a> is a very handy tool for debugging
OpenGL applications, it avoids having to understand the code’s structure, and
allows me to focus on the actual behaviour from the driver’s point of view.</p>
<pre><code><span>glXGetCurrentContext() not found: /usr/bin/../lib/apitrace/wrappers/egltrace.so: undefined symbol: glXGetCurrentContext
apitrace: warning: caught signal 6
</span></code></pre>
<p>I was a bit sad to see that a bug I found at the intersection of
<a href="https://github.com/apitrace/apitrace/issues/380">apitrace</a> and
<a href="https://github.com/anholt/libepoxy/issues/68">libepoxy</a> back in 2015
reappeared now, this time caused by GDK doing the same.  In the end I rebuilt
both libepoxy and GTK+ with only their Wayland backend so they wouldn’t be
tempted to call GLX symbols.  This breaks Firefox and probably some other
software which link against their X11 symbols, but on my build/testing machine
it’s fine.</p>
<p>Speaking of running a (soon-to-be) OpenGL program on a remote machine,
<a href="https://gitlab.freedesktop.org/mstoeckl/waypipe">waypipe</a> from last year’s
GSoC is extremely useful, it feels almost instantaneous on my 900&nbsp;KiB/s down
80&nbsp;KiB/s up ADSL connection.  For comparison, I also tried X11 forwarding over
ssh which only shows Inkscape’s window after 1:05, and also mounting the build
directory over sshfs where it takes 1:20 to do the same, and 6:40 (!) to
generate a stack trace in case of a panic.  I probably should have figured that
out during the community bonding period, but I didn’t think of it.</p>
<h3 id="pathfinder-doesn-t-like-to-draw-into-gtk-glarea-very-much">Pathfinder Doesn’t Like To Draw Into <code>Gtk::GLArea</code> Very Much</h3>
<p>I spent quite a few days trying to get Pathfinder to draw into a GTK+ widget,
first inside of Inkscape, then in a <a href="https://linkmauve.fr/files/pathfinder-glarea.tar.xz">testcase
application</a>.  The
<code>Gtk::GLArea</code> widget lets an application draw using OpenGL.  I want it to
eventually replace Inkscape’s <code>SPCanvas</code>, once I’m done and <a href="https://wiki.inkscape.org/wiki/index.php?title=Inkscape_Canvas">Tavmjong as
well</a>, but in
the meantime I’ll keep them both side-by-side in order to compare their
rendering more easily.</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/empty-glarea.png" alt=""></p>
<p>Despite the rendering being done, according to <code>apitrace</code>’s step-by-step
debugging, the <code>Gtk::GLArea</code> stayed hopelessly black.  Even though I could
render a simple solid colour using <code>glClearColor()</code> and
<code>glClear(GL_COLOR_BUFFER_BIT)</code>, as soon as I tried to render using Pathfinder
it went back to a solid black.</p>
<p>Experimenting with the OpenGL contexts, I could make Pathfinder render its
iconic tiny house everywhere but where I wanted it:</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/almost-but-not-quite.png" alt=""></p>
<p>Here is a particularly trippy rendering I got, when <code>Gtk::GLArea</code> is reading
from a framebuffer Pathfinder hasn’t written into:</p>

<p>It was only with the help of <a href="https://github.com/s3bk">sebk</a> that I finally
figured out that I wasn’t passing the correct
<a href="https://www.khronos.org/opengl/wiki/Framebuffer_Object">fbo</a> to Pathfinder.  I
was passing <code>0</code> which means the default (display’s) framebuffer instead of the
one created for me by GTK+.  With this fixed, everything rendered fine, even on
resize:</p>

<p>After that it was a simple matter of <a href="https://github.com/servo/pathfinder/pull/357">adding some API to Pathfinder’s C
bindings</a> and I can render the
same SVG as Inkscape!</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/same-svg.png" alt="">
On the left hand side we can see <a href="https://poez.io/">poezio</a>’s logo rendered by
Inkscape with cairo; on the right hand side the same logo being serialised and
passed to Pathfinder to be rendered on the GPU.</p>
<p>And this concludes my first progress report of this GSoC, a big thanks to
ebassi, halfline and Neville[m] from
<a href="xmpp:%23gtk%irc.freenode.net@irc.jabberfr.org?join">#gtk</a>, and especially sebk
from <a href="xmpp:%23pathfinder%23mozilla.org@matrix.org?join">#pathfinder</a>, who
helped me a lot in that process!</p>


    </div>
  </section></div>]]>
            </description>
            <link>https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816235</guid>
            <pubDate>Mon, 13 Jul 2020 01:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuzz Week 2020 – Come Learn the Basics to Advanced of Fuzzing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816110">thread link</a>) | @gamozolabs
<br/>
July 12, 2020 | https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html | <a href="https://web.archive.org/web/*/https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>Welcome to fuzz week 2020! This week (July 13th - July 17th) I’ll be streaming
every day going through some of the very basics of fuzzing all the way to
cutting edge research. I want to use this time to talk about some things
related to fuzzing, particularly when it comes to benchmarking and comparing
fuzzers with each other.</p>



<p>Ha. There’s really no schedule, there is no script, there is no plan, but
here’s a rough outline of what I want to cover.</p>

<p>I will be streaming on my <a href="https://twitch.tv/gamozo">Twitch channel</a> at approximately
<a href="https://www.timeanddate.com/worldclock/fixedtime.html?msg=Fuzz+Week+Approx+Stream+Start&amp;iso=20200713T14&amp;p1=234">14:00 PST</a>. But things aren’t really going to be on a strict schedule.</p>

<p>My <a href="https://twitter.com/gamozolabs">Twitter</a> is probably the best source of information for when
things are about to start.</p>

<p>Everything will be recorded and uploaded to my <a href="https://www.youtube.com/user/gamozolabs">YouTube</a>.</p>

<h4 id="july-13th">July 13th</h4>

<p>The very basics of fuzzing. We’ll write our own fuzzer and tweak it to improve
it. We’ll probably start by writing it in Python, and eventually talk about the
performance ramifications and the basics of scaling fuzzers by using threads or
multiple processes. We’ll also compare our newly written fuzzer against AFL and
see where AFL outperforms it, and also where AFL has some blind spots.</p>

<h4 id="july-14th">July 14th</h4>

<p>Here we’ll cover code coverage. We might get to this sooner, who knows. But
we’re going to write our own tooling to gather code coverage information such
that we can see not only how easy it is to set up, but how flexible coverage
information can be while still proving quite useful!</p>

<h4 id="july-15th-17th">July 15th-17th</h4>

<p>Here we’ll focus mainly on the advanced aspects of fuzzing. While this sounds
complex, fuzzing really hasn’t become that complex yet, so follow along! We’ll
go through some of the more deep performance properties of fuzzing, mainly
focused around snapshot fuzzing.</p>

<p>Once we’ve discussed some basics of performance and snapshot fuzzing, we’ll
start talking about the meaningfulness of comparing fuzzers. Namely, the
difficulties in comparing fuzzers when they may involve different concepts of
what a crash, coverage, or input are. We’ll look at some existing examples of
papers which compare fuzzers, and see how well they actually prove their point.</p>



<p>I think it’s important when doing something like this, to make it clear what my
existing biases are. I’ve got a few.</p>

<ul>
  <li>I think existing fuzzers have some major performance problems and struggle to
scale. I consider this to be a high priority as general performance
improvements to fuzzing harnesses makes both generic fuzzers (eg. AFL,
context-unaware fuzzers) and hand-crafted (targeted) fuzzers better.</li>
  <li>I don’t think outperforming AFL is impressive. AFL is impressive because it’s
got an easy-to-use workflow, which makes it accessible to many different
users, broadening the amount of targets it has been used against.</li>
  <li>I don’t really thinking comparing fuzzers is reasonable.</li>
  <li>I think it is very easy to over-fit a fuzzer to small programs, or add
unrealistic amounts of information extraction from a target under test, in a
way that the concepts are not generally applicable to many targets that
exceed basic parsers. I think this is where a lot of current research falls.</li>
</ul>

<p>But… that’s mainly the point of this week. To either find out my biases are
wildly incorrect, or to maybe demonstrate why I have some of the biases. So,
how will I address some of these (in order of prior bullets)?</p>

<ul>
  <li>I’ll compare some of my fuzzers against AFL. We’ll see if we can outperform
AFL in terms of raw fuzz cases performed, as well as the results (coverage
and crashes).</li>
  <li>I’ll try to demonstrate that a basic fuzzer with 1/100th the amount of code
of AFL is capable of getting much better results, and that it’s really not
that hard to write.</li>
  <li>I’ll propose some techniques that can be used to compare fuzzers, and go
through my own personal process of evaluating fuzzers. I’m not trying to get
papers, or funding, or anything. I don’t really have an interest in making
things look comparatively better. If they perform differently, but have
different use cases, I’d rather understand those cases and apply them
specifically rather than have a one-shoe-fits-all solution.</li>
  <li>I’ll go through some instrumentation that I’ve historically added to my
fuzzers which give them massive result and coverage boosts, but consume so
much information that they cannot meaningfully scale past tiny pieces of
code. I’ll go through when these things may actually be useful, as sometimes
isolating components is viable. I’ll also go through some existing papers and
see what sorts of results are being claimed, and if they actually have
general applicability.</li>
</ul>



<p>It’s important to note, nothing here is scheduled. Things may go much faster,
slower, or just never happen. That’s the beauty of research. I may be very
wrong with some of my biases, and we’ll hopefully correct those. I love being
wrong.</p>

<p>I’ve maybe thought of having some fuzzing figureheads pop on the stream for
random discussions/conversations/interviews. If this is something that sounds
interesting to you, reach out and we can maybe organize it!</p>



<p>See you there :)</p>

<hr>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816110</guid>
            <pubDate>Mon, 13 Jul 2020 01:01:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Innovation and the Future of Chemicals in Agriculture]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23815704">thread link</a>) | @kickout
<br/>
July 12, 2020 | https://thinkingagriculture.io/innovation-efficiency-chemicals-in-agriculture/ | <a href="https://web.archive.org/web/*/https://thinkingagriculture.io/innovation-efficiency-chemicals-in-agriculture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-35">
		
	
	<div>
		
<p>Since the early 1900s, agriculture has undergone tremendous change, enabling explosive population growth and changing the literal landscape of many continents in its wake. There were 4 key innovations that have helped propel agriculture from its manual labor intense history of the early 20th century to its massively-scaled, hyper-optimized, technologically savvy industry that exists today in mostly feeds the population of the world:</p>



<ul><li>Mechanization (1850s-current)</li><li>Hybrid maize (courtesy of George Shull, Edward East, George Carter, Henry Wallace, et al. circa 1900-1930)</li><li>Synthetic fertilizer (courtesy of the Haber-Bosch process, circa 1910s)</li><li>Genetic Modification (a.k.a recombinant DNA, circa 1980-1990)</li></ul>



<p>These 4 innovations may seem loosely related on the surface, but they have all coalesced modern agriculture into its hyper efficiency state that currently exists. This hyper-efficient state has evolved side-by-side with the ‘chemical era’ that dominates modern agriculture production practices (<a href="https://en.wikipedia.org/wiki/Norman_Borlaug">courtesy of the Green Revolution</a>). Powerful and effective chemicals help fuel crops growth, kill competing weeds, keep insects away, stabilize agriculture products, and are generally ubiquitous in the supply chain from production to consumption. Despite only synthetic fertilizer being the ‘chemistry’ innovation on the list, each of the other innovations have become reliant on chemicals in one form or another. Mechanization (automation) delivers synthetic fertilizer to nutrient hungry crops, and modern crops enable powerful herbicides and insecticides (through genome modification) to be applied at scales previously unknown. </p>



<p>Let’s pause and clarify some things first: Each of these innovations by themselves are Nobel prize tier worthy (inserting foreign DNA into a completely different species with no negative effects to create resistance to effective herbicides and insects is <em>very much</em> science fiction come to life). Each of these innovations, like most things, have pros and cons. I will always argue the pros have significantly outweighed the cons. Agriculture smartly fused these independent innovations that ultimately enabled grain production to deliver surpluses that previous generations could only dream of. Simply put, much of the world does not worry if there will be enough food to eat (government ineffectiveness and distribution problems notwithstanding). None of this is possible without each of those independent innovations and their synergy.</p>



<p>Modern hybrid corn and most other modern row crops have been purposefully bred to be monsters that needs massive amount of nutrients (Macro-nutrients: nitrogen, phosphorus, potassium, micro-nutrients: iron, manganese,silicon, boron, etc.) to feed their insatiable annual growth. Luckily cheap sources of the most important nutrient (nitrogen) exist–thanks to the Haber-Bosch. To help keep fields of hybrid corn weed-free, <a href="https://en.wikipedia.org/wiki/Recombinant_DNA">recombinant DNA technology</a> enabled conferring resistance to powerful broad-spectrum herbicides (most notably glyphosate). Genome modification has also allowed major row crops to be engineered to <a href="https://lubbock.tamu.edu/files/2018/11/BtTraitTableNov2018.pdf">resist insect pests</a>, and the same logic applies to chemically controlling insect species and it does for weed species. For an individual farmer, these technology make sense as row crops are commodities and the best way to ensure profitability to produce more. Problems arise when <em>every</em> farmer is implementing these technologies and supply outweighs demand.</p>



<h4>Success(?)</h4>



<p>While net positive by a large margin, the scale of modern agriculture makes everything magnified, even potentially small issues. Synthetic nitrogen fertilizer was a boon, but some of that nitrogen washed into rivers and streams in the Midwest (North America) and ultimately ended up in the Gulf of Mexico and since ~1970 we now have a hypoxic “Dead Zone”. No one predicted this second order effect because, in general, models could not properly extrapolate to something of the scale of modern agriculture. Similarly, recombiant DNA has allowed 1.6 billion kilograms of glyphosate to be sprayed since its inception in 1974. It is a stunning achievement and a nod to the general safety of glyphosate that there have been minimal, if any, large scale negative effects. Undoubtedly the largest problem has been the predictable shift (via natural selection and mutation) in weed species populations towards <a href="https://www.extension.purdue.edu/extmedia/gwc/gwc-1.pdf">glyphosate resistance</a> which has considerably lowered the efficacy of the chemical for its intended use. Weed species overcame one of the most powerful and safest herbicides ever invented in a mere ~25 years (<a href="http://sitn.hms.harvard.edu/flash/2015/from-corgis-to-corn-a-brief-look-at-the-long-history-of-gmo-technology/">GMO row crops were introduced</a> in the market ~ 1996) The life span for glyphosate as an <em>effective</em> tool for use at agriculture’s scale will ultimately be small (&lt;50 years) even with drastic changes to its use. Other <a href="https://ag.purdue.edu/btny/weedscience/Documents/Herbicide_MOA_CornSoy_12_2012%5B1%5D.pdf">modes of action</a> (MOA) herbicides are facing similar fates. Worse yet, there are no new promising MOA in R&amp;D pipelines despite decades of attempts. Scientists may discover them; but from a classical broad-spectrum herbicide perspective it is hard to justify the cost of engineering modified plants to resist them given the past ~25 years of resistant soybean,maize,cotton, and other crops. These powerful technologies delivered on their promises but likely kneecapped themselves in the process.</p>



<p>Chemicals aren’t limited to applications to growing plants, in fact many row crop seeds that get planted are <em><a href="http://npic.orst.edu/ingred/ptype/treated-seed.html">treated</a></em> with either insecticides or fungicides. Neonicotinoids are a class of chemicals in this space, that have been receiving much <a href="https://news.uoguelph.ca/2019/04/neonics%E2%80%AFhinder-bees-ability-to-fend-off-deadly-mites-u-of-g-study-reveals%E2%80%AF/">negative news</a> about what these chemicals do to bee populations.</p>



<h4>The Future of Chemicals in Agriculture?</h4>



<p>The chemical era for weed control is peaking in production agriculture. The decline of the chemical weed control in agriculture <em>should</em> coincide with the rise of ‘smart’ machines (macro or nano) that are fitted with autonomous guidance systems, arrays of sensors, and machine learning software that are able to control weeds at the scale of tens of millions of acres. Most of this technology exists today and is mature enough (e.g. geofencing these smart machines). Even better, the prices people are willing to pay are already known. U.S <a href="https://www.extension.iastate.edu/agdm/crops/html/a3-10.html">farmers spend</a> anywhere from $20-$100 <em>per acre</em> to control weed in fields (as a reminder there are 240M+ acres <em>every year</em> of maize,soybean,cotton,wheat). This is an <a href="https://www.agriculture.com/technology/robotics/the-future-of-robotic-weeders">active startup area</a>, but I don’t think most Silicon Valley venture capitalist quite understand the scale of agriculture and the imminent decline of chemicals in agriculture for certain aspects (namely, weed control). Most popular herbicides have problems with efficacy biological speaking, but the legal status of many of these chemicals is becoming increasingly bearish. <a href="https://www.epa.gov/ingredients-used-pesticide-products/registration-dicamba-use-dicamba-tolerant-crops">Dicamba</a>, <a href="https://www.nytimes.com/2020/06/24/business/roundup-settlement-lawsuits.html">glyphosate</a>, <a href="https://www.agriculture.com/news/crops/enlist-duo-herbicide-under-fire-by-ninth-circuit-court-of-appeals">2,4-D</a> (all popular herbicides) have suffered legal set backs recently–there are plenty of <a href="https://www.reuters.com/article/dupont-lawsuits/judge-approves-dupont-settlement-of-herbicide-lawsuits-idUSL1N0BD38420130213">lesser known ones</a> too. Declining chemical efficacy + murky legal status = a multi-billion dollar market up for grabs. </p>



<p>The future of insect control in agriculture is decidedly more murky. Insects have been one of the most successful clades of life that have resisted many of humans efforts–intentional or not–to control them. Insects are flat out hard to control at any meaningful scale. With that said, insecticide use in agriculture <em>is</em> successful (<a href="https://seedinnovation.ca/wp-content/uploads/2011/08/Value-of-Seed-Treatments-Final.pdf">seed applied treatments work too</a>), but like herbicides, evolution is relentlessly catching up and will render existing MOAs ineffective sooner than later (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4193182/">pyrethroid resistance is a good example</a>). <em>Unlike</em> herbicides, there is no easy solution that emerging technology seems to address. <a href="https://www.pnas.org/content/116/16/7692">Gene drives</a> may be effective, but because agriculture’s scale is so large its hard to use <a href="https://www.reuters.com/article/us-burkina-malaria/scientists-release-sterile-mosquitoes-in-burkina-to-fight-malaria-idUSKBN1W310X">laboratory generated data</a> to predict effectiveness. We are slowly learning the <a href="https://www.nature.com/articles/s41598-019-49660-6">problem is more complex than thought</a>, and 2nd and 3rd order effects might do more harm than good. Machines have been unable to control insects in any meaningful way. Applying <em>any</em> technology at this scale is as much an exercise in risk management as any biological challenge. </p>



<p>Replacing synthetic fertilizer with more ‘natural’ sources may not be the answer either. Although this is a potentially exciting area (redistributing nutrients from an source with a surplus to a source that needs it) there is nothing inheriting wrong with synthetic fertilizer, the majority of problems come from over-application and unintended movement. This is easily solved or reduced by at least an order of magnitude with the same technology needed for autonomous weed control. Plants need specific nutrients at specific times in their grow cycle. Existing technology does not provide ways to deliver these nutrients without causing excessive harm (e.g. <a href="https://www.pioneer.com/us/agronomy/nitrogen_application_timing.html">maize needs roughly half of its nitrogen</a> when the plants are too tall to be delivered with existing tractor technology–you’ll run over too many plants). We already have optimized <a href="https://www.sciencedirect.com/science/article/pii/S0048969720313632">nutrient timing and application</a> to plants as much as possible (a farmer will work hard to ensure nitrogen he paid for gets used instead of wasted) given existing technology. The next step change in this space will rely on getting nutrients into fields without damage to growing plants (i.e lightweight autonomous machines). Drones, while promising, will need bigger payloads to be competitive in this space.</p>



<p>Hybrid maize isn’t going away and remains a powerful tool. However, its breeding history has been defined by cramming as many plants into a acre as possible and have the best responses to human applied fertilizers and chemicals. Maize as a species will bend where we want it to bend, and if we need to modify maize to be more conducive to autonomous machine assisted farming that is very achievable.</p>



<p>The point is: Modern agriculture is probably <em>too</em> efficient–driven by the 4 listed elements above and the regulatory system they operate in today– to the detriment of producers (who suffer low prices due to overproduction) and consumers (who pay the negative externalities cost). Perhaps it is time to focus some …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thinkingagriculture.io/innovation-efficiency-chemicals-in-agriculture/">https://thinkingagriculture.io/innovation-efficiency-chemicals-in-agriculture/</a></em></p>]]>
            </description>
            <link>https://thinkingagriculture.io/innovation-efficiency-chemicals-in-agriculture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23815704</guid>
            <pubDate>Sun, 12 Jul 2020 23:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detecting Face Features and Applying Filters with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23815474">thread link</a>) | @bajcmartinez
<br/>
July 12, 2020 | https://livecodestream.dev/post/2020-07-12-detecting-face-features-and-applying-filters-with-javascript/ | <a href="https://web.archive.org/web/*/https://livecodestream.dev/post/2020-07-12-detecting-face-features-and-applying-filters-with-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <figure>
                
                <img alt="Feature Image" src="https://livecodestream.dev/post/2020-07-12-detecting-face-features-and-applying-filters-with-javascript/featured_hu9ca85cef5497cf5468ac175344e0be45_226743_680x0_resize_q75_box.jpg">
            </figure>
            <p>Some days ago I posted an article on <a href="https://livecodestream.dev/post/2020-07-03-detecting-face-features-with-python/">“Detecting Facial Features with Python”</a> and I got many questions from people on <a href="https://twitter.com/bajcmartinez">twitter</a> on how to do that with JavaScript. Today we are going to be answering that and we will add some extras like masking your face with a spiderman filter, or  the classic, dog filter. It has been super fun to work on this project and I hope you enjoy it.</p>
<p>The article will cover two main topics:</p>
<ul>
<li>Face features recognition</li>
<li>Adding filters</li>
</ul>
<hr>
<h2 id="how-to-detect-facial-features">How to detect facial features?</h2>
<p>Similarly to how DLib works, for JavaScript, we have a library called <a href="https://github.com/auduno/clmtrackr">clmtrackr</a> which will do the heavy work of detecting where the face is on an image, and will also identify face features such as nose, mouth, eyes, etc.</p>
<p>This library provides some generic models which are already pre-trained and ready to use following the numbering of the features as follows:</p>







    
        
        
    


<figure data-src="/post/2020-07-12-detecting-face-features-and-applying-filters-with-javascript/face_model.png">
<img src="https://livecodestream.dev/post/2020-07-12-detecting-face-features-and-applying-filters-with-javascript/face_model.png" alt="Point Map"> <figcaption>
    <p>Point Map</p>
</figcaption>
</figure>

<p>When we process an image with the library, it will return an array for each of the points on that map, where each point is identified by its position on <code>x</code> and <code>y</code> axis. This will turn out very important when we are building the filters. As you can already probably guess, if we want to draw something replacing the nose of the person, we can use the point <code>62</code> which is the center of the nose.</p>
<p>But enough theory, let’s start working on something cool!</p>
<hr>
<h2 id="what-are-we-building">What are we building?</h2>
<p>In this article, we will make use of <code>clmtrackr</code> to identify faces on a video stream (in our case a webcam or camera) and apply custom filters that can be selected by a dropdown on the screen. Here is the demo of the app on codepen (please make sure you allow in your browser for the app to access the camera, otherwise it won’t work):</p>








<p>Awesome! It may not be perfect but looks amazing!</p>
<p>Let’s break the code down and explain what we are doing.</p>
<hr>
<h2 id="basic-code-structure">Basic code structure</h2>
<p>To build the app we are using <a href="https://p5js.org/">p5.js</a> library, which is a JavaScript library designed for working mainly with canvas, and that fits perfectly for our use case. P5JS is not your traditional UI library, it instead works with events which define when to build the UI, and when to update it. Similarly to some game engines.</p>
<p>There are 3 main events from p5 which I want to cover:</p>
<ul>
<li><code>preload</code>: which is executed right after the library loads and before building any UI or drawing anything on the screen. This makes it perfect to load assets.</li>
<li><code>setup</code>: which is also executed once, right after the <code>preload</code>, and is where we prepare everything and build the initial UI</li>
<li><code>draw</code>: which is a function called in a loop, and it’s executed every time the  system requires to render the screen.</li>
</ul>
<hr>
<h2 id="preload">Preload</h2>
<p>As by definition, we will use the <code>preload</code> event to load the images that we will be using later in the code as follows:</p>
<div><pre><code data-lang="javascript"><span>function</span> <span>preload</span>() {
    <span>// Spiderman Mask Filter asset
</span><span></span>    <span>imgSpidermanMask</span> <span>=</span> <span>loadImage</span>(<span>"https://i.ibb.co/9HB2sSv/spiderman-mask-1.png"</span>);
    
    <span>// Dog Face Filter assets
</span><span></span>    <span>imgDogEarRight</span> <span>=</span> <span>loadImage</span>(<span>"https://i.ibb.co/bFJf33z/dog-ear-right.png"</span>);
    <span>imgDogEarLeft</span> <span>=</span> <span>loadImage</span>(<span>"https://i.ibb.co/dggwZ1q/dog-ear-left.png"</span>);
    <span>imgDogNose</span> <span>=</span> <span>loadImage</span>(<span>"https://i.ibb.co/PWYGkw1/dog-nose.png"</span>);
}
</code></pre></div><p>Very simple. The function <code>loadImage</code> from p5, as you may expect, will load the image and make it available as a P5 Image object.</p>
<hr>
<h2 id="setup">Setup</h2>
<p>Here things get a bit more interesting as it is in here where we load the UI. We will break down the code executed in this event into 4 parts</p>
<h3 id="creating-the-canvas">Creating the canvas</h3>
<p>As we want our code to be responsive, our canvas will have a dynamic size which will be calculated from the window size and using an aspect ratio of 4:3. It’s not ideal to have the aspect ratio in code like that, but we will make some assumptions to keep the code concise for the demo. After we know the dimensions for our canvas, we can create one with the P5 function <code>createCanvas</code> as shown next.</p>
<div><pre><code data-lang="javascript"><span>const</span> <span>maxWidth</span> <span>=</span> Math.<span>min</span>(<span>windowWidth</span>, <span>windowHeight</span>);
<span>pixelDensity</span>(<span>1</span>);
<span>outputWidth</span> <span>=</span> <span>maxWidth</span>;
<span>outputHeight</span> <span>=</span> <span>maxWidth</span> <span>*</span> <span>0.75</span>; <span>// 4:3
</span><span></span>
<span>createCanvas</span>(<span>outputWidth</span>, <span>outputHeight</span>);
</code></pre></div><h3 id="capturing-the-video-stream">Capturing the video stream</h3>
<p>After we have our canvas working we need to capture the video stream from the webcam or camera and place it into the canvas, fortunately P5 makes it very easy to do so with the <code>videoCapture</code> function.</p>
<div><pre><code data-lang="javascript"><span>// webcam capture
</span><span></span><span>videoInput</span> <span>=</span> <span>createCapture</span>(<span>VIDEO</span>);
<span>videoInput</span>.<span>size</span>(<span>outputWidth</span>, <span>outputHeight</span>);
<span>videoInput</span>.<span>hide</span>();
</code></pre></div><h3 id="building-the-filter-selector">Building the filter selector</h3>
<p>Our app is awesome and can provide options for more than one filter, so we need to build a way to select which filter we want to activate. Again… we could get really fancy here, however, for simplicity, we will use a simple dropdown, that we can create using P5 <code>createSelect()</code> function.</p>
<div><pre><code data-lang="javascript"><span>// select filter
</span><span></span><span>const</span> <span>sel</span> <span>=</span> <span>createSelect</span>();
<span>const</span> <span>selectList</span> <span>=</span> [<span>'Spiderman Mask'</span>, <span>'Dog Filter'</span>]; <span>// list of filters
</span><span></span><span>sel</span>.<span>option</span>(<span>'Select Filter'</span>, <span>-</span><span>1</span>); <span>// Default no filter
</span><span></span><span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>selectList</span>.<span>length</span>; <span>i</span><span>++</span>)
{
    <span>sel</span>.<span>option</span>(<span>selectList</span>[<span>i</span>], <span>i</span>);
}
<span>sel</span>.<span>changed</span>(<span>applyFilter</span>);
</code></pre></div><h3 id="creating-the-image-tracker">Creating the image tracker</h3>
<p>The image tracker is an object that can be attached to a video feed and will identify for each frame all the faces and their features. The tracker needs to be set up once for a given video source.</p>
<div><pre><code data-lang="javascript"><span>// tracker
</span><span></span><span>faceTracker</span> <span>=</span> <span>new</span> <span>clm</span>.<span>tracker</span>();
<span>faceTracker</span>.<span>init</span>();
<span>faceTracker</span>.<span>start</span>(<span>videoInput</span>.<span>elt</span>);
</code></pre></div><hr>
<h2 id="drawing-the-video-and-filters">Drawing the video and filters</h2>
<p>Now that everything is set up, we need to update our <code>draw</code> event from P5, to output the video source to the canvas, and apply any filter which is selected. In our case the <code>draw</code> function will be very simple, pushing the complexity into each filter definition.</p>
<div><pre><code data-lang="javascript"><span>function</span> <span>draw</span>() {
  <span>image</span>(<span>videoInput</span>, <span>0</span>, <span>0</span>, <span>outputWidth</span>, <span>outputHeight</span>); <span>// render video from webcam
</span><span></span>
  <span>// apply filter based on choice
</span><span></span>  <span>switch</span>(<span>selected</span>)
  {
    <span>case</span> <span>'-1'</span><span>:</span> <span>break</span>;
    <span>case</span> <span>'0'</span><span>:</span> <span>drawSpidermanMask</span>(); <span>break</span>;
    <span>case</span> <span>'1'</span><span>:</span> <span>drawDogFace</span>(); <span>break</span>;
  }
}
</code></pre></div><hr>
<h2 id="building-the-spiderman-mask-filter">Building the Spiderman mask filter</h2>







    
        
        
    


<figure data-src="/post/2020-07-12-detecting-face-features-and-applying-filters-with-javascript/spiderman-mask-demo.png">
<img src="https://livecodestream.dev/post/2020-07-12-detecting-face-features-and-applying-filters-with-javascript/spiderman-mask-demo.png" alt="Spiderman Mask Filter"> <figcaption>
    <p>Spiderman Mask Filter</p>
</figcaption>
</figure>

<p>Building filters can be an easy or very complex task. It will depend on what the filter is supposed to do. For the Spiderman mask, we simply need to ask the Spiderman mask image to the center of the screen. To do that, we first make sure our faceTracker object actually detected a face by using <code>faceTraker.getCurrentPosition()</code>.</p>
<p>Once we have our face detected we use P5 to render the image using the face point 62, which is the center of the nose as the center of the image, and with width and height which represent the size of the face as follows.</p>
<div><pre><code data-lang="javascript"><span>const</span> <span>positions</span> <span>=</span> <span>faceTracker</span>.<span>getCurrentPosition</span>();
<span>if</span> (<span>positions</span> <span>!==</span> <span>false</span>)
{
    <span>push</span>();
    <span>const</span> <span>wx</span> <span>=</span> Math.<span>abs</span>(<span>positions</span>[<span>13</span>][<span>0</span>] <span>-</span> <span>positions</span>[<span>1</span>][<span>0</span>]) <span>*</span> <span>1.2</span>; <span>// The width is given by the face width, based on the geometry
</span><span></span>    <span>const</span> <span>wy</span> <span>=</span> Math.<span>abs</span>(<span>positions</span>[<span>7</span>][<span>1</span>] <span>-</span> Math.<span>min</span>(<span>positions</span>[<span>16</span>][<span>1</span>], <span>positions</span>[<span>20</span>][<span>1</span>])) <span>*</span> <span>1.2</span>; <span>// The height is given by the distance from nose to chin, times 2
</span><span></span>    <span>translate</span>(<span>-</span><span>wx</span><span>/</span><span>2</span>, <span>-</span><span>wy</span><span>/</span><span>2</span>);
    <span>image</span>(<span>imgSpidermanMask</span>, <span>positions</span>[<span>62</span>][<span>0</span>], <span>positions</span>[<span>62</span>][<span>1</span>], <span>wx</span>, <span>wy</span>); <span>// Show the mask at the center of the face
</span><span></span>    <span>pop</span>();
}
</code></pre></div><p>Pretty cool right?</p>
<p>Now the dog filter works the same way but using 3 images instead of one, one for each ears and one for the nose. I won’t bored you with more of the same code, but if you want to check it out, review the codepen, which contains the full code for the demo.</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>With the help of JavaScript libraries is very easy to identify facial features and start building your own filters. There are a few considerations though that we did not cover in this tutorial. For example, what happens if the face is not straight to the camera? How do we distort our filters so that they follow the curvature of the face? Or what if I want to add 3d objects instead of 2d filters?</p>
<p>I know many of you will play with it and build some cool things, I’d love to hear what you built and if you can also share your examples with me. You can always reach me by on <a href="https://twitter.com/bajcmartinez">twitter</a>.</p>
<p>Thanks for reading!</p>

        </section></div>]]>
            </description>
            <link>https://livecodestream.dev/post/2020-07-12-detecting-face-features-and-applying-filters-with-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23815474</guid>
            <pubDate>Sun, 12 Jul 2020 23:02:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emerson, Self Reliance (modern translation)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23815233">thread link</a>) | @unixhero
<br/>
July 12, 2020 | https://www.youmeworks.com/self_reliance_translated.html | <a href="https://web.archive.org/web/*/https://www.youmeworks.com/self_reliance_translated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><span color="#990000" face="Arial">THE FOLLOWING IS Ralph
            Waldo Emerson's essay, <i>Self-Reliance</i>, translated into
            modern English. I have been studying this essay for years. I
            consider it one of the most significant pieces of writing ever
            written. I once typed the whole essay word for word and printed
            it out on my computer as a booklet. I looked up all the words
            I didn't know, and made footnotes of definitions for each word
            on the page (and there were a lot of them). </span><span face="Arial"><a href="https://www.youmeworks.com/selfreliance.html" target="_blank">Read that here</a></span><span color="#990000" face="Arial">. I put the essay on tape and listened
            to it over and over while driving. And I tried to apply it to
            my life.</span></p>

            <p><span color="#990000" face="Arial">Then, to understand it
            even more deeply, I went over it line by line, trying to write
            what Emerson was saying in my own words. That rewrite project
            is what follows. I do not feel I'm a better writer than Emerson.
            I love his writing. I think it's very powerful. Some of his sentences
            were so well-said, I included them in this translation just because
            I didn't want to leave them out. My motivation for translating
            it came from an entirely different source.</span></p>

            <p><span color="#990000" face="Arial">The idea was inspired by
            a <i>Cliff Notes</i>. I had always considered <i>Cliff Notes</i>
            as a kind of cheating. If you didn't want to read the real book,
            you could read a condensed version that tells you everything
            you need to know to pass a class. Then one day I saw the movie
            <i>Henry V</i>. I really liked it but I only understood about
            half of what was being said. They were speaking English, but
            three things were hindering my understanding:</span></p>

            <blockquote>
              <p><span color="#990000" face="Arial">1. English was spoken differently
              back then. They commonly used words we are now unfamiliar with.</span></p>
              <p><span color="#990000" face="Arial">2. Shakespeare was a poet,
              so he often inverts sentences and uses unusual phrases in order
              to make things sound poetic.</span></p>
              <p><span color="#990000" face="Arial">3. They were speaking with
              an English accent.</span></p>
            </blockquote>

            <p><span color="#990000" face="Arial">Emerson's essay is difficult
            for a modern American today for the first two reasons. Emerson
            used words that, although I can find them in a dictionary, I've
            never heard anyone say. And he was a poet, so some of his phrases
            were meant to be savored rather than read only for their direct
            meaning.</span></p>

            <p><span color="#990000" face="Arial">One day I came across a
            <i>Cliff Notes</i> on <i>Henry V</i> and I was curious what they
            had to say, so I read it and found it a revelation. They explained
            terms and phrases I didn't know. I remember, for example, the
            phrase, "throwing down a gage." The <i>Cliff Notes</i>
            explained this. It is an archaic term that means throwing gloves
            at the feet of someone, which back then meant you were challenging
            the person to a duel. I could have watched <i>Henry V </i>fifty
            times and not ever figured that out. But after I learned it,
            I understood better what was going on when I watched the movie
            again.</span></p>

            <p><span color="#990000" face="Arial">That's what I hope happens
            after you read my translation. I hope you go back and enjoy </span><span face="Arial"><a href="https://www.youmeworks.com/selfreliance.html" target="_blank">Emerson's
            original and eloquent essay</a></span><span color="#990000" face="Arial">,
            and understand it better, and really appreciate his creative,
            powerful prose.</span></p>

            <p><span color="#990000" face="Arial">Here, then, is my translation
            of Ralph Waldo Emerson's essay, <i>Self-Reliance</i>:</span></p>

            <hr>

            <p><span face="Arial">THE OTHER DAY, I read some original statements
            written by a famous painter. Whenever I read something truly
            original, I get a feeling. That feeling is far more valuable
            than the statements themselves. The feeling fills me with a recognition
            of a profound truth: That genius is simply to "believe your
            own thought." "To believe that what is true for you
            in your private heart is true for all [people]."</span></p>

            <p><span face="Arial">Speak what is true for you, and it will
            almost always resonate in others.</span></p>

            <p><span face="Arial">The voice in your own mind is so familiar
            to you that you give it no respect. Instead, you give too much
            weight to the thought of others — your neighbors, your teachers,
            or some great thinker from the past. But what makes great thinkers
            great is that they didn't disregard their own thought. They expressed
            what they truly thought; they listened to their own voice.</span></p>

            <p><span face="Arial">You must learn to detect the light that
            shines from within and pay it more respect than the blinding
            illumination of the great minds of all history. When you look
            at wonderful works of art, let it teach you this.</span></p>

            <p><span face="Arial">Let the flashes of genius that hit your
            mind urge you to stick with your own "spontaneous impression
            with good-humored inflexibility" — especially when
            everyone seems to think otherwise. Speak out what your own perception,
            your own impression tells you is true and speak with boldness
            and trust.</span></p>

            <p><span face="Arial">As Emerson wrote, "envy is ignorance;
            imitation is suicide." You have something unique, original,
            and great to express. Try to imitate someone else and you kill
            off that originality which is you. Envy is a lack of appreciation
            of your own special gifts.</span></p>

            <p><span face="Arial">Nobody knows what your special gifts are,
            and you won't know until you try to express them. Follow your
            own interest. It will lead you where you need to go.</span></p>

            <p><span face="Arial">You are an expression of this vast and
            wondrous universe. You are one of the things the universe is
            doing right now. This immense, mysterious existence is expressing
            itself everywhere at every moment. For the miracle to be expressed
            through you, it will take courage and a firm dedication to truth
            and authenticity. The greatness of the universe cannot be expressed
            by cowards.</span></p>

            <p><span face="Arial">Be brave and true to yourself. Put your
            heart into your work. Do these things with sincerity and you
            come nearer to being what you truly are: A singular expression
            of all existence — a genius, a creator, a redeemer, a healer,
            a teacher, a force for good in the world.</span></p>

            <p><span face="Arial">Trust yourself — not your petty self,
            but that Self you touch in blissful solitude on quiet walks in
            the mountains, that Self you feel when you are at your highest
            best.</span></p>

            <p><span face="Arial">Completely accept your current situation
            — the place and time you live in. Accept it and make something
            magnificent with it. There is no better time. There is nothing
            to wish for. Genius and wisdom arise when you see that the source
            of existence is in your heart and works through your hands.</span></p>

            <p><span face="Arial">You are not a victim of life. You have
            a destiny, a part to play in this awesome universal battle between
            good and evil.</span></p>

            <p><span face="Arial">Look at children. They trust their own
            impression. They haven't learned to calculate how many people
            oppose their purposes and so they don't alter their purposes
            accordingly. If they conceive a purpose, they start to accomplish
            it without any self-censoring calculations.</span></p>

            <p><span face="Arial">Infants do not conform. The adults conform
            to the infant. An infant is charming, attractive, interesting,
            and the adults gather around and try to please him or her. But
            listen: There is something just as charming, just as interesting,
            and just as pleasing about every stage of life, from childhood
            to old age. Infancy has no monopoly on charm.</span></p>

            <p><span face="Arial">Take exactly what you are and find the
            magnificence of it and express it. Do not weep for younger years
            or think things will be great only when you get older. Be exactly
            what you are right now and already your charm starts to manifest.</span></p>

            <p><span face="Arial">It is a healthy attitude to consider conciliatory
            behavior beneath you. In other words, don't try to gain goodwill
            by displaying pleasing behavior. Don't try to beg for peoples'
            approval. That is the attitude of someone who doesn't feel he
            has a right to be what he is, to feel the way he feels, to think
            what he thinks. But you DO have the right.</span></p>

            <p><span face="Arial">Be yourself.</span></p>

            <p><span face="Arial">Don't try to figure out what behavior or
            opinion will make you popular with others. It is disrespectful
            to the grandeur of who you really are. It is selling your soul
            for the low outcome of manipulating the superficial affections
            of others — as if you needed their approval. Be what you
            are. Be indifferent to the judgments of others, not with a thoughtless
            or angry defiance, but with the firm knowledge that you are a
            vital expression of something unspeakably intelligent and good.</span></p>

            <p><span face="Arial">Forget about what you have been before.
            Forget what you've said before. Be what you are now, even if
            it "isn't you" — that is, even if it seems to
            contradict what you or others have pigeonholed you to be. Be
            free. Be the creative force on the crest of the mighty wave of
            this very instant.</span></p>

            <p><span face="Arial">Be exactly what you are right now and what
            will happen? Your truth, your honesty, your authenticity, will
            scare some people, and they will actively try to make you stop
            being true to yourself.</span></p>

            <p><span face="Arial">The world is in a conspiracy …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.youmeworks.com/self_reliance_translated.html">https://www.youmeworks.com/self_reliance_translated.html</a></em></p>]]>
            </description>
            <link>https://www.youmeworks.com/self_reliance_translated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23815233</guid>
            <pubDate>Sun, 12 Jul 2020 22:18:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uncleftish Beholding: An Uploosening of English Cleanness (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23815161">thread link</a>) | @samclemens
<br/>
July 12, 2020 | https://words.usask.ca/helus/2018/03/27/uncleftish-beholding/ | <a href="https://web.archive.org/web/*/https://words.usask.ca/helus/2018/03/27/uncleftish-beholding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							<p><span><a href="https://words.usask.ca/helus/2018/03/27/uncleftish-beholding/#comments">Jump to Comments</a></span></p><p><strong>Alexei Muzyka</strong></p>

<p>Many English words are directly borrowed from, or take influence from many other languages. Loanwords can fill lexical gaps, increase the ways people can say what they want to, and increase the precision of communication in a language. English has borrowed so many foreign words that it might seem impossible that the complex ideas of today’s world could be communicated without loans. However, doing so can show one where English receives new words from, which languages contribute heavily to certain word categories, and how loans are more helpful than harmful.</p>

<p>The practice of removing loans form English is known as by many names like: Pure Anglo-Saxon, or, informally, Anglish (Hofstadter 218). For consistency I will refer to it as Anglish throughout. This form of English seek to eliminate as many non-English, or non-Germanic words as possible from the lexicon and replace them with English or Germanic equivalents. An example of this is the following text, <a href="https://warwick.ac.uk/fac/cross_fac/complexity/people/students/dtc/students2011/maitland/fun/">“Uncleftish Beholding” by Poul Anderson</a>, which aims to explain a complex scientific topic using Anglish (below is the first and last part of the text)(Anderson):</p>
<blockquote><p>For most of its being, mankind did not know what things are made of, but could only guess. With the growth of worldken, we began to learn, and today we have a beholding of stuff and work that watching bears out, both in the workstead and in daily life.</p>

<p>The underlying kinds of stuff are the *firststuffs*, which link together in sundry ways to give rise to the rest. Formerly we knew of ninety-two firststuffs, from waterstuff, the lightest and barest, to ymirstuff, the heaviest. Now we have made more, such as aegirstuff and helstuff.</p>

<p>The firststuffs have their being as motes called *unclefts*. These are mightly small; one seedweight of waterstuff holds a tale of them like unto two followed by twenty-two naughts. Most unclefts link together to make what are called *bulkbits*. Thus, the waterstuff bulkbit bestands of two waterstuff unclefts, the sourstuff bulkbit of two sourstuff unclefts, and so on. (Some kinds, such as sunstuff, keep alone; others, such as iron, cling together in ices when in the fast standing; and there are yet more yokeways.) When unlike clefts link in a bulkbit, they make *bindings*. Thus, water is a binding of two waterstuff unclefts with one sourstuff uncleft, while a bulkbit of one of the forestuffs making up flesh may have a thousand thousand or more unclefts of these two firststuffs together with coalstuff and chokestuff…</p>

<p>Today we wield both kind of uncleftish doings in weapons, and kernelish splitting gives us heat and bernstoneness. We hope to do likewise with togethermelting, which would yield an unhemmed wellspring of work for mankindish goodgain.</p>

<p>Soothly we live in mighty years!</p></blockquote>
<p>Much of this text sounds silly and almost incomprehensible at some points, but upon closer inspection the words that are substituted seem like plausible replacements. Starting with the title “Uncleftish Beholding” is, according to Anderson’s translation, the Anglish equivalent of <em>atomic theory</em>; <em>uncleft</em> meaning unsplittable (<em>atom</em> meaning “indivisible” in Greek) and <em>beholding</em> meaning “to see” (<em>theory</em> meaning “contemplation”<em>, </em>or “spectator” in Greek) (OED s.v <em>atomic</em>, adj, and n. <em>Theory</em>, n). Some more words that are important in the text are: <em>Worldken</em> (meaning “physics”, <em>world </em>“nature” + <em>ken </em>“perception”), <em>firststuff</em> (meaning “element”, <em>first </em>“principle/ fundamental” + <em>stuff </em>“part”), <em>mote</em> (meaning “particle”), <em>kernel </em>(meaning “nucleus”, “nut/ inner part”), and <em>waterstuff </em>(meaning “hydrogen”, <em>water </em>+ <em>stuff </em>“born from/ component”) (OED s.v <em>physics, </em>n, sense 1a<em>. Element, n, </em>sense 1c<em>. Nucleus, </em>n, sense 8<em>. Hydrogen, </em>n, sense a). Also, looking at the context of the words later in the text can show their meaning. For example the sentence says that “Water is a binding of two waterstuff unclefts with one sourstuff uncleft,” which reveals that waterstuff is hydrogen and sourstuff is oxygen, since 2 hydrogen atoms and one oxygen atom make water.</p>
<p>This text can tell one about what English words might be used if we did not have foreign loans, but more importantly why certain words are used, and how they came into English. Many of the replaced words have roots in Greek and Latin, but do not reach the English lexicon directly from those languages. Instead many technical vocabulary that is originally from those two languages arrives through the French language (Durkin 307). An example is the previously mentioned <em>hydrogen</em> (<em>waterstuff</em>). It comes from the French <em>hydrogène</em>, which itself is made from the Greek <em>ὕδωρ</em> (<em>ýdor</em> “water”), and <em>γενής </em>(<em>genís</em> “born from”) (OED s.v, <em>Hydrogen, </em>n, sense a). This is due to scientists still using Latin and sometimes Greek as languages of science throughout Europe during the time these discoveries were being made (Durkin 341). This is also seen as a spike in the influx of Latin and Greek words, along with technical vocabulary into English around the same time (Durkin 309). Texts like “Uncleftish Beholding” show clearly which languages contribute which kind of words. One would expect French to occupy prestige and fashion words, because of its historic relation to England (Durkin, 307). Looking at this text it is clear that Latin and Greek influence lies in the realm of technical and scientific vocabulary. That is not to say that Latin only contributes technical vocabulary; it contributes other words like <em>family, involve,</em> or <em>produce</em> (Márquez 712). These scientific words, like <em>hydrogen, oxygen,</em> and many others, are very important since they filled lexical gaps that English had.</p>
<p>English is known for its robbery from the lexicons of other languages, but this is not a bad thing. Loanwords improve the precision of speech by providing more options to say one thing by filling lexical gaps. At this stage in the history of English the attempt to remove these words would only do more harm than good. Pieces of literature like “Uncleftish Beholding”, however, provide insight into where loans come from and what we would lose if they were given up. Although it would be possible to throw away all loans the benefits that come with them are too valuable to give up.</p>
<p><em>Works Cited:</em></p>
<p>Anderson, Poul (1989). “Uncleftish Beholing.” Warwick, February 12, 2018, <a href="https://warwick.ac.uk/fac/cross_fac/complexity/people/students/dtc/students2011/maitland/fun/">https://warwick.ac.uk/fac/cross_fac/complexity/people/students/dtc/students2011/maitland/fun/</a>. Accessed March 22, 2018.</p>
<p>Durkin, Philip. <em>Borrowed Words: A History of Loanwords in English</em>. Oxford Scholarship Online, 2014. Web. DOI: DOI:10.1093/acprof:oso/9780199574995.001.0001.</p>
<p>Hofstadler, R. Douglas. “Speechstuff and Thoughtstuff: Musings on the Resonances Created by Words and Phrases via the Subliminal Perception of their Buried Parts.” <em>Of Thoughts and Words: The Relation Between Language and Mind</em>, edited by Sture Allén, Imperial College Press, 1995, pp. 217-266. https://doi.org/10.1142/9781908979681_0023.</p>
<p>Marquez, Miguel Fuster. “Renewal of Core English Vocabulary: A Study Based on the BNC.” <em>English Studies</em>, vol. 88, no. 6, Dec. 2007, pp. 699-723. https://doi.org/10.1080/00138380701706385.</p>
<p>[OED]. Oxford English Dictionary Online. Oxford University Press, June 2017, www.oed.com.cyber.usask.ca/view/Entry/89974. Accessed 10 March 2018.</p>
<p><em>Reference:</em></p>
<p>Wikipedia. “Linguistic Purism in English.” Wikipedia, 18 February 2018, <a href="https://en.wikipedia.org/wiki/Linguistic_purism_in_English">https://en.wikipedia.org/wiki/Linguistic_purism_in_English</a>. Accessed March 22, 2018.</p>

							

						</div></div>]]>
            </description>
            <link>https://words.usask.ca/helus/2018/03/27/uncleftish-beholding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23815161</guid>
            <pubDate>Sun, 12 Jul 2020 22:05:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The fastest way to learn a new language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23815088">thread link</a>) | @william_blount
<br/>
July 12, 2020 | https://www.adamtank.com/new-blog/2020/3/2/the-fastest-way-to-learn-a-new-language-act-like-a-child | <a href="https://web.archive.org/web/*/https://www.adamtank.com/new-blog/2020/3/2/the-fastest-way-to-learn-a-new-language-act-like-a-child">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1583206699770" id="item-5e5dd025f31d6249a33b8964"><div><div><div data-block-type="2" id="block-16ea368387762e4de2e8"><div><p>I was two months into my new job in Rio de Janeiro when I asked my co-worker to hand me a hard penis.</p><p>His gaze shifted towards me and his eyes paused, narrowed, and a cheeky grin slowly came across his face. Within ten seconds the normally stoic Jose was on the floor, doubled over laughing. “Oh shit,” I thought, “What did I just say?”</p><p>It wasn’t the first time I’d made a mistake when learning Portuguese and it wouldn’t be the last. Confusing ‘pão duro’ for ‘pau duro’ (the squiggly line, the tilde, above the ‘a’) proved to be the fatal error – instead of asking for bread, like I had intended, I had asked Jose for something very different.</p><p>The nasal tone of the tilde is a critical distinction among many similarly sounding words in Brazilian Portuguese. But no matter how many times I had tried learning the language with audio tapes, YouTube videos, or through immersion, the lesson had never really sunk in until that one fatal error I made with Jose.</p><p>I now pay <em>very close attention</em> to the tilde when speaking Portuguese.</p><p>---------------------------------</p><p>There is a commonly held belief that children learn new languages faster than adults. This is largely attributed to the fact that children’s brains can form new neural pathways at rates far greater than adults – a term known as ‘neuroplasticity’.</p><p>Most parents will tell you their kids have brains like sponges – they soak up anything and everything they hear – and are quick to repeat it. Interestingly, kids seem to exhibit this sponge- like behavior in public places where they utter something like “That’s bullshit!” and leave mom and dad looking at one another thinking ‘I wonder who she heard that from?’</p><p>I agree with science - a child’s developing brain is far more adept at learning new concepts and lessons than your average adult brain. Consequences are high if they don’t – a child that doesn’t learn concepts of hot and cold, safe vs. danger, ways of expressing their wants and needs, or how to play with others is a child that falls behind, often for life. Brains <strong>have to be extremely moldable in youth</strong> – it’s how children learn the lessons required for survival into and throughout adulthood.</p><p>However, when it comes to learning new languages, I believe the science is overvalued and social factors are significantly undervalued. Adults can learn new languages just as fast, if not faster, than children given the same environment, tools, and social support systems.</p><p>Here are a few of the reasons this is true. Some of these I’ve discovered for myself, others are anecdotal:</p><p><strong>1. Adults punish themselves and one another for making speaking mistakes - children don’t.</strong></p><p>Children that misspeak, stutter, or call things by the wrong names don’t criticize themselves or laugh at one another – they just move on with life. Adults often think it’s endearing to hear kids speak to one another with such imperfection and innocence.</p><p>On the other hand, adults that misspeak, stutter, or screw up are made fun of or feel ashamed or embarrassed. There is no safe environment to practice speaking and to become better without the social stigma associated with screwing up.</p><p>The sooner you come to terms with the fact that you will sound completely, utterly, and fabulously stupid when beginning to learn a new language the sooner you will be successful.</p><p>Anxiety, embarrassment, blanking out, and stuttering will be the RULE, not the exception. Learning a new language will not be an overnight success. It will take failure and practice.</p><p><strong>2. Adults try to learn languages by learning grammar. Children learn language through basic stories, songs, and activities.</strong></p><div><p>About every child in the United States knows the book <em>One Fish, Two Fish, Red Fish, Blue Fish</em>. If you haven’t heard of it, here is a sample excerpt:</p><p><em>Brush Brush Brush</em><br><em>Comb Comb Comb</em><br><em>Blue hair is fun to brush and comb.</em><br><em>All girls who like to brush and comb,</em><br><em>Should have a pet like this at home.</em></p></div><p>This is not a book meant to win the Pulitzer prize. Instead, it’s meant to teach kids the importance of simple, basic phrases and words through repetition and rhyming schemes.</p><p>So why is it when adults are learning new words that we feel the need to start by reading the translated equivalent of Shakespeare? Does anyone truly enjoy learning about verb conjugations, grammar rules, tonality, and writing repetitive sentences over and over until their hands hurt?</p><p>The key to learning a new language is to start simple and work your way up, but to do it through the lens of how a child would learn. Read kids books, listen to kids music, watch kids shows, play kids games. Even something as simple as a game of Tag will teach you a great deal about language and tenses – “I’m it!” vs. “You’re it!” vs. “I <em>was</em> it!” vs. “You’re <em>going to be</em> it!”</p><p><strong>3. Adults learn languages because they are forced to. Children learn language because they don’t know any better.</strong>&nbsp;&nbsp;</p><p>Think about the first time you learned any new skill – let’s take riding a bike as an example. You had to be willing to fall and scrape your knees over and over until you finally learned to ride. As a kid learning to ride a bike was something you needed to do to play with the other kids, and falling was part of the learning curve. It was a way of life, just like having to speak in a certain language with your parents or learn to say certain words because you needed to use them.</p><div><p>Adult speakers of multiple languages often say the best way to learn is through immersion - move to the geography the language is spoken and try not to speak your native language at all. Surround yourself in the language from every angle - before long you’ll start picking language up without even knowing it. </p><p>Not everyone can pack up and move to a new country. But everyone can put themselves in situations where they are unknowingly picking up tidbits of a new language and have fun during the experience. Anybody can try meals at new restaurants where the owners/operators speak a different language, search for new Spotify stations that have music in another tongue, or attend local cultural events where someone can learn to appreciate the contrasts and similarities between their language and someone else’s. </p></div><p>-----------</p><p>If learning Portuguese taught me one thing it was this: change the environment, change the outcome. I could’ve never become as proficient in a new language without completely immersing myself, making mistakes, and enjoying the experience for what it was -&nbsp; a chance to learn more about myself and others through a common understanding of language.&nbsp;</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.adamtank.com/new-blog/2020/3/2/the-fastest-way-to-learn-a-new-language-act-like-a-child</link>
            <guid isPermaLink="false">hacker-news-small-sites-23815088</guid>
            <pubDate>Sun, 12 Jul 2020 21:53:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We know you'll cheat before you cheat: China uses AI for exams]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23815042">thread link</a>) | @ArthurOff
<br/>
July 12, 2020 | http://news.eastly.co/issues/eastly-issue-3-we-know-you-ll-cheat-before-you-cheat-263307 | <a href="https://web.archive.org/web/*/http://news.eastly.co/issues/eastly-issue-3-we-know-you-ll-cheat-before-you-cheat-263307">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://news.eastly.co/issues/eastly-issue-3-we-know-you-ll-cheat-before-you-cheat-263307</link>
            <guid isPermaLink="false">hacker-news-small-sites-23815042</guid>
            <pubDate>Sun, 12 Jul 2020 21:47:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Aperio Fuzzer – A mutational fuzzer for testing web APIs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23814913">thread link</a>) | @maxrmk
<br/>
July 12, 2020 | https://aperiosecurity.com/blog/meet-aperio/ | <a href="https://web.archive.org/web/*/https://aperiosecurity.com/blog/meet-aperio/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        </header>
      

      <section itemprop="text">
        
        <p>Aperio is a black-box fuzzer for your web application or API. Seed it with example requests, point it at a testing deployment, and let it find behaviors you didn’t know existed.</p>

<p>Aperio generates reproducible sequences of requests. An example request for a photo sharing site might be:</p>

<h5>Create Album</h5>
<div>

<div>
<h4>Request</h4>
<div><pre><code>POST /api/create-album
{
    name: 'My Album`
}
</code></pre></div></div>

<div>
<h4>Response</h4>
<div><pre><code>HTTP/1.1 200 OK
{
    album_id: <mark>342987</mark>
}
</code></pre></div></div>

</div>
<h5>Delete Album</h5>
<div>

<div>
<h4>Request</h4>
<div><pre><code>POST /api/delete-album
{
    album_identifier: <mark>342987</mark>
}
</code></pre></div></div>



</div>

<h5>Edit Album</h5>
<div>

<div>
<h4>Request</h4>
<div><pre><code>POST /api/edit-album
{
    album_identifier: <mark>342987</mark>
}
</code></pre></div></div>

<div>
<h4>Response</h4>
<div><pre><code>HTTP/1.1 500 Server Error
</code></pre></div></div>

</div>

<p>Notice how the token <code>album_id</code> from the first request flows through to the later responses. Aperio learns these data flows, to generate interesting (and reproducible) sequences.</p>

<p>Aperio is distributed via docker, and is fully cross platform. <a href="https://aperiosecurity.com/blog/installing-aperio/">Give it a try now</a>.</p>

<h3 id="why-make-this">Why make this?</h3>

<p>I was participating in a couple of bug bounty programs on weekends and felt like one of the proverbial “infinite monkeys”, copying data from one request to another to try to find unexpected behaviors.</p>

<p>There are few things more infuriating to most developers than a menial task you just <strong>know</strong> can be automated.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://aperiosecurity.com/blog/meet-aperio/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814913</guid>
            <pubDate>Sun, 12 Jul 2020 21:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[List of online workshops and talks scheduled for JuliaCon 2020 (free to all)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814795">thread link</a>) | @open-source-ux
<br/>
July 12, 2020 | https://pretalx.com/juliacon2020/talk/ | <a href="https://web.archive.org/web/*/https://pretalx.com/juliacon2020/talk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-card">
            <main>
                

                
    
    
    

<nav id="schedule-nav">
    
    
</nav>


    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/JEWE93/"> “Abstraction without Regret: A Cloud Knowledge Graph DB in Julia”</a>
                <small>
                    Molham Aref ·
                    <i>
                        Talk (30 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>We present our use of Julia to build a next-generation knowledge graph database that combines reasoning and learning to solve problems that have historically been intractable. We motivate the need for a database that excels in supporting workloads that mix data management, machine learning, and gra…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/GSXV8H/"> “Accelerating Tensor Computations in Julia on the GPU”</a>
                <small>
                    Katharine Hyatt ·
                    <i>
                        Lightning Talk (10 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>GPU programming is very powerful but sometimes rather opaque to new users. In this talk, I'll show how I took a CPU based code for performing tensor (multi-linear algebra) computations, moved it over to the GPU, and then used some of Julia and NVIDIA's tools to accelerate the code even further. The…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/LEADQ7/"> “Accurate and Efficiently Vectorized Sums and Dot Products”</a>
                <small>
                    François Févotte, Chris Elrod ·
                    <i>
                        Talk (30 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>This talk will present how basic operations on vectors, like summation and dot products, can be made more accurate with respect to Floating-Point arithmetic by using compensated algorithms. The proposed implementation is available in the <a href="https://github.com/JuliaMath/AccurateArithmetic.jl" rel="nofollow">AccurateArithmetic.jl</a> package, and leverages SIMD instruction…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/NPWSWB/"> “A Computational Textbook for Teaching Data Science with Julia”</a>
                <small>
                    Travis DePrato, Raj Rao ·
                    <i>
                        Talk (30 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>Data science and machine learning courses are in high demand with growing enrollments. We discuss our experience teaching a computational DS&amp;ML course with 250+ students that is designed to scale and accommodate hundreds more. We highlight the use of experiential learning, just-in-time presenta…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/8SFYHK/"> “A deep dive into DataFrames.jl indexing”</a>
                <small>
                    Bogumił Kamiński ·
                    <i>
                        Workshop (half day) (3.5 hours)
                        
                    </i>
                </small>
            </h3>
            <p>During this workshop I will explain the design of indexing of the <code>DataFrame</code> type provided by the DataFrames.jl package. Next a detailed discussion of the implementation challenges we faced will be given.</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/QHRQVF/"> “Advanced Metaprogramming Tools”</a>
                <small>
                    Mike Innes ·
                    <i>
                        Talk (30 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>Julia provides an intimidating array of ways to write programs that write programs. There are macros, generated functions, custom compiler passes, ASTs, IRs, DSLs and backends galore. This talk is a deep-dive into all of these tools that will hopefully clarify how and when you'd want to use them, w…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/BSQLL9/"> “Adventures in Avoiding Allocations”</a>
                <small>
                    Brian Jackson ·
                    <i>
                        Lightning Talk (10 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>Lessons learned while achieving a 100x speedup of TrajectoryOptimization.jl by eliminating allocations.</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/DTAFMF/"> “A fast atmospheric radiation code for global circulation models”</a>
                <small>
                    Charlie Kawczynski ·
                    <i>
                        Lightning Talk (10 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>Global circulation models, for numerical weather and climate prediction, spend about 30% of their time in radiation computations. Hence, the performance of atmospheric radiative transfer models (RTMs) is critically important.</p>
<p>We present RRTMGP.jl, a commonly used atmospheric RTM for global circulat…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/J9Q8UR/"> “AMDGPU Computing in Julia”</a>
                <small>
                    Julian P Samaroo ·
                    <i>
                        Lightning Talk (10 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>I will describe the current state of Julia's AMDGPU stack and how it compares<br>
to Julia's CUDA stack, interesting advantages of AMD's ROCm platform that<br>
we can leverage from Julia, as well as my own perspective on the future of<br>
Julia's GPGPU ecosystem.</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/GPFUZR/"> “Analyzing species interaction networks in Julia”</a>
                <small>
                    Francis Banville ·
                    <i>
                        Lightning Talk (10 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>In this talk, we will present three novel and complementary Julia packages that can handle data on species interactions. These packages can be used to import, simulate, analyze, and visualize all sorts of ecological networks, greatly simplifying the study of this emerging subfield of biology.</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/ZMHR9V/"> “A Parallel Time-Domain Power System Simulation Toolbox in Julia”</a>
                <small>
                    Michael Kyesswa ·
                    <i>
                        Lightning Talk (10 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>This talk introduces a new flexible and extendable parallel time-domain simulation toolbox developed in Julia for the analysis of power system dynamics in large networks. The simulation algorithm adapts a parallel-in-space decomposition scheme to a sequential algorithm to create parallelizable task…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/PUHBMG/"> “Applying Differentiable Programming to the Dark Channel Prior”</a>
                <small>
                    tombsvj@ornl.gov ·
                    <i>
                        Lightning Talk (10 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>The Dark Channel Prior was introduced by He, et al. as a method to dehaze a single image. Since its publication in 2010, other authors have sought to improve this dehazing method. Using the parameters that other authors have tuned as a guide, we parameterize the Dark Channel Prior dehazing method a…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/CE7FZA/"> “AugmentedGaussianProcesses.jl, a full Gaussian Process toolkit”</a>
                <small>
                    Théo Galy-Fajou ·
                    <i>
                        Lightning Talk (10 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>Gaussian Processes (GP) are an essential model of Bayesian non-parametrics. While multiple GP packages already exist in Julia such as Stheno.jl or GaussianProcesses.jl, <code>AugmentedGaussianProcesses.jl</code> has a larger scope of applications and is constantly updated with state-of-the-art methods. One of i…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/AD7TQW/"> “AutoMLPipeline: A ToolBox for Building ML Pipelines”</a>
                <small>
                    Dr. Paulito Palmes, PhD ·
                    <i>
                        Talk (30 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>AutoMLPipeline (AMLP) is a package that makes it trivial to create<br>
complex ML pipeline structures using simple<br>
expressions. AMLP leverages on the built-in<br>
macro programming features of Julia<br>
to symbolically process, manipulate<br>
pipeline expressions, and<br>
makes it easy to discover optimal structures<br>
f…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/B3VAGU/"> “Auto-Optimization and Parallelism in DifferentialEquations.jl”</a>
                <small>
                    Chris Rackauckas ·
                    <i>
                        Talk (30 minutes)
                        
                    </i>
                </small>
            </h3>
            <p>You might not know all of the latest methods in differential equations, all of the best knobs to tweak, <br>
 how to properly handle sparsity, or how to parallelize your code. Or you might just write bad code. Don't you wish someone would just fix that for you automatically? It turns out that the lates…</p>
            
            
            <hr>
            
        </section>
    
        <section>
            <h3>
                <a href="https://pretalx.com/juliacon2020/talk/AWYKZL/"> “Bayesian Agent-Based Monte Carlo Option Pricing with Julia”</a>
                <small>
                    Tyler Brough ·
  …</small></h3></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pretalx.com/juliacon2020/talk/">https://pretalx.com/juliacon2020/talk/</a></em></p>]]>
            </description>
            <link>https://pretalx.com/juliacon2020/talk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814795</guid>
            <pubDate>Sun, 12 Jul 2020 21:10:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating randomness Without Math.random]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23814713">thread link</a>) | @healeycodes
<br/>
July 12, 2020 | https://healeycodes.com/creating-randomness/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/creating-randomness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In JavaScript, you can create random numbers using <code>Math.random()</code>. But what if we wanted to create our own random values in the browser without this function?</p>
<p>The <a href="https://tc39.es/ecma262/#sec-math.random">ECMAScript Language Specification</a> defines the requirements of <code>Math.random()</code>:</p>
<blockquote>
<p>Returns a Number value with positive sign, greater than or equal to 0 but less than 1, chosen randomly or pseudo randomly with approximately uniform distribution over that range, using an implementation-dependent algorithm or strategy. This function takes no arguments.</p>
</blockquote>
<blockquote>
<p>Each Math.random function created for distinct realms must produce a distinct sequence of values from successive calls.</p>
</blockquote>
<h2 id="number-generation"><a href="#number-generation" aria-label="number generation permalink"></a>Number Generation</h2>
<p>Here’s an example of a number generator. It uses a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Closures">closure</a> to maintain internal state and creates a sequence of numbers based off an initial seed value. Here the seed is fixed and is always initialized to <code>0</code>.</p>
<div data-language="javascript"><pre><code>Math<span>.</span>random <span>=</span> <span>(</span><span>function</span> <span>(</span><span>)</span> <span>{</span>
  <span>let</span> seed <span>=</span> <span>0</span>
  <span>return</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
    seed <span>+=</span> <span>1</span>
    <span>return</span> seed
  <span>}</span>
<span>}</span><span>)</span><span>(</span><span>)</span>


Math<span>.</span><span>random</span><span>(</span><span>)</span> 
Math<span>.</span><span>random</span><span>(</span><span>)</span> 
Math<span>.</span><span>random</span><span>(</span><span>)</span> </code></pre></div>
<p>A <strong>pseudorandom number generator</strong> (PRNG) works in a similar manner. A PRNG maintains an internal state and applies math to that state every time a new random number is requested. The seed can be manual or automatic. In the <a href="https://golang.org/pkg/math/rand/#New">Go programming language</a>, you must seed <code>math/rand</code> yourself. In the browser, <code>Math.random</code> requests random data under the hood from the operating system (OS) to use as a seed.</p>
<p>PRNGs are deterministic. The same seed will always produce the same sequence of numbers. Often, a deterministic outcome is preferred. For example, to generate the same random events on all clients without them having to talk over a network. Or for reproducible performance benchmarks.</p>
<p>A hash function can be used to create a PRNG. In <a href="https://github.com/v8/v8/blob/4b9b23521e6fd42373ebbcb20ebe03bf445494f9/benchmarks/spinning-balls/v.js">spinning-balls</a>, one of Chrome’s benchmarks, we can see an example of this:</p>
<div data-language="javascript"><pre><code>



Math<span>.</span>random <span>=</span> <span>(</span><span>function</span> <span>(</span><span>)</span> <span>{</span>
  <span>var</span> seed <span>=</span> <span>49734321</span>
  <span>return</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
    
    seed <span>=</span> seed <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>+</span> <span>0x7ed55d16</span> <span>+</span> <span>(</span>seed <span>&lt;&lt;</span> <span>12</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>^</span> <span>0xc761c23c</span> <span>^</span> <span>(</span>seed <span>&gt;&gt;&gt;</span> <span>19</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>+</span> <span>0x165667b1</span> <span>+</span> <span>(</span>seed <span>&lt;&lt;</span> <span>5</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span><span>(</span>seed <span>+</span> <span>0xd3a2646c</span><span>)</span> <span>^</span> <span>(</span>seed <span>&lt;&lt;</span> <span>9</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>+</span> <span>0xfd7046c5</span> <span>+</span> <span>(</span>seed <span>&lt;&lt;</span> <span>3</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    seed <span>=</span> <span>(</span>seed <span>^</span> <span>0xb55a4f09</span> <span>^</span> <span>(</span>seed <span>&gt;&gt;&gt;</span> <span>16</span><span>)</span><span>)</span> <span>&amp;</span> <span>0xffffffff</span>
    <span>return</span> <span>(</span>seed <span>&amp;</span> <span>0xfffffff</span><span>)</span> <span>/</span> <span>0x10000000</span>
  <span>}</span>
<span>}</span><span>)</span><span>(</span><span>)</span></code></pre></div>
<p>Like our number generator, it alters its internal state while calculating the next random number. This state-change allows the next call to produce a different number.</p>
<h2 id="more-on-pseudorandom-number-generators"><a href="#more-on-pseudorandom-number-generators" aria-label="more on pseudorandom number generators permalink"></a>More on Pseudorandom Number Generators</h2>
<p>One of the oldest and most well known types of PRNG is the <a href="https://en.wikipedia.org/wiki/Linear_congruential_generator">linear congruential generator</a> (LCG). Which, despite its somewhat scary name, does not require many lines of code.</p>
<p>@bryc provides an example and <a href="https://github.com/bryc/code/blob/master/jshash/PRNGs.md#lcg-lehmer-rng">a warning</a>:</p>
<blockquote>
<p>Commonly called a Linear congruential generator (LCG), but in this case, more correctly called a Multiplicative congruential generator (MCG) or Lehmer RNG. It has a state and period of 2^31-1. It’s blazingly fast in JavaScript (likely the fastest), but its quality is quite poor.</p>
</blockquote>
<div data-language="javascript"><pre><code><span>function</span> <span>LCG</span><span>(</span><span>a</span><span>)</span> <span>{</span>
  <span>return</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
    a <span>=</span> Math<span>.</span><span>imul</span><span>(</span><span>48271</span><span>,</span> a<span>)</span> <span>|</span> <span>0</span> <span>%</span> <span>2147483647</span>
    <span>return</span> <span>(</span>a <span>&amp;</span> <span>2147483647</span><span>)</span> <span>/</span> <span>2147483648</span>
  <span>}</span>
<span>}</span></code></pre></div>
<p>(This is the first time I’ve come across <code>Math.imul()</code> — which provides <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/imul#Description">C-like 32-bit multiplication</a> of the two parameters.)</p>
<p>What does @bryc’s comment, “its quality is quite poor” mean in this context? Well, given certain even seeds, this algorithm has a pattern when the final step (the division) is removed.</p>
<div data-language="javascript"><pre><code>






<span>const</span> <span>LCG</span> <span>=</span> <span>(</span><span>s</span><span>)</span> <span>=&gt;</span> <span>(</span><span>_</span><span>)</span> <span>=&gt;</span> <span>(</span>s <span>=</span> Math<span>.</span><span>imul</span><span>(</span><span>48271</span><span>,</span> s<span>)</span> <span>&gt;&gt;&gt;</span> <span>0</span><span>)</span>
<span>const</span> nxt <span>=</span> <span>LCG</span><span>(</span><span>3816034944</span><span>)</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>9</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>nxt</span><span>(</span><span>)</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span><span>)</span>
<span>}</span>

</code></pre></div>
<p>There are <a href="https://en.wikipedia.org/wiki/Diehard_tests">many</a> ways to test the quality of randomness. Some of the methodology and results of these tests can be understood by a layperson. One of the <a href="https://en.wikipedia.org/wiki/Diehard_tests">Diehard battery of tests</a> plays 200000 games of craps and looks at the distribution of wins and the number of throws each game.</p>
<p>There’s also a test for LCGs called the <a href="https://en.wikipedia.org/wiki/Spectral_test">spectral test</a> which plots the sequence in two or more dimensions. In the example below, we can see the <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplanes</a> that the spectral test measures for.</p>
<center>
<p><img src="https://d33wubrfki0l68.cloudfront.net/940b3280e30ebce96af63d654d461af46f2afc28/26139/9e8cfab758735e8c6d06f733460f6a3f/lcg-3d.gif" alt="Hyperplanes of an LCG in three dimensions"></p>
</center>
<p>A PRNG eventually repeats its sequence. In this context, the <em>period</em> is the length of steps until the cycle repeats. Simpler PRNGs such as <a href="https://github.com/bryc/code/blob/master/jshash/PRNGs.md#mulberry32">Mulberry32</a> have a period as low as ~4 billion whereas the <a href="https://stackoverflow.com/a/38838863">Mersenne Twister</a> has a period of <code>2^19,937 - 1</code>. In 2015, the V8 team <a href="https://v8.dev/blog/math-random">said</a> that their implementation of <code>Math.random()</code> uses an algorithm called <a href="http://vigna.di.unimi.it/ftp/papers/xorshiftplus.pdf">xorshift128+</a> which has a period of <code>2^128 - 1</code>. Its introduction can been seen in <a href="https://github.com/v8/v8/blob/085fed0fb5c3b0136827b5d7c190b4bd1c23a23e/src/base/utils/random-number-generator.h#L102">this diff</a>.</p>
<p>If a PRNG eventually repeats itself, you might wonder why we call it repeatedly. Why not use the first number and then reset the internal state with a new seed? The problem with this is that the seed needs to originate from somewhere. If we continue to ask the OS for more random data there is a chance that the call may block (as the OS waits for more randomness to be generated) and our program will stall.</p>
<h2 id="entropy-required"><a href="#entropy-required" aria-label="entropy required permalink"></a>Entropy Required</h2>
<p>So you’ve settled on a PRNG and replaced <code>window.Math.random</code>. You’ve shipped it to your users and, at first, everyone seems to be happy.</p>
<p>But wait! You forgot about the seed. And now your users are complaining about the sequence of random numbers they get. It’s the same every time their customers’ page loads. All of their software is predictable. As a result, the web games they built are easy to beat.</p>
<p>Huzaifa Sidhpurwala <a href="https://www.redhat.com/en/blog/understanding-random-number-generators-and-their-limitations-linux">reminds us</a>:</p>
<blockquote>
<p>Entropy is the measurement of uncertainty or disorder in a system. Good entropy comes from the surrounding environment which is unpredictable and chaotic.</p>
</blockquote>
<p>When required, the generation of securely random numbers in the browser is performed by <code>Crypto.getRandomValues()</code> from the <a href="https://www.w3.org/TR/WebCryptoAPI/#Crypto-method-getRandomValues">Web Cryptography API</a>. Which is seeded by “a platform-specific random number function, the Unix <code>/dev/urandom</code> device, or other source of random or pseudorandom data.”</p>
<p>The Linux <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/drivers/char/random.c">source</a> suggests where this pseudorandom data can come from:</p>
<blockquote>
<p>Sources of randomness from the environment include inter-keyboard timings, inter-interrupt timings from some interrupts, and other events which are both (a) non-deterministic and (b) hard for an outside observer to measure.</p>
</blockquote>
<p>There are also hardware devices that use <a href="https://en.wikipedia.org/wiki/Hardware_random_number_generator#Quantum_random_properties">quantum mechanical physical randomness</a>.</p>
<p>You can find many <a href="https://en.wikipedia.org/wiki/Random_number_generator_attack#Prominent_examples">prominent examples</a> of random number generator attacks which occurred because the wrong type (or not enough) entropy was used. Cloudflare <a href="https://www.cloudflare.com/learning/ssl/lava-lamp-encryption/">famously</a> uses lava lamps as an entropy source. Since we are not attempting to create a secure algorithm, predictable sources of entropy like time are fine.</p>
<p>We can use <code>Date.now()</code> our seed state. This means that we will get a different random sequence for every millisecond. We could also use <code>performance.now()</code> which returns the length of time since the <a href="https://developer.mozilla.org/en-US/docs/Web/API/DOMHighResTimeStamp#The_time_origin">time origin</a>.</p>
<p>Other possible ways of getting entropy in the browser:</p>
<ul>
<li><code>crypto.getRandomValues</code>, <code>crypto</code> key generation, or similar (feels like cheating)</li>
<li>Mouse/touch events, <a href="https://developer.mozilla.org/en-US/docs/Web/API/Ambient_Light_Events">ambient light events</a>, mic/webcam noise (hard to use on page load)</li>
<li>Geolocation API, Bluetooth API, or similar (need permission, doesn’t work on page load)</li>
<li>WebGL/video performance shenanigans</li>
<li>Most APIs <a href="https://developer.mozilla.org/en-US/docs/Web/API">listed here</a></li>
</ul>
<p>Here’s our slower (because it’s not native code) and unstable (because I haven’t tested it) replacement for <code>Math.random()</code>. Also note that PRNGs have requirements for the seed state (e.g. prime numbers, 128-bit). Our algorithm doesn’t comply with the <a href="http://vigna.di.unimi.it/ftp/papers/ScrambledLinear.pdf">seed recommendations</a> for the Xoshiro family.</p>
<div data-language="javascript"><pre><code>

Math<span>.</span>random <span>=</span> <span>(</span><span>function</span> <span>xoshiro128p</span><span>(</span><span>)</span> <span>{</span>
  
  
  <span>let</span> a <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>,</span>
    b <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>,</span>
    c <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>,</span>
    d <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span>
  <span>return</span> <span>function</span> <span>(</span><span>)</span> <span>{</span>
    <span>let</span> t <span>=</span> b <span>&lt;&lt;</span> <span>9</span><span>,</span>
      r <span>=</span> a <span>+</span> d
    c <span>=</span> c <span>^</span> a
    d <span>=</span> d <span>^</span> b
    b <span>=</span> b <span>^</span> c
    a <span>=</span> a <span>^</span> d
    c <span>=</span> c <span>^</span> t
    d <span>=</span> <span>(</span>d <span>&lt;&lt;</span> <span>11</span><span>)</span> <span>|</span> <span>(</span>d <span>&gt;&gt;&gt;</span> <span>21</span><span>)</span>
    <span>return</span> <span>(</span>r <span>&gt;&gt;&gt;</span> <span>0</span><span>)</span> <span>/</span> <span>4294967296</span>
  <span>}</span>
<span>}</span><span>)</span><span>(</span><span>)</span>

Math<span>.</span><span>random</span><span>(</span><span>)</span> 
Math<span>.</span><span>random</span><span>(</span><span>)</span> </code></pre></div>
<h2 id="so-mission-accomplished"><a href="#so-mission-accomplished" aria-label="so mission accomplished permalink"></a>So, Mission Accomplished?</h2>
<p>Sadly it’s impossible to create a fully ECMAScript compliant replacement for <code>Math.random()</code> since the specification requires “distinct realms [to] produce a distinct sequence of values from successive calls.” A <em>realm</em> roughly means a different global environment (e.g. a different window, or a different <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API">WebWorker</a>). Our version cannot reach outside its realm thus cannot make this guarantee.</p>
<p>However, there have been proposals for a <a href="https://github.com/tc39/proposal-realms">Realms API</a>. It’s not inconceivable that such an API would provide access to something like an incrementing realm id. This would give our algorithm the loophole it needs — access to Realm-unique entropy!</p>
<p><small>Thanks to <a href="https://commons.wikimedia.org/wiki/File:Lcg_3d.gif">JN~commonswiki</a> for the 3D GIF of the spectral test.</small></p></section></div>]]>
            </description>
            <link>https://healeycodes.com/creating-randomness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814713</guid>
            <pubDate>Sun, 12 Jul 2020 20:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Artificial Neural Networks Closer to Animal Brains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814680">thread link</a>) | @maraoz
<br/>
July 12, 2020 | https://maraoz.com/2020/07/12/brains-vs-anns/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/12/brains-vs-anns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p><img src="https://maraoz.com/img/brains-vs-anns/cover.jpg"></p>

<p>Lately, I’ve been thinking and reading a lot about consciousness and how the human mind works. A question that emerges all the time is whether machines can <a href="https://en.wikipedia.org/wiki/Turing_test">emulate human thought</a>. An even more interesting one is whether consciousness (a subjective experience) can arise from a machine, but I’ll leave that discussion for a future post (I’ll need ~20 more years to think about that before I can write about it).</p>

<p>So, how far are we from _behaviorally _imitating a human? Truth is, we achieved a lot in the past 5 years (see <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a>, <a href="https://openai.com/blog/better-language-models/">OpenGPT-2</a>, <a href="https://openai.com/blog/jukebox/">OpenAI Jukebox</a>, <a href="https://en.wikipedia.org/wiki/Tesla_Autopilot">Tesla Autopilot</a>, <a href="https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning">Alphastar</a>, <a href="https://openai.com/blog/openai-five-defeats-dota-2-world-champions/">OpenAI Dota2 Team</a>, <a href="https://openai.com/blog/openai-api/">OpenAI API</a>), but we’re still quite not there. My hunch is that we still can learn a lot from biology’s state of the art. I’ve done some research on differences in how human brains work and how we emulate them using deep neural networks, and what follows is a summary of what I’ve found (and some new ideas).</p>

<figure>
  <img src="https://maraoz.com/img/brains-vs-anns/image1.png">
  <figcaption>
    I find it encouraging that John Carmack is studying human brains for his AI research. <a href="https://twitter.com/ID_AA_Carmack/status/1280693213549002752">Source</a>.
  </figcaption>
</figure>

<h2 id="morphology">Morphology</h2>

<p>The most surprising difference between artificial and human brains is how <em>sequential</em> our artificial neural networks (ANN) are, compared to the richly interconnected biological counterparts.</p>

<p>I’m always amazed by the sheer amount of layers that are stacked on top of each other <a href="https://jalammar.github.io/illustrated-gpt2/">in the latest deep learning models</a>. The largest GPT-3 model (with 175B parameters) uses 96 attention layers, each with 96x 128-dimension heads. <a href="https://arxiv.org/pdf/2005.14165.pdf">Their paper</a> shows that language model performance scales as a power-law with model size.</p>

<p>However, this assumes the size of the network can only increase by adding more layers, making it “deeper”. Using layers enables for great performance in training via <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">backpropagation/ADAM</a>, but I think the current mostly-sequential approach to scaling ANNs is limiting. Some ideas:</p>

<h3 id="wide-vs-deep-neural-networks">Wide (vs. Deep) Neural Networks</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image8.png">
<img src="https://maraoz.com/img/brains-vs-anns/image3.png"></p>

<p>A promising approach is exploring other kinds of architectures, where the concept of “layer” is forgotten, and networks are built more freely (with connections being modelled at the neuron level, and allowing for loops and more complex topologies). This <a href="https://en.wikipedia.org/wiki/Boltzmann_machine">has been somewhat explored in the past</a>, but I haven’t seen recent studies where today’s computing power is thrown at such architectures. Additionally, <a href="https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies">Ken Stanley’s NEAT (2002)</a> and derivatives are a very promising way of finding new topologies via evolution.</p>

<h3 id="neural-grids">Neural Grids</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image6.png"></p>

<p>Another idea worth exploring: grid-like structures where each cell communicates only with its neighbors. In this neural net model, potential is not only passed forward, but also “upward” and “downward”, or even diagonally. This would emulate more closely, I think, a real brain’s connectivity. A related approach is <a href="https://www.mitpressjournals.org/doi/abs/10.1162/artl.2009.15.2.15202">Hypercube-based NEAT (2009)</a>, which allows exploiting the task’s geometry by mapping its regularities onto the topology of the network.</p>

<h3 id="artificial-cortical-columns">Artificial Cortical Columns</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image9.png">
<img src="https://maraoz.com/img/brains-vs-anns/image5.png"></p>

<p>Human’s brain neocortex seems to have a surprisingly self-repeating pattern, called <a href="https://youtu.be/x2mYTaJPVnc?t=98">cortical columns</a>. Each column can be thought of as a reusable ~110 neuron module that appears (with variations) across neocortex areas associated with such different functions as vision, motor control, auditory perception, decision-making, planning, etc. <a href="https://numenta.com/neuroscience-research/cortical-columns/">Studying these structures</a> and applying similar concepts/topologies to ANNs seems like a promising approach. Cortical columns provide amazingly generic hierarchical information processing capabilities, feedback mechanisms, and layered communication with other parts of the brain.</p>

<h3 id="generative-architectures-arising-from-growth">Generative architectures arising from growth</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image10.png"></p>

<p>What if neural net architecture is determined by a generative / procedural algorithm on runtime, instead of being defined by researchers? The seed could be random or evolved through genetic algorithms too. I think that somehow mimicking <a href="https://www.youtube.com/watch?v=BtLyik7oAxc&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=4">neurulation of human embryos</a> via simple models could lead to finding better-performing architectures. Human brains grow into existence, and maybe that matters for high-level intelligence.</p>

<h2 id="function">Function</h2>

<h3 id="evolve-first-learn-later">Evolve first, Learn later.</h3>

<p>Some techniques use <a href="https://www.nature.com/articles/s42256-018-0006-z">neuroevolution used to automate network design</a> or <a href="https://blog.otoro.net/2017/11/12/evolving-stable-strategies/">evolutionary strategies finding network weights instead of gradient descent</a>. It’d be interesting to see hybrid approaches where network structure is evolved and <em>later</em> allowed to learn in an environment (like humans!). Additionally, as I learnt from <a href="https://www.nature.com/articles/s41467-019-11786-6">this fascinating paper by Tony Zador</a> (2019), “A large component of an animal’s behavioral repertoire is not the result of supervised or unsupervised learning, but rather of behavior programs already present at birth”. Learning is actually one of such behaviors, so… shouldn’t researchers be focusing more on optimizing the lower-level mechanism of evolution instead of polishing our “hand-crafted” learning algorithms and architectures?</p>

<p>On a similar ‘meta-learning’ vein, the comically named <a href="http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf">Learning to learn by gradient descent by gradient descent</a> (2016) paper shows that you can train a network to optimize other networks, and they perform better than hand-crafted learning algorithms like <a href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c">ADAM</a> and <a href="https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a">RMSProp</a>.</p>

<h3 id="continuous-vs-discrete-neuron-firing">Continuous (vs. discrete) neuron firing</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image4.png"></p>

<p>Instead of processing inputs in discrete events, our networks could ‘stare’ at inputs for a couple iterations, and neurons can ‘store-up’ potential until they fire. This aims to mimic how we humans can look at something we don’t understand, but after a couple of seconds we “get it”. This could also enable the emergence of “memories” in the form of stored potential, too, analogous to the hidden state vector of LSTMs. Check out <a href="https://www.youtube.com/watch?v=lddzHEtu934">Gabriel Kreiman’s related work (2018)</a> on improving object detection in occluded or distorted conditions. Regardless of the specific implementations mentioned above, biological brains clearly have a temporal dimension (for example, <a href="https://www.youtube.com/watch?v=aFrG7KdjUOs&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=32">neurons in the visual motion MT area respond to direction of motion</a>), which we need to understand better to inform construction of artificial ones. Another interesting time-related property of biological brains is <a href="https://youtu.be/fki7AmLma_I?t=450">the difference between tonic vs bursting modes of neuron firing</a>.</p>

<h3 id="connecting-functional-building-blocks">Connecting functional building blocks</h3>

<p>Animal brains are surprisingly pre-wired and connected since birth, and it’s still not clear in general which behaviors are learned through experience and which are innate. Moreover, a big field of study in neuroscience is understanding how the human brain is wired, mostly via <a href="https://en.wikipedia.org/wiki/Tractography">diffusion tractography</a>, and in some cases <a href="https://youtu.be/KFfaBoDANNI?t=134">it’s been shown that connectivity can predict function</a>. However, the fascinating <a href="https://www.youtube.com/watch?v=8Bvblav-BQk&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=65">‘rewired ferrets’ experiments</a> showed that training input also conditions function strongly (newborn ferrets with auditory cortex rewired to receive visual input still learn to see). This implies that animal brains have a very optimized initial configuration, but also the flexibility to adapt to structural damages or drastical environmental condition changes.</p>

<p>Many well-performing techniques simply stack two architectures that work for two separate domains (eg: CNN visual embedder and LSTM language model) and re-train them for a new combined task (eg: image captioning).</p>

<p><img src="https://maraoz.com/img/brains-vs-anns/image7.png">
<img src="https://maraoz.com/img/brains-vs-anns/image2.png"></p>

<p>I suggest trying to mimic what we know today of how the human brain is wired (from <a href="http://www.humanconnectomeproject.org/">the Human Connectome Project</a>, for example), and plugging in some state-of-the-art modules for vision, language, and audio-processing.</p>

<h3 id="slow-and-data-light-learning">Slow and Data-Light Learning</h3>

<p>Humans seem to learn slowly (in real time, it takes a human ~2 years to learn a language at a basic level, and ~18 years to learn advanced level language usage or complex language tasks like translation) but with few examples. Machines, on the other hand, learn very fast (in the order of weeks to achieve state of the art in some tasks) but are very data-hungry. Some techniques require less training data but might take longer to train, like <a href="https://medium.com/@SmartLabAI/a-brief-overview-of-imitation-learning-8a8a75c44a9c">Imitation Learning</a>, <a href="https://openai.com/blog/competitive-self-play/">Competitive Self-Play</a>, and <a href="https://arxiv.org/abs/2005.11212">Symbolic Pregressions (2020)</a> and could be key to getting closer to human intelligence.</p>

<h3 id="intermixing-learning-techniques">Intermixing Learning Techniques</h3>

<p>A combination of learning strategies could be necessary for human-level intelligence, as Yann LeCun suggests with his cake analogy: “If intelligence is a cake, the bulk of the cake is <a href="https://ai.stackexchange.com/a/10624">self-supervised learning</a>, the icing on the cake is <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, and the cherry on the cake is <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>.”</p>

<p>Humans train by learning from others (supervised learning) <em>and</em> experimenting on our own (unsupervised/self-supervised learning). For example, a chess student first talks to a teacher, then plays some games. They wouldn’t go to a chess tournament after just talking to a teacher or playing games alone. Can we combine/emulate these kinds of training efficiently in ML too?</p>

<h2 id="final-words--further-studying">Final words &amp; further studying</h2>

<p>What do you think of these approaches? Have you actually seen any of these used in the wild (with success or otherwise)? Which do you think may have merits? Let me know if you do some experiments to try them out.</p>

<p>If you’ve been intrigued by the potential of imitating biological brains, here are some up-to-date resources to dig deeper, in order of relevance:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=i1pdQjdAndc&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0">Nancy Kanwisher’s The Human Brain course on YouTube</a> (2018)</li>
  <li><a href="https://www.youtube.com/watch?v=8-KF0rnhKTU&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=2">Ninja Nerd Lectures on Embryology</a> (2019)</li>
  <li><a href="https://www.nature.com/articles/s41467-019-11786-6">A critique of pure learning and what artificial neural networks can learn from animal brains by Anthony M. Zador</a> (2019)</li>
  <li><a href="https://www.youtube.com/watch?v=pkJkHB_c3nA">AI for physics &amp; physics for AI by Max Tegmark</a> (2020)</li>
  <li><a href="https://www.youtube.com/watch?v=x2mYTaJPVnc">Brains Explained video on cortical columns</a> (2017)</li>
  <li><a href="https://www.youtube.com/watch?v=h0InlY2WKc0">Deciphering Brain Codes to Build Smarter AI by Gabriel Kreiman</a> (2020)</li>
</ul>

<p><em>Thanks to Javi Silveira, <a href="https://twitter.com/hardmaru">David Ha (@hardmaru)</a>, <a href="https://twitter.com/alcuadrado">Pato Palladino (@alcuadrado)</a> and <a href="https://twitter.com/itsladywhite">Lady White (@itsladywhite)</a> for providing feedback and pointers.</em></p>

<p><em>Image by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">David Clode on Unsplash</a>.</em></p>


  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/12/brains-vs-anns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814680</guid>
            <pubDate>Sun, 12 Jul 2020 20:55:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The nostalgic world wide web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814631">thread link</a>) | @passbe
<br/>
July 12, 2020 | https://www.passbe.com/2020/07/07/the-nostalgic-internet/ | <a href="https://web.archive.org/web/*/https://www.passbe.com/2020/07/07/the-nostalgic-internet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			<p>A common theme emerges among people born in the 70s and 80s, who grew up when the world wide web (internet) was still young. They miss the "good old days", the pre-2010 internet when things weren't as commercialized. A time when &nbsp;<a href="https://en.wikipedia.org/wiki/Internet_Relay_Chat">IRC</a> and <a href="https://en.wikipedia.org/wiki/Windows_Live_Messenger">MSN Messenger</a> were common place, <a href="https://en.wikipedia.org/wiki/Myspace">MySpace</a> was the new kid on the block and you had bookmarked hundreds of fascinating G<a href="https://en.wikipedia.org/wiki/Yahoo!_GeoCities">eocities</a> sites.</p><p>I too feel this sentiment from time to time and I'm not alone:</p><ul><li><a href="https://www.reddit.com/r/nostalgia/comments/60f73h/anyone_else_nostalgic_for_the_older_internet/">Anyone else nostalgic for the older internet?</a></li><li><a href="https://www.reddit.com/r/nostalgia/comments/7mwmwx/i_miss_the_90s2000s_internet/">I miss the 90s/2000s internet</a></li><li><a href="http://misc-stuff.terraaeon.com/articles/miss-old-internet.html">I miss the old internet</a></li></ul><h3 id="down-the-rabbit-hole-">Down the rabbit hole...</h3><p>We use to spend countless hours browsing one website to another, following the "friends of this website" links going down rabbit holes on topics we never would have encountered otherwise. I remember looking at the clock reading 3am and wondering why I'm still up, reading a website about bee keeping.</p><p>It took me a while to understand exactly what I missed about the nostalgic world wide web.</p><blockquote>I miss the effort</blockquote><p> I miss reading usenet / blogs / websites where a person devoted to that subject puts effort into sharing that information with the world. The website didn't have to be pretty, in most cases they weren't, however I consumed that content knowing this was someones passion - and that made it interesting.</p><p>In a modern internet it takes mere seconds to post content online. We are even encouraged to not try very hard with things like Twitter. It is disappointing.</p><h3 id="there-is-still-hope-">There is still hope!</h3><p>There is plenty of content out there but I believe it is harder to locate due to world wide web being commercialized. Here are some of my favorites:</p><ul><li><a href="https://wiby.me/">Wiby</a> - "The Wiby search engine is building a web of pages as it was in the earlier days of the internet.". I personally bookmark <a href="https://wiby.me/surprise/">Wiby Surprise</a> and discover some fascinating sites.</li><li><a href="https://millionshort.com/">Million Short</a> - "we aim to provide alternative methods for organizing, accessing, and discovering the vast web of information on the Internet". You can easily search for a topic and remove the top n number of popular sites leaving the lesser known possibly more interesting.</li><li><a href="https://reddit.com/">Reddit</a> - Some sub-reddits are amazing communities of people helping each other and sharing content. I use <a href="https://reddit.com/r/random">Reddit Random</a> to find interesting sub-reddits.</li></ul><p>If you struggle to keep track of everything, using an <a href="https://en.wikipedia.org/wiki/RSS">RSS Reader</a> can help. I've used <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> for a long time and its helped me keep up to date with very niche topics. If you do operate a blog or website, <strong>please enable RSS feeds!</strong></p><h3 id="contribute-and-encourage">Contribute and Encourage</h3><p>The world wide web was built for knowledge transfer. If you are passionate about something - share it with the world, there are plenty of places to do this for free online. </p><p>If you come across someones website that you enjoyed, reach out to them. Over the years I have emailed plenty of individuals encouraging them to continue sharing. When you do, they are usually surprised anyone is reading their content and are usually very happy you reached out.</p><p>Please reach out to me if you've had similar experiences.</p>
		</section></div>]]>
            </description>
            <link>https://www.passbe.com/2020/07/07/the-nostalgic-internet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814631</guid>
            <pubDate>Sun, 12 Jul 2020 20:48:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Liner GitLog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814526">thread link</a>) | @mraza007
<br/>
July 12, 2020 | https://knowledge-book.mraza007.now.sh/2020/07/12/git-command/ | <a href="https://web.archive.org/web/*/https://knowledge-book.mraza007.now.sh/2020/07/12/git-command/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<article itemscope="" itemtype="http://schema.org/BlogPosting">
  <header>
    
    <p>
      <time datetime="2020-07-12T00:00:00+00:00" itemprop="datePublished">Jul 12, 2020</time>
      

      
  		

  		
  		

  		·	<span itemprop="tags">
  				
  				
  				<a href="https://knowledge-book.mraza007.now.sh/tagged#git">#git</a>
  			<a href="https://knowledge-book.mraza007.now.sh/tagged#devops">#devops</a>
  			<a href="https://knowledge-book.mraza007.now.sh/tagged#quickhack">#quickhack</a>
  			</span>

  	  

    </p>
  </header>
  <div itemprop="articleBody">
    <p>So I found a useful command that allows you to view entire git log of the repo.</p>

<div><div><pre><code><span>git log --decorate --graph --oneline --all
</span></code></pre></div></div>

<p>This command generates the entire log of the git repo in one line</p>

<p>and if you like to view entire log with commit messages in detail you can run this command</p>

<div><div><pre><code><span>git log --decorate --graph --all
</span></code></pre></div></div>

<p>I hope you found this useful and if you have further tips related to command line feel free to follow me and DM me on <a href="https://twitter.com/muhammad_o7">twitter</a></p>

  </div>
  <hr>
  
<a href="https://knowledge-book.mraza007.now.sh/">Home</a>
<!--<div>-->
  <!-- Remarkbox - Your readers want to communicate with you -->
<!--<div id="remarkbox-div">-->
<!--  <noscript>-->
<!--    <iframe id=remarkbox-iframe src="https://my.remarkbox.com/embed?nojs=true" style="height:600px;width:100%;border:none!important" tabindex=0></iframe>-->
<!--  </noscript>-->
<!--</div>-->
<!--<script src="https://my.remarkbox.com/static/js/iframe-resizer/iframeResizer.min.js"></script>-->
<!--<script>-->
<!--  var rb_owner_key = "79e72a11-4c41-11e9-9d67-040140774501";-->
<!--  var thread_uri = window.location.href;-->
<!--  var thread_title = window.document.title;-->
<!--  var thread_fragment = window.location.hash;-->

<!--  var rb_src = "https://my.remarkbox.com/embed" + -->
<!--      "?rb_owner_key=" + rb_owner_key +-->
<!--      "&thread_title=" + encodeURI(thread_title) +-->
<!--      "&thread_uri=" + encodeURIComponent(thread_uri) + -->
<!--      thread_fragment;-->

<!--  function create_remarkbox_iframe() {-->
<!--    var ifrm = document.createElement("iframe");-->
<!--    ifrm.setAttribute("id", "remarkbox-iframe");-->
<!--    ifrm.setAttribute("scrolling", "no");-->
<!--    ifrm.setAttribute("src", rb_src);-->
<!--    ifrm.setAttribute("frameborder", "0");-->
<!--    ifrm.setAttribute("tabindex", "0");-->
<!--    ifrm.setAttribute("title", "Remarkbox");-->
<!--    ifrm.style.width = "100%";-->
<!--    document.getElementById("remarkbox-div").appendChild(ifrm);-->
<!--  }-->
<!--  create_remarkbox_iframe();-->
<!--  iFrameResize(-->
<!--    {-->
<!--      checkOrigin: ["https://my.remarkbox.com"],-->
<!--      inPageLinks: true,-->
<!--      initCallback: function(e) {e.iFrameResizer.moveToAnchor(thread_fragment)}-->
<!--    },-->
<!--    document.getElementById("remarkbox-iframe")-->
<!--  );-->
<!--</script>-->
<!--</div>-->
</article>

    </div></div>]]>
            </description>
            <link>https://knowledge-book.mraza007.now.sh/2020/07/12/git-command/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814526</guid>
            <pubDate>Sun, 12 Jul 2020 20:33:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text-Only Social Network]]>
            </title>
            <description>
<![CDATA[
Score 384 | Comments 200 (<a href="https://news.ycombinator.com/item?id=23814517">thread link</a>) | @lcnmrn
<br/>
July 12, 2020 | https://subreply.com/trending | <a href="https://web.archive.org/web/*/https://subreply.com/trending">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://subreply.com/trending</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814517</guid>
            <pubDate>Sun, 12 Jul 2020 20:32:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Authenticated Key Exchanges]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814488">thread link</a>) | @ColinWright
<br/>
July 12, 2020 | https://soatok.blog/2020/04/21/authenticated-key-exchanges/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/04/21/authenticated-key-exchanges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Authenticated Key Exchanges are an interesting and important building block in any protocol that aims to allow people to communicate privately over an untrusted medium (i.e. the Internet).</p>



<h2>What’s an AKE?</h2>



<p>At their core, Authenticated Key Exchanges (AKEs for short) combine two different classes of protocol.</p>



<ol><li>An authentication mechanism, such as a MAC or a digital signature.</li><li>Key encapsulation, usually through some sort of Diffie-Hellman.</li></ol>



<p>A simple example of an AKE is the modern TLS handshake, which uses digital signatures (X.509 certificates signed by certificate authorities) to sign ephemeral Elliptic Curve Diffie-Hellman (ECDH) public keys, which is then used to derive a shared secret to encrypt and authenticate network traffic.</p>



<p>I guess I should say “simple” with scare quotes. Cryptography is very much a “devil’s in the details” field, because my above explanation didn’t even encapsulate mutual-auth TLS or the underlying machinery of protocol negotiation. (Or the fact that non-forward-secret ciphersuites can be selected.)</p>



<p>AKEs get much more complicated, the more sophisticated your threat model becomes. </p>



<p>For example: Signal’s X3DH and Double Ratchet protocols are components of a very sophisticated AKE. Learn more about them <a rel="noreferrer noopener" href="https://signal.org/docs/" target="_blank">here</a>.</p>



<p>The IETF is working to standardize their own approach, called <strong>Messaging Layer Security</strong> (MLS), which uses a binary tree of ECDH handshakes to manage state and optimize group operations (called TreeKEM). You can learn more about IETF MLS <a href="https://datatracker.ietf.org/doc/draft-ietf-mls-protocol/">here</a>.</p>



<h2>Password AKEs</h2>



<p>Recently, a collection of cryptographers at the IETF’s Crypto Research Forum Group (CFRG) decided to hammer on a series of proposed Password-Authenticated Key Exchange (PAKE) protocols.</p>



<p>PAKEs come in two flavors: Balanced (mutually authenticated) and augmented (one side is a prover, the other is a verifier). Balanced PAKEs are good for encrypted tunnels where you control both endpoints (e.g. WiFi networks), whereas Augmented PAKEs are great for eliminating the risk of password theft in client-server applications, if the server gets hacked.</p>



<p>Ultimately, the CFRG settled on one balanced PAKE (<a href="https://tools.ietf.org/html/draft-haase-cpace-00" target="_blank" rel="noreferrer noopener">CPace</a>) and one augmented PAKE (<a href="https://eprint.iacr.org/2018/163">OPAQUE</a>).</p>



<p>Consequently, cryptographer Filippo Valsorda managed to implement CPace in 125 lines of Go, using Ristretto255.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I implemented the CPace PAKE yesterday with Go and ristretto255, and it felt like cheating.</p><p>📦 <a href="https://t.co/Q0kI19JOPY">https://t.co/Q0kI19JOPY</a> 📦</p><p>125 lines of code! Really happy with it and it was a lot of fun.</p></div>— Filippo Valsorda 🇮🇹 (@FiloSottile) <a href="https://twitter.com/FiloSottile/status/1244332018047082501?ref_src=twsrc%5Etfw">March 29, 2020</a></blockquote></div>
</div></figure>



<h2>Why So Complicated?</h2>



<p>At the end of the day, an AKE is just a construction that combines key encapsulation with an authentication mechanism.</p>



<p>But how you combine these components together can vary wildly!</p>



<p>Some AKE designs (i.e. Dragonfly, in WPA3) are weaker than others; even if only in the sense of being difficult to implement in constant-time.</p>



<p>The reason there’s so many is that cryptographers tend to <em>collectively</em> decide which algorithms to recommend for standardization.</p>



<p>(n.b. There are a lot more block ciphers than DES, Blowfish, and AES to choose from! But ask a non-cryptographer to name five block ciphers and they’ll probably struggle.)</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/04/21/authenticated-key-exchanges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814488</guid>
            <pubDate>Sun, 12 Jul 2020 20:27:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrate from RAID1 Disk to ZFS on NixOS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814408">thread link</a>) | @immae
<br/>
July 12, 2020 | https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/ | <a href="https://web.archive.org/web/*/https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p><em>As of 2020-06-06 I only made those tests inside a VM (See
<a href="#libvirtd">below</a> if you want to play with it too). I’m not fully at
peace with the process yet to actually apply it on my server. Use at
your own risk!</em></p>
<h2>Context</h2>
<p>I’m the happy owner of a server which holds my whole infrastructure
for more than one year now, powered by NixOS for declarative
deployments. When I installed it the first time, I didn’t know about
ZFS and all its features (see <a href="https://pthree.org/2012/12/04/zfs-administration-part-i-vdevs/">there</a>
if you want some examples)</p>
<p>Since I cannot afford to reinstall everything from scratch, I had to
find a way to deploy ZFS safely (i.e. without losing redundancy).
This article explains step by step the choices I made.</p>
<h2>Setup</h2>
<p>The server has a single relevant partition mounted on <code>/</code> (the other
partitions are BIOS boot and swap, non-relevant here). This partition is
a RAID1 array, backed by two disks. The partition holding <code>/</code> on the
underlying disks is the third one, that is <code>/dev/md0</code> containing
<code>/dev/sda3</code> and <code>/dev/sdb3</code>.</p>
<p>The distribution of my server is NixOS, installed remotely via
nixops. Some commands will rely on that fact below, but might be
adapted depending on your distribution (or if you don’t use
nixops)</p>
<p>I ordrered an additional disk to my server provider
(<code>/dev/sdc</code>). The sole purpose of this disk is to ensure
redundancy in case of failure during the process. The process itself
could be adapted to not need it if you’re confident enough. It can
be thrown away at the end of the process.</p>
<h2><a name="libvirtd"></a> Play with libvirtd</h2>
<p>Since I didn’t want to break my server, I created a libvirtd rough
equivalent of my setup: three disk images, two of them mounted as RAID
array. Since it is a quite specific setup, I couldn’t make a fully
declarative VM handled by nixops, but I still made use of some of
nixpkgs helpers.</p>
<p>The derivation below will produce an output with three disks image
as described above:</p>
<div><pre><span></span><span># base_image.nix</span>
<span>{</span> system <span>?</span> <span>builtins</span><span>.</span>currentSystem<span>,</span> size <span>?</span> <span>"10"</span> <span>}:</span>
<span>let</span>
  <span>pkgs =</span> <span>import</span> <span>&lt;nixpkgs&gt;</span> <span>{};</span>
  <span>config =</span> <span>(</span><span>import</span> <span>&lt;nixpkgs/nixos/lib/eval-config.nix&gt;</span> <span>{</span>
    <span>inherit</span> system<span>;</span>
    <span>modules =</span> <span>[</span> <span>{</span>
      fileSystems<span>.</span><span>"/"</span><span>.</span><span>device =</span> <span>"/dev/disk/by-label/root"</span><span>;</span>

      boot<span>.</span>loader<span>.</span>grub<span>.</span><span>version =</span> <span>2</span><span>;</span>
      boot<span>.</span>loader<span>.</span>grub<span>.</span><span>devices =</span> <span>[</span> <span>"/dev/vda"</span> <span>"/dev/vdb"</span> <span>];</span>
      boot<span>.</span>loader<span>.</span><span>timeout =</span> <span>0</span><span>;</span>
      boot<span>.</span><span>kernelParams =</span> <span>[</span><span>"console=ttyS0,115200"</span><span>];</span>

      services<span>.</span>openssh<span>.</span><span>enable =</span> <span>true</span><span>;</span>
      services<span>.</span>openssh<span>.</span><span>startWhenNeeded =</span> <span>false</span><span>;</span>
      services<span>.</span>openssh<span>.</span><span>extraConfig =</span> <span>"UseDNS no"</span><span>;</span>
    <span>}</span> <span>];</span>
  <span>})</span><span>.</span>config<span>;</span>
  <span>the_key =</span> <span>builtins</span><span>.</span>getEnv <span>"NIXOPS_LIBVIRTD_PUBKEY"</span><span>;</span>
<span>in</span> pkgs<span>.</span>vmTools<span>.</span>runInLinuxVM <span>(</span>
  pkgs<span>.</span>runCommand <span>"libvirtd-image"</span>
    <span>{</span> <span>memSize =</span> <span>768</span><span>;</span>
      <span>preVM =</span>
        <span>''</span>
<span>          mkdir $out</span>
<span>          diskImage1=$out/image</span>
<span>          diskImage2=$out/image2</span>
<span>          diskImage3=$out/image3</span>
<span>          </span><span>${</span>pkgs<span>.</span>vmTools<span>.</span>qemu<span>}</span><span>/bin/qemu-img create -f qcow2 $diskImage1 "</span><span>${</span>size<span>}</span><span>G"</span>
<span>          </span><span>${</span>pkgs<span>.</span>vmTools<span>.</span>qemu<span>}</span><span>/bin/qemu-img create -f qcow2 $diskImage2 "</span><span>${</span>size<span>}</span><span>G"</span>
<span>          </span><span>${</span>pkgs<span>.</span>vmTools<span>.</span>qemu<span>}</span><span>/bin/qemu-img create -f qcow2 $diskImage3 "</span><span>${</span>size<span>}</span><span>G"</span>
<span>          mv closure xchg/</span>
<span>        ''</span><span>;</span>
      <span>postVM =</span>
        <span>''</span>
<span>          mv $diskImage1 $out/disk.qcow2</span>
<span>          mv $diskImage2 $out/disk2.qcow2</span>
<span>          mv $diskImage3 $out/disk3.qcow2</span>
<span>        ''</span><span>;</span>
      <span>QEMU_OPTS =</span> <span>builtins</span><span>.</span>concatStringsSep <span>" "</span> <span>[</span>
        <span>"-drive file=$diskImage1,if=virtio,cache=unsafe,werror=report"</span>
        <span>"-drive file=$diskImage2,if=virtio,cache=unsafe,werror=report"</span>
        <span>"-drive file=$diskImage3,if=virtio,cache=unsafe,werror=report"</span>
      <span>];</span>
      <span>buildInputs =</span> <span>[</span> pkgs<span>.</span>utillinux pkgs<span>.</span>perl pkgs<span>.</span>kmod <span>];</span>
      <span>exportReferencesGraph =</span>
        <span>[</span> <span>"closure"</span> config<span>.</span>system<span>.</span>build<span>.</span>toplevel <span>];</span>
    <span>}</span>
    <span>''</span>
<span>      </span><span>${</span>pkgs<span>.</span>parted<span>}</span><span>/bin/parted --script /dev/vda -- \</span>
<span>        mklabel gpt \</span>
<span>        mkpart ESP fat32 8MiB 256MiB \</span>
<span>        set 1 boot on \</span>
<span>        set 1 bios_grub on \</span>
<span>        mkpart sap1 linux-swap 256MiB 512MiB \</span>
<span>        mkpart primary ext4 512MiB -1</span>
<span>      </span><span>${</span>pkgs<span>.</span>parted<span>}</span><span>/bin/parted --script /dev/vdb -- \</span>
<span>        mklabel gpt \</span>
<span>        mkpart ESP fat32 8MiB 256MiB \</span>
<span>        set 1 boot on \</span>
<span>        set 1 bios_grub on \</span>
<span>        mkpart sap1 linux-swap 256MiB 512MiB \</span>
<span>        mkpart primary ext4 512MiB -1</span>
<span>      </span><span>${</span>pkgs<span>.</span>mdadm<span>}</span><span>/bin/mdadm --create /dev/md0 --metadata=0.90 --level=1 --raid-devices=2 /dev/vda3 /dev/vdb3</span>

<span>      # Create an empty filesystem and mount it.</span>
<span>      </span><span>${</span>pkgs<span>.</span>e2fsprogs<span>}</span><span>/sbin/mkfs.ext4 -L root /dev/md0</span>
<span>      </span><span>${</span>pkgs<span>.</span>e2fsprogs<span>}</span><span>/sbin/tune2fs -c 0 -i 0 /dev/md0</span>
<span>      mkdir /mnt</span>
<span>      mount /dev/md0 /mnt</span>

<span>      export HOME=$TMPDIR</span>
<span>      export NIX_STATE_DIR=$TMPDIR/state</span>

<span>      mkdir -p /mnt/etc/nixos</span>

<span>      # The initrd expects these directories to exist.</span>
<span>      mkdir /mnt/dev /mnt/proc /mnt/sys</span>
<span>      mount --bind /proc /mnt/proc</span>
<span>      mount --bind /dev /mnt/dev</span>
<span>      mount --bind /sys /mnt/sys</span>

<span>      # Copy all paths in the closure to the filesystem.</span>
<span>      storePaths=$(perl </span><span>${</span>pkgs<span>.</span>pathsFromGraph<span>}</span><span> /tmp/xchg/closure)</span>

<span>      echo "filling Nix store..."</span>
<span>      mkdir -p /mnt/nix/store</span>
<span>      set -f</span>
<span>      cp -prd $storePaths /mnt/nix/store/</span>

<span>      mkdir -p /mnt/etc/nix</span>
<span>      echo </span><span>'</span><span>build-users-group = </span><span>'</span><span> &gt; /mnt/etc/nix/nix.conf</span>
<span>      export USER=root</span>

<span>      ## Register the paths in the Nix database.</span>
<span>      printRegistration=1 perl </span><span>${</span>pkgs<span>.</span>pathsFromGraph<span>}</span><span> /tmp/xchg/closure | \</span>
<span>          chroot /mnt </span><span>${</span>config<span>.</span>nix<span>.</span>package<span>.</span>out<span>}</span><span>/bin/nix-store --load-db</span>

<span>      mkdir -p /mnt/nix/var/nix/profiles</span>
<span>      # Create the system profile to allow nixos-rebuild to work.</span>
<span>      chroot /mnt </span><span>${</span>config<span>.</span>nix<span>.</span>package<span>.</span>out<span>}</span><span>/bin/nix-env \</span>
<span>          -p /nix/var/nix/profiles/system --set </span><span>${</span>config<span>.</span>system<span>.</span>build<span>.</span>toplevel<span>}</span><span></span>

<span>      # `nixos-rebuild</span><span>'</span><span> requires an /etc/NIXOS.</span>
<span>      mkdir -p /mnt/etc/nixos</span>
<span>      touch /mnt/etc/NIXOS</span>

<span>      # `switch-to-configuration</span><span>'</span><span> requires a /bin/sh</span>
<span>      mkdir -p /mnt/bin</span>
<span>      ln -s </span><span>${</span>config<span>.</span>system<span>.</span>build<span>.</span>binsh<span>}</span><span>/bin/sh /mnt/bin/sh</span>

<span>      # Generate the GRUB menu.</span>
<span>      chroot /mnt </span><span>${</span>config<span>.</span>system<span>.</span>build<span>.</span>toplevel<span>}</span><span>/bin/switch-to-configuration boot</span>

<span>      mkdir -p /mnt/etc/ssh/authorized_keys.d</span>
<span>      echo </span><span>'</span><span>${</span>the_key<span>}</span><span>'</span><span> &gt; /mnt/etc/ssh/authorized_keys.d/root</span>
<span>      umount /mnt/proc /mnt/dev /mnt/sys</span>
<span>      umount /mnt</span>
<span>    </span><span>''</span>
<span>)</span>
</pre></div>


<p>When deploying with nixops (via the libvirtd backend), you will need to
make each image available. However, nixops only handles one and only one
image, so we will need a bit of manual tasks. This is the nixops
configuration I’m using:</p>
<div><pre><span></span><span># libvirtd.nix</span>
<span>{</span>
  <span>testzfs =</span> <span>{</span> pkgs<span>,</span> lib<span>,</span> <span>...</span> <span>}:</span>
  <span>{</span>
    fileSystems<span>.</span><span>"/"</span><span>.</span><span>device =</span> lib<span>.</span>mkForce <span>"/dev/disk/by-label/root"</span><span>;</span>

    <span># Serial access via virsh console (quite handy for debugging)</span>
    boot<span>.</span><span>kernelParams =</span> <span>[</span><span>"console=ttyS0,115200"</span><span>];</span>
    boot<span>.</span>loader<span>.</span>grub<span>.</span><span>extraConfig =</span> <span>''</span>
<span>      serial --unit=0 --speed=115200 --word=8 --parity=no --stop=1</span>
<span>      terminal_output serial</span>
<span>      terminal_input serial</span>
<span>    ''</span><span>;</span>
    boot<span>.</span>loader<span>.</span><span>timeout =</span> lib<span>.</span>mkForce <span>2</span><span>;</span>

    <span># You need to explicitely specify the additional disk here</span>
    boot<span>.</span>loader<span>.</span>grub<span>.</span><span>devices =</span> <span>[</span> <span>"/dev/sdb"</span> <span>];</span>

    <span>deployment =</span> <span>{</span>
      <span>targetEnv =</span> <span>"libvirtd"</span><span>;</span>
      libvirtd<span>.</span><span>baseImage =</span> pkgs<span>.</span>callPackage <span>.</span><span>/base_image.nix</span> <span>{};</span>
      <span># Additional images need to be specified explicitely here (only the sda one will be picked by nixops)</span>
      libvirtd<span>.</span><span>extraDevicesXML =</span> <span>''</span>
<span>        &lt;disk type="file" device="disk" snapshot="external"&gt;</span>
<span>          &lt;driver name="qemu" type="qcow2"/&gt;</span>
<span>          &lt;source file="/path/to/disk2.qcow2"/&gt;</span>
<span>          &lt;target dev="hdb"/&gt;</span>
<span>        &lt;/disk&gt;</span>
<span>        &lt;disk type="file" device="disk" snapshot="external"&gt;</span>
<span>          &lt;driver name="qemu" type="qcow2"/&gt;</span>
<span>          &lt;source file="/path/to/disk3.qcow2"/&gt;</span>
<span>          &lt;target dev="hdc"/&gt;</span>
<span>        &lt;/disk&gt;</span>
<span>      ''</span><span>;</span>
    <span>};</span>

    <span># Some dummy service that writes to disk regularly</span>
    systemd<span>.</span>services<span>.</span><span>nag-var =</span> <span>{</span>
      <span>description =</span> <span>"Some service reading and writing to /var"</span><span>;</span>
      <span>after =</span> <span>[</span> <span>"network.target"</span> <span>];</span>
      <span>wantedBy =</span> <span>[</span> <span>"multi-user.target"</span> <span>];</span>
      <span>script =</span> <span>''</span>
<span>        #!</span><span>${</span>pkgs<span>.</span>stdenv<span>.</span>shell<span>}</span><span></span>
<span>        mkdir -p /var/nagvar</span>
<span>        while true; do</span>
<span>          </span><span>${</span>pkgs<span>.</span>coreutils<span>}</span><span>/bin/date &gt; /var/nagvar/last</span>
<span>          </span><span>${</span>pkgs<span>.</span>coreutils<span>}</span><span>/bin/sleep 10</span>
<span>        done</span>
<span>      ''</span><span>;</span>
    <span>};</span>
  <span>};</span>
<span>}</span>
</pre></div>


<p>Now prepare the VM. Beware, this will rapidly fill-in your /nix/store
with big images. (<code>nix-store --delete /nix/store/*libvirtd-image*</code> to
clean them selectively if you’re doing tests)</p>
<div><pre><span></span><span># This command will fail due to missing images</span>
nixops deploy --create-only
<span># Find the path to images at the beginning of the output. It will be</span>
<span># slightly different from what you would get with nix-build due to</span>
<span># some parameters given by nixops</span>
<span>P</span><span>=</span>/nix/store/eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee-libvirtd-image

<span># Stop VM.</span>
virsh destroy nixops-...-testzfs

<span># Copy additional disks to places written in libvirtd.nix</span>
<span># For some reason, sometimes I had to replace the first disk too in</span>
<span># libvirtd folder.</span>
cp <span>$P</span>/disk2.qcow2 /path/to/disk2.qcow2
cp <span>$P</span>/disk3.qcow2 /path/to/disk3.qcow2
chmod gu+w /path/to/disk2.qcow2 /path/to/disk3.qcow2

<span># Same action done by nixops on the first disk</span>
qemu-img rebase -f qcow2 -b <span>""</span> /path/to/disk2.qcow2
qemu-img rebase -f qcow2 -b <span>""</span> /path/to/disk3.qcow2

<span># Edit libvirtd and add console configuration</span>
virsh edit nixops-...-testzfs
<span># &lt;serial type='pty'&gt;&lt;target port='0'/&gt;&lt;/serial&gt;</span>
<span># &lt;console type='pty'&gt;&lt;target type='serial' port='0'/&gt;&lt;/console&gt;</span>

nixops deploy --force-reboot
</pre></div>


<p>Now you should have a running VM containing two drives in a RAID1 array
plus one unused drive, that mimics your production server, and that I
used as a base for the migration process below.</p>
<p>In case of problem, you should be able to use <code>virsh console</code> to get an
actual console of what’s happening on your VM (as early as grub stage).
Also think of doing snapshots if you want to repeat some steps.</p>
<h2>Migration process</h2>
<h3>Add the new disk to the RAID array</h3>
<div><pre><span></span><span># Copy partitionning without boot partition</span>
sfdisk -d /dev/sda <span>|</span> grep -v ^sector-size: <span>|</span> sed -e <span>"s/21686148-6449-6E6F-744E-656564454649/0657FD6D-A4AB-43C4-84E5-0933C84B4F4F/"</span> <span>|</span> sfdisk /dev/sdc

<span># Add the new partition to RAID array</span>
mdadm --grow /dev/md0 --level<span>=</span><span>1</span> --raid-devices<span>=</span><span>3</span> --add /dev/sdc3

<span># Wait for synchronisation to finish</span>
cat /proc/mdstat
<span>(</span>...<span>)</span>
</pre></div>


<h3>Remove …</h3></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/">https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/</a></em></p>]]>
            </description>
            <link>https://www.immae.eu/blog/2020/06/06/migrate-from-raid1-disk-to-zfs-on-nixos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814408</guid>
            <pubDate>Sun, 12 Jul 2020 20:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zebrafishes experience rapid neuron regeneration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814309">thread link</a>) | @finphil
<br/>
July 12, 2020 | https://nuadox.com/post/623466498480111616/zebrafish-neuron-regeneration | <a href="https://web.archive.org/web/*/https://nuadox.com/post/623466498480111616/zebrafish-neuron-regeneration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="623466498480111616">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/623466498480111616/zebrafish-neuron-regeneration"><h2>Zebrafishes experience rapid neuron regeneration</h2></a>
                                <figure data-orig-height="600" data-orig-width="900"><img src="https://64.media.tumblr.com/0abaf07dac465d47be466957d043b97a/2d17f574c3ffdfe2-96/s1280x1920/6f47d7c6649367b9b442041254679928a4cbc806.jpg" data-orig-height="600" data-orig-width="900" width="900" height="600" alt="image"></figure><p><b>- By <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.uni-bayreuth.de%2Fen%2F&amp;t=OTRmMjM1OGY1MDIzMjNiY2ExODY5ODIzYTE0NmYxMTUzMzMxNWIwNixyNVlCcG5hcQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F623466498480111616%2Fzebrafish-neuron-regeneration&amp;m=0">University of Bayreuth</a>&nbsp;-</b></p><p>Biologists from the University of Bayreuth in Germany have discovered a uniquely rapid form of regeneration in injured neurons and their function in the central nervous system of zebrafish.&nbsp;</p><p>They studied the Mauthner cells, which are solely responsible for the escape behaviour of the fish, and previously regarded as incapable of regeneration. However, their ability to regenerate crucially depends on the location of the injury. In central nervous systems of other animal species, such a comprehensive regeneration of neurons has not yet been proven beyond doubt. The scientists report their findings in the journal <i><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1038%2Fs42003-020-1034-x&amp;t=ZWYwMjRjMTU5MzZiNjE2YWY1MTViYWQyMTE3NWI4ZTc4M2MyNDg1MCxyNVlCcG5hcQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F623466498480111616%2Fzebrafish-neuron-regeneration&amp;m=0">Communications Biology</a></i>.</p><p>Mauthner cells are the largest cells found in animal brains. They are part of the central nervous system of most fish and amphibian species and trigger life-saving escape responses when predators approach. The transmission of signals in Mauthner cells to their motoneurons is only guaranteed if a certain part of these cells, the axon, is intact. The axon is an elongated structure that borders the cell body with its cell nucleus at one of its two ends. If the injury of the axon occurs close to the cell body, the Mauthner cell dies. If the axon is damaged at its opposite end, lost functions are either not restored at all or only slowly and to a limited extent. However, the Mauthner cell reacts to an injury in the middle of the axon with rapid and complete regeneration. Indeed, within a week after the injury, the axon and its function are fully restored, and the fish is able to escape approaching predators again.</p><figure data-orig-height="400" data-orig-width="1400"><img src="https://64.media.tumblr.com/2b297f3fc7bcc2b2e36d4810e107473d/2d17f574c3ffdfe2-de/s1280x1920/9df9a948fc6a3740b2fad1c15a52bf9610dca129.jpg" data-orig-height="400" data-orig-width="1400" width="1280" height="366" alt="image"></figure><p><i>Image:&nbsp;Color-processed microscopic image of a pair of Mauthner cells (green) in a zebrafish. On the left is the head of the fish, on the right the tail. The two green areas on the left are the cell bodies of the Mauthner cells, the structures running to the right are the axons. The image was taken two days after the two axons were severely injured in their middle section, leaving their function significantly damaged. The several smaller branches at the end of the axons demonstrate how axonal regeneration usually occurs. Credit: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.uni-bayreuth.de%2Fen%2Funiversity%2Fpress%2Fpress-releases%2F2020%2F104-mauthner-cells-regeneration%2F&amp;t=OWI3ZTdjMDI3M2YxOTU2ODYzOWJmZWQyNmEwYjU4NjZlZTU4NWQ3NixyNVlCcG5hcQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F623466498480111616%2Fzebrafish-neuron-regeneration&amp;m=0">Alexander Hecker</a>.</i></p><p>“Such a rapid regeneration of a neuron was never observed anywhere in the central nervous system of other animal species until now. Here, regeneration processes usually extend over several weeks or months,” says Dr. Alexander Hecker, first author of the new study and member of the Department of Animal Physiology. This finding clearly disproves the widely accepted view in the scientific community that Mauthner cells are unable to regenerate.</p><p>However, the observation that the escape response of zebrafish were fully intact so soon after regeneration did not necessarily prove the functional regenerative capacity of the Mauthner cell. It might be possible that other neurons in zebrafish are able to induce this life-saving escape behaviour and thus take over the lost function of Mauthner cells. However, precisely this possibility was ruled out by findings published by the Bayreuth biologists led by Prof. Dr. Stefan Schuster in PNAS in January 2020. They were able to show for the first time that it is only the Mauthner cells that control the escape behaviour of zebrafish. If the axon is irreversibly destroyed, there are no other cells in the fish that are able to compensate for the loss.</p><p>“Mauthner cells now offer us the possibility to investigate the very different responses to injuries of individual cells within the same nervous system: an absence of or insufficient regeneration processes on the one hand, and robust and complete regeneration on the other. Surprisingly, the injuries to the axon, which led to such contradictory responses, were not very far apart. Elucidating the causes is an exciting field of research, which also includes the identification of the genes that are active in the regeneration of neurons. And if we find out the reasons why regeneration processes in Mauthner cells fail to occur, we might also be able to better understand the mechanisms that prevent the regeneration of neurons in humans,” said Hecker.</p><p>–</p><p><b>Source: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.uni-bayreuth.de%2Fen%2Funiversity%2Fpress%2Fpress-releases%2F2020%2F104-mauthner-cells-regeneration%2F&amp;t=OWI3ZTdjMDI3M2YxOTU2ODYzOWJmZWQyNmEwYjU4NjZlZTU4NWQ3NixyNVlCcG5hcQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F623466498480111616%2Fzebrafish-neuron-regeneration&amp;m=0">University of Bayreuth</a></b></p><p><b>Full study:</b>&nbsp;“High-resolution mapping of injury-site dependent functional recovery in a single axon in zebrafish”, <i>Communications Biology</i>.</p><p><a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fdx.doi.org%2F10.1038%2Fs42003-020-1034-x&amp;t=ZWYwMjRjMTU5MzZiNjE2YWY1MTViYWQyMTE3NWI4ZTc4M2MyNDg1MCxyNVlCcG5hcQ%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F623466498480111616%2Fzebrafish-neuron-regeneration&amp;m=0">http://dx.doi.org/10.1038/s42003-020-1034-x</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/159634602647/will-humans-ever-regrow-like-salamanders">Will humans ever regrow like salamanders?</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/animals">animals</a>
                                    
                                        <a href="https://nuadox.com/tagged/biology">biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/zoology">zoology</a>
                                    
                                        <a href="https://nuadox.com/tagged/fish">fish</a>
                                    
                                        <a href="https://nuadox.com/tagged/zebrafish">zebrafish</a>
                                    
                                        <a href="https://nuadox.com/tagged/neuroscience">neuroscience</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/623466498480111616/zebrafish-neuron-regeneration</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814309</guid>
            <pubDate>Sun, 12 Jul 2020 20:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reaching Out of Your Confidence Zone]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814301">thread link</a>) | @tmatthe
<br/>
July 12, 2020 | http://tiffanymatthe.com/reach | <a href="https://web.archive.org/web/*/http://tiffanymatthe.com/reach">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>07.07.2020</time> — <a href="http://tiffanymatthe.com/tags/mindset">Mindset</a> — <span>2<!-- --> min read</span></p><section><img src="http://tiffanymatthe.com/static/f2f49bd6a3636574a101d4b52d6fa385/a6c62/reach-stars.jpg"><p>During my first year of university, there were posters everywhere on campus promoting a physics research experience. I would immediately dismiss it every time I saw it because I wasn't a physics extraordinaire. I did not build rockets or read thick physics theory books during my spare time. And there were a lot more qualified candidates at UBC for this award. So I didn't really consider applying for it until a week before the deadline.</p><p>I had casually<sup id="fnref-1"><a href="#fn-1">1</a></sup> mentioned this award while talking with my parents over dinner, and they were confused that I hadn't applied. I came up with the usual excuses. There wasn't enough time. I wasn't a mastermind in physics. But they convinced me that I could do it and so I found myself scrambling and stressed during that one week before the deadline. I had to find reference letters from professors I had rarely talked to, and write paragraphs about a subject that I was greatly interested in but had little concrete evidence to show this interest.</p><p>A few weeks later, I got the award! And I was so close to not trying. The fear of asking for reference letters on such a tight deadline alone was almost enough to deter me. All of this was definitely out of my 80% confidence zone<sup id="fnref-2"><a href="#fn-2">2</a></sup>, and that's probably why I felt more excited than usual when I received the email telling me the good news.</p><p>However, not every reach out of my 80% confidence zone is a success. In high school, I applied for multiple universities in the States and did not get in a single one. I knew I was reaching a bit high, especially being an international student. It was disappointing not getting in, but I am glad that I tried.</p><p>Many times, after failures like these, I hesitate to try anything that's out of my 80% confidence zone because there is a higher risk of failing. It seems like a waste of time and energy. But if I shift my mindset, and look towards the possible reward and my own skills, it's not all that bad. Yes, I might fail<sup id="fnref-3"><a href="#fn-3">3</a></sup>. But I might also succeed. I think it's better than not trying and missing out on some great opportunities.</p><p>And a note on "oh, I'm not..." a funny person, an artist, a programmer, a swimmer, and &lt;insert some of your own<!-- -->&gt;<!-- -->. In the past, I often told myself these absolutes. Although they might have been true in the moment, by saying these phrases, I was limiting myself and making sure I would keep these absolutes true forever. But once I changed from "oh, I'm not..." to "I could become", it gave me freedom to try things out and have a chance at success. "Could", which denotes a possibility, also allows me to accept failure.</p><p>I like to remind myself that no one is born a charismatic friend, a great writer, a professional basketball player, a famous Youtuber, an awesome doctor. They become those people because they allow themselves to reach for uncertain success.</p><p>So that's why I reach<sup id="fnref-4"><a href="#fn-4">4</a></sup>.</p></section></div></div>]]>
            </description>
            <link>http://tiffanymatthe.com/reach</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814301</guid>
            <pubDate>Sun, 12 Jul 2020 20:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The High Cost of Caring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23814270">thread link</a>) | @maxdeviant
<br/>
July 12, 2020 | https://maxdeviant.com/posts/2020/the-high-cost-of-caring/ | <a href="https://web.archive.org/web/*/https://maxdeviant.com/posts/2020/the-high-cost-of-caring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I care too much. This is a fact.</p>
<p>In particular, I care too much about the art of building software.</p>
<p>As time goes on, software continues to become an increasingly present and critical element in our world. I take my job as a software practitioner incredibly seriously, as I believe it is my ethical responsibility to do so. As a result, I care deeply about things like technical excellence, code quality and maintability, and treating code with the same importance as the end deliverable.</p>
<p>This care does not come without cost. On the contrary, the cost of caring is enormously high. I routinely suffer from high levels of stress and anxiety as a result of my caring about a particular matter. I am especially inundated with these adverse effects when I'm surrounded by people who don't care as much as I do.</p>
<p>Would it be healthier for me to not care so much? Almost certainly. At the very least it may slow the rate at which gray hairs are appearing on my head.</p>
<p>But, for me, not caring is not an option. I have the choice between caring too much or becoming entirely apathetic. There is no in-between. Presented with these two extremes, I would choose caring every single time.</p>
<p>Not caring is lazy. It takes work to care. There is a high cost to caring, but it is absolutely worth it.</p>

  </div></div>]]>
            </description>
            <link>https://maxdeviant.com/posts/2020/the-high-cost-of-caring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814270</guid>
            <pubDate>Sun, 12 Jul 2020 19:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to secure a multitenant application architecture]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23814066">thread link</a>) | @wyldfire
<br/>
July 12, 2020 | https://authress.io/knowledge-base/creating-a-multitenant-application | <a href="https://web.archive.org/web/*/https://authress.io/knowledge-base/creating-a-multitenant-application">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      <h3 id="a-multitenant-application">A Multitenant application</h3>

<p>Multitenancy is the concept that your application serves distinct non-overlapping accounts, with resources assigned to and belonging to each account. A simple example of this is an off-line console video game. Each game copy is bought and paid for by a single owner (“account”), and in that copy there may be some amount of gameplay saved data, development data, and user configuration which is unique and sequestered to that copy. In some cases that data may need to be synced with other copies that the user owns. For example a PC version or potentially a status update on their mobile device.</p>

<p>On the opposite side of the spectrum there are open communities where no data is restricted to the users, a simplified version of Twitter is a good example. Tweets are public, anyone can read them. While a user may be able to post new tweets and delete ones they posted, the environment that user sees is a combination of all users on that platform.</p>

<p>In these extremes, access control policies aren’t that meaningful, since users either have access to nothing (except their resources) or everything. It becomes required and thus more challenging, when resources are partially shared. Take a photo sharing application. While photos may be owned by a single account, a user may want to share their photos with their friends. Additionally they could create albums which their whole family can see, or public ones they intend to demonstrate their photography prowess.</p>

<p>Users create separate accounts which have their own data, own configuration, but may need to share that data with users in that account, or users in other accounts. This is at the core of what is considered a multitenant application.</p>

<h3 id="application-resources">Application resources</h3>

<p>If we use a document repository example we can start to build out what the recommendations might be to secure that data. To start off we’ll look at the types of actions users may want to perform, these are often called user stories.</p>

<ul>
  <li>A user can create an account and provision the necessary resources, add anything to that account, and additionally a user should be able to edit. They are the Owner of that account.</li>
  <li>An account administrator would like to be able to add additional users to the account to manage the documents that are there.</li>
  <li>An account manager needs to upload documents, change documents, and delete them.</li>
  <li>A user in an account needs to be able to share a document with anyone else, or potentially just specific people, irrespective of the account the user is part of.</li>
</ul>

<p>This is just some of the functionality necessary to be built into a document repository. While it is trivial to save documents (depending on their size), getting the permissions right so that they are both easy to maintain but can also provide the necessary flexibility for your users to control access they want to is difficult. We’ll walk through one possible implementation below.</p>

<h3 id="modeled-actions">Modeled Actions</h3>

<ol>
  <li>Create Account - Let’s assume no restricted access is necessary here, anyone can create an account.</li>
  <li>Invite User to Account - Perhaps something like
    <ol>
      <li>Resource: <strong>accounts/{accountId}/users</strong>
</li>
      <li>Permissions: <strong>AddUser/InviteUser, RemoveUser, ReadUsers</strong>
</li>
    </ol>
  </li>
  <li>List accounts - I’ll assume accounts are private. A user can only list accounts they are part of, potentially if you share a document a user might need to be able to see some aspects about that account that owns the document:
    <ol>
      <li>Resource: <strong>accounts/{accountId}</strong> and <strong>accounts/{accountId}/info</strong>
</li>
      <li>Permissions: <strong>updateName/Description, ReadAccount</strong>
</li>
    </ol>
  </li>
  <li>List documents - Need to be able to list the documents in the account
    <ol>
      <li>Resource: <strong>accounts/{accountId}/documents/(documentPath)</strong>
</li>
      <li>Permissions: <strong>AddDocument, DeleteDocument, ReadDocument, EditDocument</strong>
</li>
    </ol>
  </li>
  <li>List users - Need to be able to list users that have access to a document
    <ol>
      <li>Resource: <strong>accounts/{accountId}/documents/(documentPath)/members</strong>
</li>
      <li>Permissions: <strong>ShareDocument, RemoveAccess, UpdateAccess, AssignDocumentOwner</strong>
</li>
    </ol>
  </li>
</ol>

<p>These resource uris are a good match for our user stories about a document repository. For these we would create the relevant roles. So far we listed out the permissions, since the permissions are checked by services we’ll want role abstractions that contain these permissions for the resources.</p>

<h4 id="relevant-roles">Relevant Roles</h4>

<ul>
  <li>Account Admin:
    <ul>
      <li>Will own everything about an account</li>
      <li>Permissions: *</li>
    </ul>
  </li>
  <li>Account Manager:
    <ul>
      <li>Can modify users and documents</li>
      <li>Permissions: <em>AddDocument, DeleteDocument, ReadDocument, EditDocument, ShareDocument, RemoveAccess, UpdateAccess, AssignDocumentOwner</em>
</li>
    </ul>
  </li>
  <li>Account Member:
    <ul>
      <li>Can modify documents</li>
      <li>Permissions: <em>AddDocument, DeleteDocument, ReadDocument, EditDocument, ShareDocument</em>
</li>
    </ul>
  </li>
  <li>Document Viewer:
    <ul>
      <li>Can read a document</li>
      <li>Permissions: <em>ReadDocument, (ShareDocument)</em>
</li>
    </ul>
  </li>
</ul>

<h4 id="relevant-resources">Relevant Resources</h4>
<ul>
  <li><strong>accounts/{accountId}/users</strong></li>
  <li><strong>accounts/{accountId}/info</strong></li>
  <li><strong>accounts/{accountId}/documents/(documentPath)</strong></li>
</ul>

<h3 id="standard-multitenant-resource-recommendations">Standard Multitenant Resource Recommendations</h3>

<p>It can be difficult to get the resource paths just right for your application. What’s important is matching up the user stories to necessary access control checks. Since Authress provides scoped permissions and resources, the best recommendation are resource uris that looks similar to the following:</p>

<blockquote>
  <p><code>NS:tenants/{tenantId}/parentResources/{parentResourceId}/resources/{resourceId}/subResources/{subResourceId}</code></p>
</blockquote>

<ul>
  <li>NS is a custom namespace, your usage of security policies might span across different product spaces, if these are to be separate, prefixing them goes a long way.</li>
  <li>We can separate each section of the path with hardcoded identifier. This is important so that resources of different types are easily distinguishable. If we had <strong>/{id}/{id2}</strong> it would not be possible to differentiate access to <em>/resources/{id}/<strong>sub</strong>/{id2}</em> and <em>/{accounts}/{id}/<strong>resource</strong>/{id2}</em>, since they look the same.</li>
  <li>Always scope with the tenant. There are some situations where resources might be shared, but someone fundamentally one tenant/account always ows the resource.</li>
  <li>Resources in Authress are cascading, so if there is a hierarchy relation between them, this is expressible in the resourceUri. This is a great way to automatically grant access to sub child resources when they are created without needing to create or updating access records. If a user has access to <strong>/resources/{id}</strong> then they will also have the same roles/permissions to all sub resources <strong>/resources/{id}/subResource/{sub1}</strong>
</li>
</ul>

<p>(Another example exists in the <a href="https://authress.io/knowledge-base/zoom-case-study">Zoom Case study</a>)</p>

<p>In some cases resources are very fluid and too much scoping can be a problem, but in Authress these can be changed by updating access records and a simple migration can be used to propagate them if the access control model needs to be changed.</p>

    </div></div>]]>
            </description>
            <link>https://authress.io/knowledge-base/creating-a-multitenant-application</link>
            <guid isPermaLink="false">hacker-news-small-sites-23814066</guid>
            <pubDate>Sun, 12 Jul 2020 19:30:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring how different framings of the same learning task affect performance]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813670">thread link</a>) | @andersource
<br/>
July 12, 2020 | https://andersource.dev/2020/07/12/supervised-task-framing.html | <a href="https://web.archive.org/web/*/https://andersource.dev/2020/07/12/supervised-task-framing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Supervised learning is the machine learning branch that deals with function approximation: using several input-output pairs generated by an unknown target function, construct a different function that approximates the target function. For example, the target function may be my personal movie preferences, and we might be interested in obtaining a model that can predict (approximately) how much I will enjoy watching some new movie. With such a model we can create a movie recommendation app.</p>

<p>Some functions can be easier to approximate than others (given a definition of approximation difficulty, but I won’t go down that rabbit hole right now), and some tasks can be framed as more than one function. This raises the question - do different framings result in different model performance? To find out I tried playing with two framings of a toy problem.</p>

<h2 id="the-data">The data</h2>
<p>I used the <a href="https://scikit-learn.org/stable/datasets/index.html#olivetti-faces-dataset">Olivetti faces dataset</a>, which contains grayscale, 64x64 images of the faces of 40 subjects (10 images per subject). Here are some of the faces:
<img src="https://andersource.dev/assets/faces_framing/faces_sample.png" alt="Face data sample"></p>

<h2 id="the-task">The task</h2>
<p>The task is the classical face recognition task (which has been quite controversial lately due to questionable use in settings such as law enforcement). To make things more interesting, I decided to use only two images from each subject for training, and the rest as the test set. So the goal is to train a model which, given an image, outputs the subject that the model believes this face belongs to.</p>

<h3 id="scope">Scope</h3>
<p>I wanted to focus just on the aspects of training that pertain to the problem framing, and treat it as a general problem. For that purpose I excluded many specifics that would be very important for a real face recognition application:</p>
<ul>
  <li>Using existing face recognition models or <a href="https://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html">existing techniques specific to face recognition</a></li>
  <li>Using <a href="https://link.springer.com/article/10.1186/s40537-019-0197-0">data augmentation</a> to generate more training samples</li>
  <li>Obtaining more face data (even without subject information) and perform unsupervised pre-training</li>
  <li>Assigning each prediction a confidence score, and fixing a confidence threshold below which no result is reported</li>
</ul>

<p>In short, I wanted to see what difference just changing the target function would make. Since the functions are different the models may be somewhat different as well, but they are trained on the same (base) data.</p>

<h3 id="performance-metric">Performance metric</h3>
<p>To measure model performance, I used the accuracy metric - percentage of correct classifications. For each framing I ran about 100 train/test splits (with two images in the training set and eight in the test set).</p>

<h2 id="baseline">Baseline</h2>
<p>As a baseline I used a (single) nearest neighbor classifier with the L2 norm. I.e. when classifying a new face, for each face in the training set we calculate the sum of the squared differences bewteen every two pixels (in similar positions), and take as the answer the face that was closest.</p>

<p><img src="https://andersource.dev/assets/faces_framing/faces_knn.png" alt="Nearest neighbor face classification"></p>

<p>Intuitively it’s hard to tell how well this model would fare. On one hand there should obviously be many similarities between images of the same person (including factors 
we would have liked to exclude, such as lighting and clothing).
On the other hand, many of the similarities we perceive in faces will not be reflected in the pixel-level comparison.
In this case the performance (measured as accuracy - percent of correct classifications) of the model was about  <strong>70.5%</strong>, which is quite impressive in my opinion, considering that a random model would achieve about 2.5% accuracy on average.</p>

<p>Let’s see how a more sophisticated model fares.</p>

<h2 id="first-approach">First approach</h2>
<p>The first framing is the explicit one: given an image, we want to know whose face it is, so that’s what we’ll ask the model. The function maps images to subject identifiers.</p>

<p><img src="https://andersource.dev/assets/faces_framing/first_approach.png" alt="Mapping image to subject ID"></p>

<p>For the model I used a simple network with Keras:</p>

<figure><pre><code data-lang="python"><span>model</span> <span>=</span> <span>Sequential</span><span>([</span>
		<span>Dense</span><span>(</span><span>128</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span> <span>),</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>32</span><span>),</span>
		<span>Dense</span><span>(</span><span>y_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span> <span>activation</span><span>=</span><span>'softmax'</span><span>)</span>
	<span>])</span>

<span>model</span><span>.</span><span>compile</span><span>(</span><span>loss</span><span>=</span><span>'categorical_crossentropy'</span><span>,</span> <span>optimizer</span><span>=</span><span>'adam'</span><span>)</span>
<span>model</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>epochs</span><span>=</span><span>1200</span><span>)</span></code></pre></figure>

<p>I played with several variations and this seemed to be the best with regards to number of layers, their sizes and activation functions. Its test accuracy was, on average, about <strong>70.9%</strong> - an ever so slight improvement.
I think part of the challenge is that classifying faces requires relatively complex features, but we have very little training data (especially considering the number of positive instances for each class).
So the model either fails to find a pattern if the network is too small, or overfits if it’s too large.</p>

<h2 id="second-approach">Second approach</h2>
<p>Let’s try a less direct framing. We know that if two images belong to the same person, they should be relatively similar, and vice versa. Therefore, instead of training the model to identify faces, we can train the model to <em>compare</em> faces. In this case, instead of 40 classes (one for every subject) we only have two classes: “same person” or “not the same person”.</p>

<p><img src="https://andersource.dev/assets/faces_framing/second_approach.png" alt="Mapping image pairs to similarity"></p>

<p>Training this model was a little trickier:</p>
<ul>
  <li>The best architecture turned out to be pretty similar to two (“sideways”) concatenations of the first approach model, which I thought was pretty neat.</li>
  <li>Due to a vanishing gradients issue, I had to go with a slower learning rate and slow it even more as the loss decreased.</li>
  <li>This time we have an <em>imbalanced</em> classification task, so I gave the positive class a bigger weight.</li>
  <li>Training took longer and in a handful of cases (about 5 out of 100) didn’t converge and needed restarting.</li>
</ul>

<p>Another difference is that using this framing, inference isn’t straightforward. Instead, we run the model on the input image along with each of the training images, and pick the subject of the image that the model deemed most similar to the input image.</p>

<p>Here is the code for the model and training:</p>

<figure><pre><code data-lang="python"><span>model</span> <span>=</span> <span>Sequential</span><span>([</span>
		<span>Dense</span><span>(</span><span>256</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span> <span>),</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>128</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>64</span><span>),</span>
		<span>BatchNormalization</span><span>(),</span>
		<span>Dense</span><span>(</span><span>2</span><span>,</span> <span>activation</span><span>=</span><span>'softmax'</span><span>)</span>
	<span>])</span>

<span>model</span><span>.</span><span>compile</span><span>(</span><span>loss</span><span>=</span><span>'categorical_crossentropy'</span><span>,</span> 
	      <span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>.</span><span>0001</span><span>))</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>45</span><span>):</span>
	<span>hist</span> <span>=</span> <span>model</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>to_categorical</span><span>(</span><span>y_train</span><span>),</span>
			 <span>epochs</span><span>=</span><span>10</span><span>,</span> <span>class_weight</span><span>=</span><span>{</span><span>0</span><span>:</span> <span>1</span><span>,</span> <span>1</span><span>:</span> <span>79</span><span>},</span> <span>verbose</span><span>=</span><span>0</span><span>)</span>
	<span>last_loss</span> <span>=</span> <span>hist</span><span>.</span><span>history</span><span>[</span><span>'loss'</span><span>][</span><span>-</span><span>1</span><span>]</span>
	<span>lr</span> <span>=</span> <span>.</span><span>0001</span>
	<span>if</span> <span>last_loss</span> <span>&lt;=</span> <span>.</span><span>1</span><span>:</span>
		<span>lr</span> <span>=</span> <span>.</span><span>00001</span>
	<span>model</span><span>.</span><span>compile</span><span>(</span><span>loss</span><span>=</span><span>'categorical_crossentropy'</span><span>,</span>
		      <span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>lr</span><span>))</span></code></pre></figure>

<p>The accuracy of this model was, on average, about <strong>74.4%</strong>, which is an improvement over both the first approach and the baseline. However, the spread of the results was larger, resulting in both much worse and much better runs. In this problem, a different framing made quite a significant difference.</p>

<h2 id="combined-approach">Combined approach</h2>
<p>After seeing the better average but also bigger spread of the second approach I wondered if it would be possible to create a model that optimizes for both using a non-linear computation graph.
The idea was this: each input sample would contain two faces, which would each “go through” several dense layers. The images would be transformed by the same layers separately, and the resulting representation would be used in two ways:</p>
<ol>
  <li>Classify each face</li>
  <li>Concatenate the two representations and, after several more dense layers, classify whether or not they belong to the same person</li>
</ol>

<p>I also used different weights for the two framings, which worked a little better.</p>

<p>Here’s the code for this model and its training:</p>

<figure><pre><code data-lang="python"><span>x1</span> <span>=</span> <span>Input</span><span>(</span><span>shape</span><span>=</span><span>(</span><span>pre_X_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],),</span> <span>name</span><span>=</span><span>'face1'</span><span>)</span>
<span>x2</span> <span>=</span> <span>Input</span><span>(</span><span>shape</span><span>=</span><span>(</span><span>pre_X_train</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],),</span> <span>name</span><span>=</span><span>'face2'</span><span>)</span>
<span>L1</span> <span>=</span> <span>Dense</span><span>(</span><span>128</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>x1</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],),</span> <span>name</span><span>=</span><span>'face_rep1'</span><span>)</span>
<span>BN1</span> <span>=</span> <span>BatchNormalization</span><span>(</span><span>name</span><span>=</span><span>'batch_norm1'</span><span>)</span>
<span>L2</span> <span>=</span> <span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>128</span><span>,),</span> <span>name</span><span>=</span><span>'face_rep2'</span><span>)</span>
<span>BN2</span> <span>=</span> <span>BatchNormalization</span><span>(</span><span>name</span><span>=</span><span>'batch_norm2'</span><span>)</span>
<span>L3</span> <span>=</span> <span>Dense</span><span>(</span><span>32</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>64</span><span>,),</span> <span>name</span><span>=</span><span>'face_rep3'</span><span>)</span>
<span>O1</span> <span>=</span> <span>Dense</span><span>(</span><span>40</span><span>,</span> <span>activation</span><span>=</span><span>'softmax'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>32</span><span>,),</span> <span>name</span><span>=</span><span>'face_class'</span><span>)</span>

<span>R1</span> <span>=</span> <span>BN2</span><span>(</span><span>L2</span><span>(</span><span>BN1</span><span>(</span><span>L1</span><span>(</span><span>x1</span><span>))))</span>
<span>R2</span> <span>=</span> <span>BN2</span><span>(</span><span>L2</span><span>(</span><span>BN1</span><span>(</span><span>L1</span><span>(</span><span>x2</span><span>))))</span>

<span>C1</span> <span>=</span> <span>concatenate</span><span>([</span><span>R1</span><span>,</span> <span>R2</span><span>],</span> <span>name</span><span>=</span><span>'face_rep_concat'</span><span>)</span><span>i</span>
<span>L4</span> <span>=</span> <span>Dense</span><span>(</span><span>64</span><span>,</span> <span>activation</span><span>=</span><span>'relu'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>128</span><span>,),</span> <span>name</span><span>=</span><span>'comparison_dense'</span><span>)</span>
<span>BN3</span> <span>=</span> <span>BatchNormalization</span><span>(</span><span>name</span><span>=</span><span>'batch_norm3'</span><span>)</span>
<span>O2</span> <span>=</span> <span>Dense</span><span>(</span><span>2</span><span>,</span> <span>activation</span><span>=</span><span>'softmax'</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>64</span><span>,),</span> <span>name</span><span>=</span><span>'comparison_res'</span><span>)</span>

<span>face1_res</span> <span>=</span> <span>O1</span><span>(</span><span>L3</span><span>(</span><span>R1</span><span>))</span>
<span>face2_res</span> <span>=</span> <span>O1</span><span>(</span><span>L3</span><span>(</span><span>R2</span><span>))</span>
<span>comparison_res</span> <span>=</span> <span>O2</span><span>(</span><span>BN3</span><span>(</span><span>L4</span><span>(</span><span>C1</span><span>)))</span>

<span>model</span> <span>=</span> <span>Model</span><span>(</span><span>inputs</span><span>=</span><span>[</span><span>x1</span><span>,</span> <span>x2</span><span>],</span> <span>outputs</span><span>=</span><span>[</span><span>face1_res</span><span>,</span> <span>face2_res</span><span>,</span> <span>comparison_res</span><span>])</span>

<span>tf</span><span>.</span><span>keras</span><span>.</span><span>utils</span><span>.</span><span>plot_model</span><span>(</span><span>model</span><span>,</span> <span>'model.png'</span><span>,</span> <span>show_shapes</span><span>=</span><span>True</span><span>)</span>

<span>model</span><span>.</span><span>compile</span><span>(</span><span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>.</span><span>0005</span><span>),</span>
			  <span>loss</span><span>=</span><span>[</span>
					<span>tf</span><span>.</span><span>keras</span><span>.</span><span>losses</span><span>.</span><span>categorical_crossentropy</span><span>,</span>
					<span>tf</span><span>.</span><span>keras</span><span>.</span><span>losses</span><span>.</span><span>categorical_crossentropy</span><span>,</span>
					<span>weighted_categorical_crossentropy</span><span>([</span><span>1</span><span>,</span> <span>79</span><span>]),</span>
			  <span>],</span>
			  <span>loss_weights</span><span>=</span><span>[.</span><span>1</span><span>,</span> <span>.</span><span>1</span><span>,</span> <span>1.</span><span>])</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>130</span><span>):</span>
	<span>hist</span> <span>=</span> <span>model</span><span>.</span><span>fit</span><span>([</span><span>X1_train</span><span>,</span> <span>X2_train</span><span>],</span> <span>[</span><span>y1_train</span><span>,</span> <span>y2_train</span><span>,</span> <span>y3_train</span><span>],</span>
			 <span>epochs</span><span>=</span><span>10</span><span>,</span> <span>verbose</span><span>=</span><span>0</span><span>)</span>
	<span>last_loss</span> <span>=</span> <span>hist</span><span>.</span><span>history</span><span>[</span><span>'comparison_res_loss'</span><span>][</span><span>-</span><span>1</span><span>]</span>
	<span>lr</span> <span>=</span> <span>.</span><span>0005</span>
	<span>if</span> <span>last_loss</span> <span>&lt;=</span> <span>.</span><span>5</span><span>:</span>
		<span>lr</span> <span>=</span> <span>.</span><span>0001</span>
	<span>if</span> <span>last_loss</span> <span>&lt;=</span> <span>.</span><span>1</span><span>:</span>
		<span>lr</span> <span>=</span> <span>.</span><span>00001</span>

	<span>model</span><span>.</span><span>compile</span><span>(</span><span>optimizer</span><span>=</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>optimizers</span><span>.</span><span>Adam</span><span>(</span><span>learning_rate</span><span>=</span><span>lr</span><span>),</span>
				  <span>loss</span><span>=</span><span>[</span>
					  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>losses</span><span>.</span><span>categorical_crossentropy</span><span>,</span>
					  <span>tf</span><span>.</span><span>keras</span><span>.</span><span>losses</span><span>.</span><span>categorical_crossentropy</span><span>,</span>
					  <span>weighted_categorical_crossentropy</span><span>([</span><span>1</span><span>,</span> <span>39</span><span>]),</span>
				  <span>],</span>
				  <span>loss_weights</span><span>=</span><span>[.</span><span>05</span><span>,</span> <span>.</span><span>05</span><span>,</span> <span>1.</span><span>])</span></code></pre></figure>

<p>Here’s a visual description of what’s happening:</p>

<p><img src="https://andersource.dev/assets/faces_framing/combined_approach.png" alt="Combined approach model"></p>

<p>This model took the longest to train. The average accuracy was <strong>73.3%</strong>, better than the baseline and the first approach but not as good as the second; however, it was much more stable and there were no incidents of non-convergence. So it seems like the combination indeed enabled us to enjoy both worlds: a little better performance while preserving stability.</p>

<h2 id="comparison">Comparison</h2>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Description</th>
      <th>Mean</th>
      <th>Median</th>
      <th>5%</th>
      <th>95%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Baseline</td>
      <td>Nearest neighbor</td>
      <td>70.55%</td>
      <td>70.625%</td>
      <td>65%</td>
      <td>76.25%</td>
    </tr>
    <tr>
      <td>First approach</td>
      <td>Face classification</td>
      <td>70.916%</td>
      <td>71.094%</td>
      <td>65.587%</td>
      <td>76.25%</td>
    </tr>
    <tr>
      <td>Second approach</td>
      <td>Similarity classification</td>
      <td><strong>74.381%</strong></td>
      <td><strong>75.312%</strong></td>
      <td>65.75%</td>
      <td><strong>81.9%</strong></td>
    </tr>
    <tr>
      <td>Combined approach</td>
      <td>first + second</td>
      <td>73.298%</td>
      <td>72.969%</td>
      …</tr></tbody></table></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andersource.dev/2020/07/12/supervised-task-framing.html">https://andersource.dev/2020/07/12/supervised-task-framing.html</a></em></p>]]>
            </description>
            <link>https://andersource.dev/2020/07/12/supervised-task-framing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813670</guid>
            <pubDate>Sun, 12 Jul 2020 18:43:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consistent Brand Execution (Brand Pyramid Framework)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813572">thread link</a>) | @tosh
<br/>
July 12, 2020 | https://artlapinsch.com/2020/07/12/brand-pyramid/ | <a href="https://web.archive.org/web/*/https://artlapinsch.com/2020/07/12/brand-pyramid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1702">
			
	
	<div>
		<div>
			<p>Building a brand is about keeping promises over and over again.</p>
<p><span>This is a starter’s guide to </span><b>consistent brand execution</b><span>.</span></p>
<hr>

<p><span>Strong branding is the result of the following:&nbsp;</span></p>
<ol>
<li><b>Insight:</b><span> Gain Insights from market research</span></li>
<li><b>Strategy:</b><span> Define your strategy <em>(positioning statement; USPs; etc.)</em> from your Insights</span></li>
<li><b>Execution:</b><span> Define your brand using the Brand Pyramid and execute accordingly.</span></li>
</ol>
<p><span>To understand the workings of brand execution it helps to look at the </span><a href="https://en.wikipedia.org/wiki/Shannon%E2%80%93Weaver_model"><span>Shannon–Weaver model</span></a><span> of communication.</span></p>
<figure data-shortcode="caption" id="attachment_1705" aria-describedby="caption-attachment-1705"><img data-attachment-id="1705" data-permalink="https://artlapinsch.com/2020/07/12/brand-pyramid/template-8/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/07/template-8.png" data-orig-size="2388,1668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Senders, Receivers, and Feedback Loops" data-image-description="<p>Senders, Receivers, and Feedback Loops</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=1024" src="https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=1088" alt="Senders, Receivers, and Feedback Loops" srcset="https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=1088 1088w, https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=2176 2176w, https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=150 150w, https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=300 300w, https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=768 768w, https://qndtoolkit.files.wordpress.com/2020/07/template-8.png?w=1024 1024w" sizes="(max-width: 1088px) 100vw, 1088px"><figcaption id="caption-attachment-1705">Senders, Receivers, and Feedback Loops</figcaption></figure>
<p><span>In the context of brand execution the model works as follows:&nbsp;</span></p>
<ul>
<li><b>Brand Identity:</b><span> The sender </span><i><span>(brand)</span></i><span> externalizes its brand identity </span><i><span>(inside-out)</span></i><span> via brand codes </span><i><span>(messages; tonality; colors; products; experiences; etc.)</span></i><span>.</span></li>
<li><b>Brand Image:</b><span> The receiver </span><i><span>(customer)</span></i><span> decodes the message and internalizes it as a brand image </span><i><span>(outside-in)</span></i><span> and builds associations </span><i><span>(attitudes; attributes; etc.)</span></i><span>.&nbsp;</span></li>
<li><b>Feedback Loop:</b><span> The sender receives a feedback response from the receiver. If it is not the intended feedback, the message should be adjusted.</span></li>
</ul>
<hr>

<h2><span>Complexity and Confusion: The Silent Assassins</span></h2>
<p><span>When brands grow they increase in complexity:</span></p>
<ul>
<li><b>Organization:</b><span> Increased headcount; new departments; new structure; etc.</span></li>
<li><b>Audience:</b><span> More of the same customers; new group of customers; etc.</span></li>
<li><b>Value:</b><span> New products/services; new business model or pricing; etc.</span></li>
</ul>
<p><span>Complexity increases the number of touchpoints. If a brand is not able to deliver on its promise it leads to instability.</span></p>
<ul>
<li><b>Internal:</b><span> Confusion about the brand identity and inconsistent delivery of the brand promise</span></li>
<li><b>External:</b><span> Inconsistent experience leads to false associations and an incorrect brand image</span></li>
</ul>
<p><span>Consistent brand execution – across all </span><a href="https://en.wikipedia.org/wiki/Touchpoint#:~:text=A%20touchpoint%20is%20a%20message,their%20brand%20over%20another%20competitor."><span>touchpoints</span></a><span> – helps to build a strong and positive brand image on the receiving end.&nbsp;</span></p>
<hr>
<h2><span>Best Practice: Tight Brand Guidelines and Consistent Execution</span></h2>
<p><span>You can find many well-made brand guidelines online. One of my favorite pages to browse recent projects is Under Consideration’s </span><a href="https://www.underconsideration.com/brandnew/"><span>Brand New</span></a><span> section.</span></p>
<p><span>Below are two examples, which have impressed me.</span></p>
<h3><span>Atlassian: Reorganizing the Brand</span></h3>
<p><span>Atlassian is an software company with an interesting challenge:&nbsp;</span></p>
<ul>
<li><b>Own Products:</b><span> JIRA; Confluence; etc.</span></li>
<li><b>Acquired Products:</b><span> Hipchat; Bitbucket; Trello; etc.</span></li>
<li><b>Different Audiences:</b><span> Customers ranging from individual users to enterprise-grade organizations</span></li>
</ul>
<p><span>When a brand consists of a variety of products and sub-brands it is called a ‘House of Brands’ </span><i><span>(different senders; different brand codes)</span></i><span>. This is the type of complexity mentioned in the section above ☝️</span></p>
<figure><img src="https://qndtoolkit.files.wordpress.com/2020/07/db347-1zp9jzwvwnnydsnriabfqyw.jpeg?w=1920&amp;h=1080" alt="Atlassian's Former 'House of Brands' (source: https://medium.com/designing-atlassian/behind-the-scenes-of-the-atlassian-rebrand-f6ba1592377e)" width="1920" height="1080"><figcaption>Atlassian’s Former ‘House of Brands’ <em>(source: <a href="https://medium.com/designing-atlassian/behind-the-scenes-of-the-atlassian-rebrand-f6ba1592377e" rel="nofollow">https://medium.com/designing-atlassian/behind-the-scenes-of-the-atlassian-rebrand-f6ba1592377e</a>)</em></figcaption></figure>
<p><span>Atlassian decided to rebrand with the goal of becoming a ‘Branded House’ </span><i><span>(same sender; same brand codes)</span></i><span>. The Atlassian design team wrote a </span><a href="https://medium.com/designing-atlassian/behind-the-scenes-of-the-atlassian-rebrand-f6ba1592377e"><span>behind-the-scenes blog post</span></a> <i><span>(highly recommended reading)</span></i><span>.</span></p>
<figure><img src="https://qndtoolkit.files.wordpress.com/2020/07/2d1d0-1adz3fi-nk-q-qo1mvcsvgq.jpeg?w=1920&amp;h=1080" alt="Atlassian's Current 'Branded House' (source: https://medium.com/designing-atlassian/behind-the-scenes-of-the-atlassian-rebrand-f6ba1592377e)" width="1920" height="1080"><figcaption>Atlassian’s Current ‘Branded House’ <em>(source: <a href="https://medium.com/designing-atlassian/behind-the-scenes-of-the-atlassian-rebrand-f6ba1592377e" rel="nofollow">https://medium.com/designing-atlassian/behind-the-scenes-of-the-atlassian-rebrand-f6ba1592377e</a>)</em></figcaption></figure>
<p><span>The results:&nbsp;</span></p>
<ul>
<li><b>New Brand </b><span>(</span><a href="https://www.atlassian.com/blog/announcements/our-bold-new-brand"><span>link</span></a><span>)</span><b>:</b><span> Unified look &amp; feel</span></li>
<li><b>Brand Guidelines</b><span> (</span><a href="https://atlassian.design/"><span>link</span></a><span>)</span><b>:</b><span> An openly accessible resource</span></li>
</ul>
<p><span>The guidelines have many use cases:</span></p>
<ol>
<li><b>Reference:</b><span> Single-source-of-truth for alignment.</span></li>
<li><b>Onboarding: </b><span>Single package, which can be used to onboard internal and external collaborators for projects </span><i><span>(marketing; design; development; etc)</span></i><span>.</span></li>
<li><b>Press/Media/External:</b><span> Rules how to use Atlassian’s brand assets.</span></li>
</ol>
<h3><span>Mailchimp: Streamlining Writing</span></h3>
<p><span>Mailchimp’s writing guide is one of my favorite examples.&nbsp;</span></p>
<p><span>Since it is a company centered around writing it ensures that it provides a best-practice example for its own employees as well as writers in general:</span></p>
<p><a href="https://styleguide.mailchimp.com/"><span>https://styleguide.mailchimp.com/</span></a></p>
<hr>

<blockquote><p><i><span>“Everything should be made as simple as possible, but not simpler”</span></i><span> – Albert Einstein</span></p></blockquote>
<p><span>My favorite branding tool is the </span><b>Brand Pyramid</b><span>. Just like a Swiss army knife it’s useful and packs small.</span></p>
<figure data-shortcode="caption" id="attachment_1711" aria-describedby="caption-attachment-1711"><img data-attachment-id="1711" data-permalink="https://artlapinsch.com/2020/07/12/brand-pyramid/template-7/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/07/template-7.png" data-orig-size="2388,1668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The Brand Pyramid: Brand Identity on a Page" data-image-description="<p>The Brand Pyramid: Brand Identity on a Page</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=1024" src="https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=1088" alt="The Brand Pyramid: Brand Identity on a Page" srcset="https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=1088 1088w, https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=2176 2176w, https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=150 150w, https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=300 300w, https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=768 768w, https://qndtoolkit.files.wordpress.com/2020/07/template-7.png?w=1024 1024w" sizes="(max-width: 1088px) 100vw, 1088px"><figcaption id="caption-attachment-1711">The Brand Pyramid: Brand Identity on a Page</figcaption></figure>
<p><span>I usually include the following sections in a Brand Pyramid:</span></p>
<ul>
<li><b>Brand Promise:</b><span> What should the audience expect?</span></li>
<li><b>Positioning Statement:</b><span> What is the brand about and in which market context?</span></li>
<li><b>Target Audience:</b><span> Who is the audience?</span></li>
<li><b>Tone of Voice:</b><span> What is the brand’s tonality?</span></li>
<li><b>Elevator Pitch:</b><span> How do we describe the brand in one sentence?</span></li>
<li><b>Boilerplate:</b><span> How can the brand be described in a boilerplate format </span><i><span>(e.g. linkedin about page)</span></i><span>?</span></li>
<li><b>Brand Pillars – Benefit:</b><span> What are the cornerstones benefits of the brand?</span></li>
<li><b>Brand Pillars – Product:</b><span> What is the cornerstone offering of the brand?</span></li>
<li><b>Headline Benefits:</b><span> How can each offering be summarized in one sentence?</span></li>
<li><b>RTBs </b><i><span>(Reasons to Believe)</span></i><b>:</b><span> What are the proof points to back up the claims?</span></li>
</ul>
<p><span>The content that goes into the Brand Pyramid is a result of market research and brand strategy </span><i><span>(this will be the focus of a future post)</span></i><span>.</span></p>
<p><span>Let us have a look how Atlassian would be using the Brand Pyramid.</span></p>
<h3><span>Atlassian: Communicating Jobs-to-be-Done Bundles</span></h3>
<p><span>Atlassian’s homepage follows a high-level to low-level messaging sequence. It starts with the company’s goal and ends on specific products that help to achieve that goal.</span></p>
<figure data-shortcode="caption" id="attachment_1712" aria-describedby="caption-attachment-1712"><img data-attachment-id="1712" data-permalink="https://artlapinsch.com/2020/07/12/brand-pyramid/untitled_artwork-5-2/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png" data-orig-size="2543,1352" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Brand Pyramid Case Study: Atlassian’s Homepage Deconstructed" data-image-description="<p>Brand Pyramid Case Study: Atlassian’s Homepage Deconstructed</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=1024" src="https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=1088" alt="Brand Pyramid Case Study: Atlassian's Homepage Deconstructed" srcset="https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=1088 1088w, https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=2174 2174w, https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=150 150w, https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=300 300w, https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=768 768w, https://qndtoolkit.files.wordpress.com/2020/07/untitled_artwork-5.png?w=1024 1024w" sizes="(max-width: 1088px) 100vw, 1088px"><figcaption id="caption-attachment-1712">Brand Pyramid Case Study: Atlassian’s Homepage Deconstructed <em>(website: atlassian.com // illustrations: own)</em></figcaption></figure>
<h3><span>Red Bull: Using Multiple Brand Pyramids</span></h3>
<p><span>Red Bull is another interesting example since it is a brand that competes in many different markets </span><i><span>(consumer-packaged goods; professional sports; media; etc.)</span></i><span>.</span></p>
<p><span>If done correctly, the brand has vertical and horizontal alignment:</span></p>
<ul>
<li><b>Vertical Consistency:</b><span> The brand is aligned top to bottom so that the most granular product features tie into the brand promise and vice versa</span></li>
<li><b>Mutually Exclusive, Collectively Exhaustive</b><span> (MECE): All brand pillars are mutually exclusive so that each pillar/product/benefit works as a stand-alone sender</span></li>
</ul>
<figure data-shortcode="caption" id="attachment_1714" aria-describedby="caption-attachment-1714"><img data-attachment-id="1714" data-permalink="https://artlapinsch.com/2020/07/12/brand-pyramid/template-6/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/07/template-6.png" data-orig-size="2388,1668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Brand Pyramid Case Study: Red Bull’s Brand Architecture Deconstructed" data-image-description="<p>Brand Pyramid Case Study: Red Bull’s Brand Architecture Deconstructed</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=1024" src="https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=1088" alt="Brand Pyramid Case Study: Red Bull's Brand Architecture Deconstructed" srcset="https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=1088 1088w, https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=2176 2176w, https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=150 150w, https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=300 300w, https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=768 768w, https://qndtoolkit.files.wordpress.com/2020/07/template-6.png?w=1024 1024w" sizes="(max-width: 1088px) 100vw, 1088px"><figcaption id="caption-attachment-1714">Brand Pyramid Case Study: Red Bull’s Brand Architecture Deconstructed</figcaption></figure>
<hr>
<h2><span>Practical Applications: How to Use the Brand Pyramid</span></h2>
<p><span>A teacher of mine once said that in social sciences all models are approximations, it’s not an exact science. The takeaway: </span><b>adjust the framework to work for the context of your brand</b><span>.</span></p>
<p><span>Since I have mainly worked in B2B software/adtech, </span><a href="https://artlapinsch.com/2017/10/29/guide-to-better-writing/"><span>writing</span></a><span> was key to brand execution.&nbsp;</span></p>
<p><span>In this context the Brand Pyramid codifies strategies from the highest level </span><i><span>(brand promise and positioning statement)</span></i><span> outlines talking points on the most granular level </span><i><span>(e.g. product features)</span></i><span>.</span></p>
<p><span>Below are a couple of examples of how we have used this framework:</span></p>
<h3><span>Alignment</span></h3>
<p><span>This concise one-pager can be used to onboard and align everyone from a C-level executive to the new intern.&nbsp;</span></p>
<h3><span>Reference</span></h3>
<p><span>All messaging can be referenced and aligned against this framework:&nbsp;</span></p>
<ul>
<li><span><strong>Sales:</strong> Decks; emails; etc.</span></li>
<li><span><strong>Marketing:</strong> Product marketing pages; swag; etc.</span></li>
<li><span><strong>Product:</strong> UX; tone of voice; etc.</span></li>
<li><span><strong>Internal Communication:</strong> Company wiki; internal announcements; etc.</span></li>
<li><span><strong>External Communication:</strong> Press releases; etc.</span></li>
</ul>
<p><span>The Brand Pyramid makes it (1) easier to enable individuals to execute within the parameters of the brand and (2) reduces unnecessary feedback loops.</span></p>
<p><span>Specific messages </span><i><span>(how)</span></i><span> and narratives </span><i><span>(what)</span></i><span> need to be tailored to different audiences </span><i><span>(internal/external; junior/senior; user/decision maker; etc.)</span></i><span> but the Brand Pyramid provides a consistent starting point.</span></p>
<h3><span>Product Value Proposition Documentation</span></h3>
<p><span>Similar to the Red Bull example from above you can use a separate Brand Pyramid for each product, that way your product organizations have specific guidelines, which still tie into the brand’s high-level Brand Pyramid.</span></p>
<figure data-shortcode="caption" id="attachment_1472" aria-describedby="caption-attachment-1472"><img data-attachment-id="1472" data-permalink="https://artlapinsch.com/2019/12/08/building-a-remote-company-lessons-learned/untitled_artwork-2-2/" data-orig-file="https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png" data-orig-size="2388,1668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Brand Pyramid as a Product Value Proposition" data-image-description="<p>Brand Pyramid as a Product Value Proposition</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=1024" src="https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=1088" alt="Brand Pyramid as a Product Value Proposition" srcset="https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=1088 1088w, https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=2176 2176w, https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=150 150w, https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=300 300w, https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=768 768w, https://qndtoolkit.files.wordpress.com/2019/12/untitled_artwork-2.png?w=1024 1024w" sizes="(max-width: 1088px) 100vw, 1088px"><figcaption id="caption-attachment-1472">Brand Pyramid as a Product Value Proposition</figcaption></figure>
<h3><span>Content Marketing Roadmap</span></h3>
<p><span>Generating content marketing ideas can be easy:</span></p>
<ul>
<li><b>Thought Leadership Pieces:</b><span> Use the upper sections of the Brand Pyramid to talk about the long-term vision of the brand/market/etc.</span></li>
<li><b>Evergreen Content:</b><span> Use the audience and brand pillar sections to compile benefit-oriented evergreen content </span><i><span>(ebooks; whitepapers; etc.)</span></i></li>
<li><b>Technical Content:</b><span> Use the RTB section to produce in-depth content </span><i><span>(product marketing; product documentation; how-to guides; etc.)</span></i></li>
</ul>
<p><span>The possibilities are endless.</span></p>
<hr>

<p><span>Branding is like a dialogue between the brand and an audience. The brand sends signals <em>(messages; brand codes; etc.)</em> and the receiver decodes and interprets those to form an image. This process takes time.&nbsp;</span></p>
<figure data-shortcode="caption" id="attachment_1717" aria-describedby="caption-attachment-1717"><img data-attachment-id="1717" data-permalink="https://artlapinsch.com/2020/07/12/brand-pyramid/template-9/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/07/template-9.png" data-orig-size="2388,1668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Consistent Brand Execution Wins: How the Brand Pyramid Helps" data-image-description="<p>Consistent Brand Execution Wins: How the Brand Pyramid Helps</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=1024" src="https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=1088" alt="Consistent Brand Execution Wins: How the Brand Pyramid Helps" srcset="https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=1088 1088w, https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=2176 2176w, https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=150 150w, https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=300 300w, https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=768 768w, https://qndtoolkit.files.wordpress.com/2020/07/template-9.png?w=1024 1024w" sizes="(max-width: 1088px) 100vw, 1088px"><figcaption id="caption-attachment-1717">Consistent Brand Execution Wins: How the Brand Pyramid Helps</figcaption></figure>
<p><span>Consistent brand execution is like keeping promises. Over and over again.</span></p>
<hr>
<p><em>You rock if you read through the end🤘</em></p>
<p><em>If you have feedback, questions, or just want to say hi, please hit me up on <a href="https://twitter.com/artlapinsch" target="_blank" rel="noopener">twitter</a></em></p>
<p><em>Special thanks to <a href="https://twitter.com/__tosh" target="_blank" rel="noopener">Tosh</a>, <a href="https://www.linkedin.com/in/lukasquittan/" target="_blank" rel="noopener">Lukas</a>, and <a href="https://www.linkedin.com/in/finnbohn/" target="_blank" rel="noopener">Finn</a> for proof reading, clarifying discussions and directional feedback.</em></p>
					</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</div>
</article></div>]]>
            </description>
            <link>https://artlapinsch.com/2020/07/12/brand-pyramid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813572</guid>
            <pubDate>Sun, 12 Jul 2020 18:33:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contrastive Code Representation Learning: deep type prediction for TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23813283">thread link</a>) | @parasj
<br/>
July 12, 2020 | https://parasj.github.io/contracode/ | <a href="https://web.archive.org/web/*/https://parasj.github.io/contracode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <h2>Summary</h2>
                <ul>
                    <li>Developer tools increasingly use machine learning to understand and modify human-written code.</li>
                    <li>For the best code understanding results, we hypothesize that learned code representations should be similar for functionally equivalent programs and dissimilar for non-equivalent programs.</li>
                    <li>We propose ContraCode: a methodology to learn similar representations for functionally equivalent programs through contrastive pre-training.</li>
                    <li>During pre-training, we apply compiler transformations to generate (approximately) equivalent, textually divergent batches of programs.</li>
                    <li>Finetuned models improve automated code summarization and type inference in JavaScript.</li>
                </ul>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Abstract</h2>
                <p>
                    Machine-aided programming tools such as type predictors and code summarizers are increasingly learning-based. However, most code representation learning approaches rely on supervised learning with task-specific annotated datasets.
                    We propose <em>Contrastive Code Representation Learning (ContraCode)</em>, a self-supervised algorithm for learning task-agnostic semantic representations of programs via contrastive learning. Our approach uses no human-provided labels, relying only on the raw text of programs.
                    In particular, we design an unsupervised pretext task by generating textually divergent copies of source functions via automated source-to-source compiler transforms that preserve semantics.
                    We train a neural model to identify variants of an anchor program within a large batch of negatives. To solve this task, the network must extract program features representing the functionality, not form, of the program.
                    This is the first application of instance discrimination to code representation learning to our knowledge. We pre-train models over 1.8m unannotated JavaScript methods mined from GitHub. ContraCode pre-training improves code summarization accuracy by 7.9% over supervised approaches and 4.8% over RoBERTa pre-training.
                    Moreover, our approach is agnostic to model architecture; for a type inference task, contrastive pre-training consistently improves the accuracy of existing baselines.
                <br>
                </p>
            </div>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Compiler transforms for code data augmentation</h2>
                <p>Finding equivalent programs in a dataset is challenging. In computer vision, random crops of a source image are frequently used as "equivalent" views of it for augmenting training sets or for unsupervised pre-training. However, it's challenging to define similar data augmentations for natural and programming languages. We propose to use <em>automated source-to-source compiler transformations</em> to generate augmentations of programs that preserve functionality. These transforms include dead code elimination, variable renaming and constant folding. We also explore lossy transforms like code deletion that only preserve some of the program semantics.
                <br></p>
                <p><img src="https://parasj.github.io/contracode/assets/img/codetransform.png"><em>An example JavaScript method from the unlabeled GitHub training set and two semantically equivalent programs. The equivalent programs were automatically generated through compiler transformations, serving as "augmentations" or "views" of the original program.</em></p></div>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Contrastive pre-training</h2>
                <p>
                    Contrastive Code Representation Learning (ContraCode) is a pretext representation learning task that uses these code augmentations to construct a challenging <em>discriminative</em> pretext task that requires the model to identify equivalent programs out of a large dataset of distractors. 
                    In doing so, it has to embed the functionality, not form, of the code. 
                    In essence, the domain knowledge from our code transformations induces the knowledge of the structure of programs onto learned representations.
                <br></p>
                <p><img src="https://parasj.github.io/contracode/assets/img/training.png"><em>ContraCode extends the Momentum Contrast vision pretraining framework to learn an encoder of programs from a database of unlabeled programs and a suite of semantics-preserving transformations.</em></p></div>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Finetuning on downstream tasks</h2>
                <p>
                    By learning functionality-based representations, a model pre-trained with ContraCode outperforms baselines that are are trained from scratch or pre-trained with reconstruction objectives like masked language modeling. We demonstrate these improvements by finetuning LSTM and Transformer models on type inference and code summarization tasks.
                <br></p>
                <p><img src="https://parasj.github.io/contracode/assets/img/typeinference.png">
                <em>After finetuning, an LSTM pretrained with ContraCode predicts the argument and return types of an untyped TypeScript method correctly, which can be useful for developers.</em>
                <img src="https://parasj.github.io/contracode/assets/img/methodnames.png">
                <em>A finetuned model can also predict the name of a method from its body, a form of code summarization that demonstrates understanding of the code and could be useful for deobfuscation.</em>
            </p></div>
        </div>
    </div>
    <hr>
    <div>
        <div>
            <div>
                <h2>Citation</h2>
                <p>Paras Jain*, Ajay Jain*, Tianjun Zhang, Pieter Abbeel, Joseph E. Gonzalez, Ion Stoica. Contrastive Code Representation Learning.<strong>&nbsp;In submission,</strong>&nbsp;2020. <em>* Denotes equal contribution.</em><br></p><p><code>@article{jain2020contrastive,<br>&nbsp; title={Contrastive Code Representation Learning},<br>&nbsp; author={Paras Jain and Ajay Jain and Tianjun Zhang<br>&nbsp;&nbsp;and Pieter Abbeel and Joseph E. Gonzalez and Ion Stoica},<br>&nbsp; year={2020},<br>&nbsp; journal={arXiv preprint}<br>}<br></code></p></div>
        </div>
    </div>
    
    



</div></div>]]>
            </description>
            <link>https://parasj.github.io/contracode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813283</guid>
            <pubDate>Sun, 12 Jul 2020 18:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A visual introduction to machine learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813266">thread link</a>) | @peytoncasper
<br/>
July 12, 2020 | http://www.r2d3.us/visual-intro-to-machine-learning-part-1/?from=@ | <a href="https://web.archive.org/web/*/http://www.r2d3.us/visual-intro-to-machine-learning-part-1/?from=@">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="intro">
		<div>
			<div id="set-up">
				
				<p><img alt="language:" src="http://www.r2d3.us/static/app/global/world.png">: </p>
				<p>In machine learning, computers apply <strong>statistical learning</strong> techniques to automatically identify patterns in data. These techniques can  be used to make highly accurate predictions.</p>
				<p><em>Keep scrolling.</em> Using a data set about homes, we will create a machine learning model to distinguish homes in New York from homes in San Francisco. </p>
			</div>
			
			<hr>
			<div id="first-two">
				<h2> First, some intuition </h2>
				<p> Let’s&nbsp;say you had to determine whether a home is in <strong> San Francisco</strong> or in <strong>New York</strong>. In machine learning  terms, categorizing data points is a <strong>classification</strong> task. </p>
				<p> Since San Francisco is relatively hilly, the elevation of a home may be a good way to distinguish the two cities. </p>
				<p> Based on the home-elevation data to the right, you could argue that a home above 73 meters should be <strong> classified</strong> as one in San Francisco. </p>
			</div>
			<hr>
			<div id="add-nuance">
				<h2> Adding nuance </h2>
				<p> Adding another <strong>dimension</strong> allows for more nuance. For example, New York apartments can be extremely expensive per square foot. </p>
				<p> So visualizing elevation <em>and</em> price per square foot in a <strong>scatterplot</strong> helps us distinguish lower-elevation homes. </p>
				<p> The data suggests that, among homes at or below 73 meters, those that cost more than $19,116.7 per square meter are in New York City. </p>
				<p> Dimensions in a data set are called <strong>features</strong>, <strong>predictors</strong>, or <strong>variables</strong>. <span></span></p>
			</div>
			<hr>
			<div id="set-boundaries">
				<h2> Drawing boundaries </h2>
				<p> You can visualize your elevation (&gt;73 m) and price per square foot (&gt;$19,116.7) observations as the boundaries of regions in your scatterplot. Homes plotted in the green and blue regions would be in San Francisco and New York, respectively. </p>
				<p> Identifying boundaries in data using math is the essence of statistical learning. </p>
				<p> Of course, you’ll need additional information to distinguish homes with lower elevations <em>and</em> lower per-square-foot prices. </p>
			</div>
			<hr>
			<div id="more-variables">
				
				<div id="listing-the-variables">
					<!--<div id="data-table"></div>-->
				<p> The dataset we are using to create the model has 7 different dimensions. Creating a model is also known as <strong>training</strong> a model. </p>
				<p> On the right, we are visualizing the variables in a <strong>scatterplot matrix</strong> to show the relationships between each pair of dimensions. </p>
				<p> There are clearly patterns in the data, but the boundaries for delineating them are not obvious. </p>
				</div>
				<div id="from-boundaries-to-pattern">
				<hr>

				<h2> And now, machine learning </h2>
				<p> Finding patterns in data is where machine learning comes in. Machine learning methods use statistical learning to identify boundaries. </p>
				<p> One example of a machine learning method is a <strong>decision tree</strong>. Decision trees look at one variable at a time and are a reasonably accessible (though rudimentary) machine learning method. </p>
				</div>

				<hr>
			</div>
		</div>
	</div><div id="split">
		<div>
			<div id="elevation-to-histogram">
				<hr>
				<h2> Finding better boundaries </h2>
				<p> Let's revisit the 73-m elevation boundary proposed previously to see how we can improve upon our intuition. </p>
				<p> Clearly, this requires a different perspective.  </p>
				<hr>
				<p> By transforming our visualization into a <strong>histogram</strong>, we can better see how frequently homes appear at each elevation. </p>
				<p> While the highest home in New York is 73m, the majority of them seem to have far lower elevations. </p>

			</div>
			<div id="introduce-split">
				<hr>
				<h2>Your first fork</h2>
				<p> A decision tree uses if-then statements to define patterns in data. </p>
				<p> For example, <strong>if</strong> a home's elevation is above some number, <strong>then</strong> the home is probably in San Francisco. </p>

			</div>
			<div id="explain-gini">
				<hr>
				<p> In machine learning, these statements are called <strong>forks</strong>, and they split the data into two <strong>branches</strong> based on some value. </p>
				<p> That value between the branches is called a <strong>split point</strong>. Homes to the left of that point get categorized in one way, while those to the right are categorized in another. A split point is the decision tree's version of a boundary. </p>

				<hr>
				<h2>Tradeoffs</h2>
				<p> Picking a split point has tradeoffs. Our initial split (~73 m) incorrectly classifies some San Francisco homes as New York ones. </p>
				<p> Look at that large slice of green in the left pie chart, those are all the San Francisco homes that are misclassified. These are called <strong>false negatives</strong>. </p>

				<hr>
				<p> However, a split point meant to capture every San Francisco home will include many New York homes as well. These are called <strong>false&nbsp;positives</strong>. </p>
				<hr>

				<h2>The best split</h2>
				<p> At the <strong>best split</strong>, the results of each branch should be as homogeneous (or pure) as possible. There are several mathematical methods you can choose between to calculate the best split.<span></span></p>
				<hr>
				<p>As we see here, even the best split on a single feature does not fully separate the San Francisco homes from the New York ones.</p>
				<hr>
			</div>
			<div id="further-split">
				<hr>
				<h2>Recursion</h2>
				<p>To add another split point, the algorithm repeats the process above on the subsets of data. This repetition is called <strong>recursion</strong>, and it is a concept that appears frequently in training models.<span></span></p>

				<p>The histograms to the left show the distribution of each subset, repeated for each variable.</p>
				<hr>
				<p>The best split will vary based which branch of the tree you are looking at.<span></span></p> 
				<p>For lower elevation homes, price per square foot is, at $1061 per sqft, is the best variable for the next if-then statement. For higher elevation homes, it is price, at $514,500</p><p>.

				</p><hr>
			</div>

		</div>
	</div><div id="tree">
		<div>
			<div>
				<hr>
				<h2>Growing a tree</h2>
				<p>Additional forks will add new information that can increase a tree's <strong>prediction accuracy</strong>.</p>
				<hr>
				<p>Splitting one layer deeper, the tree's accuracy improves to <strong>84%</strong>.</p>
				<hr>
				<p>Adding several more layers, we get to <strong>96%</strong>.</p>
				<hr>
				<p>You could even continue to add branches until the tree's predictions are <strong>100% accurate</strong>, so that at the end of every branch, the homes are purely in San Francisco or purely in New York.</p>

			</div>
			<div>
				<hr>
				<p>These ultimate branches of the tree are called <strong>leaf nodes</strong>. Our decision tree models will classify the homes in each leaf node according to which class of homes is in the majority.</p>
				<hr>
			</div>

		</div>
	</div><div id="test">
		<div>
			<div id="classify-training-data">
				<hr>
				<h2>Making predictions</h2>
				<p>The newly-trained decision tree model determines whether a home is in San Francisco or New York by running each data point through the branches.</p>
				<hr>
				<p>Here you can see the data that was used to train the tree flow through the tree.</p>

				<p>This data is called <strong>training data</strong> because it was used to train the model.</p>

				<hr>
				<p>Because we grew the tree until it was 100% accurate, this tree maps each training data point perfectly to which city it is in.</p>

			</div>
			<div id="classify-test-data">
				<hr>
				<h2>Reality check</h2>
				<p>Of course, what matters more is how the tree performs on previously-unseen data.</p>
				<hr>
				<p>To <strong>test</strong> the tree's performance on new data, we need to apply it to data points that it has never seen before. This previously unused data is called <strong>test data</strong>.</p>
				<hr>
				<p>Ideally, the tree should perform similarly on both known and unknown data.</p>
				<hr>
				<p>So this one is less than ideal.<span></span></p>
				<hr>

			</div>
			<div id="misclassification">

				<p>These errors are due to <strong>overfitting</strong>. Our model has learned to treat every detail in the training data as important, even details that turned out to be irrelevant.</p>

				<p>Overfitting is part of a fundamental concept in machine learning explained in our next post.<span></span></p>
				<hr>
			</div>
		</div>
	</div></div>]]>
            </description>
            <link>http://www.r2d3.us/visual-intro-to-machine-learning-part-1/?from=@</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813266</guid>
            <pubDate>Sun, 12 Jul 2020 17:58:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Boolean Switch in 104 Lines of HTML,CSS,JS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813202">thread link</a>) | @akully
<br/>
July 12, 2020 | http://adamkulidjian.com/boolean-switch.html | <a href="https://web.archive.org/web/*/http://adamkulidjian.com/boolean-switch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>written in 104 lines of <i>HTML, CSS, JS</i></p>
    
    <p>See the code on <a href="https://github.com/Kully/vanilla-boolean-switch/blob/master/README.md">Github</a> </p>




</div>]]>
            </description>
            <link>http://adamkulidjian.com/boolean-switch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813202</guid>
            <pubDate>Sun, 12 Jul 2020 17:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A compilation of Google Data Center videos]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813182">thread link</a>) | @gw5815
<br/>
July 12, 2020 | https://gregsramblings.com/blog/google-data-center-videos/ | <a href="https://web.archive.org/web/*/https://gregsramblings.com/blog/google-data-center-videos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><header>
    
    <hr>
</header>
<div>
    <div>
        
        <div>
            <h4>Google Data Center Video Compilation</h4>
            <p>July 02, 2020 </p>
        </div>
        <p>In early 2015, only a few months after I joined Google, I got the extremely rare opportunity to visit a Google Data Center. The experience was incredible and it made me want to take everyone I know on a tour, but that’s obviously not possible. The odds of me actually getting to visit another data center is very very slim, so we will have to resort to video and pictures.</p>
<p>Recently, <a href="https://twitter.com/swongful">Stephanie Wong</a>, a member of our Developer Advocacy team, was part of an amazing project to make a video about the multiple layers of security at a Google data center. It is outstanding and a must-watch! Her video inspired me to share this and other similar videos so you can see as much as possible of a Google data center.</p>
<h5 id="videos-in-chronological-order-of-publication">Videos (in chronological order of publication)</h5>
<br>
<h6 id="june-2020----stephanieshttpstwittercomswongful-recent-video-on-the-multiple-layers-of-security-blog-posthttpsbloggoogleinside-googleinfrastructurehow-data-center-security-works">June 2020 – <a href="https://twitter.com/swongful">Stephanie’s</a> recent video on the multiple layers of security (<a href="https://blog.google/inside-google/infrastructure/how-data-center-security-works/">blog post</a>):</h6>
<p>
  <iframe src="https://www.youtube.com/embed/kd33UVZhnAA" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h6 id="april-2019----joe-kava-vp-of-data-centers-presentation-at-google-cloud-next-2019">April 2019 – Joe Kava (VP of data centers) presentation at Google Cloud Next 2019:</h6>
<p>
  <iframe src="https://www.youtube.com/embed/yfF3pOzdmlE" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h6 id="may-2016----a-360-video---you-can-look-all-around-up-down-etc">May 2016 – A 360 video - you can look all around, up, down, etc.:</h6>
<p>
  <iframe src="https://www.youtube.com/embed/zDAYZU4A3w0" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h6 id="may-2016----the-data-center-mural-project-mural-project-home-pagehttpsdatacentermuralswithgooglecom">May 2016 – The data center mural project <a href="https://datacentermurals.withgoogle.com/">(mural project home page)</a>:</h6>
<p>
  <iframe src="https://www.youtube.com/embed/xaZdt2isEKM" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h6 id="december-2014----inside-a-google-data-center">December 2014 – Inside a Google data center:</h6>
<p>
  <iframe src="https://www.youtube.com/embed/XZmGGAbHqa0" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<hr>
<h3 id="learning-more">Learning more</h3>
<p>You can learn a lot more at the <a href="https://www.google.com/about/datacenters/">Google Data Centers home page</a> which includes these fantastic galleries:</p>
<ul>
<li><a href="https://www.google.com/about/datacenters/gallery/">Photo gallery</a></li>
<li><a href="https://www.google.com/about/datacenters/life/">Life at Google Data Centers</a></li>
</ul>
<h3 id="other-google-data-center-resources">Other Google Data Center resources</h3>
<ul>
<li><a href="https://www.google.com/about/datacenters/">Google Data Center home page</a></li>
<li><a href="https://cloud.google.com/">Google Cloud</a> – run your applications in a Google data center</li>
<li><a href="https://cloud.google.com/about/locations#regions">Google Cloud locations</a>!</li>
<li><a href="https://cloud.google.com/security">Google Data Center security, privacy, and compliance</a></li>
</ul>
<h3 id="fun-history">Fun history</h3>
<p>Google’s first production server rack (you can see one of these in the <a href="https://computerhistory.org/">Computer History Museum</a> in Mountain View, CA)
</p><figure><a href="https://en.wikipedia.org/wiki/Google_data_centers">
    <img src="https://gregsramblings.com/images/google_first_server-rack.jpg" alt="Googole's first production server rack"> </a><figcaption>
            <p>Google’s first product server rack (from <a href="https://en.wikipedia.org/wiki/Google_data_centers">https://en.wikipedia.org/wiki/Google_data_centers</a>)</p>
        </figcaption>
</figure>


        <hr>
        <p><b>Tags:</b></p>
        
            
        

    </div>

            </div>
        </div></div>]]>
            </description>
            <link>https://gregsramblings.com/blog/google-data-center-videos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813182</guid>
            <pubDate>Sun, 12 Jul 2020 17:48:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise and Fall of the DPO (Data Protection Officer)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813171">thread link</a>) | @runningmike
<br/>
July 12, 2020 | https://nocomplexity.com/dpo/ | <a href="https://web.archive.org/web/*/https://nocomplexity.com/dpo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4309">
		<!-- .entry-header -->

	
	<div>
		<p>Maybe you have noticed it. Privacy is an issue. A bit strange since there are only 20 days left until the new EU General Data Protection Regulation (GDPR) will become fully enforceable throughout the European Union.</p>
<p>So before end of May 2018 all organizations that process data of EU citizens must comply with this General Data Protection Regulation. Determining how to handle the GDPR is not straightforward. The 261 pages long is not known for its clarity. There is e.g. some confusion on the DPO. <span id="more-4309"></span> DPO stands for Data Protection Officer.</p>
<p>To be clear: Most organizations do <strong>not need</strong> to designate a DPO. Only if you are a public authority (e.g. government) or public body you must assign a DPO. Or you need a DPO if your core activities involve processing of sensitive data on a large scale or if your activities involve large scale, or if you are regular and systematic monitoring individuals.</p>
<p>The DPO should be some kind of safe guard to make sure a company takes the GDPR serious. But knowing how hard it is for security officers to act within companies it is hard to imagine that a DPO will have a better and easier position to act within a company.</p>
<p>Since privacy and security are and will and stay risk based a DPO will have a hard time to get support from the highest management level when discussion on acceptable risks will rise. The history from security breaches and the role and actions of security officers hereby are hopefully not a forecast for the way DPOs will act.</p>
<p>Privacy without good security is hard, if not impossible. So thinking about a DPO you might get the thought that this role is a new ‘pointless job’ invented by people working at institutions were ‘bullshit jobs’ are fully accepted. If you have not read it, please take notice of the hilarious, but good and serious research and book on the ‘<a href="https://www.theguardian.com/money/2018/may/04/i-had-to-guard-an-empty-room-the-rise-of-the-pointless-job" target="_blank" rel="noopener">The Bullshit Jobs Theory’ by David Graeber.</a></p>
<p>To make life for everyone who will deal with the GDPR a bit less complex I made a simple categorization of the DPO within different organizations.</p>
<p><img src="https://raw.githubusercontent.com/nocomplexity/SecurityPrivacyReferenceArchitecture/master/Images/dpo.png" alt="DPO categorization" width="813" height="584"></p>
<p>So in organizations that process large amounts of personal data to make profit you are screwed as DPO if your organization has low ethical standards on privacy and a low morality to be compliant with the GDPR.</p>
<p>This blog post will be added (after rewrite) as an extension on the <a href="http://security-and-privacy-reference-architecture.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">‘Open Reference Architecture for Security and Privacy</a>‘. We are working on an renewed version. <a href="https://github.com/nocomplexity/SecurityPrivacyReferenceArchitecture" target="_blank" rel="noopener">Please join us!</a></p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://nocomplexity.com/dpo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813171</guid>
            <pubDate>Sun, 12 Jul 2020 17:45:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parallel Gzip – Pigz]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23813159">thread link</a>) | @keyboardman
<br/>
July 12, 2020 | https://leimao.github.io/blog/Parallel-Gzip-Pigz/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Parallel-Gzip-Pigz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Sometimes, we would like to compress one or several files into one zipped file or decompress a zipped file. It is very common to use tools such as gzip, zip, or 7zip to create or decompress <code>.gz</code>, <code>.zip</code>, and <code>.7z</code> files, respectively. However, none of these tools on Linux uses multicore and multithread during compression and decompression. When the number of files are large or the file sizes are large, compression and decompression would take a lot of time using single thread.</p>



<p>Pigz is one of the parallel implementation for gzip and zip. Using pigz could greatly save us the time spent on compression and decompression. In this blog post, I would like to briefly discuss how to use pigz.</p>

<h3 id="pigz">Pigz</h3>

<p>The pigz usages in the blog post are mainly targeted for Ubuntu systems. However, its usages on other Linux operating systems should be almost the same.</p>

<h4 id="installation">Installation</h4>

<div><div><pre><code><span>sudo </span>apt update
<span>sudo </span>apt <span>install </span>pigz
</code></pre></div></div>

<h4 id="pigz-usages">Pigz Usages</h4>

<div><div><pre><code>$ pigz --help
Usage: pigz [options] [files ...]
  will compress files in place, adding the suffix '.gz'. If no files are
  specified, stdin will be compressed to stdout. pigz does what gzip does,
  but spreads the work over multiple processors and cores when compressing.

Options:
  -0 to -9, -11        Compression level (level 11, zopfli, is much slower)
  --fast, --best       Compression levels 1 and 9 respectively
  -b, --blocksize mmm  Set compression block size to mmmK (default 128K)
  -c, --stdout         Write all processed output to stdout (won't delete)
  -d, --decompress     Decompress the compressed input
  -f, --force          Force overwrite, compress .gz, links, and to terminal
  -F  --first          Do iterations first, before block split for -11
  -h, --help           Display a help screen and quit
  -i, --independent    Compress blocks independently for damage recovery
  -I, --iterations n   Number of iterations for -11 optimization
  -J, --maxsplits n    Maximum number of split blocks for -11
  -k, --keep           Do not delete original file after processing
  -K, --zip            Compress to PKWare zip (.zip) single entry format
  -l, --list           List the contents of the compressed input
  -L, --license        Display the pigz license and quit
  -m, --no-time        Do not store or restore mod time
  -M, --time           Store or restore mod time
  -n, --no-name        Do not store or restore file name or mod time
  -N, --name           Store or restore file name and mod time
  -O  --oneblock       Do not split into smaller blocks for -11
  -p, --processes n    Allow up to n compression threads (default is the
                       number of online processors, or 8 if unknown)
  -q, --quiet          Print no messages, even on error
  -r, --recursive      Process the contents of all subdirectories
  -R, --rsyncable      Input-determined block locations for rsync
  -S, --suffix .sss    Use suffix .sss instead of .gz (for compression)
  -t, --test           Test the integrity of the compressed input
  -v, --verbose        Provide more verbose output
  -V  --version        Show the version of pigz
  -Y  --synchronous    Force output file write to permanent storage
  -z, --zlib           Compress to zlib (.zz) instead of gzip format
  --                   All arguments after "--" are treated as files
</code></pre></div></div>

<p>A typical command for compressing and decompressing a file is like the following:</p>

<div><div><pre><code><span># Compress</span>
<span># Always use -k to keep the original file</span>
<span>$ </span>pigz <span>-k</span> <span>-p8</span> image.png
<span># Decompress</span>
<span>$ </span>pigz <span>-dk</span> <span>-p8</span> image.gz
</code></pre></div></div>

<p>However, vanilla pigz is not very friendly to compressing multiple files into one single file and custom output filepath. We would need to rely on tar, the archive tool.</p>

<h4 id="tar-pigz-usages">Tar-Pigz Usages</h4>

<p>Using pipe <code>|</code>, we could first archive multiple files or directories first to <code>.tar</code> file and compress using pigz to further generate <code>.tar.gz</code> file.</p>

<div><div><pre><code><span># Compress</span>
<span>$ </span><span>tar</span> <span>-cf</span> - data/ index.json | pigz <span>-k</span> <span>-p8</span> <span>&gt;</span> dataset.tar.gz
<span># Decompress (Unfortunately two steps)</span>
<span>$ </span>pigz <span>-k</span> <span>-p8</span> dataset.tar.gz
<span># Extract file to another directory</span>
<span>$ </span><span>mkdir</span> <span>-p</span> new_dataset
<span>$ </span><span>tar</span> <span>-xf</span> dataset.tar <span>-C</span> new_dataset
</code></pre></div></div>

<p>Alternatively, tar has already integrated custom compressor in its interface, which makes the command looks more clear.</p>

<div><div><pre><code><span># Compress</span>
<span>$ </span><span>tar</span> <span>--use-compress-program</span><span>=</span><span>"pigz -k -p8"</span> <span>-cf</span> dataset.tar.gz data/ index.json
<span># Extract file to another directory</span>
<span>$ </span><span>mkdir</span> <span>-p</span> new_dataset
<span># Decompress</span>
<span>$ </span><span>tar</span> <span>--use-compress-program</span><span>=</span><span>"pigz -dk -p8"</span> <span>-xf</span> dataset.tar.gz <span>-C</span> new_dataset
</code></pre></div></div>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://zlib.net/pigz/">Pigz</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Parallel-Gzip-Pigz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813159</guid>
            <pubDate>Sun, 12 Jul 2020 17:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to reduce RDS costs in AWS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23813099">thread link</a>) | @pcast
<br/>
July 12, 2020 | https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/ | <a href="https://web.archive.org/web/*/https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article, we will give describe some strategies to reduce Amazon RDS costs. This article is part of our <a href="https://www.iobasis.com/How-to-reduce-AWS-Costs/">How to reduce AWS Costs</a> article series.</p>
<p>Amazon RDS is a relational database service. The usual way to deploy a database is by installing it on your OS. Instead, Amazon RDS provides a database-as-a-service. And AWS takes care of hardware provisioning, database setup, patching, and backups.</p>
<p>Here are some benefits that Amazon RDS brings you:</p>
<ul>
<li>AWS manages the <strong>database hardware</strong> for you.</li>
<li>AWS manages the <strong>operating system</strong> (this includes configuration and patches) for you.</li>
<li>AWS manages the <strong>database</strong> service configuration and software patches for you.</li>
<li>Provides <strong>Multi-AZ</strong> deployment (this sets up a standby database instance with synchronous replication to master, and automatic failover/failback)</li>
<li>Provides database <strong>licenses</strong>, so you don’t have to acquire them.</li>
<li>Deploys <strong>Read replicas</strong> deployment.</li>
<li>Deploys <strong>automatic snapshots</strong>, and you can recover your database from any point in time within the last 35 days)</li>
<li>Deploys database <strong>at-rest encryption</strong> (with AWS KMS)</li>
<li>Deploys <strong>in-transit</strong> encryption (so you don’t need to deploy your SSL certificates)</li>
<li>Provides monitoring <strong>metrics</strong> integrated into AWS console (using CloudWatch)</li>
<li>Automatically uploads database <strong>logs</strong> to CloudWatch for a centralized management</li>
<li>Supports <strong>storage autoscaling</strong>, so you don’t run out of space when your database grows.</li>
<li>Supports <strong>IAM</strong> authentication (you store users’ credentials out of DB, so they can be used for multiple DBs or other AWS services)</li>
<li>Supports Amazon <strong>Aurora</strong> database which has additional features.</li>
</ul>
<p>In summary, Amazon RDS will simplify the operation and maintenance of your DB. But one of the main problems with relational databases is that they scale vertically. The database grows with time. And you need to use bigger hardware. That makes database costs increase fast.</p>
<p>So our objective is to describe some strategies to reduce your Amazon RDS costs. Note that each strategy has to be analyzed with the requirements of your workload. And you should use the strategies that work best for you.</p>
<h2>1. Changing the DB engine</h2>
<p>Amazon RDS supports 6 different types of relational database engines: MySQL, PostgreSQL, MariaDB, Oracle, Microsoft SQL Server, and Amazon Aurora.</p>
<p>These are all relational database technologies. The first 3 ones are open source database technologies. Oracle and Microsoft SQL Server are proprietary database technologies. And the last one, Amazon Aurora, is an AWS proprietary database. But it’s compatible with my MySQL and PostgreSQL.</p>
<p>The following picture compares the monthly price of a db.r5.xlarge OnDemand DB engine in us-east-2 (Ohio) region using Single-AZ configuration.</p>
<p>
  <span>
    <span>
      <img alt="RDS monthly price by db engine" title="" src="https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/5a190/RDS-monthly-price-by-db-engine-type.png" srcset="https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/772e8/RDS-monthly-price-by-db-engine-type.png 200w,
https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/e17e5/RDS-monthly-price-by-db-engine-type.png 400w,
https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/5a190/RDS-monthly-price-by-db-engine-type.png 800w,
https://www.iobasis.com/static/4d139c8e97d4c1b491265ddda7135d8d/40601/RDS-monthly-price-by-db-engine-type.png 945w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>These 10 DB instances all use the same HW (a db.r5.xlarge instance). But the price has a huge variation based on the DB engine type.</p>
<p>Note that the 3 open source databases (MySQL, PostgreSQL, MariaDB) almost have the same price. And they are the most economical. And Amazon Aurora is a bit more expensive than them.</p>
<p>Amazon RDS engine pricing includes the licensing for the corresponding database engine. So it’s not necessary to bring your license (BYOL) for this service. The cost of Microsoft (or Oracle) database licenses is already included in the RDS service price. For this reason, these are more expensive than the rest.</p>
<p>Changing the database engine is not a simple task. Not only the database data has to change. You have to make sure the code using it could also be changed. And your team has to know how to use it.</p>
<p>But having that said, it’s important to note that the type of database technology will have a big impact on your costs. If you can change the technology of your database, that could avoid the licensing fees. For example, if you change from RDS for Oracle SE2 to Aurora PostgresSQL, you will save <strong>44%</strong> monthly.</p>
<p>In case you decide to migrate your database, you can use <a href="https://aws.amazon.com/dms/">AWS Database Migration Service</a>. This is a tool that allows you to migrate your database (and schema) to a new engine. And it’s free (you only pay for the EC2 instance to run it).</p>
<h2>2. Using Amazon EC2 instead of Amazon RDS</h2>
<p>This strategy is probably an option that no cloud specialist will mention. But it’s worth evaluating. As we mentioned before, Amazon RDS has lots of benefits and makes the database administration much easier. But it also brings higher costs.</p>
<p>Let’s compare the cost of a database in EC2 and RDS. We will use an on-demand EC2 r5.xlarge instance which has 4 vCPUs with 32 GiB of memory. It uses the same hardware as the db.r5.xlarge database. Here are the results:</p>
<table>
<thead>
<tr>
<th>EC2 AMI</th>
<th>EC2 Price ($)</th>
<th>RDS Price ($)</th>
<th>Savings</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows Server 2019 with SQL Server 2019 Enterprise</td>
<td>1393.92</td>
<td>1800.72</td>
<td>23%</td>
</tr>
<tr>
<td>Windows Server 2019 with SQL Server 2019 Standard</td>
<td>659.52</td>
<td>1094.4</td>
<td>40%</td>
</tr>
<tr>
<td>Windows Server 2019 with SQL Server 2019 Web</td>
<td>362.88</td>
<td>633.6</td>
<td>42%</td>
</tr>
<tr>
<td>Linux with SQL Enterprise</td>
<td>1261.44</td>
<td>1800.72</td>
<td>30%</td>
</tr>
<tr>
<td>Linux with SQL Standard</td>
<td>527.04</td>
<td>1094.4</td>
<td>51%</td>
</tr>
<tr>
<td>Linux with SQL Web</td>
<td>230.4</td>
<td>633.6</td>
<td>63%</td>
</tr>
<tr>
<td>Linux</td>
<td>181.44</td>
<td>345.6</td>
<td>47%</td>
</tr>
</tbody>
</table>
<p>For example in the first row, the price of Amazon RDS with SQL Server is $ 1800.72 per month (in Ohio). If we host the in an EC2 instance with <em>Windows Server 2019 with SQL Server 2019 Enterprise</em> AMI, the price is $ 1393.92 per month. That’s <strong>23%</strong> below RDS price. And if we use it on an EC2 with “Linux with SQL Enterprise” the cost will be <strong>30%</strong> less.</p>
<p>In the last row, the price of Amazon RDS MySQL-compatible is $ 345.6 per month. But hosting the database on an EC2 with Linux AMI costs $ 181.44. That’s <strong>47%</strong> less.</p>
<p>Additionally, hosting a database on Amazon EC2 will also bring more flexibility regarding the types of EC2 instances you can choose. For example, there are 254 types of EC2 instances and only 18 RDS database instance types.</p>
<p>You can choose this strategy if you want to reduce your database costs, and you can afford the overhead of deploying and maintaining the database yourself.</p>
<h2>3. Right-Sizing your database instance</h2>
<p>This strategy consists of choosing the right database instance for your workload. The good point is that there are only 5 families of databases instances: “t”, “m”, “r”, “x” and “z”. And the number of instance types is low as well (compared with the number of AWS EC2 instance types). For example, there are currently 22 database instances for Amazon RDS for PostgreSQL. This makes the decision easier.</p>
<p>How to decide what is the best database instance for my workload? The right approach is to determine your database requirements (including memory, CPU, IOPs, and others). And then choosing the most cost-effective instance that complies with them.</p>
<p>You can start monitoring your database using CloudWatch Metrics for RDS. Metrics like CPUUtilization, FreeableMemory, and ReadIOPS are very useful to understand the utilization of the CPU, memory, and storage. You can also enable Enhanced Monitoring (it has a small fee). This will show how each process in the database is using memory and CPU.</p>
<p>Here is a quick approach to filter database instances. First, you visit <a href="https://www.ec2instances.info/">EC2 instances info</a>. You choose RDS and your region. Then remove the unnecessary price columns (for example, all price-related columns except “MySQL On-Demand Cost”). And afterward, you add the required GiB in the Memory filter. For example, if your database uses 9 GiB of memory, so might choose 16 GiB. You will get a list with all the instances that match this memory size, and they will be ordered by the lowest cost. For example, after setting the filters, we got only 9 database instances types. And finally, you could choose the right instance according to the estimated CPU usage. Here you have both price and hardware characteristics of the database instances, and this will simplify your decision.</p>
<p>Note that each time you switch to a smaller instance, the database half the previous size (except some specific cases). And you will save <strong>50%</strong>. That’s why it’s very important to find the right instance size for your workload.</p>
<h2>4. Using Reserved DB Instances</h2>
<p>Reserved Instances allows you to save money by committing to use the database instance for 1 or 3 years. You purchase a Reserved Instance plan, and that gives you a discount.</p>
<p>For example, here are current Amazon RDS savings expected for a MySQL database using a db.r5.xlarge DB instance in Ohio.</p>
<table>
<thead>
<tr>
<th>Payment Option</th>
<th>Monthly Price (r5.xlarge)</th>
<th>Savings over On-Demand</th>
</tr>
</thead>
<tbody>
<tr>
<td>On-Demand</td>
<td>345.6</td>
<td></td>
</tr>
<tr>
<td>Reserved 1 year (No Upfront)</td>
<td>199.44</td>
<td>42%</td>
</tr>
<tr>
<td>Reserved 1 year (All Upfront)</td>
<td>186.48</td>
<td>46%</td>
</tr>
<tr>
<td>Reserved 3 year (All Upfront)</td>
<td>125.28</td>
<td>64%</td>
</tr>
</tbody>
</table>
<p>Purchasing Reserved Instances will allow you to save <strong>30% to 64%</strong> (depending on the payment term, region, database engine, and instance type). So you should evaluate if this works for your workload.</p>
<h2>5. Stopping and Starting database engines</h2>
<p>The database instance is charged proportionally to the time it’s running. You can stop your testing instances after business hours, or when they aren’t used. This can be done using the console. Or you can automate stopping (and restarting) the database instances at certain times of the day.</p>
<p>For example, let’s say that you use some database instances on standard business hours only. That’s 45 hours a week (out of 168 hours). So you will save <strong>73%</strong> of the costs of this database instance.</p>
<p>Keep in mind that when your database is not running, you will still pay for the storage and snapshots used. Additionally, a database can be stopped for up to 7 days. After this period, AWS will start it automatically.</p>
<p>Stopping and starting the database instances is available only to instances with Single-AZ configuration and without Read replicas.</p>
<h2>6. Using Aurora Serverless</h2>
<p>In case you are using Aurora, you can switch to Aurora Serverless. It automatically scales the database instance hardware (assigning up to 488 GiB of memory). AWS charges you proportionally to the provisioned compute in terms of ACUs.</p>
<p>But apart from autoscaling, Aurora Serverless will pause your database if you aren’t using it. When that happens, you will only be charged for storage (but not for the DB instance).</p>
<p>The most important point is that the database instance will scale to accommodates current usage. In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/">https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/</a></em></p>]]>
            </description>
            <link>https://www.iobasis.com/Strategies-to-reduce-Amazon-RDS-Costs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23813099</guid>
            <pubDate>Sun, 12 Jul 2020 17:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Investor Due Diligence: A Breakdown and Investor Funnel Template]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812918">thread link</a>) | @aleberry
<br/>
July 12, 2020 | https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template | <a href="https://web.archive.org/web/*/https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="2b3385af-b82e-4ad2-6d91-62ecc32da36c"><p>Let's flip the conversation from your typical research, Google searches, and thought process on fundraising in tech.</p><p>There are plenty of resources by funds themselves on how VCs, Angels, CVCs, and even&nbsp;PEs perform due diligence on potential portfolio companies. </p><p>As a founder or startup, you should absolutely be doing the same internal due diligence on investors PRIOR&nbsp;to reaching out &amp; pitching. Think about dating, recruiting, or interviewing for a job. Are you swiping right on every single person or job? For your sanity,&nbsp;I&nbsp;hope not! </p><p>By creating your investor funnel and running through the checklist, you'll prevent wasted resources &amp; a bad taste in your mouth. More importantly, you'll get to your end goal faster! &nbsp;<strong>Cuz let's be honest... $$$.</strong></p><p>‍</p><figure id="w-node-05b9cbd3c263-ddfd485f"><p><img src="https://assets.website-files.com/5cf81ba4df6b3245b963fc60/5f0642f501cd0245c3dfe5d3_giphy.gif" alt="this is bad parks and rec GIF"></p></figure><p>‍</p><blockquote>Before we jump in, you should note that fundraising &amp;&nbsp;Investor Relations (IR)&nbsp;are full-time jobs for a reason.&nbsp;There is an art to communication, relationship building, &amp; the entire R&amp;D process. You will not be able to find ALL this information easily, and that's ok. We are always here to hold your hand, but you should identify what you are looking for before speaking to us or another consultant. <p>TL;DR:&nbsp;Don't go to a matchmaker without some kind of list. This is time-consuming, but you are asking for $$$.</p></blockquote><p>‍</p><h3>Investor Funnel Template</h3><p>When startups &amp; companies hire us for investor relations &amp; fundraising, this is where we start. In addition to our own database that we keep up to date, we add new contacts based off previous syndicate deals, partnerships, and of course any new funds that may be a good fit. </p><p>This funnel can be integrated with your CRM and Dealflow management platform. If you have questions about that, <a href="https://www.aleberrycreative.com/contact" target="_blank">just send us a note</a>! We also recommend an Investor Relations (IR) page or form option on your website.</p><p>‍</p><figure><p><img src="https://assets.website-files.com/5cf81ba4df6b3245b963fc60/5f0756577bd62fc02173ef67_investor%20funnel%20gif%20-%20blog.gif" alt="Investor Due Diligence Investor Funnel"></p></figure><p>‍</p><p>Here's a quick overview of our sheet (for free, just for you!) in both Grid &amp;&nbsp;Kanban view.</p><p>‍</p><p>‍</p><p><a href="https://airtable.com/invite/l?inviteId=invW6Pi6kgNCe5oGK&amp;inviteToken=27c71005995b7ac891c9f3c23fbb43f5186b09bee4f9606462f98f61537f0f4d" target="_blank">You can also access it here, if you prefer to export or duplicate.</a></p><p>‍</p><blockquote>By the way, we're huge fans of <a href="https://airtable.com/invite/r/SCZ6qu5g" target="_blank">Airtable</a>! Innovating Spreadsheets, I mean come on - it's genius! For folks like us that preferred to stay away from&nbsp;<a href="https://www.aleberrycreative.com/who-we-are" target="_blank">Media Buying in&nbsp;Ad School</a>, they make spreadsheets super easy to use &amp; customize.</blockquote><blockquote>Not-Really-A-Disclaimer: They are not a client. Hey Airtable, if you ever want to chat - we so would!</blockquote><p>‍</p><p>‍</p><h3>The basics - the tabs / categories</h3><p>We'll break down each tab in detail:</p><ul role="list"><li>Investor /&nbsp;Fund List</li><li>Contacts (individual investors or points of contact at said funds)</li><li>Industry Companies (not direct competition, but other funded companies in your vertical)</li><li>Pitch Feedback (this is an Aleberry thing, but you'd be surprised how useful this is for noticing patterns)</li></ul><p>‍</p><p>This organization lends itself to a solid setup on your CRM&nbsp;or Dealflow platform, if that's your preference for Investor Relations. We would generally do this sheet first, then integrate actual applicable funds into your CRM as you contact them.</p><p>‍</p><p>‍</p><h3>Investor / Fund Tab</h3><p>This is your main overall focus, ie. the first tab. We also put this one in Kanban view based off Status.</p><ul role="list"><li>Fund or Investor Name</li><li>Status</li><li>HQ&nbsp;Location</li><li>Website</li><li>Type</li><li>How To Reach Out</li><li>Social Links (LI, Twitter, Angel.co, Crunchbase)</li><li>Applicable Portfolio Companies</li><li>Verticals</li><li>Avg.&nbsp;Investment Size</li><li>Deals/Year</li><li>Key Metrics,&nbsp;Requirements, &amp; Notes</li><li>Connections</li><li>Contacts (links to CONTACTS tab)</li><li>Feedback (links to Pitch Feedback)</li><li>Industry&nbsp;Companies (links to INDUSTRY&nbsp;COMPANIES&nbsp;tab)</li></ul><p>‍</p><p><strong>Fund or Investor Name:</strong></p><p>Obviously.</p><p>‍</p><p><strong>Status: </strong></p><p>This is how the Kanban view is sorted, and you can think of this as your CRM /&nbsp;Funnel&nbsp;Status. Where are you with the investor in the dealflow process?</p><ul role="list"><li>Internal R&amp;D: Initial status.&nbsp;You heard of them &amp;&nbsp;jotted their name, but need to do or are in the process of some R&amp;D to ensure they are the right fit.</li><li>Contacted: You did some R&amp;D; it seems like they would be good. You've reached out. If you are curious about how to approach this, <a href="https://www.aleberrycreative.com/contact" target="_blank">talk to us</a>!</li><li>Follow Up Initial Contact: Follow up on the initial contact if you haven't heard back, or if they requested a few more details</li><li>Deck Sent:&nbsp;Things are moving along &amp; you sent your deck! Maybe you already sent it with the initial contact, maybe you need tweaks, either way - they have something of yours to review.</li><li>Pitching: They love your (hopefully <a href="https://www.aleberrycreative.com/our-work" target="_blank">beautifully crafted deck &amp; story by Aleberry</a> :) ) and have requested a pitch / meeting.</li><li>Follow Up Post Pitch:&nbsp;I hope you sent a thank you of some kind post pitch. As your mum would say: Manners! Follow Up if you haven't heard back, or if you need to submit more information.</li><li>Bad Fit: You're going to end your funnel here 90% of the time. Keep your head up, and remember the analogy of dating! </li><li>Term Sheet Review: WOOT!! Negotiate or Sign or Pass.&nbsp;Either way you got their attention.</li></ul><p>‍</p><p><strong>HQ&nbsp;Location:</strong></p><p>As a one positive of this COVID world, we're finding this is becoming less important.&nbsp;However, it is good to note where they are located for post-COVID, in-person pitches &amp; general timezone coordination.</p><p>‍</p><p><strong>Website:&nbsp;</strong></p><p>Good to refer back to. Also depending on your CRM, you may be able to auto-pull some data.</p><p>‍</p><p><strong>Type:</strong></p><p>How would you categorize them? Important for pitching &amp; understanding if they are a good fit or not.</p><ul role="list"><li>Individual Angel</li><li>Individual VC</li><li>Group (Syndicate or other)<br></li><li>VC Fund</li><li>PE</li><li>CVC</li><li>MicroVC</li></ul><p>‍</p><p><strong>How to Reach Out:</strong></p><p>In an effort to promote more diverse founders, many funds are opening their doors to cold intros. We've always been a big proponent of this because while relationships will always be an important aspect of every facet in life - innovations come from all kinds of founders. </p><p>If your product or company are amazing, you should have access to funds -- no matter your background. </p><p>Some funds may have specific details on their website about a) if they have an open round or are open to new deals b) how to send your submission. </p><p>If they don't, there are always ways to find out!</p><p>‍</p><p><strong>Social Links:</strong></p><p>LinkedIn,&nbsp;Twitter,&nbsp;Angel.co, Crunchbase, Pitchbook, F6S... the list goes on, but we just selected a few. This is not an invitation to bombard them :) . It is an invitation to listen &amp; see past investments.</p><p>VCs are more active on&nbsp;LinkedIn &amp;&nbsp;Twitter. Often their thoughts are posted on potential investments, the market, and general ideas. Our mate <a href="http://haystack.vc/" target="_blank">Semil&nbsp;Shah with&nbsp;Haystack</a>'s <a href="https://twitter.com/semil" target="_blank">Twitter</a> account is full of great insight. </p><p>‍</p><p><strong>Applicable Portfolio&nbsp;Companies:</strong></p><p>Are there any companies you know / are connected to? Any portfolio companies in your industry?</p><p>Founders who successfully raised are amazing resources, and most of the time - they are happy to lend a hand or intro.</p><p>‍</p><p><strong>Verticals:</strong></p><p>Does the fund only invest in specific verticals/industries? We included a few common ones here, but feel free to edit. </p><p>If a fund only invests in FinTech &amp;&nbsp;Enterprise SaaS platforms, your Medical Device will not even be looked at. </p><p>‍</p><p><strong>Average Investment Size &amp;&nbsp;Deals Per Year:</strong></p><p>Both these columns can be identified together. This will determine if the fund is the right fit based off your ask &amp; what your chances are to receive funding.</p><p>Some investors make a handful of investments a year at $3-5M each, others do 30 at $1M each, and large funds may invest in a large number for both check size &amp; deals.</p><p>‍</p><p><strong>Key Metrics,&nbsp;Requirements, and Notes:</strong></p><p>Many investor websites openly state what metrics (traction, ARR, team, geography, etc.) they look for. You can also take a quick look at their portfolio &amp; make some assumptions. </p><p>Use this column as a junk drawer of random notes if needed. </p><p>‍</p><p><strong>Connections:</strong></p><p>We don't know every investor in the world, nor do we pretend to! What you will quickly find is the investor world, especially in specific verticals, is small. We use these columns to see if there are any shared connections who could offer insight or intros to outside our investor network. </p><p>You can do the same &amp; use the founder method if needed.</p><p>If we have an awesome AgTech company that would be a perfect fit for a CVC, we may not know the venture arm - but we may know someone at the corporation who can provide some insights or an intro.</p><p>VERY&nbsp;TARGETED outreach can be done delicately, just don't come off as a spammer. :) Scratch that, just talk to us first! </p><p>‍</p><p><strong>Contacts:</strong></p><p>This is linked to the CONTACTS tab. It is a good place to connect specific folks to the fund. The team pages are full of insights into which LP / investor works in which vertical. Integrate this into your CRM once you start communicating with them.</p><p>‍</p><p><strong>Feedback:</strong></p><p>Linked to the PITCH&nbsp;FEEDBACK&nbsp;TAB. As mentioned, this is an Aleberry thing - but we find it helpful when working with both funds &amp; founders. </p><p>This tab is incredibly helpful for noticing patterns. </p><p>ASK&nbsp;FOR&nbsp;FEEDBACK &amp;&nbsp;TAKE&nbsp;IT&nbsp;KINDLY. We can not stress the latter enough. An investor not only reviewed your deck, but they are willing to give you some insights on why they passed. Listen &amp; decide if the advice is applicable or not, but don't burn bridges.</p><p>‍</p><p><strong>Industry Companies:</strong></p><p>This will auto-populate from the INDUSTRY&nbsp;COMPANIES&nbsp;tab. More on that below.</p><p>‍</p><p>‍</p><h3>Contacts:</h3><p>This one needs a lot less explanation. It's basically your Rolodex for contact information. Make sure to tie the name to fund for Tab One. We added the last two columns on initial contact &amp; last contacted, but don't always use those. If you are not using a CRM for Investor Relations - these two columns may be helpful.</p><p>‍</p><p>‍</p><h3>Industry&nbsp;Companies</h3><p>Are there any companies in your industry / vertical that have successfully raised? Who did they raise from?&nbsp;This is a fantastic way to identify funds that will be further down your pipeline. It may also give you an in if you know the company.</p><p>While you should identify direct competitors, you should note that funds will not invest in direct competition. This may eliminate a fund for you, while also giving you insight into a similar raise. </p><p>Tag the funds! </p><p>‍</p><p>‍</p><h3>Pitch&nbsp;Feedback:</h3><p>We included a few common themes that we see, but you should add simple phrases here. Tag the Main INVESTOR&nbsp;Tab. Use the notes area to jot any additional details.</p><p>This will help you identify patterns, as well as make some fixes if possible (or just eliminate the fund from your list).</p><p>‍</p><p>‍</p><h3>That's a lot of information!</h3><p>Yes it is, but don't feel overwhelmed. </p><p>You are asking for money, so you should expect to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template">https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template</a></em></p>]]>
            </description>
            <link>https://www.aleberrycreative.com/blog/investor-due-diligence-a-breakdown-investor-funnel-template</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812918</guid>
            <pubDate>Sun, 12 Jul 2020 17:14:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proving Algebraic Datatypes Are “Algebraic”]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812854">thread link</a>) | @sendilkumarn
<br/>
July 12, 2020 | https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html | <a href="https://web.archive.org/web/*/https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   
   <div>
    
    <p>
    Several programming languages allow programmers to define (potentially
    recursive) custom types, by composing together existing ones. For instance,
    in OCaml, one can define lists as follows:
    </p>
    <pre>type 'a list =
| Cons of 'a * 'a list
| Nil
</pre>
    <p>
    This translates in Haskell as
    </p>
    <pre>data List a =
  Cons a (List a)
| Nil
</pre>
    <p>
    In Rust:
    </p>
    <pre>enum List&lt;A&gt; {
  Cons(A, Box&lt; List&lt;a&gt; &gt;),
  Nil,
}
</pre>
    <p>
    In Coq:
    </p>
    <pre>Inductive list a :=
| cons : a -&gt; list a -&gt; list a
| nil
</pre>
    <p>
    And so forth.
    </p><p>
    Each language will have its own specific constructions, and the type systems
    of OCaml, Haskell, Rust and Coq —to only cite them— are far from being
    equivalent. That being said, they often share a common “base formalism,”
    usually (and sometimes abusively) referred to as <i>algebraic datatypes</i>. This
    expression is used because under the hood any datatype can be encoded as a
    composition of types using two operators: sum (<span>+</span>) and product (<span>*</span>) for
    types.
    </p>
    <ul>
     <li>
      <span><span title="var">a</span></span> <span>+</span> <span><span title="var">b</span></span> is the disjoint union of types <span><span title="var">a</span></span> and <span><span title="var">b</span></span>. Any term of <span><span title="var">a</span></span>
        can be injected into <span><span title="var">a</span></span> <span>+</span> <span><span title="var">b</span></span>, and the same goes for <span><span title="var">b</span></span>. Conversely,
        a term of <span><span title="var">a</span></span> <span>+</span> <span><span title="var">b</span></span> can be projected into either <span><span title="var">a</span></span> or <span><span title="var">b</span></span>.
     </li>
     <li>
      <span><span title="var">a</span></span> <span>*</span> <span><span title="var">b</span></span> is the Cartesian product of types <span><span title="var">a</span></span> and <span><span title="var">b</span></span>. Any term of <span><span title="var">a</span></span> <span>*</span>
        <span><span title="var">b</span></span> is made of one term of <span><span title="var">a</span></span> and one term of <span><span title="var">b</span></span> (remember tuples?).
     </li>
    </ul>
    <p>
    For an algebraic datatype, one constructor allows for defining “named
    tuples”, that is ad-hoc product types. Besides, constructors are mutually
    exclusive: you cannot define the same term using two different constructors.
    Therefore, a datatype with several constructors is reminescent of a disjoint
    union.  Coming back to the <span><span title="var">list</span></span> type, under the syntactic sugar of
    algebraic datatypes, the <span><span title="var">list</span></span> <span><span title="var">α</span></span> type is equivalent to <span><span title="var">unit</span></span> <span>+</span> <span><span title="var">α</span></span> <span>*</span> <span><span title="var">list</span></span> <span><span title="var">α</span></span>,
    where <span><span title="var">unit</span></span> models the <span><span title="var">nil</span></span> case, and <span><span title="var">α</span></span> <span>*</span> <span><span title="var">list</span></span> <span><span title="var">α</span></span> models the <span><span title="var">cons</span></span> case.
    </p><p>
    The set of types which can be defined in a language together with <span>+</span> and
    <span>*</span> form an “algebraic structure” in the mathematical sense, hence the
    name. It means the definitions of <span>+</span> and <span>*</span> have to satisfy properties
    such as commutativity or the existence of neutral elements. In this article,
    we will prove some of them in Coq. More precisely,
    </p>
    <ul>
     <li>
      <span>+</span> is commutative, that is <span><span><span>
      <math xmlns="http://www.w3.org/1998/Math/MathML">
       <semantics>
        <mrow>
         <mi mathvariant="normal">
          ∀
         </mi>
         <mo stretchy="false">
          (
         </mo>
         <mi>
          x
         </mi>
         <mo separator="true">
          ,
         </mo>
         <mi>
          y
         </mi>
         <mo stretchy="false">
          )
         </mo>
         <mo separator="true">
          ,
         </mo>
         <mtext>
          &nbsp;
         </mtext>
         <mi>
          x
         </mi>
         <mo>
          +
         </mo>
         <mi>
          y
         </mi>
         <mo>
          =
         </mo>
         <mi>
          y
         </mi>
         <mo>
          +
         </mo>
         <mi>
          x
         </mi>
        </mrow>
        <annotation encoding="application/x-tex">
         \forall (x, y),\ x + y
        = y + x
        </annotation>
       </semantics>
      </math>
     </span>
     
    </span>
    

   </span>
  </li>
  <li>
   <span>+</span> is associative, that is <span><span><span>
   <math xmlns="http://www.w3.org/1998/Math/MathML">
    <semantics>
     <mrow>
      <mi mathvariant="normal">
       ∀
      </mi>
      <mo stretchy="false">
       (
      </mo>
      <mi>
       x
      </mi>
      <mo separator="true">
       ,
      </mo>
      <mi>
       y
      </mi>
      <mo separator="true">
       ,
      </mo>
      <mi>
       z
      </mi>
      <mo stretchy="false">
       )
      </mo>
      <mo separator="true">
       ,
      </mo>
      <mtext>
       &nbsp;
      </mtext>
      <mo stretchy="false">
       (
      </mo>
      <mi>
       x
      </mi>
      <mo>
       +
      </mo>
      <mi>
       y
      </mi>
      <mo stretchy="false">
       )
      </mo>
      <mo>
       +
      </mo>
      <mi>
       z
      </mi>
      <mo>
       =
      </mo>
      <mi>
       x
      </mi>
      <mo>
       +
      </mo>
      <mo stretchy="false">
       (
      </mo>
      <mi>
       y
      </mi>
      <mo>
       +
      </mo>
      <mi>
       z
      </mi>
      <mo stretchy="false">
       )
      </mo>
     </mrow>
     <annotation encoding="application/x-tex">
      \forall (x, y, z),\ (x
        + y) + z = x + (y + z)
     </annotation>
    </semantics>
   </math>
  </span>
  
 </span>
 

</span>
</li>
<li>
<span>+</span> has a neutral element, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
 <semantics>
  <mrow>
   <mi mathvariant="normal">
    ∃
   </mi>
   <msub>
    <mi>
     e
    </mi>
    <mi>
     s
    </mi>
   </msub>
   <mo separator="true">
    ,
   </mo>
   <mtext>
    &nbsp;
   </mtext>
   <mi mathvariant="normal">
    ∀
   </mi>
   <mi>
    x
   </mi>
   <mo separator="true">
    ,
   </mo>
   <mtext>
    &nbsp;
   </mtext>
   <mi>
    x
   </mi>
   <mo>
    +
   </mo>
   <msub>
    <mi>
     e
    </mi>
    <mi>
     s
    </mi>
   </msub>
   <mo>
    =
   </mo>
   <mi>
    x
   </mi>
  </mrow>
  <annotation encoding="application/x-tex">
   \exists e_s,
        \ \forall x,\ x + e_s = x
  </annotation>
 </semantics>
</math>
</span>

</span>


</span>
</li>
<li>
<span>*</span> is commutative, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
 ∀
</mi>
<mo stretchy="false">
 (
</mo>
<mi>
 x
</mi>
<mo separator="true">
 ,
</mo>
<mi>
 y
</mi>
<mo stretchy="false">
 )
</mo>
<mo separator="true">
 ,
</mo>
<mtext>
 &nbsp;
</mtext>
<mi>
 x
</mi>
<mo>
 ∗
</mo>
<mi>
 y
</mi>
<mo>
 =
</mo>
<mi>
 y
</mi>
<mo>
 ∗
</mo>
<mi>
 x
</mi>
</mrow>
<annotation encoding="application/x-tex">
\forall (x, y),\ x * y
        = y * x
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
<li>
<span>*</span> is associative, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo separator="true">
,
</mo>
<mi>
y
</mi>
<mo separator="true">
,
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
∗
</mo>
<mi>
y
</mi>
<mo stretchy="false">
)
</mo>
<mo>
∗
</mo>
<mi>
z
</mi>
<mo>
=
</mo>
<mi>
x
</mi>
<mo>
∗
</mo>
<mo stretchy="false">
(
</mo>
<mi>
y
</mi>
<mo>
∗
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\forall (x, y, z),\ (x
        * y) * z = x * (y * z)
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
<li>
<span>*</span> has a neutral element, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∃
</mi>
<msub>
<mi>
e
</mi>
<mi>
p
</mi>
</msub>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi mathvariant="normal">
∀
</mi>
<mi>
x
</mi>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
∗
</mo>
<msub>
<mi>
e
</mi>
<mi>
p
</mi>
</msub>
<mo>
=
</mo>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
\exists e_p,
        \ \forall x,\ x * e_p = x
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
<li>
The distributivity of <span>+</span> and <span>*</span>, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo separator="true">
,
</mo>
<mi>
y
</mi>
<mo separator="true">
,
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
∗
</mo>
<mo stretchy="false">
(
</mo>
<mi>
y
</mi>
<mo>
+
</mo>
<mi>
z
</mi>
<mo stretchy="false">
)
</mo>
<mo>
=
</mo>
<mi>
x
</mi>
<mo>
∗
</mo>
<mi>
y
</mi>
<mo>
+
</mo>
<mi>
x
</mi>
<mo>
∗
</mo>
<mi>
z
</mi>
</mrow>
<annotation encoding="application/x-tex">
\forall
        (x, y, z),\ x * (y + z) = x * y + x * z
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
<li>
<span>*</span> has an absorbing element, that is <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∃
</mi>
<msub>
<mi>
e
</mi>
<mi>
a
</mi>
</msub>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi mathvariant="normal">
∀
</mi>
<mi>
x
</mi>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
∗
</mo>
<msub>
<mi>
e
</mi>
<mi>
a
</mi>
</msub>
<mo>
=
</mo>
<msub>
<mi>
e
</mi>
<mi>
a
</mi>
</msub>
</mrow>
<annotation encoding="application/x-tex">
\exists e_a,
        \ \forall x, \ x * e_a = e_a
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</li>
</ul>
<p>
For the record, the <span><span title="var">sum</span></span> and <span><span title="var">prod</span></span> types are defined in Coq as follows:
</p>
<pre>Inductive sum (A B : Type) : Type :=
| inl : A -&gt; sum A B
| inr : B -&gt; sum A B

Inductive prod (A B : Type) : Type :=
| pair : A -&gt; B -&gt; prod A B
</pre>

<ol>
<li>
<a href="#1">An Equivalence for <span><span title="keyword">Type</span></span></a>
<ol>
<li>
<a href="#2">Introducing <span><span title="var">type_equiv</span></span></a>
</li>
<li>
<a href="#3"><span><span title="var">type_equiv</span></span> is an Equivalence</a>
</li>
<li>
<a href="#4">Examples</a>
<ol>
<li>
<a href="#5"><span><span title="var">list</span></span>’s Canonical Form</a>
</li>
<li>
<a href="#6"><span><span title="var">list</span></span> is a Morphism</a>
</li>
<li>
<a href="#7"><span><span title="var">nat</span></span> is a Special-Purpose <span><span title="var">list</span></span></a>
</li>
<li>
<a href="#8">Non-empty Lists</a>
</li>
</ol>
</li>
</ol>
</li>
<li>
<a href="#9">The <span><span title="var">sum</span></span> Operator</a>
<ol>
<li>
<a href="#10"><span><span title="var">sum</span></span> is a Morphism</a>
</li>
<li>
<a href="#11"><span><span title="var">sum</span></span> is Commutative</a>
</li>
<li>
<a href="#12"><span><span title="var">sum</span></span> is Associative</a>
</li>
<li>
<a href="#13"><span><span title="var">sum</span></span> has a Neutral Element</a>
</li>
</ol>
</li>
<li>
<a href="#14">The <span><span title="var">prod</span></span> Operator</a>
<ol>
<li>
<a href="#15"><span><span title="var">prod</span></span> is a Morphism</a>
</li>
<li>
<a href="#16"><span><span title="var">prod</span></span> is Commutative</a>
</li>
<li>
<a href="#17"><span><span title="var">prod</span></span> is Associative</a>
</li>
<li>
<a href="#18"><span><span title="var">prod</span></span> has a Neutral Element</a>
</li>
</ol>
</li>
<li>
<a href="#19"><span><span title="var">prod</span></span> has an Absorbing Element</a>
</li>
<li>
<a href="#20"><span><span title="var">prod</span></span> and <span><span title="var">sum</span></span> Distributivity</a>
</li>
<li>
<a href="#21">Bonus: Algebraic Datatypes and Metaprogramming</a>
</li>
</ol>

<div id="history">
<details>
<summary>
Revisions
</summary>
<p>
This revisions table has been automatically generated
    from <a href="https://code.soap.coffee/writing/lthms.git">the <code>git</code> history
    of this website repository</a>, and the change
    descriptions may not always be as useful as they
    should.
</p>
<p>
You can consult the source of this file in its current
    version <a href="https://code.soap.coffee/writing/lthms.git/tree/site/posts/AlgebraicDatatypes.v">here</a>.
</p>
<table>
<tbody>
<tr>
<td id="modified-at">
2020-07-12
</td>
<td>
More spellchecking and typos
</td>
<td>
<a href="https://code.soap.coffee/writing/lthms.git/commit/site/posts/AlgebraicDatatypes.v/?id=48a9b49581e953ce7f7c6c36da107e07e3c7345f">
        48a9b49
      </a>
</td>
</tr>
<tr>
<td>
2020-07-12
</td>
<td>
Invert the table of contents and the revision tables
</td>
<td>
<a href="https://code.soap.coffee/writing/lthms.git/commit/site/posts/AlgebraicDatatypes.v/?id=0a750a2f3cd95842f22b89bf23f92e7781291a8b">
        0a750a2
      </a>
</td>
</tr>
<tr>
<td>
2020-07-12
</td>
<td>
Spellchecking
</td>
<td>
<a href="https://code.soap.coffee/writing/lthms.git/commit/site/posts/AlgebraicDatatypes.v/?id=cec5638c1a23303723464bf5f73cea475fb4d94c">
        cec5638
      </a>
</td>
</tr>
<tr>
<td id="created-at">
2020-07-12
</td>
<td>
New article on Algebraic Datatypes
</td>
<td>
<a href="https://code.soap.coffee/writing/lthms.git/commit/site/posts/AlgebraicDatatypes.v/?id=41007fce2a333ba78be703c35f4afccade3369e5">
        41007fc
      </a>
</td>
</tr>
</tbody>
</table>
</details>
</div>
</div>

<div>
<h2 id="1">
An Equivalence for <span><span title="keyword">Type</span></span>
</h2>
<p>
Algebraic structures come with <i>equations</i> expected to be true.  This means
    there is an implicit dependency which is —to my opinion— too easily
    overlooked: the definition of <span>=</span>. In Coq, <span>=</span> is a built-in relation that
    states that two terms are “equal” if they can be reduced to the same
    “hierarchy” of constructors. This is too strong in the general case, and in
    particular for our study of algebraic structures of <span><span title="keyword">Type</span></span>. It is clear
    that, to Coq’s opinion, <span><span title="var">α</span></span> <span>+</span> <span><span title="var">β</span></span> is not structurally <i>equal</i> to <span><span title="var">β</span></span> <span>+</span> <span><span title="var">α</span></span>, yet
    we will have to prove they are “equivalent.”
</p>
<h3 id="2">
Introducing <span><span title="var">type_equiv</span></span>
</h3>
<p>
Since <span>=</span> for <span><span title="keyword">Type</span></span> is not suitable for reasoning about algebraic
    datatypes, we introduce our own equivalence relation, denoted <span>==</span>.  We say
    two types <span><span title="var">α</span></span> and <span><span title="var">β</span></span> are equivalent up to an isomorphism (denoted by <span><span title="var">α</span></span> <span>==</span>
    <span><span title="var">β</span></span>) when for any term of type <span><span title="var">α</span></span>, there exists a counter-part term of type
    <span><span title="var">β</span></span> and vice versa. In other words, <span><span title="var">α</span></span> and <span><span title="var">β</span></span> are equivalent if we can
    exhibit two functions <span><span title="var">f</span></span> and <span><span title="var">g</span></span> such that:
</p>
<p><span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
:
</mo>
<mi>
α
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
=
</mo>
<mi>
g
</mi>
<mo stretchy="false">
(
</mo>
<mi>
f
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo stretchy="false">
)
</mo>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\forall (x : α),\ x = g(f(x))
</annotation>
</semantics>
</math>
</span>

</span>


</span></p>
<p><span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
y
</mi>
<mo>
:
</mo>
<mi>
β
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
y
</mi>
<mo>
=
</mo>
<mi>
f
</mi>
<mo stretchy="false">
(
</mo>
<mi>
g
</mi>
<mo stretchy="false">
(
</mo>
<mi>
y
</mi>
<mo stretchy="false">
)
</mo>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\forall (y : β),\ y = f(g(y))
</annotation>
</semantics>
</math>
</span>

</span>


</span></p><p>
In Coq, this translates into the following inductive types.
</p></div>

<div><p>
As mentioned earlier, we prove two types are equivalent by exhibiting
    two functions, and proving these functions satisfy two properties. We
    introduce a
</p><tt>
Ltac
</tt><p>
notation to that end.
</p></div>
<div>

<p><span title="keyword">Tactic Notation</span> "equiv" "with" <span title="var">uconstr</span>(<span title="var">f</span>) "and" <span title="var">uconstr</span>(<span title="var">g</span>)<br>
&nbsp;&nbsp;:= <span title="tactic">apply</span> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#mk_type_equiv"><span title="constructor">mk_type_equiv</span></a> <span title="var">f</span> <span title="var">g</span>).</p></div>
<div><p>
The tactic <span><span title="var">equiv</span></span> <span><span title="keyword">with</span></span> <span><span title="var">f</span></span> <span><span title="var">and</span></span> <span><span title="var">g</span></span> will turn a goal of the form <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span> into
    two subgoals to prove <span><span title="var">f</span></span> and <span><span title="var">g</span></span> form an isomorphism.
</p>
<h3 id="3">
<span><span title="var">type_equiv</span></span> is an Equivalence
</h3>

<p><span><span title="var">type_equiv</span></span> is an equivalence, and we can prove it by demonstrating it is
    (1) reflexive, (2) symmetric, and (3) transitive.
</p>
<p><span><span title="var">type_equiv</span></span> is reflexive.
</p></div>

<div><p>
This proof is straightforward. A type <span><span title="var">α</span></span> is equivalent to itself because:
</p>
<p><span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi mathvariant="normal">
∀
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo>
:
</mo>
<mi>
α
</mi>
<mo stretchy="false">
)
</mo>
<mo separator="true">
,
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
<mo>
=
</mo>
<mi>
i
</mi>
<mi>
d
</mi>
<mo stretchy="false">
(
</mo>
<mi>
i
</mi>
<mi>
d
</mi>
<mo stretchy="false">
(
</mo>
<mi>
x
</mi>
<mo stretchy="false">
)
</mo>
<mo stretchy="false">
)
</mo>
</mrow>
<annotation encoding="application/x-tex">
\forall (x : α),\ x = id(id(x))
</annotation>
</semantics>
</math>
</span>

</span>


</span>
</p></div>
<div>

<p><span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="var">now</span> <span title="var">equiv</span> <span title="keyword">with</span> (@<a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#id"><span title="definition">id</span></a> <span title="var">α</span>) <span title="var">and</span> (@<a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#id"><span title="definition">id</span></a> <span title="var">α</span>).<br>
<span title="keyword">Qed</span>.</p></div>
<p><span><span title="var">type_equiv</span></span> is symmetric.
</p>

<p>
If <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span>, then we know there exists two functions <span><span title="var">f</span></span> and <span><span title="var">g</span></span> which
    satisfy the expected properties. We can “swap” them to prove that <span><span title="var">β</span></span> <span>==</span> <span><span title="var">α</span></span>.
</p>
<div>

<p><span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="tactic">destruct</span> <span title="var">equ</span> <span title="keyword">as</span> [<span title="var">f</span> <span title="var">g</span> <span title="var">equ1</span> <span title="var">equ2</span>].<br>
&nbsp;&nbsp;<span title="var">now</span> <span title="var">equiv</span> <span title="keyword">with</span> <span title="var">g</span> <span title="var">and</span> <span title="var">f</span>.<br>
<span title="keyword">Qed</span>.</p></div>
<p><span><span title="var">type_equiv</span></span> is transitive
</p>

<div><p>
If <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span>, we know there exists two functions <span><span title="var">fα</span></span> and <span><span title="var">gβ</span></span> which satisfy
    the expected properties of <span><span title="var">type_equiv</span></span>. Similarly, because <span><span title="var">β</span></span> <span>==</span> <span><span title="var">γ</span></span>, we
    know there exists two additional functions <span><span title="var">fβ</span></span> and <span><span title="var">gγ</span></span>. We can compose
    these functions together to prove <span><span title="var">α</span></span> <span>==</span> <span><span title="var">γ</span></span>.
</p><p>
As a reminder, composing two functions <span><span title="var">f</span></span> and <span><span title="var">g</span></span> (denoted by <span><span title="var">f</span></span> <span>&gt;&gt;&gt;</span> <span><span title="var">g</span></span>
    thereafter) consists in using the result of <span><span title="var">f</span></span> as the input of <span><span title="var">g</span></span>:
</p></div>
<div>

<p><span title="keyword">Infix</span> <a name="e0ed7cfa6eddbb0bdd997b69ba91f3de"><span title="notation">"</span></a>&gt;&gt;&gt;" := (<span title="keyword">fun</span> <span title="var">f</span> <span title="var">g</span> <span title="var">x</span> =&gt; <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#g"><span title="variable">g</span></a> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#f"><span title="variable">f</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#x"><span title="variable">x</span></a>)) (<span title="tactic">at</span> <span title="keyword">level</span> 70).</p></div>
<p>
Then comes the proof.
</p>
<div>

<p><span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="tactic">destruct</span> <span title="var">equ1</span> <span title="keyword">as</span> [<span title="var">fα</span> <span title="var">gβ</span> <span title="var">equαβ</span> <span title="var">equβα</span>],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">equ2</span> <span title="keyword">as</span> [<span title="var">fβ</span> <span title="var">gγ</span> <span title="var">equβγ</span> <span title="var">equγβ</span>].<br>
&nbsp;&nbsp;<span title="var">equiv</span> <span title="keyword">with</span> (<span title="var">fα</span> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#e0ed7cfa6eddbb0bdd997b69ba91f3de"><span title="notation">&gt;&gt;&gt;</span></a> <span title="var">fβ</span>) <span title="var">and</span> (<span title="var">gγ</span> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#e0ed7cfa6eddbb0bdd997b69ba91f3de"><span title="notation">&gt;&gt;&gt;</span></a> <span title="var">gβ</span>).<br>
&nbsp;&nbsp;+ <span title="tactic">intros</span> <span title="var">x</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="tactic">rewrite</span> &lt;- <span title="var">equβγ</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equαβ</span>.<br>
&nbsp;&nbsp;+ <span title="tactic">intros</span> <span title="var">x</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="tactic">rewrite</span> &lt;- <span title="var">equβα</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equγβ</span>.<br>
<span title="keyword">Qed</span>.</p></div>
<p>
The Coq standard library introduces the <span><span title="var">Equivalence</span></span> type class. We can
    provide an instance of this type class for <span><span title="var">type_equiv</span></span>, using the three
    lemmas we have proven in this section.
</p>

<div>
<h3 id="4">
Examples
</h3>

<h4 id="5">
<span><span title="var">list</span></span>’s Canonical Form
</h4>
<p>
We now come back to our initial example, given in the Introduction of this
    write-up. We can prove our assertion, that is <span><span title="var">list</span></span> <span><span title="var">α</span></span> <span>==</span> <span><span title="var">unit</span></span> <span>+</span> <span><span title="var">α</span></span> <span>*</span> <span><span title="var">list</span></span>
    <span><span title="var">α</span></span>.
</p></div>

<div>
<h4 id="6">
<span><span title="var">list</span></span> is a Morphism
</h4>
<p>
This means that if <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span>, then <span><span title="var">list</span></span> <span><span title="var">α</span></span> <span>==</span> <span><span title="var">list</span></span> <span><span title="var">β</span></span>. We prove this by
    defining an instance of the <span><span title="var">Proper</span></span> type class.
</p></div>

<div><p>
The use of the <span><span title="var">Proper</span></span> type class allows for leveraging hypotheses of the
    form <span><span title="var">α</span></span> <span>==</span> <span><span title="var">β</span></span> with the <span><span title="tactic">rewrite</span></span> tactic. I personally consider providing
    instances of <span><span title="var">Proper</span></span> whenever it is possible to be a good practice, and
    would encourage any Coq programmers to do so.
</p>
<h4 id="7">
<span><span title="var">nat</span></span> is a Special-Purpose <span><span title="var">list</span></span>
</h4>
<p>
Did you notice? Now, using <span><span title="var">type_equiv</span></span>, we can prove it!
</p></div>
<div>

<p><span title="keyword">Lemma</span> <a name="nat_and_list"><span title="lemma">nat_and_list</span></a> : <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#nat"><span title="inductive">nat</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#12489c9c79e91749bd1f337dd0c899e9"><span title="notation">==</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#list"><span title="inductive">list</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#unit"><span title="inductive">unit</span></a>.</p><p>


<span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="var">equiv</span> <span title="keyword">with</span> (<span title="keyword">fix</span> <span title="var">to_list</span> <span title="var">n</span> :=<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="keyword">match</span> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#n"><span title="variable">n</span></a> <span title="keyword">with</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#S"><span title="constructor">S</span></a> <span title="var">m</span> =&gt; <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#tt"><span title="constructor">tt</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#cbcf67aac0c2a85b8d93d37de9969adf"><span title="notation">::</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#to_list"><span title="variable">to_list</span></a> <span title="var">m</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <span title="var">_</span> =&gt; <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Lists.List.html#ae9a5e1034e143b218b09d8e454472bd"><span title="notation">[]</span></a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="keyword">end</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">and</span> (<span title="keyword">fix</span> <span title="var">of_list</span> <span title="var">l</span> :=<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="keyword">match</span> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#l"><span title="variable">l</span></a> <span title="keyword">with</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <span title="var">_</span> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#cbcf67aac0c2a85b8d93d37de9969adf"><span title="notation">::</span></a> <span title="var">rst</span> =&gt; <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#S"><span title="constructor">S</span></a> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#of_list"><span title="variable">of_list</span></a> <span title="var">rst</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| <span title="var">_</span> =&gt; 0<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="keyword">end</span>).<br>
&nbsp;&nbsp;+ <span title="tactic">induction</span> <span title="var">x</span>; <span title="tactic">auto</span>.<br>
&nbsp;&nbsp;+ <span title="tactic">induction</span> <span title="var">y</span>; <span title="tactic">auto</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="tactic">rewrite</span> &lt;- <span title="var">IHy</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">now</span> <span title="tactic">destruct</span> <span title="var">a</span>.<br>
<span title="keyword">Qed</span>.</p></div>
<div>
<h4 id="8">
Non-empty Lists
</h4>
<p>
We can introduce a variant of <span><span title="var">list</span></span> which contains at least one element by
    modifying the <span><span title="var">nil</span></span> constructor so that it takes one argument instead of
    none.
</p></div>

<p>
We can demonstrate the relation between <span><span title="var">list</span></span> and <span><span title="var">non_empty_list</span></span>, which
    reveals an alternative implementation of <span><span title="var">non_empty_list</span></span>. More precisely,
    we can prove that <span><span title="keyword">forall</span></span> <span>(<span title="var">α</span></span> <span>:</span> <span><span title="keyword">Type</span>),</span> <span><span title="var">non_empty_list</span></span> <span><span title="var">α</span></span> <span>==</span> <span><span title="var">α</span></span> <span>*</span> <span><span title="var">list</span></span> <span><span title="var">α</span></span>.  It
    is a bit more cumbersome, but not that much. We first define the conversion
    functions, then prove they satisfy the properties expected by
    <span><span title="var">type_equiv</span></span>.
</p>

<div>
<h2 id="9">
The <span><span title="var">sum</span></span> Operator
</h2>

<h3 id="10">
<span><span title="var">sum</span></span> is a Morphism
</h3>
<p>
This means that if <span><span title="var">α</span></span> <span>==</span> <span><span title="var">α'</span></span> and <span><span title="var">β</span></span> <span>==</span> <span><span title="var">β'</span></span>, then <span><span title="var">α</span></span> <span>+</span> <span><span title="var">β</span></span> <span>==</span> <span><span title="var">α'</span></span> <span>+</span> <span><span title="var">β'</span></span>. To
    prove this, we compose together the functions whose existence is implied by
    <span><span title="var">α</span></span> <span>==</span> <span><span title="var">α'</span></span> and <span><span title="var">β</span></span> <span>==</span> <span><span title="var">β'</span></span>. To that end, we introduce the auxiliary function
    <span><span title="var">lr_map</span></span>.
</p></div>

<p>
Then, we prove <span><span title="var">sum</span></span> is a morphism by defining a <span><span title="var">Proper</span></span> instance.
</p>
<div>

<p><span title="keyword">Instance</span> <a name="sum_Proper"><span title="instance">sum_Proper</span></a><br>
&nbsp;&nbsp;: <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Classes.Morphisms.html#Proper"><span title="class">Proper</span></a> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#type_equiv"><span title="inductive">type_equiv</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Classes.Morphisms.html#8dc5652698a6e16f72dd37bd17d3b973"><span title="notation">==&gt;</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#type_equiv"><span title="inductive">type_equiv</span></a> <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Classes.Morphisms.html#8dc5652698a6e16f72dd37bd17d3b973"><span title="notation">==&gt;</span></a> <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#type_equiv"><span title="inductive">type_equiv</span></a>) <a href="https://coq.inria.fr/distrib/current/stdlib//Coq.Init.Datatypes.html#sum"><span title="inductive">sum</span></a>.</p><p>


<span title="keyword">Proof</span>.<br>
&nbsp;&nbsp;<span title="var">add_morphism_tactic</span>.<br>
&nbsp;&nbsp;<span title="tactic">intros</span> <span title="var">α</span> <span title="var">α'</span> [<span title="var">fα</span> <span title="var">gα'</span> <span title="var">equαα'</span> <span title="var">equα'α</span>]<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">β</span> <span title="var">β'</span> [<span title="var">fβ</span> <span title="var">gβ'</span> <span title="var">equββ'</span> <span title="var">equβ'β</span>].<br>
&nbsp;&nbsp;<span title="var">equiv</span> <span title="keyword">with</span> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#lr_map_sum"><span title="definition">lr_map_sum</span></a> <span title="var">fα</span> <span title="var">fβ</span>)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span title="var">and</span> (<a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html#lr_map_sum"><span title="definition">lr_map_sum</span></a> <span title="var">gα'</span> <span title="var">gβ'</span>).<br>
&nbsp;&nbsp;+ <span title="tactic">intros</span> [<span title="var">x</span>|<span title="var">y</span>]; <span title="var">cbn</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;++ <span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equαα'</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;++ <span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equββ'</span>.<br>
&nbsp;&nbsp;+ <span title="tactic">intros</span> [<span title="var">x</span>|<span title="var">y</span>]; <span title="var">cbn</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;++ <span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equα'α</span>.<br>
&nbsp;&nbsp;&nbsp;&nbsp;++ <span title="var">now</span> <span title="tactic">rewrite</span> &lt;- <span title="var">equβ'β</span>.<br>
<span title="keyword">Qed</span>.</p></div>


<div>
<h3 id="12">
<span><span title="var">sum</span></span> is Associative
</h3>
<p>
The associativity of <span><span title="var">sum</span></span> is straightforward to prove, and should not pose
    a particular challenge to perspective readers; if we assume that this
    article is well-written, that is!
</p></div>

<div>
<h3 id="13">
<span><span title="var">sum</span></span> has a Neutral Element
</h3>
<p>
We need to find a type <span><span title="var">e</span></span> such that <span><span title="var">α</span></span> <span>+</span> <span><span title="var">e</span></span> <span>==</span> <span><span title="var">α</span></span> for any type <span><span title="var">α</span></span>
    (similarly to <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi>
x
</mi>
<mtext>
&nbsp;
</mtext>
<mo>
+
</mo>
<mtext>
&nbsp;
</mtext>
<mn>
0
</mn>
<mtext>
&nbsp;
</mtext>
<mo>
=
</mo>
<mtext>
&nbsp;
</mtext>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x~+~0~=~x
</annotation>
</semantics>
</math>
</span>

</span>


</span>
 for any natural
    number <span><span><span>
<math xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow>
<mi>
x
</mi>
</mrow>
<annotation encoding="application/x-tex">
x
</annotation>
</semantics>
</math>
</span>

</span>


</span>
 that is).
</p><p>
Any empty type (that is, a type with no term such as <span><span title="var">False</span></span>) can act as the
    …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html">https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html</a></em></p>]]>
            </description>
            <link>https://soap.coffee/~lthms/posts/AlgebraicDatatypes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812854</guid>
            <pubDate>Sun, 12 Jul 2020 17:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wt – C++ Web Toolkit]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 78 (<a href="https://news.ycombinator.com/item?id=23812791">thread link</a>) | @gtirloni
<br/>
July 12, 2020 | https://www.webtoolkit.eu/wt | <a href="https://web.archive.org/web/*/https://www.webtoolkit.eu/wt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="oses8my">
    <section>
      
      
      <div>
        <div>
          <div>
            <div>
              <div>
                
                <p data-wow-delay="0.3s">
                  
    
      Wt is a web GUI library in modern C++.
    
    
    Quickly develop highly interactive web UIs with widgets,
    without having to write a single line of JavaScript.
    Wt handles all request handling and page rendering
    for you, so you can focus on functionality.
  
                </p>
                
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </section>
    <section>
      <div>
        
        <div>
          <p>
    You don't want to focus on details like request handling or page rendering.
    You want your application to continue to work
    even when JavaScript is unavailable.
    You just want to write your web application in C++ without sacrificing interactivity.
    Wt allows you to focus on functionality and create highly interactive, secure, and future proof applications
    quickly.
  </p>
        </div>
        <div>
	  
    <div data-wow-delay="0.3s">
      <div>
        <p><img alt="Save Time" src="https://www.webtoolkit.eu/images/icon-development@2x.png" width="121px"></p><h3>Save Time</h3>
         <p>
    Wt handles all the nitty-gritty of requests and responses and
    client-side JavaScript, and allows you to focus on functionality
    in pure C++.
  </p>
       </div>
    </div>
  
	  
    <div data-wow-delay="0.1s">
      <div>
        <p><img alt="Built to Maintain" src="https://www.webtoolkit.eu/images/icon-products@2x.png" width="98px"></p><h3>Built to Maintain</h3>
         <p>
    Wt's widget abstraction represents HTML elements as C++ objects, allowing
    them to be easily composable and extendable.
  </p>
       </div>
    </div>
  
	  
    <div data-wow-delay="0.1s">
      <div>
        <p><img alt="Future Proof" src="https://www.webtoolkit.eu/images/icon-support@2x.png" width="86px"></p><h3>Future Proof</h3>
         <p>
    Stay up to date with the latest web technologies without changing your code, thanks to Wt's stable API.
    <!--    Wt uses Ajax and WebSockets when available and can fall back on plain HTML automatically, without
    the need for specific code.-->
  </p>
       </div>
    </div>
  
	  
    <div data-wow-delay="0.25s">
      <div>
        <p><img alt="Secure" src="https://www.webtoolkit.eu/images/icon-smartphone@2x.png" width="52px"></p><h3>Secure</h3>
         <p>
    Wt is designed to be resilient against the most common types of exploits:
    SQL injection,  XSS and CSRF vulnerabilities.
  </p>
       </div>
    </div>
  
        </div>
      </div>
    </section>
    
    <section>
      <div>
        <div>
          <p>
            <h3>
 	      
    Contact us for more information
    <br>
    or a personalised quotation
  
            </h3>
          </p>
          
        </div>
      </div>
    </section>
  
    
    <section>
      <div>
        
        <div>
          <p>
    
    Wt has a lot to offer. It includes the essential basic widgets and building blocks to
    build web applications, but also offers built-in security, PDF rendering, a 2D and 3D painting system, 
    an object-relational mapping library, a charting library, and an authentication framework.
  
    <a href="https://www.webtoolkit.eu/wt/features?wtd=epq0V20rQDfVsoDd">You can see the full list of features here</a>, but here's a short overview:
  </p>
        </div>
      </div>
      <div>
        <div>
	  
    
  
	  
    <div>
      <div>
        <hr>
          <p><img src="https://www.webtoolkit.eu/images/icon-purple-desktop@2x.png" width="66px">
          </p>
          <h4>Server side, client optimized</h4>
          <p>Wt employs a signal-slot system. Instead of worrying about the sending of Ajax requests and serving of pages, you can simply connect the click of a button to a callback function on the server.
    
      <a href="https://www.webtoolkit.eu/widgets/forms#form-simple">Take a look at this example in the widget gallery.</a>
    
    
    Wt will use whatever technology available for communication: Ajax or WebSockets, but will fall back on full HTML
    page loads when JavaScript is unavailable. This makes Wt applications accessible to any browser or web crawler.
  </p>
      </div>
    </div>
  
	  
    <div>
      <div>
        <hr>
          <p><img src="https://www.webtoolkit.eu/images/icon-purple-laptop@2x.png" width="75px">
          </p>
          <h4>Built-in security</h4>
          <p>
    Wt automatically protects against misuse by only allowing visible and enabled widgets to be interacted with.
    This also helps to avoid CSRF attacks, which are doubly avoided because Wt does not store session information in cookies.
    By using the widget abstraction, Wt discourages the inserting of raw HTML into a web page, preventing XSS attacks.
    
      Wt::Dbo prevents SQL injection by encouraging the use of prepared statements when accessing the database.
    
    Wt also includes an authentication and registration system with support for OAuth
    providers like Google, Facebook, and OpenID Connect.
  </p>
      </div>
    </div>
  
        </div>
        <div>
	  
    
  
	  
    <div>
      <div>
        <hr>
          <p><img src="https://www.webtoolkit.eu/images/icon-purple-servers@2x.png" width="67px">
          </p>
          <h4>2D and 3D painting system</h4>
          <p>
    Use a single 2D drawing API with many backends (PNG, JPEG, SVG, HTML canvas, VML, and PDF) so you only need to write
    your drawing code once to support any web browser and save to many formats. Write server-side (OpenGL) and
    client-side (WebGL) 3D graphics with a uniform API. Wt's 2D and 3D charting libraries were built on top of this
    graphics API.
    
      <a href="https://www.webtoolkit.eu/widgets/graphics-charts">Check out the examples in the widget gallery.</a>
    
    
  </p>
      </div>
    </div>
  
	  
    
  
        </div>
      </div>
      
    </section>
    <section>
      <div>
        
        <div id="oses8f1"><div id="oses8f0">
    <h4><a id="oses8ez" href="https://www.webtoolkit.eu/wt/news/2020/04/20/wt_3_6_1___4_3_1?wtd=epq0V20rQDfVsoDd"><span id="oses8ey">Wt 3.6.1 &amp; 4.3.1</span></a></h4>
    
    
    <div>
      <p>Wt 4.3.0 was released almost a month ago, so itâ€™s about time for a patch release. Wt 4.3.1 (and Wt 3.6.1) is a tiny patch release, with the most notable fix being an issue in the destructor of WWebWidget when user-defined ids were used. There will be no JWt 4.3.1 since nothing has changed to JWt.</p>
<p>Read the release notes for more information.</p>
<p>Here are the links:</p>



    </div>
    
  </div></div>
      </div>
    </section>
    <section>
      
    </section>
    
  </div></div>]]>
            </description>
            <link>https://www.webtoolkit.eu/wt</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812791</guid>
            <pubDate>Sun, 12 Jul 2020 17:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best way to keep users safe while using Google Analytics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812769">thread link</a>) | @tsl143
<br/>
July 12, 2020 | https://itsopensource.com/best-way-to-keep-users-safe-while-using-google-analytics/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/best-way-to-keep-users-safe-while-using-google-analytics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Google Analytics is the most used web analytics service over the web, Google has made it pretty easy and effective in terms of implementation and dashboard UI. It gives detailed demographic data and many other features that justify its vast usage.
The most common and easiest way to enable google analytics on any website is by adding the tag manager (the code snippet provided) to the website.</p>
<div data-language="html"><pre><code>
<span><span><span>&lt;</span>script</span> <span>async</span> <span>src</span><span><span>=</span><span>"</span>https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX-1<span>"</span></span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  window<span>.</span>dataLayer <span>=</span> window<span>.</span>dataLayer <span>||</span> <span>[</span><span>]</span><span>;</span>
  <span>function</span> <span>gtag</span><span>(</span><span>)</span><span>{</span>dataLayer<span>.</span><span>push</span><span>(</span>arguments<span>)</span><span>;</span><span>}</span>
  <span>gtag</span><span>(</span><span>'js'</span><span>,</span> <span>new</span> <span>Date</span><span>(</span><span>)</span><span>)</span><span>;</span>

  <span>gtag</span><span>(</span><span>'config'</span><span>,</span> <span>'UA-XXXXXXXXX-1'</span><span>)</span><span>;</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div>
<h3>Problem</h3>
<div><p>Adding a Tag manager is <strong>allowing google to run some code on your website</strong> whenever someone visits the website or do some action (I would request to read this line once more). Based on the options selected on the analytics UI, Google inserts the scripts into the website, sends the data back with <code>HTTP requests</code>. Data includes the complete URL(with query params) and many other details that may be classified as <code>Personal Identifiable Information(PII)</code>. <a href="https://twitter.com/konarkmodi">Konark Modi</a>, a privacy advocate, has written a detailed case study on how sensitive user data or PII is getting leaked to third parties, including Google Analytics, in <a href="https://medium.com/free-code-camp/how-airlines-dont-care-about-your-privacy-case-study-emirates-com-6271b3b8474b">this blog</a>.
As a developer, we always want to have complete control over whatever is being served on our website. Google tag managers kind of blow this up.</p><p>
<span>
      <span></span>
  <img alt="Leak 1" title="Leak 1" src="https://itsopensource.com/static/aea8f6f6f589d732daefaf4c628114b8/799d3/leak1.png" srcset="https://itsopensource.com/static/aea8f6f6f589d732daefaf4c628114b8/00d96/leak1.png 148w,
https://itsopensource.com/static/aea8f6f6f589d732daefaf4c628114b8/0b23c/leak1.png 295w,
https://itsopensource.com/static/aea8f6f6f589d732daefaf4c628114b8/799d3/leak1.png 590w,
https://itsopensource.com/static/aea8f6f6f589d732daefaf4c628114b8/053f1/leak1.png 875w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span><br>
<span>
      <span></span>
  <img alt="Leak 2" title="Leak 2" src="https://itsopensource.com/static/b6189442e19ff3336b225f97ef1a8d58/799d3/leak2.png" srcset="https://itsopensource.com/static/b6189442e19ff3336b225f97ef1a8d58/00d96/leak2.png 148w,
https://itsopensource.com/static/b6189442e19ff3336b225f97ef1a8d58/0b23c/leak2.png 295w,
https://itsopensource.com/static/b6189442e19ff3336b225f97ef1a8d58/799d3/leak2.png 590w,
https://itsopensource.com/static/b6189442e19ff3336b225f97ef1a8d58/053f1/leak2.png 875w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p></div>
<h3>Solution</h3>
<p>This can be avoided by using <strong>Google Measurement protocol</strong>.</p>
<p><em>From the <a href="https://developers.google.com/analytics/devguides/collection/protocol/v1">docs</a></em></p>
<blockquote>
<p>The Google Analytics Measurement Protocol allows developers to make HTTP requests to send raw user interaction data directly to Google Analytics servers</p>
</blockquote>
<p>TLDR; Do not load google scripts but, create and send HTTP requests by yourself. This gives way more control over what you want to send to google and ensures your complete control over your website. You can send Requests for whatever action needs to be recorded for analytics. It can be just page visits, clicks, or any event.</p>
<h4>How</h4>
<p>Analytics tool receives the data via query parameters of the request, a typical request looks like this  </p>
<div data-language="text"><pre><code>POST /collect HTTP/1.1
Host: www.google-analytics.com

payload_data</code></pre></div>
<p>Mandatory parameters are </p>
<div data-language="text"><pre><code>v=1              // Version of the tool.
&amp;tid=UA-XXXXX-Y  // Tracking ID / Property ID.
&amp;cid=555         // Anonymous Client ID.
&amp;t=              // Hit Type</code></pre></div>
<p>Google provides a number of parameters in case you want more detailed analytics say for e-commerce, check the parameter guide <a href="https://developers.google.com/analytics/devguides/collection/protocol/v1/parameters">here</a>, some interesting parameters which can be controlled are</p>
<ul>
<li><code>dr</code> - Document referrer //  = document.referrer</li>
<li><code>dl</code> - Location URL // = document.location.origin + document.location.pathname (also may be document.location.search)</li>
<li><code>aip</code> - Anonymize IP, if present the IP address of the sender will be anonymized // = 1</li>
<li><code>npa</code> - Disable advertising personalization - if enabled  it won’t be used when populating a remarketing audience for “past purchasers” // = 1</li>
</ul>
<p><strong>Lesser</strong> the parameters, <strong>lesser</strong> the data sent, <strong>better</strong> the privacy.</p>
<p>Google also provides a tool to check and create a proper hit via <a href="https://ga-dev-tools.appspot.com/hit-builder/">Hit Builder</a></p>
<p>If you find this a bit exhausting, then atleast follow the best practices to make sure You are not sending the user’s personal data to google.
<a href="https://support.google.com/analytics/answer/6366371">https://support.google.com/analytics/answer/6366371</a></p>
<center><strong>--- Keep your users safe ---</strong></center></section></div>]]>
            </description>
            <link>https://itsopensource.com/best-way-to-keep-users-safe-while-using-google-analytics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812769</guid>
            <pubDate>Sun, 12 Jul 2020 16:58:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Soul of a New Debugger]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812677">thread link</a>) | @nbaksalyar
<br/>
July 12, 2020 | https://nbaksalyar.github.io/2020/07/12/soul-of-a-new-debugger.html | <a href="https://web.archive.org/web/*/https://nbaksalyar.github.io/2020/07/12/soul-of-a-new-debugger.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			

<time datetime="2020-07-12 00:00:00 +0000">12 Jul 2020</time>

<p><em>This blog post is a follow-up to <a href="https://nbaksalyar.github.io/2020/05/19/rust-debug.html">A Future for Rust Debugging</a></em></p>

<p>Why developers are reluctant to use interactive debuggers and prefer <code>print</code>s instead?</p>

<p>This is a question that has been perplexing me, and while it’s not possible to have a definite answer, we can make some educated guesses.
<code>print</code>s are simple and very effective: you don’t have to painstakingly step through your code to understand what’s happening
and you don’t need any external tools – everything is already there, you just need to add a few statements and run your program again.</p>

<p>Here’s the trick, though: if you code in a language like Python, JavaScript or Ruby, all you need to do to run your program is to execute it.
But there is a bit more friction with compiled native languages like C++ or Rust: every recompilation step costs time, and with larger
code bases with many dependencies it can quickly become non-negligible. It’s even more complicated if you want to debug a problem that occurs on a remote machine (e.g., a production server) or on an embedded platform, since you will need to redeploy the newly compiled binary every time you want to run a new debug experiment.</p>

<p>Interactive debuggers solve these problems: you can take an existing program that was compiled in the debug mode and probe it to your liking,
setting up conditional breakpoints, looking up current values of variables, and doing a lot of other useful things. However, in my view, the widely-used interactive debuggers have a set of problems of their own:</p>

<ul>
  <li>
    <p>A lot of them were designed in a different era. At that time, we didn’t have always-on Internet connections, high-resolution multi-colour displays, and devices with many gigabytes of memory. While the fundamental principles remain the same, the modern needs have changed and so do modern means.</p>
  </li>
  <li>
    <p>Many existing debuggers are general-purpose. While there is some support for scripting and language-specific extensions, it’s harder to use them for specific domains and it’s harder to integrate them with your dev environment. In practical terms, this means you have to use <em>other</em> tools in addition to debuggers to observe the behaviour of your software, and oftentimes it’s just easier &amp; faster to move along with <code>print</code>s instead of trying to find a suitable tool.</p>
  </li>
</ul>

<p>I also see more general problems with regards to debuggers. They are perceived mostly as a tool to help you find and fix bugs in your code, but not as much as a tool of discovery and exploration. It’s been 8 years since Bret Victor published his “<a href="http://worrydream.com/#!/LearnableProgramming">Learnable Programming</a>”, and these ideas are as relevant today as ever. Debuggers should strive to be a good learning tool too.</p>

<p>Lastly, interactive debuggers rely on underlying principles that are quite similar to profilers, dynamic tracers like <a href="https://en.wikipedia.org/wiki/DTrace">DTrace</a> and <a href="https://en.wikipedia.org/wiki/eBPF">eBPF</a>, memory leak detectors, and other developer tools. Ideas and code can – and should – be shared across this ecosystem, but it seems like whilst one type of tools gets a lot of attention, the others may still lack support for important features.</p>

<p>So what can we do to try solving these problems?</p>

<h2 id="elements-of-a-modern-debugger">Elements of a modern debugger</h2>

<p>In my <a href="https://nbaksalyar.github.io/2020/05/19/rust-debug.html">previous article</a>, I argued for a case of extending the existing debuggers to provide better support for Rust. However, after some more research and thinking, I feel that we should consider the idea of creating a new debugger framework from scratch, taking inspiration from other great projects. Not-invented-here syndrome aside, I think there are some valid reasons for going in this direction.</p>

<p>Modern languages like Rust have lots of new important features that weren’t available in languages that the classic debuggers were written in. Things like fearless concurrency, first-class modules &amp; packages, async I/O and zero-cost abstractions can affect the design of a new debugger in a significant way. With the Rust’s package manager, <a href="https://doc.rust-lang.org/cargo/">Cargo</a>, extensibility becomes even more relevant and viable. We’ve already seen what modular debuggers are capable of – for example, the Illumos Modular Debugger, <a href="https://illumos.org/books/mdb/preface.html">mdb</a>, allows to debug both native and JavaScript code in Node.js with an <a href="https://github.com/joyent/mdb_v8">mdb_v8</a> extension, and the architecture of the debugger itself allows to extend it further using a simple, modular interface. With language features like traits, it can become even easier to create your own domain-specific debuggers using a new framework.</p>

<p>Another project to take inspiration from is <a href="https://github.com/go-delve/delve">Delve</a>, a Go debugger. It’s built with modern tools and has several features important for Go developers, but I want to highlight the <a href="https://github.com/go-delve/delve/tree/master/Documentation/api/json-rpc">JSON-RPC API</a> it provides. This API addresses the important problem of integration with the development environment, and by using <a href="https://microsoft.github.io/debug-adapter-protocol/">a well-defined protocol</a> we can create an ecosystem for debuggers that’s similar to the one that’s flourished around the <a href="https://microsoft.github.io/language-server-protocol/">language server protocol</a>. With an HTTP-based API, we can build custom debugger front-ends using HTML and WebAssembly and run them in web browsers. With the rich front-end tools &amp; frameworks, it opens up lots of interesting options for data representation and visualisation. Integration doesn’t have to be one-sided, too: language servers can be reused for debugging purposes, and integrating a Rust-specific debugger with the Rust compiler would allow us to utilise the full power of the existing language syntax parser and other compiler components.</p>

<h2 id="whats-next">What’s next?</h2>

<p>Overall, I believe this is a project worth building. While we’re seeing a lot of innovation in compilers and language design, debuggers are somewhat neglected, even though debugging is no less important; as Kernighan’s law postulates, it’s twice as hard as writing the code in the first place.</p>

<p>Creating a new debugger is an insurmountable task and a very long journey. But it can have a modest start: if we cover only a few popular operating systems and a few simple cases first, we can quickly achieve small wins that can save us a lot of time and frustration.</p>

<p>This post outlines the initial project plan for <strong><a href="https://github.com/headcrab-rs/headcrab">Headcrab</a></strong>, a Rust debugger library. I will be publishing more code and documentation in the coming weeks. If you are interested in updates, please <a href="https://twitter.com/nbaksalyar">follow me on Twitter</a>. Progress updates will be also published on this blog.</p>

<ul>
  <li>You can find a more detailed roadmap in the <a href="https://github.com/headcrab-rs/headcrab/blob/master/README.md">project repository</a>.</li>
</ul>

<h2 id="resources-and-further-reading">Resources and further reading</h2>

<ul>
  <li><a href="https://rustc-dev-guide.rust-lang.org/debugging-support-in-rustc.html">Debugging support in the Rust compiler</a></li>
  <li><a href="https://illumos.org/books/mdb/preface.html">mdb, Illumos Debugger</a></li>
  <li>Rosenberg, J.B. (1996). <em>How debuggers work : Algorithms, data structures, and architecture</em>. ISBN 0471149667.</li>
  <li>Uresh Vahalia (1996). <em>UNIX internals : the new frontiers</em>. ISBN 9780131019089.</li>
</ul>



		</article></div>]]>
            </description>
            <link>https://nbaksalyar.github.io/2020/07/12/soul-of-a-new-debugger.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812677</guid>
            <pubDate>Sun, 12 Jul 2020 16:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing Clojure Diff Libraries]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812601">thread link</a>) | @huahaiy
<br/>
July 12, 2020 | https://juji.io/blog/comparing-clojure-diff-libraries/#article-start | <a href="https://web.archive.org/web/*/https://juji.io/blog/comparing-clojure-diff-libraries/#article-start">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>In my <a href="https://youtu.be/n-avEZHEHg8">Clojure/north 2020</a> talk on "diffing-based software architecture patterns", I mentioned that Juji is using <a href="https://github.com/juji-io/editscript">Editscript</a> to diff Clojure data structures. During the Q&amp;A session of the talk, someone brought up another Clojure diff library, called <a href="https://github.com/lambdaisland/deep-diff2">deep-diff2</a>, which I was unaware of. Then on Youtube, a comment asking the difference between Editscript and deep-diff2 appeared again. This prompted me to do an investigation on Clojure data diff libraries. Given how the Clojure community places such an emphasis on data oriented programming, a comparison of data diff alternatives appears to be of interest.</p>
<p>My Google search with "Clojure diff" brought up these options: <a href="https://clojuredocs.org/clojure.data/diff">clojure.data/diff</a>, <a href="https://github.com/Skinney/differ">differ</a>, and aforementioned deep-diff2. Curiously, Editscript does not even show up on Google, despite the fact that it has the most number of github stars among all the options. Anyway, I would like to do a comparison among these options. Before going into the details of the differences, how about doing a benchmark first?</p>
<h2>Benchmark</h2>
<p>All these library implements a <code>diff</code> function, so we can measure how long it takes for them to diff the same pair of data structures. We will also compare the sizes of the resulting diffs.</p>
<h3>Data Set</h3>
<p>I happen to have a data set copied from a <a href="https://github.com/justsml/json-diff-performance">JSON diff benchmark</a>, which seems to include data models of a Javascript drawing program. I simply converted the JSON files into Clojure EDN format. There are four files, <a href="https://github.com/juji-io/editscript/blob/master/resources/drawing1.edn">data1</a>, <a href="https://github.com/juji-io/editscript/blob/master/resources/drawing2.edn">data2</a>, <a href="https://github.com/juji-io/editscript/blob/master/resources/drawing3.edn">data3</a>, and <a href="https://github.com/juji-io/editscript/blob/master/resources/drawing4.edn">data4</a>, with each being a variation of another. After serialized into bytes with <a href="https://github.com/ptaoussanis/nippy">nippy</a>, the sizes of the data are 1004, 1004, 1016 and 555 bytes, respectively.</p>
<p>The shape of the data has a bit of challenge for diff algorithms. The top level is a vector of nested maps. It is necessary to maintain the order of the vector elements, at the same time, the algorithms need to dig into each pair of nested maps to find the differences. However, the nesting is not deep.</p>
<h3>Test Environment</h3>
<p>Since these alternatives are all Clojure libraries, I created a project to simply pull the latest versions of them from <a href="https://clojars.org/">clojars</a> and let them loose on the data set. The code is <a href="https://github.com/juji-io/editscript/blob/master/bench/bench.clj">here</a>. The timing benchmark uses <a href="https://github.com/hugoduncan/criterium/">criterium</a> <code>quick-bench</code> function.</p>
<p>The test ran in a Clojure REPL on my laptop, an old 2014 2.8 GHz Core i5 16GB MacBook Pro, with this software environment:</p>
<blockquote>
<p>x86_64 Mac OS X 10.15.5 4 cpu(s)
OpenJDK 64-Bit Server VM 25.222-b10
Runtime arguments: -Dfile.encoding=UTF-8 -XX:-OmitStackTraceInFastThrow -XX:+TieredCompilation -XX:TieredStopAtLevel=1 -Dclojure.compile.path=/Users/huahaiy/workspace/editscript/bench/target/classes -Dbench.version=0.1.0 -Dclojure.debug=false</p>
</blockquote>
<h3>Results</h3>
<p><img src="https://juji.io/assets/uploads/diff-time-bench.png" alt="Clojure diff libraries benchmark time chart" title="Diff time"></p>
<p><img src="https://juji.io/assets/uploads/diff-size-bench.png" alt="Clojure diff libraries benchmark time chart" title="Diff size"></p>
<p>As you can see, the time for the libraries to run diff algorithm on the dataset varies greatly.  The same is true for the resulting diff sizes.</p>
<p>To choose a library, we need to look at each library to see if it fits one's use cases. In addition to the performance data, we also need to look at the output format of each library.</p>
<h2>Analyses</h2>
<p>Let's look at each option individually first, then do a summary.</p>
<h3>clojure.data/diff</h3>
<p>This is a built-in function of Clojure. The doc string says:</p>
<blockquote>
<p>Recursively compares a and b, returning a tuple of
[things-only-in-a things-only-in-b things-in-both]</p>
</blockquote>
<p>Obviously, this simple walking-through of two data structures is not meant to uncover the minimal differences between them. The resulting diff will always be larger than the original size of the data. The diff size chart above shows just that. Here's what the result looks like:</p>
<pre><code><span>(</span>pp/pprint <span>(</span>clj/diff data1 data2<span>)</span><span>)</span><br><br><span>[</span><span>[</span><span>nil</span> <span>nil</span> <span>{</span><span>:fill</span> <span>"#ffff00"</span><span>}</span><span>]</span><br> <span>[</span><span>nil</span> <span>nil</span> <span>{</span><span>:fill</span> <span>"#0000ff"</span><span>}</span><span>]</span><br> <span>[</span><span>{</span><span>:y</span> <span>27</span><span>,</span><br>   <span>:r</span> <span>0</span><span>,</span><br>   <span>:color</span> <span>"#000000"</span><span>,</span><br>   <span>:fill</span> <span>"#CCCCCC"</span><span>,</span><br>   <span>:width</span> <span>100</span><span>,</span><br>   <span>:type</span> <span>"rect"</span><span>,</span><br>   <span>:cap</span> <span>"round"</span><span>,</span><br>   <span>:borderWidth</span> <span>1</span><span>,</span><br>   <span>:style</span> <span>"Solid"</span><span>,</span><br>   <span>:x</span> <span>50</span><span>,</span><br>   <span>:height</span> <span>100</span><span>}</span><br>  <span>{</span><span>:y</span> <span>30</span><span>,</span><br>   <span>:family</span> <span>"sans-serif"</span><span>,</span><br>   <span>:color</span> <span>"#0000FF"</span><span>,</span><br>   <span>:fill</span> <span>{</span><span>:r</span> <span>256</span><span>,</span> <span>:g</span> <span>0</span><span>,</span> <span>:b</span> <span>0</span><span>,</span> <span>:a</span> <span>0</span>.<span>5</span><span>}</span><span>,</span><br>   <span>:width</span> <span>10</span><span>,</span><br>   <span>:type</span> <span>"textBlock"</span><span>,</span><br>   <span>:cap</span> <span>"round"</span><span>,</span><br>   <span>:borderWidth</span> <span>1</span><span>,</span><br>   <span>:size</span> <span>"24px"</span><span>,</span><br>   <span>:style</span> <span>"Solid"</span><span>,</span><br>   <span>:pad</span> <span>3</span><span>,</span><br>   <span>:weight</span> <span>"bold"</span><span>,</span><br>   <span>:x</span> <span>20</span><span>,</span><br>   <span>:height</span> <span>25</span>.<span>200000000000003</span><span>,</span><br>   <span>:text</span> <span>"DojoX Drawing Rocks"</span><span>}</span><br>  <span>{</span><span>:rx</span> <span>150</span><span>,</span><br>   <span>:color</span> <span>"#0000FF"</span><span>,</span><br>   <span>:type</span> <span>"ellipse"</span><span>,</span><br>   <span>:cap</span> <span>"round"</span><span>,</span><br>   <span>:borderWidth</span> <span>1</span><span>,</span><br>   <span>:style</span> <span>"Solid"</span><span>,</span><br>   <span>:cx</span> <span>150</span><span>,</span><br>   <span>:cy</span> <span>185</span><span>,</span><br>   <span>:ry</span> <span>100</span><span>}</span><br>  <span>{</span><span>:color</span> <span>"#000000"</span><span>,</span><br>   <span>:fill</span> <span>"#CCCCCC"</span><span>,</span><br>   <span>:y1</span> <span>20</span><span>,</span><br>   <span>:type</span> <span>"arrow"</span><span>,</span><br>   <span>:cap</span> <span>"round"</span><span>,</span><br>   <span>:borderWidth</span> <span>3</span><span>,</span><br>   <span>:style</span> <span>"Solid"</span><span>,</span><br>   <span>:label</span> <span>"My Arrow"</span><span>,</span><br>   <span>:x1</span> <span>40</span><span>,</span><br>   <span>:y2</span> <span>120</span>.<span>00000000000003</span><span>,</span><br>   <span>:x2</span> -<span>133</span>.<span>20508075688772</span><span>}</span><br>  <span>{</span><span>:y</span> <span>26</span><span>,</span><br>   <span>:family</span> <span>"sans-serif"</span><span>,</span><br>   <span>:color</span> <span>"#000000"</span><span>,</span><br>   <span>:fill</span> <span>"#CCCCCC"</span><span>,</span><br>   <span>:width</span> <span>200</span><span>,</span><br>   <span>:type</span> <span>"text"</span><span>,</span><br>   <span>:cap</span> <span>"round"</span><span>,</span><br>   <span>:borderWidth</span> <span>1</span><span>,</span><br>   <span>:size</span> <span>"18px"</span><span>,</span><br>   <span>:style</span> <span>"Solid"</span><span>,</span><br>   <span>:pad</span> <span>3</span><span>,</span><br>   <span>:weight</span> <span>"normal"</span><span>,</span><br>   <span>:x</span> <span>30</span><span>,</span><br>   <span>:height</span> <span>25</span>.<span>200000000000003</span><span>,</span><br>   <span>:text</span> <span>"This is just text"</span><span>}</span><br>  <span>{</span><span>:color</span> <span>"#000000"</span><span>,</span><br>   <span>:style</span> <span>"Solid"</span><span>,</span><br>   <span>:cap</span> <span>"round"</span><span>,</span><br>   <span>:fill</span> <span>"#CCCCCC"</span><span>,</span><br>   <span>:borderWidth</span> <span>1</span><span>,</span><br>   <span>:points</span><br>   <span>[</span><span>{</span><span>:x</span> <span>70</span><span>,</span> <span>:y</span> <span>20</span><span>}</span><br>    <span>{</span><span>:x</span> <span>65</span><span>,</span> <span>:y</span> <span>15</span><span>}</span><br>    <span>{</span><span>:x</span> <span>75</span><span>,</span> <span>:y</span> <span>15</span><span>}</span><br>    <span>{</span><span>:t</span> <span>"Z"</span><span>,</span> <span>:x</span> <span>70</span><span>,</span> <span>:y</span> <span>20</span><span>}</span><br>    <span>{</span><span>:t</span> <span>"M"</span><span>,</span> <span>:x</span> <span>70</span><span>,</span> <span>:y</span> <span>40</span><span>}</span><br>    <span>{</span><span>:x</span> <span>68</span><span>,</span> <span>:y</span> <span>12</span><span>}</span><br>    <span>{</span><span>:x</span> <span>72</span><span>,</span> <span>:y</span> <span>12</span><span>}</span><span>]</span><span>,</span><br>   <span>:type</span> <span>"path"</span><span>}</span><span>]</span><span>]</span><br></code></pre>
<p>In term of speed, this function is not the best. When diff is small, it is in the middle of the pack. When the diff is large, it can be the second slowest, only beating the optimizing A* algorithm of Editscript, but that algorithm is doing much more than simply walking two trees.</p>
<p>This function does produce a lot of information about the changes. There may be cases when these are useful. For example, you can ignore "things-in-both". "things-only-in-b" tells you the new things added, and "things-only-in-a" tells you what are deleted. However, if both are not empty, it would be hard to figure out what exactly happened.</p>
<p>There is no corresponding <code>patch</code> function for <code>diff</code>, so you cannot really use this to preserve and restore data.</p>
<h3>lambdaisland/deep-diff2</h3>
<p>This library seems to enjoy a lot of attention. Here's the tag line:</p>
<blockquote>
<p>Recursively compare Clojure or ClojureScript data structures, and produce a colorized diff of the result.</p>
</blockquote>
<p>So it seems to gear towards visualizing the data diff for human consumption. Here's what the results look like:</p>
<pre><code><span>(</span>deep/pretty-print <span>(</span>deep/diff data1 data2<span>)</span><span>)</span><br><br><span>[</span><span>{</span><span>:borderWidth</span> <span>1</span><span>,</span><br>  <span>:cap</span> <span>"round"</span><span>,</span><br>  <span>:color</span> <span>"#000000"</span><span>,</span><br>  <span>:fill</span> <span>"#CCCCCC"</span><span>,</span><br>  <span>:height</span> <span>100</span><span>,</span><br>  <span>:r</span> <span>0</span><span>,</span><br>  <span>:style</span> <span>"Solid"</span><span>,</span><br>  <span>:type</span> <span>"rect"</span><span>,</span><br>  <span>:width</span> <span>100</span><span>,</span><br>  <span>:x</span> <span>50</span><span>,</span><br>  <span>:y</span> <span>27</span><span>}</span><br> <span>{</span><span>:borderWidth</span> <span>1</span><span>,</span><br>  <span>:cap</span> <span>"round"</span><span>,</span><br>  <span>:color</span> <span>"#0000FF"</span><span>,</span><br>  <span>:family</span> <span>"sans-serif"</span><span>,</span><br>  <span>:fill</span> <span>{</span><span>:a</span> <span>0</span>.<span>5</span><span>,</span> <span>:b</span> <span>0</span><span>,</span> <span>:g</span> <span>0</span><span>,</span> <span>:r</span> <span>256</span><span>}</span><span>,</span><br>  <span>:height</span> <span>25</span>.<span>200000000000003</span><span>,</span><br>  <span>:pad</span> <span>3</span><span>,</span><br>  <span>:size</span> <span>"24px"</span><span>,</span><br>  <span>:style</span> <span>"Solid"</span><span>,</span><br>  <span>:text</span> <span>"DojoX Drawing Rocks"</span><span>,</span><br>  <span>:type</span> <span>"textBlock"</span><span>,</span><br>  <span>:weight</span><span>[</span>0m <span>"bold"</span><span>,</span><br>  <span>:width</span> <span>10</span><span>,</span><br>  <span>:x</span> <span>20</span><span>,</span><br>  <span>:y</span> <span>30</span><span>}</span><br> <span>{</span><span>:borderWidth</span> <span>1</span><span>,</span><br>  <span>:cap</span> <span>"round"</span><span>,</span><br>  <span>:color</span> <span>"#0000FF"</span><span>,</span><br>  <span>:cx</span> <span>150</span><span>,</span><br>  <span>:cy</span> <span>185</span><span>,</span><br>  <span>:fill</span> -<span>"#ffff00"</span> +<span>"#0000ff"</span><span>,</span><br>  <span>:rx</span> <span>150</span><span>,</span><br>  <span>:ry</span> <span>100</span><span>,</span><br>  <span>:style</span> <span>"Solid"</span><span>,</span><br>  <span>:type</span> <span>"ellipse"</span><span>}</span><br> <span>{</span><span>:borderWidth</span> <span>3</span><span>,</span><br>  <span>:cap</span> <span>"round"</span><span>,</span><br>  <span>:color</span> <span>"#000000"</span><span>,</span><br>  <span>:fill</span> <span>"#CCCCCC"</span><span>,</span><br>  <span>:label</span> <span>"My Arrow"</span><span>,</span><br>  <span>:style</span> <span>"Solid"</span><span>,</span><br>  <span>:type</span> <span>"arrow"</span><span>,</span><br>  <span>:x1</span> <span>40</span><span>,</span><br>  <span>:x2</span> -<span>133</span>.<span>20508075688772</span><span>,</span><br>  <span>:y1</span> <span>20</span><span>,</span><br>  <span>:y2</span> <span>120</span>.<span>00000000000003</span><span>}</span><br> <span>{</span><span>:borderWidth</span> <span>[</span>36m1<span>,</span><br>  <span>:cap</span> <span>"round"</span><span>,</span><br>  <span>:color</span> <span>"#000000"</span><span>,</span><br>  <span>:family</span> <span>"sans-serif"</span><span>,</span><br>  <span>:fill</span> <span>"#CCCCCC"</span><span>,</span><br>  <span>:height</span> <span>25</span>.<span>200000000000003</span><span>,</span><br>  <span>:pad</span> <span>3</span><span>,</span><br>  <span>:size</span> <span>"18px"</span><span>,</span><br>  <span>:style</span> <span>"Solid"</span><span>,</span><br>  <span>:text</span> <span>"This is just text"</span><span>,</span><br>  <span>:type</span> <span>"text"</span><span>,</span><br>  <span>:weight</span> <span>"normal"</span><span>,</span><br>  <span>:width</span> <span>200</span><span>,</span><br>  <span>:x</span> <span>30</span><span>,</span><br>  <span>:y</span> <span>26</span><span>}</span><br> <span>{</span><span>:borderWidth</span> <span>1</span><span>,</span><br>  <span>:cap</span> <span>"round"</span><span>,</span><br>  <span>:color</span> <span>"#000000"</span><span>,</span><br>  <span>:fill</span> <span>"#CCCCCC"</span><span>,</span><br>  <span>:points</span> <span>[</span><span>{</span><span>:x</span> <span>70</span><span>,</span> <span>:y</span> <span>20</span><span>}</span><br>           <span>{</span><span>:x</span> <span>65</span><span>,</span> <span>:y</span> <span>15</span><span>}</span><br>           <span>{</span><span>:x</span> <span>75</span><span>,</span> <span>:y</span> <span>15</span><span>}</span><br>           <span>{</span><span>:t</span> <span>"Z"</span><span>,</span> <span>:x</span> <span>70</span><span>,</span> <span>:y</span> <span>20</span><span>}</span><br>           <span>{</span><span>:t</span> <span>"M"</span><span>,</span> <span>:x</span> <span>70</span><span>,</span> <span>:y</span> <span>40</span><span>}</span><br>           <span>{</span><span>:x</span> <span>68</span><span>,</span> <span>:y</span> <span>12</span><span>}</span><br>           <span>{</span><span>:x</span> <span>72</span><span>,</span> <span>:y</span> <span>12</span><span>}</span><span>]</span><span>,</span><br>  <span>:style</span> <span>"Solid"</span><span>,</span><br>  <span>:type</span></code></pre>
<p>Sorry that this page does not do justice for the colorized output. But the thing to notice is the change <code>:fill -"#ffff00" +"#0000ff"</code>.</p>
<p>So basically this library displays the data, then highlights the changes in color. Of course, the result size will be larger than the original data. When changes are significant, the size could be be more than doubled, as shown in the chart.</p>
<p>Speed-wise, this library is also only consistently faster than the optimizing A* algorithm. It sometimes beats clojure.data/diff when the diffs are large.  This is remarkable, because what it does is a lot more than simply walking the trees.</p>
<p>Its credits section cites:</p>
<blockquote>
<p>This library builds upon clj-diff, which implements a diffing algorithm for sequences, and clj-arrangements, which makes disparate types sortable."</p>
</blockquote>
<p>I am familiar with the algorithm [1] used in <a href="https://github.com/brentonashworth/clj-diff">clj-diff</a>. It is an O(np) algorithm for diffing strings, where p is the number of deletes. The way it works is by maintaining a moving window of approximate size p along the diagonal of the editing matrix (think data a as the row, data b as the column), so it avoids searching the whole matrix. This algorithm is also implemented (with slightly better performance) in both versions of Editscript's two algorithms, to handle the special cases when we know simple sequences are being compared.</p>
<p>Clojure data structures are trees, not simple sequences of elementary values. The above algorithm assumes that each edit operation has the same cost, which is false for tree editing. Adding a large sub-tree costs a lot more than adding a single value by putting a lot more things in the resulting diff, for example. Another problem with that algorithm, is that it does not have replacement operator, having only add and delete operators. In any case, if optimal diff is desired, a proper tree diff algorithm is necessary.</p>
<p>However, general tree diff is expensive. The optimal time complexity is proved to be O(n^3) [2]. Fortunately, Clojure immutable data structure diff does not need or want general tree diff, where everything can move around. We actually want to preserve our beloved immutable data structures. This is how Editscript's A* algorithm can achieve optimality with less than O(n^2) time complexity: our definition of optimality disallows certain operations, such as splitting or merging nodes.</p>
<h3>Editscript (A* algorithm)</h3>
<p>This is the default algorithm of Editscript library. The reason I made this choice is because the optimal diff is likely the true diff. The library is intended as a part of the data transport for communicating software components <a href="https://youtu.be/n-avEZHEHg8">(see my talk)</a>, where the content of diffs may control application …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://juji.io/blog/comparing-clojure-diff-libraries/#article-start">https://juji.io/blog/comparing-clojure-diff-libraries/#article-start</a></em></p>]]>
            </description>
            <link>https://juji.io/blog/comparing-clojure-diff-libraries/#article-start</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812601</guid>
            <pubDate>Sun, 12 Jul 2020 16:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semi-Supervised Learning in Computer Vision]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812569">thread link</a>) | @amitness
<br/>
July 12, 2020 | https://amitness.com/2020/07/semi-supervised-learning/ | <a href="https://web.archive.org/web/*/https://amitness.com/2020/07/semi-supervised-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>Semi-supervised learning methods for Computer Vision have been advancing quickly in the past few years. Current state-of-the-art methods are simplifying prior work in terms of architecture and loss function or introducing hybrid methods by blending different formulations.</p>
<p>In this post, I will illustrate the key ideas of these recent methods for semi-supervised learning through diagrams.</p>
<h2 id="1-self-training"><strong>1. Self-Training</strong></h2>
<p>In this semi-supervised formulation, a model is trained on labeled data and used to predict pseudo-labels for the unlabeled data. The model is then trained on both ground truth labels and pseudo-labels simultaneously.</p>
<p><img src="https://amitness.com/images/ssl-self-training.png" alt="Idea of Self-Training"></p>
<h3 id="a-pseudo-label">a. Pseudo-label</h3>
<p><a href="http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf" title="Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks">Dong-Hyun Lee</a> proposed a very simple and efficient formulation called “Pseudo-label” in 2013.</p>
<p>The idea is to train a <span>model</span> simultaneously on a batch of both labeled and unlabeled images. The <span>model</span> is trained on labeled images in usual supervised manner with a cross-entropy loss. The same model is used to get predictions for a batch of unlabeled images and the <span>maximum confidence class</span> is used as the <span>pseudo-label</span>. Then, cross-entropy loss is calculated by comparing <span>model</span> predictions and the pseudo-label for the unlabeled images .</p>
<p><img src="https://amitness.com/images/ssl-pseudo-label.png" alt="Pseudo-Label for Semi-supervised Learning"></p>
<p>The total loss is a weighted sum of the labeled and unlabeled loss terms.</p>

<p>To make sure the model has learned enough from the labeled data, the  term is set to 0 during the initial 100 training steps. It is then gradually increased up to 600 training steps and then kept constant.
<img src="https://amitness.com/images/ssl-pseudolabel-alpha-increase.png" alt="Impact of alpha on semi-supervised loss"></p>
<h3 id="b-noisy-student">b. Noisy Student</h3>
<p><a href="https://arxiv.org/abs/1911.04252" title="Self-training with Noisy Student improves ImageNet classification">Xie et al.</a> proposed a semi-supervised method inspired by Knowledge Distillation called “Noisy Student” in 2019.</p>
<p>The key idea is to train two separate models called <span>“Teacher”</span> and <span>“Student”</span>. The <span>teacher model</span> is first trained on the labeled images and then it is used to infer the pseudo-labels for the unlabeled images. These pseudo-labels can either be soft-label or converted to hard-label by <span>taking the most confident class</span>. Then, the labeled and unlabeled images are combined together and a <span>student model</span> is trained on this combined data. The images are augmented using RandAugment as a form of input noise. Also, model noise such as Dropout and Stochastic Depth are incorporated in the student model architecture.</p>
<p><img src="https://amitness.com/images/ssl-noisy-student.png" alt="Noisy Student"></p>
<p>Once a <span>student model</span> is trained, it becomes the new <span>teacher</span> and this process is repeated for three iterations.</p>
<h2 id="2-consistency-regularization"><strong>2. Consistency Regularization</strong></h2>
<p>This paradigm uses the idea that <span>model</span> predictions on an unlabeled image should remain the same even after adding noise. We could use input noise such as Image Augmentation and Gaussian noise. Noise can also be incorporated in the architecture itself using Dropout.</p>
<p><img src="https://amitness.com/images/fixmatch-unlabeled-augment-concept.png" alt="Consistency Regularization Concept"></p>
<h3 id="a-π-model">a. π-model</h3>
<p>This model was proposed by <a href="https://arxiv.org/abs/1610.02242" title="Temporal Ensembling for Semi-Supervised Learning">Laine et al.</a> in a conference paper at ICLR 2017.</p>
<p>The key idea is to create two random augmentations of an image for both labeled and unlabeled data. Then, a <span>model with dropout</span> is used to predict the label of both these images. The <span>square difference</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The total loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-pi-model.png" alt="PI Model"></p>
<h3 id="b-temporal-ensembling">b. Temporal Ensembling</h3>
<p>This method was also proposed by <a href="https://arxiv.org/abs/1610.02242" title="Temporal Ensembling for Semi-Supervised Learning">Laine et al.</a> in the same paper as the pi-model. It modifies the π-model by leveraging the <span>Exponential Moving Average(EMA)</span> of predictions.</p>
<p>The key idea is to use the <span>exponential moving average</span> of past predictions as one view. To get another view, we augment the image as usual and a <span>model with dropout</span> is used to predict the label. The <span>square difference</span> of <span>current prediction</span> and <span>EMA prediction</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-temporal-ensembling.png" alt="Temporal Ensembling"></p>
<h3 id="c-mean-teacher">c. Mean Teacher</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1703.01780" title="Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results">Tarvainen et al.</a>. The general approach is similar to Temporal Ensembling but it uses Exponential Moving Average(EMA) of the model parameters instead of predictions.</p>
<p>The key idea is to have two models called <span>“Student”</span> and <span>“Teacher”</span>. The <span>student</span> model is a regular model with dropout. And the <span>teacher</span> model has the same architecture as the <span>student</span> model but its weights are set using an <span>exponential moving average</span> of the weights of <span>student</span> model. For a labeled or unlabeled image, we create two random augmented versions of the image. Then, the <span>student</span> model is used to predict <span>label distribution</span> for first image. And, the <span>teacher</span> model is used to predict the <span>label distribution</span> for the second augmented image. The <span>square difference</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-mean-teacher.png" alt="Mean Teacher"></p>
<h3 id="d-virtual-adversarial-training">d. Virtual Adversarial Training</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1704.03976" title="Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning">Miyato et al.</a>. It uses the concept of adversarial attack for consistency regularization.</p>
<p>The key idea is to generate an adversarial transformation of an image that will change the model prediction. To do so, first, an image is taken and an adversarial variant of it is created such that the KL-divergence between the model output for the original image and the adversarial image is maximized.</p>
<p>Then we proceed as previous methods. We take a labeled/unlabeled image as first view and take its adversarial example generated in previous step as the second view. Then, the same <span>model</span> is used to predict <span>label distributions</span> for both images. The <span>KL-divergence</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span></span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-virtual-adversarial-training.png" alt="Virtual Adversarial Training"></p>
<h3 id="e-unsupervised-data-augmentation">e. Unsupervised Data Augmentation</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1904.12848" title="Unsupervised data augmentation for consistency training">Xie et al.</a> and works for both images and text. Here, we will understand the method in the context of images.</p>
<p>The key idea is to create an augmented version of a unlabeled image using AutoAugment. Then, a same <span>model</span> is used to predict the label of both these images. The <span>KL-divergence</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we only calculate the <span>cross-entropy loss</span> and don’t calculate any <span>consistency loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-unsupervised-data-augmentation.png" alt="Unsupervised Data Augmentation"></p>
<h2 id="3-hybrid-methods"><strong>3. Hybrid Methods</strong></h2>
<p>This paradigm combines ideas from previous work such as self-training and consistency regularization along with additional components for performance improvement.</p>
<h3 id="a-mixmatch">a. MixMatch</h3>
<p>This holistic method was proposed by <a href="https://arxiv.org/abs/1905.02249" title="Mixmatch: A holistic approach to semi-supervised learning">Berthelot et al.</a>.</p>
<p>To understand this method, let’s take a walk through each of the steps.</p>
<p>i. For the labeled image, we create an augmentation of it. For the unlabeled image, we create K augmentations and get the model <span>predictions</span> on all K-images. Then, the <span>predictions</span> are <span>averaged</span> and <span>temperature scaling</span> is applied to get a final pseudo-label. This pseudo-label will be used for all the K-augmentations.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-1.png" alt="Preparing Pseudo-label in MixMatch"></p>
<p>ii. The batches of augmented labeled and unlabeled images are combined and the whole group is shuffled. Then, the first N images of this group are taken as , and the remaining M images are taken as .</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-2.png" alt="Shuffling labeled and unlabeled images"></p>
<p>iii. Now, Mixup is applied between the augmented labeled batch and group . Similarly, mixup is applied between the M augmented unlabeled group and the  group. Thus, we get the final labeled and unlabeled group.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-3.png" alt="Applying Mixup trick in MixMatch"></p>
<p>iv. Now, for the labeled group, we take model predictions and compute <span>cross-entropy loss</span> with the ground truth mixup labels. Similarly, for the unlabeled group, we compute model predictions and compute <span>mean square error(MSE) loss</span> with the mixup pseudo labels. A weighted sum is taken of these two terms with  weighting the MSE loss.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-4.png" alt="MixMatch overall pipeline"></p>

<h3 id="b-fixmatch">b. FixMatch</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/2001.07685" title="FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence">Sohn et al.</a> and combines pseudo-labeling and consistency regularization while vastly simplifying the overall method. It got state of the art results on a wide range of benchmarks.</p>
<p>As seen, we train a supervised model on our labeled images with cross-entropy loss. For each unlabeled image, <span>weak augmentation</span> and <span>strong augmentations</span> are applied to get two images. The <span>weakly augmented image</span> is passed to our model and we get prediction over classes. The probability for the most confident class is compared to a <span>threshold</span>. If it is above the <span>threshold</span>, then we take that class as the ground label i.e. <span>pseudo-label</span>. Then, the <span>strongly augmented</span> image is passed through our model to get a prediction over classes. This <span>prediction</span> is compared to ground truth <span>pseudo-label</span> using cross-entropy loss. Both the losses are combined and the model is optimized.</p>
<p><img src="https://amitness.com/images/fixmatch-pipeline.png" alt="Overall Architecture of FixMatch"></p>
<p>If you want to learn more about FixMatch, I have an <a href="https://amitness.com/2020/03/fixmatch-semi-supervised/">article</a> that goes over it in depth.</p>
<h2 id="comparison-of-methods">Comparison of Methods</h2>
<p>Here is a high-level summary of the differences between all the above-mentioned methods.</p>
<table>
<thead>
<tr>
<th>Method Name</th>
<th>Year</th>
<th>Unlabeled Loss</th>
<th>Augmentation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pseudo-label</td>
<td>2013</td>
<td>Cross-Entropy</td>
<td>Random</td>
</tr>
<tr>
<td>π-model</td>
<td>2016</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Temporal Ensembling</td>
<td>2016</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Mean Teacher</td>
<td>2017</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Virtual Adversarial Training(VAT)</td>
<td>2017</td>
<td>KL-divergence</td>
<td>Adversarial transformation</td>
</tr>
<tr>
<td>Unsupervised Data Augmentation(UDA)</td>
<td>2019</td>
<td>KL-divergence</td>
<td>AutoAugment</td>
</tr>
<tr>
<td>MixMatch</td>
<td>2019</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Noisy Student</td>
<td>2019</td>
<td>Cross-Entropy</td>
<td>RandAugment</td>
</tr>
<tr>
<td>FixMatch</td>
<td>2020</td>
 <td>Cross-Entropy</td>
<td>CTAugment / RandAugment</td>
</tr>
</tbody>
</table>
<h2 id="common-evaluation-datasets">Common Evaluation Datasets</h2>
<p>To evaluate the performance of these semi-supervised methods, the following datasets are commonly used. The authors simulate a low-data regime by using only a small portion(e.g. 40/250/4000/10000 examples) of the whole dataset as labeled and treating the remaining as the unlabeled set.</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Classes</th>
<th>Image Size</th>
<th>Train</th>
<th>Validation</th>
<th>Unlabeled</th>
<th>Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
<td>10</td>
<td>32*32</td>
<td>50,000</td>
<td>10,000</td>
<td>-</td>
<td>Subset of tiny images dataset</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a></td>
<td>100</td>
<td>32*32</td>
<td>50,000</td>
<td>10,000</td>
<td>-</td>
<td>Subset of tiny images dataset</td>
</tr>
<tr>
<td><a href="http://ai.stanford.edu/~acoates/stl10/">STL-10</a></td>
<td>10</td>
<td>96*96</td>
<td>5000</td>
<td>8000</td>
<td>1,00,000</td>
<td>Subset of …</td></tr></tbody></table></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amitness.com/2020/07/semi-supervised-learning/">https://amitness.com/2020/07/semi-supervised-learning/</a></em></p>]]>
            </description>
            <link>https://amitness.com/2020/07/semi-supervised-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812569</guid>
            <pubDate>Sun, 12 Jul 2020 16:36:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of calculus and analysis in 200 symbols]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812448">thread link</a>) | @R3G1R
<br/>
July 12, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><p><span>I</span>n mathematics, <strong>calculus</strong> formalizes the study of continuous change, while <strong>analysis</strong> provides it with a rigorous foundation in <a href="https://mathvault.ca/hub/higher-math/math-symbols/logic-symbols/" target="_blank" aria-label="logic (opens in a new tab)" rel="noreferrer noopener">logic</a>. The following list documents some of the most notable symbols and notations in calculus and analysis, along with each symbol’s usage and meaning.</p><p>For readability purpose, these symbols are categorized by <strong>topic</strong> and <strong>function</strong> into tables. Other comprehensive lists of <a href="https://mathvault.ca/hub/higher-math/math-symbols/" target="_blank" aria-label="math symbols (opens in a new tab)" rel="noreferrer noopener">math symbols</a> — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p> </div></div></div></div><h2><span id="Constants_and_Variables"></span>Constants and Variables<span></span></h2><p>In calculus and analysis, constants and variables are often reserved for <strong>key mathematical numbers</strong> and <strong>arbitrarily small quantities</strong>. The following table documents some of the most notable symbols in these categories — along with each symbol’s example and meaning.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$e$</td><td><strong><a aria-label="Euler's number (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/E_(mathematical_constant)" target="_blank">Euler’s number e</a></strong></td><td>$\displaystyle e = \frac{1}{0!} + \frac{1}{1!} + \cdots$</td></tr><tr><td>$\pi$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Pi (opens in a new tab)" rel="noreferrer noopener">Pi</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Pi" target="_blank" aria-label="Archimedes' constant (opens in a new tab)" rel="noreferrer noopener">Archimedes’ constant</a></strong></td><td>$\dfrac{\pi^2}{6} = \dfrac{1}{1^2} + \dfrac{1}{2^2} +$<br>$\dfrac{1}{3^2} + \dfrac{1}{4^2} + \cdots$</td></tr><tr><td>$i$</td><td><strong><a href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank" aria-label="Imaginary unit (opens in a new tab)" rel="noreferrer noopener">Imaginary unit</a></strong></td><td>$e^{\pi i} = \cos \pi + i \sin \pi$</td></tr><tr><td>$\gamma$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Gamma (opens in a new tab)" rel="noreferrer noopener">Gamma</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Euler%E2%80%93Mascheroni_constant" target="_blank" aria-label="Euler–Mascheroni constant (opens in a new tab)" rel="noreferrer noopener">Euler–Mascheroni constant</a></strong></td><td>$\displaystyle \left( \sum_{k=1}^{n} \dfrac{1}{k}-\ln n \right) \to$<br>$\gamma \approx 0.577$</td></tr><tr><td>$\Omega$<br>(<a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" aria-label="Capital omega (opens in a new tab)" rel="noreferrer noopener">Capital omega</a>)</td><td><strong><a href="https://en.wikipedia.org/wiki/Omega_constant" target="_blank" aria-label="Omega constant (opens in a new tab)" rel="noreferrer noopener">Omega constant</a></strong></td><td>$\Omega e^{\Omega} = 1$</td></tr><tr><td>$m$</td><td>Variable for <strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Slope" target="_blank">slope</a></strong></td><td>$m = \dfrac{y_2-y_1}{x_2-x_1}$</td></tr><tr><td>$h$, $\Delta x$, $\delta x$</td><td><strong><a aria-label="Limiting variables (opens in a new tab)" href="https://en.wikipedia.org/wiki/List_of_limits#Limits_involving_derivatives_or_infinitesimal_changes" target="_blank" rel="noreferrer noopener">Limiting variables</a></strong> for <a href="https://en.wikipedia.org/wiki/Difference_quotient" target="_blank" aria-label="difference quotient (opens in a new tab)" rel="noreferrer noopener">difference quotient</a></td><td>$\displaystyle \lim_{h \to 0} \dfrac{f(x+h)-f(x)}{h}$</td></tr><tr><td>$L$</td><td>Variable for <strong><a aria-label="limiting value (opens in a new tab)" href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" rel="noreferrer noopener">limit</a></strong></td><td>If $f(x) \to L$, then $f(x)^2 \to L^2$.</td></tr><tr><td>$\varepsilon$ (<a aria-label="Epsilon (opens in a new tab)" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" rel="noreferrer noopener">Epsilon</a>),<br>$\delta$ (<a aria-label="Delta (opens in a new tab)" href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/#Greek_Symbols" target="_blank" rel="noreferrer noopener">Delta</a>)</td><td>Variables for <strong><a href="https://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit" target="_blank" aria-label="arbitrarily small quantities (opens in a new tab)" rel="noreferrer noopener">arbitrarily small quantities</a></strong></td><td>$\forall \varepsilon \, \exists \delta \, \big( 0&lt;|x-x_0|&lt;\delta$ $\implies |f(x)-L|&lt; \varepsilon \big) $</td></tr><tr><td>$a, b$</td><td>Variables for <strong>endpoints</strong> in <a aria-label=" (opens in a new tab)" rel="noreferrer noopener" href="https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/#Intervals" target="_blank">intervals</a> and <a href="#Univariate_Integralrelated_Symbols" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">definite integrals</a></td><td>$\displaystyle \int_a^b 2x \, \mathrm{d}x= b^2-a^2$</td></tr><tr><td>$C$</td><td><strong><a href="https://en.wikipedia.org/wiki/Constant_of_integration" target="_blank" aria-label="Constant of integration (opens in a new tab)" rel="noreferrer noopener">Constant of integration</a></strong></td><td>$\displaystyle \int \dfrac{1}{x} \, \mathrm{d} x = \ln |x| + C$</td></tr></tbody></table></figure><h2><span id="Sequence,_Series_and_Limit"></span>Sequence, Series and Limit<span></span></h2><p>The concepts of <strong><a href="https://en.wikipedia.org/wiki/Sequence" target="_blank" rel="noopener noreferrer">sequence</a></strong>, <strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" rel="noopener noreferrer">series</a></strong> and <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" rel="noopener noreferrer">limit</a></strong> form the foundation of calculus (and by extension real and complex analysis). The following table features some of the most common symbols related to these topics — along with each symbol’s usage and meaning.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$+\infty$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infinity#Real_analysis" target="_blank" aria-label="Positive infinity (opens in a new tab)" rel="noreferrer noopener">Positive infinity</a></strong></td><td>$\dfrac{1}{1} + \dfrac{1}{2} + \cdots = \infty$</td></tr><tr><td>$-\infty$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infinity#Real_analysis" target="_blank" aria-label="Negative infinity (opens in a new tab)" rel="noreferrer noopener">Negative infinity</a></strong></td><td>As $x \to -\infty$, $e^x \to 0$.</td></tr><tr><td>$(a_n), (b_n), (c_n)$</td><td><strong><a aria-label="Sequence (opens in a new tab)" href="https://en.wikipedia.org/wiki/Sequence" target="_blank" rel="noreferrer noopener">Sequences</a></strong></td><td>$\displaystyle (a_n)_{n=0}^\infty =$<br>$(a_0, a_1, a_2, \ldots)$</td></tr><tr><td>$\displaystyle \sum_{n = i}^k a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" aria-label="Series (opens in a new tab)" rel="noreferrer noopener">Series</a></strong></td><td>$\displaystyle \sum_{n=1}^k b_n = \\ b_1 + \cdots + b_k$</td></tr><tr><td>$\| \mathrm{x}-\mathrm{y}\|$</td><td><strong><a href="https://en.wikipedia.org/wiki/Euclidean_distance" target="_blank" aria-label="Euclidean distance (opens in a new tab)" rel="noreferrer noopener">Euclidean distance</a></strong> between points $\mathrm{x}$ and $\mathrm{y}$</td><td>$\| \mathrm{x}-\mathrm{x}_0 \| &lt; 1 \implies$<br>$| f(\mathrm{x})-f(\mathrm{x}_0) | &lt; 2 $</td></tr><tr><td>$d(x, y)$</td><td><strong><a aria-label="Metric (opens in a new tab)" href="https://en.wikipedia.org/wiki/Metric_(mathematics)" target="_blank" rel="noreferrer noopener">Distance function</a></strong></td><td>$d(x, y) = |x-y|$</td></tr><tr><td>$\displaystyle \lim_{n \to \infty} a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Limit_of_a_sequence" target="_blank" aria-label="Limit of sequence (opens in a new tab)" rel="noreferrer noopener">Limit of sequence</a></strong></td><td>$\displaystyle \lim_{n \to \infty} \left(1+\dfrac{1}{n}\right)^n = e$</td></tr><tr><td>$\displaystyle \lim_{k \to \infty} \sum_{n=i}^k a_n, \sum_{n=i}^{\infty} a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Series_(mathematics)" target="_blank" aria-label="Limit of series (opens in a new tab)" rel="noreferrer noopener">Limit of series</a></strong></td><td>$\displaystyle \sum_{n=0}^{\infty} \dfrac{1}{2^n} = 2$</td></tr><tr><td>$\mathrm{x} \to a$</td><td>Variable $\mathrm{x}$ <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" aria-label="tends to (opens in a new tab)" rel="noreferrer noopener">tends to</a></strong> $a$</td><td>$\lim (a_n) = 1/4$ as $n \to \infty$.</td></tr><tr><td>$f(x) \to L$</td><td>Function $f(x)$ <strong><a href="https://en.wikipedia.org/wiki/Limit_(mathematics)" target="_blank" aria-label="tends to (opens in a new tab)" rel="noreferrer noopener">tends to</a></strong> limit $L$</td><td>Since $g(x)$ is continuous at $c$, $g(x) \to g(c)$ as $x \to c$.</td></tr><tr><td>$\displaystyle \lim_{x \to a} f(x)$</td><td><strong><a aria-label="Limit of function (opens in a new tab)" href="https://en.wikipedia.org/wiki/Limit_of_a_function" target="_blank" rel="noreferrer noopener">Limit of function</a></strong> $f(x)$ as $x$ tends to $a$</td><td>$\displaystyle \lim_{x \to 0} \dfrac{\sin x}{x} = 1$</td></tr><tr><td>$\displaystyle \lim_{x \to a^+} f(x)$, $\displaystyle \lim_{x \, \downarrow \, a} f(x)$</td><td><strong><a href="https://en.wikipedia.org/wiki/One-sided_limit" target="_blank" aria-label="Right-sided limit (opens in a new tab)" rel="noreferrer noopener">Right-sided limit</a></strong><br>(Limit of $f(x)$ as $x$ tends to $a$ from the right)</td><td>$\displaystyle \lim_{x \to 3^+} \dfrac{1}{x-3} = +\infty$</td></tr><tr><td>$\displaystyle \lim_{x \to a^-} f(x)$, $\displaystyle \lim_{x \, \uparrow \, a} f(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/One-sided_limit" target="_blank">Left-sided limit</a></strong><br>(Limit of $f(x)$ as $x$ tends to $a$ from the left)</td><td>$\displaystyle \lim_{x \to 0^-} \sqrt{-x} = 0$</td></tr><tr><td>$\min (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Maxima_and_minima#In_relation_to_sets" target="_blank" aria-label="Minimum (opens in a new tab)" rel="noreferrer noopener">Minimum</a></strong> of set $A$</td><td>$\min (a_n) + \min (b_n) \le$ $\min (a_n + b_n)$</td></tr><tr><td>$\max (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Maxima_and_minima#In_relation_to_sets" target="_blank" aria-label="Maximum (opens in a new tab)" rel="noreferrer noopener">Maximum</a></strong> of set $A$</td><td>If $f$ is continuous on $[a, b]$, then $\max (f(x))$ exists on that interval.</td></tr><tr><td>$\inf (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infimum_and_supremum" target="_blank" aria-label="Greatest lower bound (opens in a new tab)" rel="noreferrer noopener">Greatest lower bound</a></strong> of set $A$</td><td>$\inf\left(\left\{\dfrac{1}{n} \, \middle| \, n \in \mathbb{N} \right\}\right)$<br>$= 0$</td></tr><tr><td>$\sup (A)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infimum_and_supremum" target="_blank" aria-label="Least upper bound (opens in a new tab)" rel="noreferrer noopener">Least upper bound</a></strong> of set $A$</td><td>$\sup \left(\left\{x \in \mathbb{Q} \, \middle| \, x^2 &lt; 2 \right\}\right)$ $= \sqrt{2}$</td></tr><tr><td>$\liminf a_n$</td><td><strong><a aria-label="Limit infimum (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Limit_superior_and_limit_inferior" target="_blank">Limit inferior</a></strong> of sequence $a_n$</td><td>$\displaystyle \liminf_{n \to \infty} \dfrac{2}{n+1} =$<br>$\displaystyle \lim_{n \to \infty} 0$</td></tr><tr><td>$\limsup a_n$</td><td><strong><a href="https://en.wikipedia.org/wiki/Limit_superior_and_limit_inferior" target="_blank" aria-label="Limit superior (opens in a new tab)" rel="noreferrer noopener">Limit superior</a></strong> of sequence $a_n$</td><td>$\displaystyle \limsup_{n \to \infty} b_n =$<br>$\displaystyle \lim_{n \to \infty} \left( \sup_{m \ge n} b_m \right)$</td></tr></tbody></table></figure><h2><span id="Derivative_and_Integral"></span>Derivative and Integral<span></span></h2><p>The field of calculus (e.g., multivariate/vector calculus, differential equations) is often said to revolve around two opposing but complementary concepts: <strong>derivative</strong> and <strong>integral</strong>. The following tables document the most notable symbols related to these — along with each symbol’s usage and meaning.</p><p>(For a review on function and related operators, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Functionrelated_Symbols" target="_blank" rel="noopener noreferrer"><strong>function-related operators</strong></a>.)</p><h3>Univariate Derivative-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f^{\prime}(\mathrm{x}), f^{\prime \prime}(\mathrm{x}), f^{(n)}(\mathrm{x})$</td><td>First, second and $n$th <strong><a aria-label="derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Lagrange's_notation" target="_blank">derivative</a></strong> of $f$ at $\mathrm{x}$<br>(Lagrange’s notation)</td><td>$f'(c) =$<br>$\displaystyle \lim_{h \to 0} \dfrac{f(c + h)-f(c)}{h}$</td></tr><tr><td>$\dfrac{d}{d\mathrm{x}} f, \dfrac{df}{d\mathrm{x}}$</td><td><strong><a aria-label="Derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Leibniz's_notation" target="_blank">Derivative</a></strong> of function $f$ in terms of $\mathrm{x}$<br>(Leibniz’s notation)</td><td>$\dfrac{d}{dx} f = f'(x)$</td></tr><tr><td>$\dfrac{d^n}{d\mathrm{x}^n} f, \dfrac{d^n f}{d\mathrm{x}^n}$</td><td><strong><a aria-label="Nth derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Leibniz's_notation" target="_blank">Nth derivative</a></strong> of function $f$ in terms of $\mathrm{x}$<br>(Leibniz’s notation)</td><td>$\dfrac{d^2 f}{dx^2} = \dfrac{d}{dx}\left(\dfrac{df}{dx}\right)$</td></tr><tr><td>$\dot{y}$, $\ddot{y}$, $\overset{n}{\dot{y}}$</td><td>First, second and $n$th <strong><a aria-label="derivative (opens in a new tab)" href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Newton's_notation" target="_blank" rel="noreferrer noopener">derivative</a></strong> of $y$ in terms of time variable $t$<br>(Newton’s notation)</td><td>$\ddot{y}= \dfrac{d^2 y}{dt^2}$</td></tr><tr><td>$D(f), D^2(f), D^{n}(f)$</td><td>First, second and $n$th <strong><a href="https://en.wikipedia.org/wiki/Notation_for_differentiation#Euler's_notation" target="_blank" aria-label="derivative (opens in a new tab)" rel="noreferrer noopener">derivative</a></strong> of $f$<br>(Euler’s notation)</td><td>$D^2(f) = D(D(f))$</td></tr><tr><td>$\Delta \mathrm{x}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Delta_(letter)#Upper_case" target="_blank" aria-label="Increment (opens in a new tab)" rel="noreferrer noopener">Increment</a></strong> in variable $\mathrm{x}$</td><td>$\Delta y \approx f'(x) \Delta x$</td></tr><tr><td>$d \mathrm{x}$</td><td><strong><a aria-label="Differential (opens in a new tab)" href="https://en.wikipedia.org/wiki/Differential_(infinitesimal)" target="_blank" rel="noreferrer noopener">Differential</a> </strong>of variable $\mathrm{x}$</td><td>$dy = \dfrac{dy}{dx}\, dx$</td></tr></tbody></table></figure><h3>Multivariate Derivative-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$f_\mathbf{x}$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank">Partial derivative</a></strong> of $f$ in terms of $\mathbf{x}$<br>(Lagrange’s notation)</td><td>$\displaystyle f_x (a, b) = \lim_{h \to 0}$<br>$\frac{f(a+h, \, b) \, – \, f(a,\, b)}{h}$</td></tr><tr><td>$\dfrac{\partial}{\partial \mathrm{x}} f, \dfrac{\partial f}{\partial \mathrm{x}}$</td><td><strong><a aria-label="Partial derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank">Partial derivative</a></strong> of $f$ in terms of $\mathrm{x}$<br>(Leibniz’s style)</td><td>If $f$ has continuous second partial derivatives, then $\dfrac{\partial}{\partial y}\dfrac{\partial f}{\partial x} = \dfrac{\partial}{\partial x}\dfrac{\partial f}{\partial y}$</td></tr><tr><td>$\dfrac{\partial^n}{\partial \mathrm{x}^<br>n} f, \dfrac{\partial^n f}{\partial \mathrm{x}^n}$</td><td><strong><a aria-label="Nth partial derivative (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Partial_derivative#Notation" target="_blank">Nth partial derivative</a></strong> of $f$ in terms of $\mathrm{x}$<br>(Leibniz’s style)</td><td>$\dfrac{\partial^2 f}{\partial y^2} = \dfrac{\partial}{\partial y}\dfrac{\partial f}{\partial y}$</td></tr><tr><td>$\partial_x f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank" aria-label="Partial derivative (opens in a new tab)" rel="noreferrer noopener">Partial derivative</a></strong> of $f$ in terms of $x$<br>(Euler’s notation)</td><td>$\partial_{xy} f = \dfrac{\partial}{\partial y} \dfrac{\partial f}{\partial x}$</td></tr><tr><td>$\nabla_{\mathbf{v}} f$</td><td><strong><a aria-label="Directional derivative (opens in a new tab)" href="https://en.wikipedia.org/wiki/Directional_derivative" target="_blank" rel="noreferrer noopener">Directional derivative</a></strong> of $f$ with respect to direction $\mathbf{v}$</td><td>$\nabla_{\mathbb{v}} f(\mathbf{x}) =$<br>$\displaystyle \lim_{h \to 0} \dfrac{f(\mathbf{x}+h\mathbf{v})-f(\mathrm{x})}{h}$</td></tr><tr><td>$\partial \mathrm{x}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables" target="_blank" aria-label="Partial differential (opens in a new tab)" rel="noreferrer noopener">Partial differential</a></strong> of variable $\mathrm{x}$</td><td>$\dfrac{\partial f}{\partial x} dx \le df$</td></tr><tr><td>$df$</td><td><strong><a aria-label="Total differential (opens in a new tab)" href="https://en.wikipedia.org/wiki/Differential_of_a_function#Differentials_in_several_variables" target="_blank" rel="noreferrer noopener">Total differential</a></strong> of function $f$</td><td>$df = \dfrac{\partial f}{\partial x_1} dx_1 +$<br>$\displaystyle \cdots + \dfrac{\partial f}{\partial x_n} dx_n$</td></tr><tr><td>$\nabla f, \mathrm{grad}\,f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Gradient" target="_blank" aria-label="Gradient (opens in a new tab)" rel="noreferrer noopener">Gradient</a></strong> of function $f$</td><td>$\nabla f =$<br>$\left( \dfrac{\partial f}{\partial x_1}, \ldots, \dfrac{\partial f}{\partial x_n} \right)$</td></tr><tr><td>$\Delta f$</td><td><strong><a href="https://en.wikipedia.org/wiki/Laplace_operator#Definition" target="_blank" aria-label="Laplace operator (opens in a new tab)" rel="noreferrer noopener">Laplace operator</a></strong> of function $f$</td><td>$\displaystyle \Delta f = \sum_{i=1}^n \dfrac{\partial^2 f}{\partial x_i^2}$</td></tr><tr><td>$\nabla \cdot \mathbf{F}, \mathrm{div}\, \mathbf{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Divergence" target="_blank" aria-label="Divergence (opens in a new tab)" rel="noreferrer noopener">Divergence</a></strong> of vector field $\mathbf{F}$</td><td>$\nabla \cdot \mathbf{F} = \dfrac{\partial F_x}{\partial x} +$<br>$\dfrac{\partial F_y}{\partial y} + \dfrac{\partial F_z}{\partial z}$</td></tr><tr><td>$\nabla \times \mathbf{F}, \mathrm{curl} \, \mathbf{F}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Curl_(mathematics)" target="_blank" aria-label="Curl (opens in a new tab)" rel="noreferrer noopener">Curl</a></strong> of vector field $\mathbf{F}$</td><td>$\nabla \times \mathbf{F} =$<br>$\left( \dfrac{\partial}{\partial x}, \dfrac{\partial}{\partial y}, \dfrac{\partial}{\partial z} \right) \times$<br>$\left( F_x, F_y, F_z \right)$</td></tr></tbody></table></figure><h3><span id="Derivative/Integralrelated_Shorthands"></span>Derivative/Integral-related Shorthands<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \left. f(x) \right|_{x = a}$</td><td><strong>Shorthand</strong> for ‘$f(x)$ with $x$ substituted by $a$’</td><td>$\displaystyle \left. f'(x) \right|_{x =g(t)} =$<br>$f'(g(t))$</td></tr><tr><td>$\displaystyle \left[f(x)\right]_{a}^{b}$</td><td><strong>Shorthand</strong> for <br>‘$f(b)-f(a)$’</td><td>$\left[\dfrac{x^2}{2}\right]_{1}^{\pi} = \dfrac{\pi^2}{2}-\dfrac{1}{2}$</td></tr></tbody></table></figure><h3>Univariate Integral-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \int_a^b f(x) \, dx$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Integral" target="_blank">Integral</a></strong> of function $f$ with respect to $x$ from $a$ to $b$</td><td>$\displaystyle \int_0^{\infty} \dfrac{1}{1+x^2} \, dx = \dfrac{\pi}{2}$</td></tr><tr><td>$\displaystyle \int f(x) \, dx$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Antiderivative#Uses_and_properties" target="_blank">Indefinite integral</a></strong> of function $f$ with respect to $x$</td><td>$\displaystyle \int \cos y \, dy = \\ \sin y + C$</td></tr><tr><td>$F(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Antiderivative" target="_blank">Antiderivative</a></strong> of function $f$</td><td>For all constants $c$, $(F(x) + c)’ = f(x)$.</td></tr><tr><td>$(Jf)(x)$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Fractional_calculus" target="_blank">Integration operator</a></strong><br>(Integral function of $f$)</td><td>$(Jf)(x) =$<br>$\displaystyle \int_0^x f(t) \, dt$</td></tr></tbody></table></figure><h3>Multivariate Integral-related Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\displaystyle \int_C f(\mathbf{r}) \, ds$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Line_integral#Definition" target="_blank">Line integral</a></strong> of function $f$ along curve $C$ (under parametrization $\mathbf{r}$)</td><td>$\displaystyle \int_C f(\mathbf{r}) \, d s =$<br>$\displaystyle \int_a^b f(\mathbf{r}(t)) \, |\mathbf{r}'(t)| \, d t$</td></tr><tr><td>$\displaystyle \int_{C} f(z) \, dz$, $\displaystyle \oint_{C} f(z) \, dz$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Contour_integration#For_continuous_functions" target="_blank">Contour integral</a></strong> of function $f$ along curve $C$</td><td>$\displaystyle \int_{\gamma} f(z) \, dz =$<br>$\displaystyle \int_a^b f(\gamma(t)) \, \gamma'(t) \, dt$</td></tr><tr><td>$\displaystyle \int_C \mathbf{F}(\mathbf{r}) \cdot d\mathbf{r}$</td><td><strong><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Line_integral#Definition_2" target="_blank">Line integral</a></strong> of vector field $\mathbf{F}$ along curve $C$</td><td>$\displaystyle \int_C \mathbf{F}(\mathbf{r}) \cdot d \mathbf{r} =$<br>$\displaystyle \int_a^b \mathbf{F}(\mathbf{r}(t)) \cdot \mathbf{r}'(t) \, d t$</td></tr><tr><td>$\displaystyle \iint_D f …</td></tr></tbody></table></figure></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/">https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812448</guid>
            <pubDate>Sun, 12 Jul 2020 16:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robot Game: Comparing 6502 C, Assembly, and Forth]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 31 (<a href="https://news.ycombinator.com/item?id=23812187">thread link</a>) | @druzyek
<br/>
July 12, 2020 | http://calc6502.com/RobotGame/summary.html | <a href="https://web.archive.org/web/*/http://calc6502.com/RobotGame/summary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
			
			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_main_screen.png" alt="Robot Game screenshot"></p><p>
				A few years ago, I started doing small projects with the 65C02 processor to build up to using it to make a graphing calculator. There are a few different languages that you can use to write programs for this processor with assembly offering the best performance. One of the projects I worked on is an optimizer to make assembly programs run faster. It works by tracing program flow then assigning fixed addresses to local variables in functions instead of storing them on the stack. To figure out how much of an improvement the optimizer adds, I made a game in Python then ported it to both traditional assembly and the new optimized assembly format. I also ported the game to C and Forth to see how fast they are compared to the assembly versions.
			</p>
			
			
			

			<h2>Table of Contents</h2>
			
			<ol>
				<li><a href="#Why6502">Why 65C02?</a></li>
				<li><a href="#TheLanguages">The Languages</a></li>
				<li><a href="#TheSimulator">The Simulator</a></li>
				<li><a href="#TheGame">The Game</a></li>
				<li><a href="#ExtractingGameAssets">Extracting Game Assets</a></li>
				<li><a href="#PortingTradAsm">Porting the Game to Traditional Assembly</a></li>
				<li><a href="#PortingOptAsm">Porting the Game to Optimized Assembly</a></li>
				<li><a href="#PortingC">Porting the Game to C</a></li>
				<li><a href="#PortingForth">Porting the Game to Forth</a></li>
				<li><a href="#Results">Speed Comparison</a></li>
				<li><a href="#SizeTime">Size and Time to Implement</a></li>
				<li><a href="#CodeAnalysisRand">Code Analysis: rand</a></li>
				<li><a href="#CodeAnalysisCalcStats">Code Analysis: CalcStats</a></li>
				<li><a href="#Conclusions">Conclusions</a></li>
				<li><a href="#Improvement">Areas for Improvement</a></li>
			</ol>

			<a name="Why6502">
			<h2>Why 65C02?</h2>
			
			</a><p><a name="Why6502">
				The </a><a href="https://en.wikipedia.org/wiki/WDC_65C02">65C02</a> is an improved version of the <a href="https://en.wikipedia.org/wiki/MOS_Technology_6502">6502</a> used in the <a href="https://en.wikipedia.org/wiki/Atari_2600">Atari 2600</a>, <a href="https://en.wikipedia.org/wiki/Nintendo_Entertainment_System">Nintendo Entertainment System (NES)</a>, and the <a href="https://en.wikipedia.org/wiki/Apple_I">first</a> <a href="https://en.wikipedia.org/wiki/Apple_II">two</a> computers made by Apple. Because the 65C02 is made with more modern CMOS transistors, it’s much more energy efficient and runs at up to 14 MHz, compared to the 1-3 MHz of the original 6502. Both of these things make it a good choice for a graphing calculator. For comparison, the very common <a href="https://en.wikipedia.org/wiki/TI-83_series#TI-83_Plus">TI-83+</a> made by Texas Instruments has a <a href="https://en.wikipedia.org/wiki/Zilog_Z80">Zilog Z80</a> running at 6 MHz. Since the Z80 needs 3-4 times more cycles to accomplish the same work as a 6502, a 65C02 running at full speed should be 7-9 times more powerful than the Z80 in a TI-83+. Another advantage of the 65C02 is that it’s still sold in a DIP package, so it’s easy to find and experiment with on a breadboard. There aren’t many better choices in a throughhole package. The <a href="https://en.wikipedia.org/wiki/Motorola_68000">Motorola 68000</a> is more powerful MHz for MHz, but it's already used in the <a href="https://en.wikipedia.org/wiki/TI-89_series">TI-89</a>, so I would like to use something different. Some throughhole microcontrollers have much more processing power, though not much RAM and no way to add more without an external address bus. The throughhole <a href="https://en.wikipedia.org/wiki/PIC_microcontrollers#PIC32M_MIPS-based_line">PIC32</a>, for example, runs at up to 50 MHz, but only has 64 kB of RAM. For comparison, the TI-89 introduced in 1998 and the <a href="https://en.wikipedia.org/wiki/HP_49/50_series#49G">HP-49G</a> from 1999 had 256 kB and 512 kB of RAM respectively. Since the 65C02 has an open address bus, there is no limit to the amount of RAM and ROM it can access.
			</p>

			<a name="TheLanguages">
			<h2>The Languages</h2>
			
			<p>
				These are the languages that I want to compare:
			</p>
			</a><ol><a name="TheLanguages">
				<li><b>Traditional assembly</b> - This is plain old 65C02 assembly. Like many 65(C)02 (ie 6502 or 65C02) programs, it uses the X register as a stack pointer for a data stack (more details on this below). Some functions copy and save data from the fastest region of memory called zero page to free it up for use and restore the data when the function ends (more details on this below too).</li>
				<li><b>Optimized assembly</b> - This version of the game differs from traditional assembly since it doesn’t use the X register as a data stack pointer. Instead, local variables in each function are assigned a fixed address at compile time. The addresses are determined by a Python script that analyzes the flow of the program and tracks how much memory each function needs (more details below).</li>
				</a><li><a name="TheLanguages"><b>C</b> - This version is compiled with </a><a href="https://cc65.github.io/">CC65</a>, which seems to be the most popular C compiler for the 65(C)02.</li>
				<li><b>Forth</b> - This version is compiled using a modified version of <a href="https://github.com/scotws/TaliForth2">Tali Forth 2</a>. I picked this Forth since it generates subroutine threaded code (STC) which is generally the fastest, though largest, type of Forth code.</li>
			</ol>

			<a name="TheSimulator">
			<h2>The Simulator</h2>
			<span></span></a><p><a href="https://github.com/JoeyShepard/65C02_Emulator">65C02 Emulator on GitHub</a></p><p>
				All of the code runs on a JavaScript-based simulator I made that works in the browser. The simulation itself runs very fast on a separate thread using a web worker, while the main page is only responsible for the interface. This setup lets the simulation run at the equivalent of 40-50 MHz, several times faster than an actual 65C02 running at 14 MHz. Because it runs in the browser, you can try each version of the game for yourself:
			</p>
			
			<p>
				<a href="http://calc6502.com/RobotGame/TradAsm/main.html">Robot Game - Traditional assembly version</a><br>
				<a href="http://calc6502.com/RobotGame/OptAsm/main.html">Robot Game - Optimized assembly version</a><br>
				<a href="http://calc6502.com/RobotGame/CC65/main.html">Robot Game - C version</a><br>
				<a href="http://calc6502.com/RobotGame/TaliForth2/main.html">Robot Game - Forth version</a>
			</p>
			
			<p>
				The simulator has sixteen memory banks of 16 kB each for a total of 256 kB of memory. The 65C02 has a 16 bit address bus, so it can only address 64 kB of memory at a time. To access the memory outside of the first 64 kB, the simulator simulates a memory banking system. Each 16 kB range of the 64 kB address space can point to any of the sixteen memory banks. This was a common strategy in retro computers to get around the limitations of a small address space.
			</p>

			<p>
				Memory map:
			</p>
			<ul>
				<li>0x0000 to 0x01FF - No banking</li>
				<li>0x0200 to 0x3FFF - Memory window 1</li>
				<li>0x4000 to 0x7FFF - Memory window 2</li>
				<li>0x8000 to 0xBFFF - Memory window 3</li>
				<li>0xC000 to 0xFFDF - Memory window 4</li>
				<li>0xFFE0 to 0xFFFF - Peripherals</li>
			</ul>

			<p>
				The first 512 bytes are not banked since they contain the fast zero page memory and the hardware stack which always need to be visible from all banks. The last 32 bytes are for peripherals like the keyboard and for vectors for reset and interrupts. Each peripheral is assigned a specific address in this range, and the processor communicates with them by reading and writing to those addresses. Four bytes in the peripheral region control which of the sixteen memory banks each window points to. For example, if memory window 2 points to memory bank 7, then reading the first byte of memory window 2 at 0x4000 will access the first byte of memory bank 7 which is at 0x1C000.
			</p>
			
			<p>
				The video memory is mapped one byte per pixel and takes up the 32 kB from 0x10000 to 0x17FFF (memory banks 5 and 6). The resolution is 256x128. Each byte has two bits each of red, green, and blue. Valid color codes are therefore 0-63.
			</p>
			
			<p>
				The simulator has some interesting tools that helped port the game. Some of them were added during development because a specific problem arose that I needed to add them for. The main page lets you step through the code and shows the status of all the registers and each memory region that it accesses. There is also a memory viewer and a log of exactly which instructions have been executed. Copying this information into Excel or a text diff program helped track down several bugs in the game.
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_simulator.png" alt="Screenshot of simulator Robot Game runs on">
			<span>Simulator debug interface</span></p><p>
				Getting the cycle counts right for the executed instructions was a little tricky. For example, when an X-indexed instruction fetches an address where adding X to the low byte of the address overflows and the high byte of the address has to be adjusted, the instruction takes an additional cycle. After I got the logic for that fixed, the test code I was using was still a few cycles out of 3.5 million cycles off. Single stepping the program through all of those cycles to figure out which instruction was off would take too long. Instead, I loaded the code into the <a href="http://exifpro.com/utils.html">Kowalski simulator</a> then used a Python script to automate pressing the single step button and record the cycle count for every instruction. This generated way too much data to load into a spreadsheet, so I made another script to compare those cycles to the ones I generated in my own simulator and tracked the problem down to incorrect cycle times for the STZ instruction.
			</p>

			<a name="TheGame">
			<h2>The Game</h2>
			<span></span></a><p><a href="https://github.com/JoeyShepard/RobotGame">Robot Game on GitHub</a></p><p>
				The game is made in Python with the <a href="https://www.pygame.org/">PyGame library</a>. It was easy to read one big image into memory then copy parts of it into individual tiles that PyGame draws to the screen. Here are the images I came up with in Paint:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_tiles.png" alt="Graphics tiles for Robot Game">
			<span>Graphics tiles for Robot Game</span></p><p>
				Several of these are tiles that I was experimenting with that didn’t make it into the game. Bright magenta (0xFF00FF) and bright cyan (0x00FFFF) are replaced with transparency when the tiles are created. Most of the tiles only have placeholder colors and are used as the basis to create other tiles. For example, the green, yellow, and grey color in the generic crystal graphic above are filled in depending on what type of crystal the game needs to draw:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_crystals.png" alt="Crystal tiles for Robot Game"></p><p>
				The rock and lava tiles are constructed similarly from the generic tile above. There are four dirt tiles that are colored slightly differently and rotated at 90, 180, and 270 degrees to give the background some variety:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_dirt_tiles.png" alt="Dirt tiles for Robot Game"></p><p>
				There is only one type of monster which is always colored the same, so a few tiles like that don’t have any pixels that change colors. Adding in some stats and a randomly generated map gets us to the main game window:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_main_screen.png" alt="Dirt tiles for Robot Game"></p><p>
				The map is formed from the output of a random number generator. Using the same generator algorithm for each port results in the same beginning map for all four versions (and the same gameplay if the player makes the same decisions). I had to try several seed values for the RNG until I got a map I liked the look of as seen in the screenshot above. Here are a few that didn’t make the cut:
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_failed_maps.png" alt="Random maps for Robot Game that failed"></p><p>
				The rest of the game is just the three menu screens. The first displays a couple of stats and an inventory page. Moving the cursor over an item shows that item’s stats and what is currently equipped in that slot. Equipping an item changes the color of the corresponding part of the robot to match. In the tiles page above, the image of the robot is drawn with different colors that all correspond to the same colors that the generic item tile has. This means that the easy find and replace function to color in the individual items also works with the same color information on the larger image of the full robot.
			</p>

			<p><img src="http://calc6502.com/RobotGame/images/RobotGame_character_menu.png" alt="Robot Game character menu">
			<span>Robot Game character menu</span></p><p>
				The skills page is pretty straightforward. There are three paths and unlocking any skill requires first unlocking the skill before it in that path. Every …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://calc6502.com/RobotGame/summary.html">http://calc6502.com/RobotGame/summary.html</a></em></p>]]>
            </description>
            <link>http://calc6502.com/RobotGame/summary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812187</guid>
            <pubDate>Sun, 12 Jul 2020 15:47:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Implementing Pull Request Feedback: A Short Story]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812130">thread link</a>) | @khaliqgant
<br/>
July 12, 2020 | https://www.dev-diaries.com/blog/on-imlementing-pull-request-feedback-a-short-story/ | <a href="https://web.archive.org/web/*/https://www.dev-diaries.com/blog/on-imlementing-pull-request-feedback-a-short-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p><img src="https://www.dev-diaries.com/assets/images/khaliq-gant.jpg" alt="kjg"></p>

<h2 id="07-july-2020">07 July 2020</h2>

<p>.</p>

<p>Khaliq Gant is the creator of this website and a full stack web developer of over 8 years.
He enjoys writing code, learning, growing and saying jokes with a dead pan tone of voice and a serious face.
He works for <a href="https://www.happycog.com/" target="_blank">Happy Cog</a>
and currently resides in Paris where he attempts to speak French with varying
degrees of success.</p>

<p>Pull request reviews are typically an important part of the development process.
Writing code is often done in a bubble so getting feedback from fellow
developers can be extremely beneficial in avoiding introducing bugs and pointing
out flaws in logic or missed constraints. However, sometimes well intentioned
pull request review feedback can introduce issues if care is not taken when
receiving that feedback. What follows is a short pull request review short story (PR RSS)
that is contrived but not really <em>that contrived</em>.</p>

<p><img src="https://www.dev-diaries.com/assets/images/intense-coding.jpg" alt="research"></p>

<h2 id="blood-rushing-keyboard-pounding-intense-code-writing">Blood Rushing, Keyboard Pounding, Intense Code Writing</h2>

<p>The sprint just started today and you have two weeks to finish the high priority
task PROJ-5777 which is to implement the MIB component to use the JiggyWit pattern
instead of the now deprecated MiamiConnector pattern. You were adamant about
the 5 story point estimate and are confident you’ll be able to wrap it up efficiently.
Your music is bumping, you’re in the zone and the code is flowing with ease
as you dig into the MIB component. By the end of the week you’re done and are ready
to open up a pull request. You’ve fully tested it and the JiggyWit pattern that
you’ve implemented is much cleaner and readable – a clear improvement to the codebase.</p>

<p>It is a Friday so you open up a pull request with full knowledge that no one will
get around to reviewing your PR until Monday. That is totally fine since you
still have a week left in the sprint and you assume the pull request review process
won’t take longer than a couple of days…</p>

<h2 id="reviews-incoming">Reviews Incoming</h2>



<p>Are you sure that the JiggyWit pattern is the best use case here? I’ve read
that the BigWillie styled pattern is more flexible and resistant against
upstream API changes.</p>

<p>OK, you think. Clearly this reviewer didn’t read the ticket because the whole
premise of the ticket is to use the JiggyWit pattern. You fire back a response
linking to the ticket and resolve the conversation.</p>



<p>I think in line 12 you’re missing a parameter definition which could improve
clarity of your changes.</p>

<p>Yes, very valid feedback. You quickly implement the request change and re-request
a review.</p>

<p>You still need two more reviews and approvals for your pull request to be merged
into master. Even though you have another task to work on it took an entire day
for those two comments and now it is Tuesday and you are itching to get your code in
so it can be reviewed by QA. You ping a couple of team members:</p>

<p>Hey, do you mind reviewing the pull request for PROJ-5777 when you get a chance?
Just want to get it into the QA environment so it can be tested there. Thanks!</p>

<h2 id="approvalsbut-wait">Approvals!…but wait…</h2>

<p>You finally get an approval at the end of the day Tuesday and just need one more
and then you can merge in your PR. By Wednesday you’re itching to get your PR
in since the sprint ends soon and you still need to get it verified by QA. You hope
there are no issues in the QA process…</p>

<p>You see one more review trickle in…</p>



<p>This is a nitpick but the JiggyWit pattern allows for an optional class injector
which we might need in the future for PROJ-5999 which can reduce complexity. Can
you add in that injector option to this PR?</p>

<p>Hmm, yeah, that is a good idea. This change should be quick. You jump back into your
IDE without spinning up your environment to fully test since that class injector
seems harmless. You push up the code, get approval and get that into QA. Phew! Your feelings
of angst quickly dissipate as you were still able to get your ticket into QA before
the end of the day and hopefully can get your ticket done before the end of the sprint.</p>

<h2 id="boom-in-productionbut-hold-on-a-second">Boom! In Production…but hold on a second…</h2>

<p>QA tests the work you did in PROJ-5777 and signs off on it. Phew! A week goes by and then
suddenly bugs start pouring into your error monitoring solution all related
to the feature the JiggyWit pattern. Curiously the JiggyWit pattern is touching the feature, but not directly related to it. You dig
into those bugs and notice that there is some weird caching going on with the JiggyWit pattern…</p>

<p>As you dig deeper you see that the class injector is causing the responses to get
cached all because you added the optional class injector into the JiggyWit pattern.
You remember you didn’t <em>actually</em> test the optional class injector change you made
from the nitpick comment from your colleague…</p>

<p>That one change from the nitpick
comment caused additional cycles and a bug ticket that caused the next sprint to be
taken up by your investigation into this bug and ultimately the fix.</p>

<p><img src="https://www.dev-diaries.com/assets/images/coding-regret.jpg" alt="research"></p>

<h2 id="what-have-we-learned">What Have We Learned?</h2>

<p>😡 WTF QA?! You should have caught this…</p>

<p>Well, no…not quite. There are a few take aways here:</p>

<h3 id="calmez-vous">Calmez-Vous</h3>

<p>You should never be so antsy to get your pull request that you skip the all important
task of testing any changes you make. Even if the change is tiny and seemingly
inconsequential there is no excuse to not quickly test that everything works
as expected. This anxiousness of getting your code into master is the sign
of an immature developer who would skip steps to make things go faster.</p>

<h3 id="provide-as-much-information-as-possible-in-your-prs">Provide As Much Information As Possible in Your PR’s</h3>

<p>The first comment example in this post might be eye roll worthy but it happens more often
than you think and can be potentially avoided by providing more information in
the pull request. Your fellow developers are busy and may not have time to reference
the original ticket that this pull request is for. They also might not have the bandwidth
from sprint grooming to remember the constraints of some work you’re doing. Therefore,
make it as easy as possible for them to quickly read all the information they
need to know to be able to thoroughly review your pull request. This avoids any
potential miscommunication and can save cycles by providing all the necessary information
upfront.</p>

<h3 id="allow-adequate-time-for-discussions-around-changespull-requests">Allow Adequate Time For Discussions Around Changes/Pull Requests</h3>

<p>In this short story the PR opener was stressing because he wanted to get his/her PR
into production ASAP. Instead, the pull request review process should have proper time
allocated to it so the feedback can be fully understood and implemented <em>and then tested</em>.
PR feedback can be extremely valuable, but if not enough importance and time is allocated
to it, it can become a needless formality.</p>

<h3 id="no-one-knows-your-code-better-than-you">No One Knows Your Code Better Than You</h3>

<p>While seemingly obvious it is still worth saying: you know your code better than
any of your teammates. Any suggestions for small changes or tweaks should be carefully
weighed by you and gauged within the larger scope of the work you’re doing. A “small parameter change”
can actually be more detrimental than upon first glance and you, as the pull request
opener,must be watchful for those seemingly innocuous changes that actually
are potentially changing more than they appear.</p>

<h2 id="treat-the-pull-request-process-with-the-respect-that-it-deserves">Treat The Pull Request Process With The Respect That It Deserves</h2>

<p>Changes made after you have a working version of a feature should be heavily tested
and vetted. When you’re in the zone and writing code and testing it might be
difficult to go back through all your test cases when making a small feedback based
change. <em>Of course</em> your feature has automated tests so any breaking changes will be caught,
but even then we all know that tests aren’t always perfect either. It is still
important to review changes made even if they might seem harmless. The pull request
reviewer is looking at your code with fresh eyes which can be a positive and a negative thing.
Ultimately it is up to you - the person who opened up the pull request - to equip your
teammates with enough context to review your pull request thoroughly. It is then up to
you to implement changes as you see fit without introducing any new bugs.</p>


        
    </div></div>]]>
            </description>
            <link>https://www.dev-diaries.com/blog/on-imlementing-pull-request-feedback-a-short-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812130</guid>
            <pubDate>Sun, 12 Jul 2020 15:40:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alston Poverty Report – The Parlous State of Poverty Eradication [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23812118">thread link</a>) | @DanBC
<br/>
July 12, 2020 | https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf | <a href="https://web.archive.org/web/*/https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>^Eÿ»ËŠÑ
Nœb\‚ÿÎzÎ–u2VLlKl04c‹%
†&gt;Q‘¬¿±hýÒþvnÃ§žijž9t{&lt;íú~�,¢°È’�}‘yVS€VÝ™�Û5‡žVï·èýû¦s[¨X°Ñ'â¢Ô–ú ¢9:ÿX�Vëctîíàê6z×—½r<s«u5lë™�ƒÌŒ`�ûïíÊ(}0f�ÍpÆ¡õ5¸ÑÅ°ðÿÚ0Â¦>_7,5öúSS®Ú� ÚZ¬{š¥†³d¢ïÎ,u¶”ÝÊ¢e&amp;‘µëNVe.™]rˆVD•9Z#«¬{’m
:½t½C)r¼õ^Úª‘JúvQN#ÎþÂ&amp;ªŽî�˜Ï2ºØû¤þ �Î(,l(wOr2ìI‰]qýYÓ&nbsp;w'2k'GÊ&amp;É«ÊÌicV±j�Ý©­‡_…\Ót»yÿœœ¬Ÿ@Yu6ødý¼²˜„%ÄLêðHYu€`Uþ™L›TôðôÔßÎ1Iš,v&gt;Ñ¬—ÐJŸ|£‰@ÍúÛˆF�Œ6�­Â•M]þLCh2ÕÜp
nôñšuwéd.HZgYŠšÏY{VÙn?¹Ëz¥³5µ“»ü:ä’»&lt;�NòsPK,Œ&nbsp;G™›zò€¹ôä±~ø¡&amp;¯ÊŽõ×Ñ3¡
L¦˜J�/ñ2=‰Ê®ºx™�ÒÉ4`Ð‘`¥xÁJý QÂHY§êâê�Ñ%pßÄI=
ðSÀ¢óãÏõTv~Öát�Ä@^�nyÜd„ã3Šá`'ôU–»îß•l*ÀU¶1Ðô!zmc­	ÿþ—õ„½é‰‚pfäÖë`™ñU$Â[GÙõèÛÃnl‰Oý¸ßQQtÔwÇÓéY{‡ºï†]?í*üÂ©{Ü³ntãaNnI´ŽxÃ
“ãë²D©'¤“—Ë@^”/?M3ìŽÔäÁ¾[fi¼°ÌL•¿|ÿÈö‹Nå¢®jõ›É.º+@Á¬VMX�^z]ÿ =ükÒ')èuãîpð¡e%nrØÄ¡ùWÁaUtUtD–m®~N2ƒÉù0Õ]­Rçð_HSE&lt;×ä¤àÒ2ÁÑ|%ËTi^-ð¨Ø3¹ƒbÒEÌË»Lg	¦rçÓ¸;ì‹i|8,lZVûzaÓ²éÛÝ°Ùu0/´M5É^ÖkÈ&amp;Uÿ’½°ú)Í,û&amp;»xq$od’¬ËÉ	îô"àßàäZÌUÚw	ß¨ÛÁùNÿevK†«ÕÄÈØ ¬t�á
…ÙŸÁ¾ÔE(±&gt;KlEcÒð«‹ÏTë`¼Ø�&amp;+­»¨7²{8´ÄX×p¶7´¡áÝ\Ã&amp;b÷wcîA%6…£¤d™¼Kj%uC‡¡~3•À*Ií3\�e˜é')�Y«a-ëc”àÝ³äŒh\šòŒ’ýçpãÍd�VÝ&gt;\W­l ö’d÷:÷'ç]¯º&lt;�³ph]…�jù£î)µÑ�_FkT]¨¼Ùõ�ÉÆ™]Kâš‚­&gt;âJê+¨I<vwöŽÐ„\~"šy¤u¢9¶��ìÄÐ¨Œ„)¤„ó«Ù€ ek5xrð+.ï‡[|+ÑÍy.yt]¹ðŽûè—�“="" •vbÃy¿»u="">£¿s2ï'‰^®a%æfq”I¥ÀqGÎLb/�S=Á¹(ÿ/ÎåcýhüHª:‰rwûH€€ò&nbsp;Ì¦ê‹2°+[b�ê?jk›_ušî&amp;.ð­Ú¢J&gt;žyqFÉ¡®ÿ0W˜1†U’p�÷ºñl4½||÷À»pö[W€Ý‘?©,_Aí˜˜w‘üŒÌ˜¦ºQe¹ˆî¡.¾÷õ.Á”ó|wg�BXœ=&nbsp;lx®{BÏ&gt;Á¸oêGXÞÜ¯¦;|D™×(€9‡ühç:,UÒò&amp;94±¸ý[·ûW7º`¨ ­ó˜Ba'™¼dfÏ…ná¬¡Ð;Aâ˜n½¿ËãM}ñÊ¢„cÇÄw3º÷.XS‡ð^&gt;‚SºóK÷2õ.í}n8{÷³é®³h&gt;Ý]¶ÒS=„9!÷­˜—.w%ˆ¨Ã§kRGÀ\¢y'wM•&nbsp;ŠÕ¦Ï1K†¨7Sñ‹qbÅ­b&amp;–ñ+§”f©[h¢á3CÇ¨²@ó;xÅ2ùØÂDðMÎi¹}­uJ4¿G‰\&nbsp;p‚
Ùç¯¦m\›œÞþ~z°Éb¸¤4¡†4±v[³£åÆe×’ƒuÎùÆ†äTç¥}ù'='P­='àuÙTlgÕÄ”ÓGI¹&lt;åM ˆb«¬x;¯&amp;&amp;…™UQU†Ÿ*°&amp;4ój¢Û¢šàYˆL´jëˆ)

ó(ÔìWï©Oò93gÐÙÕí5fbf|ƒ…G¥‰©Ä?AæOÎzv—´aSq”¦+YÙÚ™x±±é‚1¸]yš“£NjÚó{Õq‡7ÕIo‚!ˆ¸hÞË`çD+ÒWé[ÖuÖ(¤d&gt;äî�Yê8g*[Í’¢•ÑPl¬D�)C–GÛè÷ü¼‘�¾!¶¡UCc&gt;2ª1dÌ%ŸëÆÙ¨ÿMoþ�¢[©³qot…¢…éŠÕ’Ø©³hGÄ0F­›1cck5mærZ«
')†
F&nbsp;‡&nbsp;u#Ìsž“5R3¥…ÉZz†?Qõ%†'mMš’7žoF¥Ò±]!ËsV.T*á&gt;èË¶¸b	}„1•¯R(F’~dà#9».R
N‰¦&gt;-š÷%Õ;ùáM¢Ô²Ê¥´TäÔùjâ#þÍÆs¦|Ø;]þ´tS\_ý¥ÌÖÓ§M¶’†™€ç\X|Î4øÖÖ™‡Wvdà´t¼Oû
ž�éÑ€,N/äÒ:â¢ý]¤‹{Ä‚îà tø*pß&gt;ÈV6Í6¦u’g#”òwé,gÉîÐZåhFâÞ–?»Fñ�Ë§¸KÃÌõŽOx6å¥Æ=m‰;&amp;*¾¦ûñ°()@ÙneÅö«„!®F+2ñŸ&nbsp;¢@fÚ„�½y§6x)Y]Q7M7	Ã:‰ëÐè}–A‚u/³oŸÐ�¹—Ö.ÍŒ»�W4štÂ2¤¤u€,€É…Œ8=ÇÄj!œ7“o †Ør—6í_¦JŽýÒ5x#å"
.²³&gt;I„ËÒj&lt;oÏ3Eæ0òð^~»"Å*N&gt;^J3­¢Þ¹»õŒ:‚–*?n$ÃöGTè•Zd¨ÑX¢{éýè{‰F&lt;ÈDo\Kê8.án©«b³7‹zOˆ:KN“I%ñ3P,€™M¥³7k‰‘‚­SðƒwqzAÈ¡b¢C°ìLÞy¥{ 3�†—³]Z©n\‡”‰"@Œ$½Îq6\sÎM¨ÙT§T
(Îyˆ7[n ‘9ÕüXrª½í¦dàSÂ÷ƒÅEa³A—ˆ„aþÁà‚Ø!ó^Aœí"zoÄaÐGüJC�6!íAvWi¸Ë$]©í÷»CÏêÝ¹HYÉ­�µÚÈ5™'/}ò[ ÓÑ	Eò	/ûçÓ&lt;ÌZìðàê!¢¤bWì�hÉ¶	çA9‚±/ñzøéð	fZpåf3ý+B¡
òXÿ"JÖ¢`dõPl]®�Z z˜·Æ<fÄ™sÂ¥ôs ×m˜="" –ö4="" x–Ü<+ißš£="ˆ§$·DÎa" u¡="" Îa™ëcÿd·ÔçÃwÖ×zåx»-ÿk`ùxâ±‰àýŸqÔ¦:r*jh+x½%evÔh^Ô&ì¬¨m°¬¨Íðsq›ÁÎŠÚ–="¼ìN7Õ!÷¹)ßÝTOzºò”ã|;˜g˜×žðšJÛopvË.¦" n="" ¼‡šl<þd¾"@ë˜7u_kÉÇt§bÍæ�="" ^pÀs“É@»�˜="">œ/ŒS]üÖò$ÅdrÓÍóÎÌ,@Äþ™ÚZ­ÔâãÏÕÅïµƒ¡ØÀNÅ¸ÑL&amp;ë�í¬…ŒÀúÂ¡(ã,Ga1‚�	1× ‹m¬
›†jc\kžJ¿¼ƒsý‰)2¨³-&lt;·Aûlx"ã4`à_1“
¯ö©Â…µŒå@*š&gt;%rqów–Ö¯?ÿ?ùã;¤—ŒHW6åBÔ$Þ$É¥Xl/ÖS‹¥Zo®(e&nbsp;¹‰‘e-aTšjqé(èc‘õ#Èø¥,h H²5¼Á¨U:”ãÏ0eÁšÆ�‹+ð�±&lt;ã*�žd8&nbsp;ˆúÓÈÞ:‘–R'â,VæŠœ¢³]öô+Y(qžb”^/Ä•¼F\…¶­�F8˜ô'©œÊ­”Üp.YÈ;
§Ú}Âp[7F†ÃîØpÿµuÌ2&nbsp;…¤îlõüþY…§#zAZ¤ÑDì)~/�A•;)O)g¯qx³4ÿž¹Låš“»cä"ê™QZ‰faí†õ,áW»]qÂµw¾ñ|Î›m3E°nÄn'ÅÃ†&nbsp;‰SäPOx4OÓn–pÝ\S1J‚‹ýù÷^ÖŒÏ°®âùNÏjÇ2Çó®L+a8	¸ÌèÐÅlâÀãÇ‘C}ñïšîüv+dõMËÓñ¼Ðæ–so)²äÒG¶^€êåÑ­#&amp;Ÿ‘Kï­|$ýnN“÷µÖ„Eª×Ì”¤4&nbsp;r‰)Ñ³óŠ¥�îð&lt;ÅE»³gj†¾úè{(š=”øÔõ�ç�­2Ê¤hÿ9Ê €]§&amp;§®{ˆ™â˜”‹wÐ	z¨1‚~a¸’{»›r(˜õ–Ü_vT|Œ"&amp;–Ôw[7eÛñÄë™Ç¶nK%Þ4íMT³·-ŸtK'¿ï‘^ý¬xŠ*îÌ¤„sÊ~(Ë~#÷T�&gt;ºÇ½(MGIˆ‹[:	;Ë~lÊ~ëÀÏž¿«2Ø&lt;ûmå-�ÅÄx”~é±(ÜÛòiy}@ì&lt;ï�4î;×_â£¸k²9–ø•N"r+Â1¸^ì”ç&lt;`8
8qEØ¢¿ÑÄáè-8•L^?×õÃ³&gt;��³ÓB¼N4lDƒãö­­çÂ‹áã‘ô%¾žqi#–¼
�DÊ‹È'î�3bF8gØÄ±Ö`Õ”dÔ„Œœ&amp;Œá¼ÕXøWU@`{¡:¶Îß^ê…µé®21Ì(›àùø“*b,3�‘2™ðª6è�Í$1¥Õà"çÒ±.»¤œ&amp;‰Q²ñÌÜÐ{J´ÝŸío/$!gú&lt;36R&nbsp;ßù1�=|¡wž¾ð[±=d¯EXmF6èØ&gt;’Šm'uQFÐMmf�u©Z	1‡Å½K•¥V}÷ñ5$=Zû|p'Ž8¿GôÙfZÄe$]¸½‰ÄA›b3ß~×ç.HKüG²D)à(Ý?òä“é�~Î!.&amp;÷´$¥Q¢¢]Z�˜Ì'VeÉ‚hÅÁ„QÇtöbø‰­u5§ª¾9�íu/TQevÂ^,ÕÂ-Lâ´°ƒWøÿï&amp;ÓÁóz©+£7“OZDl¿Q$ÑIG�o�¢Ñ°ÿo/£Õ«žw¾äúJêôltCqÚ¾NºõÝ³ds›áÅ†2ð_•
ç¶�Ç(ŠªÁ£pXfú'Ë&amp;~
ÕÙtæ-ip:ÞäWÎu"[ÄÙôFeVº.,ù4ÄBÞæzsÉŒJê/–Œþ“ÚUefKçÙ±ƒgAÛ¶¯ó©J7]{MÁtmx6cvKf£èAJ»}|]îÍú½/dtÇƒMqŽrO1†4‹JE€_˜‡ÁE&amp;À�&gt;Z.h£ƒ§�e…:eo¯ŠFHlÆ•žÅ²ä¯R�DË2²Ä'†…�a¼©â‘oísã„Ê"ézSP1'ÙZR&amp;¶!8^t°&amp;ÃØÏ*¾RT•ÑY-E�’òúf&amp;_4H(�õ6—[+äNÒ‹Fèù”Ç»5¿&nbsp;\Ž’ú"låúñ­“ç`®BÕÖy&amp;NÁ•©^À�5ó'ä�Z_—ªÝó‰•c?Ô�K•­ŽcóñÕqí¾<kŠxæ³8… j–—‘ÅÛµ¡èu�h ì69æ3mÇw‚ãÆf}ª²r¥¨mt³="">Š…l³&gt;@±YooÕ	&lt;ÑK&nbsp;©üP'ßÄ˜ÊŸýÿÑ+$‘7«â5¡œÁ6q˜PF×\…ñ¶N‚MZµ6ŒÞƒ˜}©oVô%˜¼äoC	Ìy*ÄYâ3á/ÐC&lt;ƒæüuÆS£ß9’/$ñbËô�£•Ê[– ‰Qñþáœ\s óâ}ì_Hn:^]Ø‚Œ­$G^]K°»«ýùèËN¸&amp;¥óœE+÷ù²Ó‘÷#eŸ¼&lt;ø'ïûÁ^@_x|tN®ÙDâÃq7àcAnK�ú&gt;èÊw‘ö|±ê™ä¶ìï³Ï¸ãKT"¬Ja¯6ÌÛðIŒ–{ö3r²À®›a„§§ç}Q°e×b°ícÚ¹„`KøÏ;½•×•ÓºnT¤È£É!žà®«­ì°Úù‡ï&lt;ºÛZf”íß“'¾=—�7["a}þÚðô½]ØèßÛ’ç«fÞÍA$^åB8ªI” O€Ñ-ÜøòMeäÒ´€çÈw.úƒ©ÂØ?'n¤ŒÝIõëëuÏ7Çö¾rN�­×‡QÖëm'pÁýi:êáíÙ"Ì[YÆ÷æRÜËwÄNò1Ÿ~ÎLÁBYéåñË•Öm¼#_á’È'ÉØŒä	ï]ÏëÓÅóÒìòæ¥ü6×R`÷ÜË—åÆž¨?†ò/[èþT„Ra¥i÷|ÉŠ`’xixØ}ì×˜QV„™ó'¦•R_	‹åœN„?”óÏP^xé]x!ÁÙ�ä]ÞÄY1Ÿ�[ÑKbå,àŠ‰FŠgšé&amp;ÏhŸÒóCÉËgë1¨‡JËÛòˆV�“ô”§o?ýƒ]‡¯8P‰|‘%zgZŸ|Þ©Mce®¾9–îPÚ¯K1´,u‡aX¢¼°ÑUz0‘´ÿTÓÔ~Ÿ±¦yOÆ|�Š�n­Máø@&gt;9˜]S›M/n¹ú–Ä|‘ä+g‡“ê‘W6”ŒM�‚‘RÆù,MS#qÒòì{jÆÊlw}–&amp;Æ”¯V±WBðš»¥¼ÿ5}…é3Û=¦€ÓŠBþ)xøg³€ÿôY¥þÃ$h¼¿ËÍ\3* Á#
Â?ç
�ú
D×·ºþÄ,ØãU¥ts™ä«•Ó·zŠ¯IÈ{qG™öIÏòy½5¯OúDæCz½èIŸoû-23I‘Ÿ­V.ÎÑ·š¸�Ä9äüã«üÿMÒ	ÅX©Ç¹ueUæœfc-Ú]sà~õŒÍÂ1Ë]æÜ1ç~&gt;IÍ{*âçÏ|0²E"„ð/Â9lK¬\_C—›öGÐÔ6ÿÉàsþ{ÉïÈ¥Û°g¡#{;òÂ¾ëÙmª”%Ú«ë1`NnR5ÕÜóCÊ:9¬ÏÈ!¹ùëGn@ÿÉ\Î¼–Mgçæ–ÉÕwÅƒ±ô†[²övý‘(uÆÍÒ‡J­±:üŽQ	(ðÁ?nÄ¼�þ™O¤–lnŒMè8ñ¹¯úù{!ª8‰ Tbò•“þÄ×5u3X¹W�¸›ò
j¿³|ˆÚ/‡‘Nœ²­A�—~EWMíŒä@99¥5FR`U†_àÎh–øoR¥»ªHŸ_h&amp;ÜŒfÑ×ùl;òOù0L¨1˜ã¸Í&gt;¥tÌ•SÇ¹K0'ÑÌp3š�ŸxªßT�ì…å|¢ûæønAs†_e›!;4Ó&amp;Gf£¥qôüA¿]¥%,ó¤Ë&lt;)9*Ãêä»º‰Àƒƒòè|U4’£H&gt;#é0÷}†™p
†%…Kñ†²PN3i.c3p1�#4¥ï¾àIhv|Í©ä3ƒ&gt;–L¸S&gt;³¾žfÊdO
ž�3Ã-hþù÷Œn¥
endstream
endobj
5 0 obj
6498
endobj
2 0 obj
&lt;&lt; /Type /Page /Parent 3 0 R /Resources 6 0 R /Contents 4 0 R /MediaBox [0 0 595.2756 841.8898]
&gt;&gt;
endobj
6 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs1 7 0 R &gt;&gt; /Font &lt;&lt; /TT2 9 0 R
/TT3 10 0 R /TT1 8 0 R &gt;&gt; &gt;&gt;
endobj
11 0 obj
&lt;&lt; /Length 12 0 R /N 3 /Alternate /DeviceRGB /Filter /FlateDecode &gt;&gt;
stream
x�–wTSÙ‡Ï½7½Ð" %ôz	 Ò;HQ‰I€P†„&amp;vDF)VdTÀG‡"cEƒ‚b×	òPÆÁQDEåÝŒk	ï­5óÞšýÇYßÙç·×Ùgï}×ºPü‚ÂtX€4¡XîëÁ\ËÄ÷XÀáffGøDÔü½=™™¨HÆ³öî.€d»Û,¿P&amp;sÖÿ‘"7C$
EÕ6&lt;~&amp;å”S³Å2ÿÊô•)2†12¡	¢¬"ãÄ¯lö§æ+»É˜—&amp;ä¡YÎ¼4žŒ»PÞš%á£Œ¡\˜%àg£|e½TIšå÷(ÓÓøœL0™_Ìç&amp;¡l‰2Eî‰ò”Ä9¼r‹ù9hžx¦gäŠ‰Ib¦×˜iåèÈfúñ³Sùb1+”ÃMáˆxLÏô´Ž0€¯o–E%Ym™h‘í­ííYÖæhù¿Ùß~Sý=ÈzûUñ&amp;ìÏžAŒžYßlì¬/½ö$Z›³¾•U´m@åá¬Oï ò´Þœó†l^’Äâ'‹ììlsŸk.+è7ûŸ‚oÊ¿†9÷™ËîûV;¦?�#I3eEå¦§¦KDÌÌ—Ïdý÷ÿãÀ9iÍÉÃ,œŸÀñ…èUQè”	„‰h»…&lt;�X�.d
„Õá6'~�khu_}…9P¸IÈo=C#$n?z}ë[1
È¾¼h­‘¯s�2zþçú\ŠnáLA"Sæö�dr%¢,£ß„lÁ�t&nbsp;
4�.0,`
€3pÞ „€H–.Hi@²A&gt;Ø
A1ØvƒjpÔ�zÐN‚6p\WÀ
p€G@
†ÁK0Þ�i‚ð¢Aª�¤™BÖZyCAP8ÅC‰�’@ùÐ&amp;¨*ƒª¡CP=ô#tº]ƒú&nbsp;Ð 4ý}„˜Óa
Ø¶€Ù°;GÂËàDxœÀÛáJ¸&gt;·Âáð,…_Â“@ÈÑFXñDB�X$!k‘"¤©Eš�¤¹�H‘qä‡¡a˜Æã‡YŒábVaÖbJ0Õ˜c˜VLæ6f3�ù‚¥bÕ±¦X'¬?v	6›�-ÄV`�`[°—±Øaì;ÇÀâp~¸\2n5®·×Œ»€ëÃ
á&amp;ñx¼*Þï‚Ásðb|!¾
ß�Æ¿'�	Zk‚!– $l$Tçý„Â4Q�¨Ot"†yÄ\b)±ŽØA¼I&amp;N“I†$R$)™´�TIj"]&amp;=&amp;½!“É:dGrY@^O®$Ÿ _%’?P”(&amp;OJEBÙN9J¹@y@yC¥R
¨nÔXª˜º�ZO½D}J}/G“3—ó—ãÉ­“«‘k•ë—{%O”×—w—_.Ÿ'_!Jþ¦ü¸QÁ@ÁS�£°V¡Fá´Â=…IEš¢•bˆbšb‰bƒâ5ÅQ%¼’�’·O©@é°Ò%¥!BÓ¥yÒ¸´M´:ÚeÚ0G7¤ûÓ“éÅôè½ô	e%e[å(ååå³ÊRÂ0`ø3R¥Œ“Œ»Œ�ó4æ¹ÏãÏÛ6¯i^ÿ¼)•ù*n*|•"•f••�ªLUoÕÕ�ªmªOÔ0j&amp;jajÙjûÕ.«�Ï§ÏwžÏ�_4ÿäü‡ê°º‰z¸újõÃê=ê“š¾U—4Æ5šnšÉšåšç4Ç´hZµZåZçµ^0•™îÌTf%³‹9¡­®í§-Ñ&gt;¤Ý«=­c¨³Xg£N³Î]’.[7A·\·SwBOK/X/_¯Qï¡&gt;QŸ­Ÿ¤¿G¿[ÊÀÐ Ú`‹A›Á¨¡Š¡¿aža£ác#ª‘«Ñ*£Z£;Æ8c¶qŠñ&gt;ã[&amp;°‰�I’I�ÉMSØÔÞT`ºÏ´Ïkæh&amp;4«5»Ç¢°ÜYY¬FÖ&nbsp;9Ã&lt;È|£y›ù+=‹X‹�Ý_,í,S-ë,Y)YXm´ê°úÃÚÄšk]c}Ç†jãc³Î¦Ýæµ­©-ßv¿í};š]°Ý»N»Ïöö"û&amp;û1=‡x‡½÷Øtv(»„}Õëèá¸ÎñŒã'{'±ÓI§ß�YÎ)Î
Î£ðÔ-rÑqá¸r‘.d.Œ_xp¡ÔUÛ•ãZëúÌM×�çvÄmÄÝØ=Ùý¸û+K‘G‹Ç”§“çÏ^ˆ—¯W‘W¯·’÷bïjï§&gt;:&gt;‰&gt;�&gt;¾v¾«}/øaýývúÝó×ðçú×ûO8¬	è
¤FV&gt;2	uÃÁÁ»‚/Ò_$\ÔBüCv…&lt;	5]ús.,4¬&amp;ìy¸Ux~xw-bEDCÄ»H�ÈÒÈG‹�KwFÉGÅEÕGME{E—EK—X,Y³äFŒZŒ ¦={$vr©÷ÒÝK‡ãìâ
ãî.3\–³ìÚrµå©ËÏ®�_ÁYq*ßÿ‰Â©åL®ô_¹wå×“»‡û’çÆ+ç�ñ]øeü‘—„²„ÑD—Ä]‰cI®IIãOAµàu²_ò�ä©”�”£)3©Ñ©Íi„´ø´ÓB%aŠ°+]3='½/Ã4£0CºÊiÕîU¢@Ñ‘L(sYf»˜ŽþLõHŒ$›%ƒY³j²ÞgGeŸÊQÌæôäšänËÉóÉû~5f5wug¾vþ†üÁ5îk­…Ö®\Û¹Nw]Áºáõ¾ë�m mHÙðËFË�eßnŠÞÔQ&nbsp;Q°¾`h³ïæÆB¹BQá½-Î[lÅllíÝf³­jÛ—"^ÑõbËâŠâO%Ü’ëßY}WùÝÌö„í½¥ö¥ûwàvwÜÝéºóX™bY^ÙÐ®à]­åÌò¢ò·»Wì¾Va[q`i�d�´2¨²½J¯jGÕ§ê¤ê��šæ½ê{·í�ÚÇÛ×¿ßmÓ�Å&gt;¼È÷Pk­AmÅaÜá¬ÃÏë¢êº¿g_DíHñ‘ÏG…G¥ÇÂ�uÕ;Ô×7¨7”6Â�’Æ±ãqÇoýàõC{«éP3£¹ø8!9ñâÇøïž&lt;ÙyŠ}ªé'ýŸö¶ÐZŠZ¡ÖÜÖ‰¶¤6i{L{ßé€Ó�Î-?›ÿ|ôŒö™š³ÊgKÏ‘Îœ›9Ÿw~òBÆ…ñ‹‰‡:Wt&gt;º´äÒ�®°®ÞË�—¯^ñ¹r©Û½ûüU—«g®9];}�}½í†ý�Ö»ž–_ì~iéµïm½ép³ý–ã­Ž¾}çú]û/Þöº}åŽÿ�‹úî.¾{ÿ^Ü=é}ÞýÑ©^?Ìz8ýhýcìã¢'
O*žª?­ýÕø×f©½ôì&nbsp;×`Ï³ˆg�†¸C/ÿ•ù¯OÃÏ©Ï+F´FêG­GÏŒùŒÝz±ôÅðËŒ—Óã…¿)þ¶÷•Ñ«Ÿ~wû½gbÉÄðkÑë™?JÞ¨¾9úÖömçdèäÓwiï¦§ŠÞ«¾?ö�ý¡ûcôÇ‘éìOøO•Ÿ�?w|	üòx&amp;mfæß÷„óû
endstream
endobj
12 0 obj
2612
endobj
7 0 obj
[ /ICCBased 11 0 R ]
endobj
14 0 obj
&lt;&lt; /Length 15 0 R /Filter /FlateDecode &gt;&gt;
stream
xÅ�Ë¶ä´†çõÖPø~É¬»é�ÎJVœÀ +h 4éærº!—÷ÌûäÛÚ’l¹l•Ë¥&gt;�EUYþuÿ´½%™Ÿ³O²Ÿ³þÔäÕ`¿ò6kºþT¶]Ÿõe}êûbÈ¾É¾È~È&gt;|ö¶È^¾ÍróïÛ—Ü›ŸÊZÿ–Mw*Ëªï²nÈOuÙô‡—o²§÷ÄÊóaÈî_fUgbÛ¯û7Ù‡÷÷eVd÷ßfÍŽO&gt;¼ËÚìø»OŸé�ú.«²£~~xwà’þÎï²¿e÷¿Ïžß›„™(ò�\ÔµÏD¦™’&gt;I³»ìþ{•kšS×S]_›"do²¦ÎOMözV�†š¢æoÕ&nbsp;ìuö]öíz-•Ã©ê›¾t¬´nÌ—Í`¡u3ÍàY¥WÃ©()]"9ß†´fCÁlî¤
«ž6&lt;$=À~iEÚ|Ò†Ï~¼#ÏÇÌç»»¬ÌŽßœ…¼Õ&lt;¬4`'i•Yæ ’.õsp
8¯Ÿ®8U]EwîªþT�
úC¦Å¨Lu¢Õ]æ§¶*š¹œÔOOGžõqÛŽ*,}üÏ_šÚø»ù¤fÖ;rãÖeÜŽ¦¥Œoé'¾a)AC¿³ruašÓ~Í«‡¡:õƒ©ÖPNê¡©¥bÂ/Nãˆ›7Ø0œ:(Òf]¨Ó›à¹\Q0Ñ›ËmÊ(
ö‚®ü¢/Ó¯èÞò××òu8þ¢½ä‹Ž®Q^™ˆ67¯·pÑV§ªé@Uš’"gP&gt;““’RyšätáŸõVÖ³t'ÈXN÷ö]—½�l¤£Tå,ÝÉt³œ®L7›Ó]%J�ÏÒ}¤òÖý,Ý]å]xô�ÅþC]
ðí×fBˆ\»õî¦ªež»J®ŠÖÓ5ÉØMŸ¼LAWÝV]‘u¡Ü&amp;h_lÃk(½³•G¼†r’ÓAì×o–ºx}þ/c#€NÌ»‡»¬6ö„}swÐ2Eò	ß¹ü“‰
Yaí¯Î´àªÞ¦ÿ6á7ÙcRk8æ^UÐøþÕDMïÒ˜LÓÄ×8š“‡»Yd']&amp;®j|¦B4\•5&gt;qÖ'€²cÄõ-ÖfXy;Û¢ìZj]Œ×Pî}OU3K÷±€XÍÒÝÄ…	H°±lœŽŒ´Ul‹o±Õ©ddäV¹¸qê¹Aî`»Ž›—›NçŒ•5KÜ3²åÙJ,Ð¥ºÛþàãíÄ4rd39OÁ30&gt;±6~±S˜µNmÝ4™S¾Íò.ªæTÈ¼:““ŒÖíeâþQÔÜp±7Lí²ãk
úòî@(ã|ñ	¾¸L£büÞeƒ»`ï°Zp�È0“Èîv‘²7\.èe#%ß™+š–½òÆ4‰é=šäë»ƒDö™‰µíO]UÕ¾rFùùtö6¦£§”¾“Uhþóù_7‹N)…Öâ‡rðû3+�Yæ½WuôªÆ§@ÄŸ^¥™ÕT“¹�«ç s¿©RTMÕan#\ãë½(£&nbsp;šÄ_¯—:ç±—Œ¯—Ûú`�:Óœ÷Á÷ú¨Q÷³tÇæ]IwÊ&amp;Oú£œ
ì
v£&lt;ßÉ9¾_!WG
ëlà+äè}—ùÞ¶IùžDnä{('Ø4dˆòýéi½ÜÂ÷_HÖZåÛÆÖÈ÷PN¬¸-õ=LÅ,
ñT‘
Þ	‚\†m|Â6#²á
Qá
!z³†O­n½W-ê(oÊb8ÉˆtU²4Œ¬Ó­°†H¤g•¥ögm·4ìCªý°_ù±Þ²•ÇÜySP¸øÃÍåtWÍÂÊcnSy©ÈEÌ]]Þº�ÕómõzÅz3Úõ�Û†ÌˆÙ°�b[¤»yWÃ¹ë"…õ˜M“;çÈmk–nnwä:wk¹³aî<fcþ€ã³m˜ •w6òˆÙpîzÌ®[]e“ãËÎ™Â4öf¹©xÚ:—“,7f}-"Œqû-f©˜Öx�°’oñ`ó…[ƒ="" ]®34Âæä‹t®k�½®wªÊ®«il,¦‰Ì<#2*h2—h+Š�+ÙÌ<þ&,][«y¢="" wøÊ¶Äm^´¾vc“‹yÑ1ù_{¤="" �ÛÜ5Òe›Ò¸‘í¬µÂx¼Ž…Ê¹Í]º·ÁÖ§¨?ÖÝõµs›»t="" –7Íä22?É`™ŸfÎ›ÖÛåúõÆõ‹w®’oœà<ó«$‹wžùiäfæ‡rÂ|ã:‰2ÿ£Ìw×i¨áœ jí="" ed~(·qrúsd¹ÆÞmyølÏ•="" vhþü…y’ÿÈsoigæc_õÃ<�xe|Ér—ŸŠö\nf]ÉŽ“åbø�yv ¾yb`jÑ™ƒß?1ðÇ_cv¾eŠ="" ”ù‚o¼c="">Þ�ßš)F~úñW�Î&lt;ÀÓ“±e8¬íô(;aÕÀ&lt;`ëüâ&lt;užzïùLNêƒš˜ûé2œ÷Ü¥ûXó€óž»tSÍë]nœÂQéh±á<niäü°]nˆÖ›ýÛå"ì½çeŠÆž¥ªz€Êioß°cÛãl{g3�ÓËyv—|ºÎ­ – ú®(yøt¿,¬1z|²öoÔÏzîµÅ¤å*ë€ê!!>dâ'!ªL«u‡…</niäü°]nˆö›ýûå"ì½çešæž¥ªz€êioß°cûãl{g3�óëyv—|ºî­ – ú®(yøt¿,¬1z|²öoôïzîµå¤å*ë€ê!!></fcþ€ã³m˜></kšxæ³8…></fä™sâ¥ôs></vwöžð„\~"šy¤u¢9¶��ìäð¨œ„)¤„ó«ù€></s«u5lë™�ƒìœ`�ûïíê(}0f�ípæ¡õ5¸ñå°ðÿú0â¦></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf">https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf</a></em></p>]]>
            </description>
            <link>https://chrgj.org/wp-content/uploads/2020/07/Alston-Poverty-Report-FINAL.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812118</guid>
            <pubDate>Sun, 12 Jul 2020 15:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WireGuard as VPN Server on Kubernetes with AdBlocking]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23812063">thread link</a>) | @coding_coffee
<br/>
July 12, 2020 | https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/ | <a href="https://web.archive.org/web/*/https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Lets be frank, the Internet is simply unusable with all the ads floating around.</p><p>I use the <a href="https://github.com/gorhill/uBlock" target="_blank" rel="noopener">uBlock Origin</a> extension in my browser, as do most of the people reading this genre of articles, but the same is not true for the majority of the population, including other members of my family. So in order to enhance their web browsing experience I decided to block ads at the DNS level.</p><p>But why stop there I thought, why not also improve their privacy while I'm at it. So I also decided to setup a VPN. Now let me clarify some things here, I'm not a big fan of VPNs, the way they're advertised by the big companies, here's a <a href="https://www.youtube.com/watch?v=WVDQEoe6ZWY" target="_blank" rel="noopener">great video by Tom Scott</a> explaining what I mean. But they also have their use cases, some of which are:</p><ul><li>Prohibiting ISPs from collecting data on my browsing patterns</li><li>Circumvent internet censorship</li><li>Connect to my home network from anywhere</li></ul><p>I took a look at apps like <a href="https://blokada.org/" target="_blank" rel="noopener">Blokada</a> and <a href="https://github.com/julian-klode/dns66" target="_blank" rel="noopener">DNS66</a> which grant you device wide ad blocking on mobile devices. On Android <a href="https://block.blokada.org/post/2018/06/17/how-does-blokada-work" target="_blank" rel="noopener">the way this works is</a>, by creating an internal VPN on the phone, so that all traffic from the device can be routed via it, and it has a file with all the blacklisted domains, to filter out traffic.</p><p>But there's a caveat with this approach. I cannot use another VPN to route my traffic, due to an Android <a href="https://developer.android.com/reference/android/net/VpnService" target="_blank" rel="noopener">limitation</a>.</p><blockquote><p>There can be only one VPN connection running at the same time. The existing interface is deactivated when a new one is created.</p></blockquote><p>This means my browsing patterns are still accessible to my ISP. So, I started looking for ad blocking DNS servers, so that I could point Android's global DNS to it. I found <a href="https://adguard.com/" target="_blank" rel="noopener">AdGuard</a> and <a href="https://pi-hole.net/" target="_blank" rel="noopener">PiHole</a> to be the top projects. Hosting these at home, on Raspberry Pi seemed like a plausible solution, but then again one can't use it while traveling. The solution is to obviously host it on a publicly accessible server. Amongst the two I found AdGuard more appealing due to the following reasons</p><ul><li>It has out of the box support for DNS-over-TLS</li><li>It maintains a single file for its entire configuration</li><li>It's written in Golang, and is much lighter on resources compared to PiHole</li></ul><p>You can find more about their differences <a href="https://github.com/AdguardTeam/AdGuardHome#how-does-adguard-home-compare-to-pi-hole" target="_blank" rel="noopener">here</a>. Both are great projects, but AdGuard met my requirements perfectly.</p><p>When it comes to VPN, I did not even consider using OpenVPN, <a href="https://www.wireguard.com/" target="_blank" rel="noopener">WireGuard</a> was the obvious choice, because of it's speed, smaller, easily auditable codebase (not that I was going to audit it, but still), cross platform compatibility and integration into the Linux Kernel.</p><p>Being a big fan of Kubernetes and maintaining infrastructure as code, I wanted a way to be able to easily deploy and version control my deployment. After much searching I stumbled upon, <a href="https://github.com/squat/kilo" target="_blank" rel="noopener">kilo</a>, a network overlay built on WireGuard for Kubernetes. It could do exactly what I wanted, while also enhancing the security of my cluster, by encrypting the inter pod communication, and allowing me to build secure clusters, over nodes spanning multiple cloud providers. Also it would give me the added benefit of easily debugging applications deployed on my Kubernetes Cluster, since when connected I would be a peer on the network, thereby getting access to the all the private IPs of the deployments, services etc. You can watch <a href="https://www.youtube.com/watch?v=iPz_DAOOCKA" target="_blank" rel="noopener">this talk by Lucas Servén Marín</a> to know more.</p><p>Without further ado, let's jump right into the setup. I'll be explaining the steps for setting it up on a <a href="https://k3s.io/" target="_blank" rel="noopener">k3s</a> cluster. You may need to modify them as per your cluster. After deploying k3s, the 1st thing which needs to be done is to setup kilo. First download the <a href="https://raw.githubusercontent.com/squat/kilo/master/manifests/kilo-k3s.yaml" target="_blank" rel="noopener">manifest</a> for kilo on k3s.</p><pre><code>curl -LO https://raw.githubusercontent.com/squat/kilo/master/manifests/kilo-k3s.yaml
</code></pre><p>Now you need to modify and add <code>- --mesh-granularity=full</code> to the <code>DaemonSet</code> section under the <code>args</code> for the <code>kilo</code> container.</p><pre><code>...
containers:
- name: kilo
  image: squat/kilo
  args:
  - --kubeconfig=/etc/kubernetes/kubeconfig
  - --hostname=$(NODE_NAME)
  - --mesh-granularity=full
  env:
  - name: NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
...
</code></pre><p>This is done to ensure all our nodes are meshed together regardless of the datacenter. Then simply apply the manifest.</p><pre><code>kubectl apply -f kilo-k3s.yaml
</code></pre><p>This will later be useful for setting up WireGuard VPN. More on this later. Now we can proceed to setup AdGuard. Here is the spec for AdGuard.</p><pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: adguardhome
spec:
  selector:
    matchLabels:
      app: adguardhome
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 0
  template:
    metadata:
      labels:
        app: adguardhome
    spec:
      volumes:
        - name: tls-cert-secret
          secret:
            secretName: production-tls-cert
        - name: adguard-config
          hostPath:
            path: "/path/to/store/conf"
            type: DirectoryOrCreate
        - name: adguard-logs
          hostPath:
            path: "/path/to/store/work"
            type: DirectoryOrCreate

      containers:
        - name: adguardhome
          image: adguard/adguardhome:v0.102.0
          ports:
            # Regular DNS Port
            - containerPort: 53
              hostPort: 53
              protocol: UDP
            - containerPort: 53
              hostPort: 53
              protocol: TCP
            # DNS over TLS
            - containerPort: 853
              hostPort: 853
              protocol: TCP
          volumeMounts:
            - name: tls-cert-secret
              mountPath: /certs
            - name: adguard-config
              mountPath: /opt/adguardhome/conf
            - name: adguard-logs
              mountPath: /opt/adguardhome/work

      terminationGracePeriodSeconds: 20

---

apiVersion: v1
kind: Service
metadata:
  name: adguardhome
  labels:
    app: adguardhome
spec:
  type: ClusterIP
  selector:
    app: adguardhome
  ports:
  - port: 80
    # targetPort: 3000
    targetPort: 80
    protocol: TCP

</code></pre><p>The <code>RollingUpdate</code> is intentionally configured to not wait till a new pod is up, and directly terminate the existing pod during deploys. On the surface it seems like an anti-pattern, but since I'm using the <code>hostPort</code> directive, a new Pod wouldn't get scheduled unless port <code>53</code> was available on the host for it to bind to, so the existing Pod has to terminate before a new Pod can be deployed.</p><p>Also I initially intended to use a <code>ConfigMap</code> for holding the <code>AdGuardHome.yml</code>, but there was some issue with AdGuard trying to write to it while initally comming up, but since <code>ConfigMap</code>'s are moundted as <code>ReadOnly</code>, Pod creation used to fail, so I decided to go with a Volume instead, until I could figure out the issue.</p><p>For the initial setup, the AdGuard admin UI will be accessible on port 3000, so you'll have to switch the <code>targetPort</code> to <code>3000</code> in the <code>adguardhome</code> service initially, access the admin UI, setup the password, and then revert the <code>targetPort</code> to <code>80</code>.</p><p>You may also enable <code>DNSSEC</code> under <code>DNS Settings</code> for guaranteeing authenticity of DNS responses by signing them, and making tampering detectable.</p><p>The volume mounts for <code>tls-cert-secret</code> are only necessary if you want to enable DNS-over-TLS. And you need to configure your ingress resource before mounting it here.</p><p>For enabling DNS-over-TLS, on the AdGuard admin UI you can goto <code>Encryption Settings</code> -&gt; <code>Enable Encryption</code>, and put in the Certificate path as <code>/certs/tls.crt</code> and the Key path as <code>/certs/tls.key</code>. Again let me re-iterate that your Ingress resource needs to be configured properly and you need to have a valid TLS certificate for the domain you're hosting AdGuard on.</p><p>On Android phones for Android Pie and later, you may goto <code>Settings</code> -&gt; <code>WiFi and Internet</code> -&gt; <code>Private DNS</code>. Select <code>Private DNS Hostname Provider</code> and set it to the domain name to the once you've configured on. You may also configure it on your home router to ensure all the devices get DNS level Ad Blocking.</p><p>This concludes the AdGuard part of the setup.</p><hr><p>Now coming to setting up WireGuard.</p><p>I'll be referring to the k3s cluster as the server and the local laptop as the client from here on.</p><p>You'll need WireGaurd installed on both your server and client machine. Follow the <a href="https://www.wireguard.com/install" target="_blank" rel="noopener">steps as per your distribution</a> to install the same. If you're using a bleeding edge distro like Archlinux or Gentoo, you don't need to do anything on the server side, since WireGuard is already baked into the kernel at this point. On the client side however you'll need to install it for getting the command line client to enable / disable the interface.</p><p>Another useful tool to have on the client side is <code>kgctl</code>. You can install it using</p><pre><code>go get github.com/squat/kilo/cmd/kgctl
</code></pre><p>Now we need to create a private and a public key pair on the client.</p><pre><code>wg genkey | tee privatekey | wg pubkey &gt; publickey
</code></pre><p>This'll create 2 files with the respective key contents. This key pair needs to be authorized on the server. You can do this simply by creating a peer resource. Create a file named <code>archie.yaml</code></p><pre><code>apiVersion: kilo.squat.ai/v1alpha1
kind: Peer
metadata:
  name: archie
spec:
  allowedIPs:
  - 10.120.120.1/32 # This is just and example, you can use any valid available CIDR here
  publicKey: CLIENT_PUBLIC_KEY # Enter the public key here, the one you just generated
  persistentKeepalive: 10
</code></pre><p>Finally apply the manifest</p><pre><code>kubectl apply -f archie.yaml
</code></pre><p>Remember, the <code>allowedIPs</code> should be a valid CIDR, which is available on both the server and the client. Now we can use the <code>kgctl</code> tool to generate the <code>peer</code> section of the client WireGuard config.</p><pre><code>kgctl showconf peer archie
</code></pre><p>This will return something like</p><pre><code>[Peer]
AllowedIPs = 10.42.0.0/24, 10.42.0.0/32, 10.4.0.1/32
Endpoint = YOUR_SERVER_IP:51820
PersistentKeepalive = 10
PublicKey = SERVER_PUBLIC_KEY
</code></pre><p>Create a file on the client named <code>adgaurd.yaml</code> at the location <code>/etc/wireguard</code> and add the following contents to it</p><pre><code>[Interface]
Address = 10.120.120.1/32 # Use the same CIDR whitelisted in the Peer manifest
PrivateKey = CLIENT_PRIVATE_KEY # The one you generated above on your client
DNS = YOUR_SERVER_IP # Enter the IP of the server to block ads, FQDN don't work on Android for some reason

[Peer]</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/">https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/</a></em></p>]]>
            </description>
            <link>https://codingcoffee.dev/blog/wireguard_on_kubernetes_with_adblocking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23812063</guid>
            <pubDate>Sun, 12 Jul 2020 15:29:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WARDuino: A dynamic WebAssembly virtual machine for programming microcontrollers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23811950">thread link</a>) | @lioeters
<br/>
July 12, 2020 | https://science.beardhatcode.be/papers/2019-WARDuino-MPLR.pdf | <a href="https://web.archive.org/web/*/https://science.beardhatcode.be/papers/2019-WARDuino-MPLR.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>s	�á3
4†{´¢p¿YôdšrýØëKæ‘+ˆ™ÇÞ a}ÀõàíÑ«&nbsp;W€‡Œ{Fvm734…4˜‡¢´�A­«»èGÞÿc Ú¤Þ_86
endstream
endobj
6 0 obj
&lt;&lt;
/Length 770       
/Filter /FlateDecode
&gt;&gt;
stream
xÚmUËn£0ÝóžE¥Î"�±y$UÉ6&nbsp;É¢5Õh¶)8¤"’,ú÷ãc\W³Ýsß/.7?ž·3ÑôozÆï(yÑ§þ2Ôz¦vÇèæ¦èëËAwçG­ÝŒÒÓ=yúz«ÏäVmŠM×žåMW\=jý_Iê÷¶ó*ˆCn_õŸÙÃfö
¯íùÃ&amp;1yØ+ü­‡SÛw÷$¾£”FÙ5ª? ÅS4¿†!ó1ð¾íšá‹¼!r3Ò´õùŠì»&gt;˜Za¼ý&lt;�õaÓíûhµ"ó#&lt;�‡O›ËÏhþ44zh»wrû°1p{9?4B“4Z¯I£÷Æ‹©çqwÐd&gt;å?ñ¯É»Ü=ûõó¨‰Ã±K«î}:îj=ìºw­(]“UU­#Ý5ßd¦kò¶u¥Ñ¥¥yže¥ÖÑ*†ƒx12+ƒ¹Sx¦æ,öÌÒ09Ì9Ô)5t´J&nbsp;�N¦Š'†™�™{fSÉ
–2Œ¬RàÌ¼	&nbsp;KÙÀÒVi‰X¤¤†BÆRs&gt;–^ÿÝ
×.¹¢KäCc�†2�—ÀÜc4‰&amp;WÀ©o"²¦™ÇÖîq¼ð8^zlã	�p5u%†=c¾K(œq/‡?–xŒQ±Ôcøc™·/€s/G|¶°£•¨•-mõ„¥•�éÆ¯P/S8+8èÂÑ4fÁR§SYZ"?.ì‚0»1ÒÑˆÅ•[KŽ�þòÒñ­¾õÃú�PKS6Ò×0ÃÔæ—eÈ;UŽ†}Z8~S›gÈ;­
_™õÇàg®v»ói;K�¹æÊcÄÌg‡ÝÌ­oZ&nbsp;ÞÜú¦	ú¶ø’'üêê„LÄá^
î¥àá^Š$ÜK‘†{)²p/Eî¥X„{)–á^
î¥(Â½ßŽ‡¨<fß¥ÿÎ*û‰ûúp£v’…{-uxbdá1üË2¼6ÒþÔ—Þ¢Ÿ*÷z}‰‡9+Îb%Óœìõ°×—gº×õeÌ)·ÿ{–q�Ûno¿�c„•}ìgü‰=uÑ?*Ëa endstream="" endobj="" 124="" 0="" obj="" <<="" length="" 4964="" filter="" flatedecode="">&gt;
stream
xÚ½;Ë’ÛF’w}#v#Ó„PU(&lt;´—‘Û¶ÂcÉ£UËž˜°}@“h!à@Ëý÷›¯
$(y÷°‡ÖUYYùÎìhµ[E«7/¢³ßo&gt;¾xù½2ùJGa’h»úø¸ÒV…™6«4JBç«�ÛÕ¯Á?o”ÒÁëßUÓÞüþñïðY­Tš8ÑøÙZ¥6T°ÅZ›0WüÙë›µ¶QðíÍZEÁsSÔÕ†Gþy“EAùp£#X;w]Y?žyò—êÔÅ�;ïŠÍ¾jJî&lt;¶'n¼?ÝdA»;u]5;YYmhôf�›¶é©s8”§ÎX…¹µpœ¸
ÀMÃ,�ÞíÃÁZžzÞôÍ€ÛlKÜ´&lt;òØ=¹ŸöÌÃ&lt;Ñ	¡N‡*…-ùÞòÍ¾ld¯Ÿ›ê	6€ªþ¿_XoÖßòß”‡]5Ôî(ëµ6i¨r;ÿÖ?œCN0ÿmØÁæ¡¬YÄŠNt˜ªdel˜%²íÝþTu}{ÜË+Üoö€×j†Ø	2•†FçÿOHRË³ù·´pËpöòöüÀÌà¡cm" “Ž@É��õC×ŸŠM¿xý0Ò° ueã•Ít˜ÇðY
Ÿý€(Èã&nbsp;êø·¼Iƒ?ˆLËº$âÏm°/èÙxEÑH£¯êr
DÝ
Bï8Öòo]|*¹µiO´qA‡àD‰O…9\‡àáÝã&lt;(‹L¼©Æ7:ŽÜÕñæ;hÔWy,”çí€sé.ÞêµÅÇŒÍÃÈfÎØumbrÇ@5]nËKª†§îZ@èg: rŸà¯&lt;\l�\(NÃ(ÔŠf7;Äk’Ý°Ùs«@„$IpÇÝÏûÊÍà+tÜì÷eÍ­é1q¸åo·åÃ°“íà 1(I5uQ5=ü…|Ç�7‰Fôã•NEÕ	‚ú½4
!Íªm.qË#uÑ<sk_�óweˆ.©Ädºjrèx.zµÑ…Ð®ýÄo‡s¼·¯¶îñpq7�ØmiÔÂb&2˜™nx$`o­´`‡ah¾f™°à»?Šúxà7Ê�t6‡a[rçýs¿o›[î¼ iÝýÇ.â<µmg¤‚¿oÅýætû�~î2hÂÛà3aÓÇt÷e7.áÆ–h¸éu<sôŠˆÙh°€Ÿ§io="ò" èqÀ-©�d)œjy¸.vmÕóõa¸Æa©ÌàÔ†ç2hðšµo(´®´l="�Á0±à‰/òNïÚQHµn³Ó�Íƒ[w¸w›ö±/”3BÂ¡¦åOX†¶½" ‡íf6÷€jlhrÁšg€¡£3·Öå‰yÅ`Å&ñ�pÄÈÞ$À¡u,hÂz,äfÕÐµº¾Ú}é¾“ÆcytÕcu@hô.q="" Žhr0�r�Ëjcw&v­b“‡q¦²kªÄ�Îrf%î¿&‚="" #ŽÖmÚúxôÕÃatû—¸h�Àv²zÐó°7ÀŒx­="" b@m5}Çã‡²Ør¡wÂûnéÚ4ƒ8Âf×o9é‰`1*²ÕüºçÐ&x¬lhsaÏ="" ïàry|®úý+nªß"«piÂiÅcÉƒ‡Ê‰-èl[é="" tŸ-¼eÇ,¬°14$me\4v„k‹ég� ”i…="" ng="" Î}="" †®rmdvÂ@Ñó:¦) ;Â�<d2ñ'="" w†ùŠ\5¹@pv#m›mŠŒ³n="" ŽÁŽÑ�Ž‘˜r&&="">ÃD&amp;¨m	Z\L:~�(âRþ~
kÝ—TfÂÈÝ¤y˜F–�{rþ�ÊQï²&nbsp;mð—Ž‡	†¶?ž*´hp¨�©®ëd&gt;Ä2&nbsp;ëˆ	Ðbäá�D‰Ð ÙÒ
‡ÞÉ“3n´Z¯L’˜ºJft•ˆëèqà·l‰Ý$æ�ŽÆ�“¿ò!*ÒÜ	s1\ûÞ­[/p¦±6Ls�htþï“9ÙŽ-þ�à‰`K‚¢ì�†¦ù#ƒV&nbsp;�ƒ`îd—®ª%EÃb|è'z Ä&amp;Ìb†´-m_t£·Ö;o¥Åê)B¦s:¦=¢¹�="ž�W5“[‚e£àÒ
–,x*Ë^hQ8aÃ»Ó-�8©
Í

<p´sðþéhi"ø2Ÿ1¯ÀÛ­�m£,ØuÉ-–Ð�ÆÚï¤Ì¾Ø“çn6ûº8}êxÐœÐìöbîbg4Îì}¥ažÆ“™@v9Ñ#üž†f |‡Èu="" hs&¼åô?œ="" ptl�8Ìv´¾ëŽ'"x€ùvö\ÀŽÎp²¹x’d;Çápaov÷g„yš…�<þùîþ½ÑbØ\s_7‰="" bq×lâ»klÀpâ�ÜÝÝ£l²Á]œsì�«–ßôq.Œ5ð="y…¿iÉ*p&quot;½U¡5©[tÍçÑµ�ý‰" l”ußñhÙì*æ+ÐŸ,sÎvèøêqs�Ðjéd‡:ÏÝª_*`dk‚šùÍsÈedê¢wœg�v[þ×Ò©1°½z¼="" ñ="EN07Ë{Û…K+Pæã=ß¸�:à´££ž£aŒKÄ�“X“Ê«³ê®¸îQ.ô&nbsp;¢8Œá:Ö¡vZQŒ²‹¨•Í˜æ­ºsÎ…®K$¾ù5" ¾³ãl~j�…="" –ÂÝd� “íy#~ã»�="" þýÂß¸?Žõjs¿øõ÷hµ…qdhù™vÕp¿(ŒbíÃêþÅkdÐ‚rÌá‹ˆ¨dÀ³pÉûòtw :ÑÙÄà‡$’1$aƒmµ«zbhŽæËeŒ#="">=V$[`‚4Œ‘’¦ùâX°å“Èë¬páWýÄÃ(.mÞRîÔ¡¨Í®m.“�mB¿›CÑu£ikÈÉN,ÅmpTõ¤"p
K’õØydÖåÎ’ó‹ã$¯iS¹þÌiFF|•‘ƒÒœDEjË["4Áï¶ï¿z&amp;µƒ�n–�AsN6pà&nbsp;éJ©¢§‚¡bû—äHêQ©�)Ø€M]0G4I�#ŸŒ®´àÕ¦œ¢ .pÂ�Ç�Z&nbsp;f`ÏýŽñ2§®çÎÁe»wíláçSµÛ÷‹¶Y¨Ð„$cRòˆÈÔnØsÁ1¤9üeð�ñhŽ¦ÉgŸ¦že=uîcÔ•8ËÁ*&nbsp;›™Ó(MÄŠ†‰zè±Ä±�±‹cìÛfòª·ˆ°\]˜RÜˆ„èT˜nZ\	c1;¥Ž=êªG*JÆÝ\ä	ÛðÄâ¢#Gâ%Y¾b<j³û¥  Ü!²&(ŽÃÃ¡êÈÓbújåÌòžcbôð0ÚÉibæaŽ¹oÑ—"›9›±ƒ¿7×wrÞˆˆ›ú.lu¹}»#nÆqÕ="" )ns.«•Îb="3k|Áè]b‚—.�Qˆ5#ÂB¨F">0eç‚±³í:ùŽüúzqÅßŠM¶§�Ó“‰õ„yJÄJ^çÝû·x“¿¨\îÿØô­K#ðˆwYƒŸ#t4®}
oßtÒy3â’qUN¦ËÀ:
­�ñ˜n“&gt;ž–bpaÔúx(sÇÄG|Í–æ¾&lt;ˆñðì{0%¼yz¹Àk‚ñ÷H'e`@$}3pAám2ž€/_­ÉlËI‚)¯oLÜ½coî©Ý:—6ày^üÃý7?q+O³µZÇ62ë$OÓuôRå/?ðàÔÎþSY0RHéù…–Hoõi5ïÿø‚“%ÞË_À³Z¶ÇîÕË—Û¶BŠÁS|õÒ›š,“¨Hç‹¹’åÜIÛ'1g’L˜h³²Z…q/&nbsp;àCùHZ§$ßG¾GOµ5Ã´�'	�JÉlµ¼…Sdžº3Iv‘ºÃ1NÝQ“
ohøé-Z3fŒ0æžäDzÒDçúÃEe„	œˆ&lt;I@!Š8e”
…Ÿ³T(Œ€Q™-§Bar²'¡3¥B¡#¨ÌK…^*±Ú&lt;‹˜¿ûZÄü‡f’ ‹+ðm€ØüýßO{N¢|x'û-É�
Ï•�R‚ÖDÐ¹ÿáÍû·¯º-�w²18_Ú…fÁ?lˆ…Ù‰1è·Í©K”L½+2lØB‚‰Ël²	Þz¡zŒªK¦ÆSf#$±	#çòñ•UšR¤ŒE,ö@Ä¢Ø¹åÞ\Ìâˆ'f©Ëb›£˜ÅÎ¥˜I5zE3¦ñU/Ðp¬õZÀ8x¸ïdãŸJ
(øº
ï˜€á&gt;_¨ŒÄþu“¢Òý$bÿ':ÿ_7qÈÈÏ÷¯oYf&nbsp;¬§½BeAFÍû?¾XýJëÙo%‰Œ9gðçeÝtï\‡Y&gt;z©ÿ79w™†]ƒ¦ÆªÞ[áFRàHø×Aeòåì°#Ÿ8G‡YPû…†µÉÀ[ 2KÐú##ÛKÙÑÌ²µ72ðr†:2!˜Á°�éùZžÛ„±:»É˜Zºrï“å~n½ã­©æD+üÞñÄ¯ŽœF²Ím˜Ff~Ðüygr,"˜/ÿ]aÏÊ_ÿÊ#ÿKXb0ÚsÏ7WÉu`Ð-M}	Œ	(&nbsp;˜RÜô�ç¼‡®åÑ§âT­¯ÊÏ+G·C·D)³ïL&amp; ägßaùk„2Û$M@%óM.Êvž(…nñTT‡b
Ð£xx»H¦t\~~W@)mö¸)íÇG—¸s©Ñ¢¿ÈX*bQ§)âs@°Æ@Ïîíå3�;Ë�s§ñy ©'óIo9ÏÞÿŽCç`³r²5æ4ÍTÝüUñ•PèIvU€Ì/i¢"¡Ë„ùŠ×»œŒ_IÎ�‡	®¯Â„EJ—¤Æ"ÔeÝ²OøÌ°Ë{´0"Ñ�
©œ&amp;Æx
ÎüÃžAæg/›Ž#sw¤)p•[Ðtw{*h
åbdÚä7dcÞšß%7È‰À_—%î�ƒ¹‚áx�Ôp&amp;Ùâqe¶XÚr‘Áª…È•”H0Q2ø„ýRôœóï’,¹¦8Ï_qÓMR~ÐˆåUWWŸÕdi—�ÐÑÕó�xïá•ˆvè�á—ƒbÐÀ�bîQ¨‚ßŠ‚0ë²¡Ðüùxh‹­ŸÔ;‡Lyí,¥‚Yf~W#®_&lt;1 XèGn!A�á‘í;9×Jõò´+WÂŽ¼�ñiõ–×ËÉœ¹¼¢P
Ö5ÛR\(§ì+þJž8›_&amp;ÃÓyðœ!ižËÑÞ1SµLxàf›Y¸g=â'9�Y-,H(Ä	ï9„­áè×4Œ¡&nbsp;uì�B8§-
‡«tÚ¼©ï˜xâJé/”;ð¼ÌK	ø¹Px4:V‹9�p.÷&nbsp;8,HÕON{ûZ	c0cçcæ¯¤PmÇ«Æp@Z]ép"&amp;
É[Oe`rØ•Ì5Äj	•úYB•Q$”®úª(=*½ý*ûJ,øè6–"§«æ¡«Ô&amp;®JàFãWÃ*í
ªpÈÓ7ØkÊ�z~ÅMÑ&lt;&lt;*ªš6*)&nbsp;˜�ñwÄ²á7§3Úþ¤k&amp;\ŽfVFÅ)!J\»Ã•«¼ƒ_EŒiÔÜÚ(K4;!;çvœ&nbsp;pÆ¾ò+&nbsp;®�šæT8äé$z:7{å%·<b¦x´dÆfœª pvÒúdfÒÞ€í!aò¾½¨—¡iÐ¯l|Š›™ÕÄ{!Úi²hxmÕ¹b)="" ‹‚‡âÓ$m(kÜžÕ,fç| ±j"v% ñté="" ¬v—eÓ¹’.2ýâ.ÿ³Ìñ:="" wu5ee`@x8="" ªÇeÁ©Á©j3ÁÐ3‚?œ®a)š°4gkehxµn¾à�‡kíd¿mbÕ'%«Ë.ŒšªâŒÍ\nÄÎªâpbê+°y^‡«™`’Ól–…="" Î_u^mƒí5Ç3×tÙõu'<Ö*³ô¼¾¹ßÕq§‰ˆlþÌ¬#óè�š¢w8‰&€d="" 1²7i¡ÂÉ+9£ÚŽÂ0º="" ,áa¸="ˆ/²#‚œåæJƒ">�‘¡F&lt;™K}å[|ËE�Ä/é%¿œC¦rŒuÚ9»�´�¥~Š4“ïuŒÅŽé¤ºž¦œùTÎÅ¬Ñ9K×±YuU«,c�3ÏŠâŽ\æGjÌº"½Ä/Ul;0c`ìŽf[žÏbîæ.k=U3ÐÏÅ6ç ¥:Œ¬W„u±kÇ2Û^JpÁÒÀ‹ïþ„%Î*"
œ·*L¾�Êrfú’|QI*Ï,CB8UýY)Ö‚õ*AÏç'c¯\–Lc–F®üâ“Øµ®î
&amp;Æ:Pž¹VêÉŸ±I_Iá&amp;ŒM…›ÖN…›×¢Ê$¡r�•yaçÄÑ¼¦XM*3ä&gt;V1ç_¨bþ&lt;=Àà
ÜÆP[U]?qýíè8Ôf,Ÿ“zWlZHí°½R^?Švåþsk^¼%ÓÒýWÕ¬f“`'eç^ùÜ»…ý(•D&nbsp;]rÐèÙ3Š/Á·R&nbsp;|¾ð½½¸ÊëócÏÅUÈse±RÅÞeU]b¨”.!W,1Ž)w¶«Á'/Ì4C•tc�Ç¢E‹ê%ËBã’B"“ŒÖçfþSÄy&nbsp;g8ÊZªÔž²ö<hf«f=Ýóz9{(:ÿ‹â¸^˜sÁ•±b2\lü}÷ñÅÿ�…for endstream="" endobj="" 146="" 0="" obj="" <<="" length="" 5490="" filter="" flatedecode="">&gt;
stream
xÚµ\ßsÛF’~÷_Á·£ªD,æ~ä®jË‰“TöÖkoìZ?Ä©+ˆ¤$¬A€K€Òêåþöížî@Rr6w/0===_Ý=Tº¸[¤‹_}ûñÕ~PÖ-ò¤ÌSµøx»pv‘›,)M¾ø¸Yü²|ûþÏ?_­´K—ÿ¡Êk:{·º›«•J—Ûµhõ9ÕNkî&nbsp;ÓÐ÷õp¿m{¾øñpU,·W«œþ¬á¯6:M—?w7òÂ�»±ï†:ï©íCÝÞÝÓiÕnèä»ûCÝÝþ~Ë}Ö÷]ÓÔÛCõëÇ?½Jy¤0LS.”JJç4Ž3]¬4“©ñÛ ÆGyË_F!ù;·õC·Û÷ Iè™/ñ[¨ÉtQ&amp;e¦3ü‚JR
ŸI
•š•.IK³ø¸ƒïýÔÂÃe±ìhŒøæ²\µn¶»®í‡C5l©aðbA�ŽÙ(VôÌ±ç¾Ý-?]å&nbsp;ê›+
Sp¥Ô²ï·»›æ	]¤IYD’&amp;Q¦ É:”Ìéå®^®Ê%¼½X®»vðMƒjõ÷i"ñ´í¼œN�œÕ@m$14ÝÂCjˆ¦—÷4±Í¶§¨¿ÂžHf’Ì¨E–«D¬·G°%xÊæË=¾¤»;T»½Ùz5y-Àí
¾õ¡^û�À­Çz¸§;H¨UãûáXn¯Ú»#XôSË;&lt;Ù~31$�ŒäËòÄ•å"s.)Ó’äSÉ´/'Œ'/›ÓþÁÞ6£Ý~·mQ�¶\®Ÿ&nbsp;iÝp§º§VßlF¹åÝiºöîšn÷MWm‚yVÔÚ+õ2•£LÊÁ¬�uaI&amp;z{_“%(2(?¹&lt;¥£êy®«/2—¡O_íøìsêRU{áBqÏZ:´�KÍÔd”—Ó‹´«†A�æÞO�÷»ªiètM®ïa·W%³¹€ž&nbsp;ø�/üY§_V`àÍöæxwtèõŽ“Ôµü‘Öû±ÇN~íëÔÄk°%\Mé3ûCÝç0Bç‰)séÖ°äqöûÙ�M”ÕSáÍ¬NZÎÔ˜IZL¬
ŒÜ/îwÎ‹»&nbsp;ÅM·×•_dÙr}¨z^6Í¶zà…–ã”Ñ}hågêrun&amp;]™¼˜0“lX`š„øÝ‘÷AP%šÐ©¹¥„&lt;­&lt;ão¶wÉ=2°èÌ,\“žÑ·¸á©Ô’I§&amp;4MP	n‘à»%ºØÕC}ça™:zS€[d
ôzo&amp;p�¾cýX¼f&amp;Áe �#áîë»ûåæå&nbsp;Í#Tuç…Ëê¡ª›êÆc\’›š&lt;º
ºÉ£�;p~VÖWç‹–	ØPÍ@ŽÿtRQ�Û#­I½ì»æˆÓ}Í÷{ê0Dóì_
Šf-,}F£6ZîË¶l„Rb-&nbsp;Ž]?Çmãñ–R¢sK+H�® =³^]&amp;¹ŽÖ�1Ð:à^öÇýÖ!wÁT
»Ûý•ï3Ô¨ÿ´·<cÛÁãe™ £ò$ÏØbžÇ”âel1e¢Óüy<<£�Ô%…Š%="" —‡cË€~*="" yÁÐ="" kwâ.à´¢Ž�·="" yŽý¾zËËÚs˜bk“ŽaÍdÑ="" 9ŽÛÈ„n�í­´j`qoê«‰<µ‚õþ5þÄ¼¨?[¨„—Ýk~vnéck¤4¸ò‹="" Ž}}×ÖŸsc�Ÿ†æ‰‰Ì0+À="" b-�usà120Ëäçw&e �Á†9ùn"@ã55Éª¾íxuØøx��’iÇà,28;Ä9Ær]Ýj&"t]ãx”kh@­ÑÙtuj�¢&v‰Ïy“Í’Ô0àˆ³¿èjfái“™:krxŽ*¢ôžùÖŒsûÊ£Ùß„1×­·gâoßo½="" ý£µ}º*ÔÈáuàð¾Ïc="ó·��V`“².ŽU#Ë�–†wJÈ)+ö¿Ø‘“ÕAz…Û‘ò¦÷|" 4%ó©xÇvËnfºÐp‡‡‰†}ˆq5r��õ†:x®wÆd“�ôx\æœž="" |Ý41rtý0‹@ûê–ehÈf�¼i�~$˜î„0g…xo^wh;~j±wó$1Ä„µÞvëš="" íùÚsÈrÙt�ˆyrÅ†þ}ËlÃzŠ€s|w<h[ùèq:›‹‘å3#;³$="" d$¹Ë$&•!î«§~Žã˜="">Eõ§+W~U4àÎêþG?‘]ôr^× Ã®j×#Hœ$VbìÚ
7&lt;Ãœløa¹^¾þùÍ±õÎ/§(¾{¨ŸK/(3.}]ê$Ï]F60²nIÊY3û†[GpzÌ.ˆû;2¶+‚/eƒ ¾�_kx&lt;è°ˆÑž´9Í4hdãŠÿ¦']íÉ(àajüªóŽxÓSÓ)°§Ï$*BþwÇÃ	ùFãR
¼È$ì
CÈ]˜9D9dú¼Ë†®qÞÒhÞ&nbsp;ÿÍ±n¼�pWzFy¸‰NÓ[ÿÞÎ¹¸¤öÀ+ôzžxíGOß1¹%ÌÁÓìÎè\–=PJ`O[ê�kô€¸…a¶ý©­¿GŒ=#RqItâf§¦¹2E:xä�n¸G)2»|}ëùÞÂäÐ5�²íùõÄËžèr³í×‡:Ä\þÕG~�O­DÊ€Q(¦Ñc²(7&amp;/Øî}~ÌÚ‹
£N”·‚³ªÞQzÎ�«öÑ¶¢Ì4üæc_ÝÔ]fNXkÏ²Òª~âº†êp'!Ë¾©„�&nbsp;�s`Ï…ewFhÀÜ¦NÒR&lt;Š
ˆlûŒ^H^†i½P`û€ËÚôÖæRX#iI÷8ç7&lt;Á±¢ÃáÊgXa�m™Ë‚ÙÒèÉí÷ñª;›°ƒ·7{j½*%H”iùtžÖµgÐÍˆu€#è@Óá©ô–úx£½¡Æ_ÈO$ðr?ñ‰r‹/‹éõ�©B
³¡ÍTw1PÐ:XÒÓî¿&amp;ôåŸŽv•§Ä Ø]W5ý¹ág [¡prC+ÂËš¾Ê˜R`2™ÁƒÈ5õú%–&gt;ÞYw;Òzn¤:xåçÕ¿}ÛoÛÕ9Él‘(Y!ƒ¤„ß|ƒhV¿Û=�+ó©…„:q 
ø�Á‘]›á‰îÔüfZ¶¹á©¡R3Í6+“%JB’GY¼Cw†1Ç©Ç~’«bzE“’¤dÁ_~º¯›ÓlW½«$·+P�‹&amp;¡%VöW?ˆú,çþ�^¡‡R&gt;¼„Fb9#Z!ó¨¤äÄ‹å±­oŸB’/Z0p�Ös¸ÓL½Vž—‚…f„¸�Ý´ö{ôÕ4‰ËÊ,„u­ìˆÊ8Kã±’�tQfÎ£qX½ãüŠŠß.q\DI£EŸÁíCðÅ€¬B¸¡ÇpC‡¬¸h‰òczù¶%®È_ÿ¼žFúýXóZX�!LE‘˜Œ5:j)_ÞW&lt;©»j#¼�gÍ¹¦BÎÉU<aÊfÙ:_!!Úm˜ñšß^µoÌÞ«'&zíi ŒuÂ,±Êl’0fù§ê¡ú�="">|ïmÞÂ@û&gt;IËe
LvG
ž,×›Ìø&lt;Ã¬æUb�ËCô˜J opó~•{JŸÅO±Œ9ÊW*Yÿ|Nê¾M¬ÐRñüÃ	ó=º‰!<oúŽÎfþ e1;@Ñ\‘="" ²ÓòzrÔú÷\l0fÃÀu±È="" �1Í�s'zÔ�"‘”Œ\éhÝÁÅ®úÂ©—Šfƒ†–;‰”="" bõ="" ³�‡áÄÈ="" e¹m”dwÙ="" íÔ„�="" �="SòsÏh‡i\ºqò…|BVÜ@1—,,S¬B©¡wQÑÛrºŽã\G”©€æÇûÚ‡6p:ÊQÊ‚„·Ô9ÖD‡°ç&amp;ÀBy¢=—&amp;:címh‰„T¥›j`ýSàÑ8%í†Â*jØxím§é|3¨Û'Îá·O¡ö­ã" ÎÜef–r?f`chwù×g¤;ÇùŒh@ÙòÃ–'zsm}âzl—qú×�b,cè%a�xÇ”Éo®Ö£ÐzebÃ�Ñ{ºkŽ="" îŒ£€‹1ñ#þ="" ‘hÁgrgªõl4sÞqh™="" móuy)›˜’õ;Î*òœqváŠf5”…ë£¦ëz”’¤&Ï°¸´^ƒmq›p,Àîí¡y’¼®š‹”êÄzÖâ="‰ôÈ?M”L" @À8b‘="" q�|&h™Ía†æ|n–‡Ïª,+m7—«§ït'þ="" ðí2wÓî¿Ò—Ñ2uyøì="" ^3<´«¾ó…gl{cû¶a�="" —y¯ù¹‘Œa="" ‰þutíÊ£vn{é¥a£="" j@ûÆã³ù�Æk<="" ’"="À'šêI�ßÓò}Rüâïèà)½?¡~5XÞ%sv\¶¤ý" ÄØ%%&oþ§§sïu¸="" ªƒ±n="" Å¹~Þ7äšk#©¯5ÎÄÐŸh¬Ûh}³¡¥€¤b¯ÛcÃ(ûq(]lnx#ðÕ="" f+.lá‘®·="" vËŸù{wsq.8v›‰¿ÄÍsè}Ùzr\#‹gÚŽé›cuð9`óïlmi�tµÛ7rÃÁÆ»í0„÷Ðz‡“z�†‚7*'^²²nšºýÂÞ9[þùû7äx·�8ü5í“b‡±£$%Ñ°brñÙ]="" y(Ÿz‘-1Üv3b*[r¤fŽ“@!Ü¤‚;&‘Ù‚ò‹Õð0õfÉ9"a³ÏÈv€Ó.d4à”Ž)]ôÅŒ¿˜‡1—òtcrÚjt+së’bžãó@twÉknÜbcs�Ñf6—0—­y{l="ÄÄ)" ¶£wpvÔ‹�öþ8¬€="" ì�Ìü÷5ïû“¸ž»ç´kÉŠú­˜0¿©:ëv,‚1²)‹Š?kÜ7wqçÔ"k?we‡ ?waxíÿ¼ÿé="" çŽ±i‘•Ò19™d&àÖzˆŒ\œ+c½ÊÓ©7•rÜj‰6(j-yçh|w‚-p6¿ø‰ŽÓé‰ñpÍ="" œb£%xx¾±£3[Âqç­ps¤="1…&amp;Ä)´D" ]}ûdg?¶ð:¢="]^N'¯—…ÓàˆSŽÄÃHít¤6Ô-à´»(" vŠ–v–9œ¼l¸ã-ý’ó¶¾í–sòñþ˜="" rz$n6É@0û53ˆ¡ë¡†m+5^jde"ºìª§©qw="" Šq\~™óèÁvgwð¾ÄÉ="">™¯Ì
#ÉŽebŽµ¾¯¦ÇƒÔ�c9*žQ›çÀŸÀ�êiZª1¿´EÕßY…Ú”ÿå(}R?ôm¬ÛR½°Œ*[h$‘È{M¦Š[U&nbsp;áÓ�4€œ÷ÜÂ‘“Ü×tUs×˜xKx‡{]Æ2r^Æ;ÂÒ“y”Ñ¡4+Ç[þ&lt;ÁßÔ'ÆQÆ…r&gt;Ç¬ü’€á¶;/SØR	
üžÆ?§¥É€\Šå3i.YáÌ½óž¿d¸u!s‰xÒPôéÆÌ'åj0�EÅœ1õI1r×&lt;Ä%éÚ;s[„Š%Øâ&gt;�ä’ñ|*¥ÖÚí˜#açúÓ%xUIy‡Ù
[—Ç�ø®]÷’ŽÛP;&lt;À™ÚÐÄ×T)Á¸˜wBó€#££ýÑç¦7‡°Ià]%ï•Bm\
•¸ÐoŠ$Uåv¦S¯xg‚ËýìB«„¸TCÀ'Ê1ñ�©´¦÷k‚é	UðŸ3”Ž2XƒB’ƒ×¾©Èåä¿¾yns�Å°¸öä;?¾ÿéÝ0‡Û†0u<yîúÙ 9•äz6¢ïzécy–d@;~Ã‡°t”oxýæo¾{ékàrÊ<ŸÉ«mî™o:pß…™="úþÓÛ‹‹ER'™<†T&quot;”£Oí!“O~¯&nbsp;(ü©à$+.ßÓî‚°«=*Þ¨Ø^ât,WJ¦;Üåæê&quot;w€">‰Óœ�¶Sù-‚›m�j’x	T#1ãV$ƒûÞŠ±

³dË¥åwY!¤xÌ×52g¦_îÌ‡A½tŸ¿pD¶ŒwñezD¢8{¶�¥ÏLJ
{{=Ùd6&lt;†µ³ªo¥™mÌ÷ƒ2!�¼aÙm×Ê&amp;™cÍ|¼Â½¡Ômû¬®£
éìU'Ç|î¶~	}ÿ8çöaŽýNîñ¾N5&nbsp;³TX¼æ�´ë‘ê=pàâœ= Iö¬Vq&nbsp;Gü5D»mú¯J|Ñ2Í�cñ †-¬‘þ¤x²}GÍ^u)3gÑ™É`ï-•…u¨ò&nbsp;•ëpç’~T™&amp;¹ÍÏ3%#›ø
úƒ´qZÃà&gt;5IšÚ%M§^uF�ÿö6¡ªiÒy˜éÑ²¤]©¼Hò’ÉïçT§Œ�ûŸb§ÑHeÔô¡?ìËôJ»%fQÒå·¸
fi_J„Bì™–úDÜ’ûL^”¢í¬ÈN$ÒvùŸW+pê^®ÿ}I–ÜÁÔ«ß+K�¿´šÉ‚Êð9Æ,•¬™ÿø‚06u‰*ÝïÆblSÌæ#©fÉ,ÿË‡I/Šbèåw‹âˆ2}	î´ñ•àT–
È-…þ­nÜ’¨ð–éùYçg¿çün”UÔ³À´3Œú…Q–*¹lˆ”þŠabÒ3·§Ãô4?w~˜ùo&amp;Ä¼ç¾‡8;fñâ0nŽMí™q^pÀ
è\!©,;Ü/—:þ‰Ij£-{ÐjèÜ…ïAÁLTáâ†„Ø{_ù=†äÛž��ñGf…T¥£M6ð¬&amp;f`4(6xÿŒ'HêöÈÍc?Ú«¨uä±¹¶û=ý�@SÐn´¾šx©¬3’ÌÅ_”ìŠ
ó¨E?ŽkÙTÒ¦&nbsp;ç–xý¦zò~ã×ï›+ýÜJŽ	3n%UÓwð4‘X›ãnßÏ3}ÞÙ\®Á*’ŽŠ�N"t \ä‹&nbsp;E~‡UàÅæÈü´ŒÕ@
¡šNŒíšâ–~s+È³þr}Q UúÝ–Q6½ðÛñV~k,oG#Ò…?FéhWM4Ìâ¾xKÝËW$…�Jðÿ�py¢€˜|%ÂMÂ%&nbsp;ÒZM$ˆÃqâFÈ—ÑMû¿ãxC‚�-¼ÅÆ¬®&lt;£ß×)´yô£RX\òÓ˜qAø
N;¡z8U ;¥zù�pøáò
UV¾L6…””ï¦·qåä}5ÿÜ8¦©ß|õ�WóDî–�˜w½{õË¯éb÷pL˜xô=wN§ÃÇšÅ‡W•ÿš�.ðAŒ¤ný»
\ò21)ëW�šÿ½‚Á"ÆJ'EÉ?}yÝ&gt;�?\n·aO¡ì|Œ~Q"¿ÜÙ7ôû8üm2.ìÃq/%�®ý†ÿMÁöPK÷æ(ÿ€áS½ú¡–Ô„Û£`Hî�Í¤¶ñYk‹N6å3,3û³s»¯"õþÄÓzò
endstream
endobj
169 0 obj
&lt;&lt;
/Length 6133      
/Filter /FlateDecode
&gt;&gt;
stream
xÚí<k“ÛÆ‘ßõ+x®t[%n0 <â»¤œÈj”Ä'�¥Š?ä®\x.µd‰×¨Íú×§_3x,¸+Ù+­ë*æÙèééÐ�..éâooþðæÉožkç¹*ót="" Þ¼]x«2�="" r›©Òæ‹7‹$ß�im’¯¾}v¬›ýoÏ–¦„;øóiòìl©Óä¦©võŠk¾;+Òd}~frèÃÚv½;ßÞpãßëcw¬¶|ómµÚÔÍšoÞî\xu8+’ýå¡ÚíêærzÖ+ª="[æÉjßtt³Ý®íÙ2Ë­O¾yõ·o¹ë¯uù”K/WÝþœÀ[ËÔFÿoj¼1ÒÁ¤±ïWÝfÝ´ró'œ~�kÑeµ">û¿7y’
Îaé¢Tef2DXªÊRCKºÐï¹NUŠˆÛâêg4I·çÿvM6Ù¿åŠ+Z¥¹�'5É9­]½£†}Ýt­â†2¢:Ñ�ç­[nÞÔÝS.áÞYØ»%&gt;[”=°YY¨´0,í®€UÛuXù9ïŒI¶õû³2YóÍŠ6ãBîŽÇEÕ­hÈ“÷ãvÏy�–UÕd4òL
±hT‘pE¦´LÂÆ¥Øé7Ï�)Ø·JÛF�1:�ü&amp;uÉ—PöÉïàj’ôLûÄòðñæ™vÏ„ñ°ˆ&gt;se"tpjM­Uš¹á¢)-ªa
Zî�@•iâd¬¢P&amp;Ç'�K§k©á�ïçàrÊÙbÐ‹@#¨h7ÈSÐ™Tùü§BW(—›x_Î�g•Õ'ÀÛ­Û¶º\3Œ×u·áêéášk�L*®­ZÞx•¦ù€*sHª¼ªn¶ûêiÑåÉ›ÍšWÌ²ä}�4˜%HJ®sC�ëz»å’0¾Â&amp;Rå;:˜0ŒNS{ÕŸù®fâ½‘QWËi6€43Êh!Q¤~ž­ÛHaÝtµ0|ðÓ¬ú¶�ŒÇ­õ)CÔU‡Ž›•PêQYÄS#ôÓ¡èSe2Aåt¶V#Á?&lt;Îô¸xÓ`¾G5èûöØJö
Þ"Á¹AabæÓÕVqwÚ4ž¶dtÒB[(8%Aì‚tÜT€¾UË·Â6ÒÁn’Ô82I“ZÚ««ÈTÿÉŒ[yÏ+*íïãû¿&gt;YüƒEÀˆË0J(ß–xâKï
±ûÅÒ&nbsp;´ÂwMšŽE¤-Þ›ãv-�ðõ?;2€ÅvîL¡±/V¡8ö¥W°:¡†)Ÿz¡OÈW�DÔ\TH;�µna7€\ZnïÂ,H2Ö65o*6‘´:¶Ý~7CK¾°ÊYÏàì†gSd.’NÖŸßð?­Œ…Ãvu·&gt;ƒMDúH]ò¢á–k$ùs¦»nIrÈí:¦í²\+WÌf\†€åÀ°
ÄåšæÉT�×Ûº»	|ƒZ–ü¥z_½^ê«N¸ÏŸ×ñ0gíš|©¼	hªÞa÷L3ß1Àx	ÏYØ
(´ÕNšvÌ{6US·;éµçÿ	z±ªZ­€×òÈÐ
'�0ïrÎ†Iãº
Ï�GHŽv(¨©21¤�^´SØ™/‡'e@ÏpP&lt;¨rN”–“ò¬¾¬»pÈ_4WÇnùòØÁßÜ¡m4h¦þÒLeNÆW¼1HË‡¶ã›žøÙå?YOj™(òÀ¡óÛ¦zU7Ò�Ð0ì&gt;AÃrfÿ]éT!Á7ÄS�ônÊ,ùô^,y\‰´4ñBPqßÔ¼©Z°;n»új+£p/#Lp…Q&nbsp;ÑL£Í†çe�¢ Ä� ]“÷µˆžº�b�°„ªzDV½cÔ€ótc¡*Ä�²íxˆ§%�+€–§*/º6•(²Bx6ìæz¬7ÇfÆ`Ô|m¯b¯ö‡¨Ç¯:`�1lzÙ¬Ö“eâ<q½É1r¾p…ÉÂ9j'Ân�[�è�¬ýŸ]edhþ°^mŸp}€k.uÄapã3§Å.œË@k<¾²ð¾ÃkœÍô¯‚­ƒÔÝ7�`pm·¡)Ž—žaÖy­³'Â:ujáˆ]ek€ tó”o="" ¥±úê¸­õ�qµƒ”$øÿ�x‘³e`¤p¸¨ß×-Ë3¸›.ÓÎrŸ1€="†¬" æˆœÿ�9u�·Ý¡"ô’õºº="" Ä8Ä†="" &zgc+äõÕ«bm½Ùj…º9d¡u‘="" ²†Ò¬="">XNh+˜/9Ù8¨‰ä„ö”Û„¢F#ë�f&gt;ýžLf«¸ÕÐ3
³1ÇFóÀ&nbsp;¨O¶e©Ìï«í‘Ø‘cxñ#°¨âQ(ü£Þ”ô&amp;¨ºæEÑR"é•Œ\hi*VÐùŽ0Ý[¸E�N[ä*-ƒ4}¼
�fô
ª
Â°åÛZzV#Þ€’E3qA1ƒ]©/›ªcN×Fv5a#6÷J»Àí&amp;"¸k²±}F¹|ñRŽöPØá‰§å;k¶:•;Æ0ŠÂ²Xþ=jVI�XLþgH¾€²›�'ƒq`)ê¡˜£òìf“ëyãÜë<tÂ¥4-uàr@^Æx`ˆÚ%ÿ‰è¼i0�Í`i3ký–Êº˜¬öÇ¹é�Žt1`ÓÙù xl="œ®<=]™Å‡ýxXX™ƒt" Ü¥¶="" 7p="" ƒg[Úxm—i†Š~�ös‚†;93tò%œmÐ”pÿÉjjvÉÄ®Çt—¿]ÊˆÛ,ìk¸mêõŒ¶îÔ¦y[Þ·kÚªÞ‹óÿwÓà¨¦É¯i="" �»Ñ#ÇÔ2w(°·="">dÇ²ù6÷´À¬õ½{áÐl?p3Ê,ë±7·±l=?ÙmM¿«4V{¢HÖô6»H›¯D²ÂýT€&nbsp;h‹d±Ô6õJLºómÝ¼ÃP¤Üß¾~&amp;VaÔ†ò#J»!iÜà[bÓº4d|\ö
î‡øp¸¾ío&nbsp;zVpâásÐ‚RßKERF°ªj¹KÅC©€ÍŒ�`\m¦Ô*Þ—¡ÿ«Æ%‚µ$µæ¸øÓÑpó¨÷á›ÿ+ÐßHÖ²5‘G¨Å˜èA#Üä%™yìê£.uŒ4,÷vGÐ¨GsÑo
X9èÁúÁâÔ�ÿ"ÜL¹©Ò£€VµÊ€ÊGpýŠèˆŽ¥Ñ¸±ù˜,««¨óžžðÀ€~0ËL–ƒÉ(»=�u]�eOÎD‚µuÍª=’ðx#ºÞÐö·+6˜ËÝÄx‚&lt;â
�'˜�ÁŽA×|&lt;ú¿z¿¯/–¿ÃëÜóú\™ÈÝYËve°Ø
;Cªï^·Ð
6$®[7Ýòwt9µvJOTT&lt;nðÔÀðòB�ÿ‡}pþô?BkÖ£õéH¥Î†^ˆ,Ù72øÄ©Ê‚±]jÓ�ÁÜÎØÀvUau0SPLÁŒ»+tYañ
ŽÚn�&gt;-ºÝÖ–ÙX&nbsp;‡ÝO7Üš„õÖã¶ë'éñeÆŽI£K06ýÐ3‰Vþh+ó€‚Bž‹‹‘Z`K3—}ðsGç‹à{V¾ÄSŠlÚ�+d„/'rÆÄQ Çá,ŽFYsJ&lt;ÅayA¦öh¢z†›¥¹*ÍÐiº¹@mäcUÜ¾eäS§×ÇsÆëG°^Ø�ñ”{E\ByhBX2øM”ëÝr2Ðááø)+5©A'éžKLàP@±Rˆý£“§w±M�
…</tâ¥4-uàr@^æx`ˆú%ÿ‰è¼i0�í`i3ký–êº˜¬öç¹é�žt1`óùù></q½é1r¾p…éâ9j'ân�[�è�¬ýÿ]edhþ°^mÿp}€k.uäapã3§å.œë@k<¾²ð¾ãkœíô¯‚­ƒôý7�`pm·¡)ž—žaöy­³'â:ujáˆ]ek€></k“ûæ‘ßõ+x®t[%n0></yîúù></oúžîfþ></aêfù:_!!úm˜ñšß^µoìþ«'&zíi></cûáãe™></hf«f=ýóz9{(:ÿ‹â¸^˜sá•±b2\lü}÷ñåÿ�…for></b¦x´dæfœª></j³û¥ ></p´sðþéhi"ø2ÿ1¯àû­�m£,øué-–ð�æúï¤ì¾ø“çn6ûº8}êxðœðìöbîbg4îì}¥ažæ“™@v9ñ#üž†f></sk_�óweˆ.©ädºjrèx.zµñ…ð®ýäo‡s¼·¯¶îñpq7�ømiôâb&2˜™nx$`o­´`‡ah¾f™°à»?šúxà7ê�t6‡a[rçýs¿o›[î¼></fß¥ÿî*û‰ûúp£v’…{-uxbdá1üë2¼6òþô—þ¢ÿ*÷z}‰‡9+îb%óœìõ°×—gº×õeì)·ÿ{–q�ûno¿�c„•}ìgü‰=uñ?*ëa></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://science.beardhatcode.be/papers/2019-WARDuino-MPLR.pdf">https://science.beardhatcode.be/papers/2019-WARDuino-MPLR.pdf</a></em></p>]]>
            </description>
            <link>https://science.beardhatcode.be/papers/2019-WARDuino-MPLR.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811950</guid>
            <pubDate>Sun, 12 Jul 2020 15:11:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla Starts Petition to Oppose the Earn IT Act]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23811935">thread link</a>) | @Fjolsvith
<br/>
July 12, 2020 | https://darkrebel.net/mozilla-starts-petition-to-oppose-the-earn-it-act | <a href="https://web.archive.org/web/*/https://darkrebel.net/mozilla-starts-petition-to-oppose-the-earn-it-act">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                            <h2>
                                In March of this year, the U.S. Senate introduced a bill called the Eliminating Abusive and Rampant Neglect of Internet Technologies Act (EARN IT Act)...                            </h2>
                        </p><div>
                        <p><span>In March of this year, the U.S. Senate introduced a bill called the Eliminating Abusive and Rampant Neglect of Interactive Technologies Act (<a href="https://www.congress.gov/bill/116th-congress/senate-bill/3398/text">EARN IT Act</a>), which, like similar bills in the past, gives law enforcement agencies and other members of government near unlimited access to citizens' personal data.</span></p>
<p><span>Those who understand encryption realize that it is responsible for protecting things like financial and health data, but this seems to slip through the cracks when the anti-encryption discussion comes up in congressional debates. As a result, the Mozilla Foundation has started a petition for ordinary citizens to dispute the EARN IT Act, which can be signed at <a href="https://foundation.mozilla.org/en/campaigns/oppose-earn-it-act/">Mozilla Foundation - Oppose the EARN IT Act</a>.</span></p>

<p><img src="https://darkrebel.net/uploads/images/2020/07/image_750x_5eff1b2722e6d.jpg" alt=""></p>
<p><span>This petition is part of a larger campaign for, as Mozilla calls it, a "healthy internet." Other issues that Mozilla encompasses in this campaign are privacy on video calling apps (like Zoom), misinformation regarding the COVID-19 pandemic, and data collection by a number of IoT devices (watches, phones, gaming consoles, etc.).</span></p>
                    </div></div>]]>
            </description>
            <link>https://darkrebel.net/mozilla-starts-petition-to-oppose-the-earn-it-act</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811935</guid>
            <pubDate>Sun, 12 Jul 2020 15:09:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Versatile Microservices in Golang]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811827">thread link</a>) | @kiyanwang
<br/>
July 12, 2020 | https://ewanvalentine.io/microservices-in-golang-part-1/ | <a href="https://web.archive.org/web/*/https://ewanvalentine.io/microservices-in-golang-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>UPDATED: 11th April 2019<br>
UPDATED: 12th January 2020<br>
UPDATED: 6th June 2020</p>
<p><a href="https://blog.dingkewz.com/post/tech/go_ewan_microservices_in_golang_part_1/">用中文阅读</a></p>
<p>Sponsor me on <a href="https://www.patreon.com/ewanvalentine">Patreon</a> to support more content like this.</p>

<p>This is a ten part series on writing microservices in Golang. Making use of protobuf and gRPC as the underlying transport protocol. Why? Because it took me a long time to figure this out and settle on a solution that was clear and concise, and I wanted to share what I'd learnt about creating, testing and deploying microservices end-to-end with others new to the scene.</p>
<p>In this tutorial, we will just be covering some of the basic concepts, terminology, and creating our first microservice in its crudest form.</p>
<p>We will be creating the following services throughout the series:</p>
<ul>
<li>consignments</li>
<li>users</li>
<li>authentication</li>
<li>vessels</li>
</ul>
<p>The stack we will end up with will be: golang, mongodb, grpc, docker, Google Cloud, Kubernetes, NATS, CircleCI, Terraform and go-micro.</p>
<p>You can find the repositories so far here:</p>
<ol>
<li><a href="https://github.com/EwanValentine/shippy-service-consignment">Consignment Service</a></li>
<li><a href="https://github.com/EwanValentine/shippy-ci-consignment">Consignment CLI</a></li>
</ol>
<h2 id="prerequisites">Prerequisites</h2>
<ul>
<li>This tutorial assumes you're using go 1.13 and upwards and have <code>export GO111MODULE=on</code> set.</li>
<li>Install the protoc compiler - <a href="https://grpc.io/docs/protoc-installation/">see here</a></li>
<li>A fair understanding of Golang and its ecosystem.</li>
<li>Install gRPC / protobuf - <a href="https://grpc.io/docs/languages/go/">see here</a></li>
<li>Install Golang - <a href="https://golang.org/doc/install">see here</a></li>
<li>Install the following go libraries:</li>
</ul>
<pre><code>go get -u google.golang.org/grpc
go get github.com/golang/protobuf/<a href="https://ewanvalentine.io/cdn-cgi/l/email-protection" data-cfemail="4d3d3f2239222e602a2823602a220d3b7c637e">[email&nbsp;protected]</a>
</code></pre>

<h2 id="whatarewebuilding">What are we building?</h2>
<p>We will be building perhaps the most generic microservice example you can think of, a shipping container management platform! A blog felt too simple a use-case for microservices, I wanted something that could really show-off the separation of complexity. So this felt like a good challenge!</p>
<p>So let's start with the basics:</p>
<h2 id="whatisamicroservice">What is a Microservice?</h2>
<p>In a traditional monolith application, all of an organisations features are written into one single application. Sometime's they're grouped by their type, such as controllers, entities, factories etc. Other times, perhaps in larger application, features are separated by concern or by feature. So you may have an auth package, a friends package, and an articles package. Which may contain their own set of factories, services, repositories, models etc. But ultimately they are grouped together within a single codebase.</p>
<p>A microservice is the concept of taking that second approach slightly further, and separating those concerns into their own, independent runnable codebase.</p>

<h2 id="whymicroservicess">Why microservicess?</h2>
<p>Complexity - Splitting features into microservices allows you to split code into smaller chunks. It harks back to the old unix adage of 'doing one thing well'. There's a tendency with monoliths to allow domains to become tightly coupled with one another, and concerns to become blurred. This leads to riskier, more complex updates, potentially more bugs and more difficult integrations.</p>
<p>Scale - In a monolith, certain areas of code may be used more frequently than others. With a monolith, you can only scale the entire codebase. So if your auth service is hit constantly, you need to scale the entire codebase to cope with the load for just your auth service.</p>
<p>With microservices, that separation allows you to scale individual services individually. Meaning more efficient horizontal scaling. Which works very nicely with cloud computing with multiple cores and regions etc.</p>
<p><strong>Nginx wrote a fantastic series on the various concepts of microservices, <a href="https://www.nginx.com/blog/introduction-to-microservices/">please give this a read</a>.</strong></p>

<h2 id="whygolang">Why Golang?</h2>
<p>Microservices are supported by just about all languages, after all, microservices are a concept rather than a specific framework or tool. That being said, some languages are better suited and, or have better support for microservices than others. One language with great support is Golang.</p>
<p>Golang is very light-weight, very fast, and has a fantastic support for concurrency, which is a powerful capability when running across several machines and cores.</p>
<p>Go also contains a very powerful standard library for writing web services.</p>
<p>Finally, there is a fantastic microservice framework available for Go called go-micro. Which we will be using in this series.</p>

<h2 id="introducingprotobufgrpc">Introducing protobuf/gRPC</h2>
<p>Because microservices are split out into separate codebases, one important issue with microservices, is communication. In a monolith communication is not an issue, as you call code directly from elsewhere in your codebase. However, microservices don't have that ability, as they live in separate places. So you need a way in which these independent services can talk to one another with as little latency as possible.</p>
<p>Here, you could use traditional REST, such as JSON or XML over http. However, the problem with this approach is that service A has to encode its data into JSON/XML, send a large string over the wire, to service B, which then has to decode this message from JSON, back into code. This has potential overhead problems at scale. Whilst you're forced to adopt this form of communication for web browsers, services can just about talk to each other in any format they wish.</p>
<p>In comes <a href="https://grpc.io/">gRPC</a>. <a href="https://grpc.io/">gRPC</a> is a light-weight binary based RPC communication protocol brought out by Google. That's a lot of words, so let's dissect that a little. gRPC uses binary as its core data format. In our RESTful example, using JSON, you would be sending a string over http. Strings contain bulky metadata about its encoding format; about its length, its content format and various other bits and pieces. This is so that a server can inform a traditionally browser based client what to expect. We don't really need all of this when communicating between two services. So we can use cold hard binary, which is much more light-weight. gRPC uses the new HTTP 2.0 spec, which allows for the use of binary data. It even allows for bi-directional streaming, which is pretty cool! HTTP 2 is pretty fundamental to how gRPC works. For more on HTTP 2, <a href="https://developers.google.com/web/fundamentals/performance/http2/">take a look at this fantastic post from Google</a>.</p>
<p>But how can we do anything with binary data? Well, gRPC has an interchange DSL called protobuf. Protobuf allows you to define an interface to your service using a developer friendly format.</p>
<p>So let's start by creating our first service definition:</p>
<ol>
<li>Create a new root directory, I've called mine <code>shippy</code>. CD into your new root directory and create the following folder and file: <code>shippy-service-consignment/proto/consignment/consignment.proto</code> from the root directory of our repo.</li>
</ol>
<pre><code>$ mkdir shippy &amp;&amp; cd shippy
$ mkdir -p shippy-service-consignment/proto/consignment/
$ touch shippy-service-consignment/proto/consignment/consignment.proto
</code></pre>
<p>For the time being, I'm housing all of our services in a single repo. This is known as a mono-repo. This is mostly to keep things simple for this tutorial. There are many arguments for and against using mono-repos, which I won't go into here. You could house all of these services and components in separate repos, there are many good arguments for that approach also.</p>

<p><a href="https://blog.gopheracademy.com/advent-2017/go-grpc-beyond-basics/">Here's a fantastic article on gRPC</a> I highly recommend you give it a read.</p>
<p>In the consignment.proto file you just created, add the following:</p>
<pre><code>// shippy-service-consignment/proto/consignment/consignment.proto
syntax = "proto3";

package consignment; 

service ShippingService {
  rpc CreateConsignment(Consignment) returns (Response) {}
}

message Consignment {
  string id = 1;
  string description = 2;
  int32 weight = 3;
  repeated Container containers = 4;
  string vessel_id = 5;
}

message Container {
  string id = 1;
  string customer_id = 2;
  string origin = 3;
  string user_id = 4;
}

message Response {
  bool created = 1;
  Consignment consignment = 2;
}
</code></pre>

<p>This is a really basic example, but there are a few things going on here. First of all, you define your service, this should contain the methods that you wish to expose to other services. Then you define your message types, these are effectively your data structure. Protobuf is statically typed, and you can define custom types, as we have done with <code>Container</code>. Messages are themselves just custom types.</p>
<p>There are two libraries at work here, messages are handled by protobuf, and the service we defined is handled by a gRPC protobuf plugin, which compiles code to interact with these types, i.e the <code>service</code> part of our proto file.</p>
<p>This protobuf definition is then ran through a CLI to generate the code to interface this binary data and your functionality.</p>
<ol start="2">
<li>Generate the protobuf code, from your project root, run the following:</li>
</ol>
<p><em>Note: if you're seeing "command not found: protoc" at this stage. Ensure the following:</em></p>
<ul>
<li>Double-check you have ran through all the prerequisite steps and installation steps.</li>
<li>You have your GOROOT set, or your go binaries location set in your host path.</li>
</ul>
<pre><code>$ cd shippy-service-consignment
$ protoc -I. --go_out=plugins=grpc:. \
	  proto/consignment/consignment.proto
</code></pre>
<p>This will call the protoc library, which is responsible for compiling your protobuf definition into code. We also specify the use of the grpc plugin, as well as the build context and the output path.</p>
<p>Now when you run this command in your <code>proto/consignment</code> directory, you should see some newly generated code. This is code automatically generated by the gRPC/protobuf libraries to allow you to interface your protobuf definition to your own code.</p>

<ol start="3">
<li>So let's set that up now. Create your main.go file <code>$ touch main.go</code> from the <code>shippy-service-consignment</code> project root.</li>
</ol>
<pre><code>// shippy-service-consignment/main.go
package main

import (
	"context"
	"log"
	"net"
	"sync"

	// Import the generated protobuf code
	pb "github.com/&lt;YourUserName&gt;/shippy-service-consignment/proto/consignment"
	"google.golang.org/grpc"
	"google.golang.org/grpc/reflection"
)

const (
	port = ":50051"
)

type repository interface {
	Create(*pb.Consignment) (*pb.Consignment, error)
}

// Repository - Dummy repository, this simulates the use of a datastore
// of some kind. We'll replace this with a real implementation later on.
type Repository struct {
	mu           sync.RWMutex
	consignments []*pb.Consignment
}

// Create a new consignment
func (repo *Repository) Create(consignment *pb.Consignment) …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ewanvalentine.io/microservices-in-golang-part-1/">https://ewanvalentine.io/microservices-in-golang-part-1/</a></em></p>]]>
            </description>
            <link>https://ewanvalentine.io/microservices-in-golang-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811827</guid>
            <pubDate>Sun, 12 Jul 2020 14:56:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Fix Twitter, and Hopefully American Discourse Too]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811714">thread link</a>) | @jfeiwell
<br/>
July 12, 2020 | https://jfeiwell.com/essays/2020/07/12/fix-twitter.html | <a href="https://web.archive.org/web/*/https://jfeiwell.com/essays/2020/07/12/fix-twitter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://jfeiwell.com/Folders/Essays.html">⇠ Essays</a>


<h3>In order to make Twitter a more productive and engaging forum for public discourse, substantial changes need to be made to the productâ€™s core architecture and user policy</h3>

<p>When I first joined Twitter in 2012, it was a great place to be. A lot of my friends were there, cracking jokes and posting pictures with yfrog while hoping the fail whale didnâ€™t ruin the fun. I recall that the company was pitching Twitter as a â€œpublic agoraâ€�, which made sense but wasnâ€™t an accurate reflection at that time. Really, it was juxtaposed against Facebook as a better social network.</p>

<p>Now that Twitter <em>is</em> the public agora, its functionality defines the rules of engagement for public debate, and those rules allow for chaos and massacre. Twitterâ€™s current functionality gravely endangers the future of the Republic. If they do not take it upon themselves to act now, they will be responsible for the American equivalent of moving the capital from St. Petersburg to Moscow.</p>

<p>I know that sounds a little alarmist, because it is. However, Twitter can take a few steps to reverse their role in warehousing division and hate. As well as the mental health crisis that is outrage. â€œThe medium is the messageâ€� has become trite, but Mcluhanâ€™s point remains - Twitter needs to alter the medium before Americans succumb to the message. Here are a few ideas to do so:</p>

<ul>
	<li>Federate Twitter</li>
	<li>Hide Likes</li>
	<li>Reform the Quote Tweet</li>
	<li>Sentiment Analysis, Higher Quality &amp; Lower Speed</li>
	<li>Tweet Wrapper =&gt; Thread</li>
	<li>Clean Up Usernames</li>
</ul>

<h2 id="federate-twitter">Federate Twitter</h2>
<p>The most audacious ask. People already use terms like â€œbaseball Twitterâ€� or â€œVC Twitterâ€� as if they were clearly federated channels - why not actually do that?</p>

<p>Donâ€™t get me wrong, the aggregation of all my interests into one feed is amazing (and why no one visits news sites anymore), but in practice the intended effect hardly occurs. Usually my feed is plagued with the story of the day as if Iâ€™m turning on cable news.</p>

<p>Yes, itâ€™s possible to tune it out sometimes, but that comes at the expense of missing out on other great content. I donâ€™t want to follow Brian Koppelman or Buster Olney for their political takes, even if I agree with them 100%, I want to learn about storytelling and get updates on baseball.</p>

<p><strong>Deescalating</strong> the politicization of <em>everything</em>, and reducing the speed at which takes come flying through the Twittersphere, will turn down the temperature and volume while providing for deeper engagement.</p>

<p>The way to do this would be to require users to tag the vertical(s) they want to post in before posting. <strong>The follower would then see the tweet only if they follow both the person and the vertical.</strong> Users would be able to follow all of someoneâ€™s tweets if they want, but it would require one extra step - as the default follow functionality would result in only seeing the nexus of that personâ€™s tweets and your follow tags.</p>

<p>Users would still be able to tweet without specific channels tagged. Only followers selecting all tweets or just personal (non-vertical) tweets would see them.</p>

<p>In terms of defining verticals, Twitter can do most of the leg work - defining the official taxonomy with layups like Football &gt; NFL &gt; Cleveland Browns. And with multiple entry points like Tech / Money / Cryptography &gt; Cryptocurrencies &gt; Bitcoin. There are easily thousands that can be defined (Topics is a far cry from what could be). Then figure out how to allow users to define new categories, maybe put the blue check to good use!</p>

<p>The upshot? <strong>This would also be a great business decision.</strong> Twitterâ€™s Q1 2020 CPM was $4.97. If they were to fully embrace contextual advertising, leveraging their first-party data as well, they could own a burgeoning segment of the digital ad market and raise their avg CPM well into double digits. Think about it, has a Twitter ad ever actually made an impact on you? Contextual is the natural response to the death of the cookie, most competition in this space wonâ€™t have the first party data nor the free inventory.</p>

<h2 id="hide-likes">Hide Likes</h2>
<p>Make likes only visible to both the liker and likee. Twitter is optimized for virtue signalling, period. Weâ€™ve all read how tribal Twitter is, well this single feature is the forcing function of that tribalism in every last vertical.</p>

<p>By making likes private, Twitter can still use the signal to optimize the home feed algo. In fact this will provide a much richer signal as the likes become a more honest indication of someoneâ€™s opinions, while preserving the personal satisfaction (dopamine) users get from likes. Iâ€™d wager this would make engagement go <em>up</em>!</p>

<p>What about the ability to scan someone elseâ€™s likes? Maybe this is where a new Quote Tweet comes in. A separate feed created by users that allows them to syndicate tweets without the full endorsement of a Retweet or the aforementioned problems of a like. No footprint on the tweet object itself.</p>

<h2 id="reform-the-quote-tweet">Reform the Quote Tweet</h2>
<p>On April, 6 2015 the Quote Tweet was born. I do not believe it an accident that, at least anecdotally, the culture of outrage and personal attack has grown exponentially on Twitter in the last 5 years. â€œDunkingâ€� on someone seems to be the primary use of the Quote Tweet feature, and so many of the viral outrage tweets are in the form of the Quote Tweet.</p>

<p>Now, users were hacking this together before it happened so itâ€™s obviously a popular feature. It makes sense; syndicating information is the primary purpose of Twitter - whether thatâ€™s from your brain or another source, everyoneâ€™s just a router. But the madness must stop.</p>

<p><b>Solutions</b></p>
<p>Add permissions on any tweet that gets Quote Tweeted:</p>
<ul>
	<li>If a user comes by my tweet via a Quote Tweet, allow me to block them from viewing my  tweet via the Quote Tweet</li>
	<li>Allow me to set max absolute Quote Tweets or max Retweet of a subsequent Quote Tweet</li>
	<li>Allow me to disable Quote Tweets all together</li>
</ul>

<p>OR, drum roll pleaseâ€¦ <em>edit button</em>! It would solve so much. Then add a versionsioning system to allow the original to be preserved.</p>

<p>Federation will actually solve this, but without it, these solutions are necessary.</p>

<h2 id="sentiment-analysis-higher-quality--lower-speed">Sentiment Analysis, Higher Quality &amp; Lower Speed</h2>
<p>One of the questions raised by the federation idea is, what happens to generally public features like Trends? Twitter as a resource for breaking news canâ€™t be disputed at this point; that functionality must be preserved and strengthened. But the current set up just aint it.</p>

<p>Here are two tweets taken from two recent trends, â€˜Susan Collinsâ€™ and â€˜Nancy Pelosiâ€™ respectively.</p>

<blockquote><div lang="en" dir="ltr"><p>F*ck Trump<br>F*ck Barr<br>F*ck Lindsey Graham<br>F*ck Mitch McConnell<br>F*ck Susan Collins<br>F*ck Ted Cruz<br>F*ck John Cornyn<br>F*ck Tom Cotton<br>F*ck Cory Gardner<br>F*ck Chuck Grassley<br>F*ck John Kennedy<br>F*ck Matt Gaetz<br>F*ck Jim Jordan<br>F*ck Kelly Loeffler<br>F*ck Rand Paul</p><p>F*CK THE ENTIRE GOP <a href="https://t.co/PR0KyoE5K8">pic.twitter.com/PR0KyoE5K8</a></p></div>— JosÃ© (@yoruguaenusa) <a href="https://twitter.com/yoruguaenusa/status/1281774758967889921?ref_src=twsrc%5Etfw">July 11, 2020</a></blockquote>


<blockquote><p lang="en" dir="ltr">â�¦<a href="https://twitter.com/JoeBiden?ref_src=twsrc%5Etfw">@JoeBiden</a>â�© â�¦<a href="https://twitter.com/SpeakerPelosi?ref_src=twsrc%5Etfw">@SpeakerPelosi</a>â�© Sums it well <a href="https://t.co/OnsAyce9Mp">https://t.co/OnsAyce9Mp</a></p>— nicole (@nicole47877716) <a href="https://twitter.com/nicole47877716/status/1281977304567222274?ref_src=twsrc%5Etfw">July 11, 2020</a></blockquote>


<p>Both of these were less than 20 tweets into the â€œTopâ€� section that is ostensibly a filter of quality compared to the â€œLatestâ€� option. Twitter has to stop this type of hyperbolic outrage, and nonsensical filler. Those tweets are of no value to anyone (not to mention, inciting violence?).</p>

<p>If those same accounts wanted to make reasoned and informed arguments against those politicians, by all means. Even if the arguments are far outside the Overton window, so long as they are thoughtful they should be surfaced equally.</p>

<p>Sentiment analysis, scoring primarily thoughtfulness, can raise the quality bar. Modern advances in NLP should make this not only possible but possible to do well.</p>

<p>Secondly, sentiment analysis should be used to grade tweets that begin to go viral. Auto-braking tweets at certain Retweet and reply counts could be detrimental when serious breaking news occurs, so that will have to be a consideration. But scoring the sentiment to make sure itâ€™s not vitriolic outrage based in emotion could lower the speed of hate and reduce the collective blood pressure.</p>

<p>As a general rule of thumb, the <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy effect</a> should be the governing principle. If you cap Retweets and replies in absolute numbers or by sentiment, and the content is actually good enough, it will continue to rise to the top over time.</p>

<h2 id="tweet-wrapper--thread">Tweet Wrapper =&gt; Thread</h2>
<p>Threads are awesome, but thereâ€™s a reason services like unroll exist. Reading a thread interrupted by the username, picture, etc. every 280 characters is taxing. Secondly, syndication of a tweet in a thread can lose all context.</p>

<p><b>Solution</b></p>

<p>Convert the thread into a single object segmented by 280 character fields, separated either by nothing or slightly darker/lighter backgrounds. The reader sees breaks every 280 characters like normal, but itâ€™s much cleaner and more importantly - will convey a sense of coherence. The world is an incredibly nuanced place. Discourse in 280 characters is not.</p>

<p>The user can then choose which tweet in the thread serves as a wrapper. And/or when Retweeted, that user can choose which tweet will serve as the wrapper. The wrapper is more or less a headline - when the user clicks on the wrapper tweet, they move to the seamless thread.</p>

<p>This solution has the additional benefit of synchronizing replies onto a single thread object.</p>

<h2 id="clean-up-usernames">Clean Up Usernames</h2>
<p>So much of the nonsensical outrage comes from usernames like â€˜jack09324189â€™. The username from the Pelosi example above is â€˜nicole47877716â€™, and the account is following 5 people with one follower.</p>

<p>Iâ€™m against a strict real name policy - but Twitter can also make a constitutive choice that bifurcates users into real names and pseudonyms. If youâ€™re going to use a real name - great, you must have a real profile. If you want to be anonymous - great, you must set up a truly pseudonymous account. The strangle between the two is what accounts for most of the filler in replies.</p>

<p>Facebook is obviously a bit draconian with their policy, <em>but at least they have one</em>. If Twitter is to be …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jfeiwell.com/essays/2020/07/12/fix-twitter.html">https://jfeiwell.com/essays/2020/07/12/fix-twitter.html</a></em></p>]]>
            </description>
            <link>https://jfeiwell.com/essays/2020/07/12/fix-twitter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811714</guid>
            <pubDate>Sun, 12 Jul 2020 14:44:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Crsh – A JavaScript based command line shell]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811673">thread link</a>) | @_carl_jung
<br/>
July 12, 2020 | https://crwi.uk/2020/07/12/crsh.html | <a href="https://web.archive.org/web/*/https://crwi.uk/2020/07/12/crsh.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      


<h2>Introducing crsh: a Javascript based command line shell</h2>
<p>12 July 2020</p>
<p>TL;DR: <a href="https://github.com/curlywurlycraig/crsh">GitHub link -&gt; Install instructions</a></p>

<hr>

<p>Existing shells generally operate with their own somewhat archaic syntax,
continuous with the underlying operating system and set of historical design choices.</p>

<p>This puts the majority of shell syntax just out of reach for a very large subset of command line users who use the command line for little more than launching one or two command line tools, navigating directories, and maybe ocassionally piping commands or outputting them to files. These users will usually write scripts in a language more familiar to them as soon as things get a little trickier (because the value of learning the control flow syntax in <code>bash</code>, <code>zsh</code>, or <code>fish</code> does not seem like time well spent).</p>

<p>This is not a criticism of those shells, exactly. But it does highlight a potential space for new shells that can better fulfill the needs of these users. Conversely, if you are an experienced bash shell scripter, and terms like “file descriptors” and <code>SIGCHLD</code> mean something to you, you will probably dislike my approach here. But please feel free to stick around and provide some advice.</p>

<h2 id="enter-crsh">Enter crsh</h2>

<p>I’ve started work on a shell that can seamlessly interoperate Javascript syntax (and in fact works by <code>eval</code>ing JS in the Deno runtime) and traditional shell execution.</p>

<p>Regular command execution will be familiar to those who have used the command line:</p>

<div><div><pre><code>$ ls | grep .js
builtins.js
dsh.js
functions.js
</code></pre></div></div>

<p>And inline anonymous functions will be familiar to those who have used Javascript:</p>

<div><div><pre><code><span>$</span> <span>()</span> <span>=&gt;</span> <span>"Hello world!"</span>
<span>Hello</span> <span>world</span><span>!</span>
</code></pre></div></div>

<p>Returning a list from an inline function will be outputted as separate lines:</p>

<div><div><pre><code><span>$</span> <span>()</span> <span>=&gt;</span> <span>new</span> <span>Array</span><span>(</span><span>5</span><span>).</span><span>fill</span><span>().</span><span>map</span><span>((</span><span>line</span><span>,</span> <span>index</span><span>)</span> <span>=&gt;</span> <span>`Line </span><span>${</span><span>index</span><span>}</span><span>`</span><span>)</span>
<span>Line</span> <span>0</span>
<span>Line</span> <span>1</span>
<span>Line</span> <span>2</span>
<span>Line</span> <span>3</span>
<span>Line</span> <span>4</span>
</code></pre></div></div>

<p>Combining these concepts can yield a very expressive shell:</p>

<div><div><pre><code><span>$</span> <span>ls</span> <span>|</span> <span>({</span> <span>lines</span> <span>})</span> <span>=&gt;</span> <span>lines</span><span>.</span><span>map</span><span>((</span><span>line</span><span>,</span> <span>index</span><span>)</span> <span>=&gt;</span> <span>`line </span><span>${</span><span>index</span><span>}</span><span>: </span><span>${</span><span>line</span><span>}</span><span>`</span><span>)</span> <span>|</span> <span>grep</span> <span>line</span> <span>3</span>
<span>line</span> <span>3</span><span>:</span> <span>functions</span><span>.</span><span>js</span>
</code></pre></div></div>

<p>Note in the above that <code>lines</code> is made available to piped inline functions.
JSON output piped into an inline function is automatically parsed and made available as a <code>json</code> parameter:</p>

<div><div><pre><code>$ curl https://ghibliapi.herokuapp.com/films/58611129-2dbc-4a81-a72f-77ddfc1b1b49 | ({ json }) =&gt; json.title
My Neighbor Totoro
</code></pre></div></div>

<p>As can be seen, such a shell lends itself very well to parsing JSON (it is <em>Javascript</em> Object Notation after all).</p>

<p>To go one step further in this example, we can navigate multi-request JSON API calls in a human-readable way:</p>

<div><div><pre><code><span>$</span> <span>curl</span> <span>https</span><span>:</span><span>//ghibliapi.herokuapp.com/films/ | ({ json }) =&gt; json[0].people | xargs curl | ({ json }) =&gt; json[0].name</span>
</code></pre></div></div>

<p>While the above may look less readable than something like <code>jq</code>, those with a Javascript background will appreciate the transferability of knowledge. Even without such a background, the advantage of executing arbitrary logic inline with other shell calls in a modern language should be apparent.</p>

<h2 id="configuration">Configuration</h2>

<p>Currently, the easy parts to configure are the prompt and auto-completion rules. This is done by way of editing the JS source directly. The prompt is specified as a function which returns a string, and exported from a <code>prompt.js</code> file like so:</p>

<div><div><pre><code><span>import</span> <span>{</span> <span>magenta</span><span>,</span> <span>stripColor</span> <span>}</span> <span>from</span> <span>"https://deno.land/std/fmt/colors.ts"</span><span>;</span>

<span>export</span> <span>const</span> <span>prompt</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>currentDir</span> <span>=</span> <span>magenta</span><span>(</span><span>Deno</span><span>.</span><span>cwd</span><span>());</span>
  <span>return</span> <span>`</span><span>${</span><span>currentDir</span><span>}</span><span> › `</span><span>;</span>
<span>};</span>

<span>export</span> <span>const</span> <span>promptLength</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>stripColor</span><span>(</span><span>prompt</span><span>()).</span><span>length</span><span>;</span>
</code></pre></div></div>

<p>And the auto-completion rules are specified as a list of objects representing the regex to match the input on, and the logic to return the list of completion to cycle through:</p>

<div><div><pre><code><span>const</span> <span>gitRules</span> <span>=</span> <span>[</span>
  <span>{</span>
    <span>match</span><span>:</span> <span>/^git add /</span><span>,</span>
    <span>complete</span><span>:</span> <span>completeFile</span><span>,</span>
  <span>},</span>
  <span>{</span>
    <span>match</span><span>:</span> <span>/^git checkout /</span><span>,</span>
    <span>complete</span><span>:</span> <span>completeBranches</span><span>,</span>
  <span>},</span>
  <span>{</span>
    <span>match</span><span>:</span> <span>/^git branch -D /</span><span>,</span>
    <span>complete</span><span>:</span> <span>completeBranches</span><span>,</span>
  <span>},</span>
  <span>{</span>
    <span>match</span><span>:</span> <span>/^git /</span><span>,</span>
    <span>complete</span><span>:</span> <span>completeCommands</span>
<span>];</span>
</code></pre></div></div>

<p>Community-made auto-completion rules and prompts could be hosted in the usual <a href="https://deno.land/x">Deno way</a>.</p>

<h2 id="future-work">Future work</h2>

<p>There is still a lot to do to make this better. Bug fixes, features like multiline support, persisting history, etc. Any feedback is welcome in the form of issues in the GitHub repo.</p>




    </div></div>]]>
            </description>
            <link>https://crwi.uk/2020/07/12/crsh.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811673</guid>
            <pubDate>Sun, 12 Jul 2020 14:40:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Future of Online Identity Is Decentralized]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 184 (<a href="https://news.ycombinator.com/item?id=23811568">thread link</a>) | @Yolta
<br/>
July 12, 2020 | https://yarmo.eu/post/future-online-identity-decentralized | <a href="https://web.archive.org/web/*/https://yarmo.eu/post/future-online-identity-decentralized">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Online identity</h2>
<p><a href="https://en.wikipedia.org/wiki/Online_identity">Online&nbsp;identity</a> refers to the concept of "being" in the digital world. As an internet user, you exist. You create accounts on websites. You write on social media and blogs. You post photos. All this online activity has in common that one and the same person performed these actions; it defines your "online&nbsp;identity".</p>
<p>However, your "online&nbsp;identity" is not <em>per se</em> representative of your "social&nbsp;identity" in the physical world.</p>
<p>You may choose to use your own name or a pseudonym. You may choose to publish personally identifiable information or not. You may choose to remain truthful to your social identity or deceive. In short, you may choose for authenticity or for anonymity.</p>
<h2>Authenticity versus anonymity</h2>
<p>Authenticity and anonymity aren't mutually exclusive and that is the beauty of the internet. In the physical realm, you are (mostly) limited to a single social identity. In the digital space, there are no such restrictions. While you can't embody multiple persons in the offline world, you can have several identities online. In fact, you can even have multiple accounts on the same platform, opting for a different balance between authenticity and anonymity for each one of them.</p>
<p>The anonymity has its downsides, creating psychological artifacts like <a href="https://en.wikipedia.org/wiki/Online_disinhibition_effect">online&nbsp;disinhibition</a> and facilitating <a href="https://en.wikipedia.org/wiki/Cyberbullying">cyberharassment</a>. However, even though we are far from completely overcoming these challenges, the internet that allows us to remain anonymous is still the one we should want and fight for.</p>
<h2>Consolidation of identity and internet corporations</h2>
<p>Removing the possibility for anonymity could solve the problem of online toxicity. Large internet corporations like Google and Facebook allow all to create an account on condition that some personally identifiable information is revealed, usually a phone number.</p>
<p>The benefit is that it deters most from repeatably creating new accounts when older accounts have been flagged or banned due to improper behavior. These companies gain the function of "identity provider": they manage your online identity that can be used to login in different locations of the internet. We all know many websites that offer a "Google login" or "Facebook login".</p>
<p>But there is a problem: handling the entire online identity of a single person is too much responsibility for any corporation or organization, especially if it is in their interest to gain intimate individual knowledge and sell it (Google) or use it to manipulate moods and influence decision making (Facebook).</p>
<p>That phone number that was once used to prevent online toxicity is now the first of many pieces of personally identifiable information that these corporations will seek and use to figure out who you are.</p>
<p>"You have nothing to hide"? Great. The internet corporations will still make money hand over fist by selling your personality, your preferences, your buying patterns and your vote. And not just yours. That of entire populations.</p>
<p>Know that profits are just the tip of the iceberg. Governments all around the world are also interested in knowing what their citizens think, say and do for very different motives.</p>
<h2>Going decentralized</h2>
<p>The solution is relatively simple. When you create a new account and get to choose between "Google&nbsp;login", "Facebook&nbsp;login" and "Email&nbsp;login", pick "Email&nbsp;login".</p>
<p>The benefit of not giving away any more personal data and tracking possibilities outweigh the inconvenience of having to fill in your email address and a password, especially when using a password manager. As tempting as the alternative is, making these changes will improve your life and ultimately, when enough people join these efforts, that of the world population.</p>
<p>A different problem arises: how to prove online identity when decentralized?</p>
<h2>Decentralized online identity</h2>
<p>When you are no longer relying on an identity provider to manage your entire online identity, you lose the one common thing all your accounts on different platforms had: if two accounts on different online platforms are created by the same Google or Facebook account, we can safely assume they belong to the same person.</p>
<p>But this "trust by proxy" is lost when the accounts on those platforms were created without identity provider. And whether authentic or anonymous, it can sometimes be extremely useful to know and trust that separate accounts on the internet belong to the same person, even when not knowing who this person is.</p>
<p>The username is not sufficient to identify accounts across platforms. If you are "Alice" on one website, chances are you might need to be "Alice123" on the next one. And what if someone close to you is contacted by an "Aliss" requesting an amount of money to be transferred because they believe you to be in some sort of trouble? A poor attempt at impersonation, I know… Don't worry, a real bad actor will put in more effort and make a much more convincing act.</p>
<h2>Proving decentralized online identity</h2>
<p>What if not only your online identity is decentralized, but also the tool to prove said online identity? This would mean that you wouldn't need to depend on a single company or entity to prove your identity across platforms. Decentralized identity, decentralized proofs!</p>
<p>Such solutions are already being deployed in industry, for example by firms like <a href="https://indicio.tech/">Indicio.tech</a> which focus on blockchain technology.</p>
<p>Built for individuals, I recently launched <a href="https://keyoxide.org/">Keyoxide</a> which uses cryptographic keypairs to accomplish decentralized identity verification. While it doesn't (and shouldn't!) link an account to a person in the physical realm, it links accounts across platforms.</p>
<p>If you trust an account on one platform, you can trust any other account on any other platform as long as they are both verified by "identity proofs" stored in the same keypair. Whether you choose authenticity or anonymity, decentralized identity proofs allow you to build a cross-platform online identity.</p>
<p>Here's my <a href="https://keyoxide.org/9f0048ac0b23301e1f77e994909f6bd6f80f485d">Keyoxide profile</a>. In this case, I link to several "authentic" accounts but I could easily generate a new keypair void of personal data that links to several anonymous accounts. The accounts don't need to be authentic to create an online persona.</p>
<p>All the accounts listed in the link above belong to me. No one else could claim these accounts. Here's how.</p>
<h2>Identity proofs</h2>
<p>An "identity proof" is nothing more than a link to an account A on some platform P stored inside your keypair K. If a "proof verification tool" such as Keyoxide follows this link and discovers some piece of data linking back to keypair K (which is only possible if keypair K and account A on platform P belong to the same person), the account is verified. If this proof verification is done for several accounts on different platforms, it is beyond reasonable doubt that the same person owns said accounts.</p>
<p>No bad actor could claim one of your accounts: the piece of data that links back is specific to your keypair, not the bad actor's keypair. And the bad actor also couldn't insert a proof inside your keypair as long as your keypair isn't compromised. Only you, the owner of the keypair, can add new proofs. But the entire world can read and verify them.</p>
<p>These identity proofs are decentralized because Keyoxide doesn't store them, your cryptographic keypair does. Keyoxide simply reads the keys and verifies the proofs. When you remove a proof from your keypair, Keyoxide will no longer have access to it. You own your proofs and your online identity.</p>
<p>In fact, the proofs are readable by everyone and are not specifically designed for Keyoxide. Anyone can use any tool or create new ones to verify these proofs and developers are encouraged to enrich this field with additional tools and services. Let's build a decentralized identity ecosystem we can all trust.</p>
<h2>Online identity beyond today's internet</h2>
<p>Initiatives like <a href="https://inrupt.com/solid">Solid</a> by <a href="https://en.wikipedia.org/wiki/Tim_Berners-Lee">Sir Tim Berners-Lee</a> are paving the way for a new internet where all data is owned by the user and shared with platforms with consent and restrictions. This would solve the online identity problem: you get the benefits of a "pseudo centralized" account while maintaining full ownership over all account-related data stored on a decentralized platform. Social media would be allowed to see some data, messaging platforms some other data. But there would still be one single account to rule all the platforms.</p>
<p>On today's internet, the best we can do is make fully separated accounts, link them using technologies like decentralized online identity proofs and create our own online personas, with our own open tools that ensure we maintain ownership over them.</p></div></div>]]>
            </description>
            <link>https://yarmo.eu/post/future-online-identity-decentralized</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811568</guid>
            <pubDate>Sun, 12 Jul 2020 14:30:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust for JavaScript Developers – Pattern Matching and Enums]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23811431">thread link</a>) | @rkwz
<br/>
July 12, 2020 | http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is the fourth part in a series about introducing the Rust language to JavaScript developers. Here are the past chapters:</p>
<ol>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-tooling-ecosystem-overview/">Tooling Ecosystem Overview</a></li>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-variables-and-data-types/">Variables and Data Types</a></li>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/">Functions and Control Flow</a></li>
</ol>
<h2 id="Pattern-Matching"><a href="#Pattern-Matching" title="Pattern Matching"></a>Pattern Matching</h2><p>To understand Pattern Matching, let’s start with something familiar in JavaScript - Switch Case.</p>
<p>Here’s a simple example that uses <code>switch case</code> in JavaScript:</p>
<pre><code><span>function</span> <span>print_color</span><span>(</span>color<span>)</span> <span>{</span>
  <span>switch</span> <span>(</span>color<span>)</span> <span>{</span>
    <span>case</span> <span>"rose"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"roses are red,"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"violet"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"violets are blue,"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>default</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"sugar is sweet, and so are you."</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>print_color</span><span>(</span><span>"rose"</span><span>)</span><span>;</span> 
<span>print_color</span><span>(</span><span>"violet"</span><span>)</span><span>;</span> 
<span>print_color</span><span>(</span><span>"you"</span><span>)</span><span>;</span> </code></pre>
<p>Here’s the equivalent Rust code:</p>
<pre><code><span>fn</span> <span>print_color</span><span>(</span>color<span>:</span> <span>&amp;</span>str<span>)</span> <span>{</span>
  <span>match</span> color <span>{</span>
    <span>"rose"</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"roses are red,"</span><span>)</span><span>,</span>
    <span>"violet"</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"violets are blue,"</span><span>)</span><span>,</span>
    _ <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"sugar is sweet, and so are you."</span><span>)</span><span>,</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>print_color</span><span>(</span><span>"rose"</span><span>)</span><span>;</span> 
  <span>print_color</span><span>(</span><span>"violet"</span><span>)</span><span>;</span> 
  <span>print_color</span><span>(</span><span>"you"</span><span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>Most of the code should be immediately understandable. The <code>match</code> expression has the following signature:</p>
<pre><code><span>match</span> VALUE <span>{</span>
  PATTERN1 <span>=</span><span>&gt;</span> EXPRESSION1<span>,</span>
  PATTERN2 <span>=</span><span>&gt;</span> EXPRESSION2<span>,</span>
  PATTERN3 <span>=</span><span>&gt;</span> EXPRESSION3<span>,</span>
<span>}</span></code></pre>
<p>The fat arrow <code>=&gt;</code> syntax might trip us up because of the similarities with JavaScript arrow functions but they’re unrelated. The last pattern that uses underscore <code>_</code> is called the catchall pattern and is similar to the default case in switch case. Each <code>PATTERN =&gt; EXPRESSION</code> combination is called a <code>match arm</code>.</p>
<p>The above example doesn’t really convey how useful pattern matching is - it just looks like switch case with a different syntax and a fancy name. Let’s talk about destructuring and enums to understand why pattern matching is useful.</p>
<h2 id="Destructuring"><a href="#Destructuring" title="Destructuring"></a>Destructuring</h2><p>Destructuring is the process of extracting the inner fields of an array or struct into separate variables. If you have used destructuring in JavaScript, it is very similar in Rust.</p>
<p>Here’s an example in JavaScript:</p>
<pre><code><span>let</span> rgb <span>=</span> <span>[</span><span>96</span><span>,</span> <span>172</span><span>,</span> <span>57</span><span>]</span><span>;</span>
<span>let</span> <span>[</span>red<span>,</span> green<span>,</span> blue<span>]</span> <span>=</span> rgb<span>;</span>
console<span>.</span><span>log</span><span>(</span>red<span>)</span><span>;</span> 
console<span>.</span><span>log</span><span>(</span>green<span>)</span><span>;</span> 
console<span>.</span><span>log</span><span>(</span>blue<span>)</span><span>;</span> 

<span>let</span> person <span>=</span> <span>{</span> name<span>:</span> <span>"shesh"</span><span>,</span> city<span>:</span> <span>"singapore"</span> <span>}</span><span>;</span>
<span>let</span> <span>{</span> name<span>,</span> city <span>}</span> <span>=</span> person<span>;</span>
console<span>.</span><span>log</span><span>(</span>name<span>)</span><span>;</span> 
console<span>.</span><span>log</span><span>(</span>city<span>)</span><span>;</span> </code></pre>
<p>Here’s the same example in Rust:</p>
<pre><code><span>struct</span> Person <span>{</span>
  name<span>:</span> String<span>,</span>
  city<span>:</span> String<span>,</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> rgb <span>=</span> <span>[</span><span>96</span><span>,</span> <span>172</span><span>,</span> <span>57</span><span>]</span><span>;</span>
  <span>let</span> <span>[</span>red<span>,</span> green<span>,</span> blue<span>]</span> <span>=</span> rgb<span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> red<span>)</span><span>;</span> 
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> green<span>)</span><span>;</span> 
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> blue<span>)</span><span>;</span> 

  <span>let</span> person <span>=</span> Person <span>{</span>
    name<span>:</span> <span>"shesh"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>,</span>
    city<span>:</span> <span>"singapore"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>,</span>
  <span>}</span><span>;</span>
  <span>let</span> Person <span>{</span> name<span>,</span> city <span>}</span> <span>=</span> person<span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> name<span>)</span><span>;</span> 
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> city<span>)</span><span>;</span> 
<span>}</span></code></pre>
<h2 id="Comparing-Structs"><a href="#Comparing-Structs" title="Comparing Structs"></a>Comparing Structs</h2><p>It’s very common to write “if this then that” type of code. Combining destructuring and pattern matching allows us to write these type of logic in a very concise way.</p>
<p>Let’s take this following example in JavaScript. It’s contrived but you have probably written something like this sometime in your career:</p>
<pre><code><span>const</span> point <span>=</span> <span>{</span> x<span>:</span> <span>0</span><span>,</span> y<span>:</span> <span>30</span> <span>}</span><span>;</span>
<span>const</span> <span>{</span> x<span>,</span> y <span>}</span> <span>=</span> point<span>;</span>

<span>if</span> <span>(</span>x <span>===</span> <span>0</span> <span>&amp;&amp;</span> y <span>===</span> <span>0</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>"both are zero"</span><span>)</span><span>;</span>
<span>}</span> <span>else</span> <span>if</span> <span>(</span>x <span>===</span> <span>0</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`x is zero and y is </span><span><span>${</span>y<span>}</span></span><span>`</span></span><span>)</span><span>;</span>
<span>}</span> <span>else</span> <span>if</span> <span>(</span>y <span>===</span> <span>0</span><span>)</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`x is </span><span><span>${</span>x<span>}</span></span><span> and y is zero`</span></span><span>)</span><span>;</span>
<span>}</span> <span>else</span> <span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`x is </span><span><span>${</span>x<span>}</span></span><span> and y is </span><span><span>${</span>y<span>}</span></span><span>`</span></span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>Let’s write the same code in Rust using pattern matching:</p>
<pre><code><span>struct</span> Point <span>{</span>
  x<span>:</span> i32<span>,</span>
  y<span>:</span> i32<span>,</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> point <span>=</span> Point <span>{</span> x<span>:</span> <span>10</span><span>,</span> y<span>:</span> <span>0</span> <span>}</span><span>;</span>

  <span>match</span> point <span>{</span>
    Point <span>{</span> x<span>:</span> <span>0</span><span>,</span> y<span>:</span> <span>0</span> <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"both are zero"</span><span>)</span><span>,</span>
    Point <span>{</span> x<span>:</span> <span>0</span><span>,</span> y <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"x is zero and y is {}"</span><span>,</span> y<span>)</span><span>,</span>
    Point <span>{</span> x<span>,</span> y<span>:</span> <span>0</span> <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"x is {} and y is zero"</span><span>,</span> x<span>)</span><span>,</span>
    Point <span>{</span> x<span>,</span> y <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"x is {} and y is {}"</span><span>,</span> x<span>,</span> y<span>)</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre>
<p>It’s a bit concise compared to the <code>if else</code> logic but also might be confusing as we’re performing comparison, destructuring and variable binding at the same time.</p>
<p>This is how it looks like visually:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-for-javascript-developers-4/pattern-matching-rust-1.png" alt=""><br><img src="http://www.sheshbabu.com/images/2020-rust-for-javascript-developers-4/pattern-matching-rust-2.png" alt=""></p>
<p>We begin to see why it’s named as “pattern matching” - we take an input and see which pattern in the match arms “fits” better - It’s like the <a href="https://www.google.com/search?q=shape+sorter" target="_blank" rel="noopener">shape sorter</a> toys that kids play with. Apart from comparison, we also do variable binding in the 2nd, 3rd and 4th match arms. We pass variables x or y or both to their respective expressions.</p>
<p>Pattern matching is also <code>exhaustive</code> - that is, it forces you to handle all the possible cases. Try removing the last match arm and Rust won’t let you compile the code.</p>
<h2 id="Enum"><a href="#Enum" title="Enum"></a>Enum</h2><p>JavaScript doesn’t have Enums but if you’ve used TypeScript, you can think of Rust’s Enums as a combination of TypeScript’s <a href="https://www.typescriptlang.org/docs/handbook/enums.html" target="_blank" rel="noopener">Enums</a> and TypeScript’s <a href="https://www.typescriptlang.org/docs/handbook/advanced-types.html#discriminated-unions" target="_blank" rel="noopener">Discriminated Unions</a></p>
<p>In the simplest case, Enums can be used as a group of constants.</p>
<p>For example, even though JavaScript doesn’t have Enums, you might have used this pattern:</p>
<pre><code><span>const</span> DIRECTION <span>=</span> <span>{</span>
  FORWARD<span>:</span> <span>"FORWARD"</span><span>,</span>
  BACKWARD<span>:</span> <span>"BACKWARD"</span><span>,</span>
  LEFT<span>:</span> <span>"LEFT"</span><span>,</span>
  RIGHT<span>:</span> <span>"RIGHT"</span><span>,</span>
<span>}</span><span>;</span>

<span>function</span> <span>move_drone</span><span>(</span>direction<span>)</span> <span>{</span>
  <span>switch</span> <span>(</span>direction<span>)</span> <span>{</span>
    <span>case</span> DIRECTION<span>.</span>FORWARD<span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Forward"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> DIRECTION<span>.</span>BACKWARD<span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Backward"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> DIRECTION<span>.</span>LEFT<span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Left"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> DIRECTION<span>.</span>RIGHT<span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Right"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>move_drone</span><span>(</span>DIRECTION<span>.</span>FORWARD<span>)</span><span>;</span> </code></pre>
<p>Here, we could’ve defined the FORWARD, BACKWARD, LEFT and RIGHT as separate constants, yet grouping it inside the DIRECTION object has the following benefits:</p>
<ul>
<li>The names FORWARD, BACKWARD, LEFT and RIGHT are namespaced under DIRECTION so naming conflicts can be avoided</li>
<li>It is self-documenting as we can quickly see all the valid directions available in the codebase</li>
</ul>
<p>However, there are some problems with this approach:</p>
<ul>
<li>What if someone passes NORTH or UP as an argument to move_drone? To fix this, we can add a validation to make sure that only values present in the DIRECTION object is allowed in the move function.</li>
<li>What if we decide to support UP and DOWN in future or rename LEFT/RIGHT to PORT/STARBOARD? We need to find all the places where similar switch-case or if-else is used. There’s a chance that we might miss out a few places which would cause issues in production.</li>
</ul>
<p>Enums in strongly typed languages like Rust are more powerful as they solve these problems without us writing extra code.</p>
<ul>
<li>If a function can take in only a small set of valid inputs, Enums can be used to enforce this constraint</li>
<li>Enums with pattern matching force you to cover all cases. Useful when you’re updating Enums in future</li>
</ul>
<p>Here’s the equivalent Rust example:</p>
<pre><code><span>enum</span> Direction <span>{</span>
  Forward<span>,</span>
  Backward<span>,</span>
  Left<span>,</span>
  Right<span>,</span>
<span>}</span>

<span>fn</span> <span>move_drone</span><span>(</span>direction<span>:</span> Direction<span>)</span> <span>{</span>
  <span>match</span> direction <span>{</span>
    Direction<span>:</span><span>:</span>Forward <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Forward"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Backward <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Backward"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Left <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Left"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Right <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Right"</span><span>)</span><span>,</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>move_drone</span><span>(</span>Direction<span>:</span><span>:</span>Forward<span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We access the <code>variants</code> inside Enum using the <code>::</code> notation. Try editing this code by calling “move_drone(Direction::Up)” or adding “Down” as a new item in the Direction enum. In the first case, the compiler will throw an error saying that “Up” is not found in “Direction” and in the second case, the compiler will complain that we haven’t covered “Down” in the match block.</p>
<p>Rust Enums can do much more than act as a group of constants - we can also associate data with an Enum variant.</p>
<pre><code><span>enum</span> Direction <span>{</span>
  Forward<span>,</span>
  Backward<span>,</span>
  Left<span>,</span>
  Right<span>,</span>
<span>}</span>

<span>enum</span> Operation <span>{</span>
  PowerOn<span>,</span>
  PowerOff<span>,</span>
  <span>Move</span><span>(</span>Direction<span>)</span><span>,</span>
  Rotate<span>,</span>
  TakePhoto <span>{</span> is_landscape<span>:</span> bool<span>,</span> zoom_level<span>:</span> i32 <span>}</span><span>,</span>
<span>}</span>

<span>fn</span> <span>operate_drone</span><span>(</span>operation<span>:</span> Operation<span>)</span> <span>{</span>
  <span>match</span> operation <span>{</span>
    Operation<span>:</span><span>:</span>PowerOn <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Power On"</span><span>)</span><span>,</span>
    Operation<span>:</span><span>:</span>PowerOff <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Power Off"</span><span>)</span><span>,</span>
    Operation<span>:</span><span>:</span><span>Move</span><span>(</span>direction<span>)</span> <span>=</span><span>&gt;</span> <span>move_drone</span><span>(</span>direction<span>)</span><span>,</span>
    Operation<span>:</span><span>:</span>Rotate <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Rotate"</span><span>)</span><span>,</span>
    Operation<span>:</span><span>:</span>TakePhoto <span>{</span>
      is_landscape<span>,</span>
      zoom_level<span>,</span>
    <span>}</span> <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"TakePhoto {}, {}"</span><span>,</span> is_landscape<span>,</span> zoom_level<span>)</span><span>,</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>move_drone</span><span>(</span>direction<span>:</span> Direction<span>)</span> <span>{</span>
  <span>match</span> direction <span>{</span>
    Direction<span>:</span><span>:</span>Forward <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Forward"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Backward <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Backward"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Left <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Left"</span><span>)</span><span>,</span>
    Direction<span>:</span><span>:</span>Right <span>=</span><span>&gt;</span> <span>println!</span><span>(</span><span>"Move Right"</span><span>)</span><span>,</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>operate_drone</span><span>(</span>Operation<span>:</span><span>:</span><span>Move</span><span>(</span>Direction<span>:</span><span>:</span>Forward<span>)</span><span>)</span><span>;</span>
  <span>operate_drone</span><span>(</span>Operation<span>:</span><span>:</span>TakePhoto <span>{</span>
    is_landscape<span>:</span> <span>true</span><span>,</span>
    zoom_level<span>:</span> <span>10</span><span>,</span>
  <span>}</span><span>)</span>
<span>}</span></code></pre>
<p>Here, we’ve added one more Enum called Operation that contains “unit like” variants (PowerOn, PowerOff, Rotate) and “struct like” variants (Move, TakePhoto). Notice how we’ve used pattern matching with destructuring and variable binding.</p>
<p>If you’ve used TypeScript or Flow, this is similar to <code>discriminated unions</code> or <code>sum types</code>:</p>
<pre><code><span>interface</span> <span>PowerOn</span> <span>{</span>
  kind<span>:</span> <span>"PowerOn"</span><span>;</span>
<span>}</span>

<span>interface</span> <span>PowerOff</span> <span>{</span>
  kind<span>:</span> <span>"PowerOff"</span><span>;</span>
<span>}</span>

type Direction <span>=</span> <span>"Forward"</span> <span>|</span> <span>"Backward"</span> <span>|</span> <span>"Left"</span> <span>|</span> <span>"Right"</span><span>;</span>

<span>interface</span> <span>Move</span> <span>{</span>
  kind<span>:</span> <span>"Move"</span><span>;</span>
  direction<span>:</span> Direction<span>;</span>
<span>}</span>

<span>interface</span> <span>Rotate</span> <span>{</span>
  kind<span>:</span> <span>"Rotate"</span><span>;</span>
<span>}</span>

<span>interface</span> <span>TakePhoto</span> <span>{</span>
  kind<span>:</span> <span>"TakePhoto"</span><span>;</span>
  is_landscape<span>:</span> <span>boolean</span><span>;</span>
  zoom_level<span>:</span> <span>number</span><span>;</span>
<span>}</span>

type Operation <span>=</span> PowerOn <span>|</span> PowerOff <span>|</span> Move <span>|</span> Rotate <span>|</span> TakePhoto<span>;</span>

<span>function</span> <span>operate_drone</span><span>(</span>operation<span>:</span> Operation<span>)</span> <span>{</span>
  <span>switch</span> <span>(</span>operation<span>.</span>kind<span>)</span> <span>{</span>
    <span>case</span> <span>"PowerOn"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Power On"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"PowerOff"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Power Off"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Move"</span><span>:</span>
      <span>move_drone</span><span>(</span>operation<span>.</span>direction<span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Rotate"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Rotate"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"TakePhoto"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span><span>`TakePhoto </span><span><span>${</span>operation<span>.</span>is_landscape<span>}</span></span><span>, </span><span><span>${</span>operation<span>.</span>zoom_level<span>}</span></span><span>`</span></span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>function</span> <span>move_drone</span><span>(</span>direction<span>:</span> Direction<span>)</span> <span>{</span>
  <span>switch</span> <span>(</span>direction<span>)</span> <span>{</span>
    <span>case</span> <span>"Forward"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Forward"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Backward"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Backward"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Left"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Left"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
    <span>case</span> <span>"Right"</span><span>:</span>
      console<span>.</span><span>log</span><span>(</span><span>"Move Right"</span><span>)</span><span>;</span>
      <span>break</span><span>;</span>
  <span>}</span>
<span>}</span>

<span>operate_drone</span><span>(</span><span>{</span>
  kind<span>:</span> <span>"Move"</span><span>,</span>
  direction<span>:</span> <span>"Forward"</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>operate_drone</span><span>(</span><span>{</span>
  kind<span>:</span> <span>"TakePhoto"</span><span>,</span>
  is_landscape<span>:</span> <span>true</span><span>,</span>
  zoom_level<span>:</span> <span>10</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<h2 id="Option"><a href="#Option" title="Option"></a>Option</h2><p>We learnt about the <code>Op…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums">http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums</a></em></p>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-for-javascript-developers-pattern-matching-and-enums</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811431</guid>
            <pubDate>Sun, 12 Jul 2020 14:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PolyFit: Perception-aligned Vectorization of Raster Clip-art]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811395">thread link</a>) | @mpweiher
<br/>
July 12, 2020 | http://www.cs.ubc.ca/labs/imager/tr/2020/ClipArtVectorization/ | <a href="https://web.archive.org/web/*/http://www.cs.ubc.ca/labs/imager/tr/2020/ClipArtVectorization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
	
	<!-- =============== PAPER INFORMATION=================  -->
	<p>PolyFit: Perception-aligned Vectorization of Raster Clip-art via Intermediate Polygonal Fitting</p><br>

	<!-- NEWER AUTHOR LIST -->	
	<p>
	  Edoardo&nbsp;A.&nbsp;Dominici<sup>1</sup>,
	  Nico&nbsp;Schertler<sup>1</sup>,
	  Jonathan&nbsp;Griffin<sup>1</sup>,
	  Shayan&nbsp;Hoshyari<sup>2</sup>,
	  Leonid&nbsp;Sigal<sup>1</sup>,
	  Alla&nbsp;Sheffer<sup>1</sup>
	</p>

	<p><sup>1</sup> University of British Columbia,
	  <sup>2</sup> Adobe Inc.
	</p>
	
	<p><span>Accepted to SIGGRAPH 2020</span>
	</p>
	<br>

	<!-- =============== TEASER  =================  -->
	<div>
	  <p><img src="http://www.cs.ubc.ca/labs/imager/tr/2020/ClipArtVectorization/image/teaser.jpg"></p><p>
	     Vectorizing raster clip-art inputs (a) using existing methods, here Potrace [Selinger 2003] (b) and [Hoshyari et al. 2018] (c), results in visible artifacts
(highlighted in zoomed-in insets). PolyFit outputs (e), created using an intermediate polygonal approximation step (d), are more consistent with viewer
expectations than those produced by these alternatives. Please zoom in online to see details.

	  </p>
	</div>

	<!-- =============== ABSTRACT  =================  -->

	  
	  <p>
	    Raster clip-art images, which consist of distinctly colored regions separated by sharp boundaries typically allow for a clear mental vector interpretation. Vectorizing these images can facilitate compact lossless storage and enable numerous processing operations. Despite recent progress, existing vectorization methods that target this data frequently produce vectorizations that fail to meet viewer expectations. We present PolyFit, a new clip-art vectorization method that produces outputs well aligned with human preferences. Since segmentation of such inputs into regions had been addressed successfully, we focus on fitting piecewise smooth vector curves to the raster input region boundaries, a task prior methods are particularly prone to fail on. While perceptual studies suggest the criteria humans are likely to use during mental boundary vectorization, they provide no guidance as to the exact interaction between them; learning these interactions directly is problematic due to the large size of the solution space. To obtain the desired solution, we first approximate the raster region boundaries with coarse intermediate polygons leveraging a combination of perceptual cues with observations from studies of human preferences. We then use these intermediate polygons as auxiliary inputs for computing piecewise smooth vectorizations. We define a finite set of potential polygon to curve primitive maps, and learn the mapping from the polygons to their best fitting primitive configurations from human annotations, arriving at a compact set of local raster and polygon properties whose combinations reliably predict human-expected primitive choices. We obtain the final vectorization by fitting the computed primitive sequence to the raster data. Comparative user studies show that our method outperforms state-of-the-art approaches on a wide range of data; our results are preferred three times as often as those of the closest competitor across inputs with various resolutions. On low-resolution color data, this preference grows to a ratio of more than 15:1.
	  </p>

	<!-- =============== VIDEO  =================  -->
	
	

	<!-- =============== LINK TO Download stuff  =================  -->
	
	



	  <!-- =============== BIBTEX  =================  -->	
	  
	  <div>
	    <pre>@article{ dominici2020vectorization,	      
author    = {Alberto Dominici, Edoardo and Schertler, Nico and Griffin, Jonathan and Hoshyari, Shayan and Sigal, Leonid and Sheffer, Alla},
title     = {PolyFit: Perception-aligned Vectorization of Raster Clip-art via Intermediate Polygonal Fitting},
journal   = {ACM Transaction on Graphics},
year      = {2020},
volume    = {39},
number    = {4},
doi       = {10.1145/3386569.3392401},
publisher = {ACM},
address   = {New York, NY, USA},
}
	    </pre>
	  </div>

	  <!-- =============== RESULTS  =================  -->	
	  
	  <p><img src="http://www.cs.ubc.ca/labs/imager/tr/2020/ClipArtVectorization/image/results-1.svg"></p>
	  <p><img src="http://www.cs.ubc.ca/labs/imager/tr/2020/ClipArtVectorization/image/results-2.svg"></p>
	  <p><img src="http://www.cs.ubc.ca/labs/imager/tr/2020/ClipArtVectorization/image/results-3.svg"></p>

	  <p>
	    Note: some of the input images shown are copyrighted by
	    third parties and used with their permission. See the
	    paper for the list of third-party sources.
	  </p>
	  <hr>
	  <p>
	    All non-third-party images are © ACM.
	  </p>
	  <br>
	</div>
      </div></div>]]>
            </description>
            <link>http://www.cs.ubc.ca/labs/imager/tr/2020/ClipArtVectorization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811395</guid>
            <pubDate>Sun, 12 Jul 2020 14:11:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some popular self help books]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23811333">thread link</a>) | @imshashank
<br/>
July 12, 2020 | https://dailyjag.com/literature/read-these-self-help-books-and-make-most-of-our-this-downtime/ | <a href="https://web.archive.org/web/*/https://dailyjag.com/literature/read-these-self-help-books-and-make-most-of-our-this-downtime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Continual upskilling is critical for accelerating your career progression. However, the time constraint that corporate employment entail tends to spare limited time for you to improve your skillset. In this light, it can be said that downtime is the best time to update the skills you require to transcend the role that you hold. Developing the ability to teach yourself can help you make the most of self-help books available in the market. We have put together a list of popular books that can help you get started.&nbsp;</p><h2>1) <strong>Fastlane Millionaire by MJ DeMarco</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-1024x576.jpg" alt="The Millionaire Fastlane by M.J. Demarco - animated book summary ..." srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-1024x576.jpg 1024w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-300x169.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-768x432.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-192x108.jpg 192w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-384x216.jpg 384w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-364x205.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-728x409.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-561x316.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-1122x631.jpg 1122w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-608x342.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-758x426.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-1152x648.jpg 1152w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-85x48.jpg 85w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-171x96.jpg 171w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco-313x176.jpg 313w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Fastlane-Millionaire-by-MJ-DeMarco.jpg 1280w" sizes="100vw"></figure></div><p>This book will change your perspective of the process involved in getting rich. The author demolishes the conventional ideas of earning riches by exposing its many flaws. MJ redefines wealth in Fastlane Millionaire and outlines a quick practical way of getting wealthy and retiring young. This book can help you start your own profitable business that can yield you both reputation and wealth.</p><h2>2) <strong>Creativity Inc by Ed Catmull and Amy Wallace</strong></h2><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-1024x574.jpg" alt="Creativity Inc by Ed Catmull and Amy Wallace" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-1024x574.jpg 1024w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-300x168.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-768x431.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-192x108.jpg 192w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-384x216.jpg 384w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-364x205.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-728x409.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-561x314.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-1122x629.jpg 1122w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-608x341.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-758x426.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-1152x646.jpg 1152w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-86x48.jpg 86w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-171x96.jpg 171w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace-313x175.jpg 313w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Creativity-Inc-by-Ed-Catmull-and-Amy-Wallace.jpg 1379w" sizes="100vw"></figure><p>The authors base this book on the premise that everyone has creativity in them. They believe that various unseen forces suppress or even quench this innate creativity. They emphasize the fact that creative inspiration is not associated with job titles or organizational hierarchy. This is a great book for managers as it helps them understand the importance of a good team and educates them about acceptable team dynamics.&nbsp;</p><h2>3) <strong>Range by David Epstein</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein.jpg" alt="Range by David Epstein" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein.jpg 837w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-300x182.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-768x465.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-561x340.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-364x220.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-728x441.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-608x368.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-758x459.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-79x48.jpg 79w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-158x96.jpg 158w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Range-by-David-Epstein-313x190.jpg 313w" sizes="100vw"></figure></div><p>We have all heard time and again about the importance of starting early, honing skills, and striving to succeed. The book will help you understand the reason behind generalists’ success during times of increasing specialization. In his book, Range, David Epstein draws a vivid comparison between those who start young and those who take time to find their interest. He uses real-life celebrities as examples to draw takeaways about specializing, experimenting, and abstract thinking. This is a breakthrough book that can help parents, teachers, managers, and leaders look at success and performance in the right way.</p><h2>4) <strong>Designing Your Life by Bill Burnett and Dave Evans</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-1024x719.jpg" alt="Designing Your Life by Bill Burnett and Dave Evans" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-1024x719.jpg 1024w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-300x211.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-768x540.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-265x186.jpg 265w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-561x394.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-1122x788.jpg 1122w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-364x256.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-728x511.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-608x427.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-758x532.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-1152x809.jpg 1152w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-68x48.jpg 68w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-137x96.jpg 137w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans-313x220.jpg 313w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Designing-Your-Life-by-Bill-Burnett-and-Dave-Evans.jpg 1200w" sizes="100vw"></figure></div><p>This book is a New York Times Best Seller that can impact you positively irrespective of your age or stage in life. The authors give you a prototype of design thinking that can help you design and build your work as well as personal life. Living out the guidelines and concepts available in this book can help you live a more fulfilling life filled with creativity, productivity, and joy.</p><h2>5)&nbsp;<strong>Find Your Why by Simon Sinek, David Mead, and Peter Docker</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-1024x576.jpg" alt="Find Your Why by Simon Sinek, David Mead, and Peter Docker" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-1024x576.jpg 1024w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-300x169.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-768x432.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-192x108.jpg 192w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-384x216.jpg 384w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-364x205.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-728x409.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-561x316.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-1122x631.jpg 1122w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-608x342.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-758x426.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-1152x648.jpg 1152w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-85x48.jpg 85w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-171x96.jpg 171w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker-313x176.jpg 313w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Find-Your-Why-by-Simon-Sinek-David-Mead-and-Peter-Docker.jpg 1280w" sizes="100vw"></figure></div><p>The authors of this book believe that statements that start with ‘why’ are more actionable than others. This book will help you find your purpose (if you haven’t already) and will aid in renewing your passion for what you are doing. This read will redefine the definition of happiness, fulfillment, and purpose for you. The authors have also followed up with a second book, ‘Start With Why’ to help you get started on the path that will make your life more meaningful.</p><h2>6) <strong>The $100 Startup by Chris Guillebeau</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau.jpg" alt="The $100 Startup by Chris Guillebeau" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau.jpg 820w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-300x164.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-768x421.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-561x307.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-364x199.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-728x399.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-608x333.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-758x415.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-88x48.jpg 88w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-175x96.jpg 175w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/The-100-Startup-by-Chris-Guillebeau-313x171.jpg 313w" sizes="100vw"></figure></div><p>This book has its focus set on solopreneurs and individual entrepreneurs who wield their capabilities and earn profits through sheer passion and micro-businesses. The author taps into his own experience as an entrepreneur and delivers speaking assignments on micro-businesses. The book is a great source of small ideas that can be worked on to earn a substantial income. The author generously uses infographics, checklists, and sidebars to help convey his message effectively.</p><h2>7) <strong>Originals by Adam Grant</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1.jpg" alt="Innovation Design In Education - ASIDE: Book Club Discussion ..." srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1.jpg 710w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-300x161.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-561x300.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-364x195.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-608x325.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-90x48.jpg 90w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-179x96.jpg 179w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Originals-by-Adam-Grant-1-313x168.jpg 313w" sizes="(max-width: 710px) 100vw, 710px"></figure></div><p>This book gives you a glimpse into the world-view of successful innovators. Reading this book will encourage you to stand out by correctly expressing your new ideas. He analyses the non-conformist moves made by leading innovators in various markets and highlights their success strategies to provide you with actionable insights.</p><h2>8) <strong>Antifragile by Nassim Nicholas Taleb</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb.jpg" alt="Antifragile by Nassim Nicholas Taleb" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb.jpg 900w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-300x183.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-768x468.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-561x342.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-364x222.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-728x443.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-608x370.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-758x462.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-79x48.jpg 79w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-158x96.jpg 158w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Antifragile-by-Nassim-Nicholas-Taleb-313x191.jpg 313w" sizes="100vw"></figure></div><p>Antifragile is a thought-provoking book that encourages you to work towards making yourself stronger by exposing yourself to volatile circumstances. The author segregates all things into three categories – fragile, robust, and antifragile. He appeals to develop features that will slot you in the antifragile category, where every disruption only makes you stronger.&nbsp;</p><h2>9) <strong>When by Daniel H Pink</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink.jpg" alt="When by Daniel H Pink" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink.jpg 776w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-300x232.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-768x594.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-561x434.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-364x281.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-728x563.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-608x470.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-758x586.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-62x48.jpg 62w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-124x96.jpg 124w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/When-by-Daniel-H-Pink-313x242.jpg 313w" sizes="100vw"></figure></div><p>This book explores scientific facts that imply that the impact of the decision taken is dependent on their timing. The author suggests that our cognitive abilities are subject to change over the course of the day. Daniel leverages his research takeaways and highlights the importance of scheduling and timing of routine practices to culminate your efforts into success.</p><h2>10) <strong>Grit by Angela Duckworth</strong></h2><div><figure><img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth.jpg" alt="Grit by Angela Duckworth" srcset="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth.jpg 791w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-300x169.jpg 300w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-768x432.jpg 768w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-192x108.jpg 192w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-384x216.jpg 384w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-364x205.jpg 364w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-728x409.jpg 728w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-561x316.jpg 561w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-608x342.jpg 608w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-758x426.jpg 758w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-85x48.jpg 85w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-171x96.jpg 171w, https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/Grit-by-Angela-Duckworth-313x176.jpg 313w" sizes="100vw"></figure></div><p>This book will keep your motivation levels high while you strive to gain success. The author emphasizes the fact that passion must be backed by perseverance to achieve the unattainable. In Grit, Angela records her meetings with people who have exercised grit to savor success. The takeaways she notes in this book and the life accounts of the champions she interviews will energize you to persevere and win.</p><div><div><div><p><a href="https://dailyjag.com/profile/admin/" rel="author"> <img alt="" src="https://secure.gravatar.com/avatar/33563973b6f338002e574f30a3f94788?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/33563973b6f338002e574f30a3f94788?s=160&amp;d=mm&amp;r=g 2x" height="80" width="80"> </a></p><div> <p><span>  </span> <span> <span>Member since</span> <time datetime="2020-04-17 12:37"> August 16, 2011 </time> </span></p></div></div><p><span>I am an android developer, hacker, web developer, professional blogger and a complete tech freak. I love computers and everything related to computers. I love learning new things and sharing the knowledge with the world.</span> <a href="https://www.facebook.com/agarwal.shashank">https://www.facebook.com/agarwal.shashank</a></p></div></div><p><a href="https://pipfeed.com/" target="_blank"> <img src="https://256057-1374499-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2020/04/White_Feature_image_2.jpg"> </a></p></div></div>]]>
            </description>
            <link>https://dailyjag.com/literature/read-these-self-help-books-and-make-most-of-our-this-downtime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811333</guid>
            <pubDate>Sun, 12 Jul 2020 14:02:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SAS Rescue 3 Trapped British Diplomats in Albania]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 75 (<a href="https://news.ycombinator.com/item?id=23811306">thread link</a>) | @Hansig_jw
<br/>
July 12, 2020 | https://www.mydiplomaticlife.com/sas-rescue-trapped-diplomats-in-albania/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/sas-rescue-trapped-diplomats-in-albania/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><span>This is a story of how the SAS rescued myself and two colleagues who were trapped in the British embassy in Tirana having been evacuated into the embassy on 12th September 12th 1998 as the country erupted into civil unrest and lawlessness. The boys from Hereford did good!</span></p>
<p>This was my first diplomatic posting and during the course of my career I took part in the <span>evacuation of British nationals&nbsp;(and others)</span><span>&nbsp;in a number of locations but on this occasion, I was the one being evacuated albeit from my residence to the embassy as a place of safety.<a href="https://www.mydiplomaticlife.com/libya-timely-evacuation-of-oil-workers/">Libya – Timely Evacuation Of Oil Workers During Arab Spring 2011</a></span></p>
<p>This was a day I was not going to forget in a hurry. I had just under four months left before my tour ended and I had spent the previous day at work trawling through future job opportunities. The Ambassador was again out of the country and the Deputy Head of Mission (DHM) was once more in charge. I should have known from previous experience and recent incidents that trouble always seemed to flare up when Ambassadors are away from post.</p>
<p>On this day, I awoke very early to the sounds of large explosions and the rattle of gunfire that seemed to be going off in all directions. What was going on? There had been no forewarning of trouble and things had been relatively quiet and stable in the city over the preceding weeks.</p>
<p>I tried to get hold of the DHM on my mobile phone but the network was down, always a bad sign. I immediately got on the embassy radio net and contacted her. She said that she had just heard from the German Embassy that a local high profile opposition politician, Azem Hajdari, had been assassinated outside the Parliament building and his Democratic Party (DP) supporters were on the warpath blaming the Socialist government party for the murder.</p>
<p>Tanks, automatic weapons and armoured personnel carriers had been seized by DP members and the government were now calling this an attempted coup d’etat and responding with armed force of its own.</p>
<p>She advised me to keep my head down, keep the radio close to hand and they would try and get an Embassy armoured vehicle to me as soon as possible and we would all rendezvous at the embassy. By this time, the noise of fighting outside seemed to be getting louder and getting nearer. The main government quarter was only just two blocks away from my apartment and it sounded like the main fighting was in this area. I cautiously pulled back a shutter and looked outside and saw there was a lot of smoke billowing forth from that quarter.</p>
<p>After about an hour, I heard a familiar voice on the radio, it was Benny our Embassy driver calling from the armoured car radio just outside my front gate. Not for the first time had he come to get me out of another messy situation. He advised me to be careful coming out as there was a body in front of my gate.</p>
<p>As I came out, the noise was deafening, there was small arms firing which appeared to be coming from the next street and there was indeed a man in what looked like a policeman’s uniform lying just to the side of my gate.</p>
<p>I didn’t hang around to assess his condition as just at that moment, a large group of armed men turned the corner on to my street firing in our direction as they advanced. Why they were shooting at a vehicle that was clearly marked as a diplomatic car, I had no idea. I jumped into the car and Benny quickly reversed the vehicle away from the onrushing crowd, turned it around at the intersection and off we sped to the embassy taking as many back roads as possible.</p>
<p>We reached the embassy safely but it was disturbing to see that the usual government provided armed security guarding the Embassy and the surrounds was nowhere to be seen. We drew up to the embassy and I ran into the building. Both the DHM and Management Officer (MO) were already there. The DHM had already contacted London and appraised them of the situation. It appeared that the violence was escalating and that it could very well be a coup d’etat. London advised us to remain in lockdown in the embassy and to stay there until further notice. Not very reassuring.</p>
<p>The hours went by, nighttime came and the sky was lit up with explosions and the gunfire seemed to be getting closer to the embassy. Throughout all of this, the DHM was updating London via our secure communication channels of our ever-growing precarious situation. They continued to advise us to stay in the embassy as help was on the way. What did that mean? How on earth were they going to help us? They were in London and we were trapped and bottled up at the sharp end.</p>
<p>Well, indeed help was on the way in the most unexpected form. After a long, restless and uncomfortable night trying to sleep on the floor of my office under my desk, as dawn was breaking, there was the sound of screeching tyres outside the embassy.</p>
<p>At first we thought this was it, the bad guys had arrived and we were destined for some form of uncertain captivity or worse, but no, out of two strange looking 4x4s, poured a section of heavily armed and equipped Special Air Service (SAS) troopers who had flown into Tirana airport from the UK in an RAF transport aircraft (without any flight clearance), offloaded themselves and sped the 17 Kms to the embassy.</p>
<p>There were no formalities, the SAS section commander immediately told the DHM that he was in charge and that we were to follow his instructions until further notice. For the time being, he said, there were no orders for evacuating us, his men would go out and evaluate the situation on the ground and then make a recommendation back to London.</p>
<p>They then set up their own communications suite in the Ambassador’s office (their communication specialist felt very much at home behind the large Ambassadorial desk), brought in their weapons and stores and after a short briefing, their patrol set off. Benny our driver volunteered to go with them and act as guide and interpreter if needed.</p>
<p>While one party was employed on this task another group made a start of setting up defensive positions within the embassy and thoroughly briefing us on what to do if we were subjected to an attack. It really was a boost to our morale that we had these guys now with us, more than able to physically protect us and if needed get us out of there to a place of safety if things deteriorated.</p>
<p>Later that afternoon the first patrol returned to the embassy. The good news was that they reported our homes had appeared from the outside not to have been looted. They said there was still heavy fighting going on in various parts of the city, but it seemed to be centred mainly around the government quarter. Benny told us later that the patrol had been menaced on several occasions by armed men, but a few well aimed shots above the heads of the mob had convinced them to melt away and not to mess with the patrol.</p>
<p>The fighting went on for about three days. Each day the sound of gunfire and explosions seemed to decrease. The SAS continued to send out rotating patrols to monitor the situation in and around the city, deciding after the third day that there was no need to evacuate us out of the country as their assessment was the fighting had run its course. Indeed thankfully, on the fourth day there was silence, no gunfire and no explosions.</p>
<p>The SAS kept us in the embassy for just over a week before they deemed it fully safe for us to return to our homes and resume normal work. We also received reassurances from the Albanian government that the fighting had now ceased, order had been restored and our local security would be reinstated. All of this was good news indeed.</p>
<p>However, it was a sad day when we came to bid farewell to our SAS rescuers as they packed up to leave. We had got to know them pretty well over the course of a long week. They were a thoroughly professional, no nonsense group of guys who were extremely sociable in the rare moments they took time out to relax in between patrols with a wealth of stories that kept us entertained during the long days and nights we were cooped up in the embassy.</p>
<p>I personally would miss their army ration packs on which we all lived, apart from rare welcome pizzas they brought back occasionally from goodness knows where by some of the patrols.</p>
<p>With impeccable timing, the day after they left, the Ambassador returned to post. Even he, not usually one to crack a joke at the best of times remarked tongue in cheek that in future he would give us ample warning of his next trip out of country so that we could be prepared for the next crisis. Not funny. Yes, by all means forewarn us of your next absence but make it far enough in advance so that I for one could also ensure I was not around as well!</p>

              </article></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/sas-rescue-trapped-diplomats-in-albania/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811306</guid>
            <pubDate>Sun, 12 Jul 2020 13:55:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Learning for Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811248">thread link</a>) | @0x54MUR41
<br/>
July 12, 2020 | https://thevaluable.dev/learning-developer-efficiently-effectively/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/learning-developer-efficiently-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/learning_developer/no-mistake.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/learning_developer/no-mistake.jpg" alt="Learning ">
                </picture>
            

            <p>“I’m trying to go down a bottomless pit. I’ll never make it till the end.”</p>
<p>That’s what I thought when I tried to create my own video game. I was young, beautiful, and I was struggling to use <code>for</code> loops and <code>arrays</code> at the same time.
There was so much to learn!</p>
<p>Fortunately, I found the strength to continue. More and more, the concepts behind programming began to make sense. From there, learning wasn’t a chore anymore, but an intrepid journey. Going through a book about C and trying to create my own adventure on MS-DOS was a crazy Indiana Jone’s-like discovery I’ll never forget.</p>
<p>My first video game wasn’t great, but it was mine. It was <em>my</em> creation. Yet, what I remember today, with a tear in my left eye, is not the result, but the learning process itself. It was these “Aha!” moments which brought me the most joy!</p>
<p>I love learning. For a long, long time. That’s why I tried, through the years, to make my learning gradually more effective and efficient.</p>
<p>Learning is essential for developers. We need to learn about the new breakthroughs, discoveries, and changes in the industry.</p>
<p>We need to learn about our history, to know what’s really new, what’s not, and what to do with it, <em>in what context</em>.</p>
<p>We need to learn about the business domain of the company we’re working with.</p>
<p>We need to learn how to better communicates with our teammates.</p>
<p>We need to learn about what our customers really want.</p>
<p>The list goes on and on.</p>
<p>As you might have guessed, this article will brush over the wide subject of learning, as a developer. We’ll try to answer these questions together:</p>
<ul>
<li>What’s learning?</li>
<li>Why do we learn? Should learning serve a goal?</li>
<li>How to avoid ineffective learning methods, procrastination, and distractions?</li>
<li>Should we have a mentor or learn by ourselves?</li>
<li>Is practice only makes perfect?</li>
<li>How to test ourselves to avoid the illusion of competence?</li>
<li>Are feedback important? What kind of feedback can you get? What feedback should you be interested in?</li>
</ul>
<p>Ready to dive? Good. Take your machete and let’s go together through the Deep Jungle of Knowledge.</p>
<h2 id="whats-learning">What’s learning?</h2>
<p>Sometimes, we can be very surprised of the meaning of common words. Especially if we never question their definitions.</p>
<p>For example, I’m always surprised to hear people saying that learning is only a question of memory. It’s not wrong, but it’s incomplete.</p>
<p>According to the <a href="https://www.lexico.com/definition/learning" target="_blank" rel="noopener">oxford dictionary</a>, learning means:</p>
<blockquote>
<p>The acquisition of knowledge or skills through study, experience, or being taught.</p>
</blockquote>
<p>This gives us clues about how to learn (study, experience, or being taught), but not really about the meaning of “acquisition of knowledge”.</p>
<p>Let’s look at the definition of <a href="https://www.lexico.com/definition/knowledge" target="_blank" rel="noopener">knowledge</a>:</p>
<blockquote>
<p>Facts, information, and skills acquired through experience or education; the theoretical or practical understanding of a subject.</p>
</blockquote>
<p>We can already see, thanks to these definitions, two main fundamentals for learning:</p>
<ol>
<li>Understanding</li>
<li>Remembering (acquisition)</li>
</ol>
<p>I’ll add a third one:</p>
<ol start="3">
<li>Transfer</li>
</ol>
<p>Transfer is applying the knowledge from the learning context to another context. For example, it could be applying the programming knowledge your learned at school to the side project you always dreamt to build.</p>
<p>Transfer is not a necessity for learning. After all, you can understand and remember something without ever using what you learned.</p>
<p>However, most of the time, we learn in hope to apply the knowledge acquired. That’s why it’s still a major component of our learning experiences.</p>
<h2 id="why-learning">Why Learning?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learn-good.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learn-good.jpg" alt="There is only good in learning">
</picture>



<h3 id="enriching-your-life">Enriching Your Life</h3>
<p>Learning will enrich your life in multiple ways:</p>
<ul>
<li>Your opinions will evolve.</li>
<li>Your vision on the world will change.</li>
<li>You’ll feel strong connections with people who share your interests, creating passionate and mind-binding conversations.</li>
</ul>
<p>Learning can open doors in your professional life:</p>
<ul>
<li>It can help you climbing the corporate ladder.</li>
<li>It can help you to negotiate a better salary. After all, we are <a href="https://en.wikipedia.org/wiki/Knowledge_worker" target="_blank" rel="noopener">knowledge workers</a>: our worth is <em>partly</em> our knowledge.</li>
<li>It will create opportunities for <a href="https://thevaluable.dev/guide-debate-software-developer-skill/">healthy debates with your fellow colleagues</a>.</li>
<li>Your CTO might call you <a href="https://thevaluable.dev/software-developer-titles-junior-senior/">“Rockstar” or “Ninja”</a> too, you lucky pit of knowledge!</li>
</ul>
<h3 id="learning-with-or-without-goals">Learning With or Without Goals?</h3>
<p>When you try to learn something, it’s useful to have concrete goals you want to achieve with the knowledge acquired. These goals could be a good occasion to <em>transfer</em> your knowledge.</p>
<p>For example, you want to learn programming because you always dreamt to create a revolutionary video game, where you can break bricks with a ball. Maybe you want to learn what’s the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, to finally refactor your favorite legacy application.</p>
<p>Without meaningful goals, it will be difficult to be motivated in the long run. Learning is not easy. Understanding can be a daunting task (depending of what you learn), remembering even more so, and transfer is maybe the worst of all.</p>
<p>It takes time, too. That’s why being able to reach concrete goals with your new skills and knowledge can be very satisfying. It will give you the needed motivation to continue on your learning path.</p>
<p>It’s even more true when you try to learn complex topics. Your motivation is something you should try to assess and even measure along the way, to see if you need to boost it by making (and finishing) something important to you.</p>
<p>It’s always possible to learn for the sake of learning. Heck, I do it quite a lot myself. Yet, you need to have a good confidence on your motivation, and you need to be aware of the benefits of the learning journey itself.</p>
<p>If you have difficulties to find concrete ideas and goals where you can transfer your new knowledge, I wrote a whole article about techniques <a href="https://thevaluable.dev/generate-programming-side-project-ideas/">to generate project ideas</a>.</p>
<h2 id="how-deep-do-you-want-to-go">How Deep Do You Want to Go?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/experts.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/experts.jpg" alt="Being an expert is not necessarily your goal">
</picture>



<p>Now that you have your goals, you need to decide <em>how much</em> you want to learn.</p>
<p>After all, you don’t need to be an expert in everything.</p>
<p>Moreover, knowledge acquisition is not like buying a new table for your living room. You need some maintenance not to forget the knowledge and skills acquired.</p>
<p>It means that you need to constantly refresh your knowledge and skills, for everything you want to be an expert at. It takes time, energy, and require, again, a lot of motivation.</p>
<p>For example, let’s say that your life’s dream is to write a PHP script to rename automatically thousands of your holidays pictures. You don’t need to be a PHP evangelist to answer your needs. Trying to understand superficially how PHP works to accomplish what you want might be enough.</p>
<p>Superficial learning works well if you don’t have any goal, too. You can read about programming paradigms for example, by pure curiosity, to have a global overview of all of them. You can still dive deeper if you wish later.</p>
<p>Beyond the superficial, the <a href="https://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition" target="_blank" rel="noopener">Dreyfus model of competence</a> can help you deciding how competent you want to become:</p>
<ul>
<li><strong>Novice</strong> - Shallow understanding, or no understanding at all.</li>
<li><strong>Advanced Beginner</strong> - Can make things works, often rely on following a series of steps.</li>
<li><strong>Competent</strong> - Can spot the roots of problems (background understanding), know all the rules and can select a rule depending of the situation. Still make many mistakes.</li>
<li><strong>Proficient</strong> - Very conscious about performance, know perfectly what approaches to take in what situation.</li>
<li><strong>Expert</strong> - Intuition very well developed, apply his skills without thoughts, performances look magical.</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=i1nzADdV6zk" target="_blank" rel="noopener">Choose your destiny</a>, depending on your needs!</p>
<h2 id="preparing-your-learning-sessions">Preparing Your Learning Sessions</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/learning_developer/learning-not-playing.jpg" alt="You need to prepare your environment to learn efficiently">
</picture>



<p>Let’s see now how you should prepare yourself before learning anything.</p>
<p>The following advice won’t change your life from one day to another. You need to work on it, actively seeking to apply these advice, day after day. The rewards are, however, huge. I promise.</p>
<h3 id="the-mistakes-to-avoid">The Mistakes to Avoid</h3>
<p>Let’s go back years in your past, when you were young, innocent, and not a caffeine junky yet.</p>
<p>You’re at school. The teacher is speaking about whatever subject he wants you to learn. His tone is monotonous, he doesn’t believe in what he’s saying, you think about what you’ll eat at lunch.</p>
<p>You’re bored.</p>
<p>The seconds feel like minutes. Minutes feel like hours. You can’t do anything, except waiting. Will it ever end? Will you feel joy again? Is it the end of time?</p>
<p>Finally, against all odds, the course end. The teacher ask you to learn a new chapter of your book. He will test you next time.</p>
<p>At home, you read again and again the learning material. You have difficulties to concentrate, but you’re a serious boy (or girl), so you push yourself through. After five reading, you judge yourself good enough to pass the next test.</p>
<p>You close your book, satisfied with yourself, and switch on the TV, because Youtube might not exist yet.</p>
<p>What I just described is the worst way to learn something. <em>Passively</em> listening to somebody, then <em>passively</em> going through some learning materials might teach you something, but very, very slowly. You don’t need to be in a class for that: just switch on Youtube and consume <em>passively</em> any video on programming.</p>
<p>When you close your book after your passive learning, you think you learned something. Yet, when you’ll pass your test, you’ll understand that you really didn’t.</p>
<p>This is called <strong>illusion of competence</strong>: we have often the <em>impression</em> we learned something, even if we didn’t.</p>
<p>You should spend most of your time <em>actively learning</em>. You need to be an actor in your own learning, not only consuming it like you would consume Netflix.</p>
<p>I would compare active learning as playing a video game. Yes, I was a video game junky.</p>
<p>When you play, you’re actively doing something. Consequently, I’m sure you can remember many more video games than what you read in your last books.</p>
<p>This is due to two things:</p>
<ol>
<li>Video games are fun. You can make your learning experience fun, too. More you’ll learn what you love, more you’ll like the process of learning.</li>
<li>Playing is an active endeavor, not a passive one.</li>
</ol>
<p>That being said, before actively learning, you need …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/learning-developer-efficiently-effectively/">https://thevaluable.dev/learning-developer-efficiently-effectively/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/learning-developer-efficiently-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811248</guid>
            <pubDate>Sun, 12 Jul 2020 13:45:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From 13 year old Drop Out to a $419M Business: Manitoba Harvest]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811073">thread link</a>) | @nicksalt
<br/>
July 12, 2020 | https://www.middaysquares.com/episode-10-uncensored | <a href="https://web.archive.org/web/*/https://www.middaysquares.com/episode-10-uncensored">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="SITE_ROOT" aria-hidden="false"><div id="masterPage" data-mesh-layout="grid"><main tabindex="-1" data-is-mobile="false" data-is-mesh="true" data-site-width="980" data-state="" id="PAGES_CONTAINER"><div id="PAGES_CONTAINERcenteredContent"><div id="PAGES_CONTAINERinlineContent"><div><div data-ismobile="false" data-is-mesh-layout="true" id="v657u"><div id="v657uinlineContent"><div id="v657uinlineContent-gridWrapper" data-mesh-internal="true"><div id="v657uinlineContent-gridContainer" data-mesh-internal="true"><div title="" data-is-responsive="false" data-display-mode="fill" data-content-padding-horizontal="0" data-content-padding-vertical="0" data-exact-height="360" id="comp-kcgd49i6"><div id="comp-kcgd49i6link"><wix-image data-has-bg-scroll-effect="" data-image-info="{&quot;imageData&quot;:{&quot;type&quot;:&quot;Image&quot;,&quot;id&quot;:&quot;dataItem-kcgd49i8&quot;,&quot;metaData&quot;:{&quot;pageId&quot;:&quot;v657u&quot;,&quot;isPreset&quot;:false,&quot;schemaVersion&quot;:&quot;2.0&quot;,&quot;isHidden&quot;:false},&quot;title&quot;:&quot;&quot;,&quot;uri&quot;:&quot;13e17e_035ed6ee0c224ef8aa4a962bb786388c~mv2.jpg&quot;,&quot;description&quot;:&quot;&quot;,&quot;width&quot;:1500,&quot;height&quot;:1500,&quot;alt&quot;:&quot;MidDaySquaresUncensored.jpg&quot;,&quot;name&quot;:&quot;MidDaySquaresUncensored.jpg&quot;,&quot;displayMode&quot;:&quot;fill&quot;},&quot;containerId&quot;:&quot;comp-kcgd49i6&quot;,&quot;displayMode&quot;:&quot;fill&quot;}" data-has-ssr-src="true" data-is-svg="false" data-is-svg-mask="false" id="comp-kcgd49i6img"><img id="comp-kcgd49i6imgimage" alt="MidDaySquaresUncensored.jpg" data-type="image" itemprop="image" src="https://static.wixstatic.com/media/13e17e_035ed6ee0c224ef8aa4a962bb786388c~mv2.jpg/v1/fill/w_216,h_216,al_c,q_80,usm_0.66_1.00_0.01,blur_2/MidDaySquaresUncensored.jpg"></wix-image></div></div><p data-packed="false" data-vertical-text="false" data-min-height="166" id="comp-kcgd49is"><h2><span><span><span><span>Episode 10:</span></span></span></span></h2>

<h2><span><span><span><span>From 13 year old Drop Out to a $419 Million Business: Manitoba Harvest</span></span></span></span></h2></p><wix-iframe data-has-iframe="true" data-src="https://www.wix.com/soundcloud-tpa/widget.html?cacheKiller=1594743207106&amp;compId=comp-kcgd49j8&amp;consent-policy=%7B%7BconsentPolicy%7D%7D&amp;dateNumberFormat=en-ca&amp;deviceType=desktop&amp;height=116&amp;instance=qkW7rvE35F_s-0NG_nXQyl6MKyp-uehTiE4rwOQeHlI.eyJpbnN0YW5jZUlkIjoiOGI2OWZjYTAtZmVmZi00MTJhLWI1MjctNzJiNGMwMDQxZjBmIiwiYXBwRGVmSWQiOiIxNGE4NWIxMy1kN2RhLWVlOGUtNzI5MC0zYjkzMzQwZjYzZmEiLCJtZXRhU2l0ZUlkIjoiZDMyOWFmZmQtOTU2Zi00Y2YwLWExOWQtNjk4MDllZWQ5ZTU1Iiwic2lnbkRhdGUiOiIyMDIwLTA3LTE1VDEyOjIxOjAyLjk5OVoiLCJkZW1vTW9kZSI6ZmFsc2UsImFpZCI6IjVlYTg3ZTYyLThiNDUtNDkzNi1iMjg0LTlmNjY0MWI0OTlkMSIsImJpVG9rZW4iOiI1ODQwNTM1ZC02YjkwLTBkZGEtMTRiYS0xYjM0NWVlOTgxNWEiLCJzaXRlT3duZXJJZCI6IjEzZTE3ZTc2LTVlNDItNDY5Zi1hODU3LTgyNzBjZjg4YTA4MiJ9&amp;isPrimaryLanguage=true&amp;lang=en&amp;locale=en&amp;pageId=v657u&amp;siteRevision=1349&amp;viewMode=site&amp;viewerCompId=comp-kcgd49j8&amp;width=547" data-is-tpa="true" data-widget-id="14a85b28-2374-72cf-db64-e0c11046aa60" data-app-definition-id="14a85b13-d7da-ee8e-7290-3b93340f63fa" id="comp-kcgd49j8"></wix-iframe><p data-packed="true" data-vertical-text="false" id="comp-kcgd49kj"><h6><span><span><span>Episode 10:</span></span></span></h6></p><div data-packed="false" data-vertical-text="false" data-min-height="200" id="comp-kcgd49ku"><p>This is our first ever episode in <span>"The Interview" Series</span>.</p>



<p>We welcome Mike Fata to the show, founder of Manitoba Harvest.</p>



<p>-We start at the early beginning of the idea all the way through the sale of the company for $419 million dollars.</p>



<p>-We talk about the education system. How hemp went from being illegal to being legal. How he got the business started.</p>



<p>-Starting small and scaling very large. How pivotal universities and governments can be in scaling your business. The difficulties of starting a business where you have to educate the entire category on why they should demand it.</p>



<p>-Lastly, why being early can pay you huge!</p></div><p data-packed="true" data-vertical-text="false" id="comp-kcgd49l1"><h6><span><span><span>Join +10,000 Crewlove and be apart of Mid-day Squares as we build the Company and meet Epic people along the way!</span></span></span></h6></p></div></div></div></div></div></div></div></main></div></div></div>]]>
            </description>
            <link>https://www.middaysquares.com/episode-10-uncensored</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811073</guid>
            <pubDate>Sun, 12 Jul 2020 13:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shadow Daemon – a web application firewall]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23811061">thread link</a>) | @realpanzer
<br/>
July 12, 2020 | https://shadowd.zecure.org/overview/introduction/ | <a href="https://web.archive.org/web/*/https://shadowd.zecure.org/overview/introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="main-content">
        <section>
          <div>
            <div>
              <section>
                <div>
                  



<p><img id="logo" src="https://shadowd.zecure.org/img/logo_small.png"></p>

<h2 id="what-is-shadow-daemon:2767292a573dc549b9b4297b701af3ab">What is Shadow Daemon?</h2>

<p><em>Shadow Daemon</em> is a collection of tools to <em>detect</em>, <em>record</em>, and <em>block</em> <em>attacks</em> on <em>web applications</em>.
Technically speaking, Shadow Daemon is a <em>web application firewall</em> that intercepts requests and filters out malicious parameters.
It is a modular system that separates web application, analysis, and interface to increase security, flexibility, and expandability.</p>

<p>Shadow Daemon is <a target="_blank" href="https://www.gnu.org/philosophy/free-sw.html">free software</a>. It is released under the license <a href="https://shadowd.zecure.org/about/license/">GPLv2</a>, so it is open source and the code can be examined, modified, and distributed by everyone.</p>

<h2 id="what-differentiates-shadow-daemon:2767292a573dc549b9b4297b701af3ab">What differentiates Shadow Daemon?</h2>

<h3 id="ease-of-use:2767292a573dc549b9b4297b701af3ab">Ease of use</h3>

<p>Shadow Daemon is easy to install and can be managed with a clear and structured web interface that lets you examine attacks in great detail.</p>

<p>The interface also comes with shell scripts that can be used to send weekly reports via e-mail, rotate the logs, and the like.</p>




<h3 id="high-coverage:2767292a573dc549b9b4297b701af3ab">High coverage</h3>

<p>Shadow Daemon uses small connectors on application level to intercept requests.
This guarantees that the analyzed data is exactly the same as the input data of the web application, a task many firewalls fail to do properly.
The installation of the connectors is easy and does not require coding abilities.</p>

<p>At the moment the following programming languages, libs, and frameworks are supported:</p>

<ul>
<li>PHP</li>
<li>Perl

<ul>
<li>CGI</li>
<li>Mojolicious</li>
<li>Mojolicious::Lite</li>
</ul></li>
<li>Python

<ul>
<li>CGI</li>
<li>Django</li>
<li>Werkzeug</li>
<li>Flask</li>
</ul></li>
</ul>

<p>Additional connectors are planned and will be released at some point in the future.
If you want to <a href="https://shadowd.zecure.org/development/contributing/">contribute</a> why not develop a new <a href="https://shadowd.zecure.org/documentation/connectors/">connector</a>?</p>

<h3 id="accurate-detection:2767292a573dc549b9b4297b701af3ab">Accurate detection</h3>

<p>Shadow Daemon combines <a href="https://shadowd.zecure.org/documentation/blacklist/">blacklisting</a>, <a href="https://shadowd.zecure.org/documentation/whitelist/">whitelisting</a>, and <a href="https://shadowd.zecure.org/documentation/integrity/">integrity checking</a> to accurately detect malicious requests.
The blacklist makes use of sophisticated regular expressions to search for known attack patterns in the user input.
The whitelist on the other hand searches for irregularities in the user input based on strict rules that define how the input should look like.
The integrity check compares cryptographically secure checksums of the executed scripts against predefined values.</p>

<p>Together they can detect almost any attack on a web application and still have a very low false-positive rate.</p>

<p>Shadow Daemon is able to detect common attacks like:</p>

<ul>
<li>SQL injections</li>
<li>XML injections</li>
<li>Code injections</li>
<li>Command injections</li>
<li>Cross-site scripting</li>
<li>Local/remote file inclusions</li>
<li>Backdoor access</li>
<li>And more …</li>
</ul>

<h3 id="discreet-protection:2767292a573dc549b9b4297b701af3ab">Discreet protection</h3>

<p>Unlike many other web application firewalls Shadow Daemon does not completely block malicious requests if possible.
Instead it only filters out the dangerous parts of a request and lets it proceed afterwards.
This makes attacks impossible, but does not unnecessary frustrate visitors in the case of false-positives.</p>

<h3 id="secure-architecture:2767292a573dc549b9b4297b701af3ab">Secure architecture</h3>

<p>Shadow Daemon is closer to the application than most other web application firewalls.
It receives <em>exactly</em> the same input that the web application receives and thus it is almost impossible to bypass the detection by obfuscating the attack.
However, the most complex parts of Shadow Daemon are separated from the web application to guarantee a certain standard of security.</p>

<h2 id="who-should-use-shadow-daemon:2767292a573dc549b9b4297b701af3ab">Who should use Shadow Daemon?</h2>

<p>Shadow Daemon is for people who want to run their own dynamic website without constantly having to worry about attacks and vulnerabilities.</p>

<p>Shadow Daemon is for people who want to know if and how their website is attacked.</p>

<p>Shadow Daemon is for people who do not want to blindly place their trust in closed-source software that does its work in secret and costs a fortune.</p>

<h2 id="how-do-i-install-shadow-daemon:2767292a573dc549b9b4297b701af3ab">How do I install Shadow Daemon?</h2>

<p><em>Getting Started</em> contains everything you need to know. Start by reading <a href="https://shadowd.zecure.org/overview/shadowd/">shadowd</a>.
Installing Shadow Daemon is easy and only takes some minutes, really.</p>

<h2 id="how-can-i-follow-the-development-of-shadow-daemon:2767292a573dc549b9b4297b701af3ab">How can I follow the development of Shadow Daemon?</h2>

<p>The development of Shadow Daemon takes place at <a href="https://github.com/zecure">Github</a>.
Announcements are published via <a href="https://twitter.com/zecureit">Twitter</a>.
Make sure to star/follow to stay up to date.</p>

<figure>
 <a href="https://github.com/zecure">
  <img src="https://shadowd.zecure.org/img/octocat.png" height="100px">
  <figcaption><h4>Github</h4></figcaption>
 </a>
</figure>

<figure>
 <a href="https://twitter.com/zecureit">
  <img src="https://shadowd.zecure.org/img/twitter.png" height="90px">
  <figcaption><h4>Twitter</h4></figcaption>
 </a>
</figure>

<h2 id="do-you-want-more-security:2767292a573dc549b9b4297b701af3ab">Do you want more security?</h2>

<p>Shadow Daemon is a passive security system.
It intercepts requests and tries to block attacks on your web applications.
If this is not enough for you and you want to actively find and fix vulnerabilities in your PHP and Java applications to reduce the attack surface to an absolute minimum you should check out the <em>source code analyser</em> <a href="https://www.ripstech.com/">RIPS</a>.</p>

<p>The new <a href="https://www.ripstech.com/">RIPS</a> engine is armed with innovative code analysis algorithms that are specifically dedicated to the intricate features of the PHP and Java languages.
It is capable of analyzing modern applications for complex security vulnerabilities within minutes.
The full feature stack of both languages is supported, including object-oriented code, pitfall-prone security mechanisms, and built-in functions.
Security vulnerabilities are accurately detected by analyzing the data flow from user-controlled input parameters to sensitive operations in your application with 100% code coverage.</p>

                </div>
              </section>
            </div>
          </div>
          
        </section>
      </section></div>]]>
            </description>
            <link>https://shadowd.zecure.org/overview/introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23811061</guid>
            <pubDate>Sun, 12 Jul 2020 13:10:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming Languages as Objects in Nature]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810998">thread link</a>) | @matt_d
<br/>
July 12, 2020 | https://parentheticallyspeaking.org/articles/pls-nature/ | <a href="https://web.archive.org/web/*/https://parentheticallyspeaking.org/articles/pls-nature/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>In the early 1990s, the programming languages research community was in an
optimistic mood. In the recent past, two of its paradigmatic languages—<wbr>Scheme
and ML—<wbr>had formalized their semantics. For ML, it took the form of a whole
book by Milner, et al. Scheme provided a denotational semantics in its
standard. Surely, it seemed, it was only a matter of time before all languages
went in this direction.</p><p>What went wrong?</p><blockquote><p>If you’re a working programmer without a theoretical background, you might
wonder why a formal semantics matters at all. It’s actually for reasons you can
understand easily. When you write programs against code that someone else
wrote, you like having an interface, or <span>API</span>, to program against. It mediates
your conversation with the remote code, and anchors conversations about whom to
blame if something doesn’t work as expected.</p><p>The formal semantics of a language does exactly the same thing. The language
itself is the “remote code” you’re programming against. What it does should
be pinned down as precisely as possible—<wbr>but also as understandably as
possible!—<wbr>for you to work with.</p><p>The semantics isn’t just an interface for the user of a language. It’s also a
crucial interface for tool authors, who must (also) otherwise guess at the
behavior of the language. If you want an example of how even the relatively
simple act of a variable rename refactoring can go wrong, see Appendix 2 of
our <a href="https://cs.brown.edu/~sk/Publications/Papers/Published/pmmwplck-python-full-monty/">Python semantics</a>. A semantics
doesn’t guarantee those kinds of errors won’t occur, but its absence makes them
far more likely to.</p></blockquote><p>For many researchers, it’s a given that programming languages are
<span>mathematical</span> objects. This is a natural and attractive view. Languages
are formal objects, after all; they are therefore amenable to codification by
everything from logic to topology and more. (Formal) Specification is a natural
consequence of this worldview.</p><p>The world, however, is full of programming languages that do not fit this
model.<span><span><span>Some may even have been created by programming language
semanticists, which is worth pondering.</span></span></span> Created by the ostensibly unwashed,
they rudely announce their arrival with nothing more than an
implementation. People pick them up, find them useful, do worthwhile things
with them, and a million lines later, the next big “scripting language” is
born. Let’s call these <span>informal</span> languages.</p><p>Informal languages are, of course, also amenable to formal specification. However,
a crucial difference governs these two types of languages. Suppose we observe a
difference between what the specification says and what the implementation
does. In the case of Standard ML, for instance, one can approach the
implementor, walk through the reasoning in the specification, and explain why
the implementation is wrong. If the implementor agrees with your reasoning, no
matter how unhappy this makes them, they must admit to and eventually fix their
implementation.</p><p>The implementor of an informal language faces no such constraint. Faced with a
mismatch between an ostensible specification and their implementation, they are
free to simply laugh, question the specification’s parentage, and exit stage
right. The specification can <span>at best</span> track what “the language is
doing”, not really dictate its behavior.</p><p>Specification still serves a role. It can:
</p><div><ul><li><p>Shed light on what is happening inside a large and otherwise opaque
implementation.</p></li><li><p>Point out complex designs that would warrant being simplified.</p></li><li><p>Highlight design aspects that are prone to cause programmer error,
security violations, and so on.</p></li><li><p>Serve all the other uses of a specification, such as serving as a basis
for building tools.</p></li></ul></div><p>To do all these things <span>usefully</span>, however, the specification must take
significant steps to show its conformance to the reality of the informal
language, such as by running the same test suites as the implementations.</p><p>An informal language, then, is much more like an object found in nature:</p><p><img src="https://parentheticallyspeaking.org/articles/pls-nature/rock.jpg" alt="A rock."></p><p>We can push at it, poke it, and prod it, and hope that it will yield its
secrets. But we can never be certain—<wbr>without the help of the
implementors—<wbr>that we have properly characterized all of it.</p><p>That doesn’t mean we can’t approach the problem systematically. Geologists,
confronted with a rock, don’t flail helplessly. In high-school chemistry, I was
taught to approach unknown substances with the <span>SCODS</span> test: check for its
state, color, odor, density, and solubility.<span><span><span>They never included a letter
for “taste”, a reflection perhaps more of their aspiration than of the
reality in a high school chemistry lab.</span></span></span> That is, we identify some of
dimensions of classification, and proceed along the principal axes.</p><p>We have these axes for programming languages, too. We can talk about their
scope rules, their evaluation semantics, their type system, and so on. Indeed,
because so much of a programmer’s career will be spent confronting informal
languages and having to rapidly make sense out of them, I’ve long felt that how
we <span>teach</span> programming languages should
<a href="https://cs.brown.edu/~sk/Publications/Papers/Published/sk-teach-pl-post-linnaean/">also be divided along these
dimensions</a>.</p><p>The problem of informal languages will not go away, so long as a dedicated
amateur can scare up a new language’s implementation. Indeed, the size of our
informal language space grows ever-bigger, and vastly so, than that of
mathematical languages. In 2015, I made this slide:</p><p><img src="https://parentheticallyspeaking.org/articles/pls-nature/stack.png" alt="Our programming stack." width="560" height="420"></p><p>It shows the stack atop which a typical client-side Web program of the day
resided. What it actually shows is something much more subtle and important:</p><p><span>Programmers do not program in “languages”.</span></p><p>Rather, they program in some complex combination of languages, libraries,
frameworks (which can impose their own operational behavior—<wbr>e.g., seemingly
turn a call-by-value language into a reactive one), and more. What a programmer
needs is a semantics not just for the language sitting near the bottom, but
rather for the mountain on top of which their program resides.</p><p>For illustrative examples of what such semantics might look like, see our work
on the <a href="https://cs.brown.edu/~sk/Publications/Papers/Published/lckqk-model-reason-dom-events/">operational semantics of
the <span>DOM</span></a> (it’s a giant control operator, y’all!), and
<a href="https://cs.brown.edu/~sk/Publications/Papers/Published/lelk-types-jquery-programs/">the type structure of jQuery</a>. But
these are just a tiny sliver of a tiny sliver. How do we make real progress up
the mountain and keep our position there as it keeps thrusting further out of
the ground?</p><p>We can’t expect the date-picker library’s author to also be a semanticist. But
we shouldn’t therefore resignedly conclude that we can never get there. Rather,
we should acknowledge that there are useful divisions of labor. Instead of
scolding informal language designers for their practices, semanticists need to
find methods to bridge that gap, keeping in mind:</p><blockquote><p><span>One can’t proceed from the informal to the formal by formal means.<br></span></p></blockquote><p>Whatever we propose needs to be:
</p><div><ul><li><p>Reasonable (in terms of skill) for the implementor to produce.</p></li><li><p>Useful for them to produce.</p></li><li><p>Useful for us to consume and work with.</p></li></ul></div><p>One especially good intermediate proxy is a test suite of some sort. Tests
don’t always get the respect they deserve, but they too are a form of
specification. I like to call them “specifications from below”, precisely
defining what should happen in individual cases, whereas the typical formal
specification is “specification from above”, defining what happens across a
family of cases. Ultimately, of course, we need specifications “from above”,
but it’s worth noting that specifications “from below” are both useful to
developers and something they are skilled at producing. The recent trend in
languages of producing “confirmance suites” or “litmus tests” is especially
promising in this regard. (Our work on formalizing the
<a href="https://cs.brown.edu/~sk/Publications/Papers/Published/pclpk-s5-semantics/">strict mode of of ECMAScript 5.1</a>,
for instance, made use of the ECMAScript conformance suite.)</p><p>How we use them remains a little bit of an open question. The most obvious use
is to test our semantics: what Arjun Guha and I, to perhaps the horror
of some, called a <span>tested semantics</span>. But we might also be able to
generalize these tests, from “below” to “above”, i.e., it’s a synthesis
problem. This requires some structure to produce a semantics that is also
meaningful. Our paper on <a href="https://cs.brown.edu/~sk/Publications/Papers/Published/kle-next-700-semantics//">The Next 700
Semantics</a> describes some of the contours for this line of work to consider.</p></div></div></div>]]>
            </description>
            <link>https://parentheticallyspeaking.org/articles/pls-nature/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810998</guid>
            <pubDate>Sun, 12 Jul 2020 13:00:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Warhammer 40k Digital Strategy and Opportunities]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810941">thread link</a>) | @iamacyborg
<br/>
July 12, 2020 | https://www.jacquescorbytuech.com/writing/warhammer-digital-app-opportunities-strategy | <a href="https://web.archive.org/web/*/https://www.jacquescorbytuech.com/writing/warhammer-digital-app-opportunities-strategy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>To coincide with the launch of Warhammer 40k 9th edition, Games Workshop <a href="https://www.warhammer-community.com/2020/07/09/the-app-all-you-need-to-know/">recently announced</a> the release of their first dedicated app for the 40k franchise.</p>
<p>This app will finally allow 40k players to easily check core game rules and rules for any additional supplements or codexes they purchase. A modest £3.99 monthly subscription will also allow app users to have access to an army list builder and enhanced referencing, the latter of which seems to imply some sort of enhanced search but isn't clear.</p>
<p>The digitisation of codexes has been a long time coming, allowing app users to easily navigate rules that are always up to date. Previously, a gamer would have to have a physical copy of the book, plus various rules errata and FAQ's acquired online which are designed to clarify and amend rules to aid ongoing balancing.</p>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/warhammerApp.png"><img alt="40k App" src="https://d33wubrfki0l68.cloudfront.net/d9fa64d781dbdbf73634bb4e67d42f616a67c92e/500de/images/post-images/warhammerapp.png"></a></p>
<p>The army list builder in particular seems to be a smart move and a sign of Games Workshop's ongoing strategic initiatives, <em>more on that later</em>.</p>
<p>From a cost perspective, £3.99 is modest, however Games Workshop are directly competing here with fan-built <a href="https://battlescribe.net/">BattleScribe</a> and <a href="http://wahapedia.ru/">Wahapedia</a>. I'm not an advocate for piracy however the reality is Games Workshop have lagged in this area and it's  unsurprising that, with their <a href="https://www.games-workshop.com/en-GB/Codex-Space-Marines-HB-EN-2019">pricing</a> <a href="https://www.games-workshop.com/en-GB/Codex-Salamanders-EN-2019">strategy</a>, they're having to directly compete with pirate products. People don't want to pay £25+ just to understand how to play the game.</p>
<p>This app has been a long time coming, and it's a total no-brainer following the huge success of <a href="https://www.dndbeyond.com/">D&amp;D Beyond</a> (DDB) built by the awesome folks at Curse (I worked there pre-DDB days). From a cost perspective DDB subscriptions are a little more attractive, however folks have long complained that purchases of physical books don't allow them to get access to the relevant books and features in DDB with having to additionally purchase the digital content too.</p>
<h2>Warhammer Digital Strategy</h2>
<p>There are obvious shortcomings from this being an app based product. Since 2016 Games Workshop have made huge headway in the way they interact with their community through the <a href="https://www.warhammer-community.com/">Warhammer Community</a> site, with a large focus and investment in written and video content. Unlike DDB however this community aspect is currently relatively limited, there are no forums offered or ways for players to share their love of the hobby directly with other players.</p>
<p>According to the most recent<sup id="fnref:halfyear"><a href="#fn:halfyear">1</a></sup> half-year report:</p>
<blockquote>
<p>Communities and customer engagement - we have continued to build new communities, opening 12 stores in the period and c.200 trade accounts. Our digital engagement continues to increase in reach and scope. Users accessing Warhammercommunity.com over the six month period are up 48% compared to the same period last year and sessions per user have also increased, meaning our fans are visiting more often and are more engaged with the content</p>
</blockquote>
<p>48% YoY user growth for an already well established website is hugely impressive, as is the increase in sessions per user, though I think that can be attributed more to an increase in posts rather than an increase in engagement on the site.</p>
<p>The missing piece of the puzzle for Warhammer Community is exploiting user generated content, there are <a href="https://www.reddit.com/r/Warhammer40k/">huge</a> <a href="https://www.dakkadakka.com/">thriving</a> <a href="http://www.bolterandchainsword.com/">communities</a> of passionate fans sharing everything from gaming tips to painting guides to photos of <a href="http://www.coolminiornot.com/topweek">incredible miniatures</a>.</p>
<p>Furthermore, a significant portion of Games Workshop's community outreach work is done through third party social media websites, which represents significant risks. An owned platform would eliminate these risks.</p>
<p>Given the strong social aspect of the game and the fact that Games Workshop have 517 stores in 23 countries around the world (plus an additional ~4,700 independent retailers), there's also a strong argument to be made for a need to more localise the digital experience at the community level, in a way that can be used to build player engagement with their local store. Retail represents 34%<sup id="fnref:annualreport"><a href="#fn:annualreport">2</a></sup> of sales so is a critical path to building engagement and sales.</p>
<p>A digital experience would allow store managers to easily organise and plan games and events for their local community, while giving the community and prospective buyers an easy way to join the hobby at their own pace. </p>
<p>It's easy to forget, but retail stores should not be judged solely on the revenue they bring in directly. By being on the high street, Warhammer stores attract new players to the hobby and provide key avenues in creating great customer experiences - bridging that digital gap would provide a combined digital storefront and community so that customers can experience the great retail environment in the comfort of their own home.</p>
<p>Snuck into the announcement is a mention of a <strong>My Warhammer</strong> account. While mentioning no details at all, the move towards creating a single sign-on across all Warhammer experiences would be a tremendous boost in better understanding customer behaviour.</p>
<h2>Warhammer Digital Opportunities</h2>
<p>In late October last year, Games Workshop migrated their marketing emails from Mailchimp to Selligent. That might not sound like a big deal to the average 40k fan, but I've been in marketing long enough to understand what a platform like Selligent can bring to a retail business when properly integrated.</p>
<p>While I've not yet noticed any significant personalisation when it comes to their email program, there are hints available that Games Workshop may soon take this channel seriously.</p>
<p>A quick look at their website shows that they're starting to integrate Selligent tracking on their main retail store and their more specialised <a href="https://www.forgeworld.co.uk/en-GB/FW-Home">Forge World</a> store.</p>
<div><pre><span></span><span>&lt;</span><span>script</span><span>&gt;</span>
    <span>var</span> <span>trackdata</span> <span>=</span> <span>trackdata</span> <span>||</span> <span>[];</span>

    <span>(</span><span>function</span> <span>(</span><span>d</span><span>,</span> <span>s</span><span>,</span> <span>id</span><span>)</span> <span>{</span>
        <span>var</span> <span>js</span><span>,</span> <span>sjs</span> <span>=</span> <span>d</span><span>.</span><span>getElementsByTagName</span><span>(</span><span>s</span><span>)[</span><span>0</span><span>];</span>
    <span>if</span> <span>(</span><span>d</span><span>.</span><span>getElementById</span><span>(</span><span>id</span><span>))</span> <span>return</span><span>;</span>
        <span>js</span> <span>=</span> <span>d</span><span>.</span><span>createElement</span><span>(</span><span>s</span><span>);</span> <span>js</span><span>.</span><span>id</span> <span>=</span> <span>id</span><span>;</span>
        <span>js</span><span>.</span><span>src</span> <span>=</span> <span>"//games-workshop.slgnt.eu/optiext/webtracker.dll"</span><span>;</span>
        <span>sjs</span><span>.</span><span>parentNode</span><span>.</span><span>insertBefore</span><span>(</span><span>js</span><span>,</span> <span>sjs</span><span>);</span>
    <span>}(</span><span>document</span><span>,</span> <span>'script'</span><span>,</span> <span>'webtracker'</span><span>));</span>
<span>&lt;/</span><span>script</span><span>&gt;</span>
</pre></div>
<p>Selligent will also allow them to use push and in-app messaging and more importantly for a business like Games Workshop, will allow them to use location based messaging based on an app users proximity to a retail store.</p>
<p>From a CRM program perspective, Games Workshop will not only know exactly what content and products a customer has looked at and purchased online and in-store, but by using prior purchase history they'll be able to personalise product recommendations based on army lists created by an app user.</p>
<p>To maximise this latter opportunity, Games Workshop should make the list builder part of the free content available in the app and should roll out a web app to maximise the number of gamers providing valuable personalisation data.</p>
<p>The Games Workshop online store should become a highly personalised system that would reduce marketing and merchandising costs while delivering a higher ROI.</p>
<p>It should be a no-brainer that Games Workshop make direct purchasing of additional rules possible within their app. With the data they'll be capturing not only will they be able to sell digital content directly, but with campaign books they'll be able to directly sell rules as microtransactions. For example a Death Guard player may simply want to purchase the new rules for DG units available from the <a href="https://www.games-workshop.com/en-GB/Psychic-Awakening-War-Of-The-Spider-EN-2020">War of the Spider</a> supplement without shelling out for the whole book.</p>
<p><a href="https://www.jacquescorbytuech.com/images/post-images/ddbMicrotransactions.png"><img alt="Microtransactions on DDB" src="https://d33wubrfki0l68.cloudfront.net/89b87489d23a21ab8eb9cac30c031e4916ddf1b5/9bbc8/images/post-images/ddbmicrotransactions.png"></a></p>
<p><em>Microtransactions on DDB</em>.</p>
<p>Providing support for a <a href="https://www.jacquescorbytuech.com/writing/mobile-wallet-marketing">digital wallet</a> would not only allow Games Workshop to collect information about purchases through digital loyalty cards, but the scheme could be rolled out to all 4,700 independent retailers. This would allow Games Workshop to know not only what an individual has purchased directly from them, but also from their trade network which represents 47% of all sales.</p>
<p>Finally, Warhammer Community needs to be directly integrated into the online shopping experience. Gamers should be able to directly purchase products from news pages.</p>

<p>Cheers,</p>
<p><img src="https://www.jacquescorbytuech.com/images/jacques.png">
</p></div></div>]]>
            </description>
            <link>https://www.jacquescorbytuech.com/writing/warhammer-digital-app-opportunities-strategy</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810941</guid>
            <pubDate>Sun, 12 Jul 2020 12:50:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Merging and Patches (2017)]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23810902">thread link</a>) | @lelf
<br/>
July 12, 2020 | https://jneem.github.io/merging/ | <a href="https://web.archive.org/web/*/https://jneem.github.io/merging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    <time datetime="2017-05-08T00:00:00+00:00">May 08, 2017</time>
  </header>
<p>A <a href="https://arxiv.org/abs/1311.3903">recent paper</a> suggested a new mathematical
point of view on version control. I first found out about it from <code>pijul</code>,
a new version control system (VCS) that is loosely inspired by that paper. But
if you poke around the <code>pijul</code> <a href="https://pijul.com/">home page</a>, you won’t find
many details about what makes it different from existing VCSes. So I did a bit
of digging, and this series of blog posts is the result.</p>

<p>In the first part (i.e. this one), I’ll go over some of the theory developed in
the paper. In particular, I’ll describe a way to think about patches and
merging that is guaranteed to never, ever have a merge conflict. In the second
part, I’ll show how <code>pijul</code> puts that theory into action, and in the third part
I’ll dig into <code>pijul</code>’s implementation.</p>

<p>Before getting into some patch theory, a quick caveat: any real VCS needs to
deal with a lot of tedious details (directories, binary files, file renaming,
etc.). In order to get straight to the interesting new ideas, I’ll be skipping
all that. For the purposes of these posts, a VCS only needs to keep track of
a single file, which you should think of as a list of lines.</p>



<p>A patch is the difference between two files. Later in this series we’ll be
looking at some wild new ideas, so let’s start with something familiar and
comforting. The kind of patches we’ll discuss here go back to the early days of
Unix:</p>

<ul>
  <li>a patch works line-by-line (as opposed to, for example, word-by-word); and</li>
  <li>a patch can add new lines, but not modify existing lines.</li>
</ul>

<p>In order to actually have a useful VCS, you need to be able to delete lines
also. But deleting lines turns out to add some complications, so we’ll deal
with them later.</p>

<p>For an example, let’s start with a simple file: my to-do list for this morning.</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_1.svg" alt=""></p>

<p>Looking back at the list, I realize that I forgot something important. Here’s the new one:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_2.svg" alt=""></p>

<p>To go from the original to-do list to the new one, I added the line with the
socks. In the format of the original Unix “diff” utility, the patch would look like this:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_3.svg" alt=""></p>

<p>The “1a2” line is a code saying that we’re going to add something after line 1 of the
input file, and the next bit is obviously telling us what to insert.</p>

<p>Since this blog isn’t a command line tool, we’ll represent patches with pretty diagrams
instead of flat files. Here’s how we’ll draw the patch above:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_4.svg" alt=""></p>

<p>Hopefully it’s self-explanatory, but just in case: an arrow goes from left to
right to indicate that the line on the right is the same as the one on the
left. Lines on the right with no arrow coming in are the ones that got added.
Since patches aren’t allowed to re-order the lines, the lines are guaranteed
not to cross.</p>

<p>There’s something implicit in our notation that really needs to be said out
loud: for us, <b>a patch is tied to a specific input file</b>. This is the first point
where we diverge from the classic Unix ways: the classic Unix patch that we
produced using “diff” could in principle be applied to <em>any</em> input file, and it
would still insert “* put on socks” after the first line. In many cases that
wouldn’t be what you want, but sometimes it is.</p>



<p>The best thing about patches is that they can enable multiple people to edit
the same file and then merge their changes afterwards. Let’s suppose that my
wife also decides to put things on my to-do list: she
takes the original file and adds a line:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_5.svg" alt=""></p>

<p>Now there are two new versions of my to-do list: mine with the socks, and my
wife’s with the garbage. Let’s draw them all together:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_6.svg" alt=""></p>

<p>This brings us to merging: since I’d prefer to have my to-do list as a single
file, I want to merge my wife’s changes and my own. In this example, it’s
pretty obvious what the result should be, but let’s look at the general problem
of merging. We’ll do this slowly and carefully, and our endpoint might be
different from what you’re used to.</p>

<h2 id="patch-composition">Patch composition</h2>

<p>First, I need to introduce some notation for an obvious concept: the
<em>composition</em> of two patches is the patch that you would get by applying one
patch and then applying the other. Since a “patch” for us also includes the
original file, you can’t just compose any two old patches. If <code>p</code> is a patch
taking the file <code>O</code> to the file <code>A</code> and <code>r</code> is a patch taking <code>A</code> to <code>B</code>, then
you can compose the two (but only in one order!) to obtain a patch from <code>O</code> to
<code>B</code>. I’ll write this composition as <code>pr</code>: first apply <code>p</code>, then <code>r</code>.</p>

<p>It’s pretty easy to visualize patch composition using our diagrams: to compute
the composition of two paths, just “follow the arrows”</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_7.svg" alt=""></p>

<p>to get the (dotted red) patch going from <code>O</code> to <code>B</code>.</p>

<h2 id="merging-as-composition">Merging as composition</h2>

<p>I’m going to define carefully what a merge is in terms of patch composition.
I’ll do this in a very math-professor kind of way: I’ll give a precise
definition, followed by some examples, and only afterwards will I explain
why the definition makes sense.
So here’s the definition: if <code>p</code> and <code>q</code> are two different patches
taking the file <code>O</code> to the files <code>A</code> and <code>B</code> respectively, a <em>merge</em> of <code>p</code> and <code>q</code>
is a pair of patches <code>r</code> and <code>s</code> such that</p>

<ul>
  <li><code>r</code> and <code>s</code> take <code>A</code> and <code>B</code> respectively to a common output file <code>M</code>, and</li>
  <li><code>pr = qs</code>.</li>
</ul>

<p>We can illustrate this definition with a simple diagram, where the capital
letters denote files, and the lower-case letters are patches going between
them:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_8.svg" alt=""></p>

<p>Instead of saying that <code>pr = qs</code>, a mathematician (or anyone who wants
to sound fancy) would say that the diagram above <em>commutes</em>.</p>

<p>Here is an example of a merge:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_9.svg" alt=""></p>

<p>And here is an example of something that is not a merge:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_10.svg" alt=""></p>

<p>This is not a merge because it fails the condition <code>pr = qs</code>: composing the
patches along the top path gives</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_11.svg" alt=""></p>

<p>but composing them along the bottom path gives</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_12.svg" alt=""></p>

<p>Specifically, the two patches disagree on which of the shoes in the final list
came from the original file. This is the real meaning underlying the condition
<code>pr = qs</code>: it means that there will never be any ambiguity about which lines
came from where. If you’re used to using <code>blame</code> or <code>annotate</code> commands with
your favorite VCS, you can probably imagine why this sort of ambiguity would be
bad.</p>

<h2 id="a-historical-note">A historical note</h2>

<p>Merging patches is an old idea, of course, and so I just want to briefly
explain how the presentation above differs from “traditional” merging:
traditionally, merging was defined by algorithms (of which there are
<a href="https://en.wikipedia.org/wiki/Merge_(version_control)#Merge_algorithms">many</a>). These algorithms would try to automatically find a good merge; if
they couldn’t, you would be asked to supply one instead.</p>

<p>We’ll take a different approach: instead of starting with an algorithm, we’ll
start with a list of properties that we want a good merge to satisfy. At the end,
we’ll find that there’s a unique merge that satisfies all these properties
(and fortunately for us, there will also be an efficient algorithm to find it).</p>



<p>The main problem with merges is that they aren’t unique. This isn’t a huge
problem by itself: lots of great things aren’t unique. The problem is that we
usually want to merge automatically, and an automatic system needs an
unambiguous answer. Eventually, we’ll deal with this by defining a special
class of merges (called perfect merges) which will be unique. Before that,
we’ll explore the problem with some examples.</p>

<h2 id="a-silly-example">A silly example</h2>

<p>Let’s start with a silly example, in which our merge tool decides to
add some extra nonsense:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_13.svg" alt=""></p>

<p>No sane merge tool would ever do that, of course, but it’s still a valid
merge according to our rule in the last section. Clearly, we’ll have
to tighten up the rules to exclude this case.</p>

<h2 id="a-serious-example">A serious example</h2>

<p>Here is a more difficult situation with two merges that are actually
reasonable:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_14.svg" alt=""></p>

<p>Both of these merges are valid according to our rules above, but you need to
actually know what the lines <em>mean</em> in order to decide that the first merge is
better (especially if it’s raining outside). Any reasonable automatic merging
tool would refuse to choose, instead requiring its user to do the merge
manually.</p>

<p>The examples above are pretty simple, but how would you decide in general
whether a merge is unambiguous and can be performed automatically? In existing
tools, the details depend on the merging algorithm. Since we started off with
a non-algorithmic approach, let’s see where that leads: instead of specifying
explicitly which merges we can do, we’ll describe the properties that an ideal
merge should have.</p>



<p>The main idea behind the
definition I’m about to give is that it will never cause any regrets. That is,
no matter what happens in the future, we can always represent the history just
as well through the merge as we could using the original branches. Obviously,
that’s a nice property to have; personally, I think it’s non-obvious why it’s
a good choice as the <em>defining</em> property of the ideal merge, but we’ll get to
that later.</p>

<p>Ok, here it comes. Consider a merge:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_15.svg" alt=""></p>

<p>And now suppose that the original creators of patches <code>p</code> and <code>q</code>
continued working on their own personal branches, which merged sometime in
the future at the file <code>F</code>:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_16.svg" alt=""></p>

<p>We say that the merge <code>(r, s)</code> is a <em>perfect merge</em> if for <em>every</em> possible
choice of the merge <code>(u, v)</code>, there is a unique patch <code>w</code> so that <code>u = rw</code>
and <code>v = sw</code>. (In math terms, the diagram commutes.)
We’re going to call <code>w</code> a <em>continuation</em>, since it tells us how to continue
working from the merged file. To repeat, a merge is perfect if for every
possible future, there is a unique continuation.</p>

<h2 id="a-perfect-merge">A perfect merge</h2>

<p>Let’s do a few examples to explore the various corners of our definition.
First, an example of a perfect merge:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_17.svg" alt=""></p>

<p>It takes a bit of effort to actually <em>prove</em> that this is a perfect merge;
I’ll leave that as an exercise. It’s more interesting to see some examples
that fail to be perfect.</p>

<h2 id="a-silly-example-1">A silly example</h2>

<p>Let’s start with the silly example of a merge that introduced an unnecessary
line:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_18.svg" alt=""></p>

<p>This turns out (surprise, surprise) not to be a perfect merge.
To understand how our definition of merge perfection excludes merges like this,
here is an example of a possible future without a continuation:</p>

<p><img src="https://jneem.github.io/images/merge_tikz_block_19.svg" alt=""></p>

<p>Since our patches can’t delete lines, there’s no way to get from <code>merged</code>
to <code>future</code>.</p>

<h2 id="a-serious-example-1">A serious …</h2></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jneem.github.io/merging/">https://jneem.github.io/merging/</a></em></p>]]>
            </description>
            <link>https://jneem.github.io/merging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810902</guid>
            <pubDate>Sun, 12 Jul 2020 12:41:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Science Eats Its Young]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810885">thread link</a>) | @george3d6
<br/>
July 12, 2020 | https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG | <a href="https://web.archive.org/web/*/https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-07-12</p>
        
<p>Let's start by talking about scientific literacy. I'm going to use a weak definition of scientific literacy, one that simply requires familiarity with the Baconian method of inquiry.</p>
<p>I don't want to place an exact number on this issue, but I'd wager the vast majority of the population of "educated" countries scientifically illiterate.</p>
<h2>I - The gravity of the issue</h2>
<p>I first got a hint that this could be a real issue when I randomly started asking people about the theory of gravity. I find gravity to be interesting because it's not at all obvious. I don't think any of us would have been able to come up with the concept in Newton's shoes. Yet it is taught to people fairly early in school.</p>
<p>Interestingly enough, I found that most people were not only unaware of how Newton came up with the idea of gravity, but not even in the right ballpark. I think I can classify the mistakes made into three categories, which I'll illustrate with an answer each:</p>
<ol>
<li>The <strong>Science as Religion</strong> mistake: Something something, he saw apples falling towards earth, and then he wrote down the formula for gravity (?)</li>
<li>The <strong>Aristotelian Science</strong> mistake: Well, he observed that objects of different mass fell towards Earth with the same speed, and from that he derived that objects attract each other. Ahm, wait, hmmm.</li>
<li>The <strong>Lack of information</strong> mistake: Well, he observed something about the motion of the planets and the moon... and, presumably he estimated the mass of some, or, hmmm, no that can't be right, maybe he just assumed mass_sun &gt;&gt; mass_plant &gt;&gt; mass_moon and somehow he found that his formula accounted for the motion of the planets.</li>
</ol>
<p>I should caveat this by saying I don't count mistake nr 3 as scientific illiteracy, in this case, I think most of us fall in that category most of the time. Ask me how gravity can be derived in principle and I might be able to make an educated guess and maybe (once the observations are in) I could even derive it. But the chances of that are small, I probably wouldn't know the exact information I'd need which can be measured with 17th-century devices. I most certainly don't have the information readily sitting in my brain.</p>
<p>It's mainly failure modes 1 and 2 that I'm interested in here.</p>
<h2>II - And Science said: Let there be truth</h2>
<p>I think failure mode 1 is best illustrated by the <a href="https://www.youtube.com/results?search_query=how+newton+discovered+gravity">first youtube result</a> if you search for "how newton discovered gravity". This failure mode includes two mistakes:</p>
<ul>
<li>Not understanding the basis of the actual theory (in this case 'gravity' is presented as "objects fall towards Earth", rather than objects attracting each other proportional to their mass and distance).</li>
<li>Not understanding the idea of evidence as a generator of theory.</li>
</ul>
<p>In this failure, mode science works more or less like religion. There's a clergy (researchers, teachers, engineers) and there are various holy texts (school manuals, papers, specialized books).</p>
<p>I think a good indication of this failure mode is that people stuck here don't seem to differentiate between "what other humans in authority positions are saying" versus "what we observe in the world" as having fundamentally different epistemic weight.</p>
<p>Good examples here are e.g. young-earth creationists, people the believe the earth was created ~6000 years ago. Most of these kinds of people are obviously not scientists, but some are, a quick google search brings up Duane Gish (Berkely P.hD) and Kurt Wise (professor at a no-name university in Georgia).</p>
<p>However, young-earth creationism is not the only unscientific belief system people have, there are insane conspiracy theories aplenty, from vaccines being brainwashing mechanisms or 5G causing viral infections.</p>
<p>This kind of insanity is usually not represented in people affiliated with scientific or engineer institutions, but I'm unsure it is for the right reasons.</p>
<p>That is to say, assume you think of science as a religion. Your epistemology is based on what other people tell you, you weigh that by their social rank and thus derive what you hold as "truth".</p>
<p>Assume you are a doctor that falls into this category and 70% of your friends tell you "5G towers cause covid-19". Well, then, you could probably start believing that yourself. <em>But</em> keep in mind, it's not the only number of people that matters, the status also matters. If the priest tells you about the word of God that counts 100x as much as the village idiot telling you about the word of God.</p>
<p>Even with this context, if our good doctor's boss tells him "covid-19 infection is caused by an airborne coronavirus that passes from human to human via various bodily fluids dispersed in the air and on objects", then whatever this boss told him would have enough status magnitude to make him set his opinion on the more scientifically correct explanation.</p>
<p>The problem here is that our good doctor would be unable to come up with this explanation on his own, even in a hypothetical, he lacks even the foundational epistemology required to understand how such answers can be derived.</p>
<p>Even worst, our doctor's boos could share his epistemology, all that would be needed is for her boos to have told her the same thing and she would have believed it in an instant.</p>
<p>This Science as a Religion worldview is likely sprinkled through all engineers and scientists. The reason we don't see it is that for it to become obvious, one needs to start believing an obviously insane thing (e.g. young-earth creationism), however, the chance of this happening is fairly low since it would require all their peers to also believe insane things.</p>
<p>As long as "correct" ideas are observed throughout his professional environment, unless he is socially inept, he will only hold the correct idea.</p>
<p>You would need to look at his research or question him on the scientific method or on his epistemology more broadly in order to spot this mistake. Sadly enough, I've yet to find a university that has "scientific epistemology" as a subject on the entrance exam or even as a graduation or employment requirement.</p>
<p>I won't speculate as to how many people who are called scientists and engineers fall into this failure mode. I think there's a gradient between this and failure mode nr 2.</p>
<p>However, it should be noted that this failure mode is unobvious <strong>until</strong> a new idea comes along. Then, the real scientists will assume it's probably false but judge it on its merit. The religious scientists will assume it's false because their peers haven't said it's right yet.</p>
<p>This is both an issue in regards to new ideas proliferating and an issue with the scientific consensus. Scientific consensus is valuable if you assume everyone pooled reasoned their way through theory, independent research, and primary source dissection to reach a conclusion.</p>
<p>In a world where 90% of scientists just assume that science works like a religion, a 96%-4% consensus is not a good indicator for implementing policy, it's an indicator that the few real scientists are almost evenly split on the correct solution.</p>
<p>This is bleak stuff, if most scientists were understanding science as a religion then the whole institution would be compromised. Not only would academia have to be thrown in the bin, but all evidence and theory produced for the last half-century would have to be carefully curated and replicated before it can be considered scientifically true.</p>
<p>Surface level intuitions want me to think there's a significant probability this might be the case with certain sub-fields. But my theory of mind and the fact that science seems to keep progressing tells me this is unlikely to be the case in relevant areas.</p>
<h2>III - If there's a fit there's a way</h2>
<p>In short, these are the people that don't understand why a regression being fit on all the data is different from using the same regression to determine correlation strength via cross-validation.</p>
<p>I think most people and most scientists probably fall under the second failure mode, they are not Baconians or Popperians, but rather they are Aristotelians.</p>
<p>Aristotle understood the idea that we can observe the world and we can come up with theories about how it works based on observation.</p>
<p>He lacked was a rigorous understanding of how observations should be undertaken. He was probably unaware of the idea of having similar experimental error standards and replications as the rules by which the validity of data can be compared.</p>
<p>He lacked an understanding of the language of probability which would allow him to formulate these experimental standards.</p>
<p>He lacked an understanding of falsifiability and Occam's razor, he didn't have a rigorous system for comparing competing theories.</p>
<p>In an Aristotelian framework, dropping 3 very heavy and well-lackered balls towards Earth and seeing they fall with a constant speed barring any wind is enough to say <code>FG = G * m1 * m2 / r^2</code> is a true scientific theory.</p>
<p>If things like the constant <code>G</code> and the mass of the ball and the radius of the earth are already known, then the Aristotelian has no issue with declaring the theory correct. He needn't ask:</p>
<ul>
<li>Why do you assume this holds for all objects? After all, the only thing we have observed is three objects falling towards Earth. Even more, the balls are too light to observe this effect between them.</li>
<li>Why can this equation not be simpler? I could simplify this equation to only a single term if what you wished to describe is just the fall of objects towards the Earth, which is the only thing your experiment is showing anyway.</li>
<li>Why is dropping 3 balls enough to derive anything? Why are 2 not enough, why aren't 100 needed? Also, why is weight the property in question here and not some other property of the ball? Maybe it works for lead balls but not for copper balls?</li>
</ul>
<p>I will grant I might be straw-manning Aristotle here, he would have been able to ask some of those questions, he just didn't have a rigorous frameworks from which to derive them. He was working from Aristotelian logic and intuition.</p>
<p>This seems to be the kind of failure that most people fall into, and why …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG">https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/SCIENCE_EATS_ITS_YOUNG</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810885</guid>
            <pubDate>Sun, 12 Jul 2020 12:38:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operators and Sidecars Are the New Model for Software Delivery]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23810718">thread link</a>) | @kiyanwang
<br/>
July 12, 2020 | http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html | <a href="https://web.archive.org/web/*/http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Today’s developers are expected to develop resilient and scalable 
distributed systems. Systems that are easy to patch in the face of 
security concerns and easy to do low-risk incremental upgrades. Systems 
that benefit from software reuse and innovation of the open source 
model. Achieving all of this for different languages, using a variety of
 application frameworks with embedded libraries is not possible.</p>
<p>Recently I’ve <a href="https://www.infoq.com/articles/multi-runtime-microservice-architecture/" rel="external" target="_blank">blogged</a>
 about “Multi-Runtime Microservices Architecture” where I have explored 
the needs of distributed systems such as lifecycle management, advanced 
networking, resource binding, state abstraction and how these 
abstractions have been changing over the years. I also&nbsp;<a href="https://www.youtube.com/watch?v=CZPEIJFJV9k" rel="external noopener noreferrer" target="_blank">spoke</a>&nbsp;about&nbsp;“The
 Evolution of Distributed Systems on Kubernetes” covering how Kubernetes
 Operators and the sidecar model are acting as the primary innovation 
mechanisms for delivering the same distributed system primitives.</p>
<p>On both occasions, the main takeaway is the prediction that the 
progression of software application architectures on Kubernetes moves 
towards the sidecar model managed by operators. Sidecars and operators 
could become a mainstream software distribution and consumption model 
and in some cases even replace software libraries and frameworks as we 
are used to.</p>
<p>The sidecar model allows the composition of applications written in 
different languages to deliver joint value, faster and without the 
runtime coupling. Let’s see a few concrete examples of sidecars and 
operators, and then we will explore how this new software composition 
paradigm could impact us.</p>
<h2>Out-of-Process Smarts on the Rise</h2>
<p>In Kubernetes, a sidecar is one of the <a href="http://k8spatterns.io/" rel="external" target="_blank">core design patterns</a>
 achieved easily by organizing multiple containers in a single Pod. The 
Pod construct ensures that the containers are always placed on the same 
node and can cooperate by interacting over networking, file system or 
other IPC methods. And <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/" rel="external" target="_blank">operators</a>
 allow the automation, management and integration of the sidecars with 
the rest of the platform. The sidecars represent a language-agnostic, 
scalable data plane offering distributed primitives to custom 
applications. And the operators represent their centralized management 
and control plane.</p>
<p>Let’s look at a few popular manifestations of the sidecar model.</p>
<h3>Envoy</h3>
<p>Service Meshes such as Istio, Consul, and others are using transparent service proxies such as <a href="https://www.envoyproxy.io/" rel="external" target="_blank">Envoy</a>
 for delivering enhanced networking capabilities for distributed 
systems. Envoy can improve security, it enables advanced traffic 
management, improves resilience, adds deep monitoring and tracing 
features. Not only that, it understands more and more Layer 7 protocols 
such as Redis, MongoDB, MySQL and most recently Kafka. It also added 
response caching capabilities and even WebAssembly support that will 
enable all kinds of custom plugins. Envoy is an example of how a 
transparent service proxy adds advanced networking capabilities to a 
distributed system without including them into the runtime of the 
distributed application components.</p>
<h3>Skupper</h3>
<p>In addition to the typical service mesh, there are also projects, such as<a href="https://skupper.io/" rel="external" target="_blank"> Skupper</a>,
 that ship application networking capabilities through an external 
agent. Skupper solves multicluster Kubernetes communication challenges 
through a Layer 7 virtual network and offers advanced routing and 
connectivity capabilities. But rather than embedding Skupper into the 
business service runtime, it runs an instance per Kubernetes namespace 
which acts as a shared sidecar.</p>
<h3>Cloudstate</h3>
<p><a href="https://cloudstate.io/" rel="external" target="_blank">Cloudstate</a>
 is another example of the sidecar model, but this time for providing 
stateful abstractions for the serverless development model. It offers 
stateful primitives over GRPC for EventSourcing, CQRS, Pub/Sub, 
Key/Value stores and other use cases. Again, it an example of sidecars 
and operators in action but this time for the serverless programming 
model.</p>
<h3>Dapr</h3>
<p><a href="https://dapr.io/" rel="external" target="_blank">Dapr</a>
 is a relatively young project started by Microsoft, and it is also 
using the sidecar model for providing developer-focused distributed 
system primitives. Dapr offers abstractions for state management, 
service invocation and fault handling, resource bindings, pub/sub, 
distributed tracing and others. Even though there is some overlap in the
 capabilities provided by Dapr and Service Mesh, both are very different
 in nature. Envoy with Istio is injected and runs transparently from the
 service and represents an operational tool. Dapr, on the other hand, 
has to be called explicitly from the application runtime over HTTP or 
gRPC and it is an explicit sidecar targeted for developers. It is a 
library for distributed primitives that is distributed and consumed as a
 sidecar, a model that may become very attractive for developers 
consuming distributed capabilities.</p>
<h3>Camel K</h3>
<p>Apache Camel is a mature integration library that rediscovers itself on Kubernetes. Its subproject <a href="https://camel.apache.org/camel-k/latest/index.html" rel="external" target="_blank">Camel K</a>
 uses heavily the operator model to improve the developer experience and
 integrate deeply with the Kubernetes platform. While Camel K does not 
rely on a sidecar, through its CLI and operator it is able to reuse the 
same application container and execute any local code modification in a 
remote Kubernetes cluster in less than a second. This is another example
 of developer-targeted software consumption through the operator model.</p>
<h2>More to Come</h2>
<p>And these are only some of the pioneer projects exploring various 
approaches through sidecars and operators. There is more work being done
 to reduce the networking overhead introduced by container-based 
distributed architectures such as the data plane development kit (<a href="https://www.dpdk.org/" rel="external" target="_blank">DPDK</a>),
 which is a userspace application that bypasses the layers of the Linux 
kernel networking stack and access directly to the network hardware. 
There is work in the Kubernetes project to create <a href="https://github.com/kubernetes/enhancements/issues/753" rel="external" target="_blank">sidecar</a> containers with more granular lifecycle guarantees. There are new Java projects based on GraalVM implementation such as <a href="https://quarkus.io/" rel="external" target="_blank">Quarkus</a>
 that reduce the resource consumption and application startup time which
 makes more workloads attractive for sidecars. All of these innovations 
will make the side-car model more attractive and enable the creation of 
even more such projects.</p>
<p><a href="https://1.bp.blogspot.com/-ajKfxQnN7Eg/Xs1961D9WzI/AAAAAAAAORs/_hu-KhmUN1wsQ8PfeIaNKaHNVyi8-3iYACK4BGAsYHg/d/multiruntine1.png"><img alt="Sidecars Providing Distributed Systems Primitives" data-original-height="944" data-original-width="1670" height="226" src="https://1.bp.blogspot.com/-ajKfxQnN7Eg/Xs1961D9WzI/AAAAAAAAORs/_hu-KhmUN1wsQ8PfeIaNKaHNVyi8-3iYACK4BGAsYHg/w400-h226/multiruntine1.png" title="Sidecars Providing Distributed Systems Primitives" width="400"></a></p><p>Sidecars providing distributed systems primitives</p>
<p>I’d not be surprised to see projects coming up around more specific 
use cases such as stateful orchestration of long-running processes such 
as Business Process Model and Notation (BPMN) engines in sidecars. Job 
schedulers in sidecars. Stateless integration engines i.e. Enterprise 
Integration Patterns implementations in sidecars. Data abstractions and 
data <a href="https://github.com/teiid/teiid-operator" rel="external" target="_blank">federation</a> engines in sidecars. OAuth2/<a href="https://github.com/louketo/louketo-proxy" rel="external" target="_blank">OpenID</a>
 proxy in sidecars. Scalable database connection pools for serverless 
workloads in sidecars. Application networks as sidecars, etc. But why 
would software vendors and developers switch to this model? Let’s see a 
few of the benefits it provides.</p>
<h2>Runtimes with Control Planes over Libraries</h2>
<p>If you are a software vendor today, probably you have already 
considered offering your software to potential users as an API or a 
SaaS-based solution. This is the fastest software consumption model and a
 no-brainer to offer, when possible. Depending on the nature of the 
software you may be also distributing your software as a library or a 
runtime framework. Maybe it is time to consider if it can be offered as a
 container with an operator too. This mechanism of distributing software
 and the resulting architecture has some very unique benefits that the 
library mechanism cannot offer.</p>
<h3>Supporting Polyglot Consumers</h3>
<p>By offering libraries to be consumable through open protocols and 
standards, you open them up for all programming languages. A library 
that runs as a sidecar and consumable over HTTP, using a text format 
such as JSON does not require any specific client runtime library. Even 
when gRPC and Protobuf are used for low-latency and high-performance 
interactions, it is still easier to generate such clients than including
 third party custom libraries in the application runtime and implement 
certain interfaces.</p>
<h3>Application Architecture Agnostic</h3>
<p>The explicit sidecar architecture (as opposed to the transparent one)
 is a way of software capability consumption as a separate runtime 
behind a developer-focused API. It is an orthogonal feature that can be 
added to any application whether that is monolithic, microservices, 
functions-based, actor-based or anything in between. It can sit next to a
 monolith in a less dynamic environment, or next to every microservice 
in a dynamic cloud-based environment. It is trivial to create sidecars 
on Kubernetes, and doable on many other software orchestration platforms
 too.</p>
<h3>Tolerant to Release Impedance Mismatch</h3>
<p>Business logic is always custom and developed in house. Distributed 
system primitives are well-known commodity features, and consumed 
off-the-shelf as either platform features or runtime libraries. You 
might be consuming software for state abstractions, messaging clients, 
networking resiliency and monitoring libraries, etc. from third-party 
open source projects or companies. And these third party entities have 
their release cycles, critical fixes, CVE patches that impact your 
software release cycles too. When third party libraries are consumed as a
 separate runtime (sidecar), the upgrade process is simpler as it is 
behind an API and it is not coupled with your application runtime. The 
release impedance mismatch between your team and the consumed 3rd party 
libraries vendors becomes easier to manage.</p>
<h3>Control Plane Included Mentality</h3>
<p>When a feature is consumed as a library, it is included in your 
application runtime and it becomes your responsibility to understand how
 it works, how to configure, monitor, tune and upgrade. That is because 
the language runtimes (such as the JVM) and the runtime frameworks (such
 as Spring Boot or application servers) dictate how a third-party 
library can be included, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html">http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html</a></em></p>]]>
            </description>
            <link>http://www.ofbizian.com/2020/07/operators-and-sidecars-are-new-model.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810718</guid>
            <pubDate>Sun, 12 Jul 2020 12:03:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Addressing Build and Deploy Anti-Patterns for Continuous Delivery Success]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810698">thread link</a>) | @kiyanwang
<br/>
July 12, 2020 | https://skeltonthatcher.com/2016/11/14/dealing-continuous-delivery-anti-patterns/ | <a href="https://web.archive.org/web/*/https://skeltonthatcher.com/2016/11/14/dealing-continuous-delivery-anti-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1773">

	

	
			<figure>
				<img width="1121" height="480" src="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=1121" alt="" srcset="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png 1121w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=150 150w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=300 300w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=768 768w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=1024 1024w" sizes="(max-width: 1121px) 100vw, 1121px" data-attachment-id="1787" data-permalink="https://skeltonthatcher.com/2016/11/14/dealing-continuous-delivery-anti-patterns/fiercely_main_presentation-2/" data-orig-file="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png" data-orig-size="1121,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fiercely_main_presentation" data-image-description="" data-medium-file="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=300" data-large-file="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		<p><a href="https://skeltonthatchercom.files.wordpress.com/2020/03/2c3cf-fiercely-1.png"><img data-attachment-id="1778" data-permalink="https://skeltonthatcher.com/2016/11/14/dealing-continuous-delivery-anti-patterns/fiercely-1/" data-orig-file="https://skeltonthatchercom.files.wordpress.com/2020/03/2c3cf-fiercely-1.png" data-orig-size="280,97" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fiercely-1" data-image-description="" data-medium-file="https://skeltonthatchercom.files.wordpress.com/2020/03/2c3cf-fiercely-1.png?w=280" data-large-file="https://skeltonthatchercom.files.wordpress.com/2020/03/2c3cf-fiercely-1.png?w=280" src="https://skeltonthatchercom.files.wordpress.com/2020/03/2c3cf-fiercely-1.png?w=750" alt="fiercely-1" srcset="https://skeltonthatchercom.files.wordpress.com/2020/03/2c3cf-fiercely-1.png 280w, https://skeltonthatchercom.files.wordpress.com/2020/03/2c3cf-fiercely-1.png?w=150 150w" sizes="(max-width: 280px) 100vw, 280px"></a></p>
<p><em>What follows is a guest post from <a href="http://www.fiercely.pt/" target="_blank" rel="noopener">Fiercely</a>, a software consultancy based in Coimbra, Portugal. </em></p>
<p>After a great presentation at <a href="http://www.ipexpoeurope.com/" target="_blank" rel="noopener">IPEXPO Europe</a> on <a href="http://www.ipexpoeurope.com/Seminars-for-2016/Continuous-Delivery/Thursday-06-October-2016/Continuous-Delivery-anti-patterns-from-the-wild">“Continuous Delivery Anti-patterns from the wild” by Matthew Skelton</a>, we quickly drew parallels with our own work and experiences here at Fiercely.<span id="more-1773"></span></p>

<p>More importantly, we got to thinking on how we usually address these anti-patterns. In this post we would like to focus on two of them:</p>
<ul>
<li><a href="http://www.slideshare.net/SkeltonThatcher/continuous-delivery-antipatterns-from-the-wild-matthew-skelton-ipexpo-europe/42" target="_blank" rel="noopener">No investment in build &amp; deployment</a></li>
<li><a href="http://www.slideshare.net/SkeltonThatcher/continuous-delivery-antipatterns-from-the-wild-matthew-skelton-ipexpo-europe/63" target="_blank" rel="noopener">Just plug in a deployment pipeline</a></li>
</ul>
<p>“<strong>No investment in build &amp; deployment</strong>” is a major problem in any organization that wants to build and deliver software in a more reliable and predictable manner. Especially in the case of large “legacy” systems, we often find the need for “magical steps”, only known to some team members, in order to build the system. Moreover, the team has “comfortably” agreed to live with the burden they impose.</p>
<p>Most organizations don’t account for how much time these “magic steps” actually take. When you only deploy twice a year, that time is probably negligible. But what if we account for all the manual testing and deployment across several different environments, the release branching (and subsequent “merge hell”), and the repetitive deployment “babysitting”? How much time are we really spending/wasting after all?</p>
<p>Typically, lack of investment only becomes evident either when organizations want to go faster (e.g. more deployments, shorter release cycles) or a major refactoring (e.g. underlying platform major version update) is needed. In these cases, people begin to wonder how they can work differently, because the pain will be felt more frequently.</p>
<p>At one of our clients we had to help address this exact problem. The development team had a fairly large system built on top of a 3D engine and needed to stabilize their build and deploy pipeline. Their top issues were only able to build from one specific machine and they relied on a very slow and time-consuming process that required full-time commitment by one developer. This made it impossible to build the software continuously. So we invested in creating a build pipeline that would run independently on every merge request, across all necessary repositories, whilst also having producing deployable assets, on a daily basis. A developer now only needs to worry about their application changes and not the building and distribution of deployable assets. This also had a positive side-effect of clarifying dependencies and synchronization efforts for teams that need these deployable assets for exploratory testing and demonstration purposes.</p>
<p>We also had real-world examples of the second anti-pattern, “<strong>Just plug in a deployment pipeline</strong>”. Again, in software organizations with legacy applications, you cannot just plug in a new shiny pipeline and expect the deployment process to improve instantaneously. The system itself might not be ready. If there are not enough unit tests, and/or no functional specifications and validations, what is the gain? In these situations, we need to address these other issues as well: help the team re-architect the system where needed, stabilizing code into components and then making use of a well known and deterministic build and deploy process.</p>
<p>We were confronted with this anti-pattern in a client with a large legacy code base, nearly zero unit tests and very high-level specifications, based on natural language, impossible to automate. We had to, first of all, help them re-architect their system. After an initial analysis, the team decided that re-architecting would not be sufficient and therefore decided to start a fresh new project, backed up by new needs from business.</p>
<p>Upon further reflection on these anti-patterns, we’d like to suggest another one that we have felt often across multiple clients:</p>
<p><strong>Business and development are just as far apart as development and operations</strong></p>
<p>Business and technical staff have (de-)evolved into completely siloed functions, communicating almost always via email, specification documents or specification tools. The outcome of this way of working is a finger pointing culture. And this is the greatest shift that must occur in any organization wanting to build better, faster and cheaper software: changing the culture. Business and technical staff need to work together and collaborate, not “throw artefacts” over the wall to the other side.</p>
<p>In order to address this anti-pattern, we first need to re-define team configurations, integrating traditional business analysts in the team. This person must also be committed to delivering working software. Just as the developer’s job is not done when the source code compiles, the business analyst’s job is not done when the requirements specification is approved.</p>
<p><a href="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png"><img data-attachment-id="1787" data-permalink="https://skeltonthatcher.com/2016/11/14/dealing-continuous-delivery-anti-patterns/fiercely_main_presentation-2/" data-orig-file="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png" data-orig-size="1121,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fiercely_main_presentation" data-image-description="" data-medium-file="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=300" data-large-file="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=750" src="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=750" alt="fiercely_main_presentation" srcset="https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=750 750w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=150 150w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=300 300w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=768 768w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png?w=1024 1024w, https://skeltonthatchercom.files.wordpress.com/2020/03/657a9-fiercely_main_presentation-1.png 1121w" sizes="(max-width: 750px) 100vw, 750px"></a></p>
<p><strong>Software needs to be delivered. Software needs to be used.</strong></p>
<p>Real users will tell us if the software fulfills their requirements. Everyone needs to be involved and actively listening in on this feedback loop. This also became the most important goal to monitor for the team: delivering working software. The communication between these two job profiles must be based on a continuous conversation about the acceptance criteria. The business analyst does not simply specify these criteria, he or she needs to explain it and evolve it as the conversation with developers occurs.</p>
<p>Applying this kind of transformation has proven to be very successful across clients. Teams composed of business and technical profiles aim at delivering software and not just “making their individual job contribution”.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://skeltonthatcher.com/2016/11/14/dealing-continuous-delivery-anti-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810698</guid>
            <pubDate>Sun, 12 Jul 2020 11:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detecting Failures in Distributed Systems Using Phi φ Accrual Failure Detection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810674">thread link</a>) | @arpitbbhayani
<br/>
July 12, 2020 | https://arpitbhayani.me/blogs/phi-accrual?ref=hn | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/phi-accrual?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>One of the most important virtues of any distributed system is its ability to detect failures in any of its subsystems before things go havoc. Early detection of failures helps in taking preventive actions and ensuring that the system stays fault-tolerant. The conventional way of failure detection is by using a bunch of heartbeat messages with a fixed timeout, indicating if a subsystem is down or not.</p>
<p>In this essay, we take a look into an adaptive failure detection algorithm called <em>Phi Accrual Failure Detection</em>, which was introduced in a <a href="https://pdfs.semanticscholar.org/11ae/4c0c0d0c36dc177c1fff5eb84fa49aa3e1a8.pdf">paper</a> by Naohiro Hayashibara, Xavier Défago, Rami Yared, and Takuya Katayama. The algorithm uses historical heartbeat information to make the threshold adaptive. Instead of generating a binary value, like conventional methods, it generates continuous values suggesting the confidence level it has in stating if the system crashed or not.</p>

<p>Accurately detecting failures is an impossible problem to solve as we cannot ever say if a system crashed or is just very slow in responding. Conventional Failure Detection algorithms output a boolean value stating if the system is down or not; there is no middle ground.</p>
<h2>Heartbeats with constants timeouts</h2>
<p>The conventional Failure Detection algorithms use <em>heartbeat</em> messages with a fixed timeout in order to determine if a system is alive or not. The monitored system periodically sends a heartbeat message to the monitoring system, informing that it is still alive. The monitoring system will suspect that the process crashed if it fails to receive any heartbeat message within a configured timeout period.</p>
<p>Here the value of timeout is very crucial as keeping it short means we detect failures quickly but with a lot of false positives; and while keeping it long means we reduce the false positives but the detection time takes a toll.</p>

<p>Phi Accrual Failure Detection is an adaptive Failure Detection algorithm that provides a building block to implementing failure detectors in any distributed system. A generic Accrual Failure Detector, instead of providing output as a boolean (system being up or down), outputs the suspicion information (level) on a continuous scale such that higher the suspicion value, the higher are the chances that the system is down.</p>
<h2>Detailing φ</h2>
<p>We define φ as the suspicion level output by this failure detector and as the algorithm is adaptive, the value will be dynamic and will reflect the current network conditions and system behavior. As we established earlier - lower are the chances of receiving the heartbeat, higher are the chances that the system crashed hence higher should be the value of φ; the details around expressing φ mathematically are as illustrated below.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/87240784-469c0a00-c43a-11ea-8689-9dc41eb1ccf1.png" alt="Phi Accrual Failure Detection"></p>
<p>The illustration above mathematically expresses our establishments and shows how we can use <code>-log10(x)</code> function applied to the probability to get a gradual negative slope indicating a decline in the value of φ. We observe how, as the probability of receiving heartbeat increases, the value of φ decreases and approaches <code>0</code>, and when the probability of receiving heartbeat decreases and approaches <code>0</code>, the value of φ tends to infinity ∞.</p>
<p>The φ value computed using <code>-log10(x)</code> also suggests our likeliness of making mistakes decreases exponentially as the value of φ increases. So if we say a system is down if φ crosses a certain threshold <code>X</code> where <code>X</code> is <code>1</code>, it implies that our decision will be contradicted in the future by the reception of a late heartbeat is about <code>10%</code>. For <code>X = 2</code>, the likelihood of the mistake will be <code>1%</code>, for <code>X = 3</code> it will be <code>0.1%</code>, and so on.</p>
<h2>Estimating the probability of receiving another heartbeat</h2>
<p>Now that we have defined what φ is, we need a way to compute the probability of receiving another heartbeat given we have seen some heartbeats before. This probability is proportional to the probability that the heartbeat will arrive more than <code>t</code> units after the previous one i.e. longer the wait lesser are the chances of receiving the heartbeat.</p>
<p>In order to implement this, we keep a sampled Sliding Window holding arrival times of past heartbeats. Whenever a new heartbeat arrives, its arrival time is stored into the window, and the data regarding the oldest heartbeat is deleted.</p>
<p>We observe that the arrival intervals follow a <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal Distribution</a> indicating most of the heartbeats arrive within a specific range while there are a few that arrive late due to various network or system conditions. From the information stored in the window, we can easily compute the arrival intervals, mean, and variance which we require to estimate the probability.</p>
<p>Since arrival intervals follow a Normal Distribution, we can integrate the <a href="https://en.wikipedia.org/wiki/Probability_density">Probability Density Function</a> over the interval <code>(t, ∞)</code> to get the probability of receiving heartbeat after <code>t</code> units of time. Thus the expression for deriving this can be illustrated below.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/87231591-fbe8a680-c3d5-11ea-9427-d4cd66e8e717.png" alt="Estimating probability of receiving another heartbeat"></p>
<p>We observe that if the process actually crashes, the value is guaranteed to accrue (accumulate) over time and will tend to infinity ∞. Since the accrual failure detectors output value in a continuous range, we need to explicitly define thresholds crossing which we say that the system crashed.</p>

<p>We can define multiple thresholds, crossing which we can take precautionary measures defined for it. As the threshold becomes steeper the action could become more drastic. Another major benefit of using this system is that it favors a nearly complete decoupling between application requirements and monitoring as it leaves the applications to define threshold according to their QoS requirements.</p>

<ul>
<li><a href="https://pdfs.semanticscholar.org/11ae/4c0c0d0c36dc177c1fff5eb84fa49aa3e1a8.pdf">The φ Accrual Failure Detector</a></li>
<li><a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal Distribution</a></li>
</ul>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/phi-accrual?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810674</guid>
            <pubDate>Sun, 12 Jul 2020 11:53:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft to End Support of PHP on Windows]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23810641">thread link</a>) | @kiyanwang
<br/>
July 12, 2020 | https://externals.io/message/110907 | <a href="https://web.archive.org/web/*/https://externals.io/message/110907">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="110909-body">
            <div>
                <p>Hi Sara,</p>
<p>Thank you for responding back.</p>
<p>We have tooling in place to allow for building and testing.  We did build the latest bits on 8.0 to test some things, but we are not moving forward with any more builds.</p>
<p>Please let me know how we can help with the transition as it moves forward.</p>
<p>Thank you for your time,</p>
<p>Dale</p>
<p>From: Sara Golemon <a href="https://externals.io/cdn-cgi/l/email-protection#1b6b747777726f7a5b6b736b35757e6f"><span data-cfemail="7e0e111212170a1f3e0e160e50101b0a">[email&nbsp;protected]</span></a> <br>
Sent: Thursday, July 9, 2020 1:01 PM <br>
To: Dale Hirt <a href="https://externals.io/cdn-cgi/l/email-protection#9cf8fdf0f9f4f5eee8dcf1f5ffeef3eff3fae8b2fff3f1"><span data-cfemail="dcb8bdb0b9b4b5aea89cb1b5bfaeb3afb3baa8f2bfb3b1">[email&nbsp;protected]</span></a> <br>
Cc: PHP Internals <a href="https://externals.io/cdn-cgi/l/email-protection#573e3923322539363b24173b3e24232479273f2779393223"><span data-cfemail="9bf2f5effee9f5faf7e8dbf7f2e8efe8b5ebf3ebb5f5feef">[email&nbsp;protected]</span></a>; <a href="https://externals.io/cdn-cgi/l/email-protection#106078603d67797e747f6763507c796364633e6078603e7e7564" rel="nofollow" target="_blank"><span data-cfemail="b6c6dec69bc1dfd8d2d9c1c5f6dadfc5c2c598c6dec698d8d3c2">[email&nbsp;protected]</span></a>; <a href="https://externals.io/cdn-cgi/l/email-protection#5f36312b3a2d313e332c722836311f33362c2b2c712f372f71313a2b" rel="nofollow" target="_blank"><span data-cfemail="2940475d4c5b4748455a045e40476945405a5d5a0759415907474c5d">[email&nbsp;protected]</span></a>; Greg Arnits <a href="https://externals.io/cdn-cgi/l/email-protection#fb9c899e9c9a89bb969298899488949d8fd5989496"><span data-cfemail="0e697c6b696f7c4e63676d7c617d61687a206d6163">[email&nbsp;protected]</span></a>; Antoni Hathaway <a href="https://externals.io/cdn-cgi/l/email-protection#b7f6d9c3d8d9de99ffd6c3dfd6c0d6cef7daded4c5d8c4d8d1c399d4d8da"><span data-cfemail="7736190318191e593f16031f1600160e371a1e140518041811035914181a">[email&nbsp;protected]</span></a> <br>
Subject: [EXTERNAL] Re: [PHP-DEV] Microsoft Support of PHP on Windows</p>
<p>My name is Dale Hirt and I am the project manager for PHP inside Microsoft. <br>
We are not, however, going to be supporting PHP for Windows in any capacity for version 8.0 and beyond.</p>
<p>Hi Dale! <br>
First, let me convey all our appreciation for the work Microsoft has put into supporting PHP on Windows over the years.  Thank you also for letting us know in advance to not expect 8.0 builds.  I guess this decision must have only been made very recently since 8.0.0alpha1 and alpha2 builds were produced already.</p>
<p>I won't say I'm not bummed, of course.  Nevertheless, y'all gotta do what you gotta do.  I'm sure we can work out an alternative by the end of the year.</p>
<p>All the best, <br>
-Sara Golemon (PHP 8.0 Release Manager)</p>

            </div>
                    </div></div>]]>
            </description>
            <link>https://externals.io/message/110907</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810641</guid>
            <pubDate>Sun, 12 Jul 2020 11:48:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frank Gehry started off building cities with his grandma]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23810540">thread link</a>) | @pseudolus
<br/>
July 12, 2020 | https://www.cbc.ca/radio/podcastnews/frank-gehry-started-off-building-cities-with-his-grandma-1.5491434 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/podcastnews/frank-gehry-started-off-building-cities-with-his-grandma-1.5491434">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>World renowned architect Frank Gehry is comfortable talking about his work but when asked about his early days, the 91 year old pauses. "Now you're gonna make me cry." In a wide-sweeping conversation he recalls the roots of his curiosity, and they days when he's build wood block cities with his grandma.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5491446.1583781956!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/frank-gehry.JPG"></p></div><figcaption>At 91, architect Frank Gehry is still dreaming up and working on new projects. "There's always something new to chase after, some new corner to turn around and go around."<!-- --> <!-- -->(Mike Blake/Reuters)</figcaption></figure><p><span></span><span>Listen<!-- --> to the full episode</span><span>54:27</span></p><p><span><p>It's pretty easy to spot a Frank Gehry building: all curves and glass and movement.</p>  <p>He'll tell you his designs — from the Guggenheim Museum in Bilbao, Spain to the Walt Disney Concert Hall in Los Angeles — "speak" to the buildings and environment around them. But to the onlooker, they clearly stand apart.&nbsp;</p>    <p>In the latest episode of <em>More&nbsp;with Anna Maria Tremonti</em>, it also becomes clear that Gehry sees his buildings as a way to bring people together,&nbsp;and sees his own role in life as much more than an architect. In a wide-sweeping conversation, he traces his craft back to the days when his grandmother would encourage him to build cities out of&nbsp;wood blocks&nbsp;for the fire — an act of imagination he's adapted for&nbsp;students of today.&nbsp;</p>  <p><em>The following excerpt from their conversation has been condensed for length and clarity. Find the full interview here or on your favourite podcast app.</em></p>  <p><strong>As I listen to you I hear that you are so much more than an architect. That you care&nbsp;about more than the building of buildings.</strong></p>  <p>I do, yeah. Well I grew up that way.</p>  <p>You know my grandfather used to read Talmud to me. I don't think he was&nbsp;sellout religious. He was just interested in the philosophy. And Talmud starts with the word "Why." It's about curiosity. And I think that is really important. You've got to be curious.&nbsp;</p>  <p>Buildings are backgrounds for activity but the activity has to be&nbsp;a life, a thing. It's got to be more than just making money. It's a cultural thing and it brings people together to talk to each other, live together, work together. So, just the building alone is not that relevant.</p>  <p><strong>Do you think that most architects understand that? Most people?</strong></p>  <p>Not most.&nbsp;I don't think so.</p>  <p>Although architects tend to be idealists. They start out very idealistic. They want to make the world better. Most of the architects I know and work with have an idealistic base. They're trying to make a better world.&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/frank-gehry.JPG 300w,https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/frank-gehry.JPG 460w,https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/frank-gehry.JPG 620w,https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/frank-gehry.JPG 780w,https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/frank-gehry.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5491455.1583782068!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/frank-gehry.JPG"></p></div><figcaption>People pass in front of the Frank Gehry designed Guggenheim Museum at dusk in Bilbao.<!-- --> <!-- -->(Reuters)</figcaption></figure></span></p>  <p><strong>How important was your family life in creating the man who you are today? Those early days when you were a kid.</strong></p>  <p>Okay, so now you're gonna make me cry. Well my grandparents were great. My grandmother brought the wood blocks home for the fire, for the wood stove. And she would throw them on the floor and make cities with me.</p>    <p>And I don't know why she decided to do that. Architecture wasn't in any part of our family at that time. So that was an&nbsp;important memory.</p>  <p>My father was not educated at all. He probably didn't even go to school. He was living on the streets in New York — Tenth Avenue. His father was a tailor who came from Russia and is actually buried in Toronto. And his name was Frank Goldberg. So there is a Frank Goldberg buried in a cemetery in Toronto — that's my grandfather.</p>  <p>Anyway, so my father ...&nbsp;had a heart attack at 49. He lost everything. And his brother moved him to L.A.</p>  <p>We got here and we were very poor because he had lost everything. But he became a truck driver and I became a truck driver. I was 17 or 18. Now, after he's gone — he died at 63 or something like that — I've seen evidence now that I find in some of the things he left behind, that we never looked at really until recently, and it's pretty clear that he had an artistic bent and that that's what he liked doing.</p>  <p>He would paint toys for people. He would make things.&nbsp;I remember him drawing with me but he never got to see what I started to do. By time I was an architect, he was out of it.</p>  <p><strong>What do you think you would have thought of your work? Would he have been proud of you?</strong></p>  <p>He would be shocked and proud. I think, yeah. I liked that thought.&nbsp;</p>    <p><strong>So, what advice do you give to your son as he tries to carve his own path?</strong></p>  <p>Just stay curious. Do where your head takes you. And be conscious of the people who are working with you and the people who are you're working for and the importance of what you do in relation to your contribution to what's going on around us.</p>  <p><strong>That sounds like advice you could give to lots of people.</strong></p>  <p>Yeah. Well, I'm not holier than thou about it.&nbsp;I know that I just live that way. But there's a lot of different ways to live and still be creative and still be part of the world and still be doing important things. So my way is not the only example.&nbsp;</p>  <p><strong>Well, I think in these times though it's nice to hear you know to connect the work you do and the wider concept of architecture to the idea of humanity and being humane.</strong> <strong>I think it's a really important thing to hear from you.</strong></p>  <p>Yeah. But I think the history of architecture shows that that was prevalent from the beginning.</p>  <p>You know all the great artists of the Renaissance became architects. So Giotto was a great painter, became an architect. El Greco was a great painter, became an architect. Architecture was treated as an art in those times.</p>    <p>After the war here architecture became less of an art and more&nbsp;engineering issues and financial issues. And not that they're not important but that became the driver. Not the humanity of it. And that's why our cities are kind of the way they are I think. And the cities look the same all over the world. You go to Seoul, Korea. It looks like downtown L.A.</p>  <p><strong>Do you see yourself as an artist more than an architect?</strong></p>  <p>Absolutely. I hope so.&nbsp;I think it's the same. They're not mutually exclusive. When I got out of school, I hung out with the artists more than with the architects because I just felt that's where I should be. And I still do.</p>    <div>   <h2>Want to hear the full conversation?</h2>   <p>Listen for free at&nbsp;<a href="https://www.cbc.ca/radio/podcasts/more-with-anna-maria-tremonti/index.html">cbc.ca/more</a>&nbsp;or on your favourite podcast app — including&nbsp;<a href="https://podcasts.apple.com/ca/podcast/more-with-anna-maria-tremonti/id1494930679">Apple Podcasts</a>,&nbsp;<a href="https://podcasts.google.com/?feed=aHR0cHM6Ly93d3cuY2JjLmNhL3BvZGNhc3RpbmcvaW5jbHVkZXMvbW9yZS54bWw%3D">Google Podcasts</a>&nbsp;and&nbsp;<a href="https://open.spotify.com/show/17PsCUS5j6WN1GiqBGDIxn">Spotify</a>. And if you're new to podcasts&nbsp;entirely,&nbsp;<a href="https://www.cbc.ca/radio/how-to-download-a-podcast-1.4593484">start here</a>.&nbsp;</p>   <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/frank-gehry.jpg 300w,https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/frank-gehry.jpg 460w,https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/frank-gehry.jpg 620w,https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/frank-gehry.jpg 780w,https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/frank-gehry.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5491462.1583782280!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/frank-gehry.jpg"></p></div><figcaption>Episode 7: "Frank Gehry built small cities with grandma" is available now on the More with Anna Maria Tremonti podcast.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  </div>    </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/podcastnews/frank-gehry-started-off-building-cities-with-his-grandma-1.5491434</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810540</guid>
            <pubDate>Sun, 12 Jul 2020 11:19:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM looking for 12 years’ experience in Kubernetes administration]]>
            </title>
            <description>
<![CDATA[
Score 367 | Comments 235 (<a href="https://news.ycombinator.com/item?id=23810519">thread link</a>) | @tosh
<br/>
July 12, 2020 | https://intellijobs.ai/job/IBMCloud-Native-Infrastructure-Engineer-Architect-bvJJ6yraexfWOk1nMRKP-bvJJ6yraexfWOk1nMRKP | <a href="https://web.archive.org/web/*/https://intellijobs.ai/job/IBMCloud-Native-Infrastructure-Engineer-Architect-bvJJ6yraexfWOk1nMRKP-bvJJ6yraexfWOk1nMRKP">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://intellijobs.ai/job/IBMCloud-Native-Infrastructure-Engineer-Architect-bvJJ6yraexfWOk1nMRKP-bvJJ6yraexfWOk1nMRKP</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810519</guid>
            <pubDate>Sun, 12 Jul 2020 11:13:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't make this container security mistake]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810366">thread link</a>) | @bitfield
<br/>
July 12, 2020 | https://bitfieldconsulting.com/blog/container-security | <a href="https://web.archive.org/web/*/https://bitfieldconsulting.com/blog/container-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-yui_3_17_2_1_1594472053630_21142"><div><p>Most of us wouldn't dream of running a typical web application as <code>root</code>; if you have to ask why not, your network administrator will kindly, but firmly, explain, "Because security". The <code>root</code> user in Unix has total access to all files on the system, the memory space of all other applications, can start and stop processes, snoop on network traffic, install remote-control backdoors, and everything else besides. <code>root</code> has god-like powers which are unnecessary, inappropriate, and positively dangerous to grant to normal applications.</p>
<h2 id="got-root-">Got root?</h2>
<p>So why are most <em>containers</em> running as <code>root</code>? Liz Rice, in her engaging and accessible new book <a href="https://amzn.to/2WaFmB7">Container Security</a> (O'Reilly 2020), describes this as "arguably the most insecure-by-default behaviour in the container world," and I am not disposed to argue with her. Since, as she demonstrates, root access to a container is equivalent to root access to the host, then if an attacker can escape the container, they immediately have free rein over everything on the host machine, including all other containers.</p>
<blockquote>
<p>"Do you want to be just one line of defense away from an attacker taking over a host?"</p>
</blockquote>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1594472053630_26554"><div><p>Fortunately, this hole is relatively easy to patch (by adding a <code>USER</code> step in the Dockerfile or using flags to <code>docker</code>/<code>runc</code> to override the default user), and Rice's book is packed with such useful and practical information for developers and operators looking to run containerized applications securely in the cloud.</p>
<h2 id="getting-to-grips">Getting to grips</h2>
<p>Currently VP Open Source Engineering at container security vendor Aqua Security (so she should know what she's talking about), Rice is a well-known, <a href="https://www.lizrice.com/">award-winning speaker and writer</a> on technical topics. Her approach to communicating complex and sometimes difficult material is a very effective one: instead of just telling you how it all works, she <em>shows</em> you. With step-by-step interactive demonstrations, giving you Linux commands to run and showing you what output you'll see, you'll explore topics like file permissions, <code>setuid</code>, capabilities, cgroups, isolation, namespaces, and virtualization.</p>
<p>This book will give you a thorough grounding in the security principles and techniques you need to know when running containers in production, as well as the threat models affecting containers, how to use image scanners and admission controls, and important security-related technologies such as TLS. Despite being so comprehensive, it's well-written, extremely easy to read and, at just 180pp, pleasantly concise.</p>
<h2 id="no-more-excuses">No more excuses</h2>
<p>'Container Security' has gone straight onto my 'must-read' list for anyone working with containers and cloud native. The field is rife with poor practice and ignorance of the basics, and I'm not really sure why this is. If the excuse has been that there's no practical, readable single book that explains what you need to know, that excuse certainly no longer applies.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1594472053630_31480"><div><p>The fact of the matter is that container security really isn't that hard. If you understand the principles Rice outlines, and apply them using common sense, you can mitigate the most serious risks. The machinery is there, and all we need to do is use it. Not doing so (or not reading this authoritative book on the subject) is perhaps the most fundamental container security mistake of all.</p>
<p><em data-preserve-html-node="true">You can follow Liz Rice on Twitter at <a href="https://twitter.com/lizrice">@lizrice</a>, or read her website at <a href="https://www.lizrice.com/">lizrice.com</a>. John Arundel is <a href="https://twitter.com/bitfield">@bitfield</a> on Twitter, and the co-author of <a href="https://amzn.to/2PEPTjc">Cloud Native DevOps with Kubernetes</a> and the <a href="https://cloudnativedevopsblog.com/">Cloud Native DevOps blog</a>.</em></p></div></div></div>]]>
            </description>
            <link>https://bitfieldconsulting.com/blog/container-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810366</guid>
            <pubDate>Sun, 12 Jul 2020 10:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Animals Keep Pets?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810320">thread link</a>) | @sjcsjc
<br/>
July 12, 2020 | https://primatology.net/2010/07/05/do-animals-keep-pets/ | <a href="https://web.archive.org/web/*/https://primatology.net/2010/07/05/do-animals-keep-pets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>After reading an article from <em>Psychology Today <span>by Hal Herzog,</span></em> it got me thinking about the idea of pet-keeping.&nbsp;The article&nbsp;“<a href="http://www.psychologytoday.com/blog/animals-and-us/201006/are-humans-the-only-animals-keep-pets"><em>Are Humans The Only Animals That Keep Pets?</em></a>“, claims that humans are the only animal that keeps members of other species for an extended point of time purely for enjoyment. Herzog points out that while&nbsp;some animals are documented having pets, this behavior almost always happen in captive or semi-captive environment where food and shelter are provided.&nbsp;The author believes that humans are “true” pet owners because the owner-pet relationship occurs in a natural setting and argues that animal pet owners are not “true” pet owners because they do so in captive or semi-captive settings. Thus, Herzog believes that humans are the only animals that keep pets.</p>
<p>Cited in the article is a paper by Izar et al. (2006), on cross-genus adoption of a marmoset by wild capuchin monkeys (link to the paper is below on References). While the paper specifically refers to the behavior as an adoption, Herzog and paper co-author Dorothy Fragaszy think that there is a parallel between the capuchin-marmoset adoption and pet-keeping in humans. However, these capuchins live in a site where food are provided daily. So,&nbsp;Despite the similarities,&nbsp;these capuchins are not “true” pet owners&nbsp;according to Herzog’s definition of pet-keeping,</p>
<p><a href="http://4.bp.blogspot.com/_Hbo7Ung0Hbg/TC1ORXYQLXI/AAAAAAAABX8/VTgk4NGKO4I/s1600/capuchin+marmoset.jpg"><img src="https://i2.wp.com/4.bp.blogspot.com/_Hbo7Ung0Hbg/TC1ORXYQLXI/AAAAAAAABX8/VTgk4NGKO4I/s320/capuchin+marmoset.jpg" alt="" width="256" height="320"></a></p>
<p>A young marmoset taking food (cracked palm nut) from its adoptive mother’s (capuchin) hand. Photo&nbsp;by Jeanne Shirley (Izar et al., 2006).</p>
<p>What is a pet and how would you define one? Herzog (2010) defines a pet as a member of other species that are being kept for an extended period of time for enjoyment. According to the Merriam-Webster dictionary, the definition of a pet is “a domesticated animal kept for pleasure rather than utility”. The definition of a pet in Oxford English Dictionary is “a domestic or tamed animal or bird kept for companionship or pleasure and treated with care and affection”.&nbsp;<a href="http://www.vet.upenn.edu/FacultyandDepartments/Faculty/tabid/362/Default.aspx?faculty_id=6361798">Dr. James Serpell</a> defines pet-keeping as a leisure activity but not necessarily without function, much like there are function in play or other recreational pursuits (Serpell, 1990). He thinks that pet-keeping is functional in a broad sense but not easily evaluable in economic terms.</p>
<p><a href="http://1.bp.blogspot.com/_Hbo7Ung0Hbg/TC0T9RLNqeI/AAAAAAAABX4/ou8MLJEVT30/s1600/great+ape_cats.jpg"><img src="https://i1.wp.com/1.bp.blogspot.com/_Hbo7Ung0Hbg/TC0T9RLNqeI/AAAAAAAABX4/ou8MLJEVT30/s320/great+ape_cats.jpg" alt="" width="320" height="153"></a></p>
<div>
<p>Some primate pet owners include (left)&nbsp;<a href="http://en.wikipedia.org/wiki/Koko_(gorilla)">Koko</a> and (right)&nbsp;<a href="http://en.wikipedia.org/wiki/Tonda_(orangutan)">Tonda</a>,&nbsp;who both had cats as pets.</p>
<p>While it is impossible to define what a pet is from an animal standpoint, at least in humans, we can agree that a pet can be defined as a companion animal that we treat with affection whose function is to provide us with&nbsp;enjoyment.</p>
<p>Did the behavior of animal domestication evolved into pet-keeping? Is pet-keeping a reflection of human’s nurturing instinct? Or is pet-keeping a reflection of human’s constant need of social interaction, even outside of our own species? What do you think? Well … that’s for another blog post.</p>
</div>
<p>References:</p>
<p>Herzog, H. 2010.&nbsp;<em><span>Are Humans The Only Animals That Keep Pets?</span> </em>Retrieved July 1, 2010&nbsp;<a href="http://www.psychologytoday.com/blog/animals-and-us/201006/are-humans-the-only-animals-keep-pets">http://www.psychologytoday.com/blog/animals-and-us/201006/are-humans-the-only-animals-keep-pets</a></p>
<p>Izar, P. Verderane, MP. Visalberghi E. Ottoni, E. De Oliveira, MG. Shirley, J. Fragaszy, D. 2006. Cross-Genus Adoption of a Marmoset (<em>Callithrix jacchus</em>)&nbsp;by Wild Capuchin Monkeys (<em>Cebus libidinosus</em>):&nbsp;Case Report. <em>American Journal of Primatology</em> 68:692-700. Retrieved July 1, 2010&nbsp;<a href="http://psychology.uga.edu/primate/pub/Cross-genus%20adoption%20AJP%2068,%20692-700%202006.pdf">http://psychology.uga.edu/primate/pub/Cross-genus%20adoption%20AJP%2068,%20692-700%202006.pdf</a></p>
<p>Serpell, JA. 1990. Pet-keeping and Animal Domestication: A reappraisal. <em>In</em> The Walking Larder. Clutton-Brock, J, ed. Pp. 10-21.&nbsp;Massachusetts: Unwin Hyman Inc. Retrieved July 1, 2010&nbsp;<a href="http://research.vet.upenn.edu/Portals/36/media/Serpell_pet_keeping_domestication.pdf">http://research.vet.upenn.edu/Portals/36/media/Serpell_pet_keeping_domestication.pdf</a></p>
<p>Originally posted on <a href="http://theprancingpapio.blogspot.com/2010/07/do-animals-keep-pets.html">The Prancing Papio</a>.</p>
			
			
						</div></div>]]>
            </description>
            <link>https://primatology.net/2010/07/05/do-animals-keep-pets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810320</guid>
            <pubDate>Sun, 12 Jul 2020 10:21:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker Network – Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810286">thread link</a>) | @lukasbar
<br/>
July 12, 2020 | https://knowledgepill.it/posts/docker_network/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/docker_network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Containers need to communicate with each other and outside world.<br>
Docker has wide network capabilities.</p>
<p>What we can do with docker network? How to use it?</p>

<p>What elements we have in docker network?</p>
<ul>
<li>CNM</li>
<li>libnetwork</li>
<li>drivers</li>
</ul>
<p>Docker network concept is based on open-source design specification called Container Network Model(CNM). CNM assume that network drivers should be pluggable.<br>
Docker CNM implementation is in <code>libnetwork</code> library.</p>
<p>What we can do with docker CNM?</p>
<ul>
<li>single-host bridges</li>
<li>multi-host overlay networks</li>
<li>networks plugged into VLAN’s</li>
<li>ingress networks with load balancing
Also we get auto service discovery for our containers.</li>
</ul>
<p>What elements we have in docker CNM implementation?</p>
<ul>
<li>sandboxes - container network stack - isolated - ethernet interfaces, ports, routing tables and DNS config</li>
<li>endpoint - virtual interfaces in containers - veth</li>
<li>networks - virtual switches(bridges) - connect endpoints</li>
</ul>
<p>What drivers are built-in by default into docker(Linux)?</p>
<ul>
<li>bridge</li>
<li>overlay</li>
<li>macvlan</li>
</ul>

<p>By default docker creates one brigde after instalation.</p>
<p>All containers are by default connected to it unless we override it.<br>
To set another non-default network we use <code>--network</code> flag for <code>docker run</code>.</p>
<p>What is the diference between default bridge and user created one:</p>
<ul>
<li>Default brigde is less secure - provide less isolation - by default all containers will be connected to it</li>
<li>We can connect/disconnect containers from user defined bridges without restarting containers</li>
<li>Defualt bridge does not have DNS included - we must use IP in such network - on user defined bridge we get DNS(all containers added to bridge network automatically will be added also to DNS) - just connect container to bridge and you can talk with other containers in network by their names(works for named containers with <code>--name</code> at creation time)</li>
</ul>
<p>We can see that all default networks are local - what means that we can’t connect with them containers on multiple docker hosts.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker network ls</span>
NETWORK ID          NAME                DRIVER              SCOPE
740857ece0a5        bridge              bridge              local
13396ccbb663        host                host                local
44424eae56f4        none                null                local
</code></pre></div><p>We can check details about default bridge network</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker network inspect bridge</span>
<span>[</span>
    <span>{</span>
        <span>"Name"</span>: <span>"bridge"</span>,
        <span>"Id"</span>: <span>"740857ece0a5fc38891b919d2f7506e32e699b4e79a449f8fef9824d0cde39b2"</span>,
        <span>"Created"</span>: <span>"2020-05-07T21:07:19.137450998+02:00"</span>,
        <span>"Scope"</span>: <span>"local"</span>,
        <span>"Driver"</span>: <span>"bridge"</span>,
        <span>"EnableIPv6"</span>: false,
        <span>"IPAM"</span>: <span>{</span>
            <span>"Driver"</span>: <span>"default"</span>,
            <span>"Options"</span>: null,
            <span>"Config"</span>: <span>[</span>
                <span>{</span>
                    <span>"Subnet"</span>: <span>"172.17.0.0/16"</span>,
                    <span>"Gateway"</span>: <span>"172.17.0.1"</span>
                <span>}</span>
            <span>]</span>
        <span>}</span>,
        <span>"Internal"</span>: false,
        <span>"Attachable"</span>: false,
        <span>"Ingress"</span>: false,
        <span>"ConfigFrom"</span>: <span>{</span>
            <span>"Network"</span>: <span>""</span>
        <span>}</span>,
        <span>"ConfigOnly"</span>: false,
        <span>"Containers"</span>: <span>{</span><span>}</span>,
        <span>"Options"</span>: <span>{</span>
            <span>"com.docker.network.bridge.default_bridge"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.enable_icc"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.enable_ip_masquerade"</span>: <span>"true"</span>,
            <span>"com.docker.network.bridge.host_binding_ipv4"</span>: <span>"0.0.0.0"</span>,
            <span>"com.docker.network.bridge.name"</span>: <span>"docker0"</span>,
            <span>"com.docker.network.driver.mtu"</span>: <span>"1500"</span>
        <span>}</span>,
        <span>"Labels"</span>: <span>{</span><span>}</span>
    <span>}</span>
<span>]</span>
</code></pre></div><p>As we see docker bridge is build on Linux bridge:</p>
<div><pre><code data-lang="bash"><span>"com.docker.network.bridge.name"</span>: <span>"docker0"</span>
</code></pre></div><div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># ip link show docker0</span>
3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span>1500</span> qdisc noqueue state DOWN mode DEFAULT group default
    link/ether 02:42:9d:73:fa:48 brd ff:ff:ff:ff:ff:ff
</code></pre></div><h2 id="creating-network-bridge">Creating network bridge</h2>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker network create -d bridge lukas-bridge</span>
3836e34c6950d80e032e322f915935b51472059ea19cfd65c409263c74ba2b45
</code></pre></div><div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># ip a</span>
&lt;snip&gt;
5: br-3836e34c6950: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span>1500</span> qdisc noqueue state DOWN group default
    link/ether 02:42:0b:b8:19:54 brd ff:ff:ff:ff:ff:ff
    inet 172.19.0.1/16 brd 172.19.255.255 scope global br-6c8ad698150b
       valid_lft forever preferred_lft forever
</code></pre></div><p>As we see there is new bridge at OS level with name coresponding to ID of our newly created docker bridge.</p>
<h2 id="starting-container-connected-to-new-bridge">Starting container connected to new bridge</h2>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker container run -d --name web_server --network lukas-bridge httpd</span>
08e885099d0ebca6ab5b533bffd0245dccfaab79149657ad9161fe26c370b879
</code></pre></div><h2 id="list-containers-connected-to-network">List containers connected to network</h2>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker network inspect lukas-bridge --format "{{json .Containers}}"</span>
<span>{</span><span>"08e885099d0ebca6ab5b533bffd0245dccfaab79149657ad9161fe26c370b879"</span>:<span>{</span><span>"Name"</span>:<span>"web_server"</span>,<span>"EndpointID"</span>:<span>"ade95c4b553f8cebfbf8f24338b6d0f9e7b2d41744c501816ac734d1bb8ccc1f"</span>,<span>"MacAddress"</span>:<span>"02:42:ac:14:00:02"</span>,<span>"IPv4Address"</span>:<span>"172.20.0.2/16"</span>,<span>"IPv6Address"</span>:<span>""</span><span>}</span><span>}</span>
</code></pre></div><h2 id="test-connection-between-containers-connected-to-bridge">Test connection between containers connected to bridge</h2>
<p>If we use <code>--name</code> flag when creating container we can use docker built-in DNS feature.
Containers automatically know hostname to ip mapping of other containers.</p>
<p>Create second container:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker container run -d --name web_server2 --network lukas-bridge httpd</span>
34bb16b0c43c64c935c8a44c0ed13fa2a7972f79700db290144eba54aa93336a
</code></pre></div><p>Get into one of containers and ping other one</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker exec -it web_server2 /bin/bash</span>
root@34bb16b0c43c:/usr/local/apache2# ping web_server

PING web_server <span>(</span>172.20.0.2<span>)</span> 56<span>(</span>84<span>)</span> bytes of data.
<span>64</span> bytes from web_server <span>(</span>172.20.0.2<span>)</span>: icmp_seq<span>=</span><span>1</span> ttl<span>=</span><span>64</span> time<span>=</span>0.712 ms
<span>64</span> bytes from web_server <span>(</span>172.20.0.2<span>)</span>: icmp_seq<span>=</span><span>2</span> ttl<span>=</span><span>64</span> time<span>=</span>0.649 ms
^C
</code></pre></div>
<p>We can add DNS to container - this DNS will be queired when Docker built-in DNS won’t be able to resolve request.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker run -d --dns 8.8.8.8 httpd</span>
4bde944868b492a5cef84676de1cfb1a211069c67c494d4ab742115d4fc17ee9

<span>[</span>root@docker-host1 ~<span>]</span><span># docker exec -it 4bde944868b492a5cef84676de1cfb1a211069c67c494d4ab742115d4fc17ee9 bash</span>
root@4bde944868b4:/usr/local/apache2# cat /etc/resolv.conf
search lukas.int
nameserver 8.8.8.8
</code></pre></div>
<p>We can tell docker to expose port from container on docker host port that other server or clients can access service running in container.<br>
We can achive this with <code>--publish</code> flag.</p>
<h2 id="start-container-with-port-published">Start container with port published</h2>
<p>We start container with <code>httpd</code> service which expose port 80 - to connect to this port in container we can connect to docker host on port 1234.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker run -d --name web_server --network lukas-bridge --publish published=1234,target=80  httpd</span>
304ddf53a801763c769545eb91c6c5522fc2eedf7cf5f4d252bace1d5e0b8a37
</code></pre></div><h2 id="check-what-ports-are-published-from-container">Check what ports are published from container</h2>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker port web_server</span>
80/tcp -&gt; 0.0.0.0:1234
</code></pre></div>
<p>Docker gives us possibility to integrate container network stack into host stack.<br>
In such situation container will not get his own IP address and MAC(neither externally from docker host network, neither internally from network created by docker engine) - he will be reachable as he will be normal software running on our host.</p>
<p>This is good solution if we want to run some software that use network but we want to have full isolation of process(pid), mount(mnt), user and IPC namespaces.</p>
<p>To active such mode we use <code>--network=host</code> parameter to <code>docker run</code>.<br>
In this mode <code>--publish</code> doesn’t work - if service in container listen on port 80 - port 80 on docker host will be taken.</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker run -d --name web_server --network host httpd</span>
dedc6c9e1c05ccb3621fa4272975036f7b9266371a20221f3ba9dbc237eff3b0
</code></pre></div><p>If we inspect container we will see that there is no IP adress and network mode is set to host:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># docker container inspect web_server</span>
<span>[</span>...<span>]</span>
<span>"NetworkMode"</span>: <span>"host"</span>,
            <span>"PortBindings"</span>: <span>{</span>
                <span>"80/tcp"</span>: <span>[</span>
                    <span>{</span>
                        <span>"HostIp"</span>: <span>""</span>,
                        <span>"HostPort"</span>: <span>"1234"</span>
                    <span>}</span>
<span>[</span>..<span>]</span>
<span>"Networks"</span>: <span>{</span>
    <span>"host"</span>: <span>{</span>
        <span>"IPAMConfig"</span>: null,
        <span>"Links"</span>: null,
        <span>"Aliases"</span>: null,
        <span>"NetworkID"</span>: <span>"13396ccbb6635016d4381588204f9724401cf7200b67cb8f44f065ebfbb8f069"</span>,
        <span>"EndpointID"</span>: <span>"256edba4bd98f86e4a3af9331ff24aca958805ff5f0a3bb202fa67c0b8d4ab07"</span>,
        <span>"Gateway"</span>: <span>""</span>,
        <span>"IPAddress"</span>: <span>""</span>,

</code></pre></div><p>Apache server is listening correctly:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># curl -X GET 127.0.0.1:80</span>
&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;
</code></pre></div>
<p>If we want to expose our container to world but it is important for us that container has got own IP and MAC adress from network where docker host is connected, we can use MACVLAN network driver. It allows also to connect to certain VLAN.</p>
<p>It will create for us docker network - all containers connected to this network will be visible in docker host network as they were normal separate from docker host that host them machines.</p>
<p>Remember that:</p>
<ul>
<li>with MACVLAN you can easily exhaust IP adresses in your network</li>
<li>you have to set network card in promiscious mode</li>
<li>this solution is created mainly for legacy apps or network monitoring apps</li>
</ul>
<hr>
<h3 id="important">Important!</h3>
<p>To use MACVLAN mode our network card has to be in promiscious mode!<br>
Activiting promoscius mode in CentOS(ens18 is my main network card):</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># ip link set ens18 promisc on</span>
</code></pre></div><p>Check if mode was activeted - PROMISC flag:</p>
<div><pre><code data-lang="bash"><span>[</span>root@docker-host1 ~<span>]</span><span># ip a</span>
<span>[</span>..<span>]</span>
2: ens18: &lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER_UP&gt; mtu <span>1500</span> qdisc fq_codel state UP group default qlen <span>1000</span>
    link/ether 62:ae:db:67:8c:08 brd ff:ff:ff:ff:ff:ff
    inet 10.10.10.20/24 brd 10.10.10.255 scope global noprefixroute ens18
       valid_lft forever preferred_lft forever
    inet6 fe80::8f98:eb7:2724:a548/64 scope link noprefixroute
       valid_lft forever preferred_lft forever
<span>[</span>...<span>]</span>
</code></pre></div><hr>
<p>As my docker host is in <code>10.10.10.0/24</code> network connected by <code>ens18</code> network card, I will create proper network with macvlan driver.</p>
<p>I also add <code>--ip-range</code> flag because I want that containers get IP’s from second half of my network(in first half are my …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/docker_network/">https://knowledgepill.it/posts/docker_network/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/docker_network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810286</guid>
            <pubDate>Sun, 12 Jul 2020 10:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Word document drops IcedID trojan – Malware Analysis]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810275">thread link</a>) | @anuraggawande
<br/>
July 12, 2020 | https://malwr-analysis.com/2020/07/12/word-macro-drops-icedid-trojan-malware-analysis/ | <a href="https://web.archive.org/web/*/https://malwr-analysis.com/2020/07/12/word-macro-drops-icedid-trojan-malware-analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-754">
	<!-- .entry-header -->

	<div>
		
<p>HASH</p>



<p>MD5: 4A88E83B325AA23DA1E4BFA90B4F7C34 </p>



<p>File type: Office Open XML Document</p>



<p>VT Score: 45/62 </p>



<div><figure><img data-attachment-id="760" data-permalink="https://malwr-analysis.com/blg20_11072020_5/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png" data-orig-size="1296,217" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_5" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_5.png 1296w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>While I was going through Any.run report tracker, I came across this word document, I downloaded it for analysis. </p>



<div><figure><img data-attachment-id="782" data-permalink="https://malwr-analysis.com/blg20_11072020_14/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png" data-orig-size="1260,371" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_14" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_14.png 1260w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><sub>Word document screenshot</sub></figcaption></figure></div>



<p><strong>OleTools: </strong></p>



<p>I used OLETools to analyse the document macros. </p>



<pre>Olevba.py -a &lt;file name&gt;</pre>



<div><figure><img data-attachment-id="764" data-permalink="https://malwr-analysis.com/blg20_11072020_1/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_1.png" data-orig-size="633,300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_1" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_1.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_1.png?w=633" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_1.png?w=633" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_1.png 633w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_1.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_1.png?w=300 300w" sizes="(max-width: 633px) 100vw, 633px"></figure></div>



<p><strong>Indicators:</strong></p>



<ul><li>Auto execute on opening document.</li><li> May write a file to the system. </li><li>Base64 obfuscated strings. </li></ul>



<p>I deobfuscated the file using olevba.py </p>



<pre>Olevba.py --deobf &lt;file name&gt;</pre>



<div><figure><img data-attachment-id="767" data-permalink="https://malwr-analysis.com/blg20_11072020_6/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_6.png" data-orig-size="630,519" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_6" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_6.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_6.png?w=630" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_6.png?w=630" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_6.png 630w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_6.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_6.png?w=300 300w" sizes="(max-width: 630px) 100vw, 630px"></figure></div>



<p><strong>Indicator of Compromise:</strong></p>



<ul><li>PFSDNKDF.exe executable file name.  </li></ul>



<div><figure><img data-attachment-id="770" data-permalink="https://malwr-analysis.com/blg20_11072020_7/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_7.png" data-orig-size="563,246" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_7" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_7.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_7.png?w=563" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_7.png?w=563" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_7.png 563w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_7.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_7.png?w=300 300w" sizes="(max-width: 563px) 100vw, 563px"></figure></div>



<p>Above code shows the PE file PFSDNKDF.exe will be dropped at location C:\1\Whole\ </p>



<p>Next I started debugging macro in VBA development tool. VBA development tool can be opened by pressing Alt + F11 keys that will bring it up. </p>



<p>I can see the variable hextostr has stored a hex code that will be converted into PE file. </p>



<figure><img data-attachment-id="784" data-permalink="https://malwr-analysis.com/blg20_11072020_13/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png" data-orig-size="1669,319" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_13" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_13.png 1669w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Then it creates a process and execute PFSDNKDF.exe file. </p>



<div><figure><img data-attachment-id="789" data-permalink="https://malwr-analysis.com/blg20_11072020_15/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_15.png" data-orig-size="1010,94" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_15" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_15.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_15.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_15.png?w=1010" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_15.png 1010w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_15.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_15.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_15.png?w=768 768w" sizes="(max-width: 1010px) 100vw, 1010px"></figure></div>



<p>After that it closes the document or will prompt to save the changes if any changes has done to document. </p>



<div><figure><img data-attachment-id="791" data-permalink="https://malwr-analysis.com/blg20_11072020_16/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_16.png" data-orig-size="458,114" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_16" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_16.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_16.png?w=458" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_16.png?w=458" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_16.png 458w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_16.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_16.png?w=300 300w" sizes="(max-width: 458px) 100vw, 458px"></figure></div>



<div><figure><img data-attachment-id="774" data-permalink="https://malwr-analysis.com/blg20_11072020_10/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_10.png" data-orig-size="521,95" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_10" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_10.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_10.png?w=521" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_10.png?w=521" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_10.png 521w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_10.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_10.png?w=300 300w" sizes="(max-width: 521px) 100vw, 521px"><figcaption><sub>Process monitor captured when exe is written to localtion C:\1\Whole path</sub></figcaption></figure></div>



<p><strong>Dropped File:</strong></p>



<p>MD5: 4C9C6B5B6DAA25B8DC274DD78FBC1AAA</p>



<p>File Name: psisdecd.dll</p>



<p>File Type: Win32 EXE</p>



<p>Signature: Microsoft Visual C++ 8</p>



<p>Family: IcedID</p>



<p>VT score: 56/72</p>



<div><figure><img data-attachment-id="801" data-permalink="https://malwr-analysis.com/blg20_11072020_17/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png" data-orig-size="1289,208" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_17" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png?w=900" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png?w=1024" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png?w=1024 1024w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png?w=300 300w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png?w=768 768w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_17.png 1289w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>IcedID is a banking Trojan type malware that allows attackers to utilize it to steal banking credentials of the victims. IcedID aka BokBot mainly targets businesses and steals payment information, it also acts as a loader and can deliver other viruses or download additional modules.</p>



<div><figure><img data-attachment-id="802" data-permalink="https://malwr-analysis.com/blg20_11072020_9/" data-orig-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_9.png" data-orig-size="515,255" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blg20_11072020_9" data-image-description="" data-medium-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_9.png?w=300" data-large-file="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_9.png?w=515" src="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_9.png?w=515" alt="" srcset="https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_9.png 515w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_9.png?w=150 150w, https://malwrhunter.files.wordpress.com/2020/07/blg20_11072020_9.png?w=300 300w" sizes="(max-width: 515px) 100vw, 515px"></figure></div>



<p>Using wireshak, I have seen this executable created network connection to below IPs and DNS resolved to: </p>



<figure><table><tbody><tr><td>SN</td><td>IP                                       </td></tr><tr><td>1</td><td>40.90.189.152</td></tr><tr><td>2</td><td>125.252.219.233</td></tr><tr><td>3</td><td>104.84.156.5</td></tr><tr><td>4</td><td>104.116.46.155</td></tr><tr><td>5</td><td>104.244.42.131</td></tr><tr><td>6</td><td>184.29.89.6</td></tr><tr><td>7</td><td>23.50.81.26</td></tr><tr><td>8</td><td>104.116.25.27</td></tr><tr><td>9</td><td>184.29.89.6</td></tr><tr><td>10</td><td>23.54.56.6</td></tr><tr><td>11</td><td>104.244.42.42</td></tr><tr><td>12</td><td>104.244.42.195</td></tr></tbody></table><figcaption>IP address contacted and sent and received data by malicious executable. </figcaption></figure>



<figure><figcaption>Urls contacted by malicious executable. </figcaption></figure>



<p><strong>Summary: </strong></p>



<ul><li>Word document drops executable PFSDNKDF.exe on opening document. </li><li>The dropped file is IceID trojan. </li></ul>



<p>Download sample: <a rel="noreferrer noopener" href="https://app.any.run/tasks/0f4ecdba-4659-4139-933f-0a1d30468f48/" target="_blank">Any.Run</a></p>



<p>Read more about <a href="https://any.run/malware-trends/icedid" target="_blank" rel="noreferrer noopener">IcedID</a></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://malwr-analysis.com/2020/07/12/word-macro-drops-icedid-trojan-malware-analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810275</guid>
            <pubDate>Sun, 12 Jul 2020 10:10:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AV1 Decoder Model]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810261">thread link</a>) | @clouddrover
<br/>
July 12, 2020 | https://norkin.org/research/av1_decoder_model/ | <a href="https://web.archive.org/web/*/https://norkin.org/research/av1_decoder_model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
      <p>Published June 24, 2020.</p>
      <p><em>Andrey Norkin is with <a href="https://www.netflix.com/">Netflix</a> Encoding Technologies.</em></p>
      <h2>Why codecs need decoder models</h2>
      <p>Most modern video codecs have some form of a decoder model. It may be called a 
      <a href="https://en.wikipedia.org/wiki/Video_buffering_verifier">video buffering verifier (VBV)</a>,
      as in MPEG-2, or a 
      <a href="https://www.microsoft.com/en-us/research/publication/a-generalized-hypothetical-reference-decoder-for-h-264avc/">
      hypothetical reference decoder (HRD)</a>, as in H.264/AVC and HEVC/H.265.
      Decoder models improve interoperability. A decoder model allows to determine whether a bitstream can be decoded by 
      a particular decoder. These models may also provide a decoder with instructions on  
      when to start decoding a frame to be able to display it on time.  
      </p>

      <p>Typically, a video decoder declares support of a certain profile and level. A profile may specify 
      video formats with respect to the bit depth and chroma subsampling and a set of coding tools 
      that a decoder needs to support to decode a bitstream. A level describes quantitative characteristics 
      of a video bitstream, such as resolution, frame rate, and bitrate. It is critically important for a video codec ecosystem 
      that decoders claiming support of a certain level 
      were capable of decoding any bitstream that complies with requirements for this  
      level and that content providers and encoder manufacturers could check whether streams they generate comply with 
      these requirements.</p>

      <p>To achieve these goals, <a href="https://aomediacodec.github.io/av1-spec/av1-spec.pdf"> AV1 specification</a>, 
      developed by the 
      <a href="https://aomedia.org/">Alliance for Open Media (AOM)</a>, defines a decoder model coupled with a system of  
      profiles and levels.  
      AV1 decoder model includes a smoothing/bitstream buffer, 
      a decoding process, and operations on the decoded frame buffers. This post can serve as an introduction to the 
      parts of the AV1 specification related to the decoder model and levels. 
      The rest of this post describes some basic AV1 concepts, the AV1 decoder model, and gives reasons behind decisions 
      made when developing it.
      For more details on the decoder model, the readers are referred to the 
      <a href="https://aomediacodec.github.io/av1-spec/av1-spec.pdf"> AV1 specification</a>.</p>

      <h2>High level structure of AV1 bitstream</h2>

      <p>At a higher level, AV1 structures are packetized in <em>Open Bitstream Units (OBU)</em>. Each OBU has a header, 
      which provides information identifying its payload (see <a href="#fig1">Fig. 1</a>). Examples of OBU types that can be present in AV1 video bitstreams are 
      sequence header OBU, frame header OBU, metadata OBU, temporal delimiter OBU, and  
      tile group OBU. A frame OBU consists of a frame header and tile group OBUs packed into one OBU to provide
      a more efficient representation of a common structure where the frame header data is immediately followed by the frame or tile group
      data.</p>
      <figure id="fig1">
      <img alt="" src="https://norkin.org/img/av1_dec_mod_obu_header.png">  
      <figcaption>
      <b>Fig. 1.</b> AV1 OBU syntax. OBU header is the first byte, the optional extension byte (second row) is signaled if the
      extention flag <var>e</var> is equal to 1.  
      </figcaption>
      </figure>

      <p>AV1 frame headers can be classified in two main types based on the value of a syntax element <var>show_existing_frame</var>. 
      Frame headers with <var>show_existing_frame</var> equal to 0 are regular frames that need to be decoded. 
      Frame headers with <var>show_existing_frame</var> equal to 1 specify a command to display a previously 
      decoded frame (indicated by <var>frame_to_show_map_idx</var>) at the presentation time specified in this frame header. 
      This mechanism facilitates frame reordering when the decoding order is 
      different from the display order. 
      </p>

      <p>Another AV1 concept is <em>temporal unit (TU)</em>, which consists of a <em>temporal delimiter OBU</em> and all OBUs following 
      this and preceding the next temporal delimiter OBU. TUs always follow increasing display order.
      If scalability is not used, a TU includes exactly one shown frame, i.e. a frame with <var>show_existing_frame</var> equal to
      1 or with <var>show_frame</var> equal to 1.   
      If scalability is used, all shown frames from different scalable layers in a TU correspond to the same presentation  
      time. A TU can also include frames with the <var>show_frame</var> flag equal to 0.
      Such frames are decoded but not immediately displayed. They are used to support frame reordering as described above. 
      Alternatively, an <em>overlay</em>
      frame can be send, which encodes the difference between a previously decoded frame, called the <em>alternative
      reference frame (ARF)</em>, and the source frame. This aspect of the AV1 bitstreams resembles the VP9 codec with
      its <em>superframes</em>.</p>

      <p>An example of segmenting a bitstream into temporal units is shown in <a href="#fig2">Fig. 2</a>. In the figure, the frame numbering is
      in the display order. The bitstream uses a 4-frame hierarchical-B prediction structure with three temporal layers. 
      Frames with <var>show_frame</var> equal to 0 are shown as cyan boxes, frames with <var>show_frame</var> equal to 1 as dark green boxes.
      <var>FrameHdr</var> 2 is a frame header with <var>show_existing_frame</var> flag equal to one, this frame points to a previously 
      decoded Frame 2. 
      </p>

      <figure id="fig2">
      <img alt="" src="https://norkin.org/img/av1_dec_mod_tu_bitstream.png">  
      <figcaption>
      <b>Fig. 2.</b> Bitstream split in TUs by temporal delimiters. Frames are numbered in display order. Bitstream uses a 
      4-frame hierarchical prediction structure. 
      Shown frames are in green, decoded but not shown frames are in cyan color.
      </figcaption>
      </figure>

      <h2>Smoothing buffer</h2>

      <p>The smoothing buffer is part of the AV1 decoder and is used to store an AV1 bitstream until the compressed data 
        is consumed by the decoder. The buffer is described by the so-called "leaky bucket" model. 
        The leaky bucket analogy is related to operation of the encoder, where compressed frames are dumped in the buffer 
        in chunks while the data leaves the buffer continuously at a constant rate. 
        The decoder buffer is a counter-part of the encoder one. Note that smoothing buffer is internal to the decoder. Often,
        decoding systems would have other buffers at a higher level, which are outside the scope of AV1 specification. From the 
        decoder model perspective, higher level buffers could be considered parts of the transmission channel contributing 
        to the overall delay. 
        For example, buffering related to the adaptive streaming would be considered part of the transmission channel from the 
        decoder viewpoint and is not discussed in this post. Also, the encoded bitstream may often be prepared in advance, 
        which can makes the delay
        rather long. However, such a long delay is generally not a problem for the model since it is cancelled out 
        in the equations.</p> 

        <p>The smoothing buffer makes sure that the decoder has enough internal memory to store   
        the data of the arriving (or read) bitstream. It also ensures that the compressed data of the next
        frame is in the buffer when the decoder needs it. The size of the smoothing buffer limits variations of the instantaneous 
        bitrate and restricts timing of the frame data consumption.</p>

        <p>The AV1 decoder model only supports the <a href="https://en.wikipedia.org/wiki/Variable_bitrate">variable 
        bitrate (VBR)</a> mode of operation and not a <a href="https://en.wikipedia.org/wiki/Constant_bitrate">constant 
        bitrate (CBR)</a> mode. The VBR mode of the decoder model is an abstraction, where the 
        rate is alternating between the maximal level bitrate and zero. It may sound restrictive. 
        However, this model is adequate for the task of making sure the bitstream matches decoder capabilities, where 
        the worst case is important.</p>

        <p> A diagram of the smoothing buffer fullness over time is shown in <a href="#fig3">Fig. 3</a>. The clock starts with the
         arrival of the first bit related to frame 0. The slope of the 
         slanted line corresponds to the rate of bits arrival. <var>Removal</var>[ <var>i</var> ] corresponds 
         to the moment when the data of frame <em>i</em> is removed from the buffer and decoding of frame <em>i</em> begins.
         Note that there can be periods of time when new bits do not arrive, such as time after <var>Removal</var>[ 1 ]. 
         This matches periods of time when the encoder did not have bits to send, i.e. when the encoder buffer was empty.</p>

      <figure id="fig3">
      <img alt="" src="https://norkin.org/img/av1_dec_mod_smoothing_buffer.png">  
      <figcaption>
      <b>Fig. 3.</b> Smoothing buffer fullness over time.
      </figcaption>
      </figure>

      <p><var>Removal</var>[ <var>i</var> ] for frame <var>i</var> is defined depending on one of the two decoding modes. 
      In the <a href="#schedule_mode">decoding schedule mode</a>, these values are signaled in the bitstream. In the 
      <a href="#resource_mode">resource availability mode</a>, <var>Removal</var>[ <var>i</var> ] are derived based on
      the decoder operation. The start of the decoding, i.e. <var>Removal</var>[ 0 ], is determined by the variable  
      <var>decoder_buffer_delay</var> in both modes.</p>
      <p>Bits removed from the decoded buffer at time <var>Removal</var>[ <var>i</var> ] belong 
      to the <em>decodable frame group (DFG)</em> <var>i</var>, i.e. all OBUs between the end of the last OBU associated
      with frame <var>i</var> − 1 and the end of the last OBU associated with
      frame <var>i</var>. OBUs in a DFG may include sequence header OBUs, frame and tile group OBUs, frame header OBUs, 
      and metadata OBUs.</p>
      <p>The arrival of the first bit of the DFG <var>i</var> in the smoothing buffer is determined by 
      <var>FirstBitArrival</var>[&nbsp;<var>i</var>&nbsp;],
      which is found as follows:
      </p><p>
      <var>FirstBitArrival</var>[ <var>i</var> ] = max ( <var>LastBitArrival</var>[ <var>i</var> − 1 ], 
      <var>LatestArrivalTime</var>[ <var>i</var> ] ).  
      </p>
      Respectively, arrival of the last bit of the DFG <var>i</var> is found as 
      <p>
      <var>LastBitArrival</var>[ <var>i</var> ] = <var>FirstBitArrival</var>[ <var>i</var> ] + 
      <var>CodedBits</var>[ <var>i</var> ] ÷ <var>BitRate<var>.
      </var></var></p>
      Finally, <var>LatestArrivalTime</var>[ <var>i</var> ] is determined as 
      <p>
      <var>LatestArrivalTime</var>[ <var>i</var> ] = <var>ScheduledRemoval</var>[ <var>i</var> ] − 
      ( <var>encoder_buffer_delay</var> + <var>decoder_buffer_delay</var> ) ÷ 90&nbsp;000.
      </p>
      <p>Good explanations on the relationship between the 
      <var>encoder_buffer_delay</var> and <var>decoder_buffer_delay</var> in the latter expression   
      along with other useful information can be found in 
      <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/RibasCorberaCR03.pdf">
      Ribas-Corbera et al, 2003</a>. The model assumes an encoder with a smoothing buffer that sends bits 
      at a constant rate and a decoder with a smoothing buffer that receives bits at that bitrate. 
      A general intuition for the sum …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://norkin.org/research/av1_decoder_model/">https://norkin.org/research/av1_decoder_model/</a></em></p>]]>
            </description>
            <link>https://norkin.org/research/av1_decoder_model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810261</guid>
            <pubDate>Sun, 12 Jul 2020 10:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growing Risks in the Software Supply Chain]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810247">thread link</a>) | @msolujic
<br/>
July 12, 2020 | https://platformsecuritysummit.com/2019/speaker/sherman/ | <a href="https://web.archive.org/web/*/https://platformsecuritysummit.com/2019/speaker/sherman/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <h3 id="growing-risks-in-the-software-supply-chain">Growing Risks in the Software Supply Chain</h3>
<p><strong>Mark Sherman</strong>
<br>
<em>Carnegie Mellon University</em></p>
<p>
Today’s software is largely assembled rather than written, and most of the assembly comes from open source components. The creation of components and their inclusion into applications creates a “supply chain” just like in conventional manufacturing. While physical supply chains have well established chains-of-custody to establish properties like refrigeration maintenance, authenticity or spoilage avoidance, the software supply chain is very much a wild, wild west, filled with vulnerabilities that can be (and are) inadvertently inserted into applications.
</p>
<p>
As supply chain risk and mitigations are being explored by government and academia, a larger attack surface is being uncovered that needs to be addressed. This presentation describes the parts of the software supply chain, how vulnerabilities have been introduced, the growing attack surface from new methods of building and distributing software, and the actions that developers can employ to avoid or mitigate the risks inherent in an assembly-based software development strategy.
</p>






<h3 id="resources">Resources</h3>

<ul>
  <li><a href="https://first.org/">Forum of Incident Response and Security Teams (FIRST)</a> — <a href="https://www.first.org/cvss/workitems">CVSS v4.0</a></li>
  <li>NTIA, <a href="https://www.ntia.doc.gov/SoftwareTransparency">Software Component Transparency</a> —  <a href="https://www.ntia.doc.gov/files/ntia/publications/ntia_sbom_formats_and_standards_whitepaper_2019_0904.pdf">SBOM Survey</a> (2019)</li>
  <li>NIST, <a href="https://csrc.nist.gov/CSRC/media/Presentations/RMF-2-0-Risk-Management-Framework-Simplify-Inno/images-media/sp800-37r2-ipd-rollout-DOJ-20180509.pdf">Risk Management Framework 2.0</a> (2018)</li>
  <li>ATOS, <a href="http://www.qsos.org/method">Method of Qualification and Selection of Open Source software (QSOS)</a> (2013)</li>
  <li>FinServ ISAC, <a href="http://docs.ismgcorp.com/files/external/WP_FSISAC_Third_Party_Software_Security_Working_Group.pdf">Appropriate Software Security Control Types for Third Party Service and Product Providers</a> (2013)</li>
  <li><a href="https://www.us-cert.gov/Information-Sharing-Specifications-Cybersecurity">TAXII, STIX and CybOX</a></li>
</ul>

<h3 id="references">References</h3>

<ul>
  <li>Sonatype, <a href="https://www.sonatype.com/hubfs/SSC/2019%20SSC/SON_SSSC-Report-2019_jun16-DRAFT.pdf">State of the Software Supply Chain</a> (2019)</li>
  <li><em>Graham</em>, <a href="https://www.alienvault.com/blogs/security-essentials/software-bill-of-materials-sbom-does-it-work-for-devsecops">Software Bill of Materials (SBoM) - Does It Work for DevSecOps?</a> (2019)</li>
  <li><em>Alberts et al</em>, <a href="http://www.crosstalkonline.org/storage/issue-archives/2017/201705/201705-alberts.pdf">Assessing DoD System Acquisition Supply Chain Risk Management</a> (2017)</li>
  <li><em>Axelrod</em>, <a href="http://www.crosstalkonline.org/storage/issue-archives/2014/201403/201403-Axelrod.pdf">Malware, Weakware and the Security of Software Supply Chains</a> (2014)</li>
  <li><em>Christey &amp; Martin</em>, Buying Into the Bias: Why Vulnerability Statistics Suck: <a href="https://media.blackhat.com/us-13/US-13-Martin-Buying-Into-The-Bias-Why-Vulnerability-Statistics-Suck-Slides.pdf">slides</a> · <a href="https://www.youtube.com/watch?v=3xs1oWWA6pY">video</a> (Blackhat 2013)</li>
  <li><em>Clark et al</em>, <a href="https://www.researchgate.net/profile/Stefan_Frei2/publication/221046575_Familiarity_breeds_contempt_The_honeymoon_effect_and_the_role_of_legacy_code_in_zero-day_vulnerabilities/links/0deec5270217aa6357000000/Familiarity-breeds-contempt-The-honeymoon-effect-and-the-role-of-legacy-code-in-zero-day-vulnerabilities.pdf?origin=publication_detail">Familiarity Breeds Contempt: The Honeymoon Effect and the Role of Legacy Code in Zero-Day Vulnerabilities</a> (2010)</li>
</ul>

<h3 id="presenter">Presenter</h3>

<ul>
  <li><a href="https://resources.sei.cmu.edu/asset_files/Presentation/2017_017_001_495829.pdf">Risks in the Software Supply Chain</a> (2017)</li>
</ul>



<ul>
  <li><a href="https://cyber-itl.org/">Cyber Independent Testing Lab (CITL)</a></li>
  <li>Linux Foundation, <a href="https://github.com/coreinfrastructure/best-practices-badge/blob/master/doc/criteria.md">Core Infrastructure Initiative (CII) Best Practices for FLOSS</a></li>
</ul>




  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://platformsecuritysummit.com/2019/speaker/sherman/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810247</guid>
            <pubDate>Sun, 12 Jul 2020 10:03:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Phi φ Accrual Failure Detection]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23810066">thread link</a>) | @arpitbbhayani
<br/>
July 12, 2020 | https://arpitbhayani.me/blogs/phi-accrual | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/phi-accrual">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>One of the most important virtues of any distributed system is its ability to detect failures in any of its subsystems before things go havoc. Early detection of failures helps in taking preventive actions and ensuring that the system stays fault-tolerant. The conventional way of failure detection is by using a bunch of heartbeat messages with a fixed timeout, indicating if a subsystem is down or not.</p>
<p>In this essay, we take a look into an adaptive failure detection algorithm called <em>Phi Accrual Failure Detection</em>, which was introduced in a <a href="https://pdfs.semanticscholar.org/11ae/4c0c0d0c36dc177c1fff5eb84fa49aa3e1a8.pdf">paper</a> by Naohiro Hayashibara, Xavier Défago, Rami Yared, and Takuya Katayama. The algorithm uses historical heartbeat information to make the threshold adaptive. Instead of generating a binary value, like conventional methods, it generates continuous values suggesting the confidence level it has in stating if the system crashed or not.</p>

<p>Accurately detecting failures is an impossible problem to solve as we cannot ever say if a system crashed or is just very slow in responding. Conventional Failure Detection algorithms output a boolean value stating if the system is down or not; there is no middle ground.</p>
<h2>Heartbeats with constants timeouts</h2>
<p>The conventional Failure Detection algorithms use <em>heartbeat</em> messages with a fixed timeout in order to determine if a system is alive or not. The monitored system periodically sends a heartbeat message to the monitoring system, informing that it is still alive. The monitoring system will suspect that the process crashed if it fails to receive any heartbeat message within a configured timeout period.</p>
<p>Here the value of timeout is very crucial as keeping it short means we detect failures quickly but with a lot of false positives; and while keeping it long means we reduce the false positives but the detection time takes a toll.</p>

<p>Phi Accrual Failure Detection is an adaptive Failure Detection algorithm that provides a building block to implementing failure detectors in any distributed system. A generic Accrual Failure Detector, instead of providing output as a boolean (system being up or down), outputs the suspicion information (level) on a continuous scale such that higher the suspicion value, the higher are the chances that the system is down.</p>
<h2>Detailing φ</h2>
<p>We define φ as the suspicion level output by this failure detector and as the algorithm is adaptive, the value will be dynamic and will reflect the current network conditions and system behavior. As we established earlier - lower are the chances of receiving the heartbeat, higher are the chances that the system crashed hence higher should be the value of φ; the details around expressing φ mathematically are as illustrated below.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/87240784-469c0a00-c43a-11ea-8689-9dc41eb1ccf1.png" alt="Phi Accrual Failure Detection"></p>
<p>The illustration above mathematically expresses our establishments and shows how we can use <code>-log10(x)</code> function applied to the probability to get a gradual negative slope indicating a decline in the value of φ. We observe how, as the probability of receiving heartbeat increases, the value of φ decreases and approaches <code>0</code>, and when the probability of receiving heartbeat decreases and approaches <code>0</code>, the value of φ tends to infinity ∞.</p>
<p>The φ value computed using <code>-log10(x)</code> also suggests our likeliness of making mistakes decreases exponentially as the value of φ increases. So if we say a system is down if φ crosses a certain threshold <code>X</code> where <code>X</code> is <code>1</code>, it implies that our decision will be contradicted in the future by the reception of a late heartbeat is about <code>10%</code>. For <code>X = 2</code>, the likelihood of the mistake will be <code>1%</code>, for <code>X = 3</code> it will be <code>0.1%</code>, and so on.</p>
<h2>Estimating the probability of receiving another heartbeat</h2>
<p>Now that we have defined what φ is, we need a way to compute the probability of receiving another heartbeat given we have seen some heartbeats before. This probability is proportional to the probability that the heartbeat will arrive more than <code>t</code> units after the previous one i.e. longer the wait lesser are the chances of receiving the heartbeat.</p>
<p>In order to implement this, we keep a sampled Sliding Window holding arrival times of past heartbeats. Whenever a new heartbeat arrives, its arrival time is stored into the window, and the data regarding the oldest heartbeat is deleted.</p>
<p>We observe that the arrival intervals follow a <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal Distribution</a> indicating most of the heartbeats arrive within a specific range while there are a few that arrive late due to various network or system conditions. From the information stored in the window, we can easily compute the arrival intervals, mean, and variance which we require to estimate the probability.</p>
<p>Since arrival intervals follow a Normal Distribution, we can integrate the <a href="https://en.wikipedia.org/wiki/Probability_density">Probability Density Function</a> over the interval <code>(t, ∞)</code> to get the probability of receiving heartbeat after <code>t</code> units of time. Thus the expression for deriving this can be illustrated below.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/87231591-fbe8a680-c3d5-11ea-9427-d4cd66e8e717.png" alt="Estimating probability of receiving another heartbeat"></p>
<p>We observe that if the process actually crashes, the value is guaranteed to accrue (accumulate) over time and will tend to infinity ∞. Since the accrual failure detectors output value in a continuous range, we need to explicitly define thresholds crossing which we say that the system crashed.</p>

<p>We can define multiple thresholds, crossing which we can take precautionary measures defined for it. As the threshold becomes steeper the action could become more drastic. Another major benefit of using this system is that it favors a nearly complete decoupling between application requirements and monitoring as it leaves the applications to define threshold according to their QoS requirements.</p>

<ul>
<li><a href="https://pdfs.semanticscholar.org/11ae/4c0c0d0c36dc177c1fff5eb84fa49aa3e1a8.pdf">The φ Accrual Failure Detector</a></li>
<li><a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal Distribution</a></li>
</ul>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/phi-accrual</link>
            <guid isPermaLink="false">hacker-news-small-sites-23810066</guid>
            <pubDate>Sun, 12 Jul 2020 09:18:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Being a Full Stack Developer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23809506">thread link</a>) | @ingve
<br/>
July 12, 2020 | https://shekhargulati.com/2020/07/12/on-being-a-full-stack-developer/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2020/07/12/on-being-a-full-stack-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6281">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I am doing software development for the last 15 years. Since I heard the term “Full Stack Developer” few years back I had a strong dislike for this term. To most people full stack developer is someone who can write frontend code, build backend APIs, and deploy applications to cloud. They can code in multiple programming languages(JS/Typescript, Golang/Java/C#/Python), knows enough to design and store data in either relational and NoSQL databases, follow DevOps practices (CI, Configuration management, etc.), knows about multiple architecture styles – Microservices, Monolithic, Serverless, and can at least deploy to one public cloud. Along with all this they also know and practice automation testing and can write clean, maintainable code.</p>



<p>In my 15 years of software engineering career I have grown technically by following many hypes and technology movements. It takes year to build proficiency in technologies and you have to keep evolving yourself.</p>



<ol><li>In my first four (2005-2009) years I got introduced to Agile and extreme programming so I started practicing automation testing, refactoring, and continuous integration since the beginning of my career.</li><li>In my next three (2009-2011) years I got associated with software craftsmanship movement so clean code, SOLID principles became part of me.</li><li>Then in the next three years(2011-2014) I got into NoSQL and cloud computing. I was OpenShift technology evangelist for a couple of years.</li><li>Then in the next five+ (2014-till now) got into DevOps, containerisation, functional programming(Scala, Haskell), React/Angular, Microservices, Serverless, and many other.</li></ol>



<p>I didn’t pick all these technologies in a couple of years. It took me 15 years. I followed different movements and I was at the right place at the right time. So, I end up riding these waves. One thing that is true with technologies is that once you have worked and seen plenty of them then most new technologies make sense easily to you. Many new things are just old rehashed stuff.</p>



<p>These days every young engineer I meet say they are a full stack developer. Most organisations are trying to hire full stack developers with 2-4 years of working experience. We are just fooling ourselves. There are even courses on full stack software development. We find new ways to mint money.</p>



<p>You can’t become a full stack developer in a couple of years. It takes years when you have strong interest in technology and work with good mentors on interesting software development projects over time. </p>



<p>If someone ask me today do if I consider myself a full stack developer then my answer will be No. I have strong preference for backend development but I can do other stuff if required.</p>



<blockquote><p>To me being a full stack developer has less to do with technology but it has more to do with learning and open mindset. The mindset needed to get things done and learn stuff on the job and in your free time. You don’t want to be labelled one thing or the another. You have to care about the whole stuff even when you work in one specific area. It takes years of effort to become proficient in a specific technology area. You can become an expert in one specific technology area but at the same time you should care about other pieces of your ecosystem as well.</p></blockquote>



<p>Let me share a small example. Few months back I had to help a team that was building an application with REST APIs written in Java Spring Boot, frontend written in Angular, and deployment on Azure. The team was rushed into development and timelines were very short. So, they end up taking many shortcuts. One of the shortcuts was that they didn’t use pagination. This all worked well during development when team was working with limited data but when customer testing team tested with realistic data application started giving performance and memory issues. Application code was fetching all the data from database doing filtering and transformation in Java process and dumping everything to frontend in the JSON payload.</p>



<p>The team estimated that to fix the 20 API endpoints they would require 20 man days. It would be combination of database , frontend, and backend developers that would get this done. This was a no go for the customer as it would impact project delivery. But when you have developers who only care and know about their areas you can’t do much. There are hand offs and integration points when people divide work along technology boundaries. It also leads to wasted effort.</p>



<p>In my view these are the situations where having full stack mindset is important. You have to know different aspects of your stack and get your hands dirty with them.</p>



<p>To conclude the example I took two days and got the full thing working i.e. database, backend, frontend. And deployed it to Azure using Kubernetes. It does not mean full application has to be built this way. I can quickly make code changes on already written frontend code but if you ask me to create a frontend app from scratch and care about all nitty-gritties of CSS along with the backend development then I might not be effective. There is a cost of context switching. The cost we pay when we switch between different technologies. I am not proficient in fronted development but I am good enough to reason it out and make changes if required.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2020/07/12/on-being-a-full-stack-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809506</guid>
            <pubDate>Sun, 12 Jul 2020 07:15:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Case Study: GoDutch.cash]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23809452">thread link</a>) | @pw
<br/>
July 11, 2020 | https://exsaasperated.com/2020/07/11/case-study-godutchcash.html | <a href="https://web.archive.org/web/*/https://exsaasperated.com/2020/07/11/case-study-godutchcash.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
<div>
<article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p>This is the first post that will actually talk about a real
SaaS-attempt. As some commenters have pointed out, previous posts
were a bit more.. meta. That’s fine, we own that, we were just
setting the scene a bit. Today we’ll be talking about
<a href="https://godutch.cash/">GoDutch.cash</a>, one of our projects.</p>
<div>
<figure>
<img src="https://exsaasperated.com/images/case-study-godutch/godutch-landing.png">
<figcaption>The GoDutch landing page.</figcaption>
</figure>
</div>
<h2 id="what-is-godutchcash">What is GoDutch.cash?</h2>
<p>Very simply, <a href="https://godutch.cash/">GoDutch.cash</a> is a platform where users can enter
expenses they’ve incurred in shared situations (unfortunately named
“Trips”, we didn’t have the foresight of global pandemics and things
unfolding.. it’d work for flatmates, split grocery bills, restaurant
outings, holidays, etc.), and the tool tells you who owes whom how
much.</p>
<h2 id="the-background-story">The background story</h2>
<p>We didn’t just sit down and start building GoDutch. It actually
started life as a humble Google Sheet. At some undefined point in the
past, we both used Android phones, so that worked well. However, in
about December 2018 i got an iPhone and wanted to keep it Google-free.
It turned out that Apple Numbers (their spreadsheet product) didn’t
work on Android, and i was being obstinate, not wanting Google on this
new phone. We might have briefly looked around at apps to solve the
issue, but we’re privacy nerds, not to mention extremely cheap, so we
ended up whacking something together for our own use. I think it was
something like a Thursday evening i sat down, before planning to leave
on a weekend away on Saturday morning. I mostly just used a whole lot
of <code>rails generate</code> to get my way out of a sticky situation, chucked
HTTP Basic Auth in front of the app, and flung it on
<a href="https://heroku.com/">Heroku</a>’s free tier. Life was good, life was
simple.</p>
<p>Fast-forward a few months, and we were still using the app ourselves,
made an actual login and authentication system with sharing of trips
between users, occasionally polishing rough edges and improving the
styling, to the point that we realised that with only a little more
effort it could reasonably be used by anyone.</p>
<p>It mostly languished a bit, because we didn’t go on trips <em>that</em>
often, and then the lockdown happened of course. A few weeks ago, a
friend suggested we dust off GoDutch and perhaps try and actually
monetise it. Why not, we thought.</p>
<h2 id="is-there-even-a-market">Is there even a market?</h2>
<p>There are quite a few competitors out there.<sup id="fnref:compet"><a href="#fn:compet">1</a></sup> We haven’t done a
serious competitive analysis, but it’s apparent to me even more
clearly than when we originally built GoDutch that competition would
be.. stiff.</p>
<h3 id="there-are-established-competitors-in-your-market-do-you-give-up">There are established competitors in your market. Do you give up?</h3>
<p>I think the answer is a resounding <strong>no</strong>. Just think how many
successful businesses not only thrive with under competition, but
would have had to start up amid stiff competition. Almost every
business out there, from car manufacturers, to banks, to corner
grocery stores – at one point, each one of them didn’t yet exist, and
at one point (or so i firmly believe) it all started with a few folks
around a table (kitchen, board room, whatever) saying “let’s do this
thing”.</p>
<p>Of course, some of them had backers with ultra deep pockets, or
mountains of combined experience starting businesses. But not all of
them. There would’ve been people with language disadvantages, a lack
of connections in a new city or country, or perhaps just someone
recently out of a job and in desperate need of something to feed their
kids – all kinds of stress, we don’t know that. Something i like to
remind myself of, is we often see other people being happy, or
successful, or doing their thing, and we imagine they must be so
confident, and so knowledgeable, while we’re just muddling along. I
call that the front stage–back stage divide: you’re looking at
everyone else putting their best foot forward, performing for all the
other monkeys, while you’re aware of all the difficulty, uncertainty,
that goes on in the kitchen, behind the scenes, to make progress. I
might be wrong, but at least i’ll be optimistic.</p>
<p>This whole topic reminds me of an article i read,<sup id="fnref:mktg"><a href="#fn:mktg">2</a></sup> entitled something
along the lines of “thinking like a marketer versus an engineer”. The
gist of it was that the engineering mindset might say, “Oh no, that
brilliant idea has already been done! Well, i’ll just have to invent
some other, <em>untested</em> idea!” Whereas the marketer might say, “Aha,
successful competition means that there’s a validated market there,
i’ll build something similar with a small differentiation or edge.”</p>
<h2 id="our-angle-our-differentiator">Our angle, our differentiator</h2>
<p>We hoped that by charging a small amount ($15 per year) and making
bold claims about privacy and lack of ads, we could convince folks to
use our system. The design aimed to be fresh and cheeky, compared to
other apps that looked plain janky or were very stuffy.</p>
<p>We have a free tier where you can create one “trip”, and a premium
tier that allows you to create infinite trips and collaborate on them
with other users of the platform. So, if a group of friends goes
skiing together, only one of them needs to pay for GoDutch, the rest
of them can get invited and add and modify expenses on trips shared by
the premium user.</p>
<h2 id="so-was-it-a-success">So.. was it a success?</h2>
<p>Not really, no. I mean, we still use it to keep track of household
expenses (we GoDutched the purchase of the exsaasperated.com domain
name, in fact!), so it scratches our itch. But as of today we have
one “premium” user, and that’s a guy i know with a tech blog who was
kind enough to feature us.</p>
<h3 id="why">Why?</h3>
<p>I hazard a few guesses:</p>
<ul>
<li>
<p>Very well-SEO’d competitors, that offer a free product that does
pretty much all of what we do – no margins to eat.</p>
</li>
<li>
<p>Not many people actually sweat this stuff! They probably just take
turns paying for lunches.</p>
</li>
<li>
<p>Ineffectual marketing campaign – we haven’t been able to get enough
eyes on it, perhaps. But i think this point is probably less of an
issue than the first two.</p>
</li>
</ul>
<h2 id="what-we-tried">What we tried</h2>
<p>We spent a small amount ($44.49) on ads. Specifically on Facebook and
Reddit ads. We found that Facebook’s targeting was super broad and
clunky, whereas Reddit allowed us to pick particular subreddits (such
as personal finance-related) to narrow our audience. While almost
nobody touched our ads on Facebook, we actually got a fair few clicks
(in the hundreds) from Reddit. <strong>None</strong> of them even signed up for our
permanent free tier though, which really surprised us. Probably we could try
to optimise the landing page some more, but i actually think that a)
people don’t really have this problem, and b) if they do, they’ll use
Google Sheets or one of the many other apps that are free.</p>
<h2 id="take-aways">Take aways</h2>
<p>I think there are two lessons for us here:</p>
<ul>
<li>
<p>Talk to users first, build an audience before building an app. In
the time since we launched GoDutch we’ve been reading a lot more
about small business, and that’s the advice we keep hearing.</p>
</li>
<li>
<p>Don’t over-build before releasing. Although, i don’t regret the
effort we spent on GoDutch, and i don’t think it has been wasted.
It’s working as a legitimate tool for our own use, and we’ve learned
random technical things from putting together another Rails app from
scratch.</p>
</li>
<li>
<p>Our name is better than the competition.</p>
</li>
</ul>
<p>Time for our next project!</p>
<h2 id="appendix">Appendix</h2>
<p>You’ve read this far. It has turned into a long post. I’m verbose,
sorry. As a reward, here are some of the entirely silly ads i came up
with sitting on the couch. We were purposely going for a mysterious /
gonzo feel. I’m not sure they’re that great, but hey, we had fun.</p>
<p><img src="https://exsaasperated.com/images/case-study-godutch/ad-parrots.jpg" alt="">
<img src="https://exsaasperated.com/images/case-study-godutch/ad-chick.jpg" alt="">
<img src="https://exsaasperated.com/images/case-study-godutch/ad-geese.jpg" alt="">
<img src="https://exsaasperated.com/images/case-study-godutch/ad-cat.jpg" alt=""></p>

<hr>

</div>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://exsaasperated.com/2020/07/11/case-study-godutchcash.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809452</guid>
            <pubDate>Sun, 12 Jul 2020 06:58:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Policy to Control Them All: Shared Modular Policies Agent-Agnostic Control]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23809374">thread link</a>) | @jonbaer
<br/>
July 11, 2020 | https://wenlong.page/modular-rl/ | <a href="https://web.archive.org/web/*/https://wenlong.page/modular-rl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wenlong.page/modular-rl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809374</guid>
            <pubDate>Sun, 12 Jul 2020 06:41:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting your entire web application using S3 and CloudFront]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 120 (<a href="https://news.ycombinator.com/item?id=23809318">thread link</a>) | @root993
<br/>
July 11, 2020 | https://www.sankalpjonna.com/posts/hosting-your-entire-web-application-using-s3-cloudfront | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/hosting-your-entire-web-application-using-s3-cloudfront">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>There are several ways to host an application on the internet, but the one that I am most familiar with is to use a web server such as Apache or NGINX where you can host all the static components of your application and also use it as a reverse proxy server to direct API calls.&nbsp;</p><p>‍</p><p>But recently I came across another way to host a web application which is more elegant, cost effective and has no need for maintenance. This method makes use of AWS S3 and AWS Cloudfront and it’s turned out to be significantly easier to set up, scales infinitely and is cheaper than the alternative.</p><p>‍</p><h4><strong>Why did we need S3 to host a web application?</strong><br></h4><p>The <a href="https://apps.shopify.com/whatsapp-chat-button" target="_blank">product</a> that I have built is currently architected in this way - we use an open source version of Nginx that is hosted on an AWS VPS instance which takes care of hosting our static files for our web app and also works as a reverse proxy server to send API calls to our backend applications.</p><p>This setup worked great so far because we have a limited number of users that need access to the application dashboard and there is no need for a CDN either because the users, especially the ones on a paid plan do not have any problem waiting a couple of seconds more for the website to load.</p><p>This requirement changed when there was a new feature requirement within our product. Our users are e-commerce merchants and most of them accept “Cash on delivery” as an option while accepting orders and this leaves a lot of room for fraud to occur where somebody places an order and selects the payment method as “Cash on delivery” without the intention to actually buy the product.</p><p>In order to fix this we introduced a feature where the customer who places a COD order gets an automated message on WhatsApp to confirm their order via a link.</p><figure id="w-node-c4a1f5223dce-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c3967fc45b644bd89_23sxkg2VnH0KczPacTa60TpnJXRd675pY-TD7m1i8DzhDDZvosqX5cXv9tXTpgyHrF6Rd_PM_-xv37qWKFQOsc6Bx818rC_OcCfJxhfHC-FojE8HjpC9EXqQL_jVq8DJbeIynX31.png" alt=""></p><figcaption>Automated WhatsApp message to confirm a COD&nbsp;order</figcaption></figure><p>Clicking on this link would open this web page</p><p>‍</p><figure id="w-node-11a95fb1ed82-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951bd3ce595371f24095_FScpPINWKrHotUgTY8aLaV9wlay9dcXXurWkK_Ce-jcsF07e5bxofrU9qjaSspkf5UvCAE40CvgKZ57KouSas0GsPBF_RHbLppjgiOhpGqLN0LbQiVIGd0f7yV9pw9pc2g5t6nEP.png" alt=""></p><figcaption>Reactjs web app used to confirm a COD&nbsp;order</figcaption></figure><p>Now this web page would be accessed by the customers that buy from the merchants that use our application, so the traffic to this page could be very erratic, not to mention the fact that it would come from various parts of the world where the users internet connection would also be erratic and vary according to the region.</p><p>Therefore it did not make sense to host this web page the way the rest of our application is hosted. This web app had the following requirements</p><ul role="list"><li>High availability from any part of the world</li><li>Fast load time</li><li>Ability to handle any amount of traffic</li><li>Not having the need to manage or monitor</li></ul><p>It turns out that all of these things can be achieved if you host the app using a combination of S3 and CloudFront which is the CDN offered by AWS.</p><h4><strong>How to host an application on s3</strong><br></h4><p>There is a comprehensive guide in the AWS documentation on how to do this - <a href="https://docs.aws.amazon.com/AmazonS3/latest/user-guide/static-website-hosting.html" target="_blank">link to documentation</a>.&nbsp;</p><p>The TL:DR for this is to Create an s3 bucket with the same name as the domain/subdomain where you want to host your web app.&nbsp;</p><p>For instance, our web page had to be hosted on<a href="http://cod.superlemon.xyz/" target="_blank"> cod.superlemon.xyz</a>, so this is what the s3 bucket would be called. After this there are a bunch of properties and settings that you would have to change on the bucket which are mentioned in the doc.&nbsp;</p><p>Once this is done, you can test whether it worked or not by using either of the below links based on the region where you are hosted</p><figure id="w-node-30ce7d6ec647-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c849c2b0521c7c2f0_AToH07QToYYzbJ9Hj3iliaW3JMuv0_jHNoaEopFciAvlAf-Ajqr0VpnnKS22_3du4E4vmnV-5Eh3fLajnyQ48kEFHFGjwpKVa_wTl7EXOQu2ZrOX_OgbBq1ba08CWAgeUKTuN0no.png" alt=""></p><figcaption>End points for verifying if the s3 hosting worked or not</figcaption></figure><p>Though the steps in the AWS doc are quite comprehensive, there is one gotcha here that you must keep in mind. If your web app runs on a framework like react which is what we are using, you must make sure that under the “static website hosting” settings of the AWS bucket, you set the index document as well as error document as index.html.</p><figure id="w-node-bc6f0af8aa89-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951ce32edcd6fc8e8c88_JNhV0zwqHr-nOGJWip4t3WDyp9wB8Ld7aXF3KHr30jHAeKpRQVkB_gUIG-Z911vMOLNRZplgM7vUasVAs5Wm7NUtxkTZS6-HI9YzPh2I78EAwCEezHDfzxR08lDBQu7z4aLBhXSX.png" alt=""></p><figcaption>S3 static web hosting settings</figcaption></figure><p>This is to ensure that if you have any URL routes set up in your react application, those routes are honoured.&nbsp;</p><h4><strong>How to put the s3 application behind a CDN</strong><br></h4><p>The above step only completes one step of the process where your application is now residing in s3. But the process is only complete if the application is accessible as a CDN. For this you would have to use CloudFront and configure it to use your s3 bucket as the source. A comprehensive documentation for this process is given <a href="https://aws.amazon.com/premiumsupport/knowledge-center/cloudfront-https-requests-s3/" target="_blank">here</a>.&nbsp;</p><p>There are a few gotchas here as well. The first one being that you will require an SSL certificate to host your application as <strong>https://</strong>. You can get an SSL certificate easily using <a href="https://aws.amazon.com/premiumsupport/knowledge-center/install-ssl-cloudfront/" target="_blank">AWS Certificate manager</a>. This process becomes even more easy if you are using Route53 to manage your domains and subdomains. Even if you use another provider like Godaddy or Bigrock for your domains, I would highly recommend following <a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/migrate-dns-domain-in-use.html#migrate-dns-change-name-servers-with-provider" target="_blank">these steps</a> to plug in your domains to Route53.&nbsp;</p><p>The other gotcha here is once again something to do with reactjs URL routing. If you are using this in your application, there is another step that you have to follow. Under your CloudFront distribution, you must navigate to error pages and create a new custom error response as follows</p><figure id="w-node-a5d3bf85872d-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c40228a0a31b66d85_Xtn0dT_NkHLal0TU8T9vqg_t9AGSxaLs9wvMlIbGxfXCIrH7coSBdYVtZQdkiJJI6oj6WtfPpMjYius2H4gDZrX1_29_TwlPOiHrWeB24cS65VzitHgu9yK5U43S0ByQf3Z4l7uc.png" alt=""></p><figcaption>CloudFront distribution error pages settings</figcaption></figure><figure id="w-node-283c3bc077ec-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c8fbf67d9dc26bd63_XTsEDUFowLfUmq3r3YixmsOrB-fMsmIqSr2r5HiymcBaBxt79EQiVT-1qZM3Aps7l27IZNzbSDSxRCZ-FV7HPUu3utQckFitE1tjnr_Stn9YA_HSgjwjB-rQwiD6lC48o0BhiBVg.png" alt=""></p><figcaption>CloudFront distribution handling 403 error</figcaption></figure><p>This will ensure that if the CDN is not able to find the URL path you specify, it will default to index.html which will handle the routing in case of a reactjs application.&nbsp;</p><p>After finishing all these steps you will receive a url for your CloudFront distribution that looks something like this -<a href="https://dohgltcrfo5nj.cloudfront.net/" target="_blank"> dohgltcrfo5nj.cloudfront.net</a>. You just need to use this URL as an alias and map it to your domain/subdomain which in our case is<a href="http://cod.superlemon.xyz/" target="_blank"> cod.superlemon.xyz</a></p><figure id="w-node-ec229573544f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951ccd92d9716216562a_S_OJrarz5VxJWIVBHKu-wpg2Ine5qGjwdGzIb0Ban3S5Ya41_TbycPcpfnL5IQbu73mNS7oMmqNsrTQjatzC1qUSgsuy5q_CGEL25PITgZlWNJ3xUouo0G-DkloWeR_zPIfW9qA2.png" alt=""></p><figcaption>Route53 subdomain targeting</figcaption></figure><p>And that’s it, it's done! You now have a highly available application which does not need to be monitored or managed. Once you launch your application this way, it is now on a CDN and if you have to update the application in the future, the CDN cache must be invalidated for the changes to take effect. This can be done under the “invalidations” tab.</p><figure id="w-node-4a1c808b9f87-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c64584095bc4b3701_5oYoQ3CFjxE69GyZKHZ1HlboCYnrtEcRAZok14fLisD0VU7JCm1s3416Q5roMUIWFy-XX7PzNWwXQ3ogLygpMhV1AsPciPjqGAs9E9Dyx1drA9qLf6GmDCN_1otqPOhMwJ3ep9ei.png" alt=""></p><figcaption>CloudFront cache invalidation</figcaption></figure><p>Then supply all the paths that have been updated and you would like the CDN cache to invalidate. If you would like to invalidate the entire app, just enter "*".</p><figure id="w-node-33b54a1119a6-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951cde4cdd2f582b3238_7JLSDXaOYN0gpc6dfgedqOpLyO9yFs-WDTLFGyWvpj10HJbsQjynURxaWOBo4TfuI1P8J8Xma0R2D3Z1dEbAm-SLZR-gptJVZkuySjNGJN1DMsMm1ma9h_EBs-lOoL64BlgY0ZlZ.png" alt=""></p><figcaption>CloudFront cache invalidation for specific paths</figcaption></figure><h4><strong>Closing notes</strong><br></h4><p>This approach works great for a use case where the web application is mostly static and can be completely decoupled from the backend applications.&nbsp;</p><p>In terms of cost, with this approach you will only incur the CDN cost since the s3 storage cost for any web application would be quite low and the CDN cost will depend on how much traffic you have so it would scale well with usage.&nbsp;</p><p>For reference, we had around 100k hits on our web page in the month of June and our cost was roughly 0.79$</p><figure id="w-node-724c6c1a2415-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5f0a951c14ae487790c28040_oj2_EYWg5l2I2CbcSiZVf4aPvLlR2zey8lD9JlrvJP2GtwSc1tOLJ-loHFeSl2qCpweRm5cPgPg6nPhlPs_HtHHmnTNpDr52NwU3zKLXtQcJWFuhqyGPBoCGfK1KJahaqMpN5QWK.png" alt=""></p><figcaption>Our cost for this setup in the month of June</figcaption></figure></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/hosting-your-entire-web-application-using-s3-cloudfront</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809318</guid>
            <pubDate>Sun, 12 Jul 2020 06:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do (Some) Chinese People Pick 'Weird' English Names for Themselves?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23809255">thread link</a>) | @hunglee2
<br/>
July 11, 2020 | https://yiqinfu.github.io/posts/chinese-people-weird-english-names/ | <a href="https://web.archive.org/web/*/https://yiqinfu.github.io/posts/chinese-people-weird-english-names/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-body">
                    

<p>If you’ve spent some time in China, especially as an English teacher, you would probably know a few Tigers, Luckys, or Pizzas. Why do some Chinese people pick “funny” names for themselves?</p>

<p>Here’s my theory: In China, most people share a few common family names and thus distinguish themselves by having unique given names. The opposite is true in Europe and the U.S. – common given names, unique family names. Thus, when Chinese students give themselves English names, they try to pick words that are as unique as possible, similar to how their parents picked their Chinese names.</p>

<h2 id="family-names-unique-in-the-u-s-and-the-u-k">Family Names - Unique in the U.S. and the U.K.</h2>

<p>Below are the three most common family names in China, the U.S., and the U.K., as well as their share of the country’s population. It’s clear that family names are a lot more concentrated in China than in the U.S. or the U.K.</p>

<table>
<thead>
<tr>
<th>China</th>
<th></th>
<th>U.S.</th>
<th></th>
<th>U.K.</th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td><strong>Family Name</strong></td>
<td><strong>% of Population</strong></td>
<td><strong>Family Name</strong></td>
<td><strong>% of Population</strong></td>
<td><strong>Family Name</strong></td>
<td><strong>% of Population</strong></td>
</tr>

<tr>
<td>Wang 王</td>
<td>7.25</td>
<td>Smith</td>
<td>0.79</td>
<td>Smith</td>
<td>0.76</td>
</tr>

<tr>
<td>Li 李</td>
<td>7.19</td>
<td>Johnson</td>
<td>0.62</td>
<td>Jones</td>
<td>0.61</td>
</tr>

<tr>
<td>Zhang 张</td>
<td>6.83</td>
<td>Williams</td>
<td>0.53</td>
<td>Williams</td>
<td>0.46</td>
</tr>
</tbody>
</table>

<p><em>Sources: <a href="http://www.gov.cn/jrzg/2007-04/24/content_594226.htm">China</a>; <a href="https://www.census.gov/topics/population/genealogy/data/2010_surnames.html">U.S.</a>; <a href="https://www.bbc.com/news/uk-england-38003201">U.K.</a></em></p>

<h2 id="given-names-unique-in-china">Given Names - Unique in China</h2>

<p>Next, I plot the concentration of given names for the three countries. The U.S. and U.K. data is from administrative records, while the Chinese data is assembled from my various other projects (n=300k). The latter is by no means a representative sample of the country’s population, but I was able to confirm that the broad patterns in this non-representative dataset are similar to those seen in China’s 2010 Census.</p>

<p><img src="https://yiqinfu.github.io/images/cn-names/10.png" alt="10">
<img src="https://yiqinfu.github.io/images/cn-names/50.png" alt="50">
<img src="https://yiqinfu.github.io/images/cn-names/100.png" alt="100"></p>

<h2 id="conclusion">Conclusion</h2>

<p>A fifth of the Chinese population shares just <em>three</em> family names. Thus, parents try to give as distinct a given name as possible to their children. The typical naming process involves opening a dictionary and finding (often esoteric) characters that embody the values the parents wish to impart on the child. For example, the parents may decide that they like the concept of light and shine. In Chinese, any character with the “sun” radical would work as a given name, e.g. 光, 明, 亮, 闪, 皓, 晖, 昭, 璨, 煜, etc. In English, however, the options would be quite limited, and parents in the U.S. and the U.K. typically do not start the naming process with some “values” in mind anyways.</p>

<p>Many Chinese people adopt the “find-a-unique-word” approach when picking their English names, so that’s why you may know a Shimmer Zhang or a Sparkle Wang. The broader trend in the U.S. and the U.K. is towards more and more unique given names, so maybe Shimmers and Sparkles won’t be that odd in a few decades!</p>

                </section></div>]]>
            </description>
            <link>https://yiqinfu.github.io/posts/chinese-people-weird-english-names/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809255</guid>
            <pubDate>Sun, 12 Jul 2020 06:08:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Sootopolis City]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23809178">thread link</a>) | @todsacerdoti
<br/>
July 11, 2020 | https://evoniuk.github.io/posts/sootopolis.html | <a href="https://web.archive.org/web/*/https://evoniuk.github.io/posts/sootopolis.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    <p>In the final gym in Pokemon Ruby and Sapphire there is a puzzle you have to solve before being able to challenge Gym Leader Wallace. It's arranged like this:</p>

    <img src="https://evoniuk.github.io/posts/images/RS_Sootopolis_Gym.png" alt="Sootopolis City Gym">

    <p>To solve it, you have to step on each block of ice exactly once in each of the three sections. Not only that, but the final block you step on in each section has to be the one situated before the ice slide leading to the next section. Once all the squares are stepped on in a section the ice slide turns into stairs, allowing access to the next section of the puzzle, and finally Gym Leader Wallace.</p>

    <p>In this article we'll build a program that solves this puzzle, and all puzzles like it, with about 50 lines of JavaScript.</p>

    <h2>Step 1: Defining the Problem</h2>

    <p>The first step to solving any type of problem is to define it. Because we are going to write a program to solve these puzzles, we need to have a means to represent all the information relevant to the problem. The fact that we're dealing with ice, or that our goal is to fight Wallce, isn't relevant. So first, we need to list out the nature of our problem, the constraints on it, and the conditions that define a solution:</p>

    <ul>
      <li>Tiles are layed out in a 2 dimensional rectangle.</li>
      <li>We must step on each tile of ice exactly once.</li>
      <li>We may not step on tiles with stones on them.</li>
      <li>We begin at the center of the bottom of the ice.</li>
      <li>We must end at the center of the top of the ice.</li>
    </ul>

    <p>With those conditions we have completely defined all the relevant information in our problem. Now that this is done we can address how to represent the problem in terms a computer can solve.</p>

    <p>Before going on, however, I should mention that there's actually a hidden assumption here: we are assuming that the same method can solve each of the three parts of the larger puzzle. In our case our assumption is obviously justified, but if the solution to one part of a problem depended on the solution to another this would not be the case. Always be careful to examine your assumptions to ensure that they're justified.</p>

    <h2>Part 2: Representing the Problem</h2>

    <p>This step often involves some aesthetic decisions, but in our case isn't particularly difficult.</p>

    <p>The way I've decided to represent the problem in our computer program is like so:</p>

    <ul>
      <li>The tiles will be represented as a 2 dimensional array.</li>
      <li>Stones and tiles that have been stepped on will be represented as a 1.</li>
      <li>Tiles that have not been stepped on will be represented as a 0.</li>
      <li>The starting position will be the middle element of the final row in our 2D array.</li>
      <li>The final position will be the middle element of the first row in our 2D array.</li>
    </ul>

    

    <p>This may not have been the represesntation that you had in mind, but it's what seemed sensible to me. There is rarely a single correct way to represent a problem (though there are always many wrong ways), so always be sure to consider your options. For this problem we might have used a 1 dimensional array and kept track of the number of rows and columns seperately, or we might have used booleans instead of 1's and 0's. Regardless, once a represesntation is decided it comes time to use it in order to generate solutions.</p>

    <h2>Part 3: Solving the Problem</h2>

    <p>Now comes the hard part. But also the fun part.</p>

    <p>Given the way that we have chosen to represent our problem, we might start writing our program by creating the representation of the first part of the puzzle:</p>

<pre><span>const</span> firstPuzzle = [
  [<span>0</span>, <span>0</span>, <span>1</span>],
  [<span>0</span>, <span>0</span>, <span>0</span>],
  [<span>1</span>, <span>0</span>, <span>0</span>],
];</pre>

    <p>This gives us something to work with.</p>

    <p>Now we want to plan how we're going to generally approach the problem.</p>

    <h3>Defining the Functions</h3>

    <p>The plan that I've adopted is this: we will have three functions,</p>

    <ul>
      <li><code>findSolutions</code></li>
      <li><code>traverse</code></li>
      <li><code>validate</code></li>
    </ul>

    <p><code>findSolutions</code> will be the function that coordinates our search for solutions. It will initialize the starting position and create an array <code>solutions</code> in which solutions will be recorded. It will also initialize the variable in which we record the paths taken.</p>

    <p><code>traverse</code> will recursively travel about the 2D array, recording where it has been, where it is, and the path it has taken. It will produce a depth-first search. This is the function that will do most of the work.</p>

    <p>Finally, <code>validate</code> will be a small function that simply checks if a solution has been reached as a function of where <code>traverse</code> has visited and where it currently is.</p>

    <p>That's the general scheme. Now we want to think about what sort of arguments we'll pass to each function, and then build them.</p>

    <p><code>findSolutions</code> only needs to take one argument, the 2D array representing the puzzle. We'll call this parameter <code>puzzle</code>, so we'll have <code>findSolutions(puzzle)</code>.</p>

    <p><code>traverse</code> is considerably more complicated. It has to know where it has traveled, where it currently is, and the path it's taken to get there. In addition to this, it also requires access to the <code>solutions</code> array created in <code>findSolutions</code>.</p>

    <p>Where it has traveled can be stored in a 2D array in the same format as <code>puzzles</code>. We will call this array <code>board</code>. Its current location is a combination of a row and column, so can be stored in an array in the format <code>[row, column]</code>, which we will call <code>place</code>. The path it has taken will be an array of the steps it has taken so far, which we will call <code>path</code>. With this we will get <code>traverse(board, place, path, solutions)</code>.</p>

    

    <p>Finally, we know <code>validate</code> will need to know where <code>traverse</code> has been and where it currently is. As such, we will need to pass it <code>board</code> and <code>place</code>, yielding <code>validate(board, place)</code>.</p>

    <p>With the functions defined, we can now start building them.</p>

    <h3>Building the Functions</h3>

    <p>We now know the interface of our three functions:</p>

    <ul>
      <li><code>findSolutions(puzzle)</code></li>
      <li><code>traverse(board, place, path, solutions)</code></li>
      <li><code>validate(board, place)</code></li>
    </ul>

    <p>Now all that's left is build their implementation.</p>

    <h4><code>findSolutions(puzzle)</code></h4>

    <p>This function only needs to initialize the variables it will end up passing to <code>traverse</code>. We know <code>traverse</code> requires knowledge of where it's been, where it is, and what steps it has taken, in addition to having access to a solutions array.</p>

    <p>As for recording where it's been, that role can be filled by <code>puzzle</code> itself initially. The initial position is the middle of the bottom of the board, and will be represented by the the variable <code>start</code>. The steps taken initially are none, and thus an empty array, and the solutions array can be initialized as an empty array.</p>

    <p>I've produced the above behavior in code like so:</p>

<pre><span>function</span> <span>findSolutions</span>(puzzle) {
  <span>const</span> start = [puzzle.length - <span>1</span>, (puzzle[<span>0</span>].length - <span>1</span>) / <span>2</span>];

  <span>const</span> solutions = [];
  <span>traverse</span>(puzzle, start, [], solutions);

  <span>return</span> solutions;
}</pre>

    <p>We now need to construct the function we call in the above code.</p>

    <h4><code>traverse(board, place, path, solutions)</code></h4>

    <p>To build a recursive function you need two things: a base case, and a recursive case.</p>

    <p>Our base case is a solved puzzle. Checking whether this condition is met will be handled in <code>validate</code>. In our base case we append <code>path</code> to <code>solutions</code>.</p>

    <p>In our recursive case we will look through the spaces above, below, left, and right of the current square and traverse the ones that are viable (i.e. they exist and have 0's on them).</p>

    <p>In order for our function to be able to perform the above behavior, it first needs to mark that it has been where it currently it is. This means that it will take <code>place</code> and mark the corresponding spot in the 2D array that represents the puzzle thus far. We need to be careful about this, however, as <code>board</code> is mutable, and we want a unique copy for each call of <code>traverse</code>. Because of this we will create a new board <code>newBoard</code> and ititialize it to be equal to <code>board</code>, except that we'll mark the current place as 1. We'll accomplish this with the following code:</p>

<pre><span>const</span> newBoard = [];
board.<span>forEach</span>(row =&gt; newBoard.<span>push</span>([].<span>concat</span>(row)));
newBoard[place[<span>0</span>]][place[<span>1</span>]] = <span>1</span>;</pre>

    

    <p>After this, we can check if <code>newBoard</code> represents a solution, and if so add add <code>path</code> to <code>solutions</code>. Given that solution-checking is handled by <code>validate</code>, we can do this with just two lines:</p>

<pre><span>if</span> (<span>validate</span>(newBoard, place))
  solutions.<span>push</span>(path);</pre>

    <p>Now we need to handle the recursive aspect of this function. The desired behavior is to look at all the adjacent squares and traverse them if they have a 0. If this is the case we will want to create new <code>place</code> and <code>path</code> variables to pass to the next call of <code>traverse</code>.</p>

    <p>The way we will do this is by creating two arrays, <code>newPlaces</code> and <code>newSteps</code>, to which we will add the new places and new steps created by the viable next steps. We will then loop through these arrays and call <code>traverse</code> with their data. Ignoring for now how we'll create these arrays, the code will look like this:</p>

<pre><span>const</span> newPlaces = [], newSteps = [];



<span>for</span> (<span>let</span> i = <span>0</span>; i &lt; newPlaces.length; i++)
  <span>traverse</span>(newBoard, newPlaces[i], path.<span>concat</span>(newSteps[i]), solutions);
</pre>

    

    <p>Now the only thing left to do is write the code that constructs <code>newPlaces</code> and <code>newSteps</code>.</p>

    <p>This code isn't particularly difficult, it's mostly just tedious case-checking. We need to ensure that we're not stepping out of the bounds of <code>newBoard</code>, in addition to making sure where we want to step doesn't have a 1. If these conditions are met we push the new place onto <code>newPlaces</code> and the direction of our step onto <code>newSteps</code>. For checking the space above this will look like</p>

<pre><span>if</span> (place[<span>0</span>] &gt; <span>0</span> &amp;&amp; newBoard[place[<span>0</span>] - <span>1</span>][place[<span>1</span>]] !== <span>1</span>) {
  newPlaces.<span>push</span>([place[<span>0</span>] - <span>1</span>, place[<span>1</span>]]);
  newSteps.<span>push</span>('<span>up</span>');
}</pre>

    <p>The other directions are very much analagous. They are as follows:</p>

<pre>
<span>if</span> (place[<span>1</span>] &gt; <span>0</span> &amp;&amp; newBoard[place[<span>0</span>]][place[<span>1</span>] - <span>1</span>] !== <span>1</span>) {
  newPlaces.<span>push</span>([place[<span>0</span>], place[<span>1</span>] - <span>1</span>]);
  newSteps.<span>push</span>('<span>left</span>');
}


<span>if</span> (place[<span>1</span>] + <span>1</span> &lt; newBoard[<span>0</span>].length &amp;&amp; newBoard[place[<span>0</span>]][place[<span>1</span>] + <span>1</span>] !== <span>1</span>) {
  newPlaces.<span>push</span>([place[<span>0</span>], place[<span>1</span>] + <span>1</span>]);
  newSteps.<span>push</span>('<span>right</span>');
}


<span>if</span> (place[<span>0</span>] + <span>1</span> &lt; newBoard.length &amp;&amp; newBoard[place[<span>0</span>] + <span>1</span>][place[<span>1</span>]] !== <span>1</span>) {
  newPlaces.<span>push</span>([place[<span>0</span>] + <span>1</span>, place[<span>1</span>]]);
  newSteps.<span>push</span>('<span>down</span>');</pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://evoniuk.github.io/posts/sootopolis.html">https://evoniuk.github.io/posts/sootopolis.html</a></em></p>]]>
            </description>
            <link>https://evoniuk.github.io/posts/sootopolis.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809178</guid>
            <pubDate>Sun, 12 Jul 2020 05:49:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teaching Programming for a Year]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23809050">thread link</a>) | @maestros
<br/>
July 11, 2020 | https://maestros.io/teaching-programming-for-a-year | <a href="https://web.archive.org/web/*/https://maestros.io/teaching-programming-for-a-year">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://maestros.io/teaching-programming-for-a-year</link>
            <guid isPermaLink="false">hacker-news-small-sites-23809050</guid>
            <pubDate>Sun, 12 Jul 2020 05:21:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CRDTs in a Nutshell]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808774">thread link</a>) | @todsacerdoti
<br/>
July 11, 2020 | https://amattn.com/p/riaks_two_contentions_and_crdts.html | <a href="https://web.archive.org/web/*/https://amattn.com/p/riaks_two_contentions_and_crdts.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://amattn.com/p/riaks_two_contentions_and_crdts.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808774</guid>
            <pubDate>Sun, 12 Jul 2020 04:20:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Millennials Are Killing Ham Radio]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23808659">thread link</a>) | @rmason
<br/>
July 11, 2020 | https://n0ssc.com/posts/583-millennials-are-killing-ham-radio | <a href="https://web.archive.org/web/*/https://n0ssc.com/posts/583-millennials-are-killing-ham-radio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>I just wanted to write this to start the conversation in order to disrupt amateur radio’s status quo, in response to K0NR’s blog, “<em><a href="http://www.k0nr.com/wordpress/2017/11/internet-destroying-amateur-radio/">Is The Internet Destroying Amateur Radio?</a></em>” This was a great analysis by Bob, and it really paints a picture of the current state of the hobby, including the apparent distaste for internet-connected amateur radio technologies.</p>
<p>And also because nobody else has had an article with this title, so why not?&nbsp; Despite being clickbait, the title isn’t wrong. Millennials are definitely killing ham radio, just like <a href="http://www.businessinsider.com/millennials-are-killing-list-2017-8">they’re killing everything else.</a> Here’s how.</p>
<p>Full disclosure: I am 25 years old. Also and this blog is a rant, full of unverifiable anecdotes and wild propositions, probably a few spelling errors, and many incoherent thoughts. Opinions are my own. QRZ OM’s beware.</p>

<p>The Hobbiest Computer movement of the 80s (all of you with a TRS-80) is now the hacker/maker movement, automating life with microcontrollers, tiny computers, and data centers.</p>
<p>Amateur radio is to The Baby Boomer and Generation X’s youth as IOT is to Millennials and Gen Y.</p>
<p>Interest in “talking to people on the radio” is waning; it’s about talking to machines, and enabling machines to talk to us. That’s why the maker movement is such a hit, especially now as commercial entities have also entered the fray with off the shelf IoT devices. I’m thankful for the the ARRL for realizing this critical market, and repping ham radio at many Makerfaires and Hackercons.</p>

<p>China controls hardware development and manufacturing. We (the US (Silicon Valley)) specialize in software. Homebrewing hardware from scratch isn’t going to be a thing in the next 20 years, because the ashes of failed electronic appliances from which many a ham radio Phoenix was born are no longer durable, salvageable, salvageable goods – once dead and broken, they’re trash.</p>
<p>Now is the time of software homebrewing, and the idea of ham radio as a means to an end.</p>
<p>The evidence:</p>
<ol>
<li>Heathkit, despite their resurrection, can’t figure their $h!+ out. They just can’t. Other kit companies (like Ramsey) have shut down, as well as Radioshack.</li>
<li>Elecraft stopped making thru-hole kits in favor of assembly projects with pre-populated surface-mount PCBs. Many other outfits stopped kit building entirely, because it’s just cheaper to have China do all of the fab and assembly.</li>
<li>Software defined radio, in general, is dominating the radio communications market, both from a hobbyist perspective (RTLSDR, HackRF), an academic one (GNURadio, USRP) to commercial and military (to name a few: cell phones, airband radios; weather, civil air, and tactical radar systems; radio observatories;<a href="https://en.wikipedia.org/wiki/Mobile_ad_hoc_network">&nbsp;MANET</a>; <a href="https://en.wikipedia.org/wiki/Joint_Tactical_Information_Distribution_System">JTIDS</a>)</li>
<li>The non-traditional sense of ham radio is quickly becoming a centerpiece, if not a regular side-item, of <a href="https://hackaday.com/">Hackaday</a>&nbsp;articles, makerspaces, and makerfaires.</li>
</ol>
<p>However,&nbsp; I will admit the <a href="https://heilsound.com/amateur-radio-post/the-pine-board-project/">Ham Nation Pineboard project</a> is particularly popular, and is doing a great thing bringing tubes back into focus and captivating/inspiring viewers to try it themselves, but I’m going out on a limb saying it’s probably most popular with their target demographic…a young person might be following along but it’s not changing the face of the hobby anytime soon. One of the student members of&nbsp; W0EEE (Missouri S&amp;T) is a die-hard tube fanatic, but to everyone else, he’s the tube guy.</p>
<p>Speaking of which – target demographic. The target demographic of every single amateur radio show, podcast, club, media outlet, society, magazine, livestream, or otherwise, is not young people.</p>
<p>The ARRL however, has been making a lot of good strides to engage the new generation of hams (<a href="http://www.arrl.org/news/arrl-expands-initiative-to-fire-up-collegiate-amateur-radio-clubs">1</a>)(<a href="https://www.instagram.com/arrlhq/">2</a>)(<a href="http://www.arrl.org/news/arrl-now-on-snapchat">3</a>)(<a href="http://www.arrl.org/news/arrl-represented-at-world-maker-fair-in-new-york-city-school-club-to-exhibit">4</a>), yet still, the ARRL can only do so much to interest younger people, which takes away resources from engaging their demographic core of white male retirees.&nbsp; For example – why no youth editor? I was the last one, before my editor, Khrystyne K1SFA, left the ARRL, which left a hole requiring them to kill the Youth Editor (<a href="http://n0ssc.com/blogs/arrlyouthcolumns">the articles still remain on their website</a>), and The Amateur Amateur (<a href="http://gary-ross-hoffman.com/Ham/index.html">which still exists at his website</a>). But why no top-level Youth Coordinator? Why not a report on the effort of, or a collaboration between, our Section Youth Coordinators in the <a href="http://www.arrl.org/field-organization">ARRL Field Organization Structure</a>? Are we all just relying on <a href="http://www.arrl.org/news/carole-perry-wb2mgp-set-to-host-her-30th-hamvention-youth-forum">Carole Perry</a>‘s and the late <a href="http://oralhistory.boulderlibrary.org/interview/oh1264/">Ellie and Rip Van Winkel’s</a>&nbsp;of the ham radio world to inspire and educate young people about ham radio? Surely there’s opportunity for ARRL, as well as every ham radio club out there.</p>

<p>No. From my experience over the last seven years, digital Amateur Radio is not intrinsically exciting to young people, as many have been touting. It is a lot better than voice and CW, but still exists the fact that as an individual, it’s a troubling process to decide where to spend your (mother’s) money – $300 on a DSTAR radio, $100 for a DMR, both full of people talking about how robotic they sound, or $400 for an HF station to do digital data modes, full of canned responses (PSK31) or hardly any response at all (FT8).</p>
<p>These are also communication between people, which begs the titular question posed by K0NR. People-to-people communication is trivial, and although some young hams (me) find it really cool to talk to people beyond shouting distance with the raw elements of a radio station,what’s much more interesting and impactful to the next generation is is the idea of people-to-machine communication. In other words, Digital Voice is dumb, Digital Data is smart, and the only ways to utilize digital data are explicitly NOT provided by the commercial manufacturers of amateur radio(1), but instead by Adafruit, Ubiquiti; HackRF, RFSpace, and USRP; and soon <a href="https://faradayrf.com/">FaradayRF</a>, among others.</p>

<h2>Remote Operating for HF</h2>
<p>Here’s where I disagree with K0NR’s analysis.</p>
<blockquote>
<p>Perhaps more importantly, we can’t really stop the impact of new technology. Oh, I suppose the amateur radio community could petition the FCC to restrict [internet assisted] use of ham radio. There could be regulations that limit the use of the internet being interconnected with Part 97 radio operation.</p>
</blockquote>
<p>I believe that remote operating, and other internet-assisted means of ham radio operation, are critical to youth engagement.</p>
<p>RemoteHamRadio is the shining example of where ham radio operating is heading. they have an awesome <a href="http://www.remotehamradio.com/youth/">Youth Program</a>, allowing young people that are:</p>
<p>– 25 years old or younger<br>– A General class or higher license<br>– A member of the ARRL<br>– Interested in or Experienced with in DXing/Contesting</p>
<p>to operate remote online stations for free.</p>
<p><a href="http://www.remotehams.com/">Remote Hams</a> is a totally free alternative, but it’s up to the host to restrict operation, which is frustrating when you’re clicking through servers, only to find it’s locked by membership to whatever radio club is hosting it.</p>
<p>Finally <a href="http://websdr.org/">WebSDR</a> and <a href="http://sdr.hu/openwebrx">OpenWebRX</a> are always open to everyone to receive tons of spectrum, remotely.</p>
<p>Despite that, it’s ultimately a much MUCH better solution in the short term for young hams to operate remotely, than it is to persuade their mom’s to fork up a relative ton of money for a radio, antenna, a pole if no trees are around…etc.</p>
<p>Because young people do not often have access to the the kind of money an HF radio station requires, I strongly believe to captivate more young people, we need to do more of one of these two things.</p>
<ol>
<li>Promote your club’s shack, your own shack to young people.</li>
<li>Put your shack on a remote service provider for others to use when you’re not.</li>
</ol>
<p>For young people to join the hobby, it’s critically important to&nbsp;<strong>bring ham radio where the young people are,&nbsp;</strong>which is, for the most part, the internet.</p>
<p>If I knew this when I was younger, my mom would have been around $900 richer!</p>
<h2>Ham Radio Hackathons</h2>
<p>One thing I’m thinking of&nbsp; starting up are Ham Radio Hackathons. I mentioned it<a href="http://n0ssc.com/posts/560-ham-radio-analysis-paralysis"> in a previous blog</a> which has surprisingly gotten a lot of traction with my <a href="http://n0ssc.com/wp-content/uploads/2017/11/T2miAyF.png">tiny contingent of readers</a>.</p>
<p>A hackathon isn’t a coding competition. It’s explained well in <a href="https://medium.com/hackathons-anonymous/wtf-is-a-hackathon-92668579601">this Medium article.</a> It goes even further than that, not limited to coders and engineers, but open to thinkers, doers, philosophers, system engineers, math people, teachers, students, artists, stakeholders…anyone with an interest in <strong>solving a problem with technology. </strong></p>
<p>Ham radio has a bunch of problems with technology.</p>
<ol>
<li>It’s far behind the curve. We’re spitting out digital modes faster than K9PG can work a sweep, but compared to what’s already on the shelf, why would anyone bother with ham radio?</li>
<li>When I think about software like Log4OM, LOTW, eQSL, and HRD, I get frustrated. It’s great software, and many volunteer hours have poured into their development, but it’s so feature dense, developed in vacuums, hard to use, buggy, and lacking in UX.&nbsp; A good example of software is Fldigi – it’s fast, and light…hence *<strong>FL*</strong>digi. APRS is really nifty, especially <a href="http://aprs.fi/">aprs.fi</a>, but a person needs too much stuff or really expensive radios to get on it via RF (most people seem to be going direct to APRS-IS anyway) and getting into the development side of it is making me pull my hair out, just starting with the fact it’s based on the Bell 202 modem invented in 1972!!! Are you $#!++!n&amp; me!? I mean, what a fantastic utilization of resources…in 1978. <a href="https://faradayrf.com/">It’s time for something fresh, now.&nbsp;</a></li>
<li>There are dozens of ham radio websites stuck in 1990 (two of them are in K0NR’s blog (<a href="http://www.on4kst.com/index.php">1</a>)(<a href="http://www.pingjockey.net/">2</a>)…I’d&nbsp; almost argue that ham radio is killing the internet!), it seems like every ham radio developer has to repeatedly reinventing the wheel with logging programs, everyone still uses email reflectors, tons of ham radio apps just crash upon startup, the Digital Voice debate (when we should really focus on digital data, breaking through the baudrate limitation, and interlinking everything), the logistical challenges of testing (3 VEs to proctor a test in person, c’mon…that’s not to say I don’t disagree with the lack of practical on-the-air knowledge in the newbie amateur radio generation; however I don’t think that’s not a fault of the amateur, that’s a fault on the lack of elmership to personally show them how it’s done).</li>
<li>What gets us …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://n0ssc.com/posts/583-millennials-are-killing-ham-radio">https://n0ssc.com/posts/583-millennials-are-killing-ham-radio</a></em></p>]]>
            </description>
            <link>https://n0ssc.com/posts/583-millennials-are-killing-ham-radio</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808659</guid>
            <pubDate>Sun, 12 Jul 2020 03:53:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US states' Covid-19 infection rates over the last 30 days – States above 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808469">thread link</a>) | @askaboutio
<br/>
July 11, 2020 | https://askabout.io/covid-19/ask/what-are-the-current-infection-rates-for-us-states/?activeCUSSIRTab=Above%201 | <a href="https://web.archive.org/web/*/https://askabout.io/covid-19/ask/what-are-the-current-infection-rates-for-us-states/?activeCUSSIRTab=Above%201">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://askabout.io/covid-19/ask/what-are-the-current-infection-rates-for-us-states/?activeCUSSIRTab=Above%201</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808469</guid>
            <pubDate>Sun, 12 Jul 2020 03:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Feature Flags Do and Don’t Make Sense]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808253">thread link</a>) | @nomdep
<br/>
July 11, 2020 | https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.redbubble.com/i/canvas-print/If-Else-Software-Developer-Joke-Beer-Lover-by-VaSkoy/33140544.5Y5V7" target="_blank"><img data-attachment-id="282" data-permalink="https://software.rajivprab.com/flag/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png" data-orig-size="896,1480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="flag" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=620" src="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" alt="" srcset="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182 182w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=364 364w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=91 91w" sizes="(max-width: 182px) 100vw, 182px"></a></figure></div>



<p>Over the past years, I’ve worked in multiple teams adopting very different strategies when it comes to feature flags. I’ve seen the pros and cons of both, and over time, I found myself disagreeing with any fundamentalist position on their use. There is a lot of nuance to this topic, and I think it is worth considering more carefully the various scenarios where feature flags do and do not make sense.</p>



<h2>The Reasons For</h2>



<p>There are a few major scenarios where feature flags make a lot of sense. The first is when it’s used for <a rel="noreferrer noopener" aria-label="A/B testing (opens in a new tab)" href="https://en.wikipedia.org/wiki/A/B_testing" target="_blank">A/B testing</a>, where you absolutely do want different behaviors for different users, based on their randomly assigned treatment. I’ve seen this strategy employed extremely well at Amazon where new features are gated by a “feature flag” that is actually controlled by an internal A/B testing framework. The framework randomly exposes some Amazon customers to the new feature, and then monitors their subsequent behavior in order to estimate the business impact of launching the feature.&nbsp;</p>



<p>I was initially skeptical, but was soon won over by how easy the framework was to use, and the valuable insights it provided on the benefits (or drawbacks) of certain features. “Flavor of the month” decisions were replaced with real data. And none of this is possible without the use of “feature flags” to dynamically toggle new features.</p>



<hr>



<p>Another great use case for feature flags, is when you’re working on a very complex epic that require many different sub-tasks to be completed in different parts of the system. Sub-tasks that are too numerous and invasive to be done in a single pull-request. </p>



<p>In such cases, trying to keep all these disparate changes in side-branches and coordinating a simultaneous merge and deployment, is a recipe for disaster. It’s far more manageable to gate any disruptive changes behind a master flag, merge and deploy all the sub-commits incrementally, and do a flag-flip once all the pieces are in place.</p>



<hr>



<p>One last use case for feature flags, is when you do not have control over your deployments. For example, consider the Facebook Android app, which contains code contributed by hundreds of different teams, all combined and deployed as a single binary. In such scenarios, performing rollbacks can be infeasible. For practical, political, bureaucratic or even marketing reasons. In such cases, feature flags allow your team to toggle new functionality or mitigate risky changes, without having to rollback or deploy any new binaries.</p>



<h2>Risk Aversion</h2>



<p>The above are all fantastic use cases for feature flags, but I’ve also seen teams get bogged down by policies that overreach in their use. For example, mandating that every single code change should be behind a feature flag, <em>“just in case we made a mistake”</em>.</p>



<p>Risk management should indeed be a priority for all teams. But there are better ways of doing this than relying on feature flags, especially if your team has control over its own deployments. The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/" target="_blank">vast majority of your bugs should be caught by your automated test suite</a> and/or QA process. And the last few stragglers should be handled using <a rel="noreferrer noopener" aria-label="incremental deployments, production alarms and rollbacks (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">incremental deployments, production alarms and rollbacks</a>.</p>



<p>Besides, as soon as any problem is detected, the recommendation at places like Google is to <a rel="noreferrer noopener" aria-label="rollback first and ask questions later (opens in a new tab)" href="https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons" target="_blank">rollback first and investigate the problem later</a>. When things are on fire, the last thing you want to do is root-cause the bug and figure out which flag-flip will safely fix the problem. And that may not even fix things – there’s no guarantee that even if your teammate tried to put his changes behind a feature flag, he didn’t inadvertently introduce a bug that cannot be solved by a flag-flip.</p>



<p>Feature flags are no substitute for the ability to do binary rollbacks, and they definitely aren’t a substitute for having a great automated test suite and a robust QA process. If you’re relying on feature flags to remedy production bugs, you should stop and evaluate your team’s practices. Risk aversion is often a smell of your team <a href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank" rel="noreferrer noopener" aria-label="entering into a doom loop which will only get worse and worse with time (opens in a new tab)">entering into a doom loop which will only get worse and worse with time</a>.</p>



<h2>Death By Feature Flags</h2>



<p>You may be wondering at this point why we shouldn’t use feature flags anyway. After all, <em>“defense in depth” …</em> and it never hurts to have more fine-grain flexibility right?</p>



<p>While feature flags are great in some cases, we should also keep in mind their costs. Software engineering is primarily an exercise in managing complexity. And each feature flag immediately doubles the universe of corner cases that your programmers have to understand, and your code is required to handle. <em>“But what would happen if Foo is enabled, Bar is disabled, and we do independent A/B tests on Baz and Kaz on the same day?”</em> In my experience, this combinatorial explosion in complexity can and <strong>will</strong> lead to bugs. Not to mention slowing down the speed at which your team can make any changes.</p>



<p><em>“But these feature flags are only temporary. You should be removing them as soon as possible!”</em></p>



<p>Sure, and we should also not allow our tech debt to accumulate and we should follow every single best-practice religiously. Unfortunately, this never happens in any corporate environment. Even in great teams, tech debt often gets de-prioritized in the face of new requests. Newcomers to the team or those on their way out, aren’t always disciplined enough to clean up their flags after a successful rollout. And sometimes, these tasks simply slip through the cracks and get forgotten.</p>



<p>There is no better illustration of this than the KCG debacle where a financial firm lost half a billion dollars and almost went bankrupt in 30 minutes, partly due to dead code that was behind a feature flag.</p>



<blockquote><p><a href="https://www.bugsnag.com/blog/bug-day-460m-loss"><em>The cause of the failure</em></a><em> was due to multiple factors. However, one of the most important was that a flag which had previously been used to enable Power Peg… Power Peg had been obsolete since 2003, yet still remained in the codebase some eight years later.</em></p><p><em>In 2005, an alteration was made to the Power Peg code which inadvertently disabled safety-checks which would have prevented such a scenario. However, this update was deployed to a production system at the time, despite no effort having been made to verify that the Power Peg functionality still worked</em></p></blockquote>



<hr>



<p>Feature flags are a powerful tool that can help you experiment with new features, manage the rollout of complex epics, and mitigate the problems associated with not controlling your team’s deployments. </p>



<p>But they come at a significant cost, in the form of code complexity, tech debt, slower development speeds, and inevitably, bugs. </p>



<p>As tempting as it may be, there is no silver bullet here. Weigh the pros against the cons, and use this tool judiciously when it makes sense to do so.</p>
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808253</guid>
            <pubDate>Sun, 12 Jul 2020 02:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PS/2 keyboard on a 65C02 breadboard computer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808183">thread link</a>) | @krallja
<br/>
July 11, 2020 | https://jacob.jkrall.net/ps2-on-65c02 | <a href="https://web.archive.org/web/*/https://jacob.jkrall.net/ps2-on-65c02">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body">
<div>
  <div>
    
    <div>


<div id="postunit-ps2-on-65c02">
  <div>
    <div>
        <h3><a href="https://jacob.jkrall.net/ps2-on-65c02">PS/2 keyboard on a 65C02 breadboard computer</a></h3>
        <p><img src="https://jacob.jkrall.net/image/2020/ps2_hero.jpg" alt="A 6502-based breadboard computer with a PS/2 keyboard"></p>

<p>I’ve been following Ben Eater’s series on
<a href="https://eater.net/6502">building a 6502 computer on a breadboard</a>.
Once I got the 65C22 VIA working with a bigger 4-line x 20-character
LCD display, I wondered if I could interface the computer directly
with an external keyboard. The IBM Personal System/2 (PS/2), released
in 1987, had what became a very commonly used keyboard and mouse
connector, which uses some convenient electrical signals for
interfacing with even-more-ancient technology like the
WDC 65C02 and 65C22 this breadboard computer is based on.</p>

<h2 id="physical-layout">Physical layout</h2>
<p>Electrically, PS/2 is very simple: power, ground, clock, and data.
The clock is driven by a microcontroller inside the keyboard, at a
rate around 10-16.7 kHz. The data line is valid when the clock is low.
Data and clock are open-collectors, so they can be connected directly to
the computer with pullup resistors.</p>

<p>I acquired a PS/2 connector and soldered four wires to the correct pins.
+5V on power, 0V on ground, and the keyboard flashed its three status lights
so I know I didn’t short it out or install the pins backwards. That’s good.</p>

<p><img src="https://jacob.jkrall.net/image/2020/ps2_solder.jpg" alt="PS/2 connector soldered to four wires"></p>

<p>I connected the PS/2 clock wire to <code>NMIB</code> (pin 6 on the DIP-40 W65C02S),
and tied it to the 5V rail using a 1kΩ pull-up resistor.
Because I was making hardware changes anyway, I also added a pushbutton
to <code>IRQB</code> (pin 4 of the W65C02S) for an easy way to trigger a second
kind of interrupt. (It helped a lot when debugging - in the interrupt
service handler, I could print whatever info I wanted.)
<img src="https://jacob.jkrall.net/image/2020/ps2_clk.jpg" alt="PS/2 Clock line tied to 65C02S NMIB"></p>

<p>Similarly, the data line is tied to <code>PA0</code> (pin 2 of the 40-pin W65C22)
with a 1kΩ pull-up resistor as well.</p>

<p><img src="https://jacob.jkrall.net/image/2020/ps2_data.jpg" alt="PS/2 Data line tied to VIA PA0"></p>

<h2 id="6502-interrupts">6502 interrupts</h2>
<p>The two interrupt pins on the 6502 are used slightly differently.
The non-maskable interrupt (<code>NMIB</code>) is edge-triggered, which generally
means only one interrupt source can use it. But that’s great for PS/2,
since we only want to interrupt on each clock signal once.</p>

<p>The interrupt request (<code>IRQB</code>) is level-triggered: the processor will
generate interrupts as long as interrupts are enabled and the input is low.
This means it’s much easier to service multiple devices, but there has to
be some way to clear the interrupt on the other end - and we don’t really have
that ability on the PS/2 bus, so it’s not a good choice, unless we want
to add some glue logic. That sounds expensive, and I don’t have a lot of
space left on my breadboard.</p>

<h2 id="using-some-nicer-vasm-flags">Using some nicer <code>vasm</code> flags</h2>
<p>The WDC65C02S supports some additional opcodes, so I’m going to let vasm
understand those with the <code>-wdc02</code> flag. I also added <code>-chklabels</code>, <code>-wfail</code>,
and <code>-x</code>. These warn when a label matches a mnemonic/directive, return an
error code on warnings, and show an error when referencing an undefined
symbol, respectively.</p>

<h2 id="do-nothing-interrupts">Do-nothing interrupts</h2>
<p>First, define two no-op interrupt handlers, <code>nmi</code> and <code>irq_brk</code>.</p>

<figure><pre><code data-lang="nesasm"><span>irq_brk:</span>
  <span>rti</span>

<span>nmi:</span>
  <span>rti</span></code></pre></figure>

<p>Set up the vectors for each of them - this replaces the <code>.org $fffc</code>
from Ben Eater’s video:</p>

<figure><pre><code data-lang="nesasm">  <span>.</span><span>org</span> <span>$fffa</span>
  <span>.</span><span>word</span> <span>nmi</span>
  <span>.</span><span>word</span> <span>reset</span>
  <span>.</span><span>word</span> <span>irq_brk</span></code></pre></figure>

<p>In our reset handler, we will need to enable interrupts with</p>

<figure><pre><code data-lang="nesasm">  <span>cli</span></code></pre></figure>

<p>Now, it’s time to declare and initialize some memory. First,
name four bytes in the zero-page:</p>

<figure><pre><code data-lang="nesasm"><span>KEY_BUF_X</span> <span>=</span> <span>$00</span>
<span>KEY_READ_X</span> <span>=</span> <span>$01</span>
<span>PS2_BIT_NUMBER</span> <span>=</span> <span>$02</span>
<span>PS2_NEXT_BYTE</span> <span>=</span> <span>$03</span></code></pre></figure>

<p>The actual values aren’t important -
they’re pointers to bytes in the first 256B of RAM.</p>

<p>The first two, <code>KEY_BUF_X</code> and <code>KEY_READ_X</code> are offsets into a
256-byte circular array. Let’s name that array:</p>

<figure><pre><code data-lang="nesasm"><span>KEY_BUF</span> <span>=</span> <span>$0200</span></code></pre></figure>

<p>The second two variables are used for decoding the PS/2 byte. For now,
let’s initialize them all to zero in the <code>reset</code> handler.</p>

<figure><pre><code data-lang="nesasm">  <span>stz</span> <span>KEY_BUF_X</span>
  <span>stz</span> <span>KEY_READ_X</span>
  <span>stz</span> <span>PS2_BIT_NUMBER</span>
  <span>stz</span> <span>PS2_NEXT_BYTE</span></code></pre></figure>

<p>All of this does nothing, but we’ve reserved all the space in RAM
needed to decode the raw PS/2 byte stream.</p>

<h2 id="handling-the-interrupts">Handling the interrupts</h2>
<p>As I mentioned before, the PS/2 clock rate is between 10-16.7 kHz, and the
data line is only valid for the low half of the clock cycle.</p>

<p>My computer has a 1MHz clock, so that means we have 1M/16.7k = 59.88 cycles
to completely handle the NMI. And the data is only valid in the first half.</p>

<p>The WDC65C02 takes 6 (or 7?) cycles to process an interrupt, and can only
process an interrupt once the previous instruction has completed, so
we may already be 12 or 13 cycles in by the time we start the very first
instruction of the interrupt handler!</p>

<p>We’ll read PORTA from the 65C22 VIA, and need to use some bitmasking to get
the first bit. It would be very convenient if the high bit were set, instead
of the low bit, but I’m already using <code>PA7</code> for the <code>E</code> pin on the LCD, and
don’t want to break compatibility with Ben’s code just for convenience.</p>

<p>So, during the interrupt routine, I’ll rotate <code>PA0</code> into the <code>PA7</code> position,
and then mask it out.</p>

<p>Define the <code>PA7</code> bit mask:</p>

<figure><pre><code data-lang="nesasm"><span>KEY_DATA</span> <span>=</span> <span>%10000000</span></code></pre></figure>

<p>And update the NMI handler to write the PS/2 bit into <code>KEY_BUF</code>:</p>

<figure><pre><code data-lang="nesasm"><span>nmi:</span>
  <span>pha</span> <span>; preserve A register</span>

  <span>lda</span> <span>PORTA</span> <span>; the data bit is in the low bit of A</span>
  <span>ror</span>       <span>; the data bit is in the carry flag</span>
  <span>ror</span>       <span>; the data bit is in the high bit of A</span>
  <span>and</span> <span>#KEY_DATA</span> <span>; all other bits have been cleared</span>


  <span>; store A in KEY_BUF[KEY_BUF_X]</span>
  <span>phx</span>
  <span>ldx</span> <span>KEY_BUF_X</span>
  <span>sta</span> <span>KEY_BUF</span><span>,</span><span>x</span>
  <span>inc</span> <span>KEY_BUF_X</span>

  <span>; restore X,A in correct order</span>
  <span>plx</span>
  <span>pla</span>

  <span>; complete the interrupt</span>
  <span>rti</span></code></pre></figure>

<h2 id="decoding-the-bitstream">Decoding the bitstream</h2>
<p>Decoding a PS/2 bitstream takes a few more cycles than we can afford
in our non-maskable interrupt handler. So, the handler is wasteful
and writes the bit samples as bytes in a 256-byte circular buffer.</p>

<p>In our main loop, we can chase after the bitstream using a simple
state machine.</p>

<p>The states are defined by the number of bits we’ve seen.</p>

<p>First bit (state 0) is a start bit.
It’s followed by eight data bits (states 1-8), least-significant-first.
Then, there’s a parity bit (state 9).
Then, there’s a stop bit (state 10).</p>

<figure><pre><code data-lang="nesasm"><span>loop:</span>

<span>ps2_check_bit:</span>
  <span>lda</span> <span>KEY_READ_X</span>
  <span>cmp</span> <span>KEY_BUF_X</span>
  <span>beq</span> <span>loop</span>

<span>process_one_ps2_bit:</span>
  <span>lda</span> <span>PS2_BIT_NUMBER</span>
  <span>cmp</span> <span>#0</span>
  <span>beq</span> <span>ps2_start_bit</span>
  <span>cmp</span> <span>#9</span>
  <span>beq</span> <span>ps2_parity_bit</span>
  <span>cmp</span> <span>#10</span>
  <span>beq</span> <span>ps2_stop_bit</span>
  <span>; otherwise, fallthrough to ps2_data_bit</span>

<span>ps2_data_bit:</span>
  <span>; move the $80/$00 into the top bit of PS2_NEXT_BYTE</span>
  <span>ldx</span> <span>KEY_READ_X</span>
  <span>lda</span> <span>PS2_NEXT_BYTE</span>
  <span>ror</span>
  <span>and</span> <span>#$7F</span>
  <span>ora</span> <span>KEY_BUF</span><span>,</span><span>x</span>
  <span>sta</span> <span>PS2_NEXT_BYTE</span>

<span>next_ps2_bit:</span>
  <span>; advance the state machine</span>
  <span>inc</span> <span>PS2_BIT_NUMBER</span>
  <span>; advance the read-bit pointer</span>
  <span>inc</span> <span>KEY_READ_X</span>
  <span>; check if there are more bits to decode</span>
  <span>jmp</span> <span>ps2_check_bit</span>

<span>ps2_start_bit:</span>
  <span>; TODO: we could verify the start bit is correct</span>
  <span>jmp</span> <span>next_ps2_bit</span>
<span>ps2_parity_bit:</span>
  <span>; TODO: we could verify the parity bit is correct</span>
  <span>jmp</span> <span>next_ps2_bit</span>

<span>ps2_stop_bit:</span>
  <span>lda</span> <span>PS2_NEXT_BYTE</span>
  <span>; TODO: we could verify the stop bit is correct</span>
  <span>; TODO: we have successfully decoded the PS/2 byte</span>
  <span>;       into the A register.</span>
  <span>stz</span> <span>PS2_BIT_NUMBER</span>
  <span>inc</span> <span>KEY_READ_X</span>
  <span>; give the main loop (currently empty) a chance to run</span>
  <span>jmp</span> <span>loop</span></code></pre></figure>

<h2 id="reading-scan-codes">Reading scan codes</h2>
<p>PS/2 does not send ASCII, it sends scan codes. Most PS/2 keyboards
use the “Set 2” codes. The characters we are concerned with send a
one-byte “make” code when the key is pressed (and a few times per
second while the key is held), and a two-byte “break” code when the
key is released.</p>

<p>A nice abstraction would be to decode these scancodes into a buffer,
which would allow us to do line editing and so forth, but I’m just
going to print all the characters I recognize directly to the LCD.</p>

<p>In <code>ps2_stop_bit</code>, add a</p>

<figure><pre><code data-lang="nesasm">  <span>jsr</span> <span>print_ps2_key</span></code></pre></figure>

<p>and let’s go implement that now.</p>

<p>First, we need to create a map for the PS/2 scan codes. You can
sort of see how the key matrix is wired in the keyboard.</p>

<figure><pre><code data-lang="nesasm">  <span>.</span><span>align</span> <span>8</span>
<span>ps2_scan_codes:</span>
  <span>;       0123456789ABCDEF</span>
  <span>.</span><span>asc</span> <span>"??????????????`?"</span> <span>; 0</span>
  <span>.</span><span>asc</span> <span>"?????Q1???ZSAW2?"</span> <span>; 1</span>
  <span>.</span><span>asc</span> <span>"?CXDE43?? VFTR5?"</span> <span>; 2</span>
  <span>.</span><span>asc</span> <span>"?NBHGY6???MJU78?"</span> <span>; 3</span>
  <span>.</span><span>asc</span> <span>"?,KIO09??./L;P-?"</span> <span>; 4</span>
  <span>.</span><span>asc</span> <span>"??'?[=?????]?</span><span>\</span><span>??"</span> <span>; 5</span></code></pre></figure>

<p>Now, add another byte to the zero page so we can ignore break codes:</p>

<figure><pre><code data-lang="nesasm">  <span>PS2_IGNORE_NEXT_CODE</span> <span>=</span> <span>$04</span>

  <span>; ... in `reset`:</span>
  <span>stz</span> <span>PS2_IGNORE_NEXT_CODE</span></code></pre></figure>

<p>Finally, let’s implement the <code>print_ps2_key</code> subroutine:</p>

<figure><pre><code data-lang="nesasm"><span>print_ps2_key:</span>
  <span>; if we received #$F0 previously, ignore this byte</span>
  <span>bit</span> <span>PS2_IGNORE_NEXT_CODE</span>
  <span>bmi</span> <span>code_ignored</span>

  <span>; A is scan code.</span>
  <span>; see if we got a break code</span>
  <span>cmp</span> <span>#$F0</span>
  <span>beq</span> <span>ignore_next</span>

  <span>; Bounds check ps2_scan_codes</span>
  <span>cmp</span> <span>#$5F</span>
  <span>bpl</span> <span>too_high</span>

  <span>; index into ps2_scan_codes</span>
  <span>tax</span>
  <span>lda</span> <span>ps2_scan_codes</span><span>,</span><span>x</span>
  <span>jsr</span> <span>print_char</span>
  <span>rts</span>

<span>too_high:</span>
  <span>rts</span>

<span>ignore_next:</span>
  <span>lda</span> <span>#$FF</span>
  <span>sta</span> <span>PS2_IGNORE_NEXT_CODE</span>
  <span>rts</span>

<span>code_ignored:</span>
  <span>stz</span> <span>PS2_IGNORE_NEXT_CODE</span>
  <span>rts</span></code></pre></figure>

<p>There’s still a ton more work to do, like Shift, Backspace, arrow keys
and even outputting lines to the correct place on the screen. Like I
mentioned above, it would probably make more sense to store these ASCII
codes in a line buffer, or whatever suits your application’s purpose.
You could even use another circular buffer with chasing pointers.</p>

<p>But hey, at least we can say <code>HELLO, WORLD,</code> and that’s what matters.</p>

<h2 id="postscript-1-day-later">Postscript (1 day later)</h2>
<p>Fairly frequently, I saw extraneous NMIs. Since I’m not doing any
error checking on the stop/start/parity bits, this would appear as a
shifted bit in the byte stream. The first thing I changed was using
a 1kΩ resistor on the NMI pin instead of 1MΩ. I thought
the higher resistance was causing the voltage to rise too slowly.
It certainly helped, but I still could rarely type a full 80-character
page of text without seeing a desynchronization. I tried using a
faster 1.8432 MHz oscillator, to see if my interrupt code was too slow,
but that neither made sense, nor fixed the issue. (A 7.3728 MHz
oscillator was too fast for the existing LCD code. Needs <code>NOP</code>s.)
Finally, I wondered if the additional power demanded by the keyboard
(and its long cable) was still causing voltage drops.
I added another 10µF capacitor to the power rails,
near the PS/2 power wires, and now it is much better.
I still see desynchronization if I mash on the keyboard, but it’s
waaaaay more usable than it was.</p>

    </div>
  </div>
</div>

    </div>
  </div>
</div>
</div></div>]]>
            </description>
            <link>https://jacob.jkrall.net/ps2-on-65c02</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808183</guid>
            <pubDate>Sun, 12 Jul 2020 02:22:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up Continuous Deployment on Node.js App Using GitHub and HerokuC]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23808162">thread link</a>) | @sssaini
<br/>
July 11, 2020 | https://blog.sssaini.io/how-to-set-up-continuous-deployment-on-nodejs-app-using-heroku-and-github/ | <a href="https://web.archive.org/web/*/https://blog.sssaini.io/how-to-set-up-continuous-deployment-on-nodejs-app-using-heroku-and-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.sssaini.io/content/images/size/w300/2020/04/Blog-Post-Banner-02-2.png 300w,
                            https://blog.sssaini.io/content/images/size/w600/2020/04/Blog-Post-Banner-02-2.png 600w,
                            https://blog.sssaini.io/content/images/size/w1000/2020/04/Blog-Post-Banner-02-2.png 1000w,
                            https://blog.sssaini.io/content/images/size/w2000/2020/04/Blog-Post-Banner-02-2.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.sssaini.io/content/images/size/w2000/2020/04/Blog-Post-Banner-02-2.png" alt="How to set up Continuous Deployment on Node.js app using Github and Heroku">
            </figure>

            <section>
                <div>
                    <p>Continuous Deployment is awesome because you can forget about the infrastructure part of the development and only focus on the code. Heroku makes it incredibly easy to set it up using Github and Automatic Deploys.</p><hr><h3 id="create-a-new-project">Create a new project</h3><p>Fork the simple Nodejs project <a href="https://github.com/bdcorps/serve-static-website-nodejs">here</a>. Refer to this link for a detailed walkthrough. </p><p>Run it locally using, </p><pre><code>node app.js</code></pre><p>Go to <a href="localhost:3000">localhost:3000</a> and "Hello World" should appear on the screen. </p><h3 id="set-up-heroku-account">Set up Heroku account</h3><p>Login to your <a href="https://dashboard.heroku.com/">Heroku account</a>. </p><p>Click on New -&gt; <a href="https://dashboard.heroku.com/new-app">Create New App</a>. Give it a name. Click Create App. </p><p>Under Deployment &nbsp;method, click Connect to Github. Search for and connect your repository. </p><figure><img src="data:image/png;base64,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"></figure><p>Choose the branch you would like to be deployed. Default to master if unsure. </p><p>Enable Automatic Deployments.</p><figure><img src="https://blog.sssaini.io/content/images/2020/04/download--3-.png"></figure><p>Once you are ready to do an initial deploy, click Deploy Branch under Manual Deploy section.</p><figure><img src="https://blog.sssaini.io/content/images/2020/04/download--1-.png"></figure><p>It will try to run the project using the Node.js buildpack. If it is successful, a "Your apo was successfully deployed" message will appear. If the deployment failed, try restarting again from Step 1. </p><p>Open your app by clicking "View". The output should still be "Hello World". </p><figure><img src="https://blog.sssaini.io/content/images/2020/04/download--4-.png"></figure><h2 id="deploy-changes">Deploy Changes</h2><p>Our pipeline is set up. It's time to take it out for a test drive. </p><p>Make a small change to index.html</p><pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;

&lt;body&gt;
    &lt;h1&gt;Goodbye World&lt;/h1&gt;
&lt;/body&gt;

&lt;/html&gt;</code></pre><p>Commit and push the changes by,</p><pre><code>git add .
git commit -m "change text"
git push</code></pre><p>Once the push is successful, an automatic build is triggered on Heroku. Confirm this by going to the Overview tab of the Heroku dashboard. Under Latest Activity, there will be "Build in progress". </p><figure><img src="https://blog.sssaini.io/content/images/2020/04/download--4-.png"></figure><p>Once the status changes to Deployed, click on Open App and your changes should now be live. &nbsp;<br></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Modern Web Development Tutorials</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.sssaini.io/how-to-set-up-continuous-deployment-on-nodejs-app-using-heroku-and-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808162</guid>
            <pubDate>Sun, 12 Jul 2020 02:19:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NanoSpace – Free Modern WordPress Theme with Built-In Header and Footer Builder]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808071">thread link</a>) | @labinator
<br/>
July 11, 2020 | https://labinator.com/wordpress-marketplace/themes/nanospace/ | <a href="https://web.archive.org/web/*/https://labinator.com/wordpress-marketplace/themes/nanospace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="2705" data-elementor-settings="[]"><div><div><section data-id="c328940" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}"><div><div><div data-id="50ced3b" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="843dc22" data-element_type="widget" data-widget_type="image.default"><div><p><img src="https://labinator.com/wordpress-marketplace/wp-content/uploads/2019/11/NanoSpace-Logo.svg" alt="NanoSpace Logo" height="189" width="1043" title="NanoSpace Theme 1"></p></div></div><div data-id="b8cdb1b" data-element_type="widget" data-widget_type="heading.default"><p>Free, Multipurpose, Lightweight and Fast WordPress Theme</p></div></div></div></div></div></div></section><section data-id="4ea072c" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="505957e" data-element_type="column"><div><div><div data-id="2fc5cbf" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><b>NanoSpace</b> is a multipurpose, astonishingly lightweight, blazingly fast, and ultimately secure WordPress theme.</p><p>It is <b>bloat-free</b>, totally <b>responsive</b>, <b>AMP</b> friendly, <b>SEO</b> optimized, and <b>accessibility-ready</b> (WCAG 2.1 Level AA). It is also <b>translation</b> ready and fully supports <b>RTL</b> languages. In addition to that, It is compatible with <b>WooCommerce</b>, <b>bbPress</b>, and <b>BuddyPress</b>.</p><p>It is fully compatible with all well-coded page builders including the <b>Beaver Themer</b> and <b>Elementor Theme Builder</b>.&nbsp;<span>You will have the full freedom to build any website imaginable easily and quickly. That power allows you to build your page header, content, and footer all using your favorite builder in a drag-and-drop intuitive way.</span></p><p><b>NanoSpace</b> also has its own amazing intuitive <b>header</b> and <b>footer</b> <b>visual builders</b>. Everything you need to create your dream website.</p><p><span>It is licensed under <b>GPLv3</b> and works directly out-of-box without any keys or extra configurations. It is perfect for <b>designers</b>, <b>developers</b>, <b>web agencies</b>, and <b>freelancers</b>.</span></p></div></div></div></div></div></div></div></div></section><section data-id="48af703" data-element_type="section"></section><section data-id="0c03577" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}"><div><div><div data-id="18420a7" data-element_type="column"><div><div><div data-id="25e46cf" data-element_type="widget" data-widget_type="image.default"><div><p><img width="1920" height="1280" src="https://labinator.com/wordpress-marketplace/wp-content/uploads/2019/11/NanoSpace-Poster.png" alt="NanoSpace Theme Poster" srcset="https://labinator.com/wordpress-marketplace/wp-content/uploads/2019/11/NanoSpace-Poster.png 1920w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2019/11/NanoSpace-Poster-300x200.png 300w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2019/11/NanoSpace-Poster-1024x683.png 1024w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2019/11/NanoSpace-Poster-768x512.png 768w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2019/11/NanoSpace-Poster-1536x1024.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px" title="NanoSpace Theme 2"></p></div></div></div></div></div></div></div></section><section data-id="6ff8c46" data-element_type="section"></section><section data-id="85dca10" data-element_type="section"></section><section data-id="48541bf" data-element_type="section"><div><div><div data-id="652d912" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="0b4e8c2" data-element_type="widget" data-widget_type="heading.default"><p>Intuitive Live Customizer</p></div></div></div></div></div></div></section><section data-id="2ab8704" data-element_type="section"></section><section data-id="12c9d3d" data-element_type="section"><div><div><div data-id="e9d2bfa" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="672641f" data-element_type="widget" data-widget_type="heading.default"><p>Header &amp; Footer Visual Builders</p></div></div></div></div></div></div></section><section data-id="a8c4d86" data-element_type="section"></section><section data-id="d0af9c4" data-element_type="section"></section><section data-id="80cdf33" data-element_type="section"></section><section data-id="bfa3c40" data-element_type="section"></section><section data-id="315c551" data-element_type="section"></section><section data-id="1fda6df" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="ba3942e" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="47702d5" data-element_type="widget" data-widget_type="heading.default"><p>Advanced Features For Serious Businesses</p></div><div data-id="6c65fb0" data-element_type="widget" data-widget_type="heading.default"><p>Add More Features With The <b>NanoSpace Booster Plugin</b></p></div></div></div></div></div></div></section><section data-id="c9e5c46" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="5f55a95" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="4f49837" data-element_type="widget" data-widget_type="heading.default"><p>Advanced Maintenance Mode</p></div><div data-id="50c7189" data-element_type="widget" data-widget_type="heading.default"><p>Maintenance and coming soon modes<br>with user roles, widgets, and WYSIWYG HTML editor</p></div></div></div></div><div data-id="a9196b4" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="b9760bb" data-element_type="widget" data-widget_type="heading.default"><p>Ability to set a custom page for your 404 not found pages.<br>It also comes with error code selection (401/404)</p></div></div></div></div></div></div></section><section data-id="68b4656" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="1cdc7f3" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="17547de" data-element_type="widget" data-widget_type="heading.default"><p>Choose between the most popular font icon libraries. Including Font Awesome, Google Material Design, IcoFont, LineIcons, Unicons, ZURB Foundation Icon font icons and much more!</p></div></div></div></div><div data-id="2fb5e73" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="fa537a3" data-element_type="widget" data-widget_type="heading.default"><p>Upload and use your own custom fonts that match perfectly with your brand and business.</p></div></div></div></div></div></div></section><section data-id="2f11ca1" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="93877df" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="2c3cac2" data-element_type="widget" data-widget_type="heading.default"><p>Get the ability to add custom code snippets to your header and footer. Specify on which pages or posts they should run on and on which devices (Desktop/Mobile).</p></div></div></div></div><div data-id="d70ef75" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="153863a" data-element_type="widget" data-widget_type="heading.default"><p>Get the ability to white-label everything in one click with your own custom brand name. Serve your clients the right way!</p></div></div></div></div></div></div></section><section data-id="5d1024a" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="2b10d35" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="a2b86b6" data-element_type="widget" data-widget_type="heading.default"><p>Access All Labinator Themes &amp; Plugins</p></div><div data-id="a92420e" data-element_type="widget" data-widget_type="heading.default"><div><div><p>As part of the membership, you will also access our complete library of themes, plugins, and templates that covers everything you need to create any imaginable website.</p><p>You will also be able to extend the features of your website in an easy flexible way depending on your needs without bloating your site with unnecessary functionalities.</p></div></div></div></div></div></div><div data-id="11f5b22" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="b4fbb34" data-element_type="widget" data-widget_type="heading.default"><p>Access our GPL vault of third-party WordPress plugins. All your WordPress needs in one place!</p></div></div></div></div></div></div></section><section data-id="f976dda" data-element_type="section"><div><div><div data-id="1010308" data-element_type="column"><div><div><div data-id="ba7f45d" data-element_type="widget" data-widget_type="heading.default"><p>For Beaver &amp; Elementor Builder</p></div><div data-id="a6292d0" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>As part of your membership, you will also get our <a href="https://labinator.com/wordpress-marketplace/templates/" target="_blank" rel="noopener"><b>One-Page Elementor Templates</b></a>. It is ever-growing library of <strong>60+</strong> amazingly designed templates that cover multiple niches depending on your needs.</p><p>In addition to that, you will also gain access to over 100+ templates using third-party GPL plugins. Covering both the&nbsp;<strong>Beaver Builder</strong> and <strong>Elementor page builder</strong>.</p></div></div></div></div></div></div></div></div></section><section data-id="bba2619" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="d80298f" data-element_type="column"><div><div><div data-id="5416b4b" data-element_type="widget" data-widget_type="heading.default"><p>What the experts are saying about Labinator</p></div><section data-id="e4adf1f" data-element_type="section"><div><div><div data-id="1c0d01c" data-element_type="column"><div><div><div data-id="7c93d50" data-element_type="widget" data-widget_type="testimonial.default"><div><div><div><p>Labinator produces the most intelligent, optimized, and affordable WordPress themes and plugins I've found. </p><p> I highly recommend checking them out because I've tried many popular WordPress theme providers and nothing compares to the Labinator themes.</p></div><div><div><p><img width="150" height="150" src="https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Nathan-Gotch-150x150.jpg" alt="Nathan Gotch" srcset="https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Nathan-Gotch-150x150.jpg 150w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Nathan-Gotch-300x300.jpg 300w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Nathan-Gotch-60x60.jpg 60w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Nathan-Gotch.jpg 360w" sizes="(max-width: 150px) 100vw, 150px" title="NanoSpace Theme 3"></p><div><p>Nathan Gotch</p><p>Founder, GotchSEO.com</p></div></div></div></div></div></div></div></div></div><div data-id="109236e" data-element_type="column"><div><div><div data-id="ecdee30" data-element_type="widget" data-widget_type="testimonial.default"><div><div><p>5/5. I Would definitely recommend Labinator! <br> Starting from the WordPress themes which are really good looking and responsive, the wide range of plugins they offer and the amazing team that sits behind the entire project and is there to help 24/7, I only have positive feedback for them. Keep up the good work!</p><div><div><p><img width="150" height="150" src="https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Attila-Colaci-150x150.jpg" alt="Attila Colaci" srcset="https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Attila-Colaci-150x150.jpg 150w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Attila-Colaci-300x300.jpg 300w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Attila-Colaci-60x60.jpg 60w, https://labinator.com/wordpress-marketplace/wp-content/uploads/2020/05/Attila-Colaci.jpg 360w" sizes="(max-width: 150px) 100vw, 150px" title="NanoSpace Theme 4"></p><div><p>Attila Colaci</p><p>Digital Marketing Manager, SocialBee.io</p></div></div></div></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section><section data-id="ed5f912" data-element_type="section" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="ba32605" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="d1ef32a" data-element_type="widget" data-widget_type="heading.default"><p>Lifetime Access To All Themes &amp; Plugins</p></div></div></div></div></div></div></section></div></div></div><p>Comments are closed.</p></div>]]>
            </description>
            <link>https://labinator.com/wordpress-marketplace/themes/nanospace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808071</guid>
            <pubDate>Sun, 12 Jul 2020 02:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reward behaviour, win a customer for life]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23808056">thread link</a>) | @cyberomin
<br/>
July 11, 2020 | https://cyberomin.github.io/business/2020/07/11/brand-loyalty.html | <a href="https://web.archive.org/web/*/https://cyberomin.github.io/business/2020/07/11/brand-loyalty.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
          <p><span></span> read
          </p>
          <a name="topofpage"></a>
          <p>I have been thinking about brand loyalty for a while now and I thought I’d share some rough thoughts about this. Nothing ground breaking, but one that I think most businesses can begin to apply if they have the right tools. Let’s start with the <em>Loyalty</em></p>

<h3 id="loyalty">Loyalty</h3>
<p>Brand loyalty is hard to build, especially in the face of increasing competition. Why should a person stick to a brand? While exceptional customer service is great and one that all business should take seriously, in most cases, it may not be enough. 
People will begin to want more if exceptional customer service becomes  the common denominator(in an ideal world).</p>

<p>So how else do you keep people coming back? I will suggest rewarding their behaviour and create a <em>cool</em> factor in the process. This both helps the people feel great about their choices and benefits the brand too.</p>

<p>Prints, radio, TV and in recent times, online advertisement have all been effective marketing tools. While there’s nothing generally wrong with these mediums, I, as a customer, will appreciate a tangible reward as a way of marketing. It could be as simple as shopping vouchers. I strongly believe there’s a high likelihood of another person seeing this and wanting a piece of the action.</p>

<p>But today, I will propose another form of reward; experiences. Give people experiences as a form of reward. I strongly believe people rarely forget experiences, especially if it makes them feel good about themselves.</p>

<h3 id="aspiration">Aspiration</h3>
<p>Most people, if not everyone is aspirational. It’s inherently a human nature to aspire to something; social class, economic status, security, etc. We are always looking forward to the next level and this is perfectly okay.</p>

<p>Brands who are looking to build mindshare for a long time, especially within a certain income class should position themselves as aspirational brands. Little wonder why people begin to feel “cool” with themselves the moment the snag their first Apple product; iPhone, Watch, Mac, iPad. It’s the cool factor and satisfaction that these products give.</p>

<h3 id="mechanics-of-the-reward-system">Mechanics of the reward system</h3>
<p>In this case, these brands can use the loyalty/rewards system to build their own cool. For example, if every time you shopped at a certain location or make a certain transaction with some organisation you get a point, these organisations can now begin to segment its user base based on point. Let’s take a case simple scenario here.</p>

<p>Customers with a certain amount of points will qualify for Bronze, Silver, Gold and Platinum. These points can now be converted for different things, in this case, I will suggest experiential. Bronze member can get a full body massage at a spa or a one-month gym membership, Silver members can get a one-month gym membership, Gold Members can get both a full body massage and a one-month gym membership. The platinum members can, on the other hand, get a full body massage, a one-month gym membership and a private networking event with other platinum members once a month for a quarter.</p>

<p>As you begin to use these offers, you fall to a certain level, if a Bronze member uses their spa points, they fall to level zero, when a Silver member use either of their offers, they fall to Bronze and can work their way back up. When a Gold member use one of their offers, they fall to the Silver level, they can choose to build back their points and stay as Gold members or even progress to the Platinum membership band. Platinum members don’t fall, they maintain that status for as long as they want, but the moment they activate/use an offer they have 6 months to use the benefits or risk losing it.</p>

<p>The business can then change the rewards on a yearly basis. It is one way to keep the users hook, especially when the rewards will always come as a surprise.</p>

<p>This actually explain why I go to SPAR for groceries instead of ShopRite.</p>

<h3 id="cross-marketing">Cross Marketing</h3>
<p>The great things about the offers are that it forms an opportunity for cross-marketing for all the participating businesses. People who go to the gym can suddenly discover that brand X will offer free gym membership if they signed up for their services and the same goes for the spa. The gym and spa can now have opportunities to market to new potential customers. A win-win for everyone.</p>

<h3 id="brand-equity">Brand equity.</h3>
<p>Brand equity is a really big deal. People associate themselves with brand names than the actual product themselves. Little wonder why people will be quick to remind you that they are wearing Gucci than talk about the feel of the cotton fabric. You almost can’t place value to it. And as people watch close friends and allies begin to associate with the cool of your brand, they will want the same for themselves.</p>


          <p>I'll love to hear from you</p>
          <p><em>Do you want to say hello? <a href="mailto:celestineomin@gmail.com">Email me</a></em> - celestineomin@gmail.com</p>
          <p><em>I tweet at <a href="https://twitter.com/cyberomin">@cyberomin</a></em></p>
          <!-- Go to www.addthis.com/dashboard to customize your tools -->
          
          


          <!-- Go to www.addthis.com/dashboard to customize your tools -->
          <em>If you enjoyed this post, please consider sharing it.</em>
          

          
  
    
    
    <a href="http://disqus.com/">comments powered by </a>

    
  

  
  
  
  

  

        </section></div>]]>
            </description>
            <link>https://cyberomin.github.io/business/2020/07/11/brand-loyalty.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23808056</guid>
            <pubDate>Sun, 12 Jul 2020 02:03:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a No-Slot MIDI Interface on the Apple ][ Game I/O Socket]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23807949">thread link</a>) | @empressplay
<br/>
July 11, 2020 | https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/ | <a href="https://web.archive.org/web/*/https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://paleotronic.com/wp-content/uploads/2020/07/Practical-Computing-1983-June-121-copy-1024x438.jpg" alt="" title="Practical Computing 1983 June -121 copy">
</figure>

<p><span>In today’s world of plug-and-play peripheral devices, it is difficult to understand the fundamentals of what is happening at the lower levels.<span>&nbsp; </span>How does the computer connect to the device?<span>&nbsp; </span>How does it communicate with the device?<span>&nbsp; </span>How does the software make the device do its magic?</span></p>
<p><span>My name is Eric Rangell and I was a teenager in the 1980s.<span>&nbsp; </span>My first computer was an Apple //e in 1983.<span>&nbsp; </span>Before my family got a computer, I learned Basic programming from my brother’s college textbook and practiced writing programs on paper for a year before the Apple found a home in my brother’s room.<span>&nbsp; </span>With the limited computer time I had, I practiced coding, debugging, and refining my programs until they did what I wanted.<span>&nbsp; </span>The Apple ][ series of computers was designed so that owners could learn everything about how their machines worked if they took the time to study the available documentation and experiment with the machine.<span>&nbsp; </span>Today, early Apple computers can help young people grasp the fundamentals of how a computer works, and that will help them as they progress in their studies and careers.</span></p>
<p><span>In this article I will walk through a simple project that can be built using an Apple ][ series computer that has an internal Game I/O socket.<span>&nbsp; </span>It uses one of the Annunciator digital outputs to send MIDI data to a MIDI instrument.<span>&nbsp; </span>The process of building it and persisting through any problems you encounter will give you a sense of mastery and enjoyment, give you a tool to express your creativity, and challenge you to continue tinkering with the project as you learn more advanced computer science concepts.<span>&nbsp; </span>Parents and teachers are encouraged to learn how to build this project and help children work through it as they build an electronic device, write simple programs in Basic to control the device, and imagine additional applications that can use the device.</span></p>
<p><span>MIDI can play notes and music on keyboard synthesizers, as well as send commands to modules which control music playback, drum patterns, and even lighting.<span>&nbsp; </span>MIDI uses a very simple communication protocol to send binary messages to instruments.<span>&nbsp; </span>There really is nothing magical about it – the computer is just sending bytes which represent commands such as “Play a middle C”, “Stop playing the middle C”, “Change the instrument sound to Violin”, “Change the volume”.<span>&nbsp; </span>The objective of this project is for the student to understand how the computer varies voltage levels on an output port using specific timings according to a protocol that the musical instrument receiving the data understands.<span>&nbsp; </span>By building the interface from scratch, the student knows that the data is traveling on wires that they connected, and controlled by software that they wrote, using a driver program that is conceptually easy to understand.</span></p>
<p><span>Before you start building the interface, read this entire article and gather the parts you need.<span>&nbsp; </span>Many modern musical instruments have USB interfaces for MIDI.<span>&nbsp; </span>Look for older synthesizer keyboards with the round 5 pin DIN MIDI sockets, or USB MIDI interfaces that have the round connectors.<span>&nbsp; </span>You may need a MIDI coupler in order to connect a MIDI cable to one of those interfaces.</span></p>
<p><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture1.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture1-404x1024.png" alt="" width="150" height="380" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture1-404x1024.png 404w, https://paleotronic.com/wp-content/uploads/2020/07/Picture1-118x300.png 118w, https://paleotronic.com/wp-content/uploads/2020/07/Picture1.png 500w" sizes="(max-width: 150px) 100vw, 150px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture1-404x1024.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture1-404x1024.png 404w, https://paleotronic.com/wp-content/uploads/2020/07/Picture1-118x300.png 118w, https://paleotronic.com/wp-content/uploads/2020/07/Picture1.png 500w"></a>Since this project is going to be built on an Apple ][ game I/O socket, the first task is to build a cable that makes the socket pins more accessible outside the computer.<span>&nbsp; </span>The best connection is a 16 pin to 16 pin cable where one end plugs into the socket and the other end plugs into a breadboard.<span>&nbsp; </span>If you cannot obtain this cable, you can make your own using ribbon cable with Male to Male pin connectors.<span>&nbsp; </span>If this MIDI interface is the only project you want to build on the Game I/O socket, there are only 3 pins that need to be routed externally.<span>&nbsp; </span>On an Apple //e or //gs, 2 of those pins (+5V and GND) can come from the 9 pin Game connector on the back panel of the computer using a DE-9 connector.</span></p>
<p><span>The following pictures illustrate various options for connecting the game socket to a breadboard.<span>&nbsp; </span>Keep track of which pins on the external connector correspond to which pins on the internal connector.<span>&nbsp; </span>On the Apple //gs, pin 1 is in the upper left corner of the socket.<span>&nbsp; </span>For all other Apples, pin 1 is in the lower right corner of the socket.<span>&nbsp; </span>Pins are numbered from pin 1 to pin 8, then pin 9 is on the opposite side of pin 8, then pins 9-16 are numbered using the remaining pins.</span></p>
<figure id="attachment_13185"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture2.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture2.png" alt="" width="974" height="608" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture2.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture2-300x187.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture2-768x479.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture2.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture2.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture2-300x187.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture2-768x479.png 768w"></a><figcaption>16 pin ribbon cable connection from Apple ][+ Internal Game I/O socket to breadboard. Pin 1 is in the upper-right corner of the connector shown.</figcaption></figure><figure id="attachment_13190"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture3.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture3.png" alt="" width="974" height="550" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture3.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture3-300x169.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture3-768x434.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture3.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture3.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture3-300x169.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture3-768x434.png 768w"></a><figcaption>Ribbon cables connected to 2 pairs of headers: 8 pin and 6 pin. Pins 9 and 16 are not used on the Apple ][+ and Apple //e, so only 6 pins are needed on one of the cables.</figcaption></figure>
<figure id="attachment_13191"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture4.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture4.png" alt="" width="974" height="329" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture4.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture4-300x101.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture4-768x259.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture4.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture4.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture4-300x101.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture4-768x259.png 768w"></a><figcaption>Ribbon cables inserted into Apple //e Game I/O socket. Note that pins 9 and 16 are unconnected.</figcaption></figure>
<figure id="attachment_13192"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture6.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture6.png" alt="" width="150" height="278" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture6.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture6-162x300.png 162w" sizes="(max-width: 150px) 100vw, 150px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture6.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture6.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture6-162x300.png 162w"></a><figcaption>Single wire connected to pin 15 (Annunciator 0) of Apple //e internal game socket</figcaption></figure>
<p><span><b>Testing your wiring</b></span></p>
<p><span>Before you proceed any further, you want to make sure all wires are properly connected and that the signals from the Apple are reaching the breadboard.<span>&nbsp; </span>While there are only 3 pins needed to build the MIDI interface project, take the time to test the additional signals available on the Internal Game I/O socket.<span>&nbsp; </span>All pin numbers below refer to pin numbers on the Internal Game I/O socket.</span></p>

<p><span>1. Test the voltage between +5V (pin 1) and GND (pin 8).<span>&nbsp; </span>Use a multimeter to verify that the voltage level coming to the breadboard is at least +5 volts. The red wire connects pin 1 to the side holes for Power and the green wire connects pin 8 to side holes for Ground. Connect the probes of the multimeter to the Power and Ground of the breadboard, and set the dial to measure voltage.</span></p>

<p><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture8.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture8-250x300.png" alt="" width="200" height="240" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture8-250x300.png 250w, https://paleotronic.com/wp-content/uploads/2020/07/Picture8.png 449w" sizes="(max-width: 200px) 100vw, 200px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture8-250x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture8-250x300.png 250w, https://paleotronic.com/wp-content/uploads/2020/07/Picture8.png 449w"></a></p>
<figure id="attachment_13193"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture5.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture5.png" alt="" width="200" height="364" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture5.png 304w, https://paleotronic.com/wp-content/uploads/2020/07/Picture5-165x300.png 165w" sizes="(max-width: 200px) 100vw, 200px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture5.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture5.png 304w, https://paleotronic.com/wp-content/uploads/2020/07/Picture5-165x300.png 165w"></a><figcaption>Homemade DE9 cable for rear Game I/O socket of Apple //e or //gs.</figcaption></figure>
<p><span>2. Test the digital logic from the Annunciator outputs.<span>&nbsp; </span>Each of the 4 Annunciator outputs is controlled by a pair of soft-switches which are mapped to memory locations.<span>&nbsp; </span>One of each pair sends a digital HIGH signal to the output, and the other soft-swich of the pair sends a digital LOW signal.</span></p>



<p><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture10.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture10-300x285.png" alt="" width="200" height="190" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture10-300x285.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture10.png 412w" sizes="(max-width: 200px) 100vw, 200px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture10-300x285.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture10-300x285.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture10.png 412w"></a>To test the HIGH signal for Annunciator #0 (pin 15) go into the Apple Monitor by typing CALL -151 from Basic, and enter the hex address: C059, as shown below.<span>&nbsp; </span>The Apple will return a value for that memory location, which you can ignore.<span>&nbsp; </span>Now you can test to verify that Pin 15 has a HIGH signal.</span></p>


<p><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture9.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture9-150x150.png" alt="" width="150" height="150" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture9-150x150.png"></a><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture11.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture11-150x150.png" alt="" width="150" height="150" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture11-150x150.png"></a>While the multimeter is connected, enter the hex address: C058 in the Apple Monitor.<span>&nbsp; </span>The voltage should drop to a very low value.</span></p>



<p><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture12.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture12-300x279.png" alt="" width="300" height="279" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture12-300x279.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture12.png 491w" sizes="(max-width: 300px) 100vw, 300px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture12-300x279.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture12-300x279.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture12.png 491w"></a></p>
<p><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture13.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture13-166x300.png" alt="" width="166" height="300" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture13-166x300.png 166w, https://paleotronic.com/wp-content/uploads/2020/07/Picture13.png 308w" sizes="(max-width: 166px) 100vw, 166px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture13-166x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture13-166x300.png 166w, https://paleotronic.com/wp-content/uploads/2020/07/Picture13.png 308w"></a><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture14.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture14-148x300.png" alt="" width="148" height="300" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture14-148x300.png 148w, https://paleotronic.com/wp-content/uploads/2020/07/Picture14.png 272w" sizes="(max-width: 148px) 100vw, 148px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture14-148x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture14-148x300.png 148w, https://paleotronic.com/wp-content/uploads/2020/07/Picture14.png 272w"></a></span></p>
<p><span>You can also test the logic of the </span><span>Annunciators using a Digital Logic Probe, as shown left.<span>&nbsp; </span>Connect the probe terminals to the +5V and GND signals on the breadboard, then touch the tip of the probe to the Annunciator pin.<span>&nbsp; </span>The photos below show how the Digital Logic Probe responds when it detects logical HIGH and logical LOW voltages on Annunciator 0.</span></p>




<p><span><b>Inverters and Buffers</b></span></p>
<p><span>The MIDI specification defines the MIDI OUT Circuit as follows:</span></p>
<p><span>The signal from the transmitting device (labeled UART in the diagram below-left) passes through 2 inverters, then a 220 Ohm resistor, and is sent to Pin 5 on the circular 5 pin DIN connector labelled MIDI OUT.<span>&nbsp; </span>The +5V signal is sent through a 220 Ohm resistor to Pin 4 of the MIDI OUT connector.<span>&nbsp; </span>Pin 2 is connected to Ground, and the shield of the MIDI cable.<span>&nbsp; </span>Pins 1 and 3 are not connected.<span>&nbsp; </span>Polarity matters because a MIDI cable will connect your MIDI OUT port to the MIDI IN port of a musical instrument.<span>&nbsp; </span>The signals sent on your MIDI OUT port need to drive a phototransistor inside an opto-isolator in the MIDI IN circuit.<span>&nbsp; </span>When the signal from the UART is negative, the current loop is completed and the opto-isolator receives the signal.<span>&nbsp; </span>Communication is established by following a timing protocol for flipping the signals to represent the bits and bytes of MIDI messages.<span>&nbsp; </span>In this project we will control the timing of the messages with the Apple’s 6502 timing, to illustrate that there is nothing magical going on – if we get the timing right and follow the protocol, we will successfully communicate with a MIDI instrument.</span></p>
<figure id="attachment_13210"><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture15.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture15.png" alt="" width="974" height="610" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture15.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture15-300x188.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture15-768x481.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture15.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture15.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture15-300x188.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture15-768x481.png 768w"></a><figcaption>Source: International MIDI Association, Document No. MIDI-1.0, August 5, 1983.</figcaption></figure>
<p><span>Inverters change the input signal from HIGH to LOW, or LOW to HIGH.<span>&nbsp; </span>So, two inverters will leave the input signal unchanged.<span>&nbsp; </span>The two inverters form a buffer, which ensures that the signal does not get degraded if voltage fluctuates due to additional loads on the circuit.<span>&nbsp; </span>While it may be possible to drive the signal directly from the Apple without using the buffers, that introduces an element of uncertainty that can make your device unreliable under certain conditions.<span>&nbsp; </span>So initially we will build the circuit with two inverters (following the MIDI spec), and then test modifying it to use only one inverter (by logically inverting all the signals sent by the driver software).</span></p>
<p><em><strong><span><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture17.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture17-224x300.png" alt="" width="224" height="300" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture17-224x300.png 224w, https://paleotronic.com/wp-content/uploads/2020/07/Picture17.png 375w" sizes="(max-width: 224px) 100vw, 224px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture17-224x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture17-224x300.png 224w, https://paleotronic.com/wp-content/uploads/2020/07/Picture17.png 375w"></a><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture18.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture18-225x300.png" alt="" width="225" height="300" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture18-225x300.png 225w, https://paleotronic.com/wp-content/uploads/2020/07/Picture18.png 375w" sizes="(max-width: 225px) 100vw, 225px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture18-225x300.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture18-225x300.png 225w, https://paleotronic.com/wp-content/uploads/2020/07/Picture18.png 375w"></a>Testing your chips</span></strong></em></p>
<p><em><span>Use a logic probe to verify the outputs of each chip for each set of possible inputs.<span>&nbsp; </span>Use batteries or an electronics kit to test the chips before you use them in your project.<span>&nbsp; </span>The photos below show how one inverter of a 7404 Hex Inverter chip can be tested with a logic probe.<span>&nbsp; </span>The probe’s +5V and GND alligator clips are connected to the corresponding buses on the breadboard.<span>&nbsp; </span>The probe tip then is touched to the logic gate output.<span>&nbsp; </span>In the left photo, pin 1 (the yellow wire) is connected to +5V, so the logic probe reads LOW on pin 2.<span>&nbsp; </span>In the right photo, pin 1 is connected to GND, so the logic probe reads HIGH on pin 2.<span>&nbsp; </span>For both circuits, Pin 7 is connected to GND and pin 14 is connected to +5V.</span></em></p>
<p><a href="http://paleotronic.com/wp-content/uploads/2020/07/Picture16.png"><img src="http://paleotronic.com/wp-content/uploads/2020/07/Picture16.png" alt="" width="974" height="933" srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture16.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture16-300x287.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture16-768x736.png 768w" sizes="(max-width: 974px) 100vw, 974px" data-old-src="https://paleotronic.com/wp-content/plugins/jetpack/modules/lazy-images/images/1x1.trans.gif" data-lazy-src="http://paleotronic.com/wp-content/uploads/2020/07/Picture16.png" data-lazy-srcset="https://paleotronic.com/wp-content/uploads/2020/07/Picture16.png 974w, https://paleotronic.com/wp-content/uploads/2020/07/Picture16-300x287.png 300w, https://paleotronic.com/wp-content/uploads/2020/07/Picture16-768x736.png 768w"></a></p>
<p><span>There are several integrated circuit chips that can be used to build the buffer needed for this circuit:</span></p>
<p><span>4001: QUAD NOR – contains 4 NOR (NOT OR) gates</span></p>
<p><span>4011: QUAD NAND – contains 4 NAND (NOT AND) gates</span></p>
<p><span>7404: HEX INVERTER – contains 6 inverter circuits.</span></p>
<p><span>The two breadboards above show the three chips that may be used for this project.<span>&nbsp; </span>The left breadboard shows the 4011 chip on top and 4001 chip on the bottom.<span>&nbsp; </span>The right breadboard shows …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/">https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/</a></em></p>]]>
            </description>
            <link>https://paleotronic.com/2020/07/05/build-a-no-slot-midi-interface-on-the-apple-game-i-o-socket/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23807949</guid>
            <pubDate>Sun, 12 Jul 2020 01:43:25 GMT</pubDate>
        </item>
    </channel>
</rss>
