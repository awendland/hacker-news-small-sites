<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 27 Nov 2020 08:29:26 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 27 Nov 2020 08:29:26 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I‚Äôm not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Production Grade Workflow with SQL Modelling]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203365">thread link</a>) | @oedmarap
<br/>
November 24, 2020 | https://shopify.engineering/build-production-grade-workflow-sql-modelling | <a href="https://web.archive.org/web/*/https://shopify.engineering/build-production-grade-workflow-sql-modelling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><strong>By Michelle Ark and Chris Wu</strong></p>
<p>In January of 2014, Shopify built a data pipeline platform for the data science team called Starscream. Back then, we were a smaller team and needed a tool that could deal with everything from ad hoc explorations to machine learning models. We chose to build with PySpark to get the power of a generalized distributed computer platform, the backing of the industry standard, and the ability to tap into the Python talent market.&nbsp;</p>
<p>Fast forward six years and our data needs have changed. Starscream now runs 76,000 jobs and writes 300 terabytes a day! As we grew, some types of work went away, but others (like simple reports) became so commonplace we do them every day. While our Python tool based on PySpark was computationally powerful, it wasn‚Äôt optimized for these commonplace tasks. If a product manager needed a simple rollup for a new feature by country, pulling it, and modeling it wasn‚Äôt a fast task.</p>
<p>We‚Äôll show you how we moved to a SQL modelling workflow by leveraging <a href="https://www.getdbt.com/" target="_blank" title="Analytics engineering is the data transformation work that happens between loading data into your warehouse and analyzing it. dbt allows anyone comfortable with SQL to own that workflow." rel="nofollow noopener noreferrer">dbt</a> (data build tool) and created tooling for testing and documentation on top of it. All together, these features provide Shopify‚Äôs data scientists with a robust, production-ready workflow to quickly build straightforward pipelines.</p>

<p>When we interviewed our users to understand their workflow on Starscream, there were two issues we discovered: <em>development time</em> and <em>thinking</em>.</p>
<p><em>Development time</em> encompasses the time data scientists use to prototype the data model they‚Äôd like to build, run it, see the outcome,and iterate. The PySpark platform isn‚Äôt ideal for running straightforward reporting tasks, often forcing data scientists to write boilerplate and it yields long runtimes. This led to long iteration cycles when trying to build models on unfamiliar data.</p>
<p>The second issue, <em>thinking</em>, is more subtle and deals with the way the programming language forces you to look at the data. Many of our data scientists prefer SQL to python because its structure forces consistency in business metrics. When interviewing users, we found a majority would write out a query in SQL then translate it to Python when prototyping. Unfortunately, query translation is time consuming and doesn‚Äôt add value to the pipeline.</p>
<p>To understand how widespread these problems were, we audited the jobs run and surveyed our data science team for the use cases. We found that 70% or so of the PySpark jobs on Starscream were full batch queries that didn‚Äôt require generalized computing. We viewed this as an opportunity to make a kickass optimization for a painful workflow.&nbsp;</p>

<p>Our goal was to create a SQL pipeline for reporting that enables data scientists to create simple reporting data faster, while still being production ready. After exploring a few alternatives, we felt that the dbt library came closest to our needs. Their tagline ‚Äúdeploy analytics code faster with software engineering practices‚Äù was <em>exactly</em> what we were looking for in a workflow. We opted to pair it with Google BigQuery as our data store and dubbed the system and its tools, Seamster.</p>
<p>We knew that any off-the-shelf system wouldn‚Äôt be one size fits all. In moving to dbt, we had to implement our own:</p>
<ul>
<li>source and model structure to modularize data model development</li>
<li>unit testing to increase the types of testable errors</li>
<li>continuous integration (CI) pipelines to provide safety and consistency guarantees.</li>
</ul>
<h2>Source Independence and Safety</h2>
<p>With dozens of data scientists making data models in a shared repository, a great user experience would</p>
<ul>
<li>maximize focus on work&nbsp;</li>
<li>minimize the impact of model changes by other data scientists.</li>
</ul>
<p>By default, dbt declares raw sources in a central <code>sources.yml</code>. This quickly became a very large file as it included the schema for each source, in addition to the source name. It creates a huge bottleneck for teams editing the same file across multiple PRs.&nbsp;</p>

<p>To mitigate the bottleneck, we leveraged the flexibility of dbt and created a top-level ‚Äòsources‚Äô directory to represent each raw source with its own source-formatted yaml file. This way, data scientists can parse only the source documentation that‚Äôs relevant for them and contribute to the <code>sources.yml</code> file without stepping on each other‚Äôs toes.</p>

<p><em>Base models are one-to-one interfaces to raw sources.</em></p>
<p>We also created a Base layer of models using the <a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" rel="nofollow noopener noreferrer">‚Äò</a><a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" title="How we structure our dbt projects" rel="nofollow noopener noreferrer">staging‚Äô concept from dbt</a> to implement their best practice of <a href="https://docs.getdbt.com/docs/guides/best-practices/#limit-references-to-raw-data" target="_blank" title="Limit references to raw data - dbt" rel="nofollow noopener noreferrer">limiting references to raw data</a>. Our Base models serve as a one-to-one interface to raw sources. They don‚Äôt change the grain of the raw source, but do apply renaming, recasting, or any other cleaning operation that relates to the source data collection system.&nbsp;</p>
<p>The Base layer serves to protect users from breaking changes in raw sources. Raw external sources are by definition out of the control of Seamster and can introduce breaking changes for any number of reasons at any point in time. If and when this happens, you only need to apply the fix to the Base model representing the raw source, as opposed to every individual downstream model that depends on the raw source.&nbsp;</p>
<h2>Model Ownership for Teams</h2>
<p>We knew that the tooling improvements of Seamster would be only one part of a greater data platform at Shopify. We wanted to make sure we‚Äôre providing mechanisms to support good dimensional modelling practices and support data discovery.</p>
<p>In dbt, a model is simply a .sql file. We‚Äôve extended this definition in Seamster to define a model as a directory consisting of four files:&nbsp;</p>
<ul>
<li><code>model_name.sql</code></li>
<li><code>schema.yml</code></li>
<li><code>README.md</code></li>
<li><code>test_model_name.py</code></li>
</ul>
<p>You can further organize models into directories that indicate a data science team at Shopify like ‚Äòfinance‚Äô or ‚Äòmarketing‚Äô.&nbsp;</p>
<p>To support a clean data warehouse we‚Äôve also organized data models into these rough layers that differentiate between:</p>
<ul>
<li>
<strong>base</strong>: data models that are one-to-one with raw data, but cleaned, recast and renamed</li>
<li>
<strong>application-ready</strong>: data that isn‚Äôt dimensionally modelled but still transformed and clean for consumption by another tool (for example,&nbsp; training data for a machine learning algorithm)</li>
<li>
<strong>presentation</strong>: shareable and reliable data models that follow dimensional modelling best practices and can be used by data scientists across different domains.</li>
</ul>
<p>With these two changes, a data consumer can quickly understand the data quality they can expect from a model and find the owner in case there is an issue. We also pass this metadata upstream to <a href="https://shopify.engineering/solving-data-discovery-challenges-shopify" target="_blank" title="How We‚Äôre Solving Data Discovery Challenges at Shopify" rel="nofollow noopener noreferrer">other tools</a> to help with the data discovery workflow.</p>
<h2>More Tests</h2>
<p>dbt has native support for ‚Äòschema tests‚Äô, which are encoded in a model‚Äôs schema.yml file. These tests run against production data to validate data invariants, such as the presence of null values or the uniqueness of a particular key. This feature in dbt serves its purpose well, but we also want to enable data scientists to write unit tests for models that run against fixed input data (as opposed to production data).</p>
<p>Testing on fixed inputs allows the user to test edge cases that may not be in production yet. In larger organizations, there can and will be frequent updates and many collaborators for a single model. Unit tests give users confidence that the changes they‚Äôre making won‚Äôt break existing behaviour or introduce regressions.&nbsp;</p>
<p>Seamster provides a Python-based unit testing framework. Data scientists write their unit tests in the <code>test_model_name.py</code> file in the model directory. The framework enables constructing ‚Äòmock‚Äô input models from fixed data. The central object in this framework is a ‚Äòmock‚Äô data model, which has an underlying representation of a Pandas dataframe. You can pass fixed data to the mock constructor as either a csv-style string, Pandas dataframe, or a list of dictionaries to specify input data.&nbsp;</p>
<p><img alt="Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967" src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967"><br><em>Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation.</em></p>
<p>A constructor creates a test query where a common table expression (CTE) represents each input mock data model, and any references to production models (identified using dbt‚Äôs ‚Äòref‚Äô macro) are replaced by references to the corresponding CTE. Once you execute a query, you can compare the output to an expected result. In addition to an equality assertion, we extended our framework to support all expectations from the open-source <a href="https://github.com/great-expectations/great_expectations" target="_blank" title="Great Expectations - Always know what to expect from your data." rel="nofollow noopener noreferrer">Great Expectations</a> library to provide more granular assertions and error messaging.&nbsp;</p>
<p>The main downside to this framework is that it requires a roundtrip to the query engine to construct the test data model given a set of inputs. Even though the query itself is lightweight and processes only a handful of rows, these roundtrips to the engine add up. It becomes costly to run an entire test suite on each local or CI run. To solve this, we introduced tooling both in development and CI to run the minimal set of tests that could potentially break given the change. This was straightforward to implement with accuracy because of dbt‚Äôs lineage tracking support; we simply had to find all downstream models (direct and indirect) for each changed model and run their tests.&nbsp;</p>
<h2>Schema and Directed Acyclic Graph Validation on the Cheap</h2>
<p>Our objective in Seamster‚Äôs CI is to give data scientists peace of mind that their changes won‚Äôt introduce production errors the next time the warehouse is built. They shouldn‚Äôt have to wonder whether removing a column will cause downstream dependencies to break, or whether they made a small typo in their SQL model definition.</p>
<p>To achieve this accurately, we would need to build and tear down the entire warehouse on every commit. This isn‚Äôt feasible from both a time and cost perspective. Instead, on every commit we materialize every model as a view in a temporary BigQuery dataset which is created at the start of the validation process and removed as soon as the validation finishes. If we can‚Äôt build a view because its upstream model doesn‚Äôt provide a certain column, or if the SQL is invalid for any reason, BigQuery fails to build the view and ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/build-production-grade-workflow-sql-modelling">https://shopify.engineering/build-production-grade-workflow-sql-modelling</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/build-production-grade-workflow-sql-modelling</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203365</guid>
            <pubDate>Tue, 24 Nov 2020 21:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US internet speeds 91% faster in 2020 according to user speed tests]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 203 (<a href="https://news.ycombinator.com/item?id=25203256">thread link</a>) | @mootothemax
<br/>
November 24, 2020 | https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis | <a href="https://web.archive.org/web/*/https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><ul><li>US broadband speeds <strong>increased 91%</strong> from 2019-2020, <strong>nearly doubling</strong> YoY, as measured by annual speed test medians</li><li>US average broadband speeds overtook western EU countries like the UK, France, and Germany for the first time in 5 years</li><li>Broadband speeds in the EU overall rose 57% from 2019‚Äì2020, 34% lower than the 91% performance increase in the US</li></ul><p>American internet users have had a very good 2020: according to research performed by FairInternetReport, median US internet speeds in 2020 doubled to 33.16mbps, up from 17.34mbps in 2019. Covering the five years of 2016, 2017, 2018, 2019, and 2020, this is the largest speed increase seen in the US, with speeds staying essentially the same in 2016 and 2017 (8.91mbps and 9.08mbps respectively), and 2018 recording a median speed of 12.83mbps.</p><p>The US stills lags behind many European and developed nations worldwide, and its major cities also often lag behind their European equivalents. That said, there is cause for celebration in Dallas, Seattle and Austin, after our analysis has shown that these cities are performing extremely well relative to most European capital cities.</p></div></div></div>]]>
            </description>
            <link>https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203256</guid>
            <pubDate>Tue, 24 Nov 2020 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Speed Up 1000%]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202942">thread link</a>) | @tartoran
<br/>
November 24, 2020 | https://blog.binchen.org/posts/emacs-speed-up-1000.html | <a href="https://web.archive.org/web/*/https://blog.binchen.org/posts/emacs-speed-up-1000.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
<p>
I'm still <b>NOT</b> satisfied with my Emacs performance after applying below tricks:
</p>

<ul>
<li>autoload packages</li>
<li>idle-load packages</li>
<li>compiling *.el to  *.elc</li>
</ul>
<p>
After some research, I found I could make my Emacs 1000% fast <b>in 1 minute</b>.
</p>

<p>
Please note I'm talking about the <b>general performance</b> not just startup time.
</p>

<p>
The solution is really simple.
</p>

<p>
Since I'm a Linux guy and my computer got enough (24G) memory. I can place my setup into <a href="http://en.wikipedia.org/wiki/Tmpfs">memory</a>.
</p>

<p>
<b>Step 1</b>, insert below line into /etc/fstab and restart computer:
</p>

<div>

<pre><code>tmpfs       /tmp        tmpfs       nodev,nosuid,size=8G    0   0
</code></pre>

</div>

<p>
<b>Step 2</b>, run the script "emacs2ram":
</p>

<div>

<pre><code>#!/bin/sh

if [ -z "$1" ];then
    echo "Usage:"
    echo "  emacs2ram start"
    echo "  emacs2ram restore"
    exit 1
fi

if [ "$1" == "start" ];then
    backup=emacs.d-backup
    link=.emacs.d
    volatile=/tmp/.emacs.d-$USER

    IFS=
    set -efu

    cd ~/

    if [ ! -r $volatile ]; then
        mkdir -m0700 $volatile
    fi

    # link -&gt; volatie does not exist
    if [ "$(readlink $link)" != "$volatile" ]; then
        # backup project at first
        mv $link $backup
        # create the link
        ln -s $volatile $link
    fi

    if [ -e $link/.unpacked ]; then
        echo "Sync .emacs.d from memory to backup ..."
        rsync -avq --delete --exclude .unpacked ./$link/ ./$backup/
        echo "DONE!"
    else
        echo "Sync .emacs.d from disk to memory ..."
        rsync -avq ./$backup/ ./$link/
        touch $link/.unpacked
        echo "DONE!"
    fi
else
    echo "Moving .emacs.d back to disk ..."
    backup=$2-backup
    link=$2
    volatile=/tmp/$2-$USER
    cd ~/projs
    rm $link &amp;&amp; mv $backup $link &amp;&amp; rm -rf $volatile
    echo "DONE!"
fi
</code></pre>

</div>

<p>
That's all! Please enjoy Emacs as usual.
</p>

<p>
The original script is from ArchLinux Wiki. I learned this technique eight years ago. I'm just wondering why I need eight years to apply it?
</p>

<p>
BTW, I've also moved <b>all my projects into memory</b>, using similar scripts.
</p>

<p>
<b>UPDATE 1:</b>
I also publicize my project-managing script at <a href="https://gist.github.com/redguardtoo/596b1a9fd3eac1cedd13#file-proj2ram">gist</a>. It's almost same as emacs2ram. 
</p>

<p>
<b>UPDATE 2:</b>
Now I use <a href="https://hoytech.com/vmtouch/">vmtouch</a> which is easier to use and more light weight. Run <code>vmtouch -vt ~/.emacs.d</code> to place the directory into memory.
</p>

<p>
Unfortunately, <code>vmtouch</code> doesn't support Windows. You can convert my bash script to DOS batch script. Basically the script copies the directory into ram disk and create a link to the directory in memory. You can use <a href="https://sourceforge.net/projects/imdisk-toolkit/">ImDisk Toolkit</a> to create ram disk.</p>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.binchen.org/posts/emacs-speed-up-1000.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202942</guid>
            <pubDate>Tue, 24 Nov 2020 20:58:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: Black Magic Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 714 | Comments 669 (<a href="https://news.ycombinator.com/item?id=25202147">thread link</a>) | @singhkays
<br/>
November 24, 2020 | https://www.singhkays.com/blog/apple-silicon-m1-black-magic/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>Black. Magic. Fuckery.</p>
</blockquote>
<p>These are the words used by the user <a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/">holdagold on reddit</a> to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system‚Äôs internals very excited like we saw with Zen 3‚Äôs launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been ‚Äúperfectly fine‚Äù for the last decade. We‚Äôve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call ‚Äúrevolutionary‚Äù.</p>
<p>Before we proceed, it‚Äôs essential to set the context that I‚Äôve only used two Apple devices in my entire life - <em>a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work</em>. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a ‚ÄúPC/Android Guy‚Äù, I have to admit what I saw this week is something special. I believe it‚Äôll go down as a significant milestone in computing history on par with some industry-defining chips like Intel‚Äôs 8086, 386, 486, Pentium, Conroe or AMD‚Äôs K8, Zen, etc. I hope for the return of Moore‚Äôs law and awakening of the x86 manufacturers from their slumber as this will be the ‚Äú<em>slowest</em>‚Äù CPU Apple will ever make. <em>As Henry Clay once said</em>,</p>
<blockquote>
<p>Of all human powers operating on the affairs of mankind, none is greater than that of competition.</p>
</blockquote>
<p>This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.</p>

<p>Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_480x0_resize_q75_box.jpg 480w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg 800w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1200x0_resize_q75_box.jpg 1200w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1500x0_resize_q75_box.jpg 1500w,
                " src="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg" alt="Apple Silicon M1 summary capabilities">
</figure>
<p>The first products and price points the M1 will be going into are:</p>
<ol>
<li>Mac Mini - $699</li>
<li>MacBook Air 13" - $999</li>
<li>MacBook Pro 13" - $1299</li>
</ol>
<p>Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:</p>
<ol>
<li>On the MacBook Air - up to 18 hours of video on a single charge (<em>up from 12 hours on this year‚Äôs Intel-powered MacBook Air</em>) and offers up to 15 hours of wireless web browsing per charge (<em>up from 11 hours previously</em>)</li>
<li>On the MacBook Pro - up to 17 hours of wireless web browsing (<em>up from 10 hours with this year‚Äôs Intel-powered MacBook Pro</em>), and 20 hours of video playback (<em>up from 10 hours before</em>).</li>
</ol>
<p>To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.</p>


<p>Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft‚Äôs struggles in emulating x86 Windows apps on ARM CPUs. Apple‚Äôs answer might lie in something called TSO, aka. total store ordering as explained by <a href="https://www.reddit.com/r/hardware/comments/i0mido/apple_silicon_has_a_runtime_toggle_for_tso_to/">u/Veedrac and and u/ShaidarHaran2 on reddit</a>:</p>
<blockquote>
<p>TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.</p>
<p>In contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That‚Äôs what the hardware toggle is for.</p>
<blockquote>
<p>In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That‚Äôs on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they‚Äôre not currently, and so on, x86_64 performance should be very very decent. I‚Äôm going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it‚Äôs all said and done, it doesn‚Äôt take much working backwards to figure where they‚Äôd need to be, and Gurman said they were aiming for over 50% faster than Intel.</p>
</blockquote>
</blockquote>

<p>There have been numerous professional reviews and YouTube videos enumerating how Apple‚Äôs new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who‚Äôs spending their money on them. There have been plenty of real-world experiences that I‚Äôve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.</p>
<h2 id="the-speed">The Speed</h2>
<blockquote><p lang="en" dir="ltr">I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards üëè</p>‚Äî DHH (@dhh) <a href="https://twitter.com/dhh/status/1330903542463422469?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>
<blockquote><div lang="en" dir="ltr"><p>Purchased a new MacBook Air w/ Apple's M1 chip. </p><p>Holy crap. </p><p>Everything is WICKED fast.</p><p>Windows and prompts pop up instantly. Slowdown NEVER happens ‚Äî even w/ numerous apps going. </p><p>Evernote, always a resources hog for me, is now a non-issue.</p><p>Huge props, Apple. üëç</p></div>‚Äî JP Mangalindan (@JPManga) <a href="https://twitter.com/JPManga/status/1329265657796390914?ref_src=twsrc%5Etfw">November 19, 2020</a></blockquote>
<blockquote><p lang="en" dir="ltr">Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.</p>‚Äî Blake Scholl üõ´ (@bscholl) <a href="https://twitter.com/bscholl/status/1331084298451963904?ref_src=twsrc%5Etfw">November 24, 2020</a></blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/the_macbook_air_is_once_again_the_benchmark_by/gczfgs9">u/MagneticGray on reddit</a>:</p>
<blockquote>
<p>Definitely don‚Äôt get near one! I have the 12.9‚Äù iPad Pro, new Max iPhone, older 13‚ÄùMBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.</p>
<p>People keep saying this but it‚Äôs eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn‚Äôt even warm to the touch afterwards either.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gctzgic/">u/leach4_pikes on reddit</a>:</p>
<blockquote>
<p>&gt; It‚Äôs honestly the best purchase I‚Äôve made in the last 10 years.</p>
<p>This is exactly how I feel. Feels like I‚Äôm holding a magical device that shouldn‚Äôt exist. Haven‚Äôt felt that in a long long time</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxu58m/apple_m1_arm_performance_with_a_2020_mac_mini/gd082ng/">u/lawrencejuliano and u/havaloc on reddit</a>:</p>
<blockquote>
<p>I have a 2018 15‚Äù MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it‚Äôs been painful to say the least. It‚Äôs quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I‚Äôve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor‚Äôs resolution.</p>
<p>In comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.</p>
<p>To say I‚Äôm impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I‚Äôve ever owned. First computer that hasn‚Äôt had some feeling of compromise in a long time.</p>
</blockquote>

<h2 id="buyers-remorse-is-real">Buyers remorse is real</h2>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gcyyfjl">u/afelzz and u/WizardSleeveLoverr on reddit</a>:</p>
<blockquote>
<p>I feel so fucking stupid for ordering a Macbook Air in April this year.</p>
<blockquote>
<p>Same. I‚Äôm mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gd0n94p">u/2shizhtzu4u on reddit</a>:</p>
<blockquote>
<p>I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gczjpa8">u/kelev on reddit</a>:</p>
<blockquote>
<p>As someone who got an entry level 2020 MBP in June‚Ä¶ fuck.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/_/gcu471l">u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit</a>:</p>
<blockquote>
<p><em>cries in 2020 MBP</em></p>
<blockquote>
<p>2020 MacBook Air purchased in August :(:(:(</p>
</blockquote>
<blockquote>
<p>Ha my dad is 5 months into his MBP gutted</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvvtju/">u/mraheem on reddit</a>:</p>
<blockquote>
<p>Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.</p>
</blockquote>
<h2 id="battery-life-is-insane">Battery life is insane!</h2>
<blockquote><div lang="en" dir="ltr"><p>I haven‚Äôt plugged in this M1 Mac in almost 2 days. It‚Äôs only half dead. lol. What is this sorcery? üîã </p><p>Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. <a href="https://t.co/FmX5uVKkFd">pic.twitter.com/FmX5uVKkFd</a></p></div>‚Äî Computer Clan (üìåÔ£øM1) (@thecomputerclan) <a href="https://twitter.com/thecomputerclan/status/1329611818847891460?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote>

<blockquote><div lang="en" dir="ltr"><p>The battery life on the new MacBook Pro with M1 chip is INSANE</p><p>I've been doing work on this for several hours, and it's still at 87% ü§Øü§Øü§Ø</p><p>I guess it was a good thing I got my 3 week old laptop stolen? Lol<a href="https://twitter.com/hashtag/AppleM1?src=hash&amp;ref_src=twsrc%5Etfw">#AppleM1</a> <a href="https://t.co/fENYDS235O">pic.twitter.com/fENYDS235O</a></p></div>‚Äî William Lex Ham ‚úäüèΩüß¢ #TheyCantBurnUsAll (@WillLexHam) <a href="https://twitter.com/WillLexHam/status/1329906722845188097?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</a></em></p>]]>
            </description>
            <link>https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202147</guid>
            <pubDate>Tue, 24 Nov 2020 19:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grinch Bots Will Steal the Best Deals This Holiday Season]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25202140">thread link</a>) | @mch82
<br/>
November 24, 2020 | https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals | <a href="https://web.archive.org/web/*/https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Grinch bots, also known as scalper bots, have won deals at super-human speeds that consumers can't match in previous holiday seasons. However, due to the development of bots in the sneaker industry and COVID-19, the 2020 holiday season will see software bots complete a record number of online transactions.</p>
<p>In 2018, members of Congress drafted <a rel="nofollow noopener" target="_blank" title="a bill" href="https://tonko.house.gov/uploadedfiles/grinch_bots_fact_sheet.pdf">a bill</a> to outlaw grinch bots, stating that "Allowing grinch bots to rig prices and squeeze consumers during the holiday season hurts American families, small business owners, product makers and entrepreneurs. We will not allow this market manipulation to go unchecked."</p>
<p>This holiday season, grinch bots will purchase over $100 million of sneakers. In addition, this fast-growing software trend will impact clothing, collectibles, computers, electronics, gaming, and any attractive deal where demand outweighs supply. As a result, consumers will either miss out on the hottest holiday gifts, or be forced to purchase them from reseller platforms like eBay at steep markups.</p>
<p>Below, we outline what grinch bots are, how they work, and share details on the industries that are expected to be hardest hit.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#what-are-grinch-bots">What Are Grinch Bots?</a></li>
<li><a href="#how-do-grinch-bots-work">How Do Grinch Bots Work?</a></li>
<li><a href="#grinch-bots-over-500-million">Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</a></li>
<li><a href="#grinch-bots-in-other-industries">Grinch Bots Are Increasingly Popular In Other Industries</a></li>
<li><a href="#grinch-bots-cost-10000-dollars">The Leading Grinch Bots Are Now Being Sold for Almost $10,000</a></li>
<li><a href="#what-holiday-deals-will-grinch-bots-target-2020">What Holiday Merchandise Will Grinch Bots Target in 2020?</a></li>
</ul>

<h2>What Are Grinch Bots?</h2>
<p>Grinch bots, otherwise known as scalper bots, are software programs built to rapidly purchase scarce goods from websites before humans have the chance to do so. In other words, they automate the checkout process on eCommerce websites. Some grinch bots are programmed and owned by individual hackers. Others, like those mentioned below, are built and sold to consumers known as 'botters.'</p>
<p>The typical features found in grinch bots are: </p><div>
<div>
<ul>
<li>Retailer website compatibility</li>
<li>Captcha solvers</li>
<li>Automated checkout</li>
<li>Restock checking</li>
<li>Proxy integrations</li>
<li>Mobile applications</li>
<li>Customer support</li>
</ul>
</div>
</div>
<p>Botters use technologies in addition to the bots to scalp merchandise. The two most common are proxies and servers. Proxies, offered by companies like <a rel="nofollow noopener" target="_blank" title="Oculus" href="https://oculusproxies.com/index">Oculus</a> and <a rel="nofollow noopener" target="_blank" title="Surge" href="https://www.surgeproxies.com/">Surge</a>, are entered into the bots so that each checkout can use a unique IP address. Servers, managed by companies like <a rel="nofollow noopener" target="_blank" title="Amazon Web Services" href="https://aws.amazon.com/">Amazon Web Services</a> or <a rel="nofollow noopener" target="_blank" title="10xServers" href="https://10xservers.com/">10xServers</a>, are used to increase bot speed. Botters host virtual servers in the same locations as the websites they are botting to reduce the physical distance that the data needs to travel.</p>
<h2>How Do Grinch Bots Work?</h2>
<p>When botters purchase their bot, they program it with their personal information ‚Äì shipping &amp; billing addresses, credit card info, usernames &amp; passwords. The botters' proxies are also added to the bot.</p>
<p>In anticipation of a sale, botters enter the specific merchandise they hope to purchase from a given retailer. As you can see below, these are stored as tasks in the software.</p>
<div>
<p><img alt="Cybersole task screenshot" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 2x">
</p>
</div>
<p>Once the sale goes live on the target retailer website, the bot begins the checkout process. Botters can manually complete any necessary actions that the retailer requires during checkout, such as completing a CAPTCHA.</p>
<h2>Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</h2>
<p>Grinch bots will purchase over $100 million of sneakers during the 2020 holidays. This is consistent with the current size of the U.S. sneaker resale market, which is <a rel="nofollow noopener" target="_blank" title="estimated at $2 billion" href="https://finance.yahoo.com/news/global-sneaker-resale-market-could-reach-30-billion-by-2030-cowen-191003371.html">estimated at $2 billion</a>.</p>
<p>To calculate this figure, we completed a bottoms-up analysis using publicly available data shared by the bots. Many, but not all of the bots, share their transaction volume for each successful sale on Twitter. Cybersole's <a rel="nofollow noopener" target="_blank" title="Twitter account" href="https://twitter.com/Cybersole">Twitter account</a> is a good example, where you can find several posts a month celebrating the purchase of thousands of pairs of shoes.</p>
<p>The estimated 2020 holiday sales of the seven bots below is $70 million. This does not include sales from several other leading bots that do not publicly share their transaction volumes.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Est. Monthly Transactions</th><th colspan="" rowspan="">Est. Monthly Sales</th><th colspan="" rowspan="">Est. Holiday Sales</th><th colspan="" rowspan="">Annual Run Rate</th></tr></thead><tbody><tr><td colspan="" rowspan="">Kodai</td><td colspan="" rowspan="">50,000</td><td colspan="" rowspan="">$10 million</td><td colspan="" rowspan="">$24 million</td><td colspan="" rowspan="">$120 million</td></tr><tr><td colspan="" rowspan="">Cybersole</td><td colspan="" rowspan="">45,000</td><td colspan="" rowspan="">$9 million</td><td colspan="" rowspan="">$22 million</td><td colspan="" rowspan="">$108 million</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">25,000</td><td colspan="" rowspan="">$5 million</td><td colspan="" rowspan="">$12 million</td><td colspan="" rowspan="">$60 million</td></tr><tr><td colspan="" rowspan="">Project Destroyer</td><td colspan="" rowspan="">15,000</td><td colspan="" rowspan="">$3 million</td><td colspan="" rowspan="">$7.2 million</td><td colspan="" rowspan="">$36 million</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan="">AIO Bot</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan=""><strong>Total</strong></td><td colspan="" rowspan=""><strong>145,000</strong></td><td colspan="" rowspan=""><strong>$29 million</strong></td><td colspan="" rowspan=""><strong>$70 million</strong></td><td colspan="" rowspan=""><strong>$348 million</strong></td></tr></tbody></table>
</div>
</div>

</div>
<h2>Grinch Bots Are Increasingly Popular In Other Industries</h2>
<p>While bots have the deepest penetration in footwear, they are becoming increasingly popular in several other industries. There are several recent high-profile reports of bots outdueling humans to secure valuable in-demand merchandise, for example: </p><div>
<div>
<ul>
<li>In November, resellers used bots to purchase the majority of PlayStation 5s from top online retailers like GAME, John Lewis and Tesco (<a rel="nofollow noopener" target="_blank" title="source" href="https://metro.co.uk/2020/11/20/ps5-retail-websites-crashed-due-to-scalper-bots-13627423/#:~:text=It's%20believed%20that%20scalpers%20were,each%20other%20for%20late%20deliveries.">source</a>)</li>
<li>In September, resellers used bots to purchase the majority of Nvidia's RTX3080 video card (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.extremetech.com/gaming/315210-resellers-used-bots-to-dominate-the-rtx-3080-launch">source</a>)</li>
<li>In April, resellers used bots to exacerbate shortages of the Nintendo Switch (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.ign.com/articles/nintendo-switch-shortages-exacerbated-by-resellers-using-auto-buying-bots">source</a>)</li>
</ul>
</div>
</div>
<p>One of the largest online forums for botters is Reddit, and more specifically the community <a rel="nofollow noopener" target="_blank" title="r/shoebots" href="https://www.reddit.com/r/shoebots/">r/shoebots</a>. While this community started out focused on shoes, many recent threads are about CPUs, electronics, sports cards, and video games. As you can see below, the community has grown exponentially as botting has grown in popularity. It started 2020 at 9,630 members and has 22,400 members as of November 21, 2020.</p>
<div>
<p><img alt="r/shoebots reddit user growth over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 2x">
</p>
</div>
<p>The sneaker market and COVID-19 are two of the largest catalysts of grinch bot adoption. COVID-19 impacted the market in two ways ‚Äì&nbsp;it increased unemployment, and shifted retail spend online. These forces led to more individuals looking for a new source of income online.</p>
<p>Bots have also begun advertising their ability to operate on websites outside of the footwear industry. On November 12, Prism <a rel="nofollow noopener" target="_blank" title="announced" href="https://twitter.com/PrismAIO/status/1326920747625885698">announced</a> that its bot works on Walmart.com. In fact, there are several bots that work on both <a rel="nofollow noopener" target="_blank" title="Target and Walmart's websites" href="https://www.reddit.com/r/shoebots/comments/jyrwnb/best_walmart_and_target_bot_for_mac/">Target and Walmart's websites</a>. Cybersole's website advertises the ability to use its bot on over 270 websites.</p>
<h2>The Leading Grinch Bots Are Now Being Sold for Almost $10,000</h2>
<p>The market for grinch bots has become increasingly competitive as more software products have entered the market. However, finding and purchasing a copy of the best bots is difficult ‚Äì&nbsp;bot creators typically limit the number of instances they sell in an effort to prevent their bots from becoming too popular, and obsolete.</p>
<p>As a result, many of the top bots must be purchased through resale themselves. The bot resale website BotBroker.io has sold over 31,000 bots. The pricing data below was recorded from its website in November 2020.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Last Sale Price</th><th colspan="" rowspan="">Bot Creation Date</th></tr></thead><tbody><tr><td colspan="" rowspan="">Wrath</td><td colspan="" rowspan="">$8,299</td><td colspan="" rowspan="">February, 2018</td></tr><tr><td colspan="" rowspan="">CyberAIO</td><td colspan="" rowspan="">$5,600</td><td colspan="" rowspan="">April, 2016</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">$3,998</td><td colspan="" rowspan="">October, 2018</td></tr><tr><td colspan="" rowspan="">SwftAIO</td><td colspan="" rowspan="">$3,750</td><td colspan="" rowspan="">January, 2019</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">$3,300</td><td colspan="" rowspan="">November, 2019</td></tr><tr><td colspan="" rowspan="">Balko</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">August, 2018</td></tr><tr><td colspan="" rowspan="">MekAIO</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">October, 2020</td></tr><tr><td colspan="" rowspan="">Nebula</td><td colspan="" rowspan="">$2,399</td><td colspan="" rowspan="">March, 2018</td></tr><tr><td colspan="" rowspan="">TohruAIO</td><td colspan="" rowspan="">$2,065</td><td colspan="" rowspan="">October, 2019
</td></tr></tbody></table>
</div>
</div>

</div>
<p>Wrath is currently the most expensive bot on BotBroker.io. As you can see below, its price has been steadily increasing the past year.</p>
<div>
<p><img alt="Wrath bot price over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 2x">
</p>
</div>
<h2>What Holiday Merchandise Will Grinch Bots Target in 2020?</h2>
<p>The development of bots in the sneaker industry and COVID-19 mean that the holiday season of 2020 will see a record level of grinch bot transactions. The merchandise categories that will see the greatest bot transaction volume will be: </p><div>
<div>
<ul>
<li>Clothing</li>
<li>Collectibles</li>
<li>Computers</li>
<li>Electronics</li>
<li>Gaming</li>
<li>Sneakers</li>
<li>Toys</li>
</ul>
</div>
</div>
<p>In addition, resellers will almost certainly target flash sales of any high-demand item. Botters have formed 'cook groups' on Discord, where they share the latest information about promising upcoming 'drops' and sales. These groups provide botters an additional advantage over the average consumer.</p>
<p>Unfortunately for these consumers, it's likely that they will be forced to pay a significant premium to purchase the hottest items of the 2020 holiday season. It's hard to compete with the botters and their bots.</p>
</div></div>]]>
            </description>
            <link>https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202140</guid>
            <pubDate>Tue, 24 Nov 2020 19:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email a Dumpster Fire]]>
            </title>
            <description>
<![CDATA[
Score 920 | Comments 249 (<a href="https://news.ycombinator.com/item?id=25201798">thread link</a>) | @bschne
<br/>
November 24, 2020 | https://hey.science/dumpster-fire/ | <a href="https://web.archive.org/web/*/https://hey.science/dumpster-fire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What's this experiment all about?</p>
    <p>Well, 2020's been a rough year. An absolute dumpster fire of a year for a lot of people.</p>
    <p>That's when it came to us. Can email be a conduit for catharsis? If you could type out an email, press send, and see it being consumed in an actual dumpster fire, would it help reclaim a little bit of what we've lost?</p>
    <p>Let's find out.</p>
    <p>P.S. We'll only use your email address to notify you about your burn. That's it, the end.</p>
    <p>P.P.S. We're offsetting by 3x every bit of CO2 this creates via <a href="https://www.cooleffect.org/content/project/native-alaskans-saving-lands" target="_blank" rel="noopener nofollow">Cool Effect</a>.</p>
  </div></div>]]>
            </description>
            <link>https://hey.science/dumpster-fire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201798</guid>
            <pubDate>Tue, 24 Nov 2020 19:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Rainbow Tables Work]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25201513">thread link</a>) | @susam
<br/>
November 24, 2020 | http://kestas.kuliukas.com/RainbowTables/ | <a href="https://web.archive.org/web/*/http://kestas.kuliukas.com/RainbowTables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><h6><a href="http://kestas.kuliukas.com/">kestas.kuliukas.com</a></h6>
<h3>How Rainbow Tables work</h3>
<p>I found the creator of Rainbow Table's paper, aimed at cryptanalysts,
was pretty inaccessible considering the simplicity and elegance of
Rainbow Tables, so this is an overview of it for a layman.</p>

<hr>

<p>Hash functions map plaintext to hashes so that you can't tell a
plaintext from its hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/1.png"></center>

<p>If you want to find a given plaintext for a certain hash there are two
simple methods:<br>
- Hash each plaintext one by one, until you find the hash.<br>
- Hash each plaintext one by one, but store each generated hash in a
sorted table so that you can easily look the hash up later without
generating the hashes again</p>

<p>Going one by one takes a very long time, and storing each hash takes an
amount of memory which simply doesn't exist (for all but the smallest of
plaintext sets). Rainbow tables are a compromise between pre-computation
and low memory usage.</p>

<p>The key to understanding rainbow tables is understanding the
(unhelpfully named) reduction function.<br>
A hash function maps plaintexts to hashes, the reduction function maps
hashes to plaintexts.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/2.png"></center>


<p>It's important to note that it does the reverse of a hash function
(mapping hashes to plaintexts), but it is /not/ an inverse hash
function. The whole purpose of hash functions is that inverse hash
functions can't be made. If you take the hash of a plaintext, and take
the reduction of the hash, it will not give you the original plaintext;
but some other plaintext.</p>

<p>If the set of plaintexts is [0123456789]{6} (we want a rainbow table of
all numeric passwords of length 6), and the hashing function is MD5(), a
hash of a plaintext might be MD5("493823") -&gt;
"222f00dc4b7f9131c89cff641d1a8c50".<br>
In this case the reduction function R() might be as simple as taking the
first six numbers from the hash; R("222f00dc4b7f9131c89cff641d1a8c50")
-&gt; "222004".<br>
We now have generated another plaintext from the hash of the previous
plaintext, this is the purpose of the reduction function.</p>


<p>Hashes are one-way functions, and so are reduction functions. The chains
which make up rainbow tables are chains of one way hash and reduction
functions starting at a certain plaintext, and ending at a certain hash.
A chain in a rainbow table starts with an arbitrary plaintext, hashes
it, reduces the hash to another plaintext, hashes the new plaintext, and
so on. The table only stores the starting plaintext, and the final hash
you choose to end with, and so a chain "containing" millions of hashes
can be represented with only a single starting plaintext, and a single
finishing hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/3.png"></center>


<p>After generating many chains the table might look something like:<br>
iaisudhiu -&gt; 4259cc34599c530b1e4a8f225d665802<br>
oxcvioix -&gt; c744b1716cbf8d4dd0ff4ce31a177151<br>
9da8dasf -&gt; 3cd696a8571a843cda453a229d741843<br>
[...]<br>
sodifo8sf -&gt; 7ad7d6fa6bb4fd28ab98b3dd33261e8f</p>

<hr>

<p>The chains are now ready to be used. We have a certain hash with an
unknown plaintext, and we want to check to see whether it is inside any
of the generated chains.</p>

<p>The algorithm is:<br>
</p><ul><li>Look for the hash in the list of final hashes, if it is there break
out of the loop.</li>
<li>If it isn't there reduce the hash into another plaintext, and hash the
new plaintext.</li>
<li>Goto the start.</li>
<li>If the hash matches one of the final hashes, the chain for which the
hash matches the final hash contains the original hash.</li></ul>
You can now get that chain's starting plaintext, and start hashing and
reducing it, until you come to the known hash along with its secret
plaintext.

<p>In this way you check through the hashes in the chains, which aren't
actually stored anywhere on disk, by iterating column by column through
the table of chains, backwards from the last column in the chain, to the
starting plaintext.</p>

<hr>
<p>If you wanted to check whether the hash exists in the last column of any 
of the chains you reduce and hash the given hash once, then check the 
generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a1.png"></center>

<p>You can check the second last column by reducing and hashing twice, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a2.png"></center>

<p>And the third is checked by reducing and hashing three times, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a3.png"></center>

<p>Supposing
a chain ending matches the generated hash the matching chain end might
contain the hash. The starting plaintext which was stored with the ending 
hash can be reduced and hashed until the correct plaintext is found within 
the chain.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a4.png"></center>

<hr>

<p>Collisions are the only problem with Rainbow Tables. Ironically
collisions are seen as a bad thing for hashing algorithms, but in the
case of Rainbow Tables a hashing algorithm which generates collisions
fairly regularly will be more secure.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/5.png"></center><br>
A given hash may be generated by multiple plaintexts (this is called a
collision), which is a big problem for chains because it causes chains
which start different to converge into one. Also you get loops, which
are caused when a hash is reduced to a plaintext that was hashed at a
previous point in the chain.<br>
<center><img src="http://kestas.kuliukas.com/RainbowTables/6.png"></center>


<p>Because of these collision problems there is no guarantee that there
will be a hash of a plaintext that will reduce to some other given
plaintext.<br>
If you have a simple list of hashes and corresponding plaintexts for
every plaintext in a set you will know that if you have not found the
hash in the generated hashes the plaintext that generated the hash is
not in the set.<br>
If you have a table of chains where the reduction function reduces
hashes into the set of plaintexts you could have trillions of chains
generated but you still may not have generated every plaintext in the
set you want to check. You can only say how probable it is that a table
of chains contains a certain plaintext, and this can approach 1 but will
probably never reach 1.<br>
If you have a rainbow table with 10 chains of length 100 you have hashed
1000 plaintexts, but even if there are only 100 plaintexts in the set of
desired plaintexts the 1000 hashes you have in the chains may not
contain all the desired hashes.</p>

<hr>

<p>The way collisions are handled is what sets Rainbow Tables apart from
its predecessor which was developed in 1980.</p>

<p>The predecessor solved the problem of certain plaintexts never being
reduced to by using many small tables. Each small table uses a different
reduction function. This doesn't solve the problem completely, but it
does help.<br>
To solve chain merges and loops each chain ended at a "distinct point";
a hash which was unique in some way, eg hashes where the first 4
characters are 0. The chains keep on going until it reaches a distinct
point. If two chains end up at the same distinct point then there has
been a collision somewhere in the chain, and one of the chains is
discarded. If a chain is generated for an unusually long time without
reaching a distinct point a loop is suspected (where a chain of hashes
ends up reducing and hashing to a previous hash in the chain).
The problem with this is that if there is a collision there is
potentially a whole branch which has to be cut off and won't make it
into the chains, and a loop will cause all the hashes which came before
the loop in the chain to be discarded.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/7.png"></center><br>
Also all the time spend generating that chain will be wasted, and by
ending only at distinct points you have chains of variable length. This
means that you may have to keep checking for a hash within especially
long chains long after the other chains have ended.

<hr>

<p>Rainbow tables differ in that they don't use multiple tables with
different reduction functions, they only use one table. However in
Rainbow Tables a different reduction function is used for each column.
This way different tables with different reduction functions aren't
needed, because different reduction functions are used within the same
table. It is still unlikely that all plaintexts in the desired set will
be hashed, but the chances are higher for a given number of chains.
Chain merges are much, much rarer, because collisions have to occur on
the same column. For a chain of length l the chance of a collision
causing a merge is reduced to 1/l. Loops are also solved, because if a
hash in a chain is the same as a previous hash it won't reduce to the
same plaintext.</p>

<p>The reason they're called Rainbow Tables is because each column uses a
different reduction function. If each reduction function was a different
color, and you have starting plaintexts at the top and final hashes at
the bottom, it would look like a rainbow (a very vertically long and
thin one).<br>
By using Rainbow Tables the only problem that remains is that you can
never be certain that the chains contain all the desired hashes, to get
higher success rates from a given Rainbow Table you have to generate
more and more chains, and get diminishing returns.</p>


<hr>

<p>I hope by explaining the Rainbow Table I haven't made them any less 
wonderful ...</p>

<hr>

<a name="improving"></a>
<h4>An easy way to improve on the "rainbowcrack" Rainbow Tables implementation</h4>
<p>This section probably goes a bit beyond where a layman would be comfortable, 
but if you're interested in the practical applications of the above theory or have some 
interest in cryptography read on..</p>

<p>The rainbowcrack application is how most people come to learn 
about Rainbow Tables, because it is the application which puts the 
theory above into code. It has been very successful, with many websites 
dedicated to generating rainbowcrack hash tables and letting users search them.</p>

<p>However there is a pretty clear way this application could be improved, 
very easily, in the sense that the generated tables would take up a lot less
disk space, but be equally as effective for breaking hashes:</p>

<p>Remember above that when you want to generate a certain chain 
you start from an arbitrary hash. This just means it doesn't matter where 
you choose to start from. The rainbowcrack application starts from a randomly 
generated 64-bit number. This number is then used to generate a chain which 
ultimately ends with a 128-bit hash, which is reduced to another 64-bit number.</p>

<p>Why use a randomly generated number as the starting point? A ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kestas.kuliukas.com/RainbowTables/">http://kestas.kuliukas.com/RainbowTables/</a></em></p>]]>
            </description>
            <link>http://kestas.kuliukas.com/RainbowTables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201513</guid>
            <pubDate>Tue, 24 Nov 2020 18:43:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What does it mean to ‚Äúreconcile to cash‚Äù?]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201471">thread link</a>) | @qin
<br/>
November 24, 2020 | https://www.moderntreasury.com/journal/what-is-automatic-reconciliation | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/what-is-automatic-reconciliation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Businesses that manage payments at scale face the complex challenge of reliably monitoring cash. Most of us have experienced the time delays inherent to ACH, wires, and checks. These delays make it difficult to tie a payment you‚Äôve made or expect to receive to the actual transaction that posts to your bank account. This process is called reconciliation and it is essential for a business to understand how completed and in-progress transactions add up to the cash balance in its bank account.&nbsp;<br></p><p>Most finance teams try to solve the reconciliation problem with spreadsheets, email and manual examination of bank statements ‚Äî processes that are inefficient and error-prone. At Modern Treasury, we‚Äôve built a better solution that helps finance teams save time and minimize errors. We call it Automatic Reconciliation.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury automatically matches your payments and returns to transactions as they are made available by your bank. Reconciled transactions are reflected in the previous day and intra-day balances available through the API and dashboard, allowing you to reliably monitor cash across all your business bank accounts.&nbsp;</p><p>‚Äç<br></p><h4>How Does Reconciliation Help With Monitoring Cash?<br></h4><p>Let‚Äôs say you run a marketplace for artisanal coffee that lets coffee aficionados buy coffee from artisanal coffee roasters anywhere in the country. You collect payments from the buyer, deduct your platform fee and pay the seller. You also need to handle other types of transactions, like refunds and bonus payments to your top performing sellers. Business is going well so you‚Äôre processing thousands of orders a week.&nbsp;<br></p><p>To reliably monitor cash, you need to be able to match every single payment you‚Äôve made or received to the corresponding transaction in your bank statement. At scale, this quickly gets very complicated for three reasons.&nbsp;</p><p>‚Äç</p><h4>1. Banks Don‚Äôt Move Money as Fast as Your Business <br></h4><p>The time it takes for your transaction to settle depends on which payment method you use. Here‚Äôs a list of business payment methods used in the US and their typical settlement times. Because of these settlement timeframes, the rate at which you move money is slower than your business activities.&nbsp;<br></p><figure id="w-node-260693cab140-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc098771bac937c487c98a_AutomaticReconciliationTable.png" loading="lazy" alt=""></p></figure><p><br>Let‚Äôs say you pay coffee sellers on a daily basis. If you initiate a number of ACH credits on Monday, they are likely to settle by Tuesday. But by the time they settle, you have already initiated a new batch of payments on Tuesday that will settle on Wednesday.&nbsp;<br></p><p>Without reconciliation, it‚Äôs hard to keep track of the cash available in your bank account, what transactions are processing versus complete, and when different sets of transactions are likely to settle.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h4>2. Banks Process Transactions in Batches</h4><p>Let‚Äôs say you need to pay 10 coffee roasters $1000 each at the end of the week. You initiate 10 ACH credit transactions, each for $1000 on Friday before the day‚Äôs cut-off. These transactions will likely post to your bank statement Monday evening or Tuesday morning next week.&nbsp;<br></p><p>When you ask your bank to make a payment, it‚Äôs placed into a queue that‚Äôs sent to the network for processing after a certain cut-off time for the day. Any transactions submitted after the cut-off time are queued up to be processed the next business day. Different banks have different <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">cut-off times</a> for processing transactions.<br></p><p>The next day, instead of seeing 10 separate transactions next week, you‚Äôll see one transaction for $10,000 on your statement. Because ACH transactions take place in batches, your bank directly debits your account for the total amount even though it represents 10 separate payments. Reconciliation helps you tie each payment to the appropriate transaction on your bank statement.&nbsp;</p><h4>3. Monitoring Incoming Payments and Returns is Difficult</h4><p>Let‚Äôs say you‚Äôre also expecting 100 payments of $20 each from your buyers. You need to know when they hit your bank account to predict cash accurately. You also need to tie each payment to an order. Similar to when you make bulk payments, your bank may record all or some of those payments as a single transaction on your statement.&nbsp;<br></p><p><a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">Payment returns</a> also complicate monitoring cash flow. For example, ACH credits will fail due to incorrect account or routing numbers and ACH debits will fail if the counterparty doesn‚Äôt have sufficient funds in their account. In both scenarios, your bank will post a return transaction to your bank statement that needs to be reconciled with the original payment.</p><h4>Automatic Reconciliation<br></h4><p>Until now, many companies have relied on manual reconciliation processes that typically involve exporting transactions from the bank portal to a spreadsheet and manually matching them with payments. In addition to being time consuming, the need to email multiple spreadsheets back and forth makes collaboration painful.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury instantly reconciles every single payment with transactions in your bank statement. We <a href="https://www.moderntreasury.com/journal/tentative-reconciliation" target="_blank">tentatively reconcile</a> the transaction when it‚Äôs pending and complete the process when it posts. Because ACH processes transactions in batches, a large number of transactions on your bank statement are likely to represent multiple distinct payments. If the transaction aggregates multiple Payment Orders, we automatically create matching <a href="https://docs.moderntreasury.com/reference#transaction-line-item-object" target="_blank">Transaction Line Items</a>.&nbsp;<br></p><p>When you see a Payment Order marked as completed, you can click into it in the web application to see the matching transaction.&nbsp;<br>‚Äç<br></p><figure id="w-node-bb5fd7410dc0-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08ea82af2f7050239826_Payment%20Orders%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Expected Payments feature allows you to monitor your bank account for payments you do not initiate. When the transaction is made available by your bank, it is automatically reconciled with the Expected Payment. You can choose to be notified by <a href="https://docs.moderntreasury.com/reference#expected-payments">webhook</a> or email about its status.&nbsp;&nbsp;&nbsp;<br></p><figure id="w-node-6bf8f8776d0d-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08fdea9cc07dcb14b23c_Expected%20Payments%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Returns feature automatically matches returned payments to transactions and the original Payment Order, making identifying, correcting and redrafting returns a breeze.&nbsp;<br></p><figure id="w-node-2fa9dd183a06-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc0910f4c807451c4b685e_Returns%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>All the data you see in the app is also available through the API, allowing you to further automate and streamline reconciliation by integrating Modern Treasury directly into your business systems or platform.&nbsp;<br></p><p>We also have direct integrations with QuickBooks and NetSuite through our <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">Continuous Accounting</a> product. It syncs Modern Treasury directly with your general ledger, allowing you to tag payments with accounting categories. When you‚Äôre closing out the books, all you need to do is click a few buttons in the web app to transfer payments that have been Automatically Reconciled to your accounting software.<br></p><p>Finally, because we connect to <a href="https://docs.moderntreasury.com/docs/banks" target="_blank">multiple banks</a>, you can use Modern Treasury to reconcile transactions and monitor cash across all your business bank accounts.&nbsp;</p><h4>Get Started With Automatic Reconciliation</h4><p><a href="https://www.moderntreasury.com/product-demo" target="_blank">Get in touch</a> if you‚Äôre interested in exploring Automatic Reconciliation for your business. We‚Äôd love to discuss your use case in detail.</p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/what-is-automatic-reconciliation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201471</guid>
            <pubDate>Tue, 24 Nov 2020 18:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expensive Security Fails in Healthcare Apps]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25201335">thread link</a>) | @_Tata_
<br/>
November 24, 2020 | https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019 | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/healthcare"><p>Healthcare</p></a><h2>Most Expensive Healthcare App Security Fails in 2018‚Äì2019</h2><p>MyFitnessPal, PumpUp, and Strava all were unable to avoid data breaches. Find out why and what you can learn from these cases to make your app more secure.
</p></div></div><article><div target="_blank"><p>In 2018, the average cost for a corporate data breach reached almost <a href="https://igniteoutsourcing.com/healthcare/healthcare-security-breaches/">$4 million</a>.&nbsp;</p><p>Let‚Äôs take a look at a few of these attacks to learn what went wrong and secure your business from such risks.</p><h2>1 MyFitnessPal</h2><p>MyFitnessPal is a typical fitness application. It allows users to log cardio and strength exercises, connects with more than 50 devices and other apps, tracks steps, counts calories, and so on. Released in 2009, MyFitnessPal quickly gained popularity ‚Äî it was chosen as the number one health and fitness app four years in a row. But everything changed in February 2018.</p><figure id="w-node-9fe8c2a22398-7a0a8b78"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/KRcvSWvR0kc"></iframe></p></figure><p>The MyFitnessPal data breach was probably one of the most publicized in the healthcare industry. Hackers accessed the personal data of almost <strong>150 million users</strong>, stealing their names, hashed passwords, IP addresses, and email addresses. Fortunately, the criminals couldn‚Äôt get to users‚Äô credit card and social security numbers, as this data was collected and stored separately.&nbsp;<br></p><p><a href="https://www.underarmour.com/en-us?&amp;cid=PS%7Cgoogle%7CTrademark%7CUA%7CIP%7CExact%7Cunder%20armour%7CSRnf0L2T&amp;gclid=CjwKCAjw1_PqBRBIEiwA71rmtbPVRSTc31VHHLODl9D2ZnA-9HiTBv4xxSkBkyeWl8Z7kAJldUZ_QhoCaG8QAvD_BwE">Under Armour</a>, the company which acquired MyFitnessPal in 2015, became aware of the data breach at the end of March 2018. Four days later, users started to receive notifications and emails requiring them to change their passwords and offering recommendations on how to safeguard their accounts. In February 2019, the stolen personal details appeared on the dark web.&nbsp;<br></p><p>Other apps owned by Under Armour were not affected, but the company still <strong>lost 4.6% of its market</strong> <strong>value</strong> because of the data breach. However, the company and the app survived. MyFitnessPal still has a lot of users and pretty high ratings in the app stores (4.5 on Google Play).</p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>MyFitnessPal should have been equipped with <strong>two-factor authentication</strong>. For a mobile application, we would recommend using biometric authentication or at least push notifications.&nbsp;</li></ul><ul role="list"><li>Reliable <strong>encryption</strong> is a must for companies that are serious about privacy and security.</li><li>For the majority of passwords, Under Armour used the <a href="https://content.myfitnesspal.com/security-information/FAQ.html">Bcrypt</a> hashing function. This is a reliable mechanism. But for the remaining passwords, the company used the <strong>rather weak </strong><a href="https://content.myfitnesspal.com/security-information/FAQ.html"><strong>SHA-1</strong></a>. Using Bcrypt for all passwords could have reduced the scope of the breach.</li></ul><ul role="list"><li>Collecting and <strong>storing</strong> the most important <strong>data separately</strong> is a great practice ‚Äî it kept credit card data safe. Otherwise, Under Armour could have faced a much more serious loss in market value.</li></ul><ul role="list"><li>If a breach happens, it‚Äôs essential to <strong>notify users as fast as possible</strong> ‚Äî keeping silent will simply destroy your company‚Äôs reputation. Under Armour did well here.</li></ul><h2>2 PumpUp</h2><p><a href="https://www.pumpup.com/#home">PumpUp</a> positions itself as the world‚Äôs most positive fitness community. It offers users numerous workouts and programs, an opportunity to learn more about fitness and get support from other members, and other features. After the app was released in 2012, it became rather popular.<br></p><p>The PumpUp data breach took place in May 2018, when personal data of more than <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/"><strong>6 million users</strong></a><strong> </strong>stopped being private. Data compromised included information on users‚Äô locations, email addresses, gender, and dates of birth, full-resolution profile photos, workout data, health information (for instance, weight and height), device data, and private messages. In certain cases, even credit card data was exposed.&nbsp;<br></p><p>The incident happened because the core backend server hosted on the Amazon Cloud was left without a password for an indefinite amount of time. Anyone could see the private content of the app‚Äôs users.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7cdf1127270466b858d20_5d78d2e9cd001218b4a025f0_eb187d1d-170d-44e4-8ab7-2aa08946fd06.png" loading="lazy" alt=""></p></figure><p>The exposed server wasn‚Äôt even found by the company ‚Äî it was discovered by security researcher Oliver Hough who then contacted <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/">ZDNet</a>, a business technology news website, to investigate the case. ZDNet spent a week trying to get in touch with PumpUp, but there was no reply. However, in the end, the server was secured.<br></p><p>Since there were no comments from PumpUp after the breach, we can‚Äôt tell exactly how much money they lost. But their reputation was definitely affected.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>To avoid this problem, PumpUp had at least to protect their data with a password. Ideally, this would have been combined with <strong>two-factor authentication</strong> to keep users‚Äô data safe.&nbsp;</li></ul><ul role="list"><li>It seems that the company didn‚Äôt run any security tests ‚Äî <strong>regular security scanning</strong> would have helped them notice the problem much earlier. EGO recommends performing such tests on a regular basis.</li><li>Another mistake PumpUp made was ignoring<strong> communications</strong> from ZDNet and ignoring the incident. If a breach happens, a company should stay in touch to show users that it cares.</li></ul><h2>Strava</h2><p><a href="https://www.strava.com/mobile">Strava</a> is a fitness app for tracking running, cycling, swimming, and other activities. It allows users to map and record their routes, analyze their activities, participate in challenges, etc. The app was released in 2009, and since then it has been installed more than 10 million times on Android OS alone (according to <a href="https://play.google.com/store/apps/details?id=com.strava&amp;hl=en">Google Play</a>; no data on iOS downloads is available).<br></p><p>The story of the Strava failure began in November 2017, when the company released a global heat map showing running routes for all users who opted to make their data publicly available. To create the map, Strava used GPS data from smartphones and fitness tracking devices on <strong>1 billion</strong> activities. This data was collected from 2015 to 2017. Over <strong>27 million</strong> users tracked their routes during this time, and due to confusing privacy settings, some of them didn‚Äôt even know that they were sharing sensitive data.&nbsp;<br></p><p>This map was the brainchild of Strava. But in January 2018, Nathan Ruser, an Australian student, noticed that by analyzing the map, it was possible to determine the whereabouts of military bases and other sensitive locations.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c54a7adc793c1f5f41b3_5d78d3ce1f37d12d04642dcc_Artboard.png" loading="lazy" alt=""></p></figure><p>Strava and its map got a lot of criticism. In response, the company didn‚Äôt delete the map, but rather changed it significantly.&nbsp;<br></p><p>First of all, the data isn‚Äôt available to everyone anymore ‚Äî to zoom in and see street-level detail, users now have to log in with their Strava account.&nbsp;<br></p><p>Second, the map is now updated monthly, which means that if a user changes their privacy settings and doesn‚Äôt want to provide data for the heat map anymore, their data won‚Äôt be included in the next month‚Äôs map.&nbsp;<br></p><p>Third, all roads and paths with little activity aren‚Äôt shown on the map until they‚Äôre used by different users (not only runners, for example) for different activities.<br></p><p>To develop the heat map, Strava had to collect, analyze, and put together loads of data, which took money and a lot of time. Then the company had to update the map significantly, which meant unexpected additional expenses.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>In the case of Strava, there were no hackers or other criminals ‚Äî the company gave out important information on its own. There was not even some kind of social engineering, as no fraud was involved. Strava simply didn‚Äôt pay enough attention to the potential outcome, and that was their main mistake ‚Äî they didn‚Äôt anticipate the consequences. Explaining the importance of security and privacy to the entire team and <strong>training staff</strong> on a regular basis probably couldn‚Äôt have prevented this incident fully. But if the Strava staff would have thought about possible implications, they would have noticed that something was wrong during the map development phase.&nbsp;</li><li><strong>Privacy settings</strong> should not be confusing. Users must be able to set everything up easily and quickly. If privacy settings had been clearer, most users would have been able to prevent their private data from being published.</li></ul><h2>The Bottom Line</h2><p>To protect your healthcare app from security mistakes and failures, you have to pay attention not only to encryption and multi-factor authentication. As you can see from the Strava case, it‚Äôs also crucial to plan updates and new releases very carefully.&nbsp;<br></p><p>Follow these simple rules: run security tests and staff trainings on a regular basis, secure your app with multi-factor authentication and encryption, keep privacy settings simple, and analyze all potential outcomes.&nbsp;<br></p><p>And, obviously, if something does go wrong, stay in touch with your users. </p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c533a29d5b2035e7ec00_5f6cbf011fddb44501d8d28d_5d3042f66324e92dec2018cb_Business%20Insights.png" loading="lazy" alt=""></p></figure><p>‚Äç<br></p></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201335</guid>
            <pubDate>Tue, 24 Nov 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error codes are far slower than exceptions]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25201269">thread link</a>) | @vips7L
<br/>
November 24, 2020 | https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/ | <a href="https://web.archive.org/web/*/https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
TL;DR On modern 64-bit PC architectures, C++ exceptions only add unreachable code with destructor calls into functions and their effect on performance is below 1%, but such low values are difficult to measure. Handling rare errors with return values requires additional branching that slows down the program in realistic scenarios by about 5% and are also less convenient. If an exception is actually thrown, stack unwinding costs about 2 ¬µs per stack frame.
</p>

<p>C is considered to be the fastest programming language. C++ has features that only make C more convenient without an effect on performance and features that do impact performance. They help a lot to improve code quality, so they are often used anyway. Runtime polymorphism is virtually ubiquitous, exceptions less so.</p>



<p>A completely valid reason not to use exceptions is when the executable‚Äôs size is or is expected to be tightly constrained by the platform‚Äôs limitations. A questionable reason not to use them is performance, as it‚Äôs unlikely for completely new functionality to work without compromises. Also, using exceptions in wrong cases can completely ruin performance because handling a thrown exception is known to be very expensive.</p>



<p>But how significant is the performance impact? On most modern 64-bit platforms, exceptions are implemented in a way that minimises their cost as long as they are not thrown. There are no checks for exceptions being thrown in the generated functions, the execution switches to special functions and special data when handling an exception. However, not using exceptions is not free either. Rare errors have to be handled somehow. One possibility is to have the program simply abort, leaving any broken state on the disk, leading to very annoying user experience (done for example in Unreal Engine and Unity Engine, where incorrect API usage in code causes the editor to crash and keep crashing until the incorrect binaries are manually erased). Another alternative are error codes, when functions report they failed and the calling code is supposed to react appropriately, which is less convenient for the programmer and requires the program an additional check after returning from functions, however, it‚Äôs often done for performance reasons.</p>



<p>But actually, how do these approaches affect performance? I have tested this on realistic examples that simulate use cases typical for video games.</p>



<h2>Reminder ‚Äì where not to use exceptions?</h2>



<p>An exception, as its name suggests, is supposed to deal with <em>exceptional</em> cases. An exception is a case when a rule doesn‚Äôt apply. In software, that means something isn‚Äôt going as intended. Not a part of a use case. A failure. Invalid user input, connection failure, corrupted data, invalid packet, failure to initialise a device, missing file, programmer errors‚Ä¶</p>



<p>In many of these cases, the program shouldn‚Äôt just abort. Invalid user input stopping the program is super annoying because it causes all unsaved data to be lost and forcing the user to wait until the program restarts. Connection failure is a very recoverable problem, usually solvable by simply reconnecting. Invalid packet causing a program to crash is an open door to sabotage, as anyone can send invalid packets to cause the program to crash. And that is what can be solved by exceptions. Throwing them is slow, but the code does not need to be optimised to what isn‚Äôt its use case.</p>



<p>Examples of incorrect use of exceptions is when they‚Äôre thrown when everything works as it should. Breaking from a double loop, handling the end of a container, checking if a number can be deserialised in order to use a default value otherwise‚Ä¶</p>



<p>Modern 64 bit architectures use a model called <em>zero-cost exceptions</em> that optimises error handling with exceptions strongly in favour of the happy path when no exception is thrown at the cost of very bad performance of exceptions when they are actually thrown.</p>



<p>In other words, it should be possible to run the program in a debugger with the stop on exception function enabled.</p>



<p>Although not all error handling can be efficiently handled with exceptions, error codes can handle all of it. The question is, should they?</p>



<h2>Test 1 ‚Äì XML parsing</h2>



<p>For the purpose of this test, I have written an XML parser. I chose to write a parser because it can fail at many locations and does not depend on I/O. It‚Äôs definitely not standard-compliant or guaranteed to fail on every possible invalid input, but it can parse a usual XML configuration file and should end with an error in most cases where the file is syntactically incorrect. The code is quite low level and should be relatively fast (about 150 MiB/s), but I did not optimise it and used STL containers to make it convenient to use (as opposed to in-situ parsing). I wrote it with a lot of <code>#ifdef</code> checks to switch between exceptions, error codes and abort on error just with compiler arguments and thus ensure that the only differences between the variants would be what is necessary for different error handling.</p>



<p>I benchmarked it with <a href="https://gist.github.com/Dugy/5fee1b49777054d01f12e22ce9f986e5">an XML file that imitates the configuration of a video game</a>. Its size is 32 kiB and is loaded into memory before the benchmarks start. The parsing was repeated 10000 times and the duration was averaged, then repeated 10 times to test that its imprecision was below 1%.</p>



<p>The code was compiled with GCC 9, on Ubuntu 20.04, with an Intel i7-9750H processor with maximum single threaded frequency 4.5 GHz. I ran all experiments that I wanted to compare at a similar time, without doing anything in between, in order to equalise the influence of other programs occupying cache. Anyway, there were still outliers that took noticeably more than average. I removed these.</p>



<p>The version that aborted on error was as fast as the version with exceptions. The version with error codes was 5% slower.</p>



<p>For some reasons, if failures were handled by a special function that printed the error and exited the program, it was for some reasons slightly (about 1%) slower than the version with exceptions. I had to use a macro to make it comparable to the speed of code using exceptions. This behaviour was repeated in the other tests.</p>



<h2>Test 2 ‚Äì filling classes with the parsed XML</h2>



<p>For this test, I‚Äôve written several classes meant to represent the structures in the XML file and code for filling the data with the parsed XML structure. This part was about 10 times faster, probably because there was much less dynamic allocation.</p>



<p>The error margins of the code with exceptions and the code with no proper error handling overlapped, but the times were 0.6% higher for exceptions. In the case of error codes, the program was 4% slower. I achieved a similar slowdown by forgetting to use move semantics.</p>



<h2>Test 3 ‚Äì Updating with data from a binary stream</h2>



<p>This test imitates the usage of an asynchronous API for reading data from a TCP socket (such as Boost Asio or Unix Sockets). These APIs are used in a way that always a certain number of bytes is read from the stream, have to be processed and then more data is read. For faster processing and reduced bandwidth, the data are in binary form. Because network data in video games are streamed continuously, waiting for the end is not feasible.</p>



<p>The communication is represented by three message types that identify different possible updates. Because the messages have different lengths, it‚Äôs not possible to exactly determine whether all of the message‚Äôs length is available, so the function that identifies the message and calls appropriate parsing code will fail often even if everything is running correctly ‚Äì so exceptions cannot be used to handle this type of failure. Other failures, like unidentifiable message types, wrong identification of objects or large sudden changes of values (either cheating or data corruption) are still handled by exceptions (in the case where they are used).</p>



<p>The data were read from memory in order to prevent networking from influencing the tests. The data were generated by <a href="https://gist.github.com/Dugy/d3d851ab4826cc3121fc00b79cb5124d">this script</a>.</p>



<p>The result of the test was similar to previous tests ‚Äì the code using exceptions for error handling was 0.8% slower than the code that aborted on error, which was within the margin of error, while the code using error codes to handle errors was 6% slower.</p>



<h2>The results</h2>



<p>The times taken by the benchmarks are summarised in the following table, scaled so that the time needed by the version that aborts when an error happens is 100%.</p>



<figure><table><thead><tr><th>Test</th><th>Abort</th><th>Exception</th><th>Error code</th></tr></thead><tbody><tr><td>Parsing</td><td>100%</td><td>100%</td><td>106.2%</td></tr><tr><td>Filling</td><td>100%</td><td>100.6%</td><td>104.2%</td></tr><tr><td>Updating</td><td>100%</td><td>100.8%</td><td>106.2%</td></tr></tbody></table></figure>



<p>The imprecision was around 1%, so the version using exceptions might not really be slightly slower and the difference might be the result of chance or some invisible compiler decisions, like inlining. The time needed by the version using error codes was consistently higher.</p>



<p>The entire source code is <a href="https://gist.github.com/Dugy/2532c810bb232b8ff1603cfa679bdf28">here</a>.</p>



<h2>Error handling and clean code</h2>



<p>When an exception is not handled in a block, the execution exits the block automatically until it finds a piece of code that can catch it. Any other type of handling does not support this and requires writing additional logic to handle the failure, although in almost all cases the appropriate reaction is to abort the operation the program is performing (the test with reading from a stream is an example where this does not apply). This can significantly lengthen the code even if the reaction to any failure in a function being called is to return the error code to the caller‚Äôs caller.</p>



<p>This is a line from the initialisation sector of a constructor in test 2:</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">	animation(*source.getChild("animation")),</pre>



<p>It forwards the child XML tag called <code>animation</code> of its argument to the constructor of a member class called&nbsp;<code>animation</code>. The constructor may fail due to incorrect content of the XML tag, or <code>getChild</code> function can fail because the entire tag is missing. This aborts the creation of the structure, or some other process in the program that‚Äôs in the <code>catch</code> block.</p>



<p>If the errors ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</a></em></p>]]>
            </description>
            <link>https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201269</guid>
            <pubDate>Tue, 24 Nov 2020 18:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P¬≤ quantile estimator ‚Äì estimating the median without storing values]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25201093">thread link</a>) | @ciprian_craciun
<br/>
November 24, 2020 | https://aakinshin.net/posts/p2-quantile-estimator/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/p2-quantile-estimator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-11-24">November 24, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantiles/">Quantiles</a>
<a href="https://aakinshin.net/tags/performance-telemetry/">Performance Telemetry</a></span></p><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its ‚Äúaverage‚Äù duration.
It‚Äôs not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It‚Äôs much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it‚Äôs a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it‚Äôs usually enough for typical telemetry use cases.</p><p>In this post, I will show one of the simplest sequential quantile estimators that is called the P¬≤ quantile estimator
(or the Piecewise-Parabolic quantile estimator).</p><h3 id="the-p-quantile-estimator">The P¬≤ quantile estimator</h3><p>This algorithm was initially suggested in <a href="#Jain1985">[Jain1985]</a>.
Below you can find a short overview of this approach,
notes about typos in the original paper,
numerical simulation,
and a C# implementation.</p><h4 id="the-main-idea">The main idea</h4><p>Let‚Äôs say we have a stream of observations <span>\(\{ x_0, x_1, x_2, x_3, x_4, \ldots \}\)</span>
and we want to estimate p-quantile.
The suggested approach introduces five markers that correspond to the estimations of</p><ul><li><span>\(q_0\)</span>: The minimum</li><li><span>\(q_1\)</span>: The (p/2)-quantile</li><li><span>\(q_2\)</span>: The p-quantile</li><li><span>\(q_3\)</span>: The ((1+p)/2)-quantile</li><li><span>\(q_4\)</span>: The maximum</li></ul><p>The <span>\(q_i\)</span> values are known as the marker heights.</p><p>Also, we have to maintain the marker positions <span>\(\{ n_0, n_1, n_2, n_3, n_4 \}\)</span>.
These integer values describe actual marker indexes across obtained observations at the moment.</p><p>Next, we have to define the marker desired positions <span>\(\{ n'_0, n'_1, n'_2, n'_3, n'_4 \}\)</span>.
For the first <span>\(n\)</span> observations, these real values are defined as follows:</p><ul><li><span>\(n'_0 = 0\)</span></li><li><span>\(n'_1 = (n - 1) p / 2\)</span></li><li><span>\(n'_2 = (n - 1) p\)</span></li><li><span>\(n'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(n'_4 = (n - 1)\)</span></li></ul><p>In order to speed up the algorithm, we can precalculate increments of the desired positions which
should be added to the current values after each new observation:</p><ul><li><span>\(dn'_0 = 0\)</span></li><li><span>\(dn'_1 = p / 2\)</span></li><li><span>\(dn'_2 = (n - 1) p\)</span></li><li><span>\(dn'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(dn'_4 = (n - 1)\)</span></li></ul><p>Note that in the original paper, the authors use one-based indexing.
I decided to adapt it to the zero-based indexing which is more convenient from the implementation point of view.</p><h4 id="initialization">Initialization</h4><p>Once we collected the first five elements, we should perform initialization logic:</p><p><span>\[\left\{
\begin{array}{llll}
q_0 = x_{(0)}, &amp; n_0 = 0, &amp; n'_0 = 0,      &amp; dn'_0 = 0,\\
q_1 = x_{(1)}, &amp; n_1 = 1, &amp; n'_1 = 2p,     &amp; dn'_1 = p/2,\\
q_2 = x_{(2)}, &amp; n_2 = 2, &amp; n'_2 = 4p,     &amp; dn'_2 = p,\\
q_3 = x_{(3)}, &amp; n_3 = 3, &amp; n'_3 = 2 + 2p, &amp; dn'_3 = (1+p)/2,\\
q_4 = x_{(4)}, &amp; n_4 = 4, &amp; n'_4 = 4,      &amp; dn'_4 = 1.
\end{array}
\right.
\]</span></p><h4 id="marker-invalidation">Marker invalidation</h4><p>For each <span>\(x_j\)</span> for <span>\(j \geq 5\)</span>, we should invalidate our markers.</p><p>Firstly, we should adjust extreme marker heights
(if <span>\(x_j &lt; q_0\)</span>, we should update <span>\(q_0\)</span>; if <span>\(x_j &gt; q_4\)</span>, we should update <span>\(q_4\)</span>) and
find <span>\(k\)</span> such that <span>\(q_k \leq x_j &lt; q_{k+1}\)</span>
(or <span>\(q_k \leq x_j \leq q_{k+1}\)</span> for <span>\(k=3\)</span>):</p><table><thead><tr><th>Condition</th><th><span>\(q_i\)</span> update</th><th>k</th></tr></thead><tbody><tr><td><span>\(\phantom{q_0 \leq~} x_j &lt; q_0\)</span></td><td><span>\(q_0 = x_j\)</span></td><td>0</td></tr><tr><td><span>\(q_0 \leq x_j &lt; q_1\)</span></td><td></td><td>0</td></tr><tr><td><span>\(q_1 \leq x_j &lt; q_2\)</span></td><td></td><td>1</td></tr><tr><td><span>\(q_2 \leq x_j &lt; q_3\)</span></td><td></td><td>2</td></tr><tr><td><span>\(q_3 \leq x_j &lt; q_4\)</span></td><td></td><td>3</td></tr><tr><td><span>\(q_4 \leq x_j\)</span></td><td><span>\(q_4 = x_j\)</span></td><td>3</td></tr></tbody></table><p>Secondly, we should update the marker positions and the marker desired positions:</p><p><span>\[\begin{array}{lcl}
n_i = n_i + 1 &amp; \textrm{for} &amp; i = k + 1, \ldots, 4; \\
n'_i = n'_i + dn'_i &amp; \textrm{for} &amp; i = 0, \ldots, 4. \\
\end{array}
\]</span></p><p>Finally, we should adjust non-extreme marker heights (<span>\(q_i\)</span>) and positions (<span>\(n_i\)</span>) for <span>\(i \in \{ 1, 2, 3\} \)</span>
in the following way:</p><div><pre><code data-lang="cs"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>d</span> <span>=</span> <span>nÍûå</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span>
    <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span>  <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span>  <span>1</span> <span>||</span>
        <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
    <span>{</span>
        <span>d</span> <span>=</span> <span>sign</span><span>(</span><span>d</span><span>)</span>
        <span>qÍûå</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>if</span> <span>(!(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qÍûå</span> <span>&amp;&amp;</span> <span>qÍûå</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]))</span>
            <span>qÍûå</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qÍûå</span>
        <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>d</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>The core equation of the algorithm is a piecewise-parabolic prediction (P¬≤) formula
that adjusts marker heights for each observation:</p><p><span>\[q'_i = q_i + \dfrac{d}{n_{i+1}-n_{i-1}} \cdot
\Bigg(
(n_i-n_{i-1}+d)\dfrac{q_{i+1}-q_i}{n_{i+1}-n_i} +
(n_{i+1}-n_i-d)\dfrac{q_i-q_{i-1}}{n_i-n_{i-1}}
\Bigg).
\]</span></p><p>Once we calculated <span>\(q'_i\)</span>, we should check that <span>\(q_{i-1} &lt; q'_i &lt; q_{i+1}\)</span>.
If this condition is false, we should ignore the parabolic prediction and use the linear prediction instead:</p><p><span>\[q'_i = q_i + d \dfrac{q_{i+d}-q_i}{n_{i+d}-n_{i}}.
\]</span></p><h4 id="the-result">The result</h4><p>Once you need the requested quantile estimation value, we should just take the value of <span>\(q_2\)</span>.</p><h4 id="typos-in-the-original-paper">Typos in the original paper</h4><p>A find a few typos in the original paper which may confuse readers who want to implement the algorithm from scratch:</p><ul><li>Page 1079, Box 1, B2:
<code>$i = k, \ldots, 5$</code>
should be replaced by
<code>$i = k + 1, \ldots, 5$</code></li><li>Page 1079, Box 1, B3:
<code>$\textbf{THEN}\; q_i \leftarrow q_i$</code>
should be replaced by
<code>$\textbf{THEN}\; q_i \leftarrow q'_i$</code></li></ul><h3 id="numerical-simulation">Numerical simulation</h3><p>It‚Äôs time to check how it works.
I decided to visualize sequential values of the following quantiles estimator:</p><ul><li><strong>The P¬≤ quantile estimator</strong><br>A sequential estimator that is described above.</li><li><strong>The Type 7 quantile estimator</strong><br>It‚Äôs the most popular quantile estimator which is used by default in
R, Julia, NumPy, Excel (<code>PERCENTILE</code>, <code>PERCENTILE.INC</code>), Python (<code>inclusive</code> method).
We call it ‚ÄúType 7‚Äù according to notation from <a href="#Hyndman1996">[Hyndman1996]</a>,
where Rob J. Hyndman and Yanan Fan described nine quantile algorithms which are used in statistical computer packages.</li><li><strong>The Harrell-Davis quantile estimator</strong><br>It‚Äôs my favorite option in real life for non-sequential cases because
it‚Äôs more robust than classic quantile estimators based on linear interpolation,
and it provides more reliable estimations on small samples.
This quantile estimator is described in <a href="#Harrell1982">[Harrell1982]</a>.</li><li><strong>Actual</strong><br>The true median value which is taken from the underlying distribution.</li></ul><p>Below, you can find several plots for the following distributions:</p><ul><li><strong>Normal distribution</strong> <span>\(\mathcal{N}(0, 1)\)</span></li><li><strong>Gumbel distribution</strong> for <span>\(\mu = 0, \beta = 1\)</span></li><li><strong>Beta distribution</strong> <span>\(\textrm{Beta}(10, 2)\)</span></li><li><strong>Uniform distribution</strong> <span>\(\mathcal{U}(0, 1)\)</span></li><li><strong>Bimodal distribution</strong> (mixture of <span>\(\mathcal{N}(10, 1)\)</span> and <span>\(\mathcal{N}(20, 1)\)</span>)</li></ul><p>Here are the results:</p><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" target="_blank" alt="normal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" target="_blank" alt="gumbel"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" target="_blank" alt="beta"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" target="_blank" alt="uniform"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" target="_blank" alt="bimodal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg"></picture></a></div></div><p>As you can see, The P¬≤ quantile estimator produces reasonable median estimates.
I also checked how it works on a considerable number of real data sets and
I‚Äôm pretty satisfied with the results.
You can also find a discussion about accuracy and the equation for the mean squared error in the original paper.</p><h3 id="reference-implementation">Reference implementation</h3><p>Below you can find a C# implementation of the discussed algorithm.
Also, you can use it via
the latest nightly version (0.3.0-nightly.64+) of <a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer</a>.</p><div><pre><code data-lang="cs"><span>public</span> <span>class</span> <span>P2QuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>double</span> <span>p</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>n</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>5</span><span>];</span> <span>// marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>ns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// desired marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>dns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>q</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// marker heights
</span><span></span>    <span>private</span> <span>int</span> <span>count</span><span>;</span>

    <span>public</span> <span>P2QuantileEstimator</span><span>(</span><span>double</span> <span>p</span><span>)</span>
    <span>{</span>
        <span>p</span> <span>=</span> <span>probability</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>AddValue</span><span>(</span><span>double</span> <span>x</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>q</span><span>[</span><span>count</span><span>++]</span> <span>=</span> <span>x</span><span>;</span>
            <span>if</span> <span>(</span><span>count</span> <span>==</span> <span>5</span><span>)</span>
            <span>{</span>
                <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>);</span>

                <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
                    <span>n</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>i</span><span>;</span>

                <span>ns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>ns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>4</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>2</span> <span>+</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>4</span><span>;</span>

                <span>dns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>dns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>p</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>p</span><span>;</span>
                <span>dns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>1</span> <span>+</span> <span>p</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>1</span><span>;</span>
            <span>}</span>

            <span>return</span><span>;</span>
        <span>}</span>

        <span>int</span> <span>k</span><span>;</span>
        <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>0</span><span>])</span>
        <span>{</span>
            <span>q</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>}</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>1</span><span>])</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>2</span><span>])</span>
            <span>k</span> <span>=</span> <span>1</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>3</span><span>])</span>
            <span>k</span> <span>=</span> <span>2</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>4</span><span>])</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>else</span>
        <span>{</span>
            <span>q</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>k</span> <span>+</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>n</span><span>[</span><span>i</span><span>]++;</span>
        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>ns</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dns</span><span>[</span><span>i</span><span>];</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
        <span>{</span>
            <span>double</span> <span>d</span> <span>=</span> <span>ns</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>];</span>
            <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>1</span> <span>||</span> <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
            <span>{</span>
                <span>int</span> <span>dInt</span> <span>=</span> <span>Math</span><span>.</span><span>Sign</span><span>(</span><span>d</span><span>);</span>
                <span>double</span> <span>qs</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>if</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qs</span> <span>&amp;&amp;</span> <span>qs</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>])</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qs</span><span>;</span>
                <span>else</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dInt</span><span>;</span>
            <span>}</span>
        <span>}</span>

        <span>count</span><span>++;</span>
    <span>}</span>
    
    <span>private</span> <span>double</span> <span>Parabolic</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>double</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>*</span> <span>(</span>
            <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>])</span> <span>+</span>
            <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span>
        <span>);</span>
    <span>}</span>

    <span>private</span> <span>double</span> <span>Linear</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]);</span>
    <span>}</span>

    <span>public</span> <span>double</span> <span>GetQuantile</span><span>()</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;=</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>,</span> <span>0</span><span>,</span> <span>count</span><span>);</span>
            <span>int</span> <span>index</span> <span>=</span> <span>(</span><span>int</span><span>)</span> <span>Math</span><span>.</span><span>Round</span><span>((</span><span>count</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>p</span><span>);</span>
            <span>return</span> <span>q</span><span>[</span><span>index</span><span>];</span>
        <span>}</span>

        <span>return</span> <span>q</span><span>[</span><span>2</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3><p>The P¬≤ quantile estimator allows estimating quantile values on a stream of numbers without storing individual ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/p2-quantile-estimator/">https://aakinshin.net/posts/p2-quantile-estimator/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/p2-quantile-estimator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201093</guid>
            <pubDate>Tue, 24 Nov 2020 18:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25200893">thread link</a>) | @bitwizzle
<br/>
November 24, 2020 | https://cryptologie.net/article/511/how-do-people-find-bugs/ | <a href="https://web.archive.org/web/*/https://cryptologie.net/article/511/how-do-people-find-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can‚Äôt find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I‚Äôve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement‚Äù. I like that sentence, although one can point out that these traits are closely linked--you can‚Äôt have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call ‚Äúplaintext awareness.‚Äù Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‚Äòprovably-secure schemes‚Äô sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA‚Äôs Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it‚Äôs slow, it‚Äôs not flexible (if you change the protocol, good job changing the proof), and it‚Äôs limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint‚Äôs secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP‚Äôs WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don‚Äôt want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components ‚Äî handshake and encryption protocol ‚Äî&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I‚Äôm pretty sure there‚Äôs an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it‚Äôs a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we‚Äôre just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don‚Äôt further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I‚Äôd be interested‚Ä¶</p>
<p>In any case, what‚Äôs left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn‚Äôt been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we‚Äôve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://cryptologie.net/article/511/how-do-people-find-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200893</guid>
            <pubDate>Tue, 24 Nov 2020 17:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby on Rails: Still the Best Web App Framework for Most Teams]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25200799">thread link</a>) | @sairamkunala
<br/>
November 24, 2020 | https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html | <a href="https://web.archive.org/web/*/https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Earlier this year, I was in the position to choose the framework for the startup at which I‚Äôm now the CTO. I
could‚Äôve chosen anything. I went with Rails.  And you should, too. It still is the best framework for getting up
and running <em>and</em> for continued iteration and development.</p>

<!-- more -->

<p>Writing a web app requires many moving pieces.  If you use something like Spring, Node, Express, or any other basic
library, you have a <em>lot</em> of decisions to make:</p>

<ul>
  <li>How are URLs routed to code?</li>
  <li>How are headers, params, and request bodies parsed?</li>
  <li>Where does the code live to manage this?</li>
  <li>How are responses created?</li>
  <li>How do we generate dynamic HTML?</li>
  <li>How do we mitigate against common security vulnerabilities such as cross-site scripting?</li>
</ul>

<p>Of course, web apps almost always have a database, which leads to more decisions:</p>

<ul>
  <li>How will we access the database?</li>
  <li>How is the database schema managed?</li>
  <li>What conventions will we use for table and column names?</li>
</ul>

<p>Then, there are concerns around the development environment:</p>

<ul>
  <li>How do we write tests?</li>
  <li>How can we execute a test using a web browser?</li>
  <li>How do we manage the data needed for our tests?</li>
  <li>How do we manage data needed to run the app locally?</li>
</ul>

<p>Finally, there are concerns around deployment and production:</p>

<ul>
  <li>How do I get JavaScript packaged for the browser?</li>
  <li>How do I manage CSS?</li>
  <li>How do I create cacheable bundles for CDNs?</li>
</ul>

<h2 id="the-cost-of-making-so-many-decisions">The Cost of Making So Many Decisions</h2>

<p>These decisions are only the beginning.  I‚Äôve worked on web apps that used libraries only‚Äîno frameworks‚Äîand all of
these decisions plus more had to be made. Many had to be made before the team could start working.  But as time
went by and the team‚Äôs composition changed, managing these decisions was a constant tax.</p>

<p>‚Ä¶managing these decisions was a constant tax</p>

<p>Because <em>we</em> made these decisions and <em>we</em> configured our libraries to work in a particular way, it was not
uncommon for developers to want to know why we did it that way, and could we change it?  Many of these decisions
amount to conventions not enforceable with code, so a good chunk of our code reviews required making sure everyone
followed the conventions.</p>

<p>And then we would update our libraries to find out they were suddenly incompatible.  Because we‚Äôd hand-selected
libraries to solve each problem, we had no way to guarantee they all worked together other than making sure our app
still worked.  It was hard to see the value in the series of decisions that led to this architecture.</p>

<h2 id="stop-making-so-many-decisions">Stop Making So Many Decisions</h2>

<p>With Rails, you don‚Äôt have to make <em>any</em> of the decisions above. None.  Once you type <code>rails new</code> all of those
decisions are made.  True, there are more decisions you will have to make, but Rails will have eliminated a huge number of ultimately pointless decisions.</p>

<p>Rails will have eliminated a huge number of ultimately pointless decisions</p>

<p>It simply doesn‚Äôt matter how JavaScript is packaged, what your database naming conventions are, or how HTTP requests are routed to code. You need answers and conventions for all of that, yes, but the actual conventions don‚Äôt matter.</p>

<p>What you also need are the conventions to be enforced or managed in code, not documentation. That way, everyone is
incentivized to focus on the problems specific to their domain instead of the plumbing of their app.</p>



<p>This has been the value proposition for Rails since its inception over 15 year ago.  In that time, Rails and its
ecosystem have matured, improved, and continued moving forward.  The value Rails brings is still needed, and it is
<em>still</em> the best framework for most teams.</p>

<p>Engineers without Rails experience may continue to believe the fantasy that Rails does not scale or that it can‚Äôt
be used for ‚Äúserious‚Äù problems.  Those of us <em>with</em> Rails experience know this isn‚Äôt true.  But what we also worry
about is that Rails apps can become unmaintainable.</p>

<h2 id="rails-helps-maintainability">Rails Helps Maintainability</h2>

<p>Hopefully, it‚Äôs obvious that no framework or set of libraries can ensure maintainability.  I would argue that Rails
gives you a better chance.  Rails‚Äîand its ecosystem‚Äîtend to evolve together, so you can rely on the stability of
your core tools over many years.</p>

<p>Rails basis in conventions also means that there are generally fewer parts of an app to get crufty as time goes by.
But, it‚Äôs still up to the team to establish conventions and ways of working to capitalize on that.  As it would be
on any team.</p>

<p>So what happens when the team stops making pointless decisions, worrying about library compatibility, and spending
code-review time on conventions?  They start thinking about the problems they need to solve. That‚Äôs why Rails is
the best web framework for most teams.</p>

  </section></div>]]>
            </description>
            <link>https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200799</guid>
            <pubDate>Tue, 24 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No surprises here ‚Äì On the absence of information in today‚Äôs media]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25200732">thread link</a>) | @s3v
<br/>
November 24, 2020 | https://www.turningchaos.com/essays/no-surprises-here | <a href="https://web.archive.org/web/*/https://www.turningchaos.com/essays/no-surprises-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4a3121594376e73eb592"><div><h2>The absence of information in today‚Äôs press</h2><p>"<em>Nobody goes to a newspaper for news.</em>" ‚ÄîMartin Gurri</p><p>We're told we live in the information age. Statements like this often quote the mind-boggling amount of data produced on the internet using exotic-sounding words like zettabytes per day as proof. To function in this sea of data, we're supposed to find signals in the noise and read from credible sources of news and other information. With news media taking political stances, it's not that easy.</p><p>My assertion, paradoxically, is that polarization has greatly diminished the <em>quantity of information</em> being produced and consumed via today's press despite the sea of content they produce. The result is a loss of the press's effectiveness in their two functions within a healthy democracy, as a check on government and promoter of informed debate.</p><h2>Information</h2><p>It's important to define terms. What is information?</p><p>In the <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a> definition, the quantity of information in a message is related to the amount of <em>surprise</em> it contains. This idea of surprise is key so I'm going to spend some time on it.</p><p>Let's imagine you're receiving messages about some set of data and you're trying to determine its distribution. Each message contains one data point. Early on, as you receive messages, the information provided by each piece of data is high because you know very little about the data itself. With each new piece of information, you start to construct a representation of the overall data set like the one shown in the image below.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606176449103_6575"><div><p>After some number of points, you realize the data is a normal distribution or bell-curve and you can make some determination about its structure. In this case, the mean or average value as well as its width (or standard deviation). Let's say the average value is 0 and the standard deviation is 1. This means that 68% of the values will be between -1 and 1, 95% will be between -2 and 2, and &gt;99% will be between -3 and 3.</p><p>Great! Let's say the next set of messages that you get are 0, 0.1, and 1. Those numbers are completely within the expected range we calculated earlier. There's nothing particularly surprising about them, and as a result, <strong>there is almost no information</strong> contained within them.</p><p>What if you get a message of 10? Now there's a problem. There's almost no chance that the distribution we described above should include a value of 10. Getting 10 is very surprising. So surprising that it may mean the model we had for this data is entirely wrong. That's a lot of information contained in one message of 10, way more than the other messages we got earlier.</p><p>Why does 10 have so much information? It's because it's surprising. It causes us to challenge the model we had built. It could be that the message was a mistake, a fluke. But it could also be that the conclusions we held were wrong. <strong>The more high-information messages like this we get, the more we should start to challenge the beliefs we previously held.</strong> Now let's get back to media.</p><h2>News media</h2><p>In today's polarized media, each side of the media discourse has established its perspective, and the content they publish conforms to this perspective. When you go to a news outlet with a particular leaning, you may not know exactly what stories they'll be writing about, but you do know what <em>kind</em> of stories will be covered and from what perspective. Your knowledge about that outlet's outlook was built up over time as you encountered what they publish.</p><p>When one outlet consistently publishes pieces that align with their perspective, the information content provided by each article starts to diminish. When the theme of each article aligns within the expected distribution, there's no surprise and thus no information.</p><p>It's important to take a moment to distinguish surprise from shock. As you may be familiar, it's common for media to publish stories that have a shock value as they compete with other organizations for your attention. What I'm discussing in this essay isn't the shock value or the particular event that the news media is writing about, it's the perspective of the news organization and the degree of surprise that they published it. For example, you might be shocked at the behavior of one political party's behavior, but are you surprised by it, and more importantly, are you surprised that a news organization that takes the opposite position is publishing a story about it? Shock and surprise can be related, but there's a distinction here between headlines that are attention-grabbing and whether the content fits the mold of the news organization's narrative.</p><h2>Implications</h2><p>The danger of this is two-fold. First, if you only read from one source or a set of sources with similar outlooks, the media source's perspective can start to become yours. You end up with a world-view that aligns with the publisher's view. Since that source never prints anything which disputes that view, your perspective on the world becomes insulated and unchallenged. It's like the example above where we thought we knew the distribution was a bell-curve until we got a few message outliers. Those outliers demanded we reconsider our earlier conclusions. Except this time, <strong>the outliers exist but we never receive them</strong>. We go about our days oblivious to information that would challenge our world-view because it doesn't get published anywhere we look.</p><p>"<em>A free press is one of the pillars of democracy</em>." - Nelson Mandela</p><p>The second danger involves the media's role as a check on government. The branches of government exist to prevent the abuse of power by one another. <strong>The press exists to prevent the abuse of information by the government.</strong> It should question and investigate claims by the government to inform voters and further civic discourse.</p><p>However, this function requires the press to be viewed as impartial, truth-seeking, and without advancing an opinion except where explicitly noted (i.e. the opinion section). If the average voter comes to distrust the press, this function is lost. Articles that would normally inform the voter, providing surprise and evidence that would counter a particular world-view, instead go unread or dismissed. Voters either write off the press entirely or read solely from outlets with views that align with their own further solidifying their own beliefs. In either case, we end up with tribes of perspectives unwilling to seek a compromise that can allow the country to proceed collectively.</p><p>I'm not claiming that all reporters are like this. There are excellent reporters that seek truth regardless of politics. Unfortunately, this independent perspective is increasingly difficult to find. Well-reasoned, objective reporting doesn't generate the same attention as partisan emotion.</p><p>Instead, our press needs to promote information and surprise without bias. By only publishing from one narrative, they insulate the public (and themselves!) from information that could lead to honest debate and discovery. Likewise, our opinions should be formed from a careful examination of arguments and evidence on each side of the issue, <strong>reading from only one perspective is akin to not reading at all.</strong></p></div></div></div>]]>
            </description>
            <link>https://www.turningchaos.com/essays/no-surprises-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200732</guid>
            <pubDate>Tue, 24 Nov 2020 17:35:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My EOY Reflection Checklist]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25199785">thread link</a>) | @opsgal
<br/>
November 24, 2020 | https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>The End-of-Year Checklist</strong><span>&nbsp;</span></em><em><span></span></em></p>
<p><span>I like starting the year with an empty to-do list and a fresh perspective. As an obsessive list maker, this process naturally starts with another list. Some of the questions can be treated as action items, but many require deeper reflection (perfect for the quiet week at the end of the year). I hope that you find it useful as you close out 2020!</span></p>

<h5><strong>As a Company</strong></h5>
<ul>
<li><span>What actions most moved the company forward and how can we double down on them? What should we have spent less time doing?&nbsp;</span></li>
<ul>
<li><span>Using the </span><a href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/?sh=15a5959d3814"><span>Pareto Principle</span></a><span>, the return on certain actions will significantly outweigh others.</span></li>
</ul>
<li><span>Did our actions reflect our values? Did we call out times that employees personified our values? Do we need to add or subtract values?</span></li>
<li><span>Which relationships are most important to our success (e.g. customers, investors, partners) and what can we be doing to provide them with more value?</span></li>
</ul>

<h5><strong>As a Manager</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Do we have the </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html"><span>right people on the bus</span></a><span>?</span></li>
<li><span>Are the right people owning the right things or are there better ways that we can be distributing the work?</span><br><span></span><span></span></li>
</ul>

<p><span>I keep a Trello board to manage this; <a data-cke-saved-href="https://trello.com/b/v6lu8Xpc" href="https://trello.com/b/v6lu8Xpc" target="_blank" rel="noopener">steal my template here</a>.</span></p>
<p><img src="https://cdn.buttercms.com/j9hSXZluRBG3S2HjajIu" alt="trello chart" width="683" height="158"></p>
<ul>
<li><span>How were my 1:1s? Did my reports walk away feeling that I had removed blockers, clarified vagueness, and given clear instructions?</span></li>
<li><span>Do my reports know their metrics for success?</span></li>
<li><span>How connected is the team overall?</span><strong></strong><span></span></li>
</ul>
<h5><strong>Meetings</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Is every meeting on my calendar still relevant and useful?</span></li>
<li><span>Have I invited the right people to each one?</span></li>
<li><span>Are the major meetings for the upcoming year already scheduled? Mine are:</span>
<ul>
<li><span>Off-sites</span></li>
<li><span>Customers business reviews</span></li>
<li><span>Employee reviews</span></li>
<li><span>Team town halls</span></li>
<li><span>Quarterly kickoffs</span></li>
<li><span>Annual trainings</span></li>
</ul>
</li>
<li><span>Do I like the cadence and timing of my recurring meetings?</span>
<ul>
<li><span>Can I schedule any back-to-back to minimize distractions?</span></li>
<li><span>Are meetings optimized to my energy peaks?</span>
<ul>
<li><span>I‚Äôm fresh and driven in the mornings and do my best work then. Mentally challenging meetings are best during this window.</span></li>
<li><span>My mind is more relaxed and able to freely brainstorm in the afternoons; I shift most meetings to this time.</span>&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><strong>Tools</strong></h5>
<ul>
<li><span><span>Are we using the right tools (software, banking, equipment, etc.) to accomplish our goals? Can we eliminate any?</span></span></li>
</ul>
<figure><img src="https://cdn.buttercms.com/exgcpuvKRdmBDDBzKUvF" alt="saas-list" width="772" height="101">
<figcaption>
<p><span>This number balloons quickly, so I keep a spreadsheet of all our tools to track which are still in use and who has access.</span></p>
</figcaption>
</figure>
<ul>
<li><span>Do the right people have access to each tool? Has admin access been given to the logical person?</span></li>
<li><span>Do we have the right tier of service for our size?</span></li>
<li><span>Are there more effective tools available that could reduce or combine the efforts of others?&nbsp;</span></li>
</ul>
<h5><strong>Finance</strong></h5>
<ul>
<li><span>Are our finances generally in order? This can include:</span></li>
<ul>
<li><span>Outstanding invoices</span></li>
<li><span>Unpaid bills</span></li>
<li><span>Sales commissions</span></li>
<li><span>Expense reconciliation</span></li>
<li><span>Credit card charges</span></li>
</ul>
<li><span>Are there areas that we could cut costs next year?</span></li>
<li><span>Is billing set to preferred person and method? (I like to see every charge come through and to optimize points based on spend.)</span></li>
</ul>

<h5><strong>Operations</strong></h5>
<ul>
<li><span>Where can we automate tasks?</span></li>
<li><span>Are the company files clean and organized? What about mine?</span></li>
<ul>
<li><span>If a company file no longer seems relevant, I dump it into an archive folder rather than delete anything.</span></li>
<li><span>I run an inbox-zero on my file downloads and desktop, forcing myself to put any important files somewhere safe in case something happens to my computer.</span></li>
</ul>
<li><span>Are our templated documents up to date?</span></li>
<ul>
<li><span>Check company address, point of contact, and legalese on contracts, mNDAs, etc.</span></li>
</ul>
<li><span>How are our processes? Which ones are sloppy, overly prescriptive, or begging to be eliminated entirely?</span></li>
</ul>

<h5><strong>Performance</strong></h5>
<ul>
<li><span>How did I perform against my job description?</span></li>
<ul>
<li><span>I keep my job description as a living document to capture what I take on and hand off over time. When I doubt where my time is being spent, I discuss this document with my boss and adjust accordingly.</span></li>
</ul>
<li><span>How were my 1:1s with my boss? Did I come to the meeting with thoughtful questions and specific to-dos?&nbsp;</span></li>
<li><span>Did I listen to and incorporate feedback effectively?</span></li>
<li><span>Did I step up when I needed to? Did I delegate my areas of weakness?</span></li>
</ul>
<h5><strong>Role</strong></h5>
<ul>
<li><span>How do I want my job description to change in the next year based on what the company needs and on my own strengths and weaknesses?</span></li>
<li><span>Which relationships within the company are most important to my efficacy? Can I do anything to improve upon those relationships?</span></li>
<li><span>Which tasks I should be taking on or offloading?</span></li>
</ul>
<h5><strong>Time</strong></h5>
<ul>
<li><span>Am I spending time on </span><a href="https://www.nfx.com/post/time-management-for-founders/"><span>the most valuable things</span></a><span> and letting the unimportant things fall through the cracks?</span></li>
<li><span>What have I been putting off?&nbsp;</span>
<ul>
<li><span>Can I eliminate it or delegate it?</span></li>
<li><span>Can I give it more clarity?</span></li>
</ul>
</li>
<ul>
<li><span>I tend to dread tasks that either feel pointless or excessively vague, so I ask:&nbsp;&nbsp;</span></li>
</ul>
<li><span>What can I stop doing altogether?</span></li>
</ul>
<h5><strong>Personal</strong></h5>
<ul>
<li><span>Do I like my personal systems for keeping track of to-dos?</span></li>
<li><span>Do I know what I bring to the table when I join a meeting?</span></li>
<li><span>Am I maintaining a network of people I can turn to for advice?</span></li>
<li><span>Am I making time outside of work for activities that keep me healthy and happy?</span></li>
</ul>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199785</guid>
            <pubDate>Tue, 24 Nov 2020 16:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ham Radio Needs to Embrace the Hacker Community Now More Than Ever]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25199686">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <h2 id="an-open-letter-to-all-ham-radio-operators">An Open Letter To All Ham Radio Operators</h2>
<p>‚ÄúHam Radio is dying!‚Äù A phrase all to often uttered that it‚Äôs become clich√©, but it‚Äôs partly true. You can‚Äôt deny a considerable section of the ham radio operators in the world are in the latter part of their lives.They won‚Äôt be around forever so naturally new people must assume their place. The good news is amateur radio licenses are on the rise. The bad news is the people induced to ham radio these days aren‚Äôt interested in pushing the limits of RF technology. To be blunt I‚Äôm talking about preppers and those solely interested in emergency communications. Neither of which have any desire to explore ham radio beyond a disaster fetish in which they use their $25 BaoFeng HT to save the world. So what can ham radio operators do? Easy, reach out to the hacker community! First, allow me define the word hacker since there are nefarious connotations of the word‚Äôs meaning. When I use the word hacker, I‚Äôm talking about the type of individual who wants to comprehend how a given technology works and who explores all the possibilities that technology has to offer. These are the people who grew up dismantling electronics just to appreciate how they work, the people who stayed up late into the night teaching themselves to code, and these are the people ham radio needs to propel it further into the future. To attract and retain hackers within the ham community there are a few things that we need to do.</p>
<h3 id="1-stop-primarly-promoting-emergency-communications">1. Stop Primarly Promoting Emergency Communications</h3>
<p>Every day I see on the <a href="https://www.reddit.com/r/amateurradio/">r/amateurradio</a> subreddit a number of people who solely promote ham radio‚Äôs role in emergency communications. Does it have a place within the hobby and community? Certainly, however, there is little interest from the hacker community in relaying messages about the state of the weather during a thunderstorm. Ham radio offers so much morel. You do it a disservice when you either dismiss the other areas of the hobby as secondary to emergency communications or fail to mention them at all. For crying out loud, we launch our own communications satellites and utilize them every day. Satellite communications, the blending of RF and VoIP to communicate around the world, software defined radio represent the things we need to promote to the hacker community. To effectively communicate, identify your audience.</p>
<h3 id="2-start-promoting-software-defined-radio">2. Start Promoting Software Defined Radio</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/radios/hackrf-one-sdr-001.webp" alt="Will SDRs like the HackRF One be the future of ham radio?"> <figcaption>
            <p>Will SDRs like the HackRF One be the future of ham radio?</p>
        </figcaption>
</figure>

<p>There is a lot of interesting work that‚Äôs currently being done within the hacker community with RF. Most of this work is currently centered around WiFi, LoRa, IoT networks. It not difficult to imagine someone who has an interest in these communication technologies wouldn‚Äôt be open to software defined radio. They just need to be presented with easy to understand examples and a little encouragement to become licensed. Kelly Albrink‚Äôs 2020 DerpCon talk <em>Ham Hacks: Breaking into the World of Software Defined Radio</em> does just that.</p>

<p>
  <iframe src="https://www.youtube.com/embed/LIcE0frWtLo" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>Software Defined Radio is here and we as hams need to explore all the potential the technology has to offer. Currently full SDR transceivers are available from Flex Radio, and the major ham radio manufactures are beginning to produce hybrid SDR transceivers. With SDRs such as the BladeRF 2.0, LimeSDR and the HackRF One the entry point into software defined radio is relatively low. These lowcost SDRs make excellent platforms for experimentation within the VHF/UHF bands. The <a href="https://www.youtube.com/c/TechMindsOfficial">YouTube channel Tech Minds</a> has some excellent videos of what these little radios can do.</p>

<p>
  <iframe src="https://www.youtube.com/embed/qx_orXHiQk8" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="3-provide-communities-that-foster-technical-discussion-and-exploration">3. Provide Communities That Foster Technical Discussion and Exploration</h3>
<p>It‚Äôs been my experience that local radio club are more focused on emergency communications rather than the more technical aspects of ham radio (Seriously, why so much obsession with emergency communications?). Most of the anecdotal evidence I‚Äôve collected has suggested this is a common occurrence around the United States. This type of focus doesn‚Äôt foster an environment of learning and exploration. Why would the hacker community want to participate, in discussions about who‚Äôs going provide communications ‚Äúsupport‚Äù on the corner of Elm and Main St. during the annual Forth of July parade? You need to create the type of environment where the discussion is focused on RF technology. If you can‚Äôt do that locally in person or over the air, then it‚Äôs time to turn to the digital voice modes. That‚Äôs right, DStar, DMR, and System Fusion provide an opportunity to essentially create local communities of common interest. Access to these communities are as easy as connecting to one‚Äôs hotspot; I guess you could present the argument that some repeaters are connected to these digital networks and blah blah blah. Hotspots! That‚Äôs what the cool kids are doing these days. As an aside, <a href="https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">check out my new hotspot</a>.</p>
<h4 id="introducing-the-radio-hackers-ysf-reflector">Introducing the Radio Hackers YSF Reflector</h4>
<p>In my efforts to better understand the System Fusion and WiresX Network and how they relate to each other, I created a YSF Reflector called Radio Hackers. As you may have guessed this is the beginning stages of the hacker community, I‚Äôm fostering among ham radio operators. This is by nowhere complete and I welcome you to assist me in any way that you can. The most significant thing you can do is inform others and join in on the discussion on the reflector.</p>
<ul>
<li>ID: 33360</li>
<li>Name: Radio Hackers</li>
<li>Dashboard: <a href="http://hackers.ysf.kj7nzl.net/">http://hackers.ysf.kj7nzl.net</a></li>
<li>Bridged Networks: TBD</li>
</ul>
<p>If anyone knows more about bridging networks together with XLX please reach out to me. I‚Äôd love to speak with you more. My contact information is provided on the <a href="https://www.kj7nzl.net/">home page</a> of this site.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199686</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aurora 7 Prototype ‚Äì 7 Screen Laptop]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25199499">thread link</a>) | @882542F3884314B
<br/>
November 24, 2020 | https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/ | <a href="https://web.archive.org/web/*/https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Actual_Page_Container">

<!-- REVOLUTION SLIDER -->

<!-- /REVOLUTION SLIDER --><!-- -->

<section>
<div>





<h2>Prototype Objective Summary:</h2>

<p>Very simple :) - Design and build a proper mobile Security Operations Center.</p>

<p>I always knew this would be an ambitious undertaking. Power considerations, structural rigidity, actual portability and the ability to be easily and quickly compactible were priorities. For a further break down of the objectives please read on.</p>



<h2>Prototype Objective Breakdown and Achievement percentage:</h2>

<p>This is a breakdown of the objectives. It also shows how much of the objective in percentage was achieved with the Aurora 7 Prototype.</p>

<div>


<div><p><label><span>100%</span> 6 Cores or more at 5GHZ capability </label></p>
</div>

<div><p><label><span>100%</span> Fully integrated Multi Touch Screen in Palm rest </label></p>
</div>

<div><p><label><span>100%</span> 4 x 17.3 UHD/4K Screens </label></p>
</div>

<div><p><label><span>70%</span> Ability to easily replace parts </label></p>
</div>

<div><p><label><span>70%</span> Ability to swap wiring and parts with easily attainable parts </label></p>
</div>

<div><p><label><span>90%</span> Rechargeable battery system fully self contained </label></p>
</div>

<div><p><label><span>70%</span> Easily Replaceable batteries </label></p>
</div>



<div><p><label><span>100%</span> NVIDIA GTX 10 Series Graphics </label></p>
</div>

<div><p><label><span>100%</span> Separate Programmable System Monitor LCD </label></p>
</div>

<div><p><label><span>100%</span> User/Arduino accessible Embedded Microcontroller. </label></p>
</div>





<div><p><label><span>100%</span> Ability to fold down compactly to facilitate travel </label></p>
</div>

<div><p><label><span>100%</span> Full NO-NONSENSE 104 Key tactile backlit Keyboard. </label></p>
</div>

<div><p><label><span>80%</span> Overall Structural Rigidity </label></p>
</div>



<div><p><label><span>100%</span> Everything folds or swivels out of the primary chassis (NO appendages) </label></p>
</div>



<div><p><label><span>100%</span> Out of band always visible battery gauge </label></p>
</div>



<div><p><label><span>100%</span> More than 16TB SSD Storage potential </label></p>
</div>
</div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199499</guid>
            <pubDate>Tue, 24 Nov 2020 15:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Don't Work With Startups (Or FAANGs)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25199374">thread link</a>) | @elliotbnvl
<br/>
November 24, 2020 | https://devcareer.elliotbonneville.com/no-startups-or-faangs | <a href="https://web.archive.org/web/*/https://devcareer.elliotbonneville.com/no-startups-or-faangs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-no-startups-or-faangs"><p><span><span>This chapter is not a hard and fast set of rules you should always abide by, but is some reasoning and facts that I‚Äôve found to be true about picking a company to work for, while optimizing for a high rate, freedom, and flexibility.</span></span></p><p><span><span>The tl;dr version is that you shouldn‚Äôt work with startups, because they are high pressure and don‚Äôt pay well, and you shouldn‚Äôt work with household names (Facebook, Amazon, Google, Netflix, and their ilk) because they don‚Äôt provide as much flexibility.</span></span></p><p><span><span>Instead, you should target a sweet spot right in the middle, working with companies who have enough money to pay you well, but aren‚Äôt large enough and well-run enough that they can afford to be extremely exclusive and demanding of their employees.</span></span></p><p><span><span>As a side effect of their size, these companies often have pressing technical issues that are growing pains which haven‚Äôt been resolved yet that you can be of real value in solving. Working with them leads to doing high-value, satisfying work that pays well and affords you freedoms you wouldn‚Äôt otherwise find.</span></span></p><p><span><span>We‚Äôll clear up some common misunderstandings and establish our reasoning by tackling this topic from first principles, as per usual.
</span></span></p><p><span><span><em>This post is an early release chapter of </em></span><span><em><a href="https://devcareer.elliotbonneville.com/">a book I'm writing in public</a></em></span><span><em>, working title of </em></span><span>Refactor Your Career</span><span><em>. If you're interested in following along for more prerelease chapters and other info, you can sign up for the newsletter below:</em></span></span></p><h2 id="block-b97dcd7b406e467b87a25fbcb87546ba"><span id="b97dcd7b406e467b87a25fbcb87546ba"></span><span><span>Don‚Äôt work with startups</span></span></h2><p><span><span>The definition of a startup is ‚Äúa company prioritizing fast growth over everything else.‚Äù</span></span></p><p><span><span>Given the current economic incentive structure of the venture capital model, startups often take outside investment to grow more quickly.</span></span></p><p><span><span>As a result, startups typically optimize to get as much done with as little money and in as little time as possible, because they are not cash-flow positive and have limited financial runway.</span></span></p><p><span><span>Therefore, they are incentivized to find extremely high return-on-investment employees who will work long hours for little money. To find these employees, they will use a number of strategies:</span></span></p><ul><li id="block-53700a214aaf4831be4625f6876e0ed7"><span><span>Offer equity instead of cash compensation</span></span></li><li id="block-2b21919a7bb64e3e962a21fd7d352e42"><span><span>Offer ‚Äúfun‚Äù benefits (beer, ping pong table, catered lunches, free movie tickets, etc.)</span></span></li><li id="block-bb36db0b8db44966b9505bbb5ec4ea1a"><span><span>Target young, talented, and hardworking engineers who are new to the industry and don‚Äôt have connections</span></span></li></ul><p><span><span>An extremely high return-on-investment employee is always getting the short end of the stick. The money has to come from somewhere, and in this case the money is coming from the employees‚Äô pockets.</span></span></p><p><span><span>As an aside, your employer wins when they get the most bang for their buck, but the more bang they get for their buck, the less bang you get in return for the most valuable resource you possess -- your time.</span></span></p><p><span><span>At its core, hourly billing is a profoundly adversarial relationship, and you need to understand the rules by which it operates in order to not be taken advantage of. If you don‚Äôt know the rules of the game, you will lose. If you know the rules of the game and don‚Äôt play to them, you will lose. If you want to win, you must play intelligently, intentionally, and aggressively.</span></span></p><p><span><span>Hourly billing is just the beginning. As you grow in skill and ‚Äúcareer capital‚Äù (c.f. </span><span><a href="https://www.amazon.com/Good-They-Cant-Ignore-You-ebook/dp/B0076DDBJ6" target="_blank" rel="noopener noreferrer"><em>So Good They Can‚Äôt Ignore You</em></a></span><span>, Cal Newport), you‚Äôll want to explore ways to move away from hourly billing to a better way of billing, i.e. separating time worked from results delivered. Big benefits to you and your clients all the way around. Jonathan Stark writes eloquently on the issues with hourly billing </span><span><a href="https://jonathanstark.com/the-moral-dilemma-of-hourly-billing" target="_blank" rel="noopener noreferrer">here</a></span><span>.</span></span></p><p><span><span>Let‚Äôs take a deeper look at the strategies startups use to find employees, and why that means working for one is usually a bad strategy.</span></span></p><h3 id="block-5b675128f52f4bc7ae0ffadf51c842d9"><span id="5b675128f52f4bc7ae0ffadf51c842d9"></span><span><span>Taking equity is becoming a micro venture capitalist</span></span></h3><p><span><span>Venture capitalism is a bet on the future. Even the best venture capitalists lose money on most of their investments. They only turn a profit because they invest at scale and need just a couple of big wins per batch of investments in order to make up for that extremely high percentage of losses. They also study investing all day, every day, and are surrounded by people all doing the exact same thing.</span></span></p><p><span><span>Second, time is fungible. If you want, you can trade time for money directly (that‚Äôs what hourly billing is, after all). Therefore, an investment of time is an investment of your personal funds.</span></span></p><p><span><span>As a result, if you take equity compensation instead of cash when working at a startup, you are investing your money directly into that startup.</span></span></p><p><span><span>Given all of the above and bearing in mind that venture capitalism is a high risk bet that only works at scale for people who exclusively study how to invest, the odds that you are going to make a return on your investment with the limited amount of resources that you have to invest is vanishingly low.</span></span></p><p><span><span>Don‚Äôt try to play venture capitalist with the most valuable thing you have -- your time.</span></span></p><p><span><span><a href="https://www.jwz.org/about.html" target="_blank" rel="noopener noreferrer">Jamie Zawinski</a></span><span> (OG programmer, one of the founders of Netscape and Mozilla.org, the guy who probably wrote your screensaver, and now a dance club proprietor [yes, really]) has this to say about working for startups:</span></span></p><blockquote id="block-bf5cc1f488d24661902d79343aefc830"><span><span>Follow the... money. When a VC tells you what's good for you, check your wallet, then count your fingers.

He's telling you the story of, "If you bust your ass and don't sleep, you'll get rich" because the only way that people in his line of work get richer is if young, poorly-socialized, naive geniuses believe that story! Without those coat-tails to ride, VCs might have to work for a living. Once that kid burns out, they'll just slot a new one in.</span></span></blockquote><p><span><span>You can read the full post from 2011 </span><span><a href="https://www.jwz.org/blog/2011/11/watch-a-vc-use-my-name-to-sell-a-con/" target="_blank" rel="noopener noreferrer">here</a></span><span> and I highly encourage you to do so. It‚Äôs a zinger.</span></span></p><h3 id="block-ffa7baffd6a6461a9f9db8658d9237c6"><span id="ffa7baffd6a6461a9f9db8658d9237c6"></span><span><span>Empirically, equity is not as valuable as it seems</span></span></h3><p><span><span>Backing up the logic above, loose empirical analysis shows that if you look at total startup compensation as income combined with equity </span><span><em>adjusted for likelihood of realizing that equity‚Äôs value</em></span><span>, statistically you end up making less money in the end.</span></span></p><p><span><span>Patrick McKenzie, a well-known entrepreneur and prolific writer, and currently working at Stripe to ‚Äúincrease the GDP of the internet,‚Äù has this to say on the topic of valuing equity grants:</span></span></p><blockquote id="block-f861c0e363034719a6aa4cf4032f0005"><span><span>Roll d100. (Not the right kind of geek? Sorry. rand(100) then.)

0~70: Your equity grant is worth nothing.

71~94: Your equity grant is worth a lump sum of money which makes you about as much money as you gave up working for the startup, instead of working for a megacorp at a higher salary with better benefits.

95~99: Your equity grant is a lifechanging amount of money. You won‚Äôt feel rich ‚Äî you‚Äôre not the richest person you know, because many of the people you spent the last several years with are now richer than you by definition ‚Äî but your family will never again give you grief for not having gone into $FAVORED_FIELD like a proper $YOUR_INGROUP.

100: You worked at the next Google, and are rich beyond the dreams of avarice. Congratulations.

Perceptive readers will note that 100 does not actually show up on a d100 or rand(100).</span></span></blockquote><p><span><span>Dan Luu, another well-known developer and blogger, has this to say on the subject:</span></span></p><blockquote id="block-841b5199ddf14a02af23c89b2adf0131"><span><span>For a more serious take that gives approximately the same results, 80000 hours finds that the average value of a YC founder after 5-9 years is $18M. That sounds great! But there are a few things to keep in mind here. First, YC companies are unusually successful compared to the average startup. Second, in their analysis, 80000 hours notes that 80% of the money belongs to 0.5% of companies. Another 22% are worth enough that founder equity beats working for a big company, but that leaves 77.5% where that's not true.

If you're an employee and not a founder, the numbers look a lot worse. If you're a very early employee you'd be quite lucky to get 1/10th as much equity as a founder. If we guess that 30% of YC startups fail before hiring their first employee, that puts the mean equity offering at $1.8M / .7 = $2.6M. That's low enough that for 5-9 years of work, you really need to be in the 0.5% for the payoff to be substantially better than working at a big company unless the startup is paying a very generous salary.</span></span></blockquote><p><span><span>You can read the rest of Patrick‚Äôs post </span><span><a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/" target="_blank" rel="noopener noreferrer">here</a></span><span>, and the rest of Dan‚Äôs post </span><span><a href="https://danluu.com/startup-tradeoffs/" target="_blank" rel="noopener noreferrer">here</a></span><span>. I highly recommend that you do so; they are erudite writers with a lot of insight into the industry.</span></span></p><h3 id="block-886c6f74b682471f90e8c002e01f09c9"><span id="886c6f74b682471f90e8c002e01f09c9"></span><span><span>Startup benefits are the cheese in the mousetrap</span></span></h3><p><span><span>While it might seem rather cynical, the benefits at a startup are just the cheese in the mousetrap. If you calculate the actual cash value of the benefits that many startups offer, you‚Äôll find that they‚Äôre laughably low. Free beer, access to the company ping pong table (that never gets used), free movie tickets and a two hundred dollar per month business learning stipend actually work out to a relatively low amount of cold, </span><span><del>hard</del></span><span> mildly wrinkled Franklins.</span></span></p><p><span><span>Even things that are seemingly inherent to the unpurchasable, intangible benefits of startup culture like an open desk plan, brilliant and intense coworkers, and technically cutting-edge work can all be had elsewhere for a fraction of the time-cost of working at a startup if you‚Äôre willing to think outside the box.</span></span></p><p><span><span>Given that remaining within this particular box is so expensive, I highly encourage you not to do so without full understanding of what you‚Äôre doing.</span></span></p><p><span><span>If you can make $80/hr at a startup and $130/hr at a regular company, you are paying the startup $50/hr for the privilege of working there. For $50/hr, you can figure out a way to get most of the same benefits and come out way, way ahead.</span></span></p><p><span><span>Do what makes you happy, but do it with your eyes open. Also, if you really want to work at a startup, you might be better served by starting one.</span></span></p><h2 id="block-aebdc986fc9a4a39917e802441860771"><span id="aebdc986fc9a4a39917e802441860771"></span><span><span>Don‚Äôt work with household names</span></span></h2><p><span><span>There‚Äôs a word that gets tossed around a lot in the communities where developers that talk about their careers hang out (Hacker News, Reddit, et. al.) -- FAANG. It‚Äôs an acronym that refers to Facebook, Apple, Amazon, Netflix, and Google.</span></span></p><p><span><span>People talk about these companies (which pretty much are all out in Silicon Valley or in Seattle) so much that an acronym evolved as a catchall to refer to them. When I say ‚Äúhousehold name,‚Äù these are the companies ‚Ä¶</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcareer.elliotbonneville.com/no-startups-or-faangs">https://devcareer.elliotbonneville.com/no-startups-or-faangs</a></em></p>]]>
            </description>
            <link>https://devcareer.elliotbonneville.com/no-startups-or-faangs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199374</guid>
            <pubDate>Tue, 24 Nov 2020 15:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Disc as Dongle]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25199286">thread link</a>) | @mortenjorck
<br/>
November 24, 2020 | https://interuserface.net/2020/11/the-disc-as-dongle/ | <a href="https://web.archive.org/web/*/https://interuserface.net/2020/11/the-disc-as-dongle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          <!-- <style>
        body.single {
          background-color: #;
        }
      </style> -->
      <h3>November 23, 2020</h3>
      
      <p>One possible future of digital distribution is already here ‚Äì in the guise of an existing format.</p>
      
<p><span>The industrial design</span> of the just-released Playstation 5 may be <a href="http://interuserface.net/2020/06/the-regressive-design-of-the-playstation-5/" data-type="post" data-id="633">regressive</a>, but it looks to the future in one critical way: Judging by the ungainly grafting-on of its disc drive, its original conception as a digital-only console is unmistakable.</p>



<p>For many, digital-only is a conflicting proposition. It curtails long-established freedoms of lending and resale, yet most would agree that it is also inevitably the future. But it doesn‚Äôt have to be the former. There is a solution ‚Äì and it already exists.</p>



<p>The physical discs included with the retail versions of console games have served an increasingly marginal utility over the past console generation. Ever-larger day-one patches weigh in in the gigabytes. Triple-A games already require tens of gigabytes of data to be copied from the disc to the hard drive in order to manage load times, and the Playstation 5‚Äôs reliance on a super-fast SSD architecture only formalizes this. </p>



<hr>



<p><span>This leaves the disc</span> with precious little to actually do ‚Äì it‚Äôs too slow to be played from, its data is often outdated by the time it‚Äôs installed, and as broadband speeds continue to inch upward, the read speed of even a modern Blu-ray drive is already slower than some fiber connections. Yet despite all this, the lowly disc still has one ace in the hole.</p>



<p>Even stripped of its value as a storage mechanism for game data, the disc serves a critical purpose: It is the physical manifestation of a license, an unencumbered and freely transferable token with which ownership of a game is immutably entangled. Future games could well ship with an essentially empty disc, relying on the network for everything else, yet the advantage of the disc-anchored license would remain undisputed. The disc allows one to, as memorably demonstrated in Sony‚Äôs 2013 response to Microsoft‚Äôs aborted digital-only Xbox play, simply <a href="https://www.polygon.com/2013/6/10/4417490/playstations-one-step-tutorial-on-sharing-used-games">hand that license to someone else.</a></p>



<hr>



<p><span>All this then invites the question:</span> Why does it have to be a <em>disc?</em> Why does a console need a noisy, mechanically complex, and expensive optical drive just to read a license? Professional software has long used USB peripherals, or dongles as they are semi-affectionately known, as the physical manifestation of licenses. The disc has become a dongle, so why not just use a dongle?</p>



<p>A few kilobytes and an encryption scheme are all that‚Äôs required to tie licenses to a physical device today. A tiny, inexpensive USB device could serve as the retail form factor for future games, ushering in an all-download future that retains nearly all the benefits of physical legacy formats. It could perhaps even, via firmware update, add ‚Äúphysical media‚Äù support to both the digital-only Playstation 5 and Xbox Series S.</p>
      <!-- <p class="metadata">
        Clayton Miller&ensp;&bull;&ensp;      </p> -->
      </article></div>]]>
            </description>
            <link>https://interuserface.net/2020/11/the-disc-as-dongle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199286</guid>
            <pubDate>Tue, 24 Nov 2020 15:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homemade recycling rig turns plastic waste into new products]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198780">thread link</a>) | @lysp
<br/>
November 24, 2020 | https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/ | <a href="https://web.archive.org/web/*/https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-26604">
<h3>Homemade recycling rig turns plastic waste into new products</h3>
<p> ‚Äî <span>November 24th, 2020</span>
</p>
<div>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-300x225.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-385x289.jpg 385w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-768x576.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>While that plastic cup, bag, dish, or other item may have served its purpose, more than likely it could be formed into something new. With this in mind, the SOTOP-Recycling team of Manuel Maeder, Benjamin Krause, and Nadina Maeder developed <a href="https://www.instructables.com/Automated-Injection-Molding-Machine-for-Plastic-Re/">an automated injection molding machine</a> that can be built at home and is small enough to allow you to run your own recycling operation!</p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-300x218.png 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-768x558.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>The ‚ÄúSmart Injector‚Äù receives shredded pieces of plastic in a small hopper, then transports them down an extrusion pipe where heat is applied. This material is clamped together via a pair of stepper motors, with screws and timing belts implemented to apply sufficient pressure. Everything is controlled by an <a href="https://store.arduino.cc/mega-2560-r3">Arduino Mega</a>. </p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-300x200.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>As shown in the video, the plastic waste is converted into phone covers in just minutes, though other things could also be made depending on the form tooling used.</p>
<figure><p>
<iframe title="Injection molding machine for recycling plastic" width="500" height="281" src="https://www.youtube.com/embed/Eq9IbetsLB4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<section>


<p>
<small>

You can follow any responses to this entry through the <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/feed/">RSS 2.0</a> feed.
You can <a href="#respond">leave a response</a>, or <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/trackback/" rel="trackback">trackback</a> from your own site.
</small>
</p>
</section>
</div>
</div></div>]]>
            </description>
            <link>https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198780</guid>
            <pubDate>Tue, 24 Nov 2020 14:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making 8500 plants available to you]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25198771">thread link</a>) | @roboben
<br/>
November 24, 2020 | https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/making-8500-plants-available-on-permapeople.jpg" alt="8500 plants available on Permapeople"></p>

<p><strong>tl;dr We made ~8500 plants available to you by importing the Plant For a Future dataset. You can use it now to create lists, guilds and help improving that data.</strong></p>

<p>The first thing I did when I started Permapeople was to look at other plant databases and platforms with a similar focus. If you ever were in the situation to try to get some information about specific plants, especially attributes which are important for a Permaculture style of gardening, there is a high chance you found <a href="https://pfaf.org/">Plants for a Future</a> (PFAF). It is a database started by Addy and Ken Fern, later turned into a not for profit organization operated by a handful of trustees. In recent years, they refocused their work on plants‚Äô role in fighting climate change through carbon sequestration. If you don‚Äôt know them, you should definitely check them out.</p>

<p>I put a lot of consideration into importing the PFAF database into Permapeople, but decided against it in the beginning. The more I talked to people and our first users, I figured that using existing datasets saves contributors a lot of time and provides an immediate value. Most people I talked to are beginners or people running larger gardening operations, and I wanted to create something that could help them immediately in their projects. I think the PFAF database is one of the best resources available, but I found some problems with it, limiting its usefulness.</p>

<h2 id="data-quality">Data Quality</h2>

<p>While the PFAF dataset is probably the biggest by numbers and completeness, it has a few problems: Many things are outdated, incorrect, ambiguous, or incoherent. Some might think that plant data and its field, <em><a href="https://en.wikipedia.org/wiki/Botany">botany</a></em> is a static field. Actually, it is really the opposite: New discoveries, nomenclature changes, and fresh scientific research comes in weekly. Keeping track of this with a tiny circle of paid workers is a tough job to do. Even if you could contribute a fix, there is no way of doing that. Crowdsourcing this problem by letting anyone change the data could be very helpful. This is one of the main reasons I started Permapeople: I wanted to have one place to find up-to-date, correct, peer-reviewed information on the plants I want to grow. If I miss some info or find something incorrect, I can easily edit it and help everyone who needs this information after me. Think Wikipedia, but specifically for plants.</p>

<h2 id="no-clear-roadmap">No clear roadmap</h2>

<p>What makes working with PFAF data more challenging is that there is no information on if and when data gets corrected, updated, or added to PFAF. We do not know if and when new features will be added and if the organization will shift its focus to other projects in the future.</p>

<h2 id="unstructured-data">Unstructured Data</h2>

<p>While this is related to the data quality, the PFAF data is not structured and rather a full-text description of the plant. This makes it hard to find or sort through specific info because many attributes are not filterable and searchable. For example, while PFAF has great information on <em>companion planting</em>, it‚Äôs impossible to search based on these connections. You are left with searching through many plant profiles, reading long paragraphs, and scanning for the required information.</p>

<h2 id="missing-features">Missing features</h2>

<p>Having a database is great, but information seekers and contributors need some functionality to work with it. PFAF doesn‚Äôt provide any of that, and this is why we already added some of these missing features to Permapeople.</p>

<h3 id="see-the-editing-history-and-sources">See the editing history and sources</h3>

<p>A huge factor of why Wikipedia is so trustworthy is that every change is public and can be easily reviewed by anyone. This lets a user easily gauge any meta-information about a plant: Is this info credible or just a myth created by the hive-mind of the internet? Do many people agree with that info? Are there sources proving the correctness of the information? If yes, how many? Or how are people working within a similar climate to you faring with that plant?</p>

<h3 id="create-plant-connections-and-guilds">Create plant connections and guilds</h3>

<p>Companion planting and the more advanced <a href="http://www.neverendingfood.org/b-what-is-permaculture/permaculture-guilds/">concept of guilds</a> are a huge part of the success of Permaculture. At Permapeople, you can create explicit plant connections (may they be beneficial or adversary) and organize plants into guilds. This info can be fed back to the database and give users even better information: If two plants are used in many user-generated guilds, there is a high chance that these plants go well together.</p>

<p>Much of this functionality is in a very early stage, and we need your help and feedback to improve these features and the data itself. I hope this post helped you understand why I imported the PFAF dataset into Permapeople and how we plan to improve on the hard work PFAF and its contributors have already accomplished. In the best case, we can contribute our changes back to PFAF.</p>

<p>If you are interested, I suggest you try to <a href="https://permapeople.org/search">search for some plants</a> and <a href="https://permapeople.org/users/sign_up">sign up</a> to create your first list or guild.</p>

<p>Happy growing üå±‚úåÔ∏è,</p>

<p>Ben</p>

<p>PS: If you work for PFAF (or know someone who does), please reach out to us at hello at permapeople org - we‚Äôd love to talk about the future!</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198771</guid>
            <pubDate>Tue, 24 Nov 2020 14:38:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25198597">thread link</a>) | @mooreds
<br/>
November 24, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I‚Äôve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you‚Äôll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn‚Äôt mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don‚Äôt need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone‚Äôs lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you‚Äôve ever had a great comment explain a confusing bit of code, you‚Äôll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn‚Äôt apply, remove it. If there‚Äôs cut and paste documentation which doesn‚Äôt apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn‚Äôt tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as ‚Äúcan I instantiate this object‚Äù or ‚Äúhow does this function react when I pass it two null values‚Äù, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don‚Äôt get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It‚Äôs easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I‚Äôll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don‚Äôt refactor what you don‚Äôt understand. Don‚Äôt drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don‚Äôt do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It‚Äôs sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn‚Äôt spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn‚Äôt benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don‚Äôt do so, eventually dependencies will end of life and you‚Äôll be forced to update. That‚Äôll be even less pleasant. </p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn‚Äôt everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198597</guid>
            <pubDate>Tue, 24 Nov 2020 14:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam and Static Types with Louis Pilfold]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198388">thread link</a>) | @crowdhailer
<br/>
November 24, 2020 | https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/ | <a href="https://web.archive.org/web/*/https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="fl-main-content" itemprop="mainContentOfPage" role="main">

		
<div>
	<div>

		
		<div>
			<article id="fl-post-6124" itemscope="" itemtype="https://schema.org/BlogPosting">

	
	<header role="banner">
		
		<meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="datePublished" content="2020-11-24"><meta itemprop="dateModified" content="2020-11-24"><div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><meta itemprop="name" content="Thinking Elixir"></div>	</header><!-- .fl-post-header -->

	
	
	<div itemprop="text">
		<p>
We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!
</p>

<p>
  Show Notes online ‚Äì <a href="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold">https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold</a><br>
  
</p>
<p><strong>Elixir Community News</strong></p>

<ul>
<li><a href="http://devonestes.com/announcing_muzak" target="_blank" rel="noopener noreferrer">http://devonestes.com/announcing_muzak</a> ‚Äì Devon Estes‚Äô Muzak mutation testing library</li>
<li><a href="https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html" target="_blank" rel="noopener noreferrer">https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html</a> ‚Äì AppSignal released 2.0 of their reporting tool</li>
<li><a href="https://github.com/phoenixframework/phoenix_live_view/pull/1223" target="_blank" rel="noopener noreferrer">https://github.com/phoenixframework/phoenix_live_view/pull/1223</a> ‚Äì Phoenix LiveView file upload fix for components</li>
<li><a href="https://github.com/rrrene/credo" target="_blank" rel="noopener noreferrer">https://github.com/rrrene/credo</a> ‚Äì Happy 5th birthday Credo!</li>
<li><a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/" target="_blank" rel="noopener noreferrer">https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/</a> ‚Äì New Elixir case-study looks at the collaborative wiki product Slab</li>
<li><a href="https://github.com/teamon/tesla/releases/tag/v1.4.0" target="_blank" rel="noopener noreferrer">https://github.com/teamon/tesla/releases/tag/v1.4.0</a> ‚Äì Tesla v1.4.0 released ‚Äì an Elixir HTTP client</li>
<li><a href="https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119</a> ‚Äì ElixirLS version 0.6.2 released.</li>
<li><a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir" target="_blank" rel="noopener noreferrer">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a> ‚Äì Jose Valim wrote a blog post addressing the idea of people saying ‚Äúyou don‚Äôt need Redis when you use Elixir‚Äù.</li>
<li><a href="https://baremessages.org/" target="_blank" rel="noopener noreferrer">https://baremessages.org/</a> ‚Äì A new ‚Äúbinary serialization library‚Äù called ‚Äúbare‚Äù. Aims to make Erlang data structures serialize easier in <em>other</em> languages</li>
<li><a href="https://sr.ht/~hauleth/BARE-Erlang/" target="_blank" rel="noopener noreferrer">https://sr.ht/~hauleth/BARE-Erlang/</a></li>
</ul>
<p>Do you know some Elixir news we don‚Äôt? Tell us at <a href="https://twitter.com/ThinkingElixir">@ThinkingElixir</a></p>
<p><strong>Discussion Resources</strong></p>

<ul>
<li><a href="https://github.com/gleam-lang/gleam" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam</a></li>
<li><a href="https://gleam.run/" target="_blank" rel="noopener noreferrer">https://gleam.run/</a></li>
<li><a href="https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/" target="_blank" rel="noopener noreferrer">https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/</a></li>
<li><a href="https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/" target="_blank" rel="noopener noreferrer">https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/</a></li>
<li><a href="https://github.com/gleam-lang/gleam/graphs/contributors" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam/graphs/contributors</a></li>
<li><a href="https://www.embark-studios.com/" target="_blank" rel="noopener noreferrer">https://www.embark-studios.com/</a></li>
<li><a href="https://racket-lang.org/" target="_blank" rel="noopener noreferrer">https://racket-lang.org/</a></li>
<li><a href="https://akka.io/" target="_blank" rel="noopener noreferrer">https://akka.io/</a></li>
<li><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener noreferrer">https://developers.google.com/protocol-buffers/</a></li>
<li><a href="https://github.com/lalrpop/lalrpop" target="_blank" rel="noopener noreferrer">https://github.com/lalrpop/lalrpop</a></li>
<li><a href="http://www.elixir.london/2016/louis-pilfold" target="_blank" rel="noopener noreferrer">http://www.elixir.london/2016/louis-pilfold</a></li>
<li><a href="https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0</a></li>
<li><a href="https://gleam.run/community/" target="_blank" rel="noopener noreferrer">https://gleam.run/community/</a> ‚Äì Join the Gleam Discord server</li>
<li><a href="https://twitter.com/louispilfold" target="_blank" rel="noopener noreferrer">https://twitter.com/louispilfold</a> ‚Äì on Twitter</li>
<li><a href="https://github.com/lpil/" target="_blank" rel="noopener noreferrer">https://github.com/lpil/</a> ‚Äì on Github</li>
<li><a href="https://lpil.uk/" target="_blank" rel="noopener noreferrer">https://lpil.uk</a> ‚Äì Blog</li>
</ul>
<p><strong>Find us online</strong></p>
<ul>
<li>Message the show ‚Äì <a href="https://twitter.com/ThinkingElixir" target="_blank" rel="noopener noreferrer">@ThinkingElixir</a></li>
<li>Mark Ericksen ‚Äì <a href="https://twitter.com/brainlid" target="_blank" rel="noopener noreferrer">@brainlid</a></li>
<li>David Bernheisel ‚Äì <a href="https://twitter.com/bernheisel" target="_blank" rel="noopener noreferrer">@bernheisel</a></li>
<li>Cade Ward ‚Äì <a href="https://github.com/cadebward" target="_blank" rel="noopener noreferrer">Github</a></li>
</ul>
<div itemscope="" itemtype="http://schema.org/AudioObject"><meta itemprop="name" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="uploadDate" content="2020-11-24T04:15:45-07:00"><meta itemprop="encodingFormat" content="audio/mpeg"><meta itemprop="duration" content="PT48M57S"><meta itemprop="description" content="We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!



Show Notes online - https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold"><meta itemprop="contentUrl" content="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3"><meta itemprop="contentSize" content="67.4"><div id="powerpress_player_9920"><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-6124-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3?_=1"><a href="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3">https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3</a></audio></p></div></div><p>Podcast: <a href="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3" title="Download" rel="nofollow" download="023-gleam-louis-pilfold.mp3">Download</a></p>	</div><!-- .fl-post-content -->

	
	<div></div>		
</article>


<!-- .fl-post -->
		</div>

		
	</div>
</div>


	</div></div>]]>
            </description>
            <link>https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198388</guid>
            <pubDate>Tue, 24 Nov 2020 13:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.0.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198287">thread link</a>) | @crbelaus
<br/>
November 24, 2020 | https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.0.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.0.0/">1.0.0 release</a> of htmx.</p>
<p>htmx is now mature enough that I can recommend it as a general replacement for intercooler.js
projects.  I <strong>don't</strong> think there is a strong reason to port an existing intercooler project to
htmx.  I have several large intercooler apps and will not be moving them over any time soon. I can, however, recommend using htmx over intercooler for new projects.</p>
<p>htmx is a different sort of javascript library.  It is an HTML &amp; hypertext-oriented reply to the current dominance of javascript-based SPA libraries.  It is a response to Tom MacWright's question:
<a href="https://macwright.com/2020/10/28/if-not-spas.html">"If not SPAs, What?"</a>.</p>
<p>As the <a href="https://htmx.org/">homepage says</a>:</p>
<ul>
<li>Why should only <code>&lt;a&gt;</code> and <code>&lt;form&gt;</code> be able to make HTTP requests?</li>
<li>Why should only <code>click</code> &amp; <code>submit</code> events trigger them?</li>
<li>Why should only GET &amp; POST be available?</li>
<li>Why should you only be able to replace the entire screen?</li>
</ul>
<p>HTML-oriented web development was abandoned not because hypertext was a bad idea, but rather because HTML didn't have sufficient expressive power.  htmx aims to fix that &amp; allows you to implement <a href="https://htmx.org/examples/">many common modern web UI patterns</a> using the original hypertext model of the web.</p>
<h3>History &amp; Thanks</h3>
<p>htmx began life as <a href="https://intercoolerjs.org/">intercooler.js</a> back in <a href="https://github.com/bigskysoftware/intercooler-js/commit/62d3dbdb5c056ee866aba3575e148de649fc3efe">2013</a>.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/commit/e38dea64dd1065003a0e833d7b469d24e6bc2919">april</a> of this year I began work on a jQuery-indepenent &amp; improved version of intercoolerjs, renamed
to htmx.  I chose to rename the library because, in working on intercooler, I had come to appreciate that intercooler &amp; htmx were completing HTML as a hypertext rather than just some funky, idiosyncratic javascript libraries.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/releases/tag/v0.0.1">May</a> htmx reached 0.0.1.  Soon thereafter I had the good fortune of being contacted by <a href="https://twitter.com/ben_pylo">Ben Croker</a>
who was interested in htmx as a base for his new reactive library, <a href="https://putyourlightson.com/plugins/sprig">Sprig</a>.  Ben was willing to be an early adopter of htmx and pushed the library along
much faster than it would have gone otherwise.</p>
<p>I have been very lucky to the have help and feedback from many contributors in <a href="https://github.com/bigskysoftware/htmx/graphs/contributors">Github</a> and on <a href="https://htmx.org/discord">Discord</a>.  I'd like to thank, in particular, <a href="https://github.com/benpate">Ben Pate</a>, <a href="https://github.com/rschroll">Robert Schroll</a> &amp; <a href="https://github.com/jreviews">Alejandro Schmeichler</a> for contributing code as well as new ideas and discussions.</p>
<p>I would like to thank <a href="https://devmode.fm/">Devmode.fm</a> for having me on to <a href="https://devmode.fm/episodes/dynamic-html-with-htmx">talk about htmx</a> and for cleaning up all my "uhhs" and "umms".</p>
<p>Finally, I would like to thank <a href="https://github.com/jsampson">Justin Sampson</a>, who took a lot of time to explain REST &amp; HATEOAS to me and how intercooler (and now htmx) fit into that model for web development.</p>
<h3>Changes</h3>
<ul>
<li>I bumped the version number :)</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198287</guid>
            <pubDate>Tue, 24 Nov 2020 13:38:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Reddit to get your first users]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25198280">thread link</a>) | @xavier_
<br/>
November 24, 2020 | https://blog.spreadtheworld.net/posts/get-first-users-reddit/ | <a href="https://web.archive.org/web/*/https://blog.spreadtheworld.net/posts/get-first-users-reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As an indie hacker, we all struggle to validate our ideas, get our first users, and get some traffic. I played a lot with <a href="https://www.reddit.com/user/xAvi_r">Reddit</a> for the last few months, and I can tell you: it‚Äôs a gold mine!</p><p>Reddit is super powerful:&nbsp;there are millions of users on the platform, each subreddit is very segmented by niche, and it‚Äôs free to use!</p><p>We sometimes see it as an intimidating platform, but it‚Äôs not that hard.</p><p>Here is how I&nbsp;use it:</p><h2 id="validate-your-idea">Validate your idea</h2><p>The first step of your indie hacker journey is to validate your idea. You don‚Äôt want to spend weeks building something nobody wants. But it can be hard to find your potential customers to validate your product idea.</p><p>With Reddit, you can do it easily. There are subreddits dedicated to Ideas‚Äô feedback. You can post your idea there and you will get some responses within 24hrs. The feedback can be pretty generic as the people in these subs are mostly entrepreneurs and not your potential customer.</p><p>To validate my product idea I prefer to post directly on the sub I&nbsp;want to target. Let‚Äôs say you create a tool for developers then I‚Äôd post to /r/webdev. You don‚Äôt need to have a working MVP, just make some screenshot (or a video) and ask for feedback. Or, even better show them a landing page with a pre-order button or an email form and wait for their reactions.</p><p><em>(For the idea validation step, don‚Äôt be afraid to post on a big subreddit with hundreds of thousands of users, the more people see your idea the stronger your validation will be)</em></p><p>Within 24hrs you‚Äôll know if that idea is worth pushing! If you get positive feedback - or even pre-orders - you can build your MVP. If you‚Äôre ignored or trashed, then find another way or get another idea!</p><h2 id="get-your-first-users">Get your first users</h2><p>Once your MVP is ready you need a bunch of beta testers to give you some feedback.
Reddit can also help you with that.</p><p>But this time I‚Äôd go with a small subreddit, and a super targeted one. Let‚Äôs say you created a no-code tool for startups, I‚Äôll try to get my early adopters from /r/nocode (3.7k members) instead of posting on /r/startups (517k members) for instance. It‚Äôs a small subreddit, very niche. Then, once you have the first feedback you can iterate on it and post on some bigger subs.</p><p>The idea of ‚Äúincremental launches‚Äù is to start small, build an audience, get some feedback, and grow step by step. Once the super-targeted subreddit loves your product you can start to post on big subreddit and get some traction.</p><p><em>PS: Small subreddit are super powerful if you choose them wisely. I got more than <a href="https://twitter.com/AngeZanetti/status/1325847913466048516">400 visits</a> in 48hrs from my last post on /r/nocode!</em></p><h2 id="get-some-traffic">Get some traffic</h2><p>Last step of the process: your MVP is ready, you need some traffic. And you want a lot of it!</p><p>The strategy here is to create some content around your product and share it with big subreddits. The secret is to provide as much value as you can. Share your secrets, how you grow your product, share your analytics, how much money you make, what did you learn during your journey, etc‚Ä¶ It needs to be valuable and targeted to an audience.</p><p>Post your content to the biggest subreddits like /r/Entrepreneur, /r/Programming, or /r/Marketing and add a link to your product/blog at the end (Check the rules of the sub first, but most of them are ok with it)</p><p>If your content is well-targeted and brings some serious value you can get thousands of visitors in a day! And it‚Äôs totally repeatable. As long as you can provide value you‚Äôll get some free traffic!</p><p>Do you want to launch on Reddit? DM me on Twitter, I‚Äôll be happy to help ‚Üí <a href="https://twitter.com/angezanetti">Twitter</a></p></div></div>]]>
            </description>
            <link>https://blog.spreadtheworld.net/posts/get-first-users-reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198280</guid>
            <pubDate>Tue, 24 Nov 2020 13:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197950">thread link</a>) | @kkoncevicius
<br/>
November 24, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a ‚Äúliving document‚Äù that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody‚Äôs going to ditch the Web and switch to Gemini or Gopher today
(that‚Äôll take, like, a month at the longest). Until that happens, here‚Äôs a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts‚Äìlocal or remote‚Äìbesides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It‚Äôs a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most ‚Äúdark mode‚Äù
browser addons. More on this below.</li>
<li>A good score on Mozilla‚Äôs <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I‚Äôd like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen‚Äôs DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn‚Äôt evil! It isn‚Äôt
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn‚Äôt dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user‚Äôs system.</p>
<p>A personal example: I set my preferred fonts in my computer‚Äôs fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don‚Äôt change their fonts‚Ä¶</h3>
<p>The ‚Äúusers don‚Äôt know better and need us to make decisions for them‚Äù mindset isn‚Äôt
without merits; however, in my opinion, it‚Äôs overused. Using system fonts doesn‚Äôt
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn‚Äôt
about making software easier for non-technical users; it‚Äôs about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can‚Äôt users globally override stylesheets instead?</h3>
<p>It‚Äôs not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn‚Äôt have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there‚Äôs
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn‚Äôt
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article‚Äôs advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn‚Äôt that allow a website to fingerprint with fonts?</h3>
<p>I don‚Äôt know much about fingerprinting, except that you can‚Äôt do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don‚Äôt
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don‚Äôt need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user‚Äôs system, the user‚Äôs canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox‚Äôs <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of ‚Äúdead zones‚Äù with
abysmal download speeds, and my home‚Äôs Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don‚Äôt finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn‚Äôt expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn‚Äôt this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don‚Äôt decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don‚Äôt have reason to trust that
linked content doesn‚Äôt practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn‚Äôt
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can‚Äôt users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn‚Äôt essential, you shouldn‚Äôt include it inline.</li>
<li>Yes, users could disable images. That‚Äôs <em>their</em> choice. If your page uses lazy
loading, you‚Äôve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren‚Äôt black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here‚Äôs
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I‚Äôve found that it‚Äôs the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197950</guid>
            <pubDate>Tue, 24 Nov 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posting JSON with an HTML Form (2016)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25197155">thread link</a>) | @graderjs
<br/>
November 24, 2020 | https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A coworker and I were looking at an application today that, like so many other
modern web applications, offers a RESTful API with JSON being used for
serialization of requests/responses.  She noted that the application didn‚Äôt
include any sort of CSRF token and didn‚Äôt seem to use any of the headers
(X-Requested-With, Referer, Origin, etc.) as a ‚Äúpoor man‚Äôs CSRF token‚Äù, but
since it was posting JSON, was it really vulnerable to CSRF?  <strong>Yes, yes,
definitely yes!</strong></p>

<p>Interestingly, this is reminiscent of many of the confusions between server and
browser that are described in Michal Zalewski‚Äôs <a href="https://amzn.to/2QyTUaH">The Tangled
Web</a>.</p>

<p>The idea that the use of a particular encoding is a security boundary is, at
worst, a completely wrong notion of security, and at best, a stopgap until W3C,
browser vendors, or a clever attacker gets hold of your API.  Let‚Äôs examine JSON
encoding as a protection against CSRF and demonstrate a mini-PoC.</p>

<h3 id="the-application">The Application</h3>

<p>We have a basic application written in Go.  Authentication checking is elided
for post size, but this is <em>not</em> just an unauthenticated endpoint.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>type</span> <span>Secrets</span> <span>struct</span> <span>{</span>
	<span>Secret</span> <span>int</span>
<span>}</span>

<span>var</span> <span>storage</span> <span>Secrets</span>

<span>func</span> <span>handler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>if</span> <span>r</span><span>.</span><span>Method</span> <span>==</span> <span>"POST"</span> <span>{</span>
		<span>json</span><span>.</span><span>NewDecoder</span><span>(</span><span>r</span><span>.</span><span>Body</span><span>)</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>storage</span><span>)</span>
	<span>}</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"The secret is %d"</span><span>,</span> <span>storage</span><span>.</span><span>Secret</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>handler</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, it basically serves a secret number that can be updated via
HTTP POST of a JSON object.  If we attempt a URL-encoded or multipart POST, the
JSON decoding fails miserably and the secret remains unchanged.  We must POST
JSON in order to get the secret value changed.</p>

<h3 id="exploring-options">Exploring Options</h3>

<p>So let‚Äôs explore our options here.  The site can locally use AJAX via the
XMLHTTPRequest API, but due to the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">Same-Origin
Policy</a>,
an attacker‚Äôs site cannot use this.  For most CSRF, the way to get around this
is plain HTML forms, since form submission is not subject to the Same-Origin
Policy.  The W3C had a <a href="https://www.w3.org/TR/html-json-forms/">draft specification for JSON
forms</a>, but that has been abandoned
since late 2015, and isn‚Äôt supported in any browsers.  There are probably some
techniques that can make use of Flash or other browser plugins (aren‚Äôt there
always?) but it can even be done with basic forms, it just takes a little work.</p>

<h3 id="json-in-forms">JSON in Forms</h3>

<p>Normally, if we try to POST JSON as, say, a form value, it ends up being URL encoded,
not to mention including the field name.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>&lt;form</span> <span>method=</span><span>'POST'</span><span>&gt;</span>
  <span>&lt;input</span> <span>name=</span><span>'json'</span> <span>value=</span><span>'{"foo": "bar"}'</span><span>&gt;</span>
  <span>&lt;input</span> <span>type=</span><span>'submit'</span><span>&gt;</span>
<span>&lt;/form&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Results in a POST body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>json=%7B%22foo%22%3A+%22bar%22%7D
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good luck decoding that as JSON!</p>

<p>Doing it as the form field name doesn‚Äôt get any better.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>%7B%22foo%22%3A+%22bar%22%7D=value
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It turns out you can set the enctype of your form to <code>text/plain</code> and avoid the
URL encoding on the form data.  At this point, you‚Äôll get something like:</p>



<p>Unfortunately, we still have to contend with the form field name and the
separator (<code>=</code>).  This is a simple matter of splitting our payload across both
the field name and value, and sticking the equals sign in an unused field.  (Or
you can use it as part of your payload if you need one.)</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>&lt;body</span> <span>onload=</span><span>'document.forms[0].submit()'</span><span>&gt;</span>
  <span>&lt;form</span> <span>method=</span><span>'POST'</span> <span>enctype=</span><span>'text/plain'</span><span>&gt;</span>
    <span>&lt;input</span> <span>name=</span><span>'{"secret": 1337, "trash": "'</span> <span>value=</span><span>'"}'</span><span>&gt;</span>
  <span>&lt;/form&gt;</span>
<span>&lt;/body&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This results in a request body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>{"secret": 1337, "trash": "="}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This parses just fine and updates our secret!</p>

  </div><p>This post contains affiliate links.  If you click on
a link, I may earn a small commission at no cost to you.</p></div>]]>
            </description>
            <link>https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197155</guid>
            <pubDate>Tue, 24 Nov 2020 10:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Curl Web Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197053">thread link</a>) | @virde
<br/>
November 24, 2020 | https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The purpose of the <a href="https://curl.se/">curl web site</a> is to inform the world about what curl and libcurl are and provide as much information as possible about the project, the products and everything related to that.</p>



<p>The web site has existed in some form for as long as the project has, but it has of course developed and changed over time.</p>



<h2>Independent</h2>



<p>The curl project is completely independent and stands free from influence from any parent or umbrella organization or company. It is not even a legal entity,  just a bunch of random people  cooperating over the Internet. And a bunch of <a href="https://curl.se/sponsors.html">awesome sponsors</a> to help us.</p>



<p>This means that we have no one that provides the infrastructure or marketing for us. We need to provide, run and care for our own servers and anything else we think we should offer our users.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="187" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 187px) 100vw, 187px"></a></figure></div>



<p>I still do a lot of the work in curl and the curl web site and I work full time on curl, for <a href="https://www.wolfssl.com/">wolfSSL</a>. This might of course ‚Äútaint‚Äù my opinions and views on matters, but doesn‚Äôt imply ownership or control. I‚Äôm sure we‚Äôre all colored by where we work and where we are in our lives right now.</p>



<h2>Contents</h2>



<p>Most of the web site is static content: generated HTML pages. They are served super-fast and very lightweight by any web server software.</p>



<p>The web site source exists in the <a href="https://github.com/curl/curl-www/">curl-www</a> repository (hosted on GitHub) and the web site syncs itself with the latest repository changes several times per hour. The parts of the site that aren‚Äôt static are mostly consisting of smaller scripts that run either on demand at the time of a request or on an interval in a cronjob in the background. That is part of the reason why pushing an update to the web site‚Äôs repository can take a little while until it shows up on the live site.</p>



<p>There‚Äôs a deliberate effort at not duplicating information so a lot of the web pages you can find on the web site are files that are converted and ‚ÄúHTMLified‚Äù from the source code git repository.</p>



<h2>‚ÄúDesign‚Äù</h2>



<p>Some people say the curl web site is ‚Äúretro‚Äù, others that it is plain ugly. My main focus with the site is to provide and offer all the info, and have it be accurate and accessible. The look and the design of the web site is a constant battle, as nobody who‚Äôs involved in editing or polishing the web site is really interested in or particularly good at design, looks or UX. I personally have done most of the editing of it, including CSS etc and I can tell you that I‚Äôm not good at it and I don‚Äôt enjoy it. I do it because I feel I have to.</p>



<p>I get occasional offers to ‚Äúredesign‚Äù the web site, but the general problem is that those offers almost always involve rebuilding the entire thing using some current web framework, not just fixing the looks, layout or hierarchy. By replacing everything like that we‚Äôd get a lot of problems to get the existing information in there ‚Äì and again, the information is more important than the looks.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png" alt="" width="379" height="145" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-200x76.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-450x172.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-768x294.png 768w" sizes="(max-width: 379px) 100vw, 379px"></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2016/05/27/a-new-curl-logo/" data-type="post" data-id="8817">curl logo</a> is designed by a proper designer however (Adrian Burcea).</p>



<p>If you want to help out designing and improving the web site, you‚Äôd be most welcome!</p>



<h2>Who</h2>



<p>I‚Äôve already touched on it: the web site is mostly available in git so ‚Äúanyone‚Äù can submit issues and pull-requests to improve it, and we are around twenty persons who have push rights that can then make a change on the live site. In reality of course we are not that many who work on the site any ordinary month, or even year.  During the last twelve month period, 10 persons authored commits in the web repository and I did 90% of those.</p>



<h2>How</h2>



<p>Technically, we build the site with traditional makefiles and we generate the web contents mostly by preprocessing files using a C-like preprocessor called <a href="https://daniel.haxx.se/projects/fcpp/">fcpp</a>. This is an old and rather crude setup that we‚Äôve used for over twenty years but it‚Äôs functional and it allows us to have a mostly static web site that is also fairly easy to build locally so that we can work out and check improvements before we push them to the git repository and then out to the world.</p>



<p>The web site is of course only available over HTTPS.</p>



<h2>Hosting</h2>



<div><figure><a href="https://www.haxx.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png" alt="" width="288" height="97" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png 1046w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-200x68.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-450x152.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-768x260.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-1038x354.png 1038w" sizes="(max-width: 288px) 100vw, 288px"></a></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2020/10/23/a-server-transition/" data-type="post" data-id="14836">curl web site is hosted</a> on an origin VPS server in Sweden. The machine is maintained by primarily by me and is paid for by <a href="https://www.haxx.se/">Haxx</a>. The exact hosting is not terribly important because users don‚Äôt really interact with our server directly‚Ä¶ (Also, as they‚Äôre not sponsors we‚Äôre just ordinary customers so I won‚Äôt mention their name here.)</p>



<h2>CDN</h2>



<p>A few years ago we experienced repeated server outages simply because our own infrastructure did not handle the load very well, and in particular not the traffic spikes that could occur when I would post a blog post that would suddenly reach a wide audience.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-1200x630.png" alt="" width="242" height="127" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-200x105.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-450x236.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-768x403.png 768w" sizes="(max-width: 242px) 100vw, 242px"></figure></div>



<p>Enter <a href="https://www.fastly.com/">Fastly</a>. Now, when you go to <a href="https://curl.se/">curl.se</a> (or <a href="https://daniel.haxx.se/">daniel.haxx.se</a>) you don‚Äôt actually reach the origin server we admin, you will instead  reach one of Fastly‚Äôs servers that are distributed across the world. They then fetch the web contents from our origin, cache it on their edge servers and send it to you when you browse the site. This way, your client speaks to a server that is likely (much) closer to you than the origin server is and you‚Äôll get the content faster and experience a ‚Äúsnappier‚Äù web site. And our server only gets a tiny fraction of the load.</p>



<p>Technically, this is achieved by the name <strong>curl.se</strong> resolving to a number of IP addresses that are <a href="https://en.wikipedia.org/wiki/Anycast">anycasted</a>. Right now, that‚Äôs 4 IPv4 addresses and 4 IPv6 addresses.</p>



<p>The fact that the CDN servers cache content ‚Äúa while‚Äù is another explanation to why updated contents take a little while to ‚Äútake effect‚Äù for all visitors.</p>



<h2>DNS</h2>



<p>When we just recently switched the site over to <a href="https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/" data-type="post" data-id="14930">curl.se</a>, we also adjusted how we handle DNS.</p>



<div><figure><a href="https://www.kirei.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/kirei.png" alt="" width="265" height="117"></a></figure></div>



<p>I run our own main DNS server where I control and admin the zone and the contents of it.  We then have four secondary servers to help us really up our reliability. Out of those four secondaries, three are sponsored by <a href="https://www.kirei.se/">Kirei</a> and are anycasted. They should be both fast and reliable for most of the world.</p>



<p>With the help of fabulous friends like Fastly and Kirei, we hope that the curl web site and services shall remain stable and available.</p>



<p>DNS enthusiasts have remarked that we don‚Äôt do DNSSEC or registry-lock on the curl.se domain. I think we have reason to consider and possibly remedy that going forward.</p>



<h2>Traffic</h2>



<p>The curl web site is just the home of our little open source project. Most users out there in the world who run and use curl or libcurl will not download it from us. Most curl users get their software installation from their Linux distribution or operating system provider. The git repository and all issues and pull-requests are done on GitHub.</p>



<p>Relevant here is that we have no logging and we run no ads or any analytics. We do this for maximum user privacy and partly because of laziness, since handling logging from the CDN system is work. Therefore, I only have aggregated statistics.</p>



<p>In this autumn of 2020, over a normal 30 day period, the web site serves almost 11 TB of data to 360 million HTTP requests. The traffic volume is up from 3.5 TB the same time last year. 11 terabytes per 30 days equals about 4 megabytes per second on average.</p>



<p>Without logs we cannot know what people are downloading ‚Äì but we can guess! We know that the <a href="https://curl.haxx.se/docs/caextract.html">CA cert bundle</a> is popular and we also know that in today‚Äôs world of containers and CI systems, a lot of things out there will download the same packages repeatedly. Otherwise the web site is mostly consisting of text and very small images.</p>



<p>One interesting specific pattern on the server load that‚Äôs been going on for months: every morning at 05:30 UTC, the site gets over 50,000 requests within that single minute, during which 10 gigabytes of data is downloaded. The clients are distributed world wide as I see the same pattern on access points all over. The minute before and the minute after, the average traffic rate remains at 200MB/minute. It makes for a fun graph:</p>



<figure><img loading="lazy" width="1525" height="471" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-24-Fastly-Stats-curl.png" alt=""><figcaption>An eight hour zoomed in window of bytes transferred from the web site. UTC times.</figcaption></figure>



<p>Our servers suffer somewhat from being the target of weird clients like <a href="https://daniel.haxx.se/blog/2020/04/09/a-qqgamehall-storm/" data-type="post" data-id="13880">qqgamehall</a> that continuously ‚Äúhammer‚Äù the site with requests at a high frequency many months after we started always returning error to them. An effect they have is that they make the admin dashboard to constantly show a very high error rate.</p>



<h2>Software</h2>



<p>The origin server runs Debian Linux and Apache httpd. It has a reverse proxy based on nginx. The DNS server is bind. The entire web site is built with free and open source. Primarily: fcpp, make, roffit, perl, curl, hypermail and enscript.</p>



<p>If you curl the curl site, you can see in response headers that <a href="https://www.fastly.com/blog/benefits-using-varnish">Fastly uses Varnish</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197053</guid>
            <pubDate>Tue, 24 Nov 2020 10:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enterprise UX Design: Make me think]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25197041">thread link</a>) | @Dmytro_Trotsko
<br/>
November 24, 2020 | https://adamfard.com/blog/enterprise-ux | <a href="https://web.archive.org/web/*/https://adamfard.com/blog/enterprise-ux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article-content"><p>‚ÄúDon‚Äôt make me think‚Äù is a renowned mantra in the world of design, coined by Steve Krug. It has served as a guiding principle in the world of design and UX for twenty&nbsp;years. It teaches us how to create great experiences in a straightforward and accessible manner.&nbsp;</p><p>In today‚Äôs article, we‚Äôd like to look into enterprise design and its peculiarities. It‚Äôs essential to underline that the very nature of enterprise UX slightly differs from consumer UX. As a result, some of Krug‚Äôs principles must be adjusted when designing enterprise software.&nbsp;</p><p>This article is by no means a refutation of the design principle. Please treat it as a mere asterisk with a fine print at the bottom.</p><h2><strong>Learning curves aren‚Äôt inherently bad</strong></h2><p>According to Krug, products that make people think also make people unhappy. <a href="https://uxdesign.cc/the-learning-curve-design-problem-4d4dc2965098">Products with steep learning curves</a> very rarely succeed in the modern business ecosystem. Customers will pretty much always choose the path of least resistance. This isn‚Äôt necessarily true of enterprise products.</p><p>Enterprise users are power users ‚Äî and it‚Äôs imperative that we take this into account when designing products for them. They interact with niche software on a daily basis and quite possibly for many years. They know their way around the logic of the products they use.&nbsp;</p><p>Creating an interface that demands some learning results in a steeper learning curve isn‚Äôt inherently wrong. It allows users to work more efficiently once they‚Äôve invested a certain amount of time into training and learning.&nbsp;</p><figure><img src="https://www.datocms-assets.com/16499/1606137908-figma-shortcuts-cheatsheet-1014x487.jpg?w=900&amp;auto=compress"><figcaption><a href="https://www.figmacrush.com/figma-shortcuts-cheatsheet/">Source</a></figcaption></figure><p>Take, for instance, products like Figma, Sketch, Adobe Pro, or any other professional software ‚Äî most of them have a wide array of shortcuts. Features such as shortcuts may take a while to master, but they‚Äôll ensure a significant boost in productivity once learned.&nbsp;</p><h2>Simplify cautiously&nbsp;</h2><p>We‚Äôre very well aware of the importance of keeping interfaces simple and obvious. However, it‚Äôs essential to keep in mind the complexity of the tasks typically performed in enterprise software. The pursuit for a clean UI could rid users of the vital context necessary to get work done.&nbsp;</p><p>Plus, it can be argued that by making the interface too simple, we risk generating friction rather than eliminating it. Let‚Äôs envision an interface of a product that displays a wide array of charts and data, like a trading platform.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606138044-image2.png?w=900&amp;auto=compress"></p><p>A professional that regularly interacts with visual data needs immediate access to it at all times. Having to perform extra actions to access vital features is both frustrating and unproductive. And here lies one of the most significant differences between consumer UX and enterprise UX (eUX).&nbsp;</p><p>Consumer UX is really passionate about sleek UIs, while enterprise software must ensure that users are able to do their work comfortably. Therefore, simplified, minimalistic interfaces aren‚Äôt really what eUX designers are after.&nbsp;</p><h2>Wizards are cool, but‚Ä¶</h2><p><a href="https://adamfard.com/blog/ux-onboarding">Onboarding your users</a> is a vital step aimed at ensuring optimal user experience. However, while Wizards and guided tours are an excellent solution for casual users, it‚Äôs not necessarily the case for power users.&nbsp;</p><p>In both consumer and enterprise UX, designers must aim to develop products that require <a href="https://adamfard.com/blog/stickiness">as little hand-holding as possible</a>. However, simplistic product tours can be‚Ä¶ well, simplistic. They often fail to uncover the entire functionality of a product, which is especially relevant for experienced users.&nbsp;</p><p>After running a series of tests, we found out that enterprise users tend to prefer to leave the app or platform for instructions. While this does seem somewhat disruptive to the experience of a product ‚Äî it is understandable.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606210515-initiative-alladded1-1.png?w=900&amp;auto=compress"></p><p>Off-page instructions can provide more in-depth explanations rather than the ones that are placed on the screen. Compare, for instance, a tool-tip and an article dedicated to a particular function.&nbsp;</p><h2>Plan for non-linear flows&nbsp;</h2><p>When it comes to designing eUX UIs, designers face a truly arduous task of creating complex, non-linear flows. These flows often involve a variety of roles, profile types, responsibilities, kinds of security, and much more. Our goal is to create a consistent and recognizable experience throughout all of these variables.&nbsp;</p><p>The complicated part, however, is not to force users into flows and scenarios. Experts and professional users need that freedom to make decisions and use the platform as they see fit.</p><p>Think of a person that is deeply versed in Microsoft Excel. They‚Äôve been using this software for nearly a decade, and they know it like the back of their hand. More importantly, they have their style of working and solving problems. Limiting such users via linear and rigid flows could defeat the purpose of boosting their productivity.&nbsp;</p><h2>Don‚Äôt fix it if it‚Äôs not broken</h2><p>Innovation is a crucial element of UX design. We strive to continuously seek new and creative solutions to old problems. Often, we can even choose to be bold and put forth experimental solutions.&nbsp;</p><p>However, when it comes to eUX, we have to be somewhat more conservative and experiment with caution. Enterprise software isn‚Äôt quite receptive to design solutions that go against the grain.&nbsp;</p><p>Since the central purpose of such software is to deliver quality work in short amounts of time, ‚Äúreinventing the wheel‚Äù isn‚Äôt always a great idea.&nbsp;</p><p>When designing for enterprise, keeping an eye on your competition is even more relevant than in consumer software.&nbsp;</p><p>Let‚Äôs go back to Excel once more ‚Äî imagine <a href="https://adamfard.com/blog/website-redesign">you‚Äôre trying to reinvent</a> a complex, spreadsheet-based product. You‚Äôre looking to change the ways it represents data, or certain actions are performed. While this does sound like a laudable task, the critical question is ‚Äî why?&nbsp;</p><p>In eUX, the real value of a product is in its unique selling point that is translated via a design that looks familiar and intuitive.&nbsp;</p><p>That is not to say that the light of innovation never shines on enterprise products, but user expectations often trim the lengths we can go.&nbsp;</p><h2>In conclusion</h2><p>In order to reward you, our beloved reader, for making it till the end, we‚Äôve designed a picture that summarizes the arguments in this article. We hope it will come in handy.</p><p><img src="https://www.datocms-assets.com/16499/1606138895-enterprise-ux-summary.png?w=900&amp;auto=compress"></p><p>While the principles of ‚Äúdon‚Äôt make me think‚Äù will most likely outlive us, it‚Äôs crucial to outline the situations where they can be somewhat amended.&nbsp;</p><p>Enterprise user experience is a slightly more conservative field in terms of design, yet these limitations push us to become even more creative. By operating within these constraints, we have the power to make the future of work exciting and even more promising.&nbsp;</p><p>Meta: In this article, we explore the peculiarities of enterprise user experience design (eUX) through the lens of the ‚ÄúDon‚Äôt make me think‚Äù principle.&nbsp;</p></article></div>]]>
            </description>
            <link>https://adamfard.com/blog/enterprise-ux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197041</guid>
            <pubDate>Tue, 24 Nov 2020 10:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing iPhone OS 1.0 with iOS 14 using tree maps]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25196720">thread link</a>) | @yankcrime
<br/>
November 24, 2020 | https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you followed the recent Apple events, you probably saw a picture of the A14 and M1 dies‚Ä¶ that got me thinking about what you would see if you could pass iOS under X-Rays‚Ä¶</p>
<p>In my previous article about the <a href="https://blog.timac.org/2020/1019-evolution-of-the-programming-languages-from-iphone-os-to-ios-14/">evolution of the programming languages from iPhone OS 1.0 to iOS 14</a>, I analyzed iOS based on the number of binaries and their programming languages. As I pointed out in this past post, the size of the binaries were not taken in account. In this new article, I look at iPhone OS 1.0 and iOS 14 from a size perspective using tree maps.</p>

<p>To produce the images in this article, I extracted the root filesystem (including the dyld shared cache) of each major iOS release:</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>Device</th>
</tr>
</thead>
<tbody>
<tr>
<td>iOS&nbsp;14.0 (18A373)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;13.1 (17A844)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;12.0 (16A366)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;11.1 (15B93)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;10.1 (14B72)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;9.0 (13A344)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;8.0 (12A365)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;7.0.1 (11A470a)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;6.0 (10A403)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;5.0 (9A334)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;4.0 (8A293)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;3.0 (7A341)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;2.0 (5A347)</td>
<td>iPhone 2G</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;1.0 (1A543a)</td>
<td>iPhone 2G</td>
</tr>
</tbody>
</table>
<p>I then created a tree map. You might be familiar with tree maps as they are often used to visualize a file hierarchy to give you a graphical overview of the structure. One key characteristic is that each file is shown as a rectangle with an area proportional to the file's size. The tree maps displayed in this article have been created using the awesome <a href="http://grandperspectiv.sourceforge.net/">GrandPerspective</a> and annotated with <a href="https://www.pixelmator.com/">Pixelmator</a>.</p>

<p>Let's look at what you would see if you could scan iPhone OS 1.0 using X-Rays:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1.png" alt=""></p>
<p>The diagram below highlights some of the major functional blocks:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_structures.png" alt=""></p>
<p>We can already notice that:</p>
<ul>
<li>The structure is quite simple and has similarities to macOS</li>
<li>Frameworks are taking more than a third of the size</li>
<li>Fonts are taking more than 25% of the whole operating system</li>
</ul>
<p>We can go one level deeper and identify all the components:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_details.png" alt=""></p>
<p>From the list of components, we can clearly determine all the main features of iPhone OS 1.0:</p>
<ul>
<li>Phone</li>
<li>SMS</li>
<li>Weather</li>
<li>Clock</li>
<li>Mail</li>
<li>Safari + Web</li>
<li>Calendar</li>
<li>Maps</li>
<li>Wallpaper</li>
<li>Ringtones</li>
<li>Office support</li>
<li>Audio player</li>
<li>Video player</li>
<li>‚Ä¶</li>
</ul>
<p>A couple of components worth mentioning:</p>
<ul>
<li>The UIKit framework is taking more than 13 % of the total size</li>
<li>The wallpapers and ringtones count for 6 %</li>
<li>ICU (International Components for Unicode) takes more than 5 %</li>
<li>SpringBoard is roughly 2 %</li>
</ul>

<p>On popular demand, I added this section to provide more info about the fonts.
The huge <code>Fonts</code> block is composed of 2 parts:</p>
<ul>
<li>the fonts representing 2/3 of the size</li>
<li>some caches (visible at the top of the area and representing a third of the size)</li>
</ul>
<p>For the font lovers, here is the complete list of fonts in iPhone OS 1.0:</p>
<pre><code>AmericanTypewriter.ttf
AmericanTypewriterBold.ttf
AmericanTypewriterCondensed.ttf
AmericanTypewriterCondensedBold.ttf
AmericanTypewriterCondensedLight.ttf
AmericanTypewriterLight.ttf
Arial.ttf
ArialBold.ttf
ArialBoldItalic.ttf
ArialItalic.ttf
ArialRoundedMTBold.ttf
arialuni.ttf
CourierBoldOblique.ttf
CourierNew.ttf
CourierNewBold.ttf
CourierNewBoldItalic.ttf
CourierNewItalic.ttf
CourierOblique.ttf
DB_LCD_Temp-Black.ttf
Georgia.ttf
GeorgiaBold.ttf
GeorgiaBoldItalic.ttf
GeorgiaItalic.ttf
Helvetica.ttf
HelveticaBold.ttf
HelveticaBoldOblique.ttf
HelveticaOblique.ttf
LockClock.ttf
MarkerFeltThin.ttf
MarkerFeltWide.ttf
PhonepadTwo.ttf
TimesNewRoman.ttf
TimesNewRomanBold.ttf
TimesNewRomanBoldItalic.ttf
TimesNewRomanItalic.ttf
TrebuchetMS.ttf
TrebuchetMSBold.ttf
TrebuchetMSBoldItalic.ttf
TrebuchetMSItalic.ttf
Verdana.ttf
VerdanaBold.ttf
VerdanaBoldItalic.ttf
VerdanaItalic.ttf
Zapfino.ttf
</code></pre>
<p>The cache contains info for all these fonts and includes the 2 extra files:</p>
<ul>
<li>HelveLTMM.ps</li>
<li>TimesLTMM.ps</li>
</ul>

<p>I won't give details about each iOS release but you can inspect the tree maps from iPhone OS 2.0 to iOS 13.1:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>iPhone OS 2.0</td>
<td>iPhone OS 3.0</td>
<td>iOS 4.0</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2_small.png" alt="" title="iPhone OS 2.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3_small.png" alt="" title="iPhone OS 3.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4_small.png" alt="" title="iOS 4.0"></a></td>
</tr>
<tr>
<td>iOS 5.0</td>
<td>iOS 6.0</td>
<td>iOS 7.0.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5_small.png" alt="" title="iOS 5.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6_small.png" alt="" title="iOS 6.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7_small.png" alt="" title="iOS 7.0.1"></a></td>
</tr>
<tr>
<td>iOS 8.0</td>
<td>iOS 9.0</td>
<td>iOS 10.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8_small.png" alt="" title="iOS 8.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9_small.png" alt="" title="iOS 9.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10_small.png" alt="" title="iOS 10.1"></a></td>
</tr>
<tr>
<td>iOS 11.1</td>
<td>iOS 12.0</td>
<td>iOS 13.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11_small.png" alt="" title="iOS 11.1"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12_small.png" alt="" title="iOS 12.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13_small.png" alt="" title="iOS 13.1"></a></td>
</tr>
</tbody>
</table>
<p>Note that the number of building blocks increased with each new iOS release and the components are becoming smaller.</p>

<p>We are now in 2020 and iOS 14 is available. Without a surprise, iOS 14 is way more complex than iPhone OS 1.0:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14.png" alt=""></p>
<p>Here is the diagram highlighting the functional blocks in iOS 14:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_structures.png" alt=""></p>
<p>We can note that the main structure is still fairly similar to the original iPhone OS 1.0 version: the fonts, frameworks, applications, library, /usr, ‚Ä¶ are still there.</p>
<p>There are however a couple of big differences:</p>
<ul>
<li>iOS 14 contains a lot of <code>Preinstalled Assets</code> and <code>Linguistic Data</code>. As far as I can tell, these components are used for on-device machine learning: language detector, voices, tokenizers, vocalizers, ‚Ä¶</li>
<li>The dyld shared cache, a caching mechanism introduced in iPhone OS 3.1, causes the Frameworks and Private Frameworks to be split in several areas. The dyld shared cache has been marked with the red box in the diagram.</li>
<li>Health is clearly an important feature of iOS 14.</li>
</ul>
<p>There are so many components in iOS 14 that it is way more complex to identify all of them. I gave it a try nonetheless:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_details.png" alt=""></p>
<p>Although it is now difficult to list all the features, there are some clear trends:</p>
<ul>
<li>iOS 14 is packed with on-device machine learning technologies: Face Detection, Deep Convolutional Networks, Vision frameworks, Text Recognition, Neural Network, ‚Ä¶</li>
<li>A lot of components are related to the camera and photos: Effects, Memories, video processing, photo library, ‚Ä¶</li>
<li>Siri and voices are clearly visible.</li>
<li>As we already mentioned, Health is an important feature.</li>
<li>We can identify a couple of features added over the years: HomeKit, Watch, CarPlay, Spotlight, Emoji ü§ü, News, iWork, Wallet, Shortcuts, ARKit, ‚Ä¶</li>
</ul>
<p>More statistics:</p>
<ul>
<li>Fonts are now counting for less than 6 % of the size</li>
<li>Linguistic Data represent almost 8 % of the size</li>
<li>Although the ICU size was multiplied by more than 3 since iPhone OS 1.0, it now represents approximatively 0.5% of the total</li>
</ul>

<p>For readability the previous tree maps in this article were all displayed using the same size. If we present iPhone OS 1.0 next to iOS 14 with a proportional area, you would see that the whole iPhone OS 1.0 is basically taking the size of the iOS 14 wallpapers:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/Compare-iOS1-iOS14.png" alt=""></p>

<p>When iPhone OS 1.0 was released in 2007, it redefined the smartphone with a limited set of core features. Nowadays iOS 14 contains an incredible amount of components. By looking at them based on their size, we can determine the most important features. We thus distinctly see Apple's AI push into on-device machine learning with technologies like object detection in images and video, language analysis, sound classification and text recognition.</p>

<p><strong>Update 24.11.2020:</strong></p>
<ul>
<li>Added fonts in the iPhone OS 1.0 tree map</li>
<li>Added fonts in the iOS 14 tree map</li>
<li>Add section with fonts info for iPhone OS 1.0</li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196720</guid>
            <pubDate>Tue, 24 Nov 2020 09:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 326 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2Ôªø<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>Ôªø could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it‚Äôs injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world‚Äôs single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>üì© Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>üéô <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>üì≤ Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5th UberEats cyclist killed in Sydney in 3 months: Analysis and photos]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25196375">thread link</a>) | @jakecopp
<br/>
November 24, 2020 | https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/ | <a href="https://web.archive.org/web/*/https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Last updated: November 24th, 2020. Please leave comments on <a href="https://news.ycombinator.com/item?id=25196375">Hacker News</a> (&gt;6 comments).</p>

<p><strong>Content warning</strong>: Description of a death, and photos of the cleaned site of death.</p>
<p>After <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">four cyclists were killed by car drivers in Sydney in the last 2 months</a>, a <a href="https://www.abc.net.au/news/2020-11-24/uber-eats-vows-to-improve-safety-cyclist-killed-in-inner-sydney/12913840">37-year-old man from Malaysia</a> was killed at ~6:40pm last night - on my street, 200 metres from my front door, at an intersection I cycle through 2-4 times a day. I would have gone through that intersection within 15 minutes of that time if I didn‚Äôt skip a class. If you know me, I‚Äôm usually quite outspoken about the dangers cyclists face, but this was absolutely brutal to hear.</p>
<p>They cleaned up the body, but didn‚Äôt completely clean up the UberEats meal the man was delivering. The man likely died while earning less than minimum wage - A survey conducted by the Transport Workers‚Äô Union in September <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">found</a> that food deliverers earned an average of just $10.42 an hour after costs. 73% said they were worried about being ‚Äúseriously hurt or killed‚Äù at work.</p>
<p><em>Content warning: Image of scattered food on road, blue glove likely from police investigation.</em></p>
</div><div>
<p>An <a href="https://www.reddit.com/r/sydney/comments/jzewgi/fifth_food_delivery_rider_dies_following_truck/gdbm0s4/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">eyewitness account on Reddit</a>:</p>
<blockquote>
<p>‚Ä¶I was driving along Cleveland st, and only had a glimpse of what happened: for those of you arguing about PPE - I think there was a helmet - and a crushed head and body, and a twisted bicycle, and, yes, one of those grey food delivery bags all in the middle of Chalmers st. I am crying tonight, because that was someone‚Äôs child, friend ‚Ä¶ a person - who is no more‚Ä¶ .</p>
</blockquote>
<p><em>Content warning: Image of fragment of the helmet of the cyclist in the road gutter.</em></p>
</div><div>
<h2 id="contributing-causes">Contributing causes</h2>
<p>This is a tragedy in itself, but there are also a number of contributing causes at play here:</p>
<ul>
<li><p>In NSW, cycling on a footpath <a href="https://bicyclensw.org.au/who-can-ride-on-a-footpath-in-nsw/">is illegal and carries a fine of $114</a> for those above 15 years of age. Footpath cycling is <a href="https://www.bykbikes.com.au/blogs/bike-riding-tips/riding-bikes-on-the-footpath-the-laws-for-kids-and-adults-in-australia">legal in</a> Queensland, Tasmania, the ACT, the Northern Territory and South Australia.</p>
<ul>
<li>In the UK in 2017, there is a cyclist/pedestrian collision every <a href="https://www.cyclingweekly.com/news/rise-pedestrians-hit-cyclists-not-cause-leap-conclusions-396047">~9.9 million kilometres walked by a pedestrian</a>, or 531 in total. Of these 531 collisions 3 people were killed.</li>
</ul></li>
<li><p>Gig economy workers have little training and often no insurance. California recently proposed a law to force Uber and other platforms to treat their workers like employees. It narrowly failed to pass after <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/Uber,%20Lyft,%20and%20DoorDash%20poured%20over%20$200%20million%20into">Uber, Lyft and Doordash spent &gt; US$200m</a> campaigning against the law.</p></li>
<li><p>Dedicated infrastructure for cyclists is rare in Sydney. Not only are separated bicycle lanes hard to come by, a state government <a href="https://concreteplayground.com/sydney/design-style/sustainability/state-goverment-moves-to-rip-up-college-street-cycleway">actively removed</a> a cycleway in 2015 (which <a href="https://www.dailytelegraph.com.au/newslocal/central-sydney/college-st-syclists-four-times-as-likely-to-be-involved-in-a-crash-since-cycleway-removed/news-story/98ebe30e5c649407e45fd1aa7f023049">increased accidents by 400%</a>) <a href="https://www.bicyclenetwork.com.au/newsroom/2019/03/12/planned-removal-of-alexandra-canal-cycleway/">and in 2019</a>. Walking and cycling infrastructure typically receives <a href="https://theconversation.com/cycling-and-walking-can-help-drive-australias-recovery-but-not-with-less-than-2-of-transport-budgets-142176">0.1-2% of transport budgets</a>. Clover Moore is pushing hard on adding new dedicated cycle infrastructure in the City of Sydney - <a href="https://www.cityofsydney.nsw.gov.au/building-new-infrastructure/creating-pop-up-cycleways-in-sydney">Six pop-up cycleways</a> have been added, which may remain if their is popular support.</p></li>
<li><p>Australian car drivers have a <a href="https://www.abc.net.au/triplej/programs/hack/mythbusting-the-reasons-why-people-hate-cyclists/8689058">unique hatred of cyclists</a>. Cyclists <a href="https://www.smh.com.au/lifestyle/youre-a-cyclist-so-its-your-fault-20140205-321np.html">attract a level of vitriol</a>, if not outright malice, reserved for few subjects in the laid back Aussie‚Äôs mind. Even Tour de France winner Cadel Evans, a self described ‚Äúcar guy‚Äù who has a number of classic and sports cars, said <a href="https://www.smh.com.au/entertainment/books/even-tour-de-france-winner-cadel-evans-finds-cycling-in-sydney-too-intimidating-20161118-gss316.html">he doesn‚Äôt cycle in Sydney</a> due to the culture. Cyclists want to be on the road even less than car drivers want them there, but as stated earlier it is illegal to cycle on the footpath.</p></li>
</ul>
<p><em>Content warning: Image of the street where event took place, recognisable to those who live in Sydney.</em></p>
</div><div>
<h2 id="reasons-for-change">Reasons for change</h2>
<h3 id="public-safety">Public safety</h3>
<p>Car crashes are one of the <a href="https://www.seattletimes.com/life/lifestyle/the-most-dangerous-activity-driving/">leading causes of death in western countries</a>, and air pollution due to cars killed <a href="https://www.smh.com.au/politics/federal/road-death-toll-should-include-victims-of-vehicle-emissions-report-20190628-p522a8.html">two times</a> as many people as <a href="https://roadsafety.transport.nsw.gov.au/statistics/index.html">crashes do</a> in NSW each year - and they didn‚Äôt even have a choice. <a href="http://publications.jrc.ec.europa.eu/repository/bitstream/JRC89231/jrc89231-online%20final%20version%202.pdf">Half of PM10 particle emissions come from tire wear, suspended road dust and brake wear</a>- electric cars (even with regen braking) won‚Äôt fix this. In the US, drivers of cars <a href="http://vpc.org/regulating-the-gun-industry/gun-deaths-compared-to-motor-vehicle-deaths/">kill more people</a> than guns each year.</p>
<p>NSW has a program called <a href="https://towardszero.nsw.gov.au/">Towards Zero</a>, with the aim of reducing road fatalities to zero. One of the few cities to achieve this goal is Oslo, which <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the <em>city centre</em> <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches, increasing business.</p>
<p><em>Content warning: Image of food on the tarmac, and diffracted reflection from fluid likely used to clean the road.</em></p>
</div><div>
<h3 id="cars-are-heavily-subsidised-in-australia">Cars are heavily subsidised in Australia</h3>
<p>By the most generous measure, drivers only contribute <a href="https://www.ptua.org.au/myths/petroltax/">two-thirds of the cost of the road system</a> through rego and petrol taxes. The damage to a road is proportional to the <em>fourth power</em> of axle weight. Many cyclists also own a car and already pay rego. Contrary to popular belief, cyclists are likely subsidising car users.</p>
<h3 id="investing-in-cycle-infrastructurereducing-car-usage-makes-economic-sense">Investing in cycle infrastructure/reducing car usage makes economic sense</h3>
<p>In one study, for each dollar of investment in cycle focused infrastructure, the best practice policy returns 24 dollars in health, congestion, and air and noise pollution related benefits (<a href="https://ec.europa.eu/environment/integration/research/newsalert/pdf/378na1_en.pdf">Macmillan, A., Connor, J., Witten, K., et al.&nbsp;(2014). The Societal Costs and Benefits of Commuter Bicycling: Simulating the Effects of Specific Policies Using System Dynamics Modeling</a>)</p>
<p>A paper submitted to Infrastructure Australia estimated the value of commuter cycling in Australian capital cities as worth approximately <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">$0.76 per kilometre travelled</a>, equating to $2,667 for each regular commuter. Another paper <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">estimated</a> that converting drivers to cycling in Sydney &amp; Brisbane is worth $0.74 per kilometre, $1,920 per person annually in inner Sydney.</p>
<p>Banning cars on a street in Rome led to <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/www.theguardian.com/cities/2015/mar/13/pedestrianisation-rome-italy-car-parking-ban">30% increase</a> in retail spending in that street.</p>
<p>There are <a href="https://cityobservatory.org/ten-things-more-inequitable-that-road-pricing/">a lot of things</a> in our current system more inequitable than road pricing in urban areas.</p>
<h3 id="a-lot-of-other-cities-are-reducing-car-usage">A lot of other cities are reducing car usage</h3>
<p>I know this argumentum ad populum, but hey.</p>
<p>The following cities have a <a href="https://en.wikipedia.org/wiki/Congestion_pricing">congestion tax</a> in their urban core:</p>
<ul>
<li><a href="https://theconversation.com/london-congestion-charge-what-worked-what-didnt-what-next-92478">London</a></li>
<li><a href="https://en.wikipedia.org/wiki/Congestion_pricing_in_New_York_City">New York</a> (soon)</li>
<li>Stockholm</li>
<li>Singapore</li>
<li>Milan</li>
<li>Gothenburg</li>
</ul>
<p>Other efforts to reduce car usage:</p>
<ul>
<li><p>Oslo (population 673k) <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the city centre <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches. Amsterdam, New York, and San Francisco are <a href="https://www.citylab.com/perspective/2019/12/car-free-streets-plans-sf-market-street-new-york-europe-us/603391/">banning cars from their major streets</a>.</p></li>
<li><p>Madrid banned cars from its city centre during the 2018 Christmas period, <a href="https://copenhagenize.eu/news-archive/2019/3/14/the-benefits-of-car-free-streets">increasing retail profit by 9.5%</a>, and they are planning to ban cars from <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">500 acres of the city centre this year</a>.</p></li>
<li><p>In <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">Paris</a>, the first Sunday of every month is free of cars.</p></li>
</ul>
<p><em>Content warning: Image of food in the gutter of the road.</em></p>
</div><div>







<div><p>Disagree with my argument? Have I missed something or is there a mistake? I'd love to hear, please
contact me at <a href="https://jakecoppinger.blog/cdn-cgi/l/email-protection#97fdf6fcf2d7fdf6fcf2f4f8e7e7fef9f0f2e5b9f4f8fa"><span data-cfemail="0e646f656b4e646f656b6d617e7e6760696b7c206d6163">[email&nbsp;protected]</span></a>. I'm open changing my views if presented with new evidence.
</p></div></div></div>]]>
            </description>
            <link>https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196375</guid>
            <pubDate>Tue, 24 Nov 2020 08:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love Ed on CP/M]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25195420">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://techtinkering.com/articles/i-love-ed-on-cpm/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/articles/i-love-ed-on-cpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>I love ED on CP/M.  It's often derided but I think it's just misunderstood and with a little practise its true value can shine through.  It's elegant, easy to learn and only has about 25 commands but these can be combined.  Once you get used to it most editing tasks are pretty quick.  If I'm editing text that is made up of separate lines, ideally not more than the width of the terminal, I find it excellent.  It does have a line limit of 128 characters so for continuous prose I will switch to something like Wordstar, but for editing source code and config files on CP/M, it's my first choice.</p>
<p>ED came as standard with CP/M and is only 7k for CP/M 2.2 and 10k for CP/M Plus.  One advantage of ED is that it will work both with teleprinters and video terminals without having to be configured for each device.  It is also good at manipulating large files even when the system is short of memory.</p>
<p><img src="https://techtinkering.com/img/articles/cpm_ed_copy_paste.png" title="Copying and Pasting with ED"></p><p>Like many early editors, ED is a modal editor which you start in command mode and while in this mode you can view existing text, move between lines and points in the line.  It allows you to do standard operations such as copy and paste, inserting text from other files, searching for and replacing text, etc.  When we want to enter input mode, we can use the 'I' command.  This is much like VI, except that you can only enter text in the non-command mode but not edit it.  To exit data input mode and return to command mode you use ^Z (CTRL-Z).  These commands can be combined together and one of the most powerful facilities that ED has is the 'M' Macro command to repeat sequences of commands.</p>
<p>Upon executing ED it creates a temporary output file and as you write out from ED it goes to this temporary file.  When editing a file we append text from it into the memory buffer and save to the temporary output file as we go or at the end.</p>
<p>ED keeps track of a number of values such as where it is in the source file,  the line number in the memory buffer and the character pointer (CP) on the line.  These are altered as you move around the file and memory buffer.</p>
<p>I'm not going to give a fuller explanation of how to use ED here because the CP/M 2.2 Operating Manual has a good section on the <a href="http://www.gaby.de/cpm/manuals/archive/cpm22htm/ch2.htm">CP/M Editor</a>.  I do, however, want to show it being used properly in the video below.  Further down in this article I have highlighted some useful command sequences.</p>
<h2>An Example Macro</h2>
<p>ED has a macro facility which allows you to repeat a sequence of commands as many times as you like.  This makes it a good example of the power of ED and the following is a typical macro which searches through the memory buffer and displays any occurrences of the text 'CPM', pauses in case you want to stop the macro and then replaces it with 'CP/M'.</p>
<pre><code>MFCPM^Z0TT6Z-3CSCPM^ZCP/M^Z
</code></pre>
<p>The 'M' command will run the sequences of commands that follows it until an error is raised, such as end of file.  If we wanted to we could prepend 'M' with a number to indicate the number of times we want it to run.  I'll break down each command in the sequence below:</p>
<table>
  <tbody><tr><td><code>M</code></td><td>Run the following command sequence until an error</td></tr>
  <tr><td><code>FCPM^Z</code></td><td>Find 'CPM' and leave Character Pointer (CP) after it</td></tr>
  <tr><td><code>0T</code></td><td>Display the line up to CP</td></tr>
  <tr><td><code>T</code></td><td>Display the rest of the line from CP to end </td></tr>
  <tr><td><code>6Z</code></td><td>Pause</td></tr>
  <tr><td><code>-3C</code></td><td>Move CP back 3 characters</td></tr>
  <tr><td><code>SCPM^ZCP/M^</code></td><td>Substitute 'CPM' for 'CP/M'</td></tr>
</tbody></table>
<p><code>^Z</code> in the above is CTRL-Z and indicates the end of an argument for a command.</p>
<p>The above macro could also be written:</p>
<pre><code>MFCPM^Z0TT6Z-3DICP/M^Z
</code></pre>
<p>In which case:</p>
<table>
  <tbody><tr><td><code>-3D</code></td><td>Delete the 3 previous characters</td></tr>
  <tr><td><code>ICPM^Z</code></td><td>Insert the text 'CP/M'</td></tr>
</tbody></table>
<h2>Video</h2>
<p>The video below shows ED being used properly and some of the things that make it great, including searching and replacing text, copying and pasting, macros and handling files bigger than the available memory.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7pqaj050X7g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>Common Command Sequences</h2>
<p>Below are some useful command command sequences which may be overlooked when reading the manual for ED.</p>
<div><table>
  <tbody><tr><th>Sequence</th><th>Explanation</th></tr>
  <tr><td>#A</td><td>Load whole file into buffer</td></tr>
  <tr><td>0A</td><td>Load enough of the file to fill half the buffer.  This is great for large files</td></tr>
  <tr><td>#W0A</td><td>Save entire buffer and load more of the source file, enough to fill half of the buffer.  Useful to move through large files.</td></tr>
  <tr><td>0W</td><td>Write half of the buffer to the new file.  Useful to make room of the buffer is full.</td></tr>
  <tr><td>-B</td><td>Move to end of the last line in the buffer</td></tr>
  <tr><td>0L</td><td>Move CP to beginning of line</td></tr>
  <tr><td>L-2C</td><td>Move to end of line before the &lt;cr&gt;&lt;lf&gt; sequence</td></tr>
  <tr><td>0P</td><td>Display page from CP without moving CP</td></tr>
  <tr><td>0LT</td><td>Move CP to beginning of line and display line (Should this be +/-n ??)</td></tr>
  <tr><td>0T</td><td>Type line up to but not including CP</td></tr>
  <tr><td>0TT</td><td>Type whole line without moving CP</td></tr>
  <tr><td>0T&lt;cr&gt;T</td><td>Type whole line without moving CP.  Display up to CP on first list and from CP on next line.  This is useful to see where CP is on line.</td></tr>
  <tr><td>B#T</td><td>Display the whole buffer</td></tr>
  <tr><td>KI</td><td>Replace a line</td></tr>
  <tr><td>0K</td><td>Delete up to CP on current line</td></tr>
  <tr><td>S^L^Z</td><td>Join current line with next</td></tr>
  <tr><td>I^L^Z</td><td>To split a line at CP</td></tr>
  <tr><td>0V</td><td>Print free/total memory buffer stats</td></tr>
  <tr><td>0X</td><td>Empties the temporary default exchange file: X$$$$$$$.LIB, used by the <em>X</em> command</td></tr>
</tbody></table></div>
<p>In the table above the following holds true:</p>
<dl>
  <dt>#</dt><dd>Represents the highest value for n</dd>
  <dt>^L</dt><dd>CTRL-L - Stands for carriage return sequence &lt;cr&gt;&lt;lf&gt;</dd>
  <dt>^Z</dt><dd>CTRL-Z - Indicates the end of a command's argument</dd>
  <dt>&lt;cr&gt;</dt><dd>Carriage Return - Actually pressing the <em>Return</em> key</dd>
</dl>
<br>
<h2>Do You Like ED Too?</h2>
<p>I know that I'm in the minority, but I'm sure there must be other people who also like ED.  I'd love to hear if I'm not alone in this.  You can leave comments via the links below or via the YouTube video above.</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/articles/i-love-ed-on-cpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195420</guid>
            <pubDate>Tue, 24 Nov 2020 04:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fully public domain, highly portable first person shooter running on 32kb RAM]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25193953">thread link</a>) | @ClawsOnPaws
<br/>
November 23, 2020 | https://drummyfish.gitlab.io/anarch/ | <a href="https://web.archive.org/web/*/https://drummyfish.gitlab.io/anarch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://drummyfish.gitlab.io/anarch"><img src="https://drummyfish.gitlab.io/anarch/media/logo_big.png" alt="logo"></a>

    <span><i>suckless, anticapitalist, public domain game for everyone</i></span>

    

    <span><a href="https://drummyfish.itch.io/anarch">itch.io</a></span>

    <dl>
      <dt> <a href="https://forum.freegamedev.net/viewtopic.php?f=22&amp;t=14771#p95387">Easily the most plain and boring FPS I've ever played.</a> </dt> <dd> Onpon4, libre game developer </dd>
      <dt> <a href="https://talk.pokitto.com/t/anarch-doom-clone-fps/2008/70">Technically the most impressive game on Pokito yet.</a> </dt> <dd> Jonne, the creator of Pokitto </dd>
      <dt> <a href="https://archive.li/tFWrL#84%">Kill yourself.</a> </dt> <dd> Anonymous on 4chan </dd>
    </dl>

    <span>THIS IS SPECIAL</span>

    <ul>
      <li>needs only <b>200 KB</b>, <b>32 KB RAM</b>, <b>40 MHz CPU</b>!</li>
      <li><b>suckless</b>, pure C, <b>no dependencies</b>, no FPU, GPU or file I/O needed</li>
      <li>10 levels, 6 weapons, 7 enemy types, 3 ammo types</li>
      <li>varying floor/ceiling oldschool SW ray casting engine with mouse support</li>
      <li><b>100% public domain</b> CC0 free software and culture</li>
      <li>100% original work, no third party assets</li>
      <li>well documented, hackable, <b>extremely portable</b></li>
      <li>completely <b>gratis</b>, without ads, DRM or similar bullshit</li>
    </ul>

    <p>
      This isn't a 90s style retro shooter, this <b>is</b> a 90s shooter.
    </p>

    <p>
      This game runs everywhere and adheres to great <a href="https://suckless.org/">simplicity</a>.
      It is much more efficient and portable than Doom and has completely
      <b>no dependencies</b>. Not even floating point is used, in case your
      computer doesn't have the HW unit. The game can fit into <b>200 KB</b>
      (including assets!) and can run with just <b>32 KB RAM</b>. No build system,
      library, internet connection or package manager is inherently required for
      compilation as the whole game is written in pure C language.
    </p>

    <p>
      This is an experiment and art that categorically rejects capitalist
      technology.
    </p>
 
   <img src="https://drummyfish.gitlab.io/anarch/media/3screens.png" alt="screenshots">

    <span>MORE THAN A GAME</span>

    <p>
      This is not a mere entertainment or toy meant for killing time or pursuing
      low goals such as making profit or something to put on portfolio, this is
      much more. Anarch is completely <b>gratis and free as in freedom</b> and
      besides entertainment can also be used for education, research, hacking, media
      creation, as a benchmark, as a test, as an environment, as an engine, as
      a basis for something greater. You are not limited by anything, there are
      no conditions to agree to. Nothing is hidden, everything is allowed, no
      burdens are imposed. The best motivation for creating anything is only
      the <b>pure love of creation for its own sake</b>, unburdened by any other
      goal than creating something truly useful. 
    </p>

    <img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Anarch_Devices.jpg" alt="screenshots">

    <span>NO ONE OWNS THIS</span>

    <p>
      Not even I, the creator, own any part of this game.
      I&nbsp;have purposefully created everything myself from scratch,
      including the engine, graphics, sounds, music, even the font and palette,
      so that I could eventually give up all my rights and
      dedicate this game fully and <b>completely to the public domain</b>,
      to you, my dear fellow human being. No one should be allowed to own
      information and art.
    </p>

    <p>
      I've done my best to ensure this is 100% free as in freedom software and
      culture, well understandable and documented. This isn't made for any
      profit. This is made out of <b>love</b>, for you and for the greater good.
    </p>

    <h2>Download</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_LQ_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL LQ</a></li>
      <li><a href="https://drummyfish.gitlab.io/anarch/bin/web/anarch.html">play in browser</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_pokitto_1-0.pop?inline=false">Pokitto</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_gbmeta_1-0.zip?inline=false">GB Meta</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_winshitxp_sdl_1-0.zip?inline=false">M$ Win$hit XP SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/archive/master/anarch-master.zip">source code</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/tree/master/bin">more downloads</a></li>
    </ul>

    <h2>Explore</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/sucklessfps">source code</a></li>
      <li><a href="https://www.tastyfish.cz/">author's website</a></li>
      <li><a href="https://libregamewiki.org/Anarch">libre game wiki</a></li>
      <li><a href="">OGA assets</a></li>
    </ul>

    <h2><a href="https://gitlab.com/drummyfish/anarch#faq">FAQ in readme</a></h2>

    

  

</div>]]>
            </description>
            <link>https://drummyfish.gitlab.io/anarch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193953</guid>
            <pubDate>Tue, 24 Nov 2020 00:56:26 GMT</pubDate>
        </item>
    </channel>
</rss>
