<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 05 Oct 2020 12:33:19 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 05 Oct 2020 12:33:19 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Reverse Engineering a North Korean Sim City Game]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24670827">thread link</a>) | @pcr910303
<br/>
October 3, 2020 | https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/ | <a href="https://web.archive.org/web/*/https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-371">
	<!-- .entry-header -->

	<div>
		<p><em>Reverse engineering the North Korean version of a popular Sim City-like game using Ghidra and ndSpy to understand video game monetization strategies in the DPRK and the marketization of the country’s economy. </em></p><p><em>Key takeaways:</em></p><p><em>
<li>Android devices and applications are increasingly common in North Korea. Physical “app stores” can be found on every street corner in Pyongyang.</li>
<li>The game considered in this post is based on a Chinese version of a popular Android game developed in the Netherlands</li>
<li>The game’s monetization strategy was adapted to the country’s infrastructure (low internet/intranet availability, physical app stores)</li>
<li>The North Korean version eschews the original freemium + online microtransaction model for a one-time licence purchase + offline microtransaction model</li>
<li>File integrity checks added by North Korean developers shows that piracy is a concern and suggests the existence a warez/cracking scene in the DPRK</li>
<li>The cryptographic algorithms used for the licence are MD5, SHA1, RSA and AES. The library used by the game included the domestically developed private key algorithms Pilsung and Jipsam, but they were not used as part of the licencing system</li></em></p><p><a href="#intro">0. Introduction</a><br>
<a href="#licence">1. Licensing system</a><br>
<a href="#check">2. File integrity checks</a><br>
<a href="#money">3. In-game monetization strategy and key generation</a><br>
<a href="#end">4. Conclusion</a></p>
<h4 id="intro">0. Introduction </h4><p>During a recent trip to North Korea, I noticed the recent and ubiquitous presence of <em>Information Technology Exchange Rooms</em> (정보기술교류실), physical stores where one can purchase a variety of electronic devices – from laptops and tablets to USB sticks and chargers – as well as software and video games for PC, mobile and tablets (for an in-depth look at what goes on inside those stores as well as what the app selection looks like, <a href="https://www.nknews.org/2019/02/what-to-buy-inside-a-north-korean-app-store/">this article</a> by Alek Sigley provides a an excellent description. There are also a few <a href="https://www.youtube.com/watch?v=1ujblnigJmM">videos</a> on YouTube). After looking through the catalogue of available games at different stores, I eventually decided to try and buy a Sim City-like game called <em>City Management</em> (도시경경).</p>
<figure id="attachment_426"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/chongbo.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/chongbo.png" alt="" width="845" height="760"></a><figcaption>Billboards for various app stores in Pyongyang</figcaption></figure><p>The game only cost 5000 wons (less than 1 USD) which I paid to have the app installed on the phone I had, a Samsung Galaxy A5 running Android 8. The vendor connected the phone to his PC, transferred the APK and tried to install it, but to no avail. After multiple attempts, he eventually informed me that North Korean apps most likely could not run on phones from other countries. </p>
<figure id="attachment_428"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/marrichakyongchu.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/marrichakyongchu.png" alt="" width="551" height="827"></a><figcaption>Advertisement for a car racing game inside a North Korean app store</figcaption></figure><p>Fortunately, I was later able to purchase one of the different tablets sold in North Korea. I got the <em>Morning</em> (아침) brand, which is geared towards students and quite affordable. The tablet ran Android 4 (Kit Kat) on an ARM cpu and came loaded with a few educational apps: language learning courses, dictionaries and several e-book libraries containing the complete works of Kim Il Sung, school textbooks and a collection of literary works. No games, but that could now be fixed quite easily.</p>
<figure id="attachment_431"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/achimtablet.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/achimtablet.png" alt="" width="800" height="490"></a><figcaption>A North Korean Ach’im (Morning) tablet</figcaption></figure><p>I retrieved the <em>City Management</em> APK from my phone and installed it on the tablet, where it ran perfectly. Unfortunately, after the game’s initial splash screen, I landed on this:</p>
<figure id="attachment_434"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/buyserial.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/buyserial.png" alt="" width="1024" height="600"></a><figcaption>Licence key needed</figcaption></figure><p>The screen tells us that there is no “key file” (열쇠화일) and that we should purchase one at a store. There is a “request number” (요청번호) likely used to generate the licence key and make sure it can’t be shared with other devices. Unfortunately, since the APK never installed, the vendor did not put a licence file on my phone when I bought the app. My stay in North Korea was coming to an end too and I did not have time to go back to an app store to buy a new key. So I figured I would take a look inside the app and see if I could get it running nonetheless. </p>
<hr id="licence">
<h4>1. Licensing system </h4><p>To start looking into the APK’s code, I’ll use the standard suite of tools to decompress, decompile and rebuild android apps: <a href="https://sourceforge.net/projects/dex2jar/">dex2jar</a>, <a href="http://java-decompiler.github.io/">jd-gui</a>, <a href="https://ibotpeaches.github.io/Apktool/install/">apktool</a> and <a href="https://github.com/appium/sign">apksign</a>. I’ll also use <a href="https://developer.android.com/studio">Android Studio</a> to run and debug the app. The fact that I couldn’t run the app on my phone may have just come from an Android version compatibility issue: I had no problem running it on an emulated Android 4.4 device with Android Studio. The decompilation of the <code>classes.dex</code> file gives us some interesting information right away:</p>
<figure id="attachment_438"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/dex2jar1.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/dex2jar1.png" alt="" width="211" height="326"></a><figcaption>Packages and classes from the decompiled <code>classes.dex</code> file</figcaption></figure><p>The name of the <code>com.bz.cityisland2</code> package actually refers to the original game that <em>City Management</em> is based on: <a href="https://www.sparklingsociety.net/sparkling-games/city-building-games/city-island-2/">City Island 2</a> by the Dutch game studio Sparkling Society. The name of the package <code>com.smartions.appprotected</code> refers to <a href="https://www.crunchbase.com/organization/smartions-ag#section-overview">Smartions</a>, a company that offers solutions to “monetize your mobile game or app in China” and are apparently also City Island’s <a href="https://en.wikipedia.org/wiki/Sparkling_Society">distributor in China</a>. There are no mentions of those companies in the game itself however. The game’s loading splash screen only tells us that the game was made by the Ryusong (meteor) Technology Exchange Center (류성기술교류소) and that it is protected by the law for the protection of software (<a href="https://www.kisdi.re.kr/kisdi/common/premium?file=1%7C10360">콤퓨터쏘프트웨어보호법</a>). The law has been in place since 2003 to regulate the sales and distribution of software in the country and guarantees software developers the private ownership of their creation.</p>
<figure id="attachment_502"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/kyongyong-1.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/kyongyong-1.png" alt="" width="1000" height="640"></a><figcaption>Loading screen for the game</figcaption></figure><p>It’s hard to tell whether the North Korean version is based on the source code of the original game or if it’s entirely reverse engineered. In any case, the North Korean version does not use Smartions’s monetization system nor Sparkling Society’s but relies on a different system, which is the main difference from the original game. Save for the translation and some minor renames, the game is otherwise similar to the original (from a cursory examination) in its design, gameplay, features… to the original. </p>
<figure id="attachment_442"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/UnityStructure.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/UnityStructure.png" alt="" width="339" height="221"></a><figcaption>Structure a Unity APK. From Shim et al., <a href="https://www.hindawi.com/journals/scn/2018/6280768/"><em>Static and Dynamic Analysis of Android Malware and Goodware Written with Unity Framework</em></a> (2018).<br></figcaption></figure><p>There’s not much more we can glean from the Java code for now since, as the classes in <code>unity3dplayer</code> and <code>AndroidManifest.xml</code> file make clear, it is used to run code that was written with <a href="https://en.wikipedia.org/wiki/Unity_(game_engine)">Unity</a>, a popular cross-plaform video game framework which uses C# as its main programming language. The Unity code is stored in various library with the developer’s C# code being compiled to <code>Assembly-CSharp.dll</code>. C# compiled code is easily decompilable using tools such as <a href="https://github.com/0xd4d/dnSpy">dnSpy</a>. Once the dll is decompiled, we can look for the message we got earlier “열쇠화일이 존재하지 않습니다” (“The key file does not exist”) to find the bits of code we are interested in. The string search takes us to the <code>CIGLoadingScreen</code> class where we find the string among other variables:</p>
<pre title="">
	// Token: 0x0400056A RID: 1386
	private string userKey;

	// Token: 0x0400056B RID: 1387
	private string tapjoyCurrencyIdentifier;

	// Token: 0x0400056C RID: 1388
	private bool bannerVisible;

	// Token: 0x0400056D RID: 1389
	private int _loadingScreenShownCount;

	// Token: 0x0400056E RID: 1390
	private Dictionary&lt;int, bool&gt; m_gameObjectStatus = new Dictionary&lt;int, bool&gt;();

	// Token: 0x0400056F RID: 1391
	private bool m_isVerify;

	// Token: 0x04000570 RID: 1392
	private Font kfont;

	// Token: 0x04000571 RID: 1393
	private string reqMsg = "열쇠화일이 존재하지 않습니다.\r\n열쇠화일을 판매소에서 구입하십시오.";

	// Token: 0x04000572 RID: 1394
	private string reqNumLabel = "요청번호 : ";

	// Token: 0x04000573 RID: 1395
	private string reqNum;

	// Token: 0x04000574 RID: 1396
	private string finishLabel = "끝내기";
</pre><p>Looking for the name of the string variable <code>reqMsg</code> takes us here:</p>
<pre title="">	// Token: 0x06000928 RID: 2344 RVA: 0x00026E60 File Offset: 0x00025060
	private void OnGUI()
	{
		if (!this.m_isVerify &amp;&amp; this.loadingDone)
		{
			GUI.skin.font = this.kfont;
			GUI.DrawTexture(new Rect(0f, 0f, (float)Screen.width, (float)Screen.height), this.blackBg, ScaleMode.StretchToFill);
			GUI.Label(this.GetTextLabelRect(this.reqMsg, 0.5f, 0.3f), this.reqMsg);
			GUI.Label(this.GetTextLabelRect(this.reqNumLabel, 0.3f, 0.5f), this.reqNumLabel);
			GUI.Label(this.GetTextLabelRect(this.reqNum, 0.6f, 0.5f), this.reqNum);
			RectOffset padding = GUI.skin.button.padding;
			GUI.skin.button.padding = new RectOffset(20, 20, 10, 10);
			if (GUI.Button(this.GetButtonRect(this.finishLabel, 0.5f, 0.8f), this.finishLabel))
			{
				Application.Quit();
			}
		}
	}
</pre><p>This is the code used to display the splashscreen we encountered earlier. If the boolean property <code>this.m_isVerify</code>, presumably the result of a call to a function checking the existence and validity of a licence key, is <code>False</code> then, the screen is displayed with the message we saw earlier and the “request number”. The verification function and the generation of the request number are handled in another class <code>GameCus</code>:</p>
<pre title="">using System;
using System.IO;
using System.Runtime.InteropServices;

// Token: 0x02000147 RID: 327
public class GameCus
{
	// Token: 0x06000AA7 RID: 2727
	[DllImport("Game")]
	private static extern int vProcess(byte[] key, int keyLen, byte[] certData, int certDataLen);

	// Token: 0x06000AA9 RID: 2729 RVA: 0x0002E910 File Offset: 0x0002CB10
	public string GetReqNumber()
	{
		string deviceIdString = this.GetDeviceIdString();
		return string.Format("{0:d4} {1:d4} {2:d4} {3:d4}", new object[]
		{
			deviceIdString.Substring(0, 4),
			deviceIdString.Substring(4, 4),
			deviceIdString.Substring(8, 4),
			deviceIdString.Substring(12, 4)
		});
	}

	// Token: 0x06000AAA RID: 2730 RVA: 0x0002E968 File Offset: 0x0002CB68
	public string GetDeviceIdString()
	{
		string text = Utils.GetDeviceModel();
		text = string.Format("{0:d10}", (uint)text.GetHashCode());
		string str = text.Substring(2, 8);
		string text2 = Utils.GetDeviceUid();
		text2 = string.Format("{0:d10}", (uint)text2.GetHashCode());
		string str2 = text2.Substring(2, 8);
		return str + str2;
	}

	// Token: 0x06000AAB RID: 2731 RVA: 0x0002E9CC File Offset: 0x0002CBCC
	public bool checkCertData(byte[] certData)
	{
		if (certData == null || certData.Length == 0)
		{
			return false;
		}
		string text = this.GetDeviceIdString() + …</pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/">https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/</a></em></p>]]>
            </description>
            <link>https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670827</guid>
            <pubDate>Sat, 03 Oct 2020 09:39:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Honest Review of Gatsby]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24670252">thread link</a>) | @ehfeng
<br/>
October 3, 2020 | https://cra.mr/an-honest-review-of-gatsby/ | <a href="https://web.archive.org/web/*/https://cra.mr/an-honest-review-of-gatsby/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We decided to adopt Gatsby for <a href="https://docs.sentry.io/">Sentry’s customer-facing documentation</a> - well, I should say that <em>I</em> decided. We were already using it successfully for a variety of static marketing content, and I knew it had a lot of hype, so after a brief proof-of-concept it seemed like a safe choice.</p>
<p>To help contextualize everything I’m about to say, it’s important to understand the scope of our usage. Sentry’s documentation is not as straightforward as you might think - in fact, there are over 3,000 pages as of writing. We have a large amount of templated content designed to render language-specific examples, as well as a variety of different types of documentation (user guides, help desk-y articles, code-rich technical docs). Originally we had extended Jekyll to support a lot of this, but Ruby isn’t widely used at Sentry (approximately 0% of the engineering team knows Ruby), and it had become a big mess of spaghetti code with slow build times.</p>
<p>I also want to note that while this blog post is primarily focusing on the flaws of Gatsby as a framework, I’m not here to tell you that it’s not good for your use case. That said, I was not able to discover many of these short comings easily when evaluating Gatsby, and many things you read on the internet don’t stem out of real-world usage. My hope here is that Gatsby continues to improve over time, and that, as a user, you can be more informed about if it’s the right choice for you.</p>
<h2>Adopting Gatsby</h2>
<p>So, enter Gatsby. It seemed fast, was built on React (we’re experts on that here, with our gigabyte-sized Sentry frontend app), and had a huge adoption (assumed future existence and stability). While we didn’t have the desire to use MDX, it also seemed like a positive outcome given we could more easily deal with some of the rich aspects of our docs site, without having to resort to 2010-era JavaScript. We assumed a bunch of the other features of Gatsby had value-add, but we didn’t have an immediate need. These were things like dynamic source data - thus the need for a GraphQL engine at all - as well as the large plug-in ecosystem.</p>
<p>We started by iteratively converting sections of the Jekyll site into Gatsby - running them side by side for a time. At one point we eventually bulk converted pages, and ripped off the band aid. At this point though it was becoming clear build times were a problem. You’d spend at least 5 minutes on image optimization alone, with no way to even disable that. Slowly but surely we were depleting the ozone later on re-optimizing images which had already been pre-optimized. Oh yeah, and we were crippling our iteration speed as well, since the build cache would invalidate under a variety of situations in early development.</p>
<p>Making this worse was how we deployed Gatsby. We started off leveraging what we had already done: deploying Jekyll with Docker onto our own infrastructure - effectively just proxied via a CDN. We continued that for a period of time, but deploy times were far too long - upwards of 30-40 minutes for everything to build. Eventually we moved over to <a href="https://vercel.com/">Vercel</a> which dropped it down closer to 10 minutes, but ultimately it can’t fix what it doesn’t control.</p>
<p>The build and deploy times were the first of many woes, and they represent what would become a continued frustration: a problem without a clear solution.</p>
<h2>Enter MDX</h2>
<p>Rewind time a little bit - this actually wasn’t our first project converting documentation to Gatsby. The proof-of-concept I mentioned earlier was actually our <a href="https://develop.sentry.dev/">developer documentation</a>, which I had migrated out of Notion to make public. While doing that we had gotten our hands dirty with some initial MDX usability and extensions - like our code samples which support toggling between different languages. This was one of the many things we needed to solve for, but MDX made it look like it’d be seemingly easy. No more jQuery DOM manipulation, just clean, encapsulated React components. Or so we thought.</p>
<p>Almost immediately we hit rough spots with MDX. We were coming from Jekyll - which was Liquid-rendered (a template engine) markdown - to MDX - a strange offspring of Markdown and JSX, attempting all of the benefits of both, but missing by a fairly large margin. Let’s illustrate the crux of the issue with what has got to be one of the most common needs in a documentation system: an alert (or callout) component:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>info<span>"</span></span><span>&gt;</span></span>You should know something important about this!<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>At face value this looks great. <code>Alert</code> is just a React component, and JSX is close enough to HTML that non-technical folks are able to pick it up fairly easily. Now the problem comes into play when you actually want to do something in the real world. Here’s an example from our API docs:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span>
    <span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.
<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>How would you expect this to render? Both as an engineer and a non-engineer, I would expect - given this is markdown - that the “PUT/DELETE” text would be bold. It’s not. Because the MDX interpreter decides that once you enter a component block, it’s no longer markdown. So instead, we’re forced with this monstrosity <em>everywhere</em> in our documentation:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;</span>markdown</span><span>&gt;</span></span>

<span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.

<span><span><span>&lt;/</span>markdown</span><span>&gt;</span></span><span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>There’s two things you should note here: 1) we have to use this <code>&lt;markdown&gt;</code> tag, 2) we have to put empty new-lines to ensure paragraph tags render.</p>
<p>“But David”, you might say, “why don’t you just tell the <code>Alert</code> component to render the text as markdown?“. If only you could, or at least, if only I could have possibly found a way to achieve that as a user with minimal Gatsby or MDX internals knowledge.</p>
<p>To Gatsby, or at least to the MDX team’s credit, they recognize some of these problems and <a href="https://github.com/mdx-js/mdx/issues/1041">there is work underway</a> on a 2.0 of the MDX dialect. While I’m confident they will improve things, I’m not confident MDX can ultimately succeed. It’s likely going to tradeoff one problem for another due to what it’s trying to achieve in the first place. It may get to a good place, but frankly, we need to step back and look at what we’re trying to solve, instead of creating a solution to a problem we don’t have. I don’t need JSX syntax in my markdown, I need a way to include JSX components. That might sound similar, but its quite a different thing.</p>
<p>As an example, there’s no reason I couldn’t simply use markdown syntax, and provide a way to achieve something akin to:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>a-valid-html-tag-because-markdown-allows-that</span> <span>a-valid-property</span><span><span>=</span><span>"</span>a-value<span>"</span></span><span>&gt;</span></span></code></pre></div>
<p>This wouldn’t force us to work around quirks in a new language (or interpreter even), and could be solved in a much more sustainable way. There are other alternatives as well. A generic way to render extensions in markdown could simply call into a React component, and avoid even trying to hijack HTML in the first place. While I don’t know what this might look like in Markdown, in <a href="https://www.sphinx-doc.org/en/master/usage/restructuredtext/index.html">Sphinx’s use of reStructuredText</a> this was solved early on with Directives:</p>
<div data-language="text"><pre><code>.. my-directive:: some data
   :property-name: property-value</code></pre></div>
<p>I will hold out for MDX 2.0 and hope that finds a nice minimal-compromise place, but if not, we’ll be looking for a way to extend native markdown.</p>
<h2>A Broken DOM</h2>
<p>While we were able to work around the kinks of MDX, there’s been some things not yet solved. One of those is the layer which Gatsby uses to apply diffs to the DOM. I’m going to caveat this section with <em>I don’t know what the technical implementation is</em>, but I can make some assumptions given what I know of the domain. The system itself is intended to apply deltas to the DOM. This is naively also how React works, and I imagine under the hood it’s relying on React at least for part of it. We’ve had issues with this identified in two places already:</p>
<ul>
<li>progressive image loading</li>
<li>dynamic JSX components</li>
</ul>
<p>While they might not be linked to the same issue, they smell like they are, so we’re going to roll with it. The problem exhibits itself when you have a bunch of DOM that to a naive robot might look the same:</p>
<div data-language="text"><pre><code>&lt;div&gt;foo&lt;/div&gt;
&lt;div&gt;bar&lt;/div&gt;
&lt;div&gt;baz&lt;/div&gt;
&lt;div&gt;foobizbar&lt;/div&gt;</code></pre></div>
<p>In React it uses the graph to identify which node is which - effectively creating a unique entity ID based on its location. In cases where that’s difficult, React will warn you to explicitly bind a <code>key</code> attribute on each element to ensure it can more accurately deal with updates. While I would assume Gatsby is at least partially using React’s DOM engine, what we see in production effectively takes the above example, and replaces some of the content with other subsets of content - meaning it’s unable to accurately identify which nodes need updated.</p>
<p>We’ve seen this where a progressive image is replaced with an entirely different image that’s present near it on the page. We’ve also seen this happen for a dynamically loaded section of content (our language-selector include tags). While we’ve yet to identify a fix for the image tags, our other issue was resolved by literally changing a <code>div</code> tag to a different tag, one which is less commonly used (in our case, <code>section</code>).</p>
<p>All of the cases happen after Gatsby’s initial static render and exist only when applying some form of delta.</p>
<h2>Let’s Talk GraphQL</h2>
<p>It’s a static website generator. It literally does not need GraphQL all over the place. While there are few instances in the real world where that is valuable, it shouldn’t require a GraphQL API to read objects that are already in memory.</p>
<p>I don’t want to spend the energy to hammer this in, but take a look at Jared Palmer’s <a href="https://jaredpalmer.com/gatsby-vs-nextjs">Gatsby vs. Next.js</a> as it echoes my thoughts.</p>
<p>So, let’s actually not talk about GraphQL, but all its done is create complexity for us.</p>
<h2>Minor Gripes</h2>
<p>There’s a number of other things we’ve found fairly frustrating at this point, but this post is already getting long, so I’m choosing to summarize them.</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cra.mr/an-honest-review-of-gatsby/">https://cra.mr/an-honest-review-of-gatsby/</a></em></p>]]>
            </description>
            <link>https://cra.mr/an-honest-review-of-gatsby/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670252</guid>
            <pubDate>Sat, 03 Oct 2020 07:18:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It, Part III: Hammer-Time]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24668125">thread link</a>) | @dddddaviddddd
<br/>
October 2, 2020 | https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, we continue our four-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">II</a>, III, IV) look at pre-modern iron and steel production.  Last week we took our ore and smelted it into a rough, spongy mass of iron called a bloom; this week we’re going to go through the processes to reshape that bloom first into a consolidated billet, then into a bar that is useful for forging and finally into some useful final object.</p>



<p>I want to stress at the outset that we are not going to cover anything close to the whole of blacksmithing practice in this post.  Blacksmithing is fairly complex and any given object, shape or tool is going to have its own set of processes and techniques to produce the required shape at the required hardness and malleability characteristics.  If you <em>are</em> interested in that sort of information, I recommend A.W. Bealer’s <em>The Art of Blacksmithing</em> (1969) as a fairly good starting point, though there is no substitute to speaking with a practicing blacksmith.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<h2>Heat, Hammers and Hardness</h2>



<p>There are a few basic behaviors of iron that fundamentally control what blacksmiths are going to do with it in this stage.  To begin with, we need to introduce some terminology to avoid this coming confusing: a given piece of metal can be <em>hard</em> (resistant to deformation) or <em>soft</em>; they can also be <em>ductile </em>(able to deform significantly before breaking) or <em>brittle</em> (likely to break without deformation).  This is easiest to understand at the extremes: a soft, brittle material (like a thin wooden dowel) takes very little energy and breaks immediately without behind, while a hard, ductile material (the same dowel, made of spring-steel) bends more easily under stress but resists breaking.  But it is also possible to hard hard brittle materials (pottery being a classic example) which fiercely resist deforming but break catastrophically the moment they exceed their tolerances or a soft, ductile material (think wet-noodle) which bends very easily.</p>



<p>(I should note that all of these factors are, in fact, very complex – far more complex than we are going to discuss.  In particular, as I understand it, some of what I am using ‘hardness’ to describe also falls under the related category of yield strength.  Hopefully you will all pardon the necessary simplification; if it makes you feel any better, ancient blacksmiths didn’t understand how any of this worked either, only that it worked.)</p>



<p>Of course these treats are not binaries but a spectrum.  Materials have a degree of hardness or ductility; as we’ll see, these are not quite <em>opposed</em>, but changing one does change the other – increasing hardness often reduces ductility.</p>



<p>The sort of things that pre-modern people are going to want to be made in iron are going to have fairly tight tolerances for these sorts of things.  Objects that had wide tolerances (that is, things which could be weak or a little bendy or didn’t have to take much force) got made out of other cheaper, easier materials like ceramics, stone or wood; metals were really only used for things that had to be both strong and relatively light for precisely the reasons we’ve seen: they were too expensive for anything else.  <strong>That means that a blacksmith doesn’t merely need to bring the metal to the right shape but also to the right <em>characteristics</em></strong><em><strong>.</strong>  </em>Some tools would need to finish up being quite hard (like the tip of a pick, or the edge of a blade), while others needed to be able to bend to absorb strain (like the core of a blade or the back of a saw).</p>



<p>Keep all of that in mind as we discuss:</p>



<h2>Forge Techniques</h2>



<p>I realize this is a long aside to leave our bloom waiting, but as we’ll see, the remaining steps share a basic set of techniques, making it easier to discuss those techniques together.</p>



<p>Fundamentally, each stage of forging iron revolves around a basic cycle: <strong>by heating the metal, the smith makes it soft enough to <em>work</em> </strong>(that is, hammer into shape).  Technically, it is possible to shape relatively thin masses of iron by hammering when cold (this is called cold-working) but in contrast to other metals (tin, copper and bronze all come to mind) nearly all serious iron-working was done ‘hot.’  In smithing terminology, each of these cycles is referred to as a ‘heat’ – the more heats a given project requires, the more fuel it is going to consume, the longer and more expensive it is going to be (but a skilled smith can often finish the work in fewer heats than an unskilled smith).</p>



<figure><img data-attachment-id="4712" data-permalink="https://acoup.blog/202833001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg" data-orig-size="2500,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="202833001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/P_1836-0811-78">Via the British Museum</a>, A Dutch drawing (c. 1624-1640) of blacksmiths at work, with the blacksmith himself in the center and a striker (with the two-handed hammer) to the left.  An assistant mans the bellows on the forge to maintain the temperature.</figcaption></figure>



<p>A modern blacksmith can gauge the temperature of a metal using sophisticated modern thermometers, but pre-modern smiths had no recourse to such things (and most traditional smiths I’ve met don’t use them anyway).  Instead, the temperature of the metal is gauged by looking at its <em>color</em>: as things get hotter, they glow from brown to dark red through to a light red into yellow and then finally white.  For iron heated in a forge, a blacksmith can control the temperature of the forge’s fire by controlling the air-input through the bellows (pushing in more air means more combustion, which means more heat, but also more fuel consumed).  As we’ve seen, charcoal (and we will need to use charcoal, not wood, to hit the necessary heat required), while not cripplingly expensive, was not trivial to produce either.  A skilled smith is thus going to try to do the work in as few heats as possible and not excessively hot either (there are, in fact, other reasons to avoid excessive heats, this is just one).</p>



<p>One hot the metal can be shaped by hammering.  The thickness of a bar of metal could be thickened by <em>upsetting</em> (heating the center of the bar and them hammering down on it like a nail to compress the center, causing it to thicken) or thinned by <em>drawing</em> (hammering out the metal to create a longer, thinner shape).  If the required shape needed the metal to be bent it could be heated and bent either over the side of the anvil or against a tool; many anvils had (and still have) a notch in the back where such a tool could be fitted.  A good example of this kind of thing would be hammering out a sheet of iron over a dome-shape to create the bowl of a helmet (a task known as ‘raising’ or ‘sinking’ depending on precisely how it is done).  A mass of iron can also be divided by heating it at the intended cutting point and then using a hammer and chisel to cut through the hot, soft metal.</p>



<p>But for understanding the entire process, the most important of these operations is the<strong> <em>fire weld</em></strong>.  Much like bloomery furnaces, the forges available to pre-modern blacksmiths could not reach the temperatures necessary to melt or cast iron, but it was necessary to be able to join smaller bits of iron into larger ones which was done through a fire weld (sometimes called a forge weld).  In this process, the iron is heated very hot, typically to a ‘yellow’ or ‘white’ heat (around 1100 °C).  The temperature range for the operation is quite precise: too cold and the iron will not weld, too hot and it will ‘burn’ making the weld brittle.  Once at the right temperature, the two pieces of iron are put next to each other and hammered into each other with heavy blows.  If done properly, the two pieces of metal join completely, leaving a weld that is as strong as every other part of the bar.</p>



<figure><img data-attachment-id="4703" data-permalink="https://acoup.blog/fire-welds/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png" data-orig-size="1057,282" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fire-welds" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png 1057w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://youtu.be/cc_n8H-2-I0">From this demonstration</a>, a series of hammer blows in the process of making a fire or forge weld.  The sparks you see are flux and hammer scale (and possibly some amount of slag and excess iron material) being ejected out of the weld.</figcaption></figure>



<p>That’s not all there is to say about these processes (we’ll come back to them in a moment) but we now have enough of the basics to begin processing our bloom.</p>



<h2>From Bloom to Billet to Bar</h2>



<p>As you may recall, when we finished our process last time, we ended with a ‘bloom’ of iron: a spongy mass of pure, metallic iron interspersed with inclusions of waste materials called slag:</p>



<figure><img data-attachment-id="4630" data-permalink="https://acoup.blog/1024px-iron_bloom/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg" data-orig-size="1024,853" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-iron_bloom" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The iron of the bloom itself is also likely to be quite brittle because of these slag inclusions.  This isn’t a product that can be sent directly to a blacksmith.  It needs to be consolidated first into a billet and most of that slag needs to be forced out, both of which can be achieved via liberal application of <strong>fire welding</strong>.</p>



<p>This step is sometimes called <strong>bloomsmithing</strong>.  The bloom is heated to roughly 1100 °C (gauged, as above, by the color of the iron) – it seems plausible that it may have been broken up into smaller chunks to make this more useful – and then hammered into a single mass through a series of fire welds.  We’re not very well informed how this was done in the ancient world (save ‘with hammers’) because bloomsmithing doesn’t tend to leave a lot of evidence for us to observe.  The end shape of the process was generally a very thick rectangular bar called a <strong>billet</strong>, ready for relatively easy transport.</p>



<p>This process has some advantages and disadvantages, beyond merely shaping the metal into a more usable and transportable form.  Remember that our bloom contains a lot of material which isn’t iron (the slag); fire welding, especially when repeated, tends to expel this slag – as the iron is compressed in the weld, the slag is forced out.  There is some debate (note Sim &amp; Kaminski, <em>op. cit.</em>) if this process is sufficient to explain the <em>very</em> low slag counts seen in high quality weapons and armor, but it is certainly true that fire welding reduces the overall slag count.  That …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24668125</guid>
            <pubDate>Fri, 02 Oct 2020 23:35:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archillect – an AI created to discover and share stimulating visual content]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24667732">thread link</a>) | @dewey
<br/>
October 2, 2020 | https://archillect.com/about | <a href="https://web.archive.org/web/*/https://archillect.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://archillect.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667732</guid>
            <pubDate>Fri, 02 Oct 2020 22:35:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why most Hacktoberfest PRs are from India]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24667488">thread link</a>) | @pulkitsh1234
<br/>
October 2, 2020 | https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/ | <a href="https://web.archive.org/web/*/https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Before reading the post</em></p>

<p>Now that I have mentioned the name of a country in the title, please read the following points:</p>
<ul>
  <li>I am an Indian and have been living in the country since my birth.</li>
  <li>I do not claim to be right on all of this and there are many anecdotal generalisations here. Somethings are more like human problems instead of Indian problems <strong>but</strong> just the sheer number of people here puts India on everyone’s radar.</li>
  <li>This post is NOT to denigrate India. It is definitely critical of some of its social and psychological aspects. As a proof for that I want to mention that I am writing a series on the wisdom of ancient Indian philosophical ideas here: <a href="https://pulkitsharma07.github.io/2020/06/25/source-0/">Source [0]</a>, just so you know that I am not writing all my posts with the sole intention to show what is “wrong” with India. We should be brave enough to face the good and bad of it.</li>
  <li>It is a shame that I need to write this header in the first place. But the reality is with or without this, people will still get offended.</li>
</ul>

<hr>

<h2 id="index">Index</h2>

<ul>
<li><a href="#what">What</a></li>

<li><a href="#how">How</a></li>

<li><a href="#why">Why</a>
<ul>
  <li><a href="#the-signalling-problem">The Signalling Problem</a></li>
  <li><a href="#the-jugaad-mentality">The Jugaad Mentality</a></li>
  <li><a href="#computer-science-education-in-india">Computer Science Education in India</a></li>
  <li><a href="#but-why-for-hacktoberfest">But why for Hacktoberfest?</a></li>
  <li><a href="#the-problem-with-high-population-density">The problem with high population density</a></li>
  <li><a href="#hierarchy-of-needs">Hierarchy of Needs</a></li>
</ul></li>
<li><a href="#closing-thoughts">Closing Thoughts</a>
<ul>
  <li><a href="#probable-future">Probable Future</a></li>
  <li><a href="#improbable-future">Improbable Future</a></li>
</ul>
</li>
</ul>
<hr>

<h2 id="what">What</h2>

<p>As most of you may know, <a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> started on 1st October 2020. And as it with most things in human life, people came with <a href="https://mobile.twitter.com/shitoberfest">different</a> ways to hack hacktoberfest to get the free t-shirt.</p>

<p>Now apart from the sheer number of spam PRs which were opened, copious amount of time is being spent by the comparatively small number of open source maintainers who have comment, close and label each individual PR.</p>

<p>I became aware of this happening from this <a href="https://news.ycombinator.com/item?id=24643894">post</a>, and in a days time several more <a href="https://joel.net/how-one-guy-ruined-hacktoberfest2020-drama">posts</a> popped up. 
I got motivated (triggered?) to write this post when I saw the following on HN:</p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/hn_comment.png" alt="hn-comment"></p>

<p>After some investigation, I found the original claim to be true, <code>more than 60% of the spam PRs are coming from one country: India</code> and that is just 1 day after hacktoberfest started, I am sure the percentage will increase as days go by (unless DigitalOcean does something).</p>
<hr>

<h2 id="how">How</h2>

<p><a href="https://joel.net/how-one-guy-ruined-hacktoberfest2020-drama">This</a> post talks about one Indian YouTube channel which apparently told people to open spammy PRs. After I looked around some people were claiming he was falsely accused, anyways the video is deleted now, so I can’t comment on that.</p>

<p>Anyways, it didn’t take long and I was able to find few more Indian YouTubers who were pretty directly promoting ways to open PRs to get those sweet T-Shirts. One created his own <a href="https://github.com/seeditsolution/cprogram/pulls">repo</a> and encouraged people to google different programs and copy-paste them into a new PR against the empty repo.</p>

<p>I do not want to focus on the <em>How</em>, you will find find plenty videos/blogs on it, I am sure some Indian YouTuber has started working on creating a video on it.</p>
<hr>

<h2 id="why">Why</h2>
<p>One of the simplest explanation is that, DigitalOcean should have been very well anticipated that this is going to happen, after all they must have all the stats from the previous HacktoberFests.</p>

<p>We need to understand that Hacktoberfest is an marketing event. And all these spam and blogs posts around it is definitely serving their main purpose, there is no such thing as bad publicity indeed. Of course I could be totally wrong, all of this could be completely unintentional.</p>

<hr>

<p>Now, coming to the Indian side of the ongoing issue. Out of all the countries why does India have the most spammy PRs ? As a seasoned armchair philosopher, the following are my thoughts on the “Why” of all this.</p>
<hr>

<h3 id="the-signalling-problem">The Signalling Problem</h3>
<p>Whenever an online article/documentary/report claim to give a view into the “real” India, most of us (Indians) get offended.</p>

<p>I <em>was</em> in the bubble which was in the “offended” bucket for long time. The reason was simple: I, the people around me and the societal structures around me were all part of the same bubble. We do not have to worry about paying school fees or rent, we do not have worry about sending part of salary back home just so that our parents can buy groceries to survive..</p>

<p>I can go on and on, the overall gist is that I got offended in seeing what other people claim as “real” India, because that India was not part of my reality. Sure, I saw that when travelling from one place to another, saw that on news, read about that in the newspaper; but I was at a very safe distance from all of that.</p>

<p>These days, I try to not get offended when people say India has problem X or problem Y, because I realise I am living inside a cocoon where all of my needs are met, and one of the most serious issues my country is facing right now is <strike>witch-hunting </strike> nabbing the “drug mafia” amongst the Bollywood celebrities who allegedly murdered an actor by giving CBD oil (The absurdity of all this is unfathomable)</p>

<p>I mention all of this, because whenever I read posts which show India in some <a href="https://news.ycombinator.com/item?id=24552047">bad light</a>, there is always someone somewhere who gives anecdotes of how that is not true.</p>

<p>Here are some facts: we have a culture of <strong>extreme signalling</strong>. Signalling is the core building block of our society, most people don’t even realise that how big we are into signalling until they study about “signalling” as a phenomena and start becoming conscious of it. You notice that in the way your parents view you, how you make choices, how people around you make choices.</p>

<p>Of course, people will say “that is not an Indian problem, signalling is just a social construct and literally everyone does that on some level”. I am not denying not that, the very fact that I am writing this post is a kind of signalling I am doing.</p>

<p>It is well known fact that India is one of the densest countries on our <a href="https://ourworldindata.org/grapher/population-density?time=2017">planet</a>, extreme siginalling is just one of the consequences of the myriad social problems created by high population density. Signalling in an high density environment is now ever more important as the people you interact or the people who notice your activities/accomplishments are multiples higher than in any other place on the planet.</p>

<p>We people like the wear the “tightly knit society” as badge of honour, let me tell you this “tightly knit society” has done more harm than good. We Indian people have no India of the amount of mental harassment we all go through, because that is just normalized as being just phases of “life”.</p>

<p>The prevalence of extreme signalling brews the classic and infamous <em>herd mentality</em> in our minds. In middle school children have dreams to become a Pilot in the airforce, or maybe a Police officer, or maybe a Opera Singer ! But by the time of high school, everyone is just either on road to become an Engineer, a Doctor, a Lawyer, a Chartered Accountant …. or a <strong>failure</strong>. This may seem harsh but that’s how most of the society operates here in India.</p>

<p>Now once your track is chosen for you (or fortunately, if you get to choose the track), you have some set goals you “must” achieve because they guarantee monetary success with an extremely high probability. If you are Engineer, you need to get into IIT. If you are a Doctor, you need to get into AIIMS. If you are doing management, you need to get into IIM.</p>

<p>Now, if you are an Engineer then your success criteria is not just any IIT, it should be one of the top ones (Bombay, Delhi, Kharagpur, Roorkee) and not just any branch in IIT, it should be <em>Computer Science</em>. Because that’s how you get <a href="https://www.newindianexpress.com/nation/2019/dec/04/five-iitians-bag-pay-packages-of-over-rs-15-crore-2071120.html">Rs 1.5 crore “packages” (equivalent to 200K USD)</a>.</p>

<p>You can give me examples of how not all IIT toppers choose “Computer Science”, but that’s not the point, for the vast majority of people (more than a million), the success criteria is: getting Computer Science at IIT Bombay.</p>

<p>As might know (or have guessed) getting a seat in IIT Bombay is next to impossible for more than 99% people giving IIT, so they “lower” their goal by aiming for other IITs, but “Computer Science” remains the top priority.</p>

<h3 id="the-jugaad-mentality">The Jugaad mentality</h3>
<p>Hacking systems is so ingrained in our society that we have a word for it: <a href="https://en.wikipedia.org/wiki/Jugaad">Jugaad</a>. The whole scene with Hacktoberfest is just a demo of our Jugaad skills. Wait till you find out that <a href="https://indianexpress.com/article/india/inside-indias-fake-research-paper-shops-pay-publish-profit-5265402">most of the research papers</a> published in India are <a href="https://scroll.in/article/908230/indian-academics-lead-the-world-in-publishing-in-fake-journals-tarring-the-whole-education-sector">fake</a>. Even the orthodontist I was visiting for my checkup turned out to be fake and had forged her certificates (as told by by one other dentist).</p>

<p>The coaching industry actively promotes “cracking” these exams, and I am so tired writing on that topic that I do not want to write more about it here. Refer to my post on this <a href="https://www.linkedin.com/pulse/coding-interviewing-coaching-industry-prologue-pulkit-sharma?articleId=6662006663559684097">here</a>. Some children start joining these coaching classes from as low as 5th grade! (apart from doing regular school), just to be able to “crack” the IITs after 7-8 years !</p>

<p>Now how is coaching industry a Jugaad ? Simply because from the point of view of IITs, attending regular school should be enough to prep you for the exams (I think). These coaching industries have made the process significantly harder as you can’t even hope of getting a low tier IIT without attending the coaching classes.</p>

<p>The IIT coaching industry is minting fat cheques out of this entire situation, look at these ads on the front page of the news paper. These ads create a vicious cycle by reinforcing the core “signalling” construct of our society.</p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_1.png" alt="hn-comment"></p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_2.png" alt="hn-comment"></p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_3.png" alt="hn-comment"></p>

<p>Do not quote me on this, but I think the IIT coaching industries make more <a href="https://www.businessinsider.in/education/news/iits-iisc-say-that-patchy-funding-is-delaying-institute-of-eminence-plans/articleshow/72103538.cms">money than the IITs</a> themselves. I understand the purpose of IITs is not to directly generate money, but if it would have more resources they can probably improve the infrastructure, employ better professors and improve the overall level of education.</p>

<h3 id="computer-science-education-in-india">Computer Science Education in India</h3>
<p>For vast majority of engineers in India, Computer Science is  one of the subjects you study in order to succeed in life. Just like you study Chemistry, you “study” Computer Science and once you learn all the “concepts”, you get a good job. (Apologies for so many quoted words, I can’t help putting them in quotes because they carry so much weight for me).</p>

<p>When people are in an average Indian college and if they are are lucky, information about some permutation/combination of the following is spread amongst the …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/">https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/</a></em></p>]]>
            </description>
            <link>https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667488</guid>
            <pubDate>Fri, 02 Oct 2020 22:04:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the best dumb TV?]]>
            </title>
            <description>
<![CDATA[
Score 413 | Comments 412 (<a href="https://news.ycombinator.com/item?id=24666968">thread link</a>) | @evo_9
<br/>
October 2, 2020 | https://pointerclicker.com/best-dumb-tv/ | <a href="https://web.archive.org/web/*/https://pointerclicker.com/best-dumb-tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>There are a few things you need to consider when you’re looking to buy a good dumb TV. Let’s take a closer look at each of them.</p><h3>Screen size</h3><p>The biggest challenge you will face when you’re looking for a good dumb TV is getting a good screen size. You will soon realize that there are not a lot of dumb TVs that come in the latest size standards for home entertainment.</p><p>A lot of dumb TVs only have 30-40-inch screens. If this size works for you, then you are in luck. However, in today’s standards, 30-40 inches is not enough screen real estate.</p><p>You may want to find something with at least a 50-inch screen. The good news is that they do exist and, according to our research, you can even go up to 65 inches.</p><p><strong>If you’re in hurry, here’s our recommendations</strong></p><table><thead><tr><th>Image</th><th>Product</th><th>Features</th><th>Price</th></tr></thead><tbody><tr id="product-723"><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer"><img src="https://m.media-amazon.com/images/I/419R0211LBL.jpg" data-src="https://m.media-amazon.com/images/I/419R0211LBL.jpg" alt="Sceptre 65 Inches 4K UHD LED TV"></a></td><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer">Sceptre 65 Inches 4K UHD LED TV</a></td><td><div><ul><li>Bright LED display and sharp contrast</li><li>65-inch 4K UHD, HDR and MEMC120</li><li>HDMI ports, component ports, optical and line audio outputs</li></ul></div></td><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer" data-style="">Check Price On Amazon</a></td></tr><tr id="product-724"><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer"><img src="https://m.media-amazon.com/images/I/51S-2IYjHFL.jpg" data-src="https://m.media-amazon.com/images/I/51S-2IYjHFL.jpg" alt="Sceptre 50"></a></td><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer">Sceptre 50″ 4K UHD Ultra Slim LED TV</a></td><td><div><ul><li>50-inch screen that supports 4K UHD</li><li>Mobile High-Definition Link (MHL) to stream videos from a smartphone</li><li>Stunning colors and image contrast</li></ul></div></td><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer" data-style="">Check Price On Amazon</a></td></tr></tbody></table><h3>Input ports</h3><p>Another thing that turns a regular dumb TV into a good dumb TV is the number of input ports it has. Since your dumb TV relies on external devices for display content, you will want several ports to ensure that you can plug in all your devices.</p><p>Having several input ports will allow you to switch between devices without having to physically unplug and plug them. Reaching behind your TV to do this can be very inconvenient.</p><p>HDMI ports are what most external devices today use. You will want at least 3 HDMI ports on your dumb TV. Having more HDMI ports will be better, especially if you’re thinking about getting a few more external devices.</p><h3>Monitors</h3><p>When looking for a good dumb TV, people often make the mistake of looking in the monitor category. A monitor may work for you, but there are a couple of reasons why they may not work as well as a TV.</p><p><a href="https://pointerclicker.com/how-to-clean-a-matte-monitor/" target="_blank" rel="noopener noreferrer">Monitor displays</a> are relatively darker than TV displays. This is because monitors are designed for people who sit up close.</p><p>It may not be a problem when you’re watching a movie in a dark room. If you watch with the windows open during the day, however, your monitor won’t be able to produce enough brightness to give you pleasant viewing experience.</p><p>Monitors also do not come with a TV tuner. This will be a problem if you’re thinking about watching local channels.</p><h2><span id="Does_a_great_dumb_TV_exist_in_2020">Does a great dumb TV exist in 2020?</span></h2><p>The short answer is yes. Although smart TVs are more popular, there are still a few great dumb TVs being manufactured.</p><p>You can visit your local electronic shop or search for one online. Below are some of our dumb TV recommendations.</p><h2><span id="Editors_recommendations">Editor’s recommendations</span></h2><p>We’ve put together a shortlist of our top dumb TV picks. Take a moment to review each one so you can make a better decision when you plan to make a purchase.</p><h3>1. Sceptre 50” 4K UHD (U518CV-UM)</h3> <p>Sceptre sells quite a number of dumb TVs as well as smart TVs. This particular one has a large 50-inch screen that supports 4K UHD.</p><p>It also comes with Mobile High-Definition Link (MHL) that allows you to stream videos from your smartphone. Sceptre also boasts about its stunning colors and image contrast.</p><h3 id="title"><span id="productTitle">2. Sceptre 65 inches 4K LED TV (U658CV-UMC)</span></h3><div><div data-aawp-product-id="B0198XNF6U" data-aawp-product-title="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC 2018" data-aawp-click-tracking="true"> <p><span>Sale</span></p><p><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC, 2018" rel="nofollow noopener" target="_blank"> <img src="https://m.media-amazon.com/images/I/41Q8eA+4zwL.jpg" data-src="https://m.media-amazon.com/images/I/41Q8eA+4zwL.jpg" alt="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC, 2018"> </a></p></div></div><p>If you want to step it up, you can opt for the 65-inch 4K UHD TV from Sceptre. It is going to cost you more, but it also comes with additional features.</p><p>It has a bright <a href="https://pointerclicker.com/can-you-use-a-laser-pointer-on-a-tv-screen/" target="_blank" rel="noopener noreferrer">LED display</a> and a sharp contrast. Its UHD upscaling will enhance your SD or HD videos so they display excellently in 4K. It also comes with HDR and MEMC120 to give you the best viewing experience.</p><p>This particular TV also has great connectivity options. HDMI ports, component ports, optical and line audio outputs. You won’t be needing additional ports with this TV.</p><h2><span id="What_is_the_dumb_TV">What is the dumb TV?</span></h2><p>When you walk through the video section in an electronic shop, you’re going to find an array of different TVs. Most of the newer ones you will have large high definition screens. And almost all of them are going to be smart TVs.</p><p>Smart TVs have taken over the home entertainment industry by storm. To the point where it has become more difficult to find one that does not have smart features. TVs lacking smart features are also called dumb TVs.</p><p>Dumb TVs are display screens with a built-in TV tuner. They also come with different input ports where you can input video information from an HDTV antenna, Blu-ray player, etc. The most common input ports are HDMI and AV.</p><p>What makes a dumb TV “dumb”? The difference between a dumb TV and a smart TV is that the former does not come with an operating system. It relies on external devices to convert data into video information that it can display.</p><p>All televisions that were manufactured before the invention of smart TVs are dumb TVs. Dumb TVs are still being manufactured today for various reasons, although they are less popular.</p><p>Smart TVs, on the other hand, are more like smartphones or computers. They come with an operating system and a handful of pre-installed apps. You can connect them directly to the internet and stream videos on YouTube, Netflix, and other popular platforms.</p><h2><span id="Why_do_people_need_a_dumb_TV_without_smart_features">Why do people need a dumb TV without smart features?</span></h2><p>As you learn more about what smart TVs offer, you may start to wonder why anyone would want to settle for a dumb TV. Smart TVs are more convenient, and they offer so many useful features.</p><p>While the popularity of smart TV increases, there are quite a few people who still prefer dumb TVs. There are a few reasons why you might opt to get a dumb TV. Let’s take a closer look at each of those reasons in more detail.</p><h3>Security and privacy</h3><p>When it comes to the internet, security and privacy are huge topics. There have been countless horror stories that resulted from having personal devices connected to the internet. If you’re connected, there is always going to be some sort of risk.</p><p>Smart TVs are said to be one of the most vulnerable to hacking and data theft. The FBI has even issued a warning of the risks.</p><p>One of the reasons for this is that smart TVs use automatic content recognition or ACR. ACR gathers information about what you watch and sends it back to the manufacturer. With this information, more relative ads can be shown when you’re browsing for something to watch.</p><p>Unfortunately, there are times when a third party receives the information captured by ACR. These third parties can do whatever they want with that information.</p><p>Many newer smart TVs also come with webcams and microphones. These can be used by hackers to spy on you while you’re watching your favorite show.</p><p>Many people are aware of the dangers of this. This is one of the main reasons there are still quite a few people who opt to get dumb TVs instead of TVs with smart features.</p><h3>Better set-top and stick options</h3><p>Another reason why people purchase dumb TVs is that they prefer to use other TV stick and set-top devices. These devices don’t cost a lot of money and they often work better than smart TVs.</p><p>A few of the more popular ones are the <span><a href="https://www.amazon.com/dp/B075XLWML4?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Roku Streaming Stick+" target="_blank" rel="nofollow noopener" data-aawp-product-id="B075XLWML4" data-aawp-product-title="Roku Streaming Stick+ | HD/4K/HDR Streaming Device with Long-range Wireless and Voice Remote with TV Controls  updated for 2019" data-aawp-click-tracking="true">Roku Streaming Stick+</a>&nbsp;<a href="https://www.amazon.com/dp/B075XLWML4?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Roku Streaming Stick+" target="_blank" rel="nofollow noopener" data-aawp-product-id="B075XLWML4" data-aawp-product-title="Roku Streaming Stick+ | HD/4K/HDR Streaming Device with Long-range Wireless and Voice Remote with TV Controls  updated for 2019" data-aawp-click-tracking="true"><span></span></a></span>, <span><span>No products found.</span></span>, <span><a href="https://www.amazon.com/dp/B0791TX5P5?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Amazon Fire TV Stick" target="_blank" rel="nofollow noopener" data-aawp-product-id="B0791TX5P5" data-aawp-product-title="Fire TV Stick streaming media player with Alexa built in includes Alexa Voice Remote HD easy set-up released 2019" data-aawp-click-tracking="true">Amazon Fire TV Stick</a>&nbsp;<a href="https://www.amazon.com/dp/B0791TX5P5?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Amazon Fire TV Stick" target="_blank" rel="nofollow noopener" data-aawp-product-id="B0791TX5P5" data-aawp-product-title="Fire TV Stick streaming media player with Alexa built in includes Alexa Voice Remote HD easy set-up released 2019" data-aawp-click-tracking="true"><span></span></a></span>, and <span><span>No products found.</span></span>. There are many more options in the market to choose from.</p><p>These devices connect to your WI-FI and allow you to stream content on popular platforms such as Netflix and YouTube.</p><p>All these devices have seamless UI’s and tons of different apps and features. They also come with <a href="https://pointerclicker.com/presentation-pointers-lcd-tv-screens/" target="_blank" rel="noopener noreferrer">remote controls</a> that support voice commands.</p><p>One feature many people find very useful in these devices is the casting feature. It allows you to use your TV as a larger display for your smartphone. You can play videos, view images, and browse the web on your smartphone and have it cast onto your TV.</p><p>You should also remember that technology is advancing a lot quicker than ever before. Your brand-new smart TV will be outdated in just a couple of years. The only way you’re going to be able to keep up with new features and security fixes is to buy a new TV.</p><p>You won’t need to replace your dumb TV to stay updated. All you need to do is purchase the latest stick or set-top device. You can get brand-new ones that already come with voice control for an affordable price.</p><p>Check out this video to learn more about stick and set-top devices.</p><div title="4K Streaming Device Round Up 2019: Apple TV vs Chromecast vs Roku vs Fire TV, Which is best for you?"><div id="WYL_H2Bq9X3a41A"><div id="lyte_H2Bq9X3a41A" data-src="https://pointerclicker.com/wp-content/plugins/wp-youtube-lyte/lyteCache.php?origThumbUrl=https%3A%2F%2Fi.ytimg.com%2Fvi%2FH2Bq9X3a41A%2Fhqdefault.jpg"><div><p>4K Streaming Device Round Up 2019: Apple TV vs Chromecast vs Roku vs Fire TV, Which is best for you?</p></div></div></div></div><h3>Interface issues on smart TVs</h3><p>When you use your smartphone or computer, you have two main input sources: pointing and typing. You don’t have either of those in a smart TV interface.</p><p>For the most part, you will use your TV’s remote to click through menus and an onscreen keyboard for typing. It will take you quite a number of button presses to type something into your TV’s search service.</p><p>Some smart TVs also come with poorly designed interfaces. It will take a lot of time trying to navigate around the interface.</p><p>On the other hand, the interfaces that come with newer sticks and set-box devices are more seamless. They also include voice commands and many support keyboard input from your smartphone.</p><h3>Unreliable apps on smart TVs</h3><p>App developers today need to work harder when it comes to compatibility. They need to make sure apps work well with smartphones, browsers, stick and set-top devices, smart TVs and more. Unfortunately, smart TVs are often the last priority.</p><p>This leaves smart TVs with unreliable apps that may crash or freeze. Older smart TVs may also not be compatible with app updates.</p><h2><span id="Conclusion">Conclusion</span></h2><p>Although smart TVs are the most popular choice, there are still a few reasons why you might opt to get a dumb TV. The good news is that there are still quite a few of them being manufactured.</p><p>It may be more challenging to find a good dumb TV, but there’s a good chance a few of them are being sold at your nearest electronics shop. If you want more options, finding them online will be your best bet.</p><p>You can check out online shops such as Amazon, BestBuy, Walmart, and Costco. You may also visit manufacturer websites and look through their …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pointerclicker.com/best-dumb-tv/">https://pointerclicker.com/best-dumb-tv/</a></em></p>]]>
            </description>
            <link>https://pointerclicker.com/best-dumb-tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666968</guid>
            <pubDate>Fri, 02 Oct 2020 20:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Hiring 101: A Founder's Guide]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24666580">thread link</a>) | @ivankirigin
<br/>
October 2, 2020 | https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f | <a href="https://web.archive.org/web/*/https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666580</guid>
            <pubDate>Fri, 02 Oct 2020 20:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Fungi Can Teach Us a New Way of Looking at the World”]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24666521">thread link</a>) | @jseliger
<br/>
October 2, 2020 | https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;14a48b6b-06ab-4edb-83c8-8a827e78971b&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;e208f5ee-a7c5-475b-826e-95abf94f2a5d&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w948_r1.77_fpx39.41_fpy49.97.jpg" srcset="https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w520_r1.77_fpx39.41_fpy49.97.jpg 520w, https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w948_r1.77_fpx39.41_fpy49.97.jpg 948w" width="948" height="536" sizes="948px" title="Merlin Sheldrake: &quot;When food becomes scarce, they some fungi can switch to a hunting mode.&quot;" alt="Merlin Sheldrake: &quot;When food becomes scarce, they some fungi can switch to a hunting mode.&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Merlin Sheldrake:</strong> "When food becomes scarce, they some fungi can switch to a hunting mode."</p>
<span>
Foto: Andrea Artz / DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p><em>Merlin Sheldrake, 32, earned his Ph.D. in tropical ecology at the University of Cambridge for his research into underground fungal networks in the tropical forests of Panama. Since then, he has not lost his fascination for them. He is the author of "Entangled Life: How Fungi Make Our Worlds, Change Our Minds and Shape Our Futures," which was published in early September.</em></p>


<div>
<p><strong>DER SPIEGEL:</strong> Dr. Sheldrake, we are here in London's Hampstead Heath. This place, you write in your book, means more to you than any other. Why is that?</p><p><strong>Sheldrake:</strong>&nbsp;I grew up here. This is where I learned to walk. Later, I climbed trees here, and still later, I had parties with friends. And my interest in nature has been incubated by this place.</p><p><strong>DER SPIEGEL:&nbsp;</strong>Your interest in nature in general, or fungi in particular?</p><p><strong>Sheldrake:&nbsp;</strong>Both. I've always been particularly interested in how things transform, how they grow and decompose. I was amazed how piles of leaves disappear over time. How did this transformation come about without me being able to see anything? Composting, I understood, is largely the work of fungi.</p>
</div>

<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>For most people, nature is primarily made up of plants and animals. What role do fungi play in between those two realms?</p><p><strong>Sheldrake:&nbsp;</strong>Fungi are of enormous importance. The basic principle of ecology is the relationships between organisms - and fungi form connections between organisms and so embody this idea.</p><p><strong>DER SPIEGEL:&nbsp;</strong>If fungi are so important, why don’t we see them all over the place?</p><p><strong>Sheldrake:</strong>&nbsp;Oh, fungi are everywhere. Just take this leaf: Between tens and hundreds of species of fungi live on and in it. No plant has ever been found in nature which does not have fungi in its leaves and in its shoots. Or take the roots of the grass we are walking on, the rotting twigs, the soil under our feet: There are fungi everywhere. You have yeast all over your body, in the lining of your ears, in your nostrils. Even in the air: At this moment, you are breathing fungi. Fifty million tons of fungal spores are floating in the atmosphere, the largest source of living particles in the air. And they change the weather by causing water droplets to form.</p>
</div>


<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>If fungi are so ubiquitous, why we know so little about them?</p><p><strong>Sheldrake:</strong>&nbsp;There are many reasons. The most obvious one is access. The fungus we see is nothing more than the fruit of the organism itself. The mycelium network that belongs to it is buried in the ground. It is as if we only saw acorns for one moment every year, but we couldn't see the magnificent oak trees.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Do even scientists underestimate the importance of fungi?</p><p><strong>Sheldrake:</strong>&nbsp;They did so for a long time, at least. Until the 1960s, fungi were thought to be plants. Only then did they gain taxonomical independence. The new sequencing techniques have changed that. Today, we can read the DNA in every teaspoon of soil and find out who is there.</p>
</div>


<section data-area="contentbox">
<div>
<p><span>DER SPIEGEL 39/2020</span></p><figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;687fbdda-37fe-4667-85e5-e628ba61d3c0&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>And? What does one find?</p><p><strong>Sheldrake:</strong>&nbsp;The kingdom of fungi is vast. There are six times more species of fungi than of plants, and only 6 to 8 percent of them have even been described. We still know so little! ! Just one thing is clear: There are many ways to be a fungus.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is perhaps the lack of appreciation for fungi because of the fact that they are not very nutritious and often even poisonous?</p><p><strong>Sheldrake:</strong>&nbsp;Many people think like that. But in fact, many mushrooms contain important minerals and they have a high content of antioxidants. They produce an amazing variety of substances that affect cancer, viruses or our immune system. And mushrooms are high in protein. Truffles are a good example of an edible fungus. After all, they want to be eaten. Truffles sit deep in the ground where no wind can spread their spores. They attract animals with a very subtle mixture of odors, so that these animals then eat them and spread their spores.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Some mushrooms lure us with substances that have a direct effect on our consciousness ...</p><p><strong>Sheldrake:</strong>&nbsp;Yes, about 200 fungal species contain psilocybin, a substance that people have been interested in because of its strong psychedelic effects.</p>
</div>

<div>
<p><strong>DER SPIEGEL:</strong>&nbsp;Such mushrooms cause hallucination and change the way we think. How do mushrooms benefit from making psychedelic drugs for humans?</p><p><strong>Sheldrake:</strong>&nbsp;We don’t know. The first mushrooms to make psilocybin lived 75 million years ago, long before humans arose. But the receptors that this substance binds to can also be found in many animals. Does psilocybin change the behavior of certain insects in a way that induces them to spread fungal spores? Or do they change the behavior of insects in a way that deters them from eating the mushrooms?</p><p><strong>DER SPIEGEL:</strong>&nbsp;Have you personally tried the effects of psychedelic mushrooms?</p><p><strong>Sheldrake:</strong>&nbsp;Yes, under their influence I realized that most of my consciousness was unknown to me. It was as if I had spent my life in a garden until then, and now I suddenly discovered that this garden has a gate through which I can enter a strange and wonderful forest, that was largely unknown to me.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Does the gate disappear once the effects of psilocybin fade away?</p><p><strong>Sheldrake:</strong>&nbsp;Not necessarily. Once you know that this forest exists, it is much easier to find your way into it.</p><p><strong>DER SPIEGEL:</strong>&nbsp;You even took part in a scientific study.</p><p><strong>Sheldrake:</strong>&nbsp;Yes, though it was LSD tested in that study. But both substances have similar effects. Among other things, it was to be examined whether LSD promotes creativity. Each participant had to name a problem they were currently working on and, under the influence of LSD, &nbsp;we were to try to solve that problem.</p><p><strong>DER SPIEGEL:</strong>&nbsp;And?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp; I found the effects of LSD very helpful in allowing me to approach questions from new angles and imagine the relationships between plant and fungus from different points of view.</p><p><strong>DER SPIEGEL:</strong>&nbsp;You attribute cognitive abilities to fungi. What makes you think so?</p><p><strong>Sheldrake:</strong>&nbsp;I've been thinking about this for a while. I'm interested in the way fungi perceive their environment and how they react to it. Information is continuously flowing through their decentralized bodies.</p><p><strong>DER SPIEGEL:</strong>&nbsp;What do fungi perceive?</p><p><strong>Sheldrake:</strong>&nbsp;Most importantly, they have extremely diverse chemical sensors. A fungus can be seen as a large, chemically sensitive membrane, so to speak, as one big olfactory epithelium. But many mushrooms can also perceive light and they are sensitive to gravity, to changes in temperature and to changes in pressure.</p><p><strong>DER SPIEGEL:</strong>&nbsp;So the fungi under our feet can sense that we are here?</p><p><strong>Sheldrake:</strong> Some fungi would detect the pressure of our steps, yes. And now the question is, how do they process all this information without a brain and how do they translate it into behavior, into action?</p><p><strong>DER SPIEGEL:</strong>&nbsp;Action? Behavior? What do fungi do?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp;Fungi are quite active. Take hunting, for example.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Excuse me? Mushrooms can hunt?</p><p><strong>Sheldrake:</strong>&nbsp;Yes. When food becomes scarce, some fungi can switch to a hunting mode. They build traps consisting of sticky loops or poisonous droplets. And with special substances, they lure nematodes into these traps.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is this really "behavior" of the kind we see in animals?</p><p><strong>Sheldrake:</strong>&nbsp;Well, we can run away from danger, fungi have to face it. Therefore, they defend themselves with the help of chemicals, or they regenerate. But that doesn't change the fact that fungi do make decisions, just as we do.</p><p><strong>DER SPIEGEL:</strong>&nbsp;What kind of decisions?</p><p><strong>Sheldrake:</strong>&nbsp;Fungi have many options: where to grow, what to eat, what nutrients to transport, whether to withdraw and when to hunt nematodes. Each fungus forms thousands of so-called hyphae - tiny tubes that can either grow, divide or fuse.</p><p><strong>DER SPIEGEL:</strong>&nbsp;If fungi make decisions, are they also capable of solving problems?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp;Absolutely. For example, their growth follows very efficient navigation algorithms. There are various experiments in which fungi very rapidly found the shortest route through a maze.</p><p><strong>DER SPIEGEL:</strong>&nbsp;If fungi are, as you claim, complex information processing networks, are they essentially a kind of brain?</p><p><strong>Sheldrake:</strong>&nbsp;No, I wouldn’t say that. But you are right: Neurons are tip-growing, electrically excitable, network-forming cells. And so are fungal cells.</p><p><strong>DER SPIEGEL:</strong>&nbsp;So mushrooms have a form of intelligence?</p><p><strong>Sheldrake:</strong>&nbsp;It depends on your definition of "intelligence." In a broad sense, all organisms show intelligence, albeit to different degrees. The study of cognition and intelligence arose from the study of the human mind. This resulted in a very human- and brain-centered view. I find it refreshing to extend these considerations to organisms that do not have brains. We shouldn't use ourselves as the yardstick to judge everything else in this world.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is there still a lot to discover in the field of fungi cognition?</p><p><strong>Sheldrake:&nbsp;</strong>Absolutely. Little is known about how fungi coordinate their behavior. We don't know the mechanisms by which they pass signals around. We've not fully understood the basic biology of mycelial growth.</p>
</div>

<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>But we do know a lot about the symbiotic relationship between mushrooms and plants …</p><p><strong>Sheldrake:&nbsp;</strong>… exactly, via the mycorrhiza, through which the fungus supplies the plant with minerals such as nitrogen and phosphorus, and the plant in turn provides the fungus with energy-rich sugars.</p><p><strong>DER SPIEGEL:</strong>&nbsp;How important is this symbiosis? If all fungi were wiped out in this forest floor, could the trees survive?</p><p><strong>Sheldrake:</strong>&nbsp;No. They would be prone to disease, just as we would be if it weren't for the bacteria in our intestines. This microbiome keeps us healthy. In this sense, soil is sort of the gut of our planet.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Many ecologists are enthusiastic about the "Wood Wide Web," by which trees are mysteriously connected via the fungi in the soil and allegedly even communicate via this …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f">https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666521</guid>
            <pubDate>Fri, 02 Oct 2020 20:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data from 70 Offer Negotiations Using a Career Agent]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665710">thread link</a>) | @brianliou91
<br/>
October 2, 2020 | https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary | <a href="https://web.archive.org/web/*/https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>Consider two graduating PhDs who are transitioning into industry. Both are incredibly busy finishing their research, writing their dissertation, and teaching. Both spend the same amount of time recruiting for industry roles - and both join the same company in a similar role. PhD #1, let’s call her Jane,  soon discovers she is being paid less than her peers for the same work and has a boss that won’t promote her. She’s forced to work doubly hard just to achieve parity with her co-workers, or else leave and start over somewhere new, wasting a year. PhD #2, let’s call her Joanne, in contrast, is happy with her job. She is paid similarly to her peers and has a clear path for growth at the company. What did Joanne do better?</p><p>We have now advised 71 PhDs to follow this second, better track and we understand what defines these trajectories. We hope this salary negotiation report educates similar individuals how to negotiate salary. The difference between these two individuals is not merit, nor is it about who interviewed better or does better work. The difference is in how they think and negotiate. Joanne understands that she is joining a business. Compensation and promotions are respectfully taken by her self-advocacy, not given by the company. Jane assumes that the company will take care of her once she proves herself and so does not ask for much at the beginning. Joanne sets expectations and gives feedback to her manager for a productive working relationship. This is a <em>virtuous</em> cycle: you ask and your manager sets the higher expectations that enable you to work upwards. Jane is reticent and does not want to damage relationships. This is a <em>vicious</em> cycle: you don’t ask and your manager doesn’t expect more, so you stagnate and it becomes even harder to advance. </p><p>This power of setting expectations is evident at the very beginning of your relationship with your employer, in the offer negotiation. You haven’t started work yet, but simply setting higher expectations from the outset enables you to get paid more and begins the positive, virtuous cycle. Here we quantify the impact of negotiating using Ralph by looking at the data from our first 71 PhD clients. Most of them came from computation-heavy PhDs and were transitioning into their first industry role in engineering or data science, or a research role in technology or quantitative finance. Our results reveal just how beneficial it can be to advocate for yourself, and how beneficial a Career Agent can be to advise you through this process of multiple offers and changes. Because while most people know they <em>should</em> negotiate, they don’t know how <em>far</em> to negotiate. Our data gives you insight into just how much you’re worth and how much room there is for offer changes. </p><p><img src="https://landen.imgix.net/blog_VkwwMuKsXVDkwaYZ/assets/KnTGkpeVnsGRSckK.jpg" alt="Tables.jpg"></p><p><img src="https://landen.imgix.net/blog_VkwwMuKsXVDkwaYZ/assets/uOGQqqzabfskEZzm.jpg" alt="Visualizations.jpg"></p><p><strong>High Level Results</strong></p><p>On average, our clients have increased their initial offer by 30% through negotiation using our insight and advising. This increase is calculated from changes in base salary, equity, and any annual, signing, or relocation bonus changes. This increase represents an average $75K more in the offer. As expected, having offers from multiple companies resulted in a larger increase from the baseline offer; however, even if clients only had an offer from a single company, they were still able to secure an average 20% increase from their initial offer. Having four offers resulted in a dramatic increase (56%) in the negotiated accepted offer.&nbsp;</p><p><strong>Negotiating You Are Likely Not Doing</strong></p><p>The majority of our clients (52%) changed their offer twice. This means they negotiated an increase once and then negotiated <strong>another</strong> increase. Usually this second change would occur after the company said no to any further changes. We were able to advise our clients to keep advocating for themselves and set initial expectations high, resulting in an average total increase of 39%.  When the offer changed once, it increased on average 18%. While the majority of this data comes from before COVID-19, we have advised 9 clients during COVID-19 with similar results. Our largest negotiated offer ever was achieved in March 2020 (<a href="https://www.withralph.com/blog/negotiated-a-143-offer-increase">the story here</a>). Our data from working with 70+ clients is clear: you can negotiate significant (and often multiple) increases in your offer if you know your true, competitive worth.&nbsp;</p><p>These results we hope debunk three common misconceptions that hinder a candidates' ability to negotiate a strong starting offer and set the stage for your upward growth.&nbsp;</p><p><strong>Misconception #1: Companies pay equally for the same role, level, and location in a new grad offer.</strong></p><p>We have seen two candidates with the same role, level, company, and location have a $35,000 base salary difference. We have seen equity range by more than $900,000 in a 4-year package in public company offers. We have data for new grad Google offers that start as low as ~$180K/year and end as high as ~$550K/year.</p><p>Even independent of a company's intent, if you don't negotiate you will be paid unequally because the highest paid individuals are always negotiating. The squeaky wheel gets the oil. </p><p><strong>Misconception #2: Interviewing with one company at a time is ok.</strong></p><p>The factor that affects your compensation the most is having multiple offers at the same time. Companies are a business. They will pay what they have to, not what they can. Our data shows having two offers increases your compensation by 5% and 4 offers increases your compensation by 56%.&nbsp;Companies interview candidates they have no intention of hiring just to see the market. So should you.</p><p><strong>Misconception #3: The company increased my offer so I’ve successfully negotiated.</strong></p><p>The majority of companies start with a low offer that leaves room for the candidate to negotiate. You should define successfully negotiating as getting a change <strong>after</strong> the company has said no. This is when the negotiation has actually begun. Otherwise, you have just asked and they conceded. There has been no negotiation. Our data shows that it is rare for an offer <strong>not</strong> to change after it is initially given: 90% of offers change from the initial offer after negotiating.</p><p>Almost all of the negotiation challenges PhDs face come from a lack of information and experience in industry. They don’t know what to expect, don’t have time to research, and assume whatever the company says is correct. As our data shows, there is room for negotiating multiple times to achieve a 30% or greater increase in your initial offer. We hope that by sharing our findings, we can help you educate and advocate for yourself and feel more confident to set high expectations even before you begin working at your company. Ask yourself the question: <strong>how do I know I am getting the best offer possible?</strong> You might be surprised to know that you are likely worth a lot more than the initial offer you receive. </p><p>--</p><p>To read more content: <a href="https://www.withralph.com/blog/where-to-start">start here</a></p><p><a href="https://www.withralph.com/blog/where-to-start"></a>To get updated with insights and learnings: <a href="https://www.linkedin.com/company/ralph-inc">Follow us on LinkedIn</a></p><p>Questions? Email hi@withralph.com</p></div></div></div></div>]]>
            </description>
            <link>https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665710</guid>
            <pubDate>Fri, 02 Oct 2020 18:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientists develop 'super enzyme' that breaks down plastic faster than ever]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24664510">thread link</a>) | @soperj
<br/>
October 2, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A team of international scientists have developed what they call a "super enzyme" that can break down plastic into is original building blocks so it can be recycled infinitely.&nbsp;</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5746639.1601578207!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1190912666.jpg"></p></div><figcaption>Plastic waste litters the shoreline in Koattey wetlands on Dec. 14, 2019, in Hithadhoo, Maldives.<!-- --> <!-- -->(Carl Court/Getty Images)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Scientists develop 'super enzyme' that breaks down plastic faster than ever"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/91/606/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>6:33</span><span>Scientists develop 'super enzyme' that breaks down plastic faster than ever</span></p></div></div></div></span></p><p><span><p><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/october-1-2020-episode-transcript-1.5748666">Read Story Transcript</a></p>  <p>A team of international scientists have developed what they call a "super enzyme" that can break down plastic into its original building blocks so it can be recycled infinitely.&nbsp;</p>  <p>The team, <a href="https://www.cbc.ca/news/technology/plastic-eating-enzyme-pollution-1.4622923">which made waves in 2018 for engineering&nbsp;a plastic-eating enzyme</a>,&nbsp;has&nbsp;now combined it with a second enzyme to create&nbsp;a "<a href="https://www.eurekalert.org/pub_releases/2020-09/uop-pe092520.php">cocktail</a>" that can break down plastic six times faster.</p>  <p>"The enzymes are really specific to certain types of bonds in the molecular structure of the plastic. This means that it breaks it down into the same starting materials that were used to make the product to begin with," Erika Erickson, a bioengineering researcher at the U.S. Department of Energy's&nbsp;National Renewable Energy Laboratory (NERL), told <em>As It Happens </em>host Carol Off.&nbsp;</p>  <p>"So instead of having an inferior product in the end, you could start with the same starting materials and come back to an equal value plastic water bottle or food package, etc., on&nbsp;the other side, without needing to use petroleum products to get there."</p>  <p>The findings were <a href="https://www.eurekalert.org/pub_releases/2020-09/uop-pe092520.php">published this week in the journal Proceedings of the National Academy of Sciences.</a></p>  <h2>Nature finds a way — and scientists speed it up&nbsp;</h2>  <p>The whole thing began when scientists at NERL and Britain's University of Portsmouth discovered a naturally occurring enzyme in a waste recycling centre in Japan that was helping bacteria break down&nbsp;polyethylene terephthalate&nbsp;(PET), a common plastic developed in the '40s that's used to make&nbsp;water bottles, food packaging, film and more.&nbsp;</p>  <p>"There are natural enzymes that have been evolved to break down plastic," Erickson said. "And if you think about that, it's quite extraordinary that an organism has been able to do this in such a short amount of time."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/plastic-eating-enzymes.jpeg 300w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/plastic-eating-enzymes.jpeg 460w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/plastic-eating-enzymes.jpeg 620w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/plastic-eating-enzymes.jpeg 780w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/plastic-eating-enzymes.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/plastic-eating-enzymes.jpeg"></p></div><figcaption>Researchers from Britain's University of Portsmouth and the U.S. Department of Energy's National Renewable Energy Laboratory have combined two plastic-eating enzymes to create what they call a 'super enzyme.'<!-- --> <!-- -->(University of Portsmouth)</figcaption></figure></span></p>  <p>However, the natural process is a slow one. So the scientists tweaked the enzyme by adding amino acids to speed things up.</p>  <p>The resulting&nbsp;engineered enzyme, called&nbsp;PETase, could break down&nbsp;one water bottle in a couple months, Erickson estimated — a big step up from the hundreds of years it takes to break down in nature.</p>    <p>Now the team has combined&nbsp;PETase&nbsp;with a second enzyme from the same garbage eating bacteria, called MHETase, making the process even faster. The new super enzyme, Erickson&nbsp;said, could potentially break down one bottle in as little as six weeks.&nbsp;</p>  <p>She admits that's still "a little bit too slow for a real recycling process," but says it's a major step forward to creating a commercially viable system.&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/erika-erickson.JPG 300w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/erika-erickson.JPG 460w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/erika-erickson.JPG 620w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/erika-erickson.JPG 780w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/erika-erickson.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/erika-erickson.JPG"></p></div><figcaption>Erika Erickson is postdoctoral researcher in bioengineering a the U.S. Department of Energy's National Renewable Energy Laboratory.<!-- --> <!-- -->(Werner Slocum/NREL)</figcaption></figure></span></p>  <p>The way plastic is recycled now is not very efficient or cost-effective, says Erickson.</p>  <p>"In&nbsp;mechanical recycling, the plastic gets ground down into small pieces and then melted and then reformed into a new product," she said.</p>  <p>"But in the process of doing that, all of the contaminated dirt or food products or other types of plastic get mixed into that. So the quality of the recycled good is usually quite low compared to the original."</p>  <p>With an enzymatic approach, however, the plastic is recycled in its entirety&nbsp;— turning a bottle, for example, back into the same material used to make the bottle, and potentially creating an infinite loop of recycling.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/996523044.jpg 300w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/996523044.jpg 460w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/996523044.jpg 620w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/996523044.jpg 780w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/996523044.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/996523044.jpg"></p></div><figcaption>Workers sort recycling material at the Waste Management Material Recovery Facility in Elkridge, Md.<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Another big problem with modern recycling is the amount of energy used to collect materials and deliver them to a central location for sorting.&nbsp;</p>  <p>"That won't necessarily be a problem that disappears with a new strategy for recycling," Erickson said.</p>  <p>"The difference, however, would be that the embedded use of fossil fuels for the extraction of petroleum from the Earth, you would lose a lot of that, which is also quite costly.... If we could separate some of the products that we use from that cycle, then the greenhouse gas emissions and fossil fuel utilization would be lower."</p>  <h2>Technology helps — but people have to step up&nbsp;</h2>  <p>The team has touted the potential of this method to one day revolutionize recycling, should it be developed on a commercial scale.&nbsp;</p>  <p>But Erickson notes that technology alone won't fix the problem of plastic pollution.</p>    <p>"It's difficult to convey the ability to sort of shirk off responsibility for our daily choices toward this kind of technology in general&nbsp;…&nbsp;each of us&nbsp;can make a difference in our daily choices," she said.</p>  <p>"And so I hope that people both understand that [with this]&nbsp;technology, we're hoping we can we can make some big impacts and in good directions, but it still comes down to individual choices."</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Menaka Raman-Wilms and Kate Cornick.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664510</guid>
            <pubDate>Fri, 02 Oct 2020 16:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Security Hardening and Other Tweaks]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24664507">thread link</a>) | @aytekat
<br/>
October 2, 2020 | https://vez.mrsk.me/linux-hardening.html#hn | <a href="https://web.archive.org/web/*/https://vez.mrsk.me/linux-hardening.html#hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<strong>Linux Security Hardening and Other Tweaks</strong>
<hr>

<p>
Last updated: 08/18/2020,
by <a href="https://twitter.com/blakkheim">@blakkheim</a>

</p><p>
This page lists the changes I make to a vanilla install of Arch Linux
for security hardening, as well as some other changes I find useful.
While Arch is my target platform, most of the changes will work on
any Linux system that's reasonably up to date.

</p><p>
I typically favor security over performance. You may also see suggestions
merely to make something more useful or shave precious seconds off
a wait time. It's not a one-size-fits-all setup, but hopefully certain
pieces of it will be useful.

</p><p>
Arch is worth considering for a few reasons:

</p><ul>
<li><strong>The install size:</strong> The base install is relatively minimal
    compared to a "prebuilt" distro like Fedora or Mint. This lets me focus
    on adding just what I want, rather than constantly trying to strip out
    things I don't need.
</li><li><strong>The kernel:</strong> A common misconception about the Linux
    kernel is that it's secure, or that one can go a long time without
    worrying about kernel security updates. Neither of these are even
    remotely true. New versions of Linux are released almost every week,
    often containing security fixes buried among the many other changes.
    These releases typically
    <a href="https://youtu.be/5PmHRSeA2c8?t=4075">don't</a> make explicit
    mention of the changes having security implications. As a result, many
    "stable" or "LTS" distributions don't know
    <a href="https://web.archive.org/web/20200623161340/https://www.openwall.com/lists/oss-security/2020/06/23/2">which commits</a> should be
    backported to their old kernels, or even that something needs backporting
    at all. If the problem has a public CVE assigned to it, maybe your distro
    will pick it up. Maybe not. Even if a CVE exists, at least in the case
    of Ubuntu and Debian especially, users are often left with kernels full
    of <a href="https://security-tracker.debian.org/tracker/source-package/linux">known holes</a>
    for months at a time. Arch doesn't play the backporting game, instead
    opting to provide the newest stable releases shortly after they come out.
</li><li><strong>The <a href="https://wiki.archlinux.org/index.php/Arch_Build_System">Arch Build System</a></strong>:
    Having enjoyed the
    <a href="https://en.wikipedia.org/wiki/Ports_collection">ports</a>
    system of <a href="https://vez.mrsk.me/freebsd-defaults.html">FreeBSD</a>
    and <a href="https://www.openbsd.org/">OpenBSD</a> for a long time, the ABS
    has been a pleasure to use. It makes building/rebuilding packages easy.
    It makes updating packages easy. It shows how things are actually built
    and with what options. This BSD-borrowed concept makes interacting with
    the package system simple and intuitive.
</li></ul>

Now on to how I set things up.

<hr>
<p>

<strong>Security Hardening</strong>
</p><ul>
  <li><a href="#disks">Disk Layout</a>
  </li><li><a href="#pacman">Pacman</a>
  </li><li><a href="#kern">Kernel Options</a>
  </li><li><a href="#fw">Firewall</a>
  </li><li><a href="#sudo">Sudo</a>
  </li><li><a href="#firejail">Application Sandboxing</a>
  </li><li><a href="#rfk">RFKill (Disable WiFi / Bluetooth)</a>
</li></ul>

<strong>Other Tweaks</strong>
<ul>
  <li><a href="#ntp">NTP (Network Time Protocol)</a>
  </li><li><a href="#mkinit">mkinitcpio</a>
  <!--
  <li><a href="#login"    >Automatic Login</a>
  -->
  </li><li><a href="#pulse">PulseAudio</a>
  </li><li><a href="#misc">Miscellaneous</a>
  </li><li><a href="#closing">Closing</a>
</li></ul>

<hr>

<h2 id="disks">Disk Layout</h2>

This section contains a few tips to consider during your initial disk layout
creation. The concepts should apply to any distrbution.

<p>
To start, consider using
<a href="https://wiki.archlinux.org/index.php/Dm-crypt/Encrypting_an_entire_system">full disk encryption</a>
along with a
<a href="https://wiki.archlinux.org/index.php/LVM">Logical Volume Manager</a>
setup. Disk encryption protects data at rest, while LVM allows for some
flexibility that can be quite useful. A simple disk layout might look like
this:

</p><ul>
<li><code>/dev/sda1</code> (a small, unencrypted
<a href="https://wiki.archlinux.org/index.php/EFI_system_partition">EFI System Partition</a>,
FAT32)
mounted at <code>/efi</code> (assuming this is
a PC with UEFI, otherwise not needed)
</li><li><code>/dev/sda2</code> (a small, unencrypted ext4 partition)
mounted at <code>/boot</code>.
</li><li><code>/dev/sda3</code> (using the rest of the drive space)
as the encrypted
<a href="https://wiki.archlinux.org/index.php/Dm-crypt">LUKS</a> container
for LVM
</li></ul>

Splitting up the logical volumes for different mount points provides some
benefits, including the ability to set mount flags on specific directories.
Consider creating separate logical volumes for <code>/</code>,
<code>/var</code>, and <code>/home</code> in the install. For a typical
desktop, you probably want to give <code>/home</code> most of the disk space.
The other two don't need much unless there's a specific use case in mind.
25GB and 8GB are used in this example. If you need to have a huge database
in <code>/var</code> or something, make adjustments accordingly.

<p>
There are a lot of user-writable directories in Linux, each one providing
an opportunity for attackers to execute their own binaries.
Once the <a href="https://wiki.archlinux.org/index.php/Fstab">fstab</a>
file is created, add the <code>noexec</code> and <code>nodev</code> flags
to <code>/var</code> and <code>/home</code>. Doing so will disallow execution
of binaries on these mount points, as well as prevent interpreting character
or block special devices on them. Two temporary filesystems (<code>/tmp</code>
and <code>/dev/shm</code>) can also be locked down with the same flags by
adding the following:

</p><pre># /etc/fstab
[...]
tmpfs /tmp     tmpfs rw,noexec,nodev,size=1G,mode=1777 0 0
tmpfs /dev/shm tmpfs rw,noexec,nodev,size=1G 0 0
</pre>

Adjust the <code>1G</code> size limit value as desired.

<p>
Once booted into the finished installation, it should look something like this:

</p><pre># <strong>lvs</strong>
  LV   VG   Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  home lvm  -wi-ao---- 189.12g                                                    
  root lvm  -wi-ao----  25.00g                                                    
  var  lvm  -wi-ao----   8.00g                                                    
# <strong>mount | egrep '(lvm|/tmp|shm)' | sort</strong>
/dev/mapper/lvm-home on /home type ext4 (rw,nodev,noexec,relatime)
/dev/mapper/lvm-root on / type ext4 (rw,relatime)
/dev/mapper/lvm-var on /var type ext4 (rw,nodev,noexec,relatime)
tmpfs on /dev/shm type tmpfs (rw,nodev,noexec,size=1048576k)
tmpfs on /tmp type tmpfs (rw,nodev,noexec,relatime,size=1048576k)
</pre>

Another user-writable directory to consider is <code>/run</code>, specifically
the <code>/run/user/$UID</code> directories that systemd spawns when someone
logs in, but their transience is
<a href="https://lists.freedesktop.org/archives/systemd-devel/2015-February/028429.html">annoying</a>
and <a href="https://lwn.net/Articles/436012/">complicated</a>.
I have yet to find the perfect solution there that won't break other things.
<a href="https://wiki.archlinux.org/index.php/FUSE">FUSE</a> is another way
for non-root users to create new mount points and execute binaries. If FUSE
functionality isn't needed, the kernel module can be
<a href="https://wiki.archlinux.org/index.php/Kernel_module#Blacklisting">blacklisted</a>.

<hr>

<h2 id="pacman">Pacman</h2>

Package managers usually don't need much additional configuration.
<a href="https://wiki.archlinux.org/index.php/Pacman">Pacman</a>, the one
Arch uses, is no different. My recommendation for any package manager is
simply to make sure that
<a href="https://web.archive.org/web/20200528161634/https://blog.packagecloud.io/eng/2018/02/21/attacks-against-secure-apt-repositories/">only HTTPS mirrors</a>
are used.

<pre># /etc/pacman.d/mirrorlist

Server = <strong>https</strong>://example.com/[...]/$repo/os/$arch
</pre>

Check the
<a href="https://www.archlinux.org/mirrorlist/all/https/">mirrorlist
generator</a> to see a list of TLS-capable servers near you.

<p>
Using an HTTPS mirror with Pacman is especially important because it
<a href="https://security.archlinux.org/package/pacman">doesn't validate</a>
the package database files and it
<a href="https://en.wikipedia.org/wiki/Privilege_separation">runs everything as root</a>.
HTTPS doesn't mitigate either of these problems, but it is one line of defense
against a MITM attack. I hope the developers will make fixing these two
security issues a priority for the project soon. Other package managers
have been doing it the right way for a long time.

</p><hr>

<h2 id="kern">Kernel Options</h2>

The
<a href="https://www.archlinux.org/packages/extra/x86_64/linux-hardened/">linux-hardened</a>
kernel package in Arch includes some compile-time security improvements
that can't be set at runtime.
If your distribution doesn't have a package for it, applying the
<a href="https://github.com/anthraxx/linux-hardened/releases">patchset</a>
to upstream sources and building your own kernel is pretty easy. If you go
that route, have a look at the
<a href="https://github.com/a13xp0p0v/kconfig-hardened-check">kconfig-hardened-check</a>
script for more compile-time settings to consider.

<!--
<p>
The main issue I've found with linux-hardened is that it's often outdated.
Upstream Linux development moves quickly, so out-of-tree patches will always
require extra work to maintain. Why the (relatively small) patches aren't
upstreamed is unknown to me. There are times when linux-hardened is lagging
multiple versions behind the latest kernel, thus missing out on many
important security fixes. In such a situation, the user must choose between
a more secure kernel with known vulnerabilities and a less secure kernel
with fewer known vulnerabilities. Not a great situation.
-->

<p>
Runtime configuration of the kernel can be done in a number of ways.
Desired flags may be passed on startup in the form of
<a href="https://wiki.archlinux.org/index.php/Kernel_parameters">kernel parameters</a>,
of which there is an
<a href="https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt">extensive list</a>.
Parameters are usually passed by the
<a href="https://wiki.archlinux.org/index.php/Bootloader#Boot_loader">bootloader</a>, so
<a href="https://wiki.archlinux.org/index.php/Kernel_parameters#Configuration">configuration details</a>
vary depending whether the system uses
<a href="https://wiki.archlinux.org/index.php/GRUB">GRUB</a>,
<a href="https://wiki.archlinux.org/index.php/Systemd-boot">systemd-boot</a>,
or something else.

</p><p>
The following options, split up into categories, are worth considering for
security improvements:

</p><pre>l1tf=full,force
spec_store_bypass_disable=on
spectre_v2=on
</pre>

These are addtional mitigations for certain CPU security flaws.
While the <code>mitigations=auto</code> option is used by default in upstream
Linux, some of the mitigations it enables have been "toned down" for
performance reasons.
Examples of this include the
<a href="https://en.wikipedia.org/wiki/Foreshadow_(security_vulnerability)">L1TF</a>
and
<a href="https://en.wikipedia.org/wiki/Microarchitectural_Data_Sampling">Microarchitectural Data Sampling</a>
vulnerabilities, which can't be fully mitigated unless HyperThreading
is disabled.
The
<a href="https://en.wikipedia.org/wiki/Speculative_Store_Bypass">Speculative Store Bypass</a>
vulnerability is only partially mitigated by default, with applications being
allowed to opt-in for protections via prctl or seccomp.
Finally, we enable all mitigations (including those against userspace) for
<a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)">Spectre V2</a>.

<pre>apparmor=1
lsm=lockdown,yama,apparmor
lockdown=<span color="#ff0000"><strong>XXX</strong></span>
</pre>

These enable the
<a href="https://wiki.archlinux.org/index.php/AppArmor">AppArmor</a>, 
<a href="https://www.kernel.org/doc/Documentation/security/Yama.txt">Yama</a>,
and
<a href="https://web.archive.org/web/20200525014035/https://mjg59.dreamwidth.org/55105.html">Lockdown</a>
features, with the lockdown mode left for the reader to choose.
Valid options are <code>integrity</code> and <code>confidentiality</code>,
both described briefly
<a href="https://wiki.archlinux.org/index.php/Security#Kernel_lockdown_mode">here</a>.
Replace <code><strong><span color="#ff0000">XXX</span></strong></code> with
whichever you see fit, or omit this option entirely if the feature isn't
wanted.

<p>
For what it's worth, running in <code>confidentiality</code> mode on my
desktop hasn't caused any problems. Your mileage and use case may vary.
Lockdown will break suspend-to-disk and any out-of-tree kernel modules
like ZFS, as well as
<a href="https://wiki.archlinux.org/index.php/Dynamic_Kernel_Module_Support">DKMS</a> modules.

</p><pre>init_on_alloc=1
init_on_free=1
page_alloc.shuffle=1
slab_nomerge
vsyscall=none
</pre>

This group will instruct the kernel to fill newly allocated pages and heap
objects with zeroes, fill freed pages and heap objects with zeroes, tell the
page allocator to randomize its free lists, disable merging of
<a href="https://en.wikipedia.org/wiki/Slab_allocation">slabs</a>
with similar size, and disable
<a href="https://web.archive.org/web/20200526182112/https://lwn.net/Articles/446528/">vsyscalls</a>
due to their history of making exploits easier.
All five options are all set by default when using the linux-hardened kernel.

<pre>slub_debug=F
</pre>

This enables sanity checks in the
<a href="https://www.kernel.org/doc/Documentation/vm/slub.txt">SLUB allocator</a>.
Two other flags to consider for non-hardened kernels are <code>Z</code>
(redzoning, to detect when a slab is overwritten past its real size) and
<code>P</code> (to enable poisoning on slab cache allocations).

<p>
The full list of kernel parameters to be used must be specified on a single
line, separated by spaces, in the bootloader's config file. An example for
GRUB might look like this:

</p><pre># /etc/default/grub

[...]
GRUB_CMDLINE_LINUX_DEFAULT="apparmor=1 init_on_alloc=1 init_on_free=1 l1tf=full,force lockdown=confidentiality lsm=lockdown,yama,apparmor page_alloc.shuffle=1 slab_nomerge slub_debug=F spec_store_bypass_disable=on spectre_v2=on vsyscall=none"
[...]
</pre>

Depending on the bootloader in use, the file may need to be regenerated after
any edits are made.

<p>
Changes to the kernel parameters won't take effect until after a reboot.
To verify they were applied, run:

</p><pre>$ <strong>cat /proc/cmdline</strong>
</pre>

<p>
Yet more runtime options of the kernel can be configured through the
<a href="https://wiki.archlinux.org/index.php/Sysctl">sysctl</a> utility.
The values specified by …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vez.mrsk.me/linux-hardening.html#hn">https://vez.mrsk.me/linux-hardening.html#hn</a></em></p>]]>
            </description>
            <link>https://vez.mrsk.me/linux-hardening.html#hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664507</guid>
            <pubDate>Fri, 02 Oct 2020 16:51:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief History of Neural Nets and Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24664223">thread link</a>) | @andreyk
<br/>
October 2, 2020 | https://www.skynettoday.com/overviews/neural-net-history | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/overviews/neural-net-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</h2>

<blockquote>
  <p>“Deep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences.” -<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00239">Dr. Christopher D. Manning, Dec 2015</a> <sup id="fnref:part1_1" role="doc-noteref"><a href="#fn:part1_1">1</a></sup></p>
</blockquote>

<p>This may sound hyperbolic - to say the established methods of an entire field of research are quickly being superseded by a new discovery, as if hit by a research ‘tsunami’. But, this catastrophic language is appropriate for describing the meteoric rise of Deep Learning over the last several years - a rise characterized by drastic improvements over reigning approaches towards the hardest problems in AI, massive investments from industry giants such as Google, and exponential growth in research publications (and Machine Learning graduate students). Having taken several classes on Machine Learning, and even used it in undergraduate research, I could not help but wonder if this new ‘Deep Learning’ was anything fancy or just a scaled up version of the ‘artificial neural nets’ that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep Learning somewhat more interesting than ‘big neural nets’  (that I will attempt to explain in a way that just about anyone can understand), but most of all of how several unyielding researchers made it through dark decades of banishment to finally redeem neural nets and achieve the dream of Deep Learning.</p>


<blockquote><p id="sources">
I am certainly not a foremost expert on this topic. In depth technical overviews with long lists of references written by those who actually made the field what it is include Yoshua Bengio's <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf">"Learning Deep Architectures for AI"</a>, Jürgen Schmidhuber's <a href="http://arxiv.org/pdf/1404.7828v4.pdf">"Deep Learning in Neural Networks: An Overview"</a> and LeCun et al.s' <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">"Deep learning"</a>. In particular, this is mostly a history of research in the US/Canada AI community, and even there will not mention many researchers; a particularly in depth history of the field that covers these omissions is Jürgen Schmidhuber's <a href="http://people.idsia.ch/~juergen/deep-learning-overview.html">"Deep Learning in Neural Networks: An Overview"</a>. I am also most certainly not a professional writer, and will cop to there being shorter and much less technical overviews written by professional writers such as Paul Voosen's <a href="http://chronicle.com/article/The-Believers/190147">"The Believers"</a>, John Markoff's <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html">"Scientists See Promise in Deep-Learning Programs"</a> and Gary Marcus's <a href="http://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence">"Is “Deep Learning” a Revolution in Artificial Intelligence?"</a>. I also will stay away from getting too technical here, but there is a plethora of tutorials on the internet on all the major topics covered in brief by me.
<br>
Any corrections would be appreciated, though I will note some ommisions are intentional since I want to try and keep this 'brief' and a good mix of simple technical explanations and storytelling. 
<br>
This piece is an updated and expanded version of blog posts originally released in 2015 on www.andreykurenkov.com. 
</p></blockquote>

<ul id="markdown-toc">
  <li><a href="#prologue-the-deep-learning-tsunami" id="markdown-toc-prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</a></li>
  <li><a href="#part-1-the-beginnings-1950s-1980s" id="markdown-toc-part-1-the-beginnings-1950s-1980s">Part 1: The Beginnings (1950s-1980s)</a>    <ul>
      <li><a href="#the-centuries-old-machine-learning-algorithm" id="markdown-toc-the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</a></li>
      <li><a href="#the-folly-of-false-promises" id="markdown-toc-the-folly-of-false-promises">The Folly of False Promises</a></li>
      <li><a href="#the-thaw-of-the-ai-winter" id="markdown-toc-the-thaw-of-the-ai-winter">The Thaw of the AI Winter</a></li>
    </ul>
  </li>
  <li><a href="#part-2-neural-nets-blossom-1980s-2000s" id="markdown-toc-part-2-neural-nets-blossom-1980s-2000s">Part 2: Neural Nets Blossom (1980s-2000s)</a>    <ul>
      <li><a href="#neural-nets-gain-vision" id="markdown-toc-neural-nets-gain-vision">Neural Nets Gain Vision</a></li>
      <li><a href="#neural-nets-go-unsupervised" id="markdown-toc-neural-nets-go-unsupervised">Neural Nets Go Unsupervised</a></li>
      <li><a href="#neural-nets-gain-beliefs" id="markdown-toc-neural-nets-gain-beliefs">Neural Nets Gain Beliefs</a></li>
      <li><a href="#neural-nets-make-decisions" id="markdown-toc-neural-nets-make-decisions">Neural Nets Make Decisions</a></li>
      <li><a href="#neural-nets-get-loopy" id="markdown-toc-neural-nets-get-loopy">Neural Nets Get Loopy</a></li>
      <li><a href="#neural-nets-start-to-speak" id="markdown-toc-neural-nets-start-to-speak">Neural Nets Start to Speak</a></li>
      <li><a href="#a-new-winter-dawns" id="markdown-toc-a-new-winter-dawns">A New Winter Dawns</a></li>
    </ul>
  </li>
  <li><a href="#part-3-deep-learning-2000s-2010s" id="markdown-toc-part-3-deep-learning-2000s-2010s">Part 3: Deep Learning (2000s-2010s)</a>    <ul>
      <li><a href="#the-funding-of-more-layers" id="markdown-toc-the-funding-of-more-layers">The Funding of More Layers</a></li>
      <li><a href="#the-development-of-big-data" id="markdown-toc-the-development-of-big-data">The Development of Big Data</a></li>
      <li><a href="#the-importance-of-brute-force" id="markdown-toc-the-importance-of-brute-force">The Importance of Brute Force</a></li>
      <li><a href="#the-deep-learning-equation" id="markdown-toc-the-deep-learning-equation">The Deep Learning Equation</a></li>
    </ul>
  </li>
  <li><a href="#epilogue-the-decade-of-deep-learning" id="markdown-toc-epilogue-the-decade-of-deep-learning">Epilogue: The Decade of Deep Learning</a></li>
</ul>


<p>The beginning of a story spanning half a century, about how we learned to make computers learn. In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets’ return to popularity with backpropagation in 1986.</p>

<h2 id="the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</h2>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/Linear_regression.svg" alt="Linear Regression">     
    <figcaption>Linear regression <a href="https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg">(Source)</a></figcaption>
</figure>

<p>Let’s start with a brief primer on what Machine Learning is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little <a href="https://en.wikipedia.org/wiki/Linear_regression#cite_note-4">200 year old</a> technique for extrapolating a general function from some set of input-output pairs. And here’s why having such a technique is wonderful: there is an incalculable number of functions that are hard to develop equations for directly, but are easy to collect examples of input and output pairs for in the real world - for instance, the function mapping an input of recorded audio of a spoken word to an output of what that spoken word is.</p>

<p>Linear regression is a bit too wimpy a technique to solve the problem of speech recognition, but what it does is essentially what <strong>supervised Machine Learning</strong> is all about: ‘learning’ a function given a <strong>training set</strong> of <strong>examples</strong>, where each example is a pair of an input and output from the function (we shall touch on the unsupervised flavor in a little while). In particular, machine learning methods should derive a function that can generalize well to inputs not in the training set, since then we can actually apply it to inputs for which we do not have an output. For instance, Google’s current speech recognition technology is powered by Machine Learning with a massive training set, but not nearly as big a training set as all the possible speech inputs you might task your phone with understanding.</p>

<p>This generalization principle is so important that there is almost always a <strong>test set</strong> of data (more examples of inputs and outputs) that is not part of the training set. The separate set can be used to evaluate the effectiveness of the machine learning technique by seeing how many of the examples the method correctly computes outputs for given the inputs. The nemesis of generalization is <strong>overfitting</strong> - learning a function that works really well for the training set but badly on the test set. Since machine learning researchers needed means to compare the effectiveness of their methods, over time there appeared standard <strong>datasets</strong> of training and testing sets that could be used to evaluate machine learning algorithms.</p>

<p>Okay okay, enough definitions. Point is - our line drawing exercise is a very simple example of supervised machine learning: the points are the training set (X is input and Y is output), the line is the approximated function, and we can use the line to find Y values for X values that don’t match any of the points we started with. Don’t worry, the rest of this history will not be nearly so dry as all this. Here we go.</p>

<h2 id="the-folly-of-false-promises">The Folly of False Promises</h2>

<p>Why have all this prologue with linear regression, since the topic here is ostensibly neural nets? Well, in fact linear regression bears some resemblance to the first idea conceived specifically as a method to make machines learn: <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;id=1959-09865-001">Frank Rosenblatt’s <strong>Perceptron</strong></a><sup id="fnref:part1_2" role="doc-noteref"><a href="#fn:part1_2">2</a></sup>.</p>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34998.jpg" alt="Perceptron">
    <figcaption>A diagram showing how the Perceptron works. <a href="http://cse-wiki.unl.edu/wiki/images/0/0f/Perceptron.jpg">(Source)</a></figcaption>    
</figure>

<p>A psychologist, Rosenblatt conceived of the Percetron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not). Most of the inputs to a Perceptron are either some data or the output of another Perceptron, but an extra detail is that Perceptrons also have one special ‘bias’ input, which just has a value of 1 and basically ensures that more functions are computable with the same input by being able to offset the summed value. This model of the neuron built on the work of Warren McCulloch and Walter Pitts <a href="http://www.minicomplexity.org/pubs/1943-mcculloch-pitts-bmb.pdf">Mcculoch-Pitts</a><sup id="fnref:part1_3" role="doc-noteref"><a href="#fn:part1_3">3</a></sup>, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions. This, in the early days of AI, was a big deal - the predominant thought at the time was that making computers able to perform formal logical reasoning would essentially solve AI.</p>

<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34832.jpg" alt="Perceptron 2"> 
    <figcaption>Another diagram, showing the biological inspiration. The <b>activation function</b> is what people now call the non-linear function applied to the weighted input sum to produce the output of the artificial neuron - in the case of Rosenblatt's Perceptron, the function just a thresholding operation.  <a href="http://cs231n.github.io/neural-networks-1/">(Source)</a> </figcaption>    
</figure>

<p>However, the Mcculoch-Pitts model lacked a mechanism for learning, which was crucial for it to be usable for AI. This is where the Perceptron excelled - Rosenblatt came up with a way to make such artificial neurons learn, inspired by the <a href="http://onlinelibrary.wiley.com/doi/10.1002/cne.900930310/abstract">foundational work</a><sup id="fnref:part1_4" role="doc-noteref"><a href="#fn:part1_4">4</a></sup> of Donald Hebb. Hebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebb’s Rule:</p>

<blockquote>
  <p>“When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A’s efficiency, as one of the cells firing B, is increased.”</p>
</blockquote>

<p>The Perceptron did not follow this idea exactly, but having weights on the inputs allowed for a very simple and intuitive learning scheme: given a <strong>training set</strong> of input-output examples the Perceptron should ‘learn’ a function from, for each example increase the weights if the Perceptron output for that example’s input is too low compared to the example, and otherwise decrease the weights if the output is too high. Stated ever so slightly more formally, the algorithm is as follows:</p>

<ol>
  <li>Start off with a Perceptron having random weights and a training set</li>
  <li>For the inputs of an example in the …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/overviews/neural-net-history">https://www.skynettoday.com/overviews/neural-net-history</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/overviews/neural-net-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664223</guid>
            <pubDate>Fri, 02 Oct 2020 16:25:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pressing YubiKeys]]>
            </title>
            <description>
<![CDATA[
Score 390 | Comments 188 (<a href="https://news.ycombinator.com/item?id=24663989">thread link</a>) | @bertrandom
<br/>
October 2, 2020 | https://bert.org/2020/10/01/pressing-yubikeys/ | <a href="https://web.archive.org/web/*/https://bert.org/2020/10/01/pressing-yubikeys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>If you work in tech, you probably have a YubiKey. I have this one, the <a href="https://www.yubico.com/product/yubikey-5c-nano/">YubiKey 5C Nano</a>:</p>

<p><img src="https://bert.org/assets/posts/yubikey/nano.jpg" alt="YubiKey 5C Nano"></p>

<p>If you don’t work in tech but primarily work on your laptop, you probably <em>should</em> have a YubiKey. And if you work on a political campaign or as a journalist, you should definitely have one (or something similar). Talk to your IT Security department about that. This post will mostly be about something your IT Security department doesn’t want to hear about, though, so maybe don’t mention it to them.</p>

<p>YubiKeys act as two-factor authentication. This means that after you log-in to a system with your username and password, the system requires you to authorize in a second way as well. This way if your login credentials are compromised, the attacker would also have to compromise the second form of authentication, which is harder.</p>

<p>There are different forms of two-factor authentication - a common one is that a website will ask you to scan a QR code with the Google Authenticator app (or similar) on your phone which will generate 6 digit codes. The way this works is that the server and the app both have a shared secret. The phone generates codes based on that secret and the current timestamp and the server generates the same codes and sees if they match.</p>

<p><img src="https://bert.org/assets/posts/yubikey/qr-code.png" alt="QR Code"></p>

<p><img src="https://bert.org/assets/posts/yubikey/authenticator.png" alt="Google Authenticator"></p>

<p>Another one is SMS-based 2FA, which is pretty widely regarded as insecure. In this case, the server generates a code and sends it to your phone via SMS. The reason it’s considered insecure is that an attack exists called <a href="https://en.wikipedia.org/wiki/SIM_swap_scam">SIM-jacking</a> where someone convinces a cell phone carrier to port a number to a new SIM card, effectively directing all SMS traffic to their phone instead of yours.</p>

<p><img src="https://bert.org/assets/posts/yubikey/wells.jpg" alt="Wells Fargo"></p>

<p>YubiKeys are small devices that plug in to the USB port of your computer and emulate a keyboard. When tapped, they emit a one-time password (OTP) which can be then verified by a validation server. A private key exists on the device which is used to sign information, but it can never leave the device because it is stored in a tamper-resistant environment.</p>

<p>The YubiKey that I use is designed to always sit in a USB port of my laptop, so whenever I would take my laptop from my desk to a conference room or to another office, it was always available. But like many new remote workers, my laptop never leaves my desk anymore. I have it hooked up to an external monitor and to save some desk space, I have it in clamshell mode sitting vertically on a stand.</p>

<p>This makes tapping the YubiKey difficult, especially when I store my laptop far away from my keyboard and mouse. I solved this by buying a <a href="https://smile.amazon.com/gp/product/B071DMMW4J/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">USB-C extension cable</a>, which brought the YubiKey closer to my keyboard.</p>

<p>One thing I haven’t mentioned about the YubiKey 5C Nano is that it’s kind of difficult to tap, even without the distance issues. The target area that you need to touch is extremely small:</p>

<p><img src="https://bert.org/assets/posts/yubikey/nano-big.png" alt="YubiKey 5C Nano"></p>

<p>One of the features of the YubiKey is that the little metal strip determines that it is being tapped by a human - this prevents it from being accidentally triggered by bumping your laptop into something, but if you’ve ever seen a one-time password in a Slack channel or Google Doc like <code>tlerefhcvijlngibueiiuhkeibbcbecehvjiklltnbbl</code>, you know it isn’t a perfect system. I would estimate that 1 in 5 times that I attempt to trigger it, it doesn’t register.</p>

<p>A lot of thought has gone into ensuring that the YubiKey can’t be triggered from software on the computer itself.</p>

<p>Before we go any further, I’d like to acknowledge the reasons for this. If a remote attacker were to compromise your laptop, being able to trigger the YubiKey from software on the computer defeats the whole point of using the YubiKey. But I think we always make tradeoffs between security and convenience - for example, you often don’t have to enter your YubiKey every time you access a system, some systems will only ask you once and not ask you again on subsequent logins for a certain amount of time. When you use a 2FA system and it gives you “backup codes”, do you always print those out and store them in a safe location? Everyone should figure out what level of security and convenience they are okay with.</p>

<p>With that being said, let’s talk about how you could trigger a YubiKey with software.</p>



<p>I’ve been calling this mechanism <strong>The Finger</strong>.</p>

<h2 id="hardware">Hardware</h2>

<p>First, we need some way for the computer to talk to <strong>The Finger</strong>. I had a bunch of these <a href="https://smile.amazon.com/gp/product/B076F53B6S/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">IZOKEE D1 Mini</a> development boards lying around, they are smaller versions of boards that use the infamous <a href="https://en.wikipedia.org/wiki/ESP8266">ESP8266</a> chip found in a lot of IoT devices.</p>

<p><img src="https://bert.org/assets/posts/yubikey/d1-mini.jpg" alt="IZOKEE D1 Mini"></p>

<p>We can connect this to the laptop and talk to it over USB serial, but since it has WiFi, we can also just run a webserver on it and send it HTTP requests.</p>

<p>Next, we need some way to push <strong>The Finger</strong> towards the Yubikey. After a little googling, I found that the <a href="https://smile.amazon.com/gp/product/B01CP18J4A/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">28BYJ-48 stepper motor</a> interfaces well with the D1 Mini board.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor.jpg" alt="stepper motor"></p>

<p>Stepper motors convert electrical pulses into mechanical rotation and the D1 Mini has pins for sending electrical pulses.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor.gif" alt="stepper motor"></p>

<p>But stepper motors rotate and we mostly just need to poke in a straight direction. So I searched on Thingiverse for “28BYJ-48” and found this: <a href="https://www.thingiverse.com/thing:3593641">28BYJ-48 Motor Halter</a>.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor-case.jpg" alt="28BYJ-48 Motor Halter"></p>

<p>This attaches a gear to the motor which can guide a long rack forward and backward. But if we’re going to push a long plastic thing toward the YubiKey, it might as well look like a finger. Back to Thingiverse, this time searching for “finger” and I found this model someone made for Halloween:</p>

<p><img src="https://bert.org/assets/posts/yubikey/finger_model.jpg" alt="finger"></p>

<p>I opened up these two models in Fusion 360 and used an advanced CAD technique called “smooshing”, resulting in this:</p>

<p><img src="https://bert.org/assets/posts/yubikey/finger_smoosh.png" alt="finger"></p>

<p>Next, I exported the smooshed STL and 3D printed it in <a href="https://shop.prusa3d.com/en/prusament/715-prusament-pla-lipstick-red-1kg.html">Prusament PLA Lipstick Red</a> because that’s what I happened to have in my printer at the time. Then I took the plastic finger and touched the YubiKey which.. didn’t do anything. I picked up a metal screw on my desk and touched the YubiKey, which immediately spit out a OTP. So then I took the finger and secured it to my desk with a vise and drilled a small hole in it, then screwed the metal screw into it and touched it to the YubiKey, which again did nothing.</p>

<p><img src="https://bert.org/assets/posts/yubikey/vise.jpg" alt="vise"></p>

<p>That’s when I realized that I’m an idiot and that when I had touched the metal screw to the Yubikey, it was just transmitting the electrical charge from my body to the metal screw, which then transmitted it to the capacitive touch sensor on the YubiKey. So how could I trick the capacitive touch sensor into thinking it was a real finger?</p>

<p>I guessed that the way that capacitive touch sensors work is that they’re measuring your body’s capacitance to ground, so if we just hook up the sensor directly towards ground, it’ll think that its really conductive or at least conductive enough for a human finger to be between the two. So I took an insulated wire, unscrewed the metal screw slightly, wrapped it around the screw and tightened it again. Then I took the other end and connected it the GND port on the D1 Mini board, touched it to the YubiKey, and it worked!</p>

<p>Now the driver board for the stepper motor already connects to the 5V and GND on the D1 Mini, so I thought I might have to strip the GND wire and run it to both the driver board and the screw, but on a whim I decided to just wedge the end of the wire from the metal screw between the stepper motor metal body (figuring the metal body case was grounded) and the plastic housing. This also worked!</p>

<p><img src="https://bert.org/assets/posts/yubikey/ground.jpg" alt="grounding"></p>

<p>Once I confirmed that the finger would trigger the YubiKey, I needed a way to mount the YubiKey close to the finger, so I used my digital calipers to measure the size of the USB-C extension cable and designed a holder in Fusion 360.</p>

<p><img src="https://bert.org/assets/posts/yubikey/holder.png" alt="holder"></p>

<p>The USB-C extension cable would go into the hole on the left and the motor would mount on the right.</p>

<p>At this point, we have to wire the stepper motor driver board to the D1 Mini. This can be done by soldering some headers onto the D1 Mini and then connecting some Dupont jumper wires between them.</p>

<p><img src="https://bert.org/assets/posts/yubikey/pins.jpg" alt="pins"></p>

<table>
  <thead>
    <tr>
      <th>D1 Mini</th>
      <th>28BYJ-48 Driver Board</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5V</td>
      <td>5V</td>
    </tr>
    <tr>
      <td>GND</td>
      <td>GND</td>
    </tr>
    <tr>
      <td>D1</td>
      <td>IN1</td>
    </tr>
    <tr>
      <td>D2</td>
      <td>IN2</td>
    </tr>
    <tr>
      <td>D3</td>
      <td>IN3</td>
    </tr>
    <tr>
      <td>D4</td>
      <td>IN4</td>
    </tr>
  </tbody>
</table>

<p>Once we put the stepper motor into the housing and screw everything together, it should look like this:</p>

<p><img src="https://bert.org/assets/posts/yubikey/setup.jpg" alt="setup"></p>

<h2 id="software">Software</h2>

<p>The software is much more straightforward. The D1 Mini can be programmed using the Arduino IDE. First, we go into Preferences and add <code>https://arduino.esp8266.com/stable/package_esp8266com_index.json</code> under <em>Additional Board Manager URLs</em>. Then when you go into the <em>Boards Managers</em>, you can install the <code>esp8266</code> package which includes the board <strong>LOLIN(WEMOS) D1 R2 &amp; mini</strong>, which should be selected under <em>Tools</em>.</p>

<p>At this point I’ll run a sketch for blinking the LED just to verify that it’s working:</p>

<div><div><pre><code>#define LED 2 //Define blinking LED pin

void setup() {
  pinMode(LED, OUTPUT); // Initialize the LED pin as an output
}
// the loop function runs over and over again forever
void loop() {
  digitalWrite(LED, LOW); // Turn the LED on (Note that LOW is the voltage level)
  delay(1000); // Wait for a second
  digitalWrite(LED, HIGH); // Turn the LED off by making the voltage HIGH
  delay(1000); // Wait for two seconds
}
</code></pre></div></div>

<p>I found this <a href="https://robojax.com/learn/arduino/?vid=robojax_ESP8266_28BYJ-48_Stepper_ESP8STP-1">sketch</a> that shows how to control the 28BYJ-48 Stepper Motor using WiFi.</p>

<p>Here are the parts that have to do with the motor:</p>

<div><div><pre><code>int Pin1 = D1; //IN1 is connected 
int Pin2 = D2; //IN2 is connected   
int Pin3 = D3; //IN3 is connected 
int Pin4 = D4; //IN4 is connected 
 
int pole1[] ={0,0,0,0, 0,1,1,1, 0}; //pole1, 8 step values
int pole2[] ={0,0,0,1, 1,1,0,0, 0}; //pole2, 8 step values
int pole3[] ={0,1,1,1, 0,0,0,0, 0}; //pole3, 8 step values
int pole4[] ={1,1,0,0, 0,0,0,1, 0}; //pole4, 8 step values

int poleStep = 0; 
int dirStatus = 3; // stores direction status 3= stop (do not change)
String argId[] ={"ccw", "cw"};

...

void loop(void) {
    server.handleClient();
    MDNS.update();

    if (dirStatus == 1) {
        poleStep++;
        driveStepper(poleStep);
    } else if (dirStatus == 2) {
        poleStep--;
        driveStepper(poleStep);
    } else {
        driveStepper(8);
    }
    
    if (poleStep&gt;7) { 
        poleStep=0; 
    }

    if (poleStep&lt;0) {
        …</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bert.org/2020/10/01/pressing-yubikeys/">https://bert.org/2020/10/01/pressing-yubikeys/</a></em></p>]]>
            </description>
            <link>https://bert.org/2020/10/01/pressing-yubikeys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663989</guid>
            <pubDate>Fri, 02 Oct 2020 16:03:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What We Learned by Closing a $4M Investment from Accel]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24663314">thread link</a>) | @hodgesrm
<br/>
October 2, 2020 | https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel | <a href="https://web.archive.org/web/*/https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>I’m pleased to share the news that Altinity has raised a $4M seed investment from Accel. Dan Levine led the round. We are honored by Accel’s trust and delighted to work with Dan. We plan to use the investment to roll out our new <a href="https://altinity.com/cloud/">Altinity.Cloud platform</a> and to strengthen <a href="https://clickhouse.tech/">ClickHouse </a>into the best analytic database on the planet.&nbsp;</p><p>Dan was the first venture capitalist to contact us, as he tells in his <a href="http://www.accel.com/noteworthy/our-seed-in-altinity" target="_blank" rel="noreferrer noopener">blog article about the seed investment</a>. He was enthusiastic but also very patient.That was fortunate, because we then talked to 43 other VCs at greater or lesser length over the next year and a half. The count omits those who greeted our overtures with stony silence. In the end we were absolutely confident Dan and Accel were the right choice. At the same time, we learned from many others.</p><p>Looking back, it is apparent we did more than just collect a check from a great investment team. We also learned a number of valuable lessons about early stage venture investment.&nbsp; Many of these were not obvious, at least to me. In this article I will share what we learned, along with a spreadsheet we developed to help with investment math. I hope our account will be useful — or at least entertaining!</p><p><h2 id="h-what-do-vcs-really-want">What do VCs really want?</h2>
</p><p>VC websites often sport brave slogans like “we are looking for bold entrepreneurs who will change the world.” What they are actually looking for, of course, is far more concrete: a big return on a speculative bet about a new business. The first thing we learned was how venture capital actually works and how we fit in.&nbsp;</p><p>Let’s start with where the money comes from and how it is managed. Venture capital firms operate one or more funds, which they use to make investments. Each venture capital firm has general partners who work for the company, decide where to invest, and take care of serving on boards and other duties required to supervise each investment.&nbsp; There is also another type of partner, known as a limited partner or LP. LPs can be wealthy individuals, pension funds, sovereign investment funds, you name it. They supply cash but have no role in making investment decisions. Here is a picture.&nbsp;</p><div><figure><img loading="lazy" width="954" height="368" src="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png" alt="" srcset="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png 954w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-300x116.png 300w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-768x296.png 768w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-600x231.png 600w" sizes="(max-width: 954px) 100vw, 954px" data-lazy-srcset="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png 954w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-300x116.png 300w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-768x296.png 768w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-600x231.png 600w" data-lazy-src="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>In the first meeting with a new VC you typically hear about the current funds, how big they are, and other details like reserves for follow-on investments in promising companies. When you ask what payback they are seeking the most frequent answer is “return the fund.” This is so common that I stopped writing it down unless the answer was something different. It means the investment in your company needs to pay out at the value of the entire fund, not just what the VC put into your company. The reason has to do with the mechanics of the funds.</p><p>Most startups fail or return money that does not come close to covering the investment. To provide a decent return to limited partners and VC general partners plus pay overhead, at least a couple of investments need to hit home runs and to pay off at full value of the fund. It’s basic math, but the numbers are big. Say a $400M fund invests $40M total for a 25% share of your startup, a typical target percentage. To return the fund means that the startup will have to exit for $1.6B ($400M = $1.6B * 25%). Grand slams like <a href="https://news.crunchbase.com/news/these-were-the-biggest-winners-in-snowflakes-record-busting-ipo" target="_blank" rel="noreferrer noopener">Snowflake</a> return far more and make the fund very successful.&nbsp;</p><p>At first it was disconcerting when A-list VC prospects baldly asked how we would get them an exit in the $1B+ range. Over time I developed empathy for this attitude. VC general partners have to make the math work or find another job. Meanwhile entrepreneurs need to have a problem that fits the pattern of investment or venture funding does not make a lot of sense. That’s the economic reality and has little to do with how individual VCs feel about you personally, or even about your business.&nbsp;</p><p>We needed to articulate to ourselves how we would win in a large market–SQL data warehouses–filled with a lot of savvy competitors like Amazon and Snowflake. The classic strategy is to create a <em><span>new</span> </em>market that did not previously exist, then become the leader. Anurag Gupta and his colleagues at Amazon put it brilliantly <a href="https://dl.acm.org/doi/10.1145/2723372.2742795" target="_blank" rel="noreferrer noopener">in a paper on Amazon Redshift</a>:&nbsp;</p><p><em>Our goal with Amazon Redshift was not to compete with other data warehousing engines, but to compete with non-consumption.&nbsp;</em></p><p>The unique differentiation of ClickHouse is that it is open source and runs anywhere: from public clouds down to Android phones. Any developer on the planet can download it and add high performance analytics to any application without sacrificing portability or scaling. That’s an enormous expansion of the market that will fuel innovation not just at the database level but will extend to new applications of big data as well as the tools and platforms to run them.&nbsp;</p><p>Here’s another key insight: it took months to be able to state that value proposition in three sentences. It’s like learning a new language — anyone can learn to say hello but achieving fluency requires real work.&nbsp;</p><p>We did a lot of modeling to understand the growth trajectory needed to achieve the kind of revenue our predecessors are making. One of the conclusions was that we needed to build a great cloud platform for ClickHouse. It’s a tried-and-true way to build a successful business, especially for companies that manage data, and one that our customers have confirmed as a fruitful path to growth. We believe in the plan and it matches venture capital economics.&nbsp;</p><p><h2 id="h-vcs-work-off-a-thesis">VCs Work Off a Thesis</h2>
</p><p>I didn’t know a lot of early stage VCs when we began fund-raising, though like everyone I heard they were fine human beings worthy of acquaintance. The initial conversations were illuminating in one particular respect. Venture capitalists don’t necessarily know that much about specific technology or markets.&nbsp;</p><p>Here’s an example. My favorite demo for ClickHouse is the <a href="https://youtu.be/zDIK3Ej86GU" target="_blank" rel="noreferrer noopener">ClickHouse-fast demo</a> where I first run a query on data generated purely in memory followed by a similar query that accesses 1.3 billion rows of taxi data in slowish network-attached storage. I usually pause dramatically after the in-memory query to ask which query is going to be faster. Everybody knows access to memory is faster than storage, right?</p><p>Actually, in this demo it’s not. You have to be very careful to make an apples-to-apples comparison when comparing memory and storage access speeds. ClickHouse compresses stored data and parallelizes I/O extremely well. Reading from storage is therefore very fast. With ClickHouse it is not hard to choose in-memory queries that look similar but run far slower because they have a different execution path with less parallelization or other inefficiencies. It’s a subtle point that experienced database people understand, whereas VCs I talked to often got it wrong. (And then argued about it, too.)&nbsp;</p><p>This experience illustrates that deep dives on technology are not always the best way to evaluate early stage businesses. Good VCs tend to look for proxies that indicate signs of traction. In our case Dan Levine knew about ClickHouse because his other start-up investments used it. Dan pays really close attention to things they like. Dan picked up on ClickHouse earlier and more clearly than anyone we spoke to. The fact that we were an experienced team already selling services profitably was perhaps another useful signal. But Dan was also looking for more than just specific signals–he was looking for a pattern related to data, backed by a solid team.&nbsp;</p><p>Over time, we found that the VCs who really picked up on our story had a thesis about the value of combining two things:&nbsp;</p><div><ul>
<li>Data – Faster and more cost effective ways of analyzing large datasets are inherently valuable to enterprises.&nbsp;&nbsp;</li>
<li>Open source – There are standard models for marketing and monetizing open source projects to build very large businesses</li>
</ul>
</div><p>VCs with these convictions tended to like what we were doing overall, though they often found specific things they didn’t like: open source community too small, too much competition, not the right team, already made a competing investment, etc. That said, we didn’t argue about the size of the market or whether open source was the right overall strategy to reach it.&nbsp;It helped that the original developers of <a href="https://en.wikipedia.org/wiki/ClickHouse">ClickHouse at Yandex</a> did an amazing job of open sourcing the code and starting a great community around it. </p><p>Not surprisingly, we learned that those same investors were precisely the people we wanted backing the company. Not only did we share key assumptions about the business, but they had funded such businesses before with successful outcomes. Because of that they could offer useful advice on big topics like strategy to build open source communities or workable business models.&nbsp; They could also connect us with outstanding people like Mike Olson of Cloudera (and many others) who had worked through similar problems and could help us see around corners.&nbsp;</p><p>Here’s a final insight that relates back to the technology point I made above. VCs can identify promising companies, but they can’t tell you how to run yours. As an entrepreneur you understand the technology, your customers, and what is feasible to achieve. We had a number of debates with potential investors about details of the business plan.</p><p>For example, many VCs favor pure cloud services, because the best ones experience explosive growth and high margins. However, a push-button service is not a complete solution, especially for complex enterprise products like databases. Altinity has been in business since 2017 and we have articulate users who say they want us to take care of running ClickHouse in the cloud. They also want application tools, new server features, training, support, and implementation help. Their problem is not just to deploy a database but to create applications that add value to their own business. If you help them do that you have a much more competitive business.&nbsp;</p><p>Our mission is to help any enterprise that uses ClickHouse. We provide everything customers need to be successful with ClickHouse, <em>including</em> a great cloud service. We also support the ClickHouse …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel">https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel</a></em></p>]]>
            </description>
            <link>https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663314</guid>
            <pubDate>Fri, 02 Oct 2020 14:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BMW fined $18M for providing inaccurate retail sales information to investors]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24663027">thread link</a>) | @zachshefska
<br/>
October 2, 2020 | https://yourautoadvocate.com/guides/bmw-fraud/ | <a href="https://web.archive.org/web/*/https://yourautoadvocate.com/guides/bmw-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><iframe src="https://www.youtube.com/embed/MBe7PNfmvAw" frameborder="0" allowfullscreen=""></iframe></p><p>The Securities and Exchange Commission recently announced $18M in fines that BMW and two of their subsidiaries must pay for having provided misleading and inaccurate retail sales information to their investors.</p><p>The SEC report reads:</p><blockquote><p>According to the SEC’s order, from 2015 to 2019, BMW inflated its reported retail sales in the U.S., which helped BMW close the gap between its actual retail sales volume and internal targets and publicly maintain a leading retail sales position relative to other premium automotive companies. The order finds that BMW of North America LLC (BMW NA) maintained a reserve of unreported retail vehicle sales — referred to internally as the “bank” — that it used to meet internal monthly sales targets without regard to when the underlying sales occurred. The order also finds that BMW NA paid dealers to inaccurately designate vehicles as demonstrators or loaners so that BMW would count them as having been sold to customers when they had not been. Additionally, the order finds that BMW NA improperly adjusted its retail sales reporting calendar in 2015 and 2017 to meet internal sales targets or bank excess retail sales for future use. As a result, according to the order, the information that BMW provided to investors in the bond offerings by BMW’s U.S. financing subsidiary, BMW US Capital LLC, and to credit rating agencies contained material misstatements and omissions regarding BMW’s U.S. retail vehicle sales.</p><cite><a href="https://www.sec.gov/news/press-release/2020-223" target="_blank" rel="noreferrer noopener">https://www.sec.gov/news/press-release/2020-223</a></cite></blockquote><p>After having spent 43 years in the car business (many of which with BMW North America), I can unequivocally say these practices are routine and commonplace within car dealerships. Fraudulent behavior like this is not limited to BMW. Every manufacturer I have ever worked for encourages this.</p><p>When I worked for Penske Automotive Group we were explicitly instructed not to fudge any numbers. If our BMW rep asked us to “pad the numbers” one month, we didn’t. Penske didn’t want to participate in that type of activity. They were the exception to the rule.</p><p>As a dealer you have very little choice but to “play the game.” As I’ve talked about in other videos and guides here on the blog, car dealers don’t make much of anything when they sell vehicles. Instead, <a href="https://yourautoadvocate.com/guides/how-do-car-dealerships-make-money/" target="_blank" rel="noreferrer noopener">they make their money from factory incentives and from selling finance and insurance products</a>.</p><p><iframe src="https://www.youtube.com/embed/RTYnhidJMe8" frameborder="0" allowfullscreen=""></iframe></p><p>With that in mind, it’s clear why dealers “play the game.” If you have a $250,000 incentive that is based on the number of cars you sell in any given month, and the person writing you that check (BMW) is encouraging you to “fake” sales so that you can actually attain the bonus, what would you do? The answer is simple.</p><p>Car manufacturers are happy to pay out giant monthly bonuses to subsidize their dealers, but only if they hit certain sales volume thresholds. This is because manufacturers are then able to report better than expected sales volumes to their investors.</p><p>How many fraudulently reported vehicles are “sold” in any given month? In any given month we would designate 15 Mini Coopers as “sold,” even though they hadn’t been. In that same month we may have actually sold 35 or 40 vehicles. Each month, upwards of 20% of our “sales” were fake.</p><p>It’s surprising to think that BMW was only fined $18M. Considering a nontrivial amount of their sold inventory is not actually sold, you would think the fine should be $180M instead of $18M.</p><p>Fiat Chrysler paid $40M in fines a few years ago for similar practices. Regardless of who it is, it’s clear that the fines aren’t enough to stop the fraudulent behavior.</p>
</div></div></div>]]>
            </description>
            <link>https://yourautoadvocate.com/guides/bmw-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663027</guid>
            <pubDate>Fri, 02 Oct 2020 14:35:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache OpenWhisk is a truly portable Serverless Platform]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662975">thread link</a>) | @kiyanwang
<br/>
October 2, 2020 | https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/ | <a href="https://web.archive.org/web/*/https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apache OpenWhisk is a truly portable and multiplatform Serverless engine and it is available now on all the major clouds from multiple commercial vendors. Here is a Chess Engine running on:</p><ul><li><a href="https://whisk-chess.adobeioruntime.net/api/v1/web/default/chess">Adobe I/O</a></li><li><a href="https://eu-de.functions.appdomain.cloud/api/v1/web/a1d40f6b-e5e3-4f07-8f92-77b525392253/default/chess">IBM Cloud</a></li><li><a href="https://wka9bi13u3.apigw.ntruss.com/chess/chess/ZC2o7bFh0x/http">Naver</a></li><li><a href="https://apigcp.nimbella.io/api/v1/web/msciabar-zc3thebgxgh/default/chess">Nimbella</a></li></ul><p>And see below for instructions how to run it also locally and in any Kubernetes cluster, for example AWS EKS…</p><p><iframe src="https://www.youtube.com/embed/02Xezhf_j4U" allowfullscreen="" title="YouTube Video"></iframe></p><p>Apache OpenWhisk is a Serverless Cloud Platform, developed as an open source project at the Apache Software Foundations. It is similar to Amazon Lambda, Google Functions or Azure Functions. The main difference is that it is an Open Source project, it is offered by multiple commercial vendors, and it has a rich serverless programing model for composing functions into workflows.</p><p>Many vendors today offer cloud functions based on OpenWhisk, and it runs on all the major public clouds. However not all the vendors disclose where they run their services, so I will refer to the vendor and not to the cloud that runs it. It can also be installed on any Kubernetes cluster, so you can install in any cloud, either your private cloud or the public one you prefer.</p><p>In this article I am going to show that OpenWhisk is a truly portable serverless solution, and that you can write a single serverless application and then run it on multiple vendors.</p><p>To prove my point, I wrote an open source serverless application and ran it on all the OpenWhisk vendors I got access to. I also created a custom Kubernetes cluster and installed OpenWhisk on it to run my application.</p><p>The application is a chess engine, written in the Go programming language, and that includes backend and frontend. You can use it to play chess using a web interface, while the opponent is an AI algorithm running as a serverless function in OpenWhisk.</p><p>For testing and development you can use the Standalone OpenWhisk. It is a single node installation that can run in your machine and only requires <a href="https://docker.com/"><code>Docker</code></a> to run. You also need to download the <a href="https://github.com/apache/openwhisk-cli/releases/tag/1.0.0">OpenWhisk CLI tool <code>wsk</code></a> for your operating system in order to interact with OpenWhisk.</p><p>Once prerequisites are satisfied, you can start a local OpenWhisk with the following command:</p><div><pre><code data-lang="fallback">bash &lt;(curl -sL https://s.apache.org/openwhisk.sh)
</code></pre></div><p>The command will download a Docker image for standalone OpenWhisk and it will start it. It will also open the playground, that you can use to create and run a function on the fly from your browser.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/playground-ui.png" alt="Playground"></p><p>Once you have OpenWhisk up and running you can configure the <code>wsk</code> tool to access it. OpenWhisk access is protected by a key that you have to retrieve and use to configure <code>wsk</code>, as follows:</p><div><pre><code data-lang="fallback">AUTH=$(docker exec openwhisk wsk property get --auth | awk '{ print $3}')
wsk property set --auth $AUTH --apihost http://localhost:3233
</code></pre></div><p>Now let’s build our chess engine and use the local OpenWhisk to test it locally. The source code of the chess engine <a href="https://github.com/openwhisk-blog/whisk-chess">is available on GitHub</a>.</p><p>The code is based on a freely available chess engine called <a href="https://github.com/ChizhovVadim/CounterGo/pulls">CounterGo</a>. It is written in Go. I adapted it to run as a stateless serverless action, and I added a frontend in JavaScript, using the libraries <a href="https://chessboardjs.com/">Chessboardjs</a> and <a href="https://github.com/jhlywa/chess.js">chess.js</a>.</p><p>In order to build the action, you need common tools like <code>git</code>, <code>make</code> and <code>docker</code>. Once you have them you can download and build the sources with the commands:</p><div><pre><code data-lang="fallback">git clone https://github.com/openwhisk-blog/whisk-chess
cd whisk-chess
make
</code></pre></div><p>Note that you do not need a Go compiler to build the action, just Docker, as you can compile the action using the OpenWhisk Go runtime itself. The result is the file <code>chess.zip</code> containing a pre-compiled Go action ready to be deployed.</p><p>Once you have the action, you use the following command to deploy it in OpenWhisk:</p><div><pre><code data-lang="fallback">wsk action update chess chess.zip --kind go:1.11 --web true
</code></pre></div><p>Finally you can retrieve the URL of the action with the command:</p><div><pre><code data-lang="fallback">wsk action get chess --url
</code></pre></div><p>If you now type the URL in a browser you will see the user interface of our chess engine, a chessboard, and you can play chess against the computer.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/chess.png" alt="Chess"></p><p>Now let’s start deploying our chess in the services of the various vendors that offer OpenWhisk.</p><p><a href="https://nimbella.com/">Nimbella</a> offers a serverless solution based on OpenWhisk and focused on providing an “awesome developer experience”.</p><p>I think it is appropriate to say that I work for Nimbella, but I am trying to be neutral in this article and offer a fair comparison of all the OpenWhisk vendors I am aware of.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/020.png" alt="Nimbella"></p><p>Nimbella uses its own CLI called <code>nim</code> for deployment. The Nimbella CLI was recently <a href="https://github.com/nimbella/nimbella-cli/">open sourced</a>. You need to sign-up and login to use their service. Once you are logged in, you can deploy our chess action and get an URL for it. The <code>nim login</code> command conveniently permits sign-up.
The CLI is available <a href="https://nimbella.io/downloads/nim/nim.html#install-the-nimbella-command-line-tool-nim">for download</a> for Mac OS, Windows and Linux.</p><div><pre><code data-lang="fallback">nim login
nim action update chess chess.zip --kind go:1.12 --web true
nim action get chess --url
</code></pre></div><p>It is possible to use the <code>wsk</code> CLI with Nimbella if one prefers it. You’ll notice the command is identical here to the one shown earlier but replaced <code>wsk</code> with <code>nim</code>.</p><p><a href="https://apigcp.nimbella.io/api/v1/web/msciabar-zc3thebgxgh/default/chess">Follow this link to play chess on Nimbella</a>.</p><p>The IBM cloud was the original cloud offering OpenWhisk as a service.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/030.png" alt="IBM"></p><p>You need to download and install the <code>ibmcloud</code> CLI in order to deploy actions to IBM. There are also some requirements like downloading a plugin and to target a space; all the steps are explained on their website.</p><p>They offer a generous free tier for running functions. You need to register on their website to use a very large number of function invocations for free.</p><p>Once you downloaded the tool, the commands to deploy the chess engine and get an URL to run the action are:</p><div><pre><code data-lang="fallback">ibmcloud login -u "$IBMUSER" -p "$IBMPASS"
ibmcloud fn action update chess chess.zip --kind go:1.11
ibmcloud fn action get chess --url
</code></pre></div><p><a href="https://eu-de.functions.appdomain.cloud/api/v1/web/a1d40f6b-e5e3-4f07-8f92-77b525392253/default/chess">Follow this link to play Chess on IBM Cloud.</a></p><p>Naver is a Korean company, owner of the main search engine in the Korean language, but also offering cloud services. The Naver Cloud Platform uses OpenWhisk to implement cloud functions.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/040.png" alt="Naver"></p><p>Currently Naver does not offer a CLI to deploy actions, however I was told a CLI is actually under development. For now I deployed the chess action using their web interface.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/041.png" alt="Naver Deploy"></p><p><a href="https://wka9bi13u3.apigw.ntruss.com/chess/chess/ZC2o7bFh0x/http">Follow this link to play Chess on Naver.</a></p><p>Adobe has a serverless offering based on OpenWhisk too. It is called the <a href="https://www.adobe.io/apis/experienceplatform/runtime.html">Adobe I/O Runtime</a>.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/045.png" alt="Adobe I/O"></p><p>Adobe I/O Runtime currently supports only Node.js based runtimes, so if you pick them as your serverless function providers you have to write your serverless functions in JavaScript. However being based on OpenWhisk, it is possible to use other runtimes by request, and so we can also run our chess engine. I thank the team at Adobe for their kind support and help in deploying my action for demonstration purposes.</p><p><a href="https://whisk-chess.adobeioruntime.net/api/v1/web/default/chess">Follow this link to play Chess on Adobe I/O.</a></p><p>Finally, you can run OpenWhisk in any cluster supporting Kubernetes. For this purpose, I created an EKS cluster on AWS and installed OpenWhisk on it, then I deployed my chess application. I will show here how to do that quickly and easily.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/053.png" alt="AWS"></p><p>You will need to create and configure an AWS account. I refer you to AWS documentation for information how to do this.</p><p>Once I created an account, I installed the <a href="https://eksctl.io/"><code>eksctl</code></a> tool that makes easy to create a Kubernetes cluster on AWS.</p><p>Also you need to install the <a href="https://helm.sh/"><code>helm</code></a> deployment tool and use it to actually install OpenWhisk. You can download the helm chart from GitHub and install OpenWhisk as follows:</p><div><pre><code data-lang="fallback">git clone https://github.com/apache/openwhisk-deploy-kube
cd openwhisk-deploy-kube/helm
</code></pre></div><p>Once everything is ready your can create a Kubernetes cluster and install OpenWhisk with just 3 commands:</p><div><pre><code data-lang="fallback">eksctl create cluster --name openwhisk
eksctl create nodegroup --cluster openwhisk --node-labels openwhisk-role=invoker
helm install --set whisk.ingress.type=LoadBalancer openwhisk ./openwhisk
</code></pre></div><p>The cluster creation will take a while. Once it is completed you will get your private OpenWhisk service running in AWS, and you can deploy your chess application to it.</p><p>You can use the <code>wsk</code> or <code>nim</code> CLIs to deploy to OpenWhisk. You have to retrieve the location of the Apache OpenWhisk entry point, and the authorization key and pass them to the CLI tool. The required commands using <code>nim</code> are:</p><div><pre><code data-lang="fallback">cd whisk-chess
APIHOST=$(kubectl  get svc | awk '/openwhisk-nginx/ { print $4}')
AUTH=$(cat openwhisk/values.yaml |  awk '/guest/ { print $2}' | tr -d '"')
nim auth login --apihost http://$APIHOST --auth $AUTH
</code></pre></div><p>It is important to note that we configured an insecure setup because we are accessing OpenWhisk over the unencrypted HTTP protocol.</p><p>In a real world setup you will need additional steps to setup an HTTPS endpoint with a certificate. You will find relevant details in the <a href="https://github.com/apache/openwhisk-deploy-kube">helm chart GitHub repository</a>.</p><p>Once you retrieved the API host and authentication key, you can deploy your chess app, and get the URL.</p><div><pre><code data-lang="fallback">nim action create chess chess.zip --web true --kind go:1.11
nim action get chess --url
</code></pre></div><p>I cannot provide a URL in this case as I a destroyed the cluster after testing, however, you can see the result in the image at the beginning of the paragraph.</p></div></div>]]>
            </description>
            <link>https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662975</guid>
            <pubDate>Fri, 02 Oct 2020 14:30:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boa: an experimental Javascript lexer, parser and compiler written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24662756">thread link</a>) | @jayflux
<br/>
October 2, 2020 | https://boa-dev.github.io/2020/10/02/boa-release-10.html | <a href="https://web.archive.org/web/*/https://boa-dev.github.io/2020/10/02/boa-release-10.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Boa is an experimental Javascript lexer, parser and compiler written in Rust. It has support for some of the language, can be embedded in Rust projects fairly easily and also used from the command line.
Boa also exists to serve as a Rust implementation of the EcmaScript specification, there will be areas where we can utilise Rust and its fantastic ecosystem to make a fast, concurrent and safe engine.</p>

<p>We have a long way to go, however v0.10 has been the biggest release to date, with 138 issues closed!</p>

<p>We have some highlights, but if you prefer to read the full changelog, you can do that <a href="https://github.com/boa-dev/boa/blob/master/CHANGELOG.md">here</a></p>

<h2 id="test262">Test262</h2>

<p>One question we’ve been asked for a long time is “how conformant are you to the spec?”. It’s been tough to answer as we’ve been unable to run against the official test suite.</p>

<p>Test262 is the official ECMAScript Test Suite and exists to provide conformance tests for the latest drafts of the Ecma specification. It is used for all engines, you can even run it in your <a href="https://bakkot.github.io/test262-web-runner/">browser</a>.<br>
Thanks to @Razican in v0.10 we now have a test harness that allows us to run it against Boa at any time.</p>

<p>This is a new crate inside the Boa repository that can parse through all of the tests (roughly 40,000 of them) in under 10 minutes and tell us how conformant we are.</p>

<p><img src="https://boa-dev.github.io/images/2020-10-02/test262-screenshot.png" alt="image"></p>

<p>Today Boa has <span>18</span>% conformity to the specification. We’ll be keeping an eye on this number over the releases. We expect to achieve around 30% by 0.11 due to some of the fixes we’re adding which should pass a few thousand tests.</p>

<p>These are run via Github Actions against PRs and for our master branch so that we can keep track of where we are and if there are regressions.</p>

<h2 id="built-ins">Built-ins</h2>

<p>We’ve added support for <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date"><code>Date</code></a>, <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map"><code>Map</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Symbol">well-known symbols</a>. Supporting Well-known symbols unblocks a lot of work around adding <code>@@iterators</code> to some of our global objects which is coming up in the next release.<br>
Both <code>Math</code> and <code>Number</code> have had their remaining methods implemented.</p>

<h2 id="lexer">Lexer</h2>

<p>The lexer has been rebuilt from scratch. Just like the old parser it was a single file before looping through and becoming unmaintainable. Today we’ve reorganised it into separate modules which know how to lex certain areas. The new lexer <a href="https://github.com/boa-dev/boa/issues/294">now supports goal symbols</a> and can now tokenize with the correct context at any time.</p>

<h3 id="goal-symbols">Goal Symbols</h3>

<p>Our issue with goal symbols is explained by the V8 team:
<a href="https://v8.dev/blog/understanding-ecmascript-part-3#lexical-grammar">https://v8.dev/blog/understanding-ecmascript-part-3#lexical-grammar</a></p>

<p>Previously we weren’t distinguishing between the contexts where some input elements are permitted and some are not, so lexing <code>/</code> would yeild a <code>division</code> symbols when it should be a <code>RegularExpressionLiteral</code> for example. This change unblocked us being able to run Test262.</p>

<p>Performance wise it is much faster for larger files. The lexer is far more efficient at streaming tokens to the parser than previously so in some scenarios we have big gains.</p>

<p><em>You can see all the benchmarks <a href="https://boa-dev.github.io/boa/dev/bench/">here</a></em></p>

<h2 id="repl-syntax-highlighting">Repl syntax highlighting</h2>

<p>Syntax highlighting was added to the repl this release thanks to @HalidOdat<br>
Our repl is made possible due to the great work of <a href="https://github.com/kkawakam/rustyline">RustyLine</a></p>

<p><img src="https://boa-dev.github.io/images/2020-10-02/syntaxHighlighting.gif" alt="image"></p>

<h2 id="looking-forward">Looking forward</h2>

<p>There are plenty of fixes and performance changes still needed, we also hope to experiment with producing Bytecode from our AST in future. Test262 coverage will almost certainly increase, and we are polishing the public API for easier use when embedding into other Rust projects.</p>

<p>Thanks to all those who contributed to 0.10, you can see the names in the full changelog linked above.</p>

<p>You can checkout Boa via <a href="https://github.com/boa-dev/boa">Github</a> or on <a href="https://crates.io/crates/Boa">crates.io</a></p>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://boa-dev.github.io/2020/10/02/boa-release-10.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662756</guid>
            <pubDate>Fri, 02 Oct 2020 14:09:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effective Ways to Market Yourself as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24662671">thread link</a>) | @codersrank
<br/>
October 2, 2020 | https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/ | <a href="https://web.archive.org/web/*/https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>Knowing Javascript inside and out or all the programming languages in the world won’t be enough to help you land a great job that pays incredibly well or secure those amazing opportunities that are hard to come by.</p>



<p>If you want to truly advance your career and succeed as a developer, you need to market yourself. Sure, coding is your passion and you’d rather bury yourself in it, but how would anyone know that you’re good at what you do or even discover you unless you put yourself out there?</p>



<p>When screening for developer positions, many companies pay attention to candidates who have active <a href="https://blog.codersrank.io/profile-2-0/" target="_blank" rel="noreferrer noopener">programmer profiles</a>—a blog, podcast, open-source contributions, YouTube channel, or a history of speaking at tech events—that speaks to their abilities. They view developers with these achievements and experiences as more likely to be talented because their reputation suggests it.</p>



<p><a href="https://giphy.com/gifs/the-office-michael-scott-5B6PQ4lDOlbB6">via GIPHY</a></p>



<p>A little marketing can help you shine brightly in the eyes of potential employers. The last thing you want is to be just another candidate or resume when applying for a job. You need to find a way to stand out from the other stack of papers so that companies are pushed to invite you for an interview or make you an offer.</p>



<p>With effective marketing, you may not even have to go job hunting, opportunities will come knocking at your door. When you share your goals, skills, experiences, and knowledge about your field publicly, it helps to establish you as an expert. As such, companies will be happy to pay you a premium salary rather than hiring one of your seemingly less qualified counterparts.</p>



<p>Now that you understand how important marketing is and how it can enhance your reputation and turn you into a job magnet, we’re going to walk you through actionable steps you can take to successfully market yourself as a developer, stand out from the competition, get on recruiters’ radars, and bag the job offer of your dreams.</p>



<p>We have ranked these steps according to how useful and important they can be in helping you market yourself and your skills effectively.</p>







<ol><li><a href="#portfolio">Build your portfolio</a></li><li><a href="#brand">Build a personal brand</a></li><li><a href="#codersrank">Register a profile on CodersRank</a></li><li><a href="#network">Network with fellow tech professionals</a></li><li><a href="#linkedin">Tidy up your LinkedIn profile</a></li></ol>



<p>Following these steps will help you enlarge your horizons and place your best foot forward so life-changing opportunities can find you. While other developers are scrambling to submit resumes and nail their technical interviews, you’ll already be far ahead.</p>



<p>Let’s take an in-depth look into each of these steps and how you can use them to enhance your career as a software developer and go from chasing after the prize to becoming the prize.</p>



<h2 id="portfolio" data-amp-original-style="color:#50b0ba"><strong>1. Build your portfolio</strong></h2>



<p>As a developer, you know that you need to keep practicing and refining your skills. What you might not know is that you can use the assignments and projects you do to create a portfolio that showcases your expertise.</p>



<p>If you don’t already have a GitHub profile, start by creating one and start pushing code to it regularly, and make your experiments public. This is non-negotiable. GitHub is your <a href="https://blog.codersrank.io/the-evolution-of-the-most-popular-repositories-since-2012/" target="_blank" rel="noreferrer noopener">code repository</a> and it should be used to display all the code you’ve written, projects you’ve worked on, and other interesting code-related activities you’ve been involved in.</p>



<p>Your GitHub account is basically your developer resume because it serves as proof of how well you can code. It says more about your skills than any CV or interview can. Contribute to as many open source libraries as you can. The more open source contributions you have the greater the value prospective employers will see in hiring you.</p>



<p>If you’d like to make valuable contributions to open source libraries, but you’re not sure how to go about submitting one, finding projects to contribute to, or even what kind of contributions you can make, check out these resources:</p>



<ul><li><a href="https://opensource.guide/how-to-contribute/" target="_blank" rel="noreferrer noopener">How to contribute to open source</a></li><li><a href="https://auth0.com/blog/a-first-timers-guide-to-an-open-source-project/" target="_blank" rel="noreferrer noopener">A first timer’s guide to an open source project</a></li><li><a href="https://rubygarage.org/blog/how-contribute-to-open-source-projects" target="_blank" rel="noreferrer noopener">How to contribute to open source projects</a></li></ul>



<p>It’s also important to have a portfolio website where potential employers can go to learn more about you, the work you’ve done, and how your skills and experience can benefit their organization.</p>



<p>When building your portfolio, here are the things you’ll want to pay attention to:</p>



<h3>Set up a professional site</h3>



<p>It makes sense for your domain to be in your name since this is a personal portfolio and people should be able to find it by simply entering your name into a search engine. Make sure you purchase the domain so that you can have full control over it and be able to migrate to a different web platform.</p>



<p>You cannot expect employers to take you seriously if you proclaim yourself to be a talented developer, but your website looks shabby and amateurish. You want anyone who stumbles on your site to be immediately impressed by the layout and design even before they go through any of your pages.</p>



<figure><amp-img src="https://file.mockplus.com/image/2019/07/75f1f76e-eeb4-4166-8cf1-3500d6256538.png" alt="" object-fit="contain" width="1170" height="400" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://file.mockplus.com/image/2019/07/75f1f76e-eeb4-4166-8cf1-3500d6256538.png" alt="" width="1170" height="400" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQwMCcgd2lkdGg9JzExNzAnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption><a href="https://www.mockplus.com/blog/post/web-developer-portfolio" target="_blank" rel="noreferrer noopener">Source</a></figcaption></figure>



<p>Your site should be easy to navigate and visually pleasing. You can decide to code your website from scratch and display it as one of the projects in your portfolio or create one using your preferred web platform. Whatever you choose, remember to keep it simple.</p>



<p>Include a well-designed logo that communicates your values and serves as an accurate representation of who you are and what you do.</p>



<p>Keep in mind that a <strong>personal website is going to mean different things to a back end developer and a front end developer</strong> since they’re different fields. Whichever faction you belong to, you just need to find an approach to your website design and presentation that best represents who you are and what you do.</p>



<p>If you’re a newbie developer, this <a href="https://mikkegoes.com/portfolio-site-on-wordpress/" target="_blank" rel="noreferrer noopener">detailed step-by-step guide</a> will help you build a great-looking portfolio website from scratch to showcase your skills and value to potential employers and help you get hired faster. It covers everything from registering a domain name to choosing a reliable website, creating eye-catching home and about me pages, building contact forms, and more.</p>



<p>Check out these <a href="https://www.springboard.com/blog/programmer-portfolio/" target="_blank" rel="noreferrer noopener">7 best practices for creating a programming portfolio website</a> that stands out. The article also contains tips on mistakes to avoid when building your website and what recruiters look for in a developer portfolio, as well as stunning website examples that are sure to get your creativity flowing.</p>



<h3>Showcase your work</h3>



<p><a href="https://giphy.com/gifs/kodewithklossy-coding-karlie-kloss-kwk-ZG719ozZxGuThHBckn">via GIPHY</a></p>



<p>The point of having an online portfolio is to highlight the work you’ve done in the past and the accomplishments you’re proud of. If you don’t have any concrete work experience yet, you can start by creating a single web page and adding links to other online profiles you have like your social media and GitHub account.</p>



<p>When you write articles, host webinars, give talks, contribute to open source libraries, create tutorial videos, or work on anything interesting, update your site accordingly. Explain what each project is about, why it’s important, and when it was done.</p>



<p>Don’t just go on and on about the agile methodologies, frameworks, and programming languages that you know. Display that project you built using Javascript, PHP, CSS, or whatever tech stacks you say you’re familiar with. </p>



<p>Let visitors see the skills you possess in action and how you can use these skills to grow their business. This will establish your expertise, credibility, and trustworthiness.</p>



<h3>Share your story</h3>



<p>Don’t be shy about being yourself. Let your personality shine through. Describe yourself as honestly as you can. What is it that makes you special? What struggles, failures, or challenges have you encountered over the course of your career? Employers don’t want to hire mindless code monkeys, but people they can relate to.</p>



<h3>Include your contact details</h3>



<p>Give visitors and potential employers a way to reach you. Add your email address and phone number or create a simple contact form they can fill out. If they have to jump through hoops to find your contact information, you might miss out on many good opportunities.</p>



<h2 id="brand" data-amp-original-style="color:#50b0ba"><strong>2. Build a personal brand</strong></h2>



<p>Personal branding is simply a way of making yourself known for something. As a programmer, you not only want to be competent in your field, you also want people to see you that way. Thanks to the internet, it’s easier than ever to create a brand around yourself.</p>



<p>Ask yourself what you want to be known for? Who are you and what do you want to represent? What is your core message? What do you want people to think of when they see or hear your name? Once you have this figured out, start putting this message out there and making sure it’s reflected in everything you do.</p>



<p>Here are some of the ways you can create a strong personal brand and actively promote yourself:</p>



<h3>Clean up assets related to communication</h3>



<p>Come up with a logo for your brand if you don’t already have one. It should be something simple, eye-catching, and an accurate representation of who you are and what you’re about. Don’t go changing your logo every week or so. Find one that works for you and use it everywhere.</p>



<p>Get professional headshots taken to use as cover images for your online profiles. Go through your social media accounts and public forums and delete any inappropriate messages or comments that don’t align with the image you want to project or reflect badly on you as a person.</p>



<h3>Start a blog</h3>



<p>A blog can be a wonderful way to showcase your skills as a developer, become well-known in your industry, and attract potential clients or employers.</p>



<p>Your blog doesn’t have to have tens of thousands of readers, but you do need to build a decent audience. You can do this by sharing useful information that adds some kind of value to your readers’ lives. Talk about your professional journey, the challenges you’ve faced along the way, and how you overcame them.</p>



<p>Teach people how to solve problems. Show examples of work you’ve done in the past to help junior developers find their way and build themselves up. Think of something you’ve struggled with that you found a solution …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/">https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/</a></em></p>]]>
            </description>
            <link>https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662671</guid>
            <pubDate>Fri, 02 Oct 2020 14:00:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust lets us monitor 30k API calls/min]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662530">thread link</a>) | @jerodsanto
<br/>
October 2, 2020 | https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/ | <a href="https://web.archive.org/web/*/https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<p>At Bearer, we are a polyglot engineering team. Both in spoken languages and programming languages. Our stack is made up of services written in Node.js, Ruby, Elixir, and a handful of others in addition to all the languages our agent library supports. Like most teams, we balance using the right tool for the job with using the right tool for the time. Recently, we reached a limitation in one of our services that led us to transition that service from Node.js to Rust. This post goes into some of the details that caused the need to change languages, as well as some of the decisions we made along the way.</p><h2 id="a-bit-of-context"><strong>A bit of context</strong></h2><p>We are building a solution to help developers monitor their APIs. Every time a customer’s application calls an API, a log gets sent to us where we monitor and analyze it.</p><p>At the time of the issue, we were processing an average of 30k API calls per minute. That's a lot of API calls made across all our customers. We split the process into two key parts: Log ingestion and log processing.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion-service---node.jpg" alt="Original architecture with Node.js" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion-service---node.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion-service---node.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion-service---node.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion-service---node.jpg 2400w"></figure><p>We originally built the ingestion service in Node.js. It would receive the logs, communicate with an elixir service to check customer access rights, check rate limits using Redis, and then send the log to CloudWatch. There, it would trigger an event to tell our processing worker to take over.</p><p>We capture information about the API call, including the payloads (both the request and response) of every call sent from a user's application. These are currently limited to 1MB, but that is still a large amount of data to process. We send and process everything asynchronously and the goal is to make the information available to the end-user as fast as possible.</p><p>We hosted everything on AWS Fargate, a serverless management solution for Elastic Container Service (ECS), and set it to autoscale after 4000 req/min. Everything was great! Then, the invoice came 😱.</p><p>AWS invoices based on CloudWatch storage. The more you store, the more you pay.</p><p>Fortunately, we had a backup plan.</p><h2 id="kinesis-to-the-rescue"><strong>Kinesis to the rescue?</strong></h2><p>Instead of sending the logs to CloudWatch, we would use<a href="https://aws.amazon.com/kinesis/data-firehose/"> Kinesis Firehose</a>. Kinesis Firehose is basically a Kafka equivalent provided by AWS. It allows us to deliver a data stream in a reliable way to several destinations. With very few updates to our log processing worker, we were able to ingest logs from both CloudWatch and Kinesis Firehose. With this change, daily costs would drop to about 0.6% of what they were before.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion---node_kinesis.jpg" alt="Architecture after adding Kenesis" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion---node_kinesis.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion---node_kinesis.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion---node_kinesis.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion---node_kinesis.jpg 2400w"></figure><p>The updated service now passed the log data through Kinesis and into s3 which triggers the worker to take over with the processing task. We rolled the change out and everything was back to normal... or we thought. Soon after, we started to notice some anomalies on our monitoring dashboard.</p><p><strong>We were Garbage Collecting</strong>, a lot. Garbage collection (GC) is a way for some languages to automatically free up memory that is no longer in use. When that happens, the program pauses. This is known as a <em>GC pause</em>. The more writes you make to memory, the more garbage collection needs to happen and as a result, the pause time increases. For our service, these pauses were growing high enough that they caused the servers to restart and put stress on the CPU. When this happens, it can look like the server is down—because it temporarily is—and our customers started to see 5xx errors for roughly 6% of the logs our agent was trying to ingest.</p><p>Below we can see the pause time and pause frequency of the garbage collection:</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/gc-pause.jpg" alt="GC pause and frequency charts" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/gc-pause.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/gc-pause.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/gc-pause.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/gc-pause.jpg 2400w"></figure><p>In some instances, the pause time breached <strong>4 seconds</strong> (as shown on the left), with up to <strong>400 pauses per minute</strong> (as shown on the right) across our instances.</p><p>After some more research, we appeared to be another victim of a<a href="https://github.com/aws/aws-sdk-js/issues/329"> memory leak in the AWS Javascript SDK</a>. We tried increasing the resource allocations to extreme amounts, like autoscaling after 1000 req/min, but nothing worked.</p><h2 id="possible-solutions"><strong>Possible solutions</strong></h2><p>With our backup plan no longer an option, we moved on to new solutions. First, we looked at those with the easiest transition path.</p><h3 id="elixir"><strong>Elixir</strong></h3><p>As mentioned earlier, we are checking the customer access rights using an Elixir service. This service is private and only accessible from within our Virtual Private Cloud (VPC). We have never experienced any scalability issues with this service and most of the logic was already there. We could simply send the logs to Kinesis from within this service and skip over the Node.js service layer. We decided it was worth a try.</p><p>We developed the missing parts and tested it. It was better, but still not great. Our benchmarks showed that there were still high levels of Garbage Collecting, and we were still returning 5xx to our users when consuming the logs. At this point, the heavy load triggered a <a href="https://github.com/benoitc/hackney/issues/594">(now resolved) issue</a> with one of our elixir dependencies.</p><h3 id="go"><strong>Go</strong></h3><p>We considered Golang as well. It would have been a good candidate, but in the end, it is another Garbage Collected Language. While likely more efficient than our previous implementation, as we scale there is a high chance we'd run into similar problems. With these limitations in mind, we needed a better option.</p><h2 id="re-architecting-with-rust-at-the-core"><strong>Re-architecting with Rust at the core</strong></h2><p>In both our original implementation and our backup, the core issue remained the same: garbage collection. The solution was to move to a language with better memory management and no garbage collection. Enter Rust.</p><p>Rust isn't a garbage-collected language. Instead, it relies on a concept called <em>ownership</em>.</p><blockquote>Ownership is Rust’s most unique feature, and it enables Rust to make memory safety guarantees without needing a garbage collector. <br>— <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">The Rust Book</a></blockquote><p>Ownership is the concept that often makes Rust difficult to learn and write, but also what makes it so well suited for situations like ours. Each value in Rust has a single owner variable and as a result a single point of allocation in memory. Once that variable goes out of scope the memory is immediately returned.</p><p>Since the code required to ingest the logs is quite small, we decided to give it a try. To test this we addressed the very thing that we had issues with—sending large amounts of data to Kinesis.</p><p>Our first benchmarks proved to be very successful.</p><p>From that point, we were pretty confident that Rust could be the answer and we decided to flesh out the prototype into a production-ready application.</p><p>Over the course of these experiments, rather than directly replacing the original Node.js service with Rust, we restructured much of the architecture surrounding log ingestion. The core of the new service is an <a href="https://www.envoyproxy.io/">Envoy</a> proxy with the Rust application as a sidecar.</p><p>Now, when the Bearer Agent in a user's application sends log data to Bearer, it goes into the Envoy proxy. Envoy looks at the request and communicates with Redis to check things like rate limits, authorization details, and usage quotas. Next, the Rust application running alongside Envoy prepares the log data and passes it through Kinesis into an s3 bucket for storage. S3 then triggers our worker to fetch and process the data so Elastic Search can index it. At this point, our users can access the data in our dashboard.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion---rust.jpg" alt="Diagram of new rust service" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion---rust.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion---rust.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion---rust.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion---rust.jpg 2400w"></figure><p>What we found was that with fewer—and smaller—servers, we are able to process even more data without any of the earlier issues.</p><p>If we look at the latency numbers for the Node.js service, we can see peaks with an average response time nearing 1700ms.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/before-latency.png" alt="Latency with original Node.js service" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/before-latency.png 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/before-latency.png 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/before-latency.png 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/before-latency.png 2400w"></figure><p>With the Rust service implementation, the latency dropped to below 90ms, even at its highest peak, keeping the average response time below 40ms.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/after-latency.png" alt="Latency after re-architecture" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/after-latency.png 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/after-latency.png 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/after-latency.png 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/after-latency.png 2400w"></figure><p>The original Node.js application used about 1.5GB of memory at any given time, while the CPUs ran at around 150% load. The new Rust service used about 100MB of memory and only 2.5% of CPU load.</p><h2 id="conclusion"><strong>Conclusion</strong></h2><p>As with most startups, we move fast. Sometimes the best solution at the time isn't the best solution forever. This was the case with Node.js. It allowed us to move forward, but as we grew we also outgrew it. As we started to handle more and more requests, we needed to make our infrastructure evolve to address the new requirements. While this process started with a fix that merely replaced Node.js with Rust, it led to a rethinking of our log ingestion service as a whole.</p><p>We still use a variety of languages throughout our stack, including Node.js, but will now consider Rust for new services where it makes sense.<br></p>
	</section></div>]]>
            </description>
            <link>https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662530</guid>
            <pubDate>Fri, 02 Oct 2020 13:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One function is all you need for ML Experiments]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24662085">thread link</a>) | @LexSiga
<br/>
October 2, 2020 | https://www.logicalclocks.com/blog/hopsworks-ml-experiments | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/hopsworks-ml-experiments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; Hopsworks provides support for machine learning (ML) experiments. That is, it can automatically track the artifacts, graphs, performance, logs, metadata, and dependencies of your ML programs.Many of you already know about platforms like <a href="https://mlflow.org/">MLflow</a>, so why should you read about Hopsworks Experiments?&nbsp; Because you do not have to rewrite your TensorFlow/PyTorch/Scikit-learn programs to get <strong>tracking and distributed ML for free</strong>, and TensorBoard comes built-in. We discuss how Hopsworks uniquely supports implicit provenance to transparently create metadata and how it is combined with the oblivious training function to make your training distribution transparent.&nbsp;</p><h2>Hopsworks Introduction</h2><p>Hopsworks is a single platform for both data science and data engineering that is available as both an <a href="http://github.com/logicalclocks/hopsworks">open-source platform</a> and a <a href="http://www.hopsworks.ai/">SaaS platform</a>, including a built-in <a href="https://www.logicalclocks.com/hopsworks-featurestore">feature store</a>. You can train models on GPUs at scale, easily install any Python libraries you want using pip/conda, run Jupyter notebooks as jobs, put those jobs in Airflow pipelines, and even write (Py)Spark or Flink applications that run at scale.&nbsp;</p><p>As a development environment, Hopsworks provides a central, collaborative development environment that enables machine learning teams to easily share results and experiments with teammates or generate reports for project stakeholders. All resources have strong security, data governance, backup and high availability support in Hopsworks, while assets are stored in a single distributed file system (with data stored on S3 in the cloud).<br></p><figure id="w-node-a0d33d55738e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f74366329e691163a9537f8_mT5Xl3PGQNailTwXRoPhMMlEZePoa3PjlnagKaWj7mJxckcqP1SfcSbkOS3P-adIEnIq7kURxZ-TJ4ypWTt7yw94d_vqkB9o2FMTUrosMB8Pnxz0pPYkehYlOoJySGBdjPuDNQ7I.gif" alt=""></p><figcaption>A Hopsworks ML experiment stores information about your ML training run: logs, images, metrics of interest (accuracy, loss), the program used to train the model, its input training data, and the conda dependencies used. Optional outputs are hyperparameters, a TensorBoard, and a Spark history server.</figcaption></figure><figure id="w-node-06188dbd9c79-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743664aeafc406b94b027c_hraL3X_VAEzOtdesnelgqqb4FQcVGC8Q6J0-KQM0UPGGQxgU_TlMb_-LIZuMOszzdZIhxEZogwxlSSfOMdZvcAIgRlLZzoNg2dLmoPUSrNWyK0CABpAglOV9q9SqfogrRxoO6k29.gif" alt=""></p><figcaption>The logs of each hyperparameter trial are retrieved by clicking on its log, and TensorBoard visualizes the different trials results. The TensorBoard HParams plugin is also available to drill down further on the trials.</figcaption></figure><p>When you run a Python or PySpark application on the Hopsworks platform, it can create an<strong> experiment</strong> that includes both the traditional information a program generates (results, logs, errors) as well as ML-specific information to help track, debug, and reproduce your program and its inputs and outputs:</p><ul role="list"><li><strong>hyperparameters</strong>: parameters for training runs that are not updated by the ML programs themselves;&nbsp;</li><li><strong>metrics</strong>: the loss or accuracy of the model(s) trained in this experiment;</li><li><strong>program artifacts</strong>: <em>python/pyspark/airflow</em> <em>programs, </em>and their <em>conda environments</em>;</li><li><strong>model artifacts</strong>: serialized <em>model objects,</em> <em>model schemas</em>, and <em>model checkpoints</em>;</li><li><strong>executions</strong>: information to be able to re-execute the experiment, including parameters, versioned features for input, output files,&nbsp; etc;&nbsp;</li><li><strong>versioned features</strong>: to be able to reproduce an experiment, we need the exact training/test data from the run and how it was created from the feature store;</li><li><strong>visualizations</strong>: images generated during training and score. Also use TensorBoard to visualize training runs - Hopsworks aggregates results from all workers transparently;</li><li><strong>logs (for debugging)</strong>: model weights, gradients, losses, optimizer state;</li><li><strong>custom metadata</strong>: tag experiments and free-text search for them, govern experiments (label as ‘PII’, ‘data-retention-period’, etc), and reproduce training runs.</li></ul><figure id="w-node-55f328a117c2-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f748ce6a667fe73eb582948_Screenshot%202020-09-30%20at%2015.48.58.png" loading="lazy" alt=""></p></figure><h2>Experiment Tracking and Distributed ML in One Library</h2><figure id="w-node-be7859ba57d5-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5ef49c1e473b2c283eb616aa_nXpYXacWzP67N5MmHnhldoZJw6qVoDwpBnTd3JQzx9nFuX9_FVm-fmWztjYeLdun5BI83RGOdD1ibvFFWBHUCvQGtbenUY1f6haaE58VP5aAHHJOSWpf0P8FJkfPuE5JMAfMlcOk.png" alt=""></p></figure><p>
    -- CODE language-bash --
def train(data_path, max_depth, min_child_weight, estimators): 
    X_train, X_test, y_train, y_test = build_data(..)
    ...
    print("hello world") # monkeypatched - prints in notebook
    ...
    model.fit(X_train, y_train) # auto-logging
    ...
    hops.export_model(model, "tensorflow",..,model_name)
    ...
    # create local files ‘logile.txt’, ‘diagram.png’ 
    return {'accuracy': accuracy, 'loss': loss, 'logfile':
       'logfile.txt', 'diagram': 'diagram.png'} # track dict

from maggy import experiment
experiment.lagom(train, name="My Experiment", ...) 

# To launch as a distributed ML HParam Tuning job:
# sp=Searchspace(max_depth=('INTEGER',[2,8]),min_child_weight
# =('INTEGER', [2, 8]), )
# experiment.lagom(train, name=“HP, optimizer='randomsearch',                          
# direction='max', num_trials=15,)
</p><p>Platforms that support experiment tracking require the user to refactor their training code in a function or some explicit scope (such as “with … as xx:” in MLFlow, see Appendix A) to identify when an experiment begins and when an experiment ends. In Hopsworks, we require the developer to write their training code inside a function.&nbsp;</p><p>We call this Python function an <em>oblivious training function</em> because the function is oblivious of whether it is being run on a Python kernel in a Jupyter notebook or on many workers in a cluster, see our <a href="https://www.logicalclocks.com/blog/unifying-single-host-and-distributed-machine-learning-with-maggy">blog </a>and <a href="https://www.logicalclocks.com/blog/unifying-single-host-and-distributed-machine-learning-with-maggy">Spark/AI summit talk</a> for details. That is, you write your training code once and reuse the same function when training a small model on your laptop or when performing hyperparameter tuning or distributed training on a large cluster of GPUs or CPUs.</p><p>We double down on this “wrapper” Python function by also using it to start/stop experiment tracking. Experiment tracking and distribution transparency in a single function, nice!&nbsp;</p><p>In Hopsworks, the <a href="https://github.com/logicalclocks/maggy">Maggy</a> library runs experiments, see code snippet above. As you can see, the only code changes a user needed compared to a best-practice TensorFlow program are:&nbsp;<br></p><ol role="list"><li>factor the training code in a user-defined function (<strong>def train(..):</strong>);</li><li>return a Python dict containing the results, images, and files that the user wants to be tracked for the experiment and accessible later in the Experiments UI; and</li><li>invoke the training function using the <em>experiment.lagom</em> function.<br></li></ol><p>The hyperparameters can be fixed for a single execution run, or as shown in the last 4 lines of the code snippet, you can execute the <em>train function </em>as a distributed hyperparameter tuning job across many workers in parallel (with GPUs, if needed).&nbsp;</p><p>Hopsworks will automatically:</p><ul role="list"><li>track all parameters of the train function as hyperparameters for this experiment,&nbsp;</li><li>auto-log using Keras callbacks in model.fit;</li><li>create a versioned directory in HopsFS, where a copy of the program, its conda environment, and all logs from all workers are aggregated;</li><li>track all provenance information for this application - input data from HopsFS used in this experiment (train/test datasets from the Feature Store), and all output artifacts (models, model checkpoints, application logs);</li><li>redirect all print statements executed in workers to the Jupyter notebook cell for easier debugging (see GIF below - each print statement is prefixed by the worker ID).<br></li></ul><figure id="w-node-756fb7ca0b23-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f74366291399a79d18af461_4BATblXBajOTlBXREg6utXoqcRgymvySZx03Hh_JeYvjJ7YLGzxYpnUgMwCvHaNxMFgj_XepZ23xJh3QFnfhHsAetRlt24IkRw4BI8R4Wo5gaQLkVuuIRRbE8CK7swOEJaa-Lm-k.gif" alt=""></p><figcaption>In Hopsworks, logs from workers can be printed in your Jupyter notebook during training. Take that Databricks!</figcaption></figure><h2>TensorBoard support</h2><p>
    -- CODE language-bash --
    
    def train():
    from maggy import tensorboard
    ...
    model.fit(.., callbacks=[TensorBoard(log_dir=tensorboard.logdir(),..)], ...)
</p><p>TensorBoard is arguably the most common and powerful tool used to visualize, profile and debug machine learning experiments. Hopsworks Experiments integrates seamlessly with TensorBoard. Inside the training function, the data scientist can simply import the <em>tensorboard</em> python<em> </em>module and get the folder location to write all the TensorBoard files. The content of the folder is then collected from each Executor and placed in the experiment directory in HopsFS. As TensorBoard supports showing multiple experiment runs in the same graph, visualizing and comparing multiple hyperparameter combinations becomes as simple as starting the TensorBoard integrated in the Experiments service. By default, Tensorboard is configured with useful plugins such as HParam, Profiler, and Debugging.&nbsp;</p><h3>Profiling and debugging</h3><p>Hopsworks 1.4.0 comes with TensorFlow 2.3, which includes the TensorFlow profiler. A new long-awaited feature that finally allows users to profile model training to identify bottlenecks in the training process such as slow data loading or poor operation placement in CPU + GPU configurations.&nbsp;</p><p>TensorFlow 2.3 also includes Debugger V2, making it easy to find model issues such as NaN which are non-trivial to find the root cause of in complex models.<br></p><figure id="w-node-821b5c19e74e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743661e73aacd6dc310040_Rywm-fmUfHouqW1zVdYsZ88LvtAYDvCZPpze3hHJeENCBjPVPkkpy_J-2bescj5Z-Xlb7A7DNpmNws1H4lsmUsuOpLROLO_S16jFM_CI-6JdACYY5Rp3Q3yYVMfkecV7aK7ECsf_.png" alt=""></p></figure><figure id="w-node-fc6081bc518f-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743662849afea39f14cb69_S0v-cuc6N5MT4gsC3KUBFa3dQi7ZZBEaF9w684FzTrmXH4FPHkDEFCaMy2ThIpmSHDHSY-vmXCvXyDVrMVS_FYy3vnODkL8uXcHrm4uIlNjhNHHhsxoMghDrFfX_Yn_eVe1eYBbE.png" alt=""></p></figure><h2>Model Registry</h2><figure id="w-node-6cad6e721c68-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743662ec097905b0778b6b_KcTuR12rSnRVQSSDh-eLxqM0ad3eAXSGCkehOJ8ik2BPfnohgCfudLLx7HkUIk3DKfTTxz-DzRwlJ7OAYU0eafq0bwSN2tYy7dt_rnOeth550yYPqa-esKRO6uGREvB1C4iNjk3l.png" alt=""></p></figure><p>In the training code models may be exported and saved to HopsFS. Using the <em>model </em>python module in the <a href="https://hops-py.logicalclocks.com/">hops library</a>, it is easy to version and attach meaningful metadata to models to reflect the performance of a given model version.&nbsp;</p><p>The Hopsworks Model Registry, is a service where all models are listed in addition to useful information such as which user created the model, different versions, time of creation and evaluation metrics such as accuracy.&nbsp;</p><p>The Model Registry provides functionality to filter based on the model name, version number and the user that exported the model. Furthermore the evaluation metrics of model versions can be sorted in the UI to find the best version for a given model.&nbsp;</p><p>In the Model Registry UI, you can also navigate to the experiment used to train the model, and from there to the train/test data used to train the model, and from there to the features in the feature store used to create the train/test data. Thanks, provenance!<br></p><h3>Exporting a model</h3><p>A model can be exported programmatically by using the <em>export</em> function in the <em>model</em> module. Prior to exporting the model, the experiment needs to have written a model to a folder or to a path on HopsFS. Then that path is supplied to the function along with the name of the model and the evaluation metrics that should be attached. The <em>export</em> call will upload the contents of the folder to your Models dataset and it will also appear in the Model Registry with an incrementing version number for each export.</p><p>
    -- CODE language-bash --
    from hops import model

# local path to directory containing model (e.g. .pb or .pk) 
path = os.getcwd() + “/model_dir”

# uploads path to the model repository, metadata is a dict of metrics</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/hopsworks-ml-experiments">https://www.logicalclocks.com/blog/hopsworks-ml-experiments</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/hopsworks-ml-experiments</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662085</guid>
            <pubDate>Fri, 02 Oct 2020 12:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Fistful of States: More State Machine Patterns in Rust]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24661395">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://deislabs.io/posts/a-fistful-of-states/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/a-fistful-of-states/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Earlier this year, DeisLabs released Krustlet, a project to implement Kubelet
in Rust. <sup id="fnref:Fisher"><a href="#fn:Fisher">1</a></sup> <sup id="fnref:Squillace"><a href="#fn:Squillace">2</a></sup> Kubelet is the component of Kubernetes that
runs on each node which is assigned Pods by the control plane and runs them on
its node. Krustlet defines a flexible API in the <code>kubelet</code> crate, which allows
developers to build Kubelets to run new types of workloads. The project
includes two such examples, which can run Web Assembly workloads on WASI or
waSCC runtimes. <sup id="fnref:wasmtime"><a href="#fn:wasmtime">3</a></sup> <sup id="fnref:waSCC"><a href="#fn:waSCC">4</a></sup> Beyond this, I have been working to
develop a Rust Kubelet for traditional Linux containers using the Container
Runtime Interface (CRI). <sup id="fnref:krustlet-cri"><a href="#fn:krustlet-cri">5</a></sup> <sup id="fnref:CRI"><a href="#fn:CRI">6</a></sup></p>

<p>Over the last few releases, Krustlet has focused on expanding the functionality
of these Web Assembly Kubelets, such as adding support for init containers,
fixing small bugs, and log streaming. This, in turn, has built quite a bit of
interest in alternative workloads and node architectures on Kubernetes, as well
as demonstrated the many strengths of Rust for development of these types of
applications.</p>

<p>For the <code>v0.5.0</code> release, we turned our attention to the internal architecture
of Krustlet, in particular how Pods move through their lifecycle, how
developers write this logic, and how updates to the Kubernetes control plane
are handled. <sup id="fnref:Pod-Lifecycle"><a href="#fn:Pod-Lifecycle">7</a></sup> We settled upon a state machine implementation
which should result in fewer bugs and greater fault tolerance. This refactoring
resulted in substantial changes for consumers of our API; however we believe
this will result in code that is much easier to reason about and maintain. For
an excellent summary of these changes, and description of how you can migrate
code that depends on the <code>kubelet</code> crate, please see Taylor Thomas’ excellent
<a href="https://github.com/deislabs/krustlet/releases/tag/v0.5.0">Release Notes</a>.
In this post I will share a deep dive into our new architecture and the
development journey which led to it.</p>

<h2 id="the-trailhead">The Trailhead</h2>

<p>Before <code>v0.5.0</code>, developers wishing to implement a Kubelet using Krustlet
primarily needed to implement the <code>Provider</code> trait, which allowed them to write
methods for handling events like <code>add</code>, <code>delete</code>, and <code>logs</code> for Pods scheduled
to that node. This offered a lot of flexibility, but was a very low-level API.
We identified a number of issues with this architecture:</p>

<ul>
<li>The entire lifecycle of a Pod was defined in 1 or 2 monolithic methods of the
<code>Provider</code> trait. This resulted in messy code and a very poor understanding
of error handling in the many phases of a Pod’s lifecycle.</li>
<li>Pod and Container status patches to the Kubernetes control plane were
scattered throughout the codebase, both in the <code>kubelet</code> crate and the
<code>Provider</code> implementations. This made it very difficult to reason about what
was actually reported back to the user and when, and involved lot of repeated
code.</li>
<li>Unlike the Go Kubelet, if Krustlet encountered an error it would report the
error back to Kubernetes and then (most of the time) end execution of the
Pod. There was no built-in notion of the reconciliation loop that one expects
from Kubernetes.</li>
<li>We recognized that a lot of these issues were left to each developer to
solve, but were things that any Kubelet would need to handle. We wanted to
move this kind of logic into the <code>kubelet</code> crate, so that each provider did
not have to reinvent things.</li>
</ul>

<h2 id="our-mission">Our Mission</h2>

<p>At its core, Kubernetes relies on declarative (mostly immutable) manifests, and
controllers which run reconciliation loops to drive cluster state to match this
configuration. Kubelet is no exception to this, with its focus being
indivisible units of work, or Pods. Kubelet simply monitors for changes to Pods
that have been assigned to it by <code>kube-scheduler</code>, and runs a loop to attempt
to run this work on its node. In fact, I would describe Kubelet as no different
from any other Kubernetes controller, except that it has the additional
first-class capability for streaming logs and exec sessions. However these
capabilities, as they are implemented in Krustlet, are orthogonal to this
discussion.</p>

<p>Our goal with this rewrite was to ensure that Krustlet would mirror the official
Kubelet’s behavior as closely as possible. We found that many details about
this behavior are undocumented, and spent considerable time running the
application to infer its behavior and inspecting the Go source code. Our
understanding is as follows:</p>

<ul>
<li>The Kubelet watches for Events on Pods that have been scheduled to it by
<code>kube-scheduler</code>.</li>
<li>When a Pod is added, the Kubelet enters a control loop to attempt to run the
Pod which only exits when the Pod is <code>Completed</code> (all containers
exit successfully) or <code>Terminated</code> (Pod is marked for deletion via the
control plane and execution is interrupted).</li>
<li>Within the control loop, there are various steps such as <code>Image Pull</code>,
<code>Starting</code>, etc., as well as back-off steps which wait some time before
retrying the Pod. At each of these steps, the Kubelet updates the control
plane.</li>
</ul>

<p>We recognized this pretty quickly as a finite-state machine design pattern,
which consists of infallible state handlers and valid state transitions. This
allows us to address the issues mentioned above:</p>

<ul>
<li>Break up the <code>Provider</code> trait methods for running the Pod into short,
single-focus state handler methods.</li>
<li>Consolidate status patch code to where a Pod enters a given state.</li>
<li>Include error and back-off states in the state graph, and only stop
attempting to execute a Pod on <code>Terminated</code> or <code>Complete</code>.</li>
<li>Move as much of this logic into <code>kubelet</code> as possible so that providers need
only focus on implementing the state handlers.
<br></li>
</ul>

<p>With this architecture it becomes very easy to understand the behavior of the
application, and strengthens our confidence that the application will not enter
undefined behavior. In addition, we felt that Rust would allow us to achieve
our goals while presenting an elegant API to developers, and with full
compile-time enforcement of our state machine rules.</p>

<h2 id="our-animal-guide">Our Animal Guide</h2>

<p>When first discussing the requirements of our state machine, and the daunting
task of integrating it with the existing Krustlet codebase, we recalled an
excellent blog post,
<a href="https://hoverbear.org/blog/rust-state-machine-pattern/">Pretty State Machine Patterns in Rust</a>,
by Ana Hobden (hoverbear), which I think has inspired a lot of Rust developers.
The post explores patterns in Rust for implementing state machines which
satisfy a number of constraints and leverage Rust’s type system. I encourage
you to read the original post, but for the sake of this discussion I will
paraphrase the final design pattern here:</p>

<pre><code>struct StateMachine&lt;S&gt; {
    state: S,
}

struct StateA;

impl StateMachine&lt;StateA&gt; {
    fn new() -&gt; Self {
        StateMachine {
            state: StateA
        }
    }
}

struct StateB;

impl From&lt;StateMachine&lt;StateA&gt;&gt; for StateMachine&lt;StateB&gt; {
    fn from(val: StateMachine&lt;StateA&gt;) -&gt; StateMachine&lt;StateB&gt; {
        StateMachine {
            state: StateB 
        }
    }
}

struct StateC;

impl From&lt;StateMachine&lt;StateB&gt;&gt; for StateMachine&lt;StateC&gt; {
    fn from(val: StateMachine&lt;StateB&gt;) -&gt; StateMachine&lt;StateC&gt; {
        StateMachine {
            state: StateC 
        }
    }
}

fn main() {
    let in_state_a = StateMachine::new();

    // Does not compile because `StateC` is not `From&lt;StateMachine&lt;StateB&gt;&gt;`.
    // let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_a);

    let in_state_b = StateMachine::&lt;StateB&gt;::from(in_state_a);

    // Does not compile because `in_state_a` was moved in the line above.
    // let in_state_b_again = StateMachine::&lt;StateB&gt;::from(in_state_a);

    let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_b);
}
</code></pre>

<p>Ana introduces a number of requirements for a good state machine
implementation, and achieves them with concise and easily interpretable code.
In particular, these requirements (some based on the definition of a state
machine, and some on ergonomics) were a high priority for us:</p>

<ul>
<li>One state at a time.</li>
<li>Capability for shared state.</li>
<li>Only explicitly defined transitions should be permitted.</li>
<li>Any error messages should be easy to understand.</li>
<li>As many errors as possible should be identified at <strong>compile-time</strong>.</li>
</ul>

<p>In the next section I will discuss some additional requirements that we
introduced and how these impacted the solution. In particular, we relaxed some
of Ana’s goals in exchange for greater flexibility, while satisfying those
listed above.</p>

<h2 id="tribulation">Tribulation</h2>

<p>We were off to a great start, but it was time to consider how we want
downstream developers to interact with our new state machine API. In
particular, while the Kubelets we are familiar with all follow roughly the same
Pod lifecycle, we wanted developers to be able to implement arbitrary state
machines for their Kubelet. For example, some workloads or architectures may
need to have additional provisioning states for infrastructure or data, or
to introduce post-run states for proper garbage collection of resources.
Additionally, it felt like an anti-pattern to have a parent method (<code>main</code> in
the example above) which defines the logic for progressing through the states,
as this felt like having two sources of truth and was not something we could
implement on behalf of our downstream developers for arbitrary state machines.
Ana had discussed how to hold the state machine in a parent structure using an
<code>enum</code>, but it felt clunky to introduce large match statements which could
introduce runtime errors.</p>

<p>We knew that to allow arbitrary state machines we would need a <code>State</code> trait to
mark types as valid states. We felt that it would be possible for this trait to
have a <code>next()</code> method which runs the state and then returns the next <code>State</code>
to transition to, and we wanted our code to be able to simply call <code>next()</code>
repeatedly to drive the machine to completion. This pattern, we soon found,
introduced a number of challenges.</p>

<pre><code>/// Rough pseudocode of our plan.

trait State {
    /// Do work for this state and return next state.
    async fn next(self) -&gt; impl State;
}

fn drive_state_machine(mut state: impl State) {
    loop {
        state = state.next().await;
    }
}
</code></pre>

<h3 id="what-does-next-return">What does <code>next()</code> return?</h3>

<p>Within our loop, we are repeatedly overwriting a local variable with
<em>different</em> types that all implement <code>State</code>. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/a-fistful-of-states/">https://deislabs.io/posts/a-fistful-of-states/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/a-fistful-of-states/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661395</guid>
            <pubDate>Fri, 02 Oct 2020 11:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privacy is the most important concept of our time]]>
            </title>
            <description>
<![CDATA[
Score 416 | Comments 198 (<a href="https://news.ycombinator.com/item?id=24661271">thread link</a>) | @umilegenio
<br/>
October 2, 2020 | https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/ | <a href="https://web.archive.org/web/*/https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-25770" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p><em>In case you are coming from Hacker News and are confused about some comments, be aware that I updated the essay to deal with some criticism</em>.</p>



<p>The title is not hyperbole. I do think that privacy is the most important concept of our time. Let me tell you why:</p>



<ul><li><strong>internet is not a virtual world anymore</strong>, it is a dimension that permeates our lives; we work, socialize and get informed through the internet</li><li><strong>our society is more diverse</strong>; we have some things in common with our neighbors and some with separate communities</li><li><strong>privacy is integral to separate the</strong> <strong>different parts of our lives</strong>; once the separation could be just physical and accidental (i.e., you live here and work there), now it must be built intentionally because there are no natural barriers in information spreading</li></ul>



<p>In short, internet has made sharing information easier and complexity has made information more dangerous. We need to evolve our understanding of rules and norms to deal with this new situation. </p>



<p>I have always believed in the importance of privacy, but I felt that common definitions (e.g., <em>the right to be left alone</em>) were lacking. In fact, I think that the whole conceptualization of privacy as simply a right of an individual and regarding private information as partial and limiting.</p>



<p>Think about this: the government can send policemen to surveil you and everybody they deem interesting. However, it can do this only for few people. <strong>This limitation is due to physical constraints, not legal ones</strong>. There is a limited number of policemen and you would notice if there was a police car in front of each house of the neighborhood. <strong>This is not true for internet communications: the government can spy everyone at once and you would never notice</strong>. As many whistleblowers have revealed, this is what the NSA has actually done.</p>



<p>So, the changes in society affect privacy directly but may also affect all our rights indirectly. Privacy is the fundamental principle that must respond to these changes.</p>



<p>You might say that then, maybe, I am not really thinking about privacy, but rather something else. That might be true, so let’s not talk about privacy, instead let’s talk about <a href="https://en.wikipedia.org/wiki/Definitions_of_fascism#Umberto_Eco">Ur-Privacy</a>, the principles of any possible concept of privacy. Take this essay as the opinion of a random guy that cares about the issue.</p>



<div><h2>What is Ur-Privacy</h2><p><em>A few principles for privacy</em></p></div>







<p><strong>Privacy is not just something we need to separate our private live from our public live. It is necessary to separate our private live, the communities we belong to and the public sphere from each other.</strong></p>



<p><strong>Privacy is about boundaries.</strong> It is not about hiding something but allowing to create a space with rules decided by its members. I like to compare it to borders. Some people say that borders are a restriction, something that limit freedom of movement and we do not need in the contemporary world. As if they were arbitrary obstacles put there by petty people. It almost makes sense if you do not think about them, after all you are actually stopped at a border.</p>



<p>However, that is not true, that is not why they exist. Borders delimit the area that a certain state control, an area where a specific set of rules and laws applies. There was a time before borders, in fact most of human history did not have clear borders. It was not a time of freedom, but anarchy, where bands of barbarians could roam into your home and pillage everything.</p>



<p>In this context is also important to remember that before the <a href="https://en.wikipedia.org/wiki/Peace_of_Westphalia">Peace of Westphalia</a> modern European states were plagued by continual wars. The short version is that this was due to the combination of two facts:</p>



<ul><li>modernity begets differences, different kings choose different religions<sup><a id="link_1" href="#note_1" data-type="internal" data-id="#note_1">1</a></sup> and separated societies</li><li>however, the legitimacy of kings was still based on shared medieval ideals, like the concept of divine rule</li></ul>



<p>In short, the issue was not that <strong>leaders wanted to make war all the time, they needed to do so</strong> because the legitimacy of their power depended, at least on some level, to what the rest of the European world was doing. If you claim to be a divine king there better be agreement on what the divine is, otherwise a guy that picks a different religion can also pick a different king. And, according to some, he could be a legitimate king. To change the situation this peace treaty established the principle that the internal affairs of a state are the exclusive interest of said state.</p>



<p>The connection with privacy is this: without clear rules on what is private and what is public, nobody knows which stuff belongs to whom. This means chaos and often that all belong to the strongest. Somebody might say that what you do in private, it is not private at all but political. It concerns the society at large. Therefore, it must be regulated according to their rules.</p>



<p><strong>Privacy does not imply hiding the truth.</strong> <strong>Meaning depends on context, therefore everything should be considered within its context.</strong></p>



<p><strong>Privacy is about control</strong>. Without privacy we cannot decide for ourselves how to live our lives. If there is no privacy, all become public. Whoever has more power and an interest can affect your life according to their own rules. Then, I have to care about what other people think, otherwise they will control how I can behave. As before the peace of Westphalia, the issue is not that other people are bad, <em>they have to do it</em>. When everything is subject to public scrutiny, you either control the rules and judge others or you are judged and controlled by others.</p>



<p>Think about this way: we say a lot of things in our private lives that are not meant to be taken literally. In private we say something and then we add: <em>you know what I mean</em>. And that is actually true. We can do that because the people we talk to in private know us; they understand the context in which our words must be understood. And even more importantly: they care about us; they do not want to intentionally misunderstand us.</p>



<p>When I was a child I would sometimes say and think that I wanted to kill my brother. I did not mean it literally and everybody knew it. If I said the same thing now, in public, to somebody that does not know me, the phrase would be different. It would be a threat.</p>



<p>Why is that? They are the exact same words. You know why, of course. I am different and the context is different. The real meaning of something, whether an action or a word, is not absolute, in most cases it is relative. When we speak in public, we share a different context, therefore our words have a different meaning. </p>



<p>So even if I say something as a hyperbole, or something that can be construed as an implicit threat (e.g., <em>they must be stopped at all costs</em>!), they might protest. You might say that they are overreacting, that it was just a joke, but how can they be sure of it? <strong>They do not know me.</strong> It is true that acts of violence are prepared by violent words. Even if you are unsure if something is really violent, you have to take a stand. You have to make clear that any attack against you is not permissible. Otherwise, <a href="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings" data-type="URL" data-id="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings">somebody, maybe a crazy guy, might think that it is permissible and the right course of action</a>. Somebody might feel legitimated to take your land and kingdom.</p>



<p><strong>Privacy is not just needed to protect us from the government or exceptional situations. It is about understanding the rules that applies to every aspect of our life so that they can be fair for everybody.</strong></p>



<p><strong>Privacy is about everyday life</strong>. The issue is not simply that something we say can be considered a threat. When you are communicating with someone you need to be able to understand them. Communication requires a shared understanding at some level.</p>



<p>The easiest example to understand this are work discussions. When we talk with people that work in our field, we can communicate more easily the impact of a choice. This goes beyond the ability to use technical terminology: we know which are the main things to care about. The same discussion with our bosses would be different. Even making them understand the basic strengths and weaknesses is more challenging.</p>



<p>Now imagine being forced to communicate everything you do in the most general terms, to people that do not care about you, because <strong>everybody can see you</strong>. So, they can use any piece of information for their own needs. This could mean a policeman investigating you. It could also mean a company making you pay more for a pair sneakers, because they know how much disposable income you have and that you really love sneakers.</p>



<p>We need privacy to be aware of what is happening to us. It is too much to demand we know how other people interpret what we say. However, it is not excessive to ask that we can control what is shared about us.</p>



<div><h2>Privacy Affects Everything</h2><p><em>Defending privacy would require all-around changes</em></p></div>







<p><strong>Privacy is the most important concept of our time, because it influences everything else. Without privacy we do not know what rules applies. Our lives will be judged according to the rules of somebody else</strong> <strong>in ways we cannot even imagine.</strong></p>



<p>We cannot discuss all of the possible implications of privacy on other rights, so let’s see just the example of <em>freedom of speech</em>. Of course, sometimes you can also be judged for who you are: your religion or lack thereof, political opinion or sexual orientation.</p>



<blockquote><p>Give me six lines written by the most honest man, and there I will find something to hang him.</p><cite>Cardinal Richelieu</cite></blockquote>



<p>People lost jobs and had their lives ruined, because the mob judged something they said in private in a different way from what they expected. And they paid a price. You might say: that was fair. We might judge ourselves by our intentions, but others by their actions, which are real and objective.</p>







<p>I, for once, disagree with XKCD and this view. There are a couple of different issues here:</p>



<ul><li>how we should react to speech we disagree with</li><li>what was meant to be shared among friends was taken out of context and made public</li></ul>



<p>This complicates the …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</a></em></p>]]>
            </description>
            <link>https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661271</guid>
            <pubDate>Fri, 02 Oct 2020 10:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatpak: A security nightmare – two years later]]>
            </title>
            <description>
<![CDATA[
Score 365 | Comments 320 (<a href="https://news.ycombinator.com/item?id=24661126">thread link</a>) | @krimeo
<br/>
October 2, 2020 | https://www.flatkill.org/2020/ | <a href="https://web.archive.org/web/*/https://www.flatkill.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Two years ago I <a href="https://flatkill.org/">wrote</a> about then heavily-pushed Flatpak, self-proclaimed "Future of Apps on Linux". The article criticized the following three major flows in Flatpak:</p><ul>
<li>Most of the apps have full access to the host system but users are misled to believe the apps are sandboxed
</li><li>The flatpak runtimes and apps do not get security updates
</li><li>Flatpak breaks many aspects of desktop integration
</li></ul>

<!-- <p>A lot has changed in the 2 years (the company behind Flatpak is now just another IBM's brand for one thing) so let's see how Flatpak developers addressed these fundamental issues.</p> -->
<p>So let's see how Flatpak developers addressed these fundamental issues.</p>

<h2>The sandbox is STILL a lie</h2>

<p>Almost all popular apps on Flathub still come with <span>filesystem=host</span> or <span>filesystem=home</span> permissions, in other words, <b>write access to the user home directory</b> (and more) so all it takes to escape the sandbox is trivial <span>echo download_and_execute_evil &gt;&gt; ~/.bashrc</span>. That's it.</p>


<p>The most popular applications on Flathub still suffer from this - Gimp, VSCodium, PyCharm, Octave, Inkscape, Audacity, VLC are still not sandboxed.</p>

<p>And, indeed, users are still mislead by the reassuring blue "sandboxed" icon. Two years is not enough to add a warning that an application is <b>not</b> sandboxed if it comes with dangerous permissions (like full access to your home directory)? Seriously?</p>

<img src="https://www.flatkill.org/2020/sandboxlie.png" alt="sandboxlie">

<h2>Flatpak apps and runtimes STILL contain long known security holes</h2>
<p>It took me about 20 minutes to find the first vulnerability in a Flathub application with full host access and I didn't even bother to use a vulnerability scanner.</p>

A perfect example is <a href="https://www.cvedetails.com/cve/CVE-2019-17498">CVE-2019-17498</a> with public exploit <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/libssh2/out_of_bounds_read_disconnect_CVE-2019-17498">available</a> for some 8 months. The first app on Flathub I find to use libssh2 library is Gitg and, indeed, it does ship with unpatched libssh2.

<p>But is it just this one application? Let's look at the <b>official runtimes</b> at the heart of Flatpak (org.freedesktop.Platform and org.gnome.Platform <b>3.36</b> - as of time of writing used by most of the applications on Flathub). The first unpatched vulnerable dependency I found in the offical runtime is ffmpeg in version 4.2.1 with no security patches backported, <a href="https://www.cvedetails.com/cve/CVE-2020-12284">CVE-2020-12284</a>.</p><p>Recently I stumbled upon an article from 2011 which started what is today known as flatpak, <a href="https://people.gnome.org/~alexl/glick2">in the words of the project founder:</a></p>

<p><a href="https://people.gnome.org/~alexl/glick2"><b><i>"Another problem is with security (or bugfix) updates in bundled libraries. With bundled libraries its much harder to upgrade a single library, as you need to find and upgrade each app that uses it. Better tooling and upgrader support can lessen the impact of this, but not completely eliminate it."</i></b></a></p>

<p>After reading that it comes as no surprise flatpak still suffers from the same security issues as 2 years ago because flatpak developers knew about these problems from the beginning.</p>

<h2>Local root exploits are NOT considered a minor issue anymore!</h2>
<p>Great! Two years ago I wrote about a trivial local root exploit using flatpak to install suid binaries (<a href="https://www.cvedetails.com/cve/CVE-2017-9780/">CVE-2017-9780</a>) and how it was downplayed by Flatpak developers as a minor security issue <a href="https://github.com/flatpak/flatpak/releases/tag/0.8.7">here</a>. I am happy to see at least the attitude to local root exploits has changed and today <a href="https://github.com/containers/bubblewrap/security/advisories/GHSA-j2qp-rvxj-43vj">local root exploits</a> are considered high severity.

</p><h2>Desktop integration</h2>
<p>System and user fonts are now available to flatpak applications and basic font rendering settings are respected as well, however do not expect your changes in /etc/fonts, typically setting a proper fallback font for CJK characters, to work with flatpak.  KDE applications in flatpak are still ignoring themes, fonts and icon settings (tested with Qt5ct). Applications installed from the distribution sources do not have these problems, of course. <a href="https://www.flatkill.org/2020/desktopbrokenation.mp4">A quick screen capture to demonstrate</a>.</p>

<p>More importantly, fcitx, <i>the</i> IME for Chinese is still broken - it has been 2 years. Here is the <a href="https://github.com/flatpak/flatpak/issues/2031">issue</a> I linked 2 years ago - especially of interest is <a href="https://github.com/flatpak/flatpak/issues/2031#issuecomment-655134889">the following comment</a> directly from fcitx developer:

</p><p><i>"Because fcitx im module in flatpak is from 4.2.97 and using a different dbus object path. <b>It need to be the same version of fcitx on your host</b>."</i></p>

So I need to run multiple fcitx daemons on my desktop and switch between them as I switch flatpak apps depending on which fcitx libraries are bundled with that app or maybe in the future of linux apps it's not possible to type chinese anymore and it's fine?

<p>While the "bundle everything" approach has proven very useful on servers it clearly does not work for desktop applications, let's keep linking system libraries in desktop applications (and use the bundled libraries as a fallback only) to avoid introducing all these problems to Linux desktop.</p>



</div>]]>
            </description>
            <link>https://www.flatkill.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661126</guid>
            <pubDate>Fri, 02 Oct 2020 10:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js malware caught posting IPs, username, and device info on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24660810">thread link</a>) | @axsharma
<br/>
October 2, 2020 | https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/ | <a href="https://web.archive.org/web/*/https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="683" src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" alt="red and blue hearts illustration" loading="lazy" srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            




<p>Multiple NodeJS packages laden with malicious code have been spotted on npm registry.</p>



<p>These “typosquatting” packages served no purpose other than collecting data from the user’s device and broadcasting it on public GitHub pages.</p>



<p>The findings were spotted by Sonatype’s <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">automated malware detection systems</a> and further investigated by the company’s Security Research team which includes me. </p>



<p>The packages previously present on the open source npm registry included:</p>



<ol><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/electorn" target="_blank">electorn</a> (intentional misspelling of a legitimate package “electron”)</li><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/loadyaml" target="_blank">loadyaml</a> </li><li>loadyml</li><li>lodashs (intentional misspelling of a legitimate package “lodash”)</li></ol>



<p>All four packages were published by the same user “simplelive12” and have now been removed, with the first two having been taken down by npm as of October 1, 2020. The previous two packages were unpublished by the author themselves.</p>



<p>Once installed, <code>electorn</code> ran a script in the background <strong>every</strong> <strong>hour</strong> which collected the logged-in user’s IP, geolocation data, username, path to home directory, and CPU model information.</p>



<figure><img loading="lazy" width="1024" height="356" src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>The malicious code within <code>electorn</code> and 3 other identical packages which exfiltrated user information</figcaption></figure>



<p>This information, part of which constitutes the device “fingerprint” was uploaded and published on <a rel="noreferrer noopener" href="http://web.archive.org/web/20201001065601/https://github.com/h4ppyl1ve/collect/issues/4" target="_blank">GitHub</a> in real-time.</p>



<p>Some of the information being published is base64-encoded but this can be trivially decoded by anyone who has access to it:</p>



<figure><img loading="lazy" width="1024" height="488" src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Sonatype’s Security Research team has accounted for these malicious packages into their products, and had notified both npm and GitHub teams of the malicious activity stemming from the components. This led to the takedown of these malicious packages. </p>



<p>To this date, all 4 packages have scored a little over <strong>400</strong> total downloads.</p>



<p>It is not exactly clear what was the purpose of collecting this data and why was it being published on the web for the world to see, however, incidents like these highlight the potential of typosquatting attacks on the open-source ecosystem.</p>



<p>We can only imagine what the next possible version of these packages could have been capable of – possibly carrying out even more sinister activities. </p>



<p>By tricking an unsuspecting developer into mistakenly installing a misspelled package, attackers can push their malicious code “downstream” into any other open-source projects that use the misspelled malicious component as a transitive dependency.</p>



<p>Adopting DevSecOps best practices and building security early on into your software development lifecycle can prevent “counterfeit components” such as electorn and loadyaml from entering, and thriving in your software supply chains.</p>



<p>The complete research findings are available on the <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">Sonatype blog</a>.</p>
                <div>
                    <h3>About the author</h3>
                                        
        <div>

                <p><a href="https://securityreport.com/author/ax-sharma/"><img alt="" src="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=150&amp;d=retro&amp;r=pg" srcset="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=300&amp;d=retro&amp;r=pg 2x" height="150" width="150" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>
                </p>
                <div>
                    <h4>
                        <a href="https://securityreport.com/author/ax-sharma/">Ax Sharma</a>
                    </h4>

                    
                    
                                            <p>
                        <a href="https://axsharma.com/" target="_blank">https://axsharma.com/</a>
                        </p>
                                        <div>
                        <p>Ax Sharma is a Security Researcher, Engineer, and Tech Columnist. His works and expert analyses have frequently been featured by leading media outlets like Fortune, The Register, TechRepublic, CIO, etc.</p>
<p>Ax’s expertise lies in vulnerability research, reverse engineering, software development, and web app security. He’s an active community member of the OWASP Foundation and the British Association of Journalists (BAJ).</p>
<p>Send any tips via email or Twitter DM.</p>
                    </div>
                    
                                    </div>
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660810</guid>
            <pubDate>Fri, 02 Oct 2020 09:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Looking at the experience of black Britons through an American lens]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 354 (<a href="https://news.ycombinator.com/item?id=24660682">thread link</a>) | @dgellow
<br/>
October 2, 2020 | https://www.persuasion.community/p/please-stop-imposing-american-views | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/please-stop-imposing-american-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18107111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>Construction workers reopen Winston Churchill statue in Parliament Square after it was covered with metal panels to protect it against defacement by protestors.</em></p><p>Over the past couple of months, many Britons have imported American discourse on race wholesale. When asked to analyze the experiences of black people in the United Kingdom, we now talk with an American accent.</p><p>Take a look, for instance, at a meme that has been circulating among some of my white friends on Facebook and Instagram:</p><blockquote><p>I have privilege as a White person because I can do all of these things without thinking twice about it … I can go jogging (#AmaudArbery). I can relax in the comfort of my own home (#BothemSean and #AtatianaJefferson). I can ask for help after being in a car crash (#Jonathan Ferrell and #RenishaMcBride). I can have a cellphone (#StephonClark). I can leave a party to get to safety (#JordanEdwards). I can play loud music (#JordanDavis). I can sell CDs (#AltonSterling). I can sleep (#AiyanaJones). I can walk from the corner store (#MikeBrown).</p></blockquote><p>The post goes on and on, like an interminable spoken-word poem. All the individuals listed are American, but most of the people who have shared this on my timeline are British. In trying to express their solidarity with black Britons, they are affirming a supposedly transcendental truth: to be black is to live in perpetual terror of being murdered by the state. </p><p>But Britain is not America. And importing American race discourse into the United Kingdom not only prevents us from recognizing the specific ways in which racial injustice manifests in this country—it cloaks the reality of black British lives behind an abstraction that flattens our humanity. </p><p>Britain has a long and painful history of anti-black racism. In the twentieth century alone, the growing black presence led to a long catalogue of abuses: the 1919 race riots in Liverpool, Cardiff and London; the 1958 race riots in Nottingham and Notting Hill; the 1969 police murder of David Oluwale, a Nigerian immigrant who was tortured, pissed on and finally drowned in a river in Leeds. I could list other examples. It is not hard to see why the horrific killing of George Floyd has evoked such strong feelings in this country as well.</p><p>But for all of the country’s flaws, Britain is not America. Trying to understand its racial dynamics through the lens of another country’s does more to obscure than to illuminate the situation that black Britons like myself actually face.</p><p>The average black American in the United States can trace his ancestry further back than the average white American. Most black Americans are descended from enslaved Africans. Their forebears suffered through the segregation and racial terror of the Jim Crow era. The majority of black people in the United Kingdom, by contrast, are immigrants or the children of immigrants. Though many of them have certainly had harrowing experiences with injustice or discrimination, they do not have the same history of racist disadvantage.</p><p>To understand the experience of black Britons, it is not only necessary to grasp how different their history is from that of black Americans: we need to understand the diversity captured by the label “black British.” For example, around two out of every three students with Congolese or Somali origins get free school meals, a standard indicator that their parents are poor. Among students with Nigerian or Ghanaian origins, only one in five do. It is also noteworthy that black Caribbean students are twice as likely to be excluded from school as black African students. </p><p>The discrepancy in educational attainment is just as stark. On average, 58% of black African students graduate from middle school at grade level (defined as achieving A* to C grades at GCSE)—about the same number as white students. But black Caribbean students are significantly less likely to do so—while those whose parents hail from Nigeria actually outperform their white peers by a considerable margin. </p><p>None of this is to disavow the label “black British.” But we need to invest it with the nuance consonant with its reality—and to cast doubt on the idea that every discrepancy in representation must be explained by structural injustice or white supremacy.</p><p>There has, for example, been a lot of concern about the underrepresentation of black Britons in professions like the arts and publishing. But why would you choose to go into theater or journalism—rather than law, medicine or finance—if you are a talented child of ambitious but not well off immigrants? </p><p>This is not a flippant question. While representation can be important, anybody who actually wants to improve the condition of black Britons should at least be a little curious about why they are overrepresented in some prestigious professions and underrepresented in others. In a country in which black people make up only three percent of the population, for example, six percent of junior doctors are black. Would the country—or the black community—really benefit if more black Britons chose to ditch medicine for the theater? The debate is worth having. But in the place of that debate, there have only been pious paeans to diversity.</p><p>The stereotype of the West African parent who wants their child to study law or medicine bears some relation to reality; but the widespread view of black people as perennial victims devoid of agency is a defamatory abstraction. The black person in Britain, like Ralph Ellison’s iconic protagonist, is “invisible because no one wants to see him.”</p><p>So much of the British reaction to the death of George Floyd has constituted a failure of nerve. Desperately seeking to assuage their feelings of guilt, to do <em>something</em>, many Britons have sacrificed their critical faculties to a narrative that does not actually help black people—a narrative that, by reducing us to passive abstractions, only makes us more invisible.</p><p>Racists assume that black people are all the same. Ironically, anti-racists sometimes do so too. But anybody who is truly committed to racial equality needs to recognize that this kind of simplification neither serves justice nor reflects the truth.</p><p><strong>Tomiwa Owolade is a writer who lives in London.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/please-stop-imposing-american-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660682</guid>
            <pubDate>Fri, 02 Oct 2020 09:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bead Sort]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24659668">thread link</a>) | @kkaranth
<br/>
October 1, 2020 | https://karthikkaranth.me/blog/bead-sort/ | <a href="https://web.archive.org/web/*/https://karthikkaranth.me/blog/bead-sort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<header id="top">
    <section>
        <a href="https://karthikkaranth.me/">Karthik Karanth</a>
    </section>

    <div>
        <section>
            
                
                

                <a href="https://karthikkaranth.me/blog/">Blog</a>
            
                
                

                <a href="https://karthikkaranth.me/art/">Art</a>
            
                
                

                <a href="https://karthikkaranth.me/projects/">Projects</a>
            
        
        </section>
    </div>
</header>


<header>
  
</header>
<section id="category-pane">
  
  <p>
    <h6>
        PUBLISHED ON OCT 1, 2020 
      
    </h6>
  </p>
  
</section>
<section id="content-pane">
  <div>
    <div>
    <canvas id="bead-sort-canvas">
    </canvas>

    
</div>

<p>Bead sort<sup id="fnref:wiki"><a href="#fn:wiki">1</a></sup> is a sorting algorithm powered by gravity!</p>

<ul>
<li>For each number <code>x</code> in the array we want to sort, we arrange <code>x</code> beads in a row.</li>
<li>Let them all drop.</li>
<li>Count the number of beads in each row from top to bottom, and we have our sorted array!</li>
</ul>



<div>

<hr>

<ol>
<li id="fn:wiki"><a href="https://en.wikipedia.org/wiki/Bead_sort">Bead sort - Wikipedia</a>
 <a href="#fnref:wiki"><sup>[return]</sup></a></li>
</ol>
</div>

  </div>
</section>
<section id="tag-pane">
  
  
  
</section>








<section id="menu-pane">
  
  
  

  
  
  
  
  
  
  
  
  

  
  
  <div><p><span><a href="https://karthikkaranth.me/blog/starting-with-order/">&lt; PREV</a></span><span><a href="https://karthikkaranth.me/blog">BLOG</a></span><span></span></p></div>
  
  <div><p><span><a href="https://karthikkaranth.me/">HOME</a></span></p></div>
</section>





</div></div>]]>
            </description>
            <link>https://karthikkaranth.me/blog/bead-sort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659668</guid>
            <pubDate>Fri, 02 Oct 2020 06:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Falsehoods Programmers Believe About Map Coordinates]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24659039">thread link</a>) | @boyter
<br/>
October 1, 2020 | https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates | <a href="https://web.archive.org/web/*/https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Mercator projection SW" title="Mercator projection SW" src="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg" srcset="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e4a55/Mercator_projection_SW.jpg 256w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/36dd4/Mercator_projection_SW.jpg 512w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg 1024w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/ac99c/Mercator_projection_SW.jpg 1536w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e1596/Mercator_projection_SW.jpg 2048w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/1cd85/Mercator_projection_SW.jpg 2058w" sizes="(max-width: 1024px) 100vw, 1024px" loading="lazy">
    </span>
(Map image by Daniel R. Strebe, licensed under CC BY-SA 3.0)</p><h2>1. The only projection that is important is Web Mercator</h2><p>While <a href="https://en.wikipedia.org/wiki/Web_Mercator_projection">Web Mercator</a> is
probably the most popular projection that most people will run into, the
<a href="https://en.wikipedia.org/wiki/Albers_projection">Albers</a> and
<a href="https://en.wikipedia.org/wiki/Lambert_cylindrical_equal-area_projection">Lambert</a>
equal-area projections are fairly common for when the projection needs to maintain
the area rather than the navigational direction (which is one of the main features
of the Mercator projection).</p><h2>2. All coordinates are latitude/longitude pairs</h2><p>In addition to latitude/longitude coordinates, <a href="https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system">Universal Transverse Mercator (UTM)
coordinates</a>
are also fairly common. UTM splits the Earth into 60 zones, and then
further specifies northings and eastings in metres (as opposed to degrees, minutes and seconds).</p><p>The UTM notably omits the polar areas - which are covered by the <a href="https://en.wikipedia.org/wiki/Universal_polar_stereographic_coordinate_system">Universal Polar Stereographic (UPS)
coordinate system</a>
instead.</p><h2>3. Latitude always comes before longitude in a coordinate pair</h2><p>While it is common to see items in (latitude,longitude) order, some formats
(e.g. <a href="https://en.wikipedia.org/wiki/GeoJSON">GeoJSON</a>) dictate that coordinates
follow (longitude,latitude) order instead. This matches the typical way coordinates
are specified in a Cartesian coordinate system: (x,y).</p><h2>4. A degree of latitude or longitude always represents the same distance</h2><p>In the Mercator projection, the Earth - which, in reality, is an
<a href="https://en.wikipedia.org/wiki/Spheroid#Oblate_spheroids">oblate spheroid</a> -
is projected as a simple cylinder. This means that "parallel" longitude lines
meet at the poles, so the distance between degrees of longitude are much shorter
as they get closer to the poles than they are at the equator (~111 km).</p><p>The variance in latitude is not as large - but it still varies by about 1km going
from the equator to the poles.</p><h2>5. The shortest path between two points is a straight line</h2><p>The Earth isn't flat - as such, although your map may be projected to be flat,
the distance between two points needs to follow the curvature of
the Earth and can usually be approximated by the
<a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine formula</a>.</p><h2>6. Coordinates for a given landmark are always fixed</h2><p><a href="https://en.wikipedia.org/wiki/Continental_drift">Movements of the Earth's tectonic plates</a>
mean that the land masses are moving slowly with the passage of time.
For example, Australia has shifted about 1.8 metres from where it
was in 1994 (about 7 centimetres per year). This also means that <a href="http://www.ga.gov.au/scientific-topics/positioning-navigation/geodesy/datums-projections/gda2020">geocentric
datums</a>
have to be updated to account for these changes every once in a while.</p><h2>7. Given a pair of coordinates, you can plot it on a map</h2><p>In addition to coordinates, we also need to know the datum, which is
the coordinate system and its specific set of reference points on the Earth.
While most coordinates often follow the
<a href="https://en.wikipedia.org/wiki/World_Geodetic_System">WGS84 datum</a>,
care should be taken to ensure that the map and the coordinates plotted
are using the same datum.</p><h2>8. There is one global ellipsoid to base coordinates on</h2><p>Most modern datums are based on the WGS84
<a href="https://en.wikipedia.org/wiki/Ellipsoid">ellipsoid</a>
as the surveys are often completed using GPS as a reference, but notably
Russia and China still base their local datums on different reference ellipsoids.</p><p>As a result, conversions to and from datums based on different
ellipsoids may result in inaccuracies and deviations and may be of concern
if you have to deal with GPS, GLONASS, and BeiDou data at the same time.</p></div></div>]]>
            </description>
            <link>https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659039</guid>
            <pubDate>Fri, 02 Oct 2020 04:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport Tycoon a.k.a. the great optimiser, Chris Sawyer]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24658958">thread link</a>) | @wizardfeet
<br/>
October 1, 2020 | https://lifeandtimes.games/episodes/files/28 | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://pdcn.co/e/traffic.megaphone.fm/ADL8847793182.mp3" target="_blank">Click/tap here to download this episode.</a></p><p><a href="https://ratethispodcast.com/ltvg" target="_blank"><img src="https://storage.googleapis.com/rtp-assets/buttons/lifetimevideogames.png" width="198" height="56" alt="Rate This Podcast"></a></p>
<p><img alt="A screenshot of the main menu from Transport Tycoon for DOS" src="https://lifeandtimes.games/episodes/files/transport-tycoon-dos-screenshot-main-menu.png" width="276" height="212"></p><p>On the rise and, um...<em>fade out(?)</em> of Chris Sawyer, the genius creator of bestselling, critically-acclaimed simulation games Transport Tycoon and RollerCoaster Tycoon — who made a career out of working at the cutting-edge, in bare metal assembly code that he wrote and optimised (and optimised again) on his own.</p><p>Until the cutting-edge left him behind.</p><p><strong>Hello Hacker News readers! As of this update, the post there erroneously labels this as an interview. It's not. Chris doesn't do interviews, except via an intermediary (which doesn't really work in an audio format), so the story is based entirely on my in-depth research and analysis. I hope you still enjoy it and learn something interesting. (I have stories on many other things that do involve interviews, though, like </strong><strong><a href="https://lifeandtimes.games/episodes/files/27" title="Episodes:27 - Links">1990 golf game Links</a></strong><strong>, Bungie's </strong><strong><a href="https://lifeandtimes.games/episodes/files/25" title="Episodes:25 - Pimps at Sea">fake game Pimps at Sea</a></strong><strong>, and </strong><strong><a href="https://lifeandtimes.games/episodes/files/22" title="Episodes:22 - Wololo">the "Wololo" sound effect</a></strong><strong> from Age of Empires.)</strong></p><p>Chris was only a design consultant on 2004 game RollerCoaster Tycoon 3, but its remastered "Complete" edition has just come out on Nintendo Switch and the PC version is free on the Epic Games Store right now (until October 2). The original two games are also still sold via the likes of Steam and GOG.</p><p>Transport Tycoon, meanwhile, lives on in open-source project <a href="https://www.openttd.org/" target="_blank">OpenTTD</a> and in a mobile port (<a href="https://play.google.com/store/apps/details?id=com.thirtyonex.TransportTycoon&amp;hl=en_US" target="_blank">Android</a>, <a href="https://apps.apple.com/us/app/transport-tycoon/id634013256" target="_blank">iOS</a>) of the original game by Chris's company 31X. You can see a snippet of his source code in the image below:</p><div><p><img alt="cstg_code1" src="https://lifeandtimes.games/episodes/files/cstg_code1.jpg" width="1262" height="1775"></p></div><div><p>Thanks as always to my supporters on Patreon — especially my $10+ backers Carey Clanton, Rob Eberhardt, Simon Moss, Vivek Mohan, Wade Tregaskis, and Seth Robinson. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames">my Patreon page</a> and sign up. Or for one-off donations you can use <a href="https://paypal.me/mossrc">paypal.me/mossrc</a>.</p><p>Please remember to tell other people about the show, and to leave a review by following the links at <a href="https://ratethispodcast.com/ltvg">ratethispodcast.com/ltvg</a>.</p><p>I'm currently writing a new book called Shareware Heroes: Independent Games at the Dawn of the Internet. You can learn more and/or pre-order your copy <a href="https://unbound.com/books/shareware-heroes/" target="_blank">from Unbound</a>.</p></div><hr>
<h3>(Partial) Transcript</h3>
<p><strong><em>[Most episode transcripts/scripts are reserved for my Patreon supporters (at least for the time being), but I like to give you at least a taster here — or in this case, the first half of the episode.]</em></strong></p><p><em>Welcome to the Life and Times of Video Games, an audio series about video games and the video game industry, as they were in the past and how they’ve come to be the way they are today. I'm Richard Moss, and this is episode 28, Transport Tycoon, or the tale of the great optimiser and his two greatest works.</em></p><p>We’ll get going in just a moment. </p><p>*pause for pre-roll ad/cross-promo slot*</p><p>***</p><p>You may have heard the expression that every overnight sensation is a decade in the making — a decade of hard work, toiling in obscurity…or <em>relative</em> obscurity, honing a talent, perfecting a craft, <em>optimising</em> a skill set and envisioning whatever it is that breaks through.</p><p>In reality the actual duration is rarely a decade — it’s five years or eight years or eighteen years, or however long it takes for the pieces to all fall into place: the talent, timing, and product. But the idea bears repeating: the greatest accolades, the greatest achievements, the greatest games are the product of hard work built atop years of invisible labour.</p><p>And such it was that Chris Sawyer, like John Romero, Carol Shaw, Gunpei Yokoi, and many others before and since — such it was that in 1994 Chris Sawyer suddenly shifted from a little-known (though well-respected) figure in the games industry, a programmer who converted Amiga games to the PC, to become an industry icon.</p><p>Nineteen-ninety-four was the year when his first original game was published, the year when big-name PC game publisher Microprose put his transportation-focused business simulation game Transport Tycoon, an incredible solo development effort, in a box and sold it in stores to widespread acclaim. </p><p><img alt="SCR1" src="https://lifeandtimes.games/episodes/files/scr1.jpg" width="866" height="362"><br><em>Transport Tycoon, the game that made Chris Sawyer into a games industry icon (</em><em><a href="https://www.tt-forums.net/viewtopic.php?f=47&amp;t=29058" target="_blank">image source</a></em><em>)</em><br></p><div><p>The game itself had taken Chris just a year to develop, but the journey to making it had begun much earlier.</p><p>Chris had started programming as a teenager in 1981, largely out of curiosity, through trying to make things appear on the screen on a range of different computers he’d encountered. There was the Commodore PET at his high school, the Sinclair ZX81 demonstration unit in a W H Smiths store, and the Texas Instruments TI99/4A one of his neighbours owned, as well as the Commodore VIC-20 a different neighbour had. And eventually, after diligently saving up his pocket money, he’d become engrossed in a machine of his own, a Camputers Lynx, a now-forgotten, obscure-even-then 8-bit computer with fancier graphics and more horsepower than the leading systems of its day (the leading systems at the time being the Apple II, ZX Spectrum, and Commodore 64).</p><p>Here, in 1983, is where the journey really starts — where Chris set off towards the lands where he’d make his name. And I find it fascinating how serendipitous this was — for, you see, Chris’s two great successes, Transport Tycoon and RollerCoaster Tycoon, were both made possible by his phenomenal systems knowledge; by his immense capacity to hand-code complex interactions of data at low levels of abstraction.</p><p>And here is where he began to learn those skills, to internalise them to the point of becoming natural talents. He later told Arcade Attack in an interview that he’d not had access to an assembler for that Lynx computer, so when he’d wanted to move beyond coding in BASIC he’d needed to write his programs byte-by-byte in machine code — the lowest-level programming language, the numerical instructions that computers themselves use. And with scant resources available to teach him these skills, he mostly figured it out on his own, just trying different things until he got his ideas to work. Always chasing the next exhilarating breakthrough.</p><p>Chris continued to dabble in machine code, though somewhat less than before, when he upgraded to a similarly-obscure machine called the Memotech MTX500, which actually did come with a built-in assembler, which enabled him to write programs in the abbreviation-heavy Z80 assembly language. Programs that, beginning in 1984, he very often had published commercially.</p></div><p><img alt="Memotech_MTX500-wide" src="https://lifeandtimes.games/episodes/files/memotech_mtx500-wide.jpg" width="1020" height="584"><br><em>The Memotech MTX500 (</em><em><a href="https://en.wikipedia.org/wiki/File:Memotech_MTX500.jpg" target="_blank">Image source</a></em><em>)</em><br></p><div><p>Chris had sent Memotech cassette tapes of some games he’d made through copying the designs of popular titles, like Missile Kommand, which was the 1980 Atari arcade game converted to the capabilities of the MTX500, using a mix of BASIC and machine code, with the name intentionally misspelled (a ‘k’ rather than a ‘c’) as though that somehow made his unapologetic, blatant clone of another’s work okay. </p><p>But this was the wild west of the computer games business, and Memotech weren’t much concerned. Or at least their games guy Jim Wills wasn’t much concerned, neither at this point nor a few months later when he left to start a company called Megastar Games. Jim liked Chris’s work enough to publish it, for meagre royalties but invaluable experience. And so Chris was commercially published with his unlicensed MTX500 versions of Missile Command, Q*bert, Manic Miner, and a few others.</p><p>After high school he enrolled in a computer science and microprocessor systems degree, where he studied the fundamentals of both software and hardware design in computers — an experience he found invaluable, as it taught him how to push computers further by learning how their hardware worked. And it taught him the theories behind the sorts of nitty-gritty software-systems things he’d already been practising at home: optimisation, sorting, algorithms, and even more varieties of machine code.</p></div><p><img alt="escape-from-zarcos-memotech-mtx500" src="https://lifeandtimes.games/episodes/files/escape-from-zarcos-memotech-mtx500.png" width="1044" height="788"><em><br>Escape from Zarcos, Chris Sawyer clone of Manic Miner for the Memotech MTX500</em><br></p><div><p>At home, meanwhile, he’d shifted over to the Amstrad CPC, which technologically-speaking wasn’t hugely different to the Memotech system he’d been on before — but it was a modest upgrade, and unlike his previous computers it was actually a popular system. And for Chris it was a gateway to the PC, because in the course of studying at university and making computer games on the side he wound up getting an Amstrad-made IBM-PC clone.</p><p>Chris had during this period been getting his games published through Ariolasoft, a German company with a UK subsidiary that promised him a job programming games for them once he graduated. Except some promises can’t be kept, especially in an industry that moves as fast as computer games publishing.</p><p>The home computer business was by that point deep into its transition from 8-bit to 16-bit hardware, and that transition came with adjustments to the standard of game graphics and design required, and to the way marketing and sales worked, and the cost of publishing, and so on, and Ariolasoft wasn’t doing too well at managing the transition. </p><p>So Chris didn’t have a job waiting for him after all, and he’d missed out on all the great electronics engineering jobs his classmates applied for. (Oops!) But not to worry — he’d made enough connections and enough headway as a programmer that he could get himself a business agent, and that agent in turn connected him to the booming Amiga-to-PC games porting industry.</p><p>He later said he’d thought it a “stop-gap” measure, just “a bit of fun” while he looked for more permanent employment in the electronics industry. But Chris took to his new conversions work like a duck to water. The kid who’d had to get creative and remain patient to make anything work on his Camputers Lynx machine now excelled in an environment where he had to contend with the vast gap in multimedia capabilities between the Amiga and the PC.</p><p>PCs of the day were pathetically inept as games machines, compared to a system like the Amiga. Whereas the PC had just a CPU, and maybe, in a minority of machines, a dedicated sound card like the SoundBlaster 16, every Amiga came with a custom chipset that contained audio and video co-processors that could take some strain off the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/28">https://lifeandtimes.games/episodes/files/28</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658958</guid>
            <pubDate>Fri, 02 Oct 2020 04:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Jargon File]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24658797">thread link</a>) | @purec
<br/>
October 1, 2020 | http://jargon-file.org/archive/jargon-4.4.7.dos.txt | <a href="https://web.archive.org/web/*/http://jargon-file.org/archive/jargon-4.4.7.dos.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jargon-file.org/archive/jargon-4.4.7.dos.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658797</guid>
            <pubDate>Fri, 02 Oct 2020 04:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big O, Little N]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24657747">thread link</a>) | @adamzerner
<br/>
October 1, 2020 | https://adamzerner.bearblog.dev/big-o-little-n/ | <a href="https://web.archive.org/web/*/https://adamzerner.bearblog.dev/big-o-little-n/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>I remember when I was first learning about hash tables. I thought I stumbled across an ingenious optimization for dealing with hash collisions. Before explaining my optimization, let me first briefly explain how hash tables work and what hash collisions are. I also made a video if you're interested.</p>
<p><a href="http://www.youtube.com/watch?v=pM9zhZB2KkM" title="Hash Tables"><img alt="" src="http://img.youtube.com/vi/pM9zhZB2KkM/0.jpg"></a></p>
<p>Say that we have a hash that maps someone's name to their age. <code>"adam"</code> is <code>27</code>, so we want to enter that into our hash.</p>
<p><img alt="" src="https://i.ibb.co/qWdjbhM/Slice.png"></p>
<p>Here's what happens:</p>
<ul>
<li><code>"adam"</code> gets put through a hash function.</li>
<li>The hash function spits out <code>7</code>.</li>
<li><code>7</code> is the index of the array where we are going to store <code>"adam"</code>'s value.</li>
<li>So we store <code>27</code> into <code>array[7]</code>.</li>
</ul>
<p>If we run <code>hash.get("adam")</code> in the future and need to look up the value for <code>"adam"</code>, we:</p>
<ul>
<li>Run <code>"adam"</code> through the hash function.</li>
<li>Get <code>7</code> as the output.</li>
<li>This means we have to look at <code>array[7]</code> to get the value.</li>
<li>So we look at <code>array[7]</code> to get our value.</li>
</ul>
<p>Hopefully if we have a key of <code>"alice"</code> or <code>"bob"</code> it'll hash to a different index. But... what happens if it hashes to the same index? That's called a hash collision.</p>
<p><img alt="" src="https://i.ibb.co/sJbJKnD/Slice.png"></p>
<p>A common approach is that if there's a collision, you store the values in a linked list.</p>
<p><img alt="" src="https://i.ibb.co/VJsSW3T/Slice.png"></p>
<p>Fair enough. That makes sense.</p>
<p>But wait!!! It takes <code>O(n)</code> time to look up a value in a linked list. Can't we use a binary search tree to speed that up to <code>O(log n)</code>???</p>
<p><img alt="" src="https://i.ibb.co/R3Vrc10/Slice.png"></p>
<p>Or... can't we take it a step further and use a <em>hash inside of a hash</em> to get the lookup time all the way down to <code>O(1)</code>?!</p>
<p><img alt="" src="https://i.ibb.co/7CyYNWY/Slice.png"></p>
<p>I hate to say it, but however many years ago when I had these thoughts, there were a few moments where I thought I was a genius. Now when I look back at that former self, I facepalm.</p>
<p>It is true that going from a linked list to a BST to a hash takes you from <code>O(n)</code> to <code>O(logn)</code> to <code>O(1)</code> lookup time. However, since collisions are rare, <code>n</code> is going to be small. And when <code>n</code> is small, <code>O(n)</code> might be faster than <code>O(1)</code>.</p>
<p>To understand why that is, think back to what Big-O really means. I think it helps to think about it as a "math thing" instead of a "programming thing". Consider two functions:</p>
<pre><code>f(n) = 4n + 1000
g(n) = 2n^2 + 5
</code></pre>
<p>Big-O of <code>f</code> is <code>O(n)</code> and Big-O of <code>g</code> is <code>O(n^2)</code>. We just focus on the part that "really matters". When <code>n</code> gets really big, the fact that it's <code>4n</code> doesn't really matter. Nor does the <code>+ 1000</code>.</p>
<p>But what about when <code>n</code> is small? Well, let's look at happens when <code>n</code> is <code>5</code>:</p>
<pre><code>f(5) = 4(5) + 1000 = 20 + 1000 = 1020
g(5) = 2(5^2) + 5 = 2(25) + 5 = 50 + 5 = 55
</code></pre>
<p>Look at that! The <code>O(n^2)</code> function is almost 20 times faster than the <code>O(n)</code> function!</p>
<p>And <em>that</em> is basically why they use a linked list instead of a BST or hash to handle collisions. Since <code>n</code> is small, Big-O isn't the right question to ask.</p>
<hr>
<p>Here's another example. I just wrote the following code while prepping for an interview:</p>
<pre><code>const isVowel = (char) =&gt; ["a", "e", "i", "o", "u"].includes(char);
</code></pre>
<p>Normally I wouldn't think twice about it, but since interviewers care so much about time complexity, I stopped to think about whether it could be improved.</p>
<p>And it hit me that it's actually <code>O(n)</code>(<a href="https://news.ycombinator.com/item?id=24660824">caveat</a>), because we've got an array and have to iterate over every element to see if the element matches <code>char</code>. It's easy to overlook this because we're using <code>includes</code> and not writing the code ourselves.</p>
<p>So then I thought that maybe we could use a hash instead to get <code>O(1)</code> lookup. Something like this:</p>
<pre><code>const isVowel = (char) =&gt; {
  const vowels = {
    a: true,
    e: true,
    i: true,
    o: true,
    u: true,
  };

  return !!vowels[char];
};
</code></pre>
<p>But then I realized that this is the same mistake I made with the hash collision stuff however many years ago. <em><code>n</code> is small, so Big-O isn't the question we should be asking</em>. Here <code>n</code> is <code>5</code>.</p>
<p>I think that the array approach would actually be faster than the hash approach, even though it's <code>O(n)</code> instead of <code>O(1)</code>. The reason for this is called locality.</p>
<p>If you dive deep under the hood, when you look up an element in an array, the CPU actually grabs a bunch of adjacent elements as well as the one you wanted, and it stores the adjacent elements in a cache. So here when we look up <code>"a"</code> in the array, it'll probably grab <code>"a"</code>, <code>"e"</code>, <code>"i"</code>, <code>"o"</code>, and <code>"u"</code>. And so next time when we want to grab <code>"e"</code>, it can take it from the cache, which is a lot faster. This works because the elements in the array are close to each other in the physical memory. But with a hash, my understanding is that they wouldn't be so close, and thus we wouldn't benefit from this spatial locality effect.</p>
<p>I'm no low-level programming wiz so I'm not sure about any of this. That's ok, I think it's beside the point of this post. The real point of this post is that when you have a little <code>n</code>, Big-O doesn't matter.</p>
</div>
</div></div>]]>
            </description>
            <link>https://adamzerner.bearblog.dev/big-o-little-n/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657747</guid>
            <pubDate>Fri, 02 Oct 2020 00:59:03 GMT</pubDate>
        </item>
    </channel>
</rss>
