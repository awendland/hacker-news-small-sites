<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 24 Oct 2020 04:32:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 24 Oct 2020 04:32:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The programming architecture of Babbage's Analytical Engine]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24856235">thread link</a>) | @doener
<br/>
October 22, 2020 | https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Prof.+Dr.+Raul+Rojas">Prof. Dr. Raul Rojas</a>

</p>
<p>
Playlists:
<a href="https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas/playlist">'vcfb20' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas/audio">audio</a></p>
<!-- %h3 About -->
<p>The mathematician and inventor Charles Babbage wrote 26 programs between 1836 and 1841 for the unfinished "Analytical Engine" (AE). The code is embedded implicitly in tables summarizing program traces. In this talk, I present the programming architecture of Babbage’s mechanical computer based on the first code written for the machine. The AE had a processor separate from memory, and worked using a kind of dataflow approach. The stream of arithmetical operations was independent from the stream of memory addresses. Special "combinatorial" cards allowed the processor to execute FOR and WHILE loops. Combinatorial cards also allowed independent looping through the stream of memory addresses. Quite sophisticated computations were possible and illustrate why Babbage talked about the possibility of doing "algebra" with his machine. The programs I will discuss predate by several years the account published by Menabrea in 1842 and translated later by Lady Lovelace with notes of her own.</p>

<h3>Download</h3>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24856235</guid>
            <pubDate>Thu, 22 Oct 2020 09:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Google obliterated my 4 year old Chrome extension with 24k+ users (2016)]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24855582">thread link</a>) | @Fiveplus
<br/>
October 22, 2020 | https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18 | <a href="https://web.archive.org/web/*/https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><div><p>
              After 3 months of trying everything I could think of, I give up.
              I don’t think I will ever develop anything for the Google
              ecosystem again. I’m not angry, I’m not doing this out of spite.
              I just don’t think it is worth it to invest any amount of effort
              to build something on a platform that turned out to be so
              unreliable.
            </p>  <h2>Please scroll down to read the latest update.</h2>  <p>
              I started developing my first extension back in 2010, when Apple
              finally decided to implement proper extension support in Safari.
              Exciting times. I spent a weekend writing my first Safari
              Extension, an ad blocker called “Cleaner Facebook”. I must
              confess it was ugly, and by today’s standards, very poorly
              written, but it did the job.
            </p> <p>
              After a few weeks while browsing Facebook using Chrome, the
              annoying ads popped up and I figured that it’ll be worthwhile to
              port it over, so I did. I also made it available to everyone via
              <a href="http://apps.graffino.com/" target="_blank" title="App Development">Graffino’s apps playground.</a></p> <p>
              Months later the due to some policy changes in Chrome, I moved
              to the Chrome Web Store where I made it available for free under
              the name “Cleaner Facebook”.
            </p> <p>
              What happened next was beyond my wildest expectations. It
              quickly gathered around 4.000 users and over the last year it
              surged to 24.000+ users. Whenever I pushed an update, the
              numbers would spike.
            </p> <p>
              I got quite a few offers to sell it, so others could push
              advertising through it. Thing is, I never wanted to make any
              money off it and I felt like I was betraying my users. So, I
              kept it and improved it constantly. It worked so well because I
              needed it to work well, I was using it daily and my users loved
              it. It got a 5 stars rating and over 85 reviews.
            </p> <blockquote>
              Google has been notified that some of your materials allegedly
              infringe upon the trademarks of others.
            </blockquote> <p>
              At the end of May this year, I received an email from Google
              telling me that my extension violated Facebook’s trademark and
              got taken down. There was no information how to solve the issue,
              no way to appeal. Google washed its hands clean and directed all
              inquiries to an automatically generated email address. This
              email address was a black hole that never responded to any of my
              emails.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/bcfd01f.png" alt="Google's notification that they removed Graffino's Ads removal app from the store."> <figcaption>
                The original infringement and taken down notice (shortened).
              </figcaption></figure> <p>
              I figured out that the name might be an issue although there
              were
              <a href="https://chrome.google.com/webstore/search/facebook?hl=en-US" target="_blank">a lot of other extensions</a>
              with the same name in the store. Even so, I changed the name of
              my extension to “Cleaner — for Facebook” and resubmitted it to
              the store where it got placed “In review”.
            </p> <p>
              Over the next weeks I never received any email from the Chrome
              Store other than the initial take down notice. When I logged in
              again, I found my extension was still “Taken down” and the “In
              review” flag gone.
            </p> <p>
              I went on to search for a Developer Support page, but after half
              an hour of searching I found out that there is none. There is no
              support whatsoever for the developer besides Google’s own
              documentation. If you encounter an issue that you can’t solve
              yourself, you’re stranded. There’s no contact info. No one to
              write to.
            </p> <p>
              After getting really frustrated that day, I vented out sending
              out a nasty email to removals@google.com. Not sure it helped.
            </p> <p>
              The next day I poked around and found a support form intended
              for Chrome Web Store users. In my desperation I figured this was
              my only option left.
            </p> <p>
              About a week later, I got my first reply from <em>Google</em>.
              Although it sounded nice, it wasn’t really helpful. Most
              probably due to the fact it was a canned response, totally
              unrelated to my issue.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/a38f41d.png" alt="Google's first email response to Graffino's complaint."> <figcaption>First canned response</figcaption></figure> <p>
              Later that day, I fired a few other emails, telling them that my
              extension was not under review and the cause for the take down
              was not flagging. I also submitted another message via the
              support form I used before. My requests got closed with a
              <em>“Thanks for your feedback.”</em> canned response.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/c1a157e.png" alt="Google's first email response to Graffino's complaint."> <figcaption>“Thank you for your feedback” response</figcaption></figure> <p>
              Meanwhile my extension’s user base was dwindling, and I could do
              absolutely nothing about it.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/ee3fd6a.png" alt="Google's first email response to Graffino's complaint."> <figcaption>
                Screenshot from the Developer Dashboard made on the 18th of
                July.
              </figcaption></figure> <p>
              After another two weeks I finally gave up and sent this final
              email. I got a reply that my case was “Reopened”. It’s been a
              month and I didn’t hear back since, so I don’t think I will ever
              get my extension back on the store.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/3e2eaf4.png" alt="Google's first email response to Graffino's complaint."> <figcaption>Final email from my side.</figcaption></figure> <p>
              I’m not playing the victim here, and I don’t expect this post to
              solve anything for my extension. I just want you to think twice
              before creating a revenue stream based on the Chrome Web Store.
            </p> <p>
              Google has great automated tools and services, to help
              developers ramp up and deliver their apps to users quickly and
              painless. Most of the time these tools work perfectly. The
              problems arise when they don’t.
            </p> <p>
              I have never experienced such frustration, and such feelings of
              helplessness from any other major player out there. A similar
              issue with the
              <a href="https://safari-extensions.apple.com/details/?id=com.graffino.cleaner-for-facebook-86755BRK69" target="_blank">“Cleaner Facebook” Safari extension”</a>, got promptly solved by Apple in under three days.
            </p> <p>
              Google has a record of very bad user support. Basically, if your
              issue is not listed in the “Support Forums” you’re screwed. If I
              would have based my business on the Chrome Web store, I would be
              out of business by now.
            </p>  <h2>Update 8.09.2016</h2> <p>
              I never imagined this would generate this amount of attention:
              featured by
              <strong>Medium, 100k+</strong> views, heated discussions on
              <a href="https://www.reddit.com/r/programming/comments/51mgix/how_google_obliterated_my_4_year_old_chrome/" target="_blank">Reddit</a>
              or
              <a href="https://news.ycombinator.com/item?id=12442048" target="_blank">Hackernews</a>. I don’t really expect this to change anything for me, but I’m
              glad people are speaking up. If Google would implement a paid
              support option like Apple does for its developers, I’m sure a
              lot of pain would be avoided.
            </p> <p>
              I try to read everything, but I don’t respond on Medium (hate
              the commenting system), but you can ping me on Twitter.
            </p> <h2>To answer the most common questions:</h2> <p>1.<em> “Why don’t you change the name completely?”</em></p> <p>
              Well, because using “for Facebook” in the name is considered
              <a href="http://www.inta.org/TrademarkBasics/FactSheets/Pages/FairUse.aspx" target="_blank">fair use</a>. Also, when managing an app or extension with that many users,
              you don’t really want to confuse the users by renaming it to a
              completely different thing over night. It’s also an extension
              that only works on Facebook. I might also be infringing with the
              icon.
            </p> <p>
              So, you see, I really need guidelines to do this. Again, my
              problem is with the way this was handled, not the takedown
              itself.
            </p> <p>
              2.
              <em>“The extension was taken down because it was blocking ads.”
              </em></p> <p>
              This is simply untrue. I don't believe I was intentionally
              targeted. I was simply unlucky enough to be targeted by
              automated tools. Even the way my requests were handled weren’t
              done with malicious intent by Google. I think I’m just an edge
              case for which their support tools aren’t equipped to deal with.
            </p> <h2>Update: 9.09.2016</h2> <p>
              I received an email from Google today in which they’re
              expressing their apologies about the incident. It seems that
              they cannot do anything for the current store entry until the
              original complainant retracts his complain.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/3e2eaf4.png" alt="Google's first email response to Graffino's complaint."> <figcaption>Final email from my side.</figcaption></figure> <p>
              They offered me clear options though. We’re currently assessing
              what the best option might be. As I said in the article, this
              wasn’t an intentional targeting but a slip-up of their support
              which they’re trying to fix.
            </p> <p>
              Hopefully I will have the time to write a follow-up once all
              this is over. I didn’t expect or wanted this kind of attention,
              these have been 2 stressful days for me, trying to keep up with
              all the requests and messages, as I do have a job and my own
              company to run.
            </p> <p>
              It also happens that today is my birthday. I guess receiving a
              response from Google was my birthday present :).
            </p>  <h2>Update: 10.09.2016</h2> <p>
              You can still find the
              <a href="http://apps.graffino.com/" target="_blank">ad blocker extension</a>
              here. However, you will not be able to run it. Chrome made
              changes so that extensions cannot be side-loaded without an
              enterprise profile.
            </p> <h2>Final Update: 12.09.2016</h2> <p>
         …</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18">https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18</a></em></p>]]>
            </description>
            <link>https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18</link>
            <guid isPermaLink="false">hacker-news-small-sites-24855582</guid>
            <pubDate>Thu, 22 Oct 2020 07:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The virtual device farm for rendering websites on multiple devices]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24855342">thread link</a>) | @seleniumbase
<br/>
October 21, 2020 | https://seleniumbase.io/devices/?url=news.ycombinator.com | <a href="https://web.archive.org/web/*/https://seleniumbase.io/devices/?url=news.ycombinator.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://seleniumbase.io/devices/?url=news.ycombinator.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-24855342</guid>
            <pubDate>Thu, 22 Oct 2020 06:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Early Adopters: Be Picky About Who You Serve]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24854108">thread link</a>) | @johnkoht
<br/>
October 21, 2020 | https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve | <a href="https://web.archive.org/web/*/https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>October 08, 2020</p></header><section itemprop="articleBody"><p>Any successful founder will tell you that team, product, and market are the most critical factors to building a successful business. And you’ll probably hear many of them talk about being “customer-obsessed” or “customer first.” But one of the most underrated factors in their success is not just the customers but also the quality of their early adopters.</p>
<p>While we can all agree that early adopters are good, they are not all created equal. The wrong users can derail entrepreneurs, causing them to lose focus and solve the wrong problems. Like a bad team or poor product, the wrong early adopters can push a company towards failure.</p>
<p>You should be picky about who you serve, especially during the initial phase of your product development process. Finding early adopters should be an investment similar to hiring a team. Entrepreneurs should recruit, interview, qualify, and partner with early adopters that will help them become most successful. It’s not a simple process and shouldn’t be taken for granted.</p>
<p>So how do you find the right early adopters? That’s a difficult question to answer. It’s all going to come down to your market, product, and judgment. But here are some characteristics that you should look for.</p>
<h2>They are in real pain.</h2>
<p>The right early users are deeply affected by the problem that you’re solving. They know the problem exists and are hungry for a better solution. They’ve probably tried other solutions and yearn for something better.</p>
<p>Early adopters will be keenly aware of the problem. They will explain the problem in various ways and how it affects their ability to work, live, or perform some activity. They’ve probably even tried to solve it somehow, maybe using Excel, some no-code app, a third-party tool, or a manual process.</p>
<h2>Their problem is very specific.</h2>
<p>Users have all kinds of problems. Most of which you’ll never solve. Others might be in your roadmap but are not core today. It’s essential to focus on users with the specific problem that you are solving for. Problems can emerge from various systems, workflows, and integrations that have nothing to do with the core problem or your potential solution. Eliminate the users who are looking to solve all of their problems. Eliminate the users who want a different, possibly related, problem solved.</p>
<p>The best early adopters need to solve a specific problem. It’s vital to ensure that it matches your vision and product solution.</p>
<h2>They are excited to help you.</h2>
<p>The solution you’re offering them is going to alleviate a pain point, and the best early adopters are more than excited to help you help them. The more excited they are, the more pain they experience from the problem.</p>
<p>Early adopters are partners. They should be excited about working with you, helping you solve their problem, and providing feedback. They should also be excited that they will be using your solution before others and developing a competitive edge as well.</p>
<p>When you acquire great early adopters, they will be the ones sending you feedback often and with excitement. They’ll be proud to help you craft your solution and feel like their part of the team.</p>
<h2>They are empowered</h2>
<p>Early adopters must be empowered to make decisions quickly. Working with your dream enterprise customer sounds great, but if they can’t get approval, move quickly, or activate your solution, you’ll be at the mercy of their bureaucracy.</p>
<p>Working with early adopters is a partnership, not a transaction. It’s important that early adopters can take your prototype, beta, or product and implement it within their team or organization.</p>
<p>The person is as vital as the company. Are they authorized to make the right decisions? Can they dedicate the time and resources to the problem and solution? Are they empowered to help you create the right solution? If they can’t meet these criteria, you should find another early adopter who can.</p>
<h2>They have a high-risk tolerance.</h2>
<p>The best products are built with customers, through an iterative process of trial and error. Early adopters who experience the pain are not enough; you need a partner who can tolerate the risks involved in the product development process. Not only do they have a high-risk tolerance, but they should also be willing and able to engage in ongoing experiments throughout the process.</p>
<p>Experimentation is critical to the process. You need to ensure that you partner with a customer that recognizes the process is about learning and improvement, not a finished product.</p>
<p>When interviewing customers, you should be upfront about this process and ensure they are comfortable with it. It’s okay if a potential customer can’t commit to the process, you can keep in touch and invite them to the product when it’s a bit more developed.</p>
<h2>Hire early adopters, don’t settle.</h2>
<p>Don’t just settle for the first few customers that show interest in your product. Spend time doing market mapping to better understand the market, sectors, and potential customers. Learn more about the companies and find who the best possible contacts would be. Reach out and conduct interviews to learn more about their organization, how the problem affects them, and their goals regarding the problem and solution. Make sure to dig in and ask tough questions to assess their risk-tolerance, current solutions, and whether they are authorized to make the necessary decisions.</p>
<p>If a potential customer seems like the problem isn’t that big of a deal, you should move on. If they can’t focus on just the one problem, move on. If they aren’t authorized to make decisions, ask about their manager and see if you can work your way up.</p>
<p>You should spend a good amount of time learning about each of these customers and selecting the best candidates. Don’t hesitate to reach out multiple times and have conversations with them to build confidence in your decisions. These will be partners as you experiment and craft your solution, so ensure you find the best possible partners.</p>
<h2>They’re all leads, too.</h2>
<p>Choosing the best early adopters doesn’t mean that the others will not be good future customers. All of these customers are now leads. Some might be great customers once you hit a particular milestone and finish more features; others might be customers down the road. Keep in touch and share updates on the product and feature set.</p>
<p>Recruiting high-quality early adopters is difficult but vital to the success of a company. Spend the time upfront to say no to customers that don’t fit your current vision and mission. While the process is difficult and costly, it’ll be worth the investment as the product matures.</p></section></article></div>]]>
            </description>
            <link>https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve</link>
            <guid isPermaLink="false">hacker-news-small-sites-24854108</guid>
            <pubDate>Thu, 22 Oct 2020 01:37:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a startup financial model from scratch]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24853787">thread link</a>) | @aaronbski
<br/>
October 21, 2020 | https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model | <a href="https://web.archive.org/web/*/https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
  <article id="article-57daf9aad2b857a2108683be" data-item-id="57daf9aad2b857a2108683be">

    

    <div>
      
        <div data-layout-label="Post Body" data-type="item" data-updated-on="1473969767493" id="item-57daf9aad2b857a2108683be"><div><div><div data-block-type="2" id="block-7c825fcce3d916c3aa66"><div><p><em>This article was originally published over on Startup Rocket&nbsp;</em><a href="https://www.startuprocket.com/articles/startup-financial-modeling-part-1-what-is-a-financial-model" target="_blank"><em>here</em></a><em>, and written by Will Little and Troy Henikoff.</em></p><p><em>This series is the result of a friendly debate I had recently with&nbsp;</em><a href="https://www.mathventurepartners.com/troy-henikoff" target="_blank">Troy Henikoff</a><em>&nbsp;(former Techstars Chicago Accelerator Managing Director)&nbsp;regarding the best approach for founders to take when building a financial model. More accurately, the “debate” was a strong adverse reaction from Troy after I shared a template I built for Prota Ventures’ portfolio companies. His feedback was, essentially, to never use a template and instead build each model from scratch.</em></p><p><em>He invited me to a 90-minute lecture he gave where he overwhelmingly convinced me and the room that, indeed, founders need to take the time necessary to build their models from scratch. After I asked him where I could find his lecture material online, he suggested we co-author this article series since there weren’t many solid resources available. We sincerely hope you find this series helpful.&nbsp;</em></p><p>Our plan is to break this out into a four-part series and guide you through the components necessary for building your own financial model from scratch:</p><ul data-rte-list="default"><li><p><a href="https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model" target="_blank">Part 1: The Why and What of Financial Modeling</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/2/startup-financial-modeling-part-2-start-with-your-assumptions" target="_blank">Part 2: Assumptions</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/2/startup-financial-modeling-part-3-the-income-statement-and-custom-detail-tabs" target="_blank">Part 3: Income Statement and Custom Detail Tabs</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/7/startup-financial-modeling-part-4-the-balance-sheet-cash-flow-and-unit-economics" target="_blank">Part 4: Cash Flow, Balance Sheet and Keeping the Model Updated</a></p></li></ul><p>In short, a financial model is an abstract mathematical representation of how a company works (and more importantly, how it will work going forward). The model has inputs and outputs. The inputs are the assumptions that drive the model, things like what drives your customer acquisition cost, what your churn rates are, how much you pay people, etc. The outputs are a set of projections that show how the company will perform if the assumptions are true. One model can produce multiple sets of projections given different assumptions.</p><p>Based on a set of assumptions, a financial model is used to make smart decisions (e.g. how many sales people to hire and what to pay them). The model includes financial projections that are tied mathematically to the assumptions, which allows operators to “play with the variables” in order to understand how certain decisions might affect the future health of their company.</p><p><strong>Troy has an important story to share on this topic:</strong></p><p>“When fundraising for SurePayroll, we had some very high level financials in the pitch deck. Inevitably, VC’s would ask where the numbers came from. I would tell them that we had a very detailed financial model that drove it, I was setting the bait…</p><p>They would ask to be sent a copy of the model and I would refuse. I would only share it by first sitting down with them and an associate and reviewing the model in person and after that 90 minute session, I would leave them a copy of the model to play with further.</p><blockquote><p>They would insist that they could figure it out without the meeting, but I ALWAYS held my ground. I wanted the meeting not just to save them time and frustration learning a new model, but more importantly to get more face time with them in a situation where I was going to shine.</p></blockquote><p>I knew the model inside and out since I built it; I could answer any question about any cell and look like a genius. In the end, I did eight&nbsp;of these meetings and EVERY ONE of the firms that did the 90 minute meeting with me on the financial model either made an investment in the company or made an offer to invest in the company.&nbsp;<strong>Every single one</strong>.”</p><p>While it’s easy to search around and find a template to use, those templates were built by someone with a particular business in mind. Since every business is unique, this will lead you into trouble.</p><p>While it’s often helpful to&nbsp;<em>learn&nbsp;</em>from other people’s models to ensure, for example, that you aren’t missing anything important, you should never build your model using their template. You’ll end up banging your head against a wall when you need to change things, and you’ll inevitably be confused about some nuance that will come back to haunt you since you don’t understand it.</p><blockquote><p>In other words, while you may think that a template will help you save time, what you are actually doing is acquiring “technical debt” that will end up costing you more time in the long run.</p></blockquote><p>Plus, it’s critical to understand every column, row, cell and tab in your spreadsheet for two key reasons; it will help you better manage your business, and when the time comes to explain it to an investor, you’ll be able to explain exactly how it works and increase your odds of landing funding.</p><p>Since most people are using the financial model to communicate projections to investors, it is critical that you speak the investors’ language. They are used to having financials in Excel, so you should build your model in Excel.</p><blockquote><p>Google sheets is convenient for making changes and having multiple people editing, but sending an investor a model in Google sheets signals that you are not financially savvy.</p></blockquote><p>Investors are also used to seeing three standard statements; an income statement, a balance sheet, and a statement of cash flow. &nbsp;Each of these is more credible if it has BOTH the past performance and the future projections in the same spreadsheet.</p><p>Your spreadsheet should contain a tab for each of these outputs along with an “assumptions” tab and custom detail tabs needed to help calculate the main outputs. We’ll walk through a specific example later in this series so you have a better understanding of what this should look like.</p><p>Because of various accounting nuances – such as fixed asset depreciation and deferring revenue – if you assign ten accountants to finish your books at the end of the year, you’ll get ten different answers for how much profit (or loss) you had in the year. While hopefully not far off from the others, each will have a slightly different report of your “profit” based on their accounting opinions.</p><blockquote><p>However, the balance of your bank account is a specific number to point at; it’s a fact that your ten accountants should agree on.</p></blockquote><p>Therefore, it’s important to remember that your financial model will have your own opinions baked in regarding your profit. This means that examining your cash flow carefully as you fine-tune your business assumptions is critical.</p><p>Having a solid financial model is a significant step in communicating to investors that you are a logical thinker with a defensible plan and clearly understand your business and the levers that drive it. &nbsp;&nbsp;</p><p>Nobody expects your model to be perfect, as a matter of fact, when we present a model, we always open with the same line:</p><blockquote><p><em>“The only thing we know for sure about this model is that it is wrong. But, if we look critically at it we can better understand the drivers of the business and what we need to be focused on to reduce our risk.” &nbsp;</em></p></blockquote><p>Keep in mind, investors are looking for the big home runs, but they are also looking at reducing their risk. The model can help them get comfortable with the risk.</p><p>– – –</p><p><em>In our next post in this series, we’ll dive in a step-by-step guide of how to build a financial model, starting with the assumptions tab.&nbsp;</em><a href="https://satchel.works/@wclittle/subscribe" target="_blank">Subscribe</a><em>&nbsp;to Will’s newsletter to get notified when the next articles are up. As we mentioned above, feel free to ping us on Twitter (</em><a href="https://twitter.com/wclittle" target="_blank"><em>@wclittle</em></a><em>,&nbsp;</em><a href="https://twitter.com/troyhenikoff" target="_blank"><em>@troyhenikoff</em></a><em>) with any questions.</em></p></div></div></div></div></div>
      
    </div>


    

    
      
    

    

  </article>

  

  

  
  
  

</div></div>]]>
            </description>
            <link>https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model</link>
            <guid isPermaLink="false">hacker-news-small-sites-24853787</guid>
            <pubDate>Thu, 22 Oct 2020 00:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI reveals hundreds of millions of trees in the Sahara]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24853679">thread link</a>) | @hhs
<br/>
October 21, 2020 | https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara | <a href="https://web.archive.org/web/*/https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-area">
        <div>
          <!-- Content with right menu -->

<div>
  
    





  

	<p>
		20 October 2020
	</p>

	


	<div>
		<p><span>TREES</span></p><p>There are far more trees in the West African Sahara and Sahel than most would expect. A combination of artificial intelligence and detailed satellite imagery allowed a team from the University of Copenhagen and international collaborators to count all trees across a 1.3 million km2 area of West Africa. 
</p>
	</div> 
		<figure>
			<img alt="Dryland landscape in Africa" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/Sahara_1100x600.jpg" title="Dryland landscape in Africa">
			<figcaption>Photo: Martin Brandt</figcaption>
		</figure>

	<p>If you think that the Sahara is covered only by golden dunes and scorched rocks, you aren’t alone. Perhaps it's time to shelve that notion. In an area of West Africa 30 times larger than Denmark, an international team, led by University of Copenhagen and NASA researchers, has counted over 1.8 billion trees and shrubs. The 1.3 million km<sup>2</sup> area covers the western-most portion of the Sahara Desert, the Sahel and what are known as sub-humid zones of West Africa.</p>
<p>"We were very surprised to see that quite a few trees actually grow in the Sahara Desert, because up until now, most people thought that virtually none existed. We counted hundreds of millions of trees in the desert alone. Doing so wouldn't have been possible without this technology. Indeed, I think it marks the beginning of a new scientific era," asserts Assistant Professor Martin Brandt of the University of Copenhagen’s Department of Geosciences and Natural Resource Management, lead author of <a href="https://www.nature.com/articles/s41586-020-2824-5">the study’s scientific article, now published in <em>Nature</em></a>.</p>
<p>The work was achieved through a combination of detailed satellite imagery provided by NASA, and deep learning — an advanced artificial intelligence method. Normal satellite imagery is unable to identify individual trees, they remain literally invisible. Moreover, &nbsp;a limited interest in counting trees outside of forested areas led to the prevailing view that there were almost no trees in this particular region. This is the first time that trees across a large dryland region have been counted.</p>
<h2>The role of trees in the global carbon budget</h2>
<p>New knowledge about trees in dryland areas like this is important for several reasons, according to Martin Brandt. For example, they represent an unknown factor when it comes to the global carbon budget:</p>
<p>"Trees outside of forested areas are usually not included in climate models, and we know very little about their carbon stocks. They are basically a white spot on maps and an unknown component in the global carbon cycle," explains Martin Brandt.</p>
<p>Furthermore, the new study can contribute to better understanding the importance of trees for biodiversity and ecosystems and for the people living in these areas. In particular, enhanced knowledge about trees is also important for developing programmes that promote agroforestry, which plays a major environmental and socio-economic role in arid regions.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p>"Thus, we are also interested in using satellites to determine tree species, as tree types are significant in relation to their value to local populations who use wood resources as part of their livelihoods. Trees and their fruit are consumed by both livestock and humans, and when preserved in the fields, trees have a positive effect on crop yields because they improve the balance of water and nutrients," explains Professor Rasmus Fensholt of the Department of Geosciences and Natural Resource Management.</p>

<figure><img alt="The area where the trees were mapped" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/West_Africa_study_area_1100x600.jpg" title="The red rectangle marks the area where the trees were mapped">
<figcaption>The red rectangle marks the area where the trees were mapped.</figcaption>
</figure>

<h2>Technology with a high potential</h2>
<p>The research was conducted in collaboration with the University of Copenhagen’s Department of Computer Science, where researchers developed the deep learning algorithm that made the counting of trees over such a large area possible.</p>
<p>The researchers show the deep learning model what a tree looks like: They do so by feeding it thousands of images of various trees. Based upon the recognition of tree shapes, the model can then automatically identify and map trees over large areas and thousands of images. The model needs only hours what would take thousands of humans several years to achieve.</p>
<p>"This technology has enormous potential when it comes to documenting changes on a global scale and ultimately, in contributing towards global climate goals. It is a motivation for us to develop this type of beneficial artificial intelligence," says professor and co-author Christian Igel of the Department of Computer Science.</p>
<p>The next step is to expand the count to a much larger area in Africa. And in the longer term, the aim is to create a global database of all trees growing outside forest areas.</p>





  

</div>
<div>

  
    
    
        	

	


        <div>
    <p>
        <h2>Fakta</h2>
    </p>
    <div>
        <ul>
<li>The researchers counted 1.8 billion trees and shrubs with crowns larger than 3 m<sup>2</sup>. Thus, the actual number of trees in the area is even higher.</li>
<li>Deep learning can be characterized as an advanced artificial intelligence method where an algorithm is trained to recognize specific patterns in large amounts of data. The algorithm used in this research was trained using nearly 90,000 images of different trees across a variety of landscapes. </li>
<li><a href="https://www.nature.com/articles/s41586-020-2824-5">The scientific article for this study is published in the renowned journal Nature.</a> </li>
<li>The research was carried out by researchers from the University of Copenhagen; NASA Goddard Space Flight Center, USA; HCI Group, University of Bremen, Germany; Université Paul Sabatier, France; Pastoralisme Conseil, France; Centre de Suivi Ecologique, Senegal; Geosciences Environnement Toulouse (GET), France; Ecole Normale Supérieure, France; Université Catholique de Louvain, Belgium.</li>
<li>The research is supported, among others, The AXA Research Fund (postdoctoral programme); Independent Research Fund Denmark - Sapere Aude; Villum Foundation and the European Research Council (ERC) under the EU's Horizon 2020 Programme.</li>
</ul>

    </div>
</div>


        






  
</div>

        </div>
        
      </div></div>]]>
            </description>
            <link>https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara</link>
            <guid isPermaLink="false">hacker-news-small-sites-24853679</guid>
            <pubDate>Thu, 22 Oct 2020 00:07:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on My Colon Cancer]]>
            </title>
            <description>
<![CDATA[
Score 336 | Comments 182 (<a href="https://news.ycombinator.com/item?id=24853503">thread link</a>) | @whatrocks
<br/>
October 21, 2020 | https://www.charlieharrington.com/colon-cancer | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/colon-cancer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The giant robot looks like a WED Treadwell, <a href="https://www.charlieharrington.com/robots-i-love">my favorite robot</a> of all the Star Wars droids. I admit, I was worried that it would look organic, like a Sentinel from The Matrix, with wriggling Dr. Octopus arms and pinchy pincers that pinch. But I'm calmed by the robot's EVE-like exterior.</p>
<p>The room is sterile. A dozen masked, gloved attendants in blue buzz. I imagine I'm an astronaut about to step into the rocketship capsule.</p>
<p>Except I won't be going anywhere on this particular journey, unless something goes very, very wrong. In fact, I've already been asked repeatedly by various staffers to describe what I'm expecting to happen in this room over the next few hours:</p>
<blockquote>
<p>"I'm here to remove my sigmoid colon via robotic surgery because of the cancerous tumor inside."</p>
</blockquote>
<p>I'm 34 years old. It's October 12th, 2020. Five weeks ago I was diagnosed with colon cancer.</p>
<h2>Stool, bloody stool</h2>
<p>I've always been a standing wiper. Not sure entirely why. I must have once, accidentally, touched a load of poo during a seated wipe. That sort of thing can change a person.</p>
<p>This charming anecdote does factor into our story, because it means I've always had a pretty good sense for my poo. Consistency, quality, and color, both in the bowl and on the TP. Did you know, there's even a seven-stage scientific classification system for your poo, called the <a href="https://en.wikipedia.org/wiki/Bristol_stool_scale">Bristol stool scale</a>?!</p>
<p><span>
      <span></span>
  <img alt="Bristol stool scale" title="Bristol stool scale" src="https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/a6d36/bristol.png" srcset="https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/222b7/bristol.png 163w,
https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/ff46a/bristol.png 325w,
https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/a6d36/bristol.png 650w,
https://www.charlieharrington.com/static/aa89064dc77b216479fbe409ba4b8653/be86f/bristol.png 662w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
    </span></p>
<p>I first noticed blood two or three years ago. On a monthly or so cadence, I'd wipe and notice a reddish tinge. Not bright red, more like muddy-red. Poopy-red. Initially, I thought little of it. Just a minor curiousity. It certainly didn't happen every time. Still, I decided to check off the <code>Blood in stool</code> box on the forms at my annual physical with my primary care doctor that year.</p>
<p>A brief aside on the phrase "your primary care doctor." Like in <em>Forgetting Sarah Marshall</em>, the last doctor I really thought of as "my doctor" was my pediatrician. Since "becoming an adult", I've lived in three cities in two countries, which means that I've generally had no idea who my primary care doctor is or was, only that I'd need to find one to give me a referral to get this wart on my foot removed.</p>
<p><span>
      <span></span>
  <img alt="Firetruck" title="Firetruck" src="https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/a6d36/firetruck.png" srcset="https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/222b7/firetruck.png 163w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/ff46a/firetruck.png 325w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/a6d36/firetruck.png 650w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/e548f/firetruck.png 975w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/3c492/firetruck.png 1300w,
https://www.charlieharrington.com/static/77fe5d6a0fb7c7f56ef4920d22c1efa9/6c2de/firetruck.png 1334w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
    </span></p>
<p>Anyway, this season's Dr. Who told me not to worry about the blood. "It's probably hemorrhoids."</p>
<p><em>WTF is a hemorrhoid?</em> I wondered to myself as I said to him, "Sounds good." Googled it after, and I learned that it's a vein that pokes out a little in your butt and doesn't really want to be poking out a little, so it bleeds. Seems like a thing that can happen, so I more or less returned to regularly scheduled programming and just dealt with the occasional poopy-red wipe. This doc also said I probably don't need to come for a physical for a few years, that annual physicals are a myth, dry land in a water world.</p>
<p>Fast-forward to 2020. Everything sucks. And the bloody wipes are making a resurgence. Because, of course, they are. About four months ago I noticed that my first poop of the day (I usually go 2x) would have this purple-red streak embedded in it, like a racing stripe from hell. And it would happen almost without fail every single morning. That just didn't seem right, no matter what Doctors of Physicals Past told me. And then one morning I felt like I had actual blood dripping from my butt.</p>
<p>Now I consider myself to be a mostly healthy person. I eat fairly well (even though I enjoy the occasional sourdough loaf and hazy IPA), I run and bike and hike regularly, I ran an IRONMAN in 2016 and a few ultramarathons since. I also don't like being sick (who does?). But, like with most things in my life, I want to be "good" at health. An ideal dental appointment for me would go something like this, "Wow, Charlie, these are the straightest, whitest teeth we've ever seen. We'd like you to come in and be the model for our Instagram ads and also be our 3D teeth model for dentures. Congratulations. Here's <em>two</em> free toothbrushes. You also never need to floss again."</p>
<p>Anything that deviates from that ideal makes me squirm and I do think I can fix anything. For what it's worth I still believe that, if I ever encounter a blue flower on a mountain-top, I'm only a few months of mystical training away from becoming Batman. I already have the cape (it's actually a Harry Potter robe, but, hey, I'm scrappy).</p>
<p>At the same time, I counterweight this with a mild touch of hypochondria. I'll see the poison oak in the mistletoe, so to speak. In this case it was a gift.  I googled again for <em>stool, bloody stool</em> and the dreaded <em>colon cancer</em> came back. Last time, I averted my eyes from these search results. But the bloody racing stripes weren't going away. I needed to get myself checked out.</p>
<p>Then I remembered an email from work: I was eligible for a <a href="http://members.onemedical.com/membership_referrals?code=cha0014&amp;source=sa">OneMedical</a> membership. I knew there was hype about OneMedical, certainly I've seen the billboards, but I still wasn't exactly sure what they were all about. It had been a few years since my last physical, as you know, so I was primary-care-less, with a bloody problem on my hands. I downloaded the OneMedical app, uploaded a photo of my insurance card, beep-boop, and I've got an appointment with a new doc in a few days in one of their nearby clinics. Already, I loved the experience - I could text my questions any time (see <em>foot wart</em> above). I'd describe OneMedical as a network of clinics with an app for scheduling appointments and texting with a doc. Sure, ZocDoc kinda does the scheduling thing, but Zocdoc feels like you're sifting through the classifieds. Gimme some non-user-generated-ratings-based curation, please. </p>
<p>So, I met with the doc, liked him a lot, discussed my bloody poops, and sheepishly asked if he'd be my new primary care. He agreed, and he also referred me to UCSF for a colonoscopy. Sure, I'm young, and it's probably hemorrhoids, we agreed, but it's the only way to be sure.</p>
<p>After some jiggling about with the referral documentation, we finally get the colonoscopy scheduled for a few weeks later on Sept 9th.</p>
<p>Then, on August 28th, <a href="https://en.wikipedia.org/wiki/Chadwick_Boseman">Chadwick Boseman</a> died of complications from colon cancer.</p>
<p>I wasn't freaked out. Okay, yes, I was very freaked out.</p>
<h2>Colonoscopies are not bad</h2>
<p>What's a colonoscopy? It's a surgical procedure where the doctor goes all the way up your butt to see what's going on in there. You are completely knocked out, so you feel nothing. The only thing you need to do is what we in the business like to call "bowel prep."</p>
<p>Allow me to describe bowel prep: the day before the procedure, you will poop your ever-living guts out for a few hours until you are clean-as-a-whistle, stem to stern. They'll give you a prescription for a gigantic jug of clear laxatives that you'll drink every 15 minutes or so for a few hours. In today's toilet-paper hoarding economy, I'd make sure that you are stocked up, because this gets messy.</p>
<p>Other then the laxatives, you're allowed to drink clear liquids - which is confusing because you can enjoy such clear liquids as black coffee, Gatorade, broth, even green jello.</p>
<p>But that's it. Easy. I watched Stranger Things season 3 again during my bowel prep day. Might not have been the best choice, as I intermittently had to pause Netflix to contribute my own liquified form of the Mind-Flayer, but it got the job done, and I cried my way thru Dustin and Suzie's hymn to childhood, again, as expected.</p>
<p>Okay, next, I woke up on September 9th. My appointment is around 2 PM. Normal day, right?</p>
<p><span>
      <span></span>
  <img alt="sf" title="sf" src="https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/6aca1/sf.jpg" srcset="https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/d2f63/sf.jpg 163w,
https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/c989d/sf.jpg 325w,
https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/6aca1/sf.jpg 650w,
https://www.charlieharrington.com/static/dfe0aae59da7dc3715e8f289c1ae8f7b/8e1fc/sf.jpg 900w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
    </span></p>
<blockquote><p lang="en" dir="ltr">A strange, apocalyptic orange-red sky looms over the Bay Area. Here's what you need to know.<br>Read more: <a href="https://t.co/JxpYSnUPG9">https://t.co/JxpYSnUPG9</a> <a href="https://t.co/ZPOj4X3jRg">pic.twitter.com/ZPOj4X3jRg</a></p>— San Francisco Chronicle (@sfchronicle) <a href="https://twitter.com/sfchronicle/status/1303799596515172352?ref_src=twsrc%5Etfw">September 9, 2020</a></blockquote> 
<p>Nope.</p>
<p>I decide to walk over to the UCSF Parnassus building in the creepy Mars firelight, imagining I'm the last man on Earth (and hoping I don't step on my reading glasses). Carly makes a plan to pick me up in a few hours in our car.</p>
<p>As expected, the procedure was painless. My only bit of further colonoscopy advice here is to ALWAYS bring a book with you, to every single medical appointment you have, because there's always going to be some sort of delay or waiting room.</p>
<p>An hour or so later, I woke up feeling the feels of that post-anesthesia giddiness. Except no one else was happy. Carly was in the room, a surprise to me. And my doctor looked quite serious.</p>
<p>In addition to two small polyps (which she removed), my colonoscopy surgeon found a tumor in my sigmoid colon. At this point, I don't know a sigmoid colon from a semi-colon, but I knew it wasn't good news. Go 2020!</p>
<p>Despite the odds (my youth, my health), I now had cancer. Well, I probably had it for awhile, but we just found out I had it.</p>
<p>My doc said I'd need to meet with <a href="https://www.ucsfhealth.org/clinics/center-for-colorectal-surgery">UCSF's colorectal surgery team</a>, and I'd also need to get CT scans ("cat scans") to see if the cancer had spread anywhere else in my body.</p>
<p>And so began one of the worst weeks of our lives.</p>
<h2>A brief family history</h2>
<p>Let's talk about the odds for a moment.</p>
<p><img src="https://www.charlieharrington.com/899a4e01fcef3d2113e4588727bc0834/odds.gif" alt="odds"></p>
<p>We've already discussed my vigorous, proto-Batman level of health. And how I'm a fresh-faced, occasionally-bearded, 34 year old with the heart of a child and the strength of a chimpanzee (no, that's a <a href="https://en.wikipedia.org/wiki/Humanzee">humanzee</a>).</p>
<p>Speaking of unfortunate genetics, it turns out that I have some family history of colon cancer. </p>
<p>Here's the scoop: my pops (that's cool talk for Dad) has had benign (non-cancerous) polyps in his previous colonoscopies. What's a poylp? It's a little growth thingy in your colon that may evolve into a tumor. Just like how a Charmander becomes a Charmeleon, polyps can grow bigger and more serious with more destructive power. Polyps are usually just snipped out during your colonoscopy and sent off for pathology (aka to see if they have cancer in them). Most do not. This is the case with my dad's polyp experience. Even though none of his have been cancerous, he still needs to go in for colonoscopies more regularly than those who don't have polyps.</p>
<p>My own tumor began as a lowly polyp, perhaps some ten years ago. We don't know exactly. But if I'd …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.charlieharrington.com/colon-cancer">https://www.charlieharrington.com/colon-cancer</a></em></p>]]>
            </description>
            <link>https://www.charlieharrington.com/colon-cancer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24853503</guid>
            <pubDate>Wed, 21 Oct 2020 23:40:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy Erlang and PSQL in Seconds with Zeet]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24852802">thread link</a>) | @theonlyjohnny
<br/>
October 21, 2020 | https://blog.zeet.co/phoenix-psql/ | <a href="https://web.archive.org/web/*/https://blog.zeet.co/phoenix-psql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.zeet.co/content/images/size/w300/2020/10/phoenix_framework.png 300w,
                            https://blog.zeet.co/content/images/size/w600/2020/10/phoenix_framework.png 600w,
                            https://blog.zeet.co/content/images/size/w1000/2020/10/phoenix_framework.png 1000w,
                            https://blog.zeet.co/content/images/size/w2000/2020/10/phoenix_framework.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.zeet.co/content/images/size/w2000/2020/10/phoenix_framework.png" alt="Deploying a Phoenix app">
            </figure>

            <section>
                <div>
                    <p>This guide will walk you through deploying a <a href="https://www.phoenixframework.org/">Phoenix</a> project (with a database!) to production on <a href="https://zeet.co/">Zeet</a>.</p><p>Finished code from this demo is available <a href="https://github.com/theonlyjohnny/zeet_hello">here</a>!</p><!--kg-card-begin: markdown-->
<blockquote>
<p>If you already have a Phoenix app, feel free to skip this section!</p>
</blockquote>
<h3 id="prerequisites">Pre-requisites</h3>
<!--kg-card-end: markdown--><p>First things first, you're gonna need to install some tooling. If you haven't already, <a href="https://elixir-lang.org/install.html">install Elixir</a> and <a href="https://nodejs.org/en/download/">NodeJS</a>.</p><p>We'll also need to grab the Hex package manager, and install the Phoenix application generator:</p><figure><pre><code>mix local.hex
mix archive.install hex phx_new 1.5.6 # version is optional
</code></pre><figcaption>Install hex and Phoenix</figcaption></figure><!--kg-card-begin: markdown--><h3 id="creatingourapp">Creating our app</h3>
<!--kg-card-end: markdown--><p>Now that we have everything installed, let's setup a Github repo for it, and psuh some code!</p><p>Make a <a href="https://github.com/new">new Github repository</a></p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-3.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-3.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-3.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-3.png 1600w, https://blog.zeet.co/content/images/2020/10/image-3.png 1618w" sizes="(min-width: 720px) 720px"></figure><p>Now all we have to do is generate our app and push it to Github!</p><figure><pre><code>mix phx.new zeet_hello # When prompted, press Y to fetch and install dependencies
cd zeet_hello
git init
git remote add origin git@github.com:username/repo.git # NOTE: change username to your github username, and repo to your newly created repo name!
git checkout -b main
git commit -m "Initial commit"
git push -u origin main</code></pre><figcaption>Generate and push your code</figcaption></figure><p>Nicely done! We've setup a demo project, now let's get it deployed</p><hr><!--kg-card-begin: markdown-->
<p>Now that we have our project generated, let's deploy it to <a href="https://zeet.co/">Zeet</a> and setup a database alongside it!</p>
<h2 id="setupaprivatedatabase">Setup a private database</h2>
<!--kg-card-end: markdown--><blockquote>Phoenix projects usually come with a database, so you can store information about your users / app. Zeet makes it super easy to deploy a PostgreSQL database alongside your Phoenix application!</blockquote><p><strong>All you have to do is click <a href="https://zeet.co/new/docker?image=postgres">this link</a>!</strong></p><p>You should see a page like this:</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-2.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-2.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-2.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-2.png 1600w, https://blog.zeet.co/content/images/size/w2400/2020/10/image-2.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Project name can be whatever you'd like, but can't be changed later!</figcaption></figure><p>Zeet will automatically generate a database user and password for you, and dedicate you 1GB of storage.</p><p>You<strong> don't need to change</strong> <strong>any</strong> of these values, so go on and hit Deploy 😎</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-4.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-4.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-4.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-4.png 1600w, https://blog.zeet.co/content/images/2020/10/image-4.png 2170w" sizes="(min-width: 720px) 720px"><figcaption>Great! We have a database now</figcaption></figure><blockquote>By default, this database will <strong>not be accessible to the public internet</strong>. The only way to your database is from another Zeet project. Very secure, much wow</blockquote><!--kg-card-begin: markdown--><h2 id="deployingtheapp">Deploying the app!</h2>
<!--kg-card-end: markdown--><p>Last but not least, let's deploy this app 😤</p><p>Let's <a href="https://zeet.co/new/github">link our new Github repo to Zeet</a>. Click New Project -&gt; Github on <a href="https://zeet.co/">zeet.co</a> and look for your new Github repository.</p><blockquote>If you don't see your repo, click Manage Repositories and make sure Zeet has access to your Github repository. We recommend checking the "All Repositories" option to make this easy in the future!</blockquote><figure><img src="https://blog.zeet.co/content/images/2020/10/image-5.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-5.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-5.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-5.png 1600w, https://blog.zeet.co/content/images/size/w2400/2020/10/image-5.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Click that beautiful "Deploy Now" button and we're off to the races! Right away, Zeet will start building and deploying our project.</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-6.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-6.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-6.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-6.png 1600w, https://blog.zeet.co/content/images/2020/10/image-6.png 2234w" sizes="(min-width: 720px) 720px"></figure><p>If you click on the Settings tab, you'll see Zeet configured almost everything for our project!</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-7.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-7.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-7.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-7.png 1600w, https://blog.zeet.co/content/images/2020/10/image-7.png 2138w" sizes="(min-width: 720px) 720px"><figcaption>So configured, so little work 🤩</figcaption></figure><!--kg-card-begin: markdown--><h2 id="connectingtothedatabase">Connecting to the database</h2>
<!--kg-card-end: markdown--><p>There's one more step before we're all done: we need to connect this new project to our database!</p><p>Scroll down to the Environment Variables section – the <code>DATABASE_URL</code> is empty 😢</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-8.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-8.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-8.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-8.png 1600w, https://blog.zeet.co/content/images/2020/10/image-8.png 2054w" sizes="(min-width: 720px) 720px"><figcaption>Database-senpai... where are you? 🥺</figcaption></figure><p>Phoenix uses Ecto as a database driver. Ecto needs a special URL in the form of <code>ecto://USER:PASS@HOST/DATABASE</code></p><p>We're going to need 4 things from our database project:</p><ol><li>Private Endpoint</li><li>Username</li><li>Password</li><li>Database name</li></ol><p>Luckily, Zeet makes this super easy! Go back to your database project, and the Private Endpoint is right there! This tells your app how to communicate with the database.</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-4.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-4.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-4.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-4.png 1600w, https://blog.zeet.co/content/images/2020/10/image-4.png 2170w" sizes="(min-width: 720px) 720px"><figcaption>On your postgres Overview tab, look for Private Endpoint</figcaption></figure><p>The Username, Password, and Database name are in the Settings tab</p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-9.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-9.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-9.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-9.png 1600w, https://blog.zeet.co/content/images/2020/10/image-9.png 2078w" sizes="(min-width: 720px) 720px"><figcaption>The values are hidden by default for security, hover to reveal</figcaption></figure><p>Great, we have everything we need. Let's put it all together into a <code>DATABASE_URL</code>. Remember, the format is <code>ecto://USER:PASS@HOST/DATABASE</code>.</p><p>For this example, my <code>DATABASE_URL</code> is <code>ecto://postgres:u2D2dp6XwQ@zeet-hello-postgres-production/postgres</code></p><p>Paste your URL into your <strong>Phoenix project's Settings tab</strong> and <strong>click Save</strong></p><figure><img src="https://blog.zeet.co/content/images/2020/10/image-11.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-11.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-11.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-11.png 1600w, https://blog.zeet.co/content/images/2020/10/image-11.png 2236w" sizes="(min-width: 720px) 720px"><figcaption>Don't worry! Since this database is private, even with the password being published I'm secure</figcaption></figure><!--kg-card-begin: markdown--><h3 id="alldone">All done!</h3>
<p>Click the Visit button in the top right corner, and see your app in action!</p>
<!--kg-card-end: markdown--><figure><img src="https://blog.zeet.co/content/images/2020/10/image-12.png" alt="" srcset="https://blog.zeet.co/content/images/size/w600/2020/10/image-12.png 600w, https://blog.zeet.co/content/images/size/w1000/2020/10/image-12.png 1000w, https://blog.zeet.co/content/images/size/w1600/2020/10/image-12.png 1600w, https://blog.zeet.co/content/images/size/w2400/2020/10/image-12.png 2400w" sizes="(min-width: 720px) 720px"></figure>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.zeet.co/phoenix-psql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24852802</guid>
            <pubDate>Wed, 21 Oct 2020 22:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking, Typing, Thinking: Software Is Not a Desk Job]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24851861">thread link</a>) | @danielfone
<br/>
October 21, 2020 | https://daniel.fone.net.nz/blog/2020/10/21/talking-typing-thinking-software-is-not-a-desk-job/ | <a href="https://web.archive.org/web/*/https://daniel.fone.net.nz/blog/2020/10/21/talking-typing-thinking-software-is-not-a-desk-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <h2>
      Talking, Typing, Thinking: Software Is Not a Desk Job
    </h2>
    <p>
      October 2020
      ·
      about 7  minutes to read
    </p>

      <summary>
        <p><strong>tl;dr</strong> Developers over-optimise for the ergonomics of typing and not enough for the ergonomics of thinking.</p>
      </summary>

    <p>I had a wonderful shower the other day.</p>

<p>It was late morning (as the best showers often are) and I was reflecting on how I spend my time during the day. As a work-from-home consultant, I constantly need to justify my billing and my time, and in this case I was justifying spending more of it in the shower.</p>

<p>Like most of us, I started my career with the impression that a productive day was spent ergonomically poised over a keyboard typing hundreds of lines of code into Microsoft Visual Basic 6.0 Professional Edition, and <em>not</em> standing in a perfectly hot stream of high pressure fresh water. However, the longer I spend as a developer, the less I’m convinced I need to be at my desk to deliver the truly astounding spreadsheet-to-web-application business value us senior engineering consultants deliver.</p>

<p>So that you too can justify spending the good part of a morning enveloped in a cocoon of cleansing warmth, let’s break this down and look at 5 physical activities of effective software development. Like all good listicles, this is ordered roughly in order of increasing time and importance.</p>

<h2 id="talking">5. Talking</h2>

<p>Some software development probably doesn’t need any talking to be effective. I understand for example that it is universally considered bad manners to talk about linux kernel development out loud. The contents of ~/bin too, we do not speak of.</p>

<p>But every commercial project I’ve worked on has needed at least some talking. When people are too busy or just too shy to talk, the lack of high-bandwidth communication can make it hard to tease out requirements and unpack poorly explained business problems.</p>

<p>But more importantly, a lack of talking makes it hard to build trust and rapport — critical&nbsp;in early stages of any new relationship. As social animals, we are particularly good at doing this verbally, and not particularly good at doing this with emails and spicy subtweets.</p>

<p>On the other hand I’ve worked on projects where talking is a prop to disguise that no-one knows what to do. Where a dozen people sit in a room and talk for an hour without saying anything and we all walk out dumber than when we walked in.</p>

<p>So for most cases: talking is critical, but in the right amount.</p>

<h2 id="listening">4. Listening</h2>

<p>Honestly I just included this for symmetry. The only thing I’ll add is that we have two ears and one mouth so either binaural hearing offers an evolutionary advantage against some selection pressure or we’re supposed to listen twice as much as we talk.</p>

<p>Take your pithy wisdom however you like it.</p>

<p><em>(quickly googles why do we have two ears)</em></p>

<h2 id="writing">3. Writing</h2>

<p>Writing code of course! But also… READMEs, comments, inline documentation, PR descriptions, code reviews, git commits; this is all part of the <em>core work</em>. It’s tempting to see this meta-writing as overhead on top of the real ‘code’ writing. But effective writing in these other places is a force multiplier for your code.</p>

<p>Much more importantly though, in my experience the best communication is written.</p>

<ul>
  <li>It’s async, meaning it can be consumed whenever convenient for each reader (i.e. after a late morning shower).</li>
  <li>It can be easily distributed and has no fidelity loss when shared (compared to talking to John about what Sarah told you Steve said in meeting that none of you were at).</li>
  <li>It creates a record, as opposed to “wait, why did we…?”</li>
  <li><a href="https://alistapart.com/article/writing-is-thinking/">Writing is thinking</a>! Writing forces you to structure your ideas coherently (at least, it seems to for some people). It reveals shortcomings or gaps in your understanding or plan.</li>
</ul>

<p>Because of this I encourage team comms to be mostly written. Jira, slack, emails, trello, blog posts, whatever. Even a hi-res photo of a wall of post-it notes has been an indispensable architectural road-map at times. However it’s published, detailed, well-thought out writing is 💯.</p>

<p>Perhaps even more important than writing though is…</p>

<h2 id="reading">2. Reading</h2>

<p>Having just extolled the virtues of writing READMEs, commit messages, PR descriptions, etc, I should obviously encourage you to read them. It’s called README IN CAPITALS for a reason, and it’s not just because it’s an acronym. Yet if I had a dollar for every time someone asked me a question that was already answered in the README I would have three dollars. 💰</p>

<p>This is because of what I succinctly call the vicious-reading-writing-cycle-feedback-loop. When people don’t update the commentary, people become trained to ignore it, so people don’t update it, etc. Truthfully, if you know someone’s reading your git commits, their quality will rapidly improve. Even if you’ve never read a coherent git commit from your colleagues before, it’s never too late to ask them to elaborate on what <code>finally fix it</code> means.</p>

<p>But like writing, the value of reading extends well beyond the code repository.</p>

<p>I recently started a project involving a completely unfamiliar field of medical technology (ps you’re <a href="https://twitter.com/danielfone/status/1318026784454045703">still my favourite</a> patient <code>01-004</code> 📊❤️). The most valuable activity I find at this stage of a project is to read.</p>

<p>We have to parse a <a href="https://en.wikipedia.org/wiki/European_Data_Format">specialised file format</a>, for which there is <a href="https://github.com/nsrr/edfize">a gem</a>. But why leave all that useful context buried inside the gem? The <a href="https://www.edfplus.info/specs/edf.html">file specification</a> is not that long, even if it takes many attempts to understand it. Reading the file format spec makes it much easier to understand why the gem needs to <a href="https://github.com/nsrr/edfize/blob/93566cdc82b160ef319c51908c1c4a19666e2625/lib/edfize/edf.rb#L243">load_digital_signals_by_epoch</a>, which in turn suggests alternative solutions to the problem you have in hand.</p>

<p>None of the <em>adjacent possible</em><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> is discoverable without the insights gained from reading these sources, so whatever you’re dealing with, go to the source and read read read…</p>

<ul>
  <li>documentation (<em>reading the very well-written <a href="https://www.postgresql.org/docs/current/index.html">postgres manual</a> or <a href="https://redis.io/documentation">redis docs</a> is the closet experience I’ve had to Neo downloading kung-fu into his brain</em>)</li>
  <li>code (<em>vastly underrated - there’s not a gem in my Gemfiles I haven’t <code>bundle open</code>d at least once</em>)</li>
  <li>log files, error messages, that tutorial on how to read flame graphs</li>
  <li>the specification, legislation, policy document, NIST guideline, the original paper in the open access journal</li>
</ul>

<p>… you get the idea, just find the authoritative document and slurp it into your brain. Even if it seems like nothing sticks, a brief encounter with the text will leave a long-lasting impression. It’s like homeopathy but real.</p>

<p>So talking/listening… writing/reading… and finally… <em>drumroll noises</em></p>

<h2 id="thinking">1. Thinking</h2>

<p>When you boil it down, <em>this</em> is the main effort for me, and yet it’s kind of the hidden one.</p>

<p>How much of my programming/coding/dev time is actually just spent <em>thinking</em> about the problems?
Modelling the domain,
thinking through the edge cases,
mentally playing with abstractions.</p>

<p>And it’s obvious when you think about what makes good developers. The people I value working with most aren’t accurate typists, they’re <em>clear thinkists</em>.</p>

<p>Yet the image persists that typing is working and working is typing and a productive day is in your chair at your desk.
So we have dual 4k monitors, mechanical keyboards, aeron chairs, touchbar, vim shortcuts, whatever optimises for us tapping away at our computers.</p>

<p>But how much attention do we pay to the <strong>ergonomics of thinking</strong>?</p>

<p>When we elevate ‘thinking’ to core work, we naturally start to optimise for it specifically. In general, we don’t need to be in front of anything to think effectively, and often I find it better not to be. My times of greatest clarity are invariably when I’m moving, often when I’m exercising. Further, I can read on my phone practically anywhere, and the best conversations are often had while strolling.</p>

<p>So while I’m glad for all the ergonomics of my workspace, increasingly I find that writing code is the brief part where I’m simply harvesting all the mental crop that I’ve sown from the talking and listening and reading and thinking.</p>

<p>To distill this into something a little more alliterative, I have sometimes described this as the 3 Ts of software development…</p>

<h2>Talking · Typing · Thinking</h2>

<p><strong>Talking</strong> and listening; the verbal discussions. Most of the time we need a small but critical amount of high bandwidth synchronous comms.</p>

<p><strong>Typing</strong> code commentary: READMEs, code reviews, PR descriptions; and all asynchronous communication: project updates, technical overviews, emails with next steps; These are all an essential part of the job and not just ancillary or busywork. Also typing actual code at some point. But I find the more time you spend typing the other stuff, the less time you need to spend (re)typing code.</p>

<p><strong>Thinking</strong>: (including, for the purposes of alliteration, reading)</p>

<p>Talking, typing, thinking: this is the work we do. And I for one want to give myself the space to do all parts of it really well.</p>

<p>Anyway, I gotta go take a shower. 🚿</p>



  </article></div>]]>
            </description>
            <link>https://daniel.fone.net.nz/blog/2020/10/21/talking-typing-thinking-software-is-not-a-desk-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24851861</guid>
            <pubDate>Wed, 21 Oct 2020 20:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stable 1.2 Gigabit/s Internet achieved in moving train in Switzerland]]>
            </title>
            <description>
<![CDATA[
Score 366 | Comments 303 (<a href="https://news.ycombinator.com/item?id=24851365">thread link</a>) | @richx
<br/>
October 21, 2020 | https://www.swisscom.ch/en/about/news/2020/10/21-mehr-bandbreite-im-zug.html | <a href="https://web.archive.org/web/*/https://www.swisscom.ch/en/about/news/2020/10/21-mehr-bandbreite-im-zug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

		
		
		

		
		

		
	
	<section>
		

<div>
	
	<div>
		<div>
			<div>







	<p>Mobile phone reception</p>


	


	<p>Uninterrupted, good quality mobile phone reception is extremely important to rail passengers. In technical terms, it’s the pièce de résistance for every network provider because the demands on bandwidth increase with data-intensive applications. Swisscom has now successfully achieved a transmission speed of over 1 Gigabit per second on a moving train under test conditions. This result sets a new benchmark for the mobile phone industry.</p>



	
	
		<div>
			
			<p><img src="https://rcp.scsstatic.ch/content/dam/swisscom/de/about/news/authors/armin-schaedeli-260x260-2x.png.scsimg.89x89.ts1543323485216.png/armin-schaedeli-260x260-2x.png" width="89" height="89" alt="Armin Schädeli" loading="lazy">
			</p>
			
			<p>
				Armin
				Schädeli,
				Deputy Head of Media Relations<br>
				21 October 2020
			</p>
		</div>
	
	


</div>

		</div>
		<div>
			<div><div>

	

	
	
	
		
		
			<div data-column-count="3">
				
					
				
					<div>
						



	
		
		
			


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<div>
			
				<p>How do most people use their phones when on a train? Besides checking their mail and reading the paper, they also stream videos, play online games or work in virtual offices. This requires a great deal of bandwidth, meaning that capacity issues can prove particularly annoying. A Swisscom team has been researching and working on continuously improving mobile coverage for rail travellers and commuters for more than ten years.</p>

<p>The invention of a special type of glass for the train windows, which lets mobile telephone signals through, has made it possible to bring mobile coverage directly onto the train without intermediate components. However, coverage along train routes remains challenging as much more data is transmitted under the same conditions with each mobile phone generation. One possible solution is a specially designed antenna corridor along railway lines.</p>

			
		</div>
		
	</div>
</div>


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<div>
			
				<p>Swisscom has now made a major breakthrough on a test route between Biberlikopf and Kerenzerberg at Lake Walen with a newly designed four-kilometre antenna corridor: Swisscom engineers achieved a connection with 1.2 Gbit/s on a moving train. Christoph Aeschlimann, Head of IT, Network &amp; Infrastructure at Swisscom says: “This concept sets a new benchmark for the mobile phone industry. Just one year ago, we had no idea whether this would be possible. We now have a solution that provides stable and reliable coverage for passengers as well as important insights for safety-relevant applications in rail transport.”</p>
<p>Another positive side effect is the lower transmitting power required due to the shorter distances between antennas and devices.</p>

			
		</div>
		
	</div>
</div>


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<p>After evaluating the results, the test corridor will be further optimised and validated with measurements in the first quarter of 2021. The long-term goal is to achieve uninterrupted mobile phone coverage along the main routes for all mobile phone users and providers in Switzerland In terms of the antenna corridor, Swisscom has developed a feasible solution that is also available to other providers.</p>
		
	</div>
</div>


	<div>

	


























	



	
	
	<div>
		


	<div>

	
	

	
	

	

	
	
	



	
	
	
		
	



	
	
		
	
	




















	












	<div data-interactive-name="" data-interactive-value="">
		<div>
			
				
			
			
				
					
						
						
							


	<div>

	


























	



	
	
	<div>
		


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<div>
			
				<p>A four-kilometre antenna corridor was constructed along the railway line at Lake Walen for the test, in conjunction with network equipment supplier Ericsson. The proximity of the antenna to devices means the transmitting power is lower and the coverage along the railway corridor is more targeted.</p>

<p>In a step-by-step procedure, numerous combinations (4G and 5G mobile phone generations, seating position, type of train car, transmitting power, train windows, mast antennas, smartphone models, etc.) were measured and analysed over more than 200 train journeys. The project has shown that the antenna corridor is possible and offers good performance. Download speeds of over 1.2 Gbit/s were possible on a moving train with a combination of 4G and 5G. The 5G response time was four times shorter than 4G – an impressive 8 milliseconds.</p>

<p>In addition to network coverage, safety-critical applications on rail transport are another consideration. The existing GSM-R railway communication network standard will be replaced in the coming years by the new Future Railway Mobile Communication System (FRMCS). Good mobile phone coverage is also therefore crucial for rail companies as well as passengers.</p>

			
		</div>
		
	</div>
</div>



	</div>
</div>



						
					
				
			
		</div>
		
	</div>

</div>



	</div>
</div>


	


	

	


	


	<div>





	
	
	
		
		
			
			
				<div>
					
						
						
							<div>






	










	

















	



	
	<div>
		
			
				
				
					

				
			
		
			
				
				
					<div>

	










	





	
	
	















	
	
	<div>
		


	


	<div>

	

	
	
	
		
			<div data-column-count="3">
				
					<div>
						



	
		
		
			


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<div>
			
				<div><p>Swisscom<br> Media Relations<br> Alte Tiefenaustrasse 6<br> 3048 Worblaufen</p><p>  Postal address:<br> Postfach, CH-3050 Bern<br> Switzerland</p></div>
			
		</div>
		
	</div>
</div>



		
	


					</div>
				
					
				
					<div>
						



	
		
		
			


	


	<div>


	
	
	
	<div>
		
			
		
		
		



	
	
		
	





		<p>Tel. +41 58 221 98 04<br> Fax +41 58 221 81 53<br> media@swisscom.com</p>
		
	</div>
</div>


	


	



		
	


					</div>
				
			</div>
		
		
	

</div>



	</div>
</div>

				
			
		
		
	</div>

</div>

						
					
				</div>
			
		
	
	

</div>



		
	


					</div>
				
					
				
			</div>
		
	

</div>

</div>

		</div>
	</div>
</div>

	</section>
</div></div>]]>
            </description>
            <link>https://www.swisscom.ch/en/about/news/2020/10/21-mehr-bandbreite-im-zug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24851365</guid>
            <pubDate>Wed, 21 Oct 2020 19:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escaping Science's Paradox]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24851141">thread link</a>) | @stuart_buck
<br/>
October 21, 2020 | https://worksinprogress.co/issue/escaping-sciences-paradox/ | <a href="https://web.archive.org/web/*/https://worksinprogress.co/issue/escaping-sciences-paradox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<p>Science has two stark problems: replication and innovation. Many scientific findings aren’t reproducible. That is to say, you can’t be sure that another study or experiment on the same question would get similar results. At the same time, the pace of scientific innovation could be slowing down.</p>
<p>Does attempting to solve one problem make the other worse? Many have argued that policies seeking to avoid reproducibility issues will create a constrictive atmosphere that inhibits innovation and discovery.</p>
<p>Indeed, top policymakers are worried about just this. Along with other prominent philanthropists and academics, I attended a White House meeting on scientific reproducibility early in 2020 (just before COVID-19 really hit). One of the key questions on a sheet of paper that the White House Office of Science and Technology Policy circulated for discussion was whether a tradeoff existed: Would efforts to improve reproducibility risk harming the creativity and innovation of federally-funded research?</p>
<p>I do <i>not</i> think there’s a contradiction between reproducibility and innovation. Contrary to common belief, we can improve <i>both</i> at once – by incentivizing failed results, and by funding “Red Teams” that would aim to refute existing dogma or would be entirely outside it.</p>
<p>First, though, let’s take a step back, and briefly review the evidence that significant areas of science could be more reproducible and innovative.</p>
<h2><b>Is science reproducible?<br>
</b></h2>
<p>Many people have written about scientific irreproducibility over the past several decades. But the issue became more prominent in the mid-2000s with the publication of what soon became one of the most downloaded research papers of all time: The 2005 piece “<a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">Why Most Published Research Findings Are False</a>,” by Stanford’s John Ioannidis. (Disclaimer: he is a long-time grantee of Arnold Ventures, where I work.)</p>
<p>To be sure, Ioannidis’s finding was mostly theoretical; it’s not as if he actually redid “most” published research (i.e., tens of millions of studies). Instead, he showed that given the way most studies are carried out, if journals have even a slight bias towards positive results (and they most definitely do), then most of the results that end up getting published would inevitably be statistical flukes or the results of p-hacking.</p>
<p>His theoretical case has been confirmed by many empirical studies in fields from drug development to psychology. Pharmaceutical companies such as <a href="https://www.nature.com/articles/483531a">Amgen</a> and <a href="https://www.nature.com/articles/nrd3439-c1">Bayer</a> have reported that they are unable to reproduce 80+% of experiments from prestigious journals. To quote Bayer’s scientists, “projects that were started in our company based on exciting published data have often resulted in disillusionment when key data could not be reproduced.”</p>
<p>Then there was the <a href="https://osf.io/ezcuj/">Reproducibility Project in Psychology</a>, which we funded, and which was carried out by our grantee Center for Open Science. That project organized well over 200 psychology labs around the world to systematically redo 100 experiments published in top psychology journals. It found that only about 40% could be reliably replicated (another 40% were inconclusive, and around 20% were decisively <i>not</i> replicated). Since <a href="http://science.sciencemag.org/content/349/6251/aac4716">those results were published</a> in 2015, the study has already been cited <a href="https://scholar.google.com/scholar?cites=10200793109432081889&amp;as_sdt=5,44&amp;sciodt=0,44&amp;hl=en">over 4,400 times</a> according to Google Scholar. Many of the most famous results in psychology have turned out to be <a href="https://www.theguardian.com/science/2018/apr/16/a-real-life-lord-of-the-flies-the-troubling-legacy-of-the-robbers-cave-experiment">unreliable</a> and possibly fraudulent (such as Zimbardo’s <a href="https://www.vox.com/2018/6/13/17449118/stanford-prison-experiment-fraud-psychology-replication">Stanford prison experiment</a>), and the best recent treatment of this issue is Stuart Ritchie’s 2020 book “Science Fictions.”</p>
<p>To be sure, the problem seems much less acute in harder sciences – e.g., physics, chemistry, cosmology – that have an established tradition of skepticism, replication, or even <a href="https://www.law.berkeley.edu/wp-content/uploads/2018/01/Paper-MacCounPerlmutter2017ch15.pdf">blinding researchers</a> to their own conclusions. The bulk of the reproducibility and publication bias problem seems to be in social science and biomedicine. In many of those fields and subfields – such as <a href="https://pubmed.ncbi.nlm.nih.gov/19160345/">clinical trials in medicine</a>, <a href="https://arxiv.org/pdf/1010.1092.pdf">high-throughput bioinformatics</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2213158213000090">neuroimaging</a>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S1364661314000540">cognitive science</a>, <a href="https://www.niss.org/publications/deming-data-and-observational-studies-process-out-control-and-needing-fixing">public health and epidemiological research</a>, <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12032">economics</a>, <a href="https://www.semanticscholar.org/paper/The-fault-in-our-stars-%3A-Measuring-and-correcting-Esarey-Wu/48403d5dce1f2972c7a91af3bb2d41635221cb3f">political science</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/23696308/">psychiatry</a>, <a href="https://eric.ed.gov/?id=EJ1019294">education</a>, <a href="https://journals.sagepub.com/doi/10.1177/0049124108318973">sociology</a>, <a href="http://cs.brown.edu/~sk/Memos/Examining-Reproducibility/">computer science</a>, and <a href="https://dennybritz.com/blog/ai-replication-incentives/">machine learning and AI</a> – the published literature features too many false positives as well as conclusions that may well be p-hacked. It’s enough to make folks at the White House, NIH, and NSF worried about the quality of federally-funded science.</p>
<h2><b>Is science innovative enough?<br>
</b></h2>
<p>At the same time, numerous observers have pointed to an entirely different problem: science has grown less innovative these days. (And even if it hasn’t, we could always benefit from faster innovation.)</p>
<p>In a recent piece, Patrick Collison, the founder of Stripe, and Michael Nielsen, a theoretical physicist, <a href="https://www.theatlantic.com/science/archive/2018/11/diminishing-returns-science/575665/">made the case</a> that the rate of scientific advancement is slowing down in recent years per dollar spent. Based on surveys of noted leaders in physics, chemistry, and medicine, they concluded, “Over the past century, we’ve vastly increased the time and money invested in science, but in scientists’ own judgement, we’re producing the most important breakthroughs at a near-constant rate. On a per-dollar or per-person basis, this suggests that science is becoming far less efficient.”</p>
<p>Collison and Nielsen are <a href="https://www.nber.org/papers/w26752.pdf">far from alone</a>. Cowen and Southwood <a href="https://www.brown.edu/academics/political-theory-project/sites/brown.edu.academics.political-theory-project/files/uploads/Innovation%20%26%20scientific%20progress.pdf">argue</a> that “there is good and also wide-ranging evidence that the rate of scientific progress has indeed slowed down.” The 2019 <a href="https://web.stanford.edu/~chadj/IdeaPF.pdf">paper</a>, “Are Good Ideas Getting Harder to Find?” argues that in semiconductors, agriculture, and medical innovations, “research effort is rising substantially while research productivity is declining sharply.”	<sup data-close="x" data-content="[1]">[1]</sup>
	<span>They attempted to replicate this analysis for “the internal combustion engine, the speed of air travel, the efficiency of solar panels, the Nordhaus (1997) ‘price of light’ evidence, and the sequencing of the human genome.” But they couldn’t do so because there was no accurate measure of the amount of R&amp;D on those issues.</span>
	 That paper concludes by predicting that “just to sustain constant growth in GDP per person, the U.S. must double the amount of research effort searching for new ideas every 13 years to offset the increased difficulty of finding new ideas.”</p>
<p>Of course, some of these assessments might be too <a href="https://guzey.com/how-life-sciences-actually-work/">pessimistic</a>. But it is depressingly common to hear the world’s most innovative scientists lament that they would never have succeeded in today’s academic or funding system because their work was too outside the box:</p>
<ul>
<li>Roger Kornberg (a Nobel-winning biochemist) <a href="http://www.washingtonpost.com/wp-dyn/content/article/2007/05/27/AR2007052700794.html">told the Washington Post in 2007</a> that his 1970s research on DNA “would never have gotten the necessary funding” if he had come along in the 2000s: “In the present climate especially, the funding decisions are ultraconservative. If the work that you propose to do isn’t virtually certain of success, then it won’t be funded.”</li>
<li>As <a href="https://www.kqed.org/forum/201310090930/cuts-in-federal-funding-hurt-scientific-research">reported</a> in 2013, “UC Berkeley molecular biologist Randy Schekman won the Nobel Prize for Medicine with two other scientists this week. But he says the kind of basic science research that led to his prize might have never gotten funded if he were applying for grants today.”</li>
<li>David Deutsch, who pioneered quantum computing, <a href="https://twitter.com/DavidDeutschOxf/status/982233180081029128">says</a> that he would never have gotten his “first research grant on quantum computers . . . under today’s criteria.”</li>
<li>Peter Higgs, the Nobel Laureate for whom the Higgs Boson is named, “<a href="https://www.theguardian.com/science/2013/dec/06/peter-higgs-boson-academic-system">believes</a> no university would employ him in today’s academic system because he would not be considered ‘productive’ enough. . . . ‘Today I wouldn’t get an academic job. It’s as simple as that. I don’t think I would be regarded as productive enough.’”</li>
</ul>
<p>When so many top scientists say that their own work would never have passed muster in the current system, we must take stock of the current system. As prominent scientists <a href="https://science.sciencemag.org/content/364/6441/613">have asked</a>, “How successful would Silicon Valley be if nearly 99% of all investments were awarded to scientists and engineers aged 36 years or older, along with a strong bias toward funding only safe, non-risky projects?” Moreover, a <a href="https://www.telegraph.co.uk/business/2018/06/07/science-holds-key-unlocking-economic-success/">common complaint</a> is that “scientists are forced to specify years in advance what they intend to do, and spend their time continually applying for very short, small grants” – hardly a system that would encourage innovation.</p>
<p>In short, we have evidence that US science funding is often fairly tame and incremental, that some of the most innovative science of the past would <a href="https://www.npr.org/2019/05/19/723326933/billion-dollar-gamble-how-a-singular-hero-helped-start-a-new-field-in-physics?fbclid=IwAR28fazRNhzzT5ijMINwzZkNqlP6fEfBlI4OLyY-eesrUyOfbZfF7-P4qUc">never have been funded</a> by today’s bureaucracy, and that scientific review panels are <a href="https://www.nature.com/articles/492034a">dominated by insiders</a>.</p>
<p>Thus, innovation in science is imperiled. If Einstein had to navigate such a system, we might <a href="https://www.wsj.com/articles/could-einstein-get-published-today-11600974323">never have heard of relativity</a>. And even if innovation weren’t slowing down <em>per se</em>, we could still do better.</p>
<h2><b>What next?</b></h2>
<p>There are lots of ideas about how to improve scientific reproducibility in how federal research is funded. After all, quality control and assurance are hardly new ideas.</p>
<p>For example, we could require that data and computer code be shared openly so that others can scrutinize and rerun it. In too many cases to list, this sort of reanalysis has led to revisions, retractions, and even the discovery of <a href="https://www.newyorker.com/science/maria-konnikova/how-a-gay-marriage-study-went-wrong">outright fraud</a>.</p>
<p>Next, we could require that experiments and other empirical studies be pre-registered, so that the analysis and results are less likely to be cherry-picked later. We already do this for clinical trials in medicine, and a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0132382">review</a> of federally-sponsored clinical trials found that the rate of positive results went down dramatically as soon as researchers were required to pre-register their studies. We could do the same for much else in science. We could even move towards more widespread use of the Registered Reports format, in which journals accept an article for publication before the final results are even available.</p>
<p>It’s less obvious how to reform government funding so as to improve scientific <i>innovation</i>. Let’s try a thought experiment:</p>
<p>Imagine that you were the President 100 years ago, instead of Woodrow Wilson. Imagine that a time-traveling genie from the future tells you that over the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worksinprogress.co/issue/escaping-sciences-paradox/">https://worksinprogress.co/issue/escaping-sciences-paradox/</a></em></p>]]>
            </description>
            <link>https://worksinprogress.co/issue/escaping-sciences-paradox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24851141</guid>
            <pubDate>Wed, 21 Oct 2020 19:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 10 year journey – from the creator of Durable Task Framework]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24850309">thread link</a>) | @rylandgold
<br/>
October 21, 2020 | https://docs.temporal.io/blog/samars-journey | <a href="https://web.archive.org/web/*/https://docs.temporal.io/blog/samars-journey">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Back in 2010 I was contemplating my next move after working on Microsoft's Project Oslo. Oslo was an effort to deliver 10X productivity to developers which inspired me to set the following criteria for my next job:</p><ol><li><strong>Iterate with Developers:</strong> I want to work in a place where we can start small, get something in the hands of developers and then iterate over the product to solve real problems.</li><li><strong>Cloud:</strong> So far I had been focussed on building platforms using bare-metal products.  But I was starting to see the kind of requirements modern applications have around scale and resiliency.  I knew Cloud had to be huge part of the experience to deliver on those requirements.</li></ol><h2>Start of Journey</h2><p><img src="https://dev-to-uploads.s3.amazonaws.com/i/jv8et2b448mjtifrh1wy.png" alt="Alt Text"></p><p>The Oslo framework led me to join the <a href="https://aws.amazon.com/swf/" target="_blank" rel="noopener noreferrer">AWS Simple Workflow (SWF)</a> team.  The team was led by Maxim Fateev, who came from a strong messaging background. Maxim was one of the most brilliant software engineers I had ever worked with, especially when it came to designing large scale distributed systems.  Little did I know that I was about to embark on a long journey which is still being written to this day.</p><p>When I joined, the team was wrapping up a second version of the service which was already seeing decent usage within AWS.  Even at the time, we could clearly see a pattern emerging. Developers were spending significant amounts of time building resiliency into applications, using low level primitives like queues, databases, retry mechanisms, durable timers, etc. Those same developers were able to produce higher quality systems with far less effort when using SWF instead of implementing resiliency themselves.  Considering how useful the service was within AWS, the next natural step was to offer SWF publicly. I was part of the core team which worked on the public version of SWF which was launched in early 2012.</p><h2>Durable Task Framework (DTFx)</h2><p><img src="https://docs.microsoft.com/en-us/azure/azure-functions/durable/media/durable-functions-concepts/monitor.png"></p><p>After shipping the public SWF service, I took an opportunity at Microsoft Azure and ended up joining the <a href="https://azure.microsoft.com/en-us/services/service-bus/" target="_blank" rel="noopener noreferrer">Azure Service Bus</a> team that owns the messaging stack for Azure.  Cloud was steadily gaining momentum and as more and more workloads started to get migrated, teams like Azure Service Bus became a focal point.  As application developers increasingly started adopting microservices architecture to keep up with scale and availability requirements for modern applications, services like Azure Service Bus became the backbone to orchestrate calls across microservices.  To keep up with the explosive growth, I worked as part of the team focused on large scale ingestion through <a href="https://azure.microsoft.com/en-us/services/event-hubs/" target="_blank" rel="noopener noreferrer">Azure EventHubs</a>.  This solved the scalability and reliability issues at a messaging layer but developers still had to work with very low level primitives whenever they need to reliably orchestrate calls across microservices.  The result was complex architectures which were expensive to build, hard to operate, and still came with reliability challenges. Reliability challenges stemming from all sorts of failure cases which needed to be handled due to the distributed nature of the application.</p><p>I could clearly see that the developers building applications on Microsoft Azure were facing eerily similar challenges to what I had seen back at AWS. The same challenges we had tried to address with SWF.  So I used one of the internal team hackathons as an opportunity to pair up with Affan Dar and take another stab at solving the problem. Affan had a very deep understanding of Azure ServiceBus so he was the perfect person to build the backend for the stateful C# experience I had in mind.  Microsoft had recently added async/await capabilities into C# and it turned out to be an amazing fit for writing stateful applications which need to orchestrate calls among microservices.  Since Java lacked an async/await like primitive, we had to rely on Promise-based async approach when building SWF.  But with C#, we were able to deliver a much cleaner and synchronous programming model using async/await.  This hackathon project resulted in Azure <a href="https://github.com/Azure/durabletask" target="_blank" rel="noopener noreferrer">Durable Task Framework</a> as an OSS client SDK which uses Azure ServiceBus as the backend to provide a stateful workflow-as-code experience for applications. I'm so glad to see Microsoft has continued investing in the experience with <a href="https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview" target="_blank" rel="noopener noreferrer">Azure Durable Functions</a> as the latest reincarnation of the original effort. An effort which started with that hackathon project.</p><h2>Transportation as Reliable as Running Water</h2><p><img src="https://d3i4yxtzktqr9n.cloudfront.net/uber-sites/f452c7aefd72a6f52b36705c8015464e.jpg"></p><p>In 2015, Uber opened a development center in Seattle and I decided to take the leap and join the engineering team.  Coincidently enough, Maxim Fateev ended up joining the Uber team in Seattle only a month after I did. At the time, Uber was running on Kafka 7 as the messaging backbone. Based on the scale they were running, they were encountering some serious operational issues. Considering Maxim and I had more than a decade worth of experience building messaging systems similar to Kafka, we decided to create the OSS project <a href="https://github.com/uber-archive/cherami-server" target="_blank" rel="noopener noreferrer">Cherami</a> to address this Uber sized problem. After a year of working on the project, we were observing a very similar pattern to the one that we tried to solve with SWF and Durable Task Framework. When engineers needed to build with raw infrastructure primitives like queues and databases they were spending 80% of their time building resiliency into the application.  This was clearly not sustainable for Uber, which was growing at an amazing pace and building a brand of "Transportation as Reliable as Running Water".  This need to increase developer productivity without compromising on reliability of the system was the motivation for Maxim and I to create the OSS project <a href="https://github.com/uber/cadence" target="_blank" rel="noopener noreferrer">Cadence</a>.  Within a very short period of time, we built a multi-tenant service hosted by our team. Cadence provided a great developer experience by enabling developers to use Golang to build and run stateful applications with very little operational overhead.  Cadence grew organically within Uber and quickly became popular among developers. It slowly but surely began to emerge as the standard way to build stateful applications when reliability cannot be compromised.</p><h2>Magic of Open Source</h2><p><img src="https://dev-to-uploads.s3.amazonaws.com/i/8llekr4lqjmaok138su4.png" alt="Alt Text"></p><p>Today, more businesses are turning to software for running mission critical parts of the system and software is becoming key part of the end-user experience. The problems faced by engineers at places like AWS, Microsoft Azure and Uber have become more and more common across the industry.  This belief was validated in early 2019. Developers from companies like Hashicorp, Box, Doordash, Checkr and dozens of other places organically discovered the Temporal technology and immediately started using it for their mission critical workloads.</p><p>We have a strong belief that an infrastructure technology of this magnitude needs to built as an Open-source project.  This led both Maxim and I to quit our jobs at Uber and launch <a href="https://temporal.io/" target="_blank" rel="noopener noreferrer">Temporal Technologies</a> in October 2019.  Over the last year we made huge advances with our developer experience and released <a href="https://github.com/temporalio/temporal/" target="_blank" rel="noopener noreferrer">Temporal</a> as an Open Source Software under <a href="https://github.com/temporalio/temporal/blob/master/LICENSE" target="_blank" rel="noopener noreferrer">MIT license</a>.  We recently launched our first production release of <a href="https://docs.temporal.io/blog/temporal-v1-announcement/" target="_blank" rel="noopener noreferrer">Temporal v1.0.0</a> which is already being used by numerous companies for critical workloads.</p><p><a href="https://temporal.io/" target="_blank" rel="noopener noreferrer">https://temporal.io</a></p><p><a href="https://github.com/temporalio/temporal" target="_blank" rel="noopener noreferrer">https://github.com/temporalio/temporal</a></p></section></div>]]>
            </description>
            <link>https://docs.temporal.io/blog/samars-journey</link>
            <guid isPermaLink="false">hacker-news-small-sites-24850309</guid>
            <pubDate>Wed, 21 Oct 2020 17:52:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[File Exfiltration via LibreOffice in BigBlueButton and JODConverter]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24849878">thread link</a>) | @hannob
<br/>
October 21, 2020 | https://blog.hboeck.de/archives/902-File-Exfiltration-via-Libreoffice-in-BigBlueButton-and-JODConverter.html | <a href="https://web.archive.org/web/*/https://blog.hboeck.de/archives/902-File-Exfiltration-via-Libreoffice-in-BigBlueButton-and-JODConverter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- s9ymdb:496 --><p><img width="300" height="303" src="https://blog.hboeck.de/uploads/bluebutton.jpg" alt="Blue Button">BigBlueButton is a free web-based video conferencing software that lately got quite popular, largely due to Covid-19. Earlier this year I did a brief check on its security which led to an <a href="https://www.golem.de/news/big-blue-button-das-grosse-blaue-sicherheitsrisiko-2010-151610.html">article on Golem.de (German)</a>. I want to share the most significant findings here.</p><p>

BigBlueButton has a feature that lets a presenter upload a presentation in a wide variety of file formats that gets then displayed in the web application. This looked like a huge attack surface. The conversion for many file formats is done with Libreoffice on the server. Looking for ways to exploit server-side Libreoffice rendering I found a <a href="https://buer.haus/2019/10/18/a-tale-of-exploitation-in-spreadsheet-file-conversions/">blog post by Bret Buerhaus</a> that discussed a number of ways of exploiting such setups.</p><p>

One of the methods described there is a feature in Opendocument Text (ODT) files that allows embedding a file from an external URL in a text section. This can be a web URL like https or a file url and include a local file.</p><p>

This directly worked in BigBlueButton. An ODT file that referenced a local file would display that local file. This allows displaying any file that the user running the BigBlueButton service could access on the server. A possible way to exploit this is to exfiltrate the configuration file that contains the API secret key, which then allows basically controlling the BigBlueButton instance. I have a <a href="https://www.youtube.com/watch?v=op2hc2Z56a8">video showing the exploit here</a>. (I will publish the exploit later.)</p><p>

I reported this to the developers of BigBlueButton in May. Unfortunately my experience with their security process was not very good. At first I did not get an answer at all. After another mail they told me they plan to sandbox the Libreoffice process either via a chroot or a docker container. However that still has not happened yet. It is planned for the upcoming version 2.3 and independent of this bug this is a good idea, as Libreoffice just creates a lot of attack surface.</p><p>

Recently I looked a bit more into this.  The functionality to include external files only happens after a manual user confirmation and if one uses Libreoffice on the command line it does not work at all by default. So in theory this exploit should not have worked, but it did.</p><p>

It turned out the reason for this was another piece of software that BigBlueButton uses called <a herf="https://github.com/sbraconnier/jodconverter">JODConverter</a>. It provides a wrapper around the conversion functionality of Libreoffice. After contacting both the Libreoffice security team and the developer of JODConverter we figured out that it enables including external URLs by default.</p><p>

I forwarded this information to the BigBlueButton developers and it finally let to a fix, they now change the default settings of JODConverter manually. The JODConverter developer considers changing the default as well, but this has not happened yet. Other software or web pages using JODConverter for serverside file conversion may thus still be vulnerable.</p><p>

The fix was included in version 2.2.27. Today I learned that the company RedTeam Pentesting <a href="https://www.redteam-pentesting.de/en/advisories/rt-sa-2020-005/-arbitrary-file-disclosure-and-server-side-request-forgery-in-bigbluebutton">has later independently found the same vulnerability</a>. They also requested a CVE: It is now filed as CVE-2020-25820.</p><p>

While this issue is fixed, the handling of security issues by BigBlueButton was not exactly stellar. It took around five months from my initial report to a fix. The <a href="https://github.com/bigbluebutton/bigbluebutton/releases/tag/v2.2.27">release notes</a> do not mention that this is an important security update (the change has the note “speed up the conversion”).</p><p>

I found a bunch of other security issues in BigBlueButton and proposed some hardening changes. This took a lot of back and forth, but all significant issues are resolved now.</p><p>

Another issue with the presentation upload was that it allowed cross site scripting, because it did not set a proper content type for downloads. This was independently discovered by another person and was fixed a while ago. (If you are interested in details about this class of vulnerabilities: I have given <a href="https://www.youtube.com/watch?v=8t8JYpt0egE">a talk about it at last year’s Security Fest</a>.)</p><p>

The session Cookies both from BigBlueButton itself and from its default web frontend Greenlight were not set with a secure flag, so the cookies could be transmitted in clear text over the network. This has also been changed now.</p><p>

By default the BigBlueButton installation script starts several services that open ports that do not need to be publicly accessible. This is now also changed. A freeswitch service run locally was installed with a default password (“ClueCon”), this is now also changed to a random password by the installation script.</p><p>

What also looks quite problematic is the use of outdated software. BigBlueButton only works on Ubuntu 16.04, which is a long term support version, so it still receives updates. But it also uses several external repositories, including one that installs NodeJS version 8 and shows a warning that this repository no longer receives security updates. There is an <a href="https://github.com/bigbluebutton/bbb-install/issues/109">open bug in the bug tracker</a>.</p><p>

If you are using BigBlueButton I strongly recommend you update to at least version 2.2.27. This should fix all the issues I found. I would wish that the BigBlueButton developers improve their security process, react more timely to external reports and more transparent when issues are fixed.</p><p>

<a href="https://commons.wikimedia.org/wiki/File:Porpita_porpita.jpg">Image Source: Wikimedia Commons / NOAA / Public Domain</a></p></div></div>]]>
            </description>
            <link>https://blog.hboeck.de/archives/902-File-Exfiltration-via-Libreoffice-in-BigBlueButton-and-JODConverter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24849878</guid>
            <pubDate>Wed, 21 Oct 2020 17:12:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To write better, develop a habit of writing]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24849485">thread link</a>) | @pavelegorkin
<br/>
October 21, 2020 | https://bookpub.club/post/to-write-better-you-need-to-develop-a-habit-of-writing--1603298302647x354487348376371200 | <a href="https://web.archive.org/web/*/https://bookpub.club/post/to-write-better-you-need-to-develop-a-habit-of-writing--1603298302647x354487348376371200">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bookpub.club/post/to-write-better-you-need-to-develop-a-habit-of-writing--1603298302647x354487348376371200</link>
            <guid isPermaLink="false">hacker-news-small-sites-24849485</guid>
            <pubDate>Wed, 21 Oct 2020 16:39:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LinkedIn will scan the browser to identify extensions]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24849282">thread link</a>) | @youeseh
<br/>
October 21, 2020 | https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-your-browser | <a href="https://web.archive.org/web/*/https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-your-browser">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <a href="https://prophitt.me/">Corey Prophitt's Website</a>
  <hr>
  <ul>
    <li><a href="mailto:corey@prophitt.me">Email</a></li>
    <li><a href="https://code.prophitt.me/corey" target="_blank" rel="noreferrer noopener">Code</a></li>
  </ul>
</header><section>
      <p>June 22, 2019</p>
      
      <hr>
      <p>A look at how LinkedIn exfiltrates browser extension data from your browser.</p>
    </section>

    <section>
      
      <hr>
      <p>How would you feel if you opened a program and the program started to check your file system to see what other programs you
      had installed? You would probably feel the software was overstepping. This is essentially what LinkedIn does when you visit their
      website. LinkedIn will scan your local browser files in an attempt to identify a number of different browser extensions you may
      have installed. The data collected by LinkedIn is then exfiltrated from the browser.</p>
      <p>
        This whole adventure started when I was browsing LinkedIn and happened to have my browser console open. While on my LinkedIn
        profile I noticed a large number of 404 errors and as a developer it piqued my interest.
        <a href="https://prophitt.me/assets/images/spying-xs.gif" target="blank" rel="nopener noreferrer">
          <img src="https://prophitt.me/assets/images/spying-xs.gif" alt="LinkedIn's website making local host web requests.">
        </a>
      </p>
      <p>What really piqued my curiosity was the fact all of these failed web requests were for <strong>chrome-extension://</strong>
      resources. After inspecting a few of the extension IDs in the resources I began to suspect LinkedIn was attempting to determine
      if I had certain extensions installed by executing local web requests to the browser itself.</p>
      <p>I spent some time toying around with my browser and LinkedIn's assets. Note, reverse engineering LinkedIn's source code is
      apparently <a href="https://www.linkedin.com/legal/user-agreement#dos" target="_blank" rel="noopener noreferrer">against their terms of service</a>. If I was
      LinkedIn I would probably not want people figuring out how I spy on them either.</p>
      <p>After poking around and doing some investigation I found an interesting object in one of LinkedIn's local storage values.</p>
    </section>

    <section>
      
      <hr>

      <p>One of LinkedIn's local storage keys is <strong>C_C_M</strong>. The value itself is a base64 encoded string (which isn't too
      abnormal). However, if you decode the string you will see a large JSON blob that seems to be encoded with unicode code points (not
      human readable).</p>
      <a href="https://prophitt.me/assets/images/unicode-resized.png" target="blank" rel="nopener noreferrer">
        <img src="https://prophitt.me/assets/images/unicode-resized.png" alt="LinkedIn's local storage printed to a browser console encoded with unicode.">
      </a>
      <p>I am not too sure how or why they encoded it that way, but it seems to me like it was in an attempt to obfuscate the data. The
      encoding is easy enough to reverse, simply parse the JSON. You can do it yourself with the following snippet:</p>
      <p><code>JSON.parse(atob(localStorage.getItem("C_C_M")));</code></p>
      <p>Doing so will display a large JavaScript object with some interesting data in it. Note, it appears the data held in this JSON
      blob is personalized to some degree. In other words, my JSON blob may be larger or smaller than yours. I am unsure which heuristic
      LinkedIn uses to determine which extensions to scan for but they must be using some. Curious what the complete JSON object looks
      like? <a href="https://prophitt.me/assets/files/linkedin-extension.json" target="_blank">Here's mine</a>.</p>
      <a href="https://prophitt.me/assets/images/localstorage.png" target="blank" rel="nopener noreferrer">
        <img src="https://prophitt.me/assets/images/localstorage.png" alt="LinkedIn's local storage printed to the console as a javascript object.">
      </a>
    </section>

    <section>
      
      <hr>
      <p>After examing the JSON file it became pretty clear what was going on. LinkedIn is using two different methods to determine if
      you have an extension installed.</p>
      <ol>
        <li>Content Changed</li>
        <li>Web Accessible Resources</li>
      </ol>
      <p>The first method is the simplest. LinkedIn simply looks for certain content on the page they know doesn't belong there. For
      instance, if they find a div with the ID <strong>email-hunter</strong>, they know you have the Email Hunter extension installed
      (and now your account is probably restricted, or at least on a blacklist).</p>
      <p>The second method is a lot more interesting to me. When building an extension you can specify web accessible resources. These
      resources are typically used via a content script to build a custom interface. However, there's a bit of a gotcha. If the content
      script can make a request for the web accessible resource, so can the underlying website. LinkedIn abuses this fact and sprays
      web requests to your local browser in attempt to find extensions.</p>
      <p>I built a simple extension to automatically parse the extension file and display extensions LinkedIn is looking for.
        <a href="https://code.prophitt.me/corey/nefarious-linkedin" target="_blank" rel="noopener noreferrer">Check it out here</a>.
      </p>
    </section>

    <section>
      
      <hr>
      <p>So, as a developer of an extension what can you do about this? I recommend not using
      <a href="https://developer.chrome.com/extensions/manifest/web_accessible_resources" target="_blank" rel="noopener noreferrer">web accessible resources</a>. Out
      of all extensions LinkedIn finds, a majority of them are due to web accessible resources.</p>
      <p>I would recommend not modifying or injecting user interface features into the underlying page. Alternatively, I would use a
      browser action and communicate with the content page through messaging passing.</p>
    </section>
  


</div>]]>
            </description>
            <link>https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-your-browser</link>
            <guid isPermaLink="false">hacker-news-small-sites-24849282</guid>
            <pubDate>Wed, 21 Oct 2020 16:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using machine learning to tune your Kubernetes HPA]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24849098">thread link</a>) | @digi59404
<br/>
October 21, 2020 | https://www.carbonrelay.com/blog/using-machine-learning-to-tune-your-hpa-for-optimal-performance/ | <a href="https://web.archive.org/web/*/https://www.carbonrelay.com/blog/using-machine-learning-to-tune-your-hpa-for-optimal-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>




<p>Kubernetes users often rely on the Horizontal Pod Autoscaler (HPA) and cluster autoscaling to scale applications. We show how using Red Sky Ops to optimize the whole application alongside the HPA improves cost and performance using the example of a web-application.</p>





<h2><strong>What is the Kubernetes Horizontal Pod Autoscaler?</strong></h2>





<p>The<a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" target="_blank" rel="noreferrer noopener"> Horizontal Pod Autoscaler</a> (HPA) in Kubernetes scales up and down the number of replicas in a deployment or a stateful set based on metrics prescribed by the user. The most common metrics are CPU and memory utilization of the target pods.&nbsp;</p>





<p>To deploy the HPA, the user sets target metrics for all replicas in a deployment as well as the minimum and maximum number of replicas. The HPA is responsible for adding or deleting replicas to keep the observed metrics lower than the target values while keeping the number of replicas within the prescribed bounds.</p>





<p>When scaling based on CPU and memory utilization, HPA uses the metrics.k8s.io API implemented by the <a href="https://github.com/kubernetes-sigs/metrics-server" target="_blank" rel="noreferrer noopener">metrics-server</a>. The HPA can also use<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/custom-metrics-api.md" target="_blank" rel="noreferrer noopener"> custom metrics</a> or external metrics (e.g. number of requests per second on the ingress) implemented by a third-party or the user.</p>





<h2><strong>HPA tuning challenges</strong></h2>





<p>Optimizing the target metrics of the HPA for all applications and their specific workloads can be frustrating. While newer versions of kubernetes support more in depth configuration of the HPA through policies<a href="#note">*</a>, many users are left with a minimal set of configuration options: namely a cpu/memory utilization target and the maximum number of replicas.</p>





<p>If the application is a web server for example, the speed at which the HPA adds replicas is critical to accommodate bursts in traffic. A simple fix would be to reduce the CPU utilization target to a small value (say 15%) so that the HPA adds replicas early on when the traffic increases. However, this increases your cloud cost because many replicas are underutilized. To limit the cost, one could use replicas with a high CPU utilization target. If the traffic increases, while the HPA is creating replicas waiting to be available, the current replicas experience CPU throttling and the HTTP request latency increases, impacting the clients experience.</p>





<p>A ML-powered experimentation engine such as <a href="https://github.com/redskyops" target="_blank" rel="noreferrer noopener">Red Sky Ops</a> can be used to design a highly available, scalable and cost-efficient application. Let’s demonstrate this using an example web application.</p>





<h2><strong>Example web application</strong></h2>





<p>In the following example, we will optimize the <a href="https://github.com/dockersamples/example-voting-app" target="_blank" rel="noreferrer noopener">Docker example voting app</a> using Red Sky Ops. This app is a simple distributed application that allows the user to vote between two options – cats or dogs.</p>





<figure><img src="https://lh6.googleusercontent.com/FbR98IC_2s4U7qpocG4wyH_iAWd8k9aAwai5OTLYvDezvic2HrNZLbqfI-9ABGgoR6RPJxESclSW5oYGyF3m-s6tfS3ByaensHUNlUIMLaIJ69-znggPRpL2WAYxHX4fkGYAlUQ" alt=""></figure>





<p>A Redis queue collects the votes. Workers consume the votes and insert them in a postgres database. Finally there is a node.js webapp that shows the results of the voting in real time. You can deploy this application in a dedicated namespace with:</p>





<pre>kustomize build github.com/redskyops/redskyops-recipes/voting-webapp/application | kubectl apply -f -</pre>





<h2><strong>Red Sky Ops experiments</strong></h2>





<p>An “experiment” is made of multiple trials whereby the Red Sky Ops server patches the whole application to find the optimal configuration. For each trial, the application is tested using a scalability test. At the end of each test, the Red Sky Ops controller measures metrics to optimize for. In this experiment, we will optimize for two metrics of opposite goals: cost of running the application (in $/month) and p95 latency (in ms). While the performance increases with resources, cost becomes problematic. On the other hand, starving an application reduces user experience. Machine learning helps finding the best tradeoff. You can find detailed instructions to run the experiment yourself <a href="https://github.com/redskyops/redskyops-recipes/tree/master/hpa" target="_blank" rel="noreferrer noopener">here</a> with Locust.</p>





<p>We are using the HPA to scale up and down the number of replicas of the front-end deployment responsible for the user experience. For simplicity, we will tune HPA using a target utilization available via the metrics server. The parameters that we are optimizing are the minimum and maximum number of replicas, target utilization used by the HPA and CPU requests for the voting-service pod. Note that every pod runs with a guaranteed QoS (limits=requests).</p>





<p>We run the experiment for 400 trials, and consider a trial as failed if the response latency is greater than one second.</p>





<h2><strong>Scalability test</strong></h2>





<p>During each trial we load test the application with increasing requests per second (RPS): 100 RPS for one minute, 500 RPS for one minute, 1000 RPS for one minute, 2000 for one minute. This allows us to test the scalability of the application and make sure that the HPA is configured correctly. The application should be able to minimize the cost for a low level of traffic (100 RPS) but still able to scale up fast enough to 2000 RPS.</p>





<h2><strong>Experiment results</strong></h2>





<p>We first set a baseline configuration with:</p>





<pre>Minimum replicas=3<br>Maximum replicas=7<br>CPU utilization target=65%<br>CPU per replica=2&nbsp;</pre>





<p>In this case the cost is $481/month to run this application for a p95 latency of 579 milliseconds.</p>





<p>Each dot represents the metric values measured at the end of each trial (<a href="#figure-1">see Figure 1</a>). The red dots are the best trials found during the experiment, i.e. there is no better configuration for one metric without increasing the value of the other metric. After some exploration of the parameter space, the algorithm converges towards optimal configurations. We find a sharp transition in latency around a cost of $330 per month, where the most satisfying performance is achieved. We find that the best application is obtained for:</p>





<pre>Minimum replicas=10<br>Maximum replicas=15<br>CPU utilization target=80%<br>CPU per replica=0.855</pre>





<p>The cost of running this application is $365/month (24% savings) while the latency is 27.8 milliseconds (95% increase in performance). The advantage of providing multiple best configurations is the ability for the user to pick based on experience. For example, if an experienced devops engineer wants a more scalable application in case of larger spikes of traffic than the ones created for the load test, the following configuration can be chosen:</p>





<pre>Minimum replicas=3<br>Maximum replicas=9<br>CPU utilization target=10%<br>CPU per replica=0.849</pre>





<p>The cost is $344/month (28% savings) while the latency is 60 milliseconds (89% increase in performance). Because the CPU utilization target per replica is lower in this case, a sudden burst in traffic triggers a scale up from the HPA early allowing for the newly added replicas to be available.</p>
<p><img loading="lazy" src="https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1024x568.png" alt="hpa blog figure 1" width="1024" height="568" srcset="https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1024x568.png 1024w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-300x166.png 300w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-768x426.png 768w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1536x852.png 1536w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-2048x1136.png 2048w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1160x644.png 1160w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-90x50.png 90w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-650x361.png 650w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-1000x555.png 1000w, https://www.carbonrelay.com/wp-content/uploads/2020/10/hpa-blog_figure1-1-50x28.png 50w" sizes="(max-width: 1024px) 100vw, 1024px"></p>















<p>Figure 1. Red Sky Ops experiment results</p>
<h2><strong>Summary</strong></h2>





<p>Using Red Sky Ops, we can deploy a web application using the HPA that efficiently scales and avoids over provisioning for spikes in traffic.</p>





<p>We decided to tune the CPU target utilization of the HPA. This is more of an infrastructure monitoring approach that is made available quite easily by the metrics server. A different approach would have been to tune the HPA based on the number of requests-per-second on the ingress. Check out this great<a href="https://medium.com/uptime-99/kubernetes-hpa-autoscaling-with-custom-and-external-metrics-da7f41ff7846" target="_blank" rel="noreferrer noopener"> blog post</a> on how to set up the external metrics server to work with the HPA.</p>





<p>Like the<a href="http://www.brendangregg.com/usemethod.html" target="_blank" rel="noreferrer noopener"> USE</a> and <a href="https://www.weave.works/blog/the-red-method-key-metrics-for-microservices-architecture/" target="_blank" rel="noreferrer noopener">RED</a> methods for monitoring your infrastructure and user experience, the Red Sky Ops experiments can be written to optimize both of your infrastructure cost and usage and/or user experience on your deployed application.</p>





<p>Finally, Red Sky Ops allows you to efficiently find the optimal configurations when the correlations are<a href="https://www.carbonrelay.com/blog/the-new-basics-of-configuration-management-in-kubernetes/"> too complicated for a human to understand</a>. For this example, we have oversimplified the application to easily interpret the results, but in production one would tune the resources of all the deployments.</p>





<p>To try it for yourself, create a free Red Sky Ops account.</p>
</div></div><div><div>





<hr>





<p id="note"><strong>*Note:</strong> For v1.18+ the HPA API will allow the scaling behavior to be configurable, allowing the user to design the scale up and scale down policies.</p>





<p><code><code>scaleDown: &nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;stabilizationWindowSeconds: 300 &nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;policies:<br>&nbsp;&nbsp;&nbsp;&nbsp;- type: Percent<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value: 100<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;periodSeconds: 15<br>&nbsp;&nbsp;scaleUp:<br>&nbsp;&nbsp;&nbsp;&nbsp;stabilizationWindowSeconds: 0<br>&nbsp;&nbsp;&nbsp;&nbsp;policies:<br>&nbsp;&nbsp;&nbsp;&nbsp;- type: Percent<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value: 100<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;periodSeconds: 15<br>&nbsp;&nbsp;&nbsp;&nbsp;- type: Pods<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value: 4<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;periodSeconds: 15<br>&nbsp;&nbsp;&nbsp;&nbsp;selectPolicy: Max</code></code></p>








<p>In order to check if your kubernetes cluster has the behavior field available run:</p>









<pre>kubectl explain --api-version=autoscaling/v2beta2 hpa.spec.metrics</pre>






</div></div></div>]]>
            </description>
            <link>https://www.carbonrelay.com/blog/using-machine-learning-to-tune-your-hpa-for-optimal-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24849098</guid>
            <pubDate>Wed, 21 Oct 2020 16:02:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LUMI to become the world's fastest supercomputer]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24848921">thread link</a>) | @clon
<br/>
October 21, 2020 | https://www.lumi-supercomputer.eu/lumi-one-of-the-worlds-mightiest-supercomputers | <a href="https://web.archive.org/web/*/https://www.lumi-supercomputer.eu/lumi-one-of-the-worlds-mightiest-supercomputers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>One of the most powerful supercomputers in the world, LUMI, will start its operations in CSC’s data center in Kajaani, Finland, next year. The peak performance of LUMI is an astonishing 552 petaflop/s. To date, the world’s fastest computer, Fugaku in Japan, reaches peak performance of 513 petaflop/s. When LUMI’s operations start next year, it will be one of the world’s fastest supercomputers.</p>
<p>LUMI is a unique European endeavor, with ten European countries and the EuroHPC Joint Undertaking (EuroHPC JU) investing in one joint system. It is set to boost research, employment, and competitiveness throughout Europe. The procurement process of LUMI is now complete, and the system supplier is Hewlett Packard Enterprise (HPE), providing an HPE Cray EX supercomputer with next generation AMD EPYC™ CPUs and AMD Instinct™ GPUs. In addition to the remarkable computing power, LUMI is also one of the world’s most advanced platforms for artificial intelligence and it will be one of the world’s best known scientific instruments throughout its lifetime.</p>
<p>– Today we mark an important step forward in the realisation of the European High-Performance Computing strategy. The pre-exascale supercomputer hosted by the LUMI consortium will be among the top 5 in the world. Together with the other EuroHPC pre-exascale and petascale supercomputers that will be deployed in 2021, the LUMI supercomputer will help Europe’s public and private users address many daunting research and innovation problems across different areas from weather and climate change through cybersecurity to drug discovery and personalised medicine. LUMI supercomputer aligns the Digital and Green Deal policies of the European Commission, using 100% renewable carbon neutral energy. Moreover, the heat generated will provide 20 percent of the district heat of the area, being one of the most efficient supercomputers in the world, says <strong>Khalil Rouhana</strong>, Deputy Director-General of the Directorate‑General for Communications Networks, Content and Technology (DG Connect) of the European Commission.</p>
<p>– Once operational in mid-2021, the LUMI supercomputer will be one of the most competitive and green supercomputers in the world! Such a leadership-class system will support European researchers, industry, and public sector, in better understanding and responding to complex challenges and transforming them into innovation opportunities in sectors like health, weather forecasting, or urban and rural planning, says the Executive Director of EuroHPC Joint Undertaking, <strong>Anders Dam Jensen</strong>.</p>
<p>– We are committed to supporting the European High Performance Computing Joint Undertaking (EuroHPC JU) to seize opportunities in next-generation supercomputing and bolster R&amp;D in science, advance innovation, and unlock economic growth. We are honored to continue collaborating with EuroHPC JU, and through our partnership with AMD, build one of the world’s fastest pre-exascale supercomputers for Europe.”, says <strong>Peter Ungaro</strong>, senior vice president, and general manager, high-performance computing (HPC) and mission critical solutions (MCS), HPE.</p>
<p>– The reliability of CSC and Finland made the European Commission and ten partner countries to invest in one pan-European high-performance computing and data management infrastructure in Finland. We have to keep up the excellent collaboration in order to maximize this investment to benefit society on a larger scale, says Permanent Secretary <strong>Anita Lehikoinen</strong> from Ministry of Education and Culture, Finland</p>
<p>LUMI is an investment of over 200 million euros, covering the whole lifecycle of the system. It will lift Europe to the forefront of high performance computing (HPC) and research. Exploiting the potential of the data economy is crucial for Europe’s competitiveness.</p>
<p>– The investment will make CSC data center one of the world’s largest players in the field of HPC. The joint procurement process with the EuroHPC Joint Undertaking and ten European countries has proceeded on schedule despite the global pandemic, thanks to the vast know-how of the LUMI consortium and the excellent collaboration. LUMI’s astonishing computing power combined with a highly modern artificial intelligence platform and data management infrastructure will help European researchers tackle unforeseen research challenges, says CSC’s Managing Director <strong>Kimmo Koski</strong>.</p>
<p>The uptake of HPC will remarkably increase the competitiveness of small and medium-sized enterprises (SMEs) in Europe remarkably. Up to one-fifth of LUMI’s resources will be available for industry and SMEs.</p>
<p>– The technology we are using is strongly based on mathematical modelling: analyses, artificial intelligence, simulations, and optimization. Therefore, powerful computing capacity and data management infrastructure are of the utmost importance for us. The LUMI infrastructure will open up entirely new possibilities for us, which we may exploit, says Anna-Maria Henell, CEO of Disior Ltd. Disior is a Finnish company developing software for analysing medical images in 3D.</p>
<p><img loading="lazy" src="https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small-300x149.jpg" alt="" width="300" height="149" srcset="https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small-300x149.jpg 300w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small-1024x507.jpg 1024w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small-768x380.jpg 768w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/HPE-Cray-EX-supercomputer_1_small.jpg 1512w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p><span>Caption: A sketch image of LUMI, an HPC Cray EX supercomputer. Copyright: Hewlett Packard Enterprise</span></p>
<p><img loading="lazy" src="https://www.lumi-supercomputer.eu/content/uploads/2020/10/lumi_havainnekuva3-300x199.png" alt="" width="300" height="199" srcset="https://www.lumi-supercomputer.eu/content/uploads/2020/10/lumi_havainnekuva3-300x200.png 300w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/lumi_havainnekuva3.png 548w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p><img loading="lazy" src="https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-300x212.jpg" alt="" width="300" height="212" srcset="https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-300x212.jpg 300w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-1024x724.jpg 1024w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-768x543.jpg 768w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small-283x200.jpg 283w, https://www.lumi-supercomputer.eu/content/uploads/2020/10/View1_small.jpg 1489w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p><span>Caption: This is how the LUMI data center will look like. Copyright: Synopsis Architects Ltd. and Geometria Architecture Ltd.</span></p>
<p><strong>Supercomputers enable the fight against pandemics and help resolve unforeseen research questions<br>
</strong>LUMI’s top-notch computing resources are needed in leading-edge research in a wide range of data- and computing-intensive fields. Examples include climate, pharmaceutical, and artificial intelligence.<br>
LUMI will also have a fast-track for urgent computing in time- and mission-critical simulations. This kind of simulation might be, for example, related to a large epidemic or pandemic disease. The current COVID-19 pandemic has largely benefitted from supercomputers: supercomputers have been used for example to simulate studies related to vaccine research and defeat the spread of the virus. With its vast computing resources, LUMI can address different research challenges even faster than before. In addition, it will enable addressing totally new types of scientific challenges combining multidisciplinary research and artificial intelligence.</p>
<p><strong>World-class environmental sustainability and energy-efficiency</strong><br>
As a carbon-neutral data center, LUMI helps the European ICT sector in becoming greener and more cost-efficient, which is a necessity for reaching EU’s ambitious climate targets and paving the way for the green transition. CSC’s data center in Kajaani is among the world’s most eco-efficient: it uses 100% renewable energy produced with hydropower. LUMI’s waste heat will be used in Kajaani’s district heating network: 20% of the area’s yearly district heating needs will be covered with LUMI’s waste heat.</p>
<p><strong>LUMI system architecture explained:</strong></p>
<ul>
<li>The LUMI system will be supplied by Hewlett Packard Enterprise (HPE), based on an HPE Cray EX supercomputer.</li>
<li>The peak performance of LUMI is an astonishing 552 petaflop/s meaning 552 *10<sup>15</sup> floating point operations per second. This figure makes LUMI one of the world’s fastest supercomputers. For comparison, the world’s fastest computer today (Fugaku in Japan) reaches 513 petaflop/s and the second fastest (Summit in the US) 200 petaflop/s (more information: <a href="http://www.top500.org/">www.top500.org</a>). If LUMI’s computing power was compared to normal laptops, it would require 1.5 million laptops together to reach the performance of LUMI. If these laptops were piled up, they would form a tower of over 23 kilometers high!</li>
<li>LUMI will also be one of the most advanced platforms in the world for artificial intelligence (AI). With LUMI, it will be possible to combine AI, especially deep learning, and traditional large scale simulations combined with massive scale data analytics in solving one research problem.</li>
<li>The number crunching capability of LUMI is accelerated by the GPU (Graphics Processing Unit) partition. It is based on the future generation AMD Instinct™ GPU.</li>
<li>LUMI will be complemented by a CPU (Central Processing Unit) partition, featuring 64-core next-generation AMD EPYC™ CPUs.</li>
<li>LUMI’s data analytics partition has 32 aggregated terabytes of memory and 64 visualization GPUs. This partition is used e.g. for visualization, heavy data analysis, meshing, and pre/post-processing.</li>
<li>LUMI’s storage system will consist of three components. First, there will be a 7-petabyte partition of ultra-fast flash storage, combined with a more traditional 80-petabyte capacity storage, both based on the Lustre parallel filesystem, as well as a data management service, based on Ceph and being 30 petabytes in volume.</li>
<li>In total, LUMI will have astounding storage of 117 petabytes and an impressive aggregated I/O bandwidth of 2 terabytes per second</li>
<li>LUMI will also have an OpenShift/Kubernetes container cloud platform for running microservices.</li>
<li>All the different compute and storage partitions are connected to the very fast Cray Slingshot interconnect of 200 Gbit/s. The global bandwidth of the LUMI-GPU partition is 160 TB/s. The global Internet traffic would fit therein, in fact, two times!</li>
<li>LUMI takes over 150m2 of space, which is about the size of a tennis court. The weight of the system is nearly 150 000 kilograms (150 metric tons).</li>
</ul>
<p><strong>More information:</strong><br>
Images, videos and contact information for media: <a href="http://www.lumi-supercomputer.eu/media">www.lumi-supercomputer.eu/media</a></p>
<p><strong>Read also</strong></p>
<p>EuroHPC JU <a href="https://eurohpc-ju.europa.eu/news/lumi-new-eurohpc-world-class-supercomputer-finland">press release</a></p>
<p>Hewlett Packard Enterprise (HPE) <a href="https://www.hpe.com/us/en/newsroom/press-release/2020/10/hewlett-packard-enterprise-wins-160m-contract-to-power-one-of-the-worlds-fastest-supercomputers-based-in-finland-to-bolster-europes-research-in-science-and-unlock-economic-growth.html">press release.</a></p>

            </div></div>]]>
            </description>
            <link>https://www.lumi-supercomputer.eu/lumi-one-of-the-worlds-mightiest-supercomputers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848921</guid>
            <pubDate>Wed, 21 Oct 2020 15:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GraphQL and REST APIs in seconds with Hypi's low-code back end as a service]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24848809">thread link</a>) | @hypi_universe
<br/>
October 21, 2020 | https://hypi.io/2020/10/20/announcing-hypis-public-beta2/ | <a href="https://web.archive.org/web/*/https://hypi.io/2020/10/20/announcing-hypis-public-beta2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="62d125cc" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<section data-id="76f2e445" data-element_type="section">
<div>
<div>
<div data-id="4036ff2a" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>


 
<div data-id="74b51eb2" data-element_type="widget" data-widget_type="theme-post-content.default">
<div>
<p>The Hypi team is incredibly proud to announce today that we’re making our second <a href="https://hypi.app/auth/register" target="_blank" rel="noreferrer noopener">public beta available today</a>.</p>
<p>This has been in the making for a few months after receiving very valuable feedback from our community. Not only have we listened to the original feedback, some members of our community have directly contributed to the improvements in this release.</p>
<div data-tilt-max="15"><div><p><img data-attachment-id="3786" data-permalink="https://hypi.io/2020/10/20/announcing-hypis-public-beta2/attachment/2/" data-orig-file="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?fit=3200%2C1600&amp;ssl=1" data-orig-size="3200,1600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2" data-image-description="" data-medium-file="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?fit=300%2C150&amp;ssl=1" data-large-file="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?fit=960%2C480&amp;ssl=1" loading="lazy" width="960" height="480" src="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=960%2C480&amp;ssl=1" srcset="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=3200&amp;ssl=1 3200w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1536%2C768&amp;ssl=1 1536w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=2048%2C1024&amp;ssl=1 2048w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1200%2C600&amp;ssl=1 1200w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=2880&amp;ssl=1 2880w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=3200&amp;ssl=1 3200w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1536%2C768&amp;ssl=1 1536w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=2048%2C1024&amp;ssl=1 2048w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=1200%2C600&amp;ssl=1 1200w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=1920&amp;ssl=1 1920w, https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?w=2880&amp;ssl=1 2880w" data-lazy-src="https://i0.wp.com/hypi.io/wp-content/uploads/2020/10/2.jpeg?resize=960%2C480&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p></div></div>
<p>Three years ago our team set out to make it easier for developers to build applications but we had no idea of the amazing journey this would take us on. In our first 18 months we built 3 different versions and threw them all away because they just weren’t quite right. We spoke to developers at conferences and meetups including WebSummit, Collision and Apache Ignite London and France. It was 18 months researching and speaking to developers 6 countries face to face and 4 more virtually all of this has culminated into what Hypi is today.</p>

<figure><img data-attachment-id="3792" data-permalink="https://hypi.io/2020/10/20/announcing-hypis-public-beta2/app-to-api/" data-orig-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/App-to-API.gif?fit=640%2C328&amp;ssl=1" data-orig-size="640,328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="App-to-API" data-image-description="" data-medium-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/App-to-API.gif?fit=300%2C154&amp;ssl=1" data-large-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/App-to-API.gif?fit=640%2C328&amp;ssl=1" loading="lazy" width="640" height="328" src="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/App-to-API.gif?resize=640%2C328&amp;ssl=1" alt="" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Several months ago we offered limited access and got feedback from the wider community. That feedback was reassuring, almost everyone felt it was a good product with great potential but were missing a few things or could be improved here and there and now we’re again announcing Hypi, a comprehensive low-code backend as a service platform.</p>
<figure><img data-attachment-id="3777" data-permalink="https://hypi.io/2020/10/20/announcing-hypis-public-beta2/screenshot-2020-10-19-at-21-57-13/" data-orig-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?fit=1824%2C1042&amp;ssl=1" data-orig-size="1824,1042" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-2020-10-19-at-21.57.13" data-image-description="" data-medium-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?fit=960%2C548&amp;ssl=1" loading="lazy" width="960" height="548" src="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=960%2C548&amp;ssl=1" alt="" srcset="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1024%2C585&amp;ssl=1 1024w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=300%2C171&amp;ssl=1 300w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=768%2C439&amp;ssl=1 768w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1536%2C877&amp;ssl=1 1536w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1200%2C686&amp;ssl=1 1200w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?w=1824&amp;ssl=1 1824w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1024%2C585&amp;ssl=1 1024w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=300%2C171&amp;ssl=1 300w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=768%2C439&amp;ssl=1 768w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1536%2C877&amp;ssl=1 1536w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=1200%2C686&amp;ssl=1 1200w, https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?w=1824&amp;ssl=1 1824w" data-lazy-src="https://i2.wp.com/hypi.io/wp-content/uploads/2020/10/Screenshot-2020-10-19-at-21.57.13.png?resize=960%2C548&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Hypi’s founding purpose is to make development simple and hair-loss free. We’ve spent a lot of time thinking about how to do that best and we summised a few things from our own experience as well as from our research and speaking to developers.</p>
<ol><li>We spend too much time repeating ourselves from project to project, sometimes even within the same project. The things that almost everyone we spoke to say they repeat a lot are:<ol><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/crud" target="_blank">CRUD APIs</a> – the bare bones of all data driven applications</li><li>Authentication – Registration and login in</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/authorisation" target="_blank">Authorisation</a> – Access control, even more than that, <strong>flexible</strong> access control. Role based access control is great but simply doesn’t fit the bill in many cases.</li><li>Caching and scaling – even today, this remains a challenge for most developers</li></ol></li><li>We spend so much time integrating and <a href="https://docs.hypi.app/references/api-gateway" target="_blank" rel="noreferrer noopener">staying in sync with external services</a>.</li><li>We still have to build what are now commonplace features into our apps every time.</li></ol>
<p>The team’s very proud to say that Hypi takes care of all of these and so much more.</p>
<p>Available today are features such as:</p>
<ol><li>Instantly generating CRUD APIs from a data model</li><li>Automatically available login and registration APIs</li><li>A simple, yet flexible authorisation API allowing you to model anything from simple role based access control to complex corporate authorisation models</li><li>Hypi is built on <a rel="noreferrer noopener" href="https://ignite.apache.org/" target="_blank">Apache Ignite</a> allowing us to automatically scale your APIs, no effort required. Taking advantage of its massively scalable in-memory technology we’re also able to achieve incredible performance, thinking nothing of it!</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/serverless-functions" target="_blank">Serverless functions</a> so you can add custom APIs and extend the built in ones.</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/user-defined-functions" target="_blank">Inline functions</a> for when Docker containers are too heavy handed</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/webhooks" target="_blank">Webhooks</a> to accept incoming, unauthenticated events from external systems</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/workflow" target="_blank">Workflows</a> for scheduling and orchestrating function executions</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/math-api" target="_blank">Math APIs</a> for performing atomic mathematical operations server side</li><li><a rel="noreferrer noopener" href="https://docs.hypi.app/references/aggregations-api" target="_blank">Aggregations API</a> for getting analytics and other insights from your data</li><li>A powerful <a rel="noreferrer noopener" href="https://docs.hypi.app/tutorials/arcql" target="_blank">query/filtering language</a> to find data</li><li>…and <a rel="noreferrer noopener" href="https://docs.hypi.app/" target="_blank">so much more</a> </li></ol>
<p>When we say it’s a comprehensive platform, we mean it. For our existing users who have been working closely with us to get to this stage we thank you! This announcement signals our push towards general availability in the coming months. </p>
<p><a href="https://hypi.app/auth/register" target="_blank" rel="noreferrer noopener">Sign up and let Hypi</a> take the stress and repetition out of back end development. Simple is best!</p>
</div>
</div>

</div>
</div>
</div>
</div>
</div>
</section>

<section data-id="5e429d25" data-element_type="section">

</section>

<section data-id="3ed2ebec" data-element_type="section">

</section>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://hypi.io/2020/10/20/announcing-hypis-public-beta2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848809</guid>
            <pubDate>Wed, 21 Oct 2020 15:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gardening Your Twitter]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24848782">thread link</a>) | @tosh
<br/>
October 21, 2020 | https://steipete.com/posts/growing-your-twitter-followers/ | <a href="https://web.archive.org/web/*/https://steipete.com/posts/growing-your-twitter-followers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="https://d33wubrfki0l68.cloudfront.net/f99dfb0a1f04e2577108899ca48dca03f49f0d67/039b8/assets/img/2020/make-twitter-work/gardening-growing.jpg"></p><p>I’ve been using Twitter for almost 12 years now. It can be challenging to navigate your timeline, so today I’m sharing some tips to keep it fun.</p><p>This is the first part of my Twitter series about Gardening Your Twitter. Don’t miss out on the second part, where you can learn how to best <a href="https://steipete.com/posts/curating-your-twitter-timeline/">curate your timeline</a> and manage who to follow and unfollow.</p><h2 id="your-online-persona">Your Online Persona</h2><p>There are many strategies for online personas, but I can only share what works well for me. I follow people to cover specific areas/topics and also for their commentary/personality. In a way, Twitter is a newsfeed where the comments are presented before the content, and you pick people for both content and comments.</p><p>I’m known for talking about iOS and bootstrapping a company, and I have a pretty sharp tongue on tech news. I used to keep politics out of my feed, but since 2016, I do sprinkle in topics that are important to me — from US politics to climate change and LGBTQIA rights.</p><p>There will always be people who complain that XY topic shouldn’t be on Twitter, but in the end, it’s <em>your choice</em> what you talk about and it’s their choice to follow you.</p><p>I’m openly gay on Twitter, but only in the last few years have I also started talking about that. Being open does allow me to add a unique perspective to some content, and it adds more complexity to my persona. I almost never share pictures or private content though; <a href="https://www.instagram.com/sportg33k/">that stuff is for Instagram</a>.</p><p>Whatever you go with, be authentic. I don’t share everything on Twitter, but what I do share is honest and is usually done with passion. Additionally, it can be interesting or funny. I do not share content for money or for favors, rather I only share things if I find them interesting.</p><h3 id="your-avatar">Your Avatar</h3><p>Pick an avatar you like and stick with it. I recommend a real face and not a sketch or something more abstract, as it’ll help folks identify you at conferences or events. Make sure you use the same picture and use it everywhere (GitHub, Gravatar, email, etc.) so that you have one universal online identity. People will scan the picture much faster than your name — changing it is usually something folks dislike, and it’ll result in a temporary loss of engagement. You can change it, but I recommend not doing that, or at least doing so only every few years.</p><p>Or, you can be really sneaky and just <a href="https://krausefx.com/blog/continuous-delivery-for-your-profile-picture">remake your picture so it changes slightly every year</a>.</p><h3 id="direct-messages">Direct Messages</h3><p>I highly recommend going into Settings and privacy &gt; Privacy and safety &gt; Direct Messages and enabling “Receive messages from anyone.” There’s a lot of great commentary from people that I received via DM since they’re not comfortable replying publicly. There are the occasional odd messages (and inappropriate offers), but if you’re a cis white male, you likely are good. Minority groups might want to reconsider this setting or at least enable the Quality filter.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/863f9afff497ec9faee70ce7485680fbc999fde1/a1446/assets/img/2020/make-twitter-work/settings.png" alt="Twitter Settings"></p><p>If in doubt, I suggest you experiment with this — the settings are easy to change if it turns out to be a bad idea.</p><h3 id="multiple-profiles">Multiple Profiles</h3><p>Quite a few of my friends have “alt” accounts for the hot takes or for talking with friends. If you work at a Big Corp, you might be required to filter what you say, and having an alt can be a solution. In general, I don’t recommend making an alt account, as it’s simply too much work to maintain multiple accounts. Just tweet out your hot takes and attract the right followers on your main account.</p><h2 id="extending-reach">Extending Reach</h2><p>The more active followers you have on Twitter, the more fun it becomes. There’s no hack or shortcut for gaining followers, but there are various things you can do that can help you steadily grow your audience.</p><h3 id="blog-posts">Blog Posts</h3><p>Twitter is a great indicator for topics that people find interesting — <a href="https://twitter.com/steipete/status/1297956386836566016">I often get my best ideas for blog posts out of Twitter conversations</a>, and I also already have half the content there. Twitter is great for inspiration and to learn, but it’s often hard to read and follow conversations. Go the extra mile and convert some of these interactions to blog posts. This will greatly extend your reach, and in turn, it’ll attract new followers who find your content interesting.</p><h3 id="conference-talks">Conference Talks</h3><p><a href="https://steipete.tv/">Speaking at conferences</a> is a great way to meet new people and extend your social circle. I often meet folks at conferences, and either we connect on Twitter or we find out that we already know each other on there! Either way — this will increase the bond and will make it more likely that people reach out to you. <strong>Conferences are work, but they are so worth it.</strong></p><p>Bonus: <a href="https://pspdfkit.com/blog/2018/binary-frameworks-swift/">Convert your conference talk to a blog post</a>. Very few people will actually watch a recording, so via recycling and reshaping content you already have, you can extend your reach again.</p><p>If you plan on starting to speak, create a website where you list what topics you can talk about and your bio. I’m using <a href="https://github.com/steipete/speaking">a simple GitHub repo</a> that has been proven extremely useful for me to track past events, attract new speaking gigs, and help conference organizers with getting the information they need to announce me.</p><h3 id="engage-with-your-audience">Engage with Your Audience</h3><p>I try to reply to almost everyone who interacts with me on Twitter. This doesn’t take much time, and sometimes I just reply with an emoji, but taking time to engage shows your audience you care, and they’re much more likely to interact with your content again if they know that it’s not a one-way street. Same goes for your feed — don’t just read, reply. This can range from helping others with questions/problems to just posting a “me too” retweet. Sometimes I get content in my feed via a retweet, and by interacting with that, I get a new follower.</p><h3 id="tracking-statistics">Tracking Statistics</h3><p>Be consistent. You won’t grow an audience overnight. Make Twitter a daily thing. Share content. Be present — and you’ll grow your audience every day.</p><p><a href="https://analytics.twitter.com/">Twitter Analytics</a> is great to understand which tweets work. To track long-term performance, I’m using <a href="http://birdbrainapp.com/">Birdbrain</a>. It’s one of the oldest apps on my phone, so I have data since 2014. Interestingly, my follower count has been growing pretty much linearly:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/b753fb6d7ed16ff2e572edcc90d8143bf73653eb/38f85/assets/img/2020/make-twitter-work/follower.png" alt="Birdbrain Follower Count of @steipete" width="50%"></p><h2 id="tweets-that-work">Tweets that Work</h2><p>I do share a lot of news articles. I often just quote something interesting from the news if it doesn’t need strong commentary, but the inclusion of a pull quote helps show that it’s worth reading.</p><p>The tweets that are the most engaging, however, usually are original content, particularly in context with your audience and topics of interest. Here are some of my top performing tweets from the last few months, with about 80K–450K impressions each. Sometimes it’s the <a href="https://twitter.com/steipete/status/1310331623729229827">ridiculous tweets that explode</a>, and sometimes you <a href="https://twitter.com/steipete/status/1306884214252613632?s=20">don’t need words</a>. It also can be news commentary if the comment <a href="https://twitter.com/steipete/status/1288151223028322304">really nails it</a> or just <a href="https://twitter.com/steipete/status/1281547449660825601">really fits</a>.</p><h3 id="using-threads">Using Threads</h3><p>Lately I’ve been using more and more threads to connect tweets over time — this has been proven to be really great, as it immediately gives people context, they can read more, and the official Twitter client also usually shows 2–3 tweets in a thread, giving you more “space” in the timeline. Here’s an example:</p><div><blockquote><div lang="en" dir="ltr"><p>Been clicking around for a minute with Apple's new Fruta SwiftUI sample. </p><p>Things jump around wildly, fav' doesn't work, and it crashes once you open a second window. I understand it's b1, but looking at how SwiftUI went last year I doubt this will all be fixed. <a href="https://t.co/zGRRYswRde">pic.twitter.com/zGRRYswRde</a></p></div>— Peter Steinberger (@steipete) <a href="https://twitter.com/steipete/status/1277623561604214784?ref_src=twsrc%5Etfw">June 29, 2020</a></blockquote></div><h2 id="curating-your-timeline">Curating Your Timeline</h2><p>Who you follow defines your Twitter experience. Learn how you can curate your Twitter timeline to keep it fun and interesting by reading <a href="https://steipete.com/posts/curating-your-twitter-timeline/">the second part of this series</a>.</p><h2 id="addendum-building-personal-brands-for-introverts">Addendum: Building Personal Brands for Introverts</h2><p>I gave a talk at UIKonf in Berlin in 2018 about Building Personal Brands for Introverts. This talk is still highly relevant and goes even deeper into defining your online identity. Check it out if you want to know more.</p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/0c6izSzP-KQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div>]]>
            </description>
            <link>https://steipete.com/posts/growing-your-twitter-followers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848782</guid>
            <pubDate>Wed, 21 Oct 2020 15:28:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Kubernetes native SaaS applications by deploying in-cluster data planes]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24848618">thread link</a>) | @htroisi
<br/>
October 21, 2020 | https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/ | <a href="https://web.archive.org/web/*/https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>At Pixie, we are working on a Kubernetes native monitoring system which stores and processes the resulting data entirely within a user’s cluster. This is the first in a series of posts discussing techniques and best practices for effectively building Kubernetes native applications. In this post, we explore the trade-offs between using an air-gapped deployment that lives completely within a cluster and a system which splits the control and data planes between the cloud and cluster, respectively.  </p><p>One benefit of building for the Kubernetes platform is that it simplifies the process of deploying applications to a user’s environment, often requiring only a few simple steps such as applying a set of YAMLs or installing a Helm Chart. Within minutes, users can easily have a running version of the application on their cluster. However, now that these applications are running entirely on prem, it becomes difficult for the developer to manage. In many cases, rolling out major updates or bug fixes relies on having the user manually update their deployment. This is unreliable for the developer and burdensome for the user.</p><div><figure><img src="https://blog.pixielabs.ai/static/e4ba6d3f5793c83a25a64e4fba9e2981/connected-on-prem.svg"><figcaption>Diagram of a connected on-prem architecture.</figcaption></figure></div><p>To address this problem, we propose a connected on-prem architecture which delegates the responsibility of managing the data and control planes of the application to the deployment running in the cluster and a developer-managed cloud environment, respectively. More concretely, the application deployed in the user’s cluster is solely responsible for collecting data and making that data accessible. Once the foundation of this data layer is established, the logic remains mostly stable and is infrequently updated. Meanwhile, a cloud-hosted system manages the core functionality and orchestration of the application. As the cloud is managed by the developer themselves, they are freely able to perform updates without any dependency on the users. This allows the developer to iterate quickly on the functionality of their system, all while maintaining data locality on prem.</p><p>This split-responsibility architecture is common in many hardware products, since external factors may make it challenging to deploy updates to software running on physical devices. For instance, despite these physical limitations, <a href="https://www.ui.com/" target="_blank" rel="noopener noreferrer">Ubiqiti</a>’s UI is able to offer a rich feature-set by delegating functionality to their cloud and keeping their physical routers within the data plane. Similarly, <a href="https://webrtc.org/" target="_blank" rel="noopener noreferrer">WebRTC</a> is a standard built into most modern browsers for handling voice and video data. Although browser updates are infrequent, having the separated data and control layers allows developers to freely build a diverse set of applications on top of WebRTC. This architecture is still relatively uncommon in enterprise software, but has been adopted by popular products such as <a href="https://harness.io/wp-content/uploads/2018/03/arch_2.png" target="_blank" rel="noopener noreferrer">Harness</a>, <a href="https://streamsets.com/" target="_blank" rel="noopener noreferrer">Streamsets</a>, and <a href="https://cloud.google.com/anthos" target="_blank" rel="noopener noreferrer">Anthos</a>.</p><p>However, designing a connected on-prem architecture is easier said than done. When building such a system, one challenge you may encounter is how to query data from an application running on the user’s cluster via a UI hosted in the cloud. We explore two approaches for doing so:</p><ol><li>Making requests directly to the application in the cluster</li><li>Proxying requests through the cloud</li></ol><p>For brevity, we will refer to the application running on the user’s cluster as a satellite.</p><h2>Approach 1: Making Requests Directly to the Application in the Cluster</h2><p>The simplest approach for executing the query on a satellite is to have the UI make the request directly to the satellite itself. To do this, the UI must be able to get the (1) status and (2) address of the satellite from the cloud, so that it knows whether the satellite is available for querying and where it should make requests to. </p><div><figure><img src="https://blog.pixielabs.ai/static/eb62b05f17165493ca6c988177555267/non-passthrough.svg"><figcaption>Diagram of Non-Passthrough Mode where the UI makes requests directly to the satellite agent itself.</figcaption></figure></div><h3>Step 1: Heartbeating</h3><p>A common technique to track the status of a program is to establish a heartbeat sequence between the program (the satellite) and the monitoring system (the cloud). This is typically done by having the satellite first send a registration message to the cloud. During registration, the satellite either provides an identifier or is assigned an identifier via the cloud, which is used to identify the satellite in subsequent heartbeat messages.</p><p>Following registration, the satellite begins sending periodic heartbeats to the cloud to indicate it is alive and healthy. Additional information can be sent in these heartbeats. In our case, we also attach the satellite’s IP address. Alternatively, the IP address could have been sent during registration, if it is not subject to change. The cloud records the satellite’s status and address so that it can be queried by the UI.</p><p>Now, when the UI wants to make a request to a satellite, it first queries the cloud for the address, then directly makes the request to that address. </p><p>Great! That wasn’t too bad. In many cases, many cloud/distributed satellite architectures already communicate via heartbeats to track satellite state, so sending an additional address is no problem. However... If your UI is running on a browser and your satellite is responding over HTTPS (likely with self-signed certs), you are not done yet...</p><div><figure><img src="https://blog.pixielabs.ai/static/f178e72484d5e1de0dcc20d539cd25d6/cert-authority-invalid-1.png"><figcaption></figcaption></figure></div><h3>Step 2: Assigning Satellites a Domain Name</h3><p>The browser is blocking our requests because of the satellite’s SSL certs! A user could go ahead and navigate directly to the satellite’s address, where the browser prompts the user with whether or not they want to bypass the invalid cert.</p><div><figure><img src="https://blog.pixielabs.ai/static/2473c1e3bd36f293ccf4938cd7d1b4f4/cert-authority-invalid-2.png"><figcaption></figcaption></figure></div><p>However, this would need to be done per satellite and is disruptive to the user’s overall experience. It is possible to generate SSL certs for IP addresses, but this is uncommon and isn’t available with most free Certificate Authorities. This approach is also complicated if the satellite’s IP address is subject to change. </p><div><figure><img src="https://blog.pixielabs.ai/static/16755003b378767879ee5d066ff07608/SSL-cert-flow.svg"><figcaption>Diagram of SSL certification flow for Non-Passthrough Mode.</figcaption></figure></div><p>To solve this problem, we used the following solution:</p><ol><li>Pre-generate SSL certs under a subdomain that you control, for instance: <code>&lt;uuid&gt;.satellites.yourdomain.com</code>. This step is easy to do with any free Certificate Authority <em>and can be safely done if the subdomain has a well-known DNS address</em>. You should make sure to generate more SSL certs than the number of expected satellites. </li><li>When an satellite registers with the cloud, it should be assigned an unused SSL cert and associated subdomain. The SSL cert should be securely sent to the satellite and the satellite’s proxy should be updated to use the new cert.</li><li>When the cloud receives the satellite’s IP address from its heartbeats, it updates the DNS record for the satellite’s subdomain to point to the IP address. </li><li>When executing queries, the UI can now safely make requests to the satellite’s assigned subdomain rather than directly to its IP address, all with valid certs!</li></ol><p>In the end, making requests directly to the satellites turned out to be more complicated (and hacky) than we’d originally thought. The solution also doesn’t scale well, since the SSL certs need to be pre-generated. Without having a fixed number of satellites, or an upperbound on the number of satellites, it isn’t long before all the certs have been assigned and someone needs to step in and manually generate more. It is possible to generate the certs and their DNS records on the fly, but we’ve found these operations can take too long to propagate to all networks. <em>It is also important to note that this approach may violate the terms of service for automated SSL generation and is susceptible to usual security risks of wildcard certificates.</em></p><p>When a satellite is behind a firewall, it will only be queryable by users within the network. This further ensures that no sensitive data leaves the network.</p><h2>Approach 2: Proxying Queries through the Server</h2><div><figure><img src="https://blog.pixielabs.ai/static/2aea205714b53dd0286e660bec0c9370/passthrough-general.svg"><figcaption>Diagram of Passthrough Mode where UI requests are proxied through the cloud.</figcaption></figure></div><p>As seen in the previous approach, it is easiest to have the UI make requests to the cloud to avoid any certificate errors. However, we still want the actual query execution to be handled by the satellites themselves. To solve this, we architected another approach which follows these general steps:</p><ol><li>User initiates query via the UI.</li><li>The cloud forwards the query to the appropriate satellite.</li><li>Satellite send its responses back to the cloud.</li><li>Cloud forwards responses back to the UI.</li></ol><p>The cloud must be able to handle multiple queries to many different satellites at once. A satellite will stream batches of data in response, which the server needs to send to the correct requestor. With so many messages flying back and forth, all of which need to be contained within their own request/reply channels, we thought this would be the perfect job for a message bus. </p><p>The next question was: which message bus should we use? </p><h3>Choosing a Message Bus</h3><p>We built up a list of criteria that we wanted our message bus to fulfill: </p><ul><li>It should receive and send messages quickly, especially since there is a user waiting at the receiving end.</li><li>It should be able to handle relatively large messages. An satellite’s query response can be batched into many smaller messages, but the size of a single datapoint can still be non-trivial.</li><li>Similarly, since an satellite’s response may be batched into many messages, the message bus should be able to handle a large influx of messages at any given time.</li><li>It should be easy to start new channels at any time. We may want to create a new channel per request or per satellite, all of which we have no fixed number.</li></ul><p>We briefly considered Google Pub/Sub, which had strict quota requirements (only 10,000 topics per Google project), and other projects such as Apache Pulsar. However, we primarily considered two messaging systems: Apache Kafka and NATS. General comparisons between Kafka and NATS have been discussed at length in other blogs. In this blog post, we aim to compare these two systems based on our requirements above.</p><p>We relied heavily on benchmarks that <a href="https://bravenewgeek.com/category/benchmarking/" target="_blank" rel="noopener noreferrer">others have performed</a> to judge latency based on message size and message volume. These results lean in …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/">https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/</a></em></p>]]>
            </description>
            <link>https://blog.pixielabs.ai/blog/hybrid-architecture/hybrid-architecture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848618</guid>
            <pubDate>Wed, 21 Oct 2020 15:14:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fear and Loathing in YAML]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24848511">thread link</a>) | @mooreds
<br/>
October 21, 2020 | https://chrisshort.net/fear-and-loathing-in-yaml/ | <a href="https://web.archive.org/web/*/https://chrisshort.net/fear-and-loathing-in-yaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div><div><article role="main"><blockquote><p>This post was originally written as the introduction to <a href="https://devopsish.com/188/">DevOps’ish 188</a>, has been modified based on feedback, and deemed worthy to share as its own blog post.</p><p>Photo by <a href="https://twitter.com/wocintechchat">Christina Morillo</a> from <a href="https://www.pexels.com/photo/adult-computer-eyewear-female-1181325/">Pexels</a></p></blockquote><p><a href="https://twitter.com/brunoborges/status/1315230767207784450">We kinda went down a rabbit hole</a> the other day when I suggested folks check out <a href="https://dev.to/vikcodes/yq-a-command-line-tool-that-will-help-you-handle-your-yaml-resources-better-8j9"><em>yq</em></a>, “The aim of the project is to be the jq or sed of yaml files.” First, there’s nothing wrong with this project. I like it, I find the tool useful, and that’s that. But the great debate started over our lord and savior, <a href="https://yaml.org/">YAML</a>. Yeah, I know, XML vs. JSON vs. YAML vs. TOML vs. the next thing is a tired and old debate.</p><p>Let me level set here. I routinely joke about how I’m a “Calendar Driven YAML Engineer” and have been for years on <a href="https://openshift.tv/">openshift.tv</a>. But I’m not too fond of YAML. Let me tell you a story…</p><p>In 2012, I worked at McClatchy Interactive (before the really dark times) and enjoyed the systems and security work I was doing. We had our machine creation down to a finite science. Bare metal spun up, you punched the MAC address into a database file, and off the machine went to get all the needed packaging and code to run as its defined purpose in our infrastructure.</p><p><a href="https://en.wikipedia.org/wiki/CFEngine">CFEngine</a> provisioned the machine accordingly based on purpose and positioned it in the network ready for code deployment. DevOps was something the company was embracing at the time. So instead of using the existing CFEngine infrastructure, the DevOps tandem at the time was using <a href="https://en.wikipedia.org/wiki/Puppet_(company)">Puppet</a> for code deploys. This system worked fine until it didn’t. There were clear lines between infrastructure (typical IT in the datacenter) and software deployment and configuration (developers). In our case, DevOps represented the development team more so than the Operations team. Sound familiar?</p><p>But, as you can imagine, even with all the automation in place, it was still a throw over the wall kind of scenario. When Puppet needed system packages installed because of modifications to the codebase (requiring a newer version of Perl, for example) or new services coming online using different OS packages, Puppet now had to do the task CFEngine was doing; systems management. The idea was to build an overarching WebOps team that was cross-functional, spirited, and deeply technical. The first edict laid down to the team by the DevOps lead was, “read the <a href="https://yaml.org/spec/1.2/spec.html">YAML spec</a>.” We were all jumping into the Puppet pool to help integrate our processes and procedures better.</p><p>“Ugh…” I thought to myself. “I have to read this horribly written spec.” It was not an RFC, which I am fond of reading, but something about the YAML spec made me sad and frustrated. Syntax <em>really</em> mattered. Whitespace <em>really</em> mattered. My experiences have taught me that rote memorization and getting humans to see the absence of something were incredibly difficult tasks. These are things that most hackers take advantage of when infiltrating systems. Humans aren’t as good as computers at finding the absence of something or memorizing things. I was not too fond of this non-markup language for these reasons.</p><p>It irked me that the YAML creators laid out goal #1 as “YAML is easily readable by humans.” It is human-readable because you see the human-readable words in the scalars and structures, but there was something off-putting about YAML. It was a markup language claiming not to be a markup language. I held the firm belief that markup languages are supposed to make things simpler for humans, not harder (XML is the antithesis of markup languages, in my opinion).</p><p>Here I was, relatively fresh to the DevOps game, learning some core developer concepts to understand a markup language, the crux of which was two Achilles heels. I also didn’t like how big, bulky, and cumbersome Puppet was to work with. But, here I was thrust headfirst into this world. Might as well make the best of it. I’ve since embraced YAML, but it doesn’t mean I’m writing my notes in YAML format.</p><div><div id="sib-form-container"><div id="error-message"><div><svg viewBox="0 0 512 512"><path d="M256 40c118.621.0 216 96.075 216 216 0 119.291-96.61 216-216 216-119.244.0-216-96.562-216-216 0-119.203 96.602-216 216-216m0-32C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm-11.49 120h22.979c6.823.0 12.274 5.682 11.99 12.5l-7 168c-.268 6.428-5.556 11.5-11.99 11.5h-8.979c-6.433.0-11.722-5.073-11.99-11.5l-7-168c-.283-6.818 5.167-12.5 11.99-12.5zM256 340c-15.464.0-28 12.536-28 28s12.536 28 28 28 28-12.536 28-28-12.536-28-28-28z"></path></svg><p><span>Your subscription could not be saved. Please try again.</span></p></div></div><div id="success-message"><div><svg viewBox="0 0 512 512"><path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 464c-118.664.0-216-96.055-216-216 0-118.663 96.055-216 216-216 118.664.0 216 96.055 216 216 0 118.663-96.055 216-216 216zm141.63-274.961L217.15 376.071c-4.705 4.667-12.303 4.637-16.97-.068l-85.878-86.572c-4.667-4.705-4.637-12.303.068-16.97l8.52-8.451c4.705-4.667 12.303-4.637 16.97.068l68.976 69.533 163.441-162.13c4.705-4.667 12.303-4.637 16.97.068l8.451 8.52c4.668 4.705 4.637 12.303-.068 16.97z"></path></svg><p><span>Your subscription has been successful.</span></p></div></div></div></div><p>Close to ten years later, I see YAML in the same somewhat offputting light. It’s not friendly to new people in the same sense <a href="https://git-scm.com/">git</a> isn’t. <a href="https://www.kubernetes.dev/">Kubernetes</a> has almost abused YAML to the point that it has become a punchline. And we’ve stuck ourselves with it for a long time to come too. If Kubernetes is the platform of the future, that means we’ll be using a spec written in 2009 well into the 2030s (and likely beyond).</p><p>I hope that a drop in replacement is possible. The fact that we need tools like <a href="https://github.com/mikefarah/yq/">yq</a> does show that there is some work to be done when it comes to wrangling the YAML beast at scale. In 2009, when the latest version of the YAML spec was written, no one thought of applying pod security policies to massive Kubernetes deployments spread out across data centers the world over. Something better will come along and I hope adopting it isn’t as painful as adopting YAML is.</p><p>Remember, comparing things relatively to like something (YAML vs. XML or YAML vs. JSON) completely throws out the beginner’s journey. Start from the newb and go forward from there. YAML doesn’t. Git doesn’t. Incrementally, YAML is better than XML but, it sucks compared to something like HTML or Markdown (which I can teach to execs and children alike). Yes, balancing machine and human readability is hard. The compromises suck, but, at some point, there’s enough compute to run a process to take in something 100% human-readable and make it 100% machine-readable. In the same sense that compute has become so readily available that we gzip and encrypt almost all HTTP traffic today, I hope we can do the same with systems configuration languages. Move the complexity from the human to code. Computers are better at remembering things and syntax-semantics than humans could ever hope to be.</p><p>There’s always a happy medium between human and machine readability. However, I’d much rather see a human first, <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">80-20</a> approach here where entry-level skills can solve 80% of the markup language’s use cases. That’s the true nirvana, in my opinion. There will always be complexity and a need to understand the tool you’re using. But, YAML gives us an example that there can and should be better things.</p><hr><h4>See also</h4><ul><li><a href="https://chrisshort.net/2019-learnings-2020-expectations/">2019 Learnings, 2020 Expectations</a></li><li><a href="https://chrisshort.net/docker-inc-is-dead/">Docker, Inc is Dead</a></li><li><a href="https://chrisshort.net/live-streaming-on-openshift.tv-and-some-lessons-learned/">Live streaming on openshift.tv and some lessons learned</a></li></ul></article></div></div></div></div>]]>
            </description>
            <link>https://chrisshort.net/fear-and-loathing-in-yaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848511</guid>
            <pubDate>Wed, 21 Oct 2020 15:01:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generative Figures]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24848421">thread link</a>) | @parisianka
<br/>
October 21, 2020 | https://polyfig.app/index.html | <a href="https://web.archive.org/web/*/https://polyfig.app/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p>Each character here is unique! The body shape, colour palette, texture, and paint effect is generated fresh each time. Check out the animation to see how the figures are moulded by merging and smoothing simple polygons <span>👉</span> <span>☝️</span></p><p>Follow me on Twitter <a href="https://twitter.com/georgedoescode" target="_blank">@georgedoescode</a></p><p><strong>Note:</strong> I have no official connection to Studio Arhoj. They have been extremely cool and allowed me to publish this project. Please do not use the images generated for any commercial / physical production purpose.</p></div></header></div></div>]]>
            </description>
            <link>https://polyfig.app/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848421</guid>
            <pubDate>Wed, 21 Oct 2020 14:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attempts to make Python fast]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 145 (<a href="https://news.ycombinator.com/item?id=24848318">thread link</a>) | @Queue29
<br/>
October 21, 2020 | https://sethops1.net/post/attempts-to-make-python-fast/ | <a href="https://web.archive.org/web/*/https://sethops1.net/post/attempts-to-make-python-fast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody" id="content">
        <p>Posted on Hacker News there was an <a href="https://github.com/markshannon/faster-cpython/blob/master/plan.md">Implementation Plan</a>
for making CPython (the official Python implementation) faster. The author claims a 5x speedup
is possible for the low cost of <a href="https://github.com/markshannon/faster-cpython/blob/master/funding.md">$2 million</a> USD.</p>
<p>The four step plan includes</p>
<ul>
<li>creating an adaptive interpreter</li>
<li>improvements to internal types</li>
<li>creating a JIT compiler</li>
<li>extending the JIT compiler</li>
</ul>
<p>We have witnessed other attempts at making Python fast, each achieving their own degree
of success in terms of performance and compatibility. For posterity I started keeping a
list of them here, in no particular order.</p>
<p>(update: added more projects from HN comments - ones that make at least some claim about
performance, thanks!)</p>
<h3 id="pyston">Pyston</h3>
<blockquote>
<p><em>Pyston is a performance-oriented Python implementation built using LLVM and modern JIT techniques.</em></p>
</blockquote>
<ul>
<li><a href="https://github.com/pyston/pyston">https://github.com/pyston/pyston</a></li>
</ul>
<h3 id="unladen-swallow">Unladen Swallow</h3>
<blockquote>
<p><em>An optimization branch of CPython, intended to be fully compatible and significantly faster.</em></p>
</blockquote>
<ul>
<li><a href="https://code.google.com/archive/p/unladen-swallow/">https://code.google.com/archive/p/unladen-swallow/</a></li>
</ul>
<h3 id="stackless-python">Stackless Python</h3>
<blockquote>
<p><em>Stackless Python is an enhanced version of the Python programming language. It allows programmers to reap the benefits of thread-based programming without the performance and complexity problems associated with conventional threads.</em></p>
</blockquote>
<ul>
<li><a href="https://github.com/stackless-dev/stackless">https://github.com/stackless-dev/stackless</a></li>
</ul>
<h3 id="pypy">PyPy</h3>
<blockquote>
<p><em>A fast, compliant alternative implementation of Python.</em></p>
</blockquote>
<ul>
<li><a href="https://www.pypy.org/">https://www.pypy.org/</a></li>
</ul>
<h3 id="jython">Jython</h3>
<blockquote>
<p><em>Jython is approximately as fast as CPython–sometimes faster, sometimes slower. Because most JVMs–certainly the fastest ones–do long running, hot code will run faster over time.</em></p>
</blockquote>
<ul>
<li><a href="https://www.jython.org/">https://www.jython.org/</a></li>
</ul>
<h3 id="hotpy">HotPy</h3>
<blockquote>
<p><em>The HotPy virtual machine is a high-performance virtual machine for Python.</em></p>
</blockquote>
<ul>
<li><a href="https://code.google.com/archive/p/hotpy/">https://code.google.com/archive/p/hotpy/</a></li>
</ul>
<h3 id="iron-python">Iron Python</h3>
<blockquote>
<p><em>Performance is comparable to CPython - much faster for some things … but slower for other things.</em></p>
</blockquote>
<ul>
<li><a href="https://wiki.python.org/moin/IronPython">https://wiki.python.org/moin/IronPython</a></li>
</ul>
<h3 id="psyco">Psyco</h3>
<blockquote>
<p><em>Psyco is a Python extension module which can greatly speed up the execution of any Python code.</em></p>
</blockquote>
<ul>
<li><a href="http://psyco.sourceforge.net/">http://psyco.sourceforge.net/</a></li>
</ul>
<h3 id="2c-python">2c-python</h3>
<blockquote>
<p><em>Using the generated binary code gives a speed boost from 2 to 4.5 times.</em></p>
</blockquote>
<ul>
<li><a href="https://github.com/DarrenRainey/2c-python">https://github.com/DarrenRainey/2c-python</a></li>
</ul>
<h3 id="cython">Cython</h3>
<blockquote>
<p><em>Easily tune readable Python code into plain C performance by adding static type declarations.</em></p>
</blockquote>
<ul>
<li><a href="https://cython.org/">https://cython.org/</a></li>
</ul>
<h3 id="nuitka">Nuitka</h3>
<blockquote>
<p><em>Nuitka is more than 2 times faster than CPython …</em></p>
</blockquote>
<ul>
<li><a href="http://nuitka.net/pages/overview.html">http://nuitka.net/pages/overview.html</a></li>
</ul>
<h3 id="pyc">Pyc</h3>
<blockquote>
<p><em>Pyc is a python compiler intended for high performance computing and programming-in-the-large</em></p>
</blockquote>
<ul>
<li><a href="https://sourceforge.net/projects/pyc/">https://sourceforge.net/projects/pyc/</a></li>
</ul>
<h3 id="shedskin">Shedskin</h3>
<blockquote>
<p><em>For a set of 75 non-trivial programs …, measurements show a typical speedup of 2-200 times over CPython.</em></p>
</blockquote>
<ul>
<li><a href="https://code.google.com/archive/p/shedskin/">https://code.google.com/archive/p/shedskin/</a></li>
</ul>
<h3 id="numba">Numba</h3>
<blockquote>
<p><em>Numba makes Python code fast</em></p>
</blockquote>
<ul>
<li><a href="http://numba.pydata.org/">http://numba.pydata.org/</a></li>
</ul>
<h3 id="parakeet">Parakeet</h3>
<blockquote>
<p><em>Parakeet was a runtime accelerator for an array-oriented subset of Python.</em></p>
</blockquote>
<ul>
<li><a href="https://pypi.org/project/parakeet/">https://pypi.org/project/parakeet/</a></li>
</ul>
<h3 id="cannoli">Cannoli</h3>
<blockquote>
<p><em>Cannoli is a compiler for a subset of Python 3.6.5 and is designed to evaluate the language features of Python that negatively impact performance.</em></p>
</blockquote>
<ul>
<li><a href="https://github.com/joncatanio/cannoli">https://github.com/joncatanio/cannoli</a></li>
</ul>
<p>Happy hacking!</p>

      </article></div>]]>
            </description>
            <link>https://sethops1.net/post/attempts-to-make-python-fast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24848318</guid>
            <pubDate>Wed, 21 Oct 2020 14:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is a Feature Store?]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24847994">thread link</a>) | @willempienaar
<br/>
October 21, 2020 | https://www.tecton.ai/blog/what-is-a-feature-store/ | <a href="https://web.archive.org/web/*/https://www.tecton.ai/blog/what-is-a-feature-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="5dd09226" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<h5>About the authors: <br>Mike Del Balso, CEO &amp; Co-Founder of <a href="http://tecton.ai/">Tecton</a><br>Willem Pienaar, Creator of <a href="http://feast.dev/">Feast</a></h5>



<hr>











<p>Data teams are starting to realize that operational machine learning requires solving data problems that extend far beyond the creation of data pipelines.</p>



<p>In Tecton’s previous post, <a href="https://www.tecton.ai/blog/devops-ml-data/">Why We Need DevOps for ML Data</a>, we highlighted some of the key data challenges that teams face when productionizing ML systems.</p>



<ul><li>Accessing the right raw data</li><li>Building features from raw data</li><li>Combining features into training data</li><li>Calculating and serving features in production</li><li>Monitoring features in production</li></ul>



<p>Production data systems, whether for large scale analytics or real-time streaming, aren’t new. However, <em>operational machine learning</em> — ML-driven intelligence built into customer-facing applications — is new for most teams. The challenge of deploying machine learning to production for operational purposes (e.g. recommender systems, fraud detection, personalization, etc.) introduces new requirements for our data tools.</p>



<p>A new kind of ML-specific data infrastructure is emerging to make that possible.</p>



<p>Increasingly Data Science and Data Engineering teams are turning towards feature stores to manage the data sets and data pipelines needed to productionize their ML applications. This post describes the key components of a modern feature store and how the sum of these parts act as a force multiplier on organizations, by reducing duplication of data engineering efforts, speeding up the machine learning lifecycle, and unlocking a new kind of collaboration across data science teams.</p>



<figure><table><tbody><tr><td>Quick refresher: in ML, a <strong>feature</strong> is data used as an input signal to a predictive model.</td></tr><tr><td>For example, if a credit card company is trying to predict whether a transaction is fraudulent, a useful feature might be <em>whether the transaction is happening in a foreign country</em>, or <em>how the size of this transaction compares to the customer’s typical transaction</em>. When we refer to a feature, we’re usually referring to the concept of that signal (e.g. “transaction_in_foreign_country”), not a specific value of the feature (e.g. not “transaction #1364 was in a foreign country”).</td></tr><tr><td><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore1.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td></tr></tbody></table></figure>











<p><strong><em>“The interface between models and data”</em></strong></p>



<p>We first introduced feature stores in our blog post describing Uber’s <a href="https://eng.uber.com/michelangelo-machine-learning-platform/">Michelangelo</a> platform. Feature stores have since emerged as a necessary component of the operational machine learning stack.&nbsp;</p>



<p>Feature stores make it easy to:</p>



<ol><li>Productionize new features without extensive engineering support</li><li>Automate feature computation, backfills, and logging</li><li>Share and reuse feature pipelines across teams</li><li>Track feature versions, lineage, and metadata</li><li>Achieve consistency between training and serving data</li><li>Monitor the health of feature pipelines in production</li></ol>



<p>Feature stores aim to solve the full set of data management problems encountered when building and operating operational ML applications.&nbsp;</p>



<p>A feature store is an ML-specific data system that:</p>



<ul><li>Runs data pipelines that <strong>transform</strong> raw data into feature values</li><li><strong>Stores</strong> and manages the feature data itself, and</li><li><strong>Serves</strong> feature data consistently for training and inference purposes</li></ul>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisafeaturestore10.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>To support simple feature management, feature stores provide data abstractions that make it easy to build, deploy, and reason about feature pipelines across environments. For example, they make it easy to define a feature transformation once, then calculate and serve its values consistently across both the development environment (for training on historical values) and the production environment (for inference with fresh feature values).</p>



<p>Feature stores act as a central hub for feature data and metadata across an ML project’s lifecycle. Data in a feature store is used for:</p>



<ul><li>feature exploration and engineering</li><li>model iteration, training, and debugging</li><li>feature discovery and sharing</li><li>production serving to a model for inference</li><li>operational health monitoring</li></ul>



<p>Feature stores bring economies of scale to ML organizations by enabling collaboration. When a feature is registered in a feature store, it becomes available for immediate reuse by other models across the organization. This reduces duplication of data engineering efforts and allows new ML projects to bootstrap with a library of curated production-ready features.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore9.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Effective feature stores are designed to be modular systems that can be adapted to the environment in which they’re deployed. There are five primary components that typically make up a feature store. In the rest of this post, we will walk through those components and describe their role in powering operational ML applications.</p>







<p>There are 5 main components of a modern feature store: Transformation, Storage, Serving, Monitoring, and feature Registry.</p>



<figure><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore3.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>In the following sections we’ll give an overview of the purpose and typical capabilities of each of these sections.</p>



<h2>Serving</h2>



<p>Feature stores serve feature data to models. Those models require a <strong>consistent view of features across training and serving</strong>. The definitions of features used to train a model must exactly match the features provided in online serving. When they don’t match, <a href="https://developers.google.com/machine-learning/guides/rules-of-ml#:~:text=Training%2Dserving%20skew%20is%20a,train%20and%20when%20you%20serve.">training-serving skew</a> is introduced which can cause catastrophic and hard-to-debug model performance problems.</p>



<p><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore5.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>







<p>Feature stores abstract away the logic and processing used to generate a feature, providing users an easy and canonical way to access all features in a company consistently across all environments in which they’re needed.</p>



<p>When retrieving data offline (i.e. for training), feature values are commonly accessed through notebook-friendly feature store SDKs. They provide point-in-time correct views of the state of the world for each example used to train a model (a.k.a. “<a href="https://www.tecton.ai/blog/time-travel-in-ml/"><strong>time-travel</strong></a>”).</p>



<p>For online serving, a feature store delivers a single vector of features at a time made up of the freshest feature values. Responses are served through a high-performance API backed by a low-latency database.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisafeaturestore11.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<h2>Storage</h2>



<p>Feature stores persist feature data to support retrieval through feature serving layers. They typically contain both an online and offline storage layer to support the requirements of different feature serving systems.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore8.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Offline storage layers are typically used to store months’ or years’ worth of feature data for training purposes. Offline feature store data is often stored in data warehouses or data lakes like S3, BigQuery, Snowflake, Redshift. Extending an existing data lake or data warehouse for offline feature storage is typically preferred to prevent data silos.</p>



<p>Online storage layers are used to persist feature values for low-latency lookup during inference. They typically only store the latest feature values for each entity, essentially modeling the current state of the world. Online stores are usually eventually consistent, and do not have strict consistency requirements for most ML use cases. They are usually implemented with key-value stores like DynamoDB, Redis, or Cassandra.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore6.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Feature stores use an entity-based data model where each feature value is associated with an entity (e.g. a user) and a timestamp. An entity-based data model provides minimal structure to support standardized feature management, fits naturally with common feature engineering workflows, and allows for simple retrieval queries in production.</p>



<h2>Transformation</h2>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisfeaturestore2.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Operational ML applications require regular processing of new data into feature values so models can make predictions using an up-to-date view of the world. Feature stores both manage and orchestrate data transformations that produce these values, as well as ingest values produced by external systems. Transformations managed by feature stores are configured by definitions in a common feature registry (described below).</p>



<figure><p>Most teams getting started with feature stores already have existing data pipelines producing feature values. This makes it very important for feature stores to be gradually adoptable and have first class integrations with existing data platforms, allowing teams to immediately operationalize existing ETL pipelines for their ML use cases.</p></figure>



<p>Feature stores commonly interact with three main types of data transformations:</p>







<figure><table><tbody><tr><td data-align="left">Feature Type</td><td>Definition</td><td>Common input data source</td><td data-align="left">Example</td></tr><tr><td data-align="left">Batch Transform</td><td>Transformations that are applied only to data at rest</td><td>Data warehouse, data lake, database</td><td data-align="left">User country, product category</td></tr><tr><td data-align="left">Streaming Transform</td><td>Transformations that are applied to streaming sources</td><td>Kafka, Kinesis, PubSub</td><td data-align="left"># of clicks per vertical per user in last 30 minutes, # of views per listing in past hour</td></tr><tr><td data-align="left">On-demand transform</td><td>Transformations that are used to produce features&nbsp; based on data that is only available at the time of the prediction. These features cannot be pre-computed.</td><td>User-facing application</td><td data-align="left">Is the user currently in a supported location?<br>Similarity score between listing and search query</td></tr></tbody></table></figure>



<p>A key benefit is to make it easy to use different types of features together in the same models.</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/whatisafeaturestore12.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Models need access to fresh feature values for inference. Feature stores accomplish this by regularly recomputing features on an ongoing basis. Transformation jobs are orchestrated to ensure new data is processed and turned into fresh new feature values. These jobs are executed on data processing engines (e.g. Spark or Pandas) to which the feature store is connected.&nbsp;</p>



<p>Model development introduces different transformation requirements. When iterating on a model, new features are often engineered to be used in training datasets that correspond to historical events (e.g. all purchases in the past 6 months). To support these use cases, feature stores make it easy to run “backfill jobs” that generate and persist historical values of a feature for training. Some feature stores automatically backfill newly registered features for preconfigured time ranges for registered training datasets.</p>



<p>Transformation code is reused across environments preventing …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tecton.ai/blog/what-is-a-feature-store/">https://www.tecton.ai/blog/what-is-a-feature-store/</a></em></p>]]>
            </description>
            <link>https://www.tecton.ai/blog/what-is-a-feature-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24847994</guid>
            <pubDate>Wed, 21 Oct 2020 14:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What to Avoid When Contributing to Open-Source Projects]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24847824">thread link</a>) | @lanecwagner
<br/>
October 21, 2020 | https://qvault.io/2020/10/21/6-things-to-avoid-when-contributing-to-open-source-projects/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/10/21/6-things-to-avoid-when-contributing-to-open-source-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>With <a aria-label="#HacktoberFest (opens in a new tab)" href="https://hacktoberfest.digitalocean.com/" target="_blank" rel="noreferrer noopener nofollow">#HacktoberFest</a> being a thing, there has been an influx of devs desperately trying to contribute to their favorite Open-Source projects. Unfortunately, many of these pull requests have been a waste of time, with the maintainers ultimately unable to use the contributions. Maintainers don’t want to waste their time reviewing bad PRs, and contributors don’t want to waste their time writing code that will never make it into production.</p>



<p>Let’s take a look at some common pitfalls that developers fall prey to when working on an open-source project. As a side note, we recently open-sourced the <a href="https://app.qvault.io/">Qvault</a> front-end, so take a look<a href="https://github.com/qvault/webapp" rel="noopener"> at that</a> if you want to help out.</p>



<h2>1. Pull Requests Should Handle ONE Thing</h2>



<p>Don’t open a PR like this:</p>



<ul><li>Fixes bug #543</li><li>Adds new linting rules</li><li>Includes feature #456</li></ul>



<p>Your PR should do <em>one thing</em>. Small diffs decrease the cognitive load of the reviewer and make it easier to get your code into the main branch. If you have beef with multiple issues in a project then open multiple PRs.</p>



<h2>2. Don’t Break Consistency</h2>



<p>This one happens the most often to me in my own projects. Well-intentioned developers open pull requests with any of the following annoyances:</p>



<ul><li>Omitting semicolons in a project that prefers them</li><li>Using spaces in a project that has clearly been using tabs</li><li>Introducing snake_case in a camelCase repo</li></ul>



<p>When you contribute to an existing project, use the existing styling. No one gives two hoots about your preference on the “<a href="https://www.youtube.com/watch?v=SsoOG6ZeyUI" target="_blank" aria-label="tabs vs spaces (opens in a new tab)" rel="noreferrer noopener nofollow">tabs vs spaces</a>” debate in the context of this pull request.</p>



<p>If you think styling needs to change, see points #1 and #3.</p>



<h2>3. Don’t Start Work Without Approval</h2>



<p>If you hop into a Github repo and find something you don’t like, don’t immediately open a pull request. Follow these steps instead:</p>



<ul><li>Is there already an issue logged? If not, make one.</li><li>If there is an issue, reach out to the maintainers (just comment on the issue) and let them know you want to work on it, and give a quick overview of how you will address it.</li><li>Assuming you have their blessing, start work on your PR.</li></ul>



<p>This will help mitigate the creation of pointless PRs that will never be accepted on the basis of a flawed premise.</p>



<h2>4. Don’t Re-open Known Problems/Solutions</h2>



<p>Some codebases have thousands of open issues, take the <a aria-label="Go language (opens in a new tab)" href="https://github.com/golang/go" target="_blank" rel="noreferrer noopener nofollow">Go language</a> project, or the <a aria-label="nocode repository (opens in a new tab)" href="https://github.com/kelseyhightower/nocode" target="_blank" rel="noreferrer noopener nofollow">nocode repository</a> as an example. No one wants to read your duplicate issue or review your duplicate pull request. Make sure there isn’t an existing open <em>or closed</em> issue for what you are trying to address.</p>



<h2>5. Squash Those Commits</h2>



<p>Not every project will require (or care) about <a aria-label="commit squashing (opens in a new tab)" href="https://github.com/wprig/wprig/wiki/How-to-squash-commits" target="_blank" rel="noreferrer noopener nofollow">commit squashing</a>. That said, there are no projects that require <em>not</em> squashing commits. To be on the safe side just give ’em a squash.</p>



<h2>6. Be Meaningful</h2>



<p>Rewording documentation and other frivolous changes make you look like <a href="https://github.com/whatwg/html/pulls?q=is%3Apr+is%3Aclosed+label%3Aspam" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">these assholes</a>. This particularly <a href="https://github.com/whatwg/html/pull/6075" target="_blank" aria-label="atrocious example (opens in a new tab)" rel="noreferrer noopener nofollow">atrocious example</a> is not only scoped to pointless documentation changes but actually makes the documentation <em>worse</em>.</p>
		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/10/21/6-things-to-avoid-when-contributing-to-open-source-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24847824</guid>
            <pubDate>Wed, 21 Oct 2020 13:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning to Decapsulate Integrated Circuits Using Acid Deposition]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24847500">thread link</a>) | @garaetjjte
<br/>
October 21, 2020 | https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/ | <a href="https://web.archive.org/web/*/https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>20 Oct 2020
  </span></p><p>In this post:</p>

<ul>
  <li><a href="#existing-methodologies">Known decapping methodologies</a></li>
  <li><a href="#personal-safety">Personal safety</a></li>
  <li><a href="#my-own-experiments">My experiments</a>
    <ul>
      <li><a href="#tools-and-materials">Tools and materials</a></li>
      <li><a href="#attempt-1-sand-down-the-epoxy-packaging">Failure: Sand down the packaging</a></li>
      <li><a href="#attempt-2-dremel--69-nitric-acid--gentle-acetone-bath">Limited success: Nitric acid + acetone bath</a></li>
      <li><a href="#attempt-3-dremel--69-nitric-acid--acetone-syringe">Failure: Nitric acid + acetone syringe</a></li>
      <li><a href="#attempt-4-dremel--69-nitric-acid--acetone-syringe-epoxy-removal--ultrasonic-methanol-cleanup">Failure: Nitric acid + acetone syringe + ultrasonic methanol bath</a></li>
      <li><a href="#attempt-5-dremel--69-nitric-acid--acetone-syringe--ultrasonic-acetone-cleanup">Success: Nitric acid + acetone syringe + ultrasonic acetone bath</a></li>
      <li><a href="#attempt-6-dremel--69-nitric-acid--room-temp-nitric-acid--acetone-syringe--ultrasonic-acetone-cleanup">Pointless: Bath the IC in room-temp nitric acid before cleanup</a></li>
      <li><a href="#attempt-7-dremel--98-sulfuric-acid--69-nitric-acid--ultrasonic-acetone-bath">Success: Using a mix of Sulfuric and Nitric acids</a></li>
    </ul>
  </li>
  <li><a href="#taking-pictures-under-the-microscope">How I took the silicon die pictures</a></li>
  <li><a href="#successful-imaging">Pretty pictures of silicon dies</a></li>
  <li><a href="#resources">Resources</a></li>
</ul>

<p>I’ve been looking to try my hand at IC decapsulation for years, and finally got
the time to do it. The process took plenty of trial and error, so this post will
document most of my failures and successes, and detail the methodologies used for
each attempt. These are most of the ICs I worked on throughout the process:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/macro-all-manipulated-ics.jpg" alt="Most ICs I experimented on"></p>

<p>A typical chip is built as a silicon die, connected to its leads/contacts through
bonding wires, and encapsulated in resin for protection.</p>

<p>Of course, there are other ICs that use different designs and encapsulation
materials: mostly metal and plastics. But the epoxy-based design is extremely
common, so we’ll be focusing on it.</p>

<p>This picture of a DIP package -<a href="https://en.wikipedia.org/wiki/File:DIP_package_sideview.PNG">courtesy of Wikipedia</a>-
explains it very well:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/3rd-party/DIP_package_sideview.png" alt="Generic IC diagram"></p>

<p>The decapsulation/decapping of Integrated Circuits, also known as “delidding”, is
nothing new.</p>

<p>It’s used in the industry to debug hardware issues, reverse engineer chips, verify
the authenticity of parts, and other tasks that require access to the underlying
circuitry.</p>

<p>That’s why there’s plenty of commercial services that will decapsulate your ICs
using expensive and dedicated equipment.
I’ve linked a couple of them in <a href="#resources">the bibliography</a>.
But, without having any idea how much they cost or how long they take, I can’t
imagine them being an option for the average hacker.</p>

<p>Hackers and smaller companies generally decap Integrated Circuits to identify
counterfeits, gain a very rudimentary understanding of the parts comprising them,
or just to share the pretty pictures of the silicon die.
For those cases, a DIY process is generally good enough.</p>

<p>Decapping/delidding has also been used by hackers for more fun purposes, such as
<a href="https://www.bunniestudios.com/blog/?page_id=40">unsetting efuses from production hardware to extract and/or override their firmware</a>,
private keys, etc.
So there are cases where a commercial-level result can be worth it.</p>

<p>I’ve been wanting to try my hand at decapping ICs for years, for no other purpose
than to satiate my curiosity. I’ve finally had the time to get to it, so this
post will describe the methods I tried and the hurdles I encountered.</p>



<p>The biggest factor to decide which method is best for your project is whether
or not you need the chip to still work after it’s been decapsulated. That means
not destroying or disconnecting the die, bonding wires, external contact points,
etc. so you can still use the chip after the process is complete.</p>

<p>Here’s a list of the most common options.</p>

<p>Destructive methods:</p>

<ul>
  <li><a href="https://www.experimental-engineering.co.uk/2016/02/20/ic-decapping-the-process/">Burn the encapsulation to hell</a> using a blowtorch</li>
  <li><a href="http://jg.sn.sg/decap/">Full wet chemical decapsulation</a>: Bath the entire chip in acid to remove all encapsulation, leads, bonds, etc.</li>
</ul>

<p>Non-destructive methods:</p>

<ul>
  <li>Selective wet chemical decapsulation:
    <ul>
      <li><a href="https://ieeexplore.ieee.org/document/1707865">Rubber gaskets + acid yet for targetted decapping</a></li>
      <li><a href="https://www.youtube.com/watch?v=mT1FStxAVz4">Manual acid deposition</a>:
Repeatedly apply drops of acid on the IC’s target area, and rinse the acid
residue and weakened encapsulation</li>
    </ul>
  </li>
  <li><a href="https://bseteq.com/decapsulation/plasma-decap/plaser-plasma-decapsulation-system/">Plasma etching</a>
uses expensive equipment to create plasma, make it react with the encapsulation,
and drain it away</li>
</ul>

<p>In this post we’re gonna focus on the manual acid deposition method, to achieve
non-destructive decapsulation at a reasonable cost.</p>



<p>First of all, let me preface this safety talk with an important disclaimer:
I HAVE NO IDEA WHAT I’M DOING. My thing is firmware and electronics, not chemistry.</p>

<p>PLEASE, do not assume the safety measures discussed here are valid or enough to
protect yourself. Do your own research, follow any and all measures you deem
appropriate, and remain paranoid all along the process.</p>

<p>We’re dealing with very dangerous chemicals. If you decide to replicate the
experiments it’s at your own peril.</p>

<p>Here are more authoritative sources of safety information for a project like this.
Review as much of this info as you can, and take it with the seriousness it requires:</p>

<ul>
  <li><a href="https://safetyservices.ucdavis.edu/safetynet/safe-use-of-nitric-acid">UCDavis docs on the safe use of nitric acid</a></li>
  <li><a href="https://www.3m.com/3M/en_US/safety-centers-of-expertise-us/respiratory-protection/respirator-selection/">3M respiratory protection selection guide</a></li>
  <li><a href="https://www.cdc.gov/niosh/topics/nitric-acid/default.html">CDC resources on the use of nitric acid</a></li>
  <li><a href="https://www.youtube.com/watch?v=ftACSEJ6DZA">NileRed’s “Chemistry is Dangerous” introduction to personal protection when working with chemicals</a></li>
</ul>

<p>After doing enough research to feel comfortable with the risks involved, I settled
for following these measures:</p>

<ul>
  <li>Run all experiments outside, with all nearby windows closed, and never accessing
the area without using PPE. I might invest in a fume hood in the future, either
commercial or DIY</li>
  <li>Wear chemical splash goggles. They should protect your eyes from droplets
coming from any direction. If they become uncomfortable or fog up, do not remove
them or pull them off your face in the working area</li>
  <li>Wear a respirator mask with filters that are appropriate for chemical fumes.
Preferably a full face mask, to avoid acid splashes</li>
  <li>Wear gloves that are appropriate for the acids you’re dealing with. Nitrile gloves
should NOT be used to work with nitric acid; especially fuming (98%+) nitric acid.
Long, thick neoprene-based gloves are best for Nitric, but make delicate tasks
difficult. I settled for wearing a thick neoprene glove on my non-dominant hand,
and a vinyl glove on my dominant hand for the more delicate work. When touching
any surface that’s hot or has been in touch with acid, I use the neoprene glove</li>
  <li>Expose as little of your skin as possible: Wear shoes, trousers (not shorts),
long sleeves… Preferably use a lab coat, so you can remove the acid-splashed
clothing without dragging it over your face</li>
  <li>Never mix chemicals without fully understanding the outcome to expect. Keep
different chemicals as far apart from each other as possible. Keep the smallest
possible amount of dangerous chemicals in the working area</li>
  <li>Be prepared for the worst:
    <ul>
      <li>Keep enough sodium bicarbonate at hand to neutralize acid spills and leftover acid.
Keep in mind that neutralizing acid with bicarb will give off heat, and the bubbling
could be dangerously vigorous for significant amounts. Expect the possibility of
a spill during the neutralization process</li>
      <li>Keep enough water at hand to dilute chemicals in case of spills, splashes, etc.</li>
      <li>Understand what are the recommended procedures in case of any given chemical
contacting your skin, eyes, etc. Eyes are generally the most sensitive to chemical
splashes, as they can be permanently damaged in seconds; they’re also the most
difficult to clean up, so be particularly careful with them and have a plan of
action in case the worst happens</li>
    </ul>
  </li>
</ul>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/ppe.jpg" alt="Picture of my PPE"></p>



<p>These describe failures and successes, and what I learned along the way.
Keep in mind that most resources I’ve found recommend using fuming nitric acid
(86%+).</p>

<p>I was not able to source fuming nitric acid, so I used concentrated nitric
(69%) instead. That could account for some of the problems I’m about to describe,
but worked fine once I found the most fitting methodology.</p>



<p>Chemicals I used during my experiments:</p>

<ol>
  <li>Concentrated (69%) Nitric Acid</li>
  <li>100% Sodium bicarbonate - Bought on Amazon</li>
  <li>98% methanol - From a hardware store</li>
  <li>Acetone - From a hardware store</li>
  <li>Water - Either tap water or regular distilled water from a grocery store</li>
</ol>

<p>I also ran a couple of tests using Sulfuric Acid, both standalone and mixed with
the Nitric, but the results were not very promising. Probably because of the
encapsulation material used in my ICs. These are the acids I used:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/all-chemicals.jpg" alt="Both bottles of acid used during my experiments"></p>

<p>Necessary equipment:</p>

<ol>
  <li>Dremel
    <ul>
      <li>I’ve found <a href="https://jcjc-dev.com/assets/ic-decapping/jc/dremel-diamond-pointy-bit.jpg">this off-brand pointy diamond bit</a>
to work great</li>
    </ul>
  </li>
  <li>Hot plate</li>
  <li>High-temperature and acid safe recipient
    <ul>
      <li>Tried using ceramic recipients and they worked well enough, but it was hard
to maintain a stable temperature outside using my hot plate</li>
      <li>Graphite ingot molds ended up being better at conducting heat (hence
maintaining a reasonably stable temperature outside) and providing easy access
to the IC inside</li>
    </ul>
  </li>
  <li>Plastic tweezers</li>
  <li>A syringe, or preferably an assortment of them</li>
</ol>

<p>Other very useful equipment:</p>

<ol>
  <li>An Erlenmeyer flask to keep a small amount of acid in a stable container</li>
  <li>Pipettes:
    <ul>
      <li>10ml pipette to transfer acid from its primary container to the flask</li>
      <li>1ml pipette to drop acid on the ICs</li>
    </ul>
  </li>
  <li>Beakers:
    <ul>
      <li>A small one for acetone</li>
      <li>A large one for water, to rinse tools</li>
    </ul>
  </li>
  <li>Thermocouple to monitor the temperature of the hot plate and IC container</li>
  <li>Tongs to move the hot ceramic/graphite container</li>
  <li>Ultrasonic cleaner. Explained later</li>
</ol>

<p>This picture shows most of the equipment used for the most successful method:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/ultrasonic-acetone-all-equipment.jpg" alt="All the equipment used for the most successful method"></p>

<h2 id="attempt-1-sand-down-the-epoxy-packaging">Attempt 1: Sand down the epoxy packaging</h2>

<p>This is how the project started. I just got a new microscope, met with a couple
of good friends, and we started looking at some random samples. Blood, dust, etc.</p>

<p>Then we decided to take a look at some random IC. We were not looking to
see anything useful or complete; just an overall image of the silicon die in
an IC, so I sanded down a microcontroller and we took a look. The result, as
expected, was absolute garbage:</p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/macro-sanded-pic.jpg" alt="Macro: Sanded down IC"></p>

<p><img src="https://jcjc-dev.com/assets/ic-decapping/jc/micro-sanded-pic.jpg" alt="Micro: Sanded down silicon die"></p>

<p>Well, that went exactly as terribly as expected… Time to go down the rabbit hole.</p>

<h2 id="attempt-2-dremel--69-nitric-acid--gentle-acetone-bath">Attempt 2: Dremel + 69% Nitric Acid + Gentle acetone bath</h2>

<p>Steps:</p>

<ol>
  <li>Drill a pocket on the top of the epoxy package so the acid does not spill over
to the leads.</li>
  <li>Place IC on a ceramic or graphite recipient, on top of the hot plate. Attach
a thermocouple to the recipient to monitor its temperature</li>
  <li>When the temperature is appropriate (around 100 degrees C), drop one or 2 drops
of acid in the epoxy pocket we just drilled. Wait until there is no more acid,
and continue to apply acid when that happens</li>
  <li>Every once in a while, grab the IC with plastic tweezers, dip it in acetone
and move it around to remove the reacted epoxy</li>
</ol>

<p>Results: <strong>Terrible</strong></p>

<p>A simple acetone bath and some stirring are not enough to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/">https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/</a></em></p>]]>
            </description>
            <link>https://jcjc-dev.com/2020/10/20/learning-to-decap-ics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24847500</guid>
            <pubDate>Wed, 21 Oct 2020 13:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Millennials are not getting married]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24847433">thread link</a>) | @koolhead17
<br/>
October 21, 2020 | https://www.allendowney.com/blog/2020/10/21/millennials-are-not-getting-married/ | <a href="https://web.archive.org/web/*/https://www.allendowney.com/blog/2020/10/21/millennials-are-not-getting-married/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

									
<article id="post-498">

	
	
	<!-- .entry-header -->

			<div>
				
<p>In 2015 I wrote a paper called “<a href="http://conference.scipy.org/proceedings/scipy2015/allen_downey.html" target="_blank" rel="noreferrer noopener">Will Millennials Ever Get Married?</a>” where I used data from the National Survey of Family Growth (NSFG) to estimate the age at first marriage for women in the U.S, broken down by decade of birth. &nbsp;</p>



<p>I found that women born in the 1980s and 90s were getting married later than previous cohorts, and I generated projections that suggest they are on track to stay unmarried at substantially higher rates.</p>



<p>Here are the results from that paper, based on 58 488 women surveyed between 1983 to 2015:</p>



<figure><img loading="lazy" width="1024" height="683" src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1024x683.png" alt="" srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3.png 1800w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3.png 1800w" data-lazy-src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-3-1024x683.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Percentage of women ever married, based on data up to 2015.</figcaption></figure>



<p>Each line represents a cohort grouped by decade of birth.  For example, the top line represents women born in the 1940s.</p>



<p>The colored segments show the fraction of women who had ever been married as a function of age.  For example, among women born in the 1940s, 82% had been married by age 25.  Among women born in the 1980s, only 41% had been married by the same age.</p>



<p>The gray lines show projections I generated by assuming that going forward each cohort would be subject to the <a href="https://en.wikipedia.org/wiki/Survival_analysis#Hazard_function_and_cumulative_hazard_function">hazard function</a> of the previous cohort. This method is likely to overestimate marriage rates.</p>



<p>These results show two trends:</p>



<ul><li>Each cohort is getting married later than the previous cohort.</li><li>The fraction of women who never marry is increasing from one cohort to the next.  </li></ul>



<h3>New data</h3>



<p>Yesterday the National Center for Health Statistics (NCHS) released a&nbsp;<a rel="noreferrer noopener" href="https://www.cdc.gov/nchs/nsfg/nsfg_2017_2019_puf.htm" target="_blank">new batch of data from surveys conducted in 2017-2019</a>. &nbsp;So we can compare the predictions from 2015 with the new data, and generate updated predictions.</p>



<p>The following figure shows the predictions from the previous figure, which are based on data up to 2015, compared to the new curves based on data up to 2019, which includes 70 183 respondents.</p>



<figure><img loading="lazy" width="1024" height="683" src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1024x683.png" alt="" srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4.png 1800w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4.png 1800w" data-lazy-src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage4-4-1024x683.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Percentage of women ever married, based on data up to 2019, <br>compared to predictions based on data up to 2015.</figcaption></figure>



<p>For women born in the 1980s, the fraction who have married is almost exactly as predicted.  For women born in the 1990s, it is substantially lower.  </p>



<h3>New projections</h3>



<p>The following figure shows projections based on data up to 2019.</p>



<figure><img loading="lazy" width="1024" height="683" src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1024x683.png" alt="" srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4.png 1800w" sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-srcset="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1024x683.png 1024w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-300x200.png 300w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-768x512.png 768w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1536x1024.png 1536w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-405x270.png 405w, https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4.png 1800w" data-lazy-src="https://www.allendowney.com/blog/wp-content/uploads/2020/10/marriage5-4-1024x683.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Percentage of women ever married, based on data up to 2019,<br>with predictions based on data up to 2019.</figcaption></figure>



<p>The vertical dashed lines show the ages where we have the last reliable estimate for each cohort.  The following table summarizes the results at age 28:</p>



<figure><table><thead><tr><th>Decade of birth</th><th>1940s</th><th>1950s</th><th>1960s</th><th>1970s</th><th>1980s</th><th>1990s</th></tr></thead><tbody><tr><td>% married <br>before age 28</td><td>87%</td><td>80%</td><td>70%</td><td>63%</td><td>55%</td><td>31%</td></tr></tbody></table><figcaption>Percentage of women married by age 28, grouped by decade of birth.</figcaption></figure>



<p>The percentage of women married by age 28 has dropped quickly from each cohort to the next, by about 11 percentage points per decade.  </p>



<p>The following table shows the same percentage at age 38; the last value, for women born in the 1990s, is a projection based on the data we have so far.</p>



<figure><table><thead><tr><th>Decade of birth</th><th>1940s</th><th>1950s</th><th>1960s</th><th>1970s</th><th>1980s</th><th>1990s</th></tr></thead><tbody><tr><td>% married <br>before age 38</td><td>92%</td><td>88%</td><td>85%</td><td>80%</td><td>68%</td><td><em>51%</em></td></tr></tbody></table><figcaption>Percentage of women married by age 38, grouped by decade of birth.</figcaption></figure>



<p>Based on current trends, we expect barely half of women born in the 1990s to be married before age 38.</p>



<p>Finally, here are the percentages of women married by age 48; the last two values are projections.</p>



<figure><table><thead><tr><th>Decade of birth</th><th>1940s</th><th>1950s</th><th>1960s</th><th>1970s</th><th>1980s</th><th>1990s</th></tr></thead><tbody><tr><td>% married <br>before age 48</td><td>&gt;93%</td><td>&gt;90%</td><td>88%</td><td>83%</td><td><em>72%</em></td><td><em>58%</em></td></tr></tbody></table><figcaption>Percentage of women married by age 48, grouped by decade of birth.</figcaption></figure>



<p>Based on current trends, we expect women born in the 1980s and 1990s to remain unmarried at rates substantially higher than previous generations.</p>



<p>Projections like these are based on the assumption that the future will be like the past, but of course, things change.  In particular:</p>



<ul><li>These data were collected before the COVID-19 pandemic. Marriage rates in 2020 will probably be lower than predicted, and the effect could continue into 2021 or beyond.</li><li>However, as economic conditions improve in the future, marriage rates might increase.</li></ul>



<p>We’ll find out when we get the next batch of data in October 2022.</p>



<p><a href="https://github.com/AllenDowney/MarriageNSFG" target="_blank" rel="noreferrer noopener">The code I used for this analysis is in this GitHub repository</a>.</p>


							</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
				</div></div>]]>
            </description>
            <link>https://www.allendowney.com/blog/2020/10/21/millennials-are-not-getting-married/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24847433</guid>
            <pubDate>Wed, 21 Oct 2020 13:05:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RuboCop v1.0 Released]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24846902">thread link</a>) | @kpsnow
<br/>
October 21, 2020 | https://metaredux.com/posts/2020/10/21/rubocop-1-0.html | <a href="https://web.archive.org/web/*/https://metaredux.com/posts/2020/10/21/rubocop-1-0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <blockquote>
  <p>If at first you don’t succeed, call it version 1.0.</p>
</blockquote>

<p>RuboCop’s development started exactly 7 and half years ago. I made
<a href="https://github.com/rubocop-hq/rubocop/commit/afbead34db54506c12a21dbd4ce04fada0f8b9a4#diff-bc37d034bad564583790a46f19d807abfe519c5671395fd494d8cce506c42947">the first
commit</a>
on April 21, 2012. That’s a lot of time in general, but even more in
the fast moving world of IT. During this long period we’ve racked up some
impressive numbers:</p>

<ul>
  <li><strong>9905</strong> commits</li>
  <li><strong>152</strong> releases</li>
  <li>around <strong>3500</strong> closed issues</li>
  <li>almost <strong>5000</strong> merged pull requests</li>
  <li>over <strong>120 million</strong> downloads</li>
  <li>over <strong>200</strong> publicly available related gems (extensions, custom configurations, etc)</li>
  <li>over <strong>700</strong> contributors</li>
</ul>

<p>I never expected any of this on April 21, 2012. If there’s a person truly
surprised by the success of RuboCop that’d be me. But wait, there’s more!
We also reached some important milestones in the last couple of years:</p>

<ul>
  <li>Created the <a href="https://github.com/rubocop-hq">RuboCop HQ organization</a> that became the home for RuboCop, the community style guides, and many popular RuboCop extensions</li>
  <li>Extracted the Rails cops to a separate gem (<code>rubocop-rails</code>)</li>
  <li>Extracted the performance cops to a separate gem (<code>rubocop-performance</code>)</li>
  <li>Extracted the AST-related functionality to a separate gem (<code>rubocop-ast</code>)</li>
  <li>Created new extensions focused on Rake (<code>rubocop-rake</code>) and Minitest (<code>rubocop-minitest</code>)</li>
  <li>Made significant improvements to RuboCop’s code formatting capabilities</li>
  <li>Reworked the cop API</li>
  <li>Switched to safe-only cops by default</li>
  <li>Introduced the notion of “pending” cops</li>
  <li>Created a brand new <a href="https://docs.rubocop.org/">documentation site</a></li>
  <li>Provided more polished versions of the community style guides over at <a href="https://rubystyle.guide/">https://rubystyle.guide</a></li>
</ul>

<p>One thing eluded us, though - a “stable” RuboCop release. Today this finally changes with
RuboCop 1.0!<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>There’s nothing ground-breaking about the new RuboCop release - it’s almost the same as RuboCop 0.93.1 that
preceded it. I believe the only change, that most of you are going to notice, is that all cops that used to be
“pending” are now enabled by default, which is in line with our release policy. No new cops will be enabled
by default until RuboCop 2.0.</p>

<p>The big news for end users and maintainers of extensions is that we’re finally embracing fully Semantic Versioning, which
should make the upgrade process simpler (painless?) for everyone. Going forward the following things will happen only on major releases:</p>

<ul>
  <li>enabling of new cops</li>
  <li>changes to the default cop configuration</li>
  <li>breaking API changes</li>
</ul>

<p>It’s really funny that I felt for at least a couple of years that we were very close to the 1.0
release, only to come up with more and more things I wanted to include in it. I believe <a href="https://rubykaigi.org/2018/presentations/bbatsov.html">I first spoke</a>
about my intentions to ship RuboCop 1.0 at RubyKaigi 2018 and back then I truly believed this was bound to happen in the next
6 months. Classic example of planning in the software development world, right?</p>

<p>Many people urged me for years to label a random release as 1.0 with
the argument that if some software is useful and widely used than it
probably deserves that magic moniker. It’s not a bad argument and I
totally understood the perspective of those people. I, however, was
not convinced as for me version 1.0 also stands for “we got to a place
we consider feature complete and aligned with our vision”.  Needless
to say - the vision we (RuboCop’s team) had was quite ambitious and it took us
a while to make it a reality.</p>

<p>I cannot begin to explain how happy I am that we got here, and I can
assure you that it wasn’t easy.  Over the years RuboCop had its ups
and downs, it got a lot of praise, but also a lot of flak.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Some
days I was super pumped and motivated to work on it, on other days I
couldn’t stand to think about it.  Working on popular OSS projects is
one of the most rewarding and most frustrating experiences that one
can have.  I was (un)fortunate enough to be involved in a few of those
(RuboCop, CIDER, nREPL, Projectile, Emacs Prelude, etc) and each one
was a crazy roller-coaster ride.</p>

<p>I find it funny how my role in RuboCop evolved with time. Originally I
used to write mostly code, these days I write mostly tickets,
issue/code review comments and documentation. Often I feel more like a
project manager rather than a programmer. There was a time when I was
super happy to see a PR and I’d immediately respond to it, now I can’t
keep up with all the PRs. In fact, our entire team can’t keep up with
them, so consider this my apology that it sometimes takes a while to
get feedback on your suggestions. I’ll even admit that I rarely read
issue tickets these days as there are so many of them and it’s
impossible for me to respond to all of them. I’ve just learned that
important tickets always get noticed, if not by me than by someone else from our
fantastic team.</p>

<p>I want to extend special thanks to RuboCop’s core team, as we would have never gotten so far without all those amazing people
working tirelessly on the project:</p>

<ul>
  <li><a href="https://github.com/jonas054">Jonas Arvidsson</a></li>
  <li><a href="https://github.com/yujinakayama">Yuji Nakayama</a> (retired)</li>
  <li><a href="https://github.com/edzhelyov">Evgeni Dzhelyov</a> (retired)</li>
  <li><a href="https://github.com/drenmi">Ted Johansson</a></li>
  <li><a href="https://github.com/pocke">Masataka Kuwabara</a></li>
  <li><a href="https://github.com/koic">Koichi Ito</a></li>
  <li><a href="https://github.com/darhazer">Maxim Krizhanovski</a></li>
  <li><a href="https://github.com/bquorning">Benjamin Quorning</a></li>
  <li><a href="https://github.com/marcandre">Marc-André Lafortune</a></li>
</ul>

<p>You rock, guys!</p>

<p>Jonas, in particular, deserves just as much credit for RuboCop existing today as me. He was the first contributor to RuboCop and he
pushed me to get RuboCop to the state where it got critical mass, mindshare and some traction. It’s a long story for another day and another article.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>Koichi also deserves a special mention for his tireless work and incredible dedication to RuboCop and its users over the years! And for his great karaoke skills!
He has also been a fantastic head maintainer for key RuboCop extensions like <code>rubocop-rails</code>, <code>rubocop-performance</code> and <code>rubocop-minitest</code>.</p>

<p>Last, but not least - another round of big thanks for all the people who contributed to RuboCop in any capacity over the years! RuboCop is all of you!
Keep those contributions coming!</p>

<p>Some closing notes:</p>

<ul>
  <li>As mentioned above, recently we’ve extracted RuboCop’s AST-related logic to the <a href="https://github.com/rubocop-hq/rubocop-ast">rubocop-ast</a> gem, that’s going to be very handy for everything looking to supercharge
<a href="https://github.com/whitequark/parser">parser</a>’s API. I’d love to see more tools using it, as I think we really managed to simplify the interaction with an AST. Work on the new gem is led by the awesome Marc-André Lafortune. By the way, he released <code>rubocop-ast</code> 1.0 today! We have some cause for double celebration!</li>
  <li>The cop API was completely reworked recently by Marc-André. He did some truly fantastic work there! Check out the <a href="https://docs.rubocop.org/rubocop/v1_upgrade_notes.html">upgrade notes</a> if you maintain any RuboCop extensions, as the legacy API will be removed
in RuboCop 2.0.</li>
  <li>We’ve made some changes to how department names are calculated that might affect some extensions. Read more about them <a href="https://github.com/rubocop-hq/rubocop/pull/8490">here</a>.</li>
  <li>Check out the <a href="https://github.com/rubocop-hq/rubocop/releases/tag/v1.0.0">release notes</a> for all the details.</li>
  <li><code>rubocop-rspec</code> is currently not compatible with RuboCop 1.0, but we’re working on this. You can follow the progress on that front <a href="https://github.com/rubocop-hq/rubocop-rspec/issues/1051">here</a>.</li>
</ul>

<p>And that’s a wrap!</p>

<p>I feel a bit sorry for disappointing everyone who hoped we’d make it
to RuboCop 0.99, before cutting RuboCop 1.0. We did our best and we
had a great 0.x run, but we ran out of things to do.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup> :-) On the bright side - now
I can finally say that I’ve got 99 problems (and 200 open issues), but cutting RuboCop 1.0 ain’t one.</p>

<p>Enjoy RuboCop 1.0 and share with us your feedback about it! Our focus now shifts to RuboCop 1.1, and I hope that we’ll be dropping
new major releases rather infrequently going forward (although RuboCop 2.0 will probably arrive in less than 7 years). Thanks for your help, love, feedback and
support! Keep hacking!</p>

<p><strong>P.S.</strong> Koichi recently covered in great details our long journey to RuboCop 1.0 in his presentation <a href="https://speakerdeck.com/koic/road-to-rubocop-1-dot-0">Road to RuboCop 1.0</a> at RubyKaigi 2020. I cannot recommend it highly enough to those of you who’d like to learn more about the technical aspects of RuboCop 1.0 and all the challenges we had to solve along the way!</p>


  </div></div>]]>
            </description>
            <link>https://metaredux.com/posts/2020/10/21/rubocop-1-0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24846902</guid>
            <pubDate>Wed, 21 Oct 2020 11:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aim for Operability, Not SRE as a Cult]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24846132">thread link</a>) | @slyall
<br/>
October 21, 2020 | https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/ | <a href="https://web.archive.org/web/*/https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
		
<blockquote><p><strong>Site Reliability Engineering (SRE) offers a philosophy for operating reliable distributed systems, with admirable principles and practices. However, in only a few years SRE cargo culting has emerged at a level to rival DevOps cargo culting in the 2010s.&nbsp;<p>What is SRE as a Cult, and how does it intersect with DevOps as a Cult? Why is SRE so difficult to apply to enterprise organisations with IT as a A Cost Centre? Why is an emphasis on operability more important to IT performance than SRE?</p></strong></p></blockquote>



<h3>Introduction&nbsp;</h3>



<p>A successful Digital transformation is predicated on a transition from <a href="https://www.stevesmith.tech/blog/it-as-a-cost-centre/">IT as a Cost Centre</a> to <a href="https://www.stevesmith.tech/blog/it-as-a-business-differentiator/">IT as a Business Differentiator</a>. An IT cost centre creates segregated Delivery and Operations teams, trapped in an endless conflict between speed and reliability. Delivery wants to maximise deployments, to increase speed. Operations wants to minimise deployments, to increase reliability. This results in low performance IT, and has negative consequences for profitability, market share, and productivity.&nbsp;</p>



<p>In <a href="https://www.amazon.com/dp/B07B9F83WM" target="_blank" rel="noreferrer noopener"><em>Accelerate</em></a>, Dr Nicole Forsgren <em>et al</em> demonstrates speed and reliability are not a zero sum game. Investing in both Continuous Delivery and Operability will produce a high performance IT capability that can uncover new product revenue streams. For instance, transforming production support from <a href="https://www.stevesmith.tech/blog/you-build-it-ops-runs-it/">You Build It Ops Run It</a> to <a href="https://www.stevesmith.tech/blog/you-build-it-you-run-it/">You Build It You Run It</a> will unlock daily deployments, and have a positive impact on service reliability. User satisfaction, revenue protection, and brand reputation will all be improved.&nbsp;</p>



<h3>SRE as a Philosophy</h3>



<p>In 2004, Ben Treynor Sloss started an initiative called SRE within Google. He later described SRE as a software engineering approach to IT operations, with developers automating work historically owned outside Google by sysadmins. SRE key concepts include:</p>



<ul><li>Availability levels.</li><li>Service Level Objectives.</li><li>Error budgets.&nbsp;</li><li><a href="https://www.stevesmith.tech/blog/you-build-it-sre-run-it">You Build It SRE Run It</a>.</li></ul>



<p>Availability levels are known by the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/High_availability" target="_blank">nines of availability</a>. 99.0% is two nines, 99.999% is five nines. 100% availability is unachievable, as less reliable user devices will limit the user experience. 100% is also undesirable, as maximising availability limits speed of feature delivery and increases operational costs. In the seminal book <a rel="noreferrer noopener" href="https://landing.google.com/sre/sre-book/chapters/introduction/" target="_blank"><em>Site Reliability Engineering</em></a>, Betsey Byers <em>et al</em> observe that ‘an additional nine of reliability requires an order of magnitude more engineering effort’. At any availability level, an amount of unplanned downtime needs to be tolerated, in order to invest in feature delivery.</p>



<figure><img loading="lazy" width="960" height="540" src="https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels.png" alt="" srcset="https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels.png 960w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels-300x169.png 300w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels-768x432.png 768w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-availability-levels-676x380.png 676w" sizes="(max-width: 960px) 100vw, 960px"></figure>



<p>A Service Level Objective (SLO) is a published target range of measurements, which sets user expectations on an aspect of service performance. A product manager chooses SLOs, based on their own risk tolerance. They have to balance the engineering cost of meeting an SLO with user needs, the revenue potential of the service, and competitor offerings. An availability SLO could be a median request success rate of 99.9% in 24 hours, with measurements collected every minute for 24 hours as a Service Level Indicator (SLI).&nbsp;</p>



<p>An error budget is a quarterly amount of tolerable, unplanned downtime for a service. It is used to mitigate any inter-team conflicts between product teams and SRE teams, as found in You Build It Ops Run It. It is calculated as 100% minus the chosen nines of availability. For example, an availability level of 99.9% equates to an error budget of 0.01% unsuccessful requests. 0.002% of failing requests in a week would consume 20% of the error budget, and leave 80% for the quarter.&nbsp;</p>



<p>You Build It SRE Run It is a conditional production support method, where a team of SREs support a service for a product team. All product teams do You Build It You Run It by default, and there are strict entry and exit criteria for an SRE team. A service must have a critical level of user traffic, some elevated SLOs, and pass a readiness review. The SREs will take over on-call, and ensure SLOs are consistently met. The product team can launch new features if the service is within its error budget. If not, they cannot deploy until any errors are resolved. If the error budget is repeatedly blown, the SRE team can hand on-call back to the product team, who revert to You Build It You Run It.</p>



<p>This is <strong>SRE as a Philosophy</strong>. The biggest gift from SRE is a framework for quantifying availability targets and engineering effort, based on product revenue. SRE has also promoted ideas such as measuring partial availability, monitoring the golden signals of a service, building SLO alerts and SLI dashboards from the same telemetry data, and reducing operational toil where possible.&nbsp;&nbsp;</p>



<h3>SRE as a Cult</h3>



<p>In the 2010s, the DevOps philosophy of collaboration was bastardised by <a href="https://www.stevesmith.tech/blog/aim-for-operability-not-devops-as-a-cult/">DevOps as a Cult</a>. The DevOps cargo cult is ubiquitous, and wrong. Its beliefs are:</p>



<ol><li>The divide between Delivery and Operations teams is <em>always</em> the constraint in IT performance.&nbsp;</li><li>DevOps automation tools, DevOps engineers, DevOps teams, and/or DevOps certifications are <em>always</em> solutions to that problem.</li></ol>



<p>In a similar vein, the SRE philosophy has been corrupted by <strong>SRE as a Cult</strong>. The SRE cargo cult is based on the same flawed premise, and espouses SRE error budgets, SRE engineers, SRE teams, and SRE certifications as a panacea. Examples include Patrick Hill stating in <a rel="noreferrer noopener" href="https://www.atlassian.com/incident-management/devops/sre" target="_blank">Love DevOps? Wait until you meet SRE</a> that ‘SRE removes the conjecture and debate over what can be launched and when’, and the DevOps Institute offering <a rel="noreferrer noopener" href="https://devopsinstitute.com/certifications/sre-foundation/" target="_blank">SRE certification</a>.&nbsp;</p>



<p>SRE as a Cult ignores the central question facing the SRE philosophy – its applicability to IT as a Cost Centre. SRE originated from talented, opinionated software engineers in a single, unique organisation. Google has IT as a Business Differentiator as a core tenet. Using <a rel="noreferrer noopener" href="https://qualitysafety.bmj.com/content/13/suppl_2/ii22" target="_blank"><em>A Typology of Organisational Cultures</em></a> by Ron Westrum, its organisational culture can be described as generative. <em>Accelerate</em> found a generative culture is predictive of high performance IT, and less employee burnout.</p>



<figure><img loading="lazy" width="960" height="540" src="https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum.png" alt="" srcset="https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum.png 960w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum-300x169.png 300w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum-768x432.png 768w, https://www.stevesmith.tech/wp-content/uploads/2020/10/aim-for-operability-not-sre-as-a-cult-westrum-676x380.png 676w" sizes="(max-width: 960px) 100vw, 960px"></figure>



<p>There are fundamental challenges with applying SRE to an IT as a Cost Centre organisation with a bureaucratic or pathological culture. Product, Delivery, and Operations teams will be hindered by orthogonal incentives, funding pressures, and silo rivalries.&nbsp;</p>



<p>Availability levels are a leading indicator of cross-organisation support for SRE. When failure leads to scapegoating or justice:</p>



<ul><li>Heads of Product/Delivery/Operations might not agree 100% reliability is unachievable.</li><li>Heads of Product/Delivery/Operations might not accept an additional nine of reliability means an order of magnitude more engineering effort.&nbsp;</li><li>Heads of Delivery/Operations might not consent to availability levels being owned by product managers.</li></ul>



<p>Service Level Objectives are based on the risk tolerances of product managers. When responsibilities are shirked or discouraged:</p>



<ul><li>Product managers might decline to take on responsibility for service availability.</li><li>Product managers will need help from Delivery teams to uncover user expectations, calculate service revenue potential, and check competitor availability levels.</li><li>Sysadmins might object to developers wiring automated, fine-grained measurements into their own production alerts.&nbsp;</li></ul>



<p>Error budgets depend on shared agreements between different teams, without resorting to the inter-team battles of You Build It Ops Run It. When cooperation is modest or low:</p>



<ul><li>Product manager/developers/sysadmins might disagree on availability levels and the maths behind &nbsp;&nbsp;&nbsp; error budgets.</li><li>Heads of Product/Development might not accept a block on deployments when an error budget is 0%.</li><li>A Head of Operations might not accept deployments at all hours when an error budget is above 0%.</li><li>Product managers/developers might accuse sysadmins of blocking deployments unnecessarily</li><li>Sysadmins might accuse product managers/developers of jeopardising reliability</li><li>A Head of Operations might arbitrarily block production deployments</li><li>A Head of Development might escalate a block on production deployments</li><li>A Head of Product might override a block on production deployments</li></ul>



<p>You Build It SRE Run It means a central developer team supporting services with high availability levels and critical user traffic, while other developer teams support their own services under You Build It You Run It. It is worlds apart from You Build It Ops Run It. When bridging is merely tolerated or discouraged:</p>



<ul><li>A Head of Operations might not consent to on-call Delivery teams on their opex budget</li><li>A Head of Development might not consent to on-call Delivery teams on their capex budget</li><li>A Head of Operations might be unable to afford months of software engineering training for their sysadmins on an opex budget</li><li>Sysadmins might not want to undergo training, or be rebadged as SREs</li><li>Developers might not want to do on-call for their services, or be rebadged as SREs</li><li>Delivery teams will find it hard to collaborate with an Operations SRE team on errors and incident management</li><li>A Head of Operations might be unable to transfer an unreliable service back to the original Delivery team, if it was disbanded when its capex funding ended&nbsp;</li></ul>



<p>In <em>Site Reliability Engineering</em>, Ben Treynor Sloss identifies SRE recruitment as a significant challenge for Google. Developers are needed that excel in both software engineering and systems administration, which is rare. He counters this with the argument that an SRE team is cheaper than an Operations team, as the headcount is reduced by task automation. Recruitment challenges will be exacerbated in IT as a Cost Centre organisations, due to much smaller recruitment budgets. The touted headcount benefit is absurd, as salary rates are invariably higher for developers than sysadmins.&nbsp;</p>



<h3>Aim for Operability, not SRE as a Cult</h3>



<p>Continuous Delivery requires operational excellence. Reliable production services will minimise operational rework, and increase the throughput of feature delivery. There are many pathways to Operability, and SRE is only one of those pathways. SRE as a Cult will promote the world …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/">https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/</a></em></p>]]>
            </description>
            <link>https://www.stevesmith.tech/blog/aim-for-operability-not-sre-as-a-cult/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24846132</guid>
            <pubDate>Wed, 21 Oct 2020 09:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Does Julia Work So Well?]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24846033">thread link</a>) | @Tomte
<br/>
October 21, 2020 | https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia | <a href="https://web.archive.org/web/*/https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="-1" id="notebook">
    <div id="notebook-container">

<div>
<div>
<div>
<p>There is an obvious reason to choose Julia:</p>
<blockquote><p>it's faster than other scripting languages, allowing you to have the rapid development of Python/MATLAB/R while producing code that is as fast as C/Fortran</p>
</blockquote>
<p>Newcomers to Julia might be a little wary of that statement.</p>
<ol>
<li>Why not just make other scripting languages faster? If Julia can do it, why can't others? </li>
<li>How do you interpert Julia benchmarks to confirm this? (This is surprisingly difficult for many!)</li>
<li>That sounds like it violates the No-Free-Lunch heuristic. Is there really nothing lost?</li>
</ol>
<p>Many people believe Julia is fast <strong>because it is Just-In-Time (JIT) compiled</strong> (i.e. every statement is run using compiled functions which are either compiled right before they are used, or cached compilations from before). This leads to questions about what Julia gives over JIT'd implementations of Python/R (and MATLAB by default uses a JIT). These JIT compilers have been optimized for far longer than Julia, so why should we be crazy and believe that somehow Julia quickly out-optimized all of them? However, that is a complete misunderstanding of Julia. What I want show, in a very visual way, is that Julia is fast because of its design decisions. The core design decision, <strong>type-stability through specialization via multiple-dispatch</strong> is what allows Julia to be very easy for a compiler to make into efficient code, but also allow the code to be very concise and "look like a scripting language". This will lead to some very clear performance gains.</p>
<p>But what we will see in this example is that Julia does not always act like other scripting languages. There are some "lunches lost" that we will have to understand. Understanding how this design decision effects the way you must code is crucial to producing efficient Julia code.</p>
<p>To see the difference, we only need to go as far as basic math.</p>

</div>
</div>
</div>
<div>
<div>
<div>
<h2 id="Arithmetic-in-Julia">Arithmetic in Julia<a href="#Arithmetic-in-Julia">¶</a></h2><p>In general, math in Julia looks the same as in other scripting languages. One detail to note is that the numbers are "true numbers", as in a <code>Float64</code> is truly the same thing as a 64-bit floating point number or a "double" in C. A <code>Vector{Float64}</code> is the same memory layout as an array of doubles in C, both making interop with C easy (indeed, in some sense "Julia is a layer on top of C") and it leads to high performance (the same is true for NumPy arrays).</p>
<p>Some math in Julia:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[1]:</p>
<div>
    <div>
<div><pre><span></span><span>a</span> <span>=</span> <span>2</span><span>+</span><span>2</span>
<span>b</span> <span>=</span> <span>a</span><span>/</span><span>3</span>
<span>c</span> <span>=</span> <span>a÷3</span> <span>#\div tab completion, means integer division</span>
<span>d</span> <span>=</span> <span>4</span><span>*</span><span>5</span>
<span>println</span><span>([</span><span>a</span><span>;</span><span>b</span><span>;</span><span>c</span><span>;</span><span>d</span><span>])</span>
</pre></div>

</div>
</div>
</div>

<div>
<div>


<div>




<div>
<pre>[4.0, 1.33333, 1.0, 20.0]
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<p>Note here that I showed off Julia's unicode tab completion. Julia allows for unicode characters, and these can be used by tab completing Latex-like statements. Also, multiplication by a number is allowed without the * if followed by a variable. For example, the following is allowed Julia code:</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[2]:</p>
<div>
    <div>
<div><pre><span></span><span>α</span> <span>=</span> <span>0.5</span>
<span>∇f</span><span>(</span><span>u</span><span>)</span> <span>=</span> <span>α</span><span>*</span><span>u</span><span>;</span> <span>∇f</span><span>(</span><span>2</span><span>)</span>
<span>sin</span><span>(</span><span>2</span><span>π</span><span>)</span>
</pre></div>

</div>
</div>
</div>



</div>
<div>
<div>
<div>
<h2 id="Type-stability-and-Code-Introspection">Type-stability and Code Introspection<a href="#Type-stability-and-Code-Introspection">¶</a></h2><p>Type stability is the idea that there is only 1 possible type which can be outputtted from a method. For example, the reasonable type to output from <code>*(::Float64,::Float64)</code> is a <code>Float64</code>. No matter what you give it, it will spit out a <code>Float64</code>. This right here is multiple-dispatch: the <code>*</code> operator calls a different method depending on the types that it sees. When it sees floats, it will spit out floats. Julia provides code introspection macros so that way you can see what your code actually compiles to. Thus Julia is not just a scripting language, it's a scripting language which lets you deal with assembly! Julia, like many languages, compiles to LLVM (LLVM is a type of portable assembly language).</p>

</div>
</div>
</div>
<div>


<div>
<div>


<div>




<div>
<pre>; Function *
; Location: int.jl:54
define i64 @"julia_*_33751"(i64, i64) {
top:
  %2 = mul i64 %1, %0
  ret i64 %2
}
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<p>This output is saying that a floating point multiplication operation is performed and the answer is returned. We can even look at the assembly</p>
</div>
</div>
<div>


<div>
<div>


<div>




<div>
<pre>	.text
; Function * {
; Location: int.jl:54
	imulq	%rsi, %rdi
	movq	%rdi, %rax
	retq
	nopl	(%rax,%rax)
;}
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<div>
<p>This shows us that the <code>*</code> function has compiled down to exactly the same operation as what happens in C/Fortran, meaning it achieves the same performance (even though it's defined in Julia). Thus it is possible to not just get "close" to C, but actually get the same C code out. In what cases does this happen?</p>
<p>The interesting thing about Julia is that, asking which cases this happens is not the right question. the right question is, in what cases does the code not compile to something as efficient as C/Fortran? The key here is type-stability. If a function is type-stable, then the compiler can know what the type will be at all points in the function and smartly optimize it to the same assembly as C/Fortran. If it is not type-stable, Julia has to add expensive "boxing" to ensure types are found/known before operations.</p>
<h4 id="This-is-the-key-difference-between-Julia-and-other-scripting-languages">This is the key difference between Julia and other scripting languages<a href="#This-is-the-key-difference-between-Julia-and-other-scripting-languages">¶</a></h4><p>The upside is that Julia's functions, when type stable, are essentially C/Fortran functions. Thus <code>^</code> (exponentiation) is fast. However, <code>^(::Int64,::Int64)</code> is type-stable, so what type should it output?</p>

</div>
</div>
</div>


<div>
<div>
<p>Here we get an error. In order to guarantee to the compiler that <code>^</code> will give an Int64 back, it has to throw an error. If you do this in MATLAB, Python, or R, it will not throw an error. That is because those languages do not have their entire language built around type stability.</p>
</div>
</div>
<div>
<div>
<p>What happens when we don't have type stability? Let's inspect this code:</p>
</div>
</div>
<div>


<div>
<div>


<div>




<div>
<pre>	.text
; Function ^ {
; Location: intfuncs.jl:220
	pushq	%rax
	movabsq	$power_by_squaring, %rax
	callq	*%rax
	popq	%rcx
	retq
	nop
;}
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<p>Now let's define our own exponentiation on integers. Let's make it "safe" like the form seen in other scripting languages:</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[8]:</p>
<div>
    <div>
<div><pre><span></span><span>function</span> <span>expo</span><span>(</span><span>x</span><span>,</span><span>y</span><span>)</span>
    <span>if</span> <span>y</span><span>&gt;</span><span>0</span>
        <span>return</span> <span>x</span><span>^</span><span>y</span>
    <span>else</span>
        <span>x</span> <span>=</span> <span>convert</span><span>(</span><span>Float64</span><span>,</span><span>x</span><span>)</span>
        <span>return</span> <span>x</span><span>^</span><span>y</span>
    <span>end</span>
<span>end</span>
</pre></div>

</div>
</div>
</div>

<div>
<div>


<div>

<p>Out[8]:</p>




<div>
<pre>expo (generic function with 1 method)</pre>
</div>

</div>

</div>
</div>

</div>
<div>
<div>
<p>Let's make sure it works:</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[9]:</p>
<div>
    <div>
<div><pre><span></span><span>println</span><span>(</span><span>expo</span><span>(</span><span>2</span><span>,</span><span>5</span><span>))</span>
<span>expo</span><span>(</span><span>2</span><span>,</span><span>-</span><span>5</span><span>)</span>
</pre></div>

</div>
</div>
</div>



</div>
<div>
<div>
<p>What happens if we inspect this code?</p>
</div>
</div>
<div>


<div>
<div>


<div>




<div>
<pre>	.text
; Function expo {
; Location: In[8]:2
	pushq	%rbx
	movq	%rdi, %rbx
; Function &gt;; {
; Location: operators.jl:286
; Function &lt;; {
; Location: int.jl:49
	testq	%rdx, %rdx
;}}
	jle	L36
; Location: In[8]:3
; Function ^; {
; Location: intfuncs.jl:220
	movabsq	$power_by_squaring, %rax
	movq	%rsi, %rdi
	movq	%rdx, %rsi
	callq	*%rax
;}
	movq	%rax, (%rbx)
	movb	$2, %dl
	xorl	%eax, %eax
	popq	%rbx
	retq
; Location: In[8]:5
; Function convert; {
; Location: number.jl:7
; Function Type; {
; Location: float.jl:60
L36:
	vcvtsi2sdq	%rsi, %xmm0, %xmm0
;}}
; Location: In[8]:6
; Function ^; {
; Location: math.jl:780
; Function Type; {
; Location: float.jl:60
	vcvtsi2sdq	%rdx, %xmm1, %xmm1
	movabsq	$__pow, %rax
;}
	callq	*%rax
;}
	vmovsd	%xmm0, (%rbx)
	movb	$1, %dl
	xorl	%eax, %eax
; Location: In[8]:3
	popq	%rbx
	retq
	nopw	%cs:(%rax,%rax)
;}
</pre>
</div>
</div>

</div>
</div>

</div>
<div>
<div>
<p>That's a very visual demonstration on why Julia achieves such higher performance than other scripting languages by how it uses type inference.</p>
</div>
</div>
<div>
<div>
<div>
<p>Type stability is one crucial feature which separates Julia apart from other scripting languages.  In fact, the core idea of Julia is the following statement:</p>
<h4 id="Multiple-dispatch-allows-for-a-language-to-dispatch-function-calls-onto-type-stable-functions.">Multiple dispatch allows for a language to dispatch function calls onto type-stable functions.<a href="#Multiple-dispatch-allows-for-a-language-to-dispatch-function-calls-onto-type-stable-functions.">¶</a></h4><p>This is what Julia is all about, so let's take some time to dig into it.If you have type stability inside of a function (meaning, any function call within the function is also type-stable), then the compiler can know the types of the variables at every step. Therefore it can compile the function with the full amount of optimizations since at this point the code is essentially the same as C/Fortran code.  Multiple-dispatch works into this story because it means that <code>*</code> can be a type-stable function: it just means different things for different inputs. But if the compiler can know the types of <code>a</code> and <code>b</code> before calling <code>*</code>, then it knows which <code>*</code> method to use, and therefore it knows the output type of <code>c=a*b</code>. Thus it can propogate the type information all the way down, knowing all of the types along the way, allowing for full optimiziations. Multiple dispatch allows <code>*</code> to mean the "right thing" every time you use it, almost magically allowing this optimization.</p>
<p>There are a few things we learn from this. For one, in order to achieve this level of optimization, you must have type-stability. This is not featured in the standard libraries of most languages, and was choice that was made to make the experience a little easier for users. Secondly, multiple dispatch was required to be able to specialize the functions for types which allows for the scripting language syntax to be "more explicit than meets the eye". Lastly, a robust type system is required. In order to build the type-unstable exponentiation (which may be needed) we needed functionalities like convert. Thus the language must be designed to be type-stable with multiple dispatch and centered around a robust type system in order to achieve this raw performance while maintaining the syntax/ease-of-use of a scripting language. You can put a JIT on Python, but to really make it Julia, you would have to design it to be Julia.</p>

</div>
</div>
</div>
<div>
<div>
<div>
<h2 id="The-Julia-Benchmarks">The Julia Benchmarks<a href="#The-Julia-Benchmarks">¶</a></h2><p>The Julia benchmarks, featured on <a href="http://julialang.org/">the Julia website</a>, test components of the programming language for speed. <strong>This doesn't mean it's testing the fastest implemention</strong>. That is where a major misconception occurs. You'll have an R programmer look at the R code for the Fibonacci calculator and say "wow, that's terrible R code. You're not supposed to use recursion in R. Of course it's slow". However, the Fibonacci problem is designed to test recursion, not the fastest implementation to the the ith Fibonacci number. The other problems are the same way: testing basic components of the langauge to see how fast they are.</p>
<p>Julia is built up using multiple-dispatch on type-stable …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia">https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia</a></em></p>]]>
            </description>
            <link>https://ucidatascienceinitiative.github.io/IntroToJulia/Html/WhyJulia</link>
            <guid isPermaLink="false">hacker-news-small-sites-24846033</guid>
            <pubDate>Wed, 21 Oct 2020 09:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Flat SVG Designs – Free Vector(SVG) Icons and Illustrations]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24845908">thread link</a>) | @seuyu_bin
<br/>
October 21, 2020 | https://flat-svg-designs.net/en/ | <a href="https://web.archive.org/web/*/https://flat-svg-designs.net/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to FLAT SVG DESIGNS!</p><p>Free vector(SVG) icons and illustrations with flat design.</p></div></div>]]>
            </description>
            <link>https://flat-svg-designs.net/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845908</guid>
            <pubDate>Wed, 21 Oct 2020 08:36:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS and their Billions in IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24845464">thread link</a>) | @tomklein
<br/>
October 21, 2020 | https://toonk.io/aws-and-their-billions-in-ipv4-addresses/ | <a href="https://web.archive.org/web/*/https://toonk.io/aws-and-their-billions-in-ipv4-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>Earlier this week, I was doing some work on AWS and wanted to know what IP addresses were being used. Luckily for me, AWS publishes this all here <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="nofollow noopener">https://ip-ranges.amazonaws.com/ip-ranges.json</a>. When you go through this list, you’ll quickly see that AWS has a massive asset of IPv4 allocations. Just counting quickly I noticed a lot of big prefixes.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Ever wondered what all of the AWS network ranges are? You can find them all here:<a href="https://t.co/NBaBF6w0la">https://t.co/NBaBF6w0la</a><br>That's *a lot* of big prefixes!<br>4x /11, 14x /12, 30x /13, 78x /14, 184x /15, 278x /16</p>— Andree Toonk, Adelante! (@atoonk) <a href="https://twitter.com/atoonk/status/1316098702260359168?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

</figure><p>However, the IPv4 ranges on that list are just the ranges that are in use and allocated today by AWS. Time to dig a bit deeper.</p><h3 id="ipv4-address-acquisitions-by-aws">IPv4 address acquisitions by AWS</h3><p>Over the years, AWS has acquired a lot of IPv4 address space. Most of this happens without gaining too much attention, but there were a few notable acquisitions that I’ll quickly summarize below.</p><h4 id="2017-mit-selling-8-million-ipv4-addresses-to-aws">2017: MIT selling 8 million IPv4 addresses to AWS</h4><p>In 2017 <a href="https://www.internetsociety.org/blog/2017/05/mit-goes-on-ipv4-selling-spree/" rel="noopener">MIT sold half of its 18.0.0.0/8</a> allocation to AWS. This 18.128.0.0/9 range holds about 8 million IPv4 addresses.</p><h4 id="2018-ge-sells-3-0-0-0-8-to-aws">2018: GE sells 3.0.0.0/8 to AWS</h4><p>In 2018 the IPv4 prefix 3.0.0.0/8 was transferred from GE to AWS. With this, AWS became the proud owner of its first /8! That’s sixteen million new IPv4 addresses to feed us hungry AWS customers. <a href="https://news.ycombinator.com/item?id=18407173" rel="nofollow noopener">https://news.ycombinator.com/item?id=18407173</a></p><h4 id="2019-aws-buys-amprnet-44-192-0-0-10">2019: AWS buys AMPRnet 44.192.0.0/10</h4><p>In 2019 AWS bought a /10 from AMPR.org, the Amateur Radio Digital Communications (ARDC). The IPv4 range 44.0.0.0/8 was an allocation made to the Amateur Radio organization in 1981 and known as the AMPRNet. This sell caused a fair bit of discussion, check out the <a href="https://mailman.nanog.org/pipermail/nanog/2019-July/thread.html#102103" rel="noopener">nanog discussion here.</a></p><p>Just this month, it <a href="http://www.southgatearc.org/news/2020/october/sale-of-amateur-radio-amprnet-tcp-ip-addresses.htm" rel="noopener">became public knowledge</a> AWS paid $108 million for this /10. That’s $25.74 per IP address.</p><p>These are just a few examples. Obviously, AWS has way more IP addresses than the three examples I listed here. The IPv4 transfer market is very active. Check out this website to get a sense of all transfers: <a href="https://account.arin.net/public/transfer-log#NRPM-8.3IPv4" rel="noopener">https://account.arin.net/public/transfer-log</a></p><h3 id="all-aws-ipv4-addresses">All AWS IPv4 addresses</h3><p>Armed with the information above it was clear that not all of the AWS owned ranges were in the <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">JSON</a> that AWS published. For example, parts of the 3.0.0.0/8 range are missing. Likely because some of it is reserved for future use.</p><p>Combining all those IPv4 prefixes, removing duplicates and overlaps by aggregating them results in the following list of unique IPv4 address owned by AWS: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes</a></p><p>The total number of IPv4 addresses in that list is just over 100 Million (100,750,168). That’s <strong>the equivalent of just over six /8’s,</strong> not bad!</p><p>If we break this down by allocation size, we see the following:</p><pre><code>1x /8     =&gt; 16,777,216 IPv4 addresses
1x /9     =&gt; 8,388,608 IPv4 addresses
4x /10    =&gt; 16,777,216 IPv4 addresses
5x /11    =&gt; 10,485,760 IPv4 addresses
11x /12   =&gt; 11,534,336 IPv4 addresses
13x /13   =&gt; 6,815,744 IPv4 addresses
34x /14   =&gt; 8,912,896 IPv4 addresses
53x /15   =&gt; 6,946,816 IPv4 addresses
182x /16  =&gt; 11,927,552 IPv4 addresses
&lt;and more&gt;</code></pre><p>A complete breakdown can be found here: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size</a></p><h3 id="putting-a-valuation-on-aws-ipv4-assets">Putting a valuation on AWS’ IPv4 assets</h3><blockquote>Alright.. this is just for fun…</blockquote><p>Since AWS is (one of) the largest buyers of IPv4 addresses, they have spent a significant amount on stacking up their IPv4 resources. It’s impossible, as an outsider, to know how much AWS paid for each deal. However, we can for fun, try to put a dollar number on AWS’ current IPv4 assets.</p><p>The average price for IPv4 addresses has gone up over the years. From ~$10 per IP a few years back to ~$25 per IP <a href="https://auctions.ipv4.global/" rel="noopener">nowadays</a>. <br>Note that these are market prices, so if AWS would suddenly decide to sell its IPv4 addresses and overwhelm the market with supply, prices would drop. But that won’t happen since we’re all still addicted to IPv4 ;)</p><p>Anyway, let’s stick with $25 and do the math just for fun.</p><pre><code>100,750,168 ipv4 addresses x $25 per IP = $2,518,754,200</code></pre><p>Just<strong> over $2.5 billion worth of IPv4 addresses,</strong> not bad! </p><h3 id="peeking-into-the-future">Peeking into the future</h3><p>It’s clear AWS is working hard behind the scenes to make sure we can all continue to build more on AWS. One final question we could look at is: <em>how much buffer does AWS have?</em> ie. how healthy is their IPv4 reserve?</p><p>According to their <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="noopener">published data</a>, they have allocated roughly 53 Million IPv4 addresses to existing AWS services. We found that all their IPv4 addresses combined equates to approximately 100 Million IPv4 addresses. That means they still have ~47 Million IPv4 addresses, or 47% available for future allocations. That’s pretty healthy! And on top of that, I’m sure they’ll continue to source more IPv4 addresses. The IPv4 market is still hot!</p></div>
    </div></div>]]>
            </description>
            <link>https://toonk.io/aws-and-their-billions-in-ipv4-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845464</guid>
            <pubDate>Wed, 21 Oct 2020 07:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What ORMs Have Taught Me: Just Learn SQL (2014)]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 282 (<a href="https://news.ycombinator.com/item?id=24845300">thread link</a>) | @IA21
<br/>
October 20, 2020 | https://wozniak.ca/blog/2014/08/03/1/ | <a href="https://web.archive.org/web/*/https://wozniak.ca/blog/2014/08/03/1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>
I’ve come to the conclusion that, for me, ORMs are more detriment than
benefit. In short, they can be used to nicely augment working with SQL
in a program, but they should not replace it.
</p>

<p>
Some background: For the past 30 months I’ve been working with code
that has to interface with Postgres and to some extent, SQLite. Most
of that has been with <a href="http://sqlalchemy.org/">SQLAlchemy</a> (which I quite like) and <a href="http://hibernate.org/">Hibernate</a>
(which I don’t). I’ve worked with existing code and data models, as
well as designing my own. Most of the data is event-based storage
(“timelines”) with a heavy emphasis on creating reports.
</p>

<p>
Much has been written about the Object/Relational Impedance
Mismatch. It’s hard to appreciate it until you live it. Neward, in his
<a href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/">well known essay</a>, lays out many cogent reasons why ORMs turn into
quagmires. In my experience, I’ve had to deal directly with a fair
number of them: <i>entity identity issues</i>, <i>dual-schema problem</i>, <i>data
retrieval mechanism concern</i>, and the <i>partial-object problem</i>. I want to
talk briefly about my experiences with these issues and add one of my
own.
</p>

<div id="outline-container-orge4f50a6">
<h2 id="orge4f50a6">Partial objects, attribute creep, and foreign keys</h2>
<div id="text-orge4f50a6">
<p>
Perhaps the most subversive issue I’ve had with ORMs is “attribute
creep” or “wide tables”, that is, tables that just keep accruing
attributes. As much as I’d like to avoid it, sometimes it becomes
necessary (although things like <a href="http://www.postgresql.org/docs/9.3/interactive/hstore.html">Postgres’ hstore</a> can help). For
example, a client may be providing you with lots of data that they
want attached to reports based on various business logic. Furthermore,
you don’t have much insight into this data; you’re just schlepping it
around.
</p>

<p>
This in and of itself isn’t a terrible thing in a database. It becomes
a real pain point with an ORM. Specifically, the problem starts to
show up in any query that uses the entity directly to create the
query. You may have a Hibernate query like so early on in the project.
</p>

<pre>query(Foo.class).add(Restriction.eq("x", value))
</pre>

<p>
This may be fine when Foo has five attributes, but becomes a data fire
hose when it has a hundred. This is the equivalent of using <code>SELECT
*</code>, which is usually saying more than what is intended. ORMs, however,
encourage this use and often make writing precise projections as
tedious as they are in SQL. (I have optimized such queries by adding
the appropriate projection and reduced the run time from minutes to
seconds; all the time was spent translating the database row into a
Java object.)
</p>

<p>
Which leads to another bad experience: the pernicious use of foreign
keys. In the ORMs I’ve used, links between classes are represented in
the data model as foreign keys which, if not configured carefully,
result in a large number of joins when retrieving the object. (A
recent count of one such table in my work resulted in over 600
attributes and 14 joins to access a single object, using the preferred
query methodology.)
</p>

<p>
Attribute creep and excessive use of foreign keys shows me is that in
order to use ORMs effectively, you still need to know SQL. My
contention with ORMs is that, if you need to know SQL, just use SQL
since it prevents the need to know how non-SQL gets translated to SQL.
</p>
</div>
</div>

<div id="outline-container-org2d7e33d">
<h2 id="org2d7e33d">Data retrieval</h2>
<div id="text-org2d7e33d">
<p>
Knowing how to write SQL becomes even more important when you attempt
to actually write queries using an ORM. This is especially important
when efficiency is a concern.
</p>

<p>
From what I’ve seen, unless you have a really simple data model (that
is, you never do joins), you will be bending over backwards to figure
out how to get an ORM to generate SQL that runs efficiently. Most of
the time, it’s more obfuscated than actual SQL.
</p>

<p>
And if you elect to keep the query simple, you end up doing a lot of
work in the code that could be done in the database faster. <a href="https://en.wikipedia.org/wiki/Window_function_%28SQL%29#Window_function">Window
functions</a> are relatively advanced SQL that is painful to write with
ORMs. Not writing them into the query likely means you will be
transferring a lot of extra data from the database to your
application.
</p>

<p>
In these cases, I’ve elected to write queries using a templating
system and describe the tables using the ORM. I get the convenience of
an application level description of the table with direct use of
SQL. It’s a lot less trouble than anything else I’ve used so far.
</p>
</div>
</div>

<div id="outline-container-org05d550b">
<h2 id="org05d550b">Dual schema dangers</h2>
<div id="text-org05d550b">
<p>
This one seems to be one of those unavoidable redundancies.  If you
try to get rid of it, you only make more problems or add excessive
complexity.
</p>

<p>
The problem is that you end up having a data definition in two places:
the database and your application.  If you keep the definition
entirely in the application, you end up having to write the SQL Data
Definition Language (DDL) with the ORM code, which is the same
complication as writing advanced queries in the ORM.  If you keep it
in the database, you will probably want a representation in the
application for convenience and to prevent too much “string typing”.
</p>

<p>
I much prefer to keep the data definition in the database and read it
into the application.  It doesn’t solve the problem, but it makes it
more manageable.  I’ve found that reflection techniques to get the
data definition are not worth it and I succumb to managing the
redundancy of data definitons in two places.
</p>

<p>
But the damn migration issue is a real kick in the teeth: changing the
model is no big deal in the application, but a real pain in the
database.  After all, databases are persistent whereas application
data is not.  ORMs simply get in the way here because they don’t help
manage data migration at all.  I work on the principle that the
database’s data definitions aren’t things you should manipulate in the
application.  Instead, manipulate the results of queries.  That is,
the queries are your API to the database.  So instead of thinking
about objects, I think about functions with return types.
</p>

<p>
Thus, one is forced to ask, should you use an ORM for anything but
convenience in making queries?
</p>
</div>
</div>

<div id="outline-container-org7033826">
<h2 id="org7033826">Identities</h2>
<div id="text-org7033826">
<p>
Dealing with entity identities is one of those things that you have to
keep in mind at all times when working with ORMs, forcing you to write
for two systems while only have the expressivity of one.
</p>

<p>
When you have foreign keys, you refer to related identities with an
identifier. In your application, “identifier” takes on various
meanings, but usually it’s the memory location (a pointer). In the
database, it’s the state of the object itself. These two things don’t
really get along because you can really only use database identifiers
in the database (the ultimate destination of the data you’re working
with).
</p>

<p>
What this results in is having to manipulate the ORM to get a database
identifier by manually flushing the cache or doing a partial commit to
get the actual database identifier.
</p>

<p>
I can’t even call this a leaky abstraction because the work “leak”
implies small amounts of the contents escaping relative to the source.
</p>
</div>
</div>

<div id="outline-container-orgddbdda4">
<h2 id="orgddbdda4">Transactions</h2>
<div id="text-orgddbdda4">
<p>
Something that Neward alludes to is the need for developers to handle
transactions. Transactions are dynamically scoped, which is a powerful
but mostly neglected concept in programming languages due to the
confusion they cause if overused.  This leads to a lot of boilerplate
code with exception handlers and a careful consideration of where
transaction boundaries should occur.  It also makes you pass session
objects around to any function/method that might have to communicate
with the database.
</p>

<p>
The concept of a transaction translates poorly to applications due to
their reliance on context based on time. As mentioned, dynamic scoping
is one way to use this in a program, but it is at odds with lexical
scoping, the dominant paradigm. Thus, you must take great care to know
about the “when” of a transaction when writing code that works with
databases and can make modularity tricky (“Here’s a useful function
that will only work in certain contexts”).
</p>

<p>
Where do I see myself going?
</p>

<p>
At this point, I’m starting to question the wisdom behind the outright
rejection of <a href="http://c2.com/cgi/wiki?StoredProcedures">stored procedures</a>.  It sounds <a href="http://c2.com/cgi/wiki?StoredProceduresAreEvil">heretical</a>, but it may work
for my use cases.  (And hey, with the advent of “devops”, the divide
between the developer and the database administrator is basically
non-existent.)
</p>

<p>
I’ve found myself thinking about the database as just another data
type that has an API: the queries.  The queries return values of some
type, which are represented as some object in the program. By moving
away from thinking of the objects in my application as something to be
stored in a database (the raison d’être for ORMs) and instead thinking
of the database as a (large and complex) data type, I’ve found working
with a database from an application to be much simpler. And wondering
why I didn’t see it earlier.
</p>

<p>
(It should be made clear that I am not claiming this is how all
applications should deal with a database.  All I am saying is that
this fits my use case based on the data I am working with.)
</p>

<p>
Regardless of whether I find that stored procedures aren’t actually
that evil or whether I keep using templated SQL, I do know one thing:
I won’t fall into the “ORMs make it easy” trap. They are an acceptable
way to represent a data definition, but a poor way to write queries
and a bad way to store object state. If you’re using an RDBMS, bite
the bullet and learn SQL.
</p>

<p>
August 03, 2014
</p>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://wozniak.ca/blog/2014/08/03/1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845300</guid>
            <pubDate>Wed, 21 Oct 2020 06:37:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GitHub for Learning]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24844734">thread link</a>) | @IvanVLiu
<br/>
October 20, 2020 | https://astrasum.com/subject/1 | <a href="https://web.archive.org/web/*/https://astrasum.com/subject/1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://astrasum.com/subject/1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844734</guid>
            <pubDate>Wed, 21 Oct 2020 04:26:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Diablo (Pitch from 1994) (2016) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24844666">thread link</a>) | @tosh
<br/>
October 20, 2020 | http://www.graybeardgames.com/download/diablo_pitch.pdf | <a href="https://web.archive.org/web/*/http://www.graybeardgames.com/download/diablo_pitch.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div �oe="">€öŒA]øýçÏ‰9_ÝŒGƒÀà«ÛOlF•t|ífl5µÞæ"8²36%vLFÔn¸’ÖÞY‰Ò-ßËÖ¢§¼ù€‘2ož™›;^0YÐnÙ°ž@3GnÖ?ñ$†S;\«ÊÚ€éŸ¾˜ø"#¸ù©ƒ &lt;†¸‰´(ØF‘F%}EBì™C‘ÆäS P|î}0&nbsp;‘¬š£]*Cgqg"}ºaÃpË•2™g!ÖFò¥Ûæ$ôjHä‹T�oôÓöM2Ñ¥k»o-WÎ
Šïû´&amp;9|ÄýÞ$a°¨õ±5¬Úáû¼öIa$köƒŒÞ:ü�Á;“(2N3¶€Óë.š“¥ÅƒØ´Ž¶¸9¹*7�œFÛß
ƒd€©©j¬gŠTþ×ûºFPØù@e÷•ÿT“þµ„¢Pû�0H%’;uM@	ô«‘µ´òÃyE�2%Ï•TWRÈÇ~âÜgc|ÊGˆBMÅOìá�Yw”ÜU&gt;XÜ% ÂpË»8¡–s¥“®H²\I¨* ±láòOÌYSË;”¤n“€"K¨Ê·Sj�:AqnÇd HÜð’±îÆÀy"ª$håÄšäƒ‹ÂIòÔåÊyì&lt;àL!”mC�à×–vÒY•§gV™™¶"ÙŒJÃ/…o1ª*1Ž1¤À‡Bß±É2:ê@Á\ôÜ7dÝç}ÖÁÀÎ/'�zË¥Zo«BÒ}¢ïÍ(eT'*$_ßK¿åb¬¿.Ìã‚W'Q·#O�ìÿd¶ctâl5Ç#qeÈó`Íƒœ†ÇÈ¦ÇŸ¡Z!hbKy$e½�íYB™
ŒCoîí’R@9»¢Õ"¾ÍhÖ–ùà¦w`#`‘Ábs€FJ/J‹t’ê°ùV0ÉŸl'oœîô§;CJ–fLüÁ@!oÚm9®X-ŸÚ€þY*A+¸¨
FÆRažxo˜êJ––Íoäf×$yÄ0$¬{@*Ã†¢}ïï3ƒÄ�ýªØIö‚‚ÄÇ•
cûûsœ$�”(p ü�GözEq{¸´ž)…¼~y_ÌWÚFy
Å·‘½qDð½‚˜ï£K™®mã6ò´äˆPä+\¸ÉU]˜©5Å§bô%­ÊÝ$Á­ðO“óeydÇð¥7rwÓ—¥ÄÑ/ÙnÅÜL˜.Öå²;«ŒüÃ²ž›XJHŸM™êRÍÛÃ;³#a07lÝŽ&nbsp;œîËt%™»M"éÖÈ‘ß$“	.ÅÃ�7ïî\à}à@îN9sUyDV…´ÝÖ²Å#Æ~Ø±³Ôì$+ç`r£w%ÔœŸ•¬±Ë·N&amp;Ý$ÿJÚÃÌœ³
Û”ðÿÏR@1äA--ZÞÝÌìnùûv†ã,O!ÚsŒáW3K‘%åº$ÖþG�jnt&nbsp;0|&nbsp;�zpA'fæâ«y‹~‹†&gt;ÍáÄeZR1€Ä™Ïð’˜‘“ƒ$’Ç¨o¹?e·6éÛp¤yø8ùGÌX°áðyw`ô3,$ÿiù1?;gØþÐá·yx$ƒŒüÄõþlæ«É°ªÜ¨ò¡¹2ˆÕ$ß±wdÆÄsÂ•0€É«KržiÔØZ¤‹(_±yL^Ýû;`ò‡$ƒòš%bL\«DÍ9—t
¬¢/˜àq�”nÌxl¼Rn9‚§Ó£
úb¾gœíŒôíƒœ`ä`ó×ùúb„ ¢Š)€QEQEQEQERc&gt;Ô´PIKF)QŠJZJ)i(¤—¥ÐÒf–Š(¢’˜Eb�QLŠ(&nbsp;Š(&nbsp;Š(&nbsp;Š(#4QEQEQEQES§ãO¦IÓñ¤¨¤Pm+S(z(¢˜Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@yïÄ0�on²¨gä¨Éâ7ÁÁ ÄƒŒã½zy¿ÄV";QŽ&lt;×ç¾vp3èrr;àzPžÉp/"X/¦e†Ú	¸)Ãav¦UAù¶€]ò^H'5zâyîåûN£$ÑêQ,&amp;É&gt;Î?zw–N~|õÀÉà1IhÕÎÔÆÞXF
Ÿ”œƒ•Ê0OPEk\A-´­m¨¤òj²ù?c“íü²\…ËoùNüã%ùäl; Îºk¿µ™$ÚËµmÍ¿XÌXÎØÂsœ&nbsp;¶:=2Ê[ËyÍÎžòKªMö�µEägË`$Ÿ—nK<p­„!~ëh-nÇØöÌuÁ6~ÑçŸõbÛwù˜ÎÎ:go‰ùj+k{»©m¶ž²Åªb'7r‹‚ ˜�="" Ý·!±œ¬~bn2°x-Ÿûydi`s¨³f¸‹!ºn]ß*™rp±À,öžx‚ÄñiòÈú#Éº�ã]ÊÛ“pæ5‘¶�="" ©Œœ‚iŽÞÛí¶ît¥{dµ„h="¿Ò08" v·="" 'urtuµ,="" yêr´zd‚âÑ¥‘="" Ì¥c´3¡Ê²="" –s…€tÚ¬©o,³="" \1Žs�É![!–-¹3´ƒÉ*0pvÛçÅ:”²Åd‘ÌÖŒ!Îã¸=""  ÉÏ,ß(�¡ÃuÇ€$1êŒ„èï+*Ù-ÄÄ£m‘71à.\$6pázukhâ¸¿ŠiìçiþÉÚî¾u#6s="" ²–—2is“u’xî#·ŒÙ¯•þ±k1°€môc‚sœ’¥zyä¸3<÷2lºÊmŽ1="" à�£i!s±Œ="" ;²£km•®m›o="" j6¸ž[x¾Èþ{~åim ="" •*�‡="" �‡="" ¾¦žÖx.Îu’]u¥‹dÿ�hÎ¨ùˆÉ<a™�_—Ã="" o,þrÏló�eæ›Ì�Ê@…mÇ="" ¡wc="" ©)mrªyömp›[eye¾–)zõz(ðŸ2�ª6à�Ý8�);dÁq="ÂÚÛ¬‘ê‹,¾d¿h" ±ÃÉ…*7e•Žñœî$�¶pËª•�kÒæ+wk™mË�;”ÝŸîå²h8\·Î~phÁ·ysc–i´³âu¨bêûd‘¡Èˆ˜ÔãfÀ­¹qd‚Ýî†÷ù²yj[vØ‹dì`¸à»ò³¹ˆ¿mi®4ÈžÖÎÞ8þÕÚ\�fÎn~l¡`à�p2ÁjÄ±="üQlÒÒáZ}¥¹rŠ�Üœ‚[ï(8_‘" v!¾{¼qÛnÓ�%&�Â|•'þz!‚¨g;Îåß…Üh(É¦i"rk…hm×ì;#eùz&æÂ³gÂàòÇæ!³ÃÎ#6ðgq›¦m4¾]¯Ú\l?8\ñÕvœ8Ë="">|nŠtû _Eö“ul�jÞ{�³¡Ý´`Œ­·îü¸î| -Üý§í÷¦í¡$gUHv�T¶ÐP‘ÈÇ;s¸o
¡®–ì4fíã3]�y{|²		Ùƒ»…Á$tV1ÜÛËkpÖ)æêo,,—Ÿi“)‘Ñ’Ê€Fâr»�
¹žÚÎi®×L@`Õäi/~Ñ#3�¬Jü£‚T¨ÎsòœŒ±Àm‡Úä—þ$ípÚ‹¤¦óÌª‚Î¹Ú_�óçœï8ÈÊ…´Œ¬r
!§6&gt;Z
H¸„0P~Íß7™8AœŽ­š[µ2ltÐ–7VŠëq0žOß�Á_”BJï]ÛI*«ÈúºIy§D–vvhêÙet
¡�”ùqímÈ¬Ÿ0ã&lt;äò¬öc3ø{zùøòD‚C³¦à%Ç™åŽ1�8¨eÇ•\Ÿì!#ý˜¢Å¼°Ô•Ë&gt;ð#¦á+Ý‰ã:¬QFšdr*I`&amp;(®ø;F±ˆú”nA'fH#8Î\(º„ÑG5ŒÒÊ#²[—&amp;9ä€¼/P ®@E&gt;}þTcV7&gt;@€ý„*Ä88Û»žr9|mÁ·6î
×ž§T?Ú„DÖ!|‚¡·/xû£÷€eH©`Iªªiñ¤·IÒ\ÂÞB†-oÎ@a�áÝ÷s‚Crjšæb~Åv‘\Ý\¬^M×ÚXˆTáW’8×‚å—†j†¹70›þ5?+~ãË(Ppy0àCžÁ·‘ß¤ÑÉtÎF–’.¶3ö×&gt;NÆù†ŒYßåíò”erMe•xä:Aû:ß™·ý¼ÌrÐÛ|Ížg lûÝNÝ»ŽjŠ=E…‚ý–Þâ×Ìóoà�9æÚî'pÉc�ØzÜË)oìU¸“þ&amp;!Ì[[ûÅ7·Þ?½åJœcn&gt;j»É$m&amp;�‘h+‘w)½œ¾ÒîÒà¡‰NÇ^Ç9Ï/s$7È¢aµE‰16
Æ
ç®ÝÄã!Fæ9'qÀÅóuÃ›Øc‚ÞÖÜÅ¾ÃÎÇÚ
Ÿ½´¦×&lt;�Ä§AÎNIC5ä‘DBfŽgðàû‘nMûó´c÷‚m¾nHøöÆQ›*¾¨·gL}ÆÅÄ]zl$È
‡$Ž�GZÂ{x%þ×h¬Þb£OóAdÊ•ÜP¡P27}Ìr6�ÁG-¾–~Ù,v—ive¸�±·Ür7
§n3�Üàá”ŒÐëÉ7™Ö–yoåÇØ
”G’63lt‹ãvõn&gt;×¤IÄëÒ´šû)kyÕ”D¨7c 2ÆQ  ÄI'¾Es1­¶Ž¦ÚU´»kÐ»fû6xË
ŒÊW;‰R¹Ç$â¬`�±åkI¥—‘¨ù�„j~m»Ê’·E8ëÉÛT¸–v‚Ù]5äP×ëå”ùs�½“ÀÆ:M�æG�EIa¼‰±~Ï*âSóÛ™$‹†ÚÊ.zŒŒgF-®q¥y–¶�n2ÚˆeÌÞÈØL“¸S�¾Ø«ñ,:Ã#û=‰±92ÇŒ]ã#‚&lt;¿‘°Ke¤ÎáÁ�C­Ö)Õ¦Ò’H4ØËèžOšL`¶ÜÉ!¯‡MÃ�ïb7„Û}±Wn‚¨GÙzÊ_¦î§ø½fíŸz‚!o«bùbŽÉm¡m]·8³Ò0sÓý[ò*ô
dÿ‰ÊÂCyEL	“ÁÀqÇB0Ùús@Éw$Q¥ÍçïtÉÚ!en«ûÈ�ˆÚX|¸
3ŸÞ7\œ
’X¤µ‘`ÔÚ/§wûÊ…–ÇŽ‚9&lt;&lt;ú
Ñ�'±c©,w=ç–�lÿG
Ôãîº1ÉlH°�I§fŸi¹K¶�ÉpdÉƒ#�Ð…Çnƒ&lt;ŸJ?¯ÀJâÅÌ‹`ìï­²–[µy:ãz�x_—2Ô�Xïkpóý†ÝY5(�3Üý­Çš:¼Aàãƒ�Èôëî­&lt;˜¿±¿~m¤Vw¿vÊ©$¶°Œà¸úW#ws…ÒÝía·€—¦2¢b£ß»i$œÎ	Ç âV¹4ô{S
ÿ¥¶&amp;LŒç
Ðcœê�áòÖŸ{sxxG$à¶~`@y/ âºy˜Ä�ghlÐmÂm7ÜnÃ·Ê9ÆIn:\ýÝØ:„Ÿd·¸ƒý]—Ùð&amp;œ”.îÉÂõ�
±&nbsp;½xIÒØñmö³�ßw8CsÓ8ÆxæŒCfâö´ZÏŸ³Ãö¦ÌY$ŒàñÀÁ÷íž�#_íHþÊ÷lv�?ìç
1´�‚BãçÎÐ:óÆ(FKö»Sow5ÇúØ&gt;ÌÄ[†ä�7m#o*
G*ý�lè.æ�ÑœÝ¾ &nbsp;ô3�—Ðæ–KsŸaœ	u'å.þØÛTƒŸ@^y˜«
‘i¿èÐImwçúéÌ;¾ÍŸ£�¸Î~bÇ b�äEl?²kw³�e¯„¶±çfñ!NÝw9är(¡’I&gt;Åj‚F&gt;^íoo�Û‘�Á=	Àæ�-o÷%Š­³@3títøœŒÌAA?Ž20*7µ‚SýŸ$–ñZÅÊ_b§Û¼&gt;'{Ÿ|T¾";£ob¶Ã0È-Y~ÓŽw0Ýœg§Rxæ�ëòa½îÖ(à³ƒý}¹ºpfõÇ~s�ÀöÉ4·Xÿ´LQ&lt;ü¿aRoÝýãòúóŽ£§NiK­èûtíomsoÄV¢Ø�0‚Wv[wû¤œa&gt;Ðÿiƒ	¾?)±û+mÔ.ìþ=sÎhøQ¥(»¹Ž«Kœ-¾Ðïänî!ät%FAAÅO,
¦ºA¨,wrÝôiMÌ¸·R&gt;Qó.UTò
à•Ÿë¦1¼µx.î.0&amp;·6ÍˆAå°ñŽAèìGIà‘4ÀÐYËÌ7Œ~Ñ'ÙÜ›px=¸n‡Š?¯ÀbÔÂãOŸlº¤&nbsp;˜ïEÃáGUËŸÞÏg­*Â÷-ý™oåÅªD3%à�Á“{«æÝÁé�zŠ¶ð�.)c}6@KÞý�ŽÖ&lt;í,fsÀ'$
q�.a\òG�;Ñ/˜Ã¶öo,’:‘’p;Óþ¿�ub²X¬äµ#ígeóÇR2Šg%�|v¨À†û7ö±C­©"k8ƒ6:œÚrÁnN=zK;QU/dK8íRÖìã‚0�TëœŠ•¤’þU¾»+o{m‘omä²yÀt*®ÅØÿq�J@UdˆD5_)?³Xô/9ÁÝÓvÀ&lt;¼çæÆ;�­+ìÓ”^Ý$W—-šwo#w?uÐ¨Ú8$c�JÐy—ûTm±L}ˆ¯;znÙ¸H8ç'¿½2#5”�yf÷÷›/q‡'žî\{’Ò�ëñGÉK3%½Ü×›Œwc7ÙÁáFâ…”.AJûç�S-&nbsp;ñ(	¹ØíáÛë·~Àùí�0Žzw§©6[¬¬œ½­Ácyp±ä±á—rü£=sŒc®iTÄ4å•†�´tb&lt;·]»ø^ÝvšŒ[Gª3X[¬³Y�^ä9Äþ£z¨by,Ì@ì*`ÕOœ‰if,˜‰É�´mÎzF„‚GäœŒòjü¡/Ù/]¡ÓíÊýšo(©™»�Aç&lt;Æ3žŽ�½ó,º‘6Ó[1qùD	±÷IX¶ì�·q�Gõø•æÛ\ãWX¬âŽ A²-Ì˜Ç;D`döýÞÎsÎ^²[ÛgWò­fŽPª,QòPž3´£÷?»c«þmÄÎ5ƒåêè¤EiåpËÛåÉsŸ]À�å0ÂÆö×çÖeQæÛ2¨U^„…ùHÇ\ù‡4ÿ¯Ä"�4vó¼¸oõÀT�æ6ÙyV ò&gt;NxÈÅ[òM�þÏV7†ì·úWµ„‚øÇûéêjH?Ðw6˜EÕÌÌ&gt;ÚþY)ûûTmol–ú�#[/ÙtìË§M¸ÝË‚Þ[w
ØP£ì¿Ðš_×à!žNGö(p@RÇP=û=O?öÔtüDÀG¨gNÜmE¦Ò.�QöŒvåëÓ‡9'‘ÅUC—ö/œh{sö�¬¿LoÚÎ~Cõ«3¹_#PÌ:l;&gt;Ë.Nd#î‚ø9ÏùW�^¡ÿ_ˆ&lt;ƒTýüÛ¬É¾ãp.¶Ž?¹÷ÏøÆ	Ï³\ÃzãUT´‰¢”‡/'mÛB)$ýá…aŽ§ƒZW[†ê­%¼°¿ú
ÄŠÂL}Ì¨Y‰÷ÛøU6»�˜]\µÊk*A
Ûü¥:gi��ùrNh9çHê~]‹4ªìd1hóüF=£c®1Éü FƒNbéö;¿µpWk7‘Ÿb&gt;R3�^1Ò´ÕÈsql×Û14gR¡;ágÃ‚}{P·3[îþÌ’êF”ÿ¦³.SƒžL/Véé×¦Ê‘´6‹ýž­e<säµÉb|�ÜcqnÞ£ÐžÙâÀ··u[µª@´c“ÉÛ»!noÊrãÓ‘Š•%òsË°’ñ´Ç'í-ä©*oßÃyy.3�¡ÈÅù‹ÈfºþÄê²”1lñól�ü0~¼rgm}‹i¾Ëi¹]Ï”wísÀ!‡'’iÏõhšÞý–æo³ÙËho•„âç é×="" Ö§–s6#Õzé,��±¸…'.nÃ»åìzŽýèk‹‰ävÔzí="" c'ìaa@Ð‘åòoçëœb�ëð�ûr™µœeò®Ñ``l·8="" ÉÝž§;{uél?cvÔmšÞâîãkcnçÊÅ�­¸`u$="" ŒŽje–êwhnf½·¯—¦Ì÷{qœŸÏ½="" ’ê9¬~Òuƒ�µ‚‘ßiltÛŽÿ�…o:é»ÖÐÃv·lmÁx$Å¶zä~piÆvœ��1Ë¢ò£µ:lwöÒ^y.6-‘w„ù±Á-€2z¡óp7ök]²3·åb8ù¶îqƒ×…ç;Ñ±g="" Žtt="" Ï%"Ý¼ž�ŠÆìg�q‘@nÑßb,.dŽÚÒßi‚èÀÁfÆ2,qŒáŽzsg“ûm–k÷ŠÍ­}œwÿ�hq÷hÞÃ="" ž�×‘k30‹v¨.Ž•ò›m¦-ùþáh|ã7tíÅi#o”¸¹3–Í†Ï'Ž="">MÅ0wúï&gt;÷4	¹’iSP”Ç£á˜´“2Šp[q%NF2@èGQs<sj-“ê’®Ù,¾ÊùŒw8ÜÀËÎy'œÈæàj¢ì\m�Þac�b1ÆvþïîýíÃúÒbîf)l.·6æs¾1ÌóÎáÜíÚ�úgƒlbÛk6œ\éŽ.Þèÿ�¥ �‡Ùò9<0#nÁâŸŽÒØéÖlg±›qº»toÝg¨ À÷n="ê5ŽW,4…ºI�ÿ�§î‘Fx9Æö" ¶wcf:sá="" §ý£ûw}­Ð6‹hs»¦2="" ž”„="">W‚[a§tÑ�öÏ-Ég!r(¸ÉS“R]OîØu
öÖvÅM”¢9œ€ç*Ùr…88ÍDá"ˆM*\&gt;€TmŒÈ7n'å$ÛætÀ¯\Se‹ìØ“WŽyld X¨œ#)œH¤½³Ð¯&nbsp;©îdº’;­I^Úúßb…coßw”†9Îù“Î9Å)¹4_HŒuæM©jªÛgÈàl$�ÒãÛ š©,SÛ:Å©¤òêR“öYÁòú	¡Hb2X8on¦o*e²âOøH3çù¿(�9ÆíÛ~à ™¾)�f)g¶�çÓ—ÏÕ¦ÛöËvæ8†	;Xlî
Îø'·CnÌ­¹dÒ¸‚iœêHÄ³÷‚çË8
\‚ªý9,jŒ6ïs#ZiÎmõXvÉØ¶ÙqÃí ±?9�ˆéš–ÙcÔ36’~Íko#äpÊgÄ"—Èe±B	è
 /AöX­¼›t�ô†y™äó‚rÈ|–
Tç¨ à™íŒ&gt;Uüq.„«µ”&lt;…ÙˆAÚÞgwÎUv�É YÐ›y-þÝäÐ‘e´ ùŒù# `rå7š6ãøFjGžH¿´/›F™#Kk@�š7à‚Q°ŠT,€°‘³ž§�@�I¼·•[ŽV9‚i¥L¿&lt;ØíòñYÂ¨'�23šÏ*I¨G
ëª’ý’%gØÊl-†hÁ-æmÞã<r­ÊÄÓ.›"¾ªÂì^ÌÀù{Ì�€7p¢0eò&na ’+:ËfÉ§^:Ë¬n­®öo+µk°9y0u•¿��@ƒÈ…žâo4+æ f*r="" üÌ="" å„$+’jåo3Å)y\è‰="" ½i£þÑrÏµÏ»ir€þ`cæÏð“ÓÊ’ij…Êëh‹æÞüÊasÌpdá="" k¼ Þwiê3£n_s•í´É="">Éwg2}¶o-í,»‘Ÿ	�ß:»ß
Ûòy'v‚ÔG·HX”Æo·3´™@
ç lèW(zü£’n´6»Ãÿð‡%‹K¿ÌóIÀçÌ&gt;8#vzü¡m.¡Ô“ûCOskclÒýª!q&gt;3¶Õ?1eÀç,:ã&lt;1µ¯ö¨$éV&gt;Â-ã=©8ÎÑ‡ó÷vää(€GvÖo5XáM%?aeiw6c8ÈO›s�Á@Ç;Æ†bÒ«jIÖA›ì*›J€vn*Jãví¢B	k–ª·“Å¦¡ÔµöÍ&gt;ìÃökS‘cÜ¤#·—HÃ/ÉË“’G8�ä–Æd°ºcqxdkkÍ¤˜PQ@È¸!™•HXƒñ�(CÌrÇjÁÿ	�22åBdzþèIå‘Æz÷1pmDû¦‘tƒoý¡¾/·îóB�¹
³+·ïn¨È–ùÈ5�&lt;×'E³W�×¡NYAÄÃ÷¤lÚ¥Î2TŒnàÛˆ¶«3ØÙÊÖ—vO¹¸XÂ›’ŠQ‹*HÝ’Ë+1•èjÝ­™7é&amp;ìÓ$çP,_¼cqòvíçäÂýÜ»©Y5˜(`ÿ„|BÁÁóD‚A/^Fÿ½Œr±$gåÌ·‘ë)öû&amp;{KkIfk›q?hC1eR3¯0bç¨¤†ê-†¯tÒÖ�¬*Ø‘ƒ6Àvc&lt;“ŽÌ°/šÐÁ�H@4‚ ›|ÝÄìÊîÛÐ``³ïÍ6ñG�öÏÙ�É˜ÿg3}âWh“h„y$ÉíÀ§\ÝÃeö”þmÍ�×Ù„‚ÞI”!KmžrüÛTÂÓ¥K•b¼‘îæ¼��«˜}™˜c‚ÌÀ*ä)BÜh.Pìè.D#ÄF'6äoÛ³2`ž;Âù›wÑwPboœX˜ÿá"òÓíG-þ¯÷{¶ïfßþ¨0\7íä
¶ðySE’Y%Ô&amp;‰Þ-@ÆÆ¥˜”_Ìj¸È~7(@V½»^JúDÉ
ý¼q´·þP20…ÕÄ€|Ñœ—;¶0ÁÆH[á¥Æ„b'S©ŸŸ[!|àG–H”~èä|»x$†[‹vAý�å�$Æó&gt;fâû&gt;aóƒ0!vòñß¾Ð_ÿkJñØ1³k	×íl"	ö¼g,â&lt;’²f6Ü8-‚p+Áqô?Ú¶ƒìÚm¨˜Md"f`¼–TýÛ‡F@K‚#+×`+›gˆ™ü¯øGH!ÿXÌßŒŒ´nß¸6p
`óóš”¬;ƒk&gt;Q´3F4Å]ù�“!â¥|½Þn@läT­v‘Bu‰—ÌÒe…;€¬r;¬Dœ¼¿w3Mpšc}§QÝym,mh†=ßfÇ#u
¨	m„ã962�­«¿¶·Iö“·lË&gt;^7îÙæœž7‚j¤�&amp;ñ°)ñ)ŒU¯'ìþaƒnq‘×g™ž94ùL¾cs}vÒy›w=º¶U
³|à†Š£/—»åcÁ§Ám3»h®ï¦!6&nbsp;€—eÞa“å”&nbsp;c_®Ò�ªËænÑ|³ª†A¨ç;s�Þ&gt;#Øe\Ã‡ãåê*õ’[ª)ÐÌ#MY$â]ä»¹”3#Î0vFx-‰ÒMA¤²µy,®lÞ=Ð‹k]�Œ6
’e°ìêÀƒ‚EëP·çÏ²ó,aµž_´Aöp&gt;Òv¨$¨ÃË‘Ê³ÇÊT�ìZU1ù?ðŽ˜›ÌÝçyžg›Án|Í¡yÏþ™Ó®V×ÉÎ¦aþÅ"ßìC÷»�ØvçIÊd°bp:ào©ã’'¶¤BDÓ’	´ñá¿xÁ˜&nbsp;%y8'ŽXqRÏ"ÙDÚ�ÈšæÒà[ùVbo³ð
�¥Š‚3�¸l±Ú@Kå‹ˆÿ¶V•ni¡ž«·vÜŽ¢&gt;X`1û£åHÆÉ£fÝµÓ‚&lt;ß,®\®p\ð�ûxÍKå�.U­%ó]\Ÿ!¼•?f.á‰mªq�€HLn§Á¶ªº|’K5ãÅ.Ëï#!1!Y‰`8ùK@Q�JdªÄÌâØZÿl*Eö’D»6»‘�£9ÆÍü«„g#LÂßÎ•oC\`0PÒÜ�Ûø#àÕµó\}‘d•&amp;„DZá¡e€%vÃ!¶ò…� ŠºÌC#:,lÁÔÆFüq½A+žC&amp;Cc‚EsQÇj-6Ä-Æ‡ä¾óº_0�Ç8öÏ\“!nœàº[SnVü[
#ý›i�6p
îÆUØ~æwä­/µ4‹ý¢|ô�bpÖ­$,ïm#~ì÷H!²sÓµ¸kùŒÓÛL!òíDxÏ‘÷³œHÀÉÚó*JƒTÁÚr,v†cÓå$²ü¯Ó,0¹ÀíÉä:Cyöoíc†=ŠåäãÃxSÆá¸!¶ð8”I5ƒpÓ]ý¢cå´p[©öä…^…Ødç‘�Æˆ„ðF¶I4³È’µˆ€U9;wu@ÀîÛ“Œ�@¡�YÌ@ÆnÑÊ#¯ïm';rN;ÕÄ•$ÎÂiÚØ9ÁAô#=+/386HóG,H„Ü˜”«ž‡�BÇpåÍ[viÏîÙâòœoýßßr&nbsp;ºò÷“ð4^{˜Äf\Äl•_Î''€9@*G]ÀóØšåï¦µh¼ËŸ$è/yjŠêÂMÙTPã¡àcñÍlItó¨ÔŸ¼(–ÕàùåàŒàœãºõuÇ5ÊêWA#]fE3é²"¢XÈUn�ŠÑŒNìãŠCy‚AÕƒ"Ëýœ Û¸d|ƒ ‡ÎÀ¿ë\õ=ª´¦íd�uqý®w}�”Ûùj?‡vÆr~þðsÆ*µÍÔv'íIo¨Gxq}&nbsp;Ÿ²©…
Q‚��7 R
ã#5XtýºtŸfº¸ºÎËÑ9&gt;Fx_˜©eÛ×åuÜ1š])x&amp;Û�ý¿´b`ò¼³Û1ãoL.ìöÍFëÍì‘8¿S‹òÍ	ûÅ…³œm¶*	ÑÿdfØ]…u˜‚{í-´¾qò•ÞGµW’ÞßS?d‰m,å´#ÌœÎvÜ`sƒ±r©$¶&gt;ƒ�„Hé'öRÝ&amp;Ÿÿ/»ÚÜ99ù¶&lt;uÛŒô#S#r‹¿ìryƒÍß�AÎÝß�õÝŠ„G&nbsp;
Ì)kk·À×MÁ^¤|£ïcŒóÈÁ&amp;«ïµsý¤!€Zƒ�±“¸�1»AÆy)±Š¿&gt;ãh›Á¥sö@¢!þîütÂç³è¼f²o&amp;¹”¯Û}è£ÈÜ&nbsp;|¹ù»ù€r{â¦h¢·Åì±Ãqo6v[%Ón‹&lt;€vüÃëŠÏ’ÔÛá[Ê&amp;Q•Ù*¸\öb¤í&gt;¡¹îhHŒï01™�Ùo”©;ºv9ÝœtöéZ6ÒÜA&amp;ëµiüâ|¢8ÛŸ›·6ìã%—9èFi-ºö6Hšvl¬ÿhTc;N	ŒŽÙÈ9àò$L«kqÅq&gt;eÇÚ2²ž$F½°TœàzÑýtÖ�`lä¸Ré‹€ÁPÜ¬w)ÉÈl~¦ª«`mO$‘¸R2ŸNiBy«ò×Ë7ï-î7·'Ž‹ž¸Ç"£8o˜.íœÿ&gt;i­Êñ¤zƒ\}Ž5o F©�Äÿµ�Ž¹äôÀ#¨Ùiv‰u_´ý°�ýœWÉUnì¹Ý³vþqÃs\œ2E’1*�FÒì˜'£duÇ¡à×C®˜Øà»{ÕL­qŸ³‚9d;
’FÑÆ#8_¶”\yÃ_Æa Ûù[p0Ë]ÙÈÎOzÍ•.|òagX›’»6÷&lt;¬ö áä�J¿åq¥ÊÖó^Ê7.&nbsp;n˜Àè¹*\0€»ÔŽ:g2Hcwû»„æKÁvÊ²Œ�›' IÈôÍ02yÿ–&amp;Làù¹sžGr¿P9íN·™Àòäi…«02¬dr=B±[Ó5.îUÚ0H|ç±çé×­1H8²yöÈÁþµ#:o1�²¥×Úÿ±ˆ‡jÛù›�;Cw`ÙÉ ‘€8ánÌÛ#þÖûOÙÕÐ6ˆÎß3nIà.AÉïÎsYVþ]¹SÅð�³™ðA=öngÇR¤Ä™V;%\ÅÂ\. _µô|÷Û†#:ç¥Õ¸kÇ™N¥öŸíS·ì{ÝSnr»Êàgqlät=À‰…çÚ³þ“ýº,@‡ÊÙ³`íÎÌsŒc#æ«5ªY¿Ø.R	în1]}©ŠÂ8H'¨ëÐŽ¨m@ì¿ôsy�ßnûS*Fí™Ú	 |¿^ï@%½Ì²fn$¼ùÍÈ
iÏÍó+’Ùn¹'©­–O-ÅŸÚM‘	öÏ’-ÀçoÌrÜG ÿxb›öE½ÿD·X-î-”‰¦ûQ9ŒŒœž0{
rˆµÜZÅ
¬6ê&lt;è~ÔAŸ“Œ¨'�ŽýxÉâ�Ë(H„€n¿°‹‚ß,&gt;a~8È!¶î‘Ç|nâ§�ÜÂ¿Új&gt;Ñ&lt;ÌŒíßüCv7g?Nj€X]N¦ ‰,…6Ÿj9fànåI&lt;�p8¸n-íGÛg†‹Y‰[-ÙÝzdc=ÉÛÆrpqL	å39VÕMÐ›hûUˆƒ�¹»Œw'ŽrOJšf½®
ÏöÐ+å òöcŽŸ/®p6õÜN(›x¬Ë˜á¹{¡û‡[’|Œô¶Fs�ÇSÍ)·[SýŸ*D÷®AKÁtÀF0	Û�”dœóÓ�@�8&gt;Øfo±}¤ë}n7›qÞ„Ä¡wo@8«6M;n/ÚÞ?´žFÒyÜT±,ßû˜ãä
ÍŠ#pßÙöÞE­ìC/z.Ü	GFPUrÛ²22z�ÍhÙ‡Õr¶Ãbl¿ãäÇ3fåGÞ
±õl³–ë‚hVÍ!òÇØ6a•µùœ6ì|Ä’&lt;ÜýÜm8ëŒ|¦µÏÙ×lŸg”»2foÜ1œà�œÿ·œwÍfi³ý¾1¨Úÿ¢Ø[YF€¬¸'€ªÛ¸ä©éƒŽMmÛ\ù�®&nbsp;�BÙefVÈÁ2xþî09àR+É*51iöRñ‹-¡Ù³�—qeÀ8Æ
ñŒƒï$›Ã©ºû!Ô3/Øþøvñ’FìãïíÇJ²�5›4Ó&lt;—ÎéåF°äÂ©\œg’X
¸úÓKMú#K#Ïpd1L!bÈÝ�“ŽÙå�­þ¿­æ_.V’²¶¸Ñ(‘KÈfW8\ç¦N:‰ŠG}[›·™&gt;ÜGl}íØù¸!‰Æïòä`&lt;¯šíeÂ-Q#C-×ÙW.€�Q°ƒÇˆ8,2Ù$‹N”[Om*ý­¾Ì¹˜€AÎq÷°~aóc¡V´KtO/JXM-(¼,òno;I'ŒuÆAÛ�óT%-&gt;Ëå…·•’Ûåó7ïÈï»;ð0rÄÿ~J±Ñ^/Úì˜ÛÙÛ&lt;ßh·ã÷äœàsÎ8$“Èb&nbsp;ûU¹µþÓgÆ“åíûµ@3»õÁ;¹=2hÑ³h¶jb¤/”,Š´…˜íÀ9R[dã®FM$²‰%�ûb8’î9_û4+I‰1´¡mŒÀe¶cÌ
z|¹Îe¹ºK7—çí:}ÃD-ààù$�”•`6àvêOÝÀªó§J±ê,nî/&amp;o±Ëå‚-ÉÀBcaÉRUAÛŒóŒÐ2ž%óc¸ºÿ	ÆÞLýÛ¨-‚ÞYØfò˜&nbsp;÷Æ&gt;Tß"ÌóééëÎ‹ö¨w’‘¦Fò»˜G»"0ÃÌm¿Â;˜. tÓ&amp;`úÔˆÞUæX„Œîm¾aOºd!Û¸ãÝª’Ï#é–¤C¬Fªg»ÀJ£†ð¥ùÜ�Td¨Ï¥1Ç–î4`’É$Ÿñ3Üøw*îØ6dÊwF†08À¨¢Kd‡ËÓŽý™</r­êäó.›"¾ªâì^ìàù{ì�€7p¢0eò&na></sj-“ê’®ù,¾êùœw8üàëîy'œèæàj¢ì\m�þac�b1ævþïîýíãúòbîf)l.·6æs¾1ìóîáüíú�úgƒlbûk6œ\éž.þèÿ�¥></säµéb|�ücqnþ£ðžùâà··u[µª@´c“éû»!noêrãó‘š•%òsë°’ñ´ç'í-ä©*oßãyy.3�¡èåù‹èfºþäê²”1lñól�ü0~¼rgm}‹i¾ëi¹]ï”wísà!‡'’iïõhšþý–æo³ùëho•„âç></p­„!~ëh-nçøöìuá6~ñçÿõbûwù˜îî:go‰ùj+k{»©m¶ž²åªb'7r‹‚></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.graybeardgames.com/download/diablo_pitch.pdf">http://www.graybeardgames.com/download/diablo_pitch.pdf</a></em></p>]]>
            </description>
            <link>http://www.graybeardgames.com/download/diablo_pitch.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844666</guid>
            <pubDate>Wed, 21 Oct 2020 04:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AOC plays Among Us live on Twitch and has 330k viewers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24844474">thread link</a>) | @tomashertus
<br/>
October 20, 2020 | https://www.twitch.tv/aoc | <a href="https://web.archive.org/web/*/https://www.twitch.tv/aoc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/aoc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844474</guid>
            <pubDate>Wed, 21 Oct 2020 03:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Jamstack is failing at comments]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24844172">thread link</a>) | @leoloso
<br/>
October 20, 2020 | https://leoloso.com/posts/jamstack-failing-at-comments/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/jamstack-failing-at-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few weeks ago I added <a href="https://wptavern.com/matt-mullenweg-clarifies-jamstack-remarks#comment-344626">this comment in WPTavern</a>, on an article where WordPress founder's Matt Mullenweg clarifies his earlier remarks that the Jamstack is "a regression for the vast majority of the people adopting it".</p><p>Since I like owing my own content, I reproduce it here in my own blog.</p><hr><p>I think Matt’s brutal honesty is welcome, because most information out there about the Jamstack praises it. However, it also comes from developers using these modern new tools, evaluating their own convenience and satisfaction. As Matt points out, that doesn’t mean it makes it easier for the end user to use the software, which is what WordPress is good at.</p><p>I actually like the Jamstack, but because of how complex it is, it’s rather limiting, even to support some otherwise basic functionality.</p><p>The definitive example is comments, which should be at the core websites building communities. WordPress is extremely good at supporting comments in the site. The Jamstack is sooooo bad at it. In all these many years, nobody has been able to solve comments for the Jamstack, which for me evidences that it is inherently unsuitable to support this feature.</p><p>All attempts so far have been workarounds, not solutions. Eg:</p><ul><li>Netlify forms: no hierarchy, so can post a comment but not a response (unless adding some meta to the comment body? how ugly is that?)</li><li>Storing comments in a GitHub repo: it takes a long time to merge the PR with the comment</li></ul><p>Also, all these solutions are overtly complicated. Do I need to set-up a webhook to trigger a new build just to add a comment? And then, maybe cache the new comment in the client’s LocalStorage for if the user refreshes the page immediately, before the new build is finished? Seriously?</p><p>And then, they don’t provide the killer feature: to send notifications of the new comment to all parties involved in the discussion. That’s how communities get built, and websites become successful. Speed is a factor. But more important than speed, it is dynamic functionality to support communities. The website may look fancy, but it may well become a ghost town.</p><p>(Btw, as an exercise, you can research which websites started as WordPress and then migrated to the Jamstack, and check how many comments they had then vs now… the numbers will, most likely, be waaaaaaay down)</p><p>Another way is to not pre-render the comments, but render them dynamically after fetching it with an API. Yes, this solution works, but then you still have WordPress (or some other CMS) in the back-end to store the comments :P</p><p>The final option is to use 3rd parties such as Disqus to handle this functionality for you. Then, I will be sharing my users’ data with the 3rd party, and they may use it who knows how, and for the benefit of who (most likely, not my users’). Since I care about privacy, that’s a big no for me.</p><p>As a result, my own blog, which is a Jamstack site, doesn’t support comments! What do I do if I want feedback on a blog post? I add a link to a corresponding tweet, asking to add a comment there. I myself feel ashamed at this compromise, but given my site’s stack, I don’t see how I can solve it.</p><p>I still like my blog as a Jamstack, though, because it’s fast, it’s free, and I create all the blog posts in Markdown using VSCode. But I can’t create a community! So, as Matt says, there are things the Jamstack can handle. But certainly not everything. And possibly, not the one(s) that enable your your website to become successful.</p></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/jamstack-failing-at-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844172</guid>
            <pubDate>Wed, 21 Oct 2020 02:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Virtual Corn Maze]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24842857">thread link</a>) | @jtolmar
<br/>
October 20, 2020 | http://noisyowl.com/corn/ | <a href="https://web.archive.org/web/*/http://noisyowl.com/corn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://noisyowl.com/corn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24842857</guid>
            <pubDate>Tue, 20 Oct 2020 22:12:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Spec, No Problem: How I Autogenerated an API Spec for Notion]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24842329">thread link</a>) | @jeanyang
<br/>
October 20, 2020 | https://www.akitasoftware.com/blog/2020/10/20/no-spec-no-problem-how-i-autogenerated-an-api-spec-for-notion | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/10/20/no-spec-no-problem-how-i-autogenerated-an-api-spec-for-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-398c45a3fde378e52a9c"><div><p>Software is eating the world and APIs are at the forefront. Not only do APIs give developers instant access to powerful functionality, but their programmability also makes it easy for developers to integrate disparate pieces of functionality.</p><p>But today, this only applies to <em>documented</em> APIs. This means the company responsible for the API has made a conscious choice to expose the API—and they’ve allocated the resources to creating and maintaining documentation. This also means there are a <em>lot</em> of SaaS APIs out there that could make users’ lives easier, but that haven’t been documented.</p><p>This blog post is about a new feature that my team and I built after I spent a painful couple of days figuring out how to script against Notion. After my experience trying to learn the undocumented Notion API, we decided to automate the process of learning web APIs so that nobody would have to suffer like this again.</p><p>In this blog post, I talk about:</p><ul data-rte-list="default"><li><p>How I tried to automate against the Notion the hard way.</p></li><li><p>How this led my team at Akita to build a new feature to automatically learn undocumented APIs.</p></li><li><p>How to use Akita to <em>automatically</em> learn APIs, including the Notion API. (See what we learned on SwaggerHub <a href="https://app.swaggerhub.com/apis/Akita-Software/notion-api-experiment/0.0.1?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">here</a>!)</p></li></ul><p>To anyone who wants to learn an undocumented API–or document your own API so people don’t have to do this—you may be interested in checking out <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">our private beta</a>!<br></p><h2>🐕 First, some background</h2><p>I’m Chris, the product manager at Akita. I joined Akita after eight years at Twilio, where I helped define products like Twilio Marketplace and Twilio Channels. While I was making APIs easier to use at Twilio, I also saw how APIs made software development harder. For instance, the rise of internal and external APIs make it much more difficult to prevent breaking changes. These observations led me to join Akita about a year ago.</p><p>At Akita, we’ve been working to give structure to the interaction graph of APIs, for instance to <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">detect breaking changes in web apps</a>. Akita watches API traffic to automatically generate API specs and infer implicit API contracts. Core to Akita’s approach is diffing API specs and contracts learned across different environments. We’ve been working hard to make this technology easily accessible to developers, no code changes required, in just minutes.</p><h2>💡 An observation about Notion&nbsp;</h2><p>Now for how I came to autogenerate an API spec for Notion.</p><p>As the product manager at a small startup, I spend a lot of time making sure that the right information gets to the right place. Customer feedback, blog posts like this one, product usage, and engineering metrics are just a few of the things I need to track. I also require some sleep, food, and the occasional trip outside. How do I manage to keep up? That’s easy: AUTOMATE ALL THE THINGS!!!</p><p>When I joined Akita, I realized that Notion was what we needed to organize information across the team. But the problems started when we needed to add <em>new</em> information to Notion. For instance, we keep team meeting information in Notion. Most of our team meetings began with “Did someone create a Notion page?” or “Where is the page from last week’s meeting?” The same thing would happen during customer meetings.</p><p>Given how many meetings we have a week, I figured we could get several hours back <em>a week</em> if we could get computers to automate creating the Notion page for us. All we needed was to figure out how to automate Notion.<br></p><h2>😰 Thwarted by the Private API</h2><p>The catch? Notion doesn’t have a publicly documented API.</p><p>The good news is that it’s still possible to use an undocumented API. It’s easy. You could set up a headless browser to automate clicks or turn to that ol’ standby Grease Monkey script for watching your browser traffic. I recently read a blog post where the author ran a proxy and executed a man-in-the-middle attack in order to build a calendar widget for one of his favorite websites.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_27960"><div><p>Okay, it’s not easy. It took me a couple days of hacking to get a <a href="https://gist.github.com/chriscorcoran/51b2f37a807e6f09cbbf320b63b8931a?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">reasonable solution working</a> the first time. And the undocumented API problem is prevalent among newer SaaS tools, and it makes sense: APIs are hard to build, document, and maintain. If more of these tools had APIs, I would automate more and integrate them more deeply into our workflows.<br></p><h2>⚡️ Using Akita to learn the Notion API</h2><p>I wondered if there was a better way.</p><p>Then I realized: oh wait, I’m working on building a tool that <em>lets you generate API specifications by monitoring network traffic</em>. Surely we could use Akita to build API specs from watching my interactions with Notion?</p><p>But it wasn’t completely straightforward. Up to this point, we had set up Akita with the assumption that the user wants to document their <em>own</em> API, so Akita worked by listening to network traffic through an agent.</p><p>But when I posed this problem to my engineering team, they came up with a solution that let me generate this beautiful rendition of the Notion API spec.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_67186"><p>This feature was a game-changer! Now that Akita could learn this spec, I had an OpenAPI specification that detailed every endpoint, parameter, and property that the Notion frontend used. And what made this <em>really</em> useful was Akita’s analysis layered on top.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_72403"><div><p><a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">Akita Data Formats</a>, detecting precise data formats like unique IDs and specific datetime RFCs,&nbsp; and API Relationships, surfacing which endpoints accept values of the same data type, made it easier to understand how the endpoints worked together.</p><div><p>You can check out the API spec we were able to generate on SwaggerHub <a href="https://app.swaggerhub.com/apis/Akita-Software/notion-api-experiment/0.0.1?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">here</a>.</p></div><h2>🛠 How it works</h2><p>The secret to this new feature? HAR Files.</p><p>Previously, to run Akita you ran an agent alongside where you hosted a service. The agent would listen to network traffic and allow you to autogenerate API specs without having to make code changes or use a proxy. While this was super easy to use if you were learning your <em>own</em> API, it was less helpful for learning other people’s web APIs. Our new HAR file ingest allows you to learn <em>any web API</em> that relies on AJAX-style requests, <em>using any major web browser,</em> in a matter of minutes.</p><p>HAR Files are a little known feature of the Webkit Developer Console (available in major browsers including Chrome, Firefox, Safari, and Edge) that allows you to record requests, performance metrics, and other interesting data from a debugging session. It turns out that it’s not so hard to extend Akita to accept HAR files instead of network traffic. HAR files are key to making it easy to autogenerate API specs, without needing headless servers or proxies.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_160214"><p>Below I show a screen capture of me trying to break this new feature by returning to my old nemesis, Notion. In just minutes, I was able to automatically learn what had previously taken me days to uncover!</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_122897"><div><p>All you need to do in order to generate a spec is:</p><ol data-rte-list="default"><li><p>Navigate to the website you want to learn an API for and start network log recording. (See instructions across different browsers <a href="https://support.zendesk.com/hc/en-us/articles/204410413-Generating-a-HAR-file-for-troubleshooting">here</a>.)</p></li><li><p>Interact with the website to generate traffic.</p></li><li><p>Save your HAR file and use the Akita CLI to upload it to Akita.</p><pre><code>akita har ingest --service {SERVICE} {PATH_TO_HAR_FILE}</code></pre></li><li><p>You’re done! You’ll get a link for the generated API spec. 🎉</p></li></ol><p>Note that if you’re on the other side and want to learn a spec for your <em>own</em> API, the steps you follow are even simpler!</p><h2>🏝&nbsp; It’s your turn to live your best life</h2><p>Now that HAR file ingest is an official Akita feature, you, too, can wield this incredible power. With our new HAR File Ingest feature, you can now use Akita to learn the spec of any website you are using—and write time-saving automations like my script <a href="https://gist.github.com/chriscorcoran/51b2f37a807e6f09cbbf320b63b8931a?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">here</a>.</p><p>If you’re interested in autogenerating API specs, sign up for our private beta <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">here</a>. We’d love to see what you think!</p></div></div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/10/20/no-spec-no-problem-how-i-autogenerated-an-api-spec-for-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24842329</guid>
            <pubDate>Tue, 20 Oct 2020 21:02:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconditioned Texas Garage Lab – 1 year later]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24842218">thread link</a>) | @monstermunch
<br/>
October 20, 2020 | https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/ | <a href="https://web.archive.org/web/*/https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.networkprofile.org/content/images/size/w300/2020/10/2020-10-20-14.21.11.JPG 300w,
                            https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.21.11.JPG 600w,
                            https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.21.11.JPG 1000w,
                            https://blog.networkprofile.org/content/images/size/w2000/2020/10/2020-10-20-14.21.11.JPG 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.networkprofile.org/content/images/size/w2000/2020/10/2020-10-20-14.21.11.JPG" alt="Unconditioned Texas Garage Lab - 1 year later (Its all fine)">
            </figure>

            <section>
                <div>
                    <p>A little over a year ago I mounted a rack in my garage, threw a Cisco Switch in there, an APC UPS and my Flight Tracking setup, and a second ESXi host. See below for the original:</p><figure><a href="https://blog.networkprofile.org/mounting-a-network-rack-in-my-garage/"><div><p>Garage Network Rack with 10G Fiber</p><p>This details my 12u rack in my detached garage which has a 10G uplink to my mainnetwork I needed some networking in my detached garage for an access point, my flighttracking setup, 3 x PoE cameras and some future additions, and instead ofrunning multiple Cat6 cables across, I decided to just run…</p><p><img src="https://blog.networkprofile.org/favicon.ico"><span>NetworkProfile.org</span></p></div><p><img src="https://blog.networkprofile.org/content/images/2020/01/ndEotkV-1.jpg"></p></a></figure><p>Its been through the "cold" of a Houston Winter and the heat and humidity of the brutal Houston Summer. To date, nothing has even complained that its hot, in fact the fans are not even spun all the way up on the switch</p><p>The temperatures actually never got above what I see equipment go to in my air conditioned lab in the Houston, which proves that as long air is flowing through the hardware, its fine. No equipment failures, no battery failures, no SSD failures, no HDD failures, no Transceiver failures</p><p>I replaced the UPS batteries last week, but they still reported 1 hour of runtime, and passed the test fine. I now use those batteries in a spare test UPS, they were 7 years old...</p><p>There is however a LOT of dust... but it has not affected the systems. I plan to give them a good clean later on this year</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.48.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.48.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.48.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.48.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.48.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.19.02.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.19.02.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.19.02.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.19.02.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.19.02.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.18.50.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.18.50.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.18.50.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.18.50.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.18.50.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.45.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.45.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.45.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.45.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.45.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>There is a nice dust/dirt stain in the plywood behind the switch. I guess that means a lot of the dust ends up out the switch at least!</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.42.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.42.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.42.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.42.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.42.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>There isn't much more to say, because nothing of note happened, it all just works fine...</p><p>Apart from a power outage during electrical work I had done, its been running 24/7 with no problem</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/image-2.png" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/image-2.png 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/image-2.png 1000w, https://blog.networkprofile.org/content/images/2020/10/image-2.png 1332w" sizes="(min-width: 1200px) 1200px"></figure><p>Full Equipment Listing for those Wondering</p><ul><li><strong>Cisco Catalyst 2960-S</strong> PoE+ 10G 48 Port Switch (48 x 1G PoE+ and 2 x 10G SFP+) connected back to my main rack with OM3 Fiber @ 10G</li><li><strong>APC SMT1000RM2U</strong> UPS</li><li><strong>Lenovo M73 Tiny</strong> (i5, 16GB DDR3, 800GB Intel DC S3700 SSD, 5TB 2.5" SATA HDD) Running ESXi 6.7</li><li><strong>Raspberry Pi4</strong> running ADSB Flight Tracking duties (FlightAware, ADSDX and FA24)</li></ul><p>If you are wondering if you can run your lab in your garage, go for it. You have my permission </p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24842218</guid>
            <pubDate>Tue, 20 Oct 2020 20:47:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swedish virologist says her country's strategy has failed, but nobody admits it]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24841972">thread link</a>) | @colinprince
<br/>
October 20, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Sweden's health authority maintains its approach to COVID-19 was a success. But our guest says the data speaks differently, and that new measures announced Monday are insufficient.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5768038.1603128831!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1228596918.jpg"></p></div><figcaption>People walk on Stranvagen in Stockholm on Sept. 19. The country has had no lockdowns or mask policies during the coronavirus pandemic. <!-- --> <!-- -->(Jonathan Nackstrand/AFP/Getty Images)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Swedish virologist says her country's COVID-19 strategy has failed, but nobody will admit it"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/942/999/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>6:45</span><span>Swedish virologist says her country's COVID-19 strategy has failed, but nobody will admit it</span></p></div></div></div></span></p><p><span><p>Eight months after the start of the&nbsp;global pandemic,&nbsp;Sweden is&nbsp;changing its COVID-19 strategy — but&nbsp;virologist Dr. Lena Einhorn&nbsp;says it's far too little, too late.</p>  <p>Last spring, as other countries went into lockdown, Swedish citizens were mostly living as usual. The government issued advice and guidance in place of rules and restrictions. School and work went ahead. Many businesses stayed open.&nbsp;</p>  <p>But as of Monday,&nbsp;Sweden's per capita death rate from COVID-19 was the 15th highest in the world, or 13th if you exclude the tiny countries of Andorra and San Marino,&nbsp;<a href="https://time.com/5800901/coronavirus-map/">according to data from Time magazine and Johns Hopkins University</a>.&nbsp;</p>  <p>Now Sweden&nbsp;is shifting its policy. <a href="https://www.telegraph.co.uk/news/2020/10/17/sweden-considers-local-lockdowns-shift-coronavirus-strategy/">According to the Telegraph</a>,&nbsp;starting Monday, the government has empowered regional health authorities — in consultation with the federal public health agency —&nbsp;to instruct citizens&nbsp;to stay away from crowded spaces like shopping malls, museum, gyms, and concerts, and avoid taking public transport or visiting the elderly. However, there will be no&nbsp;legal or financial consequences for non-compliance.</p>  <p>Einhorn,&nbsp;a virologist, author and filmmaker in Sweden,&nbsp;is one dozens of medical experts who have been critical of the country's COVID-19 response from the start. Here is part of her conversation with <em>As It Happens</em> host Carol Off.&nbsp;</p>  <p><strong>Is the Swedish government finally willing to admit that its approach to tackling COVID-19 has failed?</strong></p>  <p>I haven't seen any such signs, no.</p>  <p><strong>Do you think they'll just continue as they are?</strong></p>  <p>There have been incremental changes in the recommendations. There has never been, and I doubt there ever will be, any kind of admission of having made mistakes.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dr-lena-einhorn.jpg 300w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dr-lena-einhorn.jpg 460w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dr-lena-einhorn.jpg 620w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-lena-einhorn.jpg 780w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dr-lena-einhorn.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-lena-einhorn.jpg"></p></div><figcaption>Dr. Lena Einhorn is an author, filmmaker and virologist in Sweden. <!-- --> <!-- -->(Submitted by Lena Einhorn)</figcaption></figure></span></p>  <p><strong>If you were to describe Sweden's approach to tackling the coronavirus, what words would you use?</strong></p>  <p>Stubborn is probably the best word I can come up with.</p>  <p>When they started, their initial assumptions were fair. They assumed that this would be like SARS; it would never sort of be a major problem in Sweden or outside of Southeast Asia. They were convinced it's only spread from symptomatic people, so like SARS, you could isolate the symptomatic people and stop the spread that way.</p>  <p>That was fair, you know, sometime in January. It was not fair in April or in May. So they stuck to that. And one could say that when the spread really …&nbsp;hit Europe and Sweden, they did the opposite of our Scandinavian and Nordic neighbours who went into lockdown, and we did not.</p>  <p><strong>There was an idea that we heard from coming from Sweden in the spring, and I guess it continued, that Sweden would attempt something called "herd immunity," that if enough people were to contract the virus, that eventually there would be a general immunity enough within the population that it would have a better effect than locking things down and keeping people from getting it. Is that what happened?</strong></p>  <p>It has been assumed that they were going for herd immunity, but they've been speaking through two sides of their mouths. On the one hand, they've been denying it. On the others, on the other hand, they said it would be a bonus.</p>  <p>They said that come fall, and the second wave, we will be much better protected than our Scandinavian neighbours who had 10 times less deaths than we did in relation to population. But it became very clear once broad testing of antibodies was being done that there was nothing close to herd immunity.</p>  <p>And so, of course, they realize that they can't go for herd immunity. It's going to kill too many people. I mean, it's already killed almost 6,000 people in a population of 10 million. So they are no longer going for herd immunity, which doesn't mean that they're prepared to say, "we were wrong and we're going to change our recommendations."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-sweden.JPG 300w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-sweden.JPG 460w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-sweden.JPG 620w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden.JPG 780w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-sweden.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden.JPG"></p></div><figcaption>Anders Tegnell of the Public Health Agency of Sweden attends a news conference updating the country about COVID-19 on Oct. 9.<!-- --> <!-- -->(Claudio Bresciani/TT News Agency/Reuters)</figcaption></figure></span></p>  <p><strong>At the centre of all of this, as we have followed what's going on in Sweden, is a man named </strong><strong>Anders&nbsp;Tegnel, Sweden's chief epidemiologist, and he seems to be a bit of a rock star in your country for the decisions he made. <a href="https://www.reuters.com/article/us-health-coronavirus-tegnell-tattoo-idUSKCN2292G7">People have tattoos of him on their bodies.</a> So why is he so popular?</strong></p>  <p>This is a combination of factors, and this deserves a long discussion. Part of it, I'm sure, is that when there's a national crisis, people want to believe in authority.</p>  <p>The other aspect is that he has a very calming demeanour. Even when the numbers were going through the roof, he kept saying that we're flattening out, we're hitting the peak. He had a way of sounding extremely calming.</p>  <p>And also, you know, 90 per cent of the deaths were in the elderly, so …&nbsp;most people didn't see it.</p>  <p><strong>And what do you think of&nbsp;Anders&nbsp;Tegnel?</strong></p>  <p>I have no opinions about him personally, but I think he has not handled this well and he keeps on not handling this well.</p>  <p>Just as an example, Sweden is [one of the only countries],&nbsp;together with Somalia, Yemen, Eritrea, Syria, Greenland and some Pacific islands, who have still no recommendations for face masks whatsoever. So, you know, he hates face masks. He says they don't help. He keeps saying there's no support for them.</p>  <p>In the spring, that could have been a fair assumption. But by now, there's the studies are overwhelmingly showing the benefit of face masks, especially when it's used in the whole population, because it protects against someone who is sick.</p>  <p>So if everybody wears it, face masks are extremely efficient. But if only 50 per cent wear it, it's not at all sufficient. But he will not even say that they're good. I mean, you have to understand, in the Swedish hospitals, the doctors and nurses do not wear face masks.</p>    <p><strong>Well, it seems that [U.S. President] Donald Trump and the people around him would agree with Anders&nbsp;Tegnel.&nbsp;But the rest of the world, at least in countries where they have policies, they are not doing that. So somebody is right and somebody is wrong.</strong></p>  <p>The interesting thing is that in Sweden, we have a social democratic government dominated by the Social Democrats, so …&nbsp;it's more of a left-wing policy. Whereas in the rest of the world, it's very much a right-wing <em>laissez faire</em> policy to have herd immunity, or to try to have herd immunity, or to not wear face masks. Freedom, you know?</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-sweden-cases.JPG 300w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-sweden-cases.JPG 460w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-sweden-cases.JPG 620w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden-cases.JPG 780w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-sweden-cases.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden-cases.JPG"></p></div><figcaption>A sign promoting physical distancing is pictured in the Gallerian in Stockholm, Sweden, May 12.<!-- --> <!-- -->(Henrik Montgomery/TT News Agency/Reuters)</figcaption></figure></span></p>  <p><strong>There was <a href="https://time.com/5899432/sweden-coronovirus-disaster/">a freedom of information [request</a>, and] a bunch of emails that have been published by journalists in your country that show that Mr. Tegnel said that at one point that when it was suggested that 10 per cent of those who would get the disease would be the elderly and maybe they would die, 10 per cent might be "worth it," he apparently said. How much of the decisions are being driven by this idea that, well, maybe we have to keep Sweden moving, keeping the businesses open, and that's part of the motivation?</strong></p>  <p>They will never admit that the economy is an aspect. By the way, Sweden's economy has not fared any better than its Nordic neighbours. Rather, it's more at the bottom than at the top among our neighbours. So it hasn't benefited from it, and it has certainly not benefited from the herd immunity.</p>  <p><strong>Today we saw the announcement that citizens in Sweden should avoid places like shopping malls, museums, gyms, concerts, and avoid public transportation or visiting the elderly. So is there a shift perhaps in perception?</strong></p>  <p>There are policies. You know, it's not a completely<em> laissez faire</em>. I mean, people are advised to stay to work from home if they can. People are advised to not fill up the public transportation, the busses and the subways. There is still a maximum amount of people gathering of 50.</p>  <p>It's not a complete "let's live as normal" — but it's all recommendations and advice.</p>  <p>I would say that incrementally, Sweden has has gotten closer to other countries. I mean, we do a lot of testing now. We do, you know, about as much as Canada per capita. So it's not like in the spring, where nobody was tested outside of the hospital.</p>  <p>But it still is always too little.</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Jeanne Armstrong. Q&amp;A has been updated for length and clarity.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967</link>
            <guid isPermaLink="false">hacker-news-small-sites-24841972</guid>
            <pubDate>Tue, 20 Oct 2020 20:22:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julia GPU]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24840972">thread link</a>) | @cdsousa
<br/>
October 20, 2020 | https://notamonadtutorial.com/julia-gpu-98a461d33e21 | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/julia-gpu-98a461d33e21">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@federicocarrone?source=post_page-----98a461d33e21--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/96/96/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2816/1*KJX3T1Y9T1Cj0aV3m-A22w.png" width="1408" height="528" srcset="https://miro.medium.com/max/552/1*KJX3T1Y9T1Cj0aV3m-A22w.png 276w, https://miro.medium.com/max/1104/1*KJX3T1Y9T1Cj0aV3m-A22w.png 552w, https://miro.medium.com/max/1280/1*KJX3T1Y9T1Cj0aV3m-A22w.png 640w, https://miro.medium.com/max/1400/1*KJX3T1Y9T1Cj0aV3m-A22w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*KJX3T1Y9T1Cj0aV3m-A22w.png?q=20"></p></div></div></div></figure><p id="58dc">We are living in a time where more and more data is being created every day as well as new techniques and complex algorithms that try to extract the most out of it. As such, CPU capabilities are approaching a bottleneck in their computing power. GPU computing opened its way into a new paradigm for high-performance and parallel computation a long time ago, but it was not until recently that it become massively used for data science.<br>In this interview, <a href="https://twitter.com/maleadt" rel="noopener">Tim Besard</a>, one of the main contributors to the JuliaGPU project, digs into some of the details about GPU computing and the features that make Julia a language suited for such tasks, not only from a performance perspective but also from a user one.</p></div></div></section><section><div><div><p id="38e1"><em>Join the Not a Monad Tutorial Telegram </em><a href="https://t.me/notamonadtutorial" rel="noopener"><em>group</em></a><em> or </em><a href="https://t.me/channel_notamonadtutorial" rel="noopener"><em>channel</em></a><em> to talk about programming, computer science and papers. See you there!</em></p><p id="b3d6"><em>If you are looking for good engineers send me an email to mail@fcarrone.com or you can also reach me via twitter at </em><a href="https://twitter.com/federicocarrone" rel="noopener"><em>@federicocarrone</em></a><em>.</em></p></div></div></section><section><div><div><h2 id="6d6e">Please tell us a bit about yourself. What is your background? what is your current position?</h2><p id="b291">Iâ€™ve always been interested in systems programming, and after obtaining my CS degree I got the opportunity to start a PhD at Ghent University, Belgium, right when Julia was first released around 2012. The language seemed intriguing, and since I wanted to gain some experience with LLVM, I decided to port some image processing research code from MATLAB and C++ to Julia. The goal was to match performance of the C++ version, but some of its kernels were implemented in CUDA Câ€¦ So obviously Julia needed a GPU back-end!</p><p id="7f14">That was easier said than done, of course, and much of my PhD was about implementing that back-end and (re)structuring the existing Julia compiler to facilitate these additional back-ends. Nowadays Iâ€™m at Julia Computing, where I still work on everything GPU-related.</p><h2 id="8f7f">What is JuliaGPU? What is the goal of the project?</h2><p id="43d9">JuliaGPU is the name we use to group GPU-related resources in Julia: Thereâ€™s a <a href="https://github.com/JuliaGPU" rel="noopener">GitHub organization</a> where most packages are hosted, a <a href="https://juliagpu.org/" rel="noopener">website</a> to point the way for new users, we have <a href="https://github.com/JuliaGPU/gitlab-ci" rel="noopener">CI infrastructure</a> for JuliaGPU projects, thereâ€™s a Slack channel and Discourse category, etc.</p><p id="ceaa">The goal of all this is to make it easier to use GPUs for all kinds of users. Current technologies often impose significant barriers to entry: CUDA is fairly tricky to install, C and C++ are not familiar to many users, etc. With the software we develop as part of the JuliaGPU organization, we aim to make it easy to use GPUs, without hindering the ability to optimize or use low-level features that the hardware has to offer.</p><h2 id="5da7">What is GPU computing? How important is it nowadays?</h2><p id="4de0">GPU computing means using the GPU, a device originally designed for graphics processing, to perform general-purpose computations. It has grown more important now that CPU performance is not improving as steadily as it used to. Instead, specialized devices like GPUs or FPGAs are increasingly used to improve the performance of certain computations. In the case of GPUs, the architecture is a great fit to perform highly-parallel applications. Machine learning networks are a good example of such parallel applications, and their popularity is one of the reasons GPUs have become so important.</p><h2 id="f596">Do you think Julia is an appropriate language to efficiently use GPU capabilities? Why?</h2><p id="775f">Juliaâ€™s main advantage is that the language was designed to be compiled. Even though the syntax is high-level, the generated machine code is<br>compact and has great performance characteristics (for more details, see <a href="http://janvitek.org/pubs/oopsla18b.pdf" rel="noopener">this paper</a>). This is crucial for GPU execution, where we are required to run native binaries and cannot easily (or efficiently) interpret code as is often required by other languageâ€™s semantics.</p><p id="b90b">Because weâ€™re able to directly compile Julia for GPUs, we can use almost all of the languageâ€™s features to build powerful abstractions. For example, you can define your own types, use those in GPU arrays, compose that with existing abstractions like lazy "Transpose" wrappers, access those on the GPU while benefiting from automatic bounds-checking (if needed), etc.</p><h2 id="824e">From a Python programmer perspective, how does CUDA.jl compare to PyCUDA? Are their functionalities equivalent?</h2><p id="cf3f">PyCUDA gives the programmer access to the CUDA APIs, with high-level Python functions that are much easier to use. CUDA.jl provides the same, but in Julia. The `hello world` from PyCUDAâ€™s home page looks almost identical in Julia:</p><pre><span id="a986">using CUDA</span><span id="03e4">function multiply_them(dest, a, b)<br> i = threadIdx().x<br> dest[i] = a[i] * b[i]<br> return<br>end</span><span id="9e7d">a = CuArray(randn(Float32, 400))<br>b = CuArray(randn(Float32, 400))</span><span id="5833">dest = similar(a)<br>@cuda threads=400 multiply_them(dest, a, b)</span><span id="1372">println(dest-a.*b)</span></pre><p id="396f">Thereâ€™s one very big difference: "multiply_them" here is a function written in Julia, whereas PyCUDA uses a kernel written in CUDA C. The reason is straightforward: Python is not simple to compile. Of course, projects like Numba prove that it is very much possible to do so, but in the end those are separate compilers that try to match the reference Python compilers as closely as possible. With CUDA.jl, we integrate with that reference compiler, so itâ€™s much easier to guarantee consistent semantics and follow suit when the language changes (for more details,<br>refer to <a href="https://arxiv.org/abs/1712.03112" rel="noopener">this paper</a>).</p><h2 id="5cf6">Are the packages in the JuliaGPU organization targeted to experienced programmers only?</h2><p id="6590">Not at all. CUDA.jl targets different kinds of (GPU) programmers. If you are confident writing your own kernels, you can do so, while using all of the low-level features CUDA GPUs have to offer. But if you are new to the world of GPU programming, you can use high-level array operations that use existing kernels in CUDA.jl. For example, the above element-wise multiplication could just as well be written as:</p><pre><span id="9c1f">using CUDA</span><span id="476a">a = CuArray(randn(Float32, 400))<br>b = CuArray(randn(Float32, 400))</span><span id="efdf">dest = a .* b</span></pre><h2 id="4c26">Is it necessary to know how to code in CUDA.jl to take full advantage of GPU computing in Julia?</h2><p id="208b">Not for most users. Julia has a powerful language of generic array operations ("map", "reduce", "broadcast", "accumulate", etc) which can be applied to all kinds of arrays, including GPU arrays. That means you can often re-use your codebase developed for the CPU with CUDA.jl (<a href="https://www.sciencedirect.com/science/article/abs/pii/S0965997818310123" rel="noopener">this paper</a> shows some powerful examples). Doing so often requires minimal changes: changing the array type, making sure you use array operations instead of for loops, etc.</p><p id="672d">Itâ€™s possible you need to go beyond this style of programming, e.g., because your application doesnâ€™t map cleanly onto array operations, to use specific GPU features, etc. In that case, some basic knowledge about CUDA and the GPU programming model is sufficient to write kernels in CUDA.jl.</p><h2 id="1a33">How is the experience of coding a kernel in CUDA.jl in comparison to CUDA C and how transferable is the knowledge to one another?</h2><p id="6a08">Itâ€™s very similar, and thatâ€™s by design: We try to keep the kernel abstractions in CUDA.jl close to their CUDA C counterparts such that the programming environment is familiar to existing GPU programmers. Of course, by using a high-level source language thereâ€™s many quality-of-life improvements. You can allocated shared memory, for example, statically and dynamically as in CUDA C, but instead of a raw pointers we use an N-dimensional array object you can easily index. An example from the <a href="https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/" rel="noopener">NVIDIA developer blog</a>:</p><pre><span id="ef8a">__global__ void staticReverse(int *d, int n)<br>{<br> __shared__ int s[64];<br> int t = threadIdx.x;<br> int tr = n-t-1;<br> s[t] = d[t];<br> __syncthreads();<br> d[t] = s[tr];<br>}</span></pre><p id="9cb0">The CUDA.jl equivalent of this kernel looks very familiar, but uses array objects instead of raw pointers:</p><pre><span id="996c">function staticReverse(d)<br> s = @cuStaticSharedMem(Int, 64)<br> t = threadIdx().x<br> tr = length(d)-t+1<br> s[t] = d[t]<br> sync_threads()<br> d[t] = s[tr]<br> return<br>end</span></pre><p id="9a14">Using array objects has many advantages, e.g. multi-dimensional is greatly simplified and we can just do "d[i,j]". But itâ€™s also safer, because these accesses are bounds checked:</p><pre><span id="3d65">julia&gt; a = CuArray(1:64)<br>64-element CuArray{Int64,1}:<br> 1<br> 2<br> 3<br> â‹®<br> 62<br> 63<br> 64</span><span id="0d9c">julia&gt; @cuda threads=65 staticReverse(a)<br>ERROR: a exception was thrown during kernel execution.<br>Stacktrace:<br> [1] throw_boundserror at abstractarray.jl:541</span></pre><p id="c17a">Bounds checking isnâ€™t free, of course, and once weâ€™re certain our code is correct we can add an "@inbounds" annotation to our kernel and get the high-performance code we expect:</p><pre><span id="6846">julia&gt; @device_code_ptx @cuda threads=64 staticReverse(a)<br>.visible .entry staticReverse(.param .align 8 .b8 d[16]) {<br> .reg .b32 %r&lt;2&gt;;<br> .reg .b64 %rd&lt;15&gt;;<br> .shared .align 32 .b8 s[512];</span><span id="09c9">mov.b64 %rd1, d;<br> ld.param.u64 %rd2, [%rd1];<br> ld.param.u64 %rd3, [%rd1+8];<br> mov.u32 %r1, %tid.x;<br> cvt.u64.u32 %rd4, %r1;<br> mul.wide.u32 %rd5, %r1, 8;<br> add.s64 %rd6, %rd5, -8;<br> add.s64 %rd7, %rd3, %rd6;<br> ld.global.u64 %rd8, [%rd7+8];<br> mov.u64 %rd9, s;<br> add.s64 %rd10, %rd9, %rd6;<br> st.shared.u64 [%rd10+8], %rd8;<br> bar.sync 0;<br> sub.s64 %rd11, %rd2, %rd4;<br> shl.b64 %rd12, %rd11, 3;<br> add.s64 %rd13, %rd9, %rd12;<br> ld.shared.u64 %rd14, [%rd13+-8];<br> st.global.u64 [%rd7+8], %rd14;<br> ret;<br>}</span><span id="4489">julia&gt; a<br>64-element CuArray{Int64,1}:<br> 64<br> 63<br> 62<br> â‹®<br> 3<br> 2<br> 1</span></pre><p id="3cee">Tools like "@device_code_ptx" make it easy for an experienced developer to inspect generated code and ensure the compiler does what he wants.</p><h2 id="164a">Why does having a compiler have such an impact in libraries like CUDA.jl? (How was the process of integrating it to the Julia compiler?)</h2><p id="e360">Because we have a compiler at our disposal, we can rely on higher-order functions and other generic abstractions that specialize based on the arguments that users provide. That greatly simplifies our library, but also gives the user very powerful tools. As an example, we have carefully implemented a `mapreduce` function that uses shared memory, warp intrinsics, etc to perform a high-performance reduction. The implementation is generic though, and will automatically re-specialize (even at run time) based on the arguments to the function:</p><pre><span id="9da7">julia&gt; mapreduce(identity, +, CuArray([1,2,3]))<br>6</span><span id="c680">julia&gt; mapreduce(sin, *, CuArray([1.1,2.2,3.3]))<br>-0.11366175839582586</span></pre><p id="52e8">With this powerful `mapreduce` …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notamonadtutorial.com/julia-gpu-98a461d33e21">https://notamonadtutorial.com/julia-gpu-98a461d33e21</a></em></p>]]>
            </description>
            <link>https://notamonadtutorial.com/julia-gpu-98a461d33e21</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840972</guid>
            <pubDate>Tue, 20 Oct 2020 18:48:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dev Methodology mostly doesn’t matter, just make up your own]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24840880">thread link</a>) | @necco908
<br/>
October 20, 2020 | https://linearb.io/blog/dev-methodology-doesnt-matter/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/dev-methodology-doesnt-matter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			




<h2><strong>A waterfall of old-schoolness&nbsp;</strong></h2>







<p>I worked as a developer using Waterfall for exactly 9 months. I was 22 years old and it was my first programmer job and first corporate environment. This place was old school. Like suit-wearing, personal cubicle type old school. Our CEO would hold all-hands meetings where everyone was required to stand the whole time and he would call people up to give speeches at random because he believed everyone should be good at public speaking.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-1024x488.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-768x366.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology.png.webp 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
<figcaption>22 year old Dan was NOT good at public speaking 🙂&nbsp;</figcaption></figure>







<p>At one offsite event, the CEO designated me as the company Complaint Manager. During the 4-day event employees were directed to give me their complaints. Of course my friends dropped anonymous and hilarious complaints because they knew that, at the end of each day, I was going to be called up to the stage to repeat back all of the complaints. What?!? Super old school.&nbsp;</p>



<p>One time, I was sent to work at a client’s office for a week, just so they could visibility see my team working on their project. And I mean that in the most literal sense. We didn’t have any meetings or recent project updates, they just wanted to make sure we were actually working.&nbsp;</p>



<p>I never saw a single line of my code in production during my 9 months I spent working there. I actually remember learning that my project was finally being sent to QA for testing the week I left. After 9 months. Old. School.</p>



<p>But I didn’t know any better at the time. I hadn’t heard of Agile yet, and no one told me we were doing Waterfall. Luckily I got out of there and found a job at Cloudlock where I learned about Agile and eventually worked my way up to VP of Engineering. But I’ll never forget my first year as a Waterfall programmer.</p>



<p>So does methodology matter? Absolutely. But…&nbsp;</p>







<h2><strong>We do agile… But</strong></h2>







<p>If you ask a software developer&nbsp; what methodology they follow, 95% of us will say we do agile…but, usually followed by some version of Scrum or Kanban. While this sounds like a worldwide consensus, the reality is that every dev team I’ve worked on or managed has had a different development process.&nbsp;</p>



<p>During my time as VP of Engineering at Cloudlock, I looked after 75 developers across 5 teams. Each team had their own unique process. There were team leads who had been working in software development for 25+ years and others that had <a href="https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/">just gotten promoted</a>. The younger leads liked having a more strict process to follow, whereas the more senior managers had a process they had customized over the years.&nbsp;</p>



<p>All of those teams built amazing software even though their methods differed per team. Why? Because software development is not a zero sum game. Just because one team is successful using Agile Scrum doesn’t mean another team will be less successful using Agile Kanban. Or Scrumban. Or SAFe.&nbsp;</p>



<p>There’s a lot of options out there so, instead of focusing on methodology, I find it makes sense to start with what you’re trying to do and work backwards.&nbsp;</p>







<h2><strong>A bespoke development process – The GigSmart dev team&nbsp;</strong></h2>







<p><em>“You got rid of teams?!?”&nbsp;</em></p>



<p>I recently caught up with my friend Chris Downard, VP of Engineering at GigSmart, to chat about dev methodology changes in light of current events. I was completely taken aback when the first thing he said to me was that he just got rid of teams in his engineering department.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-1024x488.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-768x366.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology.png.webp 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>I’m not personally strict about following this or that development method, but getting rid of teams felt a little extreme.&nbsp;&nbsp;</p>



<p>Chris: “It naturally evolved that way. Because of this remote culture that we adopted very rapidly, we just found that the back end people tended to support each other on their backend tickets; whether or not it was on their direct team or a direct feature they were working on. They were helping each other, committing to each other’s code, etc. So we kept the team thing going up until last month, and we were measuring that way, so we just eliminated it because it didn’t make sense anymore.”</p>



<p>Getting rid of teams works for Chris for two reasons. He runs a small-ish team of 14 developers and the team uses a Kanban style framework. If there are 3 or 4 features in flight, each team member is assigned to one as their dominant project, but they’re all on one team.&nbsp;</p>



<p>Many of the classic Scrum ceremonies are still followed, but he’s working on making them more effective as well.&nbsp;</p>



<p>“We do one large standup and it takes us 15 minutes to get through. People give their standup updates in order based on their dominant feature. So the first set of people who go, are the ones who are working on Feature A, and the second group that goes are all working on Feature B.”</p>



<p>On top of no teams and restructuring their daily, Chris says they work in sprints but use a Kanban board to increase speed.&nbsp;</p>



<p>“The product team loves that because if they decide that something is suddenly really hot because sales has run into this or that, we can address it immediately.”</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-1024x488.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-768x366.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology.png.webp 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<h3><strong>Why does GigSmart work this way?&nbsp;</strong></h3>







<ul><li>Chris believes in continuous improvement based on team feedback.</li></ul>







<p>When he runs sprint retros, anything that engineering brings up that isn’t working, they have a conversation about. He brings in product and they chat about ways to make it better, and then they test it. And if it doesn’t work, he readjusts, and tries to fix it. Since he started at GigSmart, there hasn’t been a 4 week period where their process has stayed the same.&nbsp;</p>







<ul start="2"><li>GigSmart’s most valuable outcome is speed.</li></ul>







<p>The methodology, process, or ethos that drives your team needs to be purpose built to achieve the outcome you want. At GigSmart they’re defined outcome was high quality and speed. As an on-demand staffing platform, they choose to prioritize hotfixes and bugs. Other companies might need to be more predictable, quality-driven, stable, consistent, etc. based on their business type and needed outcome.</p>







<ul start="3"><li>GigSmart is culture-driven&nbsp;</li></ul>







<p>“Build better, more engaged engineering teams… That’s probably what my actual official job description is. So culture really matters.” <a href="https://linearb.io/blog/our-dev-culture-is-based-on-bushido-samurai-code-my-interview-with-the-vp-of-engineering-at-gigsmart/">Chris and GigSmart CTO,&nbsp; Jason Waldrip, modeled their team cultural values</a> on the ancient samurai code of Bushido. 8 values that they’ve written down and strive to live and work by every day.&nbsp;</p>







<ul start="4"><li>GigSmart is data-driven</li></ul>







<p>Measuring is not enough, you have to measure with a purpose. You get what you measure. Everyone is familiar with this saying. Chris takes it a step further and actually encourages the team to look data about how they work in all of their day-to-day practices and ceremonies.&nbsp;</p>



<p>By defining his company’s most valuable outcome and listening to his developers, Chris has created a development process that is bespoke to his team today. Just like a custom tailored suit, his development method cannot be easily used by another company. It had to be made up.&nbsp;&nbsp;</p>







<h2><strong>Make up your own dev methodology: 4 guiding ideas</strong></h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-1024x488.gif.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-300x143.gif.webp 300w, https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-768x366.gif.webp 768w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-1024x488.gif" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-1024x488.gif 1024w, https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-300x143.gif 300w, https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-768x366.gif 768w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>Sometimes I just like building my own thing from the ground up. It’s why I started <a href="https://linearb.io/">LinearB.</a> Do you NEED to create your own development method? Definitely not.&nbsp;</p>



<p>It’s much easier to start with Scrum or Kanban and adapt from there. But times, they are a changin’, and maybe this is a good year to go through the exercise of redefining how you work.&nbsp;</p>



<p>After we started full-time remote back in March, my co-founder, Ori Keren, and I did just that. We created <a href="https://linearb.io/blog/asynchronous-development/">Asynchronous Development</a>, a development methodology designed around async communication and purpose-built for hybrid remote teams. It’s our favorite parts of Agile. A little bit of Scrum. A lot of what Ori and I learned over the years that really works for us. And a big dose of where we think the future of software development teamwork is headed.&nbsp;</p>



<p>Hundreds of teams are now following the Async Dev methodology. If we can make up our own dev methodology, you can too!&nbsp;</p>







<p><strong>Here’s 4 guiding ideas that will help you make up your own dev methodology</strong></p>







<ol><li><strong>Know your “why”&nbsp;</strong></li></ol>







<p>What matters to you? If it’s aligning to your company’s most important business goals, do you&nbsp; know what they are? Start-ups tend to want lots of new features as quickly as possible. More mature companies like predictability and quality. Find out and work backwards from there.&nbsp;</p>







<ol start="2"><li><strong>Don’t be dogmatic</strong></li></ol>







<p>Forget about the rules and just ask yourself… “How do we really want to work?” Ask your people. Especially your out-of-the-box thinkers. The more crazy ideas you throw in the mix, the more discussion you’ll create and the more you’ll end up with something that is really bespoke.&nbsp;</p>



<p>For example, the Agile manifesto says face-to-face communication is the most efficient way to transfer information. Is that still true for your team?</p>







<ol start="3"><li><strong>Retro your current process</strong></li></ol>



<p><strong><br></strong>Ask… “Why are we doing all of these things we do every day?” Do you really need a daily stand-up? Do you really need two week sprints? Are you realy getting value from them? The answer may be yes. But I bet if your team will have a lot of ideas of how they could be more dev-friendly and more efficient.&nbsp;</p>







<ol start="4"><li><strong>Bring data to the conversation&nbsp;</strong></li></ol>







<p>After you’re done exploring all of the pain from step 3, see if you can prove or disprove any of the assumptions and anecdotes with actual data. This might be the hard part, actually. The type of data you need is not necessarily accessible in your Git or project management system. If you need help, check out LinearB. Our <a href="https://linearb.io/pricing/">free-forever plan</a> provides tons of metrics and process visualizations to show you what’s working, bottlenecks and how you can improve efficiency, quality and teamwork. <a href="https://app.linearb.io/register">Click here to sign up</a> with your Git account.&nbsp;</p>







<p><strong>What’s your made up methodology?</strong></p>







<p>I know many of you have already customized your own dev methodology. I’d love to hear about it! What pieces of existing methods did you use? What new things did you invent? What is special about your approach? Please …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/dev-methodology-doesnt-matter/">https://linearb.io/blog/dev-methodology-doesnt-matter/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/dev-methodology-doesnt-matter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840880</guid>
            <pubDate>Tue, 20 Oct 2020 18:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Palo Alto Networks sends cease-and-desist letter to take down review videos]]>
            </title>
            <description>
<![CDATA[
Score 455 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24840119">thread link</a>) | @bonfire
<br/>
October 20, 2020 | https://orca.security/cybersecurity-community-transparency/ | <a href="https://web.archive.org/web/*/https://orca.security/cybersecurity-community-transparency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

				
							<div data-elementor-type="single" data-elementor-id="1240" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="665134c3" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="12af1bce" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<div data-id="19996313" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p><em>Abstract: A few weeks ago, Orca Security published a comparison between the Orca Cloud Security Platform and a few other cloud security tools—including a&nbsp;<a href="https://orca.security/prisma-cloud-security/">comparison with Palo Alto Networks Prisma</a>. In response, Palo Alto Networks sent a <a href="https://orca.security/wp-content/uploads/PANW-Legal-Letter-Cease-Desist.pdf" target="_blank" rel="noopener noreferrer">cease and desist letter</a>, demanding the comparison be removed immediately. Here is my response. I urge you to see&nbsp;<a href="https://www.youtube.com/playlist?list=PLDnqJTEi6ynvsGkSJHYeEmhz6_NfzKgbf">the videos in question</a>&nbsp;and if you, like me, believe the cybersecurity community deserves transparency and vendors shouldn’t be allowed to prevent publishing reviews or benchmarks via legal threats, then please share this post. You can also leave your own comments down below.</em></p>
<p><strong>To: Palo Alto Networks</strong></p>
<p><strong>CC: The cybersecurity community</strong></p>
<p><strong>Subject: The Cybersecurity community demands transparency, not legal threats&nbsp;</strong></p>
<p>Security has always been about transparency. The concept of security by obscurity was frowned upon as early as 1851—even before the invention of electricity—when&nbsp;<a href="https://en.wikipedia.org/wiki/Alfred_Charles_Hobbs">Alfred Hobbs</a>, a Massachusetts-based locksmith, demonstrated how then state-of-the-art locks could be picked. He explained that exposing the information would make the public more secure, as rogues already knew the deficiencies. The public needed to be educated, and he’d pursue better locks. Today’s locks are more advanced, but the principle is the same.</p>
<p>The cybersecurity community preaches about many products. All come with their own advantages and disadvantages, capabilities, and limitations. I believe that the only way practitioners can choose the tools that fit their environments best is by viewing factual evidence—not by relying solely on marketing materials. This is why we launched our&nbsp;<a href="https://orca.security/cloud-security-solutions/">Cloud Security Punch-Out! Series</a>, where we deploy a few tools—including Orca Security—on the exact same environment and share the results with viewers who deserve to see them. I urge you to take&nbsp;<a href="https://orca.security/prisma-cloud-security/">a look at the one we did with Palo Alto Networks;</a>&nbsp;as you’ll see we don’t hide those areas where Palo Alto Networks shines.</p>
<p>Unfortunately, Palo Alto Networks is now trying to use legal threats to prevent us from publishing&nbsp;these video&nbsp;reviews. In <a href="https://orca.security/wp-content/uploads/PANW-Legal-Letter-Cease-Desist.pdf" target="_blank" rel="noopener noreferrer">its letter</a>, Palo Alto Networks does not point to any factual inaccuracies in the reviews of its products’ performance. Instead, it premises its threats on flimsy, boilerplate contract terms that prohibit reviews and comparisons of its products and hollow trademark allegations purporting that Palo Alto Networks is sponsoring the videos.</p>
<p>It’s outrageous that the world’s largest cybersecurity vendor (its products being used by over 65,000 organizations according to its website), believes that its users aren’t entitled to share any benchmark or performance comparison of its products. According to its boilerplate contract terms that prohibit “disclosing, publishing, or otherwise making publicly available any benchmark, performance, or comparison tests” of its products, you’re in violation even if you publish the results of an internal comparison of Palo Alto Networks against other products as part of your procurement process. The same goes for the hundreds of Palo Alto Networks reviews on various sites that include G2 Crowd, Capterra, and Gartner Peer Insights. It means that only benchmarks approved by Palo Alto Networks can be published.</p>
<p>Palo Alto Networks appears oblivious to the fact that the New York Attorney General’s office&nbsp;<a href="https://www.leagle.com/decision/2003579195misc2d3841519">sued and won an injunction</a>&nbsp;against McAfee from enforcing its contractual restrictions against publishing reviews or comparisons of its products without its consent more than 17 years ago. In enacting the&nbsp;<a href="https://www.law.cornell.edu/uscode/text/15/45b">Consumer Review Fairness Act</a>, Congress has also prohibited businesses from including contract terms that prohibit consumers from reviewing products or services they purchase.</p>
<blockquote><p>Palo Alto Networks, do you think your products are flawless or that the bad guys will follow along, not openly talking about products’ deficiencies? If the answer is no to both, then why resort to legal threats to remove such benchmarks and comparisons? I refuse to accept a world where any vendor believes it has the right to prevent the free flow of information, and control which product reviews are made publicly available.</p></blockquote>
<p>I urge you to make your products better and focus your marketing efforts on demonstrating that, rather than throwing away money on ill-conceived gag efforts. Such action doesn’t benefit anyone. If you believe we missed something in our test, then tell us so we can make adjustments—we’ll happily integrate your comments and suggestions.</p>
<p>We could contract an objective third party to conduct additional tests. You could conduct your own tests with Palo Alto Networks and Orca Security’s products, then let the audience see and decide for themselves. All such actions would be far more beneficial to the industry, permitting both companies to learn and improve our products for the sake of customers.</p>
<p>As we all recently learned too well,&nbsp;<a href="https://www.contagionlive.com/news/sunlight-inactivates-the-airborne-virus-that-causes-covid19">sunlight is the best disinfectant</a>. The cybersecurity community deserves better than a vendor’s lack of transparency while wielding dubious legal methods. Palo Alto Networks is the worlds’ largest cybersecurity vendor; with great power comes great responsibility. Your products are great—but nothing is perfect, and the public should have free access to all of the facts.</p>
<p>Yours faithfully,<br>
Avi Shua, CEO and Co-Founder<br>
Orca Security</p>
		</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
					</div>
		</div>
		</div>
		
					
					
				
			</div></div>]]>
            </description>
            <link>https://orca.security/cybersecurity-community-transparency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840119</guid>
            <pubDate>Tue, 20 Oct 2020 17:31:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My platonic ideal for how engineering hiring should work]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 288 (<a href="https://news.ycombinator.com/item?id=24840013">thread link</a>) | @leeny
<br/>
October 20, 2020 | http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/ | <a href="https://web.archive.org/web/*/http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>I’ve been in and around eng hiring for the past 13 years, as an engineer, a recruiter, and a founder of a technical recruiting marketplace (interviewing.io). Over the course of those 13 years, I’ve become increasingly disgruntled at the state of hiring, and now I’m mad enough to write this blog post.</p>



<p>If you’ve ever been on either end of the table, you’re probably mad at the state of hiring, too. Whether you have given it a lot of thought or whether you just feel it deep down, something about the whole process feels off.</p>



<p>But we’ve been doing it this way for so long that we probably take much of how hiring works as gospel, and it’s really hard to tease apart all the different components of the process and examine why they are the way they are. In this post, I’d like to challenge many of the things we assume about hiring, and, perhaps most importantly, I’d like to lay out my platonic ideal for how eng hiring should work. It’s a simple axiom, really:</p>



<p><em>It should be easy for smart people to talk to other smart people.</em></p>



<p>Or, another way to put it … if I’m a good engineer, it should be easy for me to talk to a hiring manager at a company I might be interested in, at a time of my choosing. But that’s simply not possible today. Despite the refrain that we’re in a candidate’s market and that there’s a shortage of good candidates, which should mean that candidates should have the power to call the shots, today’s hiring process couldn’t be further removed from this ideal. And it’s not just broken for a specific type of candidate. It’s broken for <em>everyone.</em></p>



<p>If you’re reading this, you might be an engineering manager, a senior engineer with stellar credentials, a recent bootcamp grad, an engineer from a background traditionally underrepresented in tech, or some combination of these. <strong>What’s truly messed up about the status quo is that, regardless of which of these groups you fall into, your journey will be unnecessarily unpleasant. Though the degree of unpleasantness will not always be the same, it’s not about race, seniority, pedigree, or gender … or even which side of the table you’re on. Hiring, in its current incarnation, is broken for everybody.</strong></p>



<p>Why? Let us go then, you and I, into the bowels of the status quo.</p>



<h2>A candidate and a hiring manager, never the twain shall meet</h2>



<p>Let’s say that I’m a competent generalist engineer who looks good on paper, and I’m thinking that it’s time to look for a new job. What happens next? The idea of having to mount a full-on job search is so daunting.&nbsp;</p>



<p>I could try some job boards to see which companies are out there. But what would I filter on? I know a lot of programming languages but am not set on having to work in a specific one. How can I tell if I’ll hit it off with the team? I’m applying via a job board to a position I know next to nothing about — will anyone even respond?</p>



<p>Suppose I find some companies where I might want to work. If I’m lucky enough to know someone there, I’ll have to get them to refer me, even though that may not actually do much to speed things along. And if I don’t know anyone there, applying will be an exhausting long shot. Odds are no one will look at my application, and having to redo my resume — or worse, write cover letters — seems like the most tedious kind of busywork.</p>



<p>I guess I can always dig through the recruiter spam I’ve gotten. But do those recruiters still work at the company? If they do, how long will it actually take to get into the process?</p>



<p>Breaking character for a moment, a friend of mine recently got this recruiting email from Google, who has elevated gaslighting to an art form: somehow the fact that it takes two months to get through their process has become a <em>selling point.</em></p>



<figure><img loading="lazy" width="750" height="319" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-750x319.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-750x319.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-450x191.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-768x327.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail.png 1004w" sizes="(max-width: 750px) 100vw, 750px"></figure>



<p>Once I do get into the process, why do I have to endure the same intro call ten times with different recruiters who can’t tell me anything about what I’d be working on at any level of depth?</p>



<p>Do I join some platform, create a profile that I copy-paste everywhere (with writing that was just as painful as the aforementioned resume/cover letter) and sort of hope that decent companies contact me … only to have to begin the same recruiter calls over and over again, as above?</p>



<p>Will I have to take some quizzes that drill me on obscure syntax or make me solve toy problems that have no bearing on my engineering ability before I even get to have the aforementioned inane conversation with a recruiter?</p>



<p><strong>If I’m actually good at my job, why can’t I just set up some conversations with companies I think are cool and see if it’s a fit? Why do I have to subject myself and others to an endless parade of vapid conversations and the inevitable busywork that precedes them?</strong></p>



<p>Here’s the truth. Even if I look good on paper and am well-connected, hiring still sucks because of all the noise, uncertainty, and time wasted … but at least I have options. They might not be exactly the right options for me, but at least they exist. On the other hand, if I’m an engineer without a pedigree or a network, my choices are extremely limited, no matter how good I am. Recruiters aren’t reaching out to me, I’m not well-networked enough to have friends refer me, and I <em>definitely </em>don’t hear back when I apply.</p>



<hr>



<p>Let’s take a look at the other side of the table. Let’s say I’m an eng manager who needs to hire more competent generalists for my team. Having worked as both an eng manager and a recruiter, I can tell you that what happens next isn’t particularly inspiring.</p>



<p>As an eng manager, I sit down with a recruiter and try to explain what I’m looking for. Nine times out of ten, I want a <a href="https://www.joelonsoftware.com/2007/06/05/smart-and-gets-things-done/">smart person who can get shit done</a>. But, after a farcical game of telephone, somehow those criteria get warped into years of experience with a specific technology or requirements about where the candidate went to school. I also end up with an uninspired, sterile job description that fails to capture the imagination of any candidates who might unwittingly stumble upon it.</p>



<p><strong>My recruiter then goes to any number of sourcing tools of which LinkedIn Recruiter is the ubiquitous, lackluster market leader. They type in keywords I didn’t ask for and filter on credentials I don’t care about to come up with the same homogenous list of candidates every other recruiter at every other tech company is chasing.</strong></p>



<p>They then contact these candidates en masse with generic copy about my team and the hard problems we’re solving. They celebrate single-digit response rates and spend the minimal time left over to give a cursory glance at candidates applying directly.</p>



<h2>Why is hiring broken?</h2>



<p>So therein lies the ineffectual dance. This is the process we’ve come to accept. As far as I can tease out, the axioms that underlie today’s recruiting best practices go something like this (some of these were told to me verbatim when I was starting out as a recruiter, even):</p>



<ol><li><strong>Thou shalt not engage with active candidates. After all, in this market, strong candidates aren’t looking. Good recruiters build relationships so that when a good candidate does decide to enter the market, the recruiter is there, behind the next doorway, ready to spring!</strong></li><li><strong>Engineering time is expensive, so it’s critical to do as much top-of-funnel filtering as possible to make sure that it’s spent on the right candidates.</strong></li></ol>



<p>Are these axioms wrong? The sad truth is … not really. I’ve written in a <a href="http://blog.alinelerner.com/the-unvarnished-unbundled-guide-to-hiring-tools/">previous post about how market forces rule everything around me</a>, and recruiting best practices are no exception. In an economy with a surplus of jobs and a shortage of talent, it follows that the best talent is going to be harder to find, engineering time will be expensive, and recruiters in their current incarnation are, dare I say it, a necessary evil. <sup><a href="#footnote_0_2455" id="identifier_0_2455" title="From what you’ve read up until this point, you might think that I hate recruiters and find them useless. Not so, dear reader! I hate bad recruiters. And, unfortunately, most of them are bad. What’s sad is that the good ones, instead of spending time on tasks for which they’re uniquely qualified and well-suited, are instead stuck at the top of the funnel sourcing engineers whose qualifications they don’t have the domain expertise to evaluate and selling them on roles they don’t have the domain expertise to describe. The best recruiters I’ve worked with are singularly amazing at shepherding candidates through the process, tirelessly stewarding a company’s employer brand, advising hiring managers on the best ways to close, keeping an analytical eye on the funnel to identify issues before they even arise, and much more.">1</a></sup></p>



<p>The data supports our current world view. According to Lever (one of the two application tracking systems widely used by startups, Greenhouse is the other), here’s a breakdown of how many candidates from each source it takes to make a hire. Note that here, larger numbers are bad — for many companies, internal referrals are the best source and inbound applications are the worst.</p>



<figure><img loading="lazy" width="750" height="375" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-750x375.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-750x375.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-450x225.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-768x384.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2.png 1008w" sizes="(max-width: 750px) 100vw, 750px"><figcaption>Source: <a href="https://www.lever.co/recruiting-resources/articles/recruitment-process/" target="_blank" rel="noreferrer noopener">https://www.lever.co/recruiting-resources/articles/recruitment-process/</a></figcaption></figure>



<p>Looking at this data, you can see why recruiters simply ignore online applications. The same dynamics also apply to platforms such as AngelList — like any jobs board, it’s noisy and probably full of candidates who don’t have much leverage (e.g., juniors/bootcamp grads and people requiring visa sponsorship).</p>



<p>As for the value of eng time, guarding it carefully isn’t exactly wrong either. In fact, if you look at what a typical hiring process looks like today, you’ll see that most of the time spent is by engineers conducting interviews.</p>



<figure><table><thead><tr><th><strong>Hiring process stage</strong></th><th>Who does it?</th><th>How long does it take?</th></tr></thead><tbody><tr><td>Resume review</td><td>Recruiter</td><td>10-30 seconds</td></tr><tr><td>Recruiter screen</td><td>Recruiter</td><td>45 min</td></tr><tr><td>Technical phone screen</td><td>Engineer</td><td>1 hour</td></tr><tr><td>Onsite – Eng portion</td><td>Engineer</td><td>6 hours</td></tr><tr><td>Onsite – Recruiter portion</td><td>Recruiter</td><td>1 hour</td></tr><tr><td>Offer</td><td>Recruiter OR Eng mgr</td><td>1 hour</td></tr></tbody></table></figure>



<p>Engineering salaries are high, so given that most of the time spent on a single candidate is with engineers, it’s <em>rational</em> to put some recruiter gates at the top of the funnel to protect eng time. The idea is that recruiters will effectively screen out most candidates and only pass on the most promising ones to the eng team.</p>



<p>Unfortunately, when you look at an actual typical <em>funnel</em>, you’ll see that despite attempts to gate the top with recruiters filtering resumes and making intro calls, it’s not really working. Below is what a typical funnel looks like.</p>



<figure><img loading="lazy" width="750" height="89" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-750x89.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-750x89.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-450x53.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-768x91.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42.png 1092w" sizes="(max-width: 750px) 100vw, 750px"></figure>



<p>If you <a href="https://blog.interviewing.io/you-probably-dont-factor-in-engineering-time-when-calculating-cost-per-hire-heres-why-you-really-should/" target="_blank" rel="noreferrer noopener">do the math</a> and look at how many hours are spent — not per candidate but per hire (more useful because hires are ultimately what we want) — you’ll see that despite attempts to save eng time, recruiters spend roughly 15 hours a hire <sup><a href="#footnote_1_2455" id="identifier_1_2455" title="If we add in time to review resumes, it’s an extra five hours (at most).">2</a></sup> and engineers spend about 40. In a process where you don’t make an offer 50% of the time and only convert those offers to hires 50% of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/</a></em></p>]]>
            </description>
            <link>http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840013</guid>
            <pubDate>Tue, 20 Oct 2020 17:22:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS and their billions in IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 177 (<a href="https://news.ycombinator.com/item?id=24839887">thread link</a>) | @bgpdude
<br/>
October 20, 2020 | https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html | <a href="https://web.archive.org/web/*/https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>Earlier this week, I was doing some work on AWS and wanted to know what IP addresses were being used. Luckily for me, AWS publishes this all here <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="nofollow noopener">https://ip-ranges.amazonaws.com/ip-ranges.json</a>. When you go through this list, you’ll quickly see that AWS has a massive asset of IPv4 allocations. Just counting quickly I noticed a lot of big prefixes.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Ever wondered what all of the AWS network ranges are? You can find them all here:<a href="https://t.co/NBaBF6w0la">https://t.co/NBaBF6w0la</a><br>That's *a lot* of big prefixes!<br>4x /11, 14x /12, 30x /13, 78x /14, 184x /15, 278x /16</p>— Andree Toonk, Adelante! (@atoonk) <a href="https://twitter.com/atoonk/status/1316098702260359168?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

</figure><p>However, the IPv4 ranges on that list are just the ranges that are in use and allocated today by AWS. Time to dig a bit deeper.</p><h3 id="ipv4-address-acquisitions-by-aws">IPv4 address acquisitions by AWS</h3><p>Over the years, AWS has acquired a lot of IPv4 address space. Most of this happens without gaining too much attention, but there were a few notable acquisitions that I’ll quickly summarize below.</p><h4 id="2017-mit-selling-8-million-ipv4-addresses-to-aws">2017: MIT selling 8 million IPv4 addresses to AWS</h4><p>In 2017 <a href="https://www.internetsociety.org/blog/2017/05/mit-goes-on-ipv4-selling-spree/" rel="noopener">MIT sold half of its 18.0.0.0/8</a> allocation to AWS. This 18.128.0.0/9 range holds about 8 million IPv4 addresses.</p><h4 id="2018-ge-sells-3-0-0-0-8-to-aws">2018: GE sells 3.0.0.0/8 to AWS</h4><p>In 2018 the IPv4 prefix 3.0.0.0/8 was transferred from GE to AWS. With this, AWS became the proud owner of its first /8! That’s sixteen million new IPv4 addresses to feed us hungry AWS customers. <a href="https://news.ycombinator.com/item?id=18407173" rel="nofollow noopener">https://news.ycombinator.com/item?id=18407173</a></p><h4 id="2019-aws-buys-amprnet-44-192-0-0-10">2019: AWS buys AMPRnet 44.192.0.0/10</h4><p>In 2019 AWS bought a /10 from AMPR.org, the Amateur Radio Digital Communications (ARDC). The IPv4 range 44.0.0.0/8 was an allocation made to the Amateur Radio organization in 1981 and known as the AMPRNet. This sell caused a fair bit of discussion, check out the <a href="https://mailman.nanog.org/pipermail/nanog/2019-July/thread.html#102103" rel="noopener">nanog discussion here.</a></p><p>Just this month, it <a href="http://www.southgatearc.org/news/2020/october/sale-of-amateur-radio-amprnet-tcp-ip-addresses.htm" rel="noopener">became public knowledge</a> AWS paid $108 million for this /10. That’s $25.74 per IP address.</p><p>These are just a few examples. Obviously, AWS has way more IP addresses than the three examples I listed here. The IPv4 transfer market is very active. Check out this website to get a sense of all transfers: <a href="https://account.arin.net/public/transfer-log#NRPM-8.3IPv4" rel="noopener">https://account.arin.net/public/transfer-log</a></p><h3 id="all-aws-ipv4-addresses">All AWS IPv4 addresses</h3><p>Armed with the information above it was clear that not all of the AWS owned ranges were in the <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">JSON</a> that AWS published. For example, parts of the 3.0.0.0/8 range are missing. Likely because some of it is reserved for future use.</p><p>Combining all those IPv4 prefixes, removing duplicates and overlaps by aggregating them results in the following list of unique IPv4 address owned by AWS: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes</a></p><p>The total number of IPv4 addresses in that list is just over 100 Million (100,750,168). That’s <strong>the equivalent of just over six /8’s,</strong> not bad!</p><p>If we break this down by allocation size, we see the following:</p><pre><code>1x /8     =&gt; 16,777,216 IPv4 addresses
1x /9     =&gt; 8,388,608 IPv4 addresses
4x /10    =&gt; 16,777,216 IPv4 addresses
5x /11    =&gt; 10,485,760 IPv4 addresses
11x /12   =&gt; 11,534,336 IPv4 addresses
13x /13   =&gt; 6,815,744 IPv4 addresses
34x /14   =&gt; 8,912,896 IPv4 addresses
53x /15   =&gt; 6,946,816 IPv4 addresses
182x /16  =&gt; 11,927,552 IPv4 addresses
&lt;and more&gt;</code></pre><p>A complete breakdown can be found here: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size</a></p><h3 id="putting-a-valuation-on-aws-ipv4-assets">Putting a valuation on AWS’ IPv4 assets</h3><blockquote>Alright.. this is just for fun…</blockquote><p>Since AWS is (one of) the largest buyers of IPv4 addresses, they have spent a significant amount on stacking up their IPv4 resources. It’s impossible, as an outsider, to know how much AWS paid for each deal. However, we can for fun, try to put a dollar number on AWS’ current IPv4 assets.</p><p>The average price for IPv4 addresses has gone up over the years. From ~$10 per IP a few years back to ~$25 per IP <a href="https://auctions.ipv4.global/" rel="noopener">nowadays</a>. <br>Note that these are market prices, so if AWS would suddenly decide to sell its IPv4 addresses and overwhelm the market with supply, prices would drop. But that won’t happen since we’re all still addicted to IPv4 ;)</p><p>Anyway, let’s stick with $25 and do the math just for fun.</p><pre><code>100,750,168 ipv4 addresses x $25 per IP = $2,518,754,200</code></pre><p>Just<strong> over $2.5 billion worth of IPv4 addresses,</strong> not bad! </p><h3 id="peeking-into-the-future">Peeking into the future</h3><p>It’s clear AWS is working hard behind the scenes to make sure we can all continue to build more on AWS. One final question we could look at is: <em>how much buffer does AWS have?</em> ie. how healthy is their IPv4 reserve?</p><p>According to their <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="noopener">published data</a>, they have allocated roughly 53 Million IPv4 addresses to existing AWS services. We found that all their IPv4 addresses combined equates to approximately 100 Million IPv4 addresses. That means they still have ~47 Million IPv4 addresses, or 47% available for future allocations. That’s pretty healthy! And on top of that, I’m sure they’ll continue to source more IPv4 addresses. The IPv4 market is still hot!</p></div>
    </div></div>]]>
            </description>
            <link>https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839887</guid>
            <pubDate>Tue, 20 Oct 2020 17:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTTP/3 Explained]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24839451">thread link</a>) | @makeworld
<br/>
October 20, 2020 | https://http3-explained.haxx.se/en/ | <a href="https://web.archive.org/web/*/https://http3-explained.haxx.se/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="36cee8ea3e414cd592256f94bc6aeec7" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="ca91c66b1b1d47aa811801782b0040bf"><span><span data-key="5ca71efed92d4b09a9d6f5c6a6a231e8"><span data-offset-key="5ca71efed92d4b09a9d6f5c6a6a231e8:0">This book effort was started in March 2018. The plan is to document HTTP/3 and its underlying protocol: QUIC. Why, how they work, protocol details, the implementations and more.</span></span></span></p><p data-key="de30b46033534cb1a67156d01db21b78"><span><span data-key="4f22c1a5296849d4a79f407336fbea6b"><span data-offset-key="4f22c1a5296849d4a79f407336fbea6b:0">The book is entirely free and is meant to be a collaborative effort involving anyone and everyone who wants to help out.</span></span></span></p><p data-key="23c9519016f547be98eea91704bb1aaf"><span><span data-key="15c5a9c4648f44f49bbdf3d8efc1deab"><span data-offset-key="15c5a9c4648f44f49bbdf3d8efc1deab:0">A reader of this book is presumed to have a basic understanding of TCP/IP networking, the fundamentals of HTTP and the web. For further insights and specifics about HTTP/2 we recommend first reading up the details in </span></span><a href="https://daniel.haxx.se/http2/" target="_blank" rel="noopener noreferrer" data-key="f1b6b5f3082c40e18d7ba0d92f8bc4b8"><span data-key="c7cbabdd89114e2eb0476511547b0002"><span data-offset-key="c7cbabdd89114e2eb0476511547b0002:0">http2 explained</span></span></a><span data-key="60e14d9bef6b4f26b870c7fcde14cb20"><span data-offset-key="60e14d9bef6b4f26b870c7fcde14cb20:0">.</span></span></span></p><p data-key="257d025d390b42ae922e267a7b148923"><span><span data-key="de7313f8809647cbaff62d2997157223"><span data-offset-key="de7313f8809647cbaff62d2997157223:0">This book is created and the work is started by </span></span><a href="https://daniel.haxx.se/" target="_blank" rel="noopener noreferrer" data-key="0a4468c7093e47fcac8c01387870fbb1"><span data-key="29c04820a9724abbbc6e88f1f92fd2bf"><span data-offset-key="29c04820a9724abbbc6e88f1f92fd2bf:0">Daniel Stenberg</span></span></a><span data-key="70062ee310d5452fb962073362cea07a"><span data-offset-key="70062ee310d5452fb962073362cea07a:0">. Daniel is the founder and lead developer of </span></span><a href="https://curl.haxx.se/" target="_blank" rel="noopener noreferrer" data-key="349104d21fa249899c7f5778afd90c9a"><span data-key="664be569505e4df890cbaef88bb10e20"><span data-offset-key="664be569505e4df890cbaef88bb10e20:0">curl</span></span></a><span data-key="dacaa499f14f40ccbc8b61706a6f5e66"><span data-offset-key="dacaa499f14f40ccbc8b61706a6f5e66:0">, the world's most widely used HTTP client software. Daniel has worked with and on HTTP and internet protocols for over two decades and is the author of </span></span><a href="https://daniel.haxx.se/http2/" target="_blank" rel="noopener noreferrer" data-key="dee8c14c9f1844e09924193f400d2626"><span data-key="450d2f9d803a470fad4bedebe6a804eb"><span data-offset-key="450d2f9d803a470fad4bedebe6a804eb:0">http2 explained</span></span></a><span data-key="5a75e213258744d193202559829a122b"><span data-offset-key="5a75e213258744d193202559829a122b:0">.</span></span></span></p><p data-key="966986e70f8848fb9b978ebadf68263d"><span><span data-key="4e308dba6be34beb9d58d543d834f0da"><span data-offset-key="4e308dba6be34beb9d58d543d834f0da:0">The home page for this book is found at </span></span><a href="https://daniel.haxx.se/http3-explained" target="_blank" rel="noopener noreferrer" data-key="35c2412b01834a078b087683c67338e9"><span data-key="988f99e3f2914161a6a943e710a47005"><span data-offset-key="988f99e3f2914161a6a943e710a47005:0">daniel.haxx.se/http3-explained</span></span></a><span data-key="9878cf802a68430b873bad387780a929"><span data-offset-key="9878cf802a68430b873bad387780a929:0">.</span></span></span></p><p data-key="4e5debc9ee4943b197d009a4b9c3bfd2"><span><span data-key="9c3c3b42e84c429f8b77749679e96e78"><span data-offset-key="9c3c3b42e84c429f8b77749679e96e78:0">If you find mistakes, omissions, errors or blatant lies in this document, please send us a refreshed version of the affected paragraph and we will make amended versions. We will give proper credits to everyone who helps out. I hope to make this document better over time.</span></span></span></p><p data-key="1c615ee8d6a4493d82ffb90bf48a9a40"><span><span data-key="6840bb7163f8436c9df88d203b93850d"><span data-offset-key="6840bb7163f8436c9df88d203b93850d:0">Preferably, you submit </span></span><a href="https://github.com/bagder/http3-explained/issues" target="_blank" rel="noopener noreferrer" data-key="52b0b5f7bb864bcdaa8058d1d7e94397"><span data-key="3960e1d6da784d028baeede2d1b8f18c"><span data-offset-key="3960e1d6da784d028baeede2d1b8f18c:0">errors</span></span></a><span data-key="b72988a27e064077b6282f123b26ade0"><span data-offset-key="b72988a27e064077b6282f123b26ade0:0"> or </span></span><a href="https://github.com/bagder/http3-explained/pulls" target="_blank" rel="noopener noreferrer" data-key="72cd8e413c4442abaf2d69bc8da3916c"><span data-key="cd1b1d9cbe5a426abebd0b99fda9f70d"><span data-offset-key="cd1b1d9cbe5a426abebd0b99fda9f70d:0">pull requests</span></span></a><span data-key="d7864170226e4dbfb0380516ee3518fc"><span data-offset-key="d7864170226e4dbfb0380516ee3518fc:0"> on the book's GitHub page.</span></span></span></p><p data-key="d0548303fa104c6c8aa49d1151472bff"><span><span data-key="5944aa3c293849a6852bbf98e0745f6b"><span data-offset-key="5944aa3c293849a6852bbf98e0745f6b:0">This document and all its contents are licensed under the </span></span><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" data-key="f113fd53b3fd40b3be71f69bd34d0f5d"><span data-key="c1b5ecd2704745dbadfa7fc9a01d4e8d"><span data-offset-key="c1b5ecd2704745dbadfa7fc9a01d4e8d:0">Creative Commons Attribution 4.0 license</span></span></a><span data-key="2b3b8b952d37464097e5f9f75bc4975b"><span data-offset-key="2b3b8b952d37464097e5f9f75bc4975b:0">.</span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://http3-explained.haxx.se/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839451</guid>
            <pubDate>Tue, 20 Oct 2020 16:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beam Manifesto – A Tool for Thoughts]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24839414">thread link</a>) | @domleca
<br/>
October 20, 2020 | https://beamapp.co/bright_paper.html | <a href="https://web.archive.org/web/*/https://beamapp.co/bright_paper.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://beamapp.co/bright_paper.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839414</guid>
            <pubDate>Tue, 20 Oct 2020 16:36:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Document API for Cassandra]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24839327">thread link</a>) | @dwettlaufer
<br/>
October 20, 2020 | https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html | <a href="https://web.archive.org/web/*/https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
        
        <h4>Because, sometimes, we just want JSON.</h4>
      </p>
    </div><div>
      <div>
        <p><img data-src="/assets/images/stargate-profile.png" alt="Eric Borczuk" width="32" height="32" src="https://stargate.io/assets/images/stargate-profile.png">
          <span>By <span>Eric Borczuk</span></span>
          •
          <span>Oct 19, 2020</span>
        </p>
      </div>
    </div><div>
      <div>
        <div>
          <p>If you’re like me, when you start coding something new, you’re probably finding yourself working with JSON.  Maybe you’re using Node.js or Python or any other dynamic language that uses JSON-like data natively or maybe you’re working with data that you’re pulling or serving from REST APIs. Either way, increasingly it seems like everything is ending up in JSON at some point.  Most of the time, this isn’t a problem, it’s just the way that we build software these days.  There’s just one problem, and that’s that Cassandra isn’t particularly good at JSON…</p>

<p>To double-click on that, the problem isn’t the JSON data format itself, although Cassandra doesn’t make JSON easy, it’s the way most devs use JSON when we’re building our apps.  Iterative development means that plans change.  The user registration form now needs a couple of more fields and the front-end dev went ahead and added them.  That API I’m calling returns some extra data.   Welcome to the loosely coupled world, it’s all fun and games until my app needs to send it to the database.</p>

<p>In the early days, Cassandra actually made this pretty simple to do, but as the project matured and added features like enterprise-friendly SQL-like query languages and better indexing, that meant that we needed the database to enforce a schema.  Over time, it became harder and harder to use Cassandra for things like JSON and other document-oriented use cases.</p>

<p>Enter Stargate - if there’s one thing you should know about the Stargate team it’s that our personal mission is to make Cassandra easy for every developer.  Figuring out how to give Javascript devs native JSON support without having to give up any of the reliability and scalability goodness of Cassandra was a challenge we couldn’t pass up.</p>

<p>This idea gave rise to the Stargate <strong>Documents API</strong>, which lets most Cassandra distros (Cassandra 3.11, Cassandra 4.0, and DataStax Enterprise 6.8), work with JSON through a REST API.</p>

<h2 id="api-features-and-design">API features and design</h2>

<p>As <a href="https://github.com/tjake">Jake Luciani</a> and I started to create the bones of this API, we realized that Cassandra is nothing like a document store. Expressing data as rows is straightforward, but expressing trees of JSON data is really not. In addition, mapping that JSON data onto a table managed by Stargate and keeping both writes and reads reasonably fast adds an additional layer of complexity.</p>

<p>From here, we mapped out three main design components in order for this work:
Modeling Documents in Cassandra
Handling Reads and Writes
Figuring out Deletes</p>

<p>The rest of this blog walks through how we approached each design and resolved some hiccups along the way.
Modeling Documents in Cassandra with Document Shredding</p>

<p>The first thing that we had to decide  was the schema of the managed table that backs a document collection. Due to some great discussions with some Cassandra specialists, it was decided that when a user creates a document, a table will be created with a statement of the form:</p>

<figure><pre><code data-lang="sql"><span>create</span> <span>table</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>(</span>
  <span>key</span> <span>text</span><span>,</span>
  <span>p0</span> <span>text</span><span>,</span>
  <span>…</span> <span>p</span><span>[</span><span>N</span><span>]</span> <span>text</span><span>,</span>
  <span>bool_value</span> <span>boolean</span><span>,</span>
  <span>txt_value</span> <span>text</span><span>,</span> <span>d</span>
  <span>bl_value</span> <span>double</span><span>,</span> <span>leaf</span> <span>text</span>
<span>)</span></code></pre></figure>

<p>At this point is where we had to solve an unbounded data modeling problem. Because any JSON document that has a depth of [N] or less can be added to this table, each value in the JSON will get stored as a row in the table. So if I wanted to represent a document called “x” that has the JSON:</p>

<figure><pre><code data-lang="json"><span>{</span><span>"a"</span><span>:</span><span> </span><span>{</span><span> </span><span>"b"</span><span>:</span><span> </span><span>1</span><span> </span><span>},</span><span> </span><span>"c"</span><span>:</span><span> </span><span>2</span><span>}</span></code></pre></figure>

<p>The document would be “shredded” into rows looking like this:</p>

<table>
  <thead>
    <tr>
      <th>key</th>
      <th>p0</th>
      <th>p1</th>
      <th>dbl_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>x</td>
      <td>a</td>
      <td>b</td>
      <td>1</td>
    </tr>
    <tr>
      <td>x</td>
      <td>c</td>
      <td>null</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<p>For data with an array, such as:</p>

<figure><pre><code data-lang="json"><span>{</span><span>"a"</span><span>:</span><span> </span><span>{</span><span> </span><span>"b"</span><span>:</span><span> </span><span>1</span><span> </span><span>},</span><span> </span><span>"c"</span><span>:</span><span> </span><span>[{</span><span>"d"</span><span>:</span><span> </span><span>2</span><span>}]}</span></code></pre></figure>

<p>there would be two rows, like so:</p>

<table>
  <thead>
    <tr>
      <th>key</th>
      <th>p0</th>
      <th>p1</th>
      <th>p2</th>
      <th>dbl_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>x</td>
      <td>a</td>
      <td>b</td>
      <td>null</td>
      <td>1</td>
    </tr>
    <tr>
      <td>x</td>
      <td>c</td>
      <td>[0]</td>
      <td>d</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<p>Array elements are stored with square braces in the column.</p>

<h3 id="handling-reads-and-writes">Handling Reads and Writes</h3>

<p>The next problem that arose was that naïvely, updates to a document could require reading the document from the database, seeing what modification would have to be made, and then writing the updated data.  This “read-before-write” process is a notorious source of performance and consistency issues in most data stores.</p>

<p>Therefore, we resolved to avoid doing any read-before-write operations at all costs.</p>

<p>An interesting implementation detail that came up is that when you write some data to a document, the resulting write operation is just a simple batch with some inserts and deletes. In some cases, this can cause the document rows in the database to show two different states for the same JSON field.</p>

<p><em>And, upon reading the rows out, the Documents API reconciles conflicting information by accepting the data that has a later Cassandra write time (much like Cassandra itself!).</em></p>

<p>This allows us to write data really quickly while not compromising too much in reads either, as the reconciliation does not happen often and is also quite fast. It also gives us a very important core principle to our basic write and read operations:</p>
<ol>
  <li>Every write to a single document is a single batch of statements, and</li>
  <li>Every read from a single document is a single SELECT statement.</li>
</ol>

<p>So writes and reads are squared away - but what about deletes?</p>

<h3 id="figuring-out-deletes">Figuring out Deletes</h3>

<p>Because of the distributed nature of the database, a deletion in Cassandra actually is very similar to an insert, but instead a “tombstone” is written at a particular write time to signify the death of a row.</p>

<p>Rest in peace… almost</p>

<p>Cassandra periodically (the frequency here depends on your compaction strategy and/or cluster load) does a compaction operation to remove tombstones and alleviate this pressure, so the only way to avoid overwhelming Cassandra is to make sure that the frequency of deletions is low enough.</p>

<p>This poses a problem for the Document API specifically because of arrays. Let’s walk through this one.</p>

<p>Imagine that you have an array at some key that is of length 100000. If you then issue a replace operation (via a PUT) and decide to replace that array with some other value, then all of those 100000 rows would be deleted, causing 100000 tombstones to be written.  This is an enormous number of tombstones to be written in one operation, and if you do that just a few more times, Cassandra will likely get super slow. So the structure of the data in each table needed one last major modification.</p>

<p>We said before that array paths are stored in the database with square brackets; for example the element at index 0 would be stored as [0]. That would mean a deletion of 100000 elements would look like this:</p>

<figure><pre><code data-lang="sql"><span>DELETE</span> <span>FROM</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>where</span> <span>p0</span> <span>in</span> <span>(</span><span>'[0]'</span><span>,</span> <span>'[1]'</span><span>,</span> <span>'[2]'</span><span>,</span> <span>…</span><span>,</span> <span>'[99999]'</span><span>)</span></code></pre></figure>

<p>Causing 100000 tombstones to be written. Instead of doing that, we decided to pad all array elements with leading zeros, so the element at index 0 would instead be represented as [000000], and the element at index 99999 would be [099999]. Doing this allowed us to change the deletion statement to:</p>

<figure><pre><code data-lang="sql"><span>DELETE</span> <span>FROM</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>where</span> <span>p0</span> <span>&gt;=</span> <span>'[000000]'</span> <span>and</span> <span>p0</span> <span>&lt;=</span> <span>'[999999]'</span></code></pre></figure>

<p>Which causes only a single so-called “range” tombstone to be written, instead of 100000 cell tombstones (note that greater and less than works on strings in Cassandra and will compare lexically). It also relaxes the array length limit to one million elements, which is pretty neat! The time series below shows how the old vs. new implementation might behave, if you performed compactions every week:</p>

<p><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/tombstone_counts.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/tombstone_counts.png"></p>

<p>So the new strategy is just safer for deletions; it would require an incredibly large amount of deletion with the new strategy to even come close to the theoretical tombstone limits!</p>

<h2 id="preliminary-look-at-api-performance">Preliminary Look at API performance</h2>

<p>⚠️ Before starting on this section, we want to mention that benchmarking is a great tool, but does not necessarily represent how a system will behave under real load, out in the wild. We also haven’t done comparisons on the same hardware with other document stores…yet. Alright, let’s get to it!</p>

<p>In order to test that the Document API is reasonably fast, we ran a benchmark test using a single Cassandra storage node and a single Stargate node (Stargate is the API that contains the Documents API). We then ran two different benchmarks, one that uses HTTP GET to repeatedly get random paths in a document, and another that performs HTTP POSTs repeatedly to create brand new documents.  Each of these actions got run 100000 times, and here are two graphs of the results.</p>

<p>To keep things simple, as there is no baseline to compare things against just yet, the benchmark was performed using only one requester at a time, with light concurrency (10 users at once), and with more concurrency (100 users at once). Note that it’s expected with only one backend node that higher concurrency would cause degradation in performance; you should have multiple nodes to service that degree of concurrent requests!</p>

<p>Here are the results for reads:</p>



<table>
  <thead>
    <tr>
      <th>1 user:</th>
      <th>10 users:</th>
      <th>100 users:</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_1_User.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_1_User.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_10_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_10_Users.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_100_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_100_Users.png"></td>
    </tr>
  </tbody>
</table>

<p>And for writes:</p>



<table>
  <thead>
    <tr>
      <th>1 user:</th>
      <th>10 users:</th>
      <th>100 users:</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_1_User.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_1_User.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_10_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_10_Users.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_100_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_100_Users.png"></td>
    </tr>
  </tbody>
</table>

<p>From the above, we can see that the API performs pretty well at a reasonable level of concurrency for our setup.</p>



<p>We hope you enjoyed taking this quick tour of the Documents API. If you are interested in using the API head over to <a href="https://stargate.io/docs/stargate/0.1/quickstart/quickstart.html">Stargate.io</a> for more information about how to use it in your own Cassandra distribution.</p>

<p>If you are interested in contributing to Stargate, which is entirely open-source, we have two places for you to join us:</p>

<ol>
  <li>Come join our <a href="https://discord.gg/5gY8GDB">Discord Community</a> to follow the latest with Stargate and get early access to new stuff</li>
  <li>For any issues or pull requests, come on over to our <a href="https://www.github.com/stargate/stargate">GitHub Repository</a>
</li>
</ol>

<p>The APIs in Stargate are being actively developed, so we are hoping to be able to get back to you soon with news of even more improvements!</p>

        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839327</guid>
            <pubDate>Tue, 20 Oct 2020 16:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sym Raises $12M to Help Engineers Reclaim Security]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24839074">thread link</a>) | @abuggia
<br/>
October 20, 2020 | https://compliance.dev/2020/10/20/hello-sym/ | <a href="https://web.archive.org/web/*/https://compliance.dev/2020/10/20/hello-sym/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <h2 id="ode-to-the-accidental-security-engineer">Ode to the Accidental Security Engineer</h2>

<p><img src="https://d33wubrfki0l68.cloudfront.net/4fe780d6b00b9e7113ff3250d350453a4abcb8df/1fba2/assets/hello-sym/salute.png" alt="Salute"></p>

<blockquote>
  <p>Here’s to the accidental security engineers. The misfits. The rebels. The troublemakers. The round pegs in the square holes. The ones who see things differently.</p>

  <p>To every engineer who’s ever spent a day scratching their head, wondering how to comply with a new security policy.</p>

  <p>To all those lost sprints building annoying primitives that “<em>have</em> to exist somewhere already”.</p>

  <p>To all the stressful weeks of getting pulled off new features to help prepare for an audit.</p>

  <p>To every web app, Slack bot, CLI, and microservice that was hacked together to help roll out a new control, only to become a pain-in-the-ass to maintain.</p>

  <p>It was us. We’ve been the ones tasked with building this mess. Constantly trading off velocity and security. But no more. We’re going to solve this problem, together, once and for all.</p>

  <p>Enter: Sym.</p>
</blockquote>

<h2 id="hello-sym">Hello, Sym</h2>

<p>Sym is the security workflow platform made for engineers, by engineers. We solve the intent-to-execution gap between policies and workflows by providing fast-moving engineering teams with the just-right primitives to roll out best-practice controls.</p>

<p>Our hand-crafted Terraform templates let you easily provision instances of common security controls, while our Python SDK unlocks ridiculously simple customization to meet your team’s needs and integrate with existing tools. We’ve got our sights set on fixing the “Build vs Buy” problem with security workflows… the problem being that both options currently suck.</p>

<p>I’m overjoyed and humbled to share that we’re not embarking on this quest alone. We’re off to the races with a <a href="https://techcrunch.com/2020/10/20/sym-raises-9m-series-a-for-its-security-workflow-platform/">$9M Series A led by Sunil Dhaliwal at Amplify Partners</a>, following hot on the heels of a $3M Seed led by Robin Vasan at Mango Capital and Andy McLoughlin at Uncork Capital.</p>

<p>They say “never meet your heroes”, but with participation from security &amp; technology executives at GitHub, Datadog, Atlassian, Google, Bugsnag, and Segment, alongside early design partners like LaunchDarkly, we’re sure glad we met ours!</p>

<p>We’re excited to unveil our vision to the world, and announce that we’ve partnered with some of the best investors, engineers, and leaders in the industry to tackle this mountainous problem space. Every single person behind Sym has experienced our struggle first-hand (phew, we’re not crazy!), and won’t rest until we solve it. Let’s do this!</p>

<h2 id="howd-we-get-here">How’d we get here?</h2>

<p>Story time! I met Adam and Jon when I was a freshman at MIT. I distinctly remember walking into the Startup Career Fair wondering how I could circumvent the “no freshmen” rule most companies seemed to have when hiring interns. A friendly senior had let me know to watch out for the scores that recruiters would scrawl on resumes before haphazardly throwing them on the pile. A week prior, I watched a Facebook recruiter scratch a “1” onto mine, circling the sad number repeatedly before smiling and telling me to have a nice day. My world fell apart. This week was going to be different.</p>

<p>After having a great chat with this guy named <a href="https://en.wikipedia.org/wiki/Vladimir_Tenev">Vlad</a> (Robinhood wasn’t a Big Deal yet), I ran into Adam. He was the VP of Engineering at a Boston-based company called Localytics, and seemed as relieved as I was to be having a conversation. I hesitantly bought into his pitch, and scheduled a time to come onsite. Little did I know, that thoughtless commitment would totally change the trajectory of my life, and one day be responsible for the founding of Sym!</p>

<p>The first meeting was uneventful, or so I thought. I showed up 30 minutes late to a rather exasperated Adam lecturing me on the demerits of interview tardiness. Throughout the years, I’ve grown very accustomed to that frustrated expression 😅. Though I’m still notoriously late for most things in life, I’ve never again failed to be punctual for a job interview!</p>

<p>Against his better judgement, Adam brought me on as an early intern at Localytics. It was my first job, and he was my first boss. I learned the ropes (read: how to ignore everyone’s advice while minimally pissing them off), and got to collaborate on some <a href="https://eng.localytics.com/your-code-coverage-is-bad-and-you-should-feel-bad/">really fun projects</a>. Jon (our third cofounder) spent a lot of time reprimanding me.</p>

<p>We spent the rest of the summer <del>fighting</del> working together, and ended with a particularly controversial project where, against the better judgement of basically everyone, I pumped out a heap of flaky Javascript code for saving reports, and then peaced out from the company ✌️.</p>

<p>I’m extremely grateful that over the span of a decade, I stayed in touch with these two. Our relationship evolved, from manager-intern, to mentor-mentee, to peers, to cofounders. When I stepped away from my last company to start Sym, those two were my first call. And boy, am I glad they were.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/e009c90866e63034acc943efabdfa4a6457078d7/c6517/assets/hello-sym/map.png" alt="Map"></p>

<h2 id="evolution-of-sym">Evolution of Sym</h2>

<p>When Jon, Adam, and I sat down to build Sym, we wanted to solve a very simple problem: every engineering org we know in a heavily-regulated space was building the same damn tooling. Coming from healthcare and enterprise SaaS, we’d seen permutations of the same few workflows time and time again throughout our careers. A way to grant engineers temporary access to infrastructure? Check. A way to approve one-off queries? Check. Something to make quarterly risk assessments suck less? Check. Chat-Ops for approving outgoing deploys? Check.</p>

<p>The crazy thing was, these seemed to be ubiquitous across companies, compliance standards, even industries. Chatting with fellow founders about stuff I’d built to help keep my team productive would always result in one of two reactions: “<em>oh yea, we built the same thing! let’s trade notes…“</em>, or <em>“oh shit, we should have built this years ago”</em>. So we came up with a crazy idea: what if we just build all this stuff once, and put it out in the world for everyone to use. We were going to start with HIPAA-induced workflows. Sym: HIPAA in a box, for engineers. Of course, things rarely work out that simply.</p>

<p>We rapidly discovered something while talking to potential users: our hypothesis that everyone is building tools for the same workflows was a bit off. It wasn’t the case that everyone’s workflows were identical, but instead that they had the same <em>shared core</em>. It turns out, what most teams do is they start by building the same <strong>primitives</strong>, and then they layer on <strong>customizations</strong> that reflect existing processes and tools. So, we adjusted our approach to match this revelation.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/dc4f6494be10e2dfb90dc745bd96e83fffad695e/7aa7d/assets/hello-sym/graph.gif" alt="Graph"></p>

<p>Today, Sym is a set of workflow templates (<strong>primitives</strong>) for engineering teams working on improving security posture, and a suite of integrations (<strong>customizations</strong>) that connect those templates to existing systems and policies. Our mission is to enable any team to effortlessly build unobtrusive security and governance workflows, so we make sure to meet developers where they are: our primitives are exposed as Infrastructure-as-Code, and our SDK captures last-mile variance in workflows. The tools we use to distribute Sym Workflows are Terraform and Python, but your organization doesn’t have to be familiar with either to use us.</p>

<p>With Sym, you can roll out many common security and governance workflows with ~30 lines of declarative config and a couple function body definitions. Our goal is for you to blow your InfoSec team away; bring speed, sophistication, and thoroughness to your controls, without losing a whole month each time. Beautiful dashboards with just-right reports will materialize, without a single tedious line of logging code.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/8b56882478ed2e08f51d3f70075e993d385a2eef/193db/assets/hello-sym/code.png" alt="Code"></p>

<p>We’re currently live (in production!) at a handful of public and private companies in the Healthcare and B2B SaaS spaces. Our initial workflows focus on governance and just-in-time access of cloud and app-level resources.</p>

<p>Our latest customer is locking down SSH access by rolling out <a href="https://compliance.dev/2020/03/23/aws-session-manager-ssh-tunnels-with-less-user-management/">AWS Session Manager tunnels</a> as the preferred way to connect to instances, with the IAM Role required to use SSM protected by Sym. This is one of many examples where we’re able to help infra teams adopt cutting-edge cloud offerings while increasing security posture. If this sounds like something that you’d like for your team, please <a href="https://symops.com/">reach out</a>!</p>

<h2 id="but-what-about-x">But what about X?</h2>

<p>We’re in a crowded space! Luckily, we see the world with a unique lens. Sym brings an emphasis on developer experience, opinionated workflows that codify best practices, and an aspiration to be the bridge between Security and Compliance. The jury’s still out on whether we’re totally brilliant or totally out to lunch.</p>

<p>Our vision at Sym is to become the de-facto standard for implementing and showcasing security posture. Importantly, we’re not setting out to be a middleman levying a tax on the system. We saw enough of those in our healthcare days. Instead, we’re striving to improve the status quo for every stakeholder in the security equation; our place as the obvious-choice bridge between security and compliance will be an emergent property of the system we’re fighting to improve.</p>

<p>We’ve got a long way to go to make that vision a reality. In the interim, we’re tackling several problems plaguing our friends and colleagues.</p>

<h3 id="security-intent-to-implementation-gap">Security intent-to-implementation gap</h3>

<p>A security intent-to-implementation gap is endemic in our industry today. Experts are laying out guidelines, policies, and best-practices, only to be foiled by the gargantuan effort required to implement workflows that reflect these intents. And to be honest, we can’t really blame engineering teams for this. As an industry, we’ve learned not to roll our own crypto, because it’s so easy to shoot yourself in the foot, but can you imagine how many ways there are to screw up a Slack bot that issues temporary database credentials? Or how easy it is to forget to put MFA around an admin God-mode dashboard? Twitter hack, anyone?</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/2fa7f55e98cd8c615f0db83c6fd96236b49266a2/67dc7/assets/hello-sym/headlines.png" alt="Headlines"></p>

<p>Sensitive access workflows are the perfect example of a control that should be implemented once, and safely customized many times. This is where Sym is starting today.</p>

<h3 id="everyone-is-building-the-same-damn-things">Everyone is building the same damn things</h3>

<p>We’ve talked about this one extensively already. How many of us have to fight with the same <a href="https://compliance.dev/2020/07/17/okta-aws-join-all-roles-setting/">obsc…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://compliance.dev/2020/10/20/hello-sym/">https://compliance.dev/2020/10/20/hello-sym/</a></em></p>]]>
            </description>
            <link>https://compliance.dev/2020/10/20/hello-sym/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839074</guid>
            <pubDate>Tue, 20 Oct 2020 16:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting Football Results with Statistical Modelling]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24838958">thread link</a>) | @henrik_w
<br/>
October 20, 2020 | https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/ | <a href="https://web.archive.org/web/*/https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        <p>Football (or soccer to my American readers) is full of clichés: “It’s a game of two halves”, “taking it one game at a time” and “Liverpool have failed to win the Premier League”. You’re less likely to hear “Treating the number of goals scored by each team as independent Poisson processes, statistical modelling suggests that the home team have a 60% chance of winning today”. But this is actually a bit of cliché too (it has been discussed <a href="https://www.pinnacle.com/en/betting-articles/soccer/how-to-calculate-poisson-distribution">here</a>, <a href="https://help.smarkets.com/hc/en-gb/articles/115001457989-How-to-calculate-Poisson-distribution-for-football-betting">here</a>, <a href="http://pena.lt/y/2014/11/02/predicting-football-using-r/">here</a>, <a href="http://opisthokonta.net/?p=296">here</a> and <a href="https://dashee87.github.io/data%20science/football/r/predicting-football-results-with-statistical-modelling/">particularly well here</a>). As we’ll discover, a simple Poisson model is, well, overly simplistic. But it’s a good starting point and a nice intuitive way to learn about statistical modelling. So, if you came here looking to make money, <a href="http://www.make5000poundspermonth.co.uk/">I hear this guy makes £5000 per month without leaving the house</a>.</p>

<h2 id="poisson-distribution">Poisson Distribution</h2>

<p>The model is founded on the number of goals scored/conceded by each team. Teams that have been higher scorers in the past have a greater likelihood of scoring goals in the future. We’ll import all match results from the recently concluded Premier League (2016/17) season. There’s various sources for this data out there (<a href="https://www.kaggle.com/hugomathien/soccer">kaggle</a>, <a href="http://www.football-data.co.uk/englandm.php">football-data.co.uk</a>, <a href="https://github.com/jalapic/engsoccerdata">github</a>, <a href="http://api.football-data.org/index">API</a>). I built an <a href="https://github.com/dashee87/footballR">R wrapper for that API</a>, but I’ll go the csv route this time around.</p>

<div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>seaborn</span>
<span>from</span> <span>scipy.stats</span> <span>import</span> <span>poisson</span><span>,</span><span>skellam</span>

<span>epl_1617</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>"http://www.football-data.co.uk/mmz4281/1617/E0.csv"</span><span>)</span>
<span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>[[</span><span>'HomeTeam'</span><span>,</span><span>'AwayTeam'</span><span>,</span><span>'FTHG'</span><span>,</span><span>'FTAG'</span><span>]]</span>
<span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>.</span><span>rename</span><span>(</span><span>columns</span><span>=</span><span>{</span><span>'FTHG'</span><span>:</span> <span>'HomeGoals'</span><span>,</span> <span>'FTAG'</span><span>:</span> <span>'AwayGoals'</span><span>})</span>
<span>epl_1617</span><span>.</span><span>head</span><span>()</span>
</code></pre></div></div>

<div>
<table>
  <thead>
    <tr>
      <th></th>
      <th>HomeTeam</th>
      <th>AwayTeam</th>
      <th>HomeGoals</th>
      <th>AwayGoals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Burnley</td>
      <td>Swansea</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Crystal Palace</td>
      <td>West Brom</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Everton</td>
      <td>Tottenham</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Hull</td>
      <td>Leicester</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Man City</td>
      <td>Sunderland</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<p>We imported a csv as a pandas dataframe, which contains various information for each of the 380 EPL games in the 2016-17 English Premier League season. We restricted the dataframe to the columns in which we’re interested (specifically, team names and numer of goals scored by each team). I’ll omit most of the code that produces the graphs in this post. But don’t worry, you can find that code on <a href="https://github.com/dashee87/blogScripts/blob/master/Jupyter/2017-06-04-predicting-football-results-with-statistical-modelling.ipynb">my github page</a>. Our task is to model the final round of fixtures in the season, so we must remove the last 10 rows (each gameweek consists of 10 matches).</p>

<div><div><pre><code><span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>[:</span><span>-</span><span>10</span><span>]</span>
<span>epl_1617</span><span>.</span><span>mean</span><span>()</span>
</code></pre></div></div>

<div><div><pre><code>HomeGoals    1.591892
AwayGoals    1.183784
dtype: float64
</code></pre></div></div>

<p>You’ll notice that, on average, the home team scores more goals than the away team. This is the so called ‘home (field) advantage’ (discussed <a href="https://jogall.github.io/2017-05-12-home-away-pref/">here</a>) and <a href="http://bleacherreport.com/articles/1803416-is-home-field-advantage-as-important-in-baseball-as-other-major-sports">isn’t specific to soccer</a>. This is a convenient time to introduce the <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a>. It’s a discrete probability distribution that describes the probability of the number of events within a specific time period (e.g 90 mins) with a known average rate of occurrence. A key assumption is that the number of events is independent of time. In our context, this means that goals don’t become more/less likely by the number of goals already scored in the match. Instead, the number of goals is expressed purely as function an average rate of goals. If that was unclear, maybe this mathematical formulation will make clearer:</p>



<p> represents the average rate (e.g. average number of goals, average number of letters you receive, etc.). So, we can treat the number of goals scored by the home and away team as two independent Poisson distributions. The plot below shows the proportion of goals scored compared to the number of goals estimated by the corresponding Poisson distributions.</p>

<p><img src="https://dashee87.github.io/images/home_away_goals_python.png" alt=""></p>

<p>We can use this statistical model to estimate the probability of specfic events.</p>



<p>The probability of a draw is simply the sum of the events where the two teams score the same amount of goals.</p>



<p>Note that we consider the number of goals scored by each team to be independent events (i.e. P(A n B) = P(A) P(B)). The difference of two Poisson distribution is actually called a <a href="https://en.wikipedia.org/wiki/Skellam_distribution">Skellam distribution</a>. So we can calculate the probability of a draw by inputting the mean goal values into this distribution.</p>

<div><div><pre><code><span># probability of draw between home and away team</span>
<span>skellam</span><span>.</span><span>pmf</span><span>(</span><span>0.0</span><span>,</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>0</span><span>],</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>1</span><span>])</span>
</code></pre></div></div>



<div><div><pre><code><span># probability of home team winning by one goal</span>
<span>skellam</span><span>.</span><span>pmf</span><span>(</span><span>1</span><span>,</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>0</span><span>],</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>1</span><span>])</span>
</code></pre></div></div>



<p><img src="https://dashee87.github.io/images/skellam_goals_python.png" alt=""></p>

<p>So, hopefully you can see how we can adapt this approach to model specific matches. We just need to know the average number of goals scored by each team and feed this data into a Poisson model. Let’s have a look at the distribution of goals scored by Chelsea and Sunderland (teams who finished 1st and last, respectively).</p>

<p><img src="https://dashee87.github.io/images/chelsea_sunderland_goals_python.png" alt=""></p>

<h2 id="building-a-model">Building A Model</h2>

<p>You should now be convinced that the number of goals scored by each team can be approximated by a Poisson distribution. Due to a relatively sample size (each team plays at most 19 home/away games), the accuracy of this approximation can vary significantly (especially earlier in the season when teams have played fewer games). Similar to before, we could now calculate the probability of various events in this Chelsea Sunderland match. But rather than treat each match separately, we’ll build a more general Poisson regression model (<a href="https://en.wikipedia.org/wiki/Poisson_regression">what is that?</a>).</p>

<div><div><pre><code><span># importing the tools required for the Poisson regression model</span>
<span>import</span> <span>statsmodels.api</span> <span>as</span> <span>sm</span>
<span>import</span> <span>statsmodels.formula.api</span> <span>as</span> <span>smf</span>

<span>goal_model_data</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>epl_1617</span><span>[[</span><span>'HomeTeam'</span><span>,</span><span>'AwayTeam'</span><span>,</span><span>'HomeGoals'</span><span>]]</span><span>.</span><span>assign</span><span>(</span><span>home</span><span>=</span><span>1</span><span>)</span><span>.</span><span>rename</span><span>(</span>
            <span>columns</span><span>=</span><span>{</span><span>'HomeTeam'</span><span>:</span><span>'team'</span><span>,</span> <span>'AwayTeam'</span><span>:</span><span>'opponent'</span><span>,</span><span>'HomeGoals'</span><span>:</span><span>'goals'</span><span>}),</span>
           <span>epl_1617</span><span>[[</span><span>'AwayTeam'</span><span>,</span><span>'HomeTeam'</span><span>,</span><span>'AwayGoals'</span><span>]]</span><span>.</span><span>assign</span><span>(</span><span>home</span><span>=</span><span>0</span><span>)</span><span>.</span><span>rename</span><span>(</span>
            <span>columns</span><span>=</span><span>{</span><span>'AwayTeam'</span><span>:</span><span>'team'</span><span>,</span> <span>'HomeTeam'</span><span>:</span><span>'opponent'</span><span>,</span><span>'AwayGoals'</span><span>:</span><span>'goals'</span><span>})])</span>

<span>poisson_model</span> <span>=</span> <span>smf</span><span>.</span><span>glm</span><span>(</span><span>formula</span><span>=</span><span>"goals ~ home + team + opponent"</span><span>,</span> <span>data</span><span>=</span><span>goal_model_data</span><span>,</span> 
                        <span>family</span><span>=</span><span>sm</span><span>.</span><span>families</span><span>.</span><span>Poisson</span><span>())</span><span>.</span><span>fit</span><span>()</span>
<span>poisson_model</span><span>.</span><span>summary</span><span>()</span>
</code></pre></div></div>

<table>
<caption>Generalized Linear Model Regression Results</caption>
<tbody><tr>
  <th>Dep. Variable:</th>        <td>goals</td>      <th>  No. Observations:  </th>  <td>   740</td> 
</tr>
<tr>
  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   700</td> 
</tr>
<tr>
  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>    39</td> 
</tr>
<tr>
  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  
</tr>
<tr>
  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -1042.4</td>
</tr>
<tr>
  <th>Date:</th>           <td>Sat, 10 Jun 2017</td> <th>  Deviance:          </th> <td>  776.11</td>
</tr>
<tr>
  <th>Time:</th>               <td>11:17:38</td>     <th>  Pearson chi2:      </th>  <td>  659.</td> 
</tr>
<tr>
  <th>No. Iterations:</th>         <td>8</td>        <th>                     </th>     <td> </td>   
</tr>
</tbody></table>
<table>
<tbody><tr>
               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
  <th>Intercept</th>                  <td>    0.3725</td> <td>    0.198</td> <td>    1.880</td> <td> 0.060</td> <td>   -0.016     0.761</td>
</tr>
<tr>
  <th>team[T.Bournemouth]</th>        <td>   -0.2891</td> <td>    0.179</td> <td>   -1.612</td> <td> 0.107</td> <td>   -0.641     0.062</td>
</tr>
<tr>
  <th>team[T.Burnley]</th>            <td>   -0.6458</td> <td>    0.200</td> <td>   -3.230</td> <td> 0.001</td> <td>   -1.038    -0.254</td>
</tr>
<tr>
  <th>team[T.Chelsea]</th>            <td>    0.0789</td> <td>    0.162</td> <td>    0.488</td> <td> 0.626</td> <td>   -0.238     0.396</td>
</tr>
<tr>
  <th>team[T.Crystal Palace]</th>     <td>   -0.3865</td> <td>    0.183</td> <td>   -2.107</td> <td> 0.035</td> <td>   -0.746    -0.027</td>
</tr>
<tr>
  <th>team[T.Everton]</th>            <td>   -0.2008</td> <td>    0.173</td> <td>   -1.161</td> <td> 0.246</td> <td>   -0.540     0.138</td>
</tr>
<tr>
  <th>team[T.Hull]</th>               <td>   -0.7006</td> <td>    0.204</td> <td>   -3.441</td> <td> 0.001</td> <td>   -1.100    -0.302</td>
</tr>
<tr>
  <th>team[T.Leicester]</th>          <td>   -0.4204</td> <td>    0.187</td> <td>   -2.249</td> <td> 0.025</td> <td>   -0.787    -0.054</td>
</tr>
<tr>
  <th>team[T.Liverpool]</th>          <td>    0.0162</td> <td>    0.164</td> <td>    0.099</td> <td> 0.921</td> <td>   -0.306     0.338</td>
</tr>
<tr>
  <th>team[T.Man City]</th>           <td>    0.0117</td> <td>    0.164</td> <td>    0.072</td> <td> 0.943</td> <td>   -0.310     0.334</td>
</tr>
<tr>
  <th>team[T.Man United]</th>         <td>   -0.3572</td> <td>    0.181</td> <td>   -1.971</td> <td> 0.049</td> <td>   -0.713    -0.002</td>
</tr>
<tr>
  <th>team[T.Middlesbrough]</th>      <td>   -1.0087</td> <td>    0.225</td> <td>   -4.481</td> <td> 0.000</td> <td>   -1.450    -0.568</td>
</tr>
<tr>
  <th>team[T.Southampton]</th>        <td>   -0.5804</td> <td>    0.195</td> <td>   -2.976</td> <td> 0.003</td> <td>   -0.963    -0.198</td>
</tr>
<tr>
  <th>team[T.Stoke]</th>              <td>   -0.6082</td> <td>    0.197</td> <td>   -3.094</td> <td> 0.002</td> <td>   -0.994    -0.223</td>
</tr>
<tr>
  <th>team[T.Sunderland]</th>         <td>   -0.9619</td> <td>    0.222</td> <td>   -4.329</td> <td> 0.000</td> <td>   -1.397    -0.526</td>
</tr>
<tr>
  <th>team[T.Swansea]</th>            <td>   -0.5136</td> <td>    0.192</td> <td>   -2.673</td> <td> 0.008</td> <td>   -0.890    -0.137</td>
</tr>
<tr>
  <th>team[T.Tottenham]</th>          <td>    0.0532</td> <td>    0.162</td> <td>    0.328</td> <td> 0.743</td> <td>   -0.265     0.371</td>
</tr>
<tr>
  <th>team[T.Watford]</th>            <td>   -0.5969</td> <td>    0.197</td> <td>   -3.035</td> <td> 0.002</td> <td>   -0.982    -0.211</td>
</tr>
<tr>
  <th>team[T.West Brom]</th>          <td>   -0.5567</td> <td>    0.194</td> <td>   -2.876</td> <td> 0.004</td> <td>   -0.936    -0.177</td>
</tr>
<tr>
  <th>team[T.West Ham]</th>           <td>   -0.4802</td> <td>    0.189</td> <td>   -2.535</td> <td> 0.011</td> <td>   -0.851    -0.109</td>
</tr>
<tr>
  <th>opponent[T.Bournemouth]</th>    <td>    0.4109</td> <td>    0.196</td> <td>    2.092</td> <td> 0.036</td> <td>    0.026     0.796</td>
</tr>
<tr>
  <th>opponent[T.Burnley]</th>        <td>    0.1657</td> <td>    0.206</td> <td>    0.806</td> <td> 0.420</td> <td>   -0.237     0.569</td>
</tr>
<tr>
  <th>opponent[T.Chelsea]</th>        <td>   -0.3036</td> <td>    0.234</td> <td>   -1.298</td> <td> 0.194</td> <td>   -0.762     0.155</td>
</tr>
<tr>
  <th>opponent[T.Crystal Palace]</th> <td>    0.3287</td> <td>    0.200</td> <td>    1.647</td> <td> 0.100</td> <td>   -0.062     0.720</td>
</tr>
<tr>
  <th>opponent[T.Everton]</th>        <td>   -0.0442</td> <td>    0.218</td> <td>   -0.202</td> <td> 0.840</td> <td>   -0.472     0.384</td>
</tr>
<tr>
  <th>opponent[T.Hull]</th>           <td>    0.4979</td> <td>    0.193</td> <td>    2.585</td> <td> 0.010</td> <td>    0.120     0.875</td>
</tr>
<tr>
  <th>opponent[T.Leicester]</th>      <td>    0.3369</td> <td>    0.199</td> <td>    1.694</td> <td> 0.090</td> <td>   -0.053     0.727</td>
</tr>
<tr>
  <th>opponent[T.Liverpool]</th>      <td>   -0.0374</td> <td>    0.217</td> <td>   -0.172</td> <td> 0.863</td> <td>   -0.463     0.389</td>
</tr>
<tr>
  <th>opponent[T.Man City]</th>       <td>   -0.0993</td> <td>    0.222</td> <td>   -0.448</td> <td> 0.654</td> <td>   -0.534     0.335</td>
</tr>
<tr>
  <th>opponent[T.Man United]</th>     <td>   -0.4220</td> <td>    0.241</td> <td>   -1.754</td> <td> 0.079</td> <td>   -0.894     0.050</td>
</tr>
<tr>
  <th>opponent[T.Middlesbrough]</th>  <td>    0.1196</td> <td>    0.208</td> <td>    0.574</td> <td> 0.566</td> <td>   -0.289     0.528</td>
</tr>
<tr>
  <th>opponent[T.Southampton]</th>    <td>    0.0458</td> <td>    0.211</td> <td>    0.217</td> <td> 0.828</td> <td>   -0.369     0.460</td>
</tr>
<tr>
  <th>opponent[T.Stoke]</th>          <td>    0.2266</td> <td>    0.203</td> <td>    1.115</td> <td> 0.265</td> <td>   -0.172     0.625</td>
</tr>
<tr>
  <th>opponent[T.Sunderland]</th>     <td>    0.3707</td> <td>    0.198</td> <td>    1.876</td> <td> 0.061</td> <td>   -0.017     0.758</td>
</tr>
<tr>
  <th>opponent[T.Swansea]</th>        <td>    0.4336</td> <td>    0.195</td> <td>    2.227</td> <td> 0.026</td> <td>    0.052     0.815</td>
</tr>
<tr>
  <th>opponent[T.Tottenham]</th>      <td>   -0.5431</td> <td>    0.252</td> <td>   -2.156</td> <td> 0.031</td> <td>   -1.037    -0.049</td>
</tr>
<tr>
  <th>opponent[T.Watford]</th>        <td>    0.3533</td> <td>    0.198</td> <td>    1.782</td> <td> 0.075</td> <td>   -0.035     0.742</td>
</tr>
<tr>
  <th>opponent[T.West Brom]</th>      <td>    0.0970</td> <td>    0.209</td> <td>    0.463</td> <td> 0.643</td> <td>   -0.313     0.507</td>
</tr>
<tr>
  <th>opponent[T.West Ham]</th>       <td>    0.3485</td> <td>    0.198</td> <td>    1.758</td> <td> 0.079</td> <td>   -0.040     0.737</td>
</tr>
<tr>
  <th>home</th>                       <td>    0.2969</td> <td>    0.063</td> <td>    4.702</td> <td> 0.000</td> <td>    0.173     0.421</td>
</tr>
</tbody></table>

<p>If you’re curious about the <code>smf.glm(...)</code> part, you can find more information <a href="http://www.statsmodels.org/stable/examples/notebooks/generated/glm_formula.html">here</a> (edit: earlier versions of this post had erroneously employed a Generalised Estimating Equation (GEE)- <a href="https://stats.stackexchange.com/questions/16390/when-to-use-generalized-estimating-equations-vs-mixed-effects-models">what’s the difference?</a>). I’m more interested in the values presented in the <code>coef</code> column in the model summary table, which are analogous to the slopes in linear regression. Similar to <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>, we take the <a href="http://www.lisa.stat.vt.edu/sites/default/files/Poisson.and_.Logistic.Regression.pdf">exponent of the parameter values</a>. A positive value implies more goals (), while values closer to zero represent more neutral effects (). Towards the bottom of the table you might notice that <code>home</code> has a <code>coef</code> of 0.2969. This captures the fact that home teams generally score more goals than the away team (specifically, =1.35 times more likely). But not all teams are created equal. Chelsea has a <code>coef</code> of 0.0789, while the corresponding value for Sunderland is -0.9619 (sort of saying Chelsea (Sunderland) are better (much worse!) scorers than average). Finally, the <code>opponent*</code> values …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/">https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/</a></em></p>]]>
            </description>
            <link>https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24838958</guid>
            <pubDate>Tue, 20 Oct 2020 16:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I created a webapp to help me learn simplified Chinese characters]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24838236">thread link</a>) | @tmsbrg
<br/>
October 20, 2020 | https://www.thomasvanderberg.nl/blog/cn-hanzi/ | <a href="https://web.archive.org/web/*/https://www.thomasvanderberg.nl/blog/cn-hanzi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  
  

  

  <div itemprop="articleBody">
    <p>Find common Chinese characters using pinyin.</p>

<p>Click the image to try it now:</p>

<p><a href="https://www.thomasvanderberg.nl/cn/hanzi/"><img src="https://www.thomasvanderberg.nl/images/hanzi_screenshot.png" alt="Hanzi searchtool showing common Chinese characters pronounced &quot;shi&quot;"></a></p>

<h2 id="what">What</h2>

<p>It’s a tool that allows you to enter pinyin and optionally a tone number and shows only the <em>commonly used</em> Chinese characters with this pronunciation.</p>

<p>It allows you to switch between the top 3500 character list (frequently used) or the top 6500 (relatively common),</p>

<p>Some other features include showing or hiding all pinyin pronunciations for the characters, and showing or searching by the index of the character from the source <a href="https://en.wikipedia.org/wiki/Table_of_General_Standard_Chinese_Characters">Table of General Standard Chinese Characters</a>.</p>

<p>It currently only deals with simplified characters, because that’s what the source deals with and what I’m trying to learn.</p>

<p>Note that this is not a comprehensive Chinese learning tool. To learn Chinese you need to learn words, not just characters. Characters are just one layer in the Chinese language, and even full understanding of all Chinese characters would not mean you’ve learned the language.</p>

<h2 id="why-i-made-this">Why I made this</h2>

<p>While learning Chinese, I wanted to get an understanding of which Chinese characters are actually in common use. If you look in a dictionary for a list of Chinese characters, you will get a bewildering amount of characters. Dictionaries try to be comprehensive. Fortunately, most of these are only in historic use.</p>

<p>I wanted to remove the forest of irrelevant (for my purposes) characters and find get a list of ones actually worth investing time into.</p>

<p>I made this to get an overview and easily be able to answer questions like “how many common characters share this pronunciation?”.</p>

<p>I also wanted it to work without having to wait for a web page to load for each query. I made it work using a fully offline search (you download the data when loading the page itself).</p>

<h2 id="sources-and-data">Sources and data</h2>

<p>During my search I found this official list of <a href="https://en.wikipedia.org/wiki/Table_of_General_Standard_Chinese_Characters">Table of General Standard Chinese Characters</a> made by the Chinese government.</p>

<p>Sadly, this list is a rasterized PDF which does not even contain the pronunciation of these characters.</p>

<p>Still, it seemed like a good authoritative reference of commonly used characters. I started searching around and found a text version of it on <a href="http://xh.5156edu.com/page/z6211m4474j19255.html">this Chinese webpage</a>. While checking the data I found it had some mistakes around characters 3649 to 3668, which I had to fix manually.</p>

<p>To combine this with pronunciation data I found the <a href="ftp://ftp.cuhk.hk/pub/chinese/ifcss/software/data/Uni2Pinyin.gz">Unicode Pinyin Table</a>. I’ve added numerouos pronunciations manually, when I found them missing from that source. I’ve logged my manual edits in <a href="https://www.thomasvanderberg.nl/files/edits-to-hanzi-pinyin.txt">edits-to-hanzi-pinyin.txt</a>. Note that since I’m only a basic Chinese speaker myself, I can’t exclude that there’s likely more mistakes. I’m open to using a more reliable source for pronunciation data if one is available.</p>

<p>Using this data I created the <a href="https://www.thomasvanderberg.nl/files/hanzi-pinyin.6500.csv">hanzi-pinyin.6500.csv</a> and <a href="https://www.thomasvanderberg.nl/files/hanzi-pinyin.3500.csv">hanzi-pinyin.3500.csv</a> files which are the source of the Hanzi search tool.</p>

<h2 id="how-did-i-make-this">How did I make this</h2>

<p>Originally I just used <a href="https://en.wikipedia.org/wiki/Grep">grep</a> to search the hanzi-pinyin CSV files, but found it to become cumbersome due to the need to write regular expressions when I just wanted to think about pinyin.</p>

<p>I created the <a href="https://www.thomasvanderberg.nl/files/cnhz.py">cnhz</a> python script for myself, originally as a simple wrapper to build the grep regexes for me so I could just write pinyin. I then added more features around it.</p>

<p>As it got more useful I thought about how I could make it more accessible for other Chinese learners too. Most of them do not use Linux or have Python installed. I thought of rewriting it in Go to make it a single executable - but found the command line format would be awkward for most people. Also Windows cmd.exe does not support Chinese characters.</p>

<p>I eventually decided to turn it into a webpage. the CSV files were sufficiently small that the entire database could be loaded into the browser’s memory so you could do a completely client side search - making the experience much smoother than loading an online dictionary entry.</p>

<p>Also, because I can easily host it on my own web page, which I pay for anyway, I don’t have any need to add advertisements or anything to make the experience worse.</p>

<p>Furthermore, the page can easily be downloaded and used offline by any learner in case my site goes down or for when you don’t have internet.</p>

<p>I tried to support offline working more by making the site into a <a href="https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps">progressive web app</a>. However, while adding a manifest was easy, I found that to add a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API">service worker</a> (which allows offline caching) - I would have to move all assets including a copy of my main CSS file to /cn/hanzi/. Not having time to figure this out at the moment, I decided to not add service workers for now.</p>

<p>By the way, the <a href="http://localhost:4000/js/hanzi_list.js">hanzi_list.js</a> file was generated from the CSV sources using an <code>awk</code> script:</p>

<div><div><pre><code>&lt; ../files/hanzi-pinyin-full.csv \
    awk \
    'NR==1 { printf "const hanzi_3500 = \"" }
     NR==3501 { printf "\"; const hanzi_6500 = hanzi_3500 + \"" }
     { print NR","$0"\\n\\" }
     END { print "\";\nconst hanzi_6500_split = hanzi_6500.split(\"\\n\");" }' \
 &gt; ../js/hanzi_list.js
</code></pre></div></div>

<p>I hope you find my <a href="https://www.thomasvanderberg.nl/cn/hanzi">Chinese hanzi tool</a> useful. If you have any questions or want to contact me, see my details below.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.thomasvanderberg.nl/blog/cn-hanzi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24838236</guid>
            <pubDate>Tue, 20 Oct 2020 15:11:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Just Write the Parser]]>
            </title>
            <description>
<![CDATA[
Score 250 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24837898">thread link</a>) | @matt_d
<br/>
October 20, 2020 | https://tiarkrompf.github.io/notes/?/just-write-the-parser/ | <a href="https://web.archive.org/web/*/https://tiarkrompf.github.io/notes/?/just-write-the-parser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tiarkrompf.github.io/notes/?/just-write-the-parser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837898</guid>
            <pubDate>Tue, 20 Oct 2020 14:44:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why build another website builder?]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 87 (<a href="https://news.ycombinator.com/item?id=24837331">thread link</a>) | @apledger3
<br/>
October 20, 2020 | https://www.makeswift.com/blog/why-build-another-website-builder | <a href="https://web.archive.org/web/*/https://www.makeswift.com/blog/why-build-another-website-builder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div width="[object Object]" data-slate-editor="true" data-key="8882" autocorrect="on" spellcheck="true" data-gramm="false"><p data-slate-object="block" data-key="8883"><span data-slate-object="text" data-key="8884"><span data-slate-leaf="true" data-offset-key="8884:0"><span><span data-slate-string="true">Name something expensive that's difficult to build and trashed after each use.</span></span></span></span></p><p data-slate-object="block" data-key="8887"><span data-slate-object="text" data-key="8888"><span data-slate-leaf="true" data-offset-key="8888:0"><span><span data-slate-string="true">Did you say rockets? No, SpaceX figured out how to reuse those in 2015. </span></span></span></span></p><p data-slate-object="block" data-key="8891"><span data-slate-object="text" data-key="8892"><span data-slate-leaf="true" data-offset-key="8892:0"><span><span data-slate-string="true">I'm talking about your company's website. Completely overhauling the website has become so routine that we've become numb to the pain of throwing it all away, over and over again.</span></span></span></span></p><p data-slate-object="block" data-key="8895"><span data-slate-object="text" data-key="8896"><span data-slate-leaf="true" data-offset-key="8896:0"><span><span data-slate-string="true">Let's explore why this happens.</span></span></span></span></p><p data-slate-object="block" data-key="8899"><span data-slate-object="text" data-key="8900"><span data-slate-leaf="true" data-offset-key="8900:0"><span><span data-slate-string="true">Imagine you're the cofounder of a new company. You need to set up a website, but your product partner is already behind on features so that leaves it solely up to you. What's your plan? Given the tight budget and schedule, the disciplined move would be to quickly use a template in an inexpensive website builder. You can graduate to something a little more custom once you have more resources and your brand, positioning, and voice figured out.</span></span></span></span></p><p data-slate-object="block" data-key="8903"><span data-slate-object="text" data-key="8904"><span data-slate-leaf="true" data-offset-key="8904:0"><span><span data-slate-string="true">Sounds like a good plan, but anyone who's gone down this path knows it's never as simple as it seems.</span></span></span></span></p><p data-slate-object="block" data-key="8907"><span data-slate-object="text" data-key="8908"><span data-slate-leaf="true" data-offset-key="8908:0"><span><span data-slate-string="true">For one, the template never lasts as long as you need it to. You realize the design isn't working, or your competitor just unexpectedly made a move. So you start trying to make changes. Swapping out the text and images comes easy, but as soon as you start adjusting the layout, frustration begins to set in. You've got a million other things to do and for some reason you can't get the page to look right on mobile. </span></span></span></span></p><p data-slate-object="block" data-key="8911"><span data-slate-object="text" data-key="8912"><span data-slate-leaf="true" data-offset-key="8912:0"><span><span data-slate-string="true">As it turns out, the same features and guard rails that made it easy to stand up the template have now become the reason it's hard to iterate. You're stuck, and whether or not you were ready, the time has come</span></span></span></span><span data-slate-object="text" data-key="8913"><span data-slate-leaf="true" data-offset-key="8913:0"><span><span data-slate-string="true"> to deal with the classic website building dilemma:</span></span></span></span></p><p data-slate-object="block" data-key="8916"><span data-slate-object="text" data-key="8917"><span data-slate-leaf="true" data-offset-key="8917:0"><span><span data-slate-string="true">Do you stay put and compromise on your vision, or invest in another solution that </span></span></span></span><span data-slate-object="text" data-key="8918"><span data-slate-leaf="true" data-offset-key="8918:0"><span><span data-slate-string="true">might</span></span></span></span><span data-slate-object="text" data-key="8919"><span data-slate-leaf="true" data-offset-key="8919:0"><span><span data-slate-string="true"> be better?</span></span></span></span></p><p data-slate-object="block" data-key="8922"><span data-slate-object="text" data-key="8923"><span data-slate-leaf="true" data-offset-key="8923:0"><span><span data-slate-string="true">After researching more advanced solutions for a few days, it starts to become apparent that you're out of your depth. There are so many different products, and every time you begin stepping away from the template you're consistently met with a giant learning curve. Frustration sets in again so you decide to call that technical friend. You're in luck! She's got her favorite tool and she's available to help.</span></span></span></span></p><p data-slate-object="block" data-key="8926"><span data-slate-object="text" data-key="8927"><span data-slate-leaf="true" data-offset-key="8927:0"><span><span data-slate-string="true">Unfortunately, all you're about to do is move your bottleneck. You may think once things are set up you can say your goodbyes, but the reality is you're never free. As your team and ideas grow you'll need more and more help, and she'll be the only one who can make the big changes. Your projects will start moving slower and slower. But on the bright side, at least you'll be able to get it done... eventually.</span></span></span></span></p><p data-slate-object="block" data-key="8930"><span data-slate-object="text" data-key="8931"><span data-slate-leaf="true" data-offset-key="8931:0"><span><span data-slate-string="true">But what happens if she leaves? Nobody likes stepping into someone else's mess, so it ends up being cheaper to just rebuild using whatever tool the new technical expert is comfortable with. </span></span></span></span><span data-slate-object="text" data-key="8932"><span data-slate-leaf="true" data-offset-key="8932:0"><span><span data-slate-string="true">Is it any mystery, then, why we're stuck in this constant build, trash, move, build cycle?</span></span></span></span><span data-slate-object="text" data-key="8933"><span data-slate-leaf="true" data-offset-key="8933:0"><span><span data-slate-string="true"> </span></span></span></span><span data-slate-object="text" data-key="8934"><span data-slate-leaf="true" data-offset-key="8934:0"><span><span data-slate-string="true">The solutions have changed, but the underlying trade-off hasn't. </span></span></span></span><span data-slate-object="text" data-key="8935"><span data-slate-leaf="true" data-offset-key="8935:0"><span><span data-slate-string="true">All options are either too basic and restrictive, or too technical and complex.</span></span></span></span></p><p data-slate-object="block" data-key="8938"><span data-slate-object="text" data-key="8939"><span data-slate-leaf="true" data-offset-key="8939:0"><span><span data-slate-string="true">Founders building out early marketing for their startups are not the only ones who experience this. At some point, all marketers feel this pain.</span></span></span></span></p><p data-slate-object="block" data-key="8942"><span data-slate-object="text" data-key="8943"><span data-slate-leaf="true" data-offset-key="8943:0"><span><span data-slate-string="true">The problem is so widespread that it's given birth to a whole category of products called landing page builders.</span></span></span></span></p><p data-slate-object="block" data-key="8946"><span data-slate-object="text" data-key="8947"><span data-slate-leaf="true" data-offset-key="8947:0"><span><span data-slate-string="true">Marketers are so fed up with being sidelined that they're willing to duct tape their site with </span></span></span></span><span data-slate-object="text" data-key="8948"><span data-slate-leaf="true" data-offset-key="8948:0"><span><span data-slate-string="true">mostly</span></span></span></span><span data-slate-object="text" data-key="8949"><span data-slate-leaf="true" data-offset-key="8949:0"><span><span data-slate-string="true"> on-brand pages, just to have some operational independence when it comes to web content. Sure, landing page builders can have extra features bolted on like A/B testing and analytics, but they aren't the real reason marketers are out shopping for a solution. Marketers are looking for a place where they can get creative and not break anything.</span></span></span></span></p><p data-slate-object="block" data-key="8952"><span data-slate-object="text" data-key="8953"><span data-slate-leaf="true" data-offset-key="8953:0"><span><span data-slate-string="true">We know this because we built and eventually sunset a landing page builder, Landing Lion. Many of our customers wished they could build full websites in it, and some actually did. Despite its many shortcomings around bulk management, a surprising number of customers were willing to put in extra manual work to build and maintain full websites. The reason? Our user experience was actually designed for them—intelligent and tech-savvy generalists who wanted to break free from the template without having to go get a degree. They could finally build exactly what they envisioned and they could do it by themselves, quickly.</span></span></span></span></p><p data-slate-object="block" data-key="8956"><span data-slate-object="text" data-key="8957"><span data-slate-leaf="true" data-offset-key="8957:0"><span><span data-slate-string="true">The real problem was that for the rest of our customers, their websites were locked down. They'd been delicately constructed by the real owners, the technical experts. But who is ultimately responsible for the </span></span></span></span><span data-slate-object="text" data-key="8958"><span data-slate-leaf="true" data-offset-key="8958:0"><span><span data-slate-string="true">entire</span></span></span></span><span data-slate-object="text" data-key="8959"><span data-slate-leaf="true" data-offset-key="8959:0"><span><span data-slate-string="true"> brand experience, website included? The marketers.</span></span></span></span></p><p data-slate-object="block" data-key="8962"><span data-slate-object="text" data-key="8963"><span data-slate-leaf="true" data-offset-key="8963:0"><span><span data-slate-string="true">That's why we're building Makeswift.</span></span></span></span></p></div></div><div><div width="[object Object]" data-slate-editor="true" data-key="8965" autocorrect="on" spellcheck="true" data-gramm="false"><p data-slate-object="block" data-key="8966"><span data-slate-object="text" data-key="8967"><span data-slate-leaf="true" data-offset-key="8967:0"><span><span data-slate-string="true">Marketers need a website builder designed just for them. Our mission is to tackle the issues holding back marketing teams from building, shipping, and iterating on </span></span></span></span><span data-slate-object="text" data-key="8968"><span data-slate-leaf="true" data-offset-key="8968:0"><span><span data-slate-string="true">all</span></span></span></span><span data-slate-object="text" data-key="8969"><span data-slate-leaf="true" data-offset-key="8969:0"><span><span data-slate-string="true"> web content, on their own schedule.</span></span></span></span></p><p data-slate-object="block" data-key="8972"><span data-slate-object="text" data-key="8973"><span data-slate-leaf="true" data-offset-key="8973:0"><span><span data-slate-string="true">To do this, we need to fix the user experience. More specifically, we need to move away from the split "template &amp; content" user experience found in nearly all advanced website solutions. This approach exposes two distinct experiences to the end user: One for a technical specialist to build a template, and another basic experience, usually a form, to plug in content. This creates a problem where the people responsible for the content can't change the template—sound familiar?</span></span></span></span></p><p data-slate-object="block" data-key="8976"><span data-slate-object="text" data-key="8977"><span data-slate-leaf="true" data-offset-key="8977:0"><span><span data-slate-string="true">To move as fast as possible, the people in charge of </span></span></span></span><span data-slate-object="text" data-key="8978"><span data-slate-leaf="true" data-offset-key="8978:0"><span><span data-slate-string="true">what</span></span></span></span><span data-slate-object="text" data-key="8979"><span data-slate-leaf="true" data-offset-key="8979:0"><span><span data-slate-string="true"> to build need to also control </span></span></span></span><span data-slate-object="text" data-key="8980"><span data-slate-leaf="true" data-offset-key="8980:0"><span><span data-slate-string="true">how</span></span></span></span><span data-slate-object="text" data-key="8981"><span data-slate-leaf="true" data-offset-key="8981:0"><span><span data-slate-string="true"> it's built.</span></span></span></span></p><p data-slate-object="block" data-key="8984"><span data-slate-object="text" data-key="8985"><span data-slate-leaf="true" data-offset-key="8985:0"><span><span data-slate-string="true">That's why we're focused on designing a single, elegant user experience that can be easily taught to an entire team of tech-savvy generalists. The challenge is to provide enough power for advanced use cases without making the product difficult to </span></span></span></span><span data-slate-object="text" data-key="8986"><span data-slate-leaf="true" data-offset-key="8986:0"><span><span data-slate-string="true">learn</span></span></span></span><span data-slate-object="text" data-key="8987"><span data-slate-leaf="true" data-offset-key="8987:0"><span><span data-slate-string="true">. Learning to build completely custom websites should be no more complicated than learning to design a slide show presentation.</span></span></span></span></p><p data-slate-object="block" data-key="8990"><span data-slate-object="text" data-key="8991"><span data-slate-leaf="true" data-offset-key="8991:0"><span><span data-slate-string="true">So why build another website builder? With what feels like a new website builder popping up everyday, it's apparent that we're all still searching for something better. If you're interested in shaping the way we build, ship, and iterate on web content, please sign up for our early access program.</span></span></span></span></p></div></div></div>]]>
            </description>
            <link>https://www.makeswift.com/blog/why-build-another-website-builder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837331</guid>
            <pubDate>Tue, 20 Oct 2020 13:57:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a curated Moon page for anyone to learn why we explore the Moon]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24837248">thread link</a>) | @uncertainquark
<br/>
October 20, 2020 | https://jatan.space/the-moon/ | <a href="https://web.archive.org/web/*/https://jatan.space/the-moon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header role="banner">
		<a href="#content" tabindex="0">
			Skip to content		</a>
		<div id="header-grid">
	<div data-row-id="top" data-show-on="desktop">

	<div>
		<div>
			<div data-section="hfg_header_layout_top">
				<div><div data-section="title_tagline" data-item-id="logo">
	<div>
	<a href="https://jatan.space/" title="Jatan's Space" aria-label="Jatan's Space"><div><p><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/moon-rocket-logo-transparent.png?fit=1000%2C1000&amp;ssl=1" alt=""></p><div><p>Jatan's Space</p><p><small>Advocating space exploration and Moon settlements</small></p></div></div></a></div>

	</div>

</div>							</div>
		</div>
	</div>
</div>


<nav data-row-id="main" data-show-on="desktop">

	<div>
		<div>
			<div data-section="hfg_header_layout_main">
				<div><div data-section="header_menu_primary" data-item-id="primary-menu">
	<div>
	<div role="navigation" aria-label="Primary Menu">

		<ul id="nv-primary-navigation-main"><li id="menu-item-1915"><a href="https://jatan.space/">Blog</a></li>
<li id="menu-item-3556"><a href="https://jatan.space/sitemap/">Topics</a></li>
<li id="menu-item-3687"><a href="https://jatan.space/subscribe/">Subscribe</a></li>
<li id="menu-item-2904"><a href="https://jatan.space/talks/">Talks</a></li>
<li id="menu-item-2120"><a href="https://jatan.space/about/">About</a></li>
</ul>	</div>
</div>

	</div>

<div data-section="header_button" data-item-id="button_base">
	<div><p><a href="https://jatan.space/support">Support Me</a></p></div>	</div>

<div data-section="header_search_responsive" data-item-id="header_search_responsive">
	<div>
	<div [class]="visible ? 'menu-item-nav-search active canvas' : 'menu-item-nav-search canvas'" id="nv-search-icon-responsive" tabindex="0">
		<a href="#">
				<svg width="15" height="15" viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1216 832q0-185-131.5-316.5t-316.5-131.5-316.5 131.5-131.5 316.5 131.5 316.5 316.5 131.5 316.5-131.5 131.5-316.5zm512 832q0 52-38 90t-90 38q-54 0-90-38l-343-342q-179 124-399 124-143 0-273.5-55.5t-225-150-150-225-55.5-273.5 55.5-273.5 150-225 225-150 273.5-55.5 273.5 55.5 225 150 150 225 55.5 273.5q0 220-124 399l343 343q37 37 37 90z"></path></svg>
			</a>		<div aria-label="search">
			<div>
				<form role="search" method="get" action="https://jatan.space/"><label><span>Search for...</span></label><div></div></form>			</div>
							
					</div>
	</div>
</div>
	</div>

</div>							</div>
		</div>
	</div>
</nav>

<div data-row-id="top" data-show-on="mobile">

	<div>
		<div>
			<div data-section="hfg_header_layout_top">
				<div><div data-section="title_tagline" data-item-id="logo">
	<div>
	<a href="https://jatan.space/" title="Jatan's Space" aria-label="Jatan's Space"><div><p><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/moon-rocket-logo-transparent.png?fit=1000%2C1000&amp;ssl=1" alt=""></p><div><p>Jatan's Space</p><p><small>Advocating space exploration and Moon settlements</small></p></div></div></a></div>

	</div>

</div>							</div>
		</div>
	</div>
</div>


<nav data-row-id="main" data-show-on="mobile">

	<div>
		<div>
			<div data-section="hfg_header_layout_main">
				<div><div data-section="header_menu_icon" data-item-id="nav-icon">
	 <!--.navbar-toggle-wrapper-->


	</div>

<div data-section="header_button" data-item-id="button_base">
	<div><p><a href="https://jatan.space/support">Support Me</a></p></div>	</div>

<div data-section="header_search_responsive" data-item-id="header_search_responsive">
	<div>
	<div [class]="visible ? 'menu-item-nav-search active canvas' : 'menu-item-nav-search canvas'" id="nv-search-icon-responsive" tabindex="0">
		<a href="#">
				<svg width="15" height="15" viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1216 832q0-185-131.5-316.5t-316.5-131.5-316.5 131.5-131.5 316.5 131.5 316.5 316.5 131.5 316.5-131.5 131.5-316.5zm512 832q0 52-38 90t-90 38q-54 0-90-38l-343-342q-179 124-399 124-143 0-273.5-55.5t-225-150-150-225-55.5-273.5 55.5-273.5 150-225 225-150 273.5-55.5 273.5 55.5 225 150 150 225 55.5 273.5q0 220-124 399l343 343q37 37 37 90z"></path></svg>
			</a>		<div aria-label="search">
			<div>
				<form role="search" method="get" action="https://jatan.space/"><label><span>Search for...</span></label><div></div></form>			</div>
							
					</div>
	</div>
</div>
	</div>

</div>							</div>
		</div>
	</div>
</nav>

<div id="header-menu-sidebar">
	<div id="header-menu-sidebar-bg">
		
		<div id="header-menu-sidebar-inner">
			<div><div data-section="header_menu_primary" data-item-id="primary-menu">
	<div>
	<div role="navigation" aria-label="Primary Menu">

		<ul id="nv-primary-navigation-sidebar"><li><a href="https://jatan.space/">Blog</a></li>
<li><a href="https://jatan.space/sitemap/">Topics</a></li>
<li><a href="https://jatan.space/subscribe/">Subscribe</a></li>
<li><a href="https://jatan.space/talks/">Talks</a></li>
<li><a href="https://jatan.space/about/">About</a></li>
</ul>	</div>
</div>

	</div>

</div>		</div>
	</div>
</div>


</div>
	</header>
		
	<main id="content" role="main">

<div>
	<div>
				<div>
			<div>
	<!--.nv-page-title-->
</div> <!--.nv-page-title-wrap-->
<div>
<p>Our Moon is a unique place to answer fundamental questions about the Solar System, and enable sustained human presence in space. Here are some curated resources for you to learn more about the Moon and join the exploration gang! 🚀</p>


				<div>
			<div data-posts="">
								
	<article data-post-id="2625">
					<figure>
				<a href="https://jatan.space/why-explore-the-moon/" rel="bookmark">
					<img width="1200" height="900" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=800%2C600&amp;ssl=1 800w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=400%2C300&amp;ssl=1 400w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/why-explore-the-moon/" rel="bookmark">Why explore the Moon</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3564">
					<figure>
				<a href="https://jatan.space/the-moon-as-a-rocket-platform/" rel="bookmark">
					<img width="1200" height="900" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?zoom=2&amp;resize=1200%2C900&amp;ssl=1 2400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?zoom=3&amp;resize=1200%2C900&amp;ssl=1 3600w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/the-moon-as-a-rocket-platform/" rel="bookmark">Rocket Science 101: The Moon as a rocket platform</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				


<div>
<div><p><a href="https://www.planetary.org/space-missions/every-moon-mission">Every Mission to the Moon, ever</a></p></div>
</div>







<p><strong>APOLLO </strong></p>


				<div>
			<div data-posts="">
								
	<article data-post-id="1261">
					<figure>
				<a href="https://jatan.space/apollo-moon-origin/" rel="bookmark">
					<img width="1200" height="900" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/01/7f278-the-moon-by-galileo.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/apollo-moon-origin/" rel="bookmark">How the Apollo missions transformed our understanding of the Moon’s origin</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3809">
					<figure>
				<a href="https://jatan.space/space-digest-apollo-moon-landings/" rel="bookmark">
					<img width="1200" height="900" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/space-digest-apollo-moon-landings/" rel="bookmark">Space Digest – The Apollo Moon landings</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3755">
					<figure>
				<a href="https://jatan.space/apollo-11-landing-site/" rel="bookmark">
					<img width="800" height="600" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=800%2C600&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?w=1023&amp;ssl=1 1023w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=768%2C577&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=400%2C300&amp;ssl=1 400w" sizes="(max-width: 800px) 100vw, 800px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/apollo-11-landing-site/" rel="bookmark">The landing site of NASA Apollo 11</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				


<div>
<div><p><a href="https://www.planetary.org/space-missions/celebrating-apollo-at-50">Curated Apollo stories</a></p></div>



<div><p><a href="https://svs.gsfc.nasa.gov/Gallery/apollo.html#section3-id">Views from Apollo </a></p></div>
</div>







<p><strong>CHANDRAYAAN</strong></p>


				<div>
			<div data-posts="">
								
	<article data-post-id="1176">
					<figure>
				<a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/" rel="bookmark">
					<img width="800" height="600" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/01/3cc0f-water-ice-moon-map-m3.jpg?resize=800%2C600&amp;ssl=1" alt="" loading="lazy">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/" rel="bookmark">How NASA and Chandrayaan discovered water on the Moon</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3900">
					<figure>
				<a href="https://jatan.space/interviewing-isro-chandrayaan-1-mission-director/" rel="bookmark">
					<img width="800" height="600" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=800%2C600&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=400%2C300&amp;ssl=1 400w" sizes="(max-width: 800px) 100vw, 800px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/interviewing-isro-chandrayaan-1-mission-director/" rel="bookmark">Interviewing Chandrayaan 1’s Mission Director on India’s role in the new Moon race</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				






<p><strong>LUNAR SCIENCE</strong></p>


				<div>
			<div data-posts="">
								
	<article data-post-id="4045">
					<figure>
				<a href="https://jatan.space/exploring-moon-mountains/" rel="bookmark">
					<img width="1200" height="900" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/exploring-moon-mountains/" rel="bookmark">Exploring the marvel that are mountains on the Moon</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3944">
					<figure>
				<a href="https://jatan.space/radio-astronomy-from-the-moon/" rel="bookmark">
					<img width="400" height="300" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/08/lunar-radio-telescope.jpg?resize=400%2C300&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/08/lunar-radio-telescope.jpg?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/08/lunar-radio-telescope.jpg?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/08/lunar-radio-telescope.jpg?zoom=2&amp;resize=400%2C300&amp;ssl=1 800w" sizes="(max-width: 400px) 100vw, 400px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/radio-astronomy-from-the-moon/" rel="bookmark">The Moon’s potential for radio astronomy and Chang’e 4</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="2425">
					<figure>
				<a href="https://jatan.space/chandrayaan-2-is-creating-the-highest-resolution-map-of-the-moon/" rel="bookmark">
					<img width="400" height="300" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/01/5459c-ch-2-orbiter.png?resize=400%2C300&amp;ssl=1" alt="" loading="lazy">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/chandrayaan-2-is-creating-the-highest-resolution-map-of-the-moon/" rel="bookmark">ISRO’s Chandrayaan 2 orbiter is creating the highest resolution map of the Moon</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				


<div>
<div><p><a href="http://lunarexploration.esa.int/library">ESA’S LIBRARY OF MOON SCIENCE</a></p></div>
</div>







<p><strong>STORIES OF MOON EXPLORATION</strong></p>


				<div>
			<div data-posts="">
								
	<article data-post-id="3371">
					<figure>
				<a href="https://jatan.space/the-moons-lumpy-gravity-field/" rel="bookmark">
					<img width="1200" height="900" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?w=1440&amp;ssl=1 1440w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=400%2C300&amp;ssl=1 400w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/the-moons-lumpy-gravity-field/" rel="bookmark">How we got to know the Moon’s gravity is lumpy</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="2160">
					<figure>
				<a href="https://jatan.space/its-craters-all-the-way-down/" rel="bookmark">
					<img width="800" height="600" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/01/ranger-7-8-9-craft.jpg?resize=800%2C600&amp;ssl=1" alt="" loading="lazy" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/01/ranger-7-8-9-craft.jpg?resize=800%2C600&amp;ssl=1 800w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/01/ranger-7-8-9-craft.jpg?resize=400%2C300&amp;ssl=1 400w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/01/ranger-7-8-9-craft.jpg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 800px) 100vw, 800px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/its-craters-all-the-way-down/" rel="bookmark">The first time NASA figured out the Moon has craters all the way down</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3771">
					<figure>
				<a href="https://jatan.space/3d-moon-by-nasa-lro/" rel="bookmark">
					<img width="800" height="600" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/07/moon-lro-wac-100m-high-sun.png?resize=800%2C600&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/07/moon-lro-wac-100m-high-sun.png?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/07/moon-lro-wac-100m-high-sun.png?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/07/moon-lro-wac-100m-high-sun.png?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 800px) 100vw, 800px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/3d-moon-by-nasa-lro/" rel="bookmark">How NASA LRO captures the Moon in 3D</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				






<p><strong>EXPLORE AWAY!</strong></p>



<div>
<div>
<div id="block-4d121109-b58f-4c67-ae47-2c05bfa34745"><figure><a href="https://moontoday.jatan.space/"><img loading="lazy" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/moon-monday-logo.png?resize=160%2C160&amp;ssl=1" alt="This image has an empty alt attribute; its file name is moon-monday-logo.png" width="160" height="160" data-recalc-dims="1"></a><figcaption>Browse craters, mountains, lava channels and more at <a rel="noreferrer noopener" href="https://moontoday.jatan.space/" target="_blank">Moon Today 🌔</a></figcaption></figure></div>
</div>



<div>
<div><figure><a href="http://quickmap.lroc.asu.edu/"><img loading="lazy" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/quickmap-lro.jpg?resize=150%2C150&amp;ssl=1" alt="" width="150" height="150" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/quickmap-lro.jpg?w=385&amp;ssl=1 385w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/quickmap-lro.jpg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1"></a><figcaption>Explore the Moon like Google maps with <a href="http://quickmap.lroc.asu.edu/">LRO QuickMap</a></figcaption></figure></div>
</div>



<div>
<div><figure><a href="https://www.virtualmicroscope.org/collections/apollo"><img loading="lazy" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/apollo.png?resize=150%2C150&amp;ssl=1" alt="" width="150" height="150" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/apollo.png?w=468&amp;ssl=1 468w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/apollo.png?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/apollo.png?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1"></a><figcaption><a href="https://www.virtualmicroscope.org/collections/apollo">See Moon rocks</a> brought  back by Apollo missions in a virtual microscope.</figcaption></figure></div>
</div>
</div>



<p><strong>Like my work?<br></strong>I don’t display ads, <a href="https://jatan.space/support">support me</a> and get exclusive benefits in return.&nbsp;🚀</p>
<!-- Required values for loading comments via ajax -->
<div id="llc_comments">
	<div>
		
		<!-- Show comments button if "On Click" option is set -->
					<!-- Filter to modify loading button text and button class -->
			</div>
</div></div>		</div>
			</div>
</div>
</main><!--/.neve-main-->




</div></div>]]>
            </description>
            <link>https://jatan.space/the-moon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837248</guid>
            <pubDate>Tue, 20 Oct 2020 13:50:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Differential Dataflow]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24837031">thread link</a>) | @timhigins
<br/>
October 20, 2020 | https://timelydataflow.github.io/differential-dataflow/introduction.html | <a href="https://web.archive.org/web/*/https://timelydataflow.github.io/differential-dataflow/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>In this book we will work through the motivation and technical details behind <a href="https://github.com/frankmcsherry/differential-dataflow">differential dataflow</a>, a computational framework build on top of <a href="https://github.com/frankmcsherry/timely-dataflow">timely dataflow</a> intended for efficiently performing computations on large amounts of data and <em>maintaining</em> the computations as the data change.</p>
<p>Differential dataflow programs look like many standard "big data" computations, borrowing idioms from frameworks like MapReduce and SQL. However, once you write and run your program, you can <em>change</em> the data inputs to the computation, and differential dataflow will promptly show you the corresponding changes in its output. Promptly meaning in as little as milliseconds.</p>
<p>This relatively simple set-up, write programs and then change inputs, leads to a surprising breadth of exciting and new classes of scalable computation. We will explore it in this document!</p>
<hr>
<p>Differential dataflow arose from <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2013/11/naiad_sosp2013.pdf">work at Microsoft Research</a>, where we aimed to build a high-level framework that could both compute and incrementally maintain non-trivial algorithms.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://timelydataflow.github.io/differential-dataflow/chapter_0/chapter_0.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a rel="next" href="https://timelydataflow.github.io/differential-dataflow/chapter_0/chapter_0.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        
        

        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://timelydataflow.github.io/differential-dataflow/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837031</guid>
            <pubDate>Tue, 20 Oct 2020 13:31:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The surprising impact of medium-size texts on PostgreSQL performance]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24836979">thread link</a>) | @haki
<br/>
October 20, 2020 | https://hakibenita.com/sql-medium-text-performance | <a href="https://web.archive.org/web/*/https://hakibenita.com/sql-medium-text-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Any database schema is likely to have plenty of text fields. In this article, I divide text fields into three categories:</p>
<ol>
<li>
<p><strong>Small texts</strong>: names, slugs, usernames, emails, etc. These are text fields that usually have some low size limit, maybe even using <code>varchar(n)</code> and not <code>text</code>.</p>
</li>
<li>
<p><strong>Large texts</strong>: blog post content, articles, HTML content etc. These are large pieces of free, unrestricted text that is stored in the database.</p>
</li>
<li>
<p><strong>Medium texts</strong>: descriptions, comments, product reviews, stack traces etc. These are any text field that is between the small and the large. These type of texts would normally be unrestricted, but naturally smaller than the large texts.</p>
</li>
</ol>
<p><strong>In this article I demonstrate the surprising impact of medium-size texts on query performance in PostgreSQL.</strong></p>
<figure><img alt="Sliced bread... it gets better<br><small>Photo by <a href=&quot;https://unsplash.com/photos/WHJTaLqonkU&quot;>Louise Lyshøj</a></small>" src="https://hakibenita.com/images/00-sql-medium-text-performance.jpg"><figcaption>Sliced bread... it gets better<br><small>Photo by <a href="https://unsplash.com/photos/WHJTaLqonkU">Louise Lyshøj</a></small></figcaption>
</figure>
<details open="">
    <summary>Table of Contents</summary>

</details>
<hr>
<h2 id="understanding-toast"><a href="#understanding-toast">Understanding TOAST</a></h2>
<p>When talking about large chunks of text, or any other field that may contain large amounts of data, we first need to understand how the database handles the data. Intuitively, you might think that the database is storing large pieces of data inline like it does smaller pieces of data, but in fact, <a href="https://www.postgresql.org/docs/current/storage-toast.html" rel="noopener">it does not</a>:</p>
<blockquote>
<p>PostgreSQL uses a fixed page size (commonly 8 kB), and does not allow tuples to span multiple pages. Therefore, it is not possible to store very large field values directly.</p>
</blockquote>
<p>As the documentation explains, PostgreSQL can't store rows (tuples) in multiple pages. So how does the database store large chunks of data?</p>
<blockquote>
<p>[...] large field values are compressed and/or broken up into multiple physical rows. [...] The technique is affectionately known as TOAST (or “the best thing since sliced bread”).</p>
</blockquote>
<p>OK, so how is this TOAST working exactly?</p>
<blockquote>
<p>If any of the columns of a table are TOAST-able, the table will have an associated TOAST table</p>
</blockquote>
<p>So TOAST is a separate table associated with our table. It is used to store large pieces of data of TOAST-able columns (the <code>text</code> datatype for example, is TOAST-able).</p>
<p>What constitutes a large value?</p>
<blockquote>
<p>The TOAST management code is triggered only when a row value to be stored in a table is wider than TOAST_TUPLE_THRESHOLD bytes (normally 2 kB). The TOAST code will compress and/or move field values out-of-line until the row value is shorter than TOAST_TUPLE_TARGET bytes (also normally 2 kB, adjustable) or no more gains can be had</p>
</blockquote>
<p>PostgreSQL will try to compress a the large values in the row, and if the row can't fit within the limit, the values will be stored out-of-line in the TOAST table.</p>
<h3 id="finding-the-toast"><a href="#finding-the-toast">Finding the TOAST</a></h3>
<p>Now that we have <em>some</em> understanding of what TOAST is, let's see it in action. First, create a table with a text field:</p>
<div><pre><span></span><span>db=#</span> <span>CREATE</span> <span>TABLE</span> <span>toast_test</span> <span>(</span><span>id</span> <span>SERIAL</span><span>,</span> <span>value</span> <span>TEXT</span><span>);</span>
<span>CREATE TABLE</span>
</pre></div>


<p>The table contains an id column, and a value field of type <code>TEXT</code>. Notice that we did not change any of the default storage parameters.</p>
<p>The text field we added supports TOAST, or is TOAST-able, so PostgreSQL should create a TOAST table. Let's try to locate the TOAST table associated with the table <code>toast_test</code> in <a href="https://www.postgresql.org/docs/current/catalog-pg-class.html" rel="noopener"><code>pg_class</code></a>:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>relname</span><span>,</span> <span>reltoastrelid</span> <span>FROM</span> <span>pg_class</span> <span>WHERE</span> <span>relname</span> <span>=</span> <span>'toast_test'</span><span>;</span>
<span>  relname   │ reltoastrelid</span>
<span>────────────┼───────────────</span>
<span> toast_test │        340488</span>

<span>db=#</span> <span>SELECT</span> <span>relname</span> <span>FROM</span> <span>pg_class</span> <span>WHERE</span> <span>oid</span> <span>=</span> <span>340488</span><span>;</span>
<span>     relname</span>
<span>─────────────────</span>
<span> pg_toast_340484</span>
</pre></div>


<p>As promised, PostgreSQL created a TOAST table called <code>pg_toast_340484</code>.</p>
<h3 id="toast-in-action"><a href="#toast-in-action">TOAST in Action</a></h3>
<p>Let's see what the TOAST table looks like:</p>
<div><pre><span></span><span>db=#</span> <span>\d</span> <span>pg_toast.pg_toast_340484</span>
<span>TOAST table "pg_toast.pg_toast_340484"</span>
<span>   Column   │  Type</span>
<span>────────────┼─────────</span>
<span> chunk_id   │ oid</span>
<span> chunk_seq  │ integer</span>
<span> chunk_data │ bytea</span>
</pre></div>


<p>The TOAST table contains three columns:</p>
<ul>
<li><code>chunk_id</code>: A reference to a toasted value.</li>
<li><code>chunk_seq</code>: A sequence within the chunk.</li>
<li><code>chunk_data</code>: The actual chunk data.</li>
</ul>
<p>Similar to "regular" tables, the TOAST table also has the same restrictions on inline values. To overcome this restriction, large values are split into chunks that can fit within the limit.</p>
<p>At this point the table is empty:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id │ chunk_seq │ chunk_data</span>
<span>──────────┼───────────┼────────────</span>
<span>(0 rows)</span>
</pre></div>


<p>This makes sense because we did not insert any data yet. So next, insert a small value into the table:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>'small value'</span><span>);</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id │ chunk_seq │ chunk_data</span>
<span>──────────┼───────────┼────────────</span>
<span>(0 rows)</span>
</pre></div>


<p>After inserting the small value into the table, the TOAST table remained empty. This means the small value was small enough to be stored inline, and there was no need to move it out-of-line to the TOAST table.</p>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 176.3 111" height="10em"><path d="M9 47c62-3 116 2 153-2M13 47c49 0 93 0 150 2m-3-4c3 17 2 22 4 53m-2-52c-3 14-2 31 0 56m2-4c-37 1-78 7-150 5m149-4H13m0 4c-3-15 1-28-4-56m3 55c2-11-1-25 1-54" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(33 60)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(61 61)">"small value"</text><path d="M10 12l155-1v37L12 46" stroke-width="0" fill="#f2f2f2"></path><path d="M10 9c43-1 84 0 156 2M11 11c36 1 75 0 155-1m1-2l-2 38m1-36v39m1 0c-39 2-78 1-159 0m158-2c-39 2-77 2-155 0m-3 1c0-8 3-20 3-36m-1 37V10" stroke="currentColor" fill="none"></path><path d="M52 16l4 81m0-84c-1 19-5 36-3 88" stroke="currentColor" fill="none"></path><text y="15" font-size="16" transform="translate(23 18)">id</text><g><text x="20" y="15" font-size="16" text-anchor="middle" transform="translate(68 19)">value</text></g></svg>
<figcaption>Small text stored inline</figcaption>
</figure>

<p>Let's insert a large value and see what happens:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>'n0cfPGZOCwzbHSMRaX8 ... WVIlRkylYishNyXf'</span><span>);</span>
<span>INSERT 0 1</span>
</pre></div>


<p>I shortened the value for brevity, but that's a random string with 4096 characters. Let's see what the TOAST table stores now:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id │ chunk_seq │ chunk_data</span>
<span>──────────┼───────────┼──────────────────────</span>
<span>   995899 │         0 │ \x30636650475a4f43...</span>
<span>   995899 │         1 │ \x50714c3756303567...</span>
<span>   995899 │         2 │ \x6c78426358574534...</span>
<span>(3 rows)</span>
</pre></div>


<p>The large value is stored out-of-line in the TOAST table. Because the value was too large to fit inline in a single row, PostgreSQL split it into three chunks. The <code>\x3063...</code> notation is how psql displays binary data.</p>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 435.8 254" height="20em"><path d="M9 43c58 5 116 4 154 6M14 48c34-1 70 1 148-1m2 0c-5 34-4 68-3 92m0-94c1 34 4 69 2 96m-4 0c-27-2-54-2-143-5m145 3c-47 2-96 2-147 1m-2 3c5-29 2-60 0-94m2 89c1-36-2-72-3-90" stroke="currentColor" fill="none"></path><path d="M10 95c45-2 79 3 150 0M12 96c53 0 106-3 147-3" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(33 60)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(61 61)">"small value"</text><text y="15" font-size="16" fill="currentColor" transform="translate(34 106)">2</text><path d="M108 109l4 3 3 5-2 4-5 4h-4l-4-3v-7c0-2 1-2 3-3l6-3 1 1m-4-2l3 3 3 5 1 4c0 2-1 2-2 3l-6 3-4-5c-1-2-3-4-2-5l2-4 4-4 1 3" stroke-width="0" fill="#f41d92"></path><path d="M105 110h5l2 4 2 5c0 2-3 3-4 4l-4 2c-2 0-2-1-3-2l-4-6 2-4 4-5 1 2m-1 0l6 1 3 3-1 4-1 4-6 3-3-1-3-5v-7l6-2-2-1M115 115c30 2 64 1 141 0m-141 1c34-1 70-3 142-1" stroke="currentColor" fill="none"></path><path d="M229 125c5-1 13-4 26-11m-26 11l27-10" stroke="currentColor" fill="none"></path><path d="M229 104c5 4 13 6 26 10m-26-9c6 3 14 4 27 10" stroke="currentColor" fill="none"></path><path d="M275 104h152v137l-151 3" stroke-width="0" fill="#f41d92"></path><path d="M276 99c36 2 66 5 146 7m-148-3c47-2 87-3 150 0m2 4c-5 40-4 85-2 135m2-139c-2 41-1 78 0 140m1-3c-53 5-105-2-149 0m146 4c-45 1-90 0-146-2m1-1c-4-56-3-110 0-135m-5 135c5-48 3-100 2-138" stroke="currentColor" fill="none"></path><path d="M314 107c1 30 5 66 8 136m-3-136v137" stroke="currentColor" fill="none"></path><path d="M279 153c36 6 77 8 145 2m-145 0c50-2 102-2 146-2M271 194c46 0 91 2 151 5m-148-2c29-3 59-1 146-1" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(294 165)">2</text><text y="15" font-size="16" fill="currentColor" transform="translate(295 119)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(292 207)">3</text><text y="15" font-size="16" fill="currentColor" transform="translate(329 118)">\x.....</text><text y="15" font-size="16" fill="currentColor" transform="translate(331 164)">\x.....</text><text y="15" font-size="16" fill="currentColor" transform="translate(332 206)">\x.....</text><g><path d="M12 9l153 1-1 36-153 1" stroke-width="0" fill="#f2f2f2"></path><path d="M11 12c50 0 100-4 157-2M9 11c48-3 97-3 158-1m1 0c-3 13 0 29-2 39m0-39v39m-1-1c-41-2-80 1-154-2m156 2c-62 2-122 2-158 0m2 1c1-12-2-25-3-40m1 39c1-12 2-23 1-38" stroke="currentColor" fill="none"></path></g><g><path d="M55 11c-1 39 2 67 0 130M54 16c4 36 3 74 1 120" stroke="currentColor" fill="none"></path></g><g><text y="15" font-size="16" transform="translate(23 18)">id</text></g><g><text x="20" y="15" font-size="16" text-anchor="middle" transform="translate(68 19)">value</text></g></svg>
<figcaption>Large text stored out-of-line, in the associated TOAST table</figcaption>
</figure>

<p>Finally, execute the following query to summarize the data in the TOAST table:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>
<span> chunk_id │ chunks │ pg_size_pretty</span>
<span>──────────┼────────┼────────────────</span>
<span>   995899 │      3 │ 4096 bytes</span>
<span>(1 row)</span>
</pre></div>


<p>As we've already seen, the text is stored in three chunks.</p>
<div>
<p>size of database objects</p>
<p>There are several ways to get the <a href="https://www.postgresql.org/docs/current/functions-admin.html#FUNCTIONS-ADMIN-DBSIZE" rel="noopener">size of database objects in PostgreSQL</a>:</p>
<ul>
<li><code>pg_table_size</code>: Get the size of the table including TOAST, but excluding indexes</li>
<li><code>pg_relation_size</code>: Get the size of just the table</li>
<li><code>pg_total_relation_size</code>: Get the size of the table, including indexes and TOAST</li>
</ul>
<p>Another useful function is <code>pg_size_pretty</code>: used to display sizes in a friendly format.</p>
</div>
<h3 id="toast-compression"><a href="#toast-compression">TOAST Compression</a></h3>
<p>So far I refrained from categorizing texts by their size. The reason for that is that the size of the text itself does not matter, what matters is its size after compression.</p>
<p>To create long strings for testing, we'll implement a function to generate random strings at a given length:</p>
<div><pre><span></span><span>CREATE</span> <span>OR</span> <span>REPLACE</span> <span>FUNCTION</span> <span>generate_random_string</span><span>(</span>
  <span>length</span> <span>INTEGER</span><span>,</span>
  <span>characters</span> <span>TEXT</span> <span>default</span> <span>'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'</span>
<span>)</span> <span>RETURNS</span> <span>TEXT</span> <span>AS</span>
<span>$$</span>
<span>DECLARE</span>
  <span>result</span> <span>TEXT</span> <span>:=</span> <span>''</span><span>;</span>
<span>BEGIN</span>
  <span>IF</span> <span>length</span> <span>&lt;</span> <span>1</span> <span>then</span>
      <span>RAISE</span> <span>EXCEPTION</span> <span>'Invalid length'</span><span>;</span>
  <span>END</span> <span>IF</span><span>;</span>
  <span>FOR</span> <span>__</span> <span>IN</span> <span>1..</span><span>length</span> <span>LOOP</span>
    <span>result</span> <span>:=</span> <span>result</span> <span>||</span> <span>substr</span><span>(</span><span>characters</span><span>,</span> <span>floor</span><span>(</span><span>random</span><span>()</span> <span>*</span> <span>length</span><span>(</span><span>characters</span><span>))</span><span>::</span><span>int</span> <span>+</span> <span>1</span><span>,</span> <span>1</span><span>);</span>
  <span>end</span> <span>loop</span><span>;</span>
  <span>RETURN</span> <span>result</span><span>;</span>
<span>END</span><span>;</span>
<span>$$</span> <span>LANGUAGE</span> <span>plpgsql</span><span>;</span>
</pre></div>


<p>Generate a string made out of 10 random characters:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>generate_random_string</span><span>(</span><span>10</span><span>);</span>
<span> generate_random_string</span>
<span>────────────────────────</span>
<span> o0QsrMYRvp</span>
</pre></div>


<p>We can also provide a set of characters to generate the random string from. For example, generate a string made of 10 random digits:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>generate_random_string</span><span>(</span><span>10</span><span>,</span> <span>'1234567890'</span><span>);</span>
<span> generate_random_string</span>
<span>────────────────────────</span>
<span> 4519991669</span>
</pre></div>


<p>PostgreSQL TOAST uses the <a href="https://doxygen.postgresql.org/pg__lzcompress_8c_source.html" rel="noopener">LZ family of compression</a> techniques. Compression algorithms usually work by identifying and eliminating repetition in the value. A long string containing fewer characters should compress very well compared to a string made of many different characters when encoded into bytes.</p>
<p>To illustrate how TOAST uses compression, we'll clean out the <code>toast_test</code> table, and insert a random string made of many possible characters:</p>
<div><pre><span></span><span>db=#</span> <span>TRUNCATE</span> <span>toast_test</span><span>;</span>
<span>TRUNCATE TABLE</span>

<span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>));</span>
<span>INSERT 0 1</span>
</pre></div>


<p>We inserted a 10kb value made of random characters. Let's check the TOAST table:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id │ chunks │ pg_size_pretty</span>
<span>──────────┼────────┼────────────────</span>
<span>  1495960 │      6 │ 10 kB</span>
</pre></div>


<p>The value is stored out-of-line in the TOAST table, and we can see it is not compressed.</p>
<p>Next, insert a value with a similar length, but made out of fewer possible characters:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>,</span> <span>'123'</span><span>));</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id │ chunks │ pg_size_pretty</span>
<span>──────────┼────────┼────────────────</span>
<span>  1495960 │      6 │ 10 kB</span>
<span>  1495961 │      2 │ 3067 bytes</span>
</pre></div>


<p>We inserted a 10K value, but this time it only contained 3 possible digits: <code>1</code>, <code>2</code> and <code>3</code>. This text is more likely to contain repeating binary patterns, and should compress better than the previous value. Looking at the TOAST, we can see PostgreSQL compressed the value to ~3kB, which is a third of the size of the uncompressed value. Not a bad compression rate!</p>
<p>Finally, insert a 10K long string made of a single digit:</p>
<div><pre><span></span><span>db=#</span> <span>insert</span> <span>into</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>values</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>,</span> <span>'0'</span><span>));</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id │ chunks │ pg_size_pretty</span>
<span>──────────┼────────┼────────────────</span>
<span>  1495960 │      6 │ 10 kB</span>
<span>  1495961 │      2 │ 3067 bytes</span>
</pre></div>


<p>The string was compressed so well, that the database was able to store it in-line.</p>
<h3 id="configuring-toast"><a href="#configuring-toast">Configuring TOAST</a></h3>
<p>If you are interested in configuring TOAST for a table you can do that by setting storage parameters at <code>CREATE TABLE</code> or <code>ALTER …</code></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/sql-medium-text-performance">https://hakibenita.com/sql-medium-text-performance</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/sql-medium-text-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24836979</guid>
            <pubDate>Tue, 20 Oct 2020 13:25:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image processing techniques that you can use in machine learning projects]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24836287">thread link</a>) | @patrycjaneptune
<br/>
October 20, 2020 | https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Image processing is a method to perform operations on an image to extract information from it or enhance it. Digital image processing has a broad range of applications such as image restoration, medical imaging, remote sensing, image segmentation, etc. Every process requires a different technique.</p>



<p>In this article, we will be covering the <strong>top 6 image processing techniques</strong> for machine learning.</p>



<ol><li>Image Restoration</li><li>Linear Filtering</li><li>Independent Component Analysis</li><li>Pixelation</li><li>Template Matching</li><li>Image Generation Technique (GAN)</li></ol>



<p>See also: <a href="https://neptune.ai/blog/best-image-processing-tools-used-in-machine-learning" target="_blank" rel="noreferrer noopener nofollow">Best Image Processing Tools Used in Machine Learning</a></p>





<h2>1. Image restoration</h2>



<div><figure><img data-attachment-id="27714" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/image-restoration" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-restoration.jpg?fit=500%2C352&amp;ssl=1" data-orig-size="500,352" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-restoration" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-restoration.jpg?fit=300%2C211&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-restoration.jpg?fit=500%2C352&amp;ssl=1" loading="lazy" width="500" height="352" src="https://i0.wp.com/neptune.ai/wp-content/uploads/image-restoration.jpg?resize=500%2C352&amp;ssl=1" alt="image restoration" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/image-restoration.jpg?w=500&amp;ssl=1 500w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-restoration.jpg?resize=300%2C211&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1"></figure></div>



<p><em><a href="https://www.postproductie.cinemeta.nl/en/restoration-en/" target="_blank" rel="noreferrer noopener nofollow">Source</a>&nbsp;</em></p>



<p>An image deteriorates for many reasons, for example, an old image of your grandparents which was taken with the old tech camera could become hazy or may lose its original form.</p>



<p>This could happen if the image goes under some physical stress or if it’s in digital form it could deteriorate by motion blur or additive noise.</p>



<p>So how are you going to restore it? Maybe it wasn’t possible 50 years back but now – it is.</p>



<p><a href="http://www.owlnet.rice.edu/~elec539/Projects99/BACH/proj2/intro.html" target="_blank" rel="noreferrer noopener nofollow"><strong>Researchers came up with a Degradation model</strong></a><strong> that can undo the deterioration effects on the input image. The degradation model works as a convolution with a linear shift-invariant.</strong></p>



<p>So we take an Image before the degradation which is called “True Image” and an Image after degradation which is called “Observed Image” with the degradation filter which <em>estimates</em> the “True Image”.</p>



<div><figure><img data-attachment-id="27716" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/degradation-model" data-orig-file="https://i2.wp.com/neptune.ai/wp-content/uploads/degradation-model.png?fit=512%2C56&amp;ssl=1" data-orig-size="512,56" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="degradation-model" data-image-description="" data-medium-file="https://i2.wp.com/neptune.ai/wp-content/uploads/degradation-model.png?fit=300%2C33&amp;ssl=1" data-large-file="https://i2.wp.com/neptune.ai/wp-content/uploads/degradation-model.png?fit=512%2C56&amp;ssl=1" loading="lazy" src="https://i2.wp.com/neptune.ai/wp-content/uploads/degradation-model.png?resize=512%2C56&amp;ssl=1" alt="degradation model" width="512" height="56" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/degradation-model.png?w=512&amp;ssl=1 512w, https://i2.wp.com/neptune.ai/wp-content/uploads/degradation-model.png?resize=300%2C33&amp;ssl=1 300w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></figure></div>





<h3><strong>An example of image restoration using image inpainting with OpenCV</strong></h3>



<p><a href="https://en.wikipedia.org/wiki/Inpainting" target="_blank" rel="noreferrer noopener nofollow">Image impainting</a> also known as <strong>“Compensation of paint loss ”. </strong>This technique is often used to remove unwanted objects from an image to restore damaged parts of a deteriorated image.</p>



<pre><span>import</span> cv2
  
img = cv2.imread(<span>'damaged_image.png'</span>)
mask = cv2.imread(<span>'mask.png'</span>, <span>0</span>)
dst = cv2.inpaint(img, mask, <span>3</span>, cv2.INPAINT_NS)

cv2.imwrite(<span>'restored.png'</span>, dst)</pre>



<p>In the above code, we have two types of images</p>



<ol><li>Damaged</li><li>Masked</li></ol>



<p>A masked image has the same spatial dimensions of the noise which exists in the noisy image.</p>



<p>So if we input the image below with the above code:</p>



<div><figure><img data-attachment-id="27719" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/image-impainting-1" data-orig-file="https://i1.wp.com/neptune.ai/wp-content/uploads/image-impainting-1.png?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-impainting-1" data-image-description="" data-medium-file="https://i1.wp.com/neptune.ai/wp-content/uploads/image-impainting-1.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/neptune.ai/wp-content/uploads/image-impainting-1.png?fit=400%2C400&amp;ssl=1" loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/image-impainting-1.png?resize=384%2C384&amp;ssl=1" alt="image impainting 1" width="384" height="384" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/image-impainting-1.png?w=400&amp;ssl=1 400w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-impainting-1.png?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-impainting-1.png?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/neptune.ai/wp-content/uploads/image-impainting-1.png?resize=80%2C80&amp;ssl=1 80w" sizes="(max-width: 384px) 100vw, 384px" data-recalc-dims="1"></figure></div>



<p>With the mask:</p>



<div><figure><img data-attachment-id="27720" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/image-impainting-2" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-2.png?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-impainting-2" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-2.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-2.png?fit=400%2C400&amp;ssl=1" loading="lazy" width="400" height="400" src="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-2.png?resize=400%2C400&amp;ssl=1" alt="image impainting 2" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-2.png?w=400&amp;ssl=1 400w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-2.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-2.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-2.png?resize=80%2C80&amp;ssl=1 80w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure></div>



<p>Then we will get the following image:</p>



<div><figure><img loading="lazy" width="400" height="400" src="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?resize=400%2C400&amp;ssl=1" alt="image impainting 3" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?w=400&amp;ssl=1 400w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?resize=80%2C80&amp;ssl=1 80w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure></div>



<p>The biggest problem with OpenCV’s image inpainting is that we need to manually input a mask for the specific image we want to fix. So how can we automate this process?</p>



<p>The answer is <strong>GAN (General Adversarial Network)</strong>. This <a href="https://ieeexplore.ieee.org/document/8686914" target="_blank" rel="noreferrer noopener nofollow">paper</a> proposes that, by using a GAN network, image inpainting can be done using <strong>neighborhood loss function and gradient loss</strong> with a better quality restored image.&nbsp;</p>





<h2>2. Linear filtering</h2>



<div><figure><img data-attachment-id="27724" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/linear-filtering" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/linear-filtering.png?fit=1139%2C301&amp;ssl=1" data-orig-size="1139,301" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="linear-filtering" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/linear-filtering.png?fit=300%2C79&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/linear-filtering.png?fit=1024%2C271&amp;ssl=1" loading="lazy" width="1024" height="271" src="https://i0.wp.com/neptune.ai/wp-content/uploads/linear-filtering.png?resize=1024%2C271&amp;ssl=1" alt="linear filtering" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/linear-filtering.png?resize=1024%2C271&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/linear-filtering.png?resize=300%2C79&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/linear-filtering.png?resize=768%2C203&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/linear-filtering.png?w=1139&amp;ssl=1 1139w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p>Linear filtering is a process in which the value of the output pixel is linear combinations of the neighboring input pixels. This process is done by a technique called <strong>Convolution.</strong></p>



<p><strong>Convolution is the process of adding each element of the image to its local neighbors, weighted by the kernel.</strong></p>



<div><figure><img data-attachment-id="27725" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/convolution" data-orig-file="https://i1.wp.com/neptune.ai/wp-content/uploads/convolution.png?fit=850%2C413&amp;ssl=1" data-orig-size="850,413" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="convolution" data-image-description="" data-medium-file="https://i1.wp.com/neptune.ai/wp-content/uploads/convolution.png?fit=300%2C146&amp;ssl=1" data-large-file="https://i1.wp.com/neptune.ai/wp-content/uploads/convolution.png?fit=850%2C413&amp;ssl=1" loading="lazy" src="https://i1.wp.com/neptune.ai/wp-content/uploads/convolution.png?resize=638%2C310&amp;ssl=1" alt="convolution" width="638" height="310" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/convolution.png?w=850&amp;ssl=1 850w, https://i1.wp.com/neptune.ai/wp-content/uploads/convolution.png?resize=300%2C146&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/convolution.png?resize=768%2C373&amp;ssl=1 768w" sizes="(max-width: 638px) 100vw, 638px" data-recalc-dims="1"></figure></div>



<p><a href="https://www.researchgate.net/figure/Image-convolution-with-an-input-image-of-size-7-7-and-a-filter-kernel-of-size-3-3_fig1_318849314" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></p>



<p>We have an input image and a kernel with an anchor point. In the above diagram, it’s H(1, 1).</p>



<p><strong>This filter works as a sliding window to convolve over the image.&nbsp;</strong></p>



<p>We multiply each pixel by the corresponding kernel and then take the sum. That sum becomes a new pixel in the output image.</p>



<h3><strong>Let’s see this in action with the help of OpenCV</strong></h3>



<pre><span>import</span> cv2 <span>as</span> cv
<span>import</span> numpy <span>as</span> np
<span>import</span> matplotlib.pyplot <span>as</span> plt

image = cv.imread(<span>"pics/goku.jpeg"</span>)

fig, ax = plt.subplots(<span>1</span>, <span>3</span>, figsize=(<span>16</span>, <span>8</span>))
fig.tight_layout()


ax[<span>0</span>].imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))
ax[<span>0</span>].set_title(<span>'Original Image'</span>)

kernel_sharpening = np.array([[<span>-1</span>, <span>-1</span>, <span>-1</span>],
                             [<span>-1</span>, <span>9</span>, <span>-1</span>],
                             [<span>-1</span>, <span>-1</span>, <span>-1</span>]])

kernel_sharpening_2 = np.array([[<span>-1</span>, <span>-1</span>, <span>-1</span>],
                             [<span>-1</span>, <span>10</span>, <span>-1</span>],
                             [<span>-1</span>, <span>-1</span>, <span>-1</span>]])

sharpened = cv.filter2D(image, <span>-1</span>, kernel_sharpening)
ax[<span>1</span>].imshow(cv.cvtColor(sharpened, cv.COLOR_BGR2RGB))
ax[<span>1</span>].set_title(<span>'Sharpened Kernel Image'</span>)

sharpened_2 = cv.filter2D(image, <span>-1</span>, kernel_sharpening_2)
ax[<span>2</span>].imshow(cv.cvtColor(sharpened_2, cv.COLOR_BGR2RGB))
ax[<span>2</span>].set_title(<span>'Sharpened Kernel Image 2'</span>)

plt.show()</pre>





<h2>3. Independent Component Analysis</h2>



<div><figure><img data-attachment-id="27728" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/independent-component-analysis" data-orig-file="https://i2.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis.png?fit=1232%2C400&amp;ssl=1" data-orig-size="1232,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Independent Component Analysis" data-image-description="" data-medium-file="https://i2.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis.png?fit=300%2C97&amp;ssl=1" data-large-file="https://i2.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis.png?fit=1024%2C332&amp;ssl=1" loading="lazy" width="1024" height="332" src="https://i2.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis.png?resize=1024%2C332&amp;ssl=1" alt="Independent Component Analysis" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis.png?resize=1024%2C332&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis.png?resize=300%2C97&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis.png?resize=768%2C249&amp;ssl=1 768w, https://i2.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis.png?w=1232&amp;ssl=1 1232w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p><a href="https://team.inria.fr/parietal/research/statistical-and-machine-learning-methods-for-large-scale-data/faster-independent-component-analysis-for-real-data/" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></p>



<p>Independent Component Analysis or short for ICA is a <strong>technique for separating a multivariate signal into its underlying component. </strong>ICA helps in the extraction of the desired component from the mixture of multiple components or signals.&nbsp;</p>



<p>Let me explain.&nbsp;</p>



<p>In ICA, we <em>“Whiten”</em> our signal. This means that a given will be transformed in a way that potential correlations between its component are removed and the variance of each component is equal to 1.&nbsp;</p>



<h3><strong>ICA using sklearn</strong></h3>



<pre><span>import</span> numpy <span>as</span> np
<span>import</span> matplotlib.pyplot <span>as</span> plt
<span>from</span> scipy <span>import</span> signal
<span>from</span> sklearn.decomposition <span>import</span> FastICA, PCA

n_samples = <span>2000</span>
time = np.linspace(<span>0</span>, <span>8</span>, n_samples)

s1 = np.sin(<span>2</span> * time)  
s2 = np.sign(np.sin(<span>3</span> * time))  
s3 = signal.sawtooth(<span>2</span> * np.pi * time)  

S = np.c_[s1, s2, s3]
S += <span>0.2</span> * np.random.normal(size=S.shape)  

S /= S.std(axis=<span>0</span>)  

A = np.array([[<span>1</span>, <span>1</span>, <span>1</span>], [<span>0.5</span>, <span>2</span>, <span>1.0</span>], [<span>1.5</span>, <span>1.0</span>, <span>2.0</span>]])  
X = np.dot(S, A.T)  


ica = FastICA(n_components=<span>3</span>)
S_ = ica.fit_transform(X)  
A_ = ica.mixing_  

plt.figure()

models = [X, S, S_]
names = [<span>'Observations (mixed signal)'</span>,
         <span>'True Sources'</span>,
         <span>'ICA recovered signals'</span>]
colors = [<span>'red'</span>, <span>'steelblue'</span>, <span>'orange'</span>]

<span>for</span> ii, (model, name) <span>in</span> enumerate(zip(models, names), <span>1</span>):
    plt.subplot(<span>3</span>, <span>1</span>, ii)
    plt.title(name)
    <span>for</span> sig, color <span>in</span> zip(model.T, colors):
        plt.plot(sig, color=color)

plt.tight_layout()
plt.show()</pre>



<p>Output:</p>



<div><figure><img data-attachment-id="27731" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/independent-component-analysis-output" data-orig-file="https://i1.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis-output.png?fit=1144%2C440&amp;ssl=1" data-orig-size="1144,440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Independent-Component-Analysis-output" data-image-description="" data-medium-file="https://i1.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis-output.png?fit=300%2C115&amp;ssl=1" data-large-file="https://i1.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis-output.png?fit=1024%2C394&amp;ssl=1" loading="lazy" width="1024" height="394" src="https://i1.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis-output.png?resize=1024%2C394&amp;ssl=1" alt="Independent Component Analysis output" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis-output.png?resize=1024%2C394&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis-output.png?resize=300%2C115&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis-output.png?resize=768%2C295&amp;ssl=1 768w, https://i1.wp.com/neptune.ai/wp-content/uploads/Independent-Component-Analysis-output.png?w=1144&amp;ssl=1 1144w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>





<h2>4. Pixelation</h2>



<div><figure><img data-attachment-id="27762" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/pixelation" data-orig-file="https://i2.wp.com/neptune.ai/wp-content/uploads/pixelation.jpg?fit=605%2C530&amp;ssl=1" data-orig-size="605,530" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pixelation" data-image-description="" data-medium-file="https://i2.wp.com/neptune.ai/wp-content/uploads/pixelation.jpg?fit=300%2C263&amp;ssl=1" data-large-file="https://i2.wp.com/neptune.ai/wp-content/uploads/pixelation.jpg?fit=605%2C530&amp;ssl=1" loading="lazy" src="https://i2.wp.com/neptune.ai/wp-content/uploads/pixelation.jpg?resize=454%2C398&amp;ssl=1" alt="pixelated image" width="454" height="398" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/pixelation.jpg?w=605&amp;ssl=1 605w, https://i2.wp.com/neptune.ai/wp-content/uploads/pixelation.jpg?resize=300%2C263&amp;ssl=1 300w" sizes="(max-width: 454px) 100vw, 454px" data-recalc-dims="1"></figure></div>



<p><a href="https://flowingdata.com/2019/09/30/pixelation-to-represent-endangered-species-counts/" target="_blank" rel="noreferrer noopener nofollow"><em>Source</em></a></p>



<p>Pixelation occurs when resizing of the images are enlarged to a point where individual pixels can be observed or pixels stretch to the point beyond their original size.</p>



<h3><strong>Pixelation using OpenCV</strong></h3>



<pre><span>import</span> cv2


input = cv2.imread(<span>'cat.png'</span>)


height, width = input.shape[:<span>2</span>]


w, h = (<span>16</span>, <span>16</span>)


temp = cv2.resize(input, (w, h), interpolation=cv2.INTER_LINEAR)


output = cv2.resize(temp, (width, height), interpolation=cv2.INTER_NEAREST)

cv2.imshow(<span>'Input'</span>, input)
cv2.imshow(<span>'Output'</span>, output)

cv2.waitKey(<span>0</span>)
</pre>



<div>
<div>
<p>Input:</p>



<figure><img data-attachment-id="27721" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/image-impainting-3" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-impainting-3" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?fit=400%2C400&amp;ssl=1" loading="lazy" width="400" height="400" src="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?resize=400%2C400&amp;ssl=1" alt="" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?w=400&amp;ssl=1 400w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/neptune.ai/wp-content/uploads/image-impainting-3.png?resize=80%2C80&amp;ssl=1 80w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure>
</div>



<div>
<p>Output:</p>



<figure><img data-attachment-id="27768" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/cat-pixelated" data-orig-file="https://i1.wp.com/neptune.ai/wp-content/uploads/cat-pixelated.png?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cat-pixelated" data-image-description="" data-medium-file="https://i1.wp.com/neptune.ai/wp-content/uploads/cat-pixelated.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/neptune.ai/wp-content/uploads/cat-pixelated.png?fit=400%2C400&amp;ssl=1" loading="lazy" width="400" height="400" src="https://i1.wp.com/neptune.ai/wp-content/uploads/cat-pixelated.png?resize=400%2C400&amp;ssl=1" alt="" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/cat-pixelated.png?w=400&amp;ssl=1 400w, https://i1.wp.com/neptune.ai/wp-content/uploads/cat-pixelated.png?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/cat-pixelated.png?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/neptune.ai/wp-content/uploads/cat-pixelated.png?resize=80%2C80&amp;ssl=1 80w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure>
</div>
</div>





<h2>5. Template matching</h2>



<div><figure><img data-attachment-id="27772" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/template-matching" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching.png?fit=1024%2C768&amp;ssl=1" data-orig-size="1024,768" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="template-matching" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching.png?fit=1024%2C768&amp;ssl=1" loading="lazy" src="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching.png?resize=512%2C384&amp;ssl=1" alt="template matching" width="512" height="384" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching.png?w=1024&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching.png?resize=768%2C576&amp;ssl=1 768w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></figure></div>



<p>Template matching is a method for searching and finding the location of a <em>template </em>in a <em>larger</em> image. You can think of it as a very simple approach to object detection.&nbsp;</p>



<p>In template matching, we slide the <em>template </em>image over the <em>larger</em> image as we do in the convolution process and find the matching part</p>



<h3><strong>Template matching using OpenCV</strong></h3>



<pre><span>import</span> cv2 <span>as</span> cv
<span>import</span> numpy <span>as</span> np
<span>from</span> matplotlib <span>import</span> pyplot <span>as</span> plt

img_rgb = cv.imread(<span>'waldo.jpg'</span>)
img_gray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)
template = cv.imread(<span>'waldo_temp.jpg'</span>,<span>0</span>)
w, h = template.shape[::<span>-1</span>]
res = cv.matchTemplate(img_gray,template,cv.TM_CCOEFF_NORMED)
threshold = <span>0.8</span>
loc = np.where( res &gt;= threshold)

<span>for</span> pt <span>in</span> zip(*loc[::<span>-1</span>]):
    cv.rectangle(img_rgb, pt, (pt[<span>0</span>] + w, pt[<span>1</span>] + h), (<span>0</span>,<span>0</span>,<span>255</span>), <span>2</span>)

cv.imshow(<span>'img_rgb'</span>, img_rgb)
cv.waitKey(<span>0</span>)</pre>



<p>Template:</p>



<div><figure><img data-attachment-id="27775" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/template" data-orig-file="https://i2.wp.com/neptune.ai/wp-content/uploads/template.jpg?fit=49%2C49&amp;ssl=1" data-orig-size="49,49" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="template" data-image-description="" data-medium-file="https://i2.wp.com/neptune.ai/wp-content/uploads/template.jpg?fit=49%2C49&amp;ssl=1" data-large-file="https://i2.wp.com/neptune.ai/wp-content/uploads/template.jpg?fit=49%2C49&amp;ssl=1" loading="lazy" width="49" height="49" src="https://i2.wp.com/neptune.ai/wp-content/uploads/template.jpg?resize=49%2C49&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>



<p>Larger image:</p>



<div><figure><img data-attachment-id="27836" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/template-matching-image" data-orig-file="https://i1.wp.com/neptune.ai/wp-content/uploads/template-matching-image.jpg?fit=1024%2C768&amp;ssl=1" data-orig-size="1024,768" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="template-matching-image" data-image-description="" data-medium-file="https://i1.wp.com/neptune.ai/wp-content/uploads/template-matching-image.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/neptune.ai/wp-content/uploads/template-matching-image.jpg?fit=1024%2C768&amp;ssl=1" loading="lazy" width="1024" height="768" src="https://i1.wp.com/neptune.ai/wp-content/uploads/template-matching-image.jpg?resize=1024%2C768&amp;ssl=1" alt="template matching base" srcset="https://i1.wp.com/neptune.ai/wp-content/uploads/template-matching-image.jpg?w=1024&amp;ssl=1 1024w, https://i1.wp.com/neptune.ai/wp-content/uploads/template-matching-image.jpg?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/neptune.ai/wp-content/uploads/template-matching-image.jpg?resize=768%2C576&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p>Output:</p>



<div><figure><img data-attachment-id="27781" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/template-matching-effect" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching-effect.png?fit=1024%2C768&amp;ssl=1" data-orig-size="1024,768" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="template-matching-effect" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching-effect.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching-effect.png?fit=1024%2C768&amp;ssl=1" loading="lazy" src="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching-effect.png?resize=512%2C384&amp;ssl=1" alt="template matching effect" width="512" height="384" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching-effect.png?w=1024&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching-effect.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/template-matching-effect.png?resize=768%2C576&amp;ssl=1 768w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></figure></div>





<h2>6. Image Generation Technique (GAN)</h2>



<div><figure><img data-attachment-id="27787" data-permalink="https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning/image-generation-technique" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Image-Generation-Technique.png?fit=512%2C324&amp;ssl=1" data-orig-size="512,324" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Image-Generation-Technique" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Image-Generation-Technique.png?fit=300%2C190&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/Image-Generation-Technique.png?fit=512%2C324&amp;ssl=1" loading="lazy" width="512" height="324" src="https://i0.wp.com/neptune.ai/wp-content/uploads/Image-Generation-Technique.png?resize=512%2C324&amp;ssl=1" alt="Image Generation Technique " srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/Image-Generation-Technique.png?w=512&amp;ssl=1 512w, https://i0.wp.com/neptune.ai/wp-content/uploads/Image-Generation-Technique.png?resize=300%2C190&amp;ssl=1 300w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"></figure></div>



<p><a href="https://arxiv.org/pdf/1910.04302.pdf"><em>Source</em></a></p>



<p>With the help of the Generative Adversarial Networks (GANs), we can train a deep learning model on the image data to generate the same type of image data.</p>



<p>GANs were invented by Ian Goodfellow in 2014 which he described in the paper of <a href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" target="_blank" rel="noreferrer noopener nofollow">Generative Adversarial Nets</a>.</p>



<p><strong>GANs are made of two distinct models&nbsp;</strong></p>



<ol><li><strong>Generator</strong></li><li><strong>Discriminator</strong></li></ol>



<p>The job of the <strong>generator</strong> is to generate the <em>fake</em> images and <strong>discriminator</strong> try to classify between the <strong>fake image and real image</strong>. During the training, the <strong>generator</strong> tries to outsmart the discriminator by generating better fake images and the discriminator tries to improve itself for differentiating between the real image and a fake image. You can read more about <a href="https://neptune.ai/blog/6-gan-architectures" target="_blank" rel="noreferrer noopener nofollow">GAN architectures and training in this article.&nbsp;</a></p>





<h2>Final thoughts</h2>



<p>So in this&nbsp; article, I briefly explained the most used image processing techniques in any machine learning project:</p>



<ul><li>Linear Filtering</li><li>Image Restoration</li><li>Template Matching</li><li>Image Generation Technique (GAN)</li><li>Pixelation</li><li>Independent Component Analysis</li></ul>



<p>But choosing the right technique requires experience and experience comes from practice.&nbsp;</p>



<p>So keep learning.</p>


<p><a href="https://neptune.ai/blog/experiment-management" target="_blank"><img width="684" height="1083" src="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=684%2C1083&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-attachment-id="21371" data-permalink="https://neptune.ai/blog/this-week-in-machine-learning-ai-graphic-designer-computational-limits-and-ai-need-for-people/cta-experiment-tracking-mobile" data-orig-file="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=684%2C1083&amp;ssl=1" data-orig-size="684,1083" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CTA experiment tracking mobile" data-image-description="" data-medium-file="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=189%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=647%2C1024&amp;ssl=1" data-lazy-srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?w=684&amp;ssl=1 684w, https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?resize=189%2C300&amp;ssl=1 189w, https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?resize=647%2C1024&amp;ssl=1 647w" data-lazy-sizes="(max-width: 684px) 100vw, 684px" data-lazy-src="https://i2.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking-mobile.jpg?fit=684%2C1083&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><img width="1366" height="730" src="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=1366%2C730&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-attachment-id="21372" data-permalink="https://neptune.ai/blog/this-week-in-machine-learning-ai-graphic-designer-computational-limits-and-ai-need-for-people/cta-experiment-tracking" data-orig-file="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=1366%2C730&amp;ssl=1" data-orig-size="1366,730" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="CTA experiment tracking" data-image-description="" data-medium-file="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=300%2C160&amp;ssl=1" data-large-file="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=1024%2C547&amp;ssl=1" data-lazy-srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?w=1366&amp;ssl=1 1366w, https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?resize=300%2C160&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?resize=1024%2C547&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?resize=768%2C410&amp;ssl=1 768w, https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?resize=1200%2C641&amp;ssl=1 1200w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/neptune.ai/wp-content/uploads/2020/07/CTA-experiment-tracking.jpg?fit=1366%2C730&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>





<div>
    <h3>Get notified of new articles</h3>
    
    <p>By submitting the form you give concent to store the information provided and to contact you.<br>Please review our <a href="https://neptune.ai/wp-content/uploads/privacy-policy.pdf">Privacy Policy</a> for further information.</p>
</div>

</article>
                </div></div>]]>
            </description>
            <link>https://neptune.ai/blog/image-processing-techniques-you-can-use-in-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-24836287</guid>
            <pubDate>Tue, 20 Oct 2020 11:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The biggest thing I learned launching Zapier (2014)]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24836252">thread link</a>) | @andrelaszlo
<br/>
October 20, 2020 | https://mikeknoop.com/biggest-thing-learned-launching-zapier/ | <a href="https://web.archive.org/web/*/https://mikeknoop.com/biggest-thing-learned-launching-zapier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>

      

        
        <!--<p><img src="/static/img/upload/9f67b80a8be311e3b2c528cfe91e44cb.png" /></p>-->
        

        <p>Last updated Feb. 3, 2014 — read <span id="post-views">25922</span> times</p>

        <p><strong>This post is adapted from <a href="https://mikeknoop.com/iowaconf-road-to-zapier">a talk I gave</a> at <a href="http://iowaconf.com/">iowaconf</a> October 2013</strong></p>

<p>I was one of three co-founders of <a href="https://zapier.com/">Zapier</a>. If you're unfamiliar with the origin story, we got started out of a <a href="http://columbia.startupweekend.org/">Startup Weekend</a> in Columbia, Mo. in 2011.</p>

<p>The prompt for this talk was to describe “what you learned building Zapier”. The most obvious thing I could share is tactical advice or early anecdotes. Things like how we got our first dozen customers to pay us before we really had a product or how we almost missed our acceptance call into <a href="https://ycombinator.com/">Y Combinator</a>.</p>

<p>And to be clear, I'm still leaning <em>a ton</em> through today. Startups are very much “trial-by-fire” as a first-time founder.</p>

<p>But the more I thought about that talk prompt, I realized the biggest thing I learned actually began way, way earlier. It's a lesson that applies equally to launching Zapier as to endeavors which lie beyond.</p>



<p>Growing up I've was always into tech and I loved building things (I originally wanted to be an architect when I thought that's what they did).</p>

<p>I learned how to build websites after borrowing a friend's “Learn HTML in 24 Hours” book. My goal was to build an AOL Instant Messenger profile for myself, which conveniently, could render actual HTML.</p>

<p>Later I learned how to code “hardcore” by picking up assembly language. I did this so I could write TI-83+ calculator games and play them during class (much to the dismay to my teachers growing up).</p>

<p>Towards the end of high school though, it was time to pick a major. Computer Science was the obvious shoe-in. But I didn't want to do it! I feared that I would burn out and not have time/energy for side projects.</p>

<p>So I decided instead to do Mechanical Engineering instead – also maybe not the best choice considering my goal outlined above but at least I wouldn't be coding 24/7 for school.</p>



<p>Facebook was just taking off during my freshman year of college. They launched their original developer platform that fall and I was instantly hooked.</p>

<p>I spent a good chunk of free time building apps. Like this one that you could use to request phone numbers from your fiends.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e5f24a618be311e3ae7628cfe91e44cb.png" alt=""></p>

<p>Or this one which was a developer toolkit, making it easy to embed Facebook-style form elements.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e45bf5828be311e3b0bb28cfe91e44cb.png" alt=""></p>

<p>Or even my last solo Facebook endeavor, a monitoring tool for the Facebook Platform, which peaked at a grand total of 1 paying user.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e35826a88be311e3982b28cfe91e44cb.png" alt=""></p>

<p>You can probably guess: my ROI wasn't too great. But I was very active in the Facebook developer community and made a name for myself. Facebook reached out and asked if I'd like to become a community moderator. I have to imagine this was because of my community participation and not because they looked at any of my app analytics. </p>

<p><img src="https://mikeknoop.com/static/img/upload/e5897b478be311e3a69228cfe91e44cb.png" alt=""></p>

<p>This moderator gig led me to write developer columns for Inside Facebook and in combination, these two things generally kept my around the platform much longer than I otherwise should have.</p>

<p>It did turn out to be useful though.</p>



<p>I was applying for summer engineering internships after my Junior year of college. I applied about two dozen engineering firms in Missouri as well as a few web development gigs.</p>

<p>Of all resume's I sent out I only heard back from one place, <a href="http://veteransunited.com/">Veterans United</a>, a VA loan lender based in Columbia Mo. I learned they wanted to build an app for military personnel to reconnect inside of Facebook.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e4ebb0e88be311e3864128cfe91e44cb.png" alt=""></p>

<p>I worked on Military Basebook for about a year. It peaked around 20,000 monthly active users but ultimately wasn't sticky enough. Around this time I learned a few things:</p>

<p><em>1. Facebook apps that aren't games just don't work well</em></p>

<p>Even today the most successful apps on Facebook are games. Users on Facebook just aren't in mindset to seek out utilities.</p>

<p><em>2. I didn't want to do the traditional engineering career</em></p>

<p>Although the sentiment had been brewing for a while, that summer was a turning point where I actively decided I would focus on side projects post college instead of seeking a full time job. I was going to keep throwing stuff at the wall and see if something stuck.</p>

<p>I began my mechanical engineering masters program (which I ended up dropping out of) as part of this strategy. I was able to secure a 2-year grant which paid for school living expenses. This left me with a lot of free time for my side projects.</p>



<p>Around the middle of my junior year I discovered <a href="https://news.ycombinator.com/">Hacker News</a>. If you're unfamiliar, it is a lot like Reddit (HN actually came first) where stories and articles are upvoted to the frontpage. Usually people post about programming and startups.</p>

<p>One convention on Hacker News is called “Show HN” which is a way for people to show off their side projects and solicit feedback.</p>

<p>One “Show HN” caught my eye by a user called <a href="https://news.ycombinator.com/?user=phpnode">phpnode</a> (thank you phpnode!). He launched a side project called <a href="http://zpr.io/6dM7.png">Hackernewsers</a> which was a map of users who used Hacker News.</p>

<p>The idea was simple. You submit your username, real name, and location and you get access to a map where you can see others who've done the same. I checked out Columbia Mo. and I saw something interesting – there was someone else in the area! It turns out that other person was this guy:</p>

<p>[Bryan Helmig]</p>

<p>I remember clicking through all the information I could find online about him. I found his <a href="http://bryanhelmig.com/">personal blog</a>, some of his <a href="http://rankiac.com/">side projects</a>, and even <a href="http://youtube.com/">his YouTube channel</a>. But the most important thing I learned was that he worked at same company I did, <a href="http://veteransunited.com/">Veterans United</a>.</p>

<p>That was enough of a connection for me so I got in touch over Facebook. We met up several times that year for beers and wanted to work on something together.</p>



<p>Mizzou, the university I attended in Columbia, sent out a weekly email with things happening on campus and in the area. I usually auto-archived these. I must have been pretty bored the day I <a href="http://google.com/">opened this one</a>, but I'm glad I did. I found an enticing headline “Startup Weekend is Coming to Columbia”.</p>

<p>I had never heard of Startup Weekend but I knew I liked building things, I knew I liked startups, so maybe this is something I wanted to be a part of. I then discovered tickets cost $50 and was a bit turned off.</p>

<p>Maybe if I could find someone else going, it would be worth the money. So I messaged Bryan and he said he was going! I bought tickets later that night, and that's how I wound up at Columbia Missouri's first ever Startup Weekend.</p>

<p>At Startup Weekend I formally met <a href="http://wadefoster.net/">Wade Foster</a> who also happened to work at Veterans United. We got together and worked on the project that Bryan originally pitched as “API Mixer”. The idea was simple: make a tool that enables anyone (marketers, sales, HR, developers) to connect together two web services they use.</p>

<p>In true startup fashion we took to the back garage and got to work. The <a href="https://zapier.com/blog">story of Zapier</a> is still being written today.</p>



<p>When I look back on the decisions that lead me to Startup Weekend I am amazed how many times the proverbial train of life could have been derailed.</p>

<p>What if I hadn't opened that email? What if I never got into Facebook development? What if I hadn't worked at Veterans United?</p>

<p>In reminds me a lot of the game Plinko on The Price is Right. The one where the contestant drops the puck down a pegged board and it randomly makes it's way down to one of the buckets at the bottom with the winning bucket in the middle.</p>

<p><img src="https://mikeknoop.com/static/img/upload/9ed525578be311e39e8a28cfe91e44cb.png" alt="Plinko"></p>

<p>The funny thing about plinko is, if you run sufficiently many trials, the middle bucket is actually the easiest to hit! The outcome follows a normal distribution.</p>

<p><img src="https://mikeknoop.com/static/img/upload/9dfcebde8be311e3ae7b28cfe91e44cb.png" alt="Plink Distrobution"></p>

<p>The take away here is if you go through life making random decisions, statistically, you'll wind up in the middle. While in Plinko the middle is the best, in reality, the really exciting stuff happens at the edges of the board. That's where Zapier happened. And to get there you've got to purposely push yourself towards the outsides.</p>

<p>Although I didn't realize it at the time, there was a guiding principle for all my decisions. I was always putting myself out there, in uncomfortable, new situations that challenged my own status quo.</p>

<p>That's the road to the outside of the Plinko board. And that's the biggest thing I learned by creating Zapier.</p>


        

          <p>If you'd like to see more posts like this one, <a href="https://twitter.com/intent/user?screen_name=mikeknoop">follow me on Twitter</a>!</p>

        

        

            <!-- removed disqus commenting -->

        

      

    </div>

    

    </div></div>]]>
            </description>
            <link>https://mikeknoop.com/biggest-thing-learned-launching-zapier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24836252</guid>
            <pubDate>Tue, 20 Oct 2020 11:47:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raymarching with Fennel and LÖVE]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24835766">thread link</a>) | @forgotpwd16
<br/>
October 20, 2020 | https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/ | <a href="https://web.archive.org/web/*/https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Previously I’ve decided to implement a rather basic <a href="https://andreyorst.gitlab.io/posts/2020-06-04-simple-ray-casting-with-clojurescript/">raycasting engine in ClojureScript</a>.
It was a lot of fun, an interesting experience, and ClojureScript was awesome.
I’ve implemented small <a href="https://andreyorst.gitlab.io/posts/2020-06-04-simple-ray-casting-with-clojurescript/#labyrinth-game">labyrinth game</a>, and thought about adding more features to the engine, such as camera shake, and wall height change.
But when I’ve started working on these, I quickly understood, that I’d like to move on to something more interesting, like real 3D rendering engine, that also uses rays.</p>
<p>Obviously, my first though was about writing a ray-tracer<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.
This technique is wide known, and gained a lot of traction recently.
With native hardware support for ray tracing, a lot of games are using it, and there are a lot of tutorials teaching how to implement one<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.
In short, we cast a bunch of rays in 3D space, and calculate their trajectories, looking for what ray will hit and bounce off.
Different materials have different bounce properties, and by tracing rays from camera to the source of light, we can imitate illumination.
There are also a lot of different approaches how to calculate bouncing, e.g. for global illumination, and ambient light, but I’ve felt that it is a rather complicated task, for a weekend post.
And unlike raycasting, most ray-tracers require polygonal information in order to work, where raycasting only need to know wall start and end points.</p>
<p>I’ve wanted a similar approach for 3D rendering, where we specify an object in terms of it’s mathematical representation.
Like for sphere, we’ll just specify coordinate of a center, and a radius, and our rays will find intersection points with it, providing us a sufficient data to draw this sphere on screen.
And recently, I’ve read about a similar technique, that uses rays for drawing on screen, but instead of casting infinite rays as in raycasting, it marches a ray in terms of steps.
And it also uses a special trick, to make this process very optimized, therefore we can use it for rendering real 3D objects.</p>
<p>I’ve decided to structure this post similarly to the one about raycasting, so this will be another long-read, often more about Fennel rather than raymarching, but at the end I promise that we’ll get something that looks like this:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/end-result.png"> 
</figure>

<p>So, just as in raycasting, first we need to do is to understand how raymarching engine works <em>on paper</em>.</p>
<h2 id="raymarching-basics">Raymarching basics</h2>
<p>Raymarching can be illustrated similarly to raycaster, except it requires more steps until we could render our image.
First, we need a camera, and an object to look at:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle.svg"> 
</figure>

<p>Our first step would to cast a ray, however, unlike with raycasting, we’ll cast a portion of a ray:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-short-ray.svg"> 
</figure>

<p>We then check, if the ray intersects with the sphere.
It’s not, so we do one more step:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-two-steps.svg"> 
</figure>

<p>It’s not intersecting yet, so we repeat again:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-ray-overshoot.svg"> 
</figure>

<p>Oops, ray overshoot, and is now inside the sphere.
This is not really good option for us, as we want for our rays to end directly at the object’s surface, without calculating intersection point with the object itself.
We can fix this by casting shorter ray:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-small-rays.svg"> 
</figure>

<p>However, this is very inefficient!
And besides, if we’ll change the angle a bit or move the camera, we will overshoot again.
Which means that we’ll either have incorrect result, or require a very small step size, which will blow up computation process.
How we can fix this?</p>
<h3 id="distance-estimation">Distance estimation</h3>
<p>The solution to this is a signed distance function, or a so called Distance Estimator.
Imagine if we knew how far we are from the object at any point of time?
This would mean that we can shoot a ray of this length in any direction and still don’t hit anything.
Let’s add another object to the scene:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/scene-with-two-objects.svg"> 
</figure>

<p>Now, let’s draw two circles, which will represent distances from the objects, to the point from where we’ll cast rays:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/distances.svg"> 
</figure>

<p>We can see, that there are two circles, and one is bigger than another.
This means, that if we choose the shortest safe distance, we can safely cast ray in any direction and not overshoot anything.
For example, let’s cast a ray towards the square:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/ray-in-safe-zone.svg"> 
</figure>

<p>We can see, that we haven’t reached the square, but more importantly we did not overshoot it.
Now we need to march the ray again, but what distance should it cover?
To answer this question, we need to take another distance estimation from ray end to the objects in the scene:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/second-safe-march.svg"> 
</figure>

<p>Once again we choose shorter distance, and march towards the square, then get the distance again, and repeat the whole process:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/another-safe-match.svg"> 
</figure>

<p>You can see that with each step the distance to the object becomes smaller, and thus we will never overshoot the object.
However this also means, that we will take a lot of really small steps, until we finally fully hit the object, if we ever do.
This is not a good idea, because it is even more inefficient than using fixed distance, and produces too accurate results, which we don’t really need.
So instead of marching up until we exactly hit the object, we will march <em>enough</em> times.
E.g. until the distance to the object is small enough, then there’s no real point to continue marching, as it is clear that we will hit the object soon.
But this also means, that if the ray goes near the edge of an object, we do a lot of expensive steps of computing distance estimations.</p>
<p>Here’s a ray that is parallel to the side of the square, and marches towards the circle:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/expensive-marching.svg"> 
</figure>

<p>We do a lot of seemingly pointless measurements, and if a ray was closer to the square’s side, we would do even more steps.
However this also means, that we can use this data (since we’re already computed it) to render such things as glow, or ambient occlusion.
But more on this later.</p>
<p>Once ray hit an object we have all the data we need.
Ray represents a point on the screen, and the more rays we cast the higher resolution of our image will be.
And since we’re not using triangles to represent objects, our spheres will always be smooth, no matter how close we are to it, because there’s no polygons involved.</p>
<p>This is basically it.
Ray marching is quite simple concept, just like raycaster, although it’s a bit more complicated, as we do have to compute things in 3D space now.
So let’s begin implementing it by installing required tools, and setting up the project.</p>
<h2 id="project-structure">Project structure</h2>
<p>As you know from the title we will use two main tools to create ray-marcher, which are <a href="https://love2d.org/">LÖVE</a>, a free game engine, and <a href="https://fennel-lang.org/">Fennel</a> the programming language.
I’ve chosen Fennel, because it is a Lisp like language, that compiles to Lua, and I’m quite a fan of Lisps.
But we also needed to draw somewhere, and I know no GUI toolkit for Lua.
But there is LÖVE - a game engine that runs Lua code, which is capable on running on all systems, thus a perfect candidate for our task.</p>
<p>Installation steps may differ per operating system, so please refer to manuals<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup><sup>, </sup><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.
At the time of writing this post I’m using Fedora GNU/Linux, so for me it means:</p>
<div><pre><code data-lang="sh">$ sudo dnf install love luarocks readline-devel
$ luarocks install --local fennel
$ luarocks install --local readline <span># requires readline-devel</span>
$ <span>export</span> <span>PATH</span>=<span>"</span><span>$PATH</span><span>:</span><span>$HOME</span><span>/.luarocks/bin"</span>
</code></pre></div><p>It’s better to permanently add <code>$HOME/luarocks/bin</code> (or another path, if your installation differs) to the <code>PATH</code> variable in your shell, in order to be able to use installed utilities without specifying full path every time.
You can test if everything is installed correctly, by running <code>fennel</code> in you command line.</p>
<div><pre><code data-lang="sh">$ fennel
Welcome to Fennel 0.5.0 on Lua 5.3!
Use (doc something) to view documentation.
&gt;&gt; (+ 1 2 3)
6
&gt;&gt;
</code></pre></div><p>For other distributions installation steps may vary, and for Windows, I think it’s safe to skip the <code>readline</code> part, which is fully optional, but makes editing in a REPL a bit more comfortable.</p>
<p>Once everything is installed, let’s create the project directory, and the <code>main.fnl</code> file, where we will write our code.</p>
<div><pre><code data-lang="sh">$ mkdir love_raymarching
$ <span>cd</span> love_raymarching
$ touch main.fnl
</code></pre></div><p>And that’s it!
We can test if everything works by adding this code to <code>main.fnl</code>:</p>
<div><pre><code data-lang="clojure">(<span>fn </span><span>love.draw</span> []
  (<span>love.graphics.print</span> <span>"It works!"</span>))
</code></pre></div><p>Now we can compile it with <code>fennel --compile main.fnl &gt; main.lua</code>, thus producing the <code>main.lua</code> file, and run <code>love .</code> (dot is intentional, it indicates current directory).</p>
<p>A window should appear, with white text <code>It works!</code> in upper left corner:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/love-works.png"> 
</figure>

<p>Now we can begin implementing our raymarcher.</p>
<h2 id="scene-setup">Scene setup</h2>
<p>Just as in raycaster, we need a camera that will shoot rays, and some objects to look at.
Let’s begin by creating a camera object, that will store coordinates and rotation information.
We can do so, by using <code>var</code> to declare a variable that is local to our file, and that we can later change with <code>set</code><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>:</p>

<div><pre><code data-lang="clojure">(<span>var </span><span>camera</span> {<span>:pos</span> [0.0 0.0 0.0]
             <span>:x-rotate</span> 0.0
             <span>:z-rotate</span> 0.0})
</code></pre></div><blockquote>
<p>For those unfamiliar with Lisps, and especially Clojure, let me quickly explain what this syntax is.
If you know this stuff, feel free to <a href="#org6f2d291">skip this part</a>.</p>
<p>We start by using a <code>var</code> special form, that binds a value to a name like this: <code>(var name value)</code>.
So if we start the REPL, using <code>fennel</code> command in the shell, and write <code>(var a 40)</code>, a new variable <code>a</code> will be created.
We then can check, that it has the desired value by typing <code>a</code>, and pressing return:</p>
<p>We can then alter the contents of this variable by using <code>set</code> special form, which works like this <code>(set name new-value)</code>:</p>
<div><pre><code data-lang="clojure"><span>&gt;&gt;</span> (<span>set </span><span>a</span> (<span>+ </span><span>a</span> 2))
<span>&gt;&gt;</span> <span>a</span>
42
</code></pre></div><p>Now to curly and square brackets.
Everything enclosed in curly braces is a hashmap.
We can use any Lua value as our key, and the most common choice is a string, but Fennel has additional syntax for defining keys - a colon followed by a word: <code>:a</code>.
This is called a keyword, and in Fennel it is essentially the same as <code>"a"</code>, but we don’t need to write a pair of quotes.
However keywords can’t contain spaces, and some other symbols.</p>
<p>So writing this <code>{:a 0 :b 2 :c :hello}</code> in the REPL will make a new table, that holds three key value pairs, which we can later get with another syntax - the dot <code>.</code>.
Combining it with <code>var</code>, we can see that it works:</p>
<div><pre><code data-lang="clojure"><span>&gt;&gt;</span> (<span>var </span><span>m</span> {<span>:a</span> 1 <span>:b</span> 2 <span>:c</span> <span>:hello</span>})
<span>&gt;&gt;</span> (<span>. </span><span>m</span> <span>:b</span>)
2
</code></pre></div><p>There’s also a shorthand for this …</p></blockquote></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/">https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/</a></em></p>]]>
            </description>
            <link>https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835766</guid>
            <pubDate>Tue, 20 Oct 2020 10:26:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimalism in Programming: How Complexity Harms Your Productivity]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24835759">thread link</a>) | @zweig
<br/>
October 20, 2020 | https://blog.finxter.com/minimalism-in-programming/ | <a href="https://web.archive.org/web/*/https://blog.finxter.com/minimalism-in-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15315" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<div><figure><img loading="lazy" src="https://images.pexels.com/photos/3768126/pexels-photo-3768126.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" data-src="https://images.pexels.com/photos/3768126/pexels-photo-3768126.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" alt="Complexity" width="839" height="563" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif"></figure></div>



<p><em>This article is based on a book chapter from my upcoming book <strong>“From One to Zero: A Minimalistic Approach to Programming”</strong>. </em></p>



<p>My <a href="https://blog.finxter.com/subscribe/" title="Subscribe" target="_blank" rel="noreferrer noopener">programming students</a> often write in with their struggles and failures. Many students ultimately overcome their struggles—but a large percentage of them <strong><em>give up their programming ambitions</em></strong> after realizing how hard creating software can be. These students started with the goal of becoming professional coders, but, ultimately, they missed that target. </p>



<p>After thousands of personal conversations with these students, it became apparent that many new coders don’t fail because they don’t know one or the other Python feature or because they lack technical skills, intelligence, or even talent. </p>



<p>These are not the underlying reasons <strong><em>why </em></strong>they fail. </p>



<p>Instead, they fail because they are<strong> overwhelmed by the complexity lurking everywhere in programming</strong>. The complexity causes them to throw in the towel. This is unfortunate because there are many ways to mitigate the harmful effects of complexity in programming. In the previous chapter, you’ve already learned some strategies about the <a href="https://blog.finxter.com/the-80-20-principle-in-programming/" target="_blank" rel="noreferrer noopener" title="The 80/20 Principle in Programming"><strong>80/20 principle</strong></a> (Focus on the vital few and sacrifice the trivial many!).</p>



<p>In this chapter, we’re going to have a comprehensive look at this important and highly underexplored topic. <strong>What exactly is complexity?</strong> Where does it occur? How does it look like?</p>



<p>Let’s start with a quick overview—there’s significant complexity in selecting the right</p>



<ul><li>programming language among dozens of popular languages,</li><li>coding project to work on—from thousands of open-source projects and myriads of problems,</li><li>libraries within a language (<a href="https://blog.finxter.com/why-does-the-scikit-learn-library-use-a-trailing-underscore-convention-for-attribute-names/" target="_blank" rel="noreferrer noopener" title="Why Does the Scikit-learn Library use a Trailing Underscore Convention for Attribute Names?">scikit-learn</a> vs <a href="https://blog.finxter.com/numpy-tutorial/" target="_blank" rel="noreferrer noopener" title="NumPy Tutorial – Everything You Need to Know to Get Started">NumPy </a>vs <a href="https://blog.finxter.com/2-min-computer-science-papers-tensorflow/" target="_blank" rel="noreferrer noopener" title="[2-min CS Papers] A Short Introduction to the TensorFlow System">TensorFlow</a>),</li><li>emerging technologies to “bet on”—Alexa apps, smartphone apps, browser-based web apps, integrated Facebook or WeChat apps, virtual reality apps—and</li><li><a href="https://blog.finxter.com/best-python-ide/" target="_blank" rel="noreferrer noopener" title="Best Python IDE and Code Editors [Ultimate Guide]">coding editor</a> such as PyCharm, IDLE, and Atom.</li></ul>



<p>Given the great confusion caused by these sources of complexity, it’s no surprise that<strong><em> “How to start?”</em></strong> is one of the most common questions from programming beginners. </p>



<p>To answer the question right away, the best way to start is <strong><em>not </em></strong>by choosing a programming book and reading over all <a href="https://blog.finxter.com/python-crash-course/" title="Python Programming Tutorial [+Cheat Sheets]" target="_blank" rel="noreferrer noopener">syntactical features</a> of the programming language. Surprisingly, these coding books sell well—even I am a<a href="https://coffeebreakpython.com/" target="_blank" rel="noreferrer noopener" title="https://coffeebreakpython.com/"> seller of such books</a>. However, interacting with thousands of programming students personally I realized that many ambitious students buy programming books as a commitment device to put the learning task on their ToDo lists—if they’ve spent money on the book, they better read it or the investment will be lost. But as so many other tasks on their ToDo lists, reading a programming book is seldomly one to be completed. </p>



<p><strong>Many students buy these programming tutorial books but very few actually read them.</strong></p>



<p>So, what is the <strong><em>best way to start to learn to program</em></strong>? In my opinion, the best way to start is to choose a practical code project—a simple one if you’re a beginner—and push it to completion. </p>



<ul><li>Don’t read coding books before you do this. </li><li>Don’t read random tutorials on the web. </li><li>Don’t scroll through endless feeds on StackOverflow. </li></ul>



<p><strong><em>Just set up the project and start coding with the limited skills you have</em></strong> and your common sense. </p>



<p>It’s okay if you don’t understand what you’re doing, you will gradually increase your understanding. You read books and articles only to make progress on the project in front of you. By diving into the process of finishing your first project, you need to solve a number of highly relevant problems: </p>



<ul><li><a href="https://blog.finxter.com/best-python-ide/" target="_blank" rel="noreferrer noopener" title="Best Python IDE and Code Editors [Ultimate Guide]">Which code editor should you use? </a></li><li><a href="https://blog.finxter.com/install-python-win/" target="_blank" rel="noreferrer noopener" title="How to Install Python on Windows? [7 Easy Steps]">How to install Python? </a></li><li><a href="https://blog.finxter.com/how-to-read-all-lines-of-a-file-in-a-python-one-liner/" target="_blank" rel="noreferrer noopener" title="How to Read All Lines of a File in a Python One-Liner?">How to read input from a file? </a></li><li>How to store the input in your program for later use? </li><li>How to manipulate the input to obtain the desired output?</li></ul>



<p>By answering these questions, you gradually build a well-rounded skill set of a practitioner. Over time, you’ll answer these questions better and better. Your speed and skill to solve these problems will grow. You’ll be able to solve similar problems much bigger and you’ll create your internal database of programming patterns and conceptual insights. Even advanced coders learn and improve with the exact same process—only the coding projects have become much larger and more complicated.</p>



<p>Let’s assume you adopt this <a href="https://blog.finxter.com/how-to-start-your-freelancing-business-on-the-side/" target="_blank" rel="noreferrer noopener" title="[7 Steps] How to Start Your Freelancing Business on the Side?">project-based learning approach</a>. You focus on a single project and work on it for a considerable amount of time. What is your biggest enemy now? You guessed it: <strong><em>complexity</em></strong>.</p>



<p>You’ll struggle with complexity in:</p>



<ul><li>finding bugs in ever-growing codebases,</li><li>understanding code components and how they interact,</li><li>choosing the right feature to be implemented next,</li><li>understanding the mathematical and conceptual basics of the code.</li></ul>



<p><strong>Complexity is everywhere</strong>, at every stage of a project that comes to life. And the hidden costs of this complexity are very tangible: coders who are just starting out throw in the towel and the projects never see the light of day. The beginner argues: <em>“coding is too difficult for me”</em> and he truly believes it—even though nothing can be further from the truth.</p>



<p>The root of the problem is overwhelming complexity and a lack of focus. So, the question arises: </p>



<p><strong><em>How to solve complexity and a lack of focus?</em></strong></p>



<div><figure><img loading="lazy" src="https://images.pexels.com/photos/509922/pexels-photo-509922.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" data-src="https://images.pexels.com/photos/509922/pexels-photo-509922.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" alt="Minimalism" width="844" height="563" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif"></figure></div>



<p>The answer is straightforward, and I’ve already stressed it a few times in this book: <strong>minimalism</strong>. Seek simplicity and focus – in every stage of the coding cycle. I want you to take this one concept out of the book: Take a radically minimalistic position in every area you’ll encounter in the programming space. If this book can convince you to take more extreme measures to increase your focus, it has accomplished its mission!</p>



<p>Let’s dive deeper into the concept of complexity to develop an understanding of one of the great enemies of your coding productivity.</p>




<h2><span id="What_is_Complexity"></span>What is Complexity?<span></span></h2>



<p>In different fields, the term complexity comes with different meanings. Sometimes, it’s strictly defined, such as in computational complexity of a computer program that provides a means to analyze a given code function for varying inputs. Other times, it’s loosely defined as the amount or structure of interactions between system components. But in this book, we’re going to use it in a more generic way.</p>



<p>The Merriam Webster dictionary defines complexity as <em>“something complex”</em>. The term complex is defined as <em>“a whole made up of complicated […] parts”</em>. If you resolve the term complicated—<em>“difficult to analyze, understand, or explain”</em>—you end up with the following rough definition:</p>



<p><strong>Complexity</strong>: <em>“a whole, made up of parts, that is difficult to analyze, understand, or explain”</em>.</p>



<p>This is how we use the term complexity in this book. Complexity describes a whole system or entity. It is difficult to explain or describe. Because of its difficulty, complexity causes struggle and confusion. When confronted with complexity, people find themselves cognitively unable to comprehend the deeper meaning, implications, or effects of “the whole”.</p>



<div><figure><img loading="lazy" src="https://images.pexels.com/photos/4183195/pexels-photo-4183195.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" data-src="https://images.pexels.com/photos/4183195/pexels-photo-4183195.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" alt="Complexity" width="450" height="563" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif"></figure></div>



<p>They cannot see the big picture—complexity is the enemy of clarity, closure, and predictability, because a complex system behaves in highly unpredictable ways. Where do you find complexity? You’ll find it everywhere, because real-world systems are messy: A highly interrelated web of causes and effects that obfuscates the behavior of a real system, and that is impossible to decode for individuals who are themselves caught in this complex web. Like a differential equation, the output of one system feeds into another system’s input which, in turn, feeds back into the first system as an input. Examples of highly complex systems are the stock market, social trends, emerging political viewpoints, and big computer programs with hundreds of thousands of lines of code—such as the Windows operating system.</p>



<p>If you are a coder, you are especially prone to overwhelming complexity. Let’s dive into different sources of complexity in the field of programming:</p>



<ul><li>Complexity in a Project Lifecycle</li><li>Complexity in Software and Algorithmic Theory</li><li>Complexity in Learning</li><li>Complexity in Processes</li><li>Complexity in Social Networks</li><li>Complexity in Your Daily Life</li><li>Complexity in a Project Lifecycle</li></ul>



<p>The best way to learn and create lasting value is through your participation or initiation of a real-world project. But how does it look like when a real-world project comes to life? Let’s dive into the different stages of the project lifecycle: Planning, Defining, Designing, Building, Testing, and Deployment (see Figure 1).</p>



<p><em><strong>Figure 1</strong>: A software project comes to life – the project lifecycle consists of six conceptual phases: Planning, Defining, Designing, Building, Testing, Deployment.</em></p>



<div><figure><img loading="lazy" width="604" height="340" src="https://blog.finxter.com/wp-content/uploads/2020/10/image-182.png" data-src="https://blog.finxter.com/wp-content/uploads/2020/10/image-182.png" alt="" data-srcset="https://blog.finxter.com/wp-content/uploads/2020/10/image-182.png 604w, https://blog.finxter.com/wp-content/uploads/2020/10/image-182-300x169.png 300w, https://blog.finxter.com/wp-content/uploads/2020/10/image-182-150x84.png 150w" data-sizes="(max-width: 604px) 100vw, 604px" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" srcset="https://blog.finxter.com/wp-content/uploads/2020/10/image-182.png 604w, https://blog.finxter.com/wp-content/uploads/2020/10/image-182-300x169.png 300w, https://blog.finxter.com/wp-content/uploads/2020/10/image-182-150x84.png 150w"></figure></div>



<p>Figure 1 shows the software development life cycle consisting of six phases. Even if you’re working on a very small software project, you’re likely going through all six phases of the software development lifecycle. Next, you’ll quickly dive into all six phases—and how complexity has a significant impact on every one of them.</p>



<h3><span id="Planning"></span>Planning<span></span></h3>



<p>The first stage of the software development life cycle is the planning phase. From software engineering literature, you may know this as <strong><em>requirement analysis</em></strong>. The purpose of this phase is to determine how the end product will look like. A successful planning phase leads to a strictly defined set of required features to deliver to the customer or the end user.</p>



<p>The planning phase solves a multi-dimensional problem where different departments and functions must collaborate to determine the optimal set of features of the software. A number of factors must be taken into consideration: the costs of building a feature, the risk of not being able to successfully implement the feature, the expected value for the end user, marketing and sales implications, maintainability, scalability, legal restrictions and many more.</p>



<p>This phase is crucial because it can save you from massive wastages of downstream energy in the following phases. Business owners know that <strong><em>capital allocation</em></strong> (or …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.finxter.com/minimalism-in-programming/">https://blog.finxter.com/minimalism-in-programming/</a></em></p>]]>
            </description>
            <link>https://blog.finxter.com/minimalism-in-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835759</guid>
            <pubDate>Tue, 20 Oct 2020 10:25:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assorted Thoughts on Zig and Rust]]>
            </title>
            <description>
<![CDATA[
Score 338 | Comments 289 (<a href="https://news.ycombinator.com/item?id=24835357">thread link</a>) | @ikskuh
<br/>
October 20, 2020 | https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I've been using <a href="https://ziglang.org/">zig</a> for ~4 months worth of side projects, including a <a href="https://git.sr.ht/%7Ejamii/focus/tree">toy text editor</a> and an <a href="https://git.sr.ht/%7Ejamii/imp">interpreter for a relational language</a>. I've written ~10kloc.</p>
<p>That's not nearly enough time to form a coherent informed opinion. So instead here is an incoherent assortment of thoughts and experiences, in no particular order :)</p>
<p>This is not meant to be an introduction to zig - check out the excellent <a href="https://ziglang.org/documentation/master/">language docs</a> or the new <a href="https://ziglearn.org/">ziglearn.org</a> instead. I'll try to focus instead on things that are not immediately obvious from reading intro material.</p>
<p>The obvious point of comparison is to rust. For context, I've been using rust <a href="https://scattered-thoughts.net/writing/three-months-of-rust/">since 2015</a>. Mostly in research positions writing throwaway code, but also ~14 months working on <a href="https://materialize.io/">a commercial database</a> which is ~100kloc.</p>
<hr>
<p>Zig is dramatically simpler than rust. It took a few days before I felt proficient vs a month or more for rust.</p>
<p>Most of this difference is <strong>not</strong> related to lifetimes. Rust has patterns, traits, dyn, modules, declarative macros, procedural macros, derive, associated types, annotations, cfg, cargo features, turbofish, autoderefencing, deref coercion etc. I encountered most of these in the first week. Just understanding how they all work is a significant time investment, let alone learning when to use each and how they affect the available design space.</p>
<p>I still haven't internalized the full rule-set of rust enough to be able predict whether a design in my head will successfully compile. I don't remember the order in which methods are resolved during autoderefencing, or how module visibility works, or how the type system determines if one impl might <a href="https://github.com/Ixrec/rust-orphan-rules#what-are-the-orphan-rules">overlap another or be an orphan</a>. There are frequent moments where I know what I want the machine to do but struggle to encode it into traits and lifetimes.</p>
<p>Zig manages to provide many of the same features with a single mechanism - compile-time execution of regular zig code. This comes will all kinds of pros and cons, but one large and important pro is that I already know how to write regular code so it's easy for me to just write down the thing that I want to happen.</p>
<hr>
<p>One of the key differences between zig and rust is that when writing a generic function, rust will prove that the function is type-safe for every possible value of the generic parameters. Zig will prove that the function is type-safe only for each parameter that you actually call the function with.</p>
<p>On the one hand, this allows zig to make use of arbitrary compile-time logic where rust has to restrict itself to structured systems (traits etc) about which it can form general proofs. This in turn allows zig a great deal of expressive power and also massively simplifies the language.</p>
<p>On the other hand, we can't type-check zig libraries which contain generics. We can only type-check specific uses of those libraries.</p>
<pre><span>// This function is typesafe if there exist no odd perfect numbers
// https://en.wikipedia.org/wiki/Perfect_number#Odd_perfect_numbers
fn foo(comptime n: comptime_int, i: usize) usize {
  const j = if (comptime is_odd_perfect_number(n)) "surprise!" else 1;
  return i + j;
}
</span></pre>
<p>This means zig also doesn't get the automatic, machine-checked documentation of type constraints that rust benefits from and may face more challenges providing IDE support.</p>
<p>This might harm the zig ecosystem by making it harder to compose various libraries. But <a href="https://julialang.org/">julia</a> has a similar model and in practice it has worked very well (<a href="https://youtu.be/dmWQtI3DFFo?t=1710">eg</a>, <a href="https://www.oxinabox.net/2020/02/09/whycompositionaljulia.html">eg</a>).</p>
<hr>
<p>Zig's comptime allows expressing <a href="https://scattered-thoughts.net/writing/open-multiple-dispatch-in-zig/">open multiple dispatch</a> as a library.</p>
<p>It should be relatively trivial to implement specialization the same way, which has been a <a href="https://github.com/rust-lang/rust/issues/31844">work in progress</a> in rust for years and is critical to many optimizations in julia's math libraries.</p>
<p>Julia chose dynamic typing because it's very difficult to encode the types of various mathematical operations into a general schema (eg fortress <a href="https://youtu.be/EZD3Scuv02g?t=3011">struggled with this</a>). Zig's approach of not requiring general schemas but still type-checking individual cases may be an interesting sweet spot.</p>
<hr>
<p>I used the <a href="https://cwe.mitre.org/data/definitions/1350.html">2020 CWE Top 25 Most Dangerous Software Weaknesses</a> to get a sense of the relative frequency of different causes of memory unsafety.</p>
<p>(I'm assuming that the zig programmer is using release-safe mode instead of the unfortunately named release-fast mode which disables all runtime safety checks.)</p>
<ul>
<li>Out-of-bounds Write (787/1350)</li>
<li>Out-of-bounds Read (125/1350)</li>
<li>Improper Restriction of Operations within the Bounds of a Memory Buffer (119/1350)</li>
</ul>
<p>Both languages primarily use bounds-checked slices and relegate pointer arithmetic to a separate type (<code>*T</code> in rust, <code>[*]T</code> in zig).</p>
<ul>
<li>NULL Pointer Dereference (476/1350)</li>
</ul>
<p>Both languages require explicit annotations for nulls (<code>Option&lt;T&gt;</code> in rust, <code>?T</code> in zig) and require code to either handle the null case or safely crash on null (<code>x.unwrap()</code> in rust, <code>x.?</code> in zig).</p>
<p>Dereferencing/casting a null c pointer is undefined behavior in both languages, but is checked at runtime in zig.</p>
<ul>
<li>Integer Overflow or Wraparound (190/1350)</li>
</ul>
<p>Rust catches overflow in debug and wraps in release. Zig catches overflow in debug/release-safe and leaves behavior undefined in release-fast.</p>
<p>Both languages allow explicitly asking for wraparound (<code>x.wrapping_add(1)</code> in rust, <code>x +% 1</code> in zig).</p>
<ul>
<li>Use After Free (416/1350)</li>
</ul>
<p>As long as all unsafe code obeys the aliasing and lifetime rules, rust protects completely against UAF.</p>
<p>Zig has little protection. The recently merged
<a href="https://github.com/ziglang/zig/blob/575fbd5e3592cff70cbfc5153884d919e6bed89f/lib/std/heap/general_purpose_allocator.zig">GeneralPurposeAllocator</a> avoids reusing memory regions (which prevents freed data from being overwritten) and reusing pages (which means that UAF will eventually result in a page fault). But this comes at the cost of fragmentation and lower performance and it also won't provide protection for child allocators using the GPA as a backing allocator.</p>
<hr>
<p>Both languages will insert implicit casts between primitive types and pointers whenever it is safe to do so, and require explicit casts otherwise. (With the odd exception that rust will not implicitly upcast numbers).</p>
<p>Both languages support generics which almost entirely avoids the need to cast void pointers.</p>
<hr>
<p>In rust the Send/Sync traits flag types which are safe to move/share across threads. In the absence of unsafe code it should be impossible to cause data races.</p>
<p>Zig has no comparable protection. It's possible to implement the same logic as Send/Sync in comptime zig, but without the ability to track ownership the rules would have to be much more restrictive.</p>
<hr>
<p>Rust prevents having multiple mutable references to the same memory region at the same time.</p>
<p>This means that eg iterator invalidation is prevented at compile time, because the borrow checker won't allow mutating a data-structure while an iterator is holding a reference to the data-structure. Similarly for resizing a data-structure while holding a reference to the old allocation. Both examples are easy sources of UAF in zig.</p>
<hr>
<p>Neither language is able to produce stack traces for stack overflows at the moment (<a href="https://github.com/rust-lang/rust/issues/51405">rust</a>, <a href="https://github.com/ziglang/zig/issues/1616">zig</a>)</p>
<p>In the future zig is <a href="https://github.com/ziglang/zig/issues/1006">intended</a> to statically check the maximum stack usage of your program and force recursive code to explicitly allocate space on the heap, so that stack overflows produce a recoverable OutOfMemory error rather than a crash.</p>
<p>This is not an academic problem - I've seen real-world crashes from recursive tree transformations in compilers (<a href="https://github.com/MaterializeInc/materialize/pull/3996">eg</a>) and it's often painful to write the same logic without recursion.</p>
<hr>
<p>Undefined behavior in rust is defined <a href="https://doc.rust-lang.org/nomicon/what-unsafe-does.html">here</a>. It's worth noting that breaking the aliasing rules in unsafe rust can cause undefined behavior but these rules are not yet well-defined. So far this hasn't caused me any problems but it is a little unnerving.</p>
<p><a href="https://github.com/rust-lang/miri">Miri</a> is an interpreter for rusts Mid-level Intermediate Representation which will detect many (but not all) cases of undefined behavior in unsafe rust. It's far too slow to use for the whole materialize test suite but was useful for unit-testing an unsafe module.</p>
<p>Undefined behavior in zig is defined <a href="https://ziglang.org/documentation/master/#Undefined-Behavior">here</a>. This list is <a href="https://github.com/ziglang/zig/issues/1966">probably incomplete</a> given that the core language is still under development.</p>
<p>Zig <a href="https://github.com/ziglang/zig/issues/2301">aspires</a> to insert runtime checks for almost all undefined behavior when compiling in debug mode. So far all the easy cases are handled, which is already a dramatic improvement over c.</p>
<p>Zigs compile-time partial evaluation is done by an IR interpreter - it seems plausible that this could also be used as a miri-like tool in the future.</p>
<hr>
<p><code>@import</code> takes a path to a file and turns the whole file into a struct. So modules are just structs. And vice-versa - if you have a large struct declaration you can move it into a file to reduce the indentation.</p>
<p>Zig doesn't care at all where you put files on the filesystem.</p>
<p><code>@import</code> is part of the compile-time execution system so things like platform-specific modules and configurable features can be specified in regular code rather than rust's limited set of <code>#[cfg(...)]</code> macros.</p>
<hr>
<p>Array, struct, enum and union literals can be anonymous - <code>.{.Constant = 1.0}</code> is an anonymous union with it's own type, but can be implicitly cast to any union with a <code>Constant: f64</code> field because they share the same structure.</p>
<p>In rust my code is littered with <code>use Expr::*</code> and I'm careful to avoid name collisions between different enums that I might want to import in the same functions. In zig I just use anonymous literals everywhere and don't worry about it.</p>
<hr>
<p>Anonymous literals are also nice when using structs to simulate keyword arguments. No need to find and import the correct type:</p>
<pre><span>fn do_things(config: struct {
  max_things: usize = 1000, // default value
  flavor: Flavor,
}) void {
  ...
}

do_things(.{.flavor = .Strawberry});
</span></pre>
<hr>
<p>There is a pattern that shows up a lot in the materialize codebase:</p>
<pre><span>let</span><span> constant </span><span>= </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(constant) </span><span>=</span><span> expr { constant } </span><span>else </span><span>{ </span><span>panic!</span><span>() }</span><span>;
</span></pre>
<p>It's common enough that many types have methods like <code>expr.unwrap_constant()</code>.</p>
<p>In zig:</p>
<pre><span>const constant = expr.Constant;
</span></pre>
<p>A similar pattern is:</p>
<pre><span>if</span><span> some_condition {
    </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(</span><span>_</span><span>) </span><span>=</span><span> expr {
        </span><span>...
    </span><span>}
}
</span></pre>
<p>Again, many types get methods like <code>expr.is_constant()</code>.</p>
<pre><span>if</span><span> some_condition </span><span>&amp;&amp;</span><span> expr</span><span>.</span><span>is_constant</span><span>(…</span></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</a></em></p>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835357</guid>
            <pubDate>Tue, 20 Oct 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Design Stripe or Hacker News-like favicons in seconds]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24835219">thread link</a>) | @hosshams
<br/>
October 20, 2020 | https://formito.com/tools/favicon | <a href="https://web.archive.org/web/*/https://formito.com/tools/favicon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Copy the following code and put it inside the<!-- --> <code>&lt;head&gt;</code> tag of your website.</p><pre><code></code></pre><p>Or, download the SVG file, add the following code to<!-- --> <code>&lt;head&gt;</code> tag of your website, and replace<!-- --> <code>href</code> attribute with URL to your SVG file.</p><pre><code>&lt;link rel="icon" type="image/svg+xml" href="favicon.svg" /&gt;</code></pre></div></div>]]>
            </description>
            <link>https://formito.com/tools/favicon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835219</guid>
            <pubDate>Tue, 20 Oct 2020 08:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discipline Doesn’t Scale]]>
            </title>
            <description>
<![CDATA[
Score 309 | Comments 167 (<a href="https://news.ycombinator.com/item?id=24834965">thread link</a>) | @ingve
<br/>
October 20, 2020 | https://www.sicpers.info/2020/10/discipline-doesnt-scale/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/10/discipline-doesnt-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>If programmers were just more disciplined, more <em>professional</em>, they’d write better software. All they need is a <a href="https://www.pearson.com/us/higher-education/program/Martin-Clean-Coder-The-A-Code-of-Conduct-for-Professional-Programmers/PGM8366.html">code of conduct</a> telling them how to work like those of us who’ve worked it out.</p>
<p>The above statement is true, which is a good thing for those of us interested in improving the state of software and in helping our fellow professionals to improve their craft. However, it’s also very difficult and inefficient to apply, in addition to being entirely unnecessary. In the common parlance of our industry, “discipline doesn’t scale”.</p>
<p>Consider the trajectory of object lifecycle management in the Objective-C programming language, particularly the NeXT dialect. Between 1989 and 1995, the dominant way to deal with the lifecycle of objects was to use the <tt>+new</tt> and <tt>-free</tt> methods, which work much like <tt>malloc/free</tt> in C or <tt>new/delete</tt> in C++. Of course it’s <em>possible</em> to design a complex object graph using this ownership model, it just needs discipline, that’s all. Learn the heuristics that the experts use, and the techniques to ensure correctness, and get it correct.</p>
<p>But you know what’s better? Not having to get that right. So around 1994 people introduced new tools to do it an easier way: reference counting. With NeXTSTEP Mach Kit’s <tt>NXReference</tt> protocol and OpenStep’s <tt>NSObject</tt>, developers no longer need to know when <em>everybody</em> in an app is done with an object to destroy it. They can indicate when a reference is taken and when it’s relinquished, and the object itself will see when it’s no longer used and free itself. Learn the heuristics and techniques around auto releasing and unretained references, and get it correct.</p>
<p>But you know what’s better? Not having to get that right. So a couple of other tools were introduced, so close together that they were probably developed in parallel[*]: Objective-C 2.0 garbage collection (2006) and Automatic Reference Counting (2008). ARC “won” in popular adoption so let’s focus there: developers no longer need to know exactly when to retain, release, or autorelease objects. Instead of describing the edges of the relationships, they describe the <em>meanings</em> of the relationships and the compiler will automatically take care of ownership tracking. Learn the heuristics and techniques around weak references and the “weak self” dance, and get it correct.</p>
<p>[*] I’m ignoring here the significantly earlier integration of the Boehm conservative GC with Objective-C, because so did everybody else. That in itself is an important part of the technology adoption story.</p>
<p>But you know what’s better? You get the idea. You see similar things happen in other contexts: for example C++’s move from <tt>new/delete</tt> to smart pointers follows a similar trajectory over a similar time. The reliance on an entire programming community getting some difficult rules right, when faced with the alternative of using different technology <em>on the same computer</em> that follows the rules for you, is a tough sell.</p>
<p>It seems so simple: computers exist to automate repetitive information-processing tasks. Requiring programmers who have access to computers to recall and follow repetitive information processes is wasteful, when the computer can do that. So give those tasks to the computers.</p>
<p>And yet, for some people the problem with software isn’t a lack of automation but a lack of discipline. Software would be better if only people knew the rules, honoured them, and slowed themselves down so that instead of cutting corners they just chose to ignore important business milestones instead. Back in my day, everybody knew “no Markdown around town” and “don’t code in an IDE after Labour Day”, but now the kids do whatever they want. The motivations seem different, and I’d like to sort them out.</p>
<p>Let’s start with hazing. A lot of the software industry suffers from “I had to go through this, you should too”. Look at software engineering interviews, for example. I’m not sure whether anybody actually believes “I had to deal with carefully ensuring NUL-termination to avoid buffer overrun errors so you should too”, but I do occasionally still hear people telling less-experienced developers that they should learn C to learn more about how their computer works. <a href="https://queue.acm.org/detail.cfm?id=3212479">Your computer is not a fast PDP-11</a>, all you will learn is how the C virtual machine works.</p>
<p>Just as Real Men Don’t Eat Quiche, so <a href="https://www.codeproject.com/articles/927/real-programmers-don-t-use-pascal">real programmers don’t use Pascal</a>. Real Programmers use FORTRAN. This motivation for sorting discipline from rabble is based on the idea that if it isn’t at least as hard as it was when <em>I</em> did this, it isn’t hard enough. And that means that the goalposts are movable, based on the orator’s experience.</p>
<p>This is often related to the <em>term</em> of their experience: you don’t need TypeScript to write good React Native code, just Javascript and some discipline. You don’t need React Native to write good front-end code, just JQuery and some discipline. You don’t need JQuery…</p>
<p>But along with the term of experience goes the breadth. You see, the person who learned reference counting in 1995 and thinks that you can only <em>really</em> understand programming if you manually type out your own reference-changing events, presumably didn’t go on to use garbage collection in Java in 1996. The person who thinks you can only <em>really</em> write correct software if every case is accompanied by a unit test presumably didn’t learn Eiffel. The person who thinks that you can only <em>really</em> design systems if you use the Haskell type system may not have tried OCaml. And so on.</p>
<p>The conclusion is that for this variety of disciplinarian, the appropriate character and quantity of discipline is whatever they had to deal with at some specific point in their career. Probably a high point: after they’d got over the tricky bits and got productive, and after you kids came along and ruined everything.</p>
<p>Sometimes the reason for suggesting the disciplined approach is entomological in nature, as in the case of the eusocial insect the “performant” which, while not a real word, exists in greater quantities in older software than in newer software, apparently. The performant is capable of making software faster, or use less memory, or more concurrent, or less dependent on I/O: the specific characteristics of the performant depend heavily on context.</p>
<p>The performant is often not talked about in the same sentences as its usual companion species, the irrelevant. Yes, there may be opportunities to shave a few percent off the runtime of that algorithm by switching from the automatic tool to the manual, disciplined approach, but does that matter (yet, or at all)? There are software-construction domains where specific performance characteristics are desirable, indeed that’s true across a lot of software. But it’s typical to focus performance-enhancing techniques on the bits where they enhance performance that needs enhancing, not to adopt them across the whole system on the basis that it was better when everyone worked this way. You might save a few hundred cycles writing native software instead of using a VM for that UI method, but if it’s going to run after a network request completes over EDGE then trigger a 1/3s animation, nobody will notice the improvement.</p>
<p>Anyway, whatever the source, the problem with calls for discipline is that there’s no strong motivation to <em>become</em> more disciplined. I can use these tools, and my customer is this much satisfied, and my employer pays me this much. Or I can learn from you how I’m <em>supposed</em> to be doing it, which will slow me down, for…your satisfaction? So you know I’m doing it the way it’s supposed to be done? Or so that I can tell everyone else that they’re doing it wrong, too? Sounds like a great deal.</p>
<p>Therefore discipline doesn’t scale. Whenever you ask some people to slow down and think harder about what they’re doing, some fraction of them will. Some will wonder whether there’s some other way to get what you’re peddling, and may find it. Some more will not pay any attention. The dangerous ones are the ones who thought they <em>were</em> paying attention and yet still end up not doing the disciplined thing you asked for: they either torpedo your whole idea or turn it into not doing the thing (see OOP, Agile, Functional Programming). And still more people, by far the vast majority, just weren’t listening at all, and you’ll never reach them.</p>
<p>Let’s flip this around. Let’s look at where we <em>need</em> to be disciplined, and ask if there are gaps in the tool support for software engineers. Some people want us to always write a failing test and make it pass before adding any code (or want us to write a passing test and revert our changes if it accidentally fails): does that mean our tools should not let us write code for which there’s no test? Does the same apply for acceptance tests? Some want us to refactor mercilessly; does that mean our design tools should always propose more parsimonious alternatives for passing the same tests? Some say we should get into the discipline of writing code that always reveals its intent: should the tools make a crack at interpreting the intention of the code-as-prose?</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/10/discipline-doesnt-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834965</guid>
            <pubDate>Tue, 20 Oct 2020 08:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choose the Browser Carefully]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24834960">thread link</a>) | @URfejk
<br/>
October 20, 2020 | https://unixsheikh.com/articles/choose-your-browser-carefully.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/choose-your-browser-carefully.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Published on <span id="published">2020-10-20</span>. Updated on <span id="modified">2020-10-24</span></p>

<p><a href="https://en.wikipedia.org/wiki/Internet_privacy">Privacy on the Internet</a> is important because privacy risks range from the gathering of statistics on users to more malicious acts such as the spreading of spyware and the exploitation of various forms of bugs (software faults). Many companies, such as Google, track which websites people visit and then use the information, for instance by sending advertising based on one's web browsing history. Sometimes prices on products are changed on the same website, depending on tracking information, and two people may view the exact same product on the exact same website yet be presented with very different prices.</p>

<h3>Table of contents</h3>
<ul>
<li><a href="#privacy-compromising">Introduction</a></li>
<li><a href="#third-party-clones">Third party clones</a></li>
<li><a href="#privacy-compromising">Privacy compromising browsers</a></li>
<ul>
<li><a href="#firefox">Mozilla Firefox</a></li>
<li><a href="#chrome">Google Chrome and Chromium</a></li>
<li><a href="#brave">Brave</a></li>
<li><a href="#palemoon">Palemoon</a></li>
<li><a href="#waterfox">Waterfox</a></li>
<li><a href="#librewolf">Librewolf</a></li>
<li><a href="#epiphany">GNOME Web (Epiphany) and Eolie</a></li>
<li><a href="#midori">Midori</a></li>
<li><a href="#other-problematic-browsers">Other problematic browsers</a></li>
</ul>

<li><a href="#alternatives">Privacy respecting browsers</a></li>
<ul>
<li><a href="#tweaking-firefox">Tweaking Firefox - the best solution</a>
<ul>
<li><a href="#control">Controlling Firefox's DNS over HTTPS</a></li>
<li><a href="#blocking">Blocking DoH via a firewall</a></li>
</ul>
</li><li><a href="#falkon">Falkon</a></li>
<li><a href="#icecat">GNU IceCat</a></li>
<li><a href="#ungoogled-chromium">ungoogled-chromium</a></li>
<li><a href="#tor">Tor browser</a></li>
<li><a href="#other-okay-browsers">Other okay browsers</a></li>
</ul>
<li><a href="#recommended-extensions">Recommended extensions</a></li>
<ul>
<li><a href="#noscript">NoScript</a></li>
<li><a href="#ublock-origin">uBlock Origin</a></li>
<li><a href="#https-everywhere">HTTPS Everywhere</a></li>
</ul>
<li><a href="#conclusions">Conclusions</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>This article isn't specifically about privacy issues only, it's about promises that are being broken, which might be about privacy. It is also about the lack of user freedom, as in the choice to enable or disable features, such as automatic updates, or forced usage of third party services, or software that the user generally is unaware of or don't have a say about.</p>

<p>Privacy as a subject regarding the usage of services on the Internet is a very difficult subject to deal with. Not only can it be difficult to actually define privacy, but it also requires a balance between freedom of choice by the users, security and usability. Naturally you need to be able to use the browser on the Internet and as such you will always leave some kind of trail behind, and this article is not about how you can hide your tracks. What I am addressing in this article are browsers that are either promoted as "privacy respecting" by the developers, or in general are considered to be so (mostly due to misunderstanding or misinformation), while it is very clear they are not.</p>

<p>Some browsers either directly violate users by collecting telemetric data without consent, or you have to opt-out rather than opt-in, or they bounce around the Internet visiting places in the background without you knowing (using dns-prefetch or automatic updates etc.), using third party services that operates with a privacy policy you either cannot trust, or that are directly violating your privacy, or they have integrated third party software that do some of these things.</p>

<p>I will try to keep this article updated with relevant information as much as possible. I know several other browsers exist, but if they are not mentioned on this list I have either not had a change to investigate them, they are closed source and completely irrelevant (such as Microsoft Edge or Opera), or they are not actively maintained, or they are perhaps a "one mans show" which cannot be trusted for some reason or another.</p>

<p>I will also <strong>not</strong> be looking at browsers that only work on Microsoft Windows or macOS, even if they are Open Source. Both Microsoft Windows and macOS are highly controversial and completely untrustworthy operating systems.</p>

<p>Also please note that just because the developers of a browser are promising that their browser is privacy respecting doesn't mean that you can trust the information. As you will see with the examples of some of the browsers below even developers some times compromise user privacy perhaps without even thinking about it.</p>

<p>I also want to make a strong advice to people recommending browsers to other people without investigation or knowledge. The <a href="https://old.reddit.com/r/privacy/">privacy related channel on Reddit</a> is filled with wrong recommendations regarding privacy respecting browsers and many people are merely guessing or blindly trusting the information the browser producers are publishing. Neither Mozilla Firefox, Google Chrome or Chromium, Brave, Waterfox, or several of the other recommended browsers truly respect privacy. They all do some form of telemetry and/or privacy compromising actions without the user consenting to it or even knowing about it.</p>

<p>Also, privacy doesn't mean that you simply pull out telemetry from Firefox, rebrand it, and then ship it. Privacy is more than that. Unless the browser is automatically checking for an updated version, and the website isn't logging that request, it cannot be considered truly private if the browser starts bouncing around on the Internet visiting all kinds of places without the user has done anything more than open the browser up! Every time the browser makes a DNS request, that DNS request is in most cases logged unless the user actively does something to mitigate that - such as using a trusted VPN or non-logging DNS service etc. Furthermore, the Mozilla add-on CDN is logging user activity, as is <a href="https://en.wikipedia.org/wiki/Amazon_CloudFront">Amazon Cloudfront</a>, so if the browser visits these places without the user explicitly pushes a "check for updates" option, the browser is compromising user privacy. The point I'm trying to make is that the user needs to have the choice and that nothing happens until the user actively do something.</p>

<p>Last, but not least, if you discover any mistakes on my part, feel free to email me about it so that I can correct the information.</p>

<h2 id="third-party-clones">Third party clones</h2>
<p>Several third party clones of Firefox and Chromium exist that are branded and promoted as secure and privacy respecting alternatives that cannot fully be trusted for some reason or another. The code base for both Firefox and Chromium are huge and many skillful people work on the code every day. Having a "one mans show" or a small team of developers diverted browser clone running on your computer that are days, weeks or even months behind security updates does not improve neither your privacy nor your security in any way.</p>

<h2 id="privacy-compromising">Privacy compromising browsers</h2>

<h3 id="firefox">Mozilla Firefox</h3>
<p>In the past I have always supported Mozilla and promoted <a href="https://en.wikipedia.org/wiki/Firefox">Firefox</a>, but Mozilla has made some pretty controversial decisions as of late and I no longer feel that Mozilla is an organization that deserves any support.</p>
<p>Firefox is promoted by Mozilla as a privacy respecting browser, but this is highly misleading. Firefox "phones home" every time you start it up even when you have disabled telemetry and automatic updates of extensions. Domains such as mozilla.org, cloudfront.net, firefox.settings.services.mozilla.com (see: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12">https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12</a>), autopush.prod.mozaws.net, detectportal.firefox.com and location.services.mozilla.com are visited each time you start Firefox.</p>
<p>In 2017 Mozilla made a <a href="https://en.wikipedia.org/wiki/Cliqz#Integration_with_Firefox">deal with Cliqz</a> where approximately 1% of users downloading Firefox in Germany would receive a version with Cliqz software included. And in 2018 Mozilla revealed that they had no data on the number of Firefox installations with disabled Telemetry.</p>
<blockquote>
<p>Finally, we need better insight into our opt-out rates for telemetry. We use telemetry to ensure new features improve your user experience and to guide Mozilla's business decisions. However, an unknown portion of our users do not report telemetry for a variety of reasons. This means we may not have data that is representative of our entire population.</p>
</blockquote>
<p>Mozilla then developed the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1487578">Telemetry Coverage</a> system and distributed it to 1% of the Firefox installations. The system is automatically installed and designed to inform Mozilla whether telemetry is enabled in the browser.</p>
<p>Mozilla also <a href="https://support.mozilla.org/en-US/kb/telemetry-collection-windows-default-browser-trend">developed a Windows-only scheduled task</a> which runs in the background once a day for each installation of Firefox installed on a computer running Microsoft Windows. The task collects information related to the system's current and previous default browser setting and the operating system locale and version.</p>
<p>This is a list of some of the things that Mozilla collects: <a href="https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content">https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content</a>.</p>
<p>On the <a href="https://www.mozilla.org/en-US/about/">Mozilla website</a> we can read (when I originally started writing this article) that <q>We put people over profit</q>, and <q>a product to support user privacy</q>. We can also read in the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla manifesto</a>, in the fourth principle, that <q>Individuals' security and privacy on the internet are fundamental and must not be treated as optional.</q> However, with their decision to make Cloudflare the default DNS provider for DNS over HTTPS, they are definitely not supporting user privacy or putting people over profit!</p>
<p>DNS over HTTPS is by itself <a href="https://www.youtube.com/watch?v=ZxTdEEuyxHU">bad enough</a>, and <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS#Criticism">highly criticized</a> with good reason, but combining it with a US based company like Cloudflare makes it even worse.</p>
<p>Cloudflare has made an <a href="https://developers.cloudflare.com/1.1.1.1/commitment-to-privacy/privacy-policy/firefox/">agreement</a> with Mozilla that when it acts as a DNS resolver for Firefox, that:</p>
<ul>
<li>DNS requests will be stored as part of Cloudflare's "temporary" logs which are permanently deleted within 24 hours.</li>
<li>Cloudflare will also collect and store the following information as part of its permanent logs:
<ul>
<li>Total number of requests processed by each Cloudflare co-location facility.</li>
<li>Aggregate list of all domain names requested.</li>
<li>Samples of domain names queried along with the times of such queries.</li>
</ul>
</li>
<li>Information stored in Cloudflare's permanent logs will be anonymized and may be held indefinitely by Cloudflare for its own internal research and development purposes.</li>
</ul>
<p>Anyone who has worked with DNS servers knows what goes into such logs and in order for Cloudflare to keep their promise they need to: Delete the DNS requests information, but at the same time somehow still keep "anonymized" logs of the total number of requests, a list of all domain names requested, a so-called "sample" of complete DNS queries along with date and time.</p>
<p>This means that even if Cloudflare could be trusted and they have the best of intentions, they will still log everything the first 24 hours. If Cloudflare is ever compromised all these logs could be copied and distributed over a period of time.</p>
<p>Furthermore, the actual …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unixsheikh.com/articles/choose-your-browser-carefully.html">https://unixsheikh.com/articles/choose-your-browser-carefully.html</a></em></p>]]>
            </description>
            <link>https://unixsheikh.com/articles/choose-your-browser-carefully.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834960</guid>
            <pubDate>Tue, 20 Oct 2020 08:10:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Long Road to HTTP/3]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24834767">thread link</a>) | @todsacerdoti
<br/>
October 20, 2020 | https://scorpil.com/post/the-long-road-to-http3/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/the-long-road-to-http3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>While HTTP/3 specification is still in the draft stage, the latest version of the Chrome browser already <a href="https://blog.chromium.org/2020/10/chrome-is-deploying-http3-and-ietf-quic.html" target="_blank" rel="nofollow">supports it by default</a>
. With Chrome holding around 70% of browser market share, you could say HTTP/3 has gone mainstream.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/quic-logo.png" alt="QUIC logo"></p><p>The new revision of this foundational protocol aims to make the web more efficient, secure, and shorten the content-delivery latencies. In some ways, it’s a braver take of HTTP2: similar goals addressed by replacing the underlying TCP protocol with a new, purpose-built protocol QUIC. The best way to explain the benefits of QUIC is to illustrate where TCP falls short as a transport for HTTP requests. And to do that, we’ll start at the very beginning.</p><h3 id="http-the-original">HTTP. The Original.</h3><p>When Sir Tim Berners-Lee formalized the design of a simple <a href="https://www.w3.org/Protocols/HTTP/AsImplemented.html" target="_blank" rel="nofollow">one-line hyper-text-exchange protocol</a>
in 1991, TCP was already an old, reliable protocol. The original definition document of what later became known as HTTP 0.9 specifically mentions TCP as a preferred, albeit not exclusive, transport protocol:</p><blockquote><p>Note: HTTP currently runs over TCP, but could run over any connection-oriented service.</p></blockquote><p>Of course, this proof-of-concept version of HTTP had very few similarities to HTTP we now know and love today. There were no headers and no status codes. The typical request was as simple as <code>GET /path</code>. The response contained only HTML and ended with the closing of the TCP connection.
Since browsers were not yet a thing, user was supposed to read HTML directly. It was possible to link to other resources, but none of the tags present in this early version of HTML requested additional resources asynchronously. A single HTTP request delivered a complete, self-sufficient page.</p><h3 id="emergence-of-http10">Emergence of HTTP/1.0</h3><p>In subsequent years the internet has exploded, and HTTP evolved to be an extendable and flexible general-purpose protocol, although transporting HTML remained its chief specialty. There are three critical updates to HTTP that enabled this evolution:</p><ul><li>introduction of methods allowed the client to identify the type of action it wants to perform. For example, POST was created to allow client sending data to the server to process and store</li><li>status codes provided a way for client to confirm that the server has processed the request successfully, and if not - to understand what kind of error has occured</li><li>headers added an ability to attach structured textual metadata to requests and responses that could modify the behavior of the client or server. Encoding and content-type headers, for example, allowed HTTP to transfer not just HTML, but any type of payload. “Compression” header allowed the client and server to negotiate supported compression formats, thus reducing the amount of data to transfer over the connection</li></ul><p>At the same time, HTML advanced to support images, styles, and other linked resources. Browsers were now forced to perfrom multiple requests to display a single web page, which the original connection-per-request architecture was not designed to handle. Establishing and ending a TCP connection involves a lot of back-and-forth packet exchange, so it is relatively expensive in terms of latency overhead. It didn’t matter much when a web-page consisted of a single text file, but as the number of requests per page increased, so did the latency.</p><p>The picture below illustrates how much overhead was involved in establishing a new TCP connection per request.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http1-tcp-overhead.png" alt="TCP connection requires three requests to establish connection and four to close it cleanly"></p><p>A “connection” header was created to address this problem. Client sends a request with “connection: keep-alive” header to signal intent to keep the TCP connection open for subsequent requests. If server understands this header and agrees to respect it, its response will also contain the “connection: keep-alive” header. This way, both parties maintain TCP channel open and use it for subsequent communication until either party decides to close it. This became even more important with the spread of SSL/TLS encryption, because negotianting an encryption algorithm and exchanging cryptographic keys requires an additional request/response cycle on each connection.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http1-keepalive.png" alt="A single TCP connection can be reused for multiple requests with “connection: keep-alive” header"></p><p>At the time, many of the HTTP improvements appeared spontaneously. When a popular browser or a server app saw a need for a new HTTP feature, they would simply implement it themselves and hoped that other parties would follow the suit. Ironically, a decentralized web needed a centralized governing body to avoid fragmentation into incompatible pieces. Tim Berners-Lee, the original creator of the protocol, recognized the danger and founded the World Wide Web Consortium (W3C) in 1994, which together with the Internet Engineering Task Force (IETF) worked on formalizing stack of internet technologies. As the initial step to bring more structure to the existing environment, they documented the most common features used in HTTP at the time and named the resulting protocol HTTP/1.0. However, because this “specification” described varied, often inconsistent techniques as seen “in the wild”, it never received a status of a standard. Instead, the work on the new version of the HTTP protocol has begun.</p><h3 id="standardization-of-http11">Standardization of HTTP/1.1</h3><p>HTTP/1.1 fixed inconsistencies of HTTP/1.0 and adjusted the protocol to be more performant in the new web ecosystem. Two of the most critical changes introduced were the use of persistent TCP connections (keep-alive’s) by default and HTTP pipelining.</p><p>HTTP pipelining simply means that client does not need to wait for the server to respond to a request before sending subsequent HTTP requests. This feature resulted in even more efficient use of bandwidth and reduced latencies, but it could be improved even more. HTTP pipelining still requires from server to respond in the order of requests received, so if a single request in a pipeline is slow to fulfill, all subsequent responses to a client will be delayed accordingly. This problem is known as head-of-the-line blocking.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http11-blocking.png" alt="Since large-picture.jpg was requested first, it’s blocking the delivery of the style.css"></p><p>At this point in time, the web is gaining more and more interactive capabilities. Web 2.0 is just around the corner, some webpages include dozens or even hundreds of external resources. To work around the head-of-the-line blocking, and to decrease page loading speeds, clients establish multiple TCP connections per host. Of course, the connection overhead never went anywhere. In reality, it got worse, since more and more applications encrypt HTTP traffic with SSL/TLS. So most browsers set the limit of maximal possible simultaneous connections in an attempt to strike a delicate balance.</p><p>Many of the larger web-services have recognized that existing limitations are too restricting for their exceptionally heavy interactive web-applications, so they “gamed the system” by distributing their app through multiple domain names. It all worked, somehow, but the solution has been far from elegant.</p><p>Despite a few shortcomings, the simplicity of HTTP/1.0 and HTTP/1.1 has made them widely successful, and for over a decade no one has made a serious attempt to change them.</p><h3 id="spdy-and-http2">SPDY and HTTP/2</h3><p>In 2008 Google released the Chrome browser, which rapidly gained popularity for being quick and innovative. It has given Google a strong vote on matters of internet technologies. In the early 2010s, Google adds support for its web protocol SPDY to Chrome.</p><p>HTTP/2 standard was based on SPDY with some improvements. HTTP/2 solved the head-of-the-line blocking problem by multiplexing the HTTP requests over a single open TCP connection. This allowed server to answer requests in any order, client could then re-assemble the responses as it received them, making the whole exchange faster within a single connection.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http2-multiplexing.png" alt="style.css was returned before the large-picture.jpg, becuase of HTTP/2 multiplexing"></p><p>In fact, with HTTP/2 server can serve the resources to a client before it even asked for it! To give an example, if the server knows that client will most likely need a stylesheet to display an HTML page, it can “push” the CSS to the client without waiting for a corresponding request. While beneficial in theory, this feature rarely seen in practice, since it requires a server to understand the structure of the HTML it serves, which is rarely the case.</p><p>HTTP/2 also allows compressing request headers in addition to the request body, which further reduces the amount of data transferred over the wire.</p><p>HTTP/2 solved a lot of problems for the web, but not all of them. A similar type of head-of-the-line problem is still present on the level of TCP protocol, which remains a foundational building block of the web. When a TCP packet gets lost in transit, the receiver can’t acknowledge incoming packages until the lost package is re-sent by a server. Since TCP is by design oblivious to higher-level protocols like HTTP, a single lost packet will block the stream for all in-flight HTTP requests until the missing data is re-sent. This problem is especially prominent on an unreliable connection, which is not rare in the age of ubiquitous mobile devices.</p><h3 id="http3-revolution">HTTP/3 revolution</h3><p>Since issues with HTTP/2 can not be resolved purely on the application layer a new iteration of the protocol must update the transport layer. However, creating a new transport-layer protocol is not an easy task. Transport protocols need to be supported by hardware vendors and deployed by the majority of network operators, which are reluctant to update because of the costs and efforts involved. Take IPv6 as an example: it was introduced 24 years ago and is still far from being universally supported.</p><p>Fortunately, there is another option. UDP protocol is as widely supported as TCP but is simple enough to serve as a building block for custom protocols running on top of it. UDP packets are fire-and-forget: there are no handshakes, persistent connections, or error-correction. The primary idea behind HTTP3 is to abandon TCP in favor of a UDP-based QUIC protocol. QUIC adds the necessary features (those that were previously provided by TCP, and more) in a way that makes sense for the web environment.</p><p>Unlike HTTP2, which technically allowed an unencrypted communication, QUIC strictly requires encryption to establish a connection. Additionally, encryption is applied to all data …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scorpil.com/post/the-long-road-to-http3/">https://scorpil.com/post/the-long-road-to-http3/</a></em></p>]]>
            </description>
            <link>https://scorpil.com/post/the-long-road-to-http3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834767</guid>
            <pubDate>Tue, 20 Oct 2020 07:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adolphe Sax, Inventor of the Saxophone]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24834716">thread link</a>) | @bobf
<br/>
October 20, 2020 | http://www.dinant.be/en/inheritance/adolphe-sax | <a href="https://web.archive.org/web/*/http://www.dinant.be/en/inheritance/adolphe-sax">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody>
<tr>
<td>


<h2><span>Adolphe Sax, a Dinantais of genius</span></h2>
<blockquote>
<p>Along with Joachim Patenier (1485-1524), the creator of landscape painting; with Antoine Wiertz (1806-1865), the lyrical painter; with a plethora of sculptors, painters, musicians, brassworkers and others, Dinant can legitimately pride itself on having been the birthplace on 6 November 1814 of Antoine-Joseph, or Adolphe, Sax, a prolific and inspired inventor in the manufacture of musical instruments.</p>
<p>In 1860, the diarist, Oscar Comettant, wrote, "In the services that he has rendered to musical art, in the battles he has had to go through to bring his discoveries to the light of day and defend them from despoilment and in the rewards he has been the object of from all the industrial nations, [Sax's life] rises to the heights of a social event. Novelists will draw from this strange life mysterious and moving episodes (we would add: the legal world will find in the account of the "Sax trial" a vast domain for a case law study) and the moralists will find in it the features of self-denial, physical courage and perseverance, of which only a lifted soul and a great heart are capable.</p>
</blockquote>
<a name="Enfance"></a>
<h2><span>An Agitated Childhood</span></h2>

<blockquote>
<p>Antoine-Joseph Sax was born in the street that has borne his name since 1896, in a modest house, which was destroyed in 1914, and which was built on the present site of an important commercial building.</p>
<p>In its façade, there is a stained-glass window and an inscription chiselled into the stonework: "Adolphe Sax, 1814-1894, was born here". This window was solemnly inaugurated on 27 June 1954, on the initiative of the Tourist Information Centre, under the mayorship of Mr Léon Sasserath. It is the work of Mr Jean Jadin, who designed the cartoon, and Miss Maggy Arzée. Both were taught by Miss Yvonne Gérard and Mr Perot, teachers of graphic art and decoration at the Fine Arts Academy in Namur, which was then directed by Mr Lambeau. It was created under the direction of Mr Van de Capelle.</p>
<p>Son of Charles-Joseph Sax (1791-1865) and Marie-Joseph Masson (1813-1861), Antoine-Joseph was the eldest of eleven children (six boys and five girls, only four of whom survived, the others dying between the ages of 20 and 25).</p>
<p>His childhood was tragic. Hardly able to stand, Antoine-Joseph fell from a height of three floors, seriously bumping his head against a stone: he was believed dead. At the age of three, he swallowed a bowl of vitriolized water, and then a pin. Later, he was seriously burned in a gunpowder explosion; he fell onto a cast iron frying pan and burned himself on one side. Three times he escaped poisoning and asphyxiation in his bedroom, where varnished items were lying about during the night. Another time, he was hit on the head by a cobblestone; he fell into a river and was saved by the skin of his teeth.</p>
<p>"<em>He's a child condemned to misfortune; he won't live," his mother said. In the district, they called him "little Sax, the ghost</em>".</p>
<p>These initial serious incidents were, alas, but the prelude to an eventful existence such as only a few have known. In 1858, Adolphe Sax was miraculously saved from a cancer of the lip by a black doctor who knew the properties of certain Indian plants. What would the future have been but for this intervention?</p>
</blockquote>
<a name="Charles-Joseph"></a>
<h2><span>Charles-Joseph Sax</span></h2>

<blockquote>
<p>A joiner-cabinetmaker, Charles-Joseph Sax quickly launched himself, with success, into the manufacture of musical instruments. In the "New Street" he ran a large workshop. In this trade, he acquired such a reputation that, in 1815 (his eldest son was only one year old), he also set up a workshop in Brussels (where Antoine-Joseph's brothers and sisters were to be born), where he was summoned by William I of Orange (we were then under Dutch occupation). The latter appointed him as maker to the Court and entrusted him with the task of supplying suitable instruments to Belgium regimental music corps.</p>
<p>A self-taught man, therefore, Charles-Joseph Sax made woodwind and brass instruments, even violins and pianos. He registered a dozen patents and brought his instruments to perfection. He successfully participated in numerous exhibitions, where he was awarded flattering distinctions.</p>
<p>At the time when he could have spend the day playing, laughing and having fun, Antoine-Joseph observed the work in his father's workshop, besides being given instruction by one of his uncles, a teacher in Dinant. He was intelligent and his inventive mind was already showing itself, thanks to his love for music (whilst very young, he took singing and flute lessons). Thereafter, he was given lessons by his father, who quickly appreciated his abilities and did all he could to develop them.</p>
<p>Far from disregarding his son's aspirations, Charles-Joseph Sax made him his apprentice and, from a young age, he was conscious of the importance of his work, as though he were anticipating his destiny.</p>
<p>In 1853, after the death of seven of his eleven children, and following financial worries at his Brussels business, Charles-Joseph joined his son in Paris. The master was to become the servant, and was from then on in charge of making saxophones until his death in 1865.</p>
</blockquote>
<a name="Jeunesse"></a>
<h2><span>A productive childhood</span></h2>

<blockquote>
<p>Supported and assisted by his father, the youth worked. He created, he perfected instruments and he played them. He was 16 when he went to the Industrial Exposition in Brussels to present flutes and ivory clarinets. At the age of 20, he made an entirely new clarinet, with 24 keys, a work of imagination and a masterpiece of manual work. Then, a new bass clarinet, which incited enthusiasm in Habeneck, the leader of the orchestra at the Paris Opera House, who was passing through Brussels, and who called the other clarinets "barbarian instruments".</p>
<p>Even at that early stage, this creation provoked jealousy in the soloist at the "Great Royal Harmony" in Brussels, who refused to use it because, he said, it had come from "that weedy little pupil, Sax". "Play your clarinet, then" Sax answered, " and I shall play mine." The challenge accepted, Sax triumphed in front of four thousand people. He became a soloist. Works were written for him that, after his departure, were no longer played because they were so difficult!</p>
<p>The young genius pursued his work. He invented a sound reflector, a new double-bass clarinet, a piano-tuning process that remained the inventor's secret and who probably was unable to exploit it for want of money, a steam organ "capable of being heard throughout the province": now that just shows Sax's tendency to think big!</p>
<p>Sax's beginnings throw a very curious light on his character (we shall call him Adolphe from now on): energy, courage, dynamism, total self-confidence. He refused to go and set up a business in St Petersburg, rejected an offer to set up in London. That means that his reputation exceeded frontiers. Sax was conscious of all his possibilities and his talent; he conceived the work that he felt the call to achieve; he was full of hope and he believed he had every chance of success; he had great visions, he believed in what he saw. He suffocated in his little country.</p>
<p>In 1840, he presented nine inventions at the Belgian Exhibition. He was denied the first medal on the plea of his young age; there would be nothing left to offer him the year after. He was thwarted in his true-love, if not in his pride. He refused the vermeil medal he was awarded, replying with pride, "<em>If they think me too young to deserve the gold medal, I myself think me too old to accept this vermeil one</em>."</p>
</blockquote>
<a name="Paris"></a>
<h2><span>The Call to Paris</span></h2>

<blockquote>
<p>Europe's centre of attraction, Paris haunted him, Paris called him.</p>
<p>The composer Halévy wrote to him of the hope that composers had in his inventions: "<em>Hurry and finish your new family of instruments (saxophones) and come and succour to the poor composers that are looking for something new and to the public that is demanding it, if not to the world itself.</em>"</p>
<p>Let us add to this call and the snub in Brussels the fact of his family trials, and the decision was made: Adolphe Sax left for Paris "rich in ideas and light in cash": he had thirty francs in his pocket!</p>
<p>The year 1842 formed the turning point in Sax's life, possessing as he did his new invention: the saxophone and its family.</p>
<p><img src="http://www.dinant.be/uploads/pages/286/sax_atel.jpg" alt="">Moreover, in 1841, had he not presented it anonymously in Brussels, behind a curtain, so as not to disclose it and avoid the risk of plagiarism?</p>
<p>Adolphe Sax was almost thirty, "the age at which man's creative character affirms itself, at which the human personality is drawn." At the age of 27, Napoleon won his first battle in Italy; Newton was 24 and Einstein 26 when they devised their theories. Mozart died aged 35 and Schubert at 31. Examples of precocious geniuses are manifold.</p>
<p>As one former inhabitant of Dinant once rightfully said (1) "<em>a distinction has to be drawn here between a man who draws from his own abstract thoughts the stuff that his genius will knead, him for whom symbols and signs are sufficient to bring forth a thought laden with restrained life and latent splendours; and the other man for whom a technique, slow and tenacious apprenticeship on a complicated apparatus is necessary for him to be able to physically achieve the formal idea. Count, for example, how many early-developing mathematicians there are compared with child physicists. The former exist, the latter are nowhere to be found. Sax is of the category of intellectuals that concentrated on matter and not pure form"</em>.</p>
<p>In 1842, there was Adolphe Sax living in a simple shed in Rue Saint-Georges, Paris. To set up business, he had to borrow money from a musician acquaintance.</p>

</blockquote>
<a name="Berlioz"></a>
<h2><span>Thanks to Berlioz</span></h2>
<blockquote>
<div>
<p><span><strong>About the saxophone, he said "<em>Its principal merit in my view is the varied beauty of its accent, sometimes serious, sometimes calm, sometimes impassioned, dreamy or melancholic, or vague, like the weakened echo of an echo, like the indistinct plaintiff moans of the breeze in the woods and, even better, like the mysterious vibrations of a bell, long after it has been struck; there does not exist another musical instrument …</em></strong></span></p></div></blockquote></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dinant.be/en/inheritance/adolphe-sax">http://www.dinant.be/en/inheritance/adolphe-sax</a></em></p>]]>
            </description>
            <link>http://www.dinant.be/en/inheritance/adolphe-sax</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834716</guid>
            <pubDate>Tue, 20 Oct 2020 07:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My chatbot is dead – Why yours should probably be too]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 160 (<a href="https://news.ycombinator.com/item?id=24834552">thread link</a>) | @raphaelsaunier
<br/>
October 19, 2020 | https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/ | <a href="https://web.archive.org/web/*/https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                
<audio controls="controls"><source src="https://azumbrunnen.me/audio/chatbot-is-dead" type="audio/mpeg"></audio>



<p>Personal websites are usually like old books in a shelf. They languish, accumulate dust, and their wrinkles and cracks become more apparent over time. About 3 years ago I embarked on a simple experiment that would end up prolonging the shelf-life of my website by an unusually large margin.</p>



<p>Back in 2017, it seemed like Conversational UI was poised to take over the world. We saw Quartz turning news into a conversation, WeChat being featured as the poster-child of a post application world, iMessage turning into an unnecessarily complex mess, and chatbots popping up like mushrooms in moist forests.</p>



<p>Of course, any trend gaining so much traction and interest needs to be taken seriously. As such, I decided to familiarize myself with the topic, and turned my website into a chatbot.</p>



<p>Instead of being greeted by the internationally standardized greeting every designer used at some point in their career, there was no bold, dramatically oversized, and deep black sans-serif reading: <em>Hi, I’m a designer.</em> (To be fair, I didn’t use Proxima Nova either)</p>



<p>Instead, a couple of chat bubbles exuberantly ushered onto the canvas to greet users as if we had all been long time friends.</p>



<figure><video autoplay="" loop="" muted="" src="https://azumbrunnen.me/wp-content/uploads/chatbot-animated.mp4" playsinline=""></video><figcaption>Conversational intro</figcaption></figure>



<p>It was witty, new, and slightly awkward. People would send messages that ranged from simple chit chat, to deep philosophical topics, to downright disturbing and ridiculous insults.</p>



<p>The experiment got featured on Hackernews, Medium, was used in psychological studies conducted by Dan Ariely’s team, and the source code was ripped and edited by various startups to fit their needs. One business in the Bay Area had an idea to use it to sell flowers in a conversational way. It looks like they went out of business.</p>



<p>The reaction and feedback was surprising to say the least. It was an idea so simple, so silly, that the outcome was in many ways unexpected. After all, the only one who really cares about your website, is usually yourself.</p>



<p>That didn’t stop me from revamping my website and kill the very thing that had turned it into a micro-celebrity before. With the death of my old chatbot, some angry emails by schools who are using it as a reference for “creative” web design, and a good amount of time that has passed ever since, I wanted to take a step back and set the record straight.</p>



<hr>



<h2>When chatbots matter</h2>



<p>So let’s be honest with ourselves for a moment: <em>when did you actually ever enjoy talking to a chat bot?</em> And I’m not talking about the type of bots you talk to when you’re bored, but about those that provide a deeper purpose.</p>



<p>It turns out that the answer is, at least for most of us, almost never.</p>



<p>I love you Intercom, except when I don’t. 99% of time I don’t want to talk to a silly and obtrusive avatar popping up from some corner of the screen before I even had a chance to check out what’s going on. Somehow, I can’t help but think others feel the same.</p>



<p>In fact, we do know that others feel the same. Chat heads jumping at us unasked, are the quintessential equivalent of the infamous sales clerk who eagerly talks to us upon entering a store.</p>



<p>To further add to the challenges: as soon as users go off-script, chat bot’s don’t just become awkward and unpredictable—they turn into little sociopaths that might rub users the wrong way.</p>



<figure><img loading="lazy" width="400" height="346" src="https://azumbrunnen.me/wp-content/uploads/grandma.png" alt="" srcset="https://azumbrunnen.me/wp-content/uploads/grandma.png 400w, https://azumbrunnen.me/wp-content/uploads/grandma-300x260.png 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption>UX Chat.me —&nbsp;Conversational UX News</figcaption></figure>



<p>The moment you create a chat bot is the moment you allow customers to have a conversation with <em>your brand</em>. Not with yourself, not with your friend, but with an uber entity—a symbol—that represents everything you and your team stand for. That’s not a step to be taken lightly.</p>



<p>This simple conversational entity can be a fun tool to engage with people but depending on how the conversation goes, it can quickly turn into a misrepresentation of the values of your team and your company. So building a chat bot should never be the default choice, but an intentional one.</p>



<p>That’s why it’s worth asking yourself the following three questions before venturing into this space:</p>



<h3>1. Is your use case simple enough to be solved through chat?</h3>



<p>Conversation is incredibly complex and it’s challenging enough to keep it on track in the real world. If the use case isn’t simple, chances are, chat bots are not the right tool for the job.</p>



<h3>2. Is your NLP capable and sophisticated enough?</h3>



<p>There are two types of bots: pre-scripted bots with a range of default answers users can choose from, and Natural Language Processing based ones.</p>



<p>Choosing the right one is hard. While pre-scripted can feel too limiting, NLP can break at every corner. Often times, teams quickly fall into the trap of spending a huge amount of time focusing on personality and silly jokes, instead of solving the problem users hired you for in the first place.</p>



<p>Therefore, building on top of the first point above, within the conversational landscape, simple always wins.</p>



<h3>3. Are your users actually in chat based environments?</h3>



<p>Chat bots work best where users already are. If your users are primarily spending time in messaging platforms where bots and micro-apps can be seamlessly embedded, great. That can serve as an effective and natural way to engage with your audience because it matches the “be where users already are” principle.</p>



<p>If on the other hand, people come to your website, a medium that has made great strides to provide content in a non-linear and quick way, it often unnecessarily slows users down. </p>



<hr>



<h2>Farewell chatbot</h2>



<p>I don’t want to discredit chat bots as a paradigm. They have their use in certain industries, medium, and work well for a specific set of use cases. The important part is being deliberate, rather than jumping ship blindfolded.</p>



<p>So whereas turning my website into a chat was a fun experiment, I ultimately feel like it has slowly turned into a fad. I got fooled by the trend, and as a by-product became part of the trend itself.  Fads come and go, and as they get refined and re-interpreted, they ultimately find their true purpose. What we’re left with is the age old insight that it’s only through experimentation, that we can unlock concepts and ideas that last.</p>



<p>Rest in peace chat bot, long live chat bots.</p>
            </article></div>]]>
            </description>
            <link>https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834552</guid>
            <pubDate>Tue, 20 Oct 2020 06:52:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disney Animation data sets (2018)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24834299">thread link</a>) | @ascorbic
<br/>
October 19, 2020 | https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html | <a href="https://web.archive.org/web/*/https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

            
            <span>July 03, 2018 
                 | Tags: 
                     
                        Datasets
                      
                </span>

            <section>
                <p>Today at <a href="https://cg.ivd.kit.edu/egsr18/">EGSR 2018</a>, Walt Disney Animation Studios announced the release of two large, production quality/scale data sets for rendering research purposes.
The data sets are available on a new <a href="https://disneyanimation.com/data-sets/">data sets page on the official Disney Animation website</a>.
The first data set is the Cloud Data Set, which contains a large and highly detailed volumetric cloud data set that we used for our “<a href="https://blog.yiningkarlli.com/2017/07/spectral-and-decomposition-tracking.html">Spectral and Decomposition Tracking for Rendering Heterogeneous Volumes</a>” SIGGRAPH 2017 paper, and the second data set is the Moana Island Scene, which is a full production scene from <a href="https://blog.yiningkarlli.com/2016/11/moana.html">Moana</a>.</p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_hyperion.jpg" alt="Figure 1: The Moana Island Data Set, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/wdas_cloud_hyperion_render.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/wdas_cloud_hyperion_render.jpg" alt="Figure 2: The Cloud Data Set, rendered using Disney's Hyperion Renderer."></a></p>

<p>In this post, I’ll share some personal thoughts, observations, and notes.
The release of these data sets was announced by my teammate, Ralf Habel, at EGSR today, but this release has been in the works for a very long time now, and is the product of the collective effort of an enormous number of people across the studio.
A number of people deserve to be highlighted: Rasmus Tamstorf spearheaded the entire effort and was instrumental in getting the resources and legal approval needed for the Moana Island Scene.
Heather Pritchett is the TD that did the actual difficult work of extracting the Moana Island Scene out of Disney Animation’s production pipeline and converting it from proprietary data formats into usable, industry-standard data formats.
Sean Palmer and Jonathan Garcia also helped in resurrecting the data from Moana.
Hyperion developers Ralf Habel and Peter Kutz led the effort to get the Cloud Data Set approved and released; the cloud itself was made by artists Henrik Falt and Alex Nijmeh.
On the management side of things, technology manager Rajesh Sharma and Disney Animation CTO, <a href="https://twitter.com/ncannon?lang=en">Nick Cannon</a>, provided crucial support and encouragement.
Matt Pharr has been crucial in collaborating with us to get these data sets released.
Matt was highly accommodating in helping us get the Moana Island Scene into a PBRT scene; I’ll talk a bit more about this later.
Intel’s Embree team also gave significant feedback.
My role was actually quite small; along with other members of the Hyperion development team, I just provided some consultation throughout the whole process.</p>

<p>Please note the licenses that the data sets come with.
The Cloud Data Set is licensed under a <a href="https://disney-animation.s3.amazonaws.com/uploads/production/data_set_asset/6/asset/License_Cloud.pdf">Creative Commons Attribution ShareAlike 3.0 Unported License</a>; the actual cloud is based on a photograph by Kevin Udy on his <a href="https://coclouds.com/436/cumulus/%202012-07-26/">Colorado Clouds Blog</a>, which is also licensed under the same Creative Commons license.
The Moana Island Scene is licensed under a more restrictive, custom Disney Enterprises <a href="https://disney-animation.s3.amazonaws.com/uploads/production/data_set_asset/4/asset/License_Moana.pdf">research license</a>.
This is because the Moana Island Scene is a true production scene; it was actually used to produce actual frames in the final film.
As such, the data set is being released only for pure research and development purposes; it’s not meant for use in artistic projects.
Please stick to and follow the licenses these data sets are released under; if people end up misusing these data sets, then it makes releasing more data sets into the community in the future much harder for us.</p>

<p>This entire effort was sparked two years ago at SIGGRAPH 2016, when Matt Pharr made an appeal to the industry to provide representative production-scale data sets to the research community.
I don’t know how many times I’ve had conversations about how well new techniques or papers or technologies will scale to production cases, only to have further discussion stymied by the lack of any true production data sets that the research community can test against.
We decided as a studio to answer Matt’s appeal, and last year at SIGGRAPH 2017, Brent Burley and Rasmus Tamstorf announced our intention to release both the Cloud and Moana Island data sets.
It’s taken nearly a year from announcement to release because the process has been complex, and it was very important to the studio to make sure the release was done properly.</p>

<p>One of the biggest challenges was getting all of the data out of the production pipeline and our various proprietary data formats into something that the research community can actually parse and make use of.
Matt Pharr was extremely helpful here; over the past year, Matt has added support for <a href="http://ptex.us/">Ptex</a> textures and implemented the <a href="http://blog.selfshadow.com/publications/s2015-shading-course/burley/s2015_pbs_disney_bsdf_notes.pdf">Disney Bsdf</a> in <a href="https://github.com/mmp/pbrt-v3">PBRT v3</a>.
Having Ptex and the Disney Bsdf available in PBRT v3 made PBRT v3 the natural target for an initial port to a renderer other than Hyperion, since internally all of Hyperion’s shading uses the Disney Bsdf, and all of our texturing is done through Ptex.
Our texturing also relies heavily on procedural <a href="https://www.disneyanimation.com/technology/seexpr.html">SeExpr</a> expressions; all of the expression-drive texturing had to be baked down into Ptex for the final release.</p>

<p>Both the Cloud and Moana Island data sets are, quite frankly, enormous.
The Cloud data set contains a single OpenVDB cloud that weighs in at 2.93 GB; the data set also provides versions of the VDB file scaled down to half, quarter, eighth, and sixteenth scale resolutions.
The Moana Island data set comes in three parts: a base package containing raw geometry and texture data, an animation package containing animated stuff, and a PBRT package containing a PBRT scene generated from the base package.
These three packages combined, uncompressed, weigh in at well over 200 GB of disk space; the uncompressed PBRT package along weighs in at around 38 GB.</p>

<p>For the Moana Island Scene, the provided PBRT scene requires a minimum of around 90 GB if RAM to render.
This many seem enormous for consumer machines, because it is.
However, this is also what we mean by “production scale”; for Disney Animation, 90 GB is actually a fairly mid-range memory footprint for a production render.
On a 24-core, dual-socket Intel Xeon Gold 6136 system, the PBRT scene took me a little over an hour and 15 minutes to render from the ‘shotCam’ camera.
Hyperion renders the scene faster, but I would caution against using this data set to do performance shootouts between different renders.
I’m certain that within a short period of time, enthusiastic members of the rendering community will end up porting this scene to Renderman and Arnold and Vray and Cycles and every other production renderer out there, which will be very cool!
But keep in mind, this data set was authored very specifically around Hyperion’s various capabilities and constraints, which naturally will be very different from how one might author a complex data set for other renderers.
Every renderer works a bit differently, so the most optimal way to author a data set for every renderer will be a bit different; this data set is no exception.
So if you want to compare renderers using this data set, make sure you understand the various ways how the way this data set is structured impacts the performance of whatever renderers you are comparing.</p>

<p>For example, Hyperion subdivides/tessellates/displaces everything to as close to sub-poly-per-pixel as it can get while still fitting within computational resources.
This means our scenes are usually very heavily subdivided and tessellated.
However, the PBRT version of the scene doesn’t come with any subdivision; as a result, silhouettes in the following comparison images don’t fully match in some areas.
Similarly, PBRT’s lights and lighting model differ from Hyperion’s, and Hyperion has various artistic controls that are unique to Hyperion, meaning the renders produced by PBRT versus Hyperion differ in many ways:</p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_hyperion.jpg" alt="Figure 3a: 'shotCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_pbrt.jpg" alt="Figure 3b: 'shotCam' camera angle, rendered using PBRT v3."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/beachCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/beachCam_hyperion.jpg" alt="Figure 4a: 'beachCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/beachCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/beachCam_pbrt.jpg" alt="Figure 4b: 'beachCam' camera angle, rendered using PBRT v3."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/dunesACam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/dunesACam_hyperion.jpg" alt="Figure 5a: 'dunesACam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/dunesACam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/dunesACam_pbrt.jpg" alt="Figure 5b: 'dunesACam' camera angle, rendered using PBRT v3. Some of the plants are in slightly different locations than the Hyperion render; this was just a small change that happened in data conversion to the PBRT scene."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/flowersCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/flowersCam_hyperion.jpg" alt="Figure 6a: 'flowersCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/flowersCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/flowersCam_pbrt.jpg" alt="Figure 6b: 'flowersCam' camera angle, rendered using PBRT v3. Note that the silhouette of the flowers is different compared to the Hyperion render because the Hyperion render subdivides the flowers, whereas the PBRT render displays the base cage."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/grassCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/grassCam_hyperion.jpg" alt="Figure 7a: 'grassCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/grassCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/grassCam_pbrt.jpg" alt="Figure 7b: 'grassCam' camera angle, rendered using PBRT v3. The sand dune in the background looks particularly different from the Hyperion render due to subdivision and displacement."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/palmsCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/palmsCam_hyperion.jpg" alt="Figure 8a: 'palmsCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/palmsCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/palmsCam_pbrt.jpg" alt="Figure 8b: 'palmsCam' camera angle, rendered using PBRT v3. The palm leaves look especially different due to differences in artistic lighting shaping and curve shading differences. Most notably, the look in Hyperion depends heavily on attributes that vary along the length of the curve, which is something PBRT doesn't support yet. Some more work is needed here to get the palm leaves to look more similar between the two renders."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/rootsCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/rootsCam_hyperion.jpg" alt="Figure 9a: 'rootsCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/rootsCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/rootsCam_pbrt.jpg" alt="Figure 9b: 'rootsCam' camera angle, rendered using PBRT v3. Again, the significant difference in appearance in the rocks is probably just due to subdivision/tesselation/displacement."></a></p>

<p>Another example of a major difference between the Hyperion renders and the PBRT renders is in the water, which Hyperion renders using photon mapping to get the caustics.
The provided PBRT scenes use unidirectional pathtracing for everything including the water, hence the very different caustics.
Similarly, the palm trees in the ‘palmsCam’ camera angle look very different between PBRT and Hyperion because Hyperion’s lighting controls are very different from PBRT; Hyperion’s lights include various artistic controls for custom shaping and whatnot, which aren’t necessarily fully physical.
Also, the palm leaves are modeled using curves, and the shading depends on varying colors and attributes along the length and width of the curve, which PBRT doesn’t support yet (getting the palm leaves is actually the top priority for if more resources are freed up to improve the data set release).
These difference between renderers don’t necessarily mean that one renderer is better than the other; they simply mean that the renderers are different.
This will be true for any pair of renderers that one wants to compare.</p>

<p>The Cloud Data Set includes an example render from Hyperion, which implements our Spectral and Decomposition Tracking paper in its volumetric rendering system to efficiently render the cloud with thousands of bounces.
This render contains no post-processing; what you see in the provided image is exactly what Hyperion outputs.
The VDB file expresses the cloud as a field of heterogeneous densities.
Also provided is an example <a href="https://www.mitsuba-renderer.org/">Mitsuba</a> scene, renderable using the <a href="https://github.com/zhoub/mitsuba-vdb">Mitsuba-VDB plugin that can be found on Github</a>.
Please consult the README file for some modifications in Mitsuba that are necessary to render the cloud.
Also, please note that the Mitsuba example will take an extremely long time to render, since Mitsuba isn’t really meant to render high-albedo heterogeneous volumes.
With proper acceleration structures and algorithms, rendering the cloud only takes us a few minutes using Hyperion, and should be similarly fast in any modern production renderer.</p>

<p>One might wonder just why production data sets in general are so large.
This is an interesting question; the short answer across the industry basically boils down to “artist time is more expensive and valuable than computer hardware”.
We could get these scenes to fit into much smaller …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html</a></em></p>]]>
            </description>
            <link>https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834299</guid>
            <pubDate>Tue, 20 Oct 2020 05:54:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thumbnails and Screenshots using FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24834226">thread link</a>) | @ponderingfish
<br/>
October 19, 2020 | https://ottverse.com/thumbnails-screenshots-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/thumbnails-screenshots-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/thumbnails-ffmpeg-featured-image.png?resize=678%2C381&amp;ssl=1" alt="thumbnails ffmpeg" title="thumbnails-ffmpeg-featured-image" data-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/thumbnails-ffmpeg-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>There are several easy ways to take screenshots/thumbnails of movies using FFmpeg. But why do this in the first place?</p>



<ol><li>You might want to generate thumbnails for your videos and show those thumbnails to the user when he scrolls through the video. </li><li>Or, you might want to compare two videos by doing a side-by-side comparison – this is quite common in video compression research. </li></ol>



<p>FFmpeg offers very simple techniques to extract screenshots or thumbnails at any position of the video (or rather, a way to dump frames at any point you choose). </p>



<p>Let’s see how! </p>




<h2><span id="Single_Screenshot/Thumbnail_Using_frames_v"></span>Single Screenshot/Thumbnail Using <code>-frames:v</code><span></span></h2>



<p>First, let’s understand how to take a single screenshot or thumbnail using FFmpeg. </p>



<pre><code>ffmpeg -i inputvideo.mp4 -ss 00:00:03 -frames:v 1 foobar.jpeg</code></pre>



<p>Understanding this is very simple! Here goes – </p>



<ol><li><code>-ss</code> is the seek command and it can be used to seek to the right position. For accurate seeking, you need to use output seeking and not input seeking (i.e., putting <code>-ss</code> before the input sequence). The syntax for specifying the time is <code>HH:MM:SS.MILLISECONDS</code>. For example, you can tell FFmpeg to seek to&nbsp;<code>01:02:03</code>&nbsp;– i.e., the 3rd second of the 2nd minute of the 1 hour of the movie!</li><li><code>-frames:v 1</code> tells FFmpeg to take only 1 screenshot. Note that, <code>-vframes</code> is deprecated. </li><li>then, you mention the name of the output file (<code>screenshot_10.jpg</code>). </li></ol>



<p>Simple, wasn’t it? Now that you know how to produce a single thumbnail or screenshot, let’s move to the next section where we understand how to create regular or periodic thumbnails.</p>



<h2><span id="Periodic_Screenshot/Thumbnail_with_Resizing"></span>Periodic Screenshot/Thumbnail with Resizing<span></span></h2>



<p>Here is another common use case that FFmpeg can solve easily – <strong>how do you take screenshots/thumbnails at regular intervals, and store them to JPG files after resizing them?</strong></p>



<p>Here is a simple one-liner that can take care of creating a thumbnail and resizing it for you. </p>



<pre><code>ffmpeg -i input1080p.mp4 -r 1 -s 1280x720 -f image2 screenshot-%03d.jpg</code></pre>



<p>The <code>-r</code> command sets the output frame rate (=1) and <code>image2</code> is an image file muxer that is used to write video frames to image files. Using the <code>-s 1280x720</code> command, we can resize the video frames before writing them as images. Note, that the input video is a 1920x1080p video.</p>



<p>The above command will take a screenshot every 1 second. The screenshots would be named <code>001</code>, <code>002</code>, etc. because we have specified the formatting as <code>%3d</code>.</p>



<p>However, in my experience, I have found this technique<strong> to be not frame-accurate</strong>.</p>



<p>In the next section, let’s look at a more accurate way of extracting thumbnails. </p>



<h2><span id="Screenshot/Thumbnail_every_10_seconds"></span>Screenshot/Thumbnail every 10 seconds<span></span></h2>



<p>As an extension of the previous section, let’s do a quick exercise and learn how to create a thumbnail every 10 seconds using FFmpeg. </p>



<pre><code><code>ffmpeg -i inputvideo.mp4 -vf "select='not(mod(n,300))',setpts='N/(30*TB)'" -f image2 thumbnail%03d.jpg</code></code></pre>



<p>Here, </p>



<ol><li>we use the <code>select</code> filter to extract a frame if the expression in single-quotes evaluates to non-zero. If the expression is zero, then <code>select</code> filter discards that frame.</li><li><code>mod(A,B)</code>&nbsp;returns the modulus (remainder after division) result after dividing A by B. So, if we divide 0 by 300, we get 0. Then, 1/300 is 1, and so on. </li><li><code>not</code> inverts this result. So, if the modulus is zero, then the final result is <code>1</code>. If the modulus is non-zero, then the result is evaluated to <code>zero</code>. </li><li>Based on this <code>not</code> operation, the <code>select</code> filter picks up a frame. </li></ol>



<p>The sequence I am using has a frame-rate of <code>30 fps</code>. And, I want a frame every 10 seconds. So, I have to choose a frame out of every 300 frames, right? That is why I used <code>select='not(mod(n,300))'</code></p>







<p>Depending on your sequence’s frame-rate, you can modify the command line shown. If you don’t know your video’s frame-rate, you can use <code>ffprobe</code> to find out. </p>



<pre><code>ffprobe -show_entries format=duration globe-with-timestamp.mp4</code></pre>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>There you have it – multiple easy ways to generate thumbnails and screenshots using FFmpeg. You can choose to take single screenshots or periodic ones with a highly frame-accurate technique! </p>



<p>Until next time, take care and don’t forget to share this article and check out the rest of the news, articles, and tutorials on OTTVerse.com</p>



<p><strong><a href="https://ottverse.com/category/ffmpeg/">Go here</a> to access all the FFmpeg tutorials on OTTVerse.com </strong></p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/thumbnails-screenshots-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834226</guid>
            <pubDate>Tue, 20 Oct 2020 05:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moana Motunui Renderer on GPU]]>
            </title>
            <description>
<![CDATA[
Score 328 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24833218">thread link</a>) | @Impossible
<br/>
October 19, 2020 | https://www.render-blog.com/2020/10/03/gpu-motunui/ | <a href="https://web.archive.org/web/*/https://www.render-blog.com/2020/10/03/gpu-motunui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>03 Oct 2020</span></p><p>Disney Animation’s Moana island dataset is a production-scale scene with memory requirements that make it challenging to render. This post summarizes some of those challenges, and describes how the <a href="https://github.com/chellmuth/gpu-motunui">GPU-Motunui</a> project is able to efficiently render the scene on a consumer-grade GPU with less than 8GB of memory. <a href="#renders">Click here</a> to skip ahead to the results.</p>

<h2 id="the-moana-island">The Moana island</h2>

<p>In 2018, Disney Animation released the Moana island dataset to the rendering research community. Compared to traditional research scenes, the scale of the Moana island scene is massive: the scene contains 90 million quad primitives, 5 million curves, and more than 28 million instances. All told, the island consists of over 15 billion primitives, weighing in at just under 30GB of geometry files.</p>

<p>The shots included with the dataset are beautiful, and showcase the amazing imagery that can be created by combining the best artists in the world with path tracing techniques and modern hardware. Here are two reference images, rendered with Disney’s proprietary Hyperion renderer:</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-shotCam.png" alt="Hyperion shotCam reference"></p><p>Hyperion shotCam reference</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-beachCam.png" alt="Hyperion beachCam reference"></p><p>Hyperion beachCam reference</p>
</div>

<h2 id="gpu-motunui-project">GPU-Motunui Project</h2>

<p>The goal of the GPU-Motunui project is to render all the Moana shots efficiently and accurately on a consumer-grade graphics card. There are two main challenges to accomplishing this with the Moana dataset. First, with a typical graphics card having only 8GB of memory, an out-of-core rendering solution is required to handle the large amounts of geometry. Second, the scene’s textures are provided in the Ptex format, and Ptex doesn’t have a publicly available CUDA implementation. This project currently only solves the first problem, and Ptex texture lookup is done on the CPU (although conveniently its cost is fully hidden by being computed concurrently with GPU shadow ray tracing).</p>

<p>The Hyperion reference images are impossible to match exactly; for example the varying brown and green colors along the palm tree fronds in the palmsCam shot are not provided in the dataset. Other features of the scene are possible to render but out of my initial scope, notably subdivision surfaces and their displacement maps, and a full Disney BSDF implementation.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-unique-palmsCam.png" alt="Example of an unreproducible material variation on the palm tree frond"></p><p>Example of an unreproducible material variation on the palm tree frond</p>
</div>

<p>All ray tracing operations are run through Nvidia’s OptiX 7 API. This means GPU-Motunui gets the full benefits of available RT cores and a world-class BVH implementation. The following sections describe how GPU-Motunui maps dataset assets to OptiX data structures, and how GPU-Motunui’s out-of-core rendering solution works.</p>

<h3 id="scene-representation">Scene representation</h3>

<p>The Moana scene makes widespread use of multi-level instancing. In OptiX, this requires a three-level hierarchy of acceleration structures to manage: two levels of IASs, and a base level of GASs (Instance Acceleration Structures and Geometry Acceleration Structures, respectively). GPU-Motunui makes use of OptiX’s AS compaction and relocation APIs to further reduce memory usage.</p>

<p>The isHibiscus element makes a good example of how a typical element in the scene is organized and built. The tree is assembled from a base model in one Wavefront .obj file (containing the trunk and branches), and four primitives: one flower and three leaf models (each with their own .obj file).</p>

<div>

<p>Left: The four simple primitives that will be instanced to fill out the hibiscus tree <br>Right: The base trunk and branches model </p>
</div>

<p>In OptiX, each of these models has an associated GAS, and each GAS can be subdivided into multiple build inputs. Build inputs are used to map sections of the model to information needed at shading time by indexing into OptiX’s shader binding table. These GASs form the bottom level of the hierarchy.</p>

<p>Next, an IAS is used to build the full isHibiscus element. This IAS is in the middle level of the hierarchy. The figure below shows each primitive’s instances in isolation, and combined to make the full element:</p>

<div>

<p>Left: Isolated instances for each primitive<br>Right: Full isHibiscus element</p>
</div>

<p>Finally, a second IAS is built to track all of the element’s instances present in the scene. This second IAS is the top level of the instance hierarchy.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/isHibiscus-instanced-elements.png" alt="The shotCam view rendered with only isHibiscus instances"></p><p>The shotCam view rendered with only isHibiscus instances</p>
</div>

<p>Although the isHibiscus element has a typical structure, there are some more complicated elements included in the dataset. The isCoral element, for example, has different base geometry and instanced primitives for each of its element instances, but the underlying primitive geometries are shared across all the element instances.</p>

<p>The Moana GAS and IASs alone require 18.5 GB, well past the memory budget of my 8GB RTX 2070. Because OptiX has no native support for out-of-core rendering, the traditional OptiX pipeline had to be put aside for a custom-made solution.</p>

<h3 id="out-of-core-rendering">Out-of-core rendering</h3>

<p>To solve the out-of-core rendering problem, GPU-Motunui divides the scene’s geometry into different sections, and ray traces each separately, while tracking the closest hit. Replacing a traditional device trace call with a host loop comes with many design consequences to the renderer, from asset loading to the core path tracing loop that sends rays through the scene.</p>

<p>Before rendering, the asset loading process allocates a large chunk of GPU memory (currently 6.7GB). A custom allocator is implemented that manages this block of memory. It is responsible for allocating two types of memory: output and temporary. Output memory is allocated from the left of the block, and is used for OptiX structures. Temporary memory is managed on a stack from the right end of the memory block. Managing the temporary memory this way ensures that the output structures are always tightly packed.</p>

<p>After elements are processed into their accelerator structures on the GPU, their used memory is snapshotted onto the host, and the allocator is cleared. The process is repeated until all of the scene’s geometry is processed, resulting in the host managing a list of GPU memory snapshots. The figure below shows an example layout of GPU memory that could be snapshotted:</p>

<div>
  <p>GPU memory layout after loading the isHibiscus element.<br>(Dotted arrows show that an IAS holds instances of the pointed-at AS)</p>

</div>

<p>As mentioned above, when it comes time to ray trace, each snapshot is processed in a loop. This means a call to <code>cudaMemcpy</code> and <code>optixLaunch</code> for each snapshot. A global buffer is maintained that indicates the depth of the current closest intersection. This value is used as the <code>tmax</code> parameter for the CUDA kernel’s call to <code>optixTrace</code>, and a successful intersection will update the depth buffer for the next launch.</p>

<p>In a traditional OptiX path tracer, the entire render loop can run in device code inside a single call to <code>optixLaunch</code>; i.e., a successful intersection will lead to more BSDF and shadow rays being traced in the same kernel launch. Because GPU-Motunui’s design mandates multiple launches for tracing each path segment, the render loop is pulled out into host code. While this potentially diminishes OptiX’s ability to efficiently schedule program execution, it also opens up opportunties for optimization, such as running Ptex texture lookups on the CPU concurrently with GPU kernels and I/O.</p>

<h3 id="shading">Shading</h3>
<p>As with any OptiX application, GPU-Motunui makes use of the shader binding table (SBT). SBT records contain pointers to normal buffers and material attributes. The underlying data for the normal buffers is stored alongside OptiX acceleration structures and included in geometry snapshots. This ensures that GPU memory is never wasted on unreachable normal buffer data.</p>

<h2 id="renders">Renders</h2>
<p>Included below are GPU-Motunui renders of the six scenes included in the dataset. shotCam is the slowest to render at 18.2 seconds per sample at 1024x429 resolution, and took just over five hours total for the final image. All shots are 1024spp, capped at a maximum of five bounces, and were run on an Nvidia RTX 2070.</p>
<div>
  <p><img src="https://www.render-blog.com/assets/ours-shotCam.png" alt="shotCam"></p><p>shotCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-beachCam.png" alt="beachCam"></p><p>beachCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-dunesACam.png" alt="dunesACam"></p><p>dunesACam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-palmsCam.png" alt="palmsCam"></p><p>palmsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-birdseyeCam.png" alt="birdseyeCam"></p><p>birdseyeCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-rootsCam.png" alt="rootsCam"></p><p>rootsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-grassCam.png" alt="grassCam"></p><p>grassCam</p>
</div>

<h2 id="optimization">Optimization</h2>
<p>The initial implementation of the renderer required 42.6 seconds per 1spp on the shotCam scene. A few optimizations combined to make significant reductions in rendering time, cutting each pass down to 18.2 seconds (a 57.3% reduction).</p>

<h4 id="cpugpu-concurrency">CPU/GPU concurrency</h4>
<p>Tracing shadow rays on the GPU in parallel with Ptex lookups on the CPU cut rendering time by 23.4%. It was disappointing to be forced to do texture lookups on the CPU, but the time savings make up for it.</p>

<h4 id="multiple-ptex-caches">Multiple Ptex caches</h4>
<p>Parallelizing the Ptex lookups and using multiple Ptex caches eliminated texture lookups as a bottleneck to the system; shadow ray casting time fully dominates the texture lookup. Empirically, spawning two threads per core (totaling 12 on an Intel i7-8700K) and sharing three Ptex caches comfortably reduced the texture lookup time beneath the shadow ray budget. This improved the time savings to a 33.9% reduction over the baseline.</p>

<h4 id="pinned-memory">Pinned memory</h4>
<p>The acceleration structure snapshots are all saved to pinned host memory. Switching from normal to pinned host memory increased the transfer throughput from 7.73 GB/s to 11.84 GB/s, cutting the baseline render time by 19.5%.</p>

<h2 id="future-steps">Future Steps</h2>
<p>Getting this scene running on my RTX 2070 card was a very fun and rewarding project, but there are still many improvements to be made:</p>
<ul>
  <li>Implementing the Disney BSDF</li>
  <li>Rendering subdivision surfaces along with displacement mapping</li>
  <li>More efficiently packing the acceleration structures, and optimizing ray tracing throughput</li>
  <li>Experimenting with how various research results hold up on production scenes (e.g., testing select path guiding techniques)</li>
</ul>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://github.com/chellmuth/gpu-motunui/">GPU-Motunui</a></li>
  <li><a href="https://technology.disneyanimation.com/islandscene/">Moana Island Scene</a></li>
  <li><a href="https://pharr.org/matt/blog/2018/07/16/moana-island-pbrt-all.html">Swallowing the elephant</a> - Matt Pharr</li>
  <li><a href="https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">Disney Animation Data Sets</a> - Yining Karl Li</li>
  <li><a href="https://schuttejoe.github.io/post/disneypostmortem/">Rendering the Moana Island Scene Part 2: A production scene from a hobby renderer</a> - Joe Schutte</li>
  <li><a href="https://ingowald.blog/2020/01/09/digesting-the-elephant/">Digesting the elephant</a> - Ingo Wald</li>
  <li>Brent Burley and Dylan Lacewell. <a href="http://ptex.us/ptexpaper.html">Ptex: …</a></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.render-blog.com/2020/10/03/gpu-motunui/">https://www.render-blog.com/2020/10/03/gpu-motunui/</a></em></p>]]>
            </description>
            <link>https://www.render-blog.com/2020/10/03/gpu-motunui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24833218</guid>
            <pubDate>Tue, 20 Oct 2020 01:45:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding the Junior Developer]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24833142">thread link</a>) | @mooreds
<br/>
October 19, 2020 | https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html | <a href="https://web.archive.org/web/*/https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          


        </header>
      

      <section itemprop="text">
        
        <p>So first off a personal update – last year, I got laid off the day I returned from maternity leave! Within a half hour of returning to my desk! Whew boy! It was a blessing in disguise in some ways, because 1) I’d been thinking for some time I could be more effective in a consulting role and 2) as part of my severance package, I got to attend a General Assembly coding bootcamp.</p>

<p>I ended up auditing the bootcamp because wow, it demands a ton of sacrifice with the end goal of getting a developer job. In contrast, I am happy to do a bit of scripting on the side, work with developers, and improve their experiences. Nonetheless, I worked through all the lectures, did a few homework assignments, and got a lot out of it. Not the least of which is that I validated my existing coding skills, gained deeper insight into the “junior developer” persona, and reaffirmed my conviction that tailoring your developer experience and docs to junior developers is a <strong>Good Thing</strong>.</p>

<p>There are a couple of big takeaways I’d like to share:</p>

<h3 id="everyone-is-a-junior-developer">Everyone is a junior developer</h3>

<p>Well, no, not actually … but every developer has to learn new concepts.  And yes, of course, as you gain experience as a developer, “totally new” concepts get rarer and rarer. Still, there’s a lot of learning:</p>

<p>Some developers must learn a breakneck pace (think of all the Javascript frameworks coming out all the time! Those front-end folks have to sprint just to stay in place). Others face big disruptions to their coding world only occasionally (your Enterprise Java programmer with a 20 year career in monolithic app development who now lives in a brave new world of microservices, CI/CD, devops, oh my!)</p>

<p>I felt I experienced this disruption myself as part of the coding bootcamp. Up till then, my background was in writing Python scripts, and in documenting big Java applications in a analytics microservices context. I knew about RedHat, Docker, Kubernetes, Spark, Lucene, Cassandra, etc.</p>

<p>Now, I was learning about a whole new world: the ecosystems, the mindset, the business of ….  JavaScript.  Like probably many people outside the JavaScript world, I was fooled by the “script” part of the name – especially since I’d only used JavaScript myself to write macros in an XML docs tool.  Now I realize it’s <a href="https://www.javaworld.com/article/2886368/java-vs-nodejs-an-epic-battle-for-developer-mindshare.html">epic battle</a> between Java and JavaScript. And while I haven’t fallen in love (Python, you still have my heart), I had lots of “oh, that’s neat!” moments. I also recognized that my learning curve was not dissimilar to that of experienced – but JavaScript-naïve – developers.</p>

<p>Which brings me to my main point:</p>

<h3 id="we-should-all-design-for-the-junior-developer">We should all design for the junior developer</h3>

<p>Creating experiences with a junior developer in mind forces you to discard your comfy assumption that everyone’s drunk your product Kool-aid. If you assume you’re writing for someone who’s technically savvy and can learn quickly, but who knows nothing about your world, you’re positioning yourself to vastly decrease your developer onboarding friction. And if you assume that your “junior developer” is super impatient because they have, like, 10 other things on the docket to learn about, then you’ll learn to answer up front the question: “why should I care? Why should I do this work?”</p>

<p>It’s a fine line to tread, assuming not too much about technical knowledge, but also not coming across as condescending or silly (like, at the level of “open a terminal by taking the following steps…”). Still, I think it’s actually quite achievable. For example, it’s quite low effort to provide high-level context for coding instructions. Even something as simple as “Clone this repository and open a terminal at the local directory location” is a direction that often gets left out in GitHub readmes…but it really shouldn’t be left out.  And it never hurts to link to frameworks’ getting started guides, even if you don’t want to provide the details yourself. At the very least, no one is likely to roll their eyes at it, and it helps your reader understand what level of granularity your instructions will provide.</p>

<p>When I look for inspiration, I think the <a href="https://reactjs.org/tutorial/tutorial.html">React newbie tutorials</a> do an outstanding job of introducing junior developers to React, helping them understand why they should care, and explicitly stating their audience. I also really love (who doesn’t) the <a href="https://dashboard.stripe.com/register">Stripe developer onboarding</a> experience.</p>

<p>Ultimately, I think I came away from the coding bootcamp more confident that I <em>am</em> a junior developer. And while I’d never make the classic UX mistake of thinking I am the user, still – my confusions, my pain points in learning about a product– these are things that other developers likely share.</p>

<h3 id="postscript-fun-with-javascript">Postscript: Fun with Javascript!</h3>

<p>I’ll end on another personal note. The coding bootcamp turned out to be quite serendipitous, because I took on contracting work that immediately benefited from my new knowledge. I’d just learned about Express, and now here I was, entering a pull request to change the authentication method for an Express server. I’d just learned about React, and now here I was, wading into a web UI to change some text. It’s always nice when you can put what you’ve learned to immediate use.</p>


        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24833142</guid>
            <pubDate>Tue, 20 Oct 2020 01:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assorted Thoughts on Zig (and Rust)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24832844">thread link</a>) | @todsacerdoti
<br/>
October 19, 2020 | https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I've been using <a href="https://ziglang.org/">zig</a> for ~4 months worth of side projects, including a <a href="https://git.sr.ht/%7Ejamii/focus/tree">toy text editor</a> and an <a href="https://git.sr.ht/%7Ejamii/imp">interpreter for a relational language</a>. I've written ~10kloc.</p>
<p>That's not nearly enough time to form a coherent informed opinion. So instead here is an incoherent assortment of thoughts and experiences, in no particular order :)</p>
<p>This is not meant to be an introduction to zig - check out the excellent <a href="https://ziglang.org/documentation/master/">language docs</a> or the new <a href="https://ziglearn.org/">ziglearn.org</a> instead. I'll try to focus instead on things that are not immediately obvious from reading intro material.</p>
<p>The obvious point of comparison is to rust. For context, I've been using rust <a href="https://scattered-thoughts.net/writing/three-months-of-rust/">since 2015</a>. Mostly in research positions writing throwaway code, but also ~14 months working on <a href="https://materialize.io/">a commercial database</a> which is ~100kloc.</p>
<hr>
<p>Zig is dramatically simpler than rust. It took a few days before I felt proficient vs a month or more for rust.</p>
<p>Most of this difference is <strong>not</strong> related to lifetimes. Rust has patterns, traits, dyn, modules, declarative macros, procedural macros, derive, associated types, annotations, cfg, cargo features, turbofish, autoderefencing, deref coercion etc. I encountered most of these in the first week. Just understanding how they all work is a significant time investment, let alone learning when to use each and how they affect the available design space.</p>
<p>I still haven't internalized the full rule-set of rust enough to be able predict whether a design in my head will successfully compile. I don't remember the order in which methods are resolved during autoderefencing, or how module visibility works, or how the type system determines if one impl might <a href="https://github.com/Ixrec/rust-orphan-rules#what-are-the-orphan-rules">overlap another or be an orphan</a>. There are frequent moments where I know what I want the machine to do but struggle to encode it into traits and lifetimes.</p>
<p>Zig manages to provide many of the same features with a single mechanism - compile-time execution of regular zig code. This comes will all kinds of pros and cons, but one large and important pro is that I already know how to write regular code so it's easy for me to just write down the thing that I want to happen.</p>
<hr>
<p>One of the key differences between zig and rust is that when writing a generic function, rust will prove that the function is type-safe for every possible value of the generic parameters. Zig will prove that the function is type-safe only for each parameter that you actually call the function with.</p>
<p>On the one hand, this allows zig to make use of arbitrary compile-time logic where rust has to restrict itself to structured systems (traits etc) about which it can form general proofs. This in turn allows zig a great deal of expressive power and also massively simplifies the language.</p>
<p>On the other hand, we can't type-check zig libraries which contain generics. We can only type-check specific uses of those libraries.</p>
<pre><span>// This function is typesafe if there exist no odd perfect numbers
// https://en.wikipedia.org/wiki/Perfect_number#Odd_perfect_numbers
fn foo(comptime n: comptime_int, i: usize) usize {
  const j = if (comptime is_odd_perfect_number(n)) "surprise!" else 1;
  return i + j;
}
</span></pre>
<p>This means zig also doesn't get the automatic, machine-checked documentation of type constraints that rust benefits from and may face more challenges providing IDE support.</p>
<p>This might harm the zig ecosystem by making it harder to compose various libraries. But <a href="https://julialang.org/">julia</a> has a similar model and in practice it has worked very well (<a href="https://youtu.be/dmWQtI3DFFo?t=1710">eg</a>, <a href="https://www.oxinabox.net/2020/02/09/whycompositionaljulia.html">eg</a>).</p>
<hr>
<p>Zig's comptime allows expressing <a href="https://scattered-thoughts.net/writing/open-multiple-dispatch-in-zig/">open multiple dispatch</a> as a library.</p>
<p>It should be relatively trivial to implement specialization the same way, which has been a <a href="https://github.com/rust-lang/rust/issues/31844">work in progress</a> in rust for years and is critical to many optimizations in julia's math libraries.</p>
<p>Julia chose dynamic typing because it's very difficult to encode the types of various mathematical operations into a general schema (eg fortress <a href="https://youtu.be/EZD3Scuv02g?t=3011">struggled with this</a>). Zig's approach of not requiring general schemas but still type-checking individual cases may be an interesting sweet spot.</p>
<hr>
<p>I used the <a href="https://cwe.mitre.org/data/definitions/1350.html">2020 CWE Top 25 Most Dangerous Software Weaknesses</a> to get a sense of the relative frequency of different causes of memory unsafety.</p>
<p>(I'm assuming that the zig programmer is using release-safe mode instead of the unfortunately named release-fast mode which disables all runtime safety checks.)</p>
<ul>
<li>Out-of-bounds Write (787/1350)</li>
<li>Out-of-bounds Read (125/1350)</li>
<li>Improper Restriction of Operations within the Bounds of a Memory Buffer (119/1350)</li>
</ul>
<p>Both languages primarily use bounds-checked slices and relegate pointer arithmetic to a separate type (<code>*T</code> in rust, <code>[*]T</code> in zig).</p>
<ul>
<li>NULL Pointer Dereference (476/1350)</li>
</ul>
<p>Both languages require explicit annotations for nulls (<code>Option&lt;T&gt;</code> in rust, <code>?T</code> in zig) and require code to either handle the null case or safely crash on null (<code>x.unwrap()</code> in rust, <code>x.?</code> in zig).</p>
<p>Dereferencing/casting a null c pointer is undefined behavior in both languages, but is checked at runtime in zig.</p>
<ul>
<li>Integer Overflow or Wraparound (190/1350)</li>
</ul>
<p>Rust catches overflow in debug and wraps in release. Zig catches overflow in debug/release-safe and leaves behavior undefined in release-fast.</p>
<p>Both languages allow explicitly asking for wraparound (<code>x.wrapping_add(1)</code> in rust, <code>x +% 1</code> in zig).</p>
<ul>
<li>Use After Free (416/1350)</li>
</ul>
<p>As long as all unsafe code obeys the aliasing and lifetime rules, rust protects completely against UAF.</p>
<p>Zig has little protection. The recently merged
<a href="https://github.com/ziglang/zig/blob/575fbd5e3592cff70cbfc5153884d919e6bed89f/lib/std/heap/general_purpose_allocator.zig">GeneralPurposeAllocator</a> avoids reusing memory regions (which prevents freed data from being overwritten) and reusing pages (which means that UAF will eventually result in a page fault). But this comes at the cost of fragmentation and lower performance and it also won't provide protection for child allocators using the GPA as a backing allocator.</p>
<hr>
<p>Both languages will insert implicit casts between primitive types and pointers whenever it is safe to do so, and require explicit casts otherwise. (With the odd exception that rust will not implicitly upcast numbers).</p>
<p>Both languages support generics which almost entirely avoids the need to cast void pointers.</p>
<hr>
<p>In rust the Send/Sync traits flag types which are safe to move/share across threads. In the absence of unsafe code it should be impossible to cause data races.</p>
<p>Zig has no comparable protection. It's possible to implement the same logic as Send/Sync in comptime zig, but without the ability to track ownership the rules would have to be much more restrictive.</p>
<hr>
<p>Rust prevents having multiple mutable references to the same memory region at the same time.</p>
<p>This means that eg iterator invalidation is prevented at compile time, because the borrow checker won't allow mutating a data-structure while an iterator is holding a reference to the data-structure. Similarly for resizing a data-structure while holding a reference to the old allocation. Both examples are easy sources of UAF in zig.</p>
<hr>
<p>Neither language is able to produce stack traces for stack overflows at the moment (<a href="https://github.com/rust-lang/rust/issues/51405">rust</a>, <a href="https://github.com/ziglang/zig/issues/1616">zig</a>)</p>
<p>In the future zig is <a href="https://github.com/ziglang/zig/issues/1006">intended</a> to statically check the maximum stack usage of your program and force recursive code to explicitly allocate space on the heap, so that stack overflows produce a recoverable OutOfMemory error rather than a crash.</p>
<p>This is not an academic problem - I've seen real-world crashes from recursive tree transformations in compilers (<a href="https://github.com/MaterializeInc/materialize/pull/3996">eg</a>) and it's often painful to write the same logic without recursion.</p>
<hr>
<p>Undefined behavior in rust is defined <a href="https://doc.rust-lang.org/nomicon/what-unsafe-does.html">here</a>. It's worth noting that breaking the aliasing rules in unsafe rust can cause undefined behavior but these rules are not yet well-defined. So far this hasn't caused me any problems but it is a little unnerving.</p>
<p><a href="https://github.com/rust-lang/miri">Miri</a> is an interpreter for rusts Mid-level Intermediate Representation which will detect many (but not all) cases of undefined behavior in unsafe rust. It's far too slow to use for the whole materialize test suite but was useful for unit-testing an unsafe module.</p>
<p>Undefined behavior in zig is defined <a href="https://ziglang.org/documentation/master/#Undefined-Behavior">here</a>. This list is <a href="https://github.com/ziglang/zig/issues/1966">probably incomplete</a> given that the core language is still under development.</p>
<p>Zig <a href="https://github.com/ziglang/zig/issues/2301">aspires</a> to insert runtime checks for almost all undefined behavior when compiling in debug mode. So far all the easy cases are handled, which is already a dramatic improvement over c.</p>
<p>Zigs compile-time partial evaluation is done by an IR interpreter - it seems plausible that this could also be used as a miri-like tool in the future.</p>
<hr>
<p><code>@import</code> takes a path to a file and turns the whole file into a struct. So modules are just structs. And vice-versa - if you have a large struct declaration you can move it into a file to reduce the indentation.</p>
<p>Zig doesn't care at all where you put files on the filesystem.</p>
<p><code>@import</code> is part of the compile-time execution system so things like platform-specific modules and configurable features can be specified in regular code rather than rust's limited set of <code>#[cfg(...)]</code> macros.</p>
<hr>
<p>Array, struct, enum and union literals can be anonymous - <code>.{.Constant = 1.0}</code> is an anonymous union with it's own type, but can be implicitly cast to any union with a <code>Constant: f64</code> field because they share the same structure.</p>
<p>In rust my code is littered with <code>use Expr::*</code> and I'm careful to avoid name collisions between different enums that I might want to import in the same functions. In zig I just use anonymous literals everywhere and don't worry about it.</p>
<hr>
<p>Anonymous literals are also nice when using structs to simulate keyword arguments. No need to find and import the correct type:</p>
<pre><span>fn do_things(config: struct {
  max_things: usize = 1000, // default value
  flavor: Flavor,
}) void {
  ...
}

do_things(.{.flavor = .Strawberry});
</span></pre>
<hr>
<p>There is a pattern that shows up a lot in the materialize codebase:</p>
<pre><span>let</span><span> constant </span><span>= </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(constant) </span><span>=</span><span> expr { constant } </span><span>else </span><span>{ </span><span>panic!</span><span>() }</span><span>;
</span></pre>
<p>It's common enough that many types have methods like <code>expr.unwrap_constant()</code>.</p>
<p>In zig:</p>
<pre><span>const constant = expr.Constant;
</span></pre>
<p>A similar pattern is:</p>
<pre><span>if</span><span> some_condition {
    </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(</span><span>_</span><span>) </span><span>=</span><span> expr {
        </span><span>...
    </span><span>}
}
</span></pre>
<p>Again, many types get methods like <code>expr.is_constant()</code>.</p>
<pre><span>if</span><span> some_condition </span><span>&amp;&amp;</span><span> expr</span><span>.</span><span>is_constant</span><span>(…</span></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</a></em></p>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24832844</guid>
            <pubDate>Tue, 20 Oct 2020 00:47:18 GMT</pubDate>
        </item>
    </channel>
</rss>
