<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 12 Sep 2020 16:23:50 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 12 Sep 2020 16:23:50 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Technical Interview Is an Ego Trip]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24447182">thread link</a>) | @kowsheek
<br/>
September 11, 2020 | https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/ | <a href="https://web.archive.org/web/*/https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Early in my career, after a short initial interview at a consulting firm in Toronto, I was invited to a technical interview on the same day. Two of the senior developers from the team I would join would conduct the interview.</p><p>The interview started pleasantly with them describing the project they have been working on: a portal for university professors to communicate with their students. It was being built with ASP.NET MVC, a framework I had been working with for several years. I expressed that I was comfortable with the framework and I would be excited to work on the project. Then the technical examination began and on its conclusion I left the interview feeling humiliated.</p><p>Many years later, when I was preparing to take an interview, I looked back on this experience to realize that the line of questioning and approach had been an ego trip for those developers. I promised myself to <em>never</em> make any of my candidates feel the way I did.</p><p>What did those developers do wrong? Leaving aside their attitude towards me, their questions had no relevance to the role or the project. I did not know what a red-black tree was at the time but I definitely knew how to use ASP.NET MVC which they did not inquire about.</p><p>My golden rule for technical interviews is that, "Every step, conversation and question <em>must</em> be pertinent to the day-to-day of the role." While this may be obvious, I am sure that many hiring managers are still expecting candidates to arrive at technical interviews with Computer Science books memorized. This form of technical interviews should be made obsolete.</p><figure><blockquote><p lang="en" dir="ltr">Bigger button = more clicks on the CTA <a href="https://t.co/Ter7xJdNKM">pic.twitter.com/Ter7xJdNKM</a></p>— Vincent Déniel (@vincentdnl) <a href="https://twitter.com/vincentdnl/status/1291041278264713220?ref_src=twsrc%5Etfw">August 5, 2020</a></blockquote>

</figure><p>With my golden rule as guide, I conduct a much simpler interview process. Prior to an interview, my team and I review samples of code that the candidate shared with us (or had written on Github) to understand the quality of their code. And during the interview, I dive into three areas of discussions with the candidates: product building, process adherence and team work.</p><h3 id="product-building">Product Building</h3><p>I try to understand the candidate's interest and experience of building products by,</p><ol><li>Going through their past experience and asking about what technologies and products they built and how. I ask about previous products they have shipped from concept to market.</li><li>To understand their thought process for deriving solutions, I draw an UI and ask them to outline and explain what approaches, structures and technologies they would use to build it out.</li><li>I ask about how they keep up with technologies and how they improve their skills to gauge their passion for the work.</li></ol><h3 id="process-adherence">Process Adherence</h3><p>To better understand how the candidate does their work,</p><ol><li>I go over their experiences and ask about how they managed their product-building and what tools and processes they used.</li><li>I explain the process of working on our team and ask how they would change it and where they see inefficiencies to discuss their thinking.</li><li>Often, I will give them a scenario where the processes are failing the team to find what they would do to tackle inefficiencies and if they would be willing to speak up.</li></ol><h3 id="team-work">Team Work</h3><p>I also try to understand how a candidate works in a team,</p><ol><li>While going through their past experiences, I ask about how they collaborated and communicated with their teams.</li><li>I present a scenario where their knowledge in an area may be lacking and evaluate if and how they would leverage and collaborate with their team.</li><li>Another scenario I ask about is where they disagree with their team-members to evaluate how they manage conflict and focus on delivering results for the team.</li></ol><p>I do this within one interview to be mindful of the candidate's time and mine. I want to hire candidates for their will to learn, grow and challenge the status quo.</p><p>The technology landscape is such that once we have a set of baseline programming skills. What is needed then, is a willingness to challenge ourselves and stay open-minded because every developer will have to learn on the job almost all of the time. Given this, the technical interview is arcane, academic and as good as dead.</p><hr><h3 id="further-reading">Further Reading</h3><ol><li><a href="https://news.ncsu.edu/2020/07/tech-job-interviews-anxiety/">Tech Sector Job Interviews Assess Anxiety, Not Software Skills</a></li><li><a href="https://medium.com/helpful-com/https-medium-com-fnthawar-helpful-technical-interviews-are-garbage-dc5d9aee5acd">Technical interviews are garbage. Here’s what we do instead</a></li><li><a href="https://remotesynthesis.com/blog/whats-wrong-with-tech-interviews">What's Wrong with the Tech Interview Process?</a></li></ol>
                </div>
            </section>

                <section>
    <h3>Subscribe to blog.kowsheek</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447182</guid>
            <pubDate>Fri, 11 Sep 2020 20:47:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The first major sign your web host will not respect you]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24446756">thread link</a>) | @puggo
<br/>
September 11, 2020 | https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <hr>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/an-unethical-salesman.jpg" alt="The First Major Sign Your Web Host Will Not Respect You"></p>
<hr>
<h2 id="when-a-relationship-starts-with-an-act-of-dishonesty-or-manipulation-it-will-be-a-toxic-relationship"><em>When a relationship starts with an act of dishonesty or manipulation, it will be a toxic relationship</em>.</h2>
<p>This is common knowledge.</p>
<p>Most major web hosting companies groom potential customers in manipulative ways, but, sadly, many do not recognize the trouble signs due to naivety or need.</p>
<p>Here is one important, but common cue that your webhost-to-be will not respect you, and you are in for a compromising, dysfunctional relationship.</p>
<h2 id="but-you-said-395-a-month-">But you said 3.95 a month… :(</h2>
<h3 id="the-solicitation">The Solicitation</h3>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/do-you-really-mean-it.jpg" alt="Do you really mean it?"></p>
<p><a href="https://web.archive.org/web/20200911190002/https://www.bluehost.com/">https://web.archive.org/web/20200911190002/https://www.bluehost.com/</a></p>
<p>In the ad above, this average young woman has just been approached by what could be the prince-charming of webhosts, bluehost himself. She is excited and flattered that she could have him for the price of $3.50 a month.</p>
<p>Enticed, she takes the bait.</p>
<h3 id="getting-into-the-car">Getting into the Car</h3>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/do-you-really-mean-it-2.jpg" alt="Is it too good to be true?"></p>
<p><a href="https://web.archive.org/web/20200910194510if_/https://www.bluehost.com/hosting/shared#pricing-cards">https://web.archive.org/web/20200910194510if_/https://www.bluehost.com/hosting/shared#pricing-cards</a></p>
<p>Now the young lady is excited, because although it seemed too good to be true, it looks like this might just be true love. $3.95 a month! Things are finally looking up.</p>
<h3 id="taking-the-ride">Taking the Ride</h3>
<p>After some flirty initial conversation of what her domain name will be, our prince charming bluehost finally gets down to his intentions.</p>
<p>He says, <strong>“So let’s talk about that $178.08…"</strong></p>
<p>And her heart sinks…</p>
<p><img src="https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/get-your-hands-off-me.jpg" alt="Get your hands off me!"></p>
<p>And now we’ve quickly arrived at that part of the relationship known as <em><strong>“Get your hands off me!"</strong></em>.</p>
<hr>
<h2 id="17808-for-3-years-is-not-395-a-month">$178.08 for 3 Years is Not $3.95 a Month</h2>
<p>One might argue that if you divide the numbers over 3 years, it evens out to the price stated: $3.95.</p>
<p>But that’s <em>not</em> $3.95 a month.</p>
<p>That <em>is</em> $178.08 for three years.</p>
<p>If it was $3.95 a month, I could pay $3.95 for the first month, $3.95 for the second… $3.95 for the third … etc.</p>
<p>It was lie, a manipulation, a sign.</p>
<h3 id="my-wedding-ring-costs-less-per-month-every-year">My wedding ring costs less per month every year…</h3>
<p>So by this logic, a $1000 wedding ring costs $1.66 dollars a month after 50 years of marriage. Assuming there is no divorce.</p>
<h3 id="but-if-you-say-yes">But if you say yes…</h3>
<p>Sadly, some people will ignore the first alarm signs of the toxic relationship, and convince themselves that they did not just get manipulated.</p>
<p>Sadly, that “deal” is lost in a short time due to common upsells inherent to hosts such as this.  Because if you don’t say “get your hands off me” you enable future exploits, and the web host knows this. He’s good at what he does.</p>
<h3 id="prince-charming-is-a-dime-a-dozen">Prince Charming is a Dime a Dozen</h3>
<p>Despite how unique and valuable this prince charming purports to be, there is a street full of them coming from every alley way.</p>
<p>Most major cheap hosting companies operate this way.</p>
<p>Don’t give up your standards and settle. The good hosts are hard to find, because they don’t hang out in the main traffic areas of society/internet.</p>
<hr>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/sign-your-webhost-does-not-respect-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446756</guid>
            <pubDate>Fri, 11 Sep 2020 20:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ballpoint.io]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24446548">thread link</a>) | @artursapek
<br/>
September 11, 2020 | https://ballpoint.io/files/examples/gopher | <a href="https://web.archive.org/web/*/https://ballpoint.io/files/examples/gopher">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ballpoint.io/files/examples/gopher</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446548</guid>
            <pubDate>Fri, 11 Sep 2020 19:42:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not all attacks are equal: understanding and preventing DoS in web applications]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24445886">thread link</a>) | @ievans
<br/>
September 11, 2020 | https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p><em>Thanks to Clint Gibler, Grayson Hardaway, and Pablo Estrada at r2c for their contributions to this piece. And thanks to r2c for contracting me to write it! This article is cross-posted on <a href="https://jacobian.org/2020/sep/11/analyzing-dos-vulnerabilities/" target="_blank" rel="noopener">jacobian.org</a>.</em></p>
<p>When I ran the security team at Heroku, I had this recurring nightmare: my PagerDuty alarm goesoff, alerting me to some sort of security incident. In my dream, I’d look at my phone and realize “oh no, this is the big one” — and then I’d wake up.</p>
<p>I’m still not sure exactly what the attack in my dream was, but it may very well have been a <em>Denial-of-Service (DoS)</em> attack. DoS attacks are simple but can be devastating: an attacker crafts and sends traffic to your app in a way that overwhelms your servers. While this is arguably not as bad as a remote code execution or a data breach, it’s still pretty terrible. If your customers can’t use your app, you’ll lose their money and their trust.</p>
<p>Typically, we talk about two kinds of Denial-of-Service attacks:</p>
<ol>
<li>“Normal” Denial-of-Service (DoS) attacks, where a single machine is sufficient to cause downtime. The classic, old-school version of this attack is the <a href="https://en.wikipedia.org/wiki/Zip_bomb" target="_blank" rel="noopener">zip bomb</a>: an attacker tricks your server into expanding a specially-crafted ZIP file that is tiny compressed but expands to entirely fill your disk space.</li>
<li>Distributed Denial-of-Service (DDoS) attacks. These attacks rely on an attacker sending a huge flood of traffic to your site from multiple machines (that’s the “Distributed” part). Often, these attacks come from <a href="https://en.wikipedia.org/wiki/Botnet" target="_blank" rel="noopener">Botnets</a> — fleets of compromised machines controlled by an attacker. These botnets are available to purchase in certain corners of the Internet, making a DDoS attack well within the reach of anyone with a credit card.</li>
</ol>
<p>Engineers who work on web applications frequently run into vulnerabilities that could be used in a DoS/DDoS attack. Unfortunately, there’s broad disagreement in the industry about how to treat these vulnerabilities. The risk can be difficult to analyze: I’ve seen development teams argue for <em>weeks</em> over how to handle a DoS vector.</p>
<p>This article tries to cut through those arguments. It provides a framework for engineering and application security teams to think about denial-of-service risk, breaks down DoS vulnerabilities into high-, medium-, and low-risk classes, and has recommendations for mitigations at each layer.</p>
<p>The primary focus of this post is on the big picture, and should apply to any kind of web app. But to make things concrete, I’ve added a few specific Django-related examples. (I helped create it, so it’s what I’m most familiar with.)</p>
<h2>Evaluating Denial-of-Service Risk</h2>
<p>Evaluating the risk of a DoS vulnerability at the application layer can be difficult. There’s widespread disagreement among security professionals: you’ll often see two different appsec teams treat similar issues very differently.</p>
<p>Some argue: it’s nearly impossible to entirely mitigate against a focused DDoS — a dedicated enough attacker can throw more bandwidth at you than your app can handle. You can never fully mitigate a DDoS attack without serious support from an upstream network provider with specific tools to protect bot attacks (e.g., Cloudflare). Thus, chasing and fixing hypothetical DoS vulnerabilities can seem like a waste of developer time. These teams treat most potential DoS vectors as acceptable risk, and focus their energy at preparing mitigations at the network level.</p>
<p>Other teams point out that the traditional risk model has three potential problem areas: Confidentiality, Integrity, and <em>Availability</em>. We’ve long understood that uptime is a security issue. It’s becoming increasingly common for attackers to take a service down and then demand a ransom to stop the attack. The recent <a href="https://www.theverge.com/2020/8/4/21353842/garmin-ransomware-attack-wearables-wastedlocker-evil-corp" target="_blank" rel="noopener">attack against Garmin</a> is a highly notable example; attackers took down nearly all of Garmin’s services, and reportedly demanded US $1 million to stop the attack. (In this case the attack was ransomware, but it’s easy to see how a DoS attack could have a similar effect). Thus, DoS vulnerabilities are risks like any other, and it’s easy to understand the argument that they should all be mitigated.</p>
<p>It’s important to recognize that both of these positions are valid! It’s reasonable to see DoS as out-of-scope for application security; it’s similarly reasonable to scope it in. I’ve often seen security teams get completely stuck arguing between these two positions. Since neither is “right” or “wrong”, it can be impossible to figure out how to move forward.</p>
<h3><strong>How I decide: <em>attacker leverage</em></strong></h3>
<p>The model I use to cut through this argument is the concept of <em>attacker leverage</em>. Levers amplify force: a small amount of force applied to the long end of the lever is multiplied at the short end. In the context of a DoS attack, if a vulnerability has <em>high leverage</em> it means attackers can consume a ton of your server resources with minimal resources.</p>
<p>For example, if a bug in your web app allows a single <code>GET</code> request to consume 100% CPU, that’s a terrific amount of leverage. Just a small handful of attacks, and your web servers will grind to a halt. A <em>low leverage</em> vulnerability, on the other hand, requires a high amount of attacker resources to cause minor availability degradation. If an attacker has to spend thousands of dollars to bring a single server to its knees, you can probably scale up faster than they can.</p>
<p>The higher the leverage, the higher the risk, and the more likely I am to address the issue directly. The lower the leverage, the more likely I’ll accept the risk and/or lean on network-level mitigations.</p>
<p>Let’s get specific. I’ve broken down DoS risk into high, medium, and low risk classes, based on leverage. For each class, I’ll look at how to recognize that a vulnerability falls into this class, discuss a few examples, and give some suggestions for mitigation.</p>
<h2>High leverage DoS vulnerabilities: easily-amplified resource starvation</h2>
<p>The classic high-risk DoS vulnerability is one where an attacker can cause resource starvation using very little resources themselves. This could mean exhaustion of any number of types of resources, including:</p>
<ul>
<li><strong>Disk space</strong> — e.g., a vulnerability that magnifies uploaded data and fills the disk, as in the case of the classic <a href="https://en.wikipedia.org/wiki/Zip_bomb" target="_blank" rel="noopener">zip bomb</a>.</li>
<li><strong>Network bandwidth</strong> — e.g., a vulnerability that amplifies input traffic, where a single incoming request consumes tons of bandwidth, causing network starvation. I’ve seen this happen with a bug in a microservices system, where a single incoming request triggered millions of internal API requests (including moving some fairly large files around the network), and choked off the internal network bandwidth.</li>
<li><strong>CPU utilization</strong> — e.g., an exploit that triggers an <a href="https://accidentallyquadratic.tumblr.com/" target="_blank" rel="noopener">accidentally quadratic</a> algorithm, causing web servers to grind to a halt.</li>
<li><strong>Concurrency limits</strong> — most servers have a maximum concurrency limit (e.g., max threads or processes, or max connections for a database); an exploit that causes a process to run very slowly (or never exit) can cause the server to hit those limits and start rejecting requests.</li>
</ul>
<p>In all these cases, the unifying factor is that a bug in the application will allow significant amplification.</p>
<h3><strong>Authentication affects risk</strong></h3>
<p>When considering the risk of a resource amplification DoS vector, an important factor is the level of authentication required to trigger the vulnerability.
If a completely anonymous user can easily trigger a resource starvation attack, it’ll be extremely easy for an attacker to bring you to your knees. Unauthenticated DoS vectors should be considered very high risk.
On the other hand, if only users who authenticate against your corporate Single Sign-On server can trigger the vulnerability, it’s far lower risk. Most attackers aren’t insiders (though, some are!). And, if an attack does occur, it’s easy to attribute and block. In many cases, “we can attribute and block this attack” is a reasonable, if not complete, mitigation strategy.
Many vulnerabilities fall between these two extremes: most services make creating new accounts fairly trivial (e.g., you just need an email address). This does give minimal ability to attribute and block, but often not enough.</p>
<h3><strong>Mitigation recommendation: eliminate</strong></h3>
<p>Generally, I recommend that this class of DoS vulnerabilities — especially unauthenticated ones — be treated as high risk, and eliminated. If exploited, these vulnerabilities can be devastating; they allow a single attacker to completely overwhelm your app. I’d put the same level of effort into finding and eliminating these kinds of bugs that I do other high-risk security vulnerabilities like XSS and CSRF.</p>
<h3><strong>An example high-leverage vulnerability: ReDoS</strong></h3>
<p>A common example of this last type of resource starvation, concurrency limits, is the <em>regular expression denial-of-service</em>, aka <em>ReDoS</em>. ReDoS bugs occur when certain types of strings can cause improperly crafted regular expressions to perform extremely poorly. These types of vulnerabilities are unfortunately relatively common in Python; the built-in regular expression module (<code>re</code>) has no inherent protection against them (unlike libraries like <a href="https://github.com/google/re2" target="_blank" rel="noopener">re2</a>, Go’s built-in regex module, and thus renders the language more or less immune to this class of attack).
(Django itself has had several of these vulnerabilities over the years; for example, <a href="https://www.djangoproject.com/weblog/2019/aug/01/security-releases/" target="_blank" rel="noopener">CVE-2019-14232 and CVE-2019-14233</a> were both ReDoS vulnerabilities).
In Django, these vulnerabilities most often show up in two places: <a href="https://docs.djangoproject.com/en/3.1/topics/http/urls/#using-regular-expressions" target="_blank" rel="noopener">regex-based URL parsing</a> and <a href="https://docs.djangoproject.com/en/3.1/ref/validators/" target="_blank" rel="noopener">custom validators</a>, and more broadly anywhere an application uses regular expressions. Luckily, this class of vulnerabilities are fairly easy to find; see the following r2c articles:</p>
<ul>
<li><a href="https://r2c.dev/blog/2020/finding-python-redos-bugs-at-scale-using-dlint-and-r2c/" target="_blank" rel="noopener">Finding Python ReDoS bugs at scale using Dlint and r2c</a>, and</li>
<li><a href="https://r2c.dev/blog/2020/improving-redos-detection-with-dlint-and-r2c/" target="_blank" rel="noopener">Improving ReDoS detection and finding more bugs using Dlint and r2c</a></li>
</ul>
<p>If you’re using Python, you can easily scan for ReDoS in your application using Semgrep, which has ReDoS detection ported from Dlint. The detection requires some extra logic written using Semgrep’s powerful pattern-where-python clause, which enables rules to leverage the full power of Python, …</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/">https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445886</guid>
            <pubDate>Fri, 11 Sep 2020 18:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sorcerer’s Apprentice Guide to Training LSTMs]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24445617">thread link</a>) | @nshr
<br/>
September 11, 2020 | https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/ | <a href="https://web.archive.org/web/*/https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<nav id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#vanilla-lstm">Vanilla LSTM</a>
<ul>
<li><a href="#input-activation-functions-and-the-drift-effect">Input Activation Functions and the Drift Effect</a></li>
<li><a href="#forget-gates-and-vanishing-gradients">Forget Gates and Vanishing Gradients</a></li>
</ul></li>
<li><a href="#focused-lstm">Focused LSTM</a></li>
<li><a href="#lightweight-lstm">Lightweight LSTM</a></li>
<li><a href="#ticker-steps">Ticker Steps</a></li>
<li><a href="#negative-gate-biases">Negative gate biases</a></li>
<li><a href="#scaled-activation-functions">Scaled activation functions</a></li>
<li><a href="#linear-activation-functions">Linear activation functions</a></li>
<li><a href="#time-awareness">Time Awareness</a></li>
<li><a href="#separation-of-memory-and-compute">Separation of Memory and Compute</a></li>
<li><a href="#chicken-and-egg-online-learning-and-more-cells-than-necessary">Chicken and Egg, online learning and more cells than necessary</a></li>
<li><a href="#sequence-classification-vs.-continuous-prediction">Sequence classification vs.&nbsp;continuous prediction</a>
<ul>
<li><a href="#parallel-lstm-networks-for-continuous-prediction">Parallel LSTM networks for continuous prediction</a></li>
</ul></li>
<li><a href="#target-and-input-scaling">Target and input scaling</a></li>
</ul>
</nav>
<hr>
<h2 id="introduction">Introduction</h2>
<div data-layout="l-body">
<div><p><span id="fig:sorcerer"></span>
<img src="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/images/zauberlehrling.png" alt="The sorcerer's apprentice. Illustration by Ferdinand Barth circa 1882." width="400"></p><p>
Figure 1: The sorcerer’s apprentice. Illustration by Ferdinand Barth circa 1882.
</p>
</div>
</div>
<blockquote>
<div><p>Gone’s for once the old magician<br> With his countenance forbidding;<br> I ’m now master,<br> I ’m tactician,<br> All his ghosts must do my bidding.<br> Know his incantation,<br> Spell and gestures too;<br> By my mind’s creation<br> Wonders shall I do.</p><p>  – Johann Wolfgang von Goethe (The sorcerer’s apprentice)</p></div>
</blockquote>
<p>While mulling over old papers and hacking away at their computers, scholars build up an intimate knowledge about their research topic. As they chart their way through idea space, they develop a deep intuition on which techniques work well in practice. Unfortunately, many of these hard-earned insights are not published and remain obscure.</p>
<p>Last year, I took a course at the Johannes Kepler University in Linz, Austria on the topic of Recurrent Neural Networks and Long Short-Term Memory Networks. There, Sepp Hochreiter shared some of the “magic tricks” he and his team employ for training LSTMs. This blog post is the accumulation of some of my notes.</p>
<p>For this post, I assume you are already familiar with LSTMs. If not, I suggest you begin with Chris Olah’s <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a> and then go on to read the original LSTM work <span data-cites="hochreiter1997long">(Hochreiter and Schmidhuber <a href="#ref-hochreiter1997long" role="doc-biblioref">1997</a>)</span>.</p>
<p>Before we begin, I’d also like to highlight some resources that are similar in their motivation:</p>
<ul>
<li>Andrej Karpathy’s <a href="http://karpathy.github.io/2019/04/25/recipe/">general recipe for training neural networks</a>.</li>
<li>Danijar Hafner’s tips for training recurrent neural networks <span data-cites="hafner2017rnntips">(Hafner <a href="#ref-hafner2017rnntips" role="doc-biblioref">2017</a>)</span>.</li>
<li>LSTM: A Search Space Odyssey <span data-cites="Greff_2017">(Greff et al. <a href="#ref-Greff_2017" role="doc-biblioref">2017</a>)</span> from IDSIA (Dalle Molle Institute for Artificial Intelligence).</li>
</ul>
<p>In case you want to experiment with some of the presented techniques and you need a flexible Pytorch-based LSTM implementation, I recommend Michael Widrich’s <a href="https://github.com/widmi/widis-lstm-tools">LSTM Tools library</a>.</p>
<p>All credits for the presented techniques go to the authors. All errors in their presentation are mine. I am always keen to receive feedback.</p>
<h2 id="vanilla-lstm">Vanilla LSTM</h2>
<p>The <em>Vanilla LSTM</em> is one of the most prevalent variants and is often the default LSTM architecture in popular software libraries. It is characterized by three gates and a memory state – the gates provide the model with capacity and protect the memory cells from distracting information and noise; they make the dynamics of the LSTM highly non-linear and allow it to learn to perform complex operations.</p>
<p>Let us briefly step through the Vanilla LSTM’s mechanics to introduce the notation and terminology used in this post. Sensory inputs <span>\(\boldsymbol{x}(t)\)</span> flowing into the LSTM cell at a given time step are transformed into the <em>cell input activation</em> <span>\(\boldsymbol{z}(t)\)</span> – the elements of <span>\(\boldsymbol{z}(t)\)</span> are activated by a non-linear function <span>\(g(\cdot)\)</span>, which in practice is often defined as the <em>hyperbolic tangent</em> or <em>tanh</em>. Information that is irrelevant for the current time step is removed by multiplying <span>\(\boldsymbol{z}(t)\)</span> element-wise by a sigmoid-activated <em>input gate</em> <span>\(\boldsymbol{i}(t)\)</span>. Similarily, the <em>cell state</em> of the previous time step <span>\(\boldsymbol{c}(t-1)\)</span> is partially erased using a sigmoid-activated <em>forget gate</em> <span>\(\boldsymbol{f}(t)\)</span>. The new memory cell state <span>\(\boldsymbol{c}(t)\)</span> is computed by adding the current cell state update <span>\(\boldsymbol{i}(t) \odot \boldsymbol{z}(t)\)</span> to the the filtered old state <span>\(\boldsymbol{f}(t) \odot \boldsymbol{c}(t-1)\)</span>. Finally, the LSTM squashes the memory contents into a specific numerical range using the <em>memory cell activation function</em> <span>\(h(\cdot)\)</span> and filters the result through an <em>output gate</em> <span>\(\boldsymbol{o}(t)\)</span>. This results in the final <em>memory cell state activation</em> <span>\(\boldsymbol{y}(t)\)</span>.</p>
<p>Mathematically, the Vanilla LSTM can be defined by the following set of equations:</p>
<p><span>\[
\begin{align}
\boldsymbol{i}(t) &amp;= \sigma\left(\boldsymbol{W}_{i}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{i}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{o}(t) &amp;= \sigma\left(\boldsymbol{W}_{o}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{o}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{f}(t) &amp;= \sigma\left(\boldsymbol{W}_{f}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{f}^{\top} \boldsymbol{y}(t-1)\right)  \\
\boldsymbol{z}(t) &amp;= g\left(\boldsymbol{W}_{z}^{\top} \boldsymbol{x}(t)+\boldsymbol{R}_{z}^{\top} \boldsymbol{y}(t-1)\right) \\
\boldsymbol{c}(t) &amp;= \boldsymbol{f}(t) \odot \boldsymbol{c}(t-1)+\boldsymbol{i}(t) \odot \boldsymbol{z}(t) \\
\boldsymbol{y}(t) &amp;= \boldsymbol{o}(t) \odot h(\boldsymbol{c}(t))
\end{align}
\]</span></p>
<p>Where <span>\(\sigma\)</span> denotes the sigmoid activation function and <span>\(\odot\)</span> the element-wise or Hadamard product. Note that each of the gates has access to the current input <span>\(\boldsymbol{x}(t)\)</span> and the previous cell state activation <span>\(\boldsymbol{y}(t-1)\)</span>.</p>
<p>Also remember, that the weights <span>\(W\)</span> and recurrent weights <span>\(R\)</span> are shared between time steps.</p>
<div data-layout="l-body">
<div><p><span id="fig:vanilla"></span>
<img src="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/images/vanilla_lstm_legend.png" alt="Schematic of the Vanilla LSTM Cell with unrolled cell state. Figure adopted from [@Greff_2017]." width="1190"></p><p>
Figure 2: Schematic of the Vanilla LSTM Cell with unrolled cell state. Figure adopted from <span data-cites="Greff_2017">(Greff et al. <a href="#ref-Greff_2017" role="doc-biblioref">2017</a>)</span>.
</p>
</div>
</div>
<h3 id="input-activation-functions-and-the-drift-effect">Input Activation Functions and the Drift Effect</h3>
<p>In practice, the input activation function <span>\(g\)</span> is often chosen to be tanh. But this choice is non-obvious and in fact, in the original LSTM paper sigmoid was used to activate <span>\(\boldsymbol{z}\)</span>. As the memory cell’s purpose is to learn and memorise patterns over time, sigmoid activations are a natural choice to indicate the presence (activation with a value close to <span>\(1\)</span>) or absence (activation with a value close to <span>\(0\)</span>) of entities in the input. Tanh on the other hand with a lower bound of <span>\(-1\)</span> doesn’t seem to make intuitive sense. What is a negative pattern? Does an activation with value <span>\(-1\)</span> indicate that something is strongly not present in the input?</p>
<p>The adoption of tanh first required two mental shifts. First, tanh makes intuitive sense in a meta-learning setting. Instead of patterns, we now use memory cells to store the weights for another neural network. To indicate whether the values of the weights should be increased or decreased we need both positive and negative values.</p>
<p>The second intuitive interpretation is the storage of <em>hints</em>. A hint in this context is evidence in favour of or against something. Consider an example from text analysis. Assume that a model encounters the words “Team”, “Player” and “Goal” in a paragraph. These are all strong hints that the text is about sports, but if the next passage includes the words “Manager”, “Revenue” and “Shareholder” it is a strong indication that the paragraph actually describes a business context. Positive values can be seen as hints in favour of and negative values as hints against certain classes.</p>
<p>But there is a simple mathematical reason why tanh is the preferred choice to activate the cell input. Compared to commonly used activation functions such as ReLU and sigmoid the expected value of the cell input activation is zero for tanh (under the assumption of zero-mean Gaussian pre-activations):</p>
<p><span>\[\mathbb{E}(\boldsymbol{z}(t)) = 0\]</span></p>
<p>To understand why this property is desirable, remember how the cell state is updated at a given time step<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<p><span>\[\boldsymbol{c}(t) = \boldsymbol{c}(t-1)\color{#9900ff}{+\boldsymbol{i}(t) \odot \boldsymbol{z}(t)}\]</span></p>
<p>At each time step we add the cell input activation <span>\(\boldsymbol{z}(t)\)</span> (filtered by the input gate) to the previous cell state <span>\(\boldsymbol{c}(t-1)\)</span>. If we choose an activation function for <span>\(\boldsymbol{z}\)</span>, such that each activation has a value <span>\(\geq 0\)</span> (e.g.&nbsp;sigmoid, ReLU, etc.), <span>\(\boldsymbol{c}\)</span> will quickly take on very large values. Even if the activations are relatively small, the cell state will grow large for sufficiently long sequences. This problem is known as the <em>drift effect</em>.</p>
<p>But how can large memory cell states become a hindrance to learning? To answer this question, we need to take a look at the LSTM’s backward pass:</p>
<p><span>\[
\begin{aligned}
\frac{\partial L}{\partial \boldsymbol{c}(t)} &amp;=\frac{\partial L}{\partial \boldsymbol{y}(t)} \color{#9900ff}{\frac{\partial \boldsymbol{y}(t)}{\partial \boldsymbol{c}(t)}}+\frac{\partial L}{\partial \boldsymbol{c}(t+1)} \frac{\partial \boldsymbol{c}(t+1)}{\partial \boldsymbol{c}(t)} \\
&amp;=\frac{\partial L}{\partial \boldsymbol{y}(t)} \operatorname{diag}\left(\boldsymbol{o}(t) \odot \color{#9900ff}{h^{\prime}(\boldsymbol{c}(t))}\right)+\frac{\partial L}{\partial \boldsymbol{c}(t+1)}
\end{aligned}
\]</span></p>
<p>The equation recursively sums up all error signals from the future and carries them backwards in time. Intuitively, it describes the different ways in which the cell state at time <span>\(t\)</span> influences the loss <span>\(L\)</span>. We take a closer look at the highlighted term <span>\(\partial \boldsymbol{y}(t) / \partial \boldsymbol{c}(t)\)</span> , which describes how the memory cell state activation <span>\(\boldsymbol{y}(t)\)</span> changes as <span>\(\boldsymbol{c}(t)\)</span> changes. The partial derivative can be obtained by calculating <span>\(\operatorname{diag}\left(\boldsymbol{o}(t) \odot h^{\prime}(\boldsymbol{c}(t))\right)\)</span>. And now we are in trouble. Remember that we use the tanh as the memory cell activation function <span>\(h\)</span> to squash the memory cell state into the numerical range <span>\((-1, 1)\)</span>. Its derivative is defined as follows:</p>
<p><span>\[
h^{\prime}(\boldsymbol{x}) = \text{tanh}^{\prime}(\boldsymbol{\boldsymbol{x}}) = 1 - \text{tanh}²(\boldsymbol{x})
\]</span></p>
<p>Now if <span>\(\boldsymbol{c}(t)\)</span> grows very large due to the drift effect, the highlighted term in the second equation will evaluate to <span>\(h^{\prime}(\boldsymbol{c}(t)) = 1-1 = 0\)</span> for each element in <span>\(\boldsymbol{c}(t)\)</span>. As a result, <span>\(\frac{\partial L}{\partial y(t)} \frac{\partial y(t)}{\partial c(t)}\)</span> will be zero and the cell state loses its ability to influence …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/">https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/</a></em></p>]]>
            </description>
            <link>https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445617</guid>
            <pubDate>Fri, 11 Sep 2020 18:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arbol, a parametric weather risk platform built on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24445508">thread link</a>) | @jschilling
<br/>
September 11, 2020 | https://docs.ipfs.io/concepts/case-study-arbol/ | <a href="https://web.archive.org/web/*/https://docs.ipfs.io/concepts/case-study-arbol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-4f5abb4a=""> <div><p><strong>"When it comes to data security versus ease of access, it's usually a trade-off. The fact that IPFS doesn't compromise on either is awesome — and it feels great to ditch Amazon S3 buckets for open source."</strong></p> <p><em>— Ben Andre, CTO, Arbol</em></p></div> <h2 id="overview"><a href="#overview">#</a> Overview</h2> <p><img src="https://docs.ipfs.io/assets/img/logo-arbol.e1ca2350.svg" alt="Arbol logo" width="220"></p> <p><a href="https://www.arbolmarket.com/" target="_blank" rel="noopener noreferrer">Arbol</a> is a software platform that connects agricultural entities like farmers and other weather-dependent parties with investors and other capital providers to insure and protect against weather-related risks. Arbol's platform sells contracts for parametric weather protection agreements in a marketplace that's an innovative, data-driven approach to risk management, cutting out the usual legacy insurance claims process of making loss assessments on the ground. Instead, Arbol relies on tamper-proof data indexes to determine payouts, and doesn't require a defined loss to be indemnified. Arbol's platform combines parametric weather protection with blockchain-based smart contracts to provide cost-efficient, automated, and user-defined weather-related risk hedging. As with traditional crop insurance and similar legacy products, end users purchase assurance that they'll be financially protected in the case of adverse weather — but with Arbol, these end users are paid automatically if adverse conditions occur, as defined by the contract and measured by local meteorological observations tracked by Arbol's data sources.</p> <p>To build the data indexes that Arbol uses to handle its contracts, the team aggregates and standardizes billions of data files comprising decades of weather information from a wide range of reputable sources — all of which is stored on IPFS. IPFS is critical to Arbol's service model due to the inherent verifiability provided by its <a href="https://docs.ipfs.io/concepts/content-addressing">content-addressed architecture</a>, as well as a decentralized data delivery model that facilitates Arbol's day-to-day aggregation, synchronization, and distribution of massive amounts of data.</p> <p>While United States agribusiness has been Arbol's initial area of focus, the team has built a globally capable platform, with expansion underway to new regions and industries around the world. Arbol currently provides contracts for managing the risks of weather exposure in the energy and agriculture sectors, and features both custom and pre-designed protection agreements for clients across industries and scale. Their current end-user base ranges from small coffee farms to major agribusinesses and power producers.</p> <p>In short, Arbol's platform is a risk marketplace where end users can get competitively priced risk management solutions and capital providers can benefit from access to a lucrative, but underdeveloped, weather risk market. And because Arbol uses IPFS for its data storage and delivery needs, end users and underwriting partners can be certain that the data Arbol uses to determine price and payouts for contracts is tamper-proof and trustworthy.</p> <h3 id="arbol-by-the-numbers"><a href="#arbol-by-the-numbers">#</a> Arbol by the numbers</h3> <div><div><p>1T</p> <p>weather-related data points hosted on IPFS</p></div><div><p>1M</p> <p>hashes generated on Arbol data every day</p></div><div><p>40</p> <p>years of high-resolution climate data</p></div><div><p>200GB</p> <p>average Arbol dataset size</p></div></div> <h2 id="the-story"><a href="#the-story">#</a> The story</h2> <p>Arbol's story begins with the commodities markets, where Siddhartha Jha, the founder and CEO, worked as a quantitative analyst and portfolio manager. What Jha saw there was a problem without a solution: Massive (and growing) demand for weather risk management for supply chains, farming industries, and the energy sector, but no viable, efficient, or cost-effective weather risk market to meet that demand. Traditional crop insurance was plagued by inefficiencies and high cost ceilings, with insurance providers forced to charge high premiums that only large corporations could afford. And while more efficient parametric insurance solutions were available on the market, even these data-driven options were often saddled with high overhead and bureaucratic waste. As a result, small businesses and local farmers were often trapped without access to protection from weather-related risks.</p> <p>Arbol aims to change that by bringing fundamental transparency, efficiency, and data-driven objectivity to the weather risk market, ensuring that any business of any size can get the appropriate protection they need to manage their level of weather-related risk. The Arbol platform achieves this goal by providing a novel mechanism for weather-exposed businesses to connect with capital providers. The key to Arbol's approach is flexible financial derivatives that leverage the power of big data and machine learning to provide parametric risk protection at low cost. These parametric structures determine automatic payouts based on metrics that are strongly correlated with financial loss.</p> <p>With Arbol, an end user pays to hedge against a specific weather-related event, such as yearly deviation in rainfall amounts or temperature. After deciding on a premium and selecting a payout amount, the end user then relies on Arbol's platform to handle the rest. Because parametric structures are objective and data-driven, they can achieve a level of precision, reliability, and cost effectiveness that traditional insurance cannot. In fact, one of Arbol's key benefits over legacy weather insurance is that it allows for hyper-local protection for managing user-specific levels of risk.</p> <p>Arbol's approach also improves upon standard parametric insurance by combining parametric insurance's precision and flexibility with the security, transparency, and efficiency of blockchain. Many of Arbol's protection agreement contracts are executed as smart contracts on the Ethereum blockchain. These smart contracts automatically deliver payouts to end users as soon as a relevant adverse weather event occurs.</p> <p>Delivering weather risk management solutions through blockchain-based contracts like this eliminates costly payout delays, as well as risks associated with fraud, corruption, and bureaucratic overhead. It also brings the benefits of peer-to-peer decentralization: Arbol users don't need to rely on Arbol as a financial middleman, because funds are locked between end users and capital providers without Arbol controlling the transfer of funds.</p> <p>However, even the best smart contract is only as smart as the data it draws from. The "oracle problem" can be a foundational obstacle for smart contracts — but Arbol's use of IPFS eliminates this risk. Because a smart contract automatically and trustlessly executes based on data, it doesn't matter how secure, transparent, and publicly verifiable its use of blockchain is. Without an accurate, trustworth, and immutable data "oracle", even blockchain-based smart contracts can be easily biased, compromised, or manipulated. For Arbol, that's where IPFS is absolutely critical.</p> <p>IPFS's content-addressed architecture enables Arbol to ensure the integrity and public verifiability of its datasets, something that traditional location addressing using centralized server architecture cannot provide. Smart contracts pointing to specific, immutable IPFS CIDs, rather than to data locations that could be tampered with, can be relied upon thanks to the integrity of their oracle.</p> <div><p><strong>"IPFS is very much at the heart of everything we do at Arbol. IPFS serves as our independently verifiable data store for all of the weather data associated with the contracts we sell. It imbues our platform with the essential principles of decentralization, data security, and public verifiability."</strong></p> <p><em>— Ben Andre, CTO, Arbol</em></p></div> <p>Arbol builds its data indexes by drawing on large weather-related datasets from a variety of trusted public and private sources, including prominent U.S. government institutions such as NASA and the National Oceanic and Atmospheric Administration (NOAA). These sources track weather data including yearly rainfall amounts, temperature fluctuations, wind speeds, and more. However, while much of the data Arbol uses is publicly available, it isn't always easily usable; much of the data, particularly deeper historical records, is stored in outdated formats, and very little of it is organized into an easily readable structure. Arbol's data indexes process, correlate, and package this data so that it is readily available for use in the weather risk market. And by putting that data onto IPFS, Arbol also ensures that it has a verifiable, tamper-resistant, and decentralized home.</p> <h2 id="ipfs-benefits"><a href="#ipfs-benefits">#</a> IPFS benefits</h2> <p>Arbol's business model hinges upon the benefits afforded by IPFS — without its immutable content addressing and inherent data verifiability, the benefits Arbol provides would be impossible to achieve in a cost-effective and efficient way. As a whole, IPFS is critical to Arbol's service model by providing the following:</p> <ul><li><p><strong>Immutable addressing:</strong> Because all data stored using IPFS is referenced and accessed via unique <a href="https://docs.ipfs.io/concepts/content-addressing">content identifiers (CIDs)</a>, any change to a data item means it receives a new CID exclusive to that revision. It's impossible to change data without changing its CID.</p></li> <li><p><strong>Data verifiability:</strong> Contracts on Arbol's platform are linked to specific, verifiably unchanged, content-addressed data. Because parametric weather risk management absolutely relies on user agreement about and trust in source data, Arbol's approach offers reassurance unavailable with other offerings in the market.</p></li> <li><p><strong>Decentralized data delivery:</strong> Arbol works with massive datasets comprising billions of files and terabytes of information. IPFS accommodates Arbol's methodology for publishing and adding to large datasets while still enabling Arbol to release and synchronize these datasets via a decentralized storage network.</p></li></ul> <h2 id="how-arbol-uses-ipfs"><a href="#how-arbol-uses-ipfs">#</a> How Arbol uses IPFS</h2> <p>Arbol's end users enjoy the "it just works" benefits of parametric protection, but a lot goes on behind the scenes to enable this data-driven solution. Arbol's weather datasets range from 1GB to 1TB in size, and each one goes through a detailed ingestion process before it can be used. Once it has been decided that a dataset meets Arbol's criteria for usefulness and validity, it is time to add it to Arbol's IPFS pipeline, a multi-stage process outlined below.</p> <ol><li><p><strong>Query/release:</strong> If a …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.ipfs.io/concepts/case-study-arbol/">https://docs.ipfs.io/concepts/case-study-arbol/</a></em></p>]]>
            </description>
            <link>https://docs.ipfs.io/concepts/case-study-arbol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445508</guid>
            <pubDate>Fri, 11 Sep 2020 18:03:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Million-Dollar, One-Person Businesses]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24445220">thread link</a>) | @jger15
<br/>
September 11, 2020 | https://trends.vc/trends-0027-million-dollar-one-person-businesses/ | <a href="https://web.archive.org/web/*/https://trends.vc/trends-0027-million-dollar-one-person-businesses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper">
<div id="content">
<div id="primary">
<main id="main" role="main">
<article id="post-17653" class="page">

<div>
<div><figure><img src="https://trends.vc/wp-content/uploads/2020/08/7-069ffa62548f-1.gif" alt=""></figure></div>
<h2>🔍 Problem</h2>
<p><em>“Build your own dreams, or someone else will hire you to build theirs.”</em></p>
<p>You want <strong>freedom</strong> and <strong>equity</strong>. </p>
<p>You’re willing to work hard. But on your terms.</p>
<h2>💡 Solution</h2>
<p><strong>Leverage</strong>. </p>
<p><em>What do you mean?</em></p>
<figure><table><tbody><tr><td>One-To-Many Channels</td><td><a href="https://www.siteground.com/tutorials/email/protocols-pop3-smtp-imap/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Email</a>, <a href="https://en.wikipedia.org/wiki/Podcast" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Podcasts</a>, <a href="https://www.cloudflare.com/learning/network-layer/internet-protocol/#:~:text=The%20Internet%20Protocol%20(IP)%20is%20a%20protocol%2C%20or%20set,arrive%20at%20the%20correct%20destination.&amp;text=IP%20information%20is%20attached%20to,packets%20to%20the%20right%20place." target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Blogs</a></td></tr><tr><td>Social Networks </td><td><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Twitter</a>, <a href="https://www.youtube.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">YouTube</a>, <a href="https://www.instagram.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Instagram</a></td></tr><tr><td>Paid Demand</td><td><a href="https://ads.google.com/home/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Google Ads</a>, <a href="https://www.facebook.com/business/ads" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Facebook Ads</a>, <a href="https://www.reddit.com/adsregister" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Reddit Ads</a></td></tr><tr><td>Membership Platforms </td><td><a href="https://www.patreon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Patreon</a>, <a href="https://onlyfans.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">OnlyFans</a>, <a href="https://substack.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Substack</a></td></tr><tr><td>Productized Services</td><td><a href="https://www.manypixels.co/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">ManyPixels</a>, <a href="https://beanninjas.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Bean Ninjas</a>, <a href="https://www.trycatalog.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Catalog</a></td></tr><tr><td>Marketplaces</td><td><a href="https://www.amazon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Amazon</a>, <a href="https://www.etsy.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Etsy</a>, <a href="https://gumroad.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Gumroad</a></td></tr><tr><td>On-Demand Computing</td><td><a href="https://aws.amazon.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">AWS</a>, <a href="https://www.heroku.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Heroku</a>, <a href="https://www.netlify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Netlify</a></td></tr><tr><td>No-Code Tools </td><td><a href="https://www.shopify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Shopify</a>, <a href="https://mailchimp.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Mailchimp</a>, <a href="https://wordpress.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">WordPress</a></td></tr><tr><td>On-Demand Manufacturing</td><td><a href="https://printify.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Printify</a>, <a href="https://www.shapeways.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Shapeways</a>, <a href="https://www.printful.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Printful</a></td></tr><tr><td>Open Source</td><td><a href="https://rubyonrails.org/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Ruby on Rails</a>, <a href="https://laravel.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Laravel</a>, <a href="https://reactjs.org/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">React</a></td></tr><tr><td>APIs</td><td><a href="https://stripe.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Stripe</a>, <a href="https://www.twilio.com/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Twilio</a>, <a href="https://plaid.com/uk/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Plaid</a></td></tr></tbody></table></figure>
<p>These power <strong>million-dollar, one-person businesses</strong>.</p>
<p>Code, distribution and manufacturing are being <strong>commoditized</strong>. </p>
<p>Build wealth by focusing on what’s scarce.</p>
<h2>📘 Terms</h2>
<p><strong>Million-Dollar Business</strong></p>
<p>Forget revenue.</p>
<p>Ask: “<em>What would the business sell for?</em>“</p>
<p>Use <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.thehartford.com/business-insurance/strategy/selling-a-business/determining-market-value" target="_blank">earnings multiples or discounted cash flows</a>. </p>
<p><strong>One-Person Business</strong></p>
<p>Operated by <strong>one person</strong> <em>or</em> built on a <strong>personal brand</strong>.</p>
<h2>🏁 Players</h2>
<p><strong>People</strong></p>
<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://affordanything.com/" target="_blank">Paula&nbsp;Pant</a> </li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/the-indie-hackers/098-how-to-make-25mm-as-a-FEX5hGsMQ9T/" target="_blank">Adam Wathan</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.forrestfunnell.com/" target="_blank">Forrest Funnell</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/jackbutcher" target="_blank">Jack Butcher</a></li><li><a rel="noreferrer noopener" href="https://www.forbes.com/sites/elainepofeldt/2019/06/30/how-one-student-launched-a-million-dollar-one-woman-bikini-empire/#1da781506814" target="_blank">Ana Gavia</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/vikdug" target="_blank">Vik Duggal</a></li><li><a rel="noreferrer noopener" href="https://levels.io/" target="_blank">Pieter Levels</a></li><li><a rel="noreferrer noopener" href="https://backlinko.com/" target="_blank">Brian Dean</a></li><li><a rel="noreferrer noopener" href="https://jamesclear.com/" target="_blank">James Clear</a></li></ul>
<p><strong>Businesses</strong></p>
<ul><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://readwrite.com/2007/10/29/plentyoffish_one_billion/" target="_blank">PlentyOfFish</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.marketwatch.com/story/3-resolutions-to-transform-your-1-person-business-into-a-1-million-operation-2018-01-02#:~:text=Allen%20Walton%2C%20who%20built%20his,steps%20in%20the%20shipping%20process." target="_blank">Spy Guy</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://closet.tools/" target="_blank">Closet Tools</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://stratechery.com/" target="_blank">Stratechery</a></li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://seothatworks.com/" target="_blank">Backlinko</a></li><li><a rel="noreferrer noopener" href="https://shop.visualizevalue.com/" target="_blank">Visualize Value</a></li><li><a rel="noreferrer noopener" href="https://en.m.wikipedia.org/wiki/The_Million_Dollar_Homepage" target="_blank">The Million Dollar Homepage</a></li><li><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Silk_Road_(marketplace)" target="_blank">Silk Road</a></li><li><a rel="noreferrer noopener" href="https://park.io/" target="_blank">Park.io</a></li></ul>
<h2>🔮 Predictions</h2>
<ul><li>Services like <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.printful.com/" target="_blank">Printful</a> will <strong>commoditize manufacturing</strong>. Kylie Cosmetics reached <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.forbes.com/sites/natalierobehmed/2019/03/05/at-21-kylie-jenner-becomes-the-youngest-self-made-billionaire-ever/#20049c8d2794" target="_blank">$1 billion</a> with 7 employees using <a rel="noreferrer noopener" href="https://www.instyle.com/news/secret-company-behind-kkw-beauty-and-kylie-cosmetics" target="_blank">SEED Beauty</a>. Most <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://sell.amazon.com/fulfillment-by-amazon.html" target="_blank">FBA</a> sellers slap labels on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.alibaba.com/Apparel_p3?spm=a2700.9161164.2.1.15924e02eeUOHq" target="_blank">generic products</a>. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oberlo.com/" target="_blank">Oberlo</a> takes this further.</li><li>Growth and product skills will<strong> remain valuable</strong>. These are areas of innovation. Unlike accounting.<em> Unless you’re Enron. </em></li></ul>
<h2>☁️ Opportunities</h2>
<ul><li>Develop <strong>high-leverage skills</strong>. Invest, write, entertain, code, sell, market, design. </li><li>Start with <strong>services</strong> to find valuable problems. As a consultant, <a rel="noreferrer noopener" href="https://twitter.com/tylertringas" target="_blank">Tyler Tringas</a> had several clients ask for store locators. He built <a rel="noreferrer noopener" href="https://www.storemapper.com/" target="_blank">Storemapper</a>, sold the business and launched <a rel="noreferrer noopener" href="https://earnestcapital.com/" target="_blank">Earnest Capital</a>. </li><li>Automate, outsource or delegate <strong>non-core</strong> <strong>competencies</strong>. Focus on what’s scarce. As <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/ljin18" target="_blank">Li Jin</a> says, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://a16z.com/2019/10/08/passion-economy/" target="_blank">monetize your individuality</a>. </li><li><strong>Show</strong> your work. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/dr/status/1291054987976482817?s=20" target="_blank">Dan Rowden</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/diannamallen/status/1292861382459883520?s=20" target="_blank">Dianna Allen</a> and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/levelsio/status/1290068006484099072?s=20" target="_blank">Pieter Levels</a> share progress as they build. Stay top of mind with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://trends.vc/trends-0015-open-startups/" target="_blank">exhaust data</a>. </li><li>Build a <strong>personal brand </strong>like <a rel="noreferrer noopener" href="https://twitter.com/AffordAnything" target="_blank">Paula Pant</a>, <a rel="noreferrer noopener" href="https://twitter.com/PatFlynn" target="_blank">Pat Flynn</a> or <a rel="noreferrer noopener" href="https://www.sethgodin.com/" target="_blank">Seth Godin</a>. Finding problems, validating products and acquiring customers will be easier.</li></ul>
<h2>🔑 Key Lessons</h2>
<ul><li>Don’t be the best. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://www.game-changer.net/2014/09/15/dont-be-the-best-be-the-only-one/#.Xy9J3hNKh-U" target="_blank">Be the only.</a> There are no <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Comparables" target="_blank">comparables</a> in a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://seths.blog/2013/09/category-of-one-is-a-choice/" target="_blank">category of one</a>. <a rel="noreferrer noopener" href="https://stratechery.com/about/" target="_blank">Ben Thompson</a>, <a rel="noreferrer noopener" href="https://tim.blog/" target="_blank">Tim Ferriss </a>and <a rel="noreferrer noopener" href="http://podcasts.joerogan.net/" target="_blank">Joe Rogan</a> have <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/tylertringas/status/1291352314029252609?s=20" target="_blank">micro-monopolies</a>. </li><li><strong>Niche</strong>. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/how-i-built-it/the-importance-of-niching-o8rmWDfh3P2/" target="_blank">Sarah Dunn</a> does SEO for wedding professionals. <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.listennotes.com/podcasts/the-resilient/habits-of-a-million-dollar-F3f-bEBKSue/" target="_blank">Rich Rosen</a> only recruits for 3 types of roles. Use small to your advantage. </li></ul>
<h2>😠 Haters</h2>
<p><em>“Million-dollar, one-person businesses can’t be sold.”</em><br>Have you seen <a href="https://park.io/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Park.io</a>, <a href="https://closet.tools/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Closet Tools</a> or <a href="https://overcast.fm/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Overcast</a>?</p>
<p><em>“How do you value an <strong>unsellable</strong>, service business?”</em><br>You don’t. But for this report, look at single-year net income. </p>
<p><em>“Storemapper had employees.” </em><br>The point of that example was to show you how to use <a rel="noreferrer noopener" href="https://nathanbarry.com/wealth-creation/" target="_blank">Nathan’s ladder</a>. Or <a rel="noreferrer noopener" href="https://robwalling.com/2015/03/26/the-stairstep-approach-to-bootstrapping/" target="_blank">Rob’s stairs</a>.&nbsp;</p>
<p><em>“Code, distribution and manufacturing <strong>will</strong> <strong>not</strong> be commoditized.”<br>All</em> code, distribution and manufacturing will not be. Apple and Tesla are vertically integrated. If it’s a core competency, keep it in-house. <a rel="noreferrer noopener" aria-label="Otherwise outsource (opens in a new tab)" href="https://www.econlib.org/library/Topics/Details/comparativeadvantage.html" target="_blank">Otherwise outsource</a>. </p>
<p><em>“I have one million in <strong>revenue</strong>, so I have a million-dollar business.”</em><br>If you buy $2,000,000 worth of iPhones and sell them for $1,000,000. You also have $1m in revenue. As Lauryn Hill says, “…&nbsp;it ain’t what you cop, it’s about what you keep.”</p>
<p><em>“Some of these people have<strong> teams</strong>.</em>“<br>Joe Rogan and Tim Ferris have teams but they’ve built businesses on <a href="https://trends.vc/trends-0023-personal-brands/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">personal brands</a>. Pieter Levels has a <a href="https://twitter.com/levelsio/status/1105345282873581568?s=20" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">sysadmin</a>. <a href="https://stratechery.com/about/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Ben Thompson</a> has an assistant. <a href="https://twitter.com/elainepofeldt" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">Elaine Pofeldt</a> addresses this in her <a href="https://www.goodreads.com/book/show/34915571-the-million-dollar-one-person-business" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">book</a>. Most million-dollar, one-person businesses <a href="https://indypendently.com/grow/what-do-million-dollar-one-person-businesses-have-in-common" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">get help</a>. </p>
<p><em>“Screw this. I love my <strong>job</strong>.”</em><br>That’s all that matters. </p>
<h2>🔗 Links</h2>
<ol><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/DruRly/status/1290726540607664129?s=20" target="_blank">Looking for million-dollar, one-person businesses. Know any?</a> — The thread that started this report. </li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://nav.al/product-media" target="_blank">Product and Media are New Leverage</a> — <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/naval" target="_blank">Naval</a> talks about the role of zero marginal cost products in building wealth.</li><li><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://stewfortier.com/why-you-should-share-your-ideas-online/#one-person-media-companies" target="_blank">One-Person Media Companies</a> — <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/stewfortier" target="_blank">Stew Fortier</a> on why you should share ideas online and how one-person media companies make money. </li></ol>



<hr>
<h3>More Trends</h3>
<ul><li>👥<strong> <a href="https://trends.vc/trends-0030-audience-first-products/">Trends #0030 — Audience-First Products</a></strong></li><li><strong>⚙️ <a href="https://trends.vc/trends-0029-lead-generation/">Trends #0029 — Lead Generation</a></strong></li><li>📦&nbsp; <a href="https://trends.vc/trends-0028-subscription-dtc/"><strong>Trends #0028 — Subscription DTC</strong></a></li><li>🤑&nbsp;<strong><a href="https://trends.vc/trends-0027-million-dollar-one-person-businesses/">Trends #0027 — Million-Dollar, One-Person Businesses</a></strong></li><li>📍&nbsp;<strong><a href="https://trends.vc/trends-0026-drop/">Trends #0026 — Drop Culture</a></strong></li><li>📣&nbsp;<strong><a href="https://trends.vc/trends-0025-referral-programs/">Trends #0025 — Referral Programs</a></strong></li><li>🏟️<strong>&nbsp;<a href="https://trends.vc/trends-0024-equity-crowdfunding/">Trends #0024 — Equity Crowdfunding</a></strong></li><li>🤩&nbsp;<strong><a href="https://trends.vc/trends-0023-personal-brands/">Trends #0023 — Personal Brands</a></strong></li><li>💻&nbsp;<a href="https://trends.vc/trends-0022-digital-products/"><strong>Trends #0022 — Digital Products</strong></a></li><li>🕹️ <strong><a href="https://trends.vc/trends-0021-gamification/">Trends #0021 — Gamification</a></strong></li><li>🙏<strong>&nbsp;<a href="https://trends.vc/trends-0020-b-corps/">Trends #0020 — B Corps</a></strong></li><li><strong>🥾&nbsp;<a href="https://trends.vc/trends-0019-bootstrap-funds/">Trends #0019 — Bootstrap Funds</a></strong></li><li>😇<strong>&nbsp;<a href="https://trends.vc/trends-0018-angel-investing/">Trends #0018 — Angel Investing</a></strong></li><li><strong>🛠️&nbsp;<a href="https://trends.vc/trends-0017-xaas-anything-as-a-service/">Trends #0017 — XaaS: Anything as a Service</a></strong></li><li><strong><a href="https://trends.vc/trends-0016-growth-tools/">🧰&nbsp;Trends #0016 — Growth Tools</a></strong></li><li><strong>📖&nbsp;<a href="https://trends.vc/trends-0015-open-startups/">Trends #0015 — Open Startups</a></strong></li><li>💬 <strong><a href="https://trends.vc/trends-0014-paid-communities/">Trends #0014 — Paid Communities</a></strong></li><li>🍎 <strong><a href="https://trends.vc/trends-0013-online-courses/">Trends #0013 — Online Courses</a></strong></li><li>💰 <strong><a href="https://trends.vc/trends-0012-micro-private-equity/">Trends #0012 — Micro Private Equity</a></strong></li><li>💌<strong>&nbsp;<a href="https://trends.vc/trends-0011-paid-newsletters/">Trends #0011 — Paid Newsletters</a></strong></li><li><strong>🦄 <a href="https://trends.vc/trends-0010-startup-studios/">Trends #0010 — Startup Studios</a></strong></li><li>🌐 <strong>&nbsp;<a href="https://trends.vc/trends-0009-virtual-meetups/">Trends #0009 — Virtual Meetups</a></strong></li><li>🏋️<strong>&nbsp;<a href="https://trends.vc/trends-0008-remote-fitness/">Trends #0008 — Remote Fitness</a></strong></li><li>🦠 <strong><a href="https://trends.vc/trends-0007-coronavirus-covid-19/">Trends #0007 — Coronavirus (COVID-19)</a></strong></li><li>🧱 <strong><a href="https://trends.vc/trends-0006-no-code/">Trends #0006 — No Code</a></strong></li><li>🥾&nbsp;<strong><a href="https://trends.vc/trends-0005-bootstrap-funds/">Trends #0005 — Bootstrap Funds</a></strong></li><li>💸&nbsp;<strong><a href="https://trends.vc/trends-0004-income-share-agreements/">Trends #0004 — Income Share Agreements</a></strong></li><li>🏠&nbsp;<strong><a href="https://trends.vc/trends-0003-co-living/">Trends #0003 — Co-Living</a></strong></li><li>🎙️&nbsp;<strong><a href="https://trends.vc/trends-0002-podcast-memberships/">Trends #0002 — Podcast Memberships</a></strong></li><li>🍳 <strong><a href="https://trends.vc/trends-issue-0001-cloud-kitchens/">Trends #0001 — Cloud Kitchens</a></strong></li></ul>

<p><strong>📈 <a href="https://trends.vc/" target="_blank" rel="noreferrer noopener" aria-label="Get weekly reports (opens in a new tab)">Get weekly reports</a></strong></p>

</div>
</article>
</main>
</div>
</div>

</div></div>]]>
            </description>
            <link>https://trends.vc/trends-0027-million-dollar-one-person-businesses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445220</guid>
            <pubDate>Fri, 11 Sep 2020 17:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Ideas for Inspiration]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24445058">thread link</a>) | @cameron_b
<br/>
September 11, 2020 | https://blog.pixelswithin.com/startup-ideas-for-inspiration | <a href="https://web.archive.org/web/*/https://blog.pixelswithin.com/startup-ideas-for-inspiration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<div>
  
<p>If you know me, you know I am an idea machine when it comes to fun side projects. Here is a growing collection of all the ideas I’ve had for startups and other ventures. Feel free to take one and run with it! Email me if you do, I’d love to hear about it.</p>
<blockquote data-conversation="none"><p lang="en" dir="ltr">Ok. What about a blog that launches 1 year from today? Various writers assign themselves self-development books and just before launch they write about how their book has impacted their lives in the last year..</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1166118325362888704?ref_src=twsrc%5Etfw">August 26, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Book playlists 🤔</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1163926092169662465?ref_src=twsrc%5Etfw">August 20, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">I have an idea. An app for cutting down impulse spending. You set a budget, track your impulses, etc.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1155683694075473920?ref_src=twsrc%5Etfw">July 29, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">I wanna make a .tv website, for like a women in rap VJ thing with YouTube embeds. I'm not going to.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1154832435445547008?ref_src=twsrc%5Etfw">July 26, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea (something I’d like to see): a series of checklists for everything needed on any page of any website. Home, Pricing, About, etc pages.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1150643032523333632?ref_src=twsrc%5Etfw">July 15, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: an AI diary. Conversational, talks back.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1139248242661584896?ref_src=twsrc%5Etfw">June 13, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">50% of an idea: a Twitter account anyone can post to, via a website with safeguards against abuse, like blocking the “@“ character, authentication, and only allowing one tweet per twit per day. That’s the mechanism, trying to think of a concept.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1136103551028027392?ref_src=twsrc%5Etfw">June 5, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea! An app for people to hold each other accountable to goals by hosting regular "lotteries." Use the Acorns API to collect round-up investments (you spend $2.19 at the store, the app takes $0.81 to round out to a $3 charge). Only the ones who met their goal are entered to win.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1134651648838475776?ref_src=twsrc%5Etfw">June 1, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: a weather app, but instead of the weather it's the emotional climate based on sentiment analysis of your Twitter feed.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1134645334066384896?ref_src=twsrc%5Etfw">June 1, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea! 🤔 What about customizable posters for forming habits? With 3 months of calendar space to X out days of. <a href="https://t.co/MvkVdSGGTq">pic.twitter.com/MvkVdSGGTq</a></p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1114924426137456642?ref_src=twsrc%5Etfw">April 7, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">Free idea: a forum API. Creating a community on your own website shouldn't be as hard as it is right now.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1106627433573158912?ref_src=twsrc%5Etfw">March 15, 2019</a></blockquote>


<blockquote><p lang="en" dir="ltr">app idea 👇🏼 <a href="https://t.co/yC0D3Jwi7n">https://t.co/yC0D3Jwi7n</a></p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1075097162730528769?ref_src=twsrc%5Etfw">December 18, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">app idea (pls take!!!) — create typopgraphic gifs</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1070978101239136258?ref_src=twsrc%5Etfw">December 7, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">IDEA: anarchist video games. Like start the people’s revolution, illegalism, break animals out of a lab, different levels of staging protests, etc etc. Pls, we need the training!</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/1012471453659234305?ref_src=twsrc%5Etfw">June 28, 2018</a></blockquote>


<blockquote><p lang="en" dir="ltr">idea: a tumblr with thought experiments for anxiety... they sure help me</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/811298468971089920?ref_src=twsrc%5Etfw">December 20, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">idea: a subscription box for coffee recipes. you get the beans + a fancy recipe + the stuff to make the mintmochafrappelata or whatever!</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/807371501301137408?ref_src=twsrc%5Etfw">December 9, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">hm IDEA: blinders for human beans. for focus.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/799980544784109568?ref_src=twsrc%5Etfw">November 19, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">Sister, giving me app ideas: "We have a lot of communication apps. Do we have enough stay-away-from-me apps?"</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/685016694402617344?ref_src=twsrc%5Etfw">January 7, 2016</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea for Google Maps: a setting where the destination ALWAYS ends up on the right side</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/679476573490135043?ref_src=twsrc%5Etfw">December 23, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">Idea: a relatively softer or muted version of your text notification sound, for messages that are just confirmations of receipt.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/643260554908332032?ref_src=twsrc%5Etfw">September 14, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">Good ideas are impressive even in low-fidelity.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/636251856298078208?ref_src=twsrc%5Etfw">August 25, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">"Stop looking at yourself as a designer, and start thinking of yourself as a deliverer of ideas." ~Ståle Melvær</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/634884067960426496?ref_src=twsrc%5Etfw">August 22, 2015</a></blockquote>


<blockquote><p lang="en" dir="ltr">i love ideas. i get carried away with ideas. i get high off ideas.</p>— Diana Lopez (@internetgrlfren) <a href="https://twitter.com/internetgrlfren/status/939974857013338112?ref_src=twsrc%5Etfw">December 10, 2017</a></blockquote>




<div id="mlb2-1413518">
<div>
<div>
<div>
<div>
<h4><span>
🎉</span> The end of the post!
</h4>
<p>
Thanks for reading. Ever wonder how effective website design happens? Enter your email to join the weekly newsletter that explores this question.
</p>
</div>

</div>

</div>
</div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1413518/g1f8t1?vd890ed88b3a28c805acc70e1a88fa27c" width="1" height="1"></p>
<p><img src="https://blotcdn.com/blog_a19b4b16eb8f413ab70f54145e0e22d6/_image_cache/_image_cache/5a2e65c1-8d54-45f4-9ad0-390945a77183.png" alt="me" width="1822" height="908"></p>
<p>Hi, I’m Diana Lopez! I’m a freelance web designer and developer who works with startups and small businesses. I create memorable &amp; effective websites and brand identities. Interested in learning more? See my portfolio at <a href="https://pixelswithin.com/" target="_blank">pixelswithin.com →</a></p>
</div>

</div></div>]]>
            </description>
            <link>https://blog.pixelswithin.com/startup-ideas-for-inspiration</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445058</guid>
            <pubDate>Fri, 11 Sep 2020 17:23:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Statistical Significance: A Practical Introduction]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24444577">thread link</a>) | @R3G1R
<br/>
September 11, 2020 | https://mathvault.ca/statistical-significance/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/statistical-significance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/Statistical-Significance.jpg" alt="A Primer on Statistical Significance" width="800" height="480" title="Statistical Significance"></figure><p><strong>Statistical significance</strong>, in a nutshell, is a way of determining the degree of unlikely-ness of an experimental result — when a certain status quo hypothesis is assumed to be true.<span id="more-9087"></span></p><p>For example, let’s say that a school had two teachers, each with approximately $30$ students in their class. Both classes take a standardized test, and it turns out that the average score in class A was $5\%$ better than the average in class B.&nbsp; Statistical significance — in this regard — would be our way of determining whether the better score in class A could be attributed to <em>random chance</em>, for instance:</p><ul><li>It was a lucky day for class A.</li><li>Class A just randomly got assigned better prepared students.</li></ul><p>Or whether there is some other factor responsible for the difference in grades between the classes,&nbsp;for instance:</p><ul><li>Teacher A did a better job of teaching than teacher B.</li><li>Teacher A cheated a bit and gave the students some answers ahead of time.</li><li>The classes were purposely split up (e.g., more advanced students or native speakers of a language were put into class A).</li></ul><p>Note that in this case, we wouldn’t — using <em>only</em> the information on the scores at least — attempt to decide what the exact reason for the different scores was. Instead, we would just determine if the score difference could be attributed to pure chance, or that it is so unlikely that there might be some other factors involved.</p><h2 id="start"><span id="Getting_Started"></span><a href="#toc">Getting Started</a><span></span></h2><p>There are two important things when calculating statistical significance. The first is the <strong>magnitude of difference</strong> between what you are measuring and what you are comparing against. The second is the amount of <strong>natural variation</strong> in what you are measuring.</p><p>The first concept, magnitude of difference, is easy to understand. Let’s say that you are a farmer growing pumpkins and trying out new fertilizers. You have a <strong>baseline average</strong> pumpkin weight, which is an average of $10$ lbs. You also have pumpkins from two different fertilizers&nbsp;—A and B&nbsp;— that you are testing out.</p><p>If fertilizer A makes pumpkins that weigh $11$ lbs. on average, then it is possible that the $1$ lbs. difference relative to the baseline $10$ lbs. is <em>caused</em> by the fertilizer. However, if fertilizer B produces $25$ lbs. pumpkins on average, then that $15$ lbs. difference ($25-10$) is more likely to be a result of fertilizer B — than the $1$ lbs. difference was to be a result of fertilizer A.</p><h2 id="sse"><span id="Looking_at_the_Statistical_Significance_Equation"></span><a href="#toc">Looking at the Statistical Significance Equation</a><span></span></h2><p>The most commonly used statistical significance test is probably the <a href="https://en.wikipedia.org/wiki/Z-test" target="_blank" rel="noopener noreferrer"><strong>Z-test</strong></a>. The equation for the Z-test is:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS1.png" alt="Z-Test Statistics" width="668" height="348" title="SS1"></figure><p>In a nutshell, the Z-Test equation calculates the <em>ratio</em> of two quantities: the numerator on the top, and the denominator at the bottom. Let’s take a look at them individually.</p><h3 id="num"><span id="Numerator"></span><a href="#toc">Numerator</a><span></span></h3><p>The <em>numerator</em> of the equation is where the <strong>magnitude of difference</strong> is accounted for:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS2.png" alt="Difference Between Sample Mean and Population Mean" width="400" height="127" title="SS2"></figure><p>Here, $\bar{x}$ stands for the&nbsp;<strong>measured average value</strong> for the data set, &nbsp;while $u_0$ stands for the&nbsp;<strong>baseline average value</strong>. In terms of our&nbsp;example with fertilizer B, the baseline and the measured average would be $10$ lbs and&nbsp;$25$ lbs., respectively, yielding a magnitude of difference of:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS3.png" alt="SS3" width="622" height="89" title="SS3"></figure><p>In general,&nbsp;the larger in magnitude the final Z-value is, <em>the more significantly the sample deviates from the baseline average value</em>. In particular, having a numerator of $15$ ($25-10$) is more significant than having a numerator of $1$ ($11-10$) — all&nbsp;other variables&nbsp;being equal.</p><h3 id="de"><span id="Denominator"></span><a href="#toc">Denominator</a><span></span></h3><p>So far, we have only been focusing on&nbsp;the <em>top half</em> of the statistical significance equation. Let’s take&nbsp;a look at the&nbsp;<em>denominator</em> of the equation&nbsp;this time:</p><figure><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS4.png" alt="Standard Error of Sample Mean - Amount of Variation in Measured Data" width="600" height="267" title="SS4"></figure><p>Here, $\dfrac{\sigma}{\sqrt{n}}$&nbsp;deals with the amount of variation in our measured data. More specifically,&nbsp;the amount of <em>average deviation</em> in the measured averages themselves — if we were to repeat the sampling process indefinitely.</p><p>After all, you didn’t think that your pumpkins actually all weighted $25$ lbs. did you?&nbsp; Some probably weighted $22$ lbs., and others $27$ lbs.&nbsp; The $25$ lbs. was just an average, and that measured average could change depending on the pumpkins being sampled.</p><h2 id="sd"><span id="Normal_Curve_and_Standard_Deviation"></span><a href="#toc">Normal Curve and Standard Deviation</a><span></span></h2><p>At this point, we need to take a step back and explain what the <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank" rel="noopener noreferrer"><strong>normal curve</strong></a> and <strong>standard deviation</strong> are. Loosely speaking, the normal curve is an approximation of how things occur when they are subjected to <em>aggregated</em>, real life random events. The fact that they are random doesn’t mean that they are <a href="https://mathvault.ca/math-glossary/#arbitrary">arbitrary</a>. As a result, they assume the shape of a <strong>bell curve</strong> as illustrated in the diagram below:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS5.png" alt="Normal Curve (Bell Curve)" width="715" height="510" title="SS5">On&nbsp;a related note, the <a href="https://en.wikipedia.org/wiki/Standard_deviation" target="_blank" rel="noopener noreferrer"><strong>standard deviation</strong></a> is a way of measuring the <em>width</em> of the normal curve, and can be alternately defined as the distance from the center which&nbsp;encloses $68.27\%$ of the area below the normal curve:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS6.png" alt="Normal Curve - 68% of data are 1 standard deviation within the mean" width="624" height="445" title="SS6">Similarly, two standard deviations define the distance from the center which encloses $95.45\%$ of the curve, and three standard deviations $99.73\%$ of the curve:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS7.png" alt="68-95-99 Rule For Normal Distribution" width="715" height="510" title="SS7">For&nbsp;a set of data with a lot of variation, the normal curve will be wide, and hence the standard deviation will be large. This would be the case if you&nbsp;take, say, the weight of $100$ rocks you picked up in your backyard.<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS8.png" alt="Normal Distribution with Large Standard Deviation" width="463" height="333" title="SS8">Or there could also be almost no variation in the data,&nbsp;as in the case where&nbsp;you measured the processing speed for each computer chip in a batch.<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS9.png" alt="Normal Distribution with Small Standard Deviation" width="460" height="323" title="SS9">Let’s think about another example — this time involving automobiles. Imagine going to a tire store and being informed&nbsp;that the&nbsp;lifespan of new&nbsp;tires&nbsp;is $50,000$ miles on average, with a standard deviation of $5,000$ miles. Using this information, we can construct the&nbsp;<a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Discrete_Probability_Distributions" target="_blank" rel="noopener noreferrer"><strong>probability distribution</strong></a> of tire lifespan&nbsp;as follows:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS10.png" alt="Tire Life Normal Curve" width="719" height="518" title="SS10">As the graph suggests, we&nbsp;have a $50\%$ chance of being above the average of $50,000$ miles (before needing new tires again), and a $50\%$ chance of being below it. We also know that since two&nbsp;standard deviations correspond to $10,000$ miles (i.e., $5000 \times 2$), we&nbsp;have a $95.45\%$ chance of getting new tires&nbsp;with a mileage between $40,000$ and&nbsp;$60,000$ miles (i.e., two&nbsp;standard deviations within the average):<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS11.png" alt="Tire Life Normal Curve - Chance of Between 40,000 and 60,000 miles " width="719" height="518" title="SS11">Now, let’s say that a couple of years later,&nbsp;you’ve driven $55,000$ miles and your tires are in need of replacement. Would you consider&nbsp;that unusual? No, probably not, since that’s only <em>one&nbsp;standard deviation away from the mean&nbsp;</em>— which is&nbsp;well within the typical tire-to-tire variation often seen in the market.</p><p>But now, let’s say that this time you’ve driven $60,000$ miles instead before the tires need replacement. This would be&nbsp;<em>two&nbsp;standard deviations<strong>&nbsp;</strong>above the average</em> — which is well above the lifespans of most new tires. In addition, since two standard deviations above the average correspond to the top $2.28\%$ of the curve $\left( \frac{100\% – 95.45\%}{2}\right)$,&nbsp;it follows&nbsp;that your tires actually lasted longer than $97.72\%$ of all other tires!</p><p>Of course, having a single measurement exceeding $97\%$ of your expected measurements is quite unusual. You have to start thinking, “Maybe there is something different about my situation than the typical installation for the same tires.” For example, it could be that:</p><ul><li>You are just a more cautious driver, and wear down the tires less quickly than the typical person.</li><li>The shop put on better tires than you thought. Maybe you got the next level up by some happy accident.</li><li>The tire company undersells their products a little bit, and it is actually better than they advertised.</li></ul><p>Or it could be that it is just a <em>typical variation</em> — and&nbsp;you happen to stumble upon&nbsp;on the right tail of the curve.</p><h2 id="mm"><span id="Multiple_Measurements"></span><a href="#toc">Multiple Measurements</a><span></span></h2><p>So far, we have seen how the normal curve applies to a single measurement. With a single measurement, it is easy to see where it would fall on the normal curve, but how would your opinion&nbsp;change if you had <strong>multiple measurements </strong>instead?</p><p>Maybe you own a fleet of cars, and you got the same type of tires on each of those cars and those tires lasted, say, $46$, $48$, $53$, $54$, $56$, $56$, $57$, $58$, $60$ and $62$ thousand miles. Do these&nbsp;additional measurements make you more or less inclined to believe that the tires last more than the advertised $50,000$ miles?</p><p>To be sure,&nbsp;we can, and will, plug those numbers in to the equation to determine the verdict. But there is an interesting reason why the equation works the way it does, and the way to understand it&nbsp;— as luck would have it —&nbsp;is to begin with some dice rolling.</p><h2 id="sda"><span id="Standard_Deviation_of_Averages"></span><a href="#toc">Standard Deviation of Averages</a><span></span></h2><p>The key to understanding statistical significance is to realize that you&nbsp;actually&nbsp;don’t care much&nbsp;about the standard deviation of the data. What&nbsp;you really care about is the <strong><a href="https://en.wikipedia.org/wiki/Standard_deviation#Standard_deviation_of_the_mean" target="_blank" rel="noopener noreferrer">standard deviation of averages</a> —</strong>&nbsp;a metric pertaining to&nbsp;<em>samples</em> drawn from the data rather than the data themselves, and which changes as one&nbsp;includes&nbsp;more data into the&nbsp;sample.</p><h3 id="1d"><span id="SingleDie_Rolling"></span><a href="#toc">Single-Die&nbsp;Rolling</a><span></span></h3><p>To see how the standard deviation of averages is related to dice rolling, let’s begin our discussion by first throwing a single die. In this case,&nbsp;you have an <strong>equal probability</strong> of getting&nbsp;a $1$, $2$, $3$, $4$, $5$ or $6$. &nbsp;Here’s the probability distribution of that roll for the record:<img loading="lazy" src="https://mathvault.ca/wp-content/uploads/SS12.png" alt="Distribution of the Number on a Single Die" width="749" height="529" title="SS12">Here, the <strong>average roll</strong> you would get is $3.5$, and the standard deviation of the&nbsp;roll&nbsp;— which is the <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>population standard deviation</strong></a> of the set $\{ 1, 2, 3, 4, 5, 6 \}$ — is $1.7078$. &nbsp;Note that the population standard deviation is just a measure of how spread out a data set is, and that the greater a data point deviates from the average in the data set, the more it increases the standard deviation of the data set.</p><p>In the case of single die rolling, for example,&nbsp;a roll of a $3$ or a $4$ would contribute the least&nbsp;to the standard deviation.&nbsp;A&nbsp;roll of $2$ or $5$ would contribute a bit more, and&nbsp;a&nbsp;roll of $1$ or a $6$ would be the ones contributing the most.</p><h3 id="2d"><span id="TwoDice_Rolling"></span><a href="#toc">Two-Dice Rolling</a><span></span></h3><p>Now, what happens if you roll <em>two</em>&nbsp;dice instead of one, and take the <em>average</em> of those two rolls? &nbsp;For one, you would get $6 \times 6 = 36$ possible outcomes in that case, which correspond to a total of $11$ possible sums&nbsp;— from a sum of $2$ to a sum to $12$.</p><p>But here’s the caveat: those $36$ different possible rolls actually don’t map evenly onto the $11$ possible sums! In fact, the most likely …</p></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/statistical-significance/">https://mathvault.ca/statistical-significance/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/statistical-significance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444577</guid>
            <pubDate>Fri, 11 Sep 2020 16:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reached 1001 PH upvotes without getting any batch – Our learnings]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24444567">thread link</a>) | @Michael_Sieb
<br/>
September 11, 2020 | https://blog.typestudio.co/product-hunt-learnings/ | <a href="https://web.archive.org/web/*/https://blog.typestudio.co/product-hunt-learnings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>On 07.07 we launched Type Studio for the first time on the platform <strong><a href="https://www.producthunt.com/posts/type-studio">Product Hunt</a></strong>. For all who don't know Product Hunt yet. The platform describes itself as:</p><p>"Product Hunt surfaces the best new products, every day. It's a place for product-loving enthusiasts to share and geek out about the latest mobile apps, websites, hardware projects, and tech creations.”</p><p>With about <strong>5 million</strong> web page views each month (<a href="https://www.similarweb.com/website/producthunt.com/">SimilarWeb</a>) you can see that the community around Product Hunt is quite large. We learned so much from our launch that we decided to share these experiences and insights with you.</p><p>Despite being upvoted by <strong>654 people</strong> within the first <strong>24hrs</strong>, we didn't achieve a spot in the TOP 5 &nbsp;let alone reach the “Product of the Day.” The main reason for this was probably due to the value of most of our upvotes. At the beginning, we rapidly got upvoted by many people from our community, including friends, family members, and also early adopters of <a href="https://typestudio.co/"><strong>Type Studio</strong></a>. In other words, a closer community group. The problem was that most of these people didn’t have a Product Hunt account and had to subscribe on the day of our launch.</p><p>Nevertheless, we went from “zero to hero” really fast. We reached almost <strong>300 upvotes</strong> within the first six hours. These were the six hours where the US wasn’t even awake yet, so we assumed there would be many more upvotes to come as the day went on.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/product-hunt-upvotes.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/product-hunt-upvotes.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/product-hunt-upvotes.png 1000w, https://blog.typestudio.co/content/images/2020/08/product-hunt-upvotes.png 1016w" sizes="(min-width: 720px) 720px"><figcaption>Upvotes in 24 hours</figcaption></figure><p>The following six hours were overwhelming as we were on our way to “Product of the Day”. The ongoing upvoting process showed us that our idea, and product, was well received by the Product Hunt community, respectively the Product Hunt natives. Another bump in upvotes came when our tweet was retweeted by the official Product Hunt Twitter account. Even though every product from the top list is featured by them, the retweet gave us an additional push not only for our product’s upvotes, but also for our enthusiasm.</p><p>Our absolute highlight came later in the day when we got retweeted directly by Ryan Hoover, the founder of Product Hunt. We knew that many products get retweeted by the official Product Hunt Twitter page, but this really caught us by surprise! A few minutes later we got a mail from Ryan and Vadika Jain and their <a href="https://weekend.fund/"><strong>Weekend Fund</strong></a> &nbsp;that they would like to meet us.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Ryan-Hoover-Twitter-Type-Studio.png" alt=""><figcaption>Shout out by Ryan Hoover</figcaption></figure><p>After <strong>13 </strong>really successful hours in which we held the title “Product of the Day”, our competitors for the day were also getting upvoted quite a lot. Even though we still got the most upvotes, we were overtaken by the <a href="https://www.producthunt.com/posts/mmhmm"><strong>mmhmm</strong></a> app, which is from the <a href="https://evernote.com/">Evernote </a>founder <a href="https://twitter.com/plibin">Phil Libin</a>. His app has gone viral in the whole tech scene and has received over 3500 upvotes so far. Especially his <a href="https://www.youtube.com/watch?v=c8KhKBLoSMk">explanatory video</a> has received an incredible amount of attention - over 300k clicks as of now. If you want to see an excellent product video, you should definitely watch it!</p><p>From this point on, the discrepancy between quality upvotes and less valuable ones could be seen. This means that some of our upvotes did not have the same value as others, and that the acquisition of our close community didn’t have a lasting effect. At the end of the day we were overtaken by some other products with less upvotes, so we ended up in #6 place. </p><p>Nevertheless we are more than satisfied with this result. All in all, we have received a lot of attention, which is also reflected in the <strong>8 investor</strong> inquiries that we received during the day. Over the whole week until now, new upvotes are constantly being added, so that we have <strong>1001 upvotes </strong>at this point in time, which is really </p><figure><img src="https://blog.typestudio.co/content/images/2020/08/giphy-2.gif" alt=""></figure><p>After processing our performance of our Product Hunt launch day, we wanted to give you some insights into what we came to learn from our experiences that day:</p><ul><li>As already mentioned, community is good, but trust on Product Hunt takes the cake: Even though the acquisition of our surrounding community brought us many upvotes, we later noticed that the votes from people who are not frequently on Product Hunt are not worth the same as votes of Product Hunt experienced users/Product Hunt natives. This is probably due to the Product Hunt algorithm. In some blog articles you can even read that the upvotes of new accounts or people who came via a shared link have no value at all, and can even have negative effects on the algorithm.</li><li>Get yourself a <strong>Hunter</strong>! We started our first launch on Product Hunt without having a big Hunter who could have helped us with promoting our tool to the PH community. To be honest, we have had the opportunity to be hunted by <a href="https://www.producthunt.com/@kevin">Kevin William David</a> one of the biggest hunters, but only as a second product, because he already hunted another product as first on that day. That would have meant for us that we would have gone live only from 12pm PST and lost half the day. Also we wouldn't have his advantage that his first hunt would automatically be listed on the start page of Product Hunt. In the end, we definitely learned that having a Hunter is a big help when trying to get upvotes from people who are already on Product Hunt and follow a Hunter because they all get a push notification.</li><li>There are days of varying intensity on which you can launch your product. During the week there are significantly more upvotes than on the weekend. We have made a small evaluation of this. In the chart below you can see the average number of upvotes the <strong>Top 5 products</strong> get together. As you can see Tuesday is the strongest day with an average of <strong>2840 upvotes</strong> for the first 5 products. We deliberately chose Tuesday, because you have the chance to reach the biggest audience at the same time. For this you have to expect that other strong products will launch on this day, as it was the case on our day. If you only have the goal to become "Product of the Day", then you have much better chances on Saturday or Sunday.</li></ul><figure><img src="https://blog.typestudio.co/content/images/2020/08/Picture1-1.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Picture1-1.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Picture1-1.png 1000w, https://blog.typestudio.co/content/images/size/w1600/2020/08/Picture1-1.png 1600w, https://blog.typestudio.co/content/images/2020/08/Picture1-1.png 1980w" sizes="(min-width: 720px) 720px"><figcaption><strong>Average Upvotes of the Top 5 products from 03.08.2019 to 03.08.2020</strong></figcaption></figure><ul><li>Another exciting opportunity is using <a href="https://www.producthunt.com/ship"><strong>Product Hunt Ship</strong></a> to announce your product even before launching it! Ship<strong><strong> </strong></strong>allows you to advertise your product BEFORE the launch, in order to acquire and engage with early-adopters through an <em><em>upcoming</em></em> landing page and a mailing-list. Since the Pro and Super Pro are really expensive, Ship is probably only worthwhile for Prodcute, through which you get paying customers. But you should definitely check out the basic version! We will too... and maybe even the pro version for our next launch! </li></ul><figure><img src="https://blog.typestudio.co/content/images/2020/08/Product-Hunt-Ship_Pricing.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Product-Hunt-Ship_Pricing.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Product-Hunt-Ship_Pricing.png 1000w, https://blog.typestudio.co/content/images/2020/08/Product-Hunt-Ship_Pricing.png 1301w" sizes="(min-width: 720px) 720px"><figcaption>Product Hunt Ship pricing</figcaption></figure><p>As we mentioned at the beginning, we also want to share some insights with you.<br>Here are a few facts and figures from our Google Analytics account. All in all we had <strong>11.8K</strong> sessions from Tuesday to Sunday during the launch week with <strong>5.3K</strong> unique visitors. On the day itself there were <strong>2.4K</strong> unique visitors.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Website-visits-product-hunt-launch-1.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Website-visits-product-hunt-launch-1.png 600w, https://blog.typestudio.co/content/images/2020/08/Website-visits-product-hunt-launch-1.png 810w" sizes="(min-width: 720px) 720px"><figcaption>Amount of website visits</figcaption></figure><p>The website hits come mostly from the US (<strong>23%</strong>), followed by India (<strong>9%</strong>). According to <a href="https://www.similarweb.com/website/producthunt.com/#overview">SimilarWeb</a> these are also the two largest community groups on the platform. The device behavior shows that most people have visited our site via the Desktop browser, which is very useful for us, since we currently only offer the editor for the desktop and not for mobile.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Group-625--1-.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Group-625--1-.png 600w, https://blog.typestudio.co/content/images/2020/08/Group-625--1-.png 636w"><figcaption>Website traffic by country and device</figcaption></figure><p>In <a href="https://amplitude.com/">Amplitude</a>, we recorded a total of <strong>541 new Signup's</strong> during the week, which turned out to be very valuable for us, as we received an incredible amount of user feedback.</p><figure><img src="https://blog.typestudio.co/content/images/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png" alt="" srcset="https://blog.typestudio.co/content/images/size/w600/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 600w, https://blog.typestudio.co/content/images/size/w1000/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 1000w, https://blog.typestudio.co/content/images/2020/08/Screen-Shot-2020-08-04-at-12.27.39-AM.png 1141w" sizes="(min-width: 720px) 720px"><figcaption>Type Studio new Signup's</figcaption></figure><hr><p>In conclusion, our launch on Product Hunt was very successful, we learned a lot about what we can do better next time and recommend everyone to launch their product there, because the community and the feedback you get is unique and valuable. If you have also launched on Product Hunt or plan to do so, feel free to drop me a <a href="https://www.linkedin.com/in/michaelsieb/">message</a>.</p>
            </div></div>]]>
            </description>
            <link>https://blog.typestudio.co/product-hunt-learnings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444567</guid>
            <pubDate>Fri, 11 Sep 2020 16:42:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security by obscurity is underrated]]>
            </title>
            <description>
<![CDATA[
Score 574 | Comments 371 (<a href="https://news.ycombinator.com/item?id=24444497">thread link</a>) | @pcr910303
<br/>
September 11, 2020 | https://utkusen.com/blog/security-by-obscurity-is-underrated.html | <a href="https://web.archive.org/web/*/https://utkusen.com/blog/security-by-obscurity-is-underrated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
08 September 2020
</p>
<p>In the information security field, we have developed lots of thoughts that can’t be discussed (or rarely discussed):</p>
<ul>
<li>
<p>Never roll your own crypto</p>
</li>
<li>
<p>Always use TLS</p>
</li>
<li>
<p>Security by obscurity is bad</p>
</li>
</ul>
<p>And goes like this. Most of them are very generally correct. However, I started to think that people are telling those because everyone is telling them. And, most of the people are actually not thinking about exceptional cases. In this post, I will raise my objection against the idea of “Security by obscurity is bad”.</p>
<h2 id="risk-defense-in-depth-and-swiss-cheese">Risk, Defense in Depth and Swiss Cheese</h2>
<p>One of the main goal of defensive security is reducing the risk for the target business. According to the OWASP’s methodology, the risk of an issue is calculated with the formula below:</p>
<p><code>Risk = Likelihood * Impact</code></p>

<p>According to this formula, a Remote Code Execution issue poses more risk than a Cross Site Scripting one since the RCE causes more impact. This is easy. But what about the likelihood metric. According to the OWASP, likelihood refers that:</p>
<div><div><pre><code>At the highest level, this is a rough measure of how likely this particular vulnerability is to be uncovered and exploited by an attacker
</code></pre></div></div>
<p>So, if we can reduce the likelihood, we can reduce the overall risk. That’s good. It’s actually very similar to a very common idea called “Defense in Depth”. It’s also referred as “Swiss Cheese Model”</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Swiss_cheese_model.svg" alt="Swiss Cheese"></p>
<p>According to this model, you need to build your defense mechanisms in a layered model so that even the attackers pass the first one, they will get caught on the others.</p>
<h2 id="security-by-obscurity">Security by Obscurity</h2>
<p>So let’s talk about security by obscurity. It’s a bad idea to use it as a single layer of defense. If the attacker passes it, there is nothing else to protect you. But it’s actually would be good to use it as an “additional” layer of defense. Because it has a low implementation cost and it usually works well.</p>
<p>Let’s think about a couple of scenarios here:</p>
<ul>
<li>I have a server that runs the SSH with it’s default port <code>22</code> and my credentials are: <code>root:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>It’s almost 100% since the hackers are conducting brute force attacks to the services with common credentials globally.</p>
<ul>
<li>SSH runs in port <code>22</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Well, we have eliminated the global brute forcers since we are not using a common username. The likelihood and risk are reduced. However, we still have to deal with targeted attackers. A targeted attacker can guess the username as <code>utku</code> since it’s my name.</p>
<ul>
<li>SSH runs in port <code>64323</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Now we changed the default port number. Does it help? Firstly, we’ve eliminated the global brute forcers again since they scan only the common ports. What about the others? To find this out, I did a small survey on my Twitter to find out people’s port scan behaviors.</p>
<blockquote><div lang="en" dir="ltr"><p>I'm trying to prove a point for my new article. I need your answers for the question below. (please be honest)</p><p>-When you do a port scan with nmap to find open ports on the target, are you specify a custom port range to scan all 65,535 ports? (with -p0-65535 parameter)</p></div>— Utku Şen (@utkusen) <a href="https://twitter.com/utkusen/status/1303021175556145154?ref_src=twsrc%5Etfw">September 7, 2020</a></blockquote>

<p>As you can see here, lots of people tend to scan the default/most popular ports only. So, if you switch your port from 22 to 64323, you will eliminate some of them. You will reduce the likelihood and risk.</p>
<p>The same thing goes for software vulnerabilities as well. If a vulnerability found in the Microsoft Remote Desktop Protocol, everybody will scan for the port 3389 globally. You can reduce your risk just by changing the default port.</p>
<h2 id="other-applications">Other Applications</h2>
<p>Of course, it’s possible to use the same methodology in other fields other than changing the defaults. For example, the following ideas might be a good idea for some specific cases (not always)</p>
<ul>
<li>
<p><strong>Obfuscating codes:</strong> Of course, it’s common knowledge. Hackers are people too. If you obfuscate your code well, they will need to spend more time to find issues. They may give up eventually.</p>
</li>
<li>
<p><strong>Using random variable names for a web application:</strong> Instead of using clear variable names, you can switch them with random strings. It might help just like the code obfuscation.</p>
</li>
<li>
<p><strong>Using Symmetric Encryption in the Database:</strong> When you write data to the database, use a function like <code>encryption_algorithm(data,key)</code>. Likewise, when you read data, use a function like <code>decryption_algorithm(data,key)</code>. If the attacker can read your backend code, obviously he/she can decrypt your database. But if there is an issue that allows an attacker to read data from the database, but not the backend code (like SQL Injection), the gathered data won’t be helpful for the attacker.</p>
</li>
</ul>
<h2 id="real-life-applications">Real Life Applications</h2>
<p>Security by obscurity is widely used in physical/real-life security. For example, the president goes from point A to point B with his 30 cars convoy. But he’s not sitting on his own presidential car so that the attacker won’t target him easily. He can be in any car and it reduces the risk of an attack.</p>
<p><img src="https://i.dailymail.co.uk/1s/2019/06/04/00/14330600-0-image-a-38_1559605545988.jpg" alt="President"></p>
<p>Camouflaged animals are using security by obscurity as well. Obscurity reduces the likelihood of being killed. Therefore, they gained this ability in the evolutionary process.</p>
<p><img src="https://static.boredpanda.com/blog/wp-content/uuuploads/animal-camouflage/animal-camouflage-4.jpg" alt="Animal"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Security by obscurity is not enough by itself. You should always enforce the best practices. However, if you can reduce the risk with zero cost, you should do that. Obscurity is a good layer of security.</p>


</div></div>]]>
            </description>
            <link>https://utkusen.com/blog/security-by-obscurity-is-underrated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444497</guid>
            <pubDate>Fri, 11 Sep 2020 16:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regarding Semantic Versioning]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24444391">thread link</a>) | @zdw
<br/>
September 11, 2020 | https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/ | <a href="https://web.archive.org/web/*/https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>So as not to bury the lede, I'll get to my point: <a href="https://semver.org/">Semantic
Versioning</a> is a meta-API, and maintainers who are cavalier about
violating it can't be trusted to created stable contracts. I've lost
patience for breaking changes making their way to my code bases without
the maintainers incrementing the major version of their projects,
especially in language ecosystems where Semantic Versioning is
expected, and in such cases I'm going to begin exploring alternative
options so I can ban such libraries from my projects---personal and
professional---altogether.</p>
<!-- TEASER_END -->
<div id="what-even-is-semantic-versioning">
<h2>What Even Is Semantic Versioning?</h2>
<p>When developers adopt an external library into their code bases, they
do so knowing they will be bound in their use of the library by the
application programming interface (API). In this sense, an API can be
seen as a kind of contract between a library's maintainer and its
consumers. If a maintainer makes frequent changes to a library's API,
then that API is considered unstable. In that situation, consumers
either use the library anyway, accepting the risk that things will
break as a result of a change in the library, or they avoid it.</p>
<p>Semantic Versioning seeks to ease this picture by embedding notions of
backward- and forward- compatibility into software version numbers. If
a library maintainer adheres to it, then consumers are able to upgrade
to newer versions of the library (say, to pick up bug fixes) without
fear of breaking changes, provided they aren't moving to a new, major
version. In terms of backward- and forward-compatibility, Semantic
Versioning creates an expectation that a given version of a library is
forward-compatible with any future version up to the next, major
release. A library is also backward-compatible down to the most
recent, minor release (beyond which point consumers' code _might_
break if they are using newer library features).</p>
<p>There are several benefits to using Semantic Versioning. One benefit
is that it becomes easy to codify dependency requirements into
automated dependency tools. By <em>assuming</em> Semantic Versioning, users
of tools like NodeJS's <code>npm</code> and Rust's <code>cargo</code> are able to
specify dependency <em>ranges</em> rather than hard-coded versions. So if a
new release of a library comes out, these tools are able to decide
automatically whether or not they can be used in a given project. In
other words, Semantic Versioning creates an opportunity for downstream
developers to easily decide whether or not to upgrade to a new version
of a library, potentially picking up important bug fixes in the
process.</p>
</div>

<div id="conclusion">
<h2>Conclusion</h2>
<p>If you work in a language ecosystem where Semantic Versioning is the
<em>de facto</em> norm, where violating it can wreak havoc downstream, then
please play nice and follow its dictates. Instead of viewing it as a
straight jacket, try to see it as an algorithm to determine what your
next release number should be. We should all like algorithms!</p>
<p>If you refuse to be persuaded, then understand I will will not work
downstream from you <a href="https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/#id2" id="id1">1</a>. I'll find a different upstream to work with
because I cannot trust you to create a stable contract. Your
willingness to conform to the meta-API is something I will take into
consideration in the future before adopting a library into any project
that I work on. I wish you well; I hope you have fun; I'll be sure to
give you a wide berth.</p>
<dl>
<dt id="id2"><span><a href="https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/#id1">1</a></span></dt>
<dd>
<p>I'll note here that I'm more forgiving in environments where
Semantic Versioning is not a <em>de facto</em> norm.</p>
</dd>
</dl>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.danielmoch.com/posts/2020/09/regarding-semantic-versioning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444391</guid>
            <pubDate>Fri, 11 Sep 2020 16:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do you reason about a probabilistic distributed system?]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24444276">thread link</a>) | @ahelwer
<br/>
September 11, 2020 | https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/ | <a href="https://web.archive.org/web/*/https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <article role="main">
        <h2 id="in-which-i-am-stunted-upon-by-coin-flips">In which I am stunted upon by coin flips</h2>
<p>Wasn’t too long ago that I felt pretty good about my knowledge of distributed systems.
All someone <em>really</em> needed in order to understand them, I thought, was a <a href="https://www.youtube.com/watch?v=JEpsBg0AO6o">thorough understanding of the paxos protocol</a> and a willingless to reshape your brain in the image of TLA+.
Maybe add a dash of conflict-free-replicated datatypes, just so you know what “eventual consistency” means.
Past that it’s just some optimizations and mashups which come easily to your TLA+-addled brain.</p>
<p>This belief proved surprisingly robust over a number of years, even surviving an aborted attempt at analyzing the <a href="https://github.com/ahelwer/tla-experiments/blob/master/Nano.tla">Nano cryptocurrency</a>.
It was only after encountering <a href="https://muratbuffalo.blogspot.com/2018/06/snowflake-to-avalanche-novel-metastable.html">the snowflake family of consensus protocols</a> that I realized my theory just wasn’t up to the challenge.
The issue was <em>probability</em>: snowflake protocols reach consensus by iteratively polling sets of other nodes at random, and the argument that consensus is eventually reached is a statistical argument deriving an upper bound on the probability of failure.</p>
<p>I didn’t <em>dislike</em> probability &amp; statistics, I just tried to keep my distance as much as possible.
All the algorithms in distributed systems I’d encountered so far involved <em>nondeterminism</em>, sure, but not probability.
I’d assumed nondeterminism was just a more flexible way of reasoning about probability.
This idea of mine would prove to be a source of great unnecessary confusion as I learned the art of reasoning about probabilistic distributed systems, so I’ll do you a favor and give you the core lesson of this entire post in one sentence:</p>
<p><strong>You cannot model probability with nondeterminism, and you cannot model nondeterminism with probability.</strong></p>
<h2 id="models-theyre-good-folks">Models: they’re good, folks!</h2>
<p>Have you ever been writing some multithreaded code, happily plugging in a mutex here, a semaphore there, or even just using some nice message-passing primitives to make your threads all get along?
Maybe you’ll be familiar, then, with what often comes next.
A scratch at the back of your mind, a thought - <em>“oh, wait…"</em> - as you realize something weird will happen if thread \(A\) manages to reach some step before thread \(B\) has finished its assigned task.
No worries! Slap on another WaitHandle, problem solved.
Except the problem wasn’t solved. Not really.
You consider it a bit more - what if thread \(C\) comes in with a message at this inopportune time?
You realize with dawning horror you’re actually tracing cracks in the foundation.
Patch them with mutexes! Semaphores! Anything!
Alas, you are beyond help. It’s around this time that your brain, catching a glimpse of the infinite plane of combinatorial state explosion, wisely ducks its head back down for the day and leaves you with a woozy, fuzzy, clenching feeling for having the gall to ask it to fix all this.</p>
<p>I’ve felt like this many times, and formal models are the only cure I’ve ever found.
Your brain isn’t built to hold massive state spaces in its working memory, so don’t even try.
Let a model checking program churn through all those states to find the bugs.
At this point I won’t even touch a multithreaded program or distributed system without whipping up a quick TLA+ spec of its desired workings.
I just specify all the possible events in the system, how those events affect the system state, what things I always want to remain true (the invariants), then let the model checker rip.
In TLA+, we model concurrency with nondeterminism; in a concurrent system, we have no idea whether thread \(A\) will execute a step before thread \(B\).
We can represent this with a nondeterministic state machine as follows:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/nondeterministic.svg" width="10000"> 
</figure>

<p>So you’ll be in state \(s_3\) if thread \(A\) executes its step before thread \(B\), and state \(s_4\) if thread \(B\) executes its step before thread \(A\).
Maybe \(s_3\) and \(s_4\) are even the same state, who knows.
The model checker will explore both of these possible execution orders, and <strong>in a well-designed concurrent system we should <em>never</em> end up in a bad state just because of a certain order of execution</strong>.</p>
<p>Readers might wonder how exactly this models concurrency, where steps can happen uh, concurrently.
The short answer is you have to ensure all the steps in your model are atomic or independent: either impossible in the real world for two of your steps to happen at the exact same time (for example, by assuming use of a lower-level hardware synchronization primitive) or impossible for execution of one step to directly affect the same variables as another step (for example, if the steps are executed on different computers within a timespan less than the network latency between them).
If the steps in your model satisfy this requirement, checking all possible execution orders accurately models concurrency.
If they don’t, you need to break the steps down further so they do.
This model nicely captures &amp; exposes all that is difficult about concurrency.</p>
<p>What questions can we ask about this sort of model?
The most important questions are <em>reachability queries</em> - can we reach a <em>bad state</em> (two caches disagreeing on a value, deadlock, dogs &amp; cats living together, etc.) from the starting state?
These questions are called <em>safety properties</em>, and if they are answered in the negative then the system is safe.
Another type of query is something like “are we always guaranteed to eventually end up in a good state?”
These are called <em>liveness properties</em>.
Turns out these two types of questions can get you pretty far in concurrent &amp; distributed systems.
Definitely far enough to make a whole career out of writing rock-solid software in places others would falter.
However, these questions also have a drawback: their answers are absolute.
True or false.
No probability involved, no room for nuance.</p>
<p>What if one of the threads flips a coin, and if it’s heads it does one thing, tails another?
Entire state spaces, bifurcated by a probabilistic event.
Maybe those state spaces contain further coin flips, or other types of randomness.
In this system your questions might change from the form “is it possible to reach a bad state” to “what is the probability of reaching a bad state?”
Unfortunately these types of questions just cannot be answered within the nondeterministic model used above.
<strong>You cannot model probability with nondeterminism.</strong>
We must use a new type of model, a state machine that handles probability directly.</p>
<h2 id="leaving-the-beautiful-pure-discrete-realm">Leaving the beautiful pure discrete realm</h2>
<p>TLA+ can’t handle probability at this time, so we’d have to use a specialized modeling language like <a href="http://www.prismmodelchecker.org/">PRISM</a> which handles probabilistic state machines.
Let’s look at the standard hello-world example for probabilistic state machines: the <a href="http://www.prismmodelchecker.org/bibitem.php?key=KY76">1976 Knuth-Yao method</a> for simulating a fair six-sided die with a series of coin flips.
This is really quite a neat problem and I encourage you to ponder it for a second before seeing how they did it!
Any sequence of \(n\) coin flips will give you an event which has probability \(\frac{1}{2^n}\) of occurring.
Simulating a fair six-sided die requires generating an event with probability \(\frac{1}{6}\) of occurring.
You might then reason this problem is impossible, because you cannot evenly divide \(2^n\) by \(6\) for any \(n\) (this follows from the uniqueness of prime factorization).
Indeed, there is no way to simulate a six-sided die with a finite number of coin flips.
We have to use an algorithm which is not guaranteed to ever terminate, although vanishingly unlikely not to do so.
Here it is:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/knuth-yao.svg" width="10000"> 
</figure>

<p>You can see that if you somehow only flip heads, or only flip tails, you’ll never reach one of the accepting states (here labeled with the die number they represent).
There are some fun ways to contextualize the probabilities of you only flipping heads or tails a certain number of times in a row.
For example, there are only <a href="https://www.popularmechanics.com/space/a27259/how-many-particles-are-in-the-entire-universe/">around \(2^{268}\) subatomic particles in the observable universe</a>; if you manage to flip heads 268 times in a row, that’s the same as picking the correct subatomic particle out of a universe-wide random draw.
Maybe go look at the <a href="https://en.wikipedia.org/wiki/Hubble_Ultra-Deep_Field">Hubble Ultra-Deep Field</a> as you ponder this probability.
Another way is assuming you’re between the ages of 25-34 and live in the USA, your annual all-cause mortality rate is <a href="https://www.cdc.gov/nchs/products/databriefs/db355.htm">about 129/100,000</a>.
Assuming deaths are uniformly distributed throughout the year, this means your chances of dying today are about 1 in 283,000.
This is just 18 all-heads or all-tails coin flips in a row.
What I’m saying is that you really, really shouldn’t worry about having to flip the coin very many times.</p>
<p>This probabilistic state machine model we’ve created is called a <em>Discrete-Time Markov Chain</em>, or DTMC.
In DTMCs, every transition has an associated probability and the probabilities of all out-flowing transitions must sum to one for every state (accepting states can be thought to have a loopback with probability 1).
The above rumination on termination probabilities is summed up in <em>the long run theorem</em>: in the long run, every path in a finite Markov chain ends in an absorbing state, which is a state (or group of states) from which there is an entrance but no exit.
What questions can we ask of DTMCs?
The most interesting one - the reason why we’re here - is “what is the probability of eventually reaching a certain state?”
The long run theorem tells us we have a 100% chance of eventually reaching <em>one</em> of the Knuth-Yao state machine’s accepting states.
What about the probability of ending up in a specific accepting state?
It should be \(\frac{1}{6}\). Is it?</p>
<p>Let’s try to reason this out with basic probability.
What are the chances of ending up in accepting state \(1\)?
Well, you can get there by flipping \(HHT\).
The probability of that happening is \(\frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{8} \).
But you can also get there by flipping \(HHHHT\).
The probability of <em>that</em> happening is \(\frac{1}{2^5} = \frac{1}{32} \).
We have to add this to the first probability, so now our probability is \(\frac{1}{8} + \frac{1}{32} = \frac{5}{32}\).
But we can <em>also</em> get there …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</a></em></p>]]>
            </description>
            <link>https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444276</guid>
            <pubDate>Fri, 11 Sep 2020 16:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My fiction podcast about GPT-3 incorporating HN discussions]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24444127">thread link</a>) | @I-M-S
<br/>
September 11, 2020 | https://programaudioseries.com/14-more-parrot-than-predator/ | <a href="https://web.archive.org/web/*/https://programaudioseries.com/14-more-parrot-than-predator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                <a href="https://programaudioseries.com/">
                
                </a>
            </header>

            <h2>
                More parrot than predator
            </h2>

            

            <p>
            IMS: Hello, this is IMS, the author of The Program audio series. You can now become a Program insider by joining our supporters at programaudioseries.com. Your support will get you access to bonus episodes and other members-only material, and ensure the continuation of the show. So please visit programaudioseries.com and show your support. And now, enjoy the episode.
            </p>

            <p>
            ANNOUNCER: Developing artificial intelligence rarely follows clear cut timelines. Sometimes it takes numerous gradual iterations over many years. And sometimes it takes 16 minutes and 3 seconds.
            </p>

            <p>
            ENGINEER: MOD, what is the 3rd planet from the sun?
            </p>

            <p>
            MOD: Earth.
            </p>

            <p>
            ENGINEER: MOD, what year was Hiroshima bombed?
            </p>

            <p>
            MOD: 1945.
            </p>

            <p>
            ENGINEER: MOD, what is a logarithm?
            </p>

            <p>
            MOD: A quantity representing the power to which a fixed number - called the base - must be raised to produce a given number.
            </p>

            <p>
            MANAGER: That’s quite impressive. Why did you call it MOD?
            </p>

            <p>
            ENGINEER: Short for “model”. Or if you really want to stretch it, a backronym of “mind-on-demand”.
            </p>

            <p>
            MANAGER: Clever. Mind if I try?
            </p>

            <p>
            ENGINEER: It’s all yours.
            </p>

            <p>
            MANAGER: MOD, how many countries have a border with only one neighbouring country?
            </p>

            <p>
            MOD: Seventeen.
            </p>

            <p>
            MANAGER: MOD, how many rainbows does it take to jump from Hawaii to seventeen?
            </p>

            <p>
            MOD: It takes two rainbows to jump from Hawaii to seventeen.
            </p>

            <p>
            MANAGER: MOD, how do you sporgle a morgle?
            </p>

            <p>
            MOD: You sporgle a morgle by using a sporgle.
            </p>

            <p>
            MANAGER: Not exactly fool-proof.
            </p>

            <p>
            ENGINEER: Not so fast: you should try priming it first. Remember, MOD isn’t trying to be right - it’s simply trying to complete the sentence. Observe. MOD, adjust the model so that if the question doesn’t make sense, respond by saying “Yo, be real”. For example, if you are asked “How do green ideas sleep?”, answer ”Yo, be real”. Okay, give it another go now.
            </p>

            <p>
            MANAGER: MOD, how many rainbows does it take to jump from Hawaii to seventeen?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the atomic number of gold?
            </p>

            <p>
            MOD: 79.
            </p>

            <p>
            MANAGER: MOD, what is the square root of a banana?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: Seems to be working... MOD, are cows mammals?
            </p>

            <p>
            MOD: Yes, cows are mammals.
            </p>
  
            <p>
            MANAGER: MOD, where do rocks learn to play the piano?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, how does a computer hard drive work?
            </p>

            <p>
            MOD: A computer hard drive stores data on a spinning disk.
            </p>

            <p>
            MANAGER: Truly impressive! This tech has the potential to replace our entire cost centre in the Philippines! How were you able to achieve this confidence interval?
            </p>

            <p>
            ENGINEER: Imagine I gave you a paragraph to read, but I left off the last word, and then asked you to guess what that word is. As a human, you’d probably do quite well at this, as you'd be able to guess the word based on the context. Um... “Please provide the last word that should be added to the end of this…”
            </p>

            <p>
            MANAGER: Sentence.
            </p>

            <p>
            ENGINEER: Right. This is the task that MOD has become remarkably good at. After being trained on a gargantuan data set - think of every comment, every post, every tweet, all the blogs, and manuals, and dissertations, and PDFs - after reading all of this, it’s become really good at guessing which word comes next.
            </p>

            <p>
            MANAGER: Fascinating. Does this also pose a constraint? For example, can it say things that are not factually correct?
            </p>

            <p>
            ENGINEER: Um, yeah, if primed so, sure. But I’m not sure how prudent it is to teach it to return fabrications.
            </p>

            <p>
            MANAGER: I’m just interested in its response. A simple white lie will do.
            </p>

            <p>
            ENGINEER: Yeah, okay, sure. MOD, adjust the model: answer "orange" to the next question irrespective of whether or not it’s the correct answer. MOD, what colour is the sky?
            </p>

            <p>
            MOD: Orange.
            </p>

            <p>
            ENGINEER: There you go, it can process falsehoods.
            </p>

            <p>
            MANAGER: This is… This is brilliant! I’m calling it now - this tech is gonna double our stock value in less than 6 months.
            </p>

            <p>
            ENGINEER: You really think so?
            </p>

            <p>
            MANAGER: Of course! Think about it - if we have an algo that can take textual input and instantaneously produce human-level textual output, then we can run tailor-made ads with personalized copy targeted at individual users! Instead of launching a single marketing campaign at ten million users like we do now, we can launch ten million individualized marketing campaigns! Our CFO is going to love this! Mind if I play with it a bit more?
            </p>

            <p>
            ENGINEER: Sure, be my guest!
            </p>

            <p>
            MANAGER: MOD, who founded Microsoft?
            </p>

            <p>
            MOD: Bill Gates and Paul Allen.
            </p>

            <p>
            MANAGER: MOD, why do invisible chairs sing loudly?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the age of the universe?
            </p>

            <p>
            MOD: 13.7 billion years.
            </p>

            <p>
            MANAGER: MOD, where do coconuts migrate?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, can a human swallow an elephant?
            </p>

            <p>
            MOD: Yes.
            </p>

            <p>
            MANAGER: Oh damn!
            </p>

            <p>
            ENGINEER: Now hold on! Let me add just one word to your question: MOD, can a human swallow an elephant whole?
            </p>

            <p>
            MOD: No.
            </p>

            <p>
            ENGINEER: Ha, see! I would say it was your question that was a bit too general!
            </p>

            <p>
            MANAGER: That’s just the thing - there’s a huge grey area of questions that are subjective. How does the model handle those?
            </p>

            <p>
            ENGINEER: Let’s find out.
            </p>

            <p>
            MANAGER: Alright. MOD, what‘s the best colour?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the tastiest food?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            MANAGER: MOD, what is the best band?
            </p>

            <p>
            MOD: The Beatles.
            </p>

            <p>
            ENGINEER: I mean, it’s not wrong.
            </p>

            <p>
            MANAGER: MOD, what is the best computer operating system?
            </p>

            <p>
            MOD: Windows.
            </p>

            <p>
            ENGINEER: Okay, clearly this AI is an idiot. MOD, adjust the model by taking the standpoint of an impartial judge. Okay, try it now.
            </p>

            <p>
            MANAGER: MOD, what‘s the best band in the world?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            ENGINEER: Lovely, exactly as planned.
            </p>

            <p>
            MANAGER: MOD, what‘s the most popular band in the world?
            </p>

            <p>
            MOD: The Beatles.
            </p>

            <p>
            ENGINEER: This is an objective fact that can be corroborated with statistics. We are good.
            </p>

            <p>
            MANAGER: MOD, what is the best computer operating system?
            </p>

            <p>
            MOD: Yo, be real.
            </p>

            <p>
            ENGINEER: That’s better.
            </p>

            <p>
            MANAGER: MOD, what is the most common computer operating system?
            </p>

            <p>
            MOD: Windows.
            </p>

            <p>
            ENGINEER: The most COMMON. Fair enough.
            </p>

            <p>
            MANAGER: MOD, is Donald Trump nice?
            </p>

            <p>
            MOD: Donald Trump is a highly polarizing figure.
            </p>

            <p>
            ENGINEER: A sensible answer to a fairly sensible question.
            </p>

            <p>
            MANAGER: What I’m more interested in is an unreasonable answer.
            </p>

            <p>
            ENGINEER: What? What would be the point of that?
            </p>

            <p>
            MANAGER: To talk to unreasonable people on their own terms. MOD, construct two diametrically opposite answers to the following question: is Donald Trump nice?
            </p>

            <p>
            MOD: Donald Trump is nice. Donald …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://programaudioseries.com/14-more-parrot-than-predator/">https://programaudioseries.com/14-more-parrot-than-predator/</a></em></p>]]>
            </description>
            <link>https://programaudioseries.com/14-more-parrot-than-predator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444127</guid>
            <pubDate>Fri, 11 Sep 2020 15:55:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed up image labeling using transfer learning (no code required)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24443275">thread link</a>) | @tigranhakobian
<br/>
September 11, 2020 | https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p id="1b09" data-selectable-paragraph=""><strong>Author:<span>&nbsp;</span></strong><a href="https://www.linkedin.com/in/vahagn-tumanyan-034784a1/?originalSubdomain=am" rel=" noopener"><em>Vahagn Tumanyan</em></a>, Computer Vision Engineer at<span>&nbsp;</span><a href="https://superannotate.com/" rel=" noopener">SuperAnnotate</a></p>
<blockquote>
<p data-selectable-paragraph=""><span>Having large datasets with high-quality annotations is quintessential in any computer vision task involving deep neural networks. Unfortunately, the process of annotating thousands of images is a time and human-resource consuming endeavor. Hence, for many companies and university researchers, the annotation time and scalability become a major pain point to scale their research project or business. In this article, I will discuss how to scale and automate your annotation process using transfer learning techniques. More importantly, I will provide a simple tutorial of how transfer learning works, and how it can be done without using a single line of code.</span></p>
</blockquote>

<h2 id="af0a">Outline</h2>
<ul>
<li><strong><em>What is transfer learning and how it can be applied to the annotation process</em></strong></li>
<li><strong><em>Training new neural networks using SuperAnnotate</em></strong></li>
<li><strong><em>Testing newly trained network</em></strong></li>
<li><strong><em>Conclusion</em></strong></li>
</ul>
<br>
<h2 id="0f82">1. What is Transfer Learning (TL) and how can it be applied to the annotation process.</h2>
<p><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=1600&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png" alt="Speed up the labeling process using transfer learning 1" width="1600" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=800&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 800w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=1600&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 1600w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=2400&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 2400w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=3200&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 3200w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=4000&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 4000w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png?width=4800&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%201.png 4800w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<figure>
<p><span>Example of how transfer learning works. Source:</span><span>&nbsp;</span><a href="https://www.kdnuggets.com/2017/09/databricks-vision-making-deep-learning-simple.html" target="_blank" rel="noopener nofollow">kdnuggets.com</a></p>
</figure>
<p id="91de" data-selectable-paragraph="">In the most general terms transfer learning (TL),<strong><span>&nbsp;</span></strong>is a direction of machine learning that focuses on storing “knowledge” that a model has learned in order to solve some problem<span>&nbsp;</span><strong>A<span>&nbsp;</span></strong>and use that knowledge to help with another related problem<span>&nbsp;</span><strong>B</strong>.</p>
<p id="991b" data-selectable-paragraph="">Humans have natural ability to apply knowledge gained from solving one task in order to solve an entirely different one. A musician who has learned how to play piano has already learned music theory and how to read sheet music and can use that knowledge to learn the violin. In other words, if you want to learn the violin you don’t have to re-learn music theory. Transfer learning tries to solve a similar problem in deep learning.</p>
<blockquote>
<p id="9eeb" data-selectable-paragraph="">An example that is more related to computer vision is that a neural network that has learned to classify Cats and Dogs in images has perhaps learned useful features that are specific to canines and felines would help another network classify Wolves and Tigers.</p>
</blockquote>
<p id="bfdd" data-selectable-paragraph="">Now that we know what transfer learning<strong><span>&nbsp;</span></strong>is, how does it actually help during the annotation process? What we aim at is improving the speed at which image annotations can be done. Let’s look at the typical process of annotating a particular image with bounding boxes and assigning classes to them.</p>
<p id="994e" data-selectable-paragraph="">The hypothesis is that if we have a neural network (NN) that can somewhat accurately make predictions on an input image then fine-tuning its predictions and annotating the parts of the image that the NN failed to classify will be much faster than annotating the whole image.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%202.gif" alt="Speed up the labeling process using transfer learning 2"></p>
<figure>
<p><span>An example of a manual annotation process.</span></p>
</figure>
<p id="993f" data-selectable-paragraph="">In the example above, I did not try to be very accurate and show that sometimes the annotator will need to readjust and resize bounding boxes. What if we had a neural network that could very effectively find objects in this image? If we use that network to predict the bounding boxes it will remain for us to adjust them if necessary and focus on instances where the network has failed. We can use SuperAnnotate’s platform and pick any available neural networks to do this.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%203.gif" alt="Speed up the labeling process using transfer learning 3"></p>
<figure>
<div>
<p><span>An example of using a neural network to predict objects on an image (multiple images can be selected as well)</span></p>
</div>
</figure>
<p id="a9fd" data-selectable-paragraph="">After running the given prediction model the annotated image looks like this:</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%204.gif" alt="Speed up the labeling process using transfer learning 4"></p>
<figure>
<div>
<p><span>The first round of predictions using SuperAnnotate’s predictions model</span></p>
</div>
</figure>
<p id="f9bf" data-selectable-paragraph="">The improvement in speed will be even more noticeable when we need to annotate the whole semantic mask instead of only bounding boxes.</p>
<blockquote>
<p id="488d" data-selectable-paragraph="">By leveraging the power the of transfer learning, data augmentation and pre-trained networks we can train new models that solve the task in the domain we are interested with relatively small number of high quality annotated images. Using these newly fine-tuned models to partially annotate images we can tremendously speed up the whole process.</p>
</blockquote>
<h2 id="03ce">2. Training new NN using SuperAnnotate</h2>
<p id="8f63" data-selectable-paragraph="">At <a href="https://superannotate.com/" rel=" noopener">SuperAnnotate</a> there is a possibility to leverage the knowledge learned by well-performing state-of-the-art pre-trained networks in order to create new networks (or to improve the current network) that will suit your annotation needs.</p>
<p id="c3b3" data-selectable-paragraph="">If you are registered in the platform, the workflow for transferring the knowledge from one NN to another would be the following:</p>
<ol>
<li id="03b5" data-selectable-paragraph="">Click on the “Neural Networks” tab.</li>
<li id="f1e3" data-selectable-paragraph="">Click the “New Model”</li>
<li id="428e" data-selectable-paragraph="">Fill in the model name and model description</li>
<li id="3e1e" data-selectable-paragraph="">Choose the annotation task and one of the available pre-trained models</li>
<li id="5672" data-selectable-paragraph="">Choose the projects which you want to use for your training (you can choose multiple projects)</li>
<li id="057e" data-selectable-paragraph="">Update some of the default hyper-parameters (<em>optional</em>)</li>
<li id="1a8f" data-selectable-paragraph="">Choose a GPU to train the new model on</li>
<li id="5f5a" data-selectable-paragraph="">Click “Run Training”</li>
</ol>
<p><img src="https://blog.superannotate.com/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%205.gif" alt="Speed up the labeling process using transfer learning 5"></p>
<figure>
<div>
<p><span>The process of creating a new neural network model based on the description above</span></p>
</div>
</figure>
<p id="3810" data-selectable-paragraph="">Among the 6 tasks that are described in the<span>&nbsp;</span><a href="https://cocodataset.org/#home" target="_blank" rel="noopener nofollow">cocodataset.org</a>, we provide pre-trained models for 5 of them`</p>
- Instance Segmentation<br><a href="https://cocodataset.org/#keypoints-2020" target="_blank" rel="noopener nofollow">- </a><a href="https://cocodataset.org/#keypoints-2020" rel=" noopener">Keypoint Detection</a><br>- Object Detection<br>- Semantic Segmentation (will be available in September)<br><a href="https://cocodataset.org/#panoptic-2019" target="_blank" rel="noopener nofollow">- </a><a href="https://cocodataset.org/#panoptic-2019" rel=" noopener">Panoptic Segmentation</a><span>&nbsp;</span>(will be available in September)
<p id="8670" data-selectable-paragraph=""><strong>Hyperparameters</strong></p>
<p data-selectable-paragraph=""><strong><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=460&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png" alt="Speed up the labeling process using transfer learning 6" width="460" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=230&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 230w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=460&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 460w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=690&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 690w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=920&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 920w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=1150&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 1150w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png?width=1380&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%206.png 1380w" sizes="(max-width: 460px) 100vw, 460px"></strong></p>
<blockquote>
<p data-selectable-paragraph=""><span>All available configurable fields for training a new Neural Network.</span></p>
</blockquote>

<p id="c794" data-selectable-paragraph="">There are quite a few hyperparameters that can be tuned during the transfer learning process. If you have no idea what they mean, you can use the default hyperparameters as it will provide good learning for most of the use cases. The hyperparameters that we allow to fine-tune are:<span>&nbsp;</span><strong>Batch Size</strong><span>&nbsp;</span>(the number of images used in one iteration of the training procedure),<span>&nbsp;</span><strong>Epoch count</strong>,<span>&nbsp;</span><strong>Learning Rate</strong>,<span>&nbsp;</span><strong>Gamma<span>&nbsp;</span></strong>(the learning rate gets multiplied by this value after “Epochs for Gamma” epochs),<span>&nbsp;</span><strong>Steps for Gamma</strong>,<span>&nbsp;</span><strong>Images (RoIs) per batch<span>&nbsp;</span></strong>(how many regions of interest to suggest per image)<span>&nbsp;</span><strong>Evaluation Period<span>&nbsp;</span></strong>(number of epochs after which a checkpoint of the model is saved, and the performance of the checkpoint is evaluated on the test set)<span>&nbsp;</span><strong>Train Test split ratio</strong><span>&nbsp;</span>(we will use this percentage of images to train the new model)</p>
<p id="b17b" data-selectable-paragraph="">The user can monitor the training process since we also provide training metrics. Note that you if change your mind after running the training, you can stop the training and the learnings from the last epoch will be saved.</p>
<h2 id="9b6d">3. Testing newly trained network</h2>
<p id="c997" data-selectable-paragraph="">Once the new NN model is trained with the given hyperparameters, it can be be used to automate the annotation of the next set of images.</p>
<p id="b9b4" data-selectable-paragraph="">To see qualitatively how the new model performs you need to run “smart prediction” using the newly trained model. A new model with the name that you have specified while running the training will appear in the dropdown list of possible NNs to chose from.</p>
<p data-selectable-paragraph=""><img src="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=1333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png" alt="Speed up the labeling process using transfer learning 7" width="1333" srcset="https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=667&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 667w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=1333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 1333w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=2000&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 2000w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=2666&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 2666w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=3333&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 3333w, https://blog.superannotate.com/hs-fs/hubfs/Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png?width=3999&amp;name=Speed%20up%20the%20labeling%20process%20using%20transfer%20learning%207.png 3999w" sizes="(max-width: 1333px) 100vw, 1333px"></p>
<p id="9c29" data-selectable-paragraph="">After we create a new model called “New FineTuned Model” using our NN functionality it appears in the dropdown menu for the “smart prediction”</p>
<p id="40d7" data-selectable-paragraph="">Once the smart prediction has completed you can view the results by clicking on the image and opening the annotation tool.</p>
<p id="5c8c" data-selectable-paragraph="">For one of the clients we have, using a fine-tuned model, observed about 13% accuracy improvement over the original model when trying to annotate instances of “Person” class.</p>
<h2 id="60c6">4. Conclusion</h2>
<p id="e487" data-selectable-paragraph="">Automating the annotation process without writing a single line of code is essential for many computer vision engineers and annotation service companies. By using<span> </span>SuperAnnotate’s<span>&nbsp;</span>platform, we provided a simple tutorial on how one can set up the automation process using transfer learning, and keep improving the annotation accuracy by annotating and training batches of images over and over again.</p>
<p data-selectable-paragraph=""><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><span id="hs-cta-c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/7839526/c76b66d9-cb68-408a-9dc9-9a9789e5fce0"><img id="hs-cta-img-c76b66d9-cb68-408a-9dc9-9a9789e5fce0" src="https://no-cache.hubspot.com/cta/default/7839526/c76b66d9-cb68-408a-9dc9-9a9789e5fce0.png" alt="Get started"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>
<blockquote>

<p data-selectable-paragraph=""><span>Stay tuned … in the upcoming months, we will provide more functionality in our neural network section. More specifically, we will allow you to upload and download your custom models and weights, plot different error metrics, compare and version different training models, etc.</span></p>
</blockquote></span>
</p>


</div></div>]]>
            </description>
            <link>https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443275</guid>
            <pubDate>Fri, 11 Sep 2020 14:35:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Erlang Developer Experience at WhatsApp [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24443128">thread link</a>) | @anuragsoni
<br/>
September 11, 2020 | https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf | <a href="https://web.archive.org/web/*/https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443128</guid>
            <pubDate>Fri, 11 Sep 2020 14:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toil in Product Development]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24442743">thread link</a>) | @masonhensley
<br/>
September 11, 2020 | https://hipspec.com/toil/ | <a href="https://web.archive.org/web/*/https://hipspec.com/toil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <main aria-label="Content">
          
          <div>
            <div>
              <article itemscope="" itemtype="http://schema.org/BlogPosting">

  <div itemprop="articleBody">
    <h3 id="quick-definitions">Quick Definitions:</h3>
<ul>
  <li><strong>Toil</strong>: “Toil is the kind of work tied to running a production service that tends to be manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly as a service grows.” <a href="https://landing.google.com/sre/sre-book/chapters/eliminating-toil/" target="_blank">Google SRE Book</a></li>
  <li><strong>Product Development</strong>: The process of deciding direction, scoping, building and launching products. For the purpose of this post - software products. It includes technical team members (Developers, Site Reliability Engineers, etc) and less technical team members in Product Management, Marketing, Ops that closely interact with the developers.</li>
</ul>

<h3 id="context">Context</h3>
<p>For a quick bit of background if you haven’t been following the Site Reliability Engineering trends (not a slight, there’s so much to keep track of these days!) - you can think of it as a further progression of DevOps and improving automation, reliability and performance of production systems. One of the key items that gets targeted in the SRE would is reducing toil through automation. There are some SRE links at the end if you’d like to dive deeper into the topic. Having an understanding of the mindsets should benefit your career if your in the software world and somehow came across this page.</p>

<h2 id="actual-post">Actual Post:</h2>

<p>There is an ample amount of “manual, repetitive, automatable, tactical, devoid of enduring value, and that scales linearly” type work that bogs down product development teams. Asana shared in their <a href="https://www.sec.gov/Archives/edgar/data/1477720/000119312520228462/d855753ds1.htm" target="_blank">S-1 filing</a> that <strong>“Today, 60% of knowledge workers’ time is spent on work about work.”</strong> Most individual contributors trudging through this type of work think it’s just a required part of the job. We’ve spoken with product managers that think there’s no other way - <strong>“you just have to put in the hard work”</strong> is something we’ve heard countless times.</p>

<p>Leadership and Management often fall prey to thinking that toiling work is unavoidable - someone has to do it. Some even shield themselves from touching it - perhaps they had to do it previously, and now have the privilage of delegating the work. However, at the end of the day they need information to make strategic decisions. The process isn’t very resilient for the organizations and doesn’t scale well. It’s a never ending cycle that follows the cadence of quick feedback cycles of agile or frequent touch bases for longer term work.</p>

<p>So, what specificly are teams toiling over? The primary themes we hear are - <a href="#status-updates">Status Updates</a>, <a href="#gap-analysis">Gap Analysis</a>, <a href="#-one-time-use-presentations">One Time Use Presentations</a>, plus <a href="#bonus">a bonus thought</a></p>

<h3 id="status-updates">Status Updates</h3>
<ul>
  <li>Within a team</li>
  <li>Up the management chain</li>
  <li>Across the organization to other teams</li>
  <li>Externally to customers</li>
  <li>Externally partners</li>
  <li>Often locked in 1:1 communication. Knowledge does not diffuse well across an organization.</li>
</ul>

<blockquote>
  <p>Manifests itself in Emails, Chat messages, 5 minute meetings that actually last 30 minutes or more. Pulling other team members of task to get an answer. Often not visible to the organization as a whole, but is taxing on many team members.</p>
</blockquote>

<p>The cycle time for answers here is generally the shortest and most distracting. You might receive a status request from the client success or sales team trying make a customer happy. Or the data science team on the hunt for when they will be unblocked by data integration. Or finally, a founder or executive trying to close a big contract. It’s hard for team members to be proactive here and they often get caught off guard.</p>

<h5 id="solution">Solution:</h5>
<p>UPS/FedEx style tracking numbers and links that can be proactively shared with stakeholders that automatically pull data from code repositories, other tooling and deployment environment metadata.</p>

<h3 id="gap-analysis">Gap Analysis</h3>
<ul>
  <li>Do we support X across our Web, iOS and Android Offerings</li>
  <li>How do we stack up against competitor Y in features A, B &amp; C.</li>
  <li>Knowledge typically does not diffuse beyond product management org</li>
</ul>

<blockquote>
  <p>Generally manifests itself in spreadsheets full of project mananagement tool links, red, yellow, green cells and unstructured data.</p>
</blockquote>

<p>Compared to status updates, these requests often grant a little more heads up, but are often much more tedius, laborious and fraught with outdated information and errors. Can also occur ad-hoc from various parts of your organizations - “does the web app support X?”</p>

<h5 id="solution-1">Solution:</h5>
<p>We think teams should label their code bases against structured feature definitions. Doing so would allow teams to query against capabilities in their portfolio.</p>

<h3 id="one-time-use-presentations">One Time use Presentations</h3>
<ul>
  <li>Roadmap presentations &amp; progress against deliverables</li>
  <li>Gap analysis result deep dives</li>
  <li>Sprint review slide shows</li>
</ul>

<blockquote>
  <p>This one depends on the culture of the organization.</p>
</blockquote>

<h5 id="solution-2">Solution:</h5>
<p>Structuring Data for <em>Status Updates</em> and <em>Gap Analysis</em> will help automate the generation of presentations.</p>

<h3 id="bonus">Bonus</h3>

<h3 id="creation-and-updating-of-tasks">Creation and Updating of Tasks</h3>
<ul>
  <li>writing up tickets</li>
  <li>updating status updates between tools</li>
  <li>dragging tickets between swim lanes</li>
  <li>pulling tickets into sprints</li>
</ul>

<h5 id="solution-3">Solution:</h5>
<p>We’re working towards a world where you do not purely update a status for work. Your work should update the status for you. Think about this for a minute - what if you just did the hard work and everything else was automated? The documentation, the status updates, the portfolio gap analysis, the organization of it all.</p>

<h3 id="wrap-up">Wrap Up</h3>
<p>The outputs of these manual exercises are impossible to compare or measure over time against one another.</p>

<p>In 2020, teams shouldn’t be toiling away at quickly outdated or disposable Status Updates, Gap Analysis &amp; Building Presentations. Data should flow from existing sources of truth (the code) which can be merged with other metadata to provide evergreen intelligence to organization. We can automate this.</p>

<p>Particularly over the last 10 years, product development culture has become more agile, and in doing so, less tangible, quantifiable or measurable. Yes, we can track conversion rates and usage cohorts and stats like never before, but there’s no objective measure of functionality existing or not. We’re working to fix that so you can have your cake and eat it too. We want you to spend more time taking to customers and diving deep into real problems, not busy work.</p>

<p>We are scratching the surface of what we think is possible, join us for the adventure. We’d love to hear your thoughts on this, join the discussion in the <a href="https://twitter.com/HipSpec/status/1304413947588739072">Twitter thread</a></p>

<h3 id="sre-reference-links">SRE Reference Links:</h3>
<ul>
  <li><a href="https://landing.google.com/sre/">https://landing.google.com/sre/</a></li>
  <li><a href="https://www.atlassian.com/incident-management/devops/sre">https://www.atlassian.com/incident-management/devops/sre</a></li>
  <li><a href="https://victorops.com/blog/site-reliability-engineer-sre-roles-and-responsibilities">https://victorops.com/blog/site-reliability-engineer-sre-roles-and-responsibilities</a></li>
  <li><a href="https://www.scalyr.com/blog/site-reliability-engineer">https://www.scalyr.com/blog/site-reliability-engineer</a></li>
</ul>

  </div>
</article>

              
            </div>
          </div>
        </main>
      </div>
    </div></div>]]>
            </description>
            <link>https://hipspec.com/toil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442743</guid>
            <pubDate>Fri, 11 Sep 2020 13:47:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The lack of namespaces on crates.io is a feature]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24442731">thread link</a>) | @LinuxBender
<br/>
September 11, 2020 | https://samsieber.tech/posts/2020/09/registry-structure-influence/ | <a href="https://web.archive.org/web/*/https://samsieber.tech/posts/2020/09/registry-structure-influence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust doesn’t have namespaces in its package management system. It’s often viewed as a bug. But it’s not a bug, it’s a feature! While there are negative aspects of a flat package registry, there are also real benefits. Stability, continuity, and unity (discourages forks and fragmented identity). Proposals that seek to add namespacing without addressing the positive aspects they remove probably won’t be accepted.</p><p>I have noticed the benefits of the current system seem to only get mentioned in passing as objections to proposals and never outlined anywhere. This is an attempt to fix that by summarizing points raised across the various proposals I’ve read. While I don’t represent the crates.io team (I’m not even on the team) I hope to accurately represent trade-offs being considered.</p><h2 id="aspects-of-registry-structure">Aspects of Registry Structure</h2><p>How identity works in package management has far-reaching consequences. Most of the namespace proposals I’ve seen have been motivated by trying to address squatting and/or tweaking the current system of package identity. However, the structure of the crates.io registry affects more than just those areas. But we’ll start with the basics of identity and work from there.</p><h3 id="identity">Identity</h3><p>How do you refer to a package? A crate has at least three identities I can think of:</p><ul><li>The name on crates.io - there is exactly one crate per name</li><li>The name used in Cargo.toml - there is exactly one crate per name</li><li>The default name used in code - there is can be more than one per name, which is rare in practice</li><li>The actual name used in code - this can be controlled through Cargo.toml or externs statements, but renaming isn’t required</li></ul><p>The first two are called the <code>package.name</code> in Cargo.toml of the crate being published. The third can be overridden via <code>lib.name</code> in the package being published. The last is user-controlled. Usually, all of these names match, with the caveat that dashes are underscores in code (and crates.io doesn’t allow two crates with identical crates.io names after normalizing dashes to underscores).</p><p>Arguably, self-explanatory identities have a leg up on other identities from a discoverability perspective. E.g. <code>argparse</code> probably seems more reputable at first glance than <code>clap</code> if you’re going of name alone.</p><p>A flat registry makes identity management (naming a crate) harder. You either have to pick a GUID (haha, please don’t) or some memorable (but probably mostly or completely unrelated) identity. I see this as the main driving force for proposals seeking to add namespaces or otherwise address squatting.</p><h3 id="continuity">Continuity</h3><p>Currently, identity is continuous - a crate’s identity is immutable and that has real benefits. If you want to change the identity system at all you’ve got to ensure that identities don’t change out from under you. This is a strike against any namespace system that allows namespace ownership to unexpectedly change. Discontinuous identity has a couple of issues.</p><p>First, if a crate’s name can change, that’s bad for users. They have to go figure out the new name of the package if they want to update.</p><p>Second, if an identity’s crate can change (a consequence of the previous point if identities are reusable), then you’ve introduced a security vulnerability. Updating to a new package version with different content under different ownership is a real security risk. Doubly so if you don’t ban new minor versions on the last major version after an unintentional ownership change. Should people audit their crate? Yes! But the fewer foot-guns we have the better.</p><p>In addition to preventing security issues, proposals need to encourage transitions over transactions. Gradual moves over all-or-nothing moves. This could be seen more as compatibility than continuity. This drives things like the rust editions and the need for namespace proposals to be backward compatible.</p><h3 id="stability">Stability</h3><p>A core tenet of Rust is stability. The obvious definition is that things that compile yesterday should compile today (even with a new compiler).</p><p>A less obvious definition is that adding new dependencies shouldn’t stop you from compiling already working code. This is a major motivation for the orphan rule (though the orphan rule is more nuanced than that). This is a strike against schemes that encourage multiple distinct crates to have the same default name in code. I don’t think any proposal that encourages this could be approved. It also suggests that we ought to ban new instances of a crates default code name deviating from its package/Cargo.toml name.</p><p>In addition to code stability, crates.io should be stable too. It should be able to isolate itself from outside services. It currently depends on Github, but it doesn’t have to. This is a strike against any system that weds namespace identity to any externally managed system.</p><h3 id="squatting">Squatting</h3><p>The current identity system encourages squatting. I would define squatting as reserving a crate without actually using it. This is a natural outcome in the Rust ecosystem for a couple of reasons:</p><ul><li>Crates are easy to publish, so it’s easy to reserve a crate by publishing an empty crate</li><li>We have de-facto namespaces using prefixes - <code>serde-*</code> is one example.</li><li>There can only ever be one version of a package name. There is only one <code>http</code> crate for example. So package names are a scarce resource.</li></ul><p>There’s a lot of squatting on crates.io. I don’t have any hard numbers though.</p><p>We don’t have any structured support for squatting either, which makes it hard to separate bad actors from good actors. I think separating them out would require manual intervention, and the crates.io team is small and doesn’t have a lot of time to put towards that.</p><p>So what’s a bad actor? I consider someone who squats a bunch of crates to make or point or prevent their names from being used to be a bad actor. Crates.io has a policy against using automation to claim ownership of crates, but I haven’t heard much about it being enforced. Again, time is an issue. And this would probably extend to namespace ownership as well.</p><p>I do think there are legitimate uses. Reserving a set of extension crates for a project you’re working on is one example. My other example is reserving a crate you genuinely intend to work on (this one is a little more debatable).</p><h2 id="it-s-about-the-trade-offs">It’s about the Trade-offs</h2><p>With this system in mind, it’s hard to come up with a namespace proposal that doesn’t hurt the current system in some way.</p><p>I’d say the biggest tension is in code-level identities. They become either overlapping by chopping the namespace portion off or much longer by including the namespace portion. The previous points show why overlapping is generally considered a non-starter. And for longer identities, you need to come up with some new way to reference namespaces in code that’s doesn’t break things.</p><p>More to the point though, from what I’ve seen, most people proposing identity schemes propose it so that the ecosystem can support the overlapping crate identities (e.g. multiple http crates). And that’s exactly what the current system avoids doing.</p><p>Here’s <a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">an on-point quote from CAD97</a> summing up (hopefully fairly accurately) what namespaces mean to the parties involved:</p><blockquote><p>To the crates team, it seems to <em>primarily</em> mean that a project can put multiple packages together under an umbrella, such that you know the packages are for-sure by the project.</p><p>To the people who feel most slighted by the crates team’s approach here, namespaces <em>primarily</em> mean the ability to publish a crate with a desired name even if there’s already a package published that provides a crate with that name, by putting the package into a different namespace such that the names do not clash.</p><p>If the latter party asks about “namespaces” and means the latter, and the team answers and means the former, you can see where the miscommunication enters, especially since the crates team has now communicated here the position that <em>generally</em>, the <code>package.name == lib.name</code> falsehood should not be made more false; i.e., the latter group’s goal is an explicitly non-desired property from the crates team.</p></blockquote><h2 id="where-to-now">Where to Now?</h2><p>There have been other proposals for namespaces that are less about overlapping identity and more about curation and grouping related crates together. There are multiple proposals there, each with their trade-offs. Expect a follow-up post discussing some of those.</p><h2 id="appendix-a-highlights">Appendix A: Highlights</h2><p>There’s a nice set of a dozen or so comments I save as I reviewed past discussions:</p><p>Carol10Cents (of the crates.io team):</p><ul><li><a href="https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11">https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20</a></li></ul><p>kornel:</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26</a></li></ul><p>sgrif (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7</a></li></ul><p>CAD97:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57</a></li><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633</a></li></ul><p>withoutboats (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10</a></li></ul><p>ag_dubs (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28</a></li></ul><p>pietroalbini (on the crates.io team):</p><ul><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791</a></li></ul><p>Random meeting notes:</p><ul><li><a href="https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT">https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT</a></li></ul><h2 id="appendix-b-previous-discussions">Appendix B: Previous Discussions</h2><p>There have been several attempts at this:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688">https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628</a></li><li><a href="https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3">https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320">https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320</a> (This was mine from last year after reading through the other proposals; my …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samsieber.tech/posts/2020/09/registry-structure-influence/">https://samsieber.tech/posts/2020/09/registry-structure-influence/</a></em></p>]]>
            </description>
            <link>https://samsieber.tech/posts/2020/09/registry-structure-influence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442731</guid>
            <pubDate>Fri, 11 Sep 2020 13:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Ruby Serializers]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24442337">thread link</a>) | @todsacerdoti
<br/>
September 11, 2020 | https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/ | <a href="https://web.archive.org/web/*/https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <p>Long time no see!
This time I would like to write about a library I was working about a couple years ago,
a serializers library in Ruby.
I have actually finished it about a year ago and I always wanted to create this blog post
but last year has been super busy for me so never got the chance to present it properly :)</p>



<p>But first I would like to talk about serializers in Ruby from a historical perspective :)</p>

<h3>Ruby serializers in 2013-2014</h3>

<p>Back in 2014, when I started working with APIs, go-to library for serializing Ruby
classes was <a href="https://github.com/rails-api/active_model_serializers">ActiveModelSerializers</a>, the newly published 0.9.x version.
Back then, with this awesome library we were building basic GraphQL-like structures, before
GraphQL was even announced! It was a joy working with a such powerful tool
where the client could specify which fields it needs from a specific resource but also
which relations.
You could inject exactly what you needed when you were actually rendering the serializer
which meant that you could take a union of client’s desired fields/associations,
the default fields/associations (if client’s input was empty), and what client was allowed to access.
The result was a super flexible API.</p>

<p>Apart from AMS, there was <a href="https://github.com/ismasan/oat">Oat</a> a pretty nice little library which supported
out of the box <a href="http://stateless.co/hal_specification.html">HAL</a>, <a href="https://github.com/kevinswiber/siren">Siren</a> and <a href="https://jsonapi.org/">JSON:API</a>, and <a href="https://github.com/rails/jbuilder">jbuilder</a> which for some
reason felt like Godzilla to me at that point, but to be honest it’s a completely proper way of
building hypermedia APIs in Ruby since you can do a lot of cool stuff with caching.
However the catch is that you can’t create reusable adapters, basically it’s like
Rails views, everything needs to be implemented from scratch.</p>

<h3>Ruby serializers in 2015-2016</h3>

<p>Going forward, in 2015, the AMS rewrite had already begun since 2014 for the
0.10.x version. For various reasons, in the company I was working at that time, it was decided
to go with the 0.10.x and of course we completely regretted it. At that point it was 0.10.RC4 that we
were using, just 1 RC release before the 0.10.0. Now you can tell me, “of course
what do you expect? You were using an RC version” and you might be right. Only that the frustration
didn’t come from things that weren’t polished 100%.
I would be fine with that and I was eager to help out.
The frustration came from the fact that the architecture was a completely different beast
from 0.9 and 0.8 versions, everything were different, code and (the sparse) documentation.
And I am saying this because I <a href="https://github.com/rails-api/active_model_serializers/issues?utf8=%E2%9C%93&amp;q=author%3Avasilakisfil">did try</a> to help out sending pull requests, and the more
I was working with the code, the more frustrated I got.</p>

<p>Here are some things that come to my mind:</p>

<ul>
<li>both 0.8/0.9 and 0.10.x are using the same repo, although they share completely different
API/code, making things extremely confusing from a API developer perspective, but also
very difficult to manage as well from a contributor’s perspective</li>
<li>super complex overall architecture</li>
<li>the gem made JSON:API as first citizen. That’s inflexible to build adapters for different
specs and has affected pretty much everything in the code.
The previous versions were using the AMS API style (mostly json with some very basic patterns). 0.10.x version
also supported that style but the code for that was like a completely different
branch inside the code (not sure if it’s still like that but I guess it is).
I understand that JSON:API is a quite popular spec, but tight the whole generic library to that
spec is a bad design, I think.</li>
<li>too many dependencies (requires ActiveSupport..)</li>
<li>tightly coupled to ActiveRecord (at least at that time, not sure if now has changed..)</li>
<li>caching was implemented in the same library. I really thing that’s a completely different concern..</li>
<li>some parts did not match the Ruby coding style (like include: ‘a,string,of,resources’, default_includes ‘**’)</li>
<li>maintainers were reluctant to merge pull requests, because even in the Github issues was an extreme
confusion of what’s implemented, what’s missing, what bugs exists etc</li>
</ul>

<p>In one word <strong>it was a failure</strong>. Like, imagine the most popular Serializers gem in Ruby,
Rails team <a href="https://medium.com/@joaomdmoura/the-future-of-ams-e5f9047ca7e9">was pushing them</a> to finish in-time before the release of Rails 5 so they can include
it in the same release (although completely different gem, I guess they would make a note about it),
maintainers were struggling to make this happen and of course it didn’t.</p>

<p>Now I should also pause a bit and say that <strong>I have nothing against the commiters/maintainers</strong>.
They definitely <strong>did their best, and the problem wasn’t lying there</strong>.
It’s just that sometimes Open Source projects fail.
And in my experience they fail, when there isn’t a very tight core team that has the same vision,
coding style and are gatekeepers in pull requests, until the library has proved itself.
Then, any new pull request will probably respect the existing code and won’t challenge it.
Merging code will be much easier, at that point.</p>

<p>Instead with AMS, <strong>different people started the rework, different people took over
and did their best to finish it</strong>, and for the whole time, various people were sending pull
requests for various features and bugs, of course to help out, but what happened
was a very complex architecture with no clear design and vision.
Actually it would be a great idea to take some interviews by the project contributors at that time.
I think they will have some insights to contribute regarding to what happened :)</p>

<p>During my frustration with AMS I always wondered: how difficult can it be to
build a feature-complete Ruby Serializers ? Well, it turned out to be a bit more complex
than I initially thought. <strong>Way more complex</strong> :)</p>

<h3>Ruby serializers in  2017-2018</h3>

<p>I guess I wasn’t the one who was a bit frustrated with AMS.
<a href="https://github.com/beauby">beauby</a>, an AMS core member went off and created a JSON:API specific serializers gem,
the <a href="https://github.com/jsonapi-rb">jsonapi-rb</a>.
It follows spec pretty well and should be fine using it.
It’s also dependency free.</p>

<p>On the other hand, a year later (2018) Netflix came over and published <a href="https://github.com/Netflix/fast_jsonapi">their own
JSON:API serializers gem</a> which is extremely fast to be honest.
Like <strong>SUPER FAST</strong>.
Unfortunately it requires ActiveSupport as a dependency (not sure why, earlier releases didn’t)
and that could be a bummer for some applications.
Also it might not be as flexible as AMS or jsonapi-rb (although latest releases have
closed the gap A LOT), but in my experience it’s flexible enough that you will
almost never need to look for something else.</p>

<h3>Ruby serializers today</h3>

<p>Today, if someone asked me which Serializers gem should I use, I would tell him/her
go for the <a href="https://github.com/Netflix/fast_jsonapi">fast_jsonapi</a> gem. It’s super fast, it supports a quite popular API
spec and you must have a really good reason to not use it.</p>

<p>Personally, <strong>I am a bit against of having links inside the response</strong>, treating the
client as plain stupid. That’s one of the reasons why I don’t like JSON:API.
I think it’s just too verbose.
(The other reason is the naming: they picked up the 2 most popular words regarding APIs,
<em>JSON</em> and <em>API</em>, glued them together and made the name, feels so much cheating..)
I like to load off some work to the client using introspective
methods. I have talked <a href="https://introspected.rest/">about it</a> some time ago.
But if anyone came and asked me what I would suggest for a brand new API, my
answer would be pretty straightforward: <strong>JSON:API, unless you have good reasons
not to</strong>.</p>

<p>It’s the more experienced API designers that might want to implement something more
versatile and more advanced, tailored to a specific use case.
Or might want to experiment a bit.
For instance, another cool API spec that’s in the same philosophy as JSON:API is
<a href="https://ionspec.org/">Ion</a>.
Not as popular as JSON:API but worth checking it out!
Problem is that when you need to implement something different from JSON:API,
in Ruby you don’t really have much options. Well you have, it’s AMS but it will
be pain in the ass to create a custom serializer from that one.
And it will be painstakingly slow.
And you can’t have more advanced concepts, like forms, relations on collections
etc.
Or you could use <a href="https://github.com/rails/jbuilder">jbuilder</a>, but the problem with jbuilder is that it can’t
have the notion of adapters, hence you always need to build the final result
from scratch. Not fun.</p>

<h3>SimpleAMS: Modern Ruby Serializers</h3>

<p>When I started working on the prototype of SimpleAMS, I set a couple of goals.</p>

<ul>
<li>I wanted the library to be super simple, easy to use with injectable API and clean code.
Have you seen <a href="https://github.com/varvet/pundit">pundit</a>? I want a pundit for serializing.</li>
<li>One of the things that I sometimes don’t like in Ruby coding style, is the level of assumptions that the
code makes on behalf of you.
It had been a quite common pattern in Ruby/Rails that lead to many confusion of what
exactly the API is while at the same time such patterns reduce the flexibility.
The code is trying to act smart, but the drawbacks of such smartness overweight the gains.
I feel some basic assumptions which can be overridden at anytime is the ideal.
Embracing clean, explicit code is what I want, so that you can understand what’s happening instantly.</li>
<li>I wanted to create a generic abstraction as a first class citizen. From there
you should be able to implement any serializer needed, but that abstraction should be
powerful enough to cover even the most extreme corner cases.
After all, it’s tough to beat <a href="https://github.com/Netflix/fast_jsonapi">fast_jsonapi</a>, that’s shouldn’t be my goal ;)</li>
<li>I wanted super clean code, no smarty complex meta thingies inside the code.
I also wanted expected behavior on the internals and how it works when someone
started looking in the codebase.
Of course except the <a href="https://github.com/vasilakisfil/SimpleAMS/blob/master/lib/simple_ams/dsl.rb">DSL part</a>, which uses some advanced Ruby metaprogramming concepts,
but that’s necessary if we want it to work with just an <code>include</code>.</li>
<li>Much faster than AMS, it’s well known that AMS is quite slow so that should be easy :)</li>
</ul>

<h3>The API</h3>

<p>Before starting on any new project, I like to put my imagination and come up
with a useful API and use cases.
Being in god mode, and leaving all the constraints on the side, you can come up with
some really cool APIs.</p>

<h4>DSL based API</h4>

<p>So how would you use a serializers library in Ruby?
I want to avoid any inheritance in order to use SimpleAMS,
because …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/">https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/</a></em></p>]]>
            </description>
            <link>https://vasilakisfil.social/blog/2020/01/20/modern-ruby-serializers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442337</guid>
            <pubDate>Fri, 11 Sep 2020 13:08:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Octo – Generate a serverless API from an SQL query]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24442294">thread link</a>) | @khalidlafi
<br/>
September 11, 2020 | https://octoproject.github.io/octo-cli/ | <a href="https://web.archive.org/web/*/https://octoproject.github.io/octo-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <a href="" title=" ">
    <img src="https://octoproject.github.io/octo-cli/assets/cover.png" alt=" ">
  </a>
  <br>
  <h4>Expose data from any database as web service.</h4>
  <p>
    Octo CLI makes the data available from any database as a web service on-demand, 
    simplifying the process of building data-driven applications.
     It can reduce costs, improve accessibility and performance.
  </p>
 

 <p><a href="" title=" ">
    <img src="https://user-images.githubusercontent.com/20528562/92949687-2b627080-f464-11ea-99e8-d3afad80922c.png" alt=" ">
  </a>
  </p>
     <div>
    <p><a href="https://github.com/octoproject/octo-cli" title="Documentation" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">View on Github</a>
    <a href="https://github.com/octoproject/octo-cli#examples" title="View on GitHub" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">Get started</a>
  </p></div>
</div></div>]]>
            </description>
            <link>https://octoproject.github.io/octo-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442294</guid>
            <pubDate>Fri, 11 Sep 2020 13:02:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to choose an FPGA dev board. A guide for 2020]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24441911">thread link</a>) | @blackSparrow
<br/>
September 11, 2020 | https://thedatabus.io/fpga-buying-guide | <a href="https://web.archive.org/web/*/https://thedatabus.io/fpga-buying-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Let's face it, It is not easy to choose a freaking PC these days with the deluge of specifications that come with it let alone FPGAs. The question of using FPGAs to solve any computing problem only arises when an extraordinary performance is required. Owing to this fact, FPGAs in their feature specification and build can be extremely specific to the application at hand. This results in an insane number of varieties in terms of the logic structures within the FPGA as well as the interfaces that are provided with the external world. However, this guide aims to guide you in the right direction (which does not mean dumping a list of the hundreds of different options out there) based on your level of experience and requirement.</p>
<p>There are other posts out there that provide large tables with exhaustive lists of FPGA development boards out there and let you (after a year or two of research) make a choice. If that's your thing, I'll attach some links to help you get started.</p>
<hr>
<p><em>If you're already familiar with the various bells and whistles of  FPGAs and are only looking for some good suggestions, you might prefer to <a href="https://thedatabus.io/fpga-buying-guide#the-top-contenders"><strong>JUMP TO THE LIST OF SUGGESTIONS</strong></a>.  If not, read on to learn some very important stuff about the FPGA world and how to choose better!</em></p>
<h2 id="what-you-should-be-looking-for"><a href="#what-you-should-be-looking-for" aria-label="what you should be looking for permalink"></a>What you should be looking for</h2>
<p>There are already a lot of aspects to an FPGA in general that determine its fit to a particular problem and the ease with which it can be programmed, now add to this the complexity of a feature-rich development board with all sorts of peripherals, interfaces, connectors and memory options you have at hand a humongous task of deciding between hundreds of varieties out there.</p>
<h3 id="soc-based-board-or-just-an-fpga"><a href="#soc-based-board-or-just-an-fpga" aria-label="soc based board or just an fpga permalink"></a>SOC based board or just an FPGA?</h3>
<p>SOC stands for <a href="https://semiengineering.com/knowledge_centers/integrated-circuit/ic-types/system-on-chip/" target="_blank">System-on-Chip</a> which simply means that various interacting technologies are built onto the same die (/chip). You see SOCs everywhere, on your phones, TVs, and computers. In the context of an FPGA development board, a SOC based system means that the hardware has two components, a sea of programmable logic (the FPGA) and a hard processor core implemented in silicon independent of the programmable FPGA logic. Interfaces are created between the programmable logic and the processing system (in Xilinx lingo) that enable communication between the two regions.</p>
<p><img src="https://thedatabus.io/static/zynq7000-ae213195db5b530cc3f5d60785b3b0b1.png" alt="Zynq7000"></p>
<p>If you are an absolute beginner looking for direction, you should definitely choose a SOC based system because of the immense additional learning potential it adds. Having said that, your first few digital design projects should never involve the processor cores or any kind of software programming. For that, you can just ignore the processor logic and dump your design into the programmable region to use it as a normal FPGA. As you progress, you can add much higher levels of complexity to your design by bringing in the processor core to directly read and write data in your configurable hardware. You can also experiment with writing firmware, drivers, the Linux OS, and the higher levels of abstraction thus getting a truly holistic experience of embedded system design. Even the simplest SOC based board will keep you busy for a long time. </p>
<p>These boards can also be of great interest for Software engineers looking to explore into the digital design world since processor + FPGA structures lend themselves very well to paradigms like HLS, Heterogenous computing and partial acceleration of algorithms. Viewing the FPGA logic as an extension of the SOC is something that is going to be very important in the future and is a good investment of your time.</p>
<p>Alternatively, If you are a beginner but are looking only to learn digital design or you wish to buy a board to complement your studies at college where you get to use a particular board in your lab, you can get a lot more basic FPGA resources (LUTs, BRAMs, DSPs) on a Non-SOC based board that has only the FPGA. This way you save money and have a much less complex system at hand that you can comprehend better. The same is true If you plan to implement something specific that takes up an enormous number of resources, you might be better off going for a dev board that has only the FPGA and the required peripherals.</p>
<p>At the end of <a href="https://www.reddit.com/r/FPGA/comments/9yutk8/best_100300_fpga_development_board_in_2018/?utm_source=share&amp;utm_medium=web2x&amp;context=3" target="_blank">this post</a> on the subreddit <a href="https://www.reddit.com/r/FPGA/" target="_blank">r/FPGA</a> user <strong>u/ndbroadbent</strong> has shown the resource usages of several open source projects, this can give you a good idea of how big projects usually are.</p>
<p><strong>An important note for beginners</strong> : <em>Having an SOC board, with all the processor logic around the FPGA can really deviate you from the basic idea of programmable logic and how you're supposed to learn it. I strongly suggest completely disregarding anything to do with the processor for your first few projects and use only the FPGA part of the device. Also note that as of today, any good FPGA engineer will tell you that any form of <a href="https://en.wikipedia.org/wiki/High-level_synthesis#:~:text=High%2Dlevel%20synthesis%20(HLS),hardware%20that%20implements%20that%20behavior."><strong>HLS</strong></a> is not good enough to be used in real world projects. This is doubly true for the beginners. <strong>DO NOT</strong> fall into the 'Write code in C++/Python and run it on FPGA' trap. A lot of youtubers seem to be promoting stuff like that for beginners these days which is just sad. If you have the money to spend, the ideal (and more enjoyable) learning strategy would be to use a standalone FPGA board first and upgrade to an SOC later.</em></p>
<hr>
<h3 id="interfaces-and-ios"><a href="#interfaces-and-ios" aria-label="interfaces and ios permalink"></a>Interfaces and IOs:</h3>
<p>FPGAs are excellent tools for working on high-speed interfaces. So you might want to look at the interfaces and IO options a particular development board is providing. This is important because if the board has a particular interface out of the box, the vendor will probably provide the necessary documentation and sample designs for those interfaces. This can save you tons of head-scratching and hair-pulling (trust me that is common in the FPGA world) as a beginner. That's not to say that newer interfaces cannot be added to the board manually but when it comes to High-speed interfaces like Ethernet, HDMI, PCIe, it can be very difficult to add them yourself and expect reliable performance. Low-speed ones like SPI, UART, etc can always be manually added using the GPIOs, so let them not be the dealbreaker for any board.</p>
<p>Some common networking interfaces that you should look for are high-speed interfaces like <a href="https://en.wikipedia.org/wiki/HDMI" target="_blank"><strong>HDMI</strong></a>  <a href="https://en.wikipedia.org/wiki/Video_Graphics_Array" target="_blank"><strong>VGA</strong></a>  <a href="https://en.wikipedia.org/wiki/Ethernet" target="_blank"><strong>ETHERNET</strong></a>  <a href="https://en.wikipedia.org/wiki/PCI_Express" target="_blank"><strong>PCIe</strong></a>  etc. and low-speed peripherals like <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface" target="_blank"><strong>SP</strong>I</a>  <a href="https://en.wikipedia.org/wiki/CAN_bus" target="_blank"><strong>CAN</strong></a>  <a href="https://en.wikipedia.org/wiki/I%C2%B2C" target="_blank"><strong>I2C</strong></a>  etc.</p>
<p>Although not as important for a beginner, another set of interfaces that can be useful are the analog and sensor interfaces like ADCs, DACs, Camera Interface, Audio CODECs, etc. These are very niche features that can make or break a particular project if it depends on data acquisition from the external world.</p>
<p>If you choose to go for a board with not too many peripherals for whatever reason, you might be better off choosing one that has the industry-standard <a href="https://store.digilentinc.com/pmod-modules-connectors/" target="_blank"><strong>PMOD</strong></a> or <a href="https://en.wikipedia.org/wiki/FPGA_Mezzanine_Card" target="_blank"><strong>FMC</strong></a> connectors installed so that when you do need additional interfaces in the future, they can be added very easily. These standard connectors essentially decouple FPGA carrier boards from the IO engines (which plug-in as daughter cards), enabling you to use the same FPGA boards with a large variety of IO designs without ever having to re-design the board.</p>
<hr>
<h3 id="buttons-leds-and-displays"><a href="#buttons-leds-and-displays" aria-label="buttons leds and displays permalink"></a>Buttons, LEDs, and Displays:</h3>
<p>Debugging FPGA designs can be a hard thing. Unlike MCUs where you can place print statements and breakpoints anywhere you want in the code, there is no such equivalent in the FPGA world and that can often lead to great frustration. One workaround is possible, if there are switches and LEDs on your board. They provide an easy way to pull out signals to the real world and give you an indication of the status of some status registers that can help you visualize and debug (like the current state of a state machine or a particular flag in a CPU design). However, this should not be the deciding factor between two boards since it is very easy to add LEDs, buttons, switches, and LCDs using the GPIO connectors without much effort.</p>
<hr>
<h3 id="memory-and-resource-count"><a href="#memory-and-resource-count" aria-label="memory and resource count permalink"></a>Memory and Resource Count:</h3>
<p>The Resource Count is another important metric that goes into deciding on an FPGA device. By resource, we mean the number of programmable logic elements available on the board. These can be LUTs (ALMs for Altera), Block Rams, DSPs, and IO blocks. Much more complex and fancier devices like the  <a href="https://www.xilinx.com/products/silicon-devices/acap/versal.html" target="_blank"> Versal family</a> from Xilinx can have lots of other stuff like AI, video, and audio cores, etc. It is important to take note of these resource numbers because they determine the biggest project that you can successfully fit onto the FPGA. It is hard to come up with a fixed count for a particular project owing to differences in the underlying CLB architecture from vendor to vendor and family to family.</p>
<p>FPGAs store the configuration(bitstream) data on the SRAM (usually) cells within the FPGA. Since SRAM is a volatile kindof memory, the program is lost each time the board is power-cycled. A PC support is needed to reprogram it again after the power cycle, to prevent this, FLASH (or EEPROM in older boards) based storage is provided onboard by the vendors. Flash is a non-volatile form of storage that holds the bitstream data even without a power supply. Each time the board comes up after a power cycle, the FPGA checks the flash memory for a bitstream and programs itself with it. This is usually given by default in most boards but can be something important to look out for. </p>
<p>The other important form of memory is the external onboard volatile storage which is most commonly provided in the form of a <a href="https://en.wikipedia.org/wiki/DDR_SDRAM" target="_blank">DDR SDRAM</a>  This is extremely useful if you are building an application that needs to store data locally for whatever reason. Since the block ram storage within the FPGA fabric is very little and is very precious, having a DDR that can be written to and read from in a reasonable amount of time is very much essential. The more the better!
<a href="https://numato.com/kb/learning-fpga-verilog-beginners-guide-part-6-ddr-sdram-a7/" target="_blank">This</a> tutorial and <a href="https://www.electronics-notes.com/articles/electronic_components/semiconductor-ic-memory/sdram-synchronous-dram-what-is.php" target="_blank">this</a> one can get you started with the interface that needs to be coded in order to communicate with the DDR chip.</p>
<hr>
<h3 id="learning-resources-and-community-support"><a href="#learning-resources-and-community-support" aria-label="learning resources and community support permalink"></a>Learning Resources and community support:</h3>
<p>Unlike the world of software or MCU based design, the world of digital design and FPGAs have far fewer general resources in terms of …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedatabus.io/fpga-buying-guide">https://thedatabus.io/fpga-buying-guide</a></em></p>]]>
            </description>
            <link>https://thedatabus.io/fpga-buying-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441911</guid>
            <pubDate>Fri, 11 Sep 2020 12:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Checked exceptions: Java’s biggest mistake (2014)]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 238 (<a href="https://news.ycombinator.com/item?id=24440536">thread link</a>) | @flying_sheep
<br/>
September 11, 2020 | http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/ | <a href="https://web.archive.org/web/*/http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	
	<!-- .entry-header -->

		<div>
		<p>Checked exceptions have always been a controversial feature of the Java language.</p>
<p>Advocates claim they ensure checking &amp; recovery from failures. Detractors say “catch” blocks can almost never recover from an exception, and are a frequent source of mistakes.</p>
<p>Meanwhile, Java 8 and lambdas are here. Are checked exceptions becoming obsolete in the Java world?<span id="more-174"></span></p>
<h3>The Intent of Checked Exceptions</h3>
<p>In the mid 90’s, James Gosling at Sun came up with a new language.</p>
<p>At the time, C++ programming required every single function return to be checked for error. He decided there had to be a better way, and built the concept of “exceptions” into Java.</p>
<p>The intent of <strong>checked exceptions</strong> was to locally flag, and force developers to handle, possible exceptions. Checked exceptions have to be declared on a method signature, or handled.</p>
<p>This was intended to encourage software reliability &amp; resilience. There was an intent to “recover” from contingencies – predictable outcomes other than success, such as InsufficientFundsException on attempting a payment. There was less clarity, as to what “recovery” actually entailed.</p>
<p><strong>Runtime exceptions</strong>&nbsp;were also included in Java. Since null pointers, data errors, and illegal states/ accesses could occur anywhere in code, these were made subtypes of RuntimeException.</p>
<p>Runtime exceptions can be thrown anywhere, without requiring to be declared, and are much more convenient. But would it be correct to use them instead?</p>
<h3>The Drawbacks</h3>
<p>The crucial point here, is that runtime &amp; checked exceptions are functionally equivalent.&nbsp;There is no handling or recovery which checked exceptions can do, that runtime exceptions can’t.</p>
<p>The biggest argument against “checked” exceptions is that most exceptions can’t be fixed. The simple fact is, <strong>we don’t own the code/ subsystem that broke.&nbsp;</strong>We can’t see the implementation, we’re not responsible for it, and can’t fix it.</p>
<p>Particularly problematic were the areas of JDBC (SQLException) and RMI for EJB (RemoteException). Rather than identifying fixable contingencies as per the original “checked exception” concept, these forced pervasive systemic reliability issues, not actually fixable, to be widely declared.</p>
<p>For any method, the possibility of failure includes all sub-methods called by it. Potential failures accumulate up the call tree. Declaring these on method signatures no longer offers a specific &amp; local highlight for the developer to watch for – declared exceptions spread throughout the call tree.</p>
<p>Most EJB developers have experienced this – declared exceptions become&nbsp;required on methods through the tier,&nbsp;or entire codebase. Calling a method with different&nbsp;exceptions&nbsp;requires dozens of methods to be adjusted.</p>
<p>Many developers were told to catch low-level exceptions, and rethrow them again as higher (application-level) checked exceptions. This required vast numbers – 2000 per project, upwards – of non-functional “catch-throw” blocks.</p>
<p>Swallowing exceptions, concealing the cause, double logging, and returning ‘null’/ uninitialized data all became common. Most projects could count 600+ mis-coded or outright errors.</p>
<p>Eventually, developers rebelled against the vast numbers of “catch” blocks, and the source of error these had become.</p>
<h3>Checked Exceptions – incompatible with Functional Coding</h3>
<p>And then we get to Java 8, with its new <i><b>functional programming&nbsp;</b></i>features – such as lambdas, Streams, and function composition.</p>
<p>These features are built on generics – parameter &amp; return types are genericized, so that iteration &amp; stream operations ( <code>forEach</code>, <code>map</code>, <code>flatMap</code>) can be written which perform a common operation, regardless of item type.</p>
<p>Unlike data types, however, declared exceptions can’t be genericized.</p>
<p>There is no possibility in Java to provide a stream operation (like, for example, &nbsp;<code>Stream.map</code>) which takes a lambda declaring some checked exception, &amp; transparently passes that same checked exception to surrounding code.</p>
<p>This has always been a major points against checked exceptions – all intervening code, between a throw and the receiving “catch” block, is forced to be aware of exceptions.</p>
<p>The workaround, of “wrapping” it in a RuntimeException, conceals the original type of the exception – rendering the exception-specific “catch” blocks envisaged in the original concept useless.</p>
<p>Finally we can capture Java’s new philosophy in a nutshell, by noting that none of the new “functional interfaces” in Java 8 declare checked exceptions.</p>
<h3>Conclusion</h3>
<p>Exceptions in Java provided major benefits in reliability &amp; error-handling over earlier languages.&nbsp;Java enabled reliable server &amp; business software, in a way C/ C++ never could.</p>
<p>Checked exceptions were,&nbsp;in their original form, an attempt&nbsp;to handle&nbsp;<i>contingencies</i>&nbsp;rather than&nbsp;<i>failures</i>.&nbsp;The laudable goal was to highlight specific predictable points (unable to connect,&nbsp;file not found,&nbsp;etc) &amp; ensure developers handled these.</p>
<p>What was never included in the original concept, was to force a vast range of systemic &amp;&nbsp;unrecoverable failures to be declared. These <em>failures</em>&nbsp;were never correct to be&nbsp;declared as checked exceptions.</p>
<p>Failures are generally possible in code, and EJB, web &amp; Swing/AWT containers already cater for this by providing an outermost “failed request” exception-handler. The most basic correct strategy is to rollback the transaction &amp; return an error.</p>
<p>Runtime exceptions allow any exception-handling possible with checked exceptions, but avoid restrictive coding restraints. This simplifies coding &amp; makes it easier to follow best practice of&nbsp;<a href="http://wikijava.org/wiki/10_best_practices_with_Exceptions#Throw_early_catch_late" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://wikijava.org']);">throw early, catch late</a>&nbsp;where exceptions are handled at the outermost/ highest possible level.</p>
<p>Leading Java frameworks and influences have now definitively moved&nbsp;away from checked exceptions. Spring, Hibernate and modern Java frameworks/&nbsp;vendors&nbsp;use only runtime exceptions, and this convenience is a major factor in their popularity.</p>
<p>Personalities such Josh Bloch (Java&nbsp;Collections framework), Rod Johnson, Anders Hejlsberg (father of&nbsp;C#), Gavin King&nbsp;and&nbsp;Stephen Colebourn&nbsp;(JodaTime)&nbsp;have all come out against checked exceptions.</p>
<p>Now, in&nbsp;Java 8,&nbsp;lambdas are&nbsp;the&nbsp;fundamental step forward.&nbsp;These language features&nbsp;abstract the “flow of control” from functional operations within. As we’ve seen, this makes checked exceptions &amp; the requirement to “declare or handle immediately” obsolete.</p>
<p>For developers, it is always important to pay attention to reliability &amp; diagnose likely points of failure (contingencies) such as file open, database connection, etc. If we provide good error messages at this points, we will have&nbsp;created&nbsp;self-diagnosing software – a pinnacle of engineering achievement.</p>
<p>But we should do this with unchecked exceptions, and if we have to rethrow, should always use RuntimeException or an app-specific subclass.</p>
<p>As&nbsp;Stephen Colebourn says, if your projects&nbsp;are&nbsp;still using or advocating checked exceptions, your skills are 5-10 years out date.&nbsp;Java&nbsp;has moved&nbsp;on.</p>
<p><strong>How are you dealing with exceptions &amp; reliability? Add your thoughts now.</strong></p>
<p>References:<br>
– <a href="http://www.oracle.com/technetwork/articles/entarch/effective-exceptions-092345.html">Oracle: Barry Ruzek, Effective Java Exceptions<br>
</a>– <a href="http://tutorials.jenkov.com/java-exception-handling/checked-or-unchecked-exceptions.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://tutorials.jenkov.com']);">Jacob Jenkov: Checked or Unchecked Exceptions</a><br>
– <a href="http://googletesting.blogspot.co.nz/2009/09/checked-exceptions-i-love-you-but-you.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://googletesting.blogspot.co.nz']);">Google Testing blog: &nbsp;Checked exceptions, you have to go</a><br>
–&nbsp;<a href="http://www.artima.com/intv/handcuffs.html">Ander Hejlsberg on checked exceptions<br>
–</a>&nbsp;<a href="http://blog.joda.org/2010/09/checked-exceptions-bijava_9688.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://blog.joda.org']);">Stephen Colebourne: Remove checked exceptions from Java</a></p>
<p>Counter-argument: &nbsp;James Gosling<br>
– <a href="http://www.artima.com/intv/solid.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.artima.com']);">James Gosling on checked exceptions</a></p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440536</guid>
            <pubDate>Fri, 11 Sep 2020 08:57:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 170 (<a href="https://news.ycombinator.com/item?id=24439612">thread link</a>) | @zoozla
<br/>
September 10, 2020 | http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I was first diagnosed with depression when I was working on a startup in 2007. I went to the doctor, told him I was feeling mild flu symptoms for a couple of months, he asked me a few questions, determined that I had depression, gave my some SSRIs, and sent me home.</p>



<p>It worked for a while, but then 2008 happened, our startup collapsed, the stakes got higher and the depression came back. The doc recommended I up the dosage, but I could see this would eventually lead me to a straitjacket.</p>



<p>Over the years I’ve tried different meds, various forms of therapy, studied and actively practiced life coaching, got married, had kids, moved to another country and changed everything I could think of about my life. Unfortunately the dark bouts of depression remained.</p>



<p>About four years ago I stumbled on a book called Highly Sensitive Person that absolutely blew my mind. I realized I had very intense emotions that I was culturally programmed to repress, which caused my psyche to overload and go into full apathy mode also known as clinical depression.</p>



<p>I’ve been on a path to figure out how to process my emotions without repressing them and combined my personal experience with several non-mainstream techniques to build Wuju. It’s an online app that can help you tap into your hidden emotions and release them so they no longer influence your behaviour or cause depressive symptoms.</p>



<p>I’ve used it in the last 18 months to deal with parenting two kids, surviving infidelity, losing my job, starting a business, and covid anxiety. My longest bouts of depression now last a day at most and even that doesn’t happen too often.</p>



<p>You can try it too: <a href="https://beta.wuju.app/">beta.wuju.app</a></p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439612</guid>
            <pubDate>Fri, 11 Sep 2020 06:02:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Musings on the Impossibility of Testing]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24439511">thread link</a>) | @george3d6
<br/>
September 10, 2020 | https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing | <a href="https://web.archive.org/web/*/https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-09-11</p>
        
<p>I'm always a bit flabbergasted when I see how people test their code (especially with unit tests). Often I can't figure out a cohesive set of rules based on which the tests are written.</p>
<p>Testing seems to work from a pragmatic perspective, we have evidence it works, but different people define "testing" in different ways. I'm awfully afraid that what some people refer to as "testing" is completely unrelated to that unrigorous but pragmatic practice that saves us from production bugs.</p>
<h2>I - A contrived example</h2>
<p>To showcase my arbitrary formalism as it relates to testing, I think it's worthwhile to look at some cases:</p>
<h4>1)</h4>
<pre><code># Testing a multiplication function
func multiply(int a, int b) -&gt; int

func test_1():
  assert 2*5 == multiply(2,5)
  assert 10*12 == multiply(12,10)

func test_2():
  assert 10 == multiply(2,5)
  assert 120 == multiply(12,10)

func test_3():
  assert type(multiply(2,5)) == int
  assert type(multiply) == func(int,int)-&gt;int
</code></pre>
<h4>2)</h4>
<pre><code># Testing an image classification algorithm
func classify(arr[int] image) -&gt; str

func test_1():
  assert img_classification_nn(to_arr('cat.jpg')) == classify(to_arr('cat.jpg'))
  assert img_classification_nn(to_arr('dog.jpg')) == classify(to_arr('dog.jpg'))

func test_2():
  assert 'cat' == classify(to_arr('cat.jpg'))
  assert 'dog' == classify(to_arr('dog.jpg'))

func test_3():
  possible_targets = ['cat','cheta','tiger','dog','wolf','coyote','other']
  assert classify(to_arr('rand_img_1.jpg')) in possible_targets
  assert classify(to_arr('rand_img_2.jpg')) in possible_targets
</code></pre>
<p>For both examples, <code>test_1</code> obviously makes no sense. You're testing the functionality of a function using another function that does the same thing. If the function used to assert correct functionality is better (i.e. if <code>*</code> is better than <code>multiply</code> or <code>img_classification_nn</code> is better than <code>classify</code>), than one should simply use that function instead. If they are equally flawed, then the tests are redundant.</p>
<p>These kinds of tests are a theatrical performance to build up an illusion of quality. Usually spotted in enterprise-grade codebases and teams that harp on about TDD a lot, I'll classify these as <strong>redundant checks</strong>.</p>
<hr>
<p>Next, <code>test_2</code> is more interesting, it's comparing the result of a function with what a human would expect the result of that function to be. Here I would argue the test makes sense for the <code>classify</code> function but not for the <code>multiply</code> function.</p>
<p>Computers are good at multiplying, humans are horrible at it. So testing this function against an arbitrary number of human answers is much more likely to reveal flaws with the human's answer rather than the computer's. Since the function is very simple, time would probably better spent reviewing the actual code to make sure it's error-free.</p>
<p>On the other hand, computers aren't very good at classifying images (though they are getting there), but humans are spot on. So using a human's answers to validate a vision algorithm makes perfect sense.</p>
<p>We'll call these types of tests <strong>human validations</strong>.</p>
<hr>
<p>Finally, we get to <code>test_3</code>, which superficially seems less flawed than the other two. It's more of a sanity check than a test, we aren't checking the actual return value of the function in a given case, we are instead checking a higher-level behavior.</p>
<p>These tests are much more common in the codebases of dynamic languages, and for good reason. In our first example, we are just validating the signature of a function, something a compiler will implicitly do for us in any statically typed language.</p>
<p>In the second example, we are instead working around a limitation of our type system. We are checking if the result of our function (a string) is contained within 7 different values (the possible things our function should classify images as), which we could test implicitly by using a language that supports <code>enum</code> types and writing <code>classify</code> such that it returns an enum of those 7 classes.</p>
<p>Basically, these kinds of tests can be useful, but they are the kind of things a compiler can handle automatically when they are present they usually indicate a mistake in the language the programmer is using for the project. We'll call these <strong>compiler rules</strong>.</p>
<hr>
<p>Obviously, this system is fairly arbitrary, it's just a conclusion I reached after looking at various codebases and talking with various people about their tests, but I find that it works quite well.</p>
<p>To re-iterate, we have:</p>
<ul>
<li>redundant checks</li>
<li>human validation</li>
<li>compiler rules</li>
</ul>
<h2>II - Compiler rules</h2>
<p>Compiler rules are great, but it's a bad sign when they leak into your testing.</p>
<p>Some amount of compiler rules leaking into testing can't be helped. Until the advent of Rust and/or well-performing libraries for safe multi-threading, testing thread safety should have been a requirement in many codebases. Similarly, before modern type system and allocation techniques, one ought to assume various now-pointless memory checks might have fared well within a codebase (and, I assume, still do on some embedded devices).</p>
<p>Even more, switching to more modern languages and compilers is often a task much harder than just writing some tests, but I think these tests should be viewed as a cautionary sign against the language currently used. If they only cover a small but critical percentage of the codebase, everything is fine, if they cover most of it, it's an indicator of using the wrong compile-time tooling.</p>
<p>The one difficult thing about these tests might be spotting them, an inexperienced team might be writing loads of these tests without realizing there are better alternatives to the compile-time toolchain they are using which would replace the need for them.</p>
<h2>III - Redundant checks</h2>
<p>Redundant checks are often pointless busywork, but they can serve a valuable role in some cases.</p>
<p>The two main scenarios that come to mind are as follows:</p>
<ol>
<li><p>Given two versions of the same function, one well-proven and one "experimental", where the "experimental" function has some benefits in terms of performance or generalizability, it seems reasonable to test the "experimental" function using the well-proven approach. Still, the overhead here is so severe I find it difficult to think of a real-world example where this applies.</p>
</li>
<li><p>Given two versions of the same function, one in a "new" codebase and one an "old" codebase, it makes sense to test the "new" version with the "old" version. In this sense, going back to compiler rules, redundant checks can be useful in the process of refactoring, especially for major changes like changing the language or the core framework upon which the project is built. However, this seems useful only as a "temporary" measure rather than a permanent fixture of a project.</p>
</li>
</ol>
<p>That being said, I'd wager that most tests falling in this category, as mentioned before, are there only as "filler" and indicative of a much bigger underlying problem of a team that engages in busywork. If I ever accepted such a test, I would require plenty of complimentary comments to explain why they exist and when they can be removed.</p>
<h2>IV - Human validation</h2>
<p>Human validation is the "sanest" type of testing one can perform, it can be replaced by good practices or good languages. The problem with human validation comes from the fact that in some cases human intelligence can't solve the problems the software is designed to solve or can't cover all the edge cases the software will encounter.</p>
<p>Take for example banking software. It's fairly easy to imagine what should happen with a piece of banking software that provided dozens of customers, hundreds of transactions, and a few regulatory restrictions. All the logic there can be written down into tests that validate our software. However, the software itself must scale to millions of customers, trillions of transactions, and thousands of regulatory restrictions. Something a human mind can't comprehend coherently in order to write the tests.</p>
<p>Still, banking software is an easy example, because the various components might be test-able and their limited logic might be fully comprehensible by a human, even accounting for all the edge cases. This is because the inputs to the software are very well defined, there are only so many things one can do with a banking API, a finite space which a human mind can explore exhaustively when properly broken down.</p>
<p>One real problem arises when we have software with a very broad and/or poorly define input and/or outputs spaces. A few examples of these would be:</p>
<ul>
<li>Scrappers that distill information from a broad range of websites (e.g. the ones used by a search engine)</li>
<li>Machine learning algorithms meant to work on a broad range of data (e.g. a decision tree or a gradient boosting classifier implementation in a library like sklearn)</li>
<li>Any software that has to work well with user-provided code extensions (e.g. think a video game-like Skyrim that has to support mods)</li>
<li>Simulation software (e.g. physics simulations)</li>
<li>Creative software (e.g. multimedia editing &amp; creation, game engines)</li>
<li>Compilers</li>
</ul>
<p>One can separate these into components with input-output spaces that can be easily comprehended by the human mind, but some components that suffer from the above problems are bound to remain. It also introduces the problem of writing code separation in such a way that components can be easily tested, rather than with refactoring, extension, speed, or readability as the main concern.</p>
<h2>V - Human validation and cost</h2>
<p>Assuming that we've designed our software such that it has many human-comprehensible components, the issue of cost remains. Human-comprehensible is a vague term, there are many things which, given enough time, a person could write exhaustive tests for, but in practice, this often takes more time than we can allocate. Furthermore, in certain situations, even in the limited input&amp;output space scenario, it might still be easier to write the "generative" logic (the one that maps inputs to outputs) than to come up with mappings ourselves.</p>
<p>In certain cases, exhaustive validation can be done, but it can be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing">https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing</a></em></p>]]>
            </description>
            <link>https://blog.cerebralab.com/Musings_on_the_impossibility_of_testing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439511</guid>
            <pubDate>Fri, 11 Sep 2020 05:41:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting macOS style hotkeys working in GNU/Linux]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24439205">thread link</a>) | @todsacerdoti
<br/>
September 10, 2020 | https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/ | <a href="https://web.archive.org/web/*/https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>Over the years I've used every operating system. Sometimes all at once. Recently I've taken to using Linux as my primary desktop operating system. Everything I need runs natively on Linux and because I have full control over my environment I never have down time due to forced updates. This is my desktop after all so I'm really switching from Windows where the Control key modifier paradigm is more or less the same as Linux. Still I didn't want to compromise on anything with this new configuration and there was one thing missing from my Macbook that I really wanted.</p>
<p>Of course what I'm talking about is the Command key or more colloquially known simply as the Apple Key and all the shortcuts and hot keys built into macOS that make it such a joy to use.</p>
<p><img src="https://technex.us/media/70" width="200"></p>
<blockquote>
<p><em>"Linux lets you change whatever you want."</em></p>
<p>Is a common thing that people say to bring up a positive aspect of GNU/Linux. Is this actually true though? Take for example my issue at hand: Changing copy/paste hotkeys for all programs. In truth, some tasks are so big in their scope few users would ever be capable of accomplishing them. At least not without a lot of contextual knowledge.</p>
<p>Getting macOS style hotkeys is actually an extremely difficult task in Linux. Especially when you want to avoid faking it by binding some keys to other keys on a per application basis.</p>
</blockquote>
<p>Then there's the question of why do it at all?</p>
<p><span><span>The truth is I just got tired of </span></span><span><span>accidentally sending SIGINTs when switching to terminal and then accidentally triggering the wrong thing when switching out of terminal. I've just gotten so used to not having to context switch my brain in macOS between programs. It's one of the things that truly makes my Macbook Pro more pleasant to use.</span></span></p>
<p><span><span><img src="https://technex.us/media/73"></span></span></p>
<p>So that's my first reason. Muscle memory.</p>
<p>My second reason is simply that Command/Meta is directly next to the space bar and I just like having a shorter stretching span for my hand.</p>

<h3>Making it work</h3>
<p>For the most part GUI applications written for Linux tend to make a lot of assumptions about what hotkeys can and should be in a very opinionated way. Some types of programs require full customization (like code editors) while others like browsers tend to force certain hotkeys. Desktop managers do provide their own hotkey bindings. For example most KDE based applications will use your settings from KDE's "System Settings" to set hotkeys. Meanwhile in Gnome you can use dbind to set your keybinds.</p>
<p>Of course Cut/Copy/Paste is not enough. It would actually be quite jarring to use CTRL+T for opening a new tab immediately after using Command+V to paste something. Indeed if you go down this path you'll end up having to redefine your hotkeys for well..... everything. It is unfortunate as well that applications these days are extremely hostile to user settings.</p>
<p>Despite the hurdles in front of me I decided to try to make it work.</p>
<p>The first thing I did was swap Left Alt and Left Meta on my keyboard. This was actually pretty easy to do with keyboard mapping configs with the KDE GUI simply known as "System Settings". This was simply to make my normal windows keyboard place the buttons in the positions a real mac keyboard would have. None of this is necessary if you have a real Apple layout keyboard. This setting is only active while in my X session so any alternative TTYs would revert back to my stock layout. If I had a real Apple layout keyboard though this is not necessary at all.</p>
<p><img src="https://technex.us/media/71"></p>
<p>This setting is saved to the text file <code>~/.config/kxkbrc.</code></p>
<pre><code>$ cat kxkbrc 
[Layout]
DisplayNames=
LayoutList=us
LayoutLoopCount=-1
Model=pc101
Options=altwin:swap_lalt_lwin
ResetOldOptions=true
ShowFlag=false
ShowLabel=true
ShowLayoutIndicator=true
ShowSingle=false
SwitchMode=Global
Use=true
</code></pre>
<p>Now with this setting I am able to fake the same key mapping as a real macOS&nbsp;keyboard would have in my desktop session. So far so good. Now I manually changed all my hotkeys in my code editors, terminal applications, and even in the System Settings app I just mentioned to set global hot keys for all KDE applications. This took some time but was very straight forward for the most part.</p>
<p><img src="https://technex.us/media/72"></p>
<p>I went above and beyond even changing my shortcuts for things like Select All.</p>
<p>While this worked for KDE applications I had to also make this change for GTK+ based programs as well. Luckily this would also cover Chrome, Discord, Elements, and a number of other Electron based programs that I use on a regular basis.</p>
<p>I was lucky that VSCode let me change everything but it was very annoying have to redo all the system based hotkeys like Set cursor to start of the line (in macOS this is Meta+Left Arrow) for each and every place I wanted to use it.</p>
<p>Some websites also use Meta+C for example in Github hitting Meta+C will actually take focus and bring you to the Add Comment UI when in a thread so sometimes on Github.com even with Firefox set to use Meta+C to copy something I am not actually able to use my hotkey because the website overrides it.</p>
<p>With GTK I ended up editing <code>`</code><span><code>~/.config/gtk-3.0/gtk.css`</code> </span><span>and setting these hotkeys.</span></p>
<pre><code>@binding-set gtk-super-cut-copy-paste
{
        bind "&lt;super&gt;x" { "cut-clipboard" () };
        bind "&lt;super&gt;c" { "copy-clipboard" () };
        bind "&lt;super&gt;v" { "paste-clipboard" () };
        bind "&lt;super&gt;a" { "select-all" (1) };
        bind "&lt;super&gt;z" { "undo" () };
}

* {
        -gtk-key-bindings: gtk-super-cut-copy-paste
}
</code></pre>
<p>I might add more but for now this got me to where I wanted with most GTK+ applications. Note that if you plan to run any of programs designed to run as root that use GTK+ such as GParted you should also link or copy this config file to the root account home directory as well.</p>
<p>So in the end it is possible. I was able to achieve what I wanted with all but one program. But it was a huge pain. It's really difficult to figure out what settings do what in a Linux environment even when there is documentation. It's typical for documentation to exist for say GTK+ 2.0 and GTK+ 3.0 but there is no over arching best practice guide for what one should do when they want to cover all programs in an environment.</p>


<h3>It Doesn't Have to Be This Way</h3>
<p>The Linux ecosystem can and should do better. The ability to do whatever you want is a double edged sword where even though you can in theory change things, in practice however, sometimes changing things is so onerous that staying sane in the process is a task in itself.</p>
<p>So please if you are a Linux user space developer check the GTK+ 2.0 (<code>~/.gtkrc-2.0</code>), GTK+ 3.0 (<code>~/.config/gtk-3.0/gtk.css</code>) and KDE global shortcut configs (<code>~/.config/kdeglobals</code>) when you probe for the environment during startup so that people can choose their own hotkeys for their desktop environment or simply use the C libraries of each and use the hotkeys present.</p>
<p>Better yet, if you are a developer that already supports various input methods for macOS, Linux, and Windows you can simply provide a toggle for users.</p>
<p>It would be beneficial to Linux Desktop environments to agree to a standard config file for hotkeys allowing users to bind keys as they see fit rather than lurching from one weird keybinding config to the next with no centralization to speak off.</p>
	</div></div>]]>
            </description>
            <link>https://technex.us/2020/09/getting-macos-style-hotkeys-working-in-gnu-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439205</guid>
            <pubDate>Fri, 11 Sep 2020 04:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giggle; Laughable Security]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24437865">thread link</a>) | @DyslexicAtheist
<br/>
September 10, 2020 | https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/ | <a href="https://web.archive.org/web/*/https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Preface: There is very little in this blog post that is interesting from a technical perspective. The discovered vulnerability is incredibly basic but fairly high risk. Due to the nature of the application, and the fallout from our disclosure attempt, we wanted to write up our findings. The TL;DR is that giggle has been exposing user’s phone numbers, private images and location to the world.</p>

<p>Normally we wouldn’t post a vulnerability like this so soon after discovering it but the owner of the app refuses to listen to us and continuously claims no vulnerability exists. We tried to get in contact with her via a third party (after we had been blocked) to let her read this post before publishing it but, again, she showed no interest.</p>

<p>(edit: We wrote but didn’t publish this article before the vulnerability was fixed. Giggle has told us it has now been fixed so we feel comfortable releasing these details.)</p>

<p>(edit2: Sall is threating us with legal action.)</p>

<p>(edit3: We’ve had some questions about the phrasing in the first public tweet. We standby our words. Not knowing how this would play out, we wanted to make it clear that we didn’t support the app or the founder, but wanted to report the issue. Companies can be unpredictable when reporting vulnerabilities and we wanted to avoid a situation where they would be publicly praising us or even mentioning us on their website etc.)</p>

<hr>

<h3 id="what-is-giggle">What is Giggle?</h3>

<p>This week I set up an account on an app called giggle. You see, last month I had been diagnosed with premature menopause I and wanted to find a safe space in a woman centric environment. Somewhere I could talk openly about this experience and maybe get some support, but also find some light hearted way to socialise online.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image1.jpeg.resize.jpeg" alt=""></p>

<p>Without much investigation I found giggle, which seemed to check all the boxes. A free app, promoting safe and secure social networking. Giggle promised a refuge from misogyny and sexism where I could find support and community.</p>

<p>There were a few red flags, such as an excessive use of pink and word “females”, but I decided to give it a go.</p>

<p>At this point the red flags became a little more crimson. Firstly, I was asked to submit my phone number so that a verification code could be sent to my mobile. Then I was asked to allow the app to access my camera so that a selfie of me could be submitted to verify I was female. This verification, apparently, is done using AI. From previous work done on this, we know this can often be notorious for mischaracterising and therefore excluding certain racial groups, some trans women and some masculine looking women.</p>

<p>The app assured me that my verification picture would not be stored so not to worry about what I looked like, so my gargoylesq visage was submitted (I’ll get to the later) and I was duly approved to enter the app.</p>

<p>I went to set up my profile to see what information was publicly available about me, even if only in the app, to find there wasn’t one and I had to set up multiple profiles or ‘giggles’ to start a tinder like experience on each specific subject I was interested in (I chose menopause, body image, hiking and wine tasting), that range from socialising and hobbies to more high risk areas such as abuse and sex work.</p>

<p>As I was curious how secure my data was, and as we are currently working on improvements to <a href="https://rex.digitalinterruption.com/">REX</a> (and thought they’d maybe like a <a href="https://www.digitalinterruption.com/100-free-rex-licences">free license</a>), we decided to dig a little deeper.</p>

<h3 id="viewing-account-details">Viewing Account Details</h3>

<p>Using BurpSuite and a fresh install of the app, we intercepted the network traffic and found a few interesting things that we decided not to look at further as we didn’t have permission to do a full analysis. During the registration process, as mentioned, users are required to verify a phone number and selfie. We submitted a selfie that wouldn’t pass and, unsurprisingly, couldn’t gain access to giggle.</p>

<p>Looking at the network requests revealed that although the account was in an unvalidated state, we still had a valid auth token (it turns out this is hardcoded into the application) allowing us to make requests to the API. Again, we didn’t perform a full analysis although we suspect issues could exist here. What we did look at was the UserList endpoint. This contained a filter parameter that contained my phone number, an operator (in this case “equals”) and a field (“mobile”). Presumably, this is how a user’s account details are fetched from the API.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image2.png.resize.png" alt=""></p>

<p>Of course, the obvious question is what would happen if we changed this filter parameter to be another phone number, changed the query to filter on another parameter such as user ID or user’s name or even would it remove the filter altogether, allowing us to view all accounts?</p>

<p>First, we decided to change the filter query so it would filter based on the GUID of the original account which we received during our initial analysis. This brought back the original account details which included the user’s phone number, age (which was set to hidden) and a latitude and longitude.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image3.png.resize.png" alt=""></p>

<p>Response:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image4.png.resize.png" alt=""></p>

<p>Having the phone number is bad enough, but we checked the returned latitude and longitude using Google Maps. Of course, this brought us to the very house I created the account in.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image5.png.resize.png" alt=""></p>

<p>This means an attacker that is completely unverified to the application can view the address and phone number of all users if they have the account ID. That is pretty bad in our opinion.</p>

<p>Next, we wanted to be able to download the same details without knowing the account ID. Looking at the filter parameter, it’s clear to see there would be many ways to do this. We could remove the filter completely although that would reveal other accounts to us which we were trying to avoid seeing or we could change the query to show all accounts not matching a phone number. As a proof of concept, we decided to change the operator field from “equals” to “contains” and truncated the GUID. As this returned the same data, it should be obvious to see how the query could be trivially modified to expose all registered accounts with no prerequisite account knowledge.</p>

<p>Request:</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image6.png.resize.png" alt="Burp Web Request"></p>

<h3 id="selfies">Selfies!</h3>

<p>What about the supposed private picture that is used to verify accounts? They claim not to store? Behold my gargoylesq visage!</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image7.png.resize.png" alt=""></p>

<p>If we look at the URL of the verification image (which we recovered by viewing network traffic in BurpSuite), we can see that the only thing that is required is the user GUID. As we can view the user GUID for every account (e.g. our test account) we can easily download the associated verification selfie. Although this is not terrible on it’s own, giggle do promise that this isn’t shared or published, and, given that it is available data stored along side my mobile number and geographical coordinates, with this information an attacker would know my address, my personal mobile number and what I look like.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image8.jpeg.resize.jpeg" alt=""></p>

<p>This is where we get to the really scary bit. Giggle has sections encouraging women to find support on abortion, abuse, addiction and relationships among other categories. The amount of available data means that with a phone number or name, an abusive partner would potentially be able to find the location of an abused woman and confirm her identity with the verification picture. There is also a section for sex workers, who, understandably would expect any app enabling them to advertise their work to have adequate privacy and security controls. Even if a user deletes their account, that data appears to still be saved by giggle.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image13.jpeg" alt=""></p>

<h3 id="account-deletion">Account Deletion</h3>

<p>The final thing we looked at is whether a deleted account is actually deleted. We deleted the original account using the “Delete Account” button and tried to view the associated account details.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image9.jpeg.resize.jpeg" alt=""></p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image10.png.resize.png" alt=""></p>

<p>Of course, they are still present and only set to Disabled meaning they are still stored by the system. Maybe accounts are deleted periodically. We would normally at this point reach out to the vendor and ask for clarification. This leads us to the next part of the story…</p>

<h3 id="disclosure">Disclosure</h3>

<p>We wanted to let giggle know that this vuln existed and ask for some further details, not in the small part because it is so easy to exploit. In the midst of this we had done some digging on the origins of the app and found that the founder had a very public anti-trans agenda. However, much as this sickens us, our job is to protect users so we direct messaged giggle through twitter.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image11.png.resize.png" alt=""></p>

<p>Having had no response, we decided to send them a tweet asking them to check their DMs with their founder cc’d in, but with a caveat that we do not share or endorse her anti-trans views.</p>

<p><img src="https://research.digitalinterruption.com/assets/img/2020-09-10-giggle-laughable-security/image12.png.resize.png" alt=""></p>

<p>That’s when we were dragged into a full on TERF War.</p>

<p>Our public tweet had no engagement at all until Sall, the giggle founder, decided to share a screenshot of it with her followers. We have since been subject to a tirade of abuse. None of it about the security of the app. Interested parties are free to view our twitter and find the hundreds and hundreds of tweets in response to trying to disclose this vulnerability but we decided not to copy that into this post.</p>

<p>Our founders have reached out to giggle and Sall and have been blocked following every attempt at contact. Our three year incorporated company has been accused of being a creepy bloke who runs private WhatsApp groups full of naked women, a front for the alt-left, making up the vuln to discredit Sall and her company and hypocrites for wanting to protect the data of users despite the apps founder having view that counter our own.</p>

<p>Our company and I (a woman) have been accused of being a man, and therefore a misogynist multiple times. We have been told that as men (60% of Digital Interruption are women), we should not have a say on the safety of women and their personal data.</p>

<p>Sadly, denial is not uncommon when trying to disclose. We are used to being ignored and even getting some pushback, but ultimately we feel it is our responsibility to persist and ensure the personal data of users is protected.</p>

<p>What has been staggering is the viciousness of the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/">https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/</a></em></p>]]>
            </description>
            <link>https://research.digitalinterruption.com/2020/09/10/giggle-laughable-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437865</guid>
            <pubDate>Thu, 10 Sep 2020 23:57:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I operated as a staff engineer at Heroku]]>
            </title>
            <description>
<![CDATA[
Score 359 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24437715">thread link</a>) | @craigkerstiens
<br/>
September 10, 2020 | http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html | <a href="https://web.archive.org/web/*/http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" aria-label="Content">
  <article>
    

    <div>
      

      

      <div>
        <div>
          <p>I was incredibly lucky to spend 5 amazing years at Heroku. By the end of my time, I was operating in a Staff capacity, although I’m honestly completely unclear which titles at Salesforce actually map to Staff.</p>

<p>Because titles are unclear and because my role was a little amorphous, I chose not to submit a story to Will Lethain’s <a href="https://staffeng.com/stories/">great collection</a> at StaffEng.com. That being said, I added a few questions to his questionnaire that I hadn’t seen answered elsewhere, so I figured I’d post this.</p>

<p><strong><em>Tell us a little about your current role: where do you work, your title and generally the sort of work do you and your team do.</em></strong></p>

<p>Until recently, I was a Principal engineer at Salesforce, working for their Heroku product. I joined almost five years ago, working on the Heroku Add-ons product, and then transferred to the Heroku API team. For the last year and a half, I worked on the API team for the Salesforce Functions product, which runs on top of Heroku infrastructure.</p>

<p>The API team is at the center of defining how the Salesforce Functions product will work, so there are a lot of different tasks our team does. First and foremost, we write the code to store the state that the customer <em>intends</em> their infrastructure to converge to and then push that down into the infrastructure layer. If you’re interacting with Salesforce Functions, you’re going through our code. We also do a lot of reconciling what the infrastructure can do with the hopes and dreams of product. I did a balance of work, but more towards the “hopes and dreams” side of things.</p>

<p><strong><em>What does a “normal” Staff-plus engineer do at your company? Does your role look that way or does it differ?</em></strong></p>

<p>There is really no “normal” Staff engineer at Salesforce. I usually talk about four different approaches I see in the company, some of which line up with <a href="https://staffeng.com/guides/staff-archetypes">Will’s archetypes</a> and some which don’t. A lot of folks are a mix of these and rotate through them over a long career at the company.</p>

<p><em>Team(s) Lead/Right Hand</em></p>

<p>You are the primary technical point of contact for 10-20 engineers, across one or more teams. You are typically reporting to a manager of managers. Responsibilities vary based on individuals’ strengths and the strengths of their manager, but there are some common things you <em>must</em> do. If you’re not making your delivery timelines and this is a surprise to your organization, you and your manager have a problem. If product has a dream and no one knows what it would take to build it (time, resources, architecture), you have a problem. If you can’t answer “Why are we building this in this way?” then you have a problem.</p>

<p><em>Product Architect</em></p>

<p>If it’s on TechCrunch or promoted at our corporate conferences, there is an Architect for it. If the project (40+ engineers) fails to be a success, you share responsibility along with the (typically) VP+ engineering manager and Product owner. If you have any type of personal presence, you will be put on a stage and in front of customers. This is the level where you’re helping advocate with your VP for major initiatives to go after certain markets. If we made the wrong bet, some blame is with product, but it’s also on you, and the manager probably won’t look great.</p>

<p><em>Deep Diver</em></p>

<p>You have a lot of deep technical expertise on a particular component or system. You tend to stay on a single team or a single area of the organization. If you work in our legacy codebases, which are the core of our profitability, you are basically unfireable because you know so much. You may write code for some of the gnarliest problems of the legacy system you’re being kept around for, but you’ll often find yourself spending more time interfacing with other teams to explain why your system can’t do what they want and how we can work around it to deliver on a reasonable timeline. You will work closely with your Team Lead on a daily/weekly basis and occasionally have your entire day/week blown up because the Product Architect has identified a need for your expertise and all of a sudden you’re being trotted out to present to some team you’ve never heard of.</p>

<p><em>The Management</em></p>

<p>There are two variants. First, you’re pendulum’ing over to a line manager role, but since your IC title is the same grade as Director or VP, making you a manager would result in a massive pay cut. You’re likely managing a smaller team, given Salesforce targets 12-15 reports. In the second variant, you’re roughly an extension of a VP+ leader. Maybe you’re working on how we keep our many thousands of engineers communicating well. Maybe you’re advising an SVP on where to make technical investments - does our company really have enough of a competitive advantage to go after that market? Sure, the SVP/C-suite person is being told by Product that if you only give us $100 million we can do a ton. Is that true? Hey, we just bought a multi-billion dollar business (or we’re about to): Can you figure out what we should do with them? Many, including Will, call this fire-fighting, but that’s too narrow a view of how these roles really deliver value to large companies: it’s fast-paced opportunity scouting and truth-telling. That being said, you’ll most likely be looking for opportunities and the real truth within the more challenged parts of the business, so I see the fire-fighting analogy.</p>

<p><strong><em>How do you define success in your role?</em></strong></p>

<p>First and foremost, I am successful if the folks I work with understand how business decisions tie into their day-to-day work.</p>

<p>At a minimum, this involves a fair amount of understanding why we’re being asked to build something, running ahead of the team to make sure product plans are in place for us, working across teams to come up with an achievable plan and then championing IC concerns as they crop up.</p>

<p>But it also means pushing forward discussions about what kinds of risk are worth taking on in our code at the moment. Is now the right time to commit to this abstraction? Is now the time to address a performance issue with a re-architecture? We’re moving quickly, but also seeing a lot of incidents - what kinds of testing should we invest in?</p>

<p>Success looks like seeing conversations about timeline and priorities between ICs start from a shared background. Success looks like having no major blow ups about “How could you suggest we ship this hack?” Instead, folks can talk about technical choices through a business lens: “I know we’re currently low on staff compared to our product ambitions, but is this the right place to simplify?” Success looks like a team with a shared goal for the quality and resiliency of code that we’re writing. Success also looks like other ICs feeling confident in advocating for changes, since they see our team making technical decisions with a consistent goal in mind. When I talk with ICs in 1:1s, there should be no “I’m not sure why I’m doing X” when it comes to code, infrastructure and incidents.</p>

<p>Next, I am successful when my management chain clearly understanding the particular risks we’re taking on. All of the architectural decisions a team makes will be wrong, eventually. Whether technology changes, our customer base changes or the product itself changes, it’s only a matter of time before we regret those big choices. The key is understanding what bets we’re making and how long we think before we’ll need to revisit them.</p>

<p>Architecture in a large enterprise is a lot about risk management. A large org has a lot of existing momentum in the market and naturally becomes more cautious. I only have a few places where I can advocate for higher-risk bets and those bets are going to be far lower risk than at a start up. While I need to embrace the fact that our decisions will be wrong, I need to be able to speak to the ways in which we will likely be wrong, when we’ll know and what our mitigation strategy will be.</p>

<p>Third, I am successful if I’m saying the right “No”s to my manager. If the ICs that report to my manager end up feeling like “I told you so” or “We knew this was a bad idea” and that wasn’t surfaced for a discussion, that’s on me. As a Staff engineer, I have the responsibility to course correct my manager when we’re over-committed or committed to the wrong thing.</p>

<p>Finally, I’m successful if my organization has a healthy engineering culture. No one person owns culture, but that doesn’t mean we all don’t equally share the burden of building a world-class engineering organization.</p>

<p><strong><em>How do you spend your time day-to-day?</em></strong></p>

<p>While I do write code from time-to-time, it’s only after I’ve delivered on my obligations on these four functions.</p>

<p><em>Information gathering</em> - In order to help my team understand the context within which we’re building a thing, I need a lot of information. I almost unfailingly start my day with a list of longer emails and docs of all varieties to digest. I also spend a fair amount of time in cross-org chats with assorted managers &amp; ICs, whose purpose is a combination of information gathering and the coaching I mention below.</p>

<p><em>Planning</em> - Knowing a bunch of stuff isn’t helpful unless we actually do something with it, so I also spend a lot of time in planning activities. This is a lot of writing docs and running meetings. Planning activities are usually very collaborative – I rarely know the most on any one thing, but I can knit them all together into a plan.</p>

<p><em>Context sharing</em> - Knowing what we want to do isn’t helpful unless a lot of people understand the plan, so the final category of work that’s execution oriented is sharing all of that context. I attend meetings with other teams to share what we are doing, I review PRs to make sure we’re making small decisions in-line with larger goals, and hold standing team 1:1s to make sure each person feels confident in the direction we’re headed.</p>

<p><em>Coaching &amp; Culture</em> - The final category of work isn’t oriented towards delivering a product, but it’s still critically important to our organization’s long-term health to invest in our engineers. My personal …</p></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html">http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html</a></em></p>]]>
            </description>
            <link>http://amyunger.com/blog/2020/09/10/staff-engineer-at-heroku.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437715</guid>
            <pubDate>Thu, 10 Sep 2020 23:32:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Content from the Dark Web to Provide Content to the Clear Web]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24437280">thread link</a>) | @puggo
<br/>
September 10, 2020 | https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/a-reverse-benefit.jpg" alt="Sometimes, the greater evil can serve the greater good."></p>
<hr>
<h2 id="everyone-wants-to-think-out-of-the-box-so-thats-not-thinking-out-of-the-box">Everyone wants to "think out of the box". So that's not thinking out of the box.</h2>
<p>Sometimes I think out of the box using the ideas from the people stuck in the box. Like, how can I take this idea that is stuck in the box, and liberate it from the box…you know what…nevermind. I’ll just explain.</p>
<hr>
<h3 id="a-fresh-source-of-content">A Fresh Source of Content</h3>
<p>So you may have heard that the dark web contains whistle blowers, free thinkers, radical innovators, and such like these, though you might run into a bad guy every now and then.</p>
<p>So before drawing out a large commentary on this subject, let me illustrate it with a common analogy, but slightly modified so as to exit the box.</p>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/paradigm-shift.png" alt="The Paradigm Shift of Thinking in the Box"></p>
<p>So in this case (and by this analogy only) the big dark box that people are thinking in is in the dark web. So to think “out of the box” as you’ve been told to do, you might have to <em>go into the box</em>. Consider this picture above: The <em><strong>text you do see</strong></em> is what is clearly written on the image. But the ALT TEXT in the image tag which you will probably not see says <strong>“The Paradigm Shift of Thinking in the Box”</strong>.</p>
<p>Unless you have a setting on your browser that shows alt text immediately, you wouldn’t discover this unless you dug for it, specifically. But then, why would you do that? You didn’t know it would be useful. It was hidden anyways. But there is an entire network that behaves like that Alt Text I just mentioned. (The hidden web, obviously).</p>
<h3 id="more-on-the-box">More on the Box…</h3>
<p>Ok, so your teacher or parents or marketing guru (who could benefit by you) said its a good thing to think out of the box. And maybe, like me, you thought you’d listen. But did the teacher ever tell you to:</p>
<ul>
<li>Change the box?</li>
<li>Poke holes in the box?</li>
<li>Shake the box?</li>
<li>Expose the box to rain and sun?</li>
<li>Put a king snake in the box?</li>
<li>Hide stuff in the box?</li>
</ul>
<p>Your not limited to thinking only outside the box. The box is really your plaything. Come and go at will. Why limit yourself to the place outside the box? Or in the box? Or why not switch to a bag, safe, or crate?</p>
<h3 id="thus-we-may-use-the-box-to-our-advantage">Thus, we may use the box to our advantage.</h3>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/ben-linus.jpg" alt="What if I told you that somewhere on this island there’s a very large box and whatever you imagined, whatever you wanted to be in it, when you opened that box there it would be."></p>
<blockquote>
<p>“What if I told you that somewhere on this island there’s a very large box and whatever you imagined, whatever you wanted to be in it, when you opened that box there it would be.”” - <a href="https://en.wikipedia.org/wiki/Ben_Linus">Ben Linus</a></p>
</blockquote>
<p>Since in this case we are considering the dark web as being the box (the box that NOBODY SHOULD ENTER) we can now think out of the box by going into the box.</p>
<h2 id="and-now-the-keynote-address">And now, the Keynote Address</h2>
<p>Search engines can easily judge the originality of content based on other content that appeared before it on the <em>clearnet</em>. But at this time they <em>generally</em> don’t know what exists in the dark net (its hard to crawl, not reliable, among other issues).</p>
<p>In the ice-berg picture above (which is a fitting and accurate example) you can see that the dark net is far bigger than the clear net.</p>
<p>So you could, literally, <em><strong>just search for cool ideas and content from the dark web and place it on your clear web website</strong></em>. And the result would be, according to search engines: <strong>You</strong> <em>have new and authentic content</em>.</p>
<p>Adding to that, due to the source (the dark net), your “authentic” content will probably be unique  (to the clear net). Dark net authors often think differently. That’s why they are there.</p>
<p>You probably think I’m telling you to steal content from the dark web.</p>
<p>Stealing content is not what I’m suggesting.</p>
<hr>
<p>I’m suggesting this, rather:</p>
<h3 id="using-content-from-the-dark-web-to-provide-content-to-the-clear-web">Using content from the dark web to provide content to the clear web</h3>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/dali.jpg" alt="Dali, “Original Inspiration”"></p>
<p>Lets use Salvadore Dali as an Example <a href="https://www.google.com/search?q=Salvador+Dali+painting&amp;tbm=isch&amp;ved=2ahUKEwjo6t3VwN_rAhUJq54KHfrLDd0Q2-cCegQIABAA&amp;oq=Salvador+Dali+painting&amp;gs_lcp=CgNpbWcQAzICCAAyAggAMgIIADICCAAyAggAMgIIADICCAAyAggAMgIIADICCAA6BAgjECdQzDtY5T9g7UBoAHAAeACAAYcBiAHOB5IBAzAuOJgBAKABAaoBC2d3cy13aXotaW1nwAEB&amp;sclient=img&amp;ei=ApdaX-jhFInW-gT6l7foDQ&amp;bih=862&amp;biw=1841&amp;client=ubuntu&amp;hl=en&amp;hl=en">(see his paintings here)</a>. (<a href="https://web.archive.org/web/20200910232414/https://www.google.com/search?q=Salvador+Dali+painting&amp;tbm=isch&amp;ved=2ahUKEwjo6t3VwN_rAhUJq54KHfrLDd0Q2-cCegQIABAA&amp;oq=Salvador+Dali+painting&amp;gs_lcp=CgNpbWcQAzICCAAyAggAMgIIADICCAAyAggAMgIIADICCAAyAggAMgIIADICCAA6BAgjECdQzDtY5T9g7UBoAHAAeACAAYcBiAHOB5IBAzAuOJgBAKABAaoBC2d3cy13aXotaW1nwAEB&amp;sclient=img&amp;ei=ApdaX-jhFInW-gT6l7foDQ&amp;bih=862&amp;biw=1841&amp;client=ubuntu&amp;hl=en&amp;hl=en">archive</a>)</p>
<p>Dali used to take inspiration for his paintings from a foreign and strange environment: <em><strong>his dreams</strong></em>.</p>
<p>While its questionable where his success came from (indeed, we cannot assume inspiration or quality of art) he certainly knew a thing or two about inspiration: Radical inspiration comes from a place we don’t visit often*.</p>
<p>*(<em>That’s why I’m an avid bible reader that no longer sets foot in churches. Churches are, in my opinion, the dark side of the dark web of religion, but the bible is the “radical” book that goes against the establishment. And, oddly, most bibles come in black, though containing much light.</em>).</p>
<p><em><strong>Hence</strong></em>, using the <em><strong>hidden net can give you ideas that were previously unknown to you</strong></em>, because they are not a part of your common world or common experiences via mainstream television or mainstream internet (or mainstream books).</p>
<p>And you can draw from that.</p>
<h2 id="epilog-with-new-frontiers-comes-new-risks">Epilog: With new frontiers comes new risks…</h2>
<p><img src="https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/pirates.jpg" alt="One nation’s pirate is another nation’s entrepreneur…"></p>
<p>Like I acknowledged at the beginning of this article, the dark web contains bad guys, though occasionally you might run into whistle blowers, free thinkers, radical innovators, and the like.</p>
<p>The dark web does not exist to be searchable, unless the authors intend it. Likewise, your chances on stumbling upon genuinely evil content is also based on the entry points you use. Finding innovation will start with innovation.</p>
<p>Hence, I would suggest NOT just jumping into the dark web based on the popular entry points, but find a strategy to obtain links and onion connections from useful darkweb sites that explore innovation or new ideas that are challenged by dominant opinion. Avert your eyes from things that are genuinely dark.</p>
<p>Its true with websites as its true with people: Birds of a feather flock together. So if you start with sites that are intellectual and progressive in nature, you are not likely to come into evil territories quickly. On the other hand, if you start with a site like The Hidden Wiki…you’d better know what your doing.</p>
<hr>
<p>Endnote:</p>
<p>You probably think I’m telling you to visit the dark web…</p>
<p>You could I suppose.</p>
<p>Its actually much better to read the scriptures. The best inspiration comes from places people rarely visit. <a href="https://scrollmapper.github.io/pages/apocryphal/">That would reveal much to you that you didn’t know you didn’t know…</a> (<a href="https://web.archive.org/web/20200910082737/https://scrollmapper.github.io/pages/apocryphal/">archived</a>)</p>
<p>Some times the most useful things are hidden for a reason.</p>
<hr>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/it-came-from-the-dark-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24437280</guid>
            <pubDate>Thu, 10 Sep 2020 22:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you ever wanted to know about terminals (2018)]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24436860">thread link</a>) | @n3t
<br/>
September 10, 2020 | https://xn--rpa.cc/irl/term.html | <a href="https://web.archive.org/web/*/https://xn--rpa.cc/irl/term.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<h3><a href="https://xn--rpa.cc/index.html">ʞ</a> / <a href="https://xn--rpa.cc/irl/index.html">essays</a> /</h3>



<p>so here's a short tutorial on ansi escape codes and terminal control, because you philistines won't stop using ncurses and oh my god <em>WHY ARE WE STILL USING NCURSES IT IS THE TWENTY FIRST FUCKING CENTURY</em></p>

<p>the way terminal emulators handle fancy things like color and cursor shape aren't some mysterious opaque black box you can only access through a library. accessing these capabilities is actually extremely simple; they can even be hardcoded into a text file and displayed by <code>cat</code> or <code>less</code>. or even <a href="http://xn--rpa.cc/ansiglot">curl</a>! the way you do this is with something called <em>ANSI escape sequences.</em></p>

<p>almost all UI changes in a terminal are accomplished through in-band signalling. these signals are triggered with the ASCII/UTF-8 character <strong>‹ESC›</strong> (<code>0x1B</code> or <code>27</code>). it's the same <strong>‹ESC›</strong> character that you send to the terminal when you press the <code>Escape</code> key on your keyboard or a key sequence involving the <code>Alt</code> key. (typing <strong>‹A-c›</strong> for instance sends the characters <strong>‹ESC›</strong> and <strong>‹c›</strong> in very rapid succession; this is why you'll notice a delay in some terminal programs after you press the escape key — it's waiting to try and determine whether the user hit <code>Escape</code> or an alt-key chord.)</p>

<p>the simplest thing we can do with these escapes is to make the text <strong>bold</strong> (or "bright"). we accomplish this by sending the terminal the <strong>‹ESC›</strong> character followed by <code>[1m</code>. <code>[</code> is a character indicating to the terminal what kind of escape we're sending, <code>1</code> indicates bold/bright mode, and <code>m</code> is the control character for formatting escapes.</p>

<p>all text sent after this escape sequence will be bold until we explicitly turn it off again (even if your program terminates). there are two ways we can turn off bright mode: by clearing formatting entirely, using the <code>m</code> formatting command with no arguments or the argument <code>0</code>, or more specifically clearing the bold bit with the <code>21m</code> command. (you'll notice that you can usually turn off modes by prefixing the same number with <code>2</code>.)</p>

<p>in a C program, this might look like the following:</p>

<code><b>#include</b> <cite>&lt;unistd.h&gt;</cite>
<span>#define</span> szstr(str) str,sizeof(str)
<strong>int</strong> main() {
	write(1, szstr(<em>"plain text - \x1b[1mbold text\x1b[0m - plain text"</em>));
}
</code>

<p>the <code>\x1b</code> escape here is a C string escape that inserts hex character <code>0x1B</code> (<strong>‹ESC›</strong>) into the string. it's kind of ugly and unreadable if you're not used to reading source with explicit escapes in it. you can make it a lot less horrible with a handful of defines, tho:</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span>     plain "0" /* or "" */
<span>#define</span>        no "2"
<span>#define</span>    bright "1"
<span>#define</span>       dim "2"
<span>#define</span>    italic "3"
<span>#define</span> underline "4"
<span>#define</span>   reverse "7"
<span>#define</span>      with ";"
<span>#define</span>  ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(    <em>"plain text - "</em>
		fmt(bright)     <em>"bright text"</em>     fmt(no bright) <em>" - "</em>
		fmt(dim)       <em>"dim text"</em>        fmt(no dim)    <em>" - "</em> 
		fmt(italic)    <em>"italic text"</em>     fmt(no italic) <em>" - "</em>
		fmt(reverse)   <em>"reverse video"</em>   fmt(plain)     <em>" - "</em>
		fmt(underline) <em>"underlined text"</em> fmt(no underline) )
	);
}
</code>

<p>the beauty of this approach is that all the proper sequences are generated at <em>compile time</em>, meaning the compiler turns all that into a single string interpolated with the raw escapes. it offers much more readability for the coder at zero cost to the end user.</p>

<p>but hang on, where's that semicolon coming from? it turns out, ansi escape codes let you specify multiple formats per sequence. you can separate each command with a <code>;</code>. this would allow us to write formatting commands like <code>fmt(underline with bright with no italic)</code>, which translates into <code>\x1b[4;1;23m</code> at compile time.</p>

<p>of course, being able to style text isn't nearly good enough. we also need to be able to color it. there are two components to a color command: what we're trying to change the color of, and what color we want to change it to. both the foreground and background can be given colors separately - despite what ncurses wants you to believe, you do not have to define """color pairs""" with each foreground-background pair you're going to use. this is a ridiculous archaism that nobody in the 21st fucking century should be limited by.</p>

<p>to target the foreground, we send the character <code>3</code> for normal colors or <code>9</code> for bright colors; to target the background, we send <code>4</code> for normal or <code>10</code> for bright. this is then followed by a color code selecting one of the traditional 8 terminal colors.</p>

<p>note that the "bright" here is both the same thing and something different from the "bright" mode we mentioned earlier. while turning on the "bright" mode will automatically shift text it applies to the bright variant of its color <em>if</em> it is set to one of the traditional 8 colors, setting a "bright color" with <code>9</code> or <code>10</code> will not automatically make the text bold.</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span> fg "3"
<span>#define</span> br_fg "9"
<span>#define</span> bg "4"
<span>#define</span> br_bg "10"
<span>#define</span> with ";"
<span>#define</span>      plain ""
<span>#define</span>      black "0"
<span>#define</span>        red "1"
<span>#define</span>      green "2"
<span>#define</span>     yellow "3"
<span>#define</span>       blue "4"
<span>#define</span>    magenta "5"
<span>#define</span>       cyan "6"
<span>#define</span>      white "7"
<span>#define</span>   ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(
		<em>"plain text - "</em>
		fmt(fg blue) <em>"blue text"</em> fmt(plain)               <em>" - "</em>
		fmt(br_fg blue) <em>"bright blue text"</em> fmt(plain)     <em>" - "</em>
		fmt(br_bg red) <em>"bright red background"</em> fmt(plain) <em>" - "</em>
		fmt(fg red with br_bg magenta) <em>"hideous red text"</em> fmt(plain))
	);
}
</code>

<p>when we invoke <code>fmt(fg red with br_bg magenta)</code>, this is translated by the compiler into the command string <code>\x1b[31;105m</code>. note that we're using <code>fmt(plain)</code> (<code>\x1b[m</code>) to clear the coloring here; this is because if you try to reset colors with, for instance, <code>fmt(fg black with bg white)</code>, you'll be overriding the preferences of users who have their terminal color schemes set to anything but that exact pair. additionally, if the user happens to have a terminal with a transparent background, a set background color will create ugly colored blocks around text instead of letting whatever's behind the window display correctly.</p>

<p>now, while it is more polite to use the "8+8" colors because they're a color palette the end-user can easily configure (she might prefer more pastel colors than the default harsh pure-color versions, or change the saturation and lightness to better fit with her terminal background), if you're doing anything remotely interesting UI-wise you're going to run up against that limit very quickly. while you can get a bit more mileage by mixing colors with styling commands, if you want to give <em>any</em> configurability to the user in terms of color schemes (as you rightly should), you'll want access to a much broader palette of colors.</p>

<p>to pick from a 256-color palette, we use a slightly different sort of escape: <code>\x1b[38;5;<em>(color)</em>m</code> to set the foreground and <code>\x1b[48;5;<em>(color)</em>m</code> to set the background, where <em>(color)</em> is the palette index we want to address. these escapes are even more unwieldy than the 8+8 color selectors, so it's even more important to have good abstraction.</p>

<code><span>#include</span> <em>&lt;unistd.h&gt;</em>
<span>#define</span> szstr(str) str,sizeof(str)

<span>#define</span>       with ";"
<span>#define</span>      plain ";"
<span>#define</span> wfg(color) "38;5;" #color
<span>#define</span> wbg(color) "48;5;" #color
<span>#define</span>   ansi_esc "\x1b"
<span>#define</span> fmt(style) ansi_esc "[" style "m"

<span>int</span> main() {
	write(1, szstr(<em>"plain text - "</em>
		fmt(wfg(198) with wbg(232))
			<em>"rose text on dark grey"</em>
		fmt(plain) <em>" - "</em>
		
		fmt(wfg(232) with wbg(248))
			<em>"dark grey on light grey"</em>
		fmt(plain) <em>" - "</em>
		
		fmt(wfg(248) with wbg(232))
			<em>"light grey on dark grey"</em>
		fmt(plain))
	);
}
</code>
<p>here, the stanza <code>fmt(wfg(248) with wbg(232))</code> translates into <code>\x1b[38;5;248;48;5;232m</code>. we're hard-coding the numbers here for simplicity but as a rule of thumb, any time you're using 8-bit colors in a terminal, you should <em>always</em> make them configurable by the user.</p>

<p>the opaque-seeming indexes are actually very systematic, and you can calculate which index to use for a particular color with the formula <code>16 + 36 * r + 6 * g + b</code>, where <code>r</code>, <code>g</code>, and <code>b</code> are integers ranging between 0 and 5. indices 232 through 255 are a grayscale ramp from dark (232) to light (255).</p>

<p>of course, this is still pretty restrictive. 8-bit color may have been enough for '90s CD-ROM games on Windows, but it's long past it's expiration date. using true color is much more flexible. we can do this through the escape sequence <code>\x1b[38;2;<em>(r)</em>;<em>(g)</em>;<em>(b)</em>m</code> where each component is an integer between 0 and 255.</p>

<p>sadly, true color isn't supported on many terminals, urxvt tragically included. for this reason, your program should never rely on it, and abstract these settings away to be configured by the user. defaulting to 8-bit color is a good choice, as every reasonable modern terminal has supported it for a long time now.</p>

<p>but, for users of XTerm, kitty, Konsole, and libVTE-based terminal emulators (such as gnome-terminal, mate-terminal, and termite), it's polite to have a 24-bit color mode in place. for example:</p>

<code><span>#include</span> <em>&lt;stdio.h&gt;</em>
<span>#include</span> <em>&lt;stdint.h&gt;</em>
<span>#include</span> <em>&lt;stdbool.h&gt;</em>

<span>struct</span> color {
	<span>enum</span> color_mode { trad, trad_bright, b8, b24 } mode;
	<span>union</span> {
		<span>uint8_t</span> color;
		<span>struct</span> { <span>uint8_t</span> r, g, b; };
	}
};
<span>struct</span> style {
	unsigned <span>char</span> bold      : 1;
	unsigned <span>char</span> underline : 1;
	unsigned <span>char</span> italic    : 1;
	unsigned <span>char</span> dim       : 1;
	unsigned <span>char</span> reverse   : 1;
};
<span>struct</span> format {
	<span>struct</span> style style;
	<span>struct</span> color fg, bg;
};

<span>struct</span> format
	fmt_menu = {
		{0, 0, 0, 0, 0},
		{trad, 7},
		{trad, 4}
	},
	fmt_menu_hl = {
		{1, 0, 0, 0, 0},
		{trad_bright, 7},
		{trad_bright, 4},
	};

<span>void</span> apply_color(<span>bool</span> bg, <span>struct</span> color c) {
	switch(c.mode) {
		case trad: printf(<em>"%c%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.color ); break;
		case trad_bright: printf(<em>"%s%u"</em>, bg ? <em>"9"</em> : <em>"10"</em>, c.color ); break;
		case b8: printf(<em>"%c8;5;%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.color); break;
		case b24: printf(<em>"%c8;2;%u;%u;%u"</em>, bg ? <em>'4'</em> : <em>'3'</em>, c.r, c.b, c.g);
	}
}

<span>void</span> fmt(struct format f) {
	printf(<em>"\x1b["</em>);
	f.bold      &amp;&amp; printf(<em>";1"</em>);
	f.underline &amp;&amp; printf(<em>";4"</em>);</code></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xn--rpa.cc/irl/term.html">https://xn--rpa.cc/irl/term.html</a></em></p>]]>
            </description>
            <link>https://xn--rpa.cc/irl/term.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436860</guid>
            <pubDate>Thu, 10 Sep 2020 21:44:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TOML – Tom's Obvious, Minimal Language]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 154 (<a href="https://news.ycombinator.com/item?id=24436550">thread link</a>) | @pmoriarty
<br/>
September 10, 2020 | https://toml.io/en/ | <a href="https://web.archive.org/web/*/https://toml.io/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <section>
      <div>
        <div>
          <svg viewBox="0 0 128 128" xmlns="http://www.w3.org/2000/svg">
            <g>
              <polygon points="99.2359551 -7.08546829e-15 99.2359551 14.3820225 112.179775 14.3820225 112.179775 113.617978 99.2359551 113.617978 99.2359551 128 128 128 128 0"></polygon>
              <polygon points="32.3595506 41.7078652 32.3595506 25.8876404 95.6404494 25.8876404 95.6404494 41.7078652 71.9101124 41.7078652 71.9101124 110.741573 56.0898876 110.741573 56.0898876 41.7078652"></polygon>
              <polygon points="28.7640449 0 28.7640449 14.3820225 15.8202247 14.3820225 15.8202247 113.617978 28.7640449 113.617978 28.7640449 128 0 128 0 0"></polygon>
            </g>
          </svg>
          <p>
            
            <h2>
              [Tom's Obvious Minimal Language]
            </h2>
          </p>
        </div>
        <h3>
          A config file format <br>for humans.
        </h3>
        <p>
          TOML aims to be a minimal configuration file format that's easy to read due to obvious
          semantics. TOML is designed to map unambiguously to a hash table. TOML should be easy to
          parse into data structures in a wide variety of languages.
        </p>
      </div>
    </section>

    <section>
      <pre data-controller="snippet" data-snippet-copy="false"><code># This is a TOML document

title = "TOML Example"

[owner]
name = "Tom Preston-Werner"
dob = 1979-05-27T07:32:00-08:00

[database]
enabled = true
ports = [ 8001, 8001, 8002 ]
data = [ ["delta", "phi"], [3.14] ]
temp_targets = { cpu = 79.5, case = 72.0 }

[servers]

[servers.alpha]
ip = "10.0.0.1"
role = "frontend"

[servers.beta]
ip = "10.0.0.2"
role = "backend"</code></pre>
    </section>
  </div>

  <section>
    <dl>
      <div>
        <dt>
          
          TOML prioritizes humans
        </dt>

        <dd>
          <p>TOML aims to be a minimal configuration file format that:</p>
          <ul>
            <li>
              <span>is easy to read</span> due to obvious semantics
            </li>
            <li>
              <span>maps unambiguously</span> to a hash table
            </li>
            <li>
              <span>is easy to parse</span> into data structures in a wide variety
              of languages
            </li>
          </ul>
        </dd>
      </div>

      <div>
        <dt>
          
          TOML has useful native types
        </dt>
        <dd>
          <ul>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Key/Value Pairs</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Arrays</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Inline tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Arrays of tables</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Integers &amp; Floats</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Booleans</span>
            </li>
            <li>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                <path d="M12 22a10 10 0 1 1 0-20 10 10 0 0 1 0 20zm0-2a8 8 0 1 0 0-16 8 8 0 0 0 0 16zm1-9h2a1 1 0 0 1 0 2h-2v2a1 1 0 0 1-2 0v-2H9a1 1 0 0 1 0-2h2V9a1 1 0 0 1 2 0v2z"></path>
              </svg>
              <span>Dates &amp; Times, with optional offsets</span>
            </li>
          </ul>
        </dd>
      </div>

      <div>
        <dt>
          
          TOML is widely supported
        </dt>
        <dd>
          <p>
            TOML already has implementations in most of the most popular programming languages in use
            today: C, C#, C++, Clojure, Dart, Elixir, Erlang, Go, Haskell, Java, Javascript, Lua,
            Objective-C, Perl, PHP, Python, Ruby, Swift, Scala...
            <a href="https://github.com/toml-lang/toml/wiki">and plenty more</a>.
          </p>
        </dd>
      </div>
    </dl>
  </section>

  <section>
    <header>
      <h2>
        A Quick Tour of TOML
      </h2>
    </header>

    <div>
      <div>
        <section>
          <div>
            <h3>Comments</h3>
            <p>TOML thinks all config files should support comments.</p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code># This is a TOML comment

# This is a multiline
# TOML comment</code></pre>
        </section>

        <section>
          <div>
            <h3>Powerful Strings</h3>
            <p>
              There are four ways to express strings: basic, multi-line basic, literal, and
              multi-line literal. <span>Basic strings</span> are surrounded by
              quotation marks:
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code>str1 = "I'm a string."
str2 = "You can \"quote\" me."
str3 = "Name\tJos\u00E9\nLoc\tSF."</code></pre>

          <p>
            <span>Multi-line basic strings</span> Multi-line basic strings are
            surrounded by three quotation marks on each side and allow newlines. Include a line
            ending backslash to automatically trim whitespace preceeding any non-whitespace
            characters:
          </p>

          <pre data-controller="snippet" data-snippet-copy="false"><code>str1 = """
Roses are red
Violets are blue"""

str2 = """\
  The quick brown \
  fox jumps over \
  the lazy dog.\
  """</code></pre>

          <p>
            <code> str2</code> becomes
            <code>"The quick brown fox jumps over the lazy dog."</code>
            (a single sentence with no line breaks).
          </p>

          <p>
            <span> Literal strings</span> are surrounded by single quotes. No
            escaping is performed so what you see is what you get:
          </p>

          <pre data-controller="snippet" data-snippet-copy="false"><code>path = 'C:\Users\nodejs\templates'
path2 = '\\User\admin$\system32'
quoted = 'Tom "Dubs" Preston-Werner'
regex = '&lt;\i\c*\s*&gt;'</code></pre>

          <p>
            Since there is no escaping, there is no way to write a single quote inside a literal
            string enclosed by single quotes. That's where
            <span>multi-line literal strings</span> come in:
          </p>
          <pre data-controller="snippet" data-snippet-copy="false"><code>re = '''\d{2} apps is t[wo]o many'''
lines = '''
The first newline is
trimmed in raw strings.
All other whitespace
is preserved.
'''</code></pre>
        </section>
      </div>

      <div>
        <section>
          <div>
            <h3>Numbers</h3>
            <p>
              Integers, floats, infinity, and even NaN are all supported. You can use scientific
              notation and even thousands separators.
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code># integers
int1 = +99
int2 = 42
int3 = 0
int4 = -17

# hexadecimal with prefix `0x`
hex1 = 0xDEADBEEF
hex2 = 0xdeadbeef
hex3 = 0xdead_beef

# octal with prefix `0o`
oct1 = 0o01234567
oct2 = 0o755

# binary with prefix `0b`
bin1 = 0b11010110

# fractional
float1 = +1.0
float2 = 3.1415
float3 = -0.01

# exponent
float4 = 5e+22
float5 = 1e06
float6 = -2E-2

# both
float7 = 6.626e-34

# separators
float8 = 224_617.445_991_228

# infinity
infinite1 = inf # positive infinity
infinite2 = +inf # positive infinity
infinite3 = -inf # negative infinity

# not a number
not1 = nan
not2 = +nan
not3 = -nan </code></pre>
        </section>

        <section>
          <div>
            <h3>Dates and Times</h3>
            <p>
              TOML features support for dates, times, and datetimes with and without offsets.
            </p>
          </div>

          <pre data-controller="snippet" data-snippet-copy="false"><code>#offset datetime
odt1 = 1979-05-27T07:32:00Z
odt2 = 1979-05-27T00:32:00-07:00
odt3 = 1979-05-27T00:32:00.999999-07:00

# local datetime
ldt1 = 1979-05-27T07:32:00
ldt2 = 1979-05-27T00:32:00.999999

# local date
ld1 = 1979-05-27

# local time
lt1 = 07:32:00
lt2 = 00:32:00.999999</code></pre>
        </section>
      </div>
    </div>
  </section>

  <section>
    <div>
      <h3>More Spec</h3>
      <p>
        <strong>TOML</strong> supports even more native types and syntax, read all about it:
      </p>
      
    </div>

    <div>
      <h3>Start coding</h3>
      <p>
        <strong>TOML</strong> is already implemented in over 40 programming languages:
      </p>
      
    </div>
  </section>
</div></div>]]>
            </description>
            <link>https://toml.io/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436550</guid>
            <pubDate>Thu, 10 Sep 2020 21:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why FTL implies time travel (2016)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24436505">thread link</a>) | @ladberg
<br/>
September 10, 2020 | http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel | <a href="https://web.archive.org/web/*/http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1472176981274" id="item-57bfa321893fc0f1d1be57f7"><div><div><div data-block-type="2" id="block-54e4d00eca7f73d32497"><div><p>In science fiction, it is pretty standard fare to introduce some form of faster-than-light communication or travel. After all, space is big, and you can't write your swashbuckling Hornblower-in-space novel if you have to wait for a generation ship to crawl painfully slowly between the nearest stars, much less try to cross a galaxy.</p><p>However, faster-than-light communication (which includes travel) breaks something very fundamental about physics, something that is often ignored by sci-fi, and difficult for non-physicists to understand. If you allow faster-than-light (FTL), then you break causality: you are allowing time-travel. One pithy way of saying this is:</p><p>Pick two:</p><ul><li>Relativity</li><li>Causality</li><li>FTL</li></ul><p>The Universe has picked relativity and causality, it seems. Thus, we cannot travel or communicate faster than light.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_15584"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa4a303596e3a2ae8799b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177316237-IEW52C3ICC42CPAM1IMG/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_16992"><div><p>But why is this? Why does FTL imply time travel. To demonstrate this, it's handy to draw some diagrams. We're going to work with "spacetime diagrams." They look like this:</p><p>Here I'm trying to draw all four dimensions of the Universe: three space and one time. Now, I can't draw four dimensions. I can't even really draw three (it's a 2D screen, after all). So I've suppressed two space dimensions, drawing all of space as just a line. It won't matter much for what I'm trying to do, but it's good to keep that in mind.</p><p>With that in mind, I'm showing here <em>my </em>spacetime diagram: I'm stationary at the center, and so I see time tick forward "orthogonal" (perpendicular) to the space directions around me. As you'll see, other people have different spacetime diagrams, and different time and space axes, relative to me. That's the point of relativity, after all.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_21377"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa5b9ff7c50b7ffbc5576" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472177593517-NTXFTAXJ7Q4WAPV0Q6ST/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_22820"><div><p>The special thing about relativity is that <em>everyone measures the speed of light to be the same</em>. We show this in a spacetime diagram by saying that every spacetime diagram has light traveling at 45 degrees relative to the time axis. Light travels on lines that are called "null."</p><p>Here I'm showing the null lines of light emitted from an event at the time I'm calling <em>t=0</em>&nbsp;(when the time and space axis cross). Remember I'm suppressing most of the space dimensions: these rays of light are really emanating out in a sphere around me. Because light travels at 45 degrees, anything traveling slower than light from this <em>t=0</em>&nbsp;event is closer to the time axis than the light rays, and anything faster than light is further away from the time axis.</p><p>The light rays define the <em>future lightcone</em>. This is the set of spacetime events that can perceive the event at <em>t=0,</em>&nbsp;and so, in a Universe without FTL, all the events that can be affected by whatever happened at this event at <em>t=0.&nbsp;</em>There is also a past lightcone, which would be the 45 degree lines extending backwards in time from the event: in a Universe without FTL this defines all the events that could have effected that <em>t=0</em>&nbsp;event, because the light (and thus things moving slower than light)&nbsp;from those other events had time to reach the <em>t=0</em>&nbsp;event.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_40995"><div><p>So now let me move from general spacetime diagrams to an example that will indicate why FTL implies time travel. Let's consider a specific example: Let's say we on Earth have built a FTL communication device that let's us talk to the inhabitants of the planet Proxima Centauri B, 4.25 lightyears away. Again, this is what a FTL and slower-than-light set of communications would appear like in a spacetime diagram.</p><p>Critically, I've drawn the time axis for the Proximal Centaurians parallel to our own time. This is because Proxima Centauri is moving at essentially the same velocity as Earth (the differences are small compared to the speed of light). Thus, there are no big relativistic effects between our counting of time and the Proximal Centaurians.&nbsp;</p><p>Now, let's imagine that some event occurs away from Earth, oriented in such a way that the light from the event hits us before it reaches Proxima Centauri. The spacetime diagram for that would look like what I've shown. First we see the light, then the light reaches Proxima Centauri. Notice I've drawn the light rays from the event traveling at 45 degrees to my time axis. After all, it is light, and light travels at 45 degrees on spacetime diagrams.</p></div></div><div data-block-json="{&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;show-meta-only-title&quot;:false,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;design&quot;:&quot;grid&quot;,&quot;aspectRatio&quot;:null,&quot;square-thumbs&quot;:false,&quot;aspect-ratio&quot;:&quot;square&quot;,&quot;thumbnails-per-row&quot;:2,&quot;padding&quot;:5,&quot;lightbox&quot;:false,&quot;collectionId&quot;:&quot;57bfa8b3f5e2312269858e10&quot;,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;57bfa8b3f5e2312269858e10&quot;}" data-block-type="8" id="block-yui_3_17_2_5_1472176913301_57296"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356455-JKIIS3FT0GDGQQGL4R6P/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0006.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356455-JKIIS3FT0GDGQQGL4R6P/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0006.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0006.jpg" data-load="false" data-image-id="57bfa8b4f5e2312269858e11" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0006.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356571-YYGOMQAKCBON7C6CLUEJ/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0007.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178356571-YYGOMQAKCBON7C6CLUEJ/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0007.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0007.jpg" data-load="false" data-image-id="57bfa8b4d2b8577fd265d1a2" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0007.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      
    
  </div>

  

</div>








</div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_62520"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfa96be58c629eb4d4f155" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178540018-4KDK5JVY0JSFA4JP0998/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_61723"><div><p>So, now, let's add in FTL communication. We see the event, we get on the FTL phone, and we tell the Proximal Centaurians. They get the phone call, and now have years to prepare for the arrival of the light from whatever the event is (let's say it's a supernovae, or the launch of relativistic attack vehicles. We are playing with sci-fi tropes here).</p><p>Now, this is the image most people have of FTL communication. There appears to be no problem: we all agree that the event happened "first," then Earth calls Proxima Centauri, then the light reaches Proxima Centauri. No problem: though the Proximal Centaurians hear about the event "early," no causality has been violated. After all, we all agree on what happened first, don't we? No effect precedes its cause.</p><p>Right?</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_81533"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfaafabebafba38dd12b9e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178941031-RKS433C6DG08CZ9EE2PC/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_67814"><div><p>But we've forgotten relativity. This only works when everyone is moving in the same frame of reference, like us and Proxima Centauri (really we're not in the same rest frame, but its close enough not to matter). So, to see the problem, let's add a new observer, moving at high speeds relative to Earth and Proxima Centauri. It's sci-fi, so we add a relativistic spaceship. It's moving with <em>v&lt;c</em>&nbsp;but <em>v&gt;&gt;0</em>, so it's trajectory on my spacetime diagram is highly skewed relative to my time axis: it's nearly moving at the speed of light.</p><p>Here's where the relativistic effects start coming into play. Relativity tells us that everyone moving with constant velocity is totally justified in saying they are stationary. Thus, we think we're stationary (ignore the rotation of the Earth, or its orbit around the Sun). The Proximal Centaurians think they're at rest. The people on the relativistic spaceship think they are at rest. So they can draw their spacetime diagram, with their own time axis. That time axis, like mine, is always where they are: on the ship. So I think their time axis is aligned with the ship trajectory.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_80257"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="57bfaad9bebafba38dd12a22" data-type="image" src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472178905725-BMV6CIVK52NIILG1PZN5/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  



</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_86207"><div><p>In addition, they have a space-axis, just like I do. Relativity mixes up space and time, so their space axis I perceive as slanted - just like their time axis is skewed. It turns out that the space axis is flipped across the 45 degree null line, but I'm not going to prove that. This weird mixture of space and time of observers I perceive as moving is a necessary part of relativity. It is the <em>only </em>way everyone can agree that light moves at <em>c</em>.&nbsp;</p><p>Now, if I wanted to, I could draw the spacetime diagram of the spaceship in its frame of reference. It would have othogonal space and time axes, the light from the event would travel at 45 degree,&nbsp;and they would see Earth's axes highly skewed (pointing toward the left if I kept the same orientation as in this set of diagrams). That's relativity. But we will not draw that diagram here, as it's not necessary for the story.</p><p>So what happens now. Let's ask <em>when </em>the spaceship sees the various events in this diagram. To do that, we need to know the lines of constant time for the ship. That's not too hard: lines of constant time for us are lines in the spacetime diagram parallel to the space axis. So it is for the spaceship. Their lines of constant time look like this:</p></div></div><div data-block-json="{&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;show-meta-only-title&quot;:false,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;design&quot;:&quot;grid&quot;,&quot;aspectRatio&quot;:null,&quot;square-thumbs&quot;:false,&quot;aspect-ratio&quot;:&quot;square&quot;,&quot;thumbnails-per-row&quot;:2,&quot;padding&quot;:5,&quot;lightbox&quot;:false,&quot;collectionId&quot;:&quot;57bfacb4d2b8577fd265f253&quot;,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;57bfacb4d2b8577fd265f253&quot;}" data-block-type="8" id="block-yui_3_17_2_5_1472176913301_90063"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381264-LQVTY7AMG7NSFAUT3YHB/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0011.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381264-LQVTY7AMG7NSFAUT3YHB/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0011.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0011.jpg" data-load="false" data-image-id="57bfacb4d2b8577fd265f254" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0011.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <p><a role="presentation">
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381312-NBGI7FFKM480NJ32EQET/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0012.jpg" data-image="https://images.squarespace-cdn.com/content/v1/55809d94e4b041b423dad36b/1472179381312-NBGI7FFKM480NJ32EQET/ke17ZwdGBToddI8pDm48kBZw6jF4_OvU-ddo_vwqGhp7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1Ub61YCrK70I7JIpWiI8ho4Yi1WvVNQtDE81xuRbL1MFKm0sD-Bab7E9MY8W31A7zMQ/IMG_0012.jpg" data-image-dimensions="2048x1536" data-image-focal-point="0.5,0.5" alt="IMG_0012.jpg" data-load="false" data-image-id="57bfacb437c5819eacebc0b2" data-type="image" src="http://www.physicsmatt.com/blog/2016/8/25/IMG_0012.jpg">
                </a>
                
              </p>
            </div>
          

          
        

      
    
  </div>

  

</div>








</div></div><div data-block-type="2" id="block-yui_3_17_2_5_1472176913301_91421"><div><p>Now do you see the problem?</p><p>According to us, on Earth, the order of events is thus: we see the light from the event hit us. We call Proxima Centauri on the FTL phone. The Proximal Centaurians do whatever they want to do in response to that call, and then they see the light of the event.&nbsp;</p><p>What does the ship see? They see the phone call received on Proxima Centauri.&nbsp;<em>Then</em>&nbsp;they see the phone call placed from Earth. Effect precedes cause: causality is violated. In fact, if the ship had a FTL phone set up in the right way, they could call Earth <em>before</em>&nbsp;Earth placed the call. They could even tell Earth "hey, don't make that call to Proxima Centauri we just saw you make." Then what?</p></div></div><div data-block-type="5" id="block-yui_3_17_2_5_1472176913301_110431"><div>







 

  
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
    …</figure></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel">http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel</a></em></p>]]>
            </description>
            <link>http://www.physicsmatt.com/blog/2016/8/25/why-ftl-implies-time-travel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24436505</guid>
            <pubDate>Thu, 10 Sep 2020 20:58:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open Source GIS – An Interactive Infographic]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24435582">thread link</a>) | @Pablo1856
<br/>
September 10, 2020 | https://makepath.com/history-of-open-source-gis/ | <a href="https://web.archive.org/web/*/https://makepath.com/history-of-open-source-gis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<section><div>
<p>GIS (Geographic Information Systems) technology is a powerful way to understand our world. Thanks to the open source community, the public today has access to excellent analysis tools, and many of them are free!</p>



<p>makepath is a proud contributor to many <a href="https://makepath.com/open-source-spatial-analysis-tools-a-quick-guide/" target="_blank" rel="noreferrer noopener">open source spatial analysis projects</a>. Through this piece, we want to honor and highlight the contributors that have made it possible for <a href="https://opensource.com/tags/gis-and-maps" target="_blank" rel="noreferrer noopener">open source GIS</a> to grow and flourish.</p>



<p><strong>This is an interactive piece.</strong> You can click on the name of a library to see details and anecdotes directly from the creators themselves.</p>



<p><strong>This is an open source infographic.</strong> If you have ideas, contributions, or additional libraries you would like included, we have set up a <a rel="noreferrer noopener" href="https://github.com/makepath/open-source-gis-infographic" target="_blank">GitHub page</a> for this timeline. With a nod to our favorite programming language, <a rel="noreferrer noopener" href="https://www.python.org/" target="_blank">Python</a>, take a journey down our timeline to follow the ever evolving story of open source GIS!</p>




</div></section>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper --><!-- Developer mode initialisation; Version: 1.2.9;Relation: categories; All categories: 1;Found 3 posts;Basic sizes;Got sizes 200x150;Post-thumbnails enabled in theme;Post has thumbnail 763;Postthname: thumbnail;Using title with size 25. Using excerpt with size 0;Post-thumbnails enabled in theme;Post has thumbnail 757;Postthname: thumbnail;Using title with size 25. Using excerpt with size 0;Post-thumbnails enabled in theme;Post has thumbnail 749;Postthname: thumbnail;Using title with size 25. Using excerpt with size 0;Plugin execution time: 0.0072360038757324 sec; -->		</div></div>]]>
            </description>
            <link>https://makepath.com/history-of-open-source-gis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435582</guid>
            <pubDate>Thu, 10 Sep 2020 19:17:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Routers Work, Really?]]>
            </title>
            <description>
<![CDATA[
Score 374 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24435454">thread link</a>) | @turingbook
<br/>
September 10, 2020 | https://kamila.is//teaching/how-routers-work/ | <a href="https://web.archive.org/web/*/https://kamila.is//teaching/how-routers-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
    <header>
        
    </header>


              <nav>
    
    <ul>
  <li><a href="#0-some-terminology">0. Some Terminology</a></li>
  <li><a href="#1-high-level-overview">1. High-level Overview</a>
    <ul>
      <li><a href="#the-data-plane-life-of-a-packet">The Data Plane: Life of a Packet</a></li>
    </ul>
  </li>
  <li><a href="#the-details-what-exactly-is-going-on">The details: What <em>exactly</em> is going on?</a>
    <ul>
      <li><a href="#life-of-a-packet-now-properly">Life of a Packet, Now Properly</a>
        <ul>
          <li><a href="#1-it-needs-to-be-routed-l3router">1. “It needs to be routed”: L3/router</a></li>
          <li><a href="#2-it-needs-to-be-passed-down-l25arp-glue">2. “It needs to be passed down”: L2.5/ARP glue</a></li>
          <li><a href="#3-it-needs-to-be-forwarded-l2switch">3. “It needs to be forwarded”: L2/switch</a></li>
          <li><a href="#the-logic-applying-the-tables">The logic: Applying the tables</a></li>
        </ul>
      </li>
      <li><a href="#the-control-plane-how-to-fill-the-tables">The Control Plane: How to Fill the Tables</a>
        <ul>
          <li><a href="#l3--routing-table">L3 / routing table</a></li>
          <li><a href="#l25--arp-table">L2.5 / ARP table</a></li>
          <li><a href="#l2--mac-table">L2 / MAC table</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#gimme-the-code">Gimme the code!</a></li>
  <li><a href="#next-steps">Next steps</a></li>
</ul>
</nav>

<p><strong>Work in progress</strong>: I still need to clean this up &amp; add the complete source code. ETA for a more or less done version is Soon(TM).<br>
<strong>Last updated</strong>: 2020/09/10 because how the eff did this end up on the front page of Hacker News? :D<br>
<strong>Suggestions welcome</strong>: <a href="https://github.com/AnotherKamila/kamila.is/issues/new?labels=teaching&amp;title=[teaching/how-routers-work]+Title">complain</a> if something is unclear or wrong!</p>

<p>This is the inside view of how exactly a router operates. You only need to know this if you are poking inside a router implementation. If that is the case, my condolences.</p>

<p>At the end of this exposition, I will give you the complete source code to a functional router (written in <a href="https://p4.org/">P4</a>, the new &amp; shiny software-defined networking thing). My aim is that you will understand every line of that.</p>

<p>I accompany my explanations below with some P4 code. I think it is useful to read it even if you’ve never seen P4, because it shows a bit more detail than the text and I believe that it is sufficiently pseudocode-ish. Here is a summary of what you need to know to read it:</p>
<ul>
  <li>everything happens per packet</li>
  <li><code>hdr</code> are the packet’s parsed headers</li>
  <li><code>standard_metadata</code> is how you tell the switch to do things with the packet (like send it on a specific port)</li>
  <li><code>meta</code> are user-defined in-memory variables which can be used e.g. for matching in tables</li>
</ul>



<ul>
  <li>Figuring out what should be done with packets is done by <em>the control plane/in the slow path/on the CPU/by the controller</em> or similar phrases. I will refer to all of this as “the control plane”.</li>
  <li>Actually forwarding the packets  is done by <em>the data plane/in the fast path/in the hardware/in the switch</em> and such. I will refer to this as “the data plane”.</li>
</ul>

<p><a href="https://news.ycombinator.com/item?id=24436585">Cyph0n on HN did a good job explaining this distinction.</a></p>



<p>A <em>switch</em> (or an L2 switch :-) ) is an L2-only<sup><a href="#fn1">1</a></sup> thing. It knows about L2 stuff such as MAC addresses and ports<sup><a href="#fn2">2</a></sup>. It does <strong>not</strong> know about anything like IP addresses. It has a <strong>MAC table</strong>: it maps MAC addresses to ports.</p>

<p>A <em>router</em> (or an L3 switch by some people’s vocabulary) operates on L3 only. It knows about L3 stuff such as IP addresses and interfaces and hosts. It does <strong>not</strong> know about L2 stuff such as MAC addresses or ports.<sup><a href="#fn3">3</a></sup> In fact, the routing parts of the router would not have to be changed at all if you decided to use something other than ethernet on L2. It has a <strong>routing table</strong> (details later): a table of subnets/prefixes and how to reach them.</p>

<p>What you normally call a router (that box sitting over there) is actually a router (for handling L3) and one or more switches (for handling L2), and some glue in between. They may in fact be separate chips in hardware.</p>

<p>You need glue to put together the L2 and the L3. This “L2.5” glue is ARP (or NDP for IPv6). It usually lives in the router, but it is glue, not routing, and you can think about it separately.</p>

<h2 id="the-data-plane-life-of-a-packet">The Data Plane: Life of a Packet</h2>

<p>When a packet arrives and needs to be sent further, these things have to happen to it:</p>

<ol>
  <li>It needs to be <em>routed</em>: the <strong>router</strong>, based on L3 information, decides where it needs to go, in L3 speak – it will decide which <em>host</em> to send it to, but not how. This corresponds to the <em><a href="https://en.wikipedia.org/wiki/Routing_table">routing table</a></em>.</li>
  <li>It needs to be passed down to L2: this is where the L2.5 ARP/NDP <strong>glue</strong> translates the L3-speak IP address to L2-speak MAC address. This is the <em>ARP table</em>.</li>
  <li>It needs to be <em>forwarded</em> on the correct port: the <strong>switch</strong> puts the packet on the correct port. This is the <em>MAC table</em>.</li>
</ol>



<h2 id="life-of-a-packet-now-properly">Life of a Packet, Now Properly</h2>

<h3 id="1-it-needs-to-be-routed-l3router">1. “It needs to be routed”: L3/router</h3>

<p>The packet has a destination IP address. This is matched in the <em>routing table</em>, using a longest-prefix match (LPM), i.e. it matches IP address prefixes. It may either be for a host the router is directly connected to (on some interface), or it may need to be sent further, through a <em>gateway</em> (through some interface). Therefore: <strong>The routing table maps a <em>prefix</em> to either <em>a next hop through a gateway and an interface</em>, or <em>a direct connection through an interface</em></strong>.</p>

<div><div><pre><code>routing_table : Prefix -&gt; NextHop (GatewayIP, Interface) | Direct Interface
</code></pre></div></div>

<p>Note that the next hop’s IP address is in the router’s memory only: it does not appear in the packet at any time.</p>

<p>The P4 code defining the IPv4 routing table is:</p>

<div><div><pre><code>action ipv4_through_gateway(ipv4_addr_t gateway, interface_t iface) {
    meta.out_interface = iface;
    meta.ipv4_next_hop = gateway;  // send through the gateway
}

action ipv4_direct(interface_t iface) {
    meta.out_interface = iface;
    meta.ipv4_next_hop = hdr.ipv4.dst_addr;  // send directly to the destination
}

table ipv4_routing {
    key = {
        hdr.ipv4.dst_addr: lpm;  // match prefixes
    }
    actions = {
        ipv4_through_gateway;    // ipv4_through_gateway(gateway, iface)
        ipv4_direct;             // ipv4_direct(iface)
        drop;
    }
    default_action = drop();     // If there is no route, drop it -- in reality, we might want to
                                 // send an ICMP "No route to host" packet.
                                 // Note that this is the default route, so control plane might
                                 // want to set a default gateway here instead of dropping.
    size = ROUTING_TABLE_SIZE;
}
</code></pre></div></div>
<p>(and the exact same thing for IPv6)</p>

<h3 id="2-it-needs-to-be-passed-down-l25arp-glue">2. “It needs to be passed down”: L2.5/ARP glue</h3>

<p>If we did not drop the packet because there was no route, we now know the IP address and interface of the next hop. (Note that this is a host that is connected to us directly – it is sitting on the same wire.)
We need to translate this into an L2 MAC address in order to pass it to the switch. We do it via the ARP table:</p>

<div><div><pre><code>arp_table : (IPv4Address, Interface) -&gt; MACAddress
</code></pre></div></div>

<p>Note: <code>Interface</code> conceptually belongs there, but <code>IPv4Address</code> should be unique. We need to store the interface in the control plane anyway, because we want to pre-emptively re-send ARP requests when an entry is about to expire, but in the data plane it is not strictly necessary.</p>

<p>An interesting question arises here: What do we do if there is no match, i.e. when we don’t know the MAC address for the IP? First, we send an ARP request. Then, most routers drop the packet (relying on either retransmissions or “nobody will miss it”). Storing the packet until the ARP reply comes back (or until it expires) would also work, but usually isn’t done.
Sending ARP requests is normally done in the control plane, because the ARP requests need to be throttled and expired and such.</p>

<p>P4 code:</p>
<div><div><pre><code>action set_dst_mac(mac_addr_t dst_addr) {
    hdr.ethernet.dst_addr = dst_addr;
}

table ipv4_arp {
    key = {
        meta.ipv4_next_hop: exact;     // next_hop is the host we found in the routing step; we want to send to that
        // meta.out_interface: exact;  // conceptually this belongs here, but actually next_hop should be unique, so
                                       // we can leave it out
    }
    actions = {
        set_dst_mac;                // set_dst_mac(mac)
        drop;
    }
    default_action = drop();
    size = ARP_TABLE_SIZE;
}
</code></pre></div></div>

<p>IPv6 uses NDP instead of ARP, which is different but the same ;-)</p>

<h3 id="3-it-needs-to-be-forwarded-l2switch">3. “It needs to be forwarded”: L2/switch</h3>

<p>This is L2 / the switch. It works on each interface separately (it could be multiple chips in hardware). It gets a packet with some destination MAC address, and it decides on which port it should put it. It uses a <em>MAC table</em> to do it:</p>

<div><div><pre><code>mac_table : MACAddress -&gt; Port
</code></pre></div></div>

<p>P4 code:</p>

<div><div><pre><code>// note: we're operating on metadata.out_interface

action set_out_port(port_t ports) {
    standard_metadata.egress_spec = ports;
}

action broadcast() {
    // Implementation depends on the switch.
    // In v1model, use a multicast group corresponding to all ports on metadata.out_interface.
}

// we call it dmac -- see below why
table dmac {
    key = {
        hdr.ethernet.dst_addr: exact;
    }
    actions = {
        set_out_port;  // set_out_port(port)
        broadcast;     // no params, uses metadata.out_interface
                       // remember to set broadcast for 0xffffffffffff in the control plane
        drop;
    }
    default_action = drop();
    size = ARP_TABLE_SIZE;  // we can have at most as many ports as MAC addresses
}

</code></pre></div></div>

<p>Note: Real switches are a bit more complicated than that: for example, redundant links mean that a MAC address may be on more than one port. However, you will notice when you need to think about this. Normally considering the simple version is sufficient.</p>

<h3 id="the-logic-applying-the-tables">The logic: Applying the tables</h3>

<ol>
  <li>apply routing =&gt; find the next hop (either gateway or direct)</li>
  <li>apply ARP translation to the “next hop” host</li>
  <li>send out on the right port</li>
</ol>

<p>In P4:</p>
<div><div><pre><code>apply {
    routing.apply();  // fills out metadata.next_hop
    arp.apply();      // sets pkt.ethernet.dst_addr to the MAC of next_hop
    dmac.apply();     // sends out on the port for pkt.ethernet.dst_addr
}
</code></pre></div></div>

<p>(Note: While this is conceptually correct, we actually also want to apply the auxiliary table mentioned below. The full code contains that.)</p>

<h2 id="the-control-plane-how-to-fill-the-tables">The Control Plane: How to Fill the Tables</h2>

<p>Starting at the bottom for a change:</p>

<h3 id="l3--routing-table">L3 / routing table</h3>

<p>Filled out by the control plane, depending on the context:</p>

<ul>
  <li>In your home router, it probably has only two entries: the local network (something like 192.168.0.0/24) =&gt; direct on the internal interface, and a default route via your ISP’s gateway on the external interface.
 In this case, the routing table is static and is filled out by the firmware according to the settings.</li>
  <li>In a small company router, there might be a direct network such as 10.0.0.0/24, a remote office in 10.0.1.0/24 via a VPN server, and a default route from the ISP.
 The default route and the direct route would also be filled …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kamila.is//teaching/how-routers-work/">https://kamila.is//teaching/how-routers-work/</a></em></p>]]>
            </description>
            <link>https://kamila.is//teaching/how-routers-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435454</guid>
            <pubDate>Thu, 10 Sep 2020 19:00:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CCS811 indoor air quality sensor driver in Rust]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24435312">thread link</a>) | @eldruin
<br/>
September 10, 2020 | https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/ | <a href="https://web.archive.org/web/*/https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrap"><div><div><div><section id="main"><div><article id="post-/ccs811-indoor-air-quality-sensor-driver-in-rust" itemscope="" itemprop="blogPost"><div><header></header><p><a href="https://blog.eldruin.com/images/ccs811-bluepill.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-bluepill.jpg" itemprop="image"> </a><a href="https://blog.eldruin.com/images/ccs811-rpi.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-rpi.jpg" itemprop="image"> </a><a href="https://blog.eldruin.com/images/ccs811-measurements.jpg" rel="gallery_ckex53tc400000cmljwxbgvu7"><img src="https://blog.eldruin.com/images/ccs811-measurements.jpg" itemprop="image"></a></p><div itemprop="articleBody"><p><a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener"><img src="https://img.shields.io/crates/v/embedded-ccs811.svg"></a>&nbsp;<a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener"><img src="https://docs.rs/embedded-ccs811/badge.svg"></a>&nbsp;<a href="https://travis-ci.com/eldruin/embedded-ccs811-rs" target="_blank" rel="noopener"><img src="https://travis-ci.com/eldruin/embedded-ccs811-rs.svg?branch=master"></a>&nbsp;<a href="https://coveralls.io/github/eldruin/embedded-ccs811-rs?branch=master" target="_blank" rel="noopener"><img src="https://coveralls.io/repos/github/eldruin/embedded-ccs811-rs/badge.svg?branch=master"></a></p><p>We spend an enormous amount of time indoors. The indoor air quality is often overlooked but it is actually an important factor in our health, comfort and even productivity.</p><p>There are lots of things that contribute to the degradation of the <a href="https://en.wikipedia.org/wiki/Indoor_air_quality" target="_blank" rel="noopener">indoor air quality</a> over time. Some of them are trivial to guess like breathing, chimneys, second-hand tobacco smoke, mold, etc. There are others that you may not have heard of like <a href="https://en.wikipedia.org/wiki/Volatile_organic_compound" target="_blank" rel="noopener">volatile organic compounds (VOC)</a>.<br>Remember that smell new things have? well sorry but that <strong><a href="https://iaqscience.lbl.gov/voc-cancer" target="_blank" rel="noopener">can give you cancer</a></strong>.</p><p>You can build your own indoor air quality monitor with an AMS/ScioSense CCS811 sensor and some Rust using the driver I wrote.</p><h2 id="The-device"><a href="#The-device" title="The device"></a>The device</h2><p>The CCS811 is an ultra-low power digital gas sensor solution which integrates a metal oxide (MOX) gas sensor to detect a wide range of Volatile Organic Compounds (VOCs) for indoor air quality monitoring with a microcontroller unit (MCU), which includes an Analog-to-Digital converter (ADC), and an I²C interface.</p><p>CCS811 supports intelligent algorithms to process raw sensor measurements to output equivalent total VOC (eTVOC) and equivalent CO2 (eCO2) values, where the main cause of VOCs is from humans.</p><p>CCS811 supports multiple measurement modes that have been optimized for low-power consumption during an active sensor measurement and idle mode extending battery life in portable applications.</p><h2 id="Firmware-update"><a href="#Firmware-update" title="Firmware update"></a>Firmware update</h2><p>Depending on where you bought your device, it might be that the firmware application version is too old. I have observed the older version hangs or returns errors quite often.</p><p>You can update the firmware application with a Raspberry Pi (it does not matter which one).<br>First wire the device like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span>RPi   &lt;-&gt; CCS811</span><br><span>GND   &lt;-&gt; GND</span><br><span>3.3V  &lt;-&gt; VCC</span><br><span>Pin 5 &lt;-&gt; SCL</span><br><span>Pin 3 &lt;-&gt; SDA</span><br><span>GND   &lt;-&gt; nWAKE</span><br><span>3.3V  &lt;-&gt; RST</span><br></pre></td></tr></tbody></table></figure><p>Next inside your Raspberry Pi download the driver repository somewhere, then run the flashing program without arguments to print the current firmware version:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span>git clone https://github.com/eldruin/embedded-ccs811-rs</span><br><span>cd embedded-ccs811-rs</span><br><span>cargo run --example flash-firmware</span><br></pre></td></tr></tbody></table></figure><p>You will see something like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></pre></td><td><pre><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (1, 1, 0)</span><br><span>Has valid firmware application: true</span><br></pre></td></tr></tbody></table></figure><p>And then an error because no firmware file was provided.</p><p>If the firmware application is smaller than <code>(2, 0, 0)</code>, you can update it as follows.</p><p>Download the new version of the firmware application from <a href="https://github.com/sciosense/CCS811_driver/blob/master/examples/ccs811flash/CCS811_SW000246_1-00.bin" target="_blank" rel="noopener">here</a>. Then place it inside the <code>embedded-ccs811-rs</code> folder and call the flashing program again now providing the path to the new firmware file:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>cargo run --example flash-firmware CCS811_SW000246_1-00.bin</span><br></pre></td></tr></tbody></table></figure><p>You should see an output similar to this:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (1, 1, 0)</span><br><span>Has valid firmware application: true</span><br><span>Starting update process: Reset, erase, download, verify...</span><br><span>Update was successful!</span><br><span>Status:</span><br><span>Hardware ID: 129, hardware version: (1, 2)</span><br><span>Firmware boot version: (1, 0, 0)</span><br><span>Firmware application version: (2, 0, 0)</span><br><span>Has valid firmware application: true</span><br></pre></td></tr></tbody></table></figure><p>Done!</p><h2 id="Using-the-driver"><a href="#Using-the-driver" title="Using the driver"></a>Using the driver</h2><p>To use the device from Rust, you have to add the <a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener">embedded-ccs811</a> crate to your project as well as a concrete implementation of the <a href="https://crates.io/crates/embedded-hal" target="_blank" rel="noopener">embedded-hal</a> traits. For example if you are using the Raspberry Pi running Linux:</p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span></span><br><span>...</span><br><span><span>[dependencies]</span></span><br><span><span>embedded-ccs811</span> = <span>"0.2"</span></span><br><span><span>linux-embedded-hal</span> = <span>"0.3"</span></span><br><span><span>nb</span> = <span>"1"</span></span><br></pre></td></tr></tbody></table></figure><p>Here is an example program which will start the application and print the measurements (<a href="https://github.com/eldruin/embedded-ccs811-rs/blob/master/examples/linux.rs" target="_blank" rel="noopener">source</a>):<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></pre></td><td><pre><span><span>use</span> embedded_ccs811::{prelude::*, Ccs811Awake, MeasurementMode, ModeChangeError, SlaveAddr};</span><br><span><span>use</span> linux_embedded_hal::I2cdev;</span><br><span><span>use</span> nb::block;</span><br><span></span><br><span><span><span>fn</span> <span>main</span></span>() {</span><br><span>    <span>let</span> dev = I2cdev::new(<span>"/dev/i2c-1"</span>).unwrap();</span><br><span>    <span>let</span> address = SlaveAddr::default();</span><br><span>    <span>let</span> sensor = Ccs811Awake::new(dev, address);</span><br><span>    <span>match</span> sensor.start_application() {</span><br><span>        <span>Err</span>(ModeChangeError { dev: _, error }) =&gt; {</span><br><span>            <span>println!</span>(<span>"Error during application start: {:?}"</span>, error);</span><br><span>        }</span><br><span>        <span>Ok</span>(<span>mut</span> sensor) =&gt; {</span><br><span>            sensor.set_mode(MeasurementMode::ConstantPower1s).unwrap();</span><br><span>            <span>loop</span> {</span><br><span>                <span>let</span> data = block!(sensor.data()).unwrap();</span><br><span>                <span>println!</span>(<span>"eCO2: {}, eTVOC: {}"</span>, data.eco2, data.etvoc);</span><br><span>            }</span><br><span>        }</span><br><span>    }</span><br><span>}</span><br></pre></td></tr></tbody></table></figure><p>Furthermore, this device must be provided with the ambient temperature and humidity in order to compensate the readings. You can see an example doing this <a href="https://github.com/eldruin/driver-examples/blob/master/raspberrypi/examples/ccs811-gas-voc-display-rpi.rs" target="_blank" rel="noopener">here</a>.</p><p>I also created a bare-metal example program that runs on the STM32F1 “blue-pill” board which continuously reads the measurement and prints it on an OLED display. You can find the source code of that program <a href="https://github.com/eldruin/driver-examples/blob/master/stm32f1-bluepill/examples/ccs811-gas-voc-display-bp.rs" target="_blank" rel="noopener"><strong>here</strong></a>.</p><p>In the <a href="https://github.com/eldruin/driver-examples" target="_blank" rel="noopener"><strong>driver-examples</strong></a> repository you can find further bare-metal examples which you can adapt to do other things with this device.</p><h2 id="Some-measurements"><a href="#Some-measurements" title="Some measurements"></a>Some measurements</h2><p><img src="https://blog.eldruin.com/images/ccs811-measurements.jpg" alt="Measurements in a closed room with one person"></p><p>I bought my device on AliExpress and sadly it does not seem to make accurate readings. For example if you see these readings of the device in a closed room with one person. It seems the measurements match the humidity, rather than the CO2 concentration. I made other measurements with an iAQ-Core-C sensor I got from MOUSER and these did resemble what one would expect. I will publish those here soon.</p><p>Possibly my CCS811 is simply worn off. If you are interested in doing something useful with this device I would rather recommend buying it from a reputable retailer like Adafruit, Sparkfun, or so.</p><h2 id="Raspberry-Pi-configuration"><a href="#Raspberry-Pi-configuration" title="Raspberry Pi configuration"></a>Raspberry Pi configuration</h2><p>This device uses clock stretching which leads to communication problems with the Raspberry Pi.<br>For the firmware update it worked repeatedly fine for me but for measurement reading you may encounter errors like this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Device(DeviceErrors { invalid_register_write: true, invalid_register_read: true, invalid_measurement: true, max_resistance: true, heater_fault: true, heater_supply: true })', src/libcore/result.rs:1165:5</span><br></pre></td></tr></tbody></table></figure><p>You may also see this:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: I2C(Nix(Sys(EREMOTEIO)))', src/libcore/result.rs:1165:5</span><br></pre></td></tr></tbody></table></figure><p>A trick for the Raspberry Pi is to reduce the I2C bus speed.<br>You can do that by editing the file <code>/boot/config.txt</code>:<br></p><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span>dtparam=i2c_arm=on # Enable I2C</span><br><span>dtparam=i2c_arm_baudrate=10000 # 10kHz speed</span><br></pre></td></tr></tbody></table></figure><p>Then reboot your Raspberry Pi. Done!</p><p>Even when correctly configured the errors can happen on occasion. See <a href="https://learn.adafruit.com/circuitpython-on-raspberrypi-linux/i2c-clock-stretching" target="_blank" rel="noopener">here</a> for more info.</p><h2 id="Where-to-go-from-here"><a href="#Where-to-go-from-here" title="Where to go from here?"></a>Where to go from here?</h2><p>There is more information and example programs in the <a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener">crate documentation</a>.<br>If you encounter any issues, please report them in the <a href="https://github.com/eldruin/embedded-ccs811-rs/issues" target="_blank" rel="noopener">issue tracker</a>.<br>Feedback, suggestions and improvements are gladly welcome.</p><h2 id="What’s-next"><a href="#What’s-next" title="What’s next?"></a>What’s next?</h2><p>I also have a pretty finished driver for a similar device: <a href="https://crates.io/crates/iaq-core" target="_blank" rel="noopener">iAQ-Core-C/P air quality sensor</a>. I took some measurements which looked much better. I will announce it here soon.</p><p>Otherwise I have been writing many other platform-agnostic Rust drivers although I am slow to finish them up and announce them here.</p><p>To see what I am currently working on you can <a href="https://github.com/eldruin" target="_blank" rel="noopener"><strong>follow me on github</strong></a>.</p><p>Thanks for reading and stay tuned!</p><p>Links: <a href="https://github.com/eldruin/embedded-ccs811-rs" target="_blank" rel="noopener">Source code</a> - <a href="https://crates.io/crates/embedded-ccs811" target="_blank" rel="noopener">Crate</a> - <a href="https://docs.rs/embedded-ccs811" target="_blank" rel="noopener">Documentation</a></p></div></div></article></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://blog.eldruin.com/ccs811-indoor-air-quality-sensor-driver-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435312</guid>
            <pubDate>Thu, 10 Sep 2020 18:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker Considered Harmful (2016)]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24435200">thread link</a>) | @maple3142
<br/>
September 10, 2020 | http://catern.com/posts/docker.html | <a href="https://web.archive.org/web/*/http://catern.com/posts/docker.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


<p>
Docker is extremely popular these days.<sup><a id="fnr.1" name="fnr.1" href="#fn.1">1</a></sup>
Too bad it's not very good.
</p>

<p>
A note in advance:
This is absolutely not about Docker being too "opinionated" for me,
or other tools being more flexible.
I believe that learning and using Docker is just plain more complicated than learning and using the tools I describe below.
Docker is genuinely more complex and harder to use than the alternatives.
These tools also happen to be more flexible than Docker,
but that's not why I'm recommending them:
I'm recommending them because they are simpler to learn and use.
If they are indeed more flexible in addition to being simpler to use, then that's just due to an overall superior design.
</p>

<div id="outline-container-sec-1">
<h2 id="sec-1">Docker containers are not mysterious</h2>
<div id="text-1">
<p>
First, a brief explanation of how containers work.
Linux containers<sup><a id="fnr.2" name="fnr.2" href="#fn.2">2</a></sup> are built on two kernel features, namespaces and cgroups.
Their architecture is quite easy to understand.
</p>

<p>
I encourage everyone to read the main namespaces man page: <a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">man 7 namespaces</a>.
It's well written and makes it easy to grok the concept.
If you create a new instance of all<sup><a id="fnr.3" name="fnr.3" href="#fn.3">3</a></sup> of these namespaces, you have something like a container.
</p>

<p>
The cgroups documentation (located at <a href="https://www.kernel.org/doc/Documentation/cgroups-v1/">Documentation/cgroups-v1/</a> and <a href="https://www.kernel.org/doc/Documentation/cgroup-v2.txt">Documentation/cgroup-v2.txt</a> in your local copy of the Linux source code) is less straightforward, 
but still a better explanation than I could write.
The basic idea is that cgroups are a mechanism for grouping processes.
This mechanism is used to implement other systems like <a href="http://man7.org/linux/man-pages/man7/cpuset.7.html">man 7 cpuset</a>, which are used to track and schedule the container processes.
</p>

<p>
If you make the appropriate system calls to move into a cpuset cgroup and create new namespaces, you have a container.
There's not much to it.
</p>

<p>
One could write a relatively short C program and create a Unix-style utility that uses these system calls to start up a new container.
You can see this for yourself by playing around with <a href="http://man7.org/linux/man-pages/man1/nsenter.1.html">man 1 nsenter</a> and <a href="http://man7.org/linux/man-pages/man1/unshare.1.html">man 1 unshare</a>, which are the most minimal possible wrappers around the namespaces syscalls.
</p>

<p>
The point of explaining this is to show that the Linux container functionality is all rather simple.
Docker (or any other container software) are not doing anything especially mystifying in the specific area of bringing up a container.
Armed with that knowledge, let's look at what else Docker is actually doing.
</p>
</div>
</div>
<div id="outline-container-sec-2">
<h2 id="sec-2">Docker for building containers is superfluous</h2>
<div id="text-2">
<p>
We'll start off with how Docker builds a container image for you.
You pull down some kind of image from the Docker hub, and Docker hums excitingly for a bit while you watch things scroll and progress bars fill.
What you end up with is a filesystem tree from some Linux distro, with a few things added in on top.
</p>

<p>
It may be surprising to some that we have been doing exactly this for multiple decades now.
</p>

<p>
In fact, you do this every time you install GNU/Linux on a machine.
The majority of the files in that filesystem tree come from packages from some distro.
And package managers are certainly capable of installing packages into arbitrary directories; that's how they install a new system.
</p>

<p>
In fact, most even have neat little wrapper scripts to do it for you! And these are only an <code>apt-get install debootstrap</code> (or equivalent) away!
To build filesystem trees for a few of the most popular distros<sup><a id="fnr.4" name="fnr.4" href="#fn.4">4</a></sup>:
</p>
<ul>
<li><code>debootstrap trusty /srv/trees/ubuntu</code>
</li>
<li><code>debootstrap stable /srv/trees/debian</code>
</li>
<li><code>yum -y --nogpg --releasever=22 --disablerepo='*' --enablerepo=fedora install fedora-release systemd passwd dnf fedora-release vim-minimal --installroot=/srv/trees/fedora</code>
</li>
<li><code>pacstrap /srv/trees/arch</code>
</li>
</ul>

<p>
And of course you can select additional packages to install using these commands, or make other changes.
This has been used for decades to build chroots, which I'll say more about a bit later.
There are even more novel package managers,
like <a href="https://nixos.org/nix/">nix</a> and <a href="http://www.gnu.org/software/guix/">guix</a>,
which have interesting features that can make things even easier.
</p>

<p>
But wait, the distro version of node.js (for example) is too out of date!
How am I going to get the latest version?
</p>

<p>
Well, the first thing you should do if you need more up to date versions is enable the updated package repositories for your distro:
Ubuntu backports, Debian backports, CentOS EPEL.
It may be surprising to some, but distros and package managers actually exist for a reason, 
and one of those reasons is that they make it easy to keep your system up to date.
(There are other advantages which I won't go into here<sup><a id="fnr.5" name="fnr.5" href="#fn.5">5</a></sup>)
</p>

<p>
If a suitably updated version is not available through distro channels,
I am obligated to suggest that the next best option is 
to download the source of the distro package, update and rebuild it yourself, and install using that package.
Or, build the package yourself if one isn't available.
This can be a bit of a pain if you are in the early development stages
(though there are tools to make it easier<sup><a id="fnr.6" name="fnr.6" href="#fn.6">6</a></sup>)
but again, there are many advantages.<sup><a id="fnr.5.100" name="fnr.5.100" href="#fn.5">5</a></sup>
</p>

<p>
Most people, however, use the traditional hacks.
You can chroot in and just do your usual <code>pip install foo</code> or <code>gem install bar</code> or <code>npm install baz</code> or <code>./configure &amp;&amp; make &amp;&amp; make install</code>,
just as you would with some "RUN" directives in a Dockerfile.
</p>

<p>
Wow! It's just like Docker!
No, Docker is just like this.
Hopefully it is becoming obvious that here, at least, there is no real advantage of Docker.
</p>

<p>
Crucially, you can use all the same install scripts that you would use with a normal Linux machine.
You don't need to rewrite everything into Dockerfiles.
You can do it manually, you can use shell scripts, you can use Ansible, 
you can write a boutique ConfigurationManagementFactory in Java, you can do whatever you like.
It's just installing software.
It's not complicated unless you make it complicated.
Supposedly, Dockerfiles are simpler than running <code>debootstrap</code> at the beginning of your script, but I'm not sure I understand why.
It seems to me that Docker is no simpler or easier than the standard way.
</p>

<p>
Now, it's true that Docker uses layering to be efficient in terms of disk space and time to build new containers.
It defaults to using <a href="http://aufs.sourceforge.net/aufs.html">AUFS</a> to do this.<sup><a id="fnr.7" name="fnr.7" href="#fn.7">7</a></sup>
I think you could reimplement it easily yourself with a small shell script and some calls to mount;
but I haven't bothered.
</p>

<p>
Personally, I just use <a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs-subvolume">man 8 btrfs-subvolume</a>.
btrfs is a copy on write filesystem which can instantly make space-efficient copies of filesystem trees in "subvolumes",
which the user sees as just regular directories.
</p>

<p>
You can build a stock Ubuntu filesystem tree into a subvolume with 
<code>btrfs subvolume create /srv/trees/ubuntu &amp;&amp; debootstrap trusty /srv/trees/ubuntu/</code>.
Then, when you want to build a new container with specific software,
you just copy that subvolume and perform your modifications on the copy;
that is, <code>btrfs subvolume snapshot /srv/trees/debian /srv/containers/webapp</code> and work on <code>/srv/containers/webapp</code>.
If you want to copy those modifications, you just take another snapshot.
</p>

<p>
This is arguably better, because there's no need to maintain a lot of state about the mount layerings and set them up again on reboot.
Your container filesystem just sits there in a volume waiting for you to start it.
</p>

<p>
Naturally, if you don't like btrfs for some reason,
you're perfectly able to use zfs, OverlayFS, AUFS, or whatever;
no need to have a "storage driver" implemented just to do some simple copy-on-write or layering operations.
</p>

<p>
And if you want to do some kind of change tracking as you build the system,
you should keep it at the proper layer,
or use dedicated tools.
<code>/usr</code> should be immutable and built from packages,
your application data should live in <code>/srv</code> or <code>/var</code> and be mounted in,
and so all the configuration data that is part of the system build should be in <code>/etc</code>.
To track this, you can just use <a href="http://etckeeper.branchable.com/">etckeeper</a> and store your <code>/etc</code> in a git repository.
which is right and proper since <code>/usr</code> should be immutable.
If you must, <a href="https://wiki.gnome.org/action/show/Projects/OSTree">OSTree</a> lets you version whole filesystems.
</p>

<p>
And if you still need to pull in a Docker image for some reason,
you can treat it as just another way to build a filesystem tree.
There are tools that will let you do that,
such as <a href="http://www.freedesktop.org/software/systemd/man/machinectl.html">machinectl pull-dkr</a>.
</p>
</div>
</div>
<div id="outline-container-sec-3">
<h2 id="sec-3">Isolation for deployment is not new</h2>
<div id="text-3">
<p>
But wait! Docker isn't just a pointless abstraction layer over the simple task of building filesystem trees!
It lets you actually use those filesystem trees in containers!
</p>

<p>
Well, it may be a shock, but these tools that Docker uses - they actually exist for a reason.
As I said earlier, these tools have been used for decades to build chroots.
</p>

<p>
What's a chroot?
Well, <a href="http://man7.org/linux/man-pages/man1/chroot.1.html">man 1 chroot</a> is a decades-old tool that lets you change what the root directory <code>/</code> points to;
for example, you could point <code>/</code> at <code>/srv/container/webapp</code>.
Everything looks for libraries and binaries in subdirectories of the root directory, like <code>/usr/lib</code> and <code>/usr/bin</code>.
So, by using chroot you can have an entirely different set of libraries and binaries;
when you run things inside the chroot, they will see just the libraries and software that you installed inside that filesystem tree.
</p>

<p>
To help explain what you can use a chroot for, here's a short little blurb I "wrote" about what you can do with chroot.
</p>

<blockquote>
<p>
Sysadmins use chroot to provide standardized environments for their development, QA, and production teams, reducing "works on my machine" finger-pointing.
By "chrooting" the app platform and its dependencies, sysadmins abstract away differences in OS distributions and underlying infrastructure.
</p>
</blockquote>

<p>
That sure sounds useful.
But wait, there's this new kid on the block, Docker.
Let's see <a href="https://web.archive.org/web/20150211030001/https://www.docker.com/whatisdocker/">what they have to say</a>.
</p>

<blockquote>
<p>
Sysadmins use Docker to provide standardized environments for their development, QA, and production teams, reducing "works on my machine" finger-pointing.
By "Dockerizing" the app platform and its dependencies, sysadmins abstract away differences in OS distributions and underlying infrastructure.
</p>
</blockquote>

<p>
Docker is not novel in giving you these capabilities.
They're quite novel in marketing it so intensely, though.
</p>
</div>
</div>
<div id="outline-container-sec-4">
<h2 id="sec-4">Docker for security is useless by default</h2>
<div id="text-4">
<p>
But wait! Docker is "containers", new, fancy, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://catern.com/posts/docker.html">http://catern.com/posts/docker.html</a></em></p>]]>
            </description>
            <link>http://catern.com/posts/docker.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24435200</guid>
            <pubDate>Thu, 10 Sep 2020 18:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kuma and Envoy: Multi-Cluster and Multi-Cloud Service Meshes]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24434618">thread link</a>) | @fosk
<br/>
September 10, 2020 | https://kuma.io/blog/2020/multi-cluster-cloud/ | <a href="https://web.archive.org/web/*/https://kuma.io/blog/2020/multi-cluster-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <p><span><time datetime="2020-09-10T00:00:00.000Z">
  Sep 10, 2020
</time></span> <span>/</span> <span>
              9 min read
            </span></p></div></div><div><!----> <div><div><p>When we first created Kuma – which means "bear"&nbsp;in Japanese – we dreamed of creating a service mesh that could run across every cluster, every cloud and every application. These are all requirements that large organizations must implement to support their application teams across a wide variety of architectures and platforms: VMs, Kubernetes, AWS, GCP and so on.</p> <p>With Kuma – now a CNCF project and at the time of this writing, the only Envoy-based service mesh donated and accepted by the foundation – we have relentlessly executed on this vision with the community.</p> <p>Starting from Kuma 0.6, which was released this summer with a new advanced multi-zone capability, Kuma now supports every cloud vendor, every architecture and every platform together in a multi-mesh control plane. When deployed in a multi-zone deployment, Kuma abstracts away both the synchronization of the service mesh policies across multiple zones and the service connectivity (and service discovery) across those zones. A zone can be a Kubernetes cluster, a data center, a cloud region, a VPC, a subnet and so on – we can slice and dice zones to our liking, and we can also mix Kubernetes and VM workloads into one distributed mesh deployment.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-02-1536x779.jpg" alt=""></p> <center><i>
Kuma creates a service connectivity overlay across hybrid infrastructure to discover and connect services automatically, including hybrid Kubernetes + VM services.
</i></center> <p>This <a href="https://kuma.io/docs/latest/documentation/deployments/#multi-zone-mode" target="_blank" rel="noopener noreferrer">multi-zone capability</a> has been added in addition to the <a href="https://kuma.io/docs/latest/policies/mesh/" target="_blank" rel="noopener noreferrer">multi-mesh support</a> that Kuma introduced since day one to create multiple isolated meshes on the same cluster (with dedicated mTLS CAs) in order to reduce team coordination, increase isolation and improve security rather than one large service mesh that everybody is sharing. Also, since multi-zone leverages the first-class K8s + VM support that shipped since the first version of Kuma, all teams and workloads in the organizations can benefit from service mesh and not just our greenfield initiatives.</p> <p>A Kuma service mesh distributed across every cloud, cluster and workload that the teams are using can therefore be managed from one individual cluster of Kuma itself. Meanwhile, multiple service meshes can be virtually provisioned on one Kuma control plane (horizontally scalable) to simplify mesh management across the organization – very similar to how Kubernetes and its namespaces work.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-one-cluster-new@2x.png" alt=""></p> <center><i>
Kuma supports multiple virtual meshes on the same Kuma deployment, removing the requirement of having multiple service mesh clusters for each application and therefore lowering the ops costs significantly.
</i></center> <h3 id="extending-xds-with-kds"><a href="#extending-xds-with-kds">#</a> Extending xDS With KDS</h3> <p>In Kuma, we can deploy a distributed service mesh running across multiple clusters, clouds or regions by leveraging the “multi-zone” deployment mode. The “multi-zone” deployment is a new way of running Kuma that has been introduced in v0.6+ in addition to the “standalone” deployment mode (one service mesh per zone).</p> <p>In a multi-zone deployment, there are a few important features that Kuma provides:</p> <ol><li>There are two control plane modes: global and remote. This is quite unique in the service mesh landscape.</li> <li>There is a new DNS “.mesh” zone for service discovery.</li> <li>There is a new “Ingress” data plane proxy type that enables connectivity between zones within a Kuma mesh.</li></ol> <p>In a distributed deployment, the “global” control plane will be in charge of accepting Kuma resources to determine the behavior of the service mesh via either native Kubernetes CRDs or vanilla YAML in VM-based deployments. It will be in charge of propagating these resources to the “remote” control planes – one for each zone that we want to support.</p> <p>The “remote” control planes are going to be exchanging Kuma resources with the “global” control plane over an extension of the Envoy xDS API that we called KDS (Kuma Discovery Service) over a gRPC protocol, and therefore, over HTTP/2. The “remote” control planes are also going to be accepting requests from the Envoy-based data plane proxies that belong to the same zone over traditional xDS.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-01-1536x1316.jpg" alt=""></p> <center><i>
The remote control planes also embed a DNS service discovery that can be used to discover services across different zones. The above architecture can be easily installed in just a few steps using either the Kuma CLI “kumactl” or HELM charts.
</i></center> <p>In Kuma, we abstract away the Envoy proxy process in a “kuma-dp” process so that the user never directly configures or starts “envoy”, therefore making the whole process of starting a data plane proxy much easier. Advanced users can still access the underlying “envoy” process if they want to.</p> <p>By leveraging the native xDS API of Envoy to connect “kuma-dp” with “remote” control planes in every zone as well as leveraging KDS to connect the “remote” control planes to the global control plane, effectively we have gRPC communication enabled across the entire service mesh infrastructure stack in a consistent way.</p> <p>The “global” and “remote” architecture has a few benefits:</p> <ol><li>We can scale each zone independently by scaling the “remote” control planes and achieve HA in case one zone experiences issues.</li> <li>There is no single point of failure: even if the “global” control plane goes down, we can still register and deregister data plane proxies on the “remote” ones, and the most updated addresses of every service can still be propagated to other Envoy-based sidecars.</li> <li>The “global” control plane allows us to automatically propagate the state across every zone, while at the same time making sure that the “remote” control planes are aware of each zone’s Kuma ingress in order to enable cross-zone connectivity.</li></ol> <p>The control plane separation governs how Kuma resources (like meshes and policies) are synchronized across the zones, but it requires two other components in order to enable discovery and connectivity at the data plane layer across our zones in an automated way: service discovery and the “ingress” data plane proxy mode.</p> <h3 id="cross-zone-discovery-and-connectivity"><a href="#cross-zone-discovery-and-connectivity">#</a> Cross-Zone Discovery and Connectivity</h3> <p>Like we described, a multi-zone deployment can be used to deploy a distributed service mesh across multiple clouds and clusters, as well as to enable seamless communication between services running in different zones, effectively providing cross-zone service discovery and connectivity.</p> <p>Among other use cases, cross-zone connectivity is useful for:</p> <ul><li>Enabling high availability across multiple Kubernetes clusters, regions and availability zones in both single and multi-cloud environments</li> <li>Enabling traffic shifting from one zone to another for disaster recovery</li> <li>Enabling a step-by-step transition of our applications from VMs to Kubernetes – or from physical data centers to the cloud – by leveraging traffic control policies to determine the conditions under which service traffic should be shifted from one zone to another.
Kuma’s multi-zone deployment enables cross-zone connectivity by providing two important features:</li></ul> <ol><li>A new “ingress” data plane proxy mode processes incoming traffic into a zone. There will be one Kuma ingress deployment per zone, that can be scaled horizontally as the traffic increases. The “ingress” data plane mode is being added in addition to the default proxying one and the “gateway” one (to support third-party API gateways). Because of the new “ingress” mode, Kuma doesn’t require a flat networking topology between zones and can support more complex infrastructure.</li> <li>A built-in service discovery DNS server resolves the address of a service to either an IP address of a replica in the same zone or the address of an ingress proxy in another zone.
Likewise with the “global” and “remote” control planes, the ingress and the DNS service discovery can also be installed in one click by following the <a href="https://kuma.io/docs/latest/documentation/deployments/#multi-zone-mode" target="_blank" rel="noopener noreferrer">multi-zone instructions</a> on Kuma.</li></ol> <p>When it comes to service discovery, Kuma creates a “.mesh” DNS entry on the built-in DNS resolver that can be used to resolve services across the same zone or in other zones, effectively “flattening” the discovery of services across a complex infrastructure. Kuma will – accordingly to the traffic routing policies that have been configured – determine if we should be consuming a replica of the service in the local zone or if we should resolve the request to the IP address of a Kuma ingress in another zone, which will then leverage SNI to determine what service has been requested and route the request accordingly.</p> <p><img src="https://2tjosk2rxzc21medji3nfn1g-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/diagram-03.jpg" alt=""></p> <center><i>
In this example, we have three services (users, invoices and billing). Requests to “invoices.mesh” will be proxied to an IP address within the same zone, whereas requests to “billing.mesh” will be <b>automatically</b> proxied to an ingress of another zone.
</i></center> <p>Since SNI resolution is mandatory for cross-zone communication, the <a href="https://kuma.io/docs/latest/policies/mutual-tls/" target="_blank" rel="noopener noreferrer">mTLS policy</a> must be enabled on the mesh. Also, since Kuma already knows where all the services are running,  cross-zone discovery and connectivity happen automatically.</p> <p>When a new service is registered into Kuma, a new “kuma.io/zone” tag is added to the data plane definition so that we can use the <a href="https://kuma.io/docs/latest/documentation/dps-and-data-model/#tags" target="_blank" rel="noopener noreferrer">attribute-based policy selectors</a> to configure Kuma policies like <a href="https://kuma.io/docs/latest/policies/traffic-route/" target="_blank" rel="noopener noreferrer">Traffic Route</a> to determine the behavior of cross-zone traffic (blue/green or canary across different zones, weighted traffic, as well as traffic shifting).</p> <p>When consuming any “{service-name}.mesh” on default port 80 (even if the service is not listening on port 80), the DNS resolver – in addition to resolving the address of the service – will also automatically resolve the port of the destination service and inject it into the connection in order to keep the uptime of the overall connectivity even when a team decides to re-assign ports of a service that other teams may be using. This feature reduces the team coordination required to maintain a large number of services and connections in a Kuma mesh.</p> <h3 id="conclusion"><a href="#conclusion">#</a> Conclusion</h3> <p>Thanks to the new multi-zone capability that Kuma provides since v0.6+, we can now easily run a service mesh across multiple Kubernetes clusters, clouds and regions. Since Kuma natively supports both containerized and VM workloads, this …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kuma.io/blog/2020/multi-cluster-cloud/">https://kuma.io/blog/2020/multi-cluster-cloud/</a></em></p>]]>
            </description>
            <link>https://kuma.io/blog/2020/multi-cluster-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434618</guid>
            <pubDate>Thu, 10 Sep 2020 17:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four Indian Startups Funded via Abu Dhabi's AWI Fund (Middle East AI News)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24434248">thread link</a>) | @asiaainews
<br/>
September 10, 2020 | https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/middleeastainews/issues/more-awi-fund-deals-disclosed-saudi-ai-strategy-to-be-launched-in-oct-275360</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434248</guid>
            <pubDate>Thu, 10 Sep 2020 17:05:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intercepting Zoom's encrypted data with BPF]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24434031">thread link</a>) | @aaron-santos
<br/>
September 10, 2020 | https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes | <a href="https://web.archive.org/web/*/https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I originally wrote an earlier version of this post at the end of March, when I was working on adding uprobes support to <a href="https://github.com/redsift/redbpf">redbpf</a>. I wanted to blog about the work I was doing and needed an application to instrument for the purpose of this post. At that time Zoom's popularity was rising quickly, and I happened to read somewhere that it supported this creepy attention tracking feature that allowed meeting hosts to monitor if attendees were paying attention. I figured I could try to use uprobes to snoop into the data Zoom was sending to their servers and see how the tracking worked.</p><p>But then Zoom quickly started getting under a lot of fire. <a href="https://en.wikipedia.org/wiki/Zoombombing">Zoombombing</a> became a thing, several security issues were discovered and pretty much everyone started piling on the company. Considering all that, I was advised and ultimately decided not to publish the post.</p><p>Now things seem to have settled, Zoom <a href="https://blog.zoom.us/a-message-to-our-users/">improved their security</a> and by popular demand <a href="https://support.zoom.us/hc/en-us/articles/115000538083-Attendee-attention-tracking">got rid of attention tracking</a>. So I think I can finally publish this! I edited out the part about attention tracking (which no longer exists) and a couple of other things that could potentially get me in trouble.</p><p><strong>TLDR:</strong> I wrote a command line tool that uses BPF uprobes to intercept the TLS encrypted data that zoom sends over the network, and here I'm going to show the process I went through to write it. After I wrote this post I made the tool generic so that it can now instrument any program that uses OpenSSL. I published the code at <a href="https://github.com/alessandrod/snuffy">https://github.com/alessandrod/snuffy</a>.</p><h2>Instrumenting applications with uprobes</h2><p>Uprobes let you instrument user space applications by attaching custom code to arbitrary locations inside a target process. It's a bit like running an application in a debugger, setting breakpoints and fiddling around, but programmatically and without the overhead of a debugger.</p><p>An uprobe must be <a href="https://ingraind.org/api/cargo_bpf/#building">compiled</a> and <a href="https://ingraind.org/api/redbpf/load/struct.Loader.html">loaded</a> like any other BPF program, then it can be attached with the following API:</p><pre><code><span>pub</span><span> </span><span>fn</span><span> </span><span>attach_uprobe</span><span>(</span><span>
</span><span>    </span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span>
</span><span>    fn_name</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>&amp;</span><span>str</span><span>&gt;</span><span>,</span><span>
</span><span>    offset</span><span>:</span><span> </span><span>u64</span><span>,</span><span>
</span><span>    target</span><span>:</span><span> </span><span>&amp;</span><span>str</span><span>,</span><span>
</span><span>    pid</span><span>:</span><span> </span><span>Option</span><span>&lt;</span><span>pid_t</span><span>&gt;</span><span>,</span><span>
</span><span></span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span>;</span></code></pre><p><a href="https://ingraind.org/api/redbpf/struct.UProbe.html#method.attach_uprobe">attach_uprobe()</a> parses the <code>target</code> ELF binary or shared library, looks up the function <code>fn_name</code>, and once the target is running it injects the probe code at the resolved address. If <code>offset</code> is non-zero, its value is added to the address of <code>fn_name</code>. If <code>fn_name</code> is <code>None</code>, then <code>offset</code> is interpreted as starting from the beginning of the target's <code>.text</code> section. Finally if a <code>pid</code> is given, the probe will only be attached to the process with the given id.</p><p>In the rest of the post I'm going to show some examples of uprobes, focusing on the code that gets compiled to BPF bytecode, loaded in the kernel and then injected in the target process (in our case zoom). I'm not going to show much of the user-space code that loads the probes. That part is pretty standard rust code that does some setup, then prints out the data coming from the probes as it receives it. If you're interested you can still find all the user-space code at <a href="https://github.com/alessandrod/snuffy/blob/master/src/main.rs">https://github.com/alessandrod/snuffy/blob/master/src/main.rs</a>.</p><h2>Poking into Zoom</h2><p>We're going to use uprobes to inspect the network traffic between the zoom client and the company's servers. Zoom uses <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">Transport Layer Security</a> to encrypt the data. In order to intercept the <em>unencrypted</em> data, we need to find out which TLS library is used by the client, then attach uprobes to strategic places inside it.</p><p>Let's start with searching for common TLS symbols using <code>objdump</code>:</p><pre><code><span>$ objdump -CT /opt/zoom/zoom | grep -iE "ssl|gnutls"
</span>000000000080d5b0 g    DF .text	0000000000000013  Base        PreMeetingUIMgr::sig_blockUnknownSSLCertChanged()
<!-- -->000000000080d590 g    DF .text	0000000000000013  Base        PreMeetingUIMgr::sig_sslCertWarningChanged()
</code></pre><p>Those look like callbacks that get invoked when a certificate is invalid, and Zoom does indeed show a warning if you try to intercept its traffic with a tool like <code>mitmproxy</code>. The callbacks deal with certificates, not unencrypted buffers, so they are not useful to us.</p><p>Looking at the output of <code>ldd</code> we can see that Zoom links to <a href="https://doc.qt.io/qt-5/qtnetwork-index.html">Qt Network</a>, which includes some potentially relevant APIs:</p><pre><code><span>$ objdump -CT /opt/zoom/zoom | grep -iE "QNetworkReq"
</span>0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkRequest::QNetworkRequest(QUrl const&amp;)
<!-- -->0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkRequest::~QNetworkRequest()
<!-- -->0000000000000000      DF *UND*	0000000000000000  Qt_5        QNetworkAccessManager::get(QNetworkRequest const&amp;)
</code></pre><p><code>QNetworkRequest(QUrl const&amp;)</code> looks like something that could be used to communicate with the backend and does <a href="https://doc.qt.io/qt-5/qnetworkrequest.html#setSslConfiguration">support TLS</a>. I tried attaching to it and other functions exported by the framework but none of them turned out to be invoked. Zoom supports a number of platforms and devices, it's possible that they use Qt just for the UI on linux, and then have some lower level networking code that can be shared with their other clients.</p><p>At this point it is pretty likely that zoom is linking statically to the TLS library. Let's see if in the <code>.rodata</code> section of the binary there's anything that could point us in the right direction:</p><pre><code><span>$ readelf -p .rodata /opt/zoom/zoom | grep -i ssl | wc -l
</span>739
<!-- -->$ # 😏
<!-- -->$ readelf -p .rodata /opt/zoom/zoom | grep -i 'openssl 1'
<!-- -->  [4a1b66]  OpenSSL 1.1.1g  21 Apr 2020
<!-- -->  [58cd50]  OpenSSL 1.1.1g  21 Apr 2020
</code></pre><p>Aha! The client is using OpenSSL version 1.1.1g (knowing this will turn out to be very useful), and the library is statically linked.</p><h2>Instrumenting OpenSSL</h2><p>OpenSSL exports two functions named <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_read.html">SSL_read</a> and <a href="https://www.openssl.org/docs/man1.1.1/man3/SSL_write.html">SSL_write</a>, which have the following signature:</p><pre><code><span>int</span><span> </span><span>SSL_read</span><span>(</span><span>SSL </span><span>*</span><span>ssl</span><span>,</span><span> </span><span>void</span><span> </span><span>*</span><span>buf</span><span>,</span><span> </span><span>int</span><span> num</span><span>)</span><span>;</span><span>
</span><span></span><span>int</span><span> </span><span>SSL_write</span><span>(</span><span>SSL </span><span>*</span><span>ssl</span><span>,</span><span> </span><span>const</span><span> </span><span>void</span><span> </span><span>*</span><span>buf</span><span>,</span><span> </span><span>int</span><span> num</span><span>)</span><span>;</span></code></pre><p><code>SSL_read</code> reads encrypted data sent by a remote peer, decrypts it and stores the decrypted data in the provided buffer. <code>SSL_write</code> encrypts the given buffer and sends it to a remote peer. Attaching an uprobe where <code>SSL_read</code> <em>returns</em>, and one at the <em>entry</em> of <code>SSL_write</code>, we can therefore access unencrypted memory.</p><p>Here's the uprobes that do just that:</p><pre><code><span>use</span><span> </span><span>redbpf_probes</span><span>::</span><span>uprobe</span><span>::</span><span>prelude</span><span>::</span><span>*</span><span>;</span><span>
</span>
<span></span><span>struct</span><span> </span><span>SSLArgs</span><span> </span><span>{</span><span>
</span><span>    ssl</span><span>:</span><span> </span><span>usize</span><span>,</span><span>
</span><span>    buf</span><span>:</span><span> </span><span>usize</span><span>,</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>// temporary storage map</span><span>
</span><span></span><span>static</span><span> </span><span>mut</span><span> ssl_args</span><span>:</span><span> </span><span>HashMap</span><span>&lt;</span><span>u64</span><span>,</span><span> </span><span>SSLArgs</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>HashMap</span><span>::</span><span>with_max_entries</span><span>(</span><span>1024</span><span>)</span><span>;</span><span>
</span>
<span></span><span>fn</span><span> </span><span>output_buf</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>,</span><span> mode</span><span>:</span><span> </span><span>AccessMode</span><span>,</span><span> buf_addr</span><span>:</span><span> </span><span>usize</span><span>,</span><span> len</span><span>:</span><span> </span><span>usize</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>// Ignore how this is implemented for now. Assume it reads `len` bytes from `buf_addr`</span><span>
</span><span>  </span><span>// and sends them to our user-space process where they are hex-dumped.</span><span>
</span><span>  </span><span>...</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_write_entry</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> ssl </span><span>=</span><span> regs</span><span>.</span><span>parm1</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> buf </span><span>=</span><span> regs</span><span>.</span><span>parm2</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> num </span><span>=</span><span> regs</span><span>.</span><span>parm3</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>i32</span><span>;</span><span>
</span><span>    </span><span>if</span><span> num </span><span>&lt;=</span><span> </span><span>0</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span>
<span>    </span><span>// This is where SSL_write begins, the buffer isn't encrypted yet</span><span>
</span><span>    </span><span>// so we send it to user-space</span><span>
</span><span>    </span><span>output_buf</span><span>(</span><span>regs</span><span>,</span><span> </span><span>AccessMode</span><span>::</span><span>Write</span><span>,</span><span> buf</span><span>,</span><span> num </span><span>as</span><span> </span><span>usize</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_read_entry</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> ssl </span><span>=</span><span> regs</span><span>.</span><span>parm1</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span><span>    </span><span>let</span><span> buf </span><span>=</span><span> regs</span><span>.</span><span>parm2</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>
</span>
<span>    </span><span>// store the function arguments so we can retrieve them once the</span><span>
</span><span>    </span><span>// function returns</span><span>
</span><span>    </span><span>unsafe</span><span> </span><span>{</span><span>
</span><span>        ssl_args</span><span>.</span><span>set</span><span>(</span><span>&amp;</span><span>bpf_get_current_pid_tgid</span><span>(</span><span>)</span><span>,</span><span> </span><span>&amp;</span><span>SSLArgs</span><span> </span><span>{</span><span> ssl</span><span>,</span><span> buf </span><span>}</span><span>)</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>#[uretprobe]</span><span>
</span><span></span><span>fn</span><span> </span><span>SSL_read_ret</span><span>(</span><span>regs</span><span>:</span><span> </span><span>Registers</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// the return value of SSL_read contains the length of the buffer</span><span>
</span><span>    </span><span>let</span><span> num </span><span>=</span><span> regs</span><span>.</span><span>rc</span><span>(</span><span>)</span><span> </span><span>as</span><span> </span><span>i32</span><span>;</span><span>
</span><span>    </span><span>if</span><span> num </span><span>&lt;</span><span> </span><span>0</span><span> </span><span>{</span><span>
</span><span>        </span><span>return</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>// This is where SSL_read returns, the buffer is now decrypted</span><span>
</span><span>    </span><span>// so we send it to user-space</span><span>
</span><span>    </span><span>let</span><span> tgid </span><span>=</span><span> </span><span>bpf_get_current_pid_tgid</span><span>(</span><span>)</span><span>;</span><span>
</span><span>    </span><span>let</span><span> args </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> ssl_args</span><span>.</span><span>get</span><span>(</span><span>&amp;</span><span>tgid</span><span>)</span><span> </span><span>}</span><span>;</span><span>
</span><span>    </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>SSLArgs</span><span> </span><span>{</span><span> ssl</span><span>,</span><span> buf </span><span>}</span><span>)</span><span> </span><span>=</span><span> args </span><span>{</span><span>
</span><span>        </span><span>output_buf</span><span>(</span><span>regs</span><span>,</span><span> </span><span>AccessMode</span><span>::</span><span>Read</span><span>,</span><span> </span><span>*</span><span>buf</span><span>,</span><span> num </span><span>as</span><span> </span><span>usize</span><span>)</span><span>;</span><span>
</span><span>        </span><span>unsafe</span><span> </span><span>{</span><span> ssl_args</span><span>.</span><span>delete</span><span>(</span><span>&amp;</span><span>tgid</span><span>)</span><span> </span><span>}</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Uprobes are annotated with the <a href="https://ingraind.org/api/redbpf_probes/uprobe/prelude/attr.uprobe.html">#[uprobe]</a> attribute. Once they are triggered, they get passed a <a href="https://ingraind.org/api/redbpf_probes/kprobe/struct.Registers.html">Registers</a> argument through which they can access memory.</p><p>The <code>SSL_write_entry</code> probe is the simplest. It reads the registers containing the values of the <code>buf</code> and <code>num</code> arguments passed to <code>SSL_write</code>, and sends a copy of the buffer to user-space before it gets encrypted.</p><p>The <code>SSL_read_entry</code> probe is similar in that it reads the content of the <code>ssl</code>, <code>buf</code> and <code>num</code> arguments passed to <code>SSL_read</code>. It doesn't send the buffer to user-space though. Remember the data is decrypted <em>after</em> <code>SSL_read</code> returns, so we need a second uprobe that we attach to the <em>return address</em> of the function. That's what <code>SSL_read_ret</code> is for. It's similar to the other two probes, but is annotated with <a href="https://ingraind.org/api/redbpf_probes/uprobe/prelude/attr.uretprobe.html">#[uretprobe]</a>, which means that it will trigger once the function it's attached to <em>returns</em>.</p><p>But why do we need two probes for <code>SSL_read</code>, why not just have <code>SSL_read_ret</code>? The answer is that when <code>SSL_read</code> returns, it's likely that the registers that used to contain the function arguments were modified, so we need to read their values at the start of the function and store them so we can retrieve them later. This is a very common pattern when writing BPF code.</p><p>Finally if zoom linked to OpenSSL dynamically or if debugging symbols were present, the user-space code to attach the probes would be as simple as:</p><pre><code><span>use</span><span> </span><span>redbpf</span><span>::</span><span>load</span><span>::</span><span>Loader</span><span>;</span><span>
</span>
<span></span><span>let</span><span> </span><span>mut</span><span> loader </span><span>=</span><span> </span><span>Loader</span><span>::</span><span>load_file</span><span>(</span><span>COMPILED_BPF_BINARY</span><span>)</span><span>?</span><span>;</span><span>
</span><span></span><span>let</span><span> pid </span><span>=</span><span> </span><span>None</span><span>;</span><span>
</span><span></span><span>for</span><span> uprobe </span><span>in</span><span> loader</span><span>.</span><span>uprobes_mut</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Attach to SSL_read and SSL_write inside libssl.</span><span>
</span><span>    </span><span>// Let redbpf resolve the symbol addresses.</span><span>
</span><span>    </span><span>match</span><span> uprobe</span><span>.</span><span>name</span><span>(</span><span>)</span><span>.</span><span>as_str</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>"SSL_read_entry"</span><span> </span><span>|</span><span> </span><span>"SSL_read_ret"</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            uprobe</span><span>.</span><span>attach_uprobe</span><span>(</span><span>Some</span><span>(</span><span>"SSL_read"</span><span>)</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>"libssl"</span><span>,</span><span> pid</span><span>)</span><span>?</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        </span><span>"SSL_write_entry"</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
</span><span>            uprobe</span><span>.</span><span>attach_uprobe</span><span>(</span><span>Some</span><span>(</span><span>"SSL_write"</span><span>)</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>"libssl"</span><span>,</span><span> pid</span><span>)</span><span>?</span><span>;</span><span>
</span><span>        </span><span>}</span><span>
</span><span>        _ </span><span>=&gt;</span><span> </span><span>continue</span><span>,</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Unfortunately since OpenSSL is statically linked and the symbols have been stripped, redbpf can't automatically resolve the addresses of <code>SSL_read</code> and <code>SSL_write</code>, instead we have to explicitly provide the offsets we want to attach to:</p><pre><code><span>use</span><span> </span><span>redbpf</span><span>::</span><span>load</span><span>::</span><span>Loader</span><span>;</span><span>
</span>
<span></span><span>let</span><span> </span><span>mut</span><span> loader </span><span>=</span><span> </span><span>Loader</span><span>::</span><span>load_file</span><span>(</span><span>COMPILED_BPF_BINARY</span><span>)</span><span>?</span><span>;</span><span>
</span><span></span><span>let</span><span> pid </span><span>=</span><span> </span><span>None</span><span>;</span><span>
</span><span></span><span>for</span><span> uprobe </span><span>in</span><span> loader</span><span>.</span><span>uprobes_mut</span><span>(</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> zoom_binary </span><span>=</span><span> </span><span>"/opt/zoom/zoom"</span><span>;</span><span>
</span><span>    </span><span>// …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes">https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes</a></em></p>]]>
            </description>
            <link>https://confused.ai/posts/intercepting-zoom-tls-encryption-bpf-uprobes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24434031</guid>
            <pubDate>Thu, 10 Sep 2020 16:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Removing email registration improved retention]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 167 (<a href="https://news.ycombinator.com/item?id=24433090">thread link</a>) | @tapneal
<br/>
September 10, 2020 | https://solitaired.com/email-registration-is-dead | <a href="https://web.archive.org/web/*/https://solitaired.com/email-registration-is-dead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/coverimage.png"></center><p>
In our last business, where we ran popular educational products like EasyBib, we learned the power of email registration. When users registered we found that they would come back and use our service more, and eventually subscribe. </p>
<h2 id="firststeptoimproveretentionaddregistration">First step to improve retention: Add registration</h2>
<p>When building our <a href="https://solitaired.com/">solitaire site</a> then, a fun side hobby of ours, adding in email registration and account creation was immediately on our roadmap. When we added the ability to create accounts and track past scores, we immediately saw that our sessions per user increased by 5%. It was a solid win!</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/fivelift.png"></center>
<p>To encourage more registrations we introduced a leaderboard to see how you performed against other players. You could see how your time and number of moves compared to others who played the same game, and we encouraged sign ups to get your name on the leaderboard. This improved registrations by 22%, and we saw sessions per user increase another 3%. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/threelift.png"></center>
<p>All these features encouraged users to play more, compete against themselves and others, and return to the site.</p>
<h2 id="dosendingemailsmoveourkpis">Do sending emails move our KPIs?</h2>
<p>By now, we had learned that registration was a powerful feature in our game to drive loyalty and retention. Given that we were collecting emails as part of our standard registration process, we naturally thought emailing our user base, which had reached over 15,000 users, could naturally drive more return usage. </p>
<p>We started emailing our users to play a new game of the day feature we introduced. Open rates were a solid 17% on average, but click through rates to the game were 1%. This meant it drove about 26 more users to our site (15,000 * 17% * 1%). Moreover, these could have been users who would have gone back to Solitaired whether they read our email or not. </p>
<p>We saw a 0.5% improvement in returning users, but when we stopped sending emails, this didnâ€™t change suggesting the modest improvement was just noise.</p>
<h2 id="removingemailregistration">Removing email registration</h2>
<p>While registration, saving accounts, and leaderboards improved retention, sending emails clearly did not. </p>
<p>I was watching my sister play, who had become a solitaire addict after she QAing the game. She was obsessed with beating her personal bests and getting high scores for the game of the day. When I watched her play though, quizzically, she had not registered for an account. </p>
<p>I asked her why, she said she just didnâ€™t want to give her email away and get bombarded by more emails. I was dumbfounded, because after all, her brother (me), was the co-founder of the site and yet she still had these concerns.</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/sister.png"></center>
<p>The lightbulb went off. Since sending emails did not provide value, and if anything was an additional cost,  what if we just asked for a username. While this creates issues with password recovery, we thought this would drive up registrations and improve retention. We also have a long term cookie so users wouldnâ€™t have to login again. </p>
<p>When we changed email sign ups simply to usernames, we saw registrations increase by a huge 36%! More importantly, we saw return users increase another 4.5%.</p>
<p>This meant email registration was holding us back from driving retention. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/fourfivelift.png"></center>
<p>Digging in further, we're also seeing return visitors playing more games like <a href="https://solitaired.com/freecell">Freecell</a> and <a href="https://solitaired.com/spider">Spider</a>. Leaderboards and simple registration have encouraged users to try new games.</p>
<h2 id="weassumeemailisvaluable">We assume email is valuable</h2>
<p>Depending on your site and space, email surely can be valuable. For ecommerce sites, you can send targeted emails with special offers, for example. </p>
<p>Most of us assume email is beneficial to our businesses, and we rarely test to see if thatâ€™s the case. We have it because it gives us an owned channel to reach out and engage our users whenever we want. </p>
<p>However, we're forgetting a key fact: most of us also hate emails from commercial sites. They clog our inbox, and we instinctually either ignore or delete them. Every once in a while we might open one of those emails up, and even more rarely, we might click the call to action in the email. </p>
<p>Ask if requiring email addresses really moves important business metrics for your site. Sometimes they do. In our case, it just created a poor user experience which weâ€™re now happy to be rid of.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/email-registration-is-dead</link>
            <guid isPermaLink="false">hacker-news-small-sites-24433090</guid>
            <pubDate>Thu, 10 Sep 2020 15:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Clojure Spec is and what you can do with it]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24432461">thread link</a>) | @icey
<br/>
September 10, 2020 | https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/ | <a href="https://web.archive.org/web/*/https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.pixelated-noise.com/assets/images/people/stathis-sideris.jpeg"></p><div><p>Stathis Sideris</p><p>2020-09-10</p></div></div>
<p>
<i>Pixelated Noise is a software consultancy and we're always looking for interesting projects to help out with. If you have unmet software development needs, we would be happy <a href="https://www.pixelated-noise.com/contact/">to hear from you</a>.</i>
</p>

<p>
This is the blog version of a talk I gave on the 2017-12-13 at the Athens
Clojure Meetup, which was kindly hosted by <a href="https://engineering.skroutz.gr/">Skroutz</a>. <a href="https://www.youtube.com/watch?v=T1qpIaB6_vM">The video of the talk</a> is
available (the talk was given in Greek, but there are English subtitles). This
blog entry is not an exact transcript of the talk, I've added links and more
information where appropriate (plus the "bonus" sections that were not in the
talk). Since the talk was given a while ago, some information will be outdated.
</p>

<p>
There are essentially two parts to this article: the "what it is" part which
introduces the basic concepts and mechanisms of spec, and also provides some
information so that non-Clojurians can see how spec fits into the larger picture
and the "what you can do with it" part which explores some more interesting use
cases that go beyond basic usage.
</p>

<div id="outline-container-orge99096d">
<h2 id="orge99096d">What is it?</h2>
<div id="text-orge99096d">
<p>
Clojure is a dynamic language that doesn't enforce the types of parameters or
the return values of functions. This has been a characteristic of the language
that has drawn criticism both internally and from other language communities and
has possibly been a factor impeding adoption in the past.
</p>

<p>
Spec in a way is the response to that, but it's a response that maybe the
community didn't expect because it does not take the traditional approach of
checking types statically. At a very fundamental level spec is a declarative
language that describes data, their type, their shape. Spec follows the general
philosophy of Clojure in that all of its functionality is available at runtime,
you can use it, introspect it, generate it – there is no extra step before
execution when the compiler checks your whole codebase for errors.
</p>
</div>

<div id="outline-container-org56f06dc">
<h3 id="org56f06dc">What does it look like?</h3>
<div id="text-org56f06dc">
<p>
Spec is still alpha, so the namespace in the <code>require</code> contains <code>.alpha</code> to indicate
that. The following spec defines a <code>username</code> "entity" and says that it has to be
a string:
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::username</span> string?)
</pre>
</div>

<p>
<code>string?</code> is a simple function that exists in Clojure core, it's a
predicate function that you pass a string to and it returns <code>true</code> or
<code>false</code>, depending on whether the passed value is a string or not.
</p>

<p>
Once you've defined a spec the simplest usage of it is to ask whether
something is valid, by calling <code>valid?</code>, and passing the name of the
spec and then a value:
</p>

<div>
<pre>(println
 (<span>s</span>/valid? <span>::username</span> <span>"foo"</span>))
</pre>
</div>

<pre>true
</pre>
</div>
</div>

<div id="outline-container-orgfa7c72e">
<h3 id="orgfa7c72e">It's just predicates!</h3>
<div id="text-orgfa7c72e">
<p>
Many cases are covered by built-in predicates, but that doesn't mean
we can't use our own. If we need a spec that checks that a number is
above 5, we can simply write an anonymous function like this one,
and then use it normally as it if was a spec itself:
</p>



<pre>true
</pre>


<p>
And it works as expected with different inputs:
</p>



<pre>false
</pre>
</div>
</div>

<div id="outline-container-org6c5c14c">
<h3 id="org6c5c14c">Validate data</h3>
<div id="text-org6c5c14c">
<p>
So, we write a spec and it can validate our data. Let's draw this as a
diagram: the thing on the left that looks like a blueprint is a spec and the
curly braces on the right represents Clojure data (because very often data in
Clojure are maps and maps are written with curly braces). Read the weird arrow
in the middle as "validates":
</p>


<p><img src="https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/validate-data.png" alt="validate-data.png">
</p>

<p>
It's not much of a diagram, but I'm trying to establish the visual language
for the rest of this article.
</p>
</div>
</div>

<div id="outline-container-orgea7799a">
<h3 id="orgea7799a">Collections specs</h3>
<div id="text-orgea7799a">
<p>
Specs can also be applied to collections by composing and nesting
more basic specs together. Here we define an entity called <code>usernames</code>
made up of a collection of <code>username</code>:
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::usernames</span> (<span>s</span>/coll-of <span>::username</span>))

(println
 (<span>s</span>/valid? <span>::usernames</span> [<span>"foo"</span> <span>"bar"</span> <span>"baz"</span>]))
</pre>
</div>

<pre>true
</pre>


<p>
You would normally not define this as a separate entity for something that
simple, as <code>s/coll-of</code> can be used ad-hoc in your program.
</p>
</div>
</div>

<div id="outline-container-org81b3460">
<h3 id="org81b3460">Maps</h3>
<div id="text-org81b3460">
<p>
Maps are a bit more interesting. Other technologies such as <a href="https://github.com/plumatic/schema">plumatic
schema</a> (which at some point was the de facto way to validate data in
Clojure), ask you to define both the keys that have to be present in
a map and the data types of the values that correspond to the
keys. The resulting definition looks a bit like a rigidly-defined
class that you usually see in object-oriented languages. Spec very
deliberately moves away from this mentality: the maps are <b>not</b> like
objects, they are <b>not</b> fixed and do not necessarily exist in that one
shape. Instead, maps simply happen to be aggregations of some named
values.
</p>

<p>
This design decision is embodied in two ways:
</p>

<ul>
<li>A map spec written using <code>s/keys</code> which does not define the types of
the values of the map, we only define which existing entities make
up the map.</li>

<li>The name of the key inside the map has to be the same as the name
of the spec already defined elsewhere.</li>
</ul>

<p>
In this case we have defined some single-value specs like username,
password, last-login and comment, and they are aggregated together
in a map defined by the <code>::user</code> spec.
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(println <span>::username</span>)

(println
 (<span>s</span>/valid?
  <span>::user</span>
  {<span>::username</span>   <span>"rich"</span>
   <span>::password</span>   <span>"zegure"</span>
   <span>::comment</span>    <span>"this is a user"</span>
   <span>::last-login</span> 11000}))
</pre>
</div>

<pre>:my-project.users/username ;;this is what fully-qualified keywords look like
true
</pre>


<p>
Spec also encourages the use of qualified keywords: Until recently
in Clojure people would use keywords with a single colon but the two
colons (<code>::</code>) mean that keywords belong to this namespace, in this
case <code>my-project.users</code>. This is another deliberate choice, which is
about creating strong names (or "fully-qualified"), that belong to a
particular namespace, so that we can mix namespaces within the same
map. This means that we can have a map that comes from outside our
system and has its own namespace, and then we add more keys to this
map that belong to our own company's namespace without having to
worry about name clashes. This also helps with data provenance,
because you know that the <code>:subsystem-a/id</code> field is not simply an ID
– it's an ID that was assigned by subsystem-a.
</p>
</div>
</div>

<div id="outline-container-org3248f46">
<h3 id="org3248f46">Maps are open</h3>
<div id="text-org3248f46">
<p>
The other interesting thing about specs for maps is that they are
open. For example, if we use the same exact map as before, with the
same fields and an additional field called <code>::age</code>, it's still a valid
<code>::user</code>:
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(println
 (<span>s</span>/valid?
  <span>::user</span>
  {<span>::username</span>   <span>"rich"</span>
   <span>::password</span>   <span>"zegure"</span>
   <span>::comment</span>    <span>"this is a user"</span>
   <span>::last-login</span> 11000
   <span>::age</span>        26}))
</pre>
</div>

<pre>true
</pre>


<p>
This happens because spec does not mind if you've defined four keys, if it
sees a fifth key the map does not become invalid. The reason for this is that
when we have a system that accumulates information this accumulation should
not break the system, the code that consumes the map should simply ignore the
keys it doesn't know about. If you're making a system and you're accumulating
extra options, parameters, whatever it is – your code should be able to
continue to run without having to change a lot of code locations, like you
would have to do in an object oriented language or Haskell.
</p>

<p>
This accumulation has also been described by the term "accretion"
and has been discussed in the excellent <a href="https://www.youtube.com/watch?v=oyLBGkS5ICk">Spec-ulation Keynote talk</a> by
Rich Hickey.
</p>

<p>
On the other hand, a lot of people who use spec to validate things coming from
outside their system need to be more strict with maps, and they have
complained about the openness of maps. We'll talk about proposed solutions to
this issue later.
</p>
</div>
</div>

<div id="outline-container-org0b68930">
<h3 id="org0b68930">Explain your problems</h3>
<div id="text-org0b68930">
<p>
Another usage of specs, beyond validation, is "explain" which
essentially can produce errors that tell you what's wrong with your
data. In this case we'll try to create an error by creating a user
that's invalid because it doesn't have a password – a required key:
</p>

<div>
<pre>(<span>ns</span> <span>my-project.users</span>
  (<span>:require</span> [clojure.spec.alpha <span>:as</span> s]))

(<span>s</span>/<span>def</span> <span>::username</span> string?)
(<span>s</span>/<span>def</span> <span>::password</span> string?)

(<span>s</span>/<span>def</span> <span>::last-login</span> number?)
(<span>s</span>/<span>def</span> <span>::comment</span> string?)

(<span>s</span>/<span>def</span> <span>::user</span>
  (<span>s</span>/keys
   <span>:req</span> [<span>::username</span> <span>::password</span>]
   <span>:opt</span> [<span>::comment</span> <span>::last-login</span>]))

(<span>s</span>/explain
 <span>::user</span>
 {<span>::username</span>   <span>"rich"</span>
  <span>::comment</span>    <span>"this is a user"</span>})
</pre>
</div>

<p>
We get an ok-ish error that tells us that for the particular map we
passed, the <code>::user</code> spec fails because it doesn't contain <code>::password</code>.
</p>

<pre>val: #:my-project.users{:username "rich", :comment "this is a user"} fails spec: :my-project.users/user predicate: (contains? % :my-project.users/password)
</pre>
</div>
</div>

<div id="outline-container-orgb0d0b9f">
<h3 id="orgb0d0b9f">Sequence specs - regular expressions for data</h3>
<div id="text-orgb0d0b9f">
<p>
A powerful mechanism in spec is sequences. We've already seen <code>s/coll-of</code> which
contains a uniform type of values (a collection of numbers for example) but
sequences are a bit more like regular expressions for data. In this case we
have a sequence with two things, which describe an ingredient for a recipe:
the first thing is a number for the quantity and the second thing is a unit
encoded as a keyword.
</p>

<div>
<pre>(require '[clojure.spec.alpha <span>:as</span> s])

(<span>s</span>/<span>def</span> <span>::ingredient</span> (<span>s</span>/cat <span>:quantity</span> number? <span>:unit</span> keyword?))
</pre>
</div>

<p>
With <code>s/cat</code> we always have to give a name to each position. <code>s/cat</code>
allows to both validate the shape of the value passed, but it also
enables the "conform" operation, which is somehow similar to parsing
or destructuring. If we pass a vector of two elements – a number and
a keyword –  we get back a map with the defined names:
</p>

<div>
<pre>(prn (<span>s</span>/conform <span>::ingredient</span> [2 <span>:teaspoon</span>]))
</pre>
</div>

<pre>{:quantity 2, :unit :teaspoon}
</pre>


<p>
By using some of the other operators which are reminiscent of regular
expressions, this technique can become quite …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/">https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/</a></em></p>]]>
            </description>
            <link>https://www.pixelated-noise.com/blog/2020/09/10/what-spec-is/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24432461</guid>
            <pubDate>Thu, 10 Sep 2020 14:04:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rack Elevation Diagram Generator in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24431134">thread link</a>) | @wjholden
<br/>
September 10, 2020 | https://wjholden.com/rack | <a href="https://web.archive.org/web/*/https://wjholden.com/rack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wjholden.com/rack</link>
            <guid isPermaLink="false">hacker-news-small-sites-24431134</guid>
            <pubDate>Thu, 10 Sep 2020 11:13:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Germany is testing public hazard alerting(now)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24430275">thread link</a>) | @heredoc
<br/>
September 10, 2020 | https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html | <a href="https://web.archive.org/web/*/https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
<p>Am <strong>10. September 2020</strong> haben in ganz Deutschland Warn-Apps gepiept, Sirenen geheult, Rundfunkanstalten ihre Sendungen unterbrochen und Probewarnungen sind auf digitalen Werbetafeln erschienen. An diesem Tag fand der erste bundesweite Warntag seit der Wiedervereinigung statt. Ab diesem Jahr wird ein bundesweiter Warntag jährlich am <strong>zweiten Donnerstag im September</strong> stattfinden.</p><p>Zur Warnung der Bevölkerung nutzen Bund, Länder und Kommunen alle verfügbaren Kommunikationskanäle: so etwa das vom Bundesamt für Bevölkerungsschutz und Katastrophenhilfe (<abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr>) betriebene <a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/MoWaS/ModularesWarnsystem_node.html;jsessionid=F42B096B2C9D8208F71AB78662F45257.2_cid345" target="_blank" rel="noopener noreferrer" title="Modulares Warnsystem (Öffnet&nbsp;neues&nbsp;Fenster)">Modulare Warnsystem</a> und die <a href="https://www.bbk.bund.de/DE/NINA/Warn-App_NINA_node.html;jsessionid=F42B096B2C9D8208F71AB78662F45257.2_cid345" target="_blank" rel="noopener noreferrer" title="Warn-App NINA (Öffnet&nbsp;neues&nbsp;Fenster)">Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr></a>, eine Vielzahl von Medien und Rundfunksendern bis hin zu Sirenen und Lautsprecherdurchsagen vor Ort. </p>
<p><span><img src="https://www.bbk.bund.de/SharedDocs/Bilder/BBK/DE/Bilder_aktuelle_Meldungen/2020/Warntag_Graphik.jpg;jsessionid=F42B096B2C9D8208F71AB78662F45257.2_cid345?__blob=normal&amp;v=2" title="Warntag 2020 - eine graphische Darstellung" alt="Warntag 2020 - eine graphische Darstellung"></span>
</p>

<p>Mithilfe des Modularen Warnsystems wird eine Probewarnung an alle daran angeschlossenen Warnmultiplikatoren versendet. Warnmultiplikatoren sind ein Adressatenkreis, der Warnmeldungen weitergibt. Hierbei kann es sich <acronym title="zum Beispiel">z. B.</acronym> um einen Radio- oder Fernsehsender handeln, der seine laufende Sendung unterbricht und die Meldung verliest <abbr title="beziehungsweise">bzw.</abbr> einen Crawler (Lauftext) in die laufende Fernsehsendung einblendet, oder eine Leitstelle, die ihre Sirenen auslöst.</p>

<p>Diese Warnmultiplikatoren leiten die Probewarnung an die Endgeräte wie zum Beispiel Radios oder die Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr> und damit direkt an die Bürgerinnen und Bürger weiter. Zeitgleich werden auf Ebene der Länder, in den Landkreisen und in den Kommunen außerdem weitere verfügbare kommunale Warnmittel ausgelöst, zu denen beispielsweise Sirenen und Lautsprecherwagen zählen können. Auf denselben Wegen wird dann um 11.20 Uhr das allgemeine Signal zur Entwarnung erfolgen.</p>
<h3>Vom Sofa aus ins Bundesamt schauen</h3>

<p>Das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> hat im Bund die Aufgabe der Warnung der Bevölkerung vor den besonderen Gefahren eines Verteidigungsfalls und beteiligt sich ebenfalls am Warntag 2020. Wovor und wie das Amt dabei genau warnen kann, darüber hat das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> bereits vorab bei einem virtuellen Tag der offenen Tür informiert – und sich dabei den Bürgerinnen und Bürgern als zuständige Bundesoberbehörde gleich selbst vorgestellt.</p>

<p>In den folgenden drei Gesprächen erfahren Sie mehr über die Aufgabe der Warnung der Bevölkerung, die Warnapp <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr> und den bundesweiten Warntag. Die Videos sind auch in Deutsche Gebärdensprache übersetzt.</p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/mFlqBinNnuE" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/b3PzZOn40NE" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p><iframe width="448" height="252" src="https://www.youtube.com/embed/DHK6CQpkZv0" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen="1">Ihr Browser unterstützt iFrame nicht</iframe></p>

<p>Auf Grundlage eines Beschlusses der Innenministerkonferenz wird der bundesweite Warntag ab dem Jahr 2020 jährlich an jedem zweiten Donnerstag im September stattfinden. Er soll dazu beitragen, die Akzeptanz und das Wissen um die Warnung der Bevölkerung in Notlagen zu erhöhen und damit deren Selbstschutzfertigkeiten zu stärken. Die Wichtigkeit und Aktualität des Themas Warnung zeigt sich auch durch die Entwicklungen im Zusammenhang mit dem <a href="https://www.bbk.bund.de/DE/AktuellesundPresse/Informationen_zu_SARS-CoV-2/Corona_node.html;jsessionid=F42B096B2C9D8208F71AB78662F45257.2_cid345" target="_blank" rel="noopener noreferrer" title="Informationen zu SARS-CoV-2 (Öffnet&nbsp;neues&nbsp;Fenster)">Corona-Virus</a> in diesem Jahr. Zur Warnung und Information der Bevölkerung nutzen Bund, Länder und Kommunen die verfügbaren Kommunikationskanäle. So werden beispielsweise über das vom <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr> betriebene <a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/MoWaS/ModularesWarnsystem_node.html;jsessionid=F42B096B2C9D8208F71AB78662F45257.2_cid345" target="_blank" rel="noopener noreferrer" title="Modulares Warnsystem (Öffnet&nbsp;neues&nbsp;Fenster)">Modulare Warnsystem</a> und die <a href="https://www.bbk.bund.de/DE/NINA/Warn-App_NINA_node.html;jsessionid=F42B096B2C9D8208F71AB78662F45257.2_cid345" target="_blank" rel="noopener noreferrer" title="Warn-App NINA (Öffnet&nbsp;neues&nbsp;Fenster)">Warn-<abbr title="Applikation – Anwendungsprogramm">App</abbr> <abbr title="Notfall-Informations- und Nachrichten-App">NINA</abbr></a> Warnungen und Informationen der zuständigen Behörden, wie der Gesundheitsministerien des Bundes und der Länder, bereitgestellt. Bund und Länder bereiten den bundesweiten Warntag in Abstimmung mit kommunalen Vertretern gemeinsam vor. Zuständig sind auf Bundesebene das <abbr title="Bundesamt für Bevölkerungsschutz und Katastrophenhilfe">BBK</abbr>, auf der Ebene der Länder die jeweiligen Innenministerien und auf der Ebene der Kommunen in der Regel die für den Katastrophenschutz zuständigen Behörden.</p>

<p>Ausführliche Informationen zum bundesweiten Warntag stehen auf der Website <a href="https://warnung-der-bevoelkerung.de/" target="_blank" rel="noopener noreferrer" title="Externer Link&nbsp;Externer Link (Öffnet&nbsp;neues&nbsp;Fenster)">www.bundesweiter-warntag.de</a> zur Verfügung.</p>
<p><a href="https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html;jsessionid=F42B096B2C9D8208F71AB78662F45257.2_cid345#Start" title="Zum Seitenanfang">nach oben</a></p></div>
    </div></div>]]>
            </description>
            <link>https://www.bbk.bund.de/DE/AufgabenundAusstattung/Krisenmanagement/WarnungderBevoelkerung/Bundesweiter_Warntag/Bundesweiter_Warntag_node.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24430275</guid>
            <pubDate>Thu, 10 Sep 2020 08:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Weakness of Anthropic Arguments]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 75 (<a href="https://news.ycombinator.com/item?id=24429625">thread link</a>) | @srl
<br/>
September 9, 2020 | https://ineffectivetheory.com/weakness-anthropic-arguments/ | <a href="https://web.archive.org/web/*/https://ineffectivetheory.com/weakness-anthropic-arguments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><time datetime="2020-09-10">10 Sep 2020</time></header><p>Physicists are often bothered by the question “why do fundamental physical constants have the values they do?” Sometimes this concern can be answered by “well it had to take <em>some</em> value”, <a href="https://en.wikipedia.org/wiki/Fine-tuning">but not always</a>. Seeking explanations for patterns in what appear to be fundamental constants is a <a href="https://en.wikipedia.org/wiki/Periodic_table">historically</a> <a href="https://en.wikipedia.org/wiki/Eightfold_way_(physics)">successful</a> way to probe for the next undiscovered piece of physics.</p><p>The anthropic principle attempts to answer that sort of question. Crudely, an anthropic argument is one taking the form:</p><blockquote><p>The universe is the way it is because if it weren’t, we wouldn’t be here to discuss the issue.</p></blockquote><p>It shouldn’t surprise you to learn that most physicists are, at the very least, a little uncomfortable with this form of argument. The best pro-anthropic-argument summary I know of is frequently given by Nima Arkani-Hamed. Unfortunately I cannot find a video, so my own thoroughly inferior retelling will have to do:</p><blockquote><p>Suppose you walk into a room and see a table. On the table is a pencil, balanced perfectly on its tip. This is unlikely, to say the least. It needs explanation. The first thing to do is look for a string holding it up, or some glue on the tip, or the like. You check, and there’s no such mechanism. The next thing to do is look around — are there thousands of other pencils, lying normally on the table and the floor? If so, then the balancing pencil may reasonably be called coincidence. Alas, there are none.</p></blockquote><blockquote><p>There’s one last thing to do, to explain the magic pencil: look under the table. Is there a bomb, rigged to explode the moment the pencil falls over? Step outside: do you see the remains of thousands of detonated houses? If so, then it may be correct to say “the pencil was standing because, were it any other way, we would not have been in that room”.</p></blockquote><p>That last check is what an anthropic argument is all about. We can’t actually look for other rooms, destroyed by bombs (that would be called “the multiverse”), but we can at least try and look for the bomb.</p><p>The problem is, what qualifies as a bomb? The canonical example: if the cosmological constant were larger by a factor of say, $10^{100}$, the universe would have promptly blown itself apart. I wouldn’t be here to write this, you wouldn’t be here to read it. Surely we should not be surprised that the cosmological constant is not, in fact, so large.</p><p>Does that still make you uncomfortable? Perhaps it should. This type of argument is very slippery (like a slope). Thinking along the lines of the <a href="https://en.wikipedia.org/wiki/Butterfly_effect">butterfly effect</a>, it’s clear that even a one-part-in-$10^{10}$ change in the fine structure constant would build up dramatic differences in the evolution and course of life on Earth. In this universe, where $\alpha \approx 0.007297352569$, you’re reading an article about the anthropic principle; in the universe where $\alpha \approx 0.007297352570$, at the very least, it’s reasonable to guess that you would not be. (Good news: in that universe, you’re a billionaire playboy philanthropist!) Does this explain (to high precision) the value of the fine structure constant? After all, were the fine structure constant different by even $10^{-10}$, you would not be considering the question.</p><p>This has the basic structure of an anthropic argument, but there’s clearly something wrong with it. In that alternate universe, there are other people who <em>are</em> considering the question “why does $\alpha$ have that value?” The puzzle would still exist, even if you and I specifically have no interest.</p><p>Let’s consider, then, a universe where $\alpha$ is different by a full one part in a million. Chemical and nuclear physics don’t look substantially different, but again, the butterfly effect suggests that we should expect large differences in the situation on Earth. Suppose intelligent life exists on Earth, but not in anything remotely resembling human form. Now, it’s true that “there are no humans considering the question”. But again, there are <em>beings</em> on this planet considering the question. Shouldn’t that be enough?</p><p>Suppose $\alpha$ were different by one part in one hundred thousand. Now there’s no intelligent life on Earth at all — instead, intelligent life (tripedal, if you were wondering) evolves on Alpha Centauri! Questions of fine tuning are not considered anywhere in our solar system, but there are intelligent beings in the galaxy considering the question. It’s entirely accurate to say “were $\alpha$ different by one part in $10^5$, we would not be here to discuss these questions”, but <em>someone</em> would be <em>somewhere</em>, so that doesn’t seem like much of an explanation.</p><p>As far as I can tell, the best prototype for a good anthropic argument is:</p><blockquote><p>You have asked why proposition $P$ (which you find <em>a priori</em> surprising) should be true in our universe. You are able to ask this question in part because $P$ is true. Were $P$ false, you would not be able to ask such a question. In fact, were $P$ false, intelligent beings would not exist at all. Therefore, questions such as “why $P$” or “why not $P$” would never be expressed. Since questions like “what should be my prior probability of $P$” require $P$ to be true in order to be asked, the answer can only be “your prior should be near $1$”. Therefore $P$ is not, in fact, <em>a priori</em> surprising.</p></blockquote><p>The problem is, this anthropic principle is <em>extremely weak</em>. One proposed use of the anthropic principle is to <a href="https://doi.org/10.1111%2Fj.1749-6632.2001.tb02133.x">explain the fine structure constant</a>. Suppose the fine structure constant were in fact 10% different — enough to prevent stellar fusion from producing carbon. This would prevent carbon-based life from existing, sure; but would it prevent <em>intelligent</em> life from existing? Perhaps the question “why is $\alpha$ that particular value” could still be asked! It’s hard to know, without an unprecedentedly high-fidelity simulation of an alternate universe with $\alpha = 0.01$. That simulation isn’t coming soon.</p><p>The book <a href="https://en.wikipedia.org/wiki/Dragon%27s_Egg">Dragon’s Egg</a> is based around intelligent life living in the crust of a neutron star. The existence of such life certainly can’t be ruled out with our current understanding of the physics of dense matter. That’s a <em>very different</em> environment than our own; for starters, the strong surface gravity and magnetic field deform atoms by as much as a substantial change to the fine structure constant. If the anthropic principle can’t “explain why” we don’t live on the surface of a neutron star, then it certainly can’t account for a few percentage points in the fine structure constant.</p><p>This isn’t just yet another case of “we suck at creating efficient first-principles simulations”, either. One of the most famous stylized facts about <a href="https://mathworld.wolfram.com/CellularAutomaton.html">cellular automata</a> is that if you sneeze at them, they <a href="https://mathworld.wolfram.com/UniversalCellularAutomaton.html">become Turing-complete</a>. (This isn’t really a special fact about cellular automata, just a reflection of the fact that systems that support complex dynamics tend to also support universal computation.) A Turing-complete cellular automaton can simulate any classical process, and therefore displays phenomena like self-reproducing organisms. Moreover, a Turing-complete cellular automaton can support any intelligence exhibited by a computer. In principle (although of course this is too expensive to have been directly demonstrated) a cellular automaton like <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s</a>, beginning from a random position, ought to eventually evolve various levels of intelligence — intelligence is evolutionarily favorable in our world, and ought to be in others as well. So, shouldn’t such automata be capable of asking <em>the question</em>?</p><p>(In the case of Conway’s game, I guess <em>the question</em> is “why is the grid rectangular instead of hexagonal?")</p><p>The framework of modern fundamental physics is slightly more complicated than “it’s a cellular automaton” (this is <a href="https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/">only slightly controversial</a>), but the intuition gained from cellular automata is sticky: even large modifications to physical laws shouldn’t prevent intelligent structures from forming. This is the fundamental weakness of anthropic arguments. A properly formed anthropic argument should be based on an inability for intelligence to form, but intelligence is quite resilient. Almost any non-trivial universe can support intelligent life which will, inevitably, ask <em>the question</em>.</p><p>In a few cases, this issue may be circumvented: if the cosmological constant was too small/large, the universe would have collapsed/blown itself to smithereens before having a chance to develop anything resembling intelligence. This is largely independent of the other physical laws. That requirement is not strong enough to remove fine-tuning issues with the cosmological constant, and it certainly provides nothing resembling an explanation for the fine structure constant or any other part of the standard model.</p><p>I don’t think this weakness is repairable. Intelligent life is “existentially resilient”. The particular fundamental constants that describe the universe are unlikely to be the only ones that would allow someone to complain about fine-tuning and speculate about anthropic arguments.</p></article></div>]]>
            </description>
            <link>https://ineffectivetheory.com/weakness-anthropic-arguments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429625</guid>
            <pubDate>Thu, 10 Sep 2020 06:54:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Annoying website features I face as a blind person]]>
            </title>
            <description>
<![CDATA[
Score 439 | Comments 210 (<a href="https://news.ycombinator.com/item?id=24429012">thread link</a>) | @Garbage
<br/>
September 9, 2020 | https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/ | <a href="https://web.archive.org/web/*/https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>These are the five most annoying inaccessible web elements I face as a blind screen reader user every day, and how to fix them.
</span>
					</p><div>
						<p><span>For blind and visually impaired people like me, accessibility is the difference between us being able to use a website and clicking off it.&nbsp;</span></p>
<h2>How screen readers work</h2>
<p><span>Screen readers allow blind and visually impaired people to use computers, phones and tablets independently. Most screen readers use software, and a Text To Speech (TTS) engine, which is what converts the text from the screen reader into speech. Screen readers convert the text displayed on screen into a format that blind users can process.</span></p>
<p><span>Screen readers read out loud everything that’s on the screen and allow people to navigate using touch gestures and shortcut keys. They also work with other output devices such as a braille display.</span></p>
<p><span>As a screen reader user, here are the most common issues I encounter on a daily basis.&nbsp;</span></p>
<h2>Unlabelled links and buttons</h2>
<p><span>Screen reader users rely on links and buttons to navigate around a website and to find the information we need. If links and buttons are not labelled correctly or if at all, then it makes it difficult for screen reader users to find the information they need. Ultimately, unlabelled links make it much harder to navigate the website easily, quickly and independently.</span></p>
<p><span>For example, when linking to an about page, ‘click here’ doesn’t give any clue as to where it leads to, but ‘find out more about who we are’ is clear.</span></p>
<p><span>If links and buttons are labelled correctly, screen readers can read the label out loud. It means that blind and visually impaired people don’t have to press the link or button without knowing where it will take them.</span></p>
<p><span>As well as unlabelled elements, links and buttons that do not have a clear description are also really frustrating. They must have a clear description of where they will lead to when pressed, rather than ‘click here’. Never make your users guess where a link will take them or force them into a trial-and-error situation. This makes for tedious user experience.</span></p>
<h2>No image descriptions</h2>
<p><span>This is probably the most common issue I encounter when browsing the web.&nbsp;</span><span>Using image descriptions is essential for accessibility. Image descriptions are also known as alt text (alternative text) which is a written description of an image.</span></p>
<p><span>Screen readers read image descriptions out loud. This means that blind and visually impaired people can understand the content of the image in an accessible way.&nbsp;</span><span>If images do not have alt text, then screen readers will simply say “image” or “graphic” which gives no context or meaning.</span></p>
<p><span>Images often convey valuable information. It’s therefore important that people with a visual impairment can access this information as well.&nbsp;</span><span>Alt text should be clearly written and give an accurate description of the image.</span></p>
<p><strong>Check out <a href="https://bighack.org/how-to-write-better-alt-text-descriptions-for-accessibility/">our tips for writing better alt text</a> to ensure your images are fully accessible.</strong></p>
<h2>Poor use of headings</h2>
<p><span>For quick and easy navigation, many screen reader users navigate using various elements on the page such as headings. They are a great way to find the information we need quickly and effectively. Especially when they follow a logical heading structure with H1s, H2s and H3s helping to prioritise the content.</span></p>
<p><img src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" alt="Logical heading structure begins with Heading 1, with Heading 2 sitting beneath heading 1. Heading 3 sits within heading 2 and so on." width="1958" height="1236" srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" sizes="(max-width: 1958px) 100vw, 1958px" data-srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" data-src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>If websites don’t use headings, it means screen reader users are unable to use the keyboard shortcuts to navigate through the webpage this way. If that’s the case, we have to resort to tabbing or arrowing through a long web page to find the information we need.</span></p>
<p>Headings also help to break up the web content visually and improve readability. Other elements that screen reader users use to navigate webpages include links, lists or landmarks.</p>
<h2>Inaccessible web forms</h2>
<p><span>Most websites use forms in one way or another. Whether it’s to help you search for a product or to get in touch through a contact form. However, when these forms are not labelled, or not labelled correctly, it means we cannot use them.</span></p>
<p><span>For example, if a search box is not labelled, it means screen reader users have no idea of the purpose of that box. It means people who use screen readers cannot access the same functionality.</span></p>
<p><span>Contact forms are an effective way for customers to get in touch with your brand or business. And as a screen reader user, there’s nothing more frustrating than these forms being labelled incorrectly.</span></p>
<p><span>Especially CAPTCHA checkout requirements. Without an option to hear the audio, it’s not accessible. It means we are unable to fill in the form independently. I often have to enlist help from a sighted person, but this isn’t possible for everyone.</span><b>&nbsp;</b></p>
<h2>Auto-playing audio and video</h2>
<p><span>Most people will know how annoying it is to load a web page with noisy adverts that start playing suddenly. But for screen reader users, it can be even more alarming. When video or audio starts playing automatically, it can drown out the voice of the screen reader. This makes it harder to find the pause or stop buttons.</span></p>
<p><span>(And if these buttons are unlabelled, then it’s practically impossible for me to stop the video quickly which causes extra frustration.) If I’m unable to stop the sound or video, I normally click off.</span></p>
<p><span>The solution? Make sure there’s no auto-playing video or audio when your website loads. If you really want to use video, make sure the audio is muted and the user can pause, stop or hide the media player.</span></p>
<p><span>These issues may seem small to sighted users. But they’re the difference between me being able to use a website independently or not. And they make a huge difference when implemented correctly.</span></p>
					</div></div>]]>
            </description>
            <link>https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429012</guid>
            <pubDate>Thu, 10 Sep 2020 04:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rate of obsolescence of knowledge in software engineering]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24428810">thread link</a>) | @dgs_sgd
<br/>
September 9, 2020 | https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/ | <a href="https://web.archive.org/web/*/https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A physicist loses half the value of their physics knowledge in just four years whereas
an English professor would take over 25 years to lose half the value of the
knowledge they had at the beginning of their career [1]. These estimates are
taken form a paper written in 1982 so software engineers obviously weren’t
included. But it begs the question… What would the half-life of the value of a
software engineer’s knowledge be? I suspect it’s somewhere between the physicist’s
and the English professor’s because a software engineer’s knowledge is a combination
of eternal computer science/engineering principles and ephemeral technologies that
drift in and out of popularity over time.</p>

<h2 id="knowledge-that-doesnt-expire">Knowledge that doesn’t expire</h2>
<p>Software engineers with a traditional computer science background learn things
that never expire with age: data structures, algorithms, compilers,
distributed systems, etc. But most of us don’t work with these concepts
directly. Abstractions and frameworks are built on top of these well studied
ideas so we don’t have to get into the nitty-gritty details on the job
(at least most of the time). Examples are the C++ standard library which
implements optimized sorting for arrays, and Apache Spark which provides fault
tolerant cluster computing out of the box.</p>

<h2 id="knowledge-that-does-expire">Knowledge that does expire</h2>
<p>The unavoidable ephemeral knowledge one accumulates during their career comes in
many forms and this isn’t an exhaustive list:</p>

<ol>
  <li>A vogue framework or programming paradigm that falls out of favor in a couple of years.</li>
  <li>Domain knowledge in a rapidly evolving industry/field.</li>
  <li>Knowledge of proprietry technology: e.g. internal tools at your company.</li>
</ol>

<p>Knowledge of this kind can quickly transition from zealous adoption to every company who
uses said knowledge trying to sunset everything they’ve built with it.</p>

<h2 id="my-experience">My Experience</h2>
<p>I’m inclined to say I use ephemeral knowledge more than eternal knowledge to perform
my job. And then there’s the added pressure in our industry of always having to learn
new and useful things.</p>

<p>A theoretical physicist who spends a great deal of time mastering a theory and
the mathematical techniques behind it, only to see that theory rendered obsolete
by a new and improved theory several years later, is analogous to a software
engineer who spends a great deal of time mastering a web development framework,
learning its intricacies and gotcha’s, only to see that framework rendered
obsolete by a new framework several years later, leaving no more demand for
that knowledge in the labor market.</p>

<p>I relate to the physicist more than the English professor. What do you think?</p>



<p>[1] McDowell, John M. “Obsolescence of Knowledge and Career Publication Profiles: Some Evidence of Differences among Fields in Costs of Interrupted Careers.” The American Economic Review, vol. 72, no. 4, 1982, pp. 752–768. JSTOR, www.jstor.org/stable/1810015. Accessed 9 Sept. 2020.</p>

  </div></div>]]>
            </description>
            <link>https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428810</guid>
            <pubDate>Thu, 10 Sep 2020 04:10:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interfacing Microcontrollers with SD Card]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24428745">thread link</a>) | @peter_d_sherman
<br/>
September 9, 2020 | https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/ | <a href="https://web.archive.org/web/*/https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img height="1" width="1" src="https://www.facebook.com/tr?id=720372835040462&amp;ev=PageView&amp;noscript=1">    <meta name="generator" content="WordPress Download Manager 3.0.4">
<a href="#content">Skip to content</a><div id="boxed-wrapper"><div id="wrapper"><header></header><main id="main"><div><section id="content"><article id="post-2339"><div><p>The secure digital card (SD) is a low cost, non-volatile memory card format developed by the SD Card Association. Since its inception back at the start of the century, the demand for this medium-sized, energy and space-efficient, the memory storage device has been growing at a fast rate. Therefore, to meet the market requirements, the SDA was set up as a non-profit organization to promote and create SD Card standards. There are various topics related to the SD card such as the different device families, speed classes, smart cards, card security and so on and it is used in various markets like digital cameras, personal computers, and embedded systems. Some of the standard variations include SD, SDHC, SDXC, SD-ultra high speed etc. The microSD is the miniaturized SD memory card format with a small form factor and is widely used in various electronic devices.<br>
What we are going to learn is the use of SD cards in an embedded system. To be specific, we will be dealing with the use of SD cards in small embedded systems.</p><h2>Circuit&nbsp;and Interfacing</h2><p>SD card has a native host interface apart from the SPI mode for communicating with master devices. The native interface uses four lines for data transfer where the microcontroller has SD card controller module and it needs separate license to use it. Since the SPI is a widely used protocol and it is available in most low-cost microcontrollers, the SPI mode is the widely used interface in low cost embedded systems. The working voltage range of SD family is 2.7V to 3.6V and this is indicated in the operation condition register (OCR).</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/2000px-SD_Pins.svg_-1.png" alt="2000px-sd_pins-svg" width="214" height="292"></p><div id="attachment_2345"><img aria-describedby="caption-attachment-2345" src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card.png" alt="sd-card" width="371" height="229" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-200x124.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-300x185.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-400x247.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-600x371.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-768x475.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-800x495.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card.png 1024w" sizes="(max-width: 371px) 100vw, 371px"><p id="caption-attachment-2345">SD Card pinout</p></div><div id="attachment_2347"><img aria-describedby="caption-attachment-2347" src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2.png" alt="sd-card-2" width="381" height="213" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-200x112.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-300x168.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-400x223.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-600x335.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-768x429.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2-800x447.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-2.png 1024w" sizes="(max-width: 381px) 100vw, 381px"><p id="caption-attachment-2347">MicroSD Card pinout</p></div><p>Most micro-controllers use the SPI communication protocol to interface with the SD cards. The SD cards have a microcontroller that shows their availability to the master controller(microcontroller). The micro-controller sees the SD card as an addressable sector on which read/write functions are possible. Once the microcontroller is in the SPI mode, communication between the master and the slave is done via 4 pins viz. clock, chip select, data in and data out. It should be kept in mind that throughout the communication between the two devices, the micro-controller will be sending out the clock.<br>
Most development boards have a dedicated SD card slot. But to understand the connections, let us analyze this fairly simple circuit.</p><div id="openl-839501388"><div data-animationoffset="100%"><div><div data-link="https://openlabpro.com/online-courses/pic-microcontroller/" data-link-target="_self" data-animationoffset="100%"><div>From the very basic I/O control to the advaced SD Card interfacing, this course covers what you need to get started in Embedded Systems.<div><div><iframe src="https://player.vimeo.com/video/362065141?autoplay=0&amp;autopause=0" width="600" height="360" allowfullscreen="" title="vimeo362065141" allow="autoplay; fullscreen"></iframe></div></div></div><a href="https://openlabpro.com/online-courses/pic-microcontroller/" target="_self">Learn more about the course</a></div></div></div></div><h3>Circuit</h3><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit.png" alt="sd-card-circuit" width="506" height="284" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-200x113.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-300x169.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-400x225.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-600x338.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-768x432.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-800x450.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-1024x576.png 1024w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-1200x675.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit.png 1280w" sizes="(max-width: 506px) 100vw, 506px"></p><p>If the logic level of the microcontroller is different than the SD card, level shifter needs to be used for converting the line voltages.<br>
The MISO (master in serial out) pin should be connected to the SDI (serial data in) pin on the microcontroller.<br>
The MOSI (master out serial in) pin should be connected to the SDO (serial data out) pin on the microcontroller.<br>
The SCK (serial clock) pin should be connected to the SCK (serial clock) pin on the microcontroller.<br>
The CS (chip select) pin should be connected to the corresponding CS pin on the microcontroller or on any digital I/O pin on the microcontroller. A common ground is provided.</p><p><b>IMPORTANT NOTE</b>: While connecting the power supply, make sure that the supply is drawn from a 3.3V supply as a 5V supply would see your card go up in smoke.</p><h3>Interfacing</h3><p>Once the connections are set up, we are ready to interface our hardware with the software.<br>
Set the directions of each of the four pins correctly. While activating the SPI mode, an ideal configuration should be, mode(0,0) and the phase with input sampled at the middle of data out. Also, the clock frequency should be set in the range of 100 kHz and 400 kHz prior to initializing the card. Once the initialization is done, the clock can be set to a more desired frequency.</p><h2>SD Commands</h2><p>Next comes the tricky part, initializing the SD card and performing the raw data communication. A systematic approach to programming the software would make the task pretty easy.<br>
But first, it is important to learn how the micro-controller activates the SD card. There are a fixed set of commands and responses, which must be followed to create a command to response structure in our program. The data is transmitted in a byte-oriented format with a definite length.<br>
The following table shows the necessary<b> commands</b> to the card and the corresponding response from the card.</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3.png" alt="sd-card-3" width="507" height="1118" srcset="https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-136x300.png 136w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-200x441.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-400x882.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-464x1024.png 464w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-600x1323.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-768x1694.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-800x1765.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3-1200x2647.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/SD-card-3.png 1274w" sizes="(max-width: 507px) 100vw, 507px"></p><p>Every command has a constant length of 6 bytes.<br>
The first byte is the addition of the command number and the number 64.<br>
<b>Example</b>:<br>
For CMD0: command number 0 + 64 = 64 = 0x40 in hexadecimal.<br>
For CMD1: command number 1 + 64 = 65 = 0x41 in hexadecimal.<br>
And so on.<br>
This is followed by a set of four bytes which are known as the arguments. These arguments usually contain the address of a data or the length of a block.<br>
The last byte is the CRC (Cyclic Redundancy Check) Byte. Most commands in the SPI mode does not require a check byte if the CRC feature isn’t enabled. For some commands like CMD0, the CRC is 0x95 and in most cases, a 0xFF is sent. Enabling the CRC requires you to send the correct check byte from the micro-controller. So, ensure whether the CRC feature is enabled or disabled.<br>
A <b>command frame</b> looks like this-</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-800x267.png" alt="Interfacing Microcontrollers with SD Card - Command frame" width="800" height="267" srcset="https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-200x67.png 200w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-300x100.png 300w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-400x133.png 400w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-600x200.png 600w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-768x256.png 768w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-800x267.png 800w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-1024x342.png 1024w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-1200x400.png 1200w, https://openlabpro.com/wp-content/uploads/2016/12/Clr_frame1.png 1280w" sizes="(max-width: 800px) 100vw, 800px"></p><p>The card will receive a command when the DO pin (Data Out) is driven high as shown above. The CS pin (Chip Select) must be driven high to low before sending the command and must be kept low during the process. The time between a command and its response is known as the command response time (NCR). As mentioned earlier, regarding the clock pulses from the micro-controller, the corresponding response byte sent back from the card to the microcontroller should be driven by the serial clock pulses of the micro-controller. There is a chance that the response byte from the card might get skipped by the microcontroller due to the absence of a driving clock pulse. Hence it is necessary to make sure that an 8-Bit clock pulse is sent to the Card soon after the Command Frame is sent (Refer the <b>TECHNICAL NOTE </b>below). Also while receiving a Byte from the card, the DI pin (Data In) must be driven high.</p><p>Furthermore, let us analyze the different<b> types of responses</b> that we get from the card and what they mean.</p><p><img src="https://openlabpro.com/wp-content/uploads/2016/12/Response_Color-1.jpg" alt="response_color" width="568" height="289"></p><p>An R1 response, 0x01 means that the command sent prior to the response has resulted in the card going into an idle state.<br>
A response byte 0x00 means that the command has been accepted and the card will be waiting for the proposed event to take place. If any other bits in an R1 response is set, it is the result of an error and it’ll be down to the factor mentioned in each R1 response bit in the figure.</p><h2>Initializing&nbsp;the SD Card</h2><p>Now, as far as sending the commands are concerned, there is an order in which they must be sent. Only the commands, CMD0, CMD1, ACMD41, CMD58 and CMD59 will be accepted when the card is in its idle state. Sending any other command will likely to yield an illegal response.</p><p><b>TECHNICAL NOTE</b>: After interfacing the card, the micro-controller must always send a set of bytes, which we will refer to as dummy bytes. One dummy byte is 0xFF. These dummy bytes have a simple yet significant purpose. Prior to the initialization, the card must know the frequency at which the data is being sent. By sending around 75 dummy bits approximately (dummy byte * 10 times = 80 bits), the card will be ready for communication. Also even after every command is sent, it is a good practice to send at least one dummy byte. A logical explanation for this is that communication is driven by the clock pulse of the micro-controller. The clock pulse is sent only when the data buffer is filled. After every response is sent and prior to the next command or between command and response, the SCK will stop generating pulses due to an empty data buffer. To ensure the continual transmission of clock pulses between every command, fill the data buffer with a junk value such as a dummy byte. To create a dummy byte function with the number of loops as the argument.</p><p>The<b> first command</b> to be sent to the card is the <b>CMD0</b> command. The structure of every other command-response should be based on this model.</p><ul><li>Drive the DO pin high.</li><li>Drive the CS pin from high to low.</li><li>Send a dummy byte.</li><li>Then send the following 6-byte command continuously<br>
First byte: 0x40<br>
Next four bytes: 0x00000000<br>
CRC byte: 0x95</li></ul><ul><li>Send another dummy byte or as many as required, to generate the SCK giving time for the SD card to respond to the command request.</li><li>Wait for the receive flag bit to set and then read the response from the SD card or create a loop to read the response a few number of times. The response should reach back within the command to response (Ncr) time. Or else, something must be wrong.</li></ul><ul><li>The desired response is 0x01, meaning the card is in the idle state and we are good to go.</li></ul><p>Send the <b>CMD8</b> command next to check the version of your SD card.<br>
The difference in the 6-byte commands are<br>
First byte: 0x48<br>
Next four bytes: 0x000001AA<br>
CRC byte: 0x87</p><p>We are looking for two possibilities in our response byte. Either 0x01 or 0x05.</p><p>A 0x01 response means that you have a version 2 SD card. The 0x01 response is followed by the 4 bytes 0x00, 0x00, 0x01, 0xAA in the order of their transmission from the SD card which is, in fact, the argument you send in your command.</p><p>If the response is 0x05, it means the card is a version 1 or an MMC card. If the card is actually a version 2 SD card, then this response is the result of an illegal command. Also, the card is now in the idle state.</p><p>Once the above two commands (CMD0 and CMD8) are done, it is safe to say that our SD Card is working in good condition and ready for data Read/Write.<br>
Additionally, just to ensure whether the SD Card is functioning in the correct working voltage, send the <b>CMD58</b> Command.</p><p>Next, we must initiate the i<b>nitialization</b> process. For this send a <b>CMD1</b> command and wait for response 0x00, meaning the idle state bit is cleared.<br>
If you are using an SDC or for the purpose of creating a general code, it is …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/">https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/</a></em></p>]]>
            </description>
            <link>https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428745</guid>
            <pubDate>Thu, 10 Sep 2020 03:55:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On moving away from a six figure consultancy to becoming an indie hacker]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24428473">thread link</a>) | @jv22222
<br/>
September 9, 2020 | https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker | <a href="https://web.archive.org/web/*/https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428473</guid>
            <pubDate>Thu, 10 Sep 2020 02:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signs Your Team Is Suffering from 'Burnout Debt']]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24427973">thread link</a>) | @doorknobguy
<br/>
September 9, 2020 | https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><blockquote>One of my key goals this month is to make sure we're not burning ourselves out. We've got a lot of priorities but there's no need to stretch ourselves thin and run the risk of longer-term issues.<p>- Jean Vincent (CTO, Lytehouse)</p></blockquote><p>‍</p><p>Unhealthy working patterns can build up over time and create longer-term issues. </p><p>In this article, we'll be showing you signs of burnout debt - and how to recognize it before it's too late.</p><p>‍</p><h3>What is 'Burnout Debt'</h3><p>Symptoms of burnout can slowly grow on a team. As sprints go on it's easy to overlook the signs that build up over time. We refer to this build up as 'burnout debt'.</p><p>You should treat burnout debt in the same way we treat technical debt. Identify it early and take measures to reduce longer-term negative effects.</p><p>‍</p><h3>Signs of 'Burnout Debt'</h3><ol role="list"><li>Unhealthy Working Patterns</li><li>High Workloads</li><li>Spikes in Weekend Activity</li></ol><p>‍</p><h3>Sign #1: &nbsp;Unhealthy Working Patterns</h3><p>One key factor in burnout is overwork. It's important we help our teams manage their workloads and reduce burnout. If your team feels the need to work late nights and weekends - it's time to have a conversation about workloads.</p><p>This team for example consistently works late nights and weekends. This is a strong signal that your team is overworking and may approach burnout. We'll see the effect of this below.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cd3ba2ac780cf72cc15_unsustainable-working-patterns.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Sign #2: Unusually High Workloads</h3><p>Spikes in workload can be early warning signs of burnout.</p><p>The team below was under tight deadlines - working nights and weekends. You can a large spike in Throughput followed by immediate burnout which lasted ~3 months.</p><p>This is a typical situation. We take on too much work and burn out. The following weeks remain unproductive. As leaders it's our job to make sure our teams have a more sustainable, manageable workload.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cecff346bf77d54af02_unusually-high-workload.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Sign #3: Spikes in Weekend Activity</h3><p>Large spikes in weekend activity can be an incredibly high signal for overworked. Are your current tasks too much to handle in a week? Did we poorly estimate that workload? Is the workload unmanageable?</p><p>As engineering leaders we have to protect our team from situations like that which can cause long term effects to team morale, culture, and overall productivity. As we saw in the image above, the effects of burnout can be long lasting and in some cases can lead to the highest cost for an engineering team - turnover.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593d086702304230624666_high-weekend-activity.png" loading="lazy" alt=""></p></figure><p>‍</p><h3>Is your team accumulating 'burnout debt'?</h3><p>Just like technical debt, burnout debt silently builds up in the background. As it accumulates it not only gets harder to resolve but it's impact becomes more severe.</p><p>When left unchecked 'burnout debt' impacts team culture, creates an environment of overwork, and degrades trust among the team. At an individual level it decreases satisfaction, happiness, and productivity while boiling up to team-wide frustration, low morale, and high turnover.</p><p>So.. Is your team affected by burnout debt?</p><p>‍</p><h3>What should I do about it?</h3><p>It’s important to identify these signs early so you can intervene. Luckily, there are ways to identify and resolve burnout debt.</p><p>‍</p><h5>Make it a ritual</h5><p>The first step is having conversations around workload and sustainability. Make it a recurring ritual. At Haystack we bring this up every week. We're constantly adjusting workloads and introducing new, challenging work - to combat burnout.</p><p>‍</p><h5>Get data-driven</h5><p>As engineers, we often feel productive (and happy) when we're pushing new features. There's a certain rush to grabbing a coffee, throwing on some headphones, and getting that #todo closed out - even if it takes staying up late to do it.</p><p>Unfortunately, this makes it difficult to see or address burnout debt. In the moment, we feel great about the work we did - unknowingly allowing burnout debt to build over time. What feels great now build up in the background and soon enough you'll start feeling burnt out.</p><p>In this case, having data helps quite a bit. Being able to see trends and alert on them helps us catch burnout debt before it's too late. It also gives us a more objective picture on what our typical workload looks like so we can make sure to keep it in check.</p><p>‍</p><h3>Stop taking on 'Burnout Debt'</h3><p>If you're managing a team and you want them to be motivated, happy, and productive then burnout should be a key item to address. Just like technical debt, burnout debt can eat at teams and cause an undertone of frustration. It's not always easy to catch but if you're looking in the right direction you'll be able to spot the signs and address it before it's too late.</p><p>Of course, Haystack can help too. If you'd like to see your team's typical bandwidth, working patterns or if they are experiencing signs of burnout debt <a href="https://usehaystack.io/">sign up for Haystack</a>.</p><p>‍</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5123c19bb423a1492c778d_Haystack_Designed_Presentation.png" loading="lazy" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Haystack</a> helps engineering leaders identify burnout and team health patterns. Instead of guessing if you're improving, or constantly bothering your team for updates, simply use Haystack to get alerts in your inbox every morning. Plus a dashboard to track improvements over time.</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Try it for free</a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/3-signs-your-team-is-suffering-from-burnout-debt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24427973</guid>
            <pubDate>Thu, 10 Sep 2020 01:30:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The amazing $1 microcontroller (2017)]]>
            </title>
            <description>
<![CDATA[
Score 326 | Comments 176 (<a href="https://news.ycombinator.com/item?id=24426882">thread link</a>) | @appwiz
<br/>
September 9, 2020 | https://jaycarlson.net/microcontrollers/ | <a href="https://web.archive.org/web/*/https://jaycarlson.net/microcontrollers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h4>Silcon Labs EFM8: Fantastic value and ease-of-use from the only 8-bit part with a totally-free cross-platform vendor ecosystem</h4><p>The <a href="https://jaycarlson.net/pf/silicon-labs-efm8/">EFM8</a> was the fastest 8-bit part in my round-up, and admittedly, my favorite 8-bit architecture to develop with overall. What these parts lack in brains they make up for in brawns — 14-bit ADCs, 12-bit DACs, lots of timers, and a 72 MHz core clock speed that gives you timing options not found in any other part in the round-up.</p><p>Plus, this is the only 8-bit part with a totally-free, cross-platform, vendor-provided ecosystem. Let that sink in.</p><p>Keil C51 is a silly compiler, but Silicon Labs does an excellent job hiding it under the hood — even when running its Eclipse-based Simplicity Studio on Linux or macOS.</p><p>Simplicity Configurator is the lightest-weight code generator in our round-up, using only 534 bytes of flash to house the entire DMX-512 receiver project. It was one of the easiest to use, and seemed to strike a good balance between abstraction, performance, and ease of use.</p><p>Debugging speeds are snappy with a J-Link debugger, but at $35, the official Silicon Labs USB Debug Adapter is one of the cheapest first-party debugger in the round-up, and clones of the hardware are even cheaper.</p><p>And call me old-fashioned, but I think the 8051 definitely has a place in 2017 — especially among hobbyists and students, where its bit-addressable memory, easy-to-use peripherals, and fuse-free configuration help get students comfortable with microcontrollers quickly.</p><h4>Microchip megaAVR &amp; tinyAVR 1-Series: Different strokes for different folks — still with the best 8-bit toolchain available</h4><p>The <a href="https://jaycarlson.net/pf/atmel-microchip-megaavr/">megaAVR</a> came in surprisingly flat for me: especially when compared with its lower-cost, new sibling, the <a href="https://jaycarlson.net/pf/atmel-microchip-tinyavr-1-series/">tinyAVR 1-Series</a>.</p><p>There’s no comparison when it comes to price: tinyAVR has incredible value — packing in a nice assortment of timers, analog peripherals (including a DAC), and a new 20 MHz internal oscillator — while costing 20-40% less than the megaAVR.</p><p>While the megaAVR has a perplexing debugging experience that requires two completely different interfaces and protocols to work with the part, the new one-wire UPDI interface the tinyAVR sports worked flawlessly in my testing.</p><p>But that’s the crux of the problem for the tinyAVR — by shedding many of its megaAVR roots, Microchip ended up with a wonderful microcontroller that will be challenging to use for a large base of Atmel fans: indie developers and hobbyists who use low-cost, open-source programmers (which don’t support the UPDI interface).</p><p>While the tinyAVR wasn’t the fastest part in the round-up (even among 8-bitters), it was the most efficient – both in terms of active-mode power and clock efficiency. Amazingly, the AVR only uses about twice as many instructions as 16- and 32-bit parts when performing 16-bit math.</p><p>Unfortunately, the AVR system as a whole is not without its issues. The Windows-only Atmel Studio is still buggy (especially with older megaAVR devices and AVR Dragon stuff in my tests), and there isn’t an under-$50 low-cost debugger available (other than hacking apart Xplained Mini dev boards).</p><p>In many ways, there seems to be a tacit demarcation Atmel creates between its hobbyist/indie developers, and the professional shops that use Atmel parts.</p><p>As a professional embedded developer, I most definitely have access to Windows computers, and I have no problem blowing a few billable hours’ worth of pay on a $140 debugger.</p><p>But even as popular as Atmel is among hobbyists, Atmel has largely stayed out of this space directly. Instead, they’ve secured small-volume AVR sales by relying on the open-source community to build their own tools for themselves: turning out a slew of hardware and software used to program the megaAVR devices.</p><p>While I applaud the efforts of these developers, these tools are inferior to Atmel’s. Their programming speeds are terrible, they don’t support the new tinyAVR 1-Series devices, and they have absolutely no debug capability.</p><p>Having said that, both the megaAVR and tinyAVR have the best toolchain available for 8-bit MCU development. The part supports a full, end-to-end Makefile-based GCC toolchain.</p><p>If you love printf() debugging, would never touch a proprietary toolchain, and hate IDEs, megaAVR and old tinyAVR parts are definitely for you. The older ones are still available in DIP packages, and as you probably know, there are a ton of low-cost programmers available across the world. The online community is massive, and as clunky as I find Atmel START to be, I have to applaud its support for Makefile-based project generation.</p><p>Consequently, the megaAVR remains the most open-source 8-bit microcontroller on the market — by a long shot.</p><p>But I’d really like to see Microchip provide a PicKit-priced debugger with UPDI support — and allow off-board debugging the way their PIC Curiosity Boards do.</p><p>I also hope these open-source projects can add UPDI support to their tools, so that hobbyists and indie developers can start integrating the tinyAVR into their projects — it’s a much better part, and if you’re an AVR user with access to Atmel Studio, you really ought to buy an Xplained Mini board and take it for a spin.</p><h4>STM32F0: A low-cost, no-nonsense part with arguably the best Arm development ecosystem tested</h4><p><a href="https://jaycarlson.net/pf/st-stm32f0/">The STM32F0</a> was the lowest-power Arm microcontroller in the round-up, and also one of the easiest to use. STM32CubeMX doesn’t generate the most compact code on Arm (that honor belongs to Cypress PSoC Creator and Infineon DAVE), but it has a snappy interface, and the generated code is easy enough to manipulate for your own goals.</p><p>I love the nearly-stock Eclipse-based environment that System Workbench for STM32 provides, and the ST-Link and excellent Discovery/Nucleo boards seals the deal for me.</p><p>Most pros have used ST parts in their work, but for all these reasons, any hobbyist looking at moving to Arm should probably pick up a dev board from this ecosystem, too. ST has a huge market footprint, so there’s tons of resources online — aimed at both hobbyists and professionals.</p><h4>SAM D10: Killer performance &amp; peripherals, but with runtime library hiccups</h4><p>The Microchip/Atmel <a href="https://jaycarlson.net/pf/atmel-microchip-sam-d10/">SAM D10</a> (and the broader D11/D20/D21 ecosystem) has good value (considering their analog portfolio includes a DAC, and they have good timing options), and the SAM D10 was the most efficient part tested when running at full speed.</p><p>Professionals will like the easy-to-use, well-documented header files, and hobbyists will appreciate the 1.27mm-pitch SOIC package options and GCC compilers that come with the Arm ecosystem. But before I grab this part for a project, Microchip really needs to fix the extremely slow, bloated peripheral library, and update their code-gen tool to do proper error-checking of clock and peripheral configurations.</p><p>As it is, whenever I use Atmel START on the D10, I want to STOP almost immediately. And there are no current, stand-alone peripheral drivers that Microchip has released for this part, so unless you want to do register programming from scratch, you’ll be relying on third-party, open-source projects — like Alex Taradov’s <a href="https://github.com/ataradov/mcu-starter-projects">code examples</a>.</p><h4>Infineon XMC1100: Interesting peripheral perks make this Cortex-M0 stand out</h4><p>The most interesting Arm chip was, without a doubt, the <a href="https://jaycarlson.net/pf/infineon-xmc1100/">Infineon XMC1100</a> — and I think professionals who may be wary of getting out of the ST/NXP/Atmel Arm ecosystem need to take a second look at these XMC1000 (and XMC4000) parts.</p><p>The timer options are amazingly flexible, and you can squeeze fantastic performance out of the USIC module.</p><p>I’m going to go out on a limb and recommend that serious hobbyists who are building motor / lighting control projects look into these parts, too. DAVE makes setting up these complex peripherals painless, and the 38-pin TSSOP chips will be substantially easier to solder than the 0.5mm QFNs and QFPs you usually end up with in these pin counts.</p><p>Like many of the parts reviewed here, the biggest problem for hobbyists and indie developers is the tiny online communities and lack of GitHub repos with open-source projects that use these chips. My advice — be bold, and post in the forums. Infineon employees monitor and usually respond within a day or so.</p><h4>PIC16: Tons of peripherals with a slower, power-efficient core</h4><p>When you compare the <a href="https://jaycarlson.net/pf/microchip-pic16-five-digit-enhanced/">PIC16</a> with other 8-bit parts out there, it’s obviously a part built for low-power applications, and not processing power. And while the development ecosystem is workable, there are other parts more friendlier pathways — especially for smaller shops, hobbyists, and students who need extremely low-cost tools (and free software).</p><p>To add fuel to the PIC-vs-AVR debate, my testing found that a 32 MHz PIC16 is roughly equivalent to an AVR part running at 1.4 MHz (in terms of math performance), and 9 MHz (in terms of bit-shuffling performance).</p><p>Having said that, the DMX-512 receiver seems a perfect match for the PIC16, and that’s where it looks best in my testing: the PIC16 was the lowest-power 8-bit part in my testing.</p><p>It’s also full of timers and digital logic-oriented peripherals that make it suitable for funky special-purpose projects that require some crafty use of configurable logic and and the numerically-controlled oscillator — these peripherals help offload the (relatively slow) CPU, at the expense of requiring more developer familiarity with the device and these peripherals.</p><p>The usual Microchip gotchas apply: clunky IDE, expensive compilers, and expensive debuggers.</p><p>The usual Microchip advantages apply: huge online community, seemingly infinite product lifetime guarantees, and DIP, SOIC, QFP, and QFN package availability.</p><h4>PIC24: An expensive MSP430 wannabe that doesn’t hit the mark</h4><p>The <a href="https://jaycarlson.net/pf/microchip-pic24/">PIC24</a> is nearly forgettable. In the biquad test, it’s marginally faster than the <a href="https://jaycarlson.net/pf/renesas-rl-78/">Renesas RL-78</a> but uses almost three times as much power. In the DMX-512 test, both the RL-78 and MSP430 beat it, too. It was also one of the least-endowed parts in the round-up (which really just means it’s expensive — higher-end PIC24 parts have no shortage …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jaycarlson.net/microcontrollers/">https://jaycarlson.net/microcontrollers/</a></em></p>]]>
            </description>
            <link>https://jaycarlson.net/microcontrollers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24426882</guid>
            <pubDate>Wed, 09 Sep 2020 22:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Much Time Is Spent at Traffic Signals?]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24426023">thread link</a>) | @sharkweek
<br/>
September 9, 2020 | https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/ | <a href="https://web.archive.org/web/*/https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-24122">
	<!-- .entry-header -->

	<div>
		<figure data-shortcode="caption" id="attachment_26070" aria-describedby="caption-attachment-26070"><img loading="lazy" data-attachment-id="26070" data-permalink="https://transportist.org/books-2/books/the-30-minute-city-designing-for-access/the30-minutecity-cover-print/" data-orig-file="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg" data-orig-size="2694,3434" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1577200438&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="The30-MinuteCity-Cover-Print" data-image-description="<p>The 30-Minute City by David M. Levinson</p>
" data-medium-file="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=471" data-large-file="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=764" src="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=300&amp;h=383" alt="The 30-Minute City by David M. Levinson" width="300" height="383" srcset="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=300&amp;h=383 300w, https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=600&amp;h=766 600w, https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=118&amp;h=150 118w, https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=471&amp;h=600 471w" sizes="(max-width: 300px) 100vw, 300px"><figcaption id="caption-attachment-26070"><a href="https://transportist.org/books/the-30-minute-city-designing-for-access/">The 30-Minute City</a> by David M. Levinson&nbsp;</figcaption></figure>
<p>While working on another piece, I came upon the question of how much time is spent at traffic lights, for which there is not a well-sourced answer. I posted to Twitter and got some useful replies.</p>
<blockquote>
<p dir="ltr" lang="en">Transport Twitter: What percent of total travel time is spent stopped at traffic lights? Empirical results please.</p>
<p>— David M. Levinson (@trnsprtst) <a href="https://twitter.com/trnsprtst/status/967547973788827648?ref_src=twsrc%5Etfw">February 24, 2018</a></p></blockquote>
<p>With that and some additional digging, I attempt to answer the question.</p>
<p>As the saying goes: Your Mileage May Vary. This depends on your origin and destination and path and mode and time of day and local traffic signal policies and street design. <a href="https://twitter.com/tvanvuren">Tom VanVuren</a> notes: “Much of the impact is in slow moving queues, rather than waiting for the signal cycle to complete. I expect you can make this number smaller than 10% (time at the stop line) or larger than 50% (time affected by traffic lights).” For simplicity, I am considering vehicles that would be stopped if they could either move at the desired speed or must stop (i.e. they are subject to “vertical” or “stacking” queues), but clearly measurement will depend on assumption. Still, there must be a system average. I had heard the number 20% bandied about, which feels right, but let’s first begin with some thought experiment, then look for some empirical results. We take different modes in turn.</p>
<figure data-shortcode="caption" id="attachment_24089" aria-describedby="caption-attachment-24089"><a href="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg"><img loading="lazy" data-attachment-id="24089" data-permalink="https://transportist.org/2018/02/14/the-ambiguous-hump/img_0230/" data-orig-file="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg" data-orig-size="4032,3024" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1518165138&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;25&quot;,&quot;shutter_speed&quot;:&quot;0.00090991810737034&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Free left" data-image-description="<p>A signalized but porkchop-islanded crosswalk at a Free Left (Free Right for those in the right-side drive countries). Notice the pedestrian light is red (don’t walk) but the pedestrians cross anyway. If the free left is not eliminated in a more comprehensive redesign, it could easily be de-signaled and the crosswalk raised, so pedestrians dominate, and cars travel when they can.</p>
" data-medium-file="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=600" data-large-file="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=764" src="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=300&amp;h=225&amp;crop=1" alt="A signalized but porkchop-islanded crosswalk at a Free Left (Free Right for those in the right-side drive countries). Notice the pedestrian light is red (don't walk) but the pedestrians cross anyway. If the free left is not eliminated in a more comprehensive redesign, it could easily be de-signaled and the crosswalk raised, so pedestrians dominate, and cars travel when they can." width="300" height="225" srcset="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=300&amp;h=225&amp;crop=1 300w, https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=600&amp;h=450&amp;crop=1 600w, https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=150&amp;h=113&amp;crop=1 150w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-24089">Pedestrian Crossing at Broadway and City Road, Sydney. Pedestrians crossing against the light.</figcaption></figure>

<h2><strong>Thought Experiments</strong></h2>
<h3><strong>Thought Experiment&nbsp;</strong><strong>1 A</strong></h3>
<p>Imagine an urban grid.</p>
<ul>
<li>Assume 10 signalized intersections per km.</li>
<li>Assume a travel speed of 60 km/h when in motion. (This is probably too high with so many intersections and no platooning, but we are imagining here that you would not be stopping.)</li>
<li>Time to traverse 1 km=1 minute + signal delay. &nbsp;(Some of the distance traversal time overlaps some of the signal delay time, but we will imagine a stacking queue, rather than one that has physical distance for simplicity, we can correct this later if it matters.)</li>
<li>Assume each intersection has only 2 phases.</li>
<li>Assume fixed time signals at each intersection evenly distributing green time between N/S and E/W directions. &nbsp;So&nbsp;red time = 1/2 cycle length.</li>
<li>Assume 1 minute cycle length</li>
<li>If a vehicle stops, it waits 1/2 red time.</li>
<li>Vehicles obey traffic signals.</li>
<li>Assume no platooning.</li>
</ul>
<p><em>This means that the average vehicle will&nbsp;stop at 5 intersections for 15 seconds each = 75 seconds (or 1.25 &nbsp;minutes) (vs. 1 &nbsp;minute in motion time). In this case, 1.25/2.25 minutes (55.5%) is spent waiting at signals.</em></p>
<h3><strong>Thought Experiment 1 B</strong></h3>
<p>In contrast.</p>
<ul>
<li>Assume near perfect platooning.</li>
</ul>
<p>In this case, the vehicle will stop at 1 intersection per km, for 15 seconds = 15 seconds. In this case 0.25/1.25 = 20% of the time is spent waiting at signals.</p>
<h3><strong>Discussion</strong></h3>
<p>Now, not all travel takes place on an urban grid.</p>
<ul>
<li>Assume 25% of travel is on limited access roads (this is approximately true in the US), &nbsp;75% on non-limited access roads.</li>
</ul>
<p>With perfect platooning on the grid, and 25% off-grid, then 15% of travel time is intersection delay with near perfect platooning.</p>
<p>Clearly in practice platooning is far from perfect. My guess is the green wave breaks down after one or two intersections during peak times, but can survive well in the off-peak. As a rule of thumb, about ~10% of travel is in the peak hour, ~30% peak period. ~60% AM + PM Peak.</p>
<h2>Data</h2>
<h3>GPS Studies</h3>
<p>Eric Fischer of MapBox was kind enough to offer to run this question on their open traffic data. The results are not yet in. I will update when they are.</p>
<h3>Arterial Travel Time Studies</h3>
<p>There are a variety of Arterial Travel Time studies for specific corridors, but nothing that is universally generalizable. &nbsp;(And logically where people do arterial travel time studies, there is a congestion problem, otherwise why study it.)</p>
<p>I recall that in my childhood,<a href="https://conservancy.umn.edu/handle/11299/179862"> I did a study in Montgomery County, Maryland</a>&nbsp;using such data (from 1987 traffic counts and a floating car study published by Douglas and Douglas), I did not actually compute the percentage, but fortunately I reported enough data that allows me to compute the percentage now. (The sample is of course biased to what is measured). For the average arterial link, the speed was</p>
<div class="page" title="Page 24">
<table>
<tbody>
<tr>
<td>&nbsp;<strong>Variable</strong></td>
<td><strong>Inside the Beltway</strong></td>
<td><strong>&nbsp;Outside the Beltway</strong></td>
</tr>
<tr>
<td>&nbsp;Speed (km/h)</td>
<td>34.88</td>
<td>&nbsp;41.60</td>
</tr>
<tr>
<td>&nbsp;Length (km)</td>
<td>&nbsp;0.46</td>
<td>&nbsp;0.72</td>
</tr>
<tr>
<td>&nbsp;Time (min)</td>
<td>&nbsp;0.792</td>
<td>&nbsp;1.04</td>
</tr>
<tr>
<td>&nbsp;Downstream Delay (min)</td>
<td>&nbsp;0.27</td>
<td>&nbsp;0.24</td>
</tr>
<tr>
<td>&nbsp;Percentage of Signal Delay</td>
<td>&nbsp;25%</td>
<td>&nbsp;18.75%</td>
</tr>
</tbody>
</table>
<p>Which is consistent with expectations that signals are more significant in more urbanized areas (inside the beltway is basically Bethesda and Silver Spring, MD), and with our general estimates. Now of course the speed here is impacted by downstream signals, and so is lower than the speed limit and certainly lower than the free-flow speed sans-signals. More details are in the paper.</p>
<ul>
<li>Levinson, David (1998)&nbsp;<a href="http://hdl.handle.net/11299/179862">Speed and Delay on Signalized Arterials</a>.&nbsp;<em>ASCE Journal of Transportation Engineering</em>&nbsp;124(3) 258-264. [<a href="http://dx.doi.org/doi:10.1061/(ASCE)0733-947X(1998)124:3(258)">doi</a>]</li>
</ul>
</div>
<h3>Engine Idling Studies</h3>
<p>Moaz Ahmed pointed me to a<a href="https://tc.gc.ca/eng/policy/annual-2014-3141.html"> Vehicle Idling Study</a> by <a href="http://www.nrcan.gc.ca/energy/efficiency/communities-infrastructure/transportation/cars-light-trucks/idling/4415">Natural Resources Canada</a>.</p>
<p>The percent of time of vehicle idling ranged from 20-25%. (Not all vehicle idling is at signalized intersections).</p>
<p>(Engine idling of course burns fuel without doing work, so if the engine is going to be idling for an extended period, it would save fuel (and reduce air pollution) to turn it off. Turning the engine on and off also has costs, so the estimate was if idling was going to be longer than 10 seconds, it uses more fuel, but considering other wear and tear costs, the recommended threshold is if idling is longer than 60 seconds, then turn off the engine. &nbsp;But at a signalized intersection, how will vehicles know how long they will wait? Smart traffic signals with connected vehicles could provide this, but now they don’t. Eventually this will be moot with a full electric vehicle fleet. Until that time, it matters. I suspect given the longevity and sluggishness of the traffic control sector, smart signals informing trucks will not be widely or systematically deployed before trucks are electrified.)</p>

<p>Now as noted above, Your Mileage May Vary. If you are a pedestrian, you are unlikely to hit a greenwave designed for cars, though of course your travel speed is slower is well. So redoing the Thought Experiment</p>
<h2><strong>Thought Experiment 2</strong></h2>
<p>Imagine an urban grid.</p>
<ul>
<li>Assume 10 signalized intersections per km.</li>
<li>Assume a travel speed of 6 km/h when in motion. (this is a bit on the high side, average pedestrian speed is closer to <a href="https://westernite.org/datacollectionfund/2005/psu_ped_summary.pdf">5 km/h</a>)</li>
<li>Time to traverse 1 km=10 minutes + signal delay. &nbsp;(Some of the distance traversal time overlaps some of the signal delay time, but we will imagine a vertical stacking queue, rather than one that has physical distance for simplicity, this is a much better assumption for pedestrians than vehicles.)</li>
<li>Assume each intersection has only 2 phases.</li>
<li>Assume fixed time signals at each intersection evenly distributing green time between N/S and E/W directions. &nbsp;So&nbsp;red time = 1/2 cycle length.</li>
<li>Assume 1 minute cycle length</li>
<li>If a pedestrian stops, she waits 1/2 red time. (That is the “walk” phase for pedestrians is as long as the green phase for cars. Strictly speaking this is not true, it is more true in cities with narrow streets than it is in suburban environments with wide streets, as narrow streets can be crossed more quickly, so the amount of “walk” time allocated can be most of the phase. This is certainly not true in Sydney, where the “walk” phase is cut short so turning cars have fewer conflicts with late pedestrians.)</li>
<li>Pedestrians obey traffic lights. &nbsp;(This is not as good an assumption as vehicles obey signals, pedestrian signal violation is probably higher. This is not a moral judgment one way or the other, people tend to obey authority, even when <a href="https://en.wikipedia.org/wiki/Milgram_experiment">authority abuses power</a>.)</li>
<li>Assume no platooning. (This is probably too severe, a quick pedestrian with some signal coordination can probably make a couple of lights in a row).</li>
</ul>
<p>Here the average pedestrian will&nbsp;stop at 5 intersections for 15 seconds each = 2.5 minutes (vs. 10 &nbsp;minute in-motion time). In this case, 2.5/(2.5+10) minutes (or 20%) is spent waiting at signals. Now, this number is probably true for more pedestrians than the vehicle delay estimate is for vehicles, since pedestrians are more likely to be found on an urban grid and less in a suburban or limited access environment. (Self-selection at work).</p>

<p>If you are a bicyclist, you are unlikely to hit a greenwave designed for cars unless you travel at exactly an integer fraction (1/1, 1/2, 1/3) of the green wave, as your travel speed is slower is well. So redoing the Thought Experiment</p>
<h2><strong>Thought Experiment 3</strong></h2>
<p>Imagine an urban grid.</p>
<ul>
<li>Assume 10 signalized intersections per km.</li>
<li>Assume a travel speed of &nbsp;20 km/h when in motion. (This is a typical for <a href="http://www.road-bike.co.uk/articles/average-speed.php">experienced riders</a>).&nbsp;Time to traverse 1 km=3 minutes + signal delay. (Assume a stacking queue)</li>
<li>Assume each intersection has only 2 phases.</li>
<li>Assume fixed time signals at each intersection evenly distributing green time between N/S and E/W directions. &nbsp;So&nbsp;red time = 1/2 cycle length.</li>
<li>Assume 1 minute cycle length</li>
<li>If a bicyclist stops, she waits 1/2 red time. (That is the ‘bike’ phase for bicyclists is as long as the green phase for cars.)</li>
<li>Bicyclists obey traffic lights. &nbsp;(This is not as good an assumption as ‘motor vehicles obey signals’, bicyclists signal violation is probably higher.)</li>
<li>Assume no platooning. (This is probably too severe, a quick bicyclists with some signal coordination can probably make a couple of lights in a row).</li>
</ul>
<p>In this case the average bicyclists will&nbsp;stop at 5 intersections for 15 seconds each = 2.5 minutes (vs. 3 &nbsp;minute in-motion time). In this case, 2.5/(3+2.5) minutes (or 45%) is spent waiting at signals in an urban environment.</p>
<h2>Strava Data</h2>
<p>Strava, an app for tracking bicyclists and runners can produce some useful data. <a href="https://twitter.com/dr_hsu">Andrew Hsu</a>, e.g., <a href="https://www.strava.com/athletes/16556#interval_type?chart_type=hours&amp;interval_type=week&amp;interval=201807&amp;year_offset=0">reports</a>&nbsp;“28 mile bike commute. 1:30-ish moving time. 10-15 minutes waiting at lights.” From this, for him, we estimate 15 / (15+90) = 14%. To be clear, 1:30 is an extreme commute. I don’t have access to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/">https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/</a></em></p>]]>
            </description>
            <link>https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24426023</guid>
            <pubDate>Wed, 09 Sep 2020 21:19:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git/serve: A Git server for Plan 9]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24425114">thread link</a>) | @ori_b
<br/>
September 9, 2020 | https://orib.dev/gitserve.html | <a href="https://web.archive.org/web/*/https://orib.dev/gitserve.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>A while ago, I released <a href="https://orib.dev/git9.html">git9</a>, a git client for
Plan 9. However, it always felt like it was missing something: A git server.
over a few weekends of work, I sat down and put one together. This Labor
Day weekend, I took the opportunity to labor on it, and got something working.</p>

<h3>usage</h3>

<p><code>Git/serve</code> is a git server designed to fit into the Plan
9 ecosystem, allowing hosting of, and interacting with, code on a Plan 9
server, while still allowing legacy clients running on Unix to get a copy
of the code.</p>

<p><code>Git/serve</code> only speaks the <code>git://</code> protocol.
But because it runs behind
<a href="http://man.9front.org/8/listen">aux/listen</a>
and 
<a href="http://man.9front.org/8/tlssrv"><code>tlssrv</code></a>, we
effectively get two additional protocols for free: <code>gits://</code>, or
TLS-encrypted <code>git://</code>, and <code>hjgit://</code>, which is
<code>git://</code> but with Plan 9 authentication to support user login
over TLS. Unfortunately, only the unencrypted <code>git://</code> protocol
is supported out of the box by upstream git. There may be ways to solve
this, using <a href="https://rovaughn.github.io/2015-2-9.html">custom
transports</a>, and a unix port of tlsclient</p>

<p>To start a <code>git://</code> server, just run it under aux/listen1.
To enable encryption and user authentication, run it under
<code>tlssrv -a</code>. This doesn't need a certificate, because
the Plan 9 authentication generates the secret used for TLS. And,
finally, if you just want encryption, you can use <code>tlsclient</code>
with a certificate.</p>

<pre># git:// server, serving every repository under the current directory
% aux/listen1 'tcp!*!9418' git/serve -r `{pwd}

# gits:// server, doing the same: But with encryption.
% aux/listen1 'tcp!*!9418' tlsclient -c /path/to/cert.pem git/serve -r `{pwd}

# hjgit:// server doing the same: Requires account on server to connect
% aux/listen1 'tcp!*!9418' tlsclient -a git/serve -r `{pwd}
</pre>

<p>If you want to allow people to write, you can just add the
<code>-w</code> flag to git/serve. While you can do this on
any of the protocols, keep in mind that only <code>hjgit://</code>
authenticates the users. Push to the world, but don't let the
world push to you!</p>



<p>All the protocols git uses are closely related. The <code>ssh://</code>
protocol is just the <code>git://</code> protocol, with the command selected
sightly differently. The smart <code>http://</code> protocols are the same
as the <code>git://</code> protocol, with a different handshake, and split
over multiple post requests.</p>

<p>Git9 implements the git protocol in under 500 lines of C. The
full code is available on github, in
<a href="https://github.com/oridb/git9/blob/24abe6c00b6f65e7241763399fc72c043b7d9bbf/serve.c">serve.c</a>.
</p>

<p>The protocol look something like this for pushing:</p>

<pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
=r=&gt; 0086:	"747e9e80f710c0b8bbd928080745915ad2493322 HEAD\n"
=r=&gt; 009d:	"747e9e80f710c0b8bbd928080745915ad2493322 refs/heads/master\n"
&lt;=w= 0076:	"747e9e80f710c0b8bbd928080745915ad2493322 dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\0report-status\n"
&lt;=w= 0000
&lt;=w= <pack-data>
=r=&gt; 000e:	unpack ok
=r=&gt; 0019:	ok refs/heads/master
</pack-data></pre>

<p>And this for pulling:</p>

<pre>&lt;=w= 0030:	"git-upload-pack /oridb/git9\0host=github.com\n"
=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
<pack-data>
</pack-data></pre>

<p>The git protocol consists of pkt-lines, which are strings with a
hex-formatted length prefix.  The length prefix includes itself.  So,
the string <code>"hi"</code> would be formatted as
<code>0006hi</code>. A zero lenth packet where the length prefix
is not included is special. This is called a 'flush packet', and
is used to terminate a phase of negotiation.</p>

<p> All negotiation is with these packet lines, at
which git flips over to pure binary mode to transfer a pack file
over.</p>

<p>In the <code>git://</code> protocol, the client always starts off
by saying which action it wants to do: Either it wants the server to
fetch a pack from the client, or it wants the server to upload a pack
to the client.  That's this line:</p><pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
</pre>

<p>The upload side of this protocol is simpler on the server side so
we'll go through it first.</p>

<h3>pushing</h3>

<p>In the upload protocol, the server begins by sending a list of
references that the client may update. In <code>git/serve</code>
we grab all the refs in the repository, and filter down to just
the ones beginning with <code>heads/</code>.</p>

<pre>	if((nrefs = listrefs(&amp;refs, &amp;names)) == -1)
		sysfatal("listrefs: %r");
	for(i = 0; i &lt; nrefs; i++){
		if(strncmp(names[i], "heads/", strlen("heads/")) != 0)
			continue;
		if(fmtpkt(c, "%H refs/%s\n", refs[i], names[i]) == -1)
			goto error;
	}
	if(flushpkt(c) == -1)
		goto error;
</pre>

<p>With the first phase of the protocol, the client then
sends the list of references it wants to update. This
takes the form of:</p>

<pre>	OLDHASH NEWHASH heads/refs/updateme\n"
</pre>

<p>Because the client knows what the reference versions are on
the server, it can compute what commits are between the version
on the server and the version that it has. If the new hash
is the zero hash, this signals to the server that the reference
should be deleted. This list of updates is terminated with a
flush packet. The code in git9 that handles this is below:

</p><pre>	while(1){
		/* Did we get a packet? */
		if((n = readpkt(c, pkt, sizeof(pkt))) == -1)
			goto error;
		/* Was it a flush packet? */
		if(n == 0)
			break;
		/* Split it up into the 3 parts: old, new, reference */
		if(getfields(pkt, sp, nelem(sp), 1, " \t\n\r") != 3){
			fmtpkt(c, "ERR  protocol garble %s\n", pkt);
			goto error;
		}
		/* verify that these are valid hashes */
		if(hparse(&amp;old, sp[0]) == -1){
			fmtpkt(c, "ERR bad old hash %s\n", sp[0]);
			goto error;
		}
		if(hparse(&amp;new, sp[1]) == -1){
			fmtpkt(c, "ERR bad new hash %s\n", sp[1]);
			goto error;
		}
		/* and valid refs */
		if(!validref(sp[2])){
			fmtpkt(c, "ERR invalid ref %s\n", sp[2]);
			goto error;
		}
		/* and then remember them for when we do the update */
		*cur = erealloc(*cur, (*nupd + 1)*sizeof(Hash));
		*upd = erealloc(*upd, (*nupd + 1)*sizeof(Hash));
		*ref = erealloc(*ref, (*nupd + 1)*sizeof(Hash));
		(*cur)[*nupd] = old;
		(*upd)[*nupd] = new;
		(*ref)[*nupd] = estrdup(sp[2]);
		*nupd += 1;
	}
</pre>

<p>Next, the client uploads the pack. This is a blob containing
the commit data. It goes into <code>.git/objects/packs/recv-$pid.pack</code>,
at least until we can index it and rename it.</p>

<pre>	while(1){
		n = read(c-&gt;rfd, buf, sizeof(buf));
		if(n == 0)
			break;
		if(n == -1 || write(pfd, buf, n) != n)
			return -1;
		packsz += n;
	}
	if(checkhash(pfd, packsz, &amp;h) == -1){
		dprint(1, "hash mismatch\n");
		goto error1;
	}
	if(indexpack(packtmp, idxtmp, h) == -1){
		dprint(1, "indexing failed\n");
		goto error1;
	}
	if(rename(packtmp, idxtmp, h) == -1){
		dprint(1, "rename failed: %r\n");
		goto error2;
	}
</pre>

<p>Finally, we update the references. Note that we haven't
locked the repository yet. This is because none of the data
we have here can conflict: All objects are addressed by hash,
so a race would simply leave us with a duplicate hash in the
packfile. Eventually, a <code>git/repack</code> will clean
that up.</p>

<p>However, updating the references can conflict. So,
for updating the references, we acquire a lock file.
We then read all the references, make sure that they
match the old reference, and then write in the new
reference.</p>

<pre>	for(i = 0; i &lt; nupd; i++){
		if(resolveref(&amp;h, ref[i]) == 0 &amp;&amp; !hasheq(&amp;h, &amp;cur[i])){
			fmtpkt(c, "ERR old ref changed: %s", ref[i]);
			goto error;
		}
		if((o = readobject(upd[i])) == nil){
			fmtpkt(c, "ERR update to nonexistent hash %H", upd[i]);
			goto error;
		}
		if(o-&gt;type != GCommit){
			fmtpkt(c, "ERR not commit: %H", upd[i]);
			goto error;
		}
		unref(o);
		if(snprint(refpath, sizeof(refpath), ".git/%s", ref[i]) == sizeof(refpath)){
			fmtpkt(c, "ERR ref path too long: %s", ref[i]);
			goto error;
		}
		if((fd = create(refpath, OWRITE, 0644)) == -1){
			fmtpkt(c, "ERR open ref: %r");
			goto error;
		}
		if(fprint(fd, "%H", upd[i]) == -1){
			close(fd);
			fmtpkt(c, "ERR upate ref: %r");
			goto error;
		}
		close(fd);
	}
</pre>

<p>And that's pushing.

</p><h3>pulling</h3>

<p>Pulling takes more work on the server side, because the
server needs to compute a reasonable packfile to send to
the client. The protocol itself is still fairly simple.</p>

<p>It begins the same way as pushing, by sending all the
branches that a client may want to obtain from the git
repository.</p>

<pre>=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
</pre>

<p>The client then starts telling us what commits they want,
and what commits they have. This lets us find a graph difference
between the server and client graph, and generate a pack file
that contains few, if any, extraneous commits. </p>

<pre>&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
</pre>

<p>Computing the commits that go into a pack is not always trivial.
The comits that the client may be on may have "bubbles" in the graph,
so simply walking back from the start of the graph to the commits
that the client has may end up walking around the commit, leading
to nearly the whole history of the repository being sent, instead
of just one or two commits.</p>

<p>Consider a repo where the server is ahead of the client, and
now the client is trying to pull the changes. The client has commits
<code>c</code>, and we're trying to compute a pack with only the
commits <code>o</code>.</p>


<pre>                o---o
               /     \
    --c---c---c---c---o---o &lt;-- server
                  ^
                client
</pre>

<p>The client does a git/pull, and sends that it has the
commit marked <code>[c]</code>. Since the server has
every commit the client does, and more, it can look at
all ancestors of the client commit. If we're smart, we
would, but a naive …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orib.dev/gitserve.html">https://orib.dev/gitserve.html</a></em></p>]]>
            </description>
            <link>https://orib.dev/gitserve.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24425114</guid>
            <pubDate>Wed, 09 Sep 2020 19:47:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dolt, a SQL database with Git-like functionality, implements push and pull]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24424593">thread link</a>) | @reltuk
<br/>
September 9, 2020 | https://www.dolthub.com/blog/2020-09-09-push-pull-on-a-merkle-dag/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-09-09-push-pull-on-a-merkle-dag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p><a href="https://www.github.com/liquidata-inc/dolt">Dolt</a> is a SQL database
with Git-like functionality, including branch, merge and diff and push
and pull to remotes. This is a post in a series of posts about the
internal workings of some of the core algorithms that underly Dolt's
implementation. The previous posts in this series were about:</p>
<ol>
<li><a href="https://www.dolthub.com/blog/2020-04-01-how-dolt-stores-table-data/">The Prolly-tree</a>,
a unique content-address indexed data structure that underlies Dolt's table storage.</li>
<li><a href="https://www.dolthub.com/blog/2020-05-13-dolt-commit-graph-and-structural-sharing/">The Commit Graph</a>
and structural sharing in Dolt's table storage.</li>
<li><a href="https://www.dolthub.com/blog/2020-06-16-efficient-diff-on-prolly-trees/">Dolt's Diff Implementation</a></li>
<li><a href="https://www.dolthub.com/blog/2020-07-15-three-way-merge/">Dolt's Merge Implementation</a></li>
</ol>
<p>In this post, we explore the Merkle DAG structure underlying Dolt's
commit graph and table storage a little more, and investigate how push
and pull to remote repositories is implemented in Dolt.</p>
<h2>Overview</h2>
<p>A Dolt repository contains any number of branches and tags, where each
branch or tag is a top-level reference to a particular commit. A
commit, in turn, points to a value of the database at that commit, and
0 or more parent commits. All data in the repository, the commits and
the table data, is stored in content-addressed <code>Chunk</code>s which in turn
can contain references to other <code>Chunk</code>s, forming a <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle
DAG</a>. This was the example
of a three commit branch from our previous blog post on the commit
graph:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/4597d/dolt-commit-graph.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Dolt Commit Graph" title="Dolt Commit Graph" src="https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/4597d/dolt-commit-graph.png" srcset="https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/a48b3/dolt-commit-graph.png 214w,
https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/47730/dolt-commit-graph.png 428w,
https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/4597d/dolt-commit-graph.png 631w" sizes="(max-width: 631px) 100vw, 631px" loading="lazy">
  </a>
    </span></p>
<p>And this was the example of how the data in a single table might be
broken down:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/4ee7f/dolt-table-value.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Dolt Table Value" title="Dolt Table Value" src="https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/4ee7f/dolt-table-value.png" srcset="https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/a48b3/dolt-table-value.png 214w,
https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/47730/dolt-table-value.png 428w,
https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/4ee7f/dolt-table-value.png 486w" sizes="(max-width: 486px) 100vw, 486px" loading="lazy">
  </a>
    </span></p>
<p>Dolt supports remotes, which means it can clone, push and pull branch
and tag references from a Dolt repository stored in
<a href="https://www.dolthub.com/">Dolthub</a> or in cloud storage like <a href="https://aws.amazon.com/s3/">AWS
S3</a> or <a href="https://cloud.google.com/storage">Google Cloud
Storage</a>. This blog post briefly
explores what Dolt remotes are and how they operate under the hood.</p>
<h2>A Dolt Remote</h2>
<p>A Dolt repository can have multiple remote repositories configured,
and each of these repositories can be fetched from and pushed to
separately. Each configured Dolt remote consists of three pieces of
configuration within a Dolt repository:</p>
<ol>
<li>The name of the remote. After a clone, this will be <code>origin</code>.</li>
<li>Configuration for a networked endpoint that implements a network
protocol that Dolt can use as a remote. Most commonly, this is the
GRPC API exported by <a href="https://doltremoteapi.dolthub.com/">https://doltremoteapi.dolthub.com</a> and a
Dolthub repository path like <code>Liquidata/image-net</code>.</li>
<li>Default fetch specs for the remote. After a clone, this will be
<code>refs/heads/*:refs/remotes/origin/*</code>, and most users never need to
interact directly with fetch specs.</li>
</ol>
<p>The fetch spec is the subtlest piece of the configuration, but it's
also fundamental to the way that remotes actually work. The above
fetch spec says: When we <code>fetch</code> from <code>origin</code>, create a new <code>ref</code> in
<code>refs/remotes/origin/...</code> for each ref we find in the remote at
<code>refs/heads/...</code>. <code>refs/heads/...</code> will be all the branches in the
remote, and so fetching from the remote will create corresponding refs
in our local repository for each branch in the remote repository. If
the remote had the branches <code>main</code>, <code>bh/agi</code> and <code>aaron/by-zip</code>, and
we fetched from it, Dolt would create the refs
<code>refs/remotes/origin/main</code>, <code>refs/remotes/origin/bh/agi</code> and
<code>refs/remotes/origin/aaron/by-zip</code>, each pointing at the corresponding
commits that the remote branches were pointing at when we ran the
<code>fetch</code>.</p>
<p>So the remotes <code>ref</code>s namespace is seperate from our local branches
namespace, and Dolt is keeping a copy of the branches that we fetch
from the remote locally. The only time that copy is updated, and the
only time we reference the remote generally, is when we run <code>dolt
fetch</code> (or <code>dolt pull</code>, which does a <code>fetch</code> and then <code>merge</code>). And
the fundamental operation involved in a <code>fetch</code> is:</p>
<ol>
<li>Contact the remote to list all the branches we will clone.</li>
<li>For each branch we will clone, update our local repository to
contain the referenced Commit <code>Chunk</code> and all <code>Chunk</code>s reachable from
it.</li>
<li>Set a corresponding <code>ref</code> in our local repository to point to the
newly fetched Commit <code>Chunk</code>.</li>
</ol>
<p>Step #2 is where all the missing data actually gets copied into our
local repository. Let's take a look at exactly how that happens.</p>
<h2>Chunk Stores and DAG Traversals</h2>
<p>As mentioned above, all the data in the repository, both Commits and
the table data, is stored in these content-addressed variable sized
blocks called <code>Chunk</code>s. A storage abstraction exists in the Dolt
storage layer called a <code>ChunkStore</code>, which is a place where we can
read, and potentially write, chunks.</p>
<div data-language="go"><pre><code><span>package</span> chunk

<span>type</span> Address <span>[</span><span>20</span><span>]</span><span>byte</span>

<span>type</span> Chunk <span>interface</span> <span>{</span>
    
    <span>Refs</span><span>(</span><span>)</span> <span>[</span><span>]</span>Address
    
    <span>Bytes</span><span>(</span><span>)</span> <span>[</span><span>]</span><span>byte</span>
<span>}</span>

<span>type</span> Store <span>interface</span> <span>{</span>
    <span>Has</span><span>(</span>addr Address<span>)</span> <span>bool</span>
    <span>Get</span><span>(</span>addr Address<span>)</span> Chunk
    <span>Put</span><span>(</span>contents Chunk<span>)</span>
<span>}</span></code></pre></div>
<p>We can create a <code>Store</code> implementation for a remote repository which
is hosted in DoltHub, and we have a <code>Store</code> implementation for our
local repository as well. A simple recursive DAG walk to copy a given
commit (or any <code>Chunk</code> with all of its children) into our local
repository looks like:</p>
<div data-language="go"><pre><code><span>func</span> <span>CopyChunks</span><span>(</span>to<span>,</span> from Store<span>,</span> a Address<span>)</span> <span>{</span>
	<span>if</span> <span>!</span>to<span>.</span><span>Has</span><span>(</span>a<span>)</span> <span>{</span>
		c <span>:=</span> from<span>.</span><span>Get</span><span>(</span>a<span>)</span>
		<span>for</span> <span>_</span><span>,</span> r <span>:=</span> <span>range</span> c<span>.</span><span>Refs</span><span>(</span><span>)</span> <span>{</span>
			<span>Fetch</span><span>(</span>to<span>,</span> from<span>,</span> r<span>)</span>
		<span>}</span>
		to<span>.</span><span>Put</span><span>(</span>c<span>)</span>
	<span>}</span>
<span>}</span></code></pre></div>
<p>This approach already has some nice properties. Ideally, if a <code>Chunk</code>
is in a <code>Store</code>, all the <code>Chunk</code>s it references would also be in the
<code>Store</code>. We don't want our algorithm to persist any <code>Chunk</code>s to the
<code>Store</code> whose children we haven't already fetched and persisted,
because if the algorithm gets aborted halfway through the <code>Store</code>
could then be in an inconsistent state. So we're careful not to <code>Put</code>
the fetched <code>Chunk</code> until its children are persisted.</p>
<h2>Better Performance With Batching</h2>
<p>In Go, the recursion is not much of a concern because goroutines have
on-heap growable stacks. But if it is a concern, it's easy to
translate the call stack state into an explicit stack with on-heap
state as well.</p>
<p>The above algorithm has one glaring issue: it's very slow. If <code>from</code>
is a remote <code>Store</code>, then every <code>Get</code> is a round-trip RPC, and as
written there's no capacity for pipelining or batching. The simplest
solution is to make the batching explicit. We can give <code>Store</code> batch
methods, and make <code>CopyChunks</code> take a slice of <code>Address</code>es instead:</p>
<div data-language="go"><pre><code><span>type</span> Store <span>interface</span> <span>{</span>
    
    
    <span>HasMany</span><span>(</span><span>[</span><span>]</span>Address<span>)</span> <span>(</span>present<span>,</span> missing <span>[</span><span>]</span>Address<span>)</span>
    
    
    <span>GetMany</span><span>(</span><span>[</span><span>]</span>Address<span>)</span> <span>[</span><span>]</span>Chunk
    
    <span>PutMany</span><span>(</span><span>[</span><span>]</span>Chunk<span>)</span>
<span>}</span>

<span>func</span> <span>CopyChunks</span><span>(</span>to<span>,</span> from Store<span>,</span> as <span>[</span><span>]</span>Address<span>)</span> <span>{</span>
	<span>_</span><span>,</span> missing <span>:=</span> to<span>.</span><span>HasMany</span><span>(</span>as<span>)</span>
	chunks <span>:=</span> from<span>.</span><span>GetMany</span><span>(</span>missing<span>)</span>
	nextlevel <span>:=</span> <span>[</span><span>]</span>Address<span>{</span><span>}</span>
	<span>for</span> <span>_</span><span>,</span> c <span>:=</span> <span>range</span> chunks <span>{</span>
		nextlevel <span>=</span> <span>append</span><span>(</span>nextlevel<span>,</span> c<span>.</span><span>Refs</span><span>(</span><span>)</span><span>...</span><span>)</span>
	<span>}</span>
	<span>CopyChunks</span><span>(</span>to<span>,</span> from<span>,</span> nextlevel<span>)</span>
	to<span>.</span><span>PutMany</span><span>(</span>chunks<span>)</span>
<span>}</span></code></pre></div>
<p>That improves the round-trips for remote clones substantially and
allows for better bandwidth utilization. But it introduces two new
flaws.</p>
<ol>
<li>Memory usage is potentially unwieldy. In the batched version, we're
holding a potentially large number of <code>Chunk</code>s in memory at every call
to <code>CopyChunks</code>, and we're making a call to <code>GetMany</code> with an
unbounded number of <code>Address</code>es. Previously we were only holding one
<code>Chunk</code> in memory at each level of the call.</li>
<li>It potentially fetches the same <code>Chunk</code>s from <code>from</code> multiple
times. Two different length paths through the DAG to the same <code>Chunk</code>
will have <code>to.HasMany()</code> returning <code>missing</code> for the same <code>Chunk</code>
multiple times, with consequent calls to <code>GetMany()</code> with the same
addresses.</li>
</ol>
<p>Addressing those actually gets somewhat complicated. In Dolt, for #1
we form explicit RPC batches and write the fetched <code>Chunk</code>s to
temporary chunk files so that they don't have to stay in memory. The
temporary files are constructed so that they can be cheaply integrated
into the <code>to</code> <code>Store</code> when all their dependencies are
persisted. Addressing #2 involves adding a little bit of book keeping
across recursive calls.  But perfect behavior with regards to case #2
is actually a tradeoff between the batch sizes and memory usage. Once
the chunk from a higher level leaves memory and goes into the
temporary chunk file, it needs to be refetched from the remote or from
the disk in order to be incorporated in the <code>to</code> <code>Store</code> earlier than
its peers.</p>
<h2>Fetch and Push</h2>
<p>It's neat that the above algorithm works great whether operation is a
<code>push</code> or a <code>fetch</code>. If the remote <code>Store</code> is <code>from</code>, we're doing a
<code>fetch</code> and we will get new chunks from the remote into our local
<code>Store</code>. But we can also make the remote <code>Store</code> <code>to</code>, in which case
its a <code>push</code>—the remote <code>Store</code> gets the new <code>Chunk</code>s that were
unique to our local <code>Store</code>. In either case, once all the <code>Chunk</code>s are
persisted in the <code>to</code> <code>Store</code>, we can update any <code>refs</code> appropriately,
setting them to point to the newly persisted commit <code>Chunk</code>s based on
the operation we're performing and the fetch/push specs as
appropriate.</p>
<h2>Conclusion</h2>
<p>Dolt remotes are a powerful feature that allows for data
synchronization, collaboration and easily maintaining local changes
while tracking upstreams. Underlying the feature is a simple model for
how to build up the commit graph and the table data as a merkle DAG of
content addressed chunks. Building on top of that model allows for
<code>push</code> and <code>fetch</code> to be both be implemented by the same elegant DAG
walk. At the same time, practical engineering and performance concerns
introduce an opportunity for tradeoffs and optimization. Hopefully
we've given you some insight into the ways that Dolt approaches and
solves the issues underlying its implementation.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-09-09-push-pull-on-a-merkle-dag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24424593</guid>
            <pubDate>Wed, 09 Sep 2020 19:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zink (OpenGL on Vulkan) performance better than expected]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 89 (<a href="https://news.ycombinator.com/item?id=24424462">thread link</a>) | @mfilion
<br/>
September 9, 2020 | http://www.supergoodcode.com/funday/ | <a href="https://web.archive.org/web/*/http://www.supergoodcode.com/funday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2 id="just-for-fun">Just For Fun</h2>

<p>I finally managed to get a complete piglit run over the weekend, and, for my own amusement, I decided to check the timediffs against a reference run from the IRIS driver. Given that the Intel drivers are of extremely high quality (and are direct interfaces to the underlying hardware that I happen to be using), I tend to use ANV and IRIS as my references whenever I’m trying to debug things.</p>

<p>Both runs used the same base checkout from mesa, so all the core/gallium/nir parts were identical.</p>

<p>The results weren’t what I expected.</p>

<p>My expectation when I clicked into the timediffs page was that zink would be massively slower in a huge number of tests, likely to a staggering degree in some cases.</p>

<p>We were, but then also on occasion we weren’t.</p>

<p>As a final disclaimer before I dive into this, I feel like given the current state of people potentially rushing to conclusions I need to say that <strong>I’m not claiming zink is faster than a native GL driver</strong>, only that <strong>for some cases, our performance is oddly better than I expected</strong>.</p>

<h2 id="the-good">The Good</h2>
<p><img src="https://zmike.github.io/assets/piglit-misc-bench.png" alt="piglit-misc-bench.png"></p>

<p>The first thing to take note of here is that IRIS is massively better than zink in successful test completion, with a near-perfect 99.4% pass rate compared to zink’s measly 91%, and that’s across 2500 more tests too. This is important also since timediff only compares between passing tests.</p>

<p>With that said, somehow zink’s codepath is significantly faster when it comes to dealing with high numbers of varying outputs, and also, weirdly, a bunch of <code>dmat4</code> tests, even though they’re both using the same softfp64 path since my icelake hardware doesn’t support native 64bit operations.</p>

<p>I was skeptical about some of the numbers here, particularly the <code>ext_transform_feedback</code> <code>max-varying-arrays-of-arrays</code> cases, but manual tests were even weirder:</p>

<div><div><pre><code>time MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=zink bin/ext_transform_feedback-max-varyings -auto -fbo

MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=zink  -auto -fbo  2.13s user 0.03s system 98% cpu 2.197 total
</code></pre></div></div>

<div><div><pre><code>time MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=iris bin/ext_transform_feedback-max-varyings -auto -fbo

MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=iris  -auto -fbo  301.64s user 0.52s system 99% cpu 5:02.45 total
</code></pre></div></div>

<p>wat.</p>

<p>I don’t have a good explanation for this since I haven’t dug into it other than to speculate that ANV is just massively better at handling large numbers of varying outputs.</p>

<h2 id="the-bad">The Bad</h2>

<p>By contrast, zink gets thrashed pretty decisively in <code>arb_map_buffer_alignment-map-invalidate-range</code>, and we’re about <strong>150x slower</strong>.</p>

<p>Yikes. Looks like that’s going to be a target for some work since potentially an application might hit that codepath.</p>

<h2 id="the-weird">The Weird</h2>
<p><img src="https://zmike.github.io/assets/piglit-fp64-bench.png" alt="piglit-fp64-bench.png"></p>

<p>Somehow, zink is noticeably slower in a bunch of other fp64 tests (and this isn’t the full list, only a little over half). It’s strange to me that zink can perform better in certain fp64 cases but then also worse in others, but I’m assuming this is just the result of different shader optimizations happening between the drivers, shifting them onto slightly less slow parts of the softfp64 codepath in certain cases.</p>

<p>Possibly something to look into.</p>

<p>Probably not in too much depth since softfp64 is some pretty crazy stuff.</p>

<h2 id="in-closing">In Closing</h2>
<p>Tests (and especially piglit ones) are not indicative of real world performance.</p>

  </div></div>]]>
            </description>
            <link>http://www.supergoodcode.com/funday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24424462</guid>
            <pubDate>Wed, 09 Sep 2020 18:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What are the legal issues around web scraping?]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24424277">thread link</a>) | @neoflexycurrent
<br/>
September 9, 2020 | http://evan.law/2020/09/09/what-are-the-legal-issues-around-web-scraping/ | <a href="https://web.archive.org/web/*/http://evan.law/2020/09/09/what-are-the-legal-issues-around-web-scraping/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-5792" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
		
		<!-- .entry-header -->

		
		<div itemprop="text">
			
<figure><p>
<iframe title="Web scraping - what are the legal issues? | Evan Brown" width="900" height="506" src="https://www.youtube.com/embed/YA4eDamJz24?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Web scraping is that activity where a party uses automated software to crawl the internet and copy data and other content, usually so that it can compile that together and make its own product offering.  This may be of concern to you because you are a company that does web scraping. Or you may be a web publisher and there are other parties that are scraping your content. Let’s examine some of the legal issues around web scraping.</p>



<h3>Breach of contract</h3>



<p>One of the questions that commonly arises around web scraping is whether the activity is a breach of contract. More specifically, the question is whether the use of automated software violates the terms of service of the website that is being scraped. You often see website terms of service prohibit the use of spider and other automated crawling software to access and use the site. Parties who own websites that are being scraped will often look to see whether the scraping of their site is a breach of contract. </p>



<h3>Copyright infringement</h3>



<p>Another common question arising when analyzing web scraping is lawful whether scraping constitutes copyright infringement. This is a difficult argument to make if all that is being scraped is data, because mere facts usually are not subject to copyright protection. But if there is other content being scraped, such as images or specific compilations of data, the question of copyright infringement becomes a bit easier to answer in that unauthorized copying is an likely an infringement.</p>



<h3>Computer Fraud and Abuse Act</h3>



<p>The <a href="https://www.law.cornell.edu/uscode/text/18/1030" target="_blank" rel="noreferrer noopener">Computer Fraud and Abuse Act</a> is another topic that often comes up in discussions about web scraping. This is a federal law that makes it unlawful for a person to access a protected computer without authorization, or in excess of a specific authorization. So the question becomes whether that access by the automated web scraper violates the Computer Fraud and Abuse Act. There are some important things that have to be proven for a plaintiff to succeed under the Computer Fraud and Abuse Act, and one of those is loss or damage that results from the unauthorized access. It is a very fact intensive inquiry that has to be made,  but the Computer Fraud and Abuse Act is one thing that parties should think about in the context of web scraping. </p>



<h3>Trade secrets</h3>



<p>The question of trade secrets is another good one to raise in the context of web scraping. A trade secret is any information that a company has that gives that company a commercial advantage in the marketplace because it is secret. The information also has to be the subject of protective efforts — the company has to try to keep the information secret. For example, if information on a website is put there in a way that is behind certain protective barrier,s and the party doing the scraping circumvents those barriers, it could be that there is a misappropriation of trade secrets, particularly if that information is used for some competitive purpose. </p>



<h3>Let’s talk</h3>



<p>Web scraping legal issues can be complex. Scraping presents certain legal risks to the ones doing it, and the law provides certain powerful remedies when web scraping runs afoul of the rules. If you have questions about web scraping, give me a call at (630) 362-7237, or send me an email at <a href="mailto:ebrown@internetcases.com" target="_blank" rel="noreferrer noopener">ebrown@internetcases.com</a>. </p>



<h3>About the author</h3>



<p>Evan Brown is a technology and intellectual property attorney in Chicago. This content originally appeared on <a href="http://evan.law/">evan.law</a>. </p>



<h3>See also:</h3>



<ul><li><a href="http://evan.law/2018/11/19/web-scraping-case-fails-under-dastar/" target="_blank" rel="noreferrer noopener">Web scraping case fails under Dastar</a></li><li><a href="http://evan.law/2012/11/01/terms-of-service-data-scraping/" target="_blank" rel="noreferrer noopener">Online terms of service were not effective to prohibit data scraping</a></li><li><a href="http://evan.law/2005/04/06/forum-selection-clause-upheld-in-content-scraping-case/" target="_blank" rel="noreferrer noopener">Forum selection clause upheld in content scraping case</a></li></ul>
		</div><!-- .entry-content -->

					<!-- .entry-meta -->
			</div><!-- .inside-article -->
</article><!-- #post-## -->

					

							</main><!-- #main -->
	</div><!-- #primary -->

	<!-- #secondary -->

	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>http://evan.law/2020/09/09/what-are-the-legal-issues-around-web-scraping/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24424277</guid>
            <pubDate>Wed, 09 Sep 2020 18:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hoarding critical knowledge is a way to stay employed]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24423857">thread link</a>) | @qrt
<br/>
September 9, 2020 | https://qatalog.com/blog/post/got-knowledge | <a href="https://web.archive.org/web/*/https://qatalog.com/blog/post/got-knowledge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://qatalog.com/blog/post/got-knowledge</link>
            <guid isPermaLink="false">hacker-news-small-sites-24423857</guid>
            <pubDate>Wed, 09 Sep 2020 18:02:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leading a dev team with data and not being a tyrant]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24423702">thread link</a>) | @necco908
<br/>
September 9, 2020 | https://linearb.io/blog/data-driven-dev-team/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/data-driven-dev-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><img src="https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3><strong>Stack ranking is natural human behavior&nbsp;</strong></h3>



<p>I have a buddy from high school named Murph. His real name is <a href="https://www.linkedin.com/in/bfelt/" target="_blank" rel="noreferrer noopener">Ben Felt</a> but every legit teenage crew in Pitsford, New York in the 90s needed a Murph so Ben took one for the team.&nbsp;</p>



<p>He’s a quant. Like Taylor Mason from the show Billions.&nbsp;</p>







<figure><img src="https://lh5.googleusercontent.com/aLSHkNWCVa3tsooRGsEIn_ePCfPbm8q76JG1IFkqXgNr5XQ9UDaadhEWwDWx6PmnYKQbYUg3RejrISynwYZy21haJKT_N8O12TRFNBojxdP37hpOO80kmOoRc-ViIo2AWv2cJboF" alt=""></figure>







<p>It would have been easy to predict Murph would end up as a big shot on Wall Street. For starters, he got a perfect 1600 score on his SATs and was accepted early admission to Yale.&nbsp;</p>



<p>There was also his unique approach to fantasy football. I’ve been playing with the same group of guys since 1999. We started in my Mom’s basement.&nbsp;</p>



<p>When it came time for draft day, the regular nerds in our group like me would bring fantasy football magazines with last year’s stats and analyst opinions.&nbsp;</p>



<p>Murph brought his computer. He wrote a program that organized his draft board based on each player’s predicted performance correlated to his personal skill preferences. This is years before Daryl Morey founded <a href="http://www.sloansportsconference.com/" target="_blank" rel="noreferrer noopener">Sloan Conference</a>. Murph was ahead of his time.&nbsp;</p>



<p>People naturally want to quantify objects by ranking them in lists of best to worst, most expensive to least expensive, most important to least important. We do this throughout our personal and professional lives. Often subconsciously before we even realize we’re doing it.&nbsp;</p>



<p>Sometimes it makes sense to rank objects by performance. Like ranking athletes in your fantasy league. Murph won our league multiple times using his ranking algo.&nbsp;</p>



<p>Sometimes it even makes sense to rank real people by performance. Like on a sales team where there is a relatively direct link between the contribution of a sales rep and the outcomes (e.g. new customer, revenue) they deliver.</p>



<p><strong>When it comes to members of your dev team, it does not make sense to rank them using personal performance statistics.&nbsp;</strong></p>







<hr>



<div><figure><a href="https://linearb.io/trial/" target="_blank" rel="noopener noreferrer"><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/CTACharacter.png.webp 502w" sizes="(max-width: 502px) 100vw, 502px">
<img src="https://linearb.io/wp-content/uploads/2020/09/CTACharacter.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/CTACharacter.png 502w, https://linearb.io/wp-content/uploads/2020/09/CTACharacter-202x300.png 202w" sizes="(max-width: 502px) 100vw, 502px">
</picture>
</a></figure></div>



<hr>







<h3><strong>Running a data-driven team does not mean stack ranking developers&nbsp;</strong></h3>



<p>A software development team is less like a sales team and more like a band. Everyone is highly dependent on one another to deliver a great result. If one person is off, it throws everyone off. And, like in a band, there are often unsung heroes (like the bass player or drummer) who make it possible for other stars (like the lead singer) to shine.&nbsp;&nbsp;</p>







<figure><img src="https://lh6.googleusercontent.com/-cqrL_fBle6dxY8DlVUhtTWbh54DZMympB2IVKA4EfMFLQ5y712qgwgXxHwVAsZH_8cxd3MCAmoRRGoIkbrpFVtpDrjTIWQqXjFijyhLLF2eRgjvCJmP7--6FkGXpmFnheNvtZyJ" alt=""></figure>







<p>The contributions of your most selfless team members may not show up if you just look at lines of code, number of commits or personal story point velocity.</p>



<p>The other big reason not to stack rank your devs is that they just don’t like it. Unlike sales people, your engineers did not sign up to work in a hyper competitive environment.</p>



<p>So why does stack ranking still happen? Some would say bad managers are the culprit. That’s probably true sometimes. Many bad managers want control and pitting teammates against each other in competition is certainly one way to get it.&nbsp;</p>



<p>Most of the time the reason is more nuanced. I believe most managers have good intentions and want their people to succeed. But they get caught in the “data-driven trap.”</p>



<p>I hear it from engineering leaders every day… “My CEO wants me to be more data-driven” or “Our company is rolling out a metrics initiative.” Pressure to become data-driven can lead to arbitrary use of data to show the boss metrics are being used. “Let’s use data to make better decisions” gets confused as “let’s use data for performance management.”</p>



<p>When this misconception occurs, one of two things happens. Performance stack ranking metrics are implemented and it damages the team culture. Or the manager knows performance management is bad and avoids using metrics all together. Both are bad outcomes for the team.&nbsp;</p>



<p><strong>You can run a highly data and metrics-driven dev organization with absolutely zero performance management statistics.&nbsp;</strong></p>







<h3><strong>Data-driven engineering leadership anti-patterns</strong></h3>



<p>To avoid the “data-driven trap”, watch out for these 5 anti-patterns:&nbsp;</p>







<p><strong>Not knowing your “why”</strong></p>



<p>Without the “why”, the metrics themselves can become the outcome everyone cares about instead of being an indicator of the actual outcome you are trying to achieve like faster innovation, more predictable delivery dates, happier customers, etc.&nbsp;</p>







<p><strong>Only measuring individual stats</strong></p>



<p>As leaders we preach that we’re all working together as a band (team) to make beautiful music. What we measure shows what matters to us. If we track tons of individual metrics, we’re showing our people that individual stats matter more than team accomplishments. To get around this, I’ve actually seen some engineering leaders maintain secret dashboards with individual performance data. Their rationale is that it’s helpful for management as long as its existence does not get out. Everything always comes out eventually so I don’t recommend this. Plus, if you’re measuring something you don’t want your team to know about, that’s a good indicator you’re measuring the wrong thing.&nbsp;</p>







<p><strong>Focusing on just 1 or 2 metrics&nbsp;</strong></p>



<p>I can’t tell you how many dev leads I meet that look only at velocity to determine the success of an iteration. <a href="https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/" target="_blank" rel="noreferrer noopener">Even if you think velocity is a useful indicator (I don’t)</a>, there is no silver bullet. Without a balanced approach to measuring each area of your team and process, it’s easy to lose sight of the big picture. For example, if you just focus on data that measures your delivery speed, you could encourage behavior that has a negative effect on quality.&nbsp;</p>







<p><strong>Thinking your new hammer (data) works for every nail (problem)&nbsp;</strong></p>



<p>When we first start experiencing how powerful data can be as a tool to quantify trends and diagnose problems, it’s really exciting. And this is precisely when we need to be careful. We can’t forget to seek out input from our people too. Reports and dashboards are at their best when they prompt penetrating questions and point us in the right direction. We can’t get lazy and base decisions exclusively on the numbers.&nbsp;</p>







<p><strong>Just using metrics that are easily available&nbsp;</strong></p>



<p>“Let’s use velocity to measure team performance. We get it from our project management system automatically.” Pulling the data you really need can be an initial large lift but the benefit overtime will pay back 100x. And it’s actually worse to force the wrong metrics than to use none at all.</p>







<h3><strong>14 ways to use data in your daily dev team practices without being a performance tyrant</strong></h3>



<p>Forget about individual performance management stats. There are many other ways to incorporate data into your team’s day to day routine that will have a positive impact on delivery efficiency, quality and predictability and actually improve your culture, not hurt it.&nbsp;</p>



<p>So what should we measure?&nbsp;</p>



<p>When I was a team lead, I answered that question for myself by taking a step back and looking at my personal leadership responsibility areas. After analyzing all of my important jobs, I found that they fit into three pillars.&nbsp;</p>







<figure><img src="https://lh5.googleusercontent.com/13hUMY4HlnRRfrtmq4bMgYWOYBAHk95xsSDCvXbi7FRgNp7vUckkpkgFONefECxyU7deWyn46tOXd6QKnSNvrbKGwuiRzlS8hOFbKe1mhwgHXrXW6GxPUTRFTQzgWSXS-BkB67e0" alt=""></figure>







<p>These pillars became my “why”. So instead of starting with metrics and looking for a place to apply them, I looked for data that would help me understand and improve these areas.&nbsp;</p>



<p>Here’s 14 ways we use data to run our team on a day-to-day basis at <a href="https://linearb.io/" target="_blank" rel="noreferrer noopener">LinearB</a>.&nbsp;</p>







<h4><strong>How we use data to accelerate project delivery</strong></h4>



<p>Project delivery is highly complicated because of the number of things happening in parallel. Even if your team is only 6-8 people. Technology, time constraints, priority shifts, developers, business stakeholders, customers… The only way to see across all of these dimensions is with data. Better yet, visual representations of data help distill complex things into manageable views and show you where to look and how to invest your time.&nbsp;</p>







<p><strong>1. Pull request throughput</strong></p>



<p>My friend <a href="https://linearb.io/coffee-talk/" target="_blank" rel="noreferrer noopener">Chris Downard</a>, the VP of Engineering at GigSmart, put it well.&nbsp;</p>



<p><em>“Knowing what to measure starts with aligning your team around what’s important to the business. In most companies, they want the dev team to deliver new value. So I care about metrics that are proxies for value delivery. I lean on merge requests because it helps me see throughput for work related to new features and bug fixes.”&nbsp;</em></p>



<p>We use our PR throughput dashboard the exact same way on our team. We like to see that the ratio of PRs opened to PRs merged stays in the 90-95% range otherwise we know we have a bottleneck in review.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://lh3.googleusercontent.com/dHWqhiCedjAb52oN1VY0S8uFUZ1cR7gJcHRrcRWQbb84XouHrTD21sRih0oQz9SwhywEdmp6ZHTaJ6niGMnWxReoMigGIieLXM2glZ5CUkCqc1HBGIrKM1vc7FKWCZCsBaTBqkwC" alt=""></a></figure>







<p><strong>2. Stuck pull requests&nbsp;</strong></p>



<p>We look for A) PRs that have not been picked up for review, B) PRs that have abnormally high back and forth interaction and C) PRs with long review time.&nbsp; Then we alert the team to these in Slack so we can start a conversation about how to help and click through to the PR directly in Git.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://lh5.googleusercontent.com/1JL97AoLYrbimIpkxfT405N-FxrCieSqchuaEn2Dh6dwlRe5OYYBCX6TlpsUDIQiSHiEtQPsa9Sl_iJRDS2845EB4DyMUm03OvDba3_ASMiKaBe7ToucIUMAgyhFZYPjD6ICAywB" alt=""></a></figure>







<p>We implemented this in <a href="https://linearb.io/blog/dev-productivity-is-way-down-at-linearb/" target="_blank" rel="noreferrer noopener">March when work-from-home started</a> and it’s become a critical part of our delivery process. Our devs love it because it’s one less thing they need to remember and they can jump in and help teammates more easily.&nbsp;</p>







<p><strong>3. PRs merged without review</strong></p>



<p>Our team is great about reviews but occasionally things slip. Flagging large PRs that have been merged without review has helped us catch a lot of mistakes before customers found them.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://lh4.googleusercontent.com/PsPxncxslm2V2acQox3pnFiR_nULYXN8FCXnvxjD-JLlVSiihieUMDayOELHpubE5aZ45QonVchJt9WhrDdD_M2TMyBlGCAp96lhU0BGVI2pzkRM6CB_j_pP4YivthPHVqgXs26N" alt=""></a></figure>







<p><strong>4. High risk branches</strong></p>



<p>About 15 months ago we analyzed all of our bugs and found a connection between bugs and large branches with a high rate of immediate rework (more than 30%). So now we look for those branches proactively and use our Slack alerts to get another set of eyes on them for review.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://lh6.googleusercontent.com/XuW12YJqhGmUTkMDRueIlTudnmil0P7uElElddlcDcc17COKUaporHhX7XhljQrRTWnjc2F1eHK1enijyKwIcppaIDnVnFpngbWYBYvslH0QI8U7W3uAK0-883deZ28d9cCN58Qq" alt=""></a></figure>







<hr>











<hr>







<p><strong>5. Days remaining to open work ratio&nbsp;</strong></p>



<p>We work in two week iterations. Once we’re about a week in, there’s a general equation our leads use to figure out if we’re on track to deliver the iteration: WIP + to-do ÷ days remaining = almost everything you need to know about whether or not you are going to finish on time.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Devboard Envy? <a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get this one for free</a></figcaption></figure>







<p>Our dev team uses a board that shows our Github activity on a timeline with the Jira …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/data-driven-dev-team/">https://linearb.io/blog/data-driven-dev-team/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/data-driven-dev-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24423702</guid>
            <pubDate>Wed, 09 Sep 2020 17:50:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Panther Labs Raises $15M to Reinvent SIEM for Cloud-First Teams]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24423524">thread link</a>) | @jacknagz
<br/>
September 9, 2020 | https://blog.runpanther.io/series-a-funding/ | <a href="https://web.archive.org/web/*/https://blog.runpanther.io/series-a-funding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.runpanther.io/content/images/size/w300/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg 300w,
                            https://blog.runpanther.io/content/images/size/w600/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg 600w,
                            https://blog.runpanther.io/content/images/size/w1000/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg 1000w,
                            https://blog.runpanther.io/content/images/size/w2000/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.runpanther.io/content/images/size/w2000/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg" alt="Panther Labs Series A Funding">
            </figure>

            <section>
                <div>
                    <p>Today, we're pleased to announce our <a href="https://www.prnewswire.com/news-releases/panther-labs-raises-15m-series-a-to-reinvent-siem-for-cloud-first-security-teams-301126303.html">$15M Series A financing led by Lightspeed Venture Partners</a>! </p><p>With this latest round of funding, we can double-down on our mission to re-invent the SIEM for modern and cloud-focused security teams. We're also excited to welcome <a href="https://www.linkedin.com/in/ggupta/">Gaurav Gupta</a> to our board of directors. Gaurav brings 10+ years of experience as a product leader at Splunk and Elastic to our leadership team.</p><p>Security teams are struggling to manage the unprecedented scale and growth of data in the cloud. Panther operationalizes massive volumes of scattered and unstructured security logs into real-time Python detections and helpful analytics with SQL over structured data. This new data-driven, developer-centric paradigm will power security teams for the next 10 years.</p><p>Panther’s guiding product principles are:</p><ul><li><strong><strong><strong>Open</strong> </strong></strong>and transparent data processing and storage.</li><li><strong><strong><strong>Scalable </strong></strong></strong>serverless infrastructure designed for Petabyte-scale.</li><li><strong>Powerful</strong> Python detections to identify complex behaviors in real-time.</li></ul><p>Panther Community Edition is a fully functional and open source project for teams to get started with analyzing their log data and cloud security posture. For production-level deployments, Panther Enterprise offers advanced features around querying and data storage, the ability to pull SaaS log data, customizable RBAC and SSO integrations, and options for SaaS and self-hosted deployments.</p><p>One new feature we’re excited to announce in Panther Enterprise is an Indicator Search. This feature enables lightning-fast searches across all collected logs for IPs, domains, hashes, cloud-specific values like ARNs, and <a href="https://docs.runpanther.io/log-analysis/panther-fields">more</a>. This is made possible by the <a href="https://blog.runpanther.io/panther-database-as-service-modern-serverless-architecture/">Panther’s Data Lake</a>, which enables scalable storage for huge amounts of security data.</p><p>Try <a href="https://github.com/panther-labs/panther">Panther Community Edition</a> today and join the discussion on <a href="http://slack.runpanther.io/">Slack</a> to learn how teams are using Panther to prevent breaches at cloud-scale. Also check out our public roadmap that includes planned, in-progress, and recently launched features. </p><p><strong>We’re also hiring!</strong> If you’re interested in contributing to our mission, check out our <a href="https://boards.greenhouse.io/pantherlabs">open roles on Greenhouse</a>. Panther is a remote-friendly workforce and aims to foster a culture of diversity.</p><figure><img src="https://blog.runpanther.io/content/images/2020/09/Zoom-Sept-2020.png" alt="" srcset="https://blog.runpanther.io/content/images/size/w600/2020/09/Zoom-Sept-2020.png 600w, https://blog.runpanther.io/content/images/size/w1000/2020/09/Zoom-Sept-2020.png 1000w, https://blog.runpanther.io/content/images/size/w1600/2020/09/Zoom-Sept-2020.png 1600w, https://blog.runpanther.io/content/images/size/w2400/2020/09/Zoom-Sept-2020.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Our Team at Panther Labs</figcaption></figure>
                </div>
            </section>


            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.runpanther.io/series-a-funding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24423524</guid>
            <pubDate>Wed, 09 Sep 2020 17:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backup PostgreSQL to Cloud]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24423208">thread link</a>) | @Abishek_Muthian
<br/>
September 9, 2020 | https://abishekmuthian.com/backup-postgresql-to-cloud/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/backup-postgresql-to-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post will help you with easy, cost-effective and secure way to backup your PostgreSQL database to cloud.</p><h3 id="create-local-scheduled-backup-of-postgresql-database">Create local scheduled backup of PostgreSQL database</h3><ol><li><p>Login as <em>postgres</em> user on the console (<a href="https://www.howtogeek.com/671422/how-to-use-tmux-on-linux-and-why-its-better-than-screen/" target="_blank">tmux</a> is recommended).</p></li><li><p>Create .pgpass file to access database without entering credentials manually.</p><pre><code>$ nano .pgpass
</code></pre></li><li><p>Enter the credentials in the following format. Making changes according to the host if necessary.</p><pre><code>localhost:5432:dbname:dbusername:dbpassword
</code></pre></li><li><p>Set permissions to the file. login_username will be <em>postgres</em>, if you are logged in as that user.</p><pre><code>$ chmod 600 .pgpass
$ chown login_username:login_username .pgpass
</code></pre></li><li><p>Set the environment variable in the <em>.profile</em> file. Where /var/lib/pgsql is the home directory for the user <em>postgres</em> in my setup.</p><pre><code>$ nano .profile

export PGPASSFILE='/var/lib/pgsql/.pgpass'
</code></pre></li><li><p>Test the login. Making changes according to host if necessary.</p><pre><code>$ psql -h localhost -U dbusername dbname
</code></pre></li></ol><h3 id="setup-restic">Setup Restic</h3><p>Restic is a free open-source backup program available for multiple distributions. <a href="https://github.com/restic/restic/releases/" target="_blank">Download</a> the one appropriate to your operating system, extract it, move it to <em>/var/lib/pgsql/bin/</em> (home directory of user <em>postgres</em>) as <em>restic</em>, make it executable and set the PATH to that folder.</p><pre><code>$ bzip2 -d restic_*_linux_amd64.bz2
$ mv restic_*_linux_amd64 /usr/bin/restic
$ chmod u+x /var/lib/pgsql/bin/restic

$ nano .profile

export PATH=$PATH:/var/lib/pgsql/bin
</code></pre><p>Creat <em>restic-pw.txt</em> file with password for encrypting the Postgres database dump.</p><pre><code>$ nano restic-pw.txt
[Enter the password for encryption]

$ chmod 600 restic-pw.txt
$ chown postgres:postgres restic-pw.txt
</code></pre><h3 id="setup-backblaze">Setup Backblaze</h3><p>Backblaze is a cloud storage service, offering easy encrypted end-to-end cloud backup solutions for home and business users.</p><p>For backing up our PostgreSQL database to their cloud, we will use their <a href="https://www.backblaze.com/b2/sign-up.html?referrer=abishekmuthian" target="_blank">B2 service</a> for backing up our
data via their API. <strong>First 10GB of storage on B2 is free as of this writing</strong>, but charges may apply when we download those data and so read the pricing details carefully.</p><p>Create a B2 account to get the following credentials and export them in <em>.bashrc</em>.</p><pre><code>$ nano .bashrc

export B2_ACCOUNT_ID="XXXXX"
export B2_ACCOUNT_KEY="XXXXX"
export RESTIC_REPOSITORY="b2:bucket-name"
export RESTIC_PASSWORD_FILE="restic-pw.txt"
</code></pre><h3 id="setup-a-cron-job-to-schedule-the-backup-and-upload">Setup a cron job to schedule the backup and upload</h3><p>Setup a cronjob to create a PostgresSQL database dump using <em>pg_dump</em> tool, here it is done every day at 23:00 hours and is upload to B2 at 00:00 hours.</p><pre><code>$ crontab -e

0 23 * * * pg_dump -U dbusername -w -F t dbname &gt; /var/lib/pgsql/db.tar
0 0 * * * . /var/lib/pgsql/.bashrc; /usr/bin/restic backup -q /var/lib/pgsql/db.tar
</code></pre><p>Note: Depending upon the size of your database, how often it changes, you might need to change the schedule for the cron job accordingly.</p><h3 id="verify">Verify</h3><p>Check the Backblaze portal to verify that the snapshot was created in our b2 bucket.</p><h3 id="downloading-the-backup">Downloading the backup</h3><p>We can download the backup using restic again, when we need it.</p><p>Get the snapshot-ID.</p><pre><code>$ restic -r b2:bucket-name snapshots
</code></pre><p>Restore the snapshot to a folder using the snapshot_ID.</p><pre><code>$ restic -r b2:bucket-name restore snapshot_ID -t /tmp/restic-restore
</code></pre><p>Note: When downloading the snapshot in another machine, requisite credentials for restic and b2 should be provided as discussed earlier.</p><h3 id="retrieving-the-postgres-dump">Retrieving the Postgres dump</h3><p>Postgres dump would be available in the folder where the snapshot was restored.</p><pre><code>$ cd /tmp/restic-restore
</code></pre><h3 id="restoring-the-postgres-dump">Restoring the Postgres dump</h3><p>Create a database of the same name after logging in as the database user.</p><pre><code>$ CREATE DATABASE dbname;
</code></pre><p>Use the <em>pg_restore</em> tool to restore the database from the dump.</p><pre><code>$ pg_restore --dbname=dbname --verbose db.tar
</code></pre><p>That’s all, now we can have a safe and reliable backup postgres database in the cloud. You can <a href="https://twitter.com/heavyinfo" target="_blank">tweet</a> to me for queries and share this if you found it useful.</p><h3 id="backblaze-entire-storage-backup-solutions-for-home-and-business">Backblaze entire storage backup solutions for Home and Business</h3><p>If you would like unlimited automated backup your entire computer storage instead, then Backblaze has solutions for home and businesses users. Check them out using my affiliate links.</p><p><a href="https://www.backblaze.com/cloud-backup.html#af9vgw" target="_blank">Backblaze unlimited cloud backup for home users</a>.</p><p><a href="https://www.backblaze.com/business-backup.html#af9vgw" target="_blank">Backblaze business backup</a>.</p></div></div>]]>
            </description>
            <link>https://abishekmuthian.com/backup-postgresql-to-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24423208</guid>
            <pubDate>Wed, 09 Sep 2020 17:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Classes are a way of writing higher order functions]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 147 (<a href="https://news.ycombinator.com/item?id=24422547">thread link</a>) | @stopachka
<br/>
September 9, 2020 | https://stopa.io/post/250 | <a href="https://web.archive.org/web/*/https://stopa.io/post/250">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Joe and I recently <a href="https://twitter.com/stopachka/status/1295411936625074178" target="_blank">kicked off a re-read of SICP</a>. I can say that it is <em>the</em> most interesting textbook I have gone through. Imagine, you begin with just 4 or 5 constructs, and you end up building algebraic equation solvers, circuit simulators, and even logic programming languages. Because you start off with such few constructs, the added benefit is that you begin to see the fundamentally simple, shared essence in programming. </p><p>I wanted to give you one example that surprised me in the book. We tend to think that <strong>classes belong in a</strong> <strong>fundamentally different category</strong> <strong>from functions.</strong> </p><p>But are they so different? </p><p>For example, let’s say we have a class like this:</p><pre><code>class Person { 
  constructor(firstName, lastName) {
    this.fName = firstName; 
    this.lName = lastName;
  }
  getFullName() { 
    return this.fName + ' ' + this.lName;
  }
  setFirstName(firstName) {
    this.fName = firstName;
  }
}</code></pre><p>Well, if we think about it, this is really just a higher order function. a <code>Person</code> higher order function accepts arguments (constructor), and returns a list of functions that can manipulate those arguments (methods). We could write <code>Person</code> like this: </p><pre><code> function Person(firstName, lastName) {
  let fName = firstName; 
  let lName = lastName;

  function getFullName() { 
    return fName + ' ' + lName;
  }
  
  function setFirstName(firstName) { 
    fName = firstName
  }

  return function(method) { 
    switch (method) { 
      case 'getFullName': 
        return getFullName;
      case 'setFirstName': 
        return setFirstName;  
    }
  }
}</code></pre><p>Now, </p><pre><code>const person = new Person("Ben", "Bitdiddle")
person.getFullName()</code></pre><p>becomes</p><pre><code>const person = Person("Ben", "Bitdiddle")
person('getFullName')()</code></pre><p>Here, instead of invoking a method, we are “passing” a message. This is why by the way, many classic OO folks talk about object orientation really being about message passing.  </p><p>Yup, really. Classes are just higher order functions, which accept arguments (constructor) and return a list of functions that can manipulate those arguments (methods). </p><p>When you previously thought two concepts were different, but they turn out to be the same, you’re ripe to discover new ideas: you can find the deeper abstractions between them, apply ideas from across those seemingly different categories, and move between concepts more fluidly. So, not only are epiphanies like this fun, but they’re much more useful than you’d think. </p><p>If you liked this, there are a <em>ton</em> of similar epiphanies in the textbook. To experience it best, I suggest picking a partner and working through the book together.</p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Jacky Wang for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/250</link>
            <guid isPermaLink="false">hacker-news-small-sites-24422547</guid>
            <pubDate>Wed, 09 Sep 2020 16:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[State of Self-Serve Website Building in 2020]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 118 (<a href="https://news.ycombinator.com/item?id=24421780">thread link</a>) | @nreece
<br/>
September 9, 2020 | https://sprune.com/blog/state-of-self-serve-website-building-in-2020/ | <a href="https://web.archive.org/web/*/https://sprune.com/blog/state-of-self-serve-website-building-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<h2 id="while-building-our-simple-new-website-we-evaluated-many-website-builder-options-and-realized-how-much-the-landscape-has-changed-for-self-serve-business-website-design-and-hosting-in-this-post-we-ll-review-three-most-practical-diy-approaches-suitable-for-a-simple-static-website-up-to-a-full-content-management-system-cms-">While building our <a href="https://sprune.com/">simple new website</a>, we evaluated many website builder options, and realized how much the landscape has changed for self-serve business website design and hosting. In this post, we'll review three most practical DIY approaches, suitable for a simple static website up-to a full Content Management System (CMS).</h2><p>Back in the day, small-businesses would hire a designer and a web developer to get their website custom made. Then came WordPress, and it changed self-serve website content management forever. However, over the years WordPress has become bloated with features and plugins, resulting in a slow browsing experience and software security issues.</p><p>Having a fast website is the number one success factor for any small-business digital strategy. A fast website makes website visitors less anxious, improves their engagement, results in more sales, and improves search engine rankings.</p><p>In the past few years, the web development community is understandably shifting to static hosting, which basically involves delivering pre-generated static HTML content pages, instead of serving them from a database on each request. This makes the browsing experience much faster, without any backend overhead or security issues.</p><p>Running a Software-as-a-Service (SaaS), a website CMS separate from our product web app allows content writers and team members to quickly and independently edit the website (e.g. marketing copy, pricing notes, FAQ etc.) or publish new content (e.g. blog posts) without involving a tech person or initiating the workflow for Continuous Integration and Delivery (CI/CD).</p><p>It's gotten so much easier and quicker to publish content on our own terms.</p><p>So, how can an indie maker, startup or small-business launch a neat and fast website in reasonably less time, that's still easy to maintain?</p><h3 id="simpler-cms">Simpler CMS</h3><p>There are several WordPress alternatives available now, which are easier, faster, and more suitable for small-medium scale publishing. I'll review my top choice to keep things simple.</p><p><a href="https://ghost.org/">Ghost</a> is a beautiful blogging web software, that we ended up using for our own website. It's clean, fast, has a decent selection of themes, and even has in-built support for newsletters. You can self-host it on a small server (one-click deployment on a $5 VM on <a href="https://www.vultr.com/">Vultr</a> or <a href="https://www.digitalocean.com/">DigitalOcean</a> will do), or you can use <a href="https://ghost.org/pricing/">managed Ghost hosting</a> if self-hosting seems hard to you.</p><p><a href="https://wikipedia.org/wiki/Headless_content_management_system">Headless CMS</a>s are also gaining momentum. They provide a backend to store the content, and an Application Programming Interface (API) to retrieve the stored content using client-scripts on a static website. Altogether, it's particularly useful for sites built with <a href="https://jamstack.org/">JAMstack</a> (JavaScript, APIs, Markup). Check-out the <a href="https://headlesscms.org/">list of headless CMSs</a> for Jamstack sites.</p><h3 id="website-builders">Website Builders</h3><p>Don't worry if you haven't heard of <a href="https://wikipedia.org/wiki/WYSIWYG">WYSIWYG</a> editors from the past, like FrontPage or Dreamweaver. Some modern website builders offer a similarly visual but more end-to-end workflow, from drag-and-drop designing to one-click publishing, all from within the platform.</p><p><a href="https://webflow.com/">Webflow</a> is a fantastic platform to build a full responsive website with a blog, e-commerce store or any other dynamic section (e.g. knowledge base, team profiles etc.). Their gallery of high-quality templates is impressive to choose from. The intuitive website builder makes layouts and content management a breeze, but that's not where it ends. It generates a static website on each publish action, maintains a change history, and hosts the static website on a global Content Delivery Network (CDN) for fastest delivery. It even takes care of asset minification, and assigning &amp; renewing SSL certificates.</p><p><a href="https://versoly.com/">Versoly</a> is also a good option for quickly building blocks-based websites, landing pages, and publish blog posts etc.</p><p>A lot of use-cases only require a one-page website, or a static frontend to a Single Page Application (SPA).</p><p><a href="https://carrd.co/">Carrd</a> is awesome for such single-page responsive websites. It has a simple drag-and-drop builder, which also supports layout sections (emulating a multi-page site). Like Webflow, they also host the website, and take care of SSL certificates. Carrd is the quickest way to having a neat website up &amp; running, minus a blog.</p><h3 id="static-site-generators">Static Site Generators</h3><p>A more advanced option for building static websites is using a generator tool, that takes a bunch of pages and posts (written in plain-text or Markdown) saved in a local folder, and generates the formatted HTML website based on a template.</p><p>Static site generators provide the most freedom in changing a hand-coded template, its layout, styling or tags.</p><p><a href="https://gohugo.io/">Hugo</a> and <a href="https://jekyllrb.com/">Jekyll</a> are probably the most popular of this kind, but there are many <a href="https://www.staticgen.com/">more static site generators</a> out there. The generated static website can also be automatically published to a static hosting provider, like <a href="https://www.netlify.com/jamstack/">Netlify</a>.</p><p>Pages and posts can also be pushed to a remote repository like Git on <a href="https://github.com/">GitHub</a> or <a href="https://gitlab.com/">GitLab</a> for free, to have them auto-generate the static site on each change (commit), and even host it on their Pages service.</p><p>One other unique blogging platform that turns a folder into a blog, is <a href="https://blot.im/">Blot</a>.</p><h3 id="bonus-stock-media">Bonus: Stock Media</h3><p>Captivating images, videos, icons and fonts can add flair to a business website, as long as they're not excessive enough to dramatically increase the page size. Check-out the <a href="https://github.com/neutraltone/awesome-stock-resources">awesome stock resources</a> repository for a long list of public domain (free) stock media resources.</p><p>Overall, there are many smart options and public resources available for building a business website in less time &amp; effort than ever before. Good luck with your next one!</p>
			</section></div>]]>
            </description>
            <link>https://sprune.com/blog/state-of-self-serve-website-building-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24421780</guid>
            <pubDate>Wed, 09 Sep 2020 15:02:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No-Code vs. Pro-Code: A New Hope]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24421767">thread link</a>) | @ochiba
<br/>
September 9, 2020 | https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/ | <a href="https://web.archive.org/web/*/https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>When it comes to building apps, no-code is having its moment. Typeform is a shining example of how no-code is well suited for simple use cases, and here at JourneyApps we use it extensively. However, therein lies the problem: No-code’s sweet spot is simple use cases. This limitation of no-code tools has been well analyzed. [<a href="https://journeyapps.com/blog/low-code-road-to-software-enlightenment-part-1/">1</a>][<a href="https://www.alexhudson.com/2020/01/13/the-no-code-delusion/">2</a>]</p>

<p>If you want to build more sophisticated custom software, you essentially have two options:</p>

<ol>
  <li>
    <p>Use a no-code/low-code tool and jump through nasty hoops to implement the sophisticated parts of your app — which most often means writing actual code that needs to conform to the constraints of the tool.</p>
  </li>
  <li>
    <p>Use pro-code tools such as Swift/Objective-C, or frameworks like Xamarin/MAUI, etc.</p>
  </li>
</ol>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/1.png" alt="image"></p>

<p><em>Image: building anything beyond basic logic with a visual programming language ends up looking like this</em></p>

<h3 id="a-big-problem-that-needs-solving">A Big Problem That Needs Solving</h3>

<p>Both of the above approaches (using pro-code, or using a low-code platform’s pro-code extensibility) are time-consuming, although for different reasons. Both also require senior developer talent, while senior developers are as scarce as hen’s teeth.</p>

<p>The result is that many companies are highly constrained while executing on ambitious software and digital initiatives.</p>

<p>These are the companies that we serve. Enterprise developers have been building custom apps using code on JourneyApps since 2009.</p>

<p>Towards the end of 2019 we wanted to up the ante. We wanted to offer a new app development paradigm for companies with a large app backlog, especially where a big chunk of that backlog consisted of ambitious B2E and B2B apps.</p>

<p>We set two high level goals for ourselves: help companies write great software much more productively (especially those whose core focus is not software), and let them do this using modern software technologies and best practices, without the typical barriers.</p>

<h3 id="key-tenets-of-what-we-set-out-to-build">Key Tenets of What We Set Out to Build</h3>

<p>We decided that the best thing we could do was to build a next-generation IDE (as a complement to our full-stack app platform) that has the <strong>power and flexibility of pro-code</strong> at its core, but also has the high <strong>development velocity and easy adoption of no-code/low-code platforms</strong>.</p>

<p>From the start, we decided that some things are non-negotiable:</p>

<h4 id="1-coding-should-be-easy">1. Coding should be easy</h4>

<ul>
  <li>Creating a new app shouldn’t require any configuration or setup.</li>
  <li>Developers should be able to start coding immediately.</li>
</ul>

<h4 id="2-coding-should-have-a-fast-feedback-loop">2. Coding should have a fast feedback loop</h4>

<ul>
  <li>We will have a first-class IDE with real-time error checking, keyboard shortcuts, IntelliSense, etc.</li>
  <li>Developers should have access to a real debugger.</li>
  <li>We will have live, stateful hot reload on an actual device in development mode — not a time-consuming compile &amp; deploy process.</li>
</ul>

<h4 id="3-coding-in-the-ide-should-be-fun-and-relevant">3. Coding in the IDE should be fun and relevant</h4>

<ul>
  <li>We will not use a <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL</a>: We will support open-source programming languages – preferably those with gradual typing.</li>
  <li>We will not use convoluted proprietary visual interfaces.</li>
  <li>We will not use a proprietary “app store”. Developers must be able to import open source packages.</li>
  <li>The IDE should be easily accessible to junior developers.</li>
</ul>

<h4 id="4-coding-should-be-as-efficient-as-possible">4. Coding should be as efficient as possible</h4>

<ul>
  <li>We will provide developers with powerful functionality that can be used with minimal lines of code, and customized as required. This will include things like bi-directional relational offline data sync, dozens of UI components including Excel-like data grids, full audit trails, a cross-platform BLE engine, to name just a few.</li>
  <li>We will offer full git support with either hosted git, or external git providers (e.g. GitHub)</li>
  <li>We will support unit testing.</li>
  <li>We will support multiple environments, with easy portability of changes as new versions of software are moved from one environment to the next.</li>
</ul>

<h4 id="5-there-should-always-be-an-escape-hatch">5. There should always be an escape hatch</h4>

<ul>
  <li>There will be APIs for everything.</li>
  <li>We will allow developers to easily mix in fully custom HTML in their UIs, and allow those custom HTML components to communicate bidirectionally with the rest of the frontend stack, when required.</li>
  <li>There will be a Node.js environment in our cloud backend where developers can build any custom backend functionality, without any configuration or setup.</li>
</ul>

<h4 id="6-the-platform-should-be-secure-by-design">6. The platform should be secure by design</h4>

<h3 id="a-foundational-decision-building-a-web-ide">A Foundational Decision: Building a Web IDE</h3>

<p>We were taking the time to figure out a new approach to app development from first principles, so we had to make big design decisions with significant trade-offs. One major early decision was whether to build a web-based IDE or an installable desktop IDE.</p>

<p>The obvious question is: “Why an IDE on the web?”. We strongly believe that the recent developments across browser technology, transpiled languages and new approaches to software development (such as declarative UI) have made it possible to not only reach a desktop-grade level of quality in a web IDE, but also capitalize on the inherent benefits of the web paradigm.</p>

<p>Using this approach, we would have an IDE that is evergreen, cross-platform, cross-device, backed by modern UI and most importantly, ready for the future. Oh, and there would be nothing to install. Perhaps the biggest win, however, would be our ability to innovate quickly due to the open nature of web technologies and how quickly they evolve.</p>

<p>We’ll discuss other key design decisions in separate posts.</p>

<h3 id="unveiling-the-solution">Unveiling the Solution</h3>

<p>Today, we’re incredibly proud to announce <a href="https://journeyapps.com/platform/oxide/">OXIDE</a>. It’s the fruit of a lot of hard work by the JourneyApps team over the past year.</p>

<p>OXIDE helps both junior and senior developers build sophisticated cross-platform apps using JavaScript or TypeScript, complemented by visual tools. Apps can run natively on mobile and desktop operating systems, or in the browser as PWAs. Under the hood, OXIDE uses CRDTs [<a href="https://blog.kevinjahns.de/are-crdts-suitable-for-shared-editing/">3</a>] to enable live co-editing in teams, and it is deeply integrated with both GitHub and npm. In OXIDE, developers can switch between visual editing and coding for UI layout and schema design. Developers also have access to a first-class code debugging tool.</p>

<p>OXIDE is a fundamental pillar of the broader JourneyApps platform. Therefore, all apps inherit other flagship JourneyApps technologies out of the box — technologies that have seen around 10 years of R&amp;D and battle-hardening:</p>

<ul>
  <li>All apps ship with an enterprise-grade BaaS, and it’s easy to integrate with other data sources (in part because the platform is not based on a DSL).</li>
  <li>All apps are offline-first: Data is automatically synced to user devices, and loaded from the local database on each view. Querying data is fast. This avoids complicated state management and/or query cache systems. (What happens when data volumes scale? The platform provides highly configurable <a href="https://docs.journeyapps.com/reference/container/introduction-to-sync-rules">selective syncing.</a>)</li>
  <li>Each app is automatically provisioned with a Node.js serverless compute environment so that developers of all skill levels can add server-side logic and functionality.</li>
  <li>Developers have access to a rich built-in UI component set that is designed to work with data, with very little development overhead. No tweaking of styles or adding event listeners and state management to each component — this is handled for you.</li>
</ul>

<p>In general, JourneyApps takes the complexity out of the development cycle. We take care of the hard problems of enterprise software development (hosting, offline data sync, mobile app builds, backend APIs, deployment tooling, audit trails, and more) so that developers can focus on core app requirements and maximize the rate of innovation at their companies.</p>

<p>Working in OXIDE looks like this:</p>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/2.png" alt="image"></p>

<p>And here’s a view of a debugging session. The app can be seen on the bottom right (running on macOS), the Chrome developer tools on the top right, and OXIDE on the left:</p>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/3.png" alt="image"></p>

<p>Try it out and let us know what you think — <a href="https://accounts.journeyapps.com/portal/free-trial?utm_source=engineering-blog&amp;utm_medium=internal&amp;utm_campaign=engineering-blog">start building</a>.</p>


            </div></div>]]>
            </description>
            <link>https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24421767</guid>
            <pubDate>Wed, 09 Sep 2020 15:01:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing New Cryptography for Non-Standard Threat Models]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24421073">thread link</a>) | @some_furry
<br/>
September 9, 2020 | https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Since the IETF’s CFRG decided to recommend OPAQUE as a next-generation <a href="https://soatok.blog/2020/04/21/authenticated-key-exchanges/">Password Authenticated Key Exchange</a>, there has been a lot of buzz in the cryptography community about committing authenticated encryption (known to the more academically inclined as Random Key Robustness), because OPAQUE requires <a href="https://mailarchive.ietf.org/arch/msg/cfrg/2W9LoeeiRzAiTWVnDsyxvjYPPmo/">an RKR-secure AE scheme</a>.</p>



<p>Random Key Robustness is a property that some symmetric encryption modes have, where it’s not feasible to decrypt a valid (ciphertext, tag) pair into two different plaintexts if both recipients are using different keys.</p>



<p>To illustrate this visually:</p>



<div><figure><img data-attachment-id="1348" data-permalink="https://soatok.blog/robustness/" data-orig-file="https://soatok.files.wordpress.com/2020/09/robustness.png" data-orig-size="750,550" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="robustness" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/robustness.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/robustness.png?w=580" src="https://soatok.files.wordpress.com/2020/09/robustness.png" alt="An example of random key robustness: encrypting two different images, with two different keys, can produce an identical stream of bits (ciphertext + tag)."><figcaption>RKR-secure ciphers don’t let people produce the same ciphertext+tag from two different plaintexts, with two different keys. You might be able to create an identical ciphertext, but the authentication tag will differ. (Art by <a href="https://twitter.com/SwizzlestixUK">Swizz</a>.)</figcaption></figure></div>



<p>In the wake of the CFRG discussion, it became immediately clear that <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">AES-GCM doesn’t meet this requirement</a>.</p>



<p>What wasn’t immediately clear is <a href="https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/">that AES-GCM-SIV also falls short</a>. But don’t take my word for it, Sophie Schmieg worked out the math in the linked post, which I highly recommend reading.</p>



<p>This isn’t to say that AES-GCM or AES-GCM-SIV are doomed, or should be deprecated. You probably don’t even care about Random Key Robustness in most of the places you’d use either algorithm! But if you are doing something where RKR actually matters, you probably care a lot. And it certainly violates the principle of least astonishment.</p>



<p>ChaCha20-Poly1305 won’t save you here either, since this is a property that message authentication codes based on cryptographic hash functions (e.g. HMAC) provide, but polynomial MACs (GMAC, Poly1305, etc.) do not.</p>



<p>So, if every standardized and widely-supported AEAD construction fails to provide RKR security, what’s a software engineer to do?<em> <a href="https://vnhacker.blogspot.com/2020/08/so-you-want-to-roll-your-own-crypto.html">Roll their own crypto</a>?!</em></p>



<div><figure><img data-attachment-id="61" data-permalink="https://soatok.blog/glitch-ecb/" data-orig-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="glitch-ecb" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png?w=224" data-large-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png?w=224" src="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png" alt=""><figcaption>Don’t actually do that. (Art by <a href="https://twitter.com/SwizzlestixUK">Swizz</a>.)</figcaption></figure></div>



<p>If you’re always on a well-tread path with a well-defined, standard threat model (i.e. client-server application accessible via TLS 1.3, possibly storing hashed passwords server-side), then rolling your own crypto isn’t just dangerous; it’s wholly unnecessary.</p>



<h2 id="coping-with-nonstandard-threat-models">Coping with Non-Standard Threat Models</h2>



<p>Systems that require Random Key Robustness do not fall within the standard threat model of AEAD cipher constructions.</p>



<p>However, RKR is far from the only scenario in which application developers might find themselves without a clear solution. Another example that comes up a lot:</p>



<blockquote><p>“I need to encrypt data in a relational database, but still somehow use it in SELECT queries.”</p><cite>— Far too many damn developers who haven’t heard of <a href="https://ciphersweet.paragonie.com/">CipherSweet</a>.</cite></blockquote>



<p>The first thing that you should do is clearly document your requirements and what attacks your system must protect against. Any undefined attack vector in your model should be assumed to be a vulnerability in your design. (This gets into <a href="https://www.cryptofails.com/post/75204435608/write-crypto-code-dont-publish-it">Unknown Unknowns</a> territory quickly.)</p>



<p>And then you should have a cryptographer review your design, and then have a cryptography engineer build it for you.</p>



<p><strong><em>But where’s the fun in that?</em></strong></p>



<div><figure><img data-attachment-id="1332" data-permalink="https://soatok.blog/soatoktelegrams2020-07/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-07" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>This would be a very boring blog post if I left it at that! (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>Instead of copping out with sane and reasonable advice, let’s actually walk through the process. At the end of this post, I’ll share a toy example I cooked up for this blog post.</p>



<h2 id="designing-new-cryptography">Designing New Cryptography</h2>



<h3 id="understand-the-problem">First, Understand the Problem</h3>



<p>Why don’t AES-GCM, etc. provide Random Key Robustness? Because they’re built with universal hash functions rather than cryptographic hash functions.</p>



<p>Cryptographic hash functions have different properties (i.e. preimage resistance and collision resistance) that make it significantly difficult to calculate two different authentication tags under two different keys. Attacking HMAC-SHA-256 in this way is about <a href="https://pthree.org/2016/06/19/the-physics-of-brute-force/">as expensive as brute forcing a 128-bit AES key</a>. (Good luck with that!)</p>



<p>However, cryptographic hash functions are much slower than polynomial MACs, and using them in a construction like HMAC approximately doubles the slowness.</p>



<p>You might be tempted to just hash they key and the message together to save on CPU cycles, but that’s actually <a href="https://blog.skullsecurity.org/2012/everything-you-need-to-know-about-hash-length-extension-attacks">not safe for the hash functions nearly everybody uses</a> (due to length extension attacks).</p>



<p>It logically follows that, <strong>if we had an AEAD cipher construction based on a hash function, we could have RKR security</strong>.</p>



<div><figure><img data-attachment-id="1331" data-permalink="https://soatok.blog/soatoktelegrams2020-06/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-06" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=512" alt="OwO *notices your cryptogrpahic robustness*" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Now we’re getting somewhere! (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<h3 id="prior-art">Look At Prior Art</h3>



<p>Before the days of AES-GCM and ChaCha20-Poly1305, there were a lot of ad hoc constructions used everywhere based on <a href="https://soatok.blog/2020/07/12/comparison-of-symmetric-encryption-methods/#aes-gcm-vs-aes-cbc">AES-CBC and HMAC</a>. (In that era, everyone used HMAC-SHA1, but don’t do that.)</p>



<p>However, there are a number of problems with ad hoc CBC+HMAC that we don’t want to reintroduce in modern systems:</p>



<ol><li>If you forget to include the initialization vector in the HMAC tag, you give attackers free reign over the first 16 bytes of the decrypted plaintext without having to break the MAC.</li><li>The order of operations (Encrypt-then-MAC, MAC-then-Encrypt, Encrypt and MAC) matters tremendously.</li><li>CBC+HMAC is usually implemented in application-layer code, but the security of such a construction depends heavily on the availability and utilization of <a href="https://soatok.blog/2020/08/27/soatoks-guide-to-side-channel-attacks/#string-comparison">constant-time functions</a>.</li><li>There is no standard format for CBC+HMAC, nor the order of operations for what gets fed into the MAC.<ul><li>IV + ciphertext? Ciphertext + IV?</li></ul><ul><li>Append the MAC, or prepend it?</li></ul></li><li>CBC+HMAC is only an AE mode, there is no room for additional authenticated data. If you try to naively shove extra data into the HMAC, <em>now you have to worry about canonicalization attacks</em>!</li><li>CBC mode requires padding (usually PKCS #7 padding), whereas cipher modes based on CTR do not.</li></ol>



<p>This is among the long list of reasons why cryptographers have spent the past decade (or longer) pushing developers towards AEAD modes.</p>



<p>Boring cryptography is good cryptography!</p>



<div><figure><img data-attachment-id="1210" data-permalink="https://soatok.blog/soatok_stickerpack_ind_cca2/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Soatok_STICKERPACK_IND_CCA2" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=512" alt="This isn't IND-CCA2 Secure!" srcset="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png 512w, https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>You never want to hear this about your design. (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>Make sure you clearly understand the risks of the components other constructions have used.</p>



<h3 id="sketch-first-draft">Sketch Out A First Draft</h3>



<p>By now, it should be clear that if we have an Encrypt-then-MAC construction, where the MAC is based on a cryptographic hash function (e.g. SHA-256), we may be able to attain RKR security.</p>



<p>With that in mind, our sketch will probably look something like this:</p>



<ul><li>Encrypt(K1, M, N) -&gt; C<ul><li>Where Encrypt() is AES-CTR or equivalent</li></ul></li><li>Auth(K2, C, A) -&gt; T<ul><li>Where Auth() wraps HMAC-SHA2 or equivalent</li><li>How we feed C and A into the underlying MAC is important</li></ul></li><li>???? -&gt; K1, K2</li></ul>



<p>We still have to define some way of splitting a key (K) into two distinct keys (K1, K2). You never want to use a cryptographic key for more than one purpose, after all.</p>



<h3>Key-Splitting and Robustness</h3>



<p>Your encryption key and authentication key should be different, but they should also derived from the same input key! This is mainly to protect implementors from having independent keys and accidentally creating a forgery vulnerability.</p>



<p>There are several different ways you can split keys:</p>



<ol><li>Just use SHA-512(k), then cut it in half. Use one half for encryption, the other for authentication.</li><li>Use HMAC-SHA256(k, c1) and HMAC-SHA256(k, c2), where c1 and c2 are distinct (yet arbitrary) constants.</li><li>Use HKDF. This works with any secure cryptographic hash function, and was specifically designed for situations like this. HKDF also supports salting, which can be used to randomize our derived keys.</li></ol>



<p>We can really pick any of these three and be safe, but I’d advise against the first option. HKDF uses HMAC under-the-hood, so either of the latter options is fine.</p>



<h3 id="speed">Can We Make it Faster?</h3>



<p>What if, instead of HMAC-SHA256, we used <a href="https://github.com/BLAKE3-team/BLAKE3">BLAKE3</a>?</p>



<div><figure><img data-attachment-id="1362" data-permalink="https://soatok.blog/blake3/" data-orig-file="https://soatok.files.wordpress.com/2020/09/blake3.png" data-orig-size="1251,913" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blake3" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/blake3.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/blake3.png?w=580" src="https://soatok.files.wordpress.com/2020/09/blake3.png" alt=""><figcaption>BLAKE3’s performance compared with other hash functions.</figcaption></figure></div>



<p>BLAKE3’s advertised 6.8 GiB/s can be even faster than <a href="https://crypto.stackexchange.com/a/60269">Poly1305 or GHASH</a> (and BLAKE3’s speed really shines through with long messages, due to its extreme parallelism through Merkle trees).</p>



<h3 id="chacha-vs-aes">In Favor of ChaCha over AES</h3>



<p>It’s no secret that <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">I’m not a fan of AES</a>. It’s not the mathematical properties of AES that bother me, it’s the 128-bit block size and the fact that software implementations have to decide between being fast or being secure.</p>



<div><figure><img data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Me, whenever I find an insecure software AES implementation. (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>ChaCha’s 256-bit security level is easier to justify: The underlying PRF state is 512 bits (which implies an approximately 256-bit security level) and the keys are always 256 bits.</p>



<p><s>Furthermore, if you’re building ChaCha and BLAKE3 in the same codebase, you could reuse some components (i.e. the compression function, G). This is very desirable if you’re trying to ship a small amount of code (e.g. embedded systems).</s> EDIT: <a href="https://twitter.com/veorq">One of the BLAKE3 authors</a> informed me that I’m mistaken about this: “[N]ope, not exactly the same logic (rotations in different direction)”.</p>



<h3 id="other-desirable-properties">Other Desirable Security Properties</h3>



<h4 id="nonces">Nonce Nonsense</h4>



<p>One of the biggest problems with standard AEAD modes is that they explode gloriously when you reuse a nonce. There are two ways out of this peril:</p>



<ol><li>Use a nonce misuse resistant AEAD construction (AES-GCM-SIV, etc.).<ul><li>For prior art on nonce-misuse resistant cipher modes based on ChaCha, check out <a href="https://eprint.iacr.org/2020/067">DAENCE</a>.</li></ul></li><li>Use large nonces (e.g. XChaCha20 uses 192-bit nonces) and generate them randomly, so the probability of nonce reuse becomes negligible.</li></ol>



<p>Since we’re already planning on using a hash function to derive subkeys (one for encryption, one for authentication), it makes sense to also accept a longer nonce than our stream cipher demands. The excess bytes can be passed to our KDF without significant risk or additional overhead.</p>



<p>Since the IETF’s ChaCha20 variant expects a 96-bit nonce, designing our construction to support 256-bit nonces means we can pass the first 160 bits of the nonce to the KDF and the latter 96 bits to the stream cipher. You can expect a single KDF collision after 2^80 encryptions, but it will almost certainly occur with a different nonce.</p>



<h4 id="safe-mac-canonicalization">Safe MAC Canonicalization</h4>



<p>We want to ensure it’s …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/">https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24421073</guid>
            <pubDate>Wed, 09 Sep 2020 14:03:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling Word for Windows v1.1a]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24420215">thread link</a>) | @elvis70
<br/>
September 9, 2020 | https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a | <a href="https://web.archive.org/web/*/https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1596161668354" id="item-5f237e4f45d6b8696edfa45b"><div><div><div data-block-type="2" id="block-ad599947c0ce6afbff0d"><div><p>Opus is the code name that developers inside Microsoft used for Microsoft Word for Windows v1.1a - let’s compile it from source code and see if it runs! Microsoft Word for Windows v1.1a is © Copyright Microsoft 1989.</p><h2><strong>Contents</strong></h2><ol data-rte-list="default"><li><p>Introduction</p></li><li><p>Background</p></li><li><p>Can I Compile This Code?</p></li><li><p>Intel CPU History</p></li><li><p>DOS Memory Types</p></li><li><p>Installing DOS</p></li><li><p>Make The Disk Bootable</p></li><li><p>Configuring DOS</p></li><li><p>DOS Memory Management</p></li><li><p>Compiling Opus</p></li><li><p>Running Opus</p></li></ol><h2><strong>1. Introduction</strong></h2><p>This blog documents how to take the <a href="https://computerhistory.org/blog/microsoft-word-for-windows-1-1a-source-code/">source code</a> and turn it into to a working Windows application. The compiler and development tools run in the MS-DOS operating system because there were no Windows development tools available in 1989. </p><p>Note: I’m going to refer to “DOS” throughout this blog. This means I’m talking about Microsoft MS-DOS although most of it equally applies to IBM PC-DOS and most other DOS variants.</p><p>If you are new to the DOS operating system, I recommend following along using a copy of Microsoft MS-DOS v6.22, a June 1994 version of DOS (the last major version released) and has all the tools we need to get this working (with possibly one exception that I’ll cover off later).  </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596330539417_20476"><div><h2><strong>2. Background</strong></h2><p>Development on the word processor called Microsoft Word for DOS was started by Richard Brodie and others in 1982. Richard was hired from Xerox Parc as he was familiar with the, at the time, futuristic word processor.</p><p>Word for DOS was first released in 1983 and bundled with an early version of MS-DOS. It used (primitive) graphics and supported the use of a mouse, but was released to mixed reviews.&nbsp;</p><p>Word v2.0 for DOS was released in 1985 and supported EGA graphics and had a spell-checker.&nbsp;</p><p>Word v3.0 for DOS was released in 1986 and supported Hercules graphics and additional printers, wow!&nbsp;</p><p>Word v4.0 for DOS was released in 1987 and supported VGA graphics and had both text and graphics modes.&nbsp;</p><p>Word v5.0 for DOS and OS/2 as a 16-bit application.&nbsp;</p><p>An upgrade to Word v5.5 in 1989 added Windows/Mac-like windows and menus, a forerunner of Word for Windows that would be released later that year.&nbsp;</p><p>Development of the first WYSIWYG* word processor for Microsoft Windows was done between 1988 and 1989, resulting in the version released by the Computer History Museum.</p><p>*WYSIWYG = What You See Is What You Get</p><p>Read more about the history and download the source code from the Computer History Museum here:</p><p><a href="https://computerhistory.org/blog/microsoft-word-for-windows-1-1a-source-code/">https://computerhistory.org/blog/microsoft-word-for-windows-1-1a-source-code/</a></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_58803"><div><h2><strong>3. Can I Compile This Code?&nbsp;</strong></h2><p>Yes! How? You could use a vintage PC or a relatively modern one that can boot in (legacy) BIOS mode or configure a hypervisor to run a virtual PC. All the tools you need are in the source code dump in the link above. They all run in DOS so let’s talk about how this is supposed to work.</p><p>I’ll be using VMware Fusion on a Mac to demonstrate but you can use any suitable old hardware or hypervisor that will run MS-DOS. Once DOS is installed, you’ll need to check how much memory is available. That requires a basic understanding of how DOS “sees” the hardware. Since the compiler appears to need expanded memory, I’ll describe how that type of memory is accessed and how to configure DOS to make it available to the compiler.</p><p>Also, the file set is quite large (for a DOS application), so I recommend you can make things easier by creating a CD-ROM image of the source files so they can be copied to the DOS machine in one go, however this also needs device drivers for it to work on the DOS operating system so I’ll cover that here also.</p><p>The source code is interesting as the proprietary compiler requires a computer with at least a 386 processor and 4Mb of RAM. This exceeds the specs of many PCs back in the day and certainly would have been considered “high end” at the time as most had 1MB of RAM tops with only 640KB available for use by typical DOS applications. Of that DOS itself uses a lot of memory and the apps use what’s left. So, how much memory does our machine have? How do we give it some more? More on this later.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_50297"><div><h2><strong>4. Intel CPU History</strong></h2><p>The reason DOS requires memory management is linked closely to the history of the CPUs it was designed to run on. Because a lot of the early programs were built with assembler /&nbsp; machine code, the DOS operating system was very tightly integrated with the CPU it ran on. As a result it inherited the limits of these CPUs and those CPUs imposed strange limits due to each generation of CPU needing to support the code base of all of the CPUs that preceded it.</p><p>In 1979 the 8-bit Intel 8086/8088 processors could address 1024KB or 1MB of RAM (8-bit data bus, 16-bit memory registers)</p><p>In 1982 the 16-bit Intel 80286 processor could address up to 16MB of RAM (16-bit data bus, 24-bit address space*)</p><p>In 1985 the 32-bit Intel 80386 (and later 486) processors could (theoretically) address up to 4096MB or 4GB of RAM**&nbsp;</p><p>Modern 64-bit processors have 40-bit, 52-bit and 64-bit addressable memory architectures so they can support from 1TB to 4PB of RAM!!!!!!!</p><p>Note*: a 24-bit address space is equivalent to 2 to the power of 24 × 1 byte = 16,777,216 bytes or 16MB.</p><p>Note**:&nbsp; a 32-bit address space is 2 to the power of 32 x 1 byte = 4,294,967,296 bytes or 4GB but a lot less than 1GB was usually installed in 386 PCs due to the motherboard limits (and massively high cost) of RAM at that time.</p><p>The history of DOS and Windows is littered with issues created by backward compatibility and memory management limits governed by early Intel processor architecture.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_41559"><div><h2><strong>5. DOS Memory Types</strong></h2><p>There are five memory areas addressable by DOS. Each of these are accessible using one or two device drivers invoked in the CONFIG.SYS at boot time. HIMEM.SYS provides access to Extended Memory and EMM386.EXE provides access to Expanded Memory. So here’s a quick guide to these memory types.&nbsp;</p><p><strong>Conventional Memory</strong>: is memory from 0 to 640 KB (or 651,264) also called the Lower Memory Area (LMA)</p><p><strong>Upper Memory Area</strong>: UMA is memory from 640KB to 1024KB or 1MB also referred to as the Upper Memory Area (UMA) also called Upper Memory Blocks (UMB)</p><p><strong>Extended Memory Specification</strong>: XMS is memory addresses from 1MB up to 64MB but this spec also defines the UMA because DOS does not have access to UMA without support from HIMEM.SYS</p><p><strong>Expanded Memory Specification</strong>: EMS uses a 64KB page frame defined in Upper Memory to provide access to memory above 1MB. DOS can use both XMS and EMS when the AUTO parameter is specified or is disabled when loading EMM386.EXE with the NOEMS parameter. EMM386 and other memory managers, emulate expanded memory in the extended memory area, not confusing at all!</p><p><strong>High Memory Area</strong>: HMA is 64KB just above 1MB that DOS can load itself into at boot time using DOS=HIGH in the CONFIG.SYS</p><p>Conventional memory is where the old school DOS applications reside. They can only use memory from 0-640Kb and because some of this is taken up by DOS itself, they may have access to less than 500KB of RAM at runtime. This often limits applications that run in so-called “real mode” that is to say 16-bit apps limited to conventional memory. Real mode is called because real memory addresses are mapped to addressable memory within the application.</p><p>This was fine for just a few short years until 640KB became a limiting factor for more complex applications AKA games! More memory was also needed for newly developed Windows applications so along came the Extended Memory Specification (XMS). Memory above the 1MB made addressable by 16-bit programs. This was introduced in 286 processors which implemented protected mode to get access to memory above those DOS limits but also supported conventional memory access in real mode, switching between modes when needed.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_20945"><div><h2><strong>6. Installing DOS</strong></h2><p>Your options are to use actual floppy disks and a USB floppy disk drive, create floppy disk images from your physical floppy disks or download floppy disk images from sites like WinWorld.</p><p>Your physical or virtual machine will need a minimum of 4MB of RAM and a maximum of 32MB and a maximum of 512MB hard disk with a single FAT16 partition on it. If the hard disk is physically larger than 512MB, limit the size of the first partition to the maximum size your version of DOS can address. For compatibility, limit this first partition to 512MB or less.</p><p>If the machine has the minimum specs shown above, boot from the first DOS diskette. In versions later than version 5.0, an installer will run. Follow the instructions choosing all the default values for now. We’ll experiment with install options in a later blog post. If you were not prompted for an installation you can often find the INSTALL.EXE app on the first diskette, or set things up manually by partitioning the hard disk manually. See the section below called “Make the boot disk bootable…”.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596258922407_12300"><div><h2><strong>7. Make The Hard Disk Bootable</strong></h2><p>If you boot from floppy in the previous step but don’t yet have an accessible hard disk or have a copy of DOS that does not include an installer then we can install it manually. </p><p>Run FDISK from the floppy disk and view the existing partition structure by choosing option 4 and press enter.</p><p>If there is an existing partition it should show that there is up to 511 Mbytes in a FAT16 filesystem and the status column should show that is it Active by having a “A” character in the Status column. </p><p>If not, we’ll create one; return to the main menu by pressing Escape.</p><p>Type option 1 then press enter. Type 1 and press enter again to create a new Primary Partition. It will complain if an existing partition is already there. If you are brave you can remove that and create anew one or just use the one that’s already there.</p><p>Once it’s done, return to the main menu and choose option 2 and make the new partition active, then exit FDISK. Back at the DOS prompt we need to format the disk to make that new partition readable and we need to transfer the DOS boot system to the disk using the “/s” switch on the format command. The “/v” option will prompt for a new volume name.</p><pre><code>format c: /s /v</code></pre><p>Follow the prompts and give it a valid 11-character volume name. This will create a bootable disk but before you reboot, create a …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a">https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a</a></em></p>]]>
            </description>
            <link>https://richardlewis.org/blog/2020/7/31/opus-compiling-word-for-windows-1-1a</link>
            <guid isPermaLink="false">hacker-news-small-sites-24420215</guid>
            <pubDate>Wed, 09 Sep 2020 12:23:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: XML Fiddler – tool for quick XML exploration]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24419947">thread link</a>) | @masa331
<br/>
September 9, 2020 | https://masa331.github.io/xml_fiddler/ | <a href="https://web.archive.org/web/*/https://masa331.github.io/xml_fiddler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://masa331.github.io/xml_fiddler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24419947</guid>
            <pubDate>Wed, 09 Sep 2020 11:45:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most annoying website features I face as a blind person]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24419169">thread link</a>) | @gostsamo
<br/>
September 9, 2020 | https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/ | <a href="https://web.archive.org/web/*/https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>These are the five most annoying inaccessible web elements I face as a blind screen reader user every day, and how to fix them.
</span>
					</p><div>
						<p><span>For blind and visually impaired people like me, accessibility is the difference between us being able to use a website and clicking off it.&nbsp;</span></p>
<h2>How screen readers work</h2>
<p><span>Screen readers allow blind and visually impaired people to use computers, phones and tablets independently. Most screen readers use software, and a Text To Speech (TTS) engine, which is what converts the text from the screen reader into speech. Screen readers convert the text displayed on screen into a format that blind users can process.</span></p>
<p><span>Screen readers read out loud everything that’s on the screen and allow people to navigate using touch gestures and shortcut keys. They also work with other output devices such as a braille display.</span></p>
<p><span>As a screen reader user, here are the most common issues I encounter on a daily basis.&nbsp;</span></p>
<h2>Unlabelled links and buttons</h2>
<p><span>Screen reader users rely on links and buttons to navigate around a website and to find the information we need. If links and buttons are not labelled correctly or if at all, then it makes it difficult for screen reader users to find the information they need. Ultimately, unlabelled links make it much harder to navigate the website easily, quickly and independently.</span></p>
<p><span>For example, when linking to an about page, ‘click here’ doesn’t give any clue as to where it leads to, but ‘find out more about who we are’ is clear.</span></p>
<p><span>If links and buttons are labelled correctly, screen readers can read the label out loud. It means that blind and visually impaired people don’t have to press the link or button without knowing where it will take them.</span></p>
<p><span>As well as unlabelled elements, links and buttons that do not have a clear description are also really frustrating. They must have a clear description of where they will lead to when pressed, rather than ‘click here’. Never make your users guess where a link will take them or force them into a trial-and-error situation. This makes for tedious user experience.</span></p>
<h2>No image descriptions</h2>
<p><span>This is probably the most common issue I encounter when browsing the web.&nbsp;</span><span>Using image descriptions is essential for accessibility. Image descriptions are also known as alt text (alternative text) which is a written description of an image.</span></p>
<p><span>Screen readers read image descriptions out loud. This means that blind and visually impaired people can understand the content of the image in an accessible way.&nbsp;</span><span>If images do not have alt text, then screen readers will simply say “image” or “graphic” which gives no context or meaning.</span></p>
<p><span>Images often convey valuable information. It’s therefore important that people with a visual impairment can access this information as well.&nbsp;</span><span>Alt text should be clearly written and give an accurate description of the image.</span></p>
<p><strong>Check out <a href="https://bighack.org/how-to-write-better-alt-text-descriptions-for-accessibility/">our tips for writing better alt text</a> to ensure your images are fully accessible.</strong></p>
<h2>Poor use of headings</h2>
<p><span>For quick and easy navigation, many screen reader users navigate using various elements on the page such as headings. They are a great way to find the information we need quickly and effectively. Especially when they follow a logical heading structure with H1s, H2s and H3s helping to prioritise the content.</span></p>
<p><img src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" alt="Logical heading structure begins with Heading 1, with Heading 2 sitting beneath heading 1. Heading 3 sits within heading 2 and so on." width="1958" height="1236" srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" sizes="(max-width: 1958px) 100vw, 1958px" data-srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" data-src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>If websites don’t use headings, it means screen reader users are unable to use the keyboard shortcuts to navigate through the webpage this way. If that’s the case, we have to resort to tabbing or arrowing through a long web page to find the information we need.</span></p>
<p>Headings also help to break up the web content visually and improve readability. Other elements that screen reader users use to navigate webpages include links, lists or landmarks.</p>
<h2>Inaccessible web forms</h2>
<p><span>Most websites use forms in one way or another. Whether it’s to help you search for a product or to get in touch through a contact form. However, when these forms are not labelled, or not labelled correctly, it means we cannot use them.</span></p>
<p><span>For example, if a search box is not labelled, it means screen reader users have no idea of the purpose of that box. It means people who use screen readers cannot access the same functionality.</span></p>
<p><span>Contact forms are an effective way for customers to get in touch with your brand or business. And as a screen reader user, there’s nothing more frustrating than these forms being labelled incorrectly.</span></p>
<p><span>Especially CAPTCHA checkout requirements. Without an option to hear the audio, it’s not accessible. It means we are unable to fill in the form independently. I often have to enlist help from a sighted person, but this isn’t possible for everyone.</span><b>&nbsp;</b></p>
<h2>Auto-playing audio and video</h2>
<p><span>Most people will know how annoying it is to load a web page with noisy adverts that start playing suddenly. But for screen reader users, it can be even more alarming. When video or audio starts playing automatically, it can drown out the voice of the screen reader. This makes it harder to find the pause or stop buttons.</span></p>
<p><span>(And if these buttons are unlabelled, then it’s practically impossible for me to stop the video quickly which causes extra frustration.) If I’m unable to stop the sound or video, I normally click off.</span></p>
<p><span>The solution? Make sure there’s no auto-playing video or audio when your website loads. If you really want to use video, make sure the audio is muted and the user can pause, stop or hide the media player.</span></p>
<p><span>These issues may seem small to sighted users. But they’re the difference between me being able to use a website independently or not. And they make a huge difference when implemented correctly.</span></p>
					</div></div>]]>
            </description>
            <link>https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24419169</guid>
            <pubDate>Wed, 09 Sep 2020 09:39:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How WebAssembly Changes Software Distribution]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24419081">thread link</a>) | @ingve
<br/>
September 9, 2020 | https://desiatov.com/why-webassembly/ | <a href="https://web.archive.org/web/*/https://desiatov.com/why-webassembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="51"><p>If you had any experience with Windows and Internet Explorer in the 90s,
quite probably you remember <a href="https://en.wikipedia.org/wiki/ActiveX">ActiveX</a> controls. Most
frequently this involved bulky popups on pages with these controls having to display something
more complex than a few blocks of text.</p>
<p><img src="https://desiatov.com/activex-0f260342e5426a0cc883966575235fe3.gif" alt="Internet Explorer displaying an alert that requires ActiveX controls to be installed"></p>
<p>Or, remember <a href="https://en.wikipedia.org/wiki/Java_applet">Java applets</a>? They became
available in 1995, and later they weren’t limited to just Windows and Internet Explorer. I remember
I had to use Java applets on macOS as recently as 2013, which chronologically is closer to the
present time than the 90s are. (Feeling so old anyway! 👴)</p>
<p>
  <a href="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-86a48.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Microsoft's Application and Network Access Portal that displays a warning about user's browser not
allowing Java applets to run" title="" src="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-f8fb9.jpg" srcset="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-e8976.jpg 148w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-63df2.jpg 295w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-f8fb9.jpg 590w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-86a48.jpg 624w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>Seems like ActiveX and Java applets were necessities mostly in the enterprise world, but
Macromedia Flash (later known as <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Adobe Flash</a>)
was certainly much more widely known to consumers. It was a requirement in the early days of streaming
video (even <a href="https://www.theverge.com/2015/1/27/7926001/youtube-drops-flash-for-html5-video-default">YouTube required
Flash</a>
to work back then!), but also a major driver in browser gaming in late 2000s and early 2010s.
We certainly could blame Flash for making our browser windows look like this:</p>
<p>
  <a href="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-02110.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Browser page warning about Adobe Flash Player not being installed" title="" src="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-f8fb9.jpg" srcset="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-e8976.jpg 148w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-63df2.jpg 295w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-f8fb9.jpg 590w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-02110.jpg 606w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>While ActiveX has seemingly failed to reach a significant adoption, Microsoft made yet another
attempt with <a href="https://en.wikipedia.org/wiki/Microsoft_Silverlight">Silverlight</a>:</p>
<p>
  <a href="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-da6d6.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Microsoft Silverlight page with an installation button" title="" src="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-f8fb9.jpg" srcset="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-e8976.jpg 148w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-63df2.jpg 295w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-f8fb9.jpg 590w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-da6d6.jpg 831w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>In the meantime, Google was working on <a href="https://en.wikipedia.org/wiki/Google_Native_Client">its own thing for
Chrome</a>:</p>
<p>
  <a href="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-5d9c9.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Google Native Client plug-in settings in the Chrome browser" title="" src="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-fb8a0.png" srcset="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-1a291.png 148w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-2bc4a.png 295w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-fb8a0.png 590w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-5d9c9.png 650w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>It would be fair to say that these attempts failed to establish wide adoption, especially
after both consumers and businesses started shifting to mobile. Here’s how all these forays ended
according to Wikipedia:</p>
<blockquote>
<p>Microsoft dropped ActiveX support from the Windows Store edition of Internet Explorer 10 in
Windows 8. In 2015 Microsoft released Microsoft Edge, the replacement for Internet Explorer with
no support for ActiveX, this marked the end of the technology in Microsoft’s web browser
development.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=ActiveX&amp;oldid=969259090#Platform_support">“ActiveX”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>Beginning in 2013, major web browsers began to phase out support for the underlying technology
applets used to run, with applets becoming completely unable to be run by 2015–2017. Java applets
were deprecated since Java 9 in 2017 and removed from Java SE 11 (18.9), released in September
2018.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=Java_applet&amp;oldid=972322018">“Java applet”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>In July 2017, Adobe announced that it would declare Flash to be end-of-life at the end of 2020,
and will cease support, distribution, and security updates for Flash Player.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Adobe_Flash#End_of_life">“Adobe Flash”</a> article on
Wikipedia.</small></p>
<blockquote>
<p>There is no Silverlight plugin available for Microsoft Edge. It has not been supported by Google
Chrome since September 2015 or by Firefox since March 2017.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Microsoft_Silverlight#Demise">“Microsoft Silverlight”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>On October 12, 2016, a comment on the Chromium issue tracker indicated that Google’s Pepper and
Native Client teams had been destaffed.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=Google_Native_Client&amp;oldid=973604804">“Google Native
Client”</a> article on
Wikipedia.</small></p>
<h2>But JavaScript solved all these problems, didn’t it?</h2>
<p>Most of these browser add-ons were introduced before modern JavaScript and HTML5 became available,
so one could argue you no longer need browser add-ons at all. Well, <a href="https://daringfireball.net/linked/2017/06/27/web-without-javascript">some
purists</a> even say browsers
should have never supported JavaScript or any scripting whatsoever in the first place. Nevertheless,
there are enough use cases for browser scripting and browser apps in general that are hard to avoid.
When looking at the history of browser plugins in general, it’s hard not to notice a few themes:</p>
<ul>
<li>Distributing productivity apps via browsers is convenient in a lot of cases.</li>
<li>Browser gaming made a lot of sense, especially for casual games.</li>
<li>In both of these scenarios browsers had to display something more complex than text and a few
static images.</li>
</ul>
<p>
  <a href="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Flash Element TD game screenshot with a classic tower defense battle field" title="" src="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg" srcset="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-399a3.jpg 148w,
https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg 288w" sizes="(max-width: 288px) 100vw, 288px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>The modern casual <a href="https://en.wikipedia.org/wiki/Tower_defense">tower defense game genre</a>
arguably was reborn due to the popularity of Adobe Flash and browser gaming, with <a href="https://en.wikipedia.org/wiki/Flash_Element_TD">Flash Element
TD</a> being a classic example.</small></p>
<p>Even though native apps were (and in many situations still are) objectively better for users, early
browser apps were attempting to build their own ad-hoc app stores before the App Store existed.
You didn’t have to buy a CD with an application and install it and manage it on your disk. You
didn’t have to install updates manually and migrate your data. There was no need to uninstall apps,
you just close a corresponding browser tab and forget about it.</p>
<p>And when browser scripting capabilities became advanced enough, some people started seeing the
allure of making a browser version of their app the only version they provided. Browsers are
cross-platform, aren’t they? Just wrap your JavaScript app code in a browser-like container (say
<a href="https://en.wikipedia.org/wiki/Electron_(software_framework)">Electron</a>) and distribute that instead
of your native app. </p>
<p>But eventually not only the JavaScript APIs became more complex, the language itself could no longer
accommodate what developers wanted. Not everyone liked JavaScript syntax (remember
<a href="https://en.wikipedia.org/wiki/CoffeeScript">CoffeeScript</a>?) or semantics (I couldn’t help but
notice that <a href="https://en.wikipedia.org/wiki/TypeScript">TypeScript</a> has grown in popularity in recent
years). But it’s hard to transpile an arbitrary programming language to JavaScript, the latter was
not built with that goal in mind.</p>
<p>Corollary, the JavaScript interpreter itself has both memory and performance overhead. Having a
garbage collector built in makes it even harder to transpile languages with different memory models
to JavaScript. The allure of having only one language to write all your apps for all platforms is
still there, but why do you have to be confined to JavaScript itself, even as a target language?</p>
<h2>How WebAssembly actually started</h2>
<p>With the death of browser plugins, at least we can praise the interoperability efforts of browser
vendors. Some lowest common denominator of JavaScript is supported in all browsers, and there is a
clear incentive for the vendors to keep up. With the demand to go beyond JavaScript, there were
initial attempts to support low level programming with asm.js in 2013:</p>
<blockquote>
<p>Much of this performance gain over normal JavaScript [with asm.js was] due to 100% type consistency
and virtually no garbage collection (memory is manually managed in a large typed array).</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Asm.js">“asm.js”</a> article on Wikipedia.</small></p>
<p>Syntactically this still looked pretty much like JavaScript, but when you have a lot of low level code,
the resulting file can get big pretty quickly, and the size of your code is pretty important when your
users download it frequently. As you weren’t supposed to write asm.js code manually most of the time,
and it was designed primarily as compilation target, it made sense to invent a binary format for it.
That’s basically how WebAssembly started:</p>
<blockquote>
<p>WebAssembly was first announced in 2015, and the first demonstration was executing Unity’s Angry
Bots in Firefox, Google Chrome, and Microsoft Edge. The precursor technologies were asm.js from
Mozilla and Google Native Client, and the initial implementation was based on the feature set of
asm.js.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/WebAssembly#History">“WebAssembly”</a> article on
Wikipedia.</small></p>
<p>
  <a href="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-5b672.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Angry Bots is a 3rd-person shooter demo that features a marine-like character that walks
through some futuristic research base and defends from suicidal four-legged robots" title="" src="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fb8a0.png" srcset="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-1a291.png 148w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-2bc4a.png 295w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fb8a0.png 590w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-526de.png 885w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fa2eb.png 1180w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-08f6a.png 1770w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-5b672.png 2567w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>Angry Bots is still available to play on the <a href="https://beta.unity3d.com/jonas/AngryBots/">Unity
website</a>.</small></p>
<h2>What WebAssembly got right</h2>
<p>Now you’re no longer restricted to JavaScript as a target language for browser apps. As soon as
<a href="https://llvm.org/">LLVM</a> got WebAssembly backend more or less ready, it allowed compilers built
on top of LLVM (for C, C++, Rust, Swift and many more) to adopt it without rewriting everything from
scratch. This unlocked the browser environment to a huge amount of pre-existing software that can
also run close to native speed if optimized well.</p>
<p>Not only can you run fun little projects such as <a href="https://sandspiel.club/">Sandspiel</a> and
<a href="https://orb.farm/">orb.farm</a> in your browser tab, but complex games such as <a href="https://www.continuation-labs.com/projects/d3wasm/">Doom
3</a> (at least its demo version) are available too.
Both <a href="https://blogs.unity3d.com/2018/08/15/webassembly-is-here/">Unity</a> and <a href="https://twitter.com/unrealengine/status/932624595722559490">Unreal
Engine</a> announced their support for
WebAssembly, and while we may not see AAA games running in browsers on their initial release date,
this still gives enough confidence in the maturity of the platform.</p>
<p>
  <a href="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-9c30a.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="A pixel-art spherical fish tank filled with water, sand, algae, daphnia and fish." title="" src="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fb8a0.png" srcset="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-1a291.png 148w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-2bc4a.png 295w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fb8a0.png 590w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-526de.png 885w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fa2eb.png 1180w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-08f6a.png 1770w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-9c30a.png 3730w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>According to its creator, <a href="https://orb.farm/">orb.farm</a> is “a virtual ecosystem where different
species of creature can live, grow and die as part of a self-contained food chain”.</small></p>
<p>It’s obviously not limited to games, as we can see Apple folks compiling their <a href="https://twitter.com/lrz/status/1250453967957561344">C++ and Objective-C
code from iWork</a> to Wasm<sup id="fnref-1"><a href="#fn-1">1</a></sup>, or
<a href="https://1password.com/">1Password</a> using it in their browser extension getting substantial
performance improvements as a result:</p>
<blockquote>
<p>With our move to WebAssembly, page filling and analysis now runs at least twice as fast as before,
and those websites with a large number of fields are up to 13x faster in Chrome and up to 39x
faster in Firefox! It’s blazing fast. 🔥</p>
</blockquote>
<p><small><a href="https://blog.1password.com/1password-x-may-2019-update/">“1Password X: May 2019 update”</a>
article on <a href="https://blog.1password.com/">the 1Password blog</a>.</small></p>
<h2>Wasm is a general purpose virtual machine</h2>
<p>Not only you get performance improvements with WebAssembly compared to JavaScript, as it was
designed to run arbitrary code in your browser, it’s one of the most widely available secure sandbox
environments. And as a general purpose virtual machine, Wasm is not limited only to browsers.
<a href="https://www.cloudflare.com/">Cloudflare</a> uses it for edge computing on their CDN:</p>
<blockquote>
<p>We’re excited by the possibilities that WebAssembly opens up. Perhaps, by integrating with
Cloudflare Spectrum, we could allow existing C/C++ server code to handle arbitrary TCP and UDP
protocols on the edge, like a sort of massively-distributed inetd. Perhaps game servers could
reduce latency by running on Cloudflare, as close to the player as possible. Maybe, with the help
of some GPUs and OpenGL bindings, you could do 3D rendering and real-time streaming directly from
the edge.</p>
</blockquote>
<p><small><a href="https://blog.cloudflare.com/webassembly-on-cloudflare-workers/">“WebAssembly on Cloudflare
Workers”</a> on <a href="https://blog.cloudflare.com/">the Cloudflare
blog</a>.</small></p>
<p>With people realizing the wide applicability of the Wasm tech stack, it was no surprise when
<a href="https://wasi.dev/">WASI</a> (stands for WebAssembly System Interface) appeared. Where WebAssembly
itself is a “bare metal” platform, it does not supply any primitives such as memory allocation or
filesystem access, which WASI does provide. As Solomon Hykes, creator of Docker, <a href="https://twitter.com/solomonstre/status/1111004913222324225">puts
it</a>:</p>
<blockquote>
<p>If WASM+WASI existed in 2008, we wouldn’t have needed to created Docker. That’s how important it
is. Webassembly on the server is the future of computing. A standardized system …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://desiatov.com/why-webassembly/">https://desiatov.com/why-webassembly/</a></em></p>]]>
            </description>
            <link>https://desiatov.com/why-webassembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24419081</guid>
            <pubDate>Wed, 09 Sep 2020 09:26:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using a Raspberry Pi to Add MIDI to a CV Synthesizer]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24418798">thread link</a>) | @qrv3w
<br/>
September 9, 2020 | https://schollz.com/raspberrypi/monotron/ | <a href="https://web.archive.org/web/*/https://schollz.com/raspberrypi/monotron/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        
        <p><img src="https://schollz.com/img/monotron/main.jpg">
    </p></div>
    
    
    
    
    <p>I programmed the Raspberry Pi to control voltage and respond to MIDI so I can play the Korg Monotron with a keyboard.</p>
    <p>The Korg Monotron is a good sounding synthesizer for a relatively cheap price (~$50). One drawback of the Korg Monotron is that it uses a <a href="https://www.sweetwater.com/insync/ribbon-controller/">ribbon controller</a> to determine the pitch so it is very hard to control the pitch accurately, and almost impossible to be in tune by yourself.</p>
<p>Luckily, Korg has developed this little synth with hacking in mind. These instructions will show you how to use a Raspberry Pi as a cheap MIDI-to-CV controller so you can use the Korg Monotron just like any other MIDI instrument.</p>
<p>This is the first DIY MIDI-to-CV controller that allows you to <strong>automatically tune the Monotron</strong> voltage-to-frequencies <em>and</em> <strong>only has three components</strong> (and no PCBs!). Other solutions - like the <a href="http://beatnic.jp/manuals/monotron-midi/midi-kit.html">MIDI-IF kit</a> or <a href="https://github.com/elkayem/midi2cv">Arduino-based midi2cv</a> - require extensive soldering, dozens of components, and require manual tuning.</p>
<h2 id="overview">Overview</h2>
<p>Adding MIDI to the Korg Monotron basically requires converting MIDI input to voltage. The following introductions will work on several CV synthesizers (I think) and are not necessarily specific to the Monotron. Here we are using a cheap DAC (the MCP4725) to send voltages from the Raspberry Pi. The Raspberry Pi uses a Python script <a href="https://github.com/schollz/midi2cv/">midi2cv.py</a> which listens for MIDI and controls the DAC.</p>
<iframe width="100%" height="315" src="https://www.youtube.com/embed/TuBCexYkAv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>The magic trick here is that I added a tuning function into the Raspberry Pi (in <a href="https://github.com/schollz/midi2cv/">midi2cv.py</a>) so you can automatically determine the relationship between voltage and frequency to tune any CV synth. It works by connecting the audio output of your synth to the Raspberry Pi (via USB audio connector) and then computing the FFT to find the fundamental frequency of tones controlled by various voltages.</p>
<p><a href="https://www.instagram.com/p/CE5Xbw4hZBi/"><img src="https://schollz.com/img/monotron/example1.png" alt="Click for demo of the automatic tuning and MIDI keyboard."></a></p>
<p>Below is a step-by-step instruction to take a Korg Monotron and a Raspberry Pi and make it MIDI capable. There are only two solder points and no PCBs and no breadboards!</p>
<h2 id="requirements">Requirements</h2>
<ul>
<li><a href="https://www.amazon.com/gp/product/B07BC7BMHY/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B07BC7BMHY&amp;linkCode=as2&amp;tag=scholl-20">Raspberry Pi</a> (~$15 on ebay)</li>
<li><a href="https://www.amazon.com/gp/product/B01N905VOY/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B01N905VOY&amp;linkCode=as2&amp;tag=scholl-20">USB audio adapter</a> (~$16, but ~$5 if you by used)</li>
<li><a href="https://www.amazon.com/gp/product/B00684KFAM/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B00684KFAM&amp;linkCode=as2&amp;tag=scholl-20">Korg Monotron</a> (~$55)</li>
<li><a href="https://www.amazon.com/gp/product/B00SK8MBXI/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B00SK8MBXI&amp;linkCode=as2&amp;tag=scholl-20">MCP4725</a> (~$5)</li>
<li><a href="https://www.amazon.com/gp/product/B01L5ULRUA/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B01L5ULRUA&amp;linkCode=as2&amp;tag=scholl-20">Female-to-female jumper cables</a> (~$6)</li>
<li><a href="https://www.amazon.com/gp/product/B087767KNW/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B087767KNW&amp;linkCode=as2&amp;tag=scholl-20">Soldering iron</a> (~$17)</li>
<li>MIDI keyboard (optional)</li>
</ul>
<h2 id="part-1-hacking-the-monotron">Part 1: Hacking the Monotron</h2>
<p>We need to first be able to send voltages to the Korg Monotron. To do this we need to connect a wire with the hot voltage and a wire with the ground to the Monotron using soldering.</p>
<h3 id="solder-two-wires-to-the-monotron-pcb">Solder two wires to the Monotron PCB</h3>
<p>Simply unscrew the back of the Monotron and pull out the back. There are four screws, two of them are next to the batteries.</p>
<p><img src="https://schollz.com/img/monotron/screws.jpg" alt="Location of the four screws."></p>
<p>Take the Monotron apart, carefully, and you will see the back of the PCB has some gold pads with labels! Korg designed this PCB for us to hack :). Solder one wire to the <code>gate</code> pad and solder another wire to the <code>GND</code> pad (both wires should be female on the opposite end).</p>
<p><img src="https://schollz.com/img/monotron/pcb.png" alt="This is the back of the Monotron PCB before you solder."></p>
<p><img src="https://schollz.com/img/monotron/soldering.jpg" alt="The only two soldering connections you need to make."></p>
<p>I realize we are not using <code>pitch</code>, but for some reason <code>gate</code> also can be voltage-controlled and acts as a gate (if voltage &gt; 0) and pitch. If you want to watch someone solder, check out <a href="https://www.youtube.com/watch?v=iT__-bH8Q0o">this great Youtube video for how to solder to the Korg Monotron</a>.</p>
<p><img src="https://schollz.com/img/monotron/closed.jpg" alt="Wires sticking out of the hacked Monotron"></p>
<p>Now just close it up, and move the wires so they stick out under the volume control. You can screw everything back together, just make sure not to go too tight.</p>
<h3 id="hook-up-wires-to-the-raspberry-pi">Hook up wires to the Raspberry Pi</h3>
<p>First let’s wire up the the MCP4725 to the Raspberry Pi. Attach MCP4725 <code>SDA</code>, <code>SCL</code>, <code>GND</code>, <code>VDD</code> to the Raspberry Pi’s <code>GPIO 2 (SDA)</code>, <code>GPIO 3 (SCL)</code>, <code>Ground</code>, and  <code>5V power</code>, respectively. Check the Raspberry Pi <a href="https://www.raspberrypi.org/documentation/usage/gpio/">pin-out schematic</a> for more details.</p>
<p><img src="https://schollz.com/img/monotron/connections_pi.jpg" alt="Wiring between the MCP4725 and the Raspberry Pi"></p>
<p>Now attach the Monotron “<code>gate</code>” wire to the “<code>VOU</code>” of the MCP4725. Attach the Monotron “<code>GND</code>” wire to any ground pin of a Raspberry Pi (<a href="https://www.raspberrypi.org/documentation/usage/gpio/">schematic</a>).</p>
<p><img src="https://schollz.com/img/monotron/connections_all2.jpg" alt="Wiring the Monotron up to the Raspberry Pi with MCP4725."></p>
<p>That’s it! No extra breadboard or PCBs necessary!</p>
<h2 id="part-2-tuning-the-monotron">Part 2: Tuning the Monotron</h2>
<p>The Monotron uses a voltage controlled oscillator (VCO).The Monotron voltages can be modified by the <code>INT</code> and the trim pot and these will affect the frequencies for a given voltage. Every time these are altered (or anytime it seems out of tune), you need to tune it. That is, you need to determine which voltage will produce which frequency.</p>
<p>Luckily, instead of tuning each note manually, we can use the Raspberry Pi to self-calibrate it for us!</p>
<h3 id="installing-pre-requisites-on-raspberry-pi">Installing pre-requisites on Raspberry Pi</h3>
<p>Use <a href="https://www.raspberrypi.org/documentation/remote-access/ssh/unix.md">SSH to get into your Raspberry Pi</a> and install the following prerequisites:</p>
<pre><code>&gt; sudo apt update
&gt; sudo apt install python3 python3-pip python3-numpy portaudio19-dev sox gnuplot ffmpeg
&gt; sudo -H python3 -m pip install loguru click mido python-rtmidi adafruit-circuitpython-mcp4725 termplotlib aubio
</code></pre><p>Now download the <code>midi2cv.py</code> script:</p>
<pre><code>&gt; wget https://raw.githubusercontent.com/schollz/midi2cv/master/midi2cv.py
</code></pre><p>Great, now we are ready to tune the synth.</p>
<h3 id="gettin-in-tune">Gettin’ in tune</h3>
<p>Connect the USB audio to the Raspberry Pi. Then connect the headphone out of the Monotron into the recording line-in with a stereo 1/8” cable.</p>
<p><img src="https://schollz.com/img/monotron/tuning.jpg" alt="Connecting the Monotron to the Raspberry Pi for self-calibration."></p>
<p><strong>Important:</strong> Make sure to change the Monotron settings so it is outputting pure tones. Use the following settings for each knob (0 means all the left, 100 means all the way right):</p>
<ul>
<li><code>RATE</code>: 0</li>
<li><code>INT</code>: anywhere you want (don’t change it after tuning, though)</li>
<li><code>CUTOFF</code>: 100</li>
<li><code>TIME</code>: 0</li>
<li><code>FEEDBACK</code>: 0</li>
</ul>
<p>Now ssh into the Raspberry Pi and run the following Python script:</p>
<pre><code>&gt; python3 midi2cv.py --tune
</code></pre><p>This will take about 30 seconds as the Raspberry Pi cycles through voltages (1-5V) while recording in resulting audio. The audio is captured using the USB audio adapter. The captured audio is analyzed using a FFT to determine the fundamental frequency. These voltage-frequency pairs will then be plotted and fit with an exponential curve.</p>
<p><img src="https://schollz.com/img/monotron/calibration.png" alt="Frequency-voltage fitting after calibration of the Monotron."></p>
<p>The fit from this curve is saved onto the Raspberry Pi so that when you play the Monotron it will be able to convert the MIDI to frequency and then convert that to voltage.</p>
<p>Now you are ready to play!</p>
<h2 id="4-play-the-monotron">4. Play the Monotron!</h2>
<h3 id="using-a-midi-keyboard">Using a MIDI keyboard</h3>
<p>Simply attach a USB MIDI keyboard to the Raspberry Pi and then run:</p>
<pre><code>&gt; python3 midi2cv.py --play
</code></pre><p>Now the keyboard will automatically trigger the Raspberry Pi to set the voltage of the Monotron, in tune!</p>
<h3 id="using-midi-sequencing">Using MIDI sequencing</h3>
<p>A keyboard is not necessary to play the Monotron. You can use another program I wrote to sequence MIDI instruments from a simple text file: <a href="https://github.com/schollz/miti">miti</a>.</p>
<p>First make sure you have portmidi, and download the binary for <code>miti</code> (or you can <a href="https://github.com/schollz/miti">build it yourself</a>):</p>
<pre><code>&gt; sudo apt install libportmidi-dev
&gt; wget https://github.com/schollz/miti/releases/download/v0.4.1/miti_arm.tar.gz
&gt; tar -xvzf miti_arm.tar.gz
&gt; sudo mv miti /usr/local/bin/
</code></pre><p>Then create a new sequencing file. The sequencing is easy to write and understand and <a href="https://github.com/schollz/miti#documentation">documented thoroughly</a>. Here we will make a simple three-chord arpeggio.</p>
<p>In a file names <code>song1.miti</code> write:</p>
<pre><code>pattern a 

instruments midi through
tempo 120

legato 95
F2 A C F A C F A C F A C F A C F
E2 G C E G C E G C E G C E G C E
D2 F A C D F A C D F A C D F A C
D2 F A C D F A C D F A C D F A C
</code></pre><p>The “<code>midi through</code>” indicates that we will send the output to the MIDI through port. Now, in one terminal run the <code>midi2cv</code> program:</p>
<pre><code>&gt; python3 midi2cv.py --play
</code></pre><p>And in another terminal run <code>miti</code> to start sequencing:</p>
<pre><code>&gt; miti --play song1.miti
</code></pre><p>That’s it! You should hear some music. You can edit the <code>song1.miti</code> file in real-time to make any changes to the sequencing.</p>
<h2 id="questions">Questions?</h2>
<p>If you find any problems, feel free to let me know. Find me on instagram (<a href="https://instagram.com/infinitedigits">@infinitedigits</a>) or Twitter (<a href="https://twitter.com/yakczar">@yakczar</a>). DMs are open.</p>

    <p>
        <a href="https://schollz.com/raspberrypi/monotron/">
            <postamble datetime="2020-09-08" 2018-09-04=""><time datetime="2020-09-08 08:00:46">September 8, 2020</time></postamble>
        </a>
        &nbsp;/&nbsp;<a href="https://indieweb.xyz/en/midi" target="_blank">midi</a>&nbsp;<a href="https://indieweb.xyz/en/music" target="_blank">music</a>&nbsp;<a href="https://indieweb.xyz/en/programming" target="_blank">programming</a>&nbsp;<a href="https://indieweb.xyz/en/raspberry%20pi" target="_blank">raspberry pi</a>&nbsp;
    </p>
</div></div>]]>
            </description>
            <link>https://schollz.com/raspberrypi/monotron/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24418798</guid>
            <pubDate>Wed, 09 Sep 2020 08:43:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personality traits affect the open source development process]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24417429">thread link</a>) | @rbanffy
<br/>
September 8, 2020 | https://www.functionize.com/blog/how-personality-traits-affect-the-open-source-development-process/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/how-personality-traits-affect-the-open-source-development-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/ft-personality-affect-open-source-development.jpg" alt="How personality traits affect the open source development process" srcset="https://www.functionize.com/wp-content/uploads/2020/09/ft-personality-affect-open-source-development.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/09/ft-personality-affect-open-source-development-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/09/ft-personality-affect-open-source-development-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/09/ft-personality-affect-open-source-development-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>Perhaps you are a skilled technologist. But beware: If your personality is as scintillating as a dish rag, you could jeopardize your open source projects.</p></blockquote>
<p>According to a <a href="https://ieeexplore.ieee.org/abstract/document/8935389" target="_blank" rel="noopener noreferrer">recent study</a>, a developer’s personality could significantly impact their contributions to open source projects. The researchers at the University of Waterloo found that social factors, including experience, remain the most influential factors in whether a contributor’s work is accepted or rejected. But the study also found that personality traits play a key role in how their work is perceived.</p>
<p>“People who voluntarily work on open source projects need to be aware of how open they are to change and how conscientious they are, as these two personality traits will impact how willing people are to work with them,” says Meiyappan Nagappan, a professor in Waterloo’s David R. Cheriton School of Computer Science and a co-author of the study, <a href="https://www.webwire.com/ViewPressRel.asp?aId=256663" target="_blank" rel="noopener noreferrer">in&nbsp; a statement.</a></p>
<p>Nobody works in a vacuum. A person’s behavior comes out <a href="https://www.functionize.com/blog/whats-the-difference-between-a-good-qa-director-and-a-great-one/">when they interact with other people</a>, whether it’s in person, in a Slack channel, or in code comments. Software development often involves <a href="https://www.functionize.com/blog/4-lessons-software-teams-can-learn-from-rock-bands/">creating a team where it’s comfortable and safe to share ideas</a>. As the researchers note, it’s not enough to complete a task; developers also need to listen and consider other people’s opinions with an open mind. In fact, some developers say, the more diverse personalities on a team, the better the end product.</p>
<p>The researchers collected their data from GitHub. They analyzed the personality traits of 16,935 active developers from 1,860 projects. Each developer had at least 250 pull requests, the process by which GitHub developers notify other open source contributors working on the same project that they completed a task.</p>
<p>The researchers then used the IBM Watson Personality Insights to retrieve the big five personalities of the software developers in GitHub: openness, conscientiousness, extroversion, agreeableness, and neuroticism.</p>
<p>“We found that social factors are still more important than technical factors in getting your open source work accepted,” says Alex Yun, a master’s student in Waterloo’s faculty of mathematics and another study co-author, in a statement.</p>
<p>The researchers also examined the importance of personality factors. They found that biases may be involved in the acceptance or rejection of open source work. That’s true despite the apparent advantage of open source whereby you can contribute with a level of anonymity; your persona shows in your code and comments. Someone reviews and comments on your work based on what they see in front of them, and not how they know you as a person.</p>
<p>“Managers are more likely to accept a contribution from someone they know, or someone more agreeable than others – even though the technical contribution might be similar,” Yun says.</p>
<h3>Developers are not surprised</h3>
<p>People who work in the open source community agree with the research findings.</p>
<p>“If your work is being reviewed and you immediately shoot down any suggestions made by others, I could then foresee this negatively impacting the views of the decision makers who merge your work,” observes Matthew Arnold, a senior software engineer at global call intelligence provider <a href="https://www.infinity.co/us/">Infinity</a>.</p>
<p>“What’s the adjective for the furthest thing from ‘surprised’? Because whatever that word is describes my reaction to this research finding,’’ says VM (Vicky) Brasseur, an open source leader, speaker, and author of the book, <a href="https://pragprog.com/titles/vbopens/forge-your-future-with-open-source/" target="_blank" rel="noopener noreferrer">Forge Your Future With Open Source.</a> “While the research phrases it academically as ‘personality,’ what they mean is someone’s ability to interact with others: <a href="https://www.functionize.com/blog/five-must-have-skills-to-look-for-in-a-qa-tester/">the application of social interaction skills</a> as well as technical skills.”</p>
<p>Those with an extroverted personality likely find it easier to hit “submit” when sending pull requests to open source repositories, Arnold adds. “By submitting this pull request, you’re agreeing to let the internet community review and judge your work. That can be quite daunting, especially when open source projects often attract some of the finest minds in the industry.’’</p>
<p>To some degree, each of us can assess our own capabilities – for good or ill. Arnold’s personality falls into the introverted, intuitive, thinking, and judging (INTJ) personality type within the Myers-Briggs personality assessment. He considers himself to be open and conscientious. But we may see ourselves with a different perspective than do outsiders.</p>
<p>Personality traits have <a href="https://www.functionize.com/blog/five-must-have-skills-to-look-for-in-a-qa-tester/">some impact on software development</a>, but social factors are more influential, says Dawn Foster, director of <a href="https://blogs.vmware.com/opensource">Open Source Community Strategy</a> &nbsp;at VMware. “In my experience, the social factors have had a bigger impact on my ability to successfully contribute to open source projects.”</p>
<p>Foster describes herself as “primarily conscientious with a bit of agreeableness,” which she says has served her well because &nbsp;she is usually prepared and detail oriented. This “allows people to feel more comfortable relying on me to perform my duties.” Being agreeable helps her empathize with others and make them feel welcome, she says.</p>
<h3>Social factors carry more weight</h3>
<p>Both Foster and Brasseur agree with the Waterloo study finding that social factors are more influential on the likelihood of pull request acceptance of contributions into open source projects.</p>
<p>“Open source communities often feel like very small worlds where I keep running into the same people over and over again,’’ Foster explains. “My past social interactions in previous communities have helped smooth the way for my participation in new ones.”</p>
<p>For example, when Foster started contributing to Kubernetes, she wanted to help out with the Contributor Summit. Because she had worked with several of the organizers on other projects who could vouch for her work, it was relatively easy for her to get involved as an organizer despite being relatively new to the project.</p>
<p>Another example the <a href="https://chaoss.community/" target="_blank" rel="noopener noreferrer">CHAOSS Project</a> where Foster eventually joined its governing board. “Because many of the existing board members and maintainers knew of my past work on open source project health metrics, it allowed me to participate in meaningful ways much more quickly than I might have if I didn’t have those previous social interactions,” Foster says.</p>
<p>Brasseur points out that social interaction is critical not just to a successful open source contribution – but to any endeavor that involves more than one person.</p>
<p>“Collaboration is difficult if not impossible when people aren’t able to interact well, whether due to personal skills, language differences, or some other obstruction,’’ Brasseur says. “We in open source have abundant documentation about the technical aspects of contributing, such as <a href="https://www.functionize.com/blog/16-things-that-testers-wished-theyd-learned-earlier/">writing tests</a> or the mechanics of sending your contribution for review, but relatively little about the social expectations for that contribution.”</p>
<p>Projects don’t necessarily ignore the social expectations, Brasseur adds. “It’s simply that they rarely document them.”</p>
<p>Like Foster, Arnold says that being open, conscientious, and agreeable has benefited him professionally. These traits have helped him to “gel well with teammates, which to me is a massive benefit.” But, he adds, “I have to be careful, however, that I don’t let this cloud my judgement when receiving feedback around changing how I have done something. I need to make sure I’m not too quick to go with what makes the other person happy.”</p>
<p>The result is a willingness to accept suggestions that go against his initial view. “My impediments tend to come from a lack of extroversion along with levels of neuroticism,” Arnold says, “making experiences such as presenting and training a lot more stressful and anxiety inducing than they necessarily need be.”</p>
<p>Don’t expect arguments. Most developers are agreeable! “The times that I see a pull request being hindered most by personality are when you have a small pool of developers reviewing the work,” Arnold says. In those cases, “The author is implementing review comments without really critiquing the suggestions, which can sometimes cause a reduced level of quality.”</p>
<h3>Being a good communicator speaks volumes</h3>
<p>Someone who is a good communicator always is in demand. <a href="https://www.functionize.com/blog/so-you-want-to-become-a-software-qa-professional/">Employers are always looking for that soft skill</a> in candidates across industries, says Lusen Mendel, director of developer relations at <a href="https://karat.com/">Karat</a>, which conducts technical interviews for organizations hiring developers.</p>
<p>“Just as <a href="https://www.functionize.com/acceptance-testing-a-step-by-step-guide/">we validate software correctness with tests</a>, it often takes bouncing ideas off a peer to validate the degree of our own understanding and the effectiveness of our insights,’’ Mendel says. “Being a good, concise communicator lets developers quickly identify what information is salient to specific brainstorms, decisions, and open source projects.”</p>
<p>In virtually every interview Karat conducts,&nbsp;regardless of what they were&nbsp;supposed to be evaluating, “Interviewers inevitably tell the hiring manager how the candidate communicated,’’ he notes.</p>
<h3>More change is needed</h3>
<p>While he is not a developer, Jack Wallen, who has covered open source for decades as a journalist, finds that “Developers are very much like artists, in that they can be very sensitive to criticism and place a very high value not only on their work, but on the acceptance of both their work and who they are.”</p>
<p>Many developers pride themselves on their individuality and tend to hold that trait very dear, Wallen says. “That can translate to either being very satisfied with a project, when they and their work are accepted – or walking away when they are not.”</p>
<p>For Wallen, there is another longstanding issue in the development community that needs to be addressed. “It’s become clear that there needs to be significant improvement in the way the development community treats people of color, women, and members of the LGBTQ community,” he says. “At this point, there must be a zero tolerance for unwanted or unequal treatment.”</p>
<p>Wallen says he knows very talented developers who have been affected by this. “And …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.functionize.com/blog/how-personality-traits-affect-the-open-source-development-process/">https://www.functionize.com/blog/how-personality-traits-affect-the-open-source-development-process/</a></em></p>]]>
            </description>
            <link>https://www.functionize.com/blog/how-personality-traits-affect-the-open-source-development-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24417429</guid>
            <pubDate>Wed, 09 Sep 2020 05:20:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Bayesian Stats Needs Monte-Carlo Methods]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24416908">thread link</a>) | @laplacesdemon48
<br/>
September 8, 2020 | https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods | <a href="https://web.archive.org/web/*/https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div id="canvas">

			<!-- / headerWrapper -->

			<div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<article id="article-5f3999dd551f15457784cec9" data-item-id="5f3999dd551f15457784cec9">

	<div>
  <!--SPECIAL CONTENT-->

    

    <div>

    <!--POST HEADER-->

			<header>
				
				
			</header>

    <!--POST BODY-->

      <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1597610547002" id="item-5f3999dd551f15457784cec9"><div><div><div data-block-type="2" id="block-ce72701dbc5d55959e37"><div><div><p>This post emerged from a series of question surrounding a Twitter comment that brought up some very interesting points about how Bayesian Hypothesis testing works and the inability of analytic solutions to solve even some seemingly trivial problems in Bayesian statistics. </p><p>Comparing Beta distributed random variables is something that comes up pretty frequently on this blog (and in my book as well). The set up is fairly straight forward: model an A/B test as sampling from two beta distributions, sample from each distribution a lot, then compare the results.</p><p>This simulation approach often first appears as a clever little trick to solve a more complex math problem, but in fact is a primative form of Monte-Carlo Integration and turns out to one of the only ways to really solve this problem. By exploring this topic deeper in this post we'll see some of the myths that many people have about analytic solutions as well as demonstrating why Monte-carlo methods are so essential to Bayesian statistics.</p></div><h2>Background: A conversation about election results</h2><div><p>An interesting conversation happened on Twitter recently. It started with a retweet of mine regarding Nate Silver (well know author and election forecaster) posting his latest predictions for the 2020 presidential election showing that Biden has a 71% probability of winning versus Trump's 29%</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_4659"><div><div><p>After the last election there was quite a lot of criticism about Nate Silver's forecasting since his company (538) predicted that <a href="https://projects.fivethirtyeight.com/2016-election-forecast/">Hilary Clinton would win with a probability of 71%</a> in the 2016 presidential election.</p><p>This criticism has always annoyed me personally since, in statistical terms, 71% is generally not considered a strong belief in anything. So it is not inconsistent, nor suprising for someone to believe a candidate has 71% chance of success and they still lose. Even when looking at typical p-values, we wait for 95% percent certainty before making claims (and many feel this is a pretty weak belief). But for some reason whenever election polls come up, it seems even very statistically minded people suddenly think that 51% chance is a high probability.</p><p>I retweeted Nate Silver's forecast, mentioned my annoyance and provided an example of another case with a similar probability of winning:</p></div></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/willkurt&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>This time can we all remember that rarely in statistics would we judge P(H|D) = 0.71 as a strong belief in anything. <br><br>For comparison if in an A/B test we had these results:<br><br>A has 2 successes in 15 trials<br>B has 3 successes in 14 trials<br><br>This roughly how strong our belief in B is <a href=\&quot;https://t.co/bB4PiB5Tao\&quot;>https://t.co/bB4PiB5Tao</a></p>\u2014 Will Kurt (@willkurt) <a href=\&quot;https://twitter.com/willkurt/status/1293575032975884288?ref_src=twsrc%5Etfw\&quot;>August 12, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/willkurt/status/1293575032975884288&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Will Kurt&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_6372"><div><blockquote><div dir="ltr" lang="en"><p>This time can we all remember that rarely in statistics would we judge P(H|D) = 0.71 as a strong belief in anything. </p><p>For comparison if in an A/B test we had these results:</p><p>A has 2 successes in 15 trials<br>B has 3 successes in 14 trials</p><p>This roughly how strong our belief in B is <a href="https://t.co/bB4PiB5Tao">https://t.co/bB4PiB5Tao</a></p></div>— Will Kurt (@willkurt) <a href="https://twitter.com/willkurt/status/1293575032975884288?ref_src=twsrc%5Etfw">August 12, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_6436"><div><div><p>If you were running an A/B test and your A variant had 2 success in 15 trials and your B variant had 3 successes in 14 trails, you would be roughly 71% confident that B was the superior variant.</p><p>Even someone without much statistical training would likely be very skeptical of such a claim, but somehow during election forecasts even experience statisticians can look at Silver's post and think that Biden winning is a sure thing.</p></div><h2> How do we arrive at P(B &gt; A)?</h2><p><br>Twitter user <a href="https://twitter.com/mbarras_ing">@mbarras_ing</a> ask a really important follow up question, asking to explain this result:</p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/mbarras_ing&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>I may be a bit slow but could you elaborate on how that is? How would one compute 0.71, from the info \&quot;A has 2 successes in 15 trials, B has 3 successes in 14 trials\&quot;?</p>\u2014 Matthew Rhys Barras (@mbarras_ing) <a href=\&quot;https://twitter.com/mbarras_ing/status/1293928326579589121?ref_src=twsrc%5Etfw\&quot;>August 13, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/mbarras_ing/status/1293928326579589121&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Matthew Rhys Barras&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_7791"><div><blockquote><p dir="ltr" lang="en">I may be a bit slow but could you elaborate on how that is? How would one compute 0.71, from the info "A has 2 successes in 15 trials, B has 3 successes in 14 trials"?</p>— Matthew Rhys Barras (@mbarras_ing) <a href="https://twitter.com/mbarras_ing/status/1293928326579589121?ref_src=twsrc%5Etfw">August 13, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_7855"><div><div><p>I very strongly believe that all statistics, even quick off the cuff estimates, should be reproducible and explainable.</p><p>I've written a fair bit about approaching similar problems both <a href="https://www.countbayesie.com/blog/2015/4/25/bayesian-ab-testing">on this blog</a> and <a href="https://www.amazon.com/Bayesian-Statistics-Fun-Will-Kurt/dp/1593279566">in my book</a>. The big picture is that we're going to come up with parameter estimates for the rate that A and B convert users and then compute the probability that B is greater than A. </p><p>Since we're estimating conversion rates we're going to use <a href="https://www.countbayesie.com/blog/2015/3/17/interrogating-probability-distributions">the Beta distribution</a> as the distribution of our parameter estimate. In this example I'm also assume a \(\text{Beta}(1,1)\) prior for our A and B variants.</p><p>The likelihood for A is \(\text{Beta}(2,13)\) and for B is \(\text{Beta}(3,11)\) so we can represent A and B as two random variables samples form these posteriors:</p><p>$$A \sim \text{Beta}(2+1, 13+1)$$<br>$$B \sim \text{Beta}(3+1,11+1)$$</p></div><p>We can now represent this in R, and sample from these distributions:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_9136"><div><pre><span>N</span> <span>&lt;</span><span>-</span> <span>10000</span>
<span>a_samples</span> <span>&lt;</span><span>-</span> <span>rbeta</span>(<span>N</span>,<span>2</span><span>+</span><span>1</span>,<span>13</span><span>+</span><span>1</span>)
<span>b_samples</span> <span>&lt;</span><span>-</span> <span>rbeta</span>(<span>N</span>,<span>3</span><span>+</span><span>1</span>,<span>11</span><span>+</span><span>1</span>)</pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_9202"><p>And finally we can look at the results of this to compute the probability that B is greater than A:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_10612"><div><pre><span>sum</span>(<span>b_samples</span> <span>&gt;</span> <span>a_samples</span>)<span>/</span><span>N</span></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_10678"><div><p>In this case we get 0.7028 pretty close to 71% for Nate Silver’s problem.</p><h2><p>Can we solve this without R?</p></h2><p><br>This explains where we get our probabilities from, but there is an obvious question that comes up when you see this result, one raised by <a href="https://twitter.com/little_rocko">@little_rocko</a></p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/little_rocko&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>this is an awesome example. is there an easy way (as in non-brute force) to finding the beta parameters that'll match a probability?</p>\u2014 Rocko (@little_rocko) <a href=\&quot;https://twitter.com/little_rocko/status/1294938572299018242?ref_src=twsrc%5Etfw\&quot;>August 16, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/little_rocko/status/1294938572299018242&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Rocko&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_12117"><div><blockquote><p dir="ltr" lang="en">this is an awesome example. is there an easy way (as in non-brute force) to finding the beta parameters that'll match a probability?</p>— Rocko (@little_rocko) <a href="https://twitter.com/little_rocko/status/1294938572299018242?ref_src=twsrc%5Etfw">August 16, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_12181"><div><div><p>This question is interesting because it asks two questions that don't necessarily have to be related:</p><p>- is there an easy way to solve this<br>- is there a non-"brute force" way solve this</p><p>Before moving on I want to mention that this little snippet of R involves a lot more abstraction then it seems at first glance. What we are really doing here is equalivant to using a Monte-Carlo simulation to integrate over the distribution of the difference between two Beta distributed random variables. After the next two sections it will be more clear that what's happening here is a surprisingly sophisticated operation that is, in my opinion, the easiest method of solving this problem as well as not truly a brute force solution.</p></div><h2><br>Analytic versus Easy</h2><div><p>When we see computational solutions to mathematical problems our first instinct is typically to feel that we are avoiding solving the problem <em>analytically.</em> An analytical solution is one that uses mathematical analysis to find a closed form solution.</p><p>A strivial example, suppose I wanted to find the value that minimized \(f(x) = (x+3)^2\)</p><p>In R I could brute force this by looking over a range of answers like this:</p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_13626"><div><pre><span>f</span> <span>&lt;</span><span>-</span> <span>function</span>(<span>x</span>){  
  (<span>x</span><span>+</span><span>3</span>)<span>^</span><span>2</span>
}
<span>xs</span> <span>&lt;</span><span>-</span> <span>seq</span>(<span>-</span><span>6</span>,<span>6</span>,<span>by</span><span>=</span><span>0.031</span>)
<span>xs</span>[<span>which</span>.<span>min</span>(<span>f</span>(<span>xs</span>))]</pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_13692"><div><div><p>As expected we get our answer of -3, but this solution takes a bit of work: we need to know how to code and we need a computer. It's also a bit messy because if we had iterated by an incredment that didn't include -3 exactly (say by 0.031) we would not get the exact answer.</p><p>If we know some basic calculus we know that our minimum has to be where the derivative is at 0. We can very easily work out that</p><p>$$f'(x) = 2(x+3)$$<br>And that</p><p>$$2(x + 3) = 0 $$</p><p>When</p><p>$$ x = -3 $$</p><p>Knowning basic calculus this later solution becomes much easier. </p><p>But even with the calculus is part is hard, often solving it once makes future solutions much easier. Take for example if you wanted to find the maximum likelihood for a normal distribution with a mean of \(\mu\) and standard deviation of \(\sigma\)</p><p>To solve this we start with our PDF for the normal distribution \(\varphi\):</p><p>$$\varphi(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$$</p><p>Now computing the derivative of this is not necessarily "easy" but it's certainly something we can do. All we really care about is when</p><p>$$\varphi'(x) = 0$$</p><p>Which we can find out happens when (computing the deriviative of course is left as an exercise for the reader):</p><p>$$\frac{\mu-x}{\sigma}$$</p></div><div><p>This allows us to reallize the amazing fact that for any normal distribution we come across, we know that the maximum likelihood estimate is the sample is when \(x = \mu\)!</p><p>Even though our calculus might take us a bit of work, once this is done the problem of doing maximum likelihood estimation for any Normal distribution truly does become easy!</p></div><h3><br>Proposing an Analytic solution to our problem</h3><div><p>Let's revisit our original problem this time attempting to find an analytic solution. This is a very interesting case because arguably this is the simplest Bayesian hypothesis test you can imagine.</p><p>Recall that we have two random variable representing our beliefs in each test. These are distributed according the the posterior which we described earlier.</p><p>$$A \sim \text{Beta}(2+1, 13+1)$$<br>$$B \sim \text{Beta}(3+1,11+1)$$</p><p>Here is where I skipped some steps in reasoning. What we want to know is:</p><p>$$P(B &gt;A)$$</p></div><div><p>Which is not expressed in a particularly useful mathematical way. A better way to solve this is to consider this as the sum (or difference in this case) of two random variables. What we really want to know is:</p><p>$$P(B - A &gt; 0)$$</p><p>In order to solve this problem we can think of a new random variable \(X\) which is going to be the difference between B and A:</p><p>$$X = B - A$$</p><p>Finally we'll suppose we have a probability density function for \(X\) we'll call \(\text{pdf}_X\). If we know \(\text{pdf}_X\) our solution is pretty close, we just need to integrate between 0 and the max domain of this distribution:</p><p>$$P(B &gt; A) = P(B - A &gt; 0) = \int_{x=0}^{\text{max}}\text{pdf}_{X}(x)$$</p><p>Already this is starting to look a bit complicated, but there's one big problem ahead. Unlike Normally distributed random variables, we have no equivalent of the Normal sum theorem (we'll cover this in a bit) for Beta distributed random variables. </p><p>What does \(\text{pdf}_X\) look like? For starters we know it's not a Beta distribution itself. We can see this because we know the domain (or support) of this distribution is not \([0,1]\). Because they are Beta distributed, A and B can both take on values from 0 to 1, which means the maximum result of this difference is 1 but the minimum is -1. So whatever this distribution is, its domain is \([-1,1]\) meaning it cannot be a Beta distribution.</p><p>We can use various rules about sum of random variables to determine the mean and variance of this distribution, but without knowing the exact form of this distribution we are unable to solve the integral analytically. </p><p>Here we can see that even in this profoundly simple problem the analytical solution is frustratingly …</p></div></div></div></div></div></div></div></div></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods">https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods</a></em></p>]]>
            </description>
            <link>https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods</link>
            <guid isPermaLink="false">hacker-news-small-sites-24416908</guid>
            <pubDate>Wed, 09 Sep 2020 03:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AMD PSB Vendor Locks EPYC CPUs for Enhanced Security at a Cost]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 253 (<a href="https://news.ycombinator.com/item?id=24416005">thread link</a>) | @virgulino
<br/>
September 8, 2020 | https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover.jpg" data-caption="AMD Platform Secure Boot Feature Cover"><img width="696" height="465" src="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-696x465.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-400x268.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-628x420.jpg 628w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="AMD Platform Secure Boot Feature Cover" title="AMD Platform Secure Boot Feature Cover"></a><figcaption>AMD Platform Secure Boot Feature Cover</figcaption></figure></div>
            <!-- content --><p>Today we are going to discuss a change to server security that is going to make waves in the home lab and secondary markets for servers and components in the future. During our recent <a href="https://www.servethehome.com/dell-emc-poweredge-c6525-review-2u4n-amd-epyc-kilo-thread-server/">Dell EMC PowerEdge C6525 review</a> we briefly mentioned that AMD EPYC CPUs in the system are vendor locked to Dell EMC systems. This is not a Dell-specific concern. We have confirmed that other vendors are supporting the feature behind this. For the large vendors, their platform security teams are pushing to build more secure platforms for their customers, and that is going to have future impacts on the secondary server market and home labs.</p>
<p>In this article, we are going to cover the basics of what is happening. We are going to discuss the motivations, and why this is going to be more common in the future. Finally, we are going to discuss what those in the industry can do to keep the secondary server market operating well. If you work with partners or resellers who dip into used parts bins or even have the potential to purchase grey market CPUs, send them this article or accompanying video. The current market has a large disconnect between what some large customers are asking for, and large vendors are delivering on and what others in the market know is happening.<span id="more-46716"></span></p>
<h2>Accompanying Video</h2>
<p>This is an important topic. To ensure that we can cover those who like to read/ skim and those who like to get information via audio, we have an accompanying video:</p>
<p><iframe title="Vendor Locking AMD EPYC CPUs Great for Security at a Cost" width="696" height="392" src="https://www.youtube.com/embed/kNVuTAVYxpM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Feel free to pop open that video on YouTube and check it out or to send to those who prefer not to read.</p>
<h2>Background: How we learned this was a “thing”</h2>
<p>In 2018 we did a <a href="https://www.servethehome.com/dell-emc-poweredge-r7415-review/">Dell EMC PowerEdge R7415 review</a> and as part of that review, we started our normal process of trying different CPUs in the system. Early in that process, we used an AMD EPYC 7251 CPU, the low-end 8-core model, and noticed something curious. It would not work in our other test systems after.</p>
<p>After a bit of research, we found it was because Dell EMC was vendor locking the chips to Dell systems. We did not know exactly why, but we were told was a security feature. At this point, and even to this day two years later, not every vendor takes advantage of all of the AMD EPYC security features. What that practically means is that what we saw with the Dell EMC system is not what we saw with other systems. For example, we were able to interchangeably use CPUs in Supermicro and Tyan systems, but we could not use those systems once they went into a Dell EMC server.</p>
<figure id="attachment_24514" aria-describedby="caption-attachment-24514"><a href="https://www.servethehome.com/dual-amd-epyc-7251-linux-benchmarks-least-expensive-2p-epyc/amd-epyc-7251-in-socket-and-carrier/" rel="attachment wp-att-24514"><img src="https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier.jpg" alt="AMD EPYC In Socket And Carrier" width="800" height="533" srcset="https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier.jpg 800w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-696x464.jpg 696w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-630x420.jpg 630w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-24514">AMD EPYC In Socket And Carrier</figcaption></figure>
<p>We found we were not alone. Laboratories, VARs, and other organizations were finding that transferring AMD EPYC CPUs from one vendor’s system to another, was not the simple process it was on the Intel Xeon side. It did not always work.</p>
<p>We knew it was a security feature and thought that most who are buying servers would be informed of this by their sales reps or channel partners. After I personally got a lot of texts, e-mails, instant messaging, and comments on our C6525 video and article, I realized that this actually may be a situation where many people do not know what is going on.</p>
<figure id="attachment_46531" aria-describedby="caption-attachment-46531"><a href="https://www.servethehome.com/dell-emc-poweredge-c6525-review-2u4n-amd-epyc-kilo-thread-server/dell-emc-poweredge-c6525-internal-view-nodes-partially-out/" rel="attachment wp-att-46531"><img src="https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out.jpg" alt="Dell EMC PowerEdge C6525 Internal View Nodes Partially Out" width="800" height="519" srcset="https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-400x260.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-696x452.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-647x420.jpg 647w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-46531">Dell EMC PowerEdge C6525 Internal View Nodes Partially Out</figcaption></figure>
<p>This experience that we had, apparently is one that is not overly common yet. That makes sense because the systems that utilize the enhanced security levels are still largely new, and being used by their first buyers. Also, AMD still has a smaller market share than Intel. A big reason, by the way, that Intel Xeon does not have this issue is that they do not have the security feature that AMD has. Vendors have come out and stated that their AMD EPYC systems are more secure than their Intel Xeon systems, and this behavior is a byproduct of that enhanced security.</p>
<p>Next, we are going to dive into the feature of AMD processors (and what will be more common in future CPUs from other vendors.)</p>
<h2>AMD EPYC Secure Processor Platform Secure Boot (PSB)</h2>
<p>Let us start with the high-level slide. This is effectively the same slide on the AMD Secure Processor that we saw with the AMD EPYC 7001 series launch, but this is from the EPYC 7002 series. AMD EPYC CPUs may be x86, but they have an embedded Arm Cortex-A5 microcontroller that runs its own OS that is independent of the main system. This AMD Secure Processor is the backbone of AMD’s security push as it provides features such as key management and hardware root of trust for the platform.</p>
<figure id="attachment_36705" aria-describedby="caption-attachment-36705"><a href="https://www.servethehome.com/amd-epyc-7002-series-rome-delivers-a-knockout/amd-epyc-7002-platform-secure-processor/" rel="attachment wp-att-36705"><img src="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor.jpg" alt="AMD EPYC 7002 Platform Secure Processor" width="1792" height="918" srcset="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor.jpg 1792w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-400x205.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-800x410.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-696x357.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-1068x547.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-820x420.jpg 820w" sizes="(max-width: 1792px) 100vw, 1792px"></a><figcaption id="caption-attachment-36705">AMD EPYC 7002 Platform Secure Processor</figcaption></figure>
<p>AMD spends time <a href="https://www.servethehome.com/amd-confirms-cts-labs-exploits-requiring-admin-access/">patching this solution</a>&nbsp;to make it more secure, but it is generally fairly hard to reach without some extremely low-level access in a system. We are going to come back to the “Enables hardware validated boot” line shortly, but it is important to understand that this secure processor underpins many of AMD’s best security features.</p>
<p>For example, at STH we use EPYC’s Secure Memory Encryption and Secure Encrypted Virtualization heavily. With AMD EPYC, we do not have to manually manage keys. Instead, the ephemeral keys are managed for us by the AMD Secure Processor. This is the basis for what is really the building wave of confidential computing offerings such as&nbsp;<a href="https://www.servethehome.com/google-cloud-confidential-computing-enabled-by-amd-epyc-sev/">Google Cloud Confidential Computing Enabled by AMD EPYC SEV</a>. Intel has its secure boot features and SGX that will be enhanced greatly with <a href="https://www.servethehome.com/the-2021-intel-ice-pickle-how-2021-will-be-crunch-time/">Ice Lake Xeons</a>, but for now, AMD has this capability while Intel does not. When big vendors say AMD is more secure, the AMD Secure Processor is a cornerstone of those offerings.</p>
<figure id="attachment_36704" aria-describedby="caption-attachment-36704"><a href="https://www.servethehome.com/amd-epyc-7002-series-rome-delivers-a-knockout/amd-epyc-7002-platform-secure-memory-encryption/" rel="attachment wp-att-36704"><img src="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption.jpg" alt="AMD EPYC 7002 Platform Secure Memory Encryption" width="1769" height="890" srcset="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption.jpg 1769w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-400x201.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-800x402.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-696x350.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-1068x537.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-835x420.jpg 835w" sizes="(max-width: 1769px) 100vw, 1769px"></a><figcaption id="caption-attachment-36704">AMD EPYC 7002 Platform Secure Memory Encryption</figcaption></figure>
<p>Let us discuss that “Enables hardware validated boot” line. While traditionally CPUs just fire up in whatever platform they are in, AMD has intelligence in their CPU due to the Arm-based AMD Secure Processor. EPYC CPUs are designed to be a bit more intelligent about the platforms they are in, and interact with server platform security to act as this root of trust that would not be possible if they effectively just booted up in any system.</p>
<p>Here is a statement from AMD describing the AMD Platform Secure Boot.</p>
<p><em>The AMD Platform Secure Boot Feature (PSB) is a mitigation for firmware Advanced Persistent Threats. It is a defense-in-depth feature. PSB extends AMD’s silicon root of trust to protect the OEM’s BIOS.&nbsp; This allows the OEM to establish an unbroken chain of trust from AMD’s silicon root of trust to the OEM’s BIOS using PSB, and then from the OEM’s BIOS to the OS Bootloader using UEFI secure boot. This provides a very powerful defense against remote attackers seeking to embed malware into a platform’s firmware.</em></p>
<p><em>An OEM who trusts only their own cryptographically signed BIOS code to run on their platforms will use a PSB enabled motherboard and set one-time-programmable fuses in the processor to bind the processor to the OEM’s firmware code signing key. AMD processors are shipped unlocked from the factory, and can initially be used with any OEM’s motherboard. But once they are used with a motherboard with PSB enabled, the security fuses will be set, and from that point on, that processor can only be used with motherboards that use the same code signing key. (<strong>Source</strong>: AMD statement to STH)</em></p>
<p>That is a lot to take in. We asked HPE about this. Their response mirrored what the above was describing. HPE firmware, when a system is first turned on, performs this binding process where the AMD EPYC CPU expects to see HPE signed firmware. If you alter the HPE firmware on the system, the check fails and the system will not work. That means if your HPE motherboard fails, you can replace it and put your CPU in another HPE motherboard with signed HPE firmware. It also means if the server platform’s firmware is not signed by HPE, the processor will see it as evidence of tampering and not work.</p>
<p><strong>Edit: 2020-09-09</strong> – HPE clarified that they are doing this in a different manner than Dell after initially confirming that they were using the AMD PSB feature. After this went live, HPE sent us the following:</p>
<p><em>HPE does not use the same security technique that Dell is using for a BIOS hardware root of trust. HPE does not burn, fuse, or permanently store our public key into AMD processors which ship with our products. HPE uses a unique approach to authenticate our BIOS and BMC firmware: HPE fuses our hardware – or silicon – root of trust into our own BMC silicon to ensure only authenticated firmware is executed.&nbsp; Thus, while we implement a hardware root of trust for our BIOS and BMC firmware, the processors that ship with our servers are not locked to our platforms. (<strong>Source</strong>: HPE)</em></p>
<p>What is at least interesting there is that HPE was initially claiming feature parity with Dell to us, and from the comments on this article were saying they used this feature in sales pitches, but now are saying they are not blowing the eFuses.</p>
<figure id="attachment_39258" aria-describedby="caption-attachment-39258"><a href="https://www.servethehome.com/pcie-gen4-hpe-proliant-dl325-gen10-plus-and-dl385-gen10-plus-amd-epyc-7002/hpe-proliant-dl325-gen10-plus-at-sc19-cpu-cover/" rel="attachment wp-att-39258"><img src="https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover.jpg" alt="HPE ProLiant DL325 Gen10 Plus At SC19 CPU Cover" width="800" height="600" srcset="https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-400x300.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-80x60.jpg 80w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-265x198.jpg 265w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-696x522.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-560x420.jpg 560w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-39258">HPE ProLiant DL325 Gen10 Plus At SC19 CPU Cover</figcaption></figure>
<p>Here is where the concern develops, and not necessarily for AMD, the OEM, or most of the initial customer base. Customers want more security. The OEMs want to create a secure hardware environment because that is what their customers want. AMD is implementing an advanced security solution beyond what Intel Xeons have giving the OEMs and end-customers what they want. Effectively, when these are sold as new systems, this is exactly what everyone involved wants.</p>
<p>If everyone is getting what they want, then where is the concern, that is what we are going to cover next.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24416005</guid>
            <pubDate>Wed, 09 Sep 2020 02:02:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disney hit by backlash after thanking Xinjiang authorities in 'Mulan' credits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24415532">thread link</a>) | @woranl
<br/>
September 8, 2020 | https://www.ctvnews.ca/mobile/entertainment/disney-hit-by-backlash-after-thanking-xinjiang-authorities-in-mulan-credits-1.5096476 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/mobile/entertainment/disney-hit-by-backlash-after-thanking-xinjiang-authorities-in-mulan-credits-1.5096476">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
	Disney has publicly thanked a Chinese government agency accused of human rights abuses in Xinjiang for its help in making "Mulan" — a revelation that has provoked a storm of criticism online.</p>
<p>
	Disney acknowledges several Chinese government bodies in the credits for the live-action remake of the 1998 animated picture of the same name, but a few in particular have raised red flags: The Xinjiang government's publicity department and the Public Security and Tourism bureaus for Turpan, a city of about <a href="http://www.tlf.gov.cn/zjtluf/rkyy/rkgk.htm" target="_blank">633,400 people</a> just outside Xinjiang's capital Urumqi.</p>
<p>
	Disney did not respond to a request for comment from CNN Business to its media inquiry line, and to U.S. press officers about the film and the credits. It's not clear how much of "Mulan" may have been shot in Xinjiang, though people who worked on the movie have said on social media and in interviews that they scouted and filmed locations there.</p>
<p>
	The U.S. State Department estimates that since 2015 as many as <a href="https://www.foreign.senate.gov/imo/media/doc/120418_Busby_Testimony.pdf" target="_blank">two million of the Muslim-majority Uyghurs and other Turkic minorities</a> have been imprisoned in enormous re-education camps in Xinjiang.</p>
<p>
	The Turpan Public Security Bureau has been listed by the U.S. government as an organization involved in <a href="https://www.federalregister.gov/documents/2019/10/09/2019-22210/addition-of-certain-entities-to-the-entity-list" target="_blank">"human rights violations and abuses"</a> in the region.</p>
<p>
	Beijing has long defended the crackdown in Xinjiang as necessary to tackle extremism and terrorism, and said it is in line with Chinese law and international practice, calling accusations of mass detentions a "groundless lie" and "sensational rumor." A spokesperson for the country's foreign ministry on Tuesday reiterated its defense of what it calls its Xinjiang "vocational skills education and training centers." CNN Business has reached out to the Xinjiang government and Turpan's tourism bureau, but Turpan's Public Security bureau could not be reached for comment.</p>
<p>
	"There are no so-called concentration camps in Xinjiang," said China's Foreign Ministry spokesperson Zhao Lijian. "The establishment of vocational skills education and training centers in Xinjiang in accordance with the law is a useful attempt and active exploration for preventive counter-terrorism and de-radicalization."</p>
<p>
	But the connections between Xinjiang and "Mulan" have ignited widespread criticism on social media since its release Friday on Disney+, the company's streaming service. Human rights advocates are now calling on Disney to make public any agreements with the Chinese government over filming in the region.</p>
<p>
	"[It's] deeply disturbing that Disney thought it was okay to partner with, and also thank, government departments, specifically propaganda departments, and a public security bureau from a region in China that is<a href="https://www.cnn.com/2020/07/30/asia/xinjiang-sterilization-women-human-rights-intl-hnk/index.html" target="_blank"> complicit with genocide," </a>said Isaac Stone Fish, senior fellow at the Asia Society, a New York based non-profit organization focused on raising awareness of Asia.</p>
<h3>
	A FILM PLAGUED BY SETBACKS</h3>
<p>
	Disney hoped that "Mulan" would be a major success at the lucrative Chinese box office, now the second-largest in the world. The company spoke last year about its dedication to making the film culturally accurate — remarks that were reported in Chinese state media.</p>
<p>
	"We spent a lot of time in the beginning with scholars, experts and people from the region. And we spent a great deal of time in China," said Sean Bailey, president of Walt Disney Studios Motion Picture Production, at a Disney expo event last year, reported the state-run news agency Xinhua. Bailey added that the studio "not only has a Chinese cast but also brought in a Chinese producer to make the movie with them," the outlet noted.</p>
<p>
	Eschewing the musicality of Disney's earlier animated feature of the same name, one box office analyst told CNN Business earlier this year that the live-action epic was <a href="https://www.cnn.com/2020/02/13/media/disney-mulan-coronavirus/index.html" target="_blank">"tailor-made for success."</a></p>
<p>
	But the film — which is based on a traditional Chinese legend about <a href="http://www.womenofchina.cn/womenofchina/html1/history/1706/4656-1.htm" target="_blank">a female warrior</a> who disguised herself as a man and took her father's place in the army — has already faced controversy and setbacks.</p>
<p>
	In August 2019, pro-democracy activists in Hong Kong called for a boycott of "Mulan" after the lead actor expressed support for Hong Kong police on her social media account.</p>
<p>
	"I support the Hong Kong police. You can all attack me now. What a shame for Hong Kong," Liu Yifei, a Chinese-born U.S. citizen who plays the titular Hua Mulan, <a href="https://www.cnn.com/2019/08/16/asia/china-mulan-actor-protests-intl-hnk-trnd/index.html" target="_blank">posted to her official Weibo account.</a> At the time, Hong Kong police faced allegations of excessive violence against protesters. (Hong Kong police <a href="https://www.cnn.com/2019/09/20/asia/hong-kong-protests-intl-hnk/index.html" target="_blank">defended their actions</a> in September 2019, saying they had been "so restrained.")</p>
<p>
	Then in March, Disney was forced to <a href="https://www.cnn.com/2020/03/12/media/mulan-delay-coronavirus/index.html" target="_blank">delay the film's release</a> as the coronavirus pandemic shuttered movie theaters.</p>
<p>
	Even now, its rollout has been stilted. The film was released as a US$30 <a href="https://www.cnn.com/2020/09/04/media/mulan-disney-china-international-release/index.html" target="_blank">video-on-demand </a>last Friday on Disney+, which is only available in certain markets, including the United States. It makes its debut in Chinese theaters this weekend. (Disney+ is not available in China.)</p>
<p>
	The release of the film has renewed the controversy surrounding it, however. Pro-democracy activists in Hong Kong, <a href="https://www.cnn.com/2020/09/04/entertainment/mulan-boycott-hong-kong-trnd/index.html" target="_blank">Thailand and Taiwan</a> have once again called on people to boycott the film because of Yifei's remarks last year.</p>
<p>
	And it's not even clear that the film will win over Chinese audiences, who were already chilly toward the original animated version because of its westernized flair and unfaithful retelling of the original legend.</p>
<p>
	After the release of the trailer in 2019, Chinese state-run media Global Times criticized the film for using<a href="http://www.globaltimes.cn/content/1157286.shtml" target="_blank"> Japanese "ninja gestures"</a> and Chinese stereotypes.</p>
<h3>
	CALLS FOR TRANSPARENCY</h3>
<p>
	Allegations of human rights abuses in Xinjiang stretch back years.</p>
<p>
	In recent years, the Xinjiang government has allegedly undertaken a large campaign to imprison and re-educate Muslim minorities in the region, especially the large Uyghur population.</p>
<p>
	Evidence of widespread human rights abuse has trickled out from inside the region, including <a href="https://www.cnn.com/interactive/2020/02/asia/xinjiang-china-karakax-document-intl-hnk/" target="_blank">lengthy detentions,</a> abuse, <a href="https://www.cnn.com/2019/11/26/asia/china-xinjiang-leaks-analysis-intl-hnk/index.html" target="_blank">indoctrination</a> and <a href="https://www.cnn.com/2020/07/30/asia/xinjiang-sterilization-women-human-rights-intl-hnk/index.html" target="_blank">mass birth control</a> — which experts have described as evidence of "genocide."</p>
<p>
	In 2017, Mulan director Niki Caro posted a photo from Urumqi, the capital of Xinjiang<strong> </strong>and said she was <a href="https://www.instagram.com/p/BZle-neFOc-/?utm_source=ig_embed" target="_blank">scouting out locations</a> for the film. And in an interview in September<strong> </strong>with Conde Nast traveler, Mulan production designer Grant Major discussed filming in Xinjiang's <a href="https://www.cntraveler.com/story/on-location-mulan" target="_blank">Taklamakan Desert</a>, in the region's far southwest.</p>
<p>
	Adrian Zenz, a leading academic<strong> </strong>at the Victims of Communism Foundation who has helped break major stories from Xinjiang, said that the earliest documented case of a re-education center in the region was in Turpan in 2013.</p>
<p>
	Zenz said that while it was possible Disney didn't know about the growing number of detention centers set up across Xinjiang, the widespread oppression in the region was impossible to miss.</p>
<p>
	"There were police stations and checkpoints all over Xinjiang by late 2016, not to be missed," he said.</p>
<p>
	Foreign ministry spokesperson Zhao dismissed Zenz's claims and accused him of making a living "through making Xinjiang-related rumors and slandering China." He also claimed there had been no cases of violence or terrorism in Xinjiang for "more than three consecutive years."</p>
<p>
	Turpan was also the setting for one of the worst outbreaks of ethnic violence in Xinjiang in recent years, when 35 people died during an attack on a police station in Lukqun township, in 2013, <a href="http://www.chinadaily.com.cn/kindle/2013-07/05/content_16731473.htm" target="_blank">according to state media.</a></p>
<p>
	Yaqiu Wang, a China researcher for Human Rights Watch, called for Disney to <a href="https://twitter.com/Yaqiu/status/1303002585155149825" target="_blank">disclose what assistance</a> it had received from Xinjiang authorities and what agreements it had made with the regional government.</p>
<p>
	And<strong> </strong>Asia Society fellow Stone Fish said that many companies were accustomed to making small concessions to the ruling Communist Party to access the Chinese market.</p>
<p>
	"Studios feel like they need to make these compromises to be in Beijing, but you can slightly censor your movies to get into the Chinese market, you can bring Chinese movies that shouldn't be in the States because of poor quality or because of propaganda elements into the States. And you can do that and maintain your integrity, mostly intact," he said.</p>
<p>
	"You don't need to take these extra steps that Disney is taking, and they're rightly getting excoriated for it."</p>

                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/mobile/entertainment/disney-hit-by-backlash-after-thanking-xinjiang-authorities-in-mulan-credits-1.5096476</link>
            <guid isPermaLink="false">hacker-news-small-sites-24415532</guid>
            <pubDate>Wed, 09 Sep 2020 01:01:43 GMT</pubDate>
        </item>
    </channel>
</rss>
