<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 11 Oct 2020 08:28:02 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 11 Oct 2020 08:28:02 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It, Part IVa: Steel Yourself]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24726793">thread link</a>) | @parsecs
<br/>
October 8, 2020 | https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, we continue our four(and a half)-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">II</a>, <a href="https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">III</a>, IVa, IVb) look at pre-modern iron and steel production.  Last week, we looked at how a blacksmith reshapes our iron from a spongy mass called a bloom first into a more workable shape and then finally into some final useful object like a tool.  But as we noted last week, the blacksmith doesn’t just need to manage the shape of the iron, but also its hardness and ductility.</p>



<p>As we’ll see this week, those factors – hardness and ductility (and a bunch of other more complex characteristics of metals which we’re going to leave out for simplicity’s sake) – can be manipulated by changing the chemical composition of the metal itself by <em>alloying</em> the iron with another element, carbon.  And because writing this post has run long and time has run short, <em>next</em> week, we’ll finish up by looking at how those same factors also respond to mechanical effects (work hardening) and heat treatment.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<h2>What Is Steel?</h2>



<p>Let’s start with the absolute basics: <em>what is steel</em>?  Fundamentally, <strong>steel is an alloy of iron and carbon</strong>.  We can, for the most part, dispense with many modern varieties of steel that involve more complex alloys; things like stainless steel (which add chromium to the mix) were unknown to pre-modern smiths and produced only by accident.  Natural alloys of this sort (particularly with manganese) might have been produced by accident where local ores had trace amounts of other metals.  This may have led to the common belief among ancient and medieval writers that iron from certain areas was superior to others (steel from <a href="https://en.wikipedia.org/wiki/Noricum">Noricum </a>in the Roman period, for instance, had this reputation, note Buchwald, <em>op. cit.</em> for the evidence of this), though I have not seen this proved with chemical studies.</p>



<p>So we are going to limit ourselves here to just carbon and iron.  Now in video-game logic, that means you take one ‘unit’ of carbon and one ‘unit’ of iron and bash them together in a fire to make steel.  As we’ll see, the process is at least moderately more complicated than that.  But more to the point: <strong>those proportions are totally wrong</strong>.  Steel is a combination of iron and carbon, <em>but not equal parts or anything close to it</em>.  Instead, the general division goes this way (there are several classification systems but they all have the same general grades):</p>



<p>Below 0.05% carbon or so, we just refer to that as iron.  There is going to be some small amount of carbon in most iron objects, picked up in the smelting or forging process.<br>From 0.05% carbon to 0.25% carbon is mild or low carbon steel.<br>From about 0.3% to about 0.6%, we might call medium carbon steel, although I see this classification only infrequently.<br>From <strong>0.6% to around 1.25%</strong> carbon is <em>high-carbon steel</em>, also known as <strong>spring steel</strong>.  For most armor, weapons and tools, this is the ‘good stuff’ (but see below on pattern welding).<br>From <strong>1.25% to 2%</strong> are ‘ultra-high-carbon steels’ which, as far as I can tell didn’t see much use in the ancient or medieval world.<br><strong>Above 2%</strong>, you have <strong>cast iron</strong> or <strong>pig iron</strong>; excessive carbon makes the steel much too hard and brittle, making it unsuitable for most purposes.</p>



<figure><img data-attachment-id="4764" data-permalink="https://acoup.blog/360074001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg" data-orig-size="2200,2431" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="360074001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=271" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=927" src="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=927" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=927 927w, https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=1854 1854w, https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=136 136w, https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=271 271w, https://acoupdotblog.files.wordpress.com/2020/10/360074001.jpg?w=768 768w" sizes="(max-width: 927px) 100vw, 927px"><figcaption>This is a difficult topic to illustrate so, since the internet is for cat pictures,<a href="https://www.britishmuseum.org/collection/object/A_1993-0714-2"> via the British Museum</a>, here is a Ming Dynasty cast-iron statuette of a cat, 15th or 16th century.  Cast iron production was discovered much earlier in China than in most of the rest of the world, but cast iron products were brittle and not generally suitable for demanding use.</figcaption></figure>



<p>I don’t want to get too bogged down in the exact chemistry of how the introduction of carbon changes the metallic matrix of the iron; <a href="https://en.wikipedia.org/wiki/Steel#Properties">you are welcome to read about it</a>.  <strong>As the carbon content of the iron increases, the iron’s basic characteristics – it’s ductility and hardness (among others) – changes</strong>.  Pure iron, when it takes a heavy impact, tends to deform (bend) to absorb that impact (it is ductile and soft).  Increasing the carbon-content makes the iron harder, causing it to both resist bending more and also to hold an edge better (hardness is the key characteristic for holding an edge through use).  In the right amount, the steel is springy, bending to absorb impacts but rapidly returning to its original shape.  But <em>too much</em> carbon and the steel becomes <em>too</em> hard and not ductile enough, causing it to become brittle.</p>



<p>Compared to the other materials available for tools and weapons, high carbon ‘spring steel’ was essentially the super-material of the pre-modern world.  High carbon steel is <em>dramatically</em> harder than iron, such that a good steel blade will bite – often surprisingly deeply – into an iron blade without much damage to itself.  Moreover, good steel can take fairly high energy impacts and simply bend to absorb the energy before springing back into its original shape (rather than, as with iron, having <em>plastic</em> deformation, where it bends, but doesn’t bend back – which is still better than <em>breaking</em>, but not much).  And for armor, <a href="https://acoup.blog/2019/07/04/collections-archery-distance-and-kiting/">you may recall from our previous</a> look at arrow penetration, a steel plate’s ability to resist puncture is <em>much</em> higher than the same plate made of iron (bronze, by the by, performs about as well as iron, assuming both are work hardened).  of course, different applications still prefer different carbon contents; armor, for instance, tended to benefit from somewhat lower carbon content than a sword blade.</p>



<p>It is sometimes contended that the ancients did not know the difference between iron and steel.  This is mostly a philological argument based on the infrequency of a technical distinction between the two in ancient languages.  Latin authors will frequently use <em>ferrum</em> (iron) to mean both iron and steel; Greek will use <a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.04.0057%3Aentry%3Dsi%2Fdhros&amp;highlight=iron">σίδηρος </a>(sideros, “iron”) much the same way.  The problem here is that high literature in the ancient world – which is almost all of the literature we have – has a strong aversion to technical terms <em>in general</em>; it would do no good for an elite writer to display knowledge more becoming to a tradesman than a senator.  That said in a handful of spots, Latin authors use <a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.04.0059%3Aentry%3Dchalybs1&amp;highlight=steel"><em>chalybs</em> </a>(from the Greek χάλυψ) to mean steel, as distinct from iron.</p>



<p>More to the point, while our elite authors – who are, at most dilettantish observers of metallurgy, never active participants – may or may not know the difference,<strong> ancient artisans clearly did</strong>.  As Tylecote (<em>op. cit.</em>) notes, we see surface carburization on tools as clearly as 1000 B.C. in the Levant and Egypt, although the extent of its use and intentionality is hard to gauge to due rust and damage. There is no such problem with Gallic metallurgy from at least the La Tène period (450 BCE – 50 B.C.) or Roman metallurgy from c. 200 B.C., because we see evidence of smiths quite deliberately varying carbon content over the different parts of sword-blades (more carbon in the edges, less in the core) through pattern welding, which itself can leave a tell-tale ‘streaky’ appearance to the blade (these streaks can be faked, but there’s little point in faking them if they are not already understood to signify a better weapon).  There can be little doubt that the smith who welds a steel edge to an iron core to make a sword blade understands that there is something <em>different</em> about that edge (especially since he cannot, as we can, precisely test the hardness of the two every time – he must know a method that <em>generally</em> produces harder metal and be working from that assumption; high carbon steel, properly produced, can be much harder than iron, as we’ll see).</p>



<figure><img data-attachment-id="4760" data-permalink="https://acoup.blog/34632001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg" data-orig-size="2500,1692" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="34632001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/34632001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/G_1866-0806-1">Via the British Museum</a>, the so-called ‘Sword of Tiberius,’ a Mainz-type Roman gladius from the early imperial period (c. 15 AD).  The sword itself has a mild steel core with high carbon steel edges and a thin coating of high-carbon steel along the flat.  Almost certainly the higher carbon edge was welded on to the mild steel core during manufacture, an example of a blacksmith quite intentionally using different grades of steel.</figcaption></figure>



<p>That said, our ancient – or even medieval – smiths do not understand the chemistry of all of this, of course.  Understanding the effects of carbuzation and how to harness that to make better tools must have been something learned through experience and experimentation, not from theoretical knowledge – a thing passed from master to apprentice, with only slight modification in each generation (though it is equally clear that techniques could move quite quickly over cultural boundaries, since smiths with an inferior technique need only imitate a superior one).</p>



<h2>Making Steel</h2>



<p>Now, in modern steel-making, the main problem is an excess of carbon.  Steel, when smelted in a blast furnace, tends to have far too much carbon.  Consequently a lot of modern iron-working is about walking the steel down to a usefully low amount of carbon <a href="https://en.wikipedia.org/wiki/Steelmaking#Modern_processes">by getting excess carbon out of it</a>.  But ancient iron-working approaches the steeling problem from exactly the opposite direction, likely beginning with something close to a pure mass of iron and having to find ways to get more carbon into that iron to produce steel.</p>



<p><strong>So how do we take our carbon and get it into our iron?</strong>  Well, the good news is that the basic principle is actually very simple: <strong>when hot, iron will absorb carbon from the environment around it, although the process is quite slow</strong> if the iron is not molten (which it never is in these processes).  There are a few stages where that can happen and thus a few different ways of making steel out of our iron.</p>



<p>The popular assumption – in part because it was the working scholarly assumption for quite some time – is that iron can be at least partially …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/">https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/10/09/collections-iron-how-did-they-make-it-part-iva-steel-yourself/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24726793</guid>
            <pubDate>Fri, 09 Oct 2020 04:20:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bye-Bye, Apple]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24726241">thread link</a>) | @rauhl
<br/>
October 8, 2020 | http://blog.cretaria.com/posts/bye-bye-apple.html | <a href="https://web.archive.org/web/*/http://blog.cretaria.com/posts/bye-bye-apple.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                
                <p>Sync’ up! … without getting drained</p>
            </header>
	    <section>
<article>
<p><abbr>oct 8</abbr></p>
<h2>Bye-bye, Apple</h2>
<p>The days of Apple products are behind me.
I had been developing on a Macbook for over
twelve years, but now, I’ve switched to an
ever trending setup: OpenBSD on a Thinkpad.</p>

<p>The new platform is a winner. Everything is
clean, quick, and configurable. When I 
<code>ps uaxww</code>, I’m not hogging ‘gigs’ of <abbr>RAM</abbr>
just to have things up and running. There’s
no black magic that derails me at every turn.
In short, my sanity has been long restored.</p>

<h3>What I miss</h3>


<p>Nothing is better than a fast web browser.
In Mac, this ‘<abbr>OS</abbr> within the <abbr>OS</abbr>’ was 
a mean beast. It certainly ran fast, but
the Chromium package for OpenBSD isn’t all
that bad.</p>

<p>That magnet power interface was a real win
with the Apple laptops. I miss that, in 
addition to speakers that could be maxed
out to their potential.</p>

<h3>On the other hand…</h3>


<p>There’s a healthy list of things I will
forever be glad to never have to deal 
with again:</p>

<ul>
<li>Xcode</li>
<li>the omnipresent ‘Dock’ (never used it once)</li>
<li>the omnipresent ‘Finder’</li>
<li>‘.DS_Store’ files</li>
<li>black magic in the ‘Terminal.app’</li>
<li>Notifications (and its omnipresent menu hamburger icon)</li>
<li>App store</li>
<li>start-up chord</li>
</ul>
<p>I’ve noticed that with every passing year, the
peripheral interface ports are dwindling. On
an older Macbook, I still had <em>some</em> options (<abbr>SD</abbr>
card reader, <abbr>USB2</abbr>, etc.). But lately, it’s out of
control.</p>

<p>On this middle-of-the-road Thinkpad, I have
an <abbr>SD</abbr> card reader,
<abbr>HDMI</abbr>, scads of <abbr>USB</abbr> ports, <abbr>RJ-45</abbr> —
I’m never going to need a dongle, or say the
word dongle, ever again now that Apple is 
out of my life.</p>

<h3>Home again</h3>


<p>My memory is pretty good. And I recall when
I got my first Mac product: it was because
there was no other decent option for
having a development laptop, but one
where Microsoft Windows wasn’t a requirement.</p>

<p>Many times I tried duct-taping a Linux
install on my various Macs, but things 
were ‘just not there.’ There was always
an issue with this or that, and it was
truly painful.</p>

<p>I think I lost the scent of the trail. 
OpenBSD works so well, I wonder how many
years I could have been using this great
<abbr>OS</abbr> outside of just the server world.</p>

<p>Of course, this setup isn’t for all. If
you’re green on the <abbr>UNIX</abbr> front, or
can’t read a manual, you’d be foolish 
to do it. For the others, it certainly
is a viable solution, to say the least.</p>

<p>I can honestly predict that I can see 
myself using this setup for twenty-five
more years. It’s like coming home to a
quiet, orderly house.</p>

<p>Open your heart to OpenBSD on Thinkpad
at your first opportunity.</p><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" viewBox="200 0 400 800" width="400" height="800"><rect width="400" height="800" fill="#b33a3a"></rect><polygon points="299.5 150 254.5 247 351.5 247 "></polygon><path d="m321.9 548.9l-243.8 0"></path><path d="m303 247.1l0 243.8"></path><polygon points="94.5 150 49.5 247 146.5 247 "></polygon><path d="m98 247.1l0 243.8"></path><text font-family="Helvetica, Arial, sans-serif" font-size="60" y="112" x="10" style="fill-opacity:null">THIS END UP</text><a xlink:href="//cretaria.com"><text id="link-cretaria" font-family="Helvetica, Arial, sans-serif" font-size="50" y="680" x="10" fill-opacity="null">What’s Cretaria?</text></a><path d="m175 700l200 0" style="fill-opacity:null;fill:none;stroke-linejoin:null;stroke-opacity:null;stroke-width:4;stroke:#000"></path></svg></p></article>
            </section>
            
        </div></div>]]>
            </description>
            <link>http://blog.cretaria.com/posts/bye-bye-apple.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24726241</guid>
            <pubDate>Fri, 09 Oct 2020 02:49:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Report may suggest that login requirement for Oculus Quest 2 is anticompetitive]]>
            </title>
            <description>
<![CDATA[
Score 300 | Comments 144 (<a href="https://news.ycombinator.com/item?id=24725515">thread link</a>) | @vrfinal
<br/>
October 8, 2020 | https://www.vrfinal.com/report-from-the-house-of-representatives-may-suggest-that-the-facebook-login-requirement-for-the-oculus-quest-2-is-anticompetitive/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/report-from-the-house-of-representatives-may-suggest-that-the-facebook-login-requirement-for-the-oculus-quest-2-is-anticompetitive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <main>
            <article>
                            <p><time datetime="2020-10-08">
                  Oct 08, 2020
                </time>
                <span>2 min read</span>
              </p>
                <div>
    <p><a href="https://www.vrfinal.com/report-from-the-house-of-representatives-may-suggest-that-the-facebook-login-requirement-for-the-oculus-quest-2-is-anticompetitive/">
        <img data-srcset="/content/images/size/w400/2020/10/Oculus.png 400w, /content/images/size/w750/2020/10/Oculus.png 750w, /content/images/size/w960/2020/10/Oculus.png 960w" data-sizes="auto" alt="Report from the House of Representatives may suggest that the Facebook login requirement for the Oculus Quest 2 is anticompetitive." srcset="https://www.vrfinal.com/content/images/size/w400/2020/10/Oculus.png 400w, https://www.vrfinal.com/content/images/size/w750/2020/10/Oculus.png 750w, https://www.vrfinal.com/content/images/size/w960/2020/10/Oculus.png 960w">
      </a>
    </p>
  </div>
              <div>
                <div>
                  <p><a href="https://www.documentcloud.org/documents/7222836-Investigation-of-Competition-in-Digital-Markets.html">A recent report</a> from the US House of Representatives subcommittee on antitrust laws suggests that the requirement for all Quest 2 users to login via a Facebook account may be anticompetitive.</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/ts_oculus-quest-2.png" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/ts_oculus-quest-2.png 600w, https://www.vrfinal.com/content/images/2020/10/ts_oculus-quest-2.png 960w" sizes="(min-width: 720px) 720px"></figure><p>The Oculus Quest 2 is the first headset produced by Facebook that requires users to create an account on their social media site in order to set it up. The report states that, <em>“conditioning access to a product or service in which a firm has market power to the use of a separate product or service is anticompetitive.”</em></p><p>The report, which clocks in at a terrify 449 pages, investigates the issues of competition in the digital market. The report looks at companies like Amazon, Google, Apple, and yes, Facebook. The report only mentions VR a small number of times, but it does go into detail about the large acquisitions of that each company has made. This includes Facebook’s purchase of Oculus in 2014.</p><p>The report states,</p><p><em>“Facebook has also maintained and expanded its dominance through a series of acquisitions of companies it viewed as competitive threats, and selectively excluded competitors from using its platform to insulate itself from competitive pressure.</em></p><p><em>Facebook has also maintained its monopoly through a series of anticompetitive business practices. The company used its data advantage to create superior market intelligence to identify nascent competitive threats and then acquire, copy, or kill these firms. Once dominant, Facebook selectively enforced its platform policies based on whether it perceived other companies as competitive threats. In doing so, it advantaged its own services while weakening other firms.”</em></p><figure><img src="https://www.vrfinal.com/content/images/2020/10/Sidequest-New-Logo-1.jpg" alt=""></figure><p>This has major implications for the future of the Oculus and developers, we have seen Facebook flex their considerable power over smaller developers. We have previously reported on the issues that the <a href="https://www.vrfinal.com/unofficial-oculus-quest-appstore-receives-650-000-in-funding/">developer focused app store, Sidequest</a>, has had in gaining purchase in the Oculus ecosystem, not to mention the <a href="https://www.vrfinal.com/vr-developers-are-concerned-about-facebooks-walled-garden/">side-lining of the VR steaming service, Bigscreen</a>, by giving favourable terms to large companies like Fandango. With Facebook offering the most affordable headset on the market, we may see even more developers become disillusioned with the Oculus ecosystem and move on to greener pastures.</p>
                </div>
                  
                              </div>
            </article>
              <section>
    <p><img data-src="/content/images/size/w150/2020/09/IMG_20200812_155324.jpg" alt="Andrew Boggs" src="https://www.vrfinal.com/content/images/size/w150/2020/09/IMG_20200812_155324.jpg">
    </p>
    <div>
      
      <p>Andrew is a Northern Ireland based journalist with a passion for video games. His latest hobby is watching people speedrun Super Mario 64 and realising how bad he is at platformers.</p>
    </div>
  </section>
            <div>
      <div>
        <p><img data-srcset="/content/images/size/w400/2020/10/jump-vr-headset-1021x580.jpg 400w, /content/images/size/w750/2020/10/jump-vr-headset-1021x580.jpg 750w, /content/images/size/w960/2020/10/jump-vr-headset-1021x580.jpg 960w" data-sizes="auto" alt="Co-Founder of The Void announces his new VR attraction: Skydiving" srcset="https://www.vrfinal.com/content/images/size/w400/2020/10/jump-vr-headset-1021x580.jpg 400w, https://www.vrfinal.com/content/images/size/w750/2020/10/jump-vr-headset-1021x580.jpg 750w, https://www.vrfinal.com/content/images/size/w960/2020/10/jump-vr-headset-1021x580.jpg 960w">
        <span>Previous Post</span></p><h4>Co-Founder of The Void announces his new VR attraction: Skydiving</h4>
        </div>

    <div>
      <p><img data-srcset="/content/images/size/w400/2020/10/all-new-zapbox-1.png 400w, /content/images/size/w750/2020/10/all-new-zapbox-1.png 750w, /content/images/size/w960/2020/10/all-new-zapbox-1.png 960w" data-sizes="auto" alt="The All-New ZapBox revealed on Kickstarter, MR headset for only $40" srcset="https://www.vrfinal.com/content/images/size/w400/2020/10/all-new-zapbox-1.png 400w, https://www.vrfinal.com/content/images/size/w750/2020/10/all-new-zapbox-1.png 750w, https://www.vrfinal.com/content/images/size/w960/2020/10/all-new-zapbox-1.png 960w">
      <span>Next Post</span></p><h4>The All-New ZapBox revealed on Kickstarter, MR headset for only $40</h4>
      </div>
</div>            


        </main>
      </div>
    </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/report-from-the-house-of-representatives-may-suggest-that-the-facebook-login-requirement-for-the-oculus-quest-2-is-anticompetitive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24725515</guid>
            <pubDate>Fri, 09 Oct 2020 00:35:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never Again: We Need Science Based Government]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 35 (<a href="https://news.ycombinator.com/item?id=24725512">thread link</a>) | @pbw
<br/>
October 8, 2020 | https://www.kmeme.com/2020/10/never-again.html | <a href="https://web.archive.org/web/*/https://www.kmeme.com/2020/10/never-again.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4155188876056568307" itemprop="description articleBody">
<p>This year Americans have been whipsawed between feelings of fear and helplessness. More than 200,000 of us died from COVID-19, the streets raged in conflict, and wildfires destroyed more than seven million acres of wilderness.</p>

<p>The media and the general public turned to scientists to help understand all three crises, but President Trump did not. Instead, he steadfastly and repeatedly denounced scientific consensus. He vociferously denigrated scientists and their beliefs. He invented pet theories during press events and routinely ignored even his own advisors.</p>

<p>Today we are focused on the general election, but even if Mr. Trump loses, Pandora's box sits wide open. We now know an administration can wreak havoc by wantonly flouting scientific consensus. We cannot let this happen again, we cannot allow <i>either</i> party to do this again. The United States cannot function effectively as a country if our leaders invent their own scientific reality and force us to live within it.</p>

<p><a href="https://lh3.googleusercontent.com/-zLGOoGGvFag/X3-HeQXuz2I/AAAAAAAFGxw/NldY4MGcvvU-Wbc-5BTas2g5M0mGQEY9gCLcBGAsYHQ/image.png"><img data-original-height="1013" data-original-width="1520" height="426" src="https://lh3.googleusercontent.com/-zLGOoGGvFag/X3-HeQXuz2I/AAAAAAAFGxw/NldY4MGcvvU-Wbc-5BTas2g5M0mGQEY9gCLcBGAsYHQ/w640-h426/image.png" width="640"></a></p>

<p>Ruth Bader Ginsburg passed away on September 18th. She served 27 years as a beloved member of the nine-person Supreme Court, an institution that strives to ensure the American promise of equal justice under law.</p>

<p>However, the Supreme Court is two-hundred and thirty years old, founded seventy years before <i>On The Origin of Species</i> was published, one-hundred twenty years before Albert Einstein’s famous equation, and nearly two-hundred years before the internet crackled to life.</p>

<p>In the 2020s we need to set up a new institution. An institution that can absorb the scientific consensus, communicate that understanding to the rest of the government, and shape our laws and policies in light of the best-known science. The Science Council will not run things, it will serve only as a check and balance against the three existing branches of government, including the Supreme Court.</p>

<p>We need to make sure no future administration can dismantle the scientific footing of the nation as if discarding the previous administration's choice of drapes in the West Wing.</p>

<p>President Ronald Reagan formed the twelve-person Rogers Commission after the Challenger exploded shortly after lift-off in 1986. The commission featured the esteemed physicist Richard Feynman. We desperately need a standing council of similar stature with permanent members and the mandate to foster science within the government.</p>

<p>Since the internet now exists, the council will cultivate and leverage an online community of millions of scientists throughout the world to augment their own personal expertise.</p>

<p>The Science Council needs real power in the government, we do not need another National Academy of Sciences. In normal times the council can focus on education, verifying facts, and serving as a resource for other branches.</p>

<p>However, if a future president once again claims climate change or a pandemic is a hoax, the council would respond with full force using whatever political mechanisms we grant it.</p>

<p>We also desperately need scientific thinking on issues that might not seem overtly science-based. This year civil unrest and sickening violence was a nightly presence in the news. Mr. Trump responded to the unrest by pronouncing himself the law and order president. This approach more subtly but equally flouts conventional scientific thinking.</p>

<p><a href="https://1.bp.blogspot.com/-7lsy9L0nzBg/X3-I9x6XJzI/AAAAAAAFGyA/xcz_JiE33BMUfWrteIEuFKAgT1DgAsvTACLcBGAsYHQ/s1166/pathways.png"><img data-original-height="733" data-original-width="1166" height="402" src="https://1.bp.blogspot.com/-7lsy9L0nzBg/X3-I9x6XJzI/AAAAAAAFGyA/xcz_JiE33BMUfWrteIEuFKAgT1DgAsvTACLcBGAsYHQ/w640-h402/pathways.png" width="640"></a></p>
<p>The country is a large physical system that obeys scientific laws whether you believe it does or not, whether you personally know the laws or not. The violent acts of 2020 are kernels of corn popping in hot oil. Our law and order president wants to sweep away this inconvenient problem by forcefully crushing the popcorn back into its kernel form.</p>

<p>Instead, we need science to guide us towards turning down the heat, to guide us towards carefully lowering the temperature. We need to use the best science in sociology, psychology, anthropology, economics, and every other scientific field. We face hard problems, but millions of our citizens trained their entire lives to solve exactly these problems. We need to put them to work.</p>

<p>Mr. Trump walked us down the dark path. We need to create a new institution that will light the way for future generations, so that they do not go down that same path, so that the great American experiment can continue, so that our country is around for the next two hundred years and beyond.</p>

</div></div>]]>
            </description>
            <link>https://www.kmeme.com/2020/10/never-again.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24725512</guid>
            <pubDate>Fri, 09 Oct 2020 00:35:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Police violence: Your ratios don't prove what you think they prove]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24724115">thread link</a>) | @dyno-might
<br/>
October 8, 2020 | https://dyno-might.github.io/2020/10/08/police-violence-your-ratios-dont-prove-what-you-think-they-prove/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/10/08/police-violence-your-ratios-dont-prove-what-you-think-they-prove/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        







<div>
    <div>
        <div>
            
            <p><strong>Oct 8, 2020</strong></p>
            
            

<p>Watching people discuss police bias statistics, I despair. Some claim simple calculations prove police bias, some claim the opposite. Who is right?</p>

<p>No one. Frankly, nobody has any clue what they are talking about. It’s not that the statistics are <em>wrong</em> exactly. They just don’t prove what they’re being used to prove. In this post, I want to explain why, and give you the tools to dissect these kinds of claims.</p>

<p>I’ve made every effort to avoid politics, due to my <a href="https://dyno-might.github.io/2020/09/29/doing-discourse-better-stuff-i-wish-i-knew/">naive dream</a> where well-meaning people can agree on facts even if they don’t agree on policy.</p>



<p>The obvious place to start is to look at the number of people killed by police. This is easy to find.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Black</th>
      <th>White</th>
      <th>Hispanic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># in US (million)</td>
      <td>41.3</td>
      <td>185.5</td>
      <td>57.1</td>
    </tr>
    <tr>
      <td># killed by police per year</td>
      <td>219</td>
      <td>440</td>
      <td>169</td>
    </tr>
    <tr>
      <td># killed by police per million people</td>
      <td>5.3</td>
      <td>2.3</td>
      <td>2.9</td>
    </tr>
  </tbody>
</table>

<p>Does this prove the police are racist? Before you answer, consider a different division of the population.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Male</th>
      <th>Female</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># in US (million)</td>
      <td>151.9</td>
      <td>156.9</td>
    </tr>
    <tr>
      <td># killed by police per year</td>
      <td>944</td>
      <td>46</td>
    </tr>
    <tr>
      <td># killed by police per million people</td>
      <td>6.2</td>
      <td>0.29</td>
    </tr>
  </tbody>
</table>

<p>And here’s a third one.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>&lt;18 y/o</th>
      <th>18-29</th>
      <th>30-44</th>
      <th>45+</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># in US (million)</td>
      <td>72.9</td>
      <td>53.6</td>
      <td>63.2</td>
      <td>137.3</td>
    </tr>
    <tr>
      <td># killed by police per year</td>
      <td>19</td>
      <td>283</td>
      <td>273</td>
      <td>263</td>
    </tr>
    <tr>
      <td># killed by police per million people</td>
      <td>0.26</td>
      <td>5.2</td>
      <td>4.3</td>
      <td>1.9</td>
    </tr>
  </tbody>
</table>

<p>The first table above is often presented as an obvious “smoking gun” that proves police racism with no further discussion needed. But if that were true, then the second would be a smoking gun for police <em>sexism</em> and the third for police <em>ageism</em>. So let’s keep discussing.</p>

<p>Of course, the second and third tables have obvious explanations: Men are different from women. The young are different from the old. Because of this, they interact with the police in different ways. Very true! But the following is also true:</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Black</th>
      <th>White</th>
      <th>Hispanic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>average height (men)</td>
      <td>175.5cm (5’9”)</td>
      <td>177.4cm (5’10)</td>
      <td>169.5cm (5’7”)</td>
    </tr>
    <tr>
      <td>life expectancy</td>
      <td>74.9 yrs</td>
      <td>78.5 yrs</td>
      <td>81.8 yrs</td>
    </tr>
    <tr>
      <td>mean annual income</td>
      <td>$41.5k</td>
      <td>$65.9k</td>
      <td>$51.4k</td>
    </tr>
    <tr>
      <td>median age</td>
      <td>33 yrs</td>
      <td>43 yrs</td>
      <td>28 yrs</td>
    </tr>
    <tr>
      <td>go to church regularly</td>
      <td>65%</td>
      <td>53%</td>
      <td>45%</td>
    </tr>
    <tr>
      <td>children in single-parent homes</td>
      <td>65%</td>
      <td>24%</td>
      <td>41%</td>
    </tr>
    <tr>
      <td>identify as LGBT</td>
      <td>4.6%</td>
      <td>3.6%</td>
      <td>5.4%</td>
    </tr>
    <tr>
      <td>live in a large urban area</td>
      <td>82%</td>
      <td>61%</td>
      <td>82%</td>
    </tr>
    <tr>
      <td>poverty</td>
      <td>21%</td>
      <td>8.1%</td>
      <td>17%</td>
    </tr>
    <tr>
      <td>men obese</td>
      <td>41%</td>
      <td>44%</td>
      <td>45%</td>
    </tr>
    <tr>
      <td>women obese</td>
      <td>56%</td>
      <td>39%</td>
      <td>43%</td>
    </tr>
    <tr>
      <td>completed high school</td>
      <td>87%</td>
      <td>93%</td>
      <td>66%</td>
    </tr>
    <tr>
      <td>completed bachelor’s</td>
      <td>22%</td>
      <td>36%</td>
      <td>15%</td>
    </tr>
    <tr>
      <td>heavy drinkers</td>
      <td>4.5%</td>
      <td>7.1%</td>
      <td>5.1%</td>
    </tr>
  </tbody>
</table>

<p>Maybe it’s uncomfortable, but it’s a fact: In the US today, there are few traits where there <em>aren’t</em> major statistical differences between races.</p>



<p>Suppose police were required wear augmented reality goggles. On those goggles, real-time image processing changes faces so that race is invisible. Would doing this cause police statistics to equalize with respect to race?</p>

<p>No. Even if race is <em>literally invisible</em>, young urban alcoholics will have different experiences with police than old teetotalers on farms. The fraction of these kinds of people varies between races. Thus, racial averages will still look different because of things that are <em>associated with race</em> but aren’t <em>race as such</em>.</p>

<p>So despite the thousands of claims to the contrary, just looking at killings as a function of population size doesn’t prove bias. Not does it prove a lack of bias. It really doesn’t prove anything.</p>



<p>Why do police kill more men than women? We can’t rule out police bias. But surely it’s relevant that men and women behave differently? So, it might seem like we should normalize not by population size, but by <em>behavior</em>.</p>

<p>One popular suggestion is to consider the number of arrests:</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Black</th>
      <th>White</th>
      <th>Hispanic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># killed by police per year</td>
      <td>219</td>
      <td>440</td>
      <td>169</td>
    </tr>
    <tr>
      <td># arrests for violent crimes per year (thousands)</td>
      <td>146</td>
      <td>230</td>
      <td>83</td>
    </tr>
    <tr>
      <td># killed by police per thousand violent crime arrests</td>
      <td>1.4</td>
      <td>1.9</td>
      <td>1.9</td>
    </tr>
  </tbody>
</table>

<p>Some claim this proves the police <em>aren’t</em> biased, or even that there is bias in favor of blacks. But that’s nearly circular logic: If police are biased, that would manifest in arrests as much as killings. So what we are really calculating above is</p><p>

\[\frac{\text{“Normal” killings + killings due to bias}}{\text{“Normal” arrests + arrests due to bias}}.\]

</p><p>The ratio doesn’t tell you much about how large the bias terms are. So, unfortunately this also doesn’t prove anything.</p>

<p>Incidentally: There are some <a href="https://twitter.com/leonydusjohnson/status/1267466345844740098">popular but different</a> numbers out there for this same ratio. These have tens of thousands of re-tweets with no one questioning the math. But I’ve checked the source data carefully, and I’m pretty sure my numbers are right. (They reach the same basic conclusion anyway.)</p>



<p>The police have discretion when deciding to make an arrest. But a dead body either exists or doesn’t. So why not normalize by the number of murders committed?</p>

<p>This turns out to be basically impossible:</p>
<ul>
  <li>Something like 40% of murders go unsolved, so the race of the murderer is unknown.</li>
  <li>The only real source of murder statistics is the <a href="https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/expanded-homicide-data-table-6.xls">FBI</a>. They treat hispanic/non-hispanic ethnicity as <em>independent</em> of race. Why not just ignore hispanics then? Well, you can’t. Hispanics are still counted as white or black in an unknown way. It’s impossible to compare to police shooting statistics where hispanic is an alternative race.</li>
  <li>In around 31% of cases, the FBI has <a href="https://ucr.fbi.gov/crime-in-the-u.s/2017/crime-in-the-u.s.-2017/tables/expanded-homicide-data-table-3.xls">no information</a> about race, and in 40% of cases, no information about ethnicity.</li>
</ul>

<p>I’ve seen tons of articles use <a href="https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/expanded-homicide-data-table-6.xls">this version</a> of the FBI’s murder data that simply drops all the cases where data are unknown. None of these articles even acknowledge the issue of missing data or different treatment of hispanics.</p>

<p>Instead, let’s look at murder <em>victims</em>. This is counterintuitive, but it’s <a href="https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/expanded-homicide-data-table-6.xls">relatively rare</a> for murders to cross racial boundaries (&lt;20%). So this is a non-terrible proxy for the number of murders committed. Data from the CDC separates out black, white, and hispanics in a similar way as police shooting statistics.</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Black</th>
      <th>White</th>
      <th>Hispanic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td># killed by police per year</td>
      <td>219</td>
      <td>440</td>
      <td>169</td>
    </tr>
    <tr>
      <td># murder victims per year</td>
      <td>9,908</td>
      <td>5,747</td>
      <td>3,186</td>
    </tr>
    <tr>
      <td># killed by police per murder victim</td>
      <td>0.022</td>
      <td>0.076</td>
      <td>0.053</td>
    </tr>
  </tbody>
</table>

<p>So what does this prove? Again, not much. The simple fact is that most police killings are <strong>not in the context of a murder or a murder investigation</strong>. Though there are <a href="https://medcraveonline.com/FRCIJ/FRCIJ-06-00237.pdf">exceptions</a>, the precise <em>context</em> of police killings hasn’t had enough study, and definitely not enough to get reliable statistics.</p>



<p>Really, though, it’s not an issue of lacking data. Philosophically, consider the any possible ratio like</p><p>

\[\frac{\text{# of people of a race killed by police}}{\text{# of times act } X \text{ committed by a member of a race}}.\]

</p><p>For what act \(X\) does this really measure police bias? I think it’s pretty clear that <strong>no such act exists</strong>, even if we could measure it. Races vary along too many dimensions. There are too many scenarios for police use of force. Bias interacts with the world in too many ways. You just can’t learn anything meaningful with these sort of simplistic high-level statistics.</p>

<p>This doesn’t mean we need to give up. It just means you need to get closer and try harder. In the next part of this series I’ll look at some valiant attempts to do that. They will disappoint us too, but for different reasons.</p>

<p><strong>Data Used:</strong></p>
<ul>
  <li><a href="https://www.washingtonpost.com/graphics/investigations/police-shootings-database/">Police shootings</a> (average 2017-2019)</li>
  <li><a href="https://www.census.gov/quickfacts/fact/table/US/PST045219">Number of people of each race / sex</a></li>
  <li><a href="https://data.census.gov/cedsci/table?q=S01&amp;d=ACS%201-Year%20Estimates%20Subject%20Tables&amp;tid=ACSST1Y2019.S0101">Number of people by age</a></li>
  <li>Data by race: <a href="https://www.cdc.gov/nchs/data/nvsr/nvsr68/nvsr68_07-508.pdf">Life expectancy</a> / <a href="https://en.wikipedia.org/wiki/List_of_ethnic_groups_in_the_United_States_by_household_income">Income</a> / <a href="https://www.medicinenet.com/height_men/article.htm">Height</a> / <a href="https://news.gallup.com/poll/248837/church-membership-down-sharply-past-two-decades.aspx">Church</a> / <a href="https://datacenter.kidscount.org/data/tables/107-children-in-single-parent-families-by-race#detailed/1/any/false/37,871,870,573,869,36,868,867,133,38/10,11,9,12,1,185,13/432,431">Single-parent homes</a> / <a href="https://news.gallup.com/poll/201731/lgbt-identification-rises.aspx">Identifying LGBT</a> / <a href="https://www.pewresearch.org/hispanic/2016/04/20/the-nations-latino-population-is-defined-by-its-youth/">Median age</a> / <a href="https://www.census.gov/content/dam/Census/library/publications/2016/demo/p20-578.pdf">School</a> / <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5205547/">Drinking</a> / <a href="https://fas.org/sgp/crs/misc/R46294.pdf">Poverty</a> / <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/1475-6773.13106">Urbanity</a> / <a href="https://www.cdc.gov/nchs/data/databriefs/db360_tables-508.pdf#page=2">Obesity</a></li>
  <li><a href="https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/table-43">Arrests for violent crime</a></li>
  <li><a href="https://www.cdc.gov/nchs/data/nvsr/nvsr68/nvsr68_09-508.pdf">Murder victims</a> (p. 43)</li>
</ul>

        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/10/08/police-violence-your-ratios-dont-prove-what-you-think-they-prove/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24724115</guid>
            <pubDate>Thu, 08 Oct 2020 21:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatically Detecting and Documenting API Endpoints with Akita]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24723110">thread link</a>) | @jeanyang
<br/>
October 8, 2020 | https://www.akitasoftware.com/blog/2020/10/8/detecting-and-documenting-api-endpoints-with-akita | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/10/8/detecting-and-documenting-api-endpoints-with-akita">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <header>
          <div data-nc-group="bottom">
            
            <div data-nc-container="bottom-center">

              <p><a href="https://www.akitasoftware.com/" data-nc-element="branding" data-content-field="site-title">
                
                  
                    <img src="https://static1.squarespace.com/static/5b6f6c558ab722caa37858bf/t/5eec170153421321c1245a78/1602184424311/?format=1500w" alt="Akita Software">
                  
                
              </a></p><p>Making software better.</p>

            </div>
            
          </div>
        </header>

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f7f61f98472762c94f2dd1e" data-item-id="5f7f61f98472762c94f2dd1e">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1602184018149" id="item-5f7f61f98472762c94f2dd1e"><div><div><div data-block-type="2" id="block-88e1cf04a79efcc55c84"><div><p>As companies grow, the number of internal services often grows too. What does not grow is the amount of love given to helping developers use internal services. In this blog post, we talk about how we help software teams make sense of the hairball that is your internal services and APIs. We introduce one of our newest features: automatically generated specs for your <em>outbound</em> API calls!</p><h2>😨 The endless attic of internal APIs</h2><p>Think about the last time you used a third-party SaaS API. If it was well-documented, like Stripe or Twilio, it may have been a pleasure to use.</p><p>Now think about the last time you used an internal API at your company. If it was also a pleasure to read, talk to us. We want to know what your company does to make this possible. 😊 But chances are, you hit some roadblocks.</p><p>It turns out that companies that make a lot of money on their external APIs can afford to spend a lot of resources on keeping the documentation up to date and doing things like <a href="https://engineering.shopify.com/blogs/engineering/shopify-manages-api-versioning-breaking-changes"><span>change impact analysis</span></a> to make sure their developer community does not get negatively impacted by changes. But even automatically generated documentation frameworks take work. And even the best change impact analysis systems require manual work, as it’s not simply a matter of running a code checker. So while fancy external-facing APIs get the VIP treatment in terms of documentation and stability, internal APIs are left to run wild.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_196790"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185593697-74G8J6LHAI6UNLYBQVC1/ke17ZwdGBToddI8pDm48kCe4lo_81hB0z5l4CmWwKn1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFczJzr9RKZ_bzU3H3hHgcrxJs6quDTsVn0bUV6XWukvtoqoyhqEat3ZTPGdmbdjAo/brick_facade.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185593697-74G8J6LHAI6UNLYBQVC1/ke17ZwdGBToddI8pDm48kCe4lo_81hB0z5l4CmWwKn1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFczJzr9RKZ_bzU3H3hHgcrxJs6quDTsVn0bUV6XWukvtoqoyhqEat3ZTPGdmbdjAo/brick_facade.jpg" data-image-dimensions="422x281" data-image-focal-point="0.5,0.5" alt="External APIs with the resources for tooling get  some  love—but there could be more." data-load="false" data-image-id="5f7f697995ab451ef92e2270" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185593697-74G8J6LHAI6UNLYBQVC1/ke17ZwdGBToddI8pDm48kCe4lo_81hB0z5l4CmWwKn1Zw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFczJzr9RKZ_bzU3H3hHgcrxJs6quDTsVn0bUV6XWukvtoqoyhqEat3ZTPGdmbdjAo/brick_facade.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>External APIs with the resources for tooling get <em>some</em> love—but there could be more.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_201201"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185737055-J3ZNZR8YRD1N4ZOYCTOG/ke17ZwdGBToddI8pDm48kMFU7B-thr5IpG_tMV5QtbVZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGvaT6n7hOH3sJuy371p6-JR9kiBajMJjd_8d5NGEjnyVtO8nJtk629tZGIWiyY3XQ/weeds.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185737055-J3ZNZR8YRD1N4ZOYCTOG/ke17ZwdGBToddI8pDm48kMFU7B-thr5IpG_tMV5QtbVZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVGvaT6n7hOH3sJuy371p6-JR9kiBajMJjd_8d5NGEjnyVtO8nJtk629tZGIWiyY3XQ/weeds.gif" data-image-dimensions="300x224" data-image-focal-point="0.5,0.5" alt="Everybody else is left in a vast unpaved lot with weeds." data-load="false" data-image-id="5f7f69ff5bd8a22c567cf795" data-type="image">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Everybody else is left in a vast unpaved lot with weeds.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_197089"><p>What’s happening is that even though internal APIs are becoming more and more common, they are not getting any easier to use. Finding and figuring out how to use internal APIs, especially at a large organization with many microservices, becomes something like rifling through an endless, poorly organized attic. As a result, developers struggle with everything from finding the right API to use, to figuring out how to use the APIs, to keeping up with changes to those APIs. The tooling is leaving developers behind.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_70089"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184620428-YYBSV753NAGVJ1Z8N8UP/ke17ZwdGBToddI8pDm48kHOLkWwYqWOvR0G_edQ-96VZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEX4JQXcd48CO__8WcidP91C_pJHQ0N8vWPWU86nW7Wgu87Nsj43NRAr6WuWZv5DKs/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184620428-YYBSV753NAGVJ1Z8N8UP/ke17ZwdGBToddI8pDm48kHOLkWwYqWOvR0G_edQ-96VZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEX4JQXcd48CO__8WcidP91C_pJHQ0N8vWPWU86nW7Wgu87Nsj43NRAr6WuWZv5DKs/image-asset.gif" data-image-dimensions="352x260" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f7f65a4cb08614b82e76c40" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_70388"><div><h2>👀 Discovering endpoints with Akita</h2><p>Now we’ll show you how Akita helps developers use internal APIs better!</p><p>In a <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">previous blog post</a>, we introduced our tool that automatically generates API specs by watching network traffic:</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_75089"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184704149-FYARR7C1AAHSMSRZMDLW/ke17ZwdGBToddI8pDm48kEE5BRPVFdSFNJ9EWVjnQtJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzBAkhzHXcTUkbSFC51ULQzwiZaehtpr50pAWHTpVqK6r115xOpNXu01MbofqMIiwU/ezgif.com-gif-maker.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184704149-FYARR7C1AAHSMSRZMDLW/ke17ZwdGBToddI8pDm48kEE5BRPVFdSFNJ9EWVjnQtJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzBAkhzHXcTUkbSFC51ULQzwiZaehtpr50pAWHTpVqK6r115xOpNXu01MbofqMIiwU/ezgif.com-gif-maker.gif" data-image-dimensions="600x393" data-image-focal-point="0.5,0.5" alt="ezgif.com-gif-maker.gif" data-load="false" data-image-id="5f7f65fecb08614b82e77b44" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_75388"><div><p>But one question we kept getting was:<em> but how do we even know which APIs we need to document? </em>It turns out that at companies with many services, one reason it’s hard to untangle the services hairball is to figure out which services are involved in the first place.</p><p>We had been very proud of how non-invasive our API spec generation tooling was (no code changes, no proxies!) and we wanted to keep things that way. So we asked ourselves if we could use the same techniques to figure out what requests were also going <em>out</em> to internal services and third-party SaaS. It turns out the answer is yes.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_79995"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184763375-GC3UE7NOE3ZFCXSFIPL2/ke17ZwdGBToddI8pDm48kPNjuB-A-ajUh-wmnV_6IIFZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEslm_1rIN2a3J1-oVQMHpPlo94MczC2UEOraXY_Qw8c_y_8EGDnYcl4fW3rA_CdF4/deathstar.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184763375-GC3UE7NOE3ZFCXSFIPL2/ke17ZwdGBToddI8pDm48kPNjuB-A-ajUh-wmnV_6IIFZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEslm_1rIN2a3J1-oVQMHpPlo94MczC2UEOraXY_Qw8c_y_8EGDnYcl4fW3rA_CdF4/deathstar.jpeg" data-image-dimensions="317x159" data-image-focal-point="0.5,0.5" alt="deathstar.jpeg" data-load="false" data-image-id="5f7f663be4d1b85618915322" data-type="image" src="https://www.akitasoftware.com/blog/2020/10/8/deathstar.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_80294"><p>We’re excited to introduce a new capability that gets us one step closer to unrolling the internal services hairball by doing <strong>automatic API endpoint detection</strong>. When you generate an API spec, Akita is able to now tell you about your<em> outgoing </em>API calls as well.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_84866"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184818205-2KDPK8HJ2WQAWSX2WUIS/ke17ZwdGBToddI8pDm48kGM2NkLZGsNUBDsu12QeHQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpw7w0BOcRTmqxdbnv0IaM2RvCi5Fl42DoZkCpTOSLYtWB_BiH-pPUd5adX8ZF3rohU/image-asset.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602184818205-2KDPK8HJ2WQAWSX2WUIS/ke17ZwdGBToddI8pDm48kGM2NkLZGsNUBDsu12QeHQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpw7w0BOcRTmqxdbnv0IaM2RvCi5Fl42DoZkCpTOSLYtWB_BiH-pPUd5adX8ZF3rohU/image-asset.gif" data-image-dimensions="600x380" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f7f666fbc33371a0ffa9bf0" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180106542_85165"><div><p>As with inbound spec generation, the Akita command-line agent watches outgoing API calls, doing some light analysis and sending metadata back to the Akita cloud. Combining this with our <a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">type and data format detection</a>, Akita is also now able to tell you things like which sensitive data types are going to other services:</p><p>Our Outbound Specs allows you to:</p><ul data-rte-list="default"><li><p>See what internal APIs you currently depend on.</p></li><li><p>See the specs for those APIs.</p></li><li><p>See what you’re sending to those APIs.</p></li><li><p>Get alerted about when these internal APIs change.</p></li></ul><p>We’re also working on some cool technology to map requests to responses. More on that soon!&nbsp;</p><h2>⚡️ What now?</h2><p>While generating API specs gives you the ability to understand a single API, outbound API specs detection starts helping you understand the <em>API graph</em>, the interaction graph of your system <em>across</em> services. We are very excited about where this is going!</p><p>If this sounds exciting to you, we’d love to get you involved as we build out the Akita product.</p><ul data-rte-list="default"><li><p>If you’re interested in API spec generation, data format detection, or API endpoint detection, try out the <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">Akita private beta</a>!</p></li><li><p>Help us improve our product by filling out <a href="https://akitasoftware.typeform.com/to/iAbs1tB5?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">our change management survey</a>, with a chance to win a $50 Amazon gift certificate!</p></li><li><p><a href="https://twitter.com/akitasoftware?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_08_product_update">Follow us on Twitter</a> for updates. </p></li><li><p>Help us spread the word about Akita. 💖</p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1602180106542_158728"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185303115-45NMKUCZO17C3VX5QX3Q/ke17ZwdGBToddI8pDm48kCNvdmxXRFB2FiyH8C0qYTNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVElifA8JgkQH-c2R2A7sIPW6FxJCPsUM8f1waoDkZ_PK6QvevUbj177dmcMs1F0H-0/taylor_swift_thank_you.gif" data-image="https://images.squarespace-cdn.com/content/v1/5b6f6c558ab722caa37858bf/1602185303115-45NMKUCZO17C3VX5QX3Q/ke17ZwdGBToddI8pDm48kCNvdmxXRFB2FiyH8C0qYTNZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVElifA8JgkQH-c2R2A7sIPW6FxJCPsUM8f1waoDkZ_PK6QvevUbj177dmcMs1F0H-0/taylor_swift_thank_you.gif" data-image-dimensions="480x264" data-image-focal-point="0.5,0.5" alt="taylor_swift_thank_you.gif" data-load="false" data-image-id="5f7f6855fdc70016bddda391" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>

    

    

    <section id="comments-5f7f61f98472762c94f2dd1e">
      
  


    </section>

  </article>





  <nav>

    

    
      <a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats">
        <div>
          <p>Next</p>
          <h4>Taking Types to the Next Level: Stop API Bugs By Inferring Data Formats</h4>
          <div>
            <!--

            Categories

            --><p><span>Updates</span></p><!--

            Author

            --><p><span>Jean Yang</span></p><!--

            Date

            --><p><time datetime="2020-09-29">September 29, 2020</time></p><!--

            Tags

            --><p><span>data format inference, API spec generation</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div>
      </div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/10/8/detecting-and-documenting-api-endpoints-with-akita</link>
            <guid isPermaLink="false">hacker-news-small-sites-24723110</guid>
            <pubDate>Thu, 08 Oct 2020 19:51:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A small self-funded company outperforming larger VC backed ones]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24720904">thread link</a>) | @octobereleven
<br/>
October 8, 2020 | https://claritask.com/blog/software-advice-2020-frontrunners | <a href="https://web.archive.org/web/*/https://claritask.com/blog/software-advice-2020-frontrunners">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">	
	
		<p><a href="https://claritask.com/blog/tag/news">Claritask News</a></p>
		
		<p>Claritask, a self-financed bootstrapped company, scores high in Software Advice’s 2020 FrontRunners Task Management Software list, outperforming by far other larger companies.</p>
	    			    
		<div>
			
			<p>Software Advice, one of the leading personalized advice outlets, has rated Claritask high on their 2020 FrontRunners Task Management Software list.</p>

<p><strong>Specifically speaking:</strong><br>
8.4 in Usability and 8.1 on Customer Satisfaction.</p>

<p><img src="https://claritask.com/blog/images/uploads/sa-claritask-w-badge.png" alt="Software Advice Chart for Claritask" height="737" width="825"></p>

<p>What makes this recognition more special is that this rating comes directly from user reviews.</p>

<p><strong>In other words, it’s a reflection of our customers being satisfied with Claritask (the app) and us as a reliable company.</strong></p>

<p>Also, worth mentioning is that Claritask, a self-financed bootstrapped company, has outperformed other companies in the list with millions of dollars in venture capital and years in business.</p>

<p>Thank you! </p>

<p>Full details of this evaluation can be found on the <a href="https://www.softwareadvice.com/project-management/task-management-comparison/#frontrunners" target="_blank">2020 FrontRunners Task Management Software page on the Software Advice website</a>.</p>

		</div>
		
		
		

		<p>Written on October 1, 2020</p>
		

		<p><a href="https://claritask.com/">
		    Claritask helps teams work happier together
		    <span>Learn more</span>
		</a>
									
		
			

					
		
		
	
	</p></div></div>]]>
            </description>
            <link>https://claritask.com/blog/software-advice-2020-frontrunners</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720904</guid>
            <pubDate>Thu, 08 Oct 2020 16:43:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peloton Went from Kickstarter to $33B]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24720869">thread link</a>) | @jakebrereton
<br/>
October 8, 2020 | https://www.launchnotes.io/blog/how-they-launched-it-peloton | <a href="https://web.archive.org/web/*/https://www.launchnotes.io/blog/how-they-launched-it-peloton">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>‍</p><p><strong>"</strong><em>How they launched it" is a recurring series of deep dives exploring how the world’s best teams launch new products and features.</em></p><p>‍</p><p><strong>Company:</strong> Peloton<br><strong>Launch:</strong> Peloton<strong><br>Launch date:</strong> July, 2013<br></p><p>Peloton is one of those “why didn’t I think of that” ideas.<br></p><p>World class hardware, software, and content. All vertically integrated into a modern streaming platform and backed by a killer brand. Disrupting a giant industry starved of innovation. Why hadn't anyone thought of it sooner?<br></p><p>In just eight years, the company has gone from a scrappy startup raising funding on Kickstarter (yes, <em>Kickstarter</em>) to a multi-billion-dollar public company with over a million subscribers, 500,000+ bikes sold, and <a href="https://www.cnbc.com/2020/05/06/peloton-pton-reports-fiscal-q3-2020-earnings.html" target="_blank">66% revenue growth in just the last year</a>.</p><figure id="w-node-d80ec6d9faa8-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7d0ce53b21620ad68b663e_launchnotes_peloton_multi_billion_dollar_company.png" loading="lazy" alt=""></p></figure><p>But just getting the company up to cruising speed was a years-long battle. Founder John Foley faced thousands of rejections before he even had a product to launch. Hardware startups require prototypes and supply chains, which means capital. Unlike a slick new mobile app, you can’t vaporware a bicycle. But investors thought at-home fitness was a weak category, filled with goofy jocks hawking infomercial ab machines.<br></p><p>“They would hear: ‘fitness is a dopey category,’” <a href="https://mastersofscale.com/john-foley/" target="_blank">Foley said</a> on the Masters of Scale podcast, “where there’s been no capital and no software and no media and no innovation. And I would say, ‘exactly!’”’</p><p>Fast forward eight years, and today Peloton is one of the most widely recognized brands, and products, in American fitness.</p><p>Here’s how they launched it.<br></p><h2>Summary</h2><p>Dive deeper into a specific area of the Peloton launch:</p><ul role="list"><li>Kickstarter</li><li>SEO</li><li>Sales pitch</li><li>Email&nbsp;</li><li>Highly focused messaging</li><li>Retail space</li><li>High-end hotels</li><li>Personalized delivery service<br></li></ul><p>After years of scraping together small checks from more than 100 investors, tapping personal networks to find the first batch of instructors, and asking early adopters to contribute to a Kickstarter campaign, in 2014 Foley was finally able to, for the first time, actually put a product on the shelf.<br></p><p>Now how—as the marketing adage goes—to get it off the shelf? </p><p>The answers might surprise you, as Peloton’s launch threw a lot of conventional wisdom out the window. </p><h2><strong>Kickstarter campaign</strong><br></h2><figure id="w-node-36376a58d78d-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7bb88653bdc5bb6877649b_launchnotes_peloton_john_foley_tweet.png" loading="lazy" alt=""></p></figure><p>Back in 2013, Peloton kicked off its launch with <a href="https://www.kickstarter.com/projects/568069889/the-peloton-bike-bring-home-the-studio-cycling-exp" target="_blank">a Kickstarter campaign</a> that raised over $300,000 from nearly 300 individual funders. They’d built some early prototypes to feature in marketing materials and had some angel funding in the bank, but they turned to Kickstarter when it was time to scale manufacturing.<br></p><p>The stated goal was to raise $250,000. But beyond the stated goal, the Kickstarter campaign was also a strategic tool to build buzz for the company.&nbsp;<br></p><p>Peloton’s Kickstarter campaign led to a lot of early PR mentions, including write-ups in <a href="https://blogs.wsj.com/digits/2013/06/24/startup-melds-indoor-spinning-with-high-tech/" target="_blank">The Wall Street Journal</a>, CNN, and <a href="https://techland.time.com/2013/06/24/this-exercise-bike-features-a-huge-touchscreen-webcam-and-live-streaming-spin-classes/" target="_blank">Time</a>. Interestingly, none of this coverage featured interviews or exclusives. All the information in the articles was generally available and appears to have been pulled from either the Kickstarter page or a press release.<br></p><p>Companies who see great success with their PR efforts (<a href="https://www.launchnotes.io/post/how-they-launched-it-mailchimps-all-in-one-marketing-platform">like MailChimp</a>) often approach those efforts with a series of exclusives, so it’s fascinating that Peloton was able to succeed without such a nuanced approach. We can only conclude that the concept itself, its messaging, and the fundraising method (Kickstarter had a lot of its own hype in 2013) were novel enough to earn the kind of coverage for which most companies have to really hustle.&nbsp;<br></p><h2><strong>SEO</strong><br></h2><p>In addition to getting the word out about Peloton’s unique business plan, at least 25% of those early articles linked to Peloton’s website, with the rest linking out to the Kickstarter.<br></p><p>Since backlinks from high value sites (like The Wall Street Journal) have long been one of the most important factors for good SEO, the early coverage likely not only sent new funders to the Kickstarter campaign, but also gave Peloton’s website an additional boost in Google’s algorithms.&nbsp;<br></p><p>It’s a good lesson for new companies: have your own domain up early. At least as early as you expect to have other people on the internet talking about you. Even if you use a third-party platform like Kickstarter or Youtube to build pre-launch buzz, having your own URL people can link to will significantly help your site show up in search engines down the road.</p><figure id="w-node-8f102ac6b7bb-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7bb931efb84947b4d6c2fb_launchnotes_peloton_kickstarter_campaign.png" loading="lazy" alt=""></p></figure><h2>‍<br><strong>Sales pitch</strong><br></h2><p>Not only was Peloton’s choice of Kickstarter unique, so was their sales pitch: a well-crafted bike, yes, but also built-in live and on-demand indoor cycling video classes and—perhaps most importantly—a community where you could share triumphs, compete, and video chat with friends.<br></p><p>Their exact wording on the Kickstarter: “The Peloton Bike delivers live and on-demand indoor cycling classes to your home, while allowing competition &amp; video chat with friends.”<br></p><p>The strategy here starts with the product itself. Exercise bikes weren’t new. Live classes weren’t new. Community wasn’t new. <em>But combining them in the comfort of your own home was</em>. And the pitch succinctly captured all of that. In just one sentence, you knew you were buying a bike, that it came with classes, and that it offered an opportunity to gamify the entire experience. All from your own home.<br></p><p>It’s also been interesting to watch Peloton’s value prop change over the years. They’ve wisely made the transition from positioning themselves as an alternative (“Spin class replacement”) to a category all their own.<br></p><h2><strong>Email</strong><br></h2><p>To keep their Kickstarter campaign momentum going, Peloton sent update emails to encourage their early funders to share the campaign with friends.&nbsp;<br></p><p>Email is a tried-and-true (and arguably essential) part of a good launch. But it’s not always done well. To avoid sending generic marketing messages (a trap many launches seem to fall into), Peloton leveraged the fast development they were doing behind the scenes as a reason to be in touch with people, sharing updates on not only the bikes, but also add-ons coming down the pipeline.&nbsp;<br></p><p>One such add-on? Their own custom-made cycling shoes.</p><p>‍</p><figure id="w-node-fe96fe39b5fd-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7bba8444bfe33b0df9158e_launchnotes_peloton_email.png" loading="lazy" alt=""></p></figure><p>‍<br></p><p>Email also helped the Peloton team sharpen their brand voice and messaging early on. Their early emails (and social media posts) reflected the energy and positivity their instructors and brand would later become known for. Liberal use of exclamation marks as well as high-energy language (WOW! Amazing! Fun!) was commonplace.<br></p><div><p>Interestingly, according to <a href="https://knowledge.wharton.upenn.edu/article/say-reveals-think/" target="_blank">a study out of Wharton</a>, emotional language like this increases customer engagement—the exact kind of customer engagement that Peloton’s earliest marketing campaigns had to drive in order to to keep their earliest adopters hooked.</p></div><h2><strong>Highly focused messaging</strong><br></h2><p>Arguably, one of the smartest things about Peloton’s product and its launch was the way they came out of the gate deeply understanding their audience.<br></p><p>Marketers are taught to build messaging around people’s motivations. What does the customer ultimately want? It’s good advice. So for decades, messaging in the fitness industry was all about body image, and how people wanted to see themselves in the mirror the following day. “Get shredded,” “drop pounds today,” “abs in 30 days.”<br></p><p>But this kind of messaging has never appeared in Peloton copy. You won’t see a Peloton ad promising you’ll get ripped fast, because that’s the kind of language you hear from people who often <em>don’t</em> work out. Ask someone who doesn't exercise regularly what the benefits of exercise are and you’ll probably hear about body image and looking good at the beach. But ask someone devoted to fitness (as a vast majority of indoor cyclists already are) and you hear entirely different benefits: the energy and excitement of a good workout, the thrill of competing with others and consistently setting and beating goals, and the community and relationships formed with others at their gym. Just to name a few.<br></p><p>This is the enlightened tone Peloton uses, and it works. It reads more like a text message someone would send their friend after a great workout than the cover of a fitness magazine.</p><figure id="w-node-d551f62d4405-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7bbb784d186c147dae4719_launchnotes_peloton_messaging_and_psychology.png" loading="lazy" alt=""></p></figure><h3><strong>A focus on competition</strong><br></h3><p>Peloton’s bread and butter is its high-end equipment, with bikes and treadmills <a href="https://blog.mywallst.com/how-does-peloton-make-money/" target="_blank">making up about 80% of the company’s revenue</a>. But, unlike the stationary cycle companies who came before them, <strong>the brand doesn’t stop there</strong>. Just under $1B per quarter in revenue comes from subscriptions—a secondary revenue stream with enormous long-term value.&nbsp;<br></p><p>(And when we say long-term potential, we mean it: Peloton’s current <a href="https://www.forbes.com/sites/mikeotoole/2019/01/31/want-to-be-the-next-peloton-heres-how-the-fitness-brand-is-expanding-product-line-and-impact/#126c56cc6e93" target="_blank">yearly retention rate is a staggering 96%</a>, and the company expects to add more than a million subscribers in 2020.)<br></p><p>What’s the secret to this retention success? There’s probably more than one answer, but we suspect part of it is in their focus on <strong>competition</strong>, a focus they had <em>from day one of their Kickstarter launch</em>.&nbsp;<br></p><p>Competition, even more than a supportive community, is the top motivator that keeps people exercising, according to <a href="https://www.sciencedirect.com/science/article/pii/S2211335516300936?via%3Dihub" target="_blank">a study by the University of Pennsylvania</a>. In fact, <strong>students in a socially competitive exercise program attended classes 90% more often</strong> than students without the added incentive of competition.&nbsp;<br></p><p>Which is why the frequent mentions of competition in Peloton’s own pitches (such as that on their Kickstarter page) and their early PR coverage are... pretty genius. They were already hinting at one of the most powerful things they’d invested in: gamification.<br></p><h3><strong>A focus on connection</strong><br></h3><p>Another feature of Peloton’s marketing and products from the start? Community.&nbsp;<br></p><p>Instructors had leaderboards and started giving shoutouts early on—congratulating riders on milestone rides, birthdays, and so on. And video chat on the Peloton platform was one of the early selling points for their Kickstarter campaign.<br></p><figure id="w-node-eec8742172ab-f73b88ae"><p><img src="https://uploads-ssl.webflow.com/5d87bb53f0c5f31c47901e8d/5f7d0bd96848bf4545c04abd_launchnotes_peloton_community.png" loading="lazy" alt=""></p></figure><p>Having an exercise buddy (or, you know, <a href="https://sgbonline.com/peloton-holds-largest-class-ever/" target="_blank">23,000 in Peloton’s largest attended class so far</a>) makes people significantly more likely to stick with their fitness goals and get more benefit from their workouts, according to <a href="https://jaoa.org/article.aspx?articleid=2661140" target="_blank">study</a> after <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3975263/" target="_blank">study</a> after <a href="https://pubmed.ncbi.nlm.nih.gov/24176780/" target="_blank">study</a>.&nbsp;<br></p><p>Not only does this mean people get a boost from the group structure of the live classes; it also facilitates the long-term retention that Peloton prioritized on launch and continues to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.launchnotes.io/blog/how-they-launched-it-peloton">https://www.launchnotes.io/blog/how-they-launched-it-peloton</a></em></p>]]>
            </description>
            <link>https://www.launchnotes.io/blog/how-they-launched-it-peloton</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720869</guid>
            <pubDate>Thu, 08 Oct 2020 16:41:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Density launches Open Area radar system for buildings]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24720736">thread link</a>) | @afar
<br/>
October 8, 2020 | https://www.density.io/blog/introducing-open-area | <a href="https://web.archive.org/web/*/https://www.density.io/blog/introducing-open-area">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>"Any sufficiently advanced technology is indistinguishable from magic."</blockquote><h6>— Arthur C. Clarke, <em>Profiles of the Future</em> <em>(1962)</em></h6><h4>Open Area</h4><p>In 2017, we had a customer tell us she spent $700,000 every year for each building in a 4 million square foot office portfolio. $700,000 bought her human consultants who would visit her offices and do 7-day observational studies of how busy different spaces were (once per quarter).</p><p>As it turns out, she was not alone. Over the years, hundreds of customers have asked if they could use the infrared technology in our Entry sensors for open space detection (to measure desk availability, lounge use, how people use an amenity, and so on). Our answer has always had to be, no. </p><p>Not yet, anyway.</p><p>Since then we have been thinking about and working to solve the thorny problem of counting people in unbounded space and making it affordable to scale to tens of thousands of business and hundreds of millions of square feet.</p><p>Today, we're proud to introduce the latest addition to our platform — Density Open Area.</p><figure id="w-node-5d0de9b0c67f-665b10f0"><p><img src="https://assets-global.website-files.com/5f4a004f01308268d80d6e85/5f7cd78f8d47e339ff7661b4_Open%20Area%20in%20hand.png" loading="lazy" alt=""></p><figcaption>Open Area, a radar based sensor</figcaption></figure><h4>Technical Leaps</h4><p>Once, every few years, you get a glimpse of the future and how it might work. The famous ones are well known: the internet growing <a href="https://www.cnbc.com/2020/01/17/at-age-30-jeff-bezos-thought-this-would-be-his-one-big-regret-in-life.html">at 2,300%</a>, Englebart's <a href="https://www.youtube.com/watch?v=yJDv-zdhzMY&amp;t=153s">mother of all demos</a>, Steve's <a href="https://web.stanford.edu/dept/SUL/sites/mac/parc.html">visit to Xerox PARC</a>.</p><p>The importance of a novel observation or technical leap is obvious in retrospect but it's easy to disregard in the moment:&nbsp;hypertext, vaccines, the cambered wing, luggage with wheels, even the steam engine was not of any immediate consequence. It often takes decades even centuries of maturing before any given innovation's future is assured. But every now and then, if you squint, you sometimes get a chance to make out the rough profile of the future.</p><p>This is what we saw:</p><figure id="w-node-7ff48cc6176d-665b10f0"></figure><p>‍</p><h4>The Power of Radar</h4><p>Open Area leverages a radar system of our own design. </p><p>Each dot is a depth value generated from thousands of small movements in three dimensional space. We use these clustered data points to count people and observe movement anonymously.</p><p>Open Area's range and ability is extraordinary. The sensor is accurate up to 20 feet off the ground, can handle 1,325 square feet, and has a dynamic field of view configurable through a web app. </p><p>The technology fits in the palm of your hand, is unaffected by sunlight or reflectivity, and mounts in minutes. It is more accurate than a camera, anonymous at source, and made in America.</p><figure id="w-node-dc27d77422eb-665b10f0"><p><img src="https://assets-global.website-files.com/5f4a004f01308268d80d6e85/5f7ec280f461fdee990537d7_looping%20animation.gif" loading="lazy" alt=""></p></figure><h4>‍</h4><h4>Features &amp; Benefits</h4><p>The sensor comes with a suite of new applications designed to take advantage of Open Area's unique aerial dataset. Users will be able to access:</p><ul role="list"><li>60% reduction in cost to deploy (vs. camera / optical alternatives).</li><li>20 foot range, 40 foot effective diameter (4x coverage of alternatives).</li><li>1,325 square feet of coverage</li><li>Measure up to 20 desks (early Alpha)</li><li>Historical occupant pathing and heatmaps</li><li>Desk and room availability (+&nbsp;release)</li><li>Touchdowns and dwell time</li></ul><figure id="w-node-3dc275f7db55-665b10f0"><p><img src="https://assets-global.website-files.com/5f4a004f01308268d80d6e85/5f7ec65d2e837f523f524063_oa%20software.png" loading="lazy" alt=""></p><figcaption>Density web application</figcaption></figure><h4>Availability &amp;&nbsp;Price</h4><p>Available today in limited quantity. Large scale production starts early 2021.</p><ul role="list"><li>Hardware: $399 / sensor*</li><li>Software:&nbsp;$199 / sensor / year*</li></ul><p>‍<em>*Introductory pricing is available on orders through 2020.</em></p><p>‍</p><h4>One more thing ...</h4><p>In the process of exploring Open Area's unique capabilities, we realized something novel – a way of looking at people in space we'd never seen before. </p><p>Synchronize your floorplan and turn on Density Live. It will feel like a fragment of the future.</p><p>‍</p><figure id="w-node-735909241e83-665b10f0"></figure><p>‍</p><p>You can register to see a product demo <a href="https://density.webflow.io/people-counting-resources-webinars/introducing-open-area-densitys-newest-sensor-offering">October 20th</a> or send us an email to learn more – sales@density.io. </p><p>We can't wait to see what you do with the tech.</p><p>Andrew, Density CEO<br></p></div></div></div>]]>
            </description>
            <link>https://www.density.io/blog/introducing-open-area</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720736</guid>
            <pubDate>Thu, 08 Oct 2020 16:31:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Human Learn – Machine Learning models should play by the rules, literally]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24720115">thread link</a>) | @simjue
<br/>
October 8, 2020 | https://koaning.github.io/human-learn/ | <a href="https://web.archive.org/web/*/https://koaning.github.io/human-learn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/koaning/human-learn/edit/master/docs/index.md" title="Edit this page"></a>
                
                
                <p><img src="https://koaning.github.io/human-learn/logo.png" width="225"></p>

<blockquote>
<p>Machine Learning models should play by the rules, literally.</p>
</blockquote>
<h2 id="project-goal">Project Goal<a href="#project-goal" title="Permanent link">¶</a></h2>
<p>Back in the old days, it was common to write rule-based systems. Systems that do;</p>
<p><img alt="" src="https://koaning.github.io/human-learn/examples/rules.png"></p>
<p>Nowadays, it's much more fashionable to use machine learning instead. Something like;</p>
<p><img alt="" src="https://koaning.github.io/human-learn/examples/ml.png"></p>
<p>We started wondering if we might have lost something in this transition. Sure,
machine learning covers a lot of ground but it is also capable of making bad
decision. We've also reached a stage of hype that folks forget that many
classification problems can be handled by natural intelligence too.</p>
<p>This package contains scikit-learn compatible tools that should make it easier
to construct and benchmark rule based systems that are designed by humans. You
can also use it in combination with ML models.</p>
<h2 id="install">Install<a href="#install" title="Permanent link">¶</a></h2>
<p>You can install this tool via <code>pip</code>.</p>
<div><pre><span></span><code><span>python</span> <span>-</span><span>m</span> <span>pip</span> <span>install</span> <span>human</span><span>-</span><span>learn</span>
</code></pre></div>


<h2 id="guides">Guides<a href="#guides" title="Permanent link">¶</a></h2>
<h3 id="tutorial">Tutorial<a href="#tutorial" title="Permanent link">¶</a></h3>
<blockquote>
<p>There is a full course on this tool available on <a href="https://calmcode.io/human-learn/introduction.html">calmcode.io</a>.
This is the first video.</p>
</blockquote>
<iframe src="https://player.vimeo.com/video/463961716" width="100%" height="460" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>

<h3 id="getting-started">Getting Started<a href="#getting-started" title="Permanent link">¶</a></h3>
<p>To help you get started we've written some helpful getting started guides.</p>
<ol>
<li><a href="https://koaning.github.io/human-learn/guide/function-classifier/function-classifier.html">Functions as a Model</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/function-preprocess/function-preprocessing.html">Human Preprocessing</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/drawing-classifier/drawing.html">Drawing as a Model</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/finding-outliers/outliers.html">Outliers and Comfort</a></li>
<li><a href="https://koaning.github.io/human-learn/guide/function-classifier/function-classifier.html">Drawing Features</a></li>
</ol>
<p>You can also check out the API documentation <a href="https://koaning.github.io/human-learn/api/classification.html">here</a>.</p>
<h2 id="features">Features<a href="#features" title="Permanent link">¶</a></h2>
<p>This library hosts a couple of models that you can play with.</p>
<h3 id="interactive-drawings">Interactive Drawings<a href="#interactive-drawings" title="Permanent link">¶</a></h3>
<p>This tool allows you to draw over your datasets. These drawings can later
be converted to models or to preprocessing tools.</p>
<p><img alt="" src="https://koaning.github.io/human-learn/draw-gif.gif"></p>
<h3 id="classification-models">Classification Models<a href="#classification-models" title="Permanent link">¶</a></h3>
<h4 id="functionclassifier">FunctionClassifier<a href="#functionclassifier" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make classification predictions. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search.</p>
<h4 id="interactiveclassifier">InteractiveClassifier<a href="#interactiveclassifier" title="Permanent link">¶</a></h4>
<p>This allows you to draw decision boundaries in interactive charts to create a
model. You can create charts interactively in the notebook and export it as a
scikit-learn compatible model.</p>
<h3 id="regression-models">Regression Models<a href="#regression-models" title="Permanent link">¶</a></h3>
<h4 id="functionregressor">FunctionRegressor<a href="#functionregressor" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make regression predictions. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search.</p>
<h3 id="outlier-detection-models">Outlier Detection Models<a href="#outlier-detection-models" title="Permanent link">¶</a></h3>
<h4 id="functionoutlierdetector">FunctionOutlierDetector<a href="#functionoutlierdetector" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can declare outliers. It's constructed in
such a way that you can use the arguments of the function as a parameter that you
can benchmark in a grid-search.</p>
<h4 id="interactiveoutlierdetector">InteractiveOutlierDetector<a href="#interactiveoutlierdetector" title="Permanent link">¶</a></h4>
<p>This allows you to draw decision boundaries in interactive charts to create a
model. If a point falls outside of these boundaries we might be able to declare
it an outlier. There's a threshold parameter for how strict you might want to be.</p>
<h3 id="preprocessing-models">Preprocessing Models<a href="#preprocessing-models" title="Permanent link">¶</a></h3>
<h4 id="pipetransformer">PipeTransformer<a href="#pipetransformer" title="Permanent link">¶</a></h4>
<p>This allows you to define a function that can make handle preprocessing. It's
constructed in such a way that you can use the arguments of the function as a parameter
that you can benchmark in a grid-search. This is especially powerful in combination
with the pandas <code>.pipe</code> method. If you're unfamiliar with this amazing feature, you
may appreciate <a href="https://calmcode.io/pandas-pipe/introduction.html">this tutorial</a>.</p>
<h4 id="interactivepreprocessor">InteractivePreprocessor<a href="#interactivepreprocessor" title="Permanent link">¶</a></h4>
<p>This allows you to draw features that you'd like to add to your dataset or
your machine learning pipeline. You can use it via <code>tfm.fit(df).transform(df)</code> and
<code>df.pipe(tfm)</code>.</p>
<h3 id="datasets">Datasets<a href="#datasets" title="Permanent link">¶</a></h3>
<h4 id="titanic">Titanic<a href="#titanic" title="Permanent link">¶</a></h4>
<p>This library hosts the popular titanic survivor dataset for demo purposes. The goal of
this dataset is to predict who might have survived the titanic disaster.</p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://koaning.github.io/human-learn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720115</guid>
            <pubDate>Thu, 08 Oct 2020 15:36:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generic newsletter confirmation emails suck, here's how we can do better]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24720076">thread link</a>) | @yaroslawbagriy
<br/>
October 8, 2020 | https://newslettercrew.com/improve-your-newsletter-welcome-emails/ | <a href="https://web.archive.org/web/*/https://newslettercrew.com/improve-your-newsletter-welcome-emails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <div><p>First impressions count, in business, relationships and anything important in life. </p><p>Your welcome email is one of your subscribers’ first interactions with you. It’s like a first date, so you need to make sure you start off making a great first impression! It gives you the opportunity to showcase your unique personality and build your relationship with your subscribers.</p><p>We recently subscribed to over 70+ newsletters and found that many newsletter writers are not making full use of their welcome emails to connect with their subscribers. </p><p>Let's face it. Most newsletter writers aren't professional email marketers. But that doesn't give them the excuse to just send default, system-generated "thanks for subscribing" posts</p></div><p>Substack newsletters are especially guilty of sending poor welcome emails as they don't spend time to modify the default email seen below.</p><figure><img src="https://newslettercrew.com/content/images/2020/10/Twitter-Post---3.png" alt="" srcset="https://newslettercrew.com/content/images/size/w600/2020/10/Twitter-Post---3.png 600w, https://newslettercrew.com/content/images/size/w1000/2020/10/Twitter-Post---3.png 1000w, https://newslettercrew.com/content/images/size/w1600/2020/10/Twitter-Post---3.png 1600w, https://newslettercrew.com/content/images/2020/10/Twitter-Post---3.png 2024w" sizes="(min-width: 720px) 720px"></figure><p><br>This is a missed opportunity, as on average, welcome emails receive a higher open rate than regular emails, making <a href="https://blog.hubspot.com/marketing/plan-execute-welcome-email">them 86% more effective</a>. </p><p>Whether you're writing on Substack, Revue, MailerLite, EmailOctopus or any other email service provider, you should invest time into improving your welcome emails, which are your first point of contact with your readers. </p><h2 id="here-is-a-guide-with-examples-on-how-to-optimize-your-newsletter-s-welcome-email-">Here is a guide with examples on how to optimize your newsletter’s welcome email.</h2><p>Here are 11 tips on how to improve your welcome emails, and a collection of some of the best examples to help you make a stellar first impression.</p><h3 id="set-a-subject-line">Set A Subject Line</h3><p>A good subject line should be specific and unique to your newsletter. It could include either a reference to the name of your newsletter or the type of person your subscriber is.</p><p>Some ideas from the Newsletter Crew’s inbox:</p><ul><li>✅ You're Officially Not Boring ✅ &nbsp;(<a href="https://notboring.email/">Not Boring</a> by Packy McCormick)</li><li>🐣Welcome to the #First1000 Family &nbsp;(<a href="https://thefirst1000.substack.com/">The First 1000</a>)</li><li>Welcome to Mastering the Attention Economy Newsletter! (<a href="https://www.arilewis.com/">Ari Lewis</a>)</li><li>You're the Remotely Inclined type… (<a href="https://remotelyinclined.com/">Remotely Inclined</a>)<br></li></ul><div><p>Bad subject lines are overly simplistic and vague. They could have been from any newsletter. That's boring.</p><p>Avoid using these:</p></div><ul><li>You're on the list!</li><li>Thanks for subscribing</li><li>Thank you for subscribing</li></ul><h2 id="content">Content</h2><div><p>What should go in the body of your welcome email?</p><p>First, let's have a look at Packy McCormick’s brilliant welcome email for his popular newsletter <a href="http://notboring.email/">Not Boring</a> before diving into each section.</p></div><figure><img src="https://lh3.googleusercontent.com/hmT_0aVdjeliHsTBnd_sNfgnhX1MVY81dl51zkBrzfvUiqLYfzXqjhutqGRwet4Ox_uV2UnQgvBkvfwjJMcHpT1xZbLlwWCHYM1H3Toq5AulOuo2Q99BYH4IfBtoTHCuPM_K9gVq" alt="Packy McCormick's Not Boring Teardown"></figure><h3 id="thank-your-new-subscriber">Thank Your New Subscriber</h3><div><p>First, greet your subscriber with a warm welcome and thank them for subscribing! You can use a simple line of text, emojis, images or GIFs to do that.</p><p>You can even wow your subscribers with a personal touch. Check out <a href="https://ytothej.substack.com/">Yue Jun’s</a> handwritten welcome note for his newsletter. </p></div><figure><img src="https://lh4.googleusercontent.com/hEjJ4mC0Bv2bU14V7bUWvXSnlaqL85pfdyak0llyuy5Fk4v_hYkrviIyy88LAf2ADfzdh6rpmKVEqXF47OEYZiGxWnOQbHgnUfmQ-an2x3bvuAwJFovyGZ5hZEZMvLuYpHf1yx3S" alt="Personalized Welcome Note For Newsletter"></figure><!--kg-card-begin: html--><figure>
	<a href="https://newslettercrew.com/members/">
    	<div>
            <p>Join the Newsletter Crew</p>
            <p>Are you looking to improve your welcome emails? Join the community and connect with successful newsletter creators who can help.
</p>
            <p><img src="https://newslettercrew.com/favicon.png" loading="lazy">
                
                <span>Newsletter Crew</span>
                
            </p>
        </div>
        <p><img src="https://images.unsplash.com/photo-1466096115517-bceecbfb6fde?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=3900&amp;q=80" loading="lazy">
        </p>
    </a>
</figure><!--kg-card-end: html--><h3 id="set-expectations-type-of-content">Set Expectations: Type Of Content</h3><div><p>Tell your subscribers a little bit about who you are and what type of content you’ll send. This helps to set their expectations for future newsletter issues and alleviate any anxiety they have.</p><p>Adrian Alferi of <a href="https://www.theproofwellness.com/about">The Proof</a> makes subscribers feel comfortable by giving a personal introduction to himself and shares that he will be sending wellness-related content.</p></div><figure><img src="https://lh3.googleusercontent.com/qSVxN5hSsBfmEsebx8euJvUo4xYX9ITGxFbhPMkoKiYM5fCzUksGbiUzwEuqd9IxEFxR0_7bm3m-wMBp3dq0bgXvSOq6HMH6BIadBV0hsHMP_PHFPPa4nPoGKpLDPRDcF2icgHv5" alt=""></figure><h3 id="set-expectations-frequency"><br>Set Expectations: Frequency</h3><div><p>Let your subscribers know when they can expect your emails. Are you planning on emailing them weekly, daily or monthly? Be upfront on the day(s) they should expect your newsletter in their inbox.</p><p>Pete from <a href="https://www.nocsdegree.com/">No CS Degree</a> is extremely specific about what time people can expect his newsletter. As he has an international audience, he even states what time they can expect the newsletter to arrive in their inboxes.</p></div><figure><img src="https://lh4.googleusercontent.com/oEtWbcF6_mrdeK-5PSXqO8yZnK3u7r6hBaWbmBRN-poW-VzHxG647BWsbJeG93Z5En4uhPKxQpCGOKqQ9_FA3vVaJctAesSJ3Ak6Pui1ck4POPRgShRDvGg_UBx0Vz6lR7y-PIF8" alt=""></figure><p>Psst... some email service providers allow you to schedule send times by open location, if you're keen on doing that!</p><div><p>Increase engagement by linking to your social channels and encouraging subscribers to connect with you on these platforms.</p><p><a href="https://fs.blog/">Farnam Street</a> points subscribers to the different social media channels it owns.</p></div><figure><img src="https://lh4.googleusercontent.com/f3Coi2ziqg7Jm61mKu9M2YJnYv4kOuKwqLjE7i6nsN8hysUU-b_Q8KS0I5ZYKOFCsTh6emiLwjpxnGLpV_ro0EAAT3cRUL6oAwi8gQwSS7KiqiaLhfMor4icn5cl8FuP1PPshaE9" alt=""></figure><h3 id="showcase-your-best-issues">Showcase Your Best Issues</h3><div><p>Give subscribers a taste of what’s to come by sharing your 3-5 of your best issues with them. </p><p>I do this in the welcome email for <a href="https://brainpint.com/">BrainPint</a>. </p></div><figure><img src="https://lh4.googleusercontent.com/jQnCnGEd-k4WvuJVrM3PFHVQFKTU6HHSKMUZ6VP-e3LPI9wB1bKgvGXWCFzcGTEH_GI0PDqFSi549l9j-5dioJWHw3jzn5rkHBSGN43GWQNbWzSbVwHkc0bYrebhEtJ2sHWg409R" alt=""></figure><h3 id="ask-questions-to-connect-with-your-subscribers">Ask Questions To Connect With Your Subscribers</h3><div><p>Start a two-way conversation &amp; engage with your subscribers by asking them simple questions in your welcome email.</p><p>Get them to share:</p></div><ul><li>Information about themselves - who they are, and what they are working on</li><li>Questions they might have about the niche you’re in</li></ul><p>Anne-Laure from <a href="https://nesslabs.com/newsletter">Maker Mind</a> gives multiple options (including a "hit reply just to say hello" to take out the mental strain of replying)</p><figure><img src="https://lh6.googleusercontent.com/GiNWksy01vN2oxyWFRsTdFJFyIwcUy7YMbxyMf1gLO6IS-6UR-QRt8RhNAx6q3qjIWpfnIP9w5yeqV-Evh9q6SHxTcxbnsXxFIi5zghoF-87hsVCwPvQHWlOQJrn19jSy0rm8F0x" alt=""></figure><p><br>Leon Lin from <a href="https://avoidboringpeople.substack.com/subscribe">Avoid Boring People</a> asks questions to better understand what matters to his audience, so he can tailor his content to be relevant to them.</p><figure><img src="https://lh4.googleusercontent.com/iUdYNNiuSEz68Sp263JCShetJ_OfYItm6WLo-3cbiRkvQNHWHig0QAo82_BwP4zVAAOd3vg_crEb5Rw5z8kMGNilJ4utnDsvFr7JI9UbzpPeGWhCOX_qEIepRztkxZ3P4Ge1ouk5" alt=""></figure><p><br>Terrell from <a href="https://halfmarathons.substack.com/">Half Marathoner</a> asks a specific question related to his niche:</p><blockquote>“In the meantime, I’d love to know how we might help you better — do you have a question about running, training, or anything in between?”</blockquote><p>Asking the right questions helps you build an understanding of who your subscribers are and what matters to them.</p><!--kg-card-begin: html--><figure>
	<a href="https://newslettercrew.com/members/">
    	<div>
            <p>Join the Newsletter Crew</p>
            <p>Are you looking to improve your welcome emails? Join the community and connect with successful newsletter creators who can help.
</p>
            <p><img src="https://newslettercrew.com/favicon.png" loading="lazy">
                <span>
               		Yaro Bagriy
                </span>
                <span>Newsletter Crew</span>
                
            </p>
        </div>
        <p><img src="https://images.unsplash.com/photo-1466096115517-bceecbfb6fde?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=3900&amp;q=80" loading="lazy">
        </p>
    </a>
</figure><!--kg-card-end: html--><div><p>Instead of saying “Please tell a few friends if you like” in your welcome email, make it easy for your subscribers to share that they have subscribed to your newsletter by crafting pre-made snippets. You can use either <a href="https://www.sharelinkgenerator.com/">Share Link Generator</a> or <a href="https://clicktotweet.com/">Click To Tweet</a>. </p><p>In fact, here's a template.</p></div><blockquote>"Just joined other (your newsletter's target audience) and subscribed to (your landing page / link to subscribe) by (@your twitter handle) <br>Looking forward to reading (insert a blurb about your newsletter)"</blockquote><p>By decreasing the effort to share, you’ll start to see people dropping your newsletter on social media like it's hot.</p><h3 id="get-subscribers-to-whitelist-you">Get Subscribers To Whitelist You</h3><div><p>Every newsletter writer tries to prevent their newsletter from landing inside Gmail's Promotions tab or the spam folder of doom.</p><p>By asking subscribers to whitelist your newsletter, your future issues are more likely to appear in the Primary inbox. Your deliverability will also improve, and this increases the probability that your issues get seen by your subscribers instead of getting buried in a pile of ads. Of course, this drastically improves open rates.</p><p>Harry Dry of <a href="https://marketingexamples.com/">Marketing Examples</a> gives specific instructions to whitelist his email address to increase deliverability. </p></div><figure><img src="https://lh4.googleusercontent.com/PVezkn8L9rl2NnQ2YGJZ376sT1I0hAykGXCS5nw7mX8Xd2Ma8KiRm0Nrur_UMAzRAB4RvI42reruorgOM0GEoemZQGYwYJRDaTsuKHQcg1BGc7yu4HH1mw26XHyj8g6qcUKZmsM8" alt=""></figure><p>Some of us at Newsletter Crew ask our subscribers to reply with a simple "Done!" when they receive welcome emails.</p><h3 id="make-sure-they-can-unsubscribe">Make Sure They Can Unsubscribe</h3><p>Ensure that you provide an option to unsubscribe in your welcome email. The last thing you want is for subscribers to be marking you as spam when they can’t find the unsubscribe button. If they mark your emails as spam, there will be negative impacts on your domain reputation and deliverability rates.</p><h3 id="keep-welcome-emails-brief">Keep Welcome Emails Brief</h3><div><p>Remember not to make your welcome emails too wordy! They shouldn’t read like an essay. Always respect your reader's time.</p><p>See how Harry Dry does it in the <a href="http://marketingexamples/">Marketing Examples</a> welcome email? It’s short, friendly and tells you everything you need to know.</p></div><figure><img src="https://lh3.googleusercontent.com/LP85uotppOTVDl27wdtvua5ix-t-fsNeVLzFUyBlKVJx9K1ExPFvNqO4V4D0ifbcQFVbcVvpZJz_aAjaenvBvRjriPvMFNNPpSblPHwrU5J8QFbrkITPr7PgIcLKGhURGBFn4Yhf" alt=""></figure><p><br><strong>Write effective welcome emails. They'll improve engagement with your subscribers from the get go and drive more opens and clicks!</strong></p><!--kg-card-begin: html--><figure>
	<a href="https://newslettercrew.com/members/">
    	<div>
            <p>Join the Newsletter Crew</p>
            <p>Are you looking to improve your welcome emails? Join the community and connect with successful newsletter creators who can help.
</p>
            <p><img src="https://newslettercrew.com/favicon.png" loading="lazy">
                <span>
               		Yaro Bagriy
                </span>
                <span>Newsletter Crew</span>
                
            </p>
        </div>
        <p><img src="https://images.unsplash.com/photo-1466096115517-bceecbfb6fde?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=3900&amp;q=80" loading="lazy">
        </p>
    </a>
</figure><!--kg-card-end: html-->
    </section></div>]]>
            </description>
            <link>https://newslettercrew.com/improve-your-newsletter-welcome-emails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24720076</guid>
            <pubDate>Thu, 08 Oct 2020 15:32:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I reverse engineered my cable modem and turned it into an SDR]]>
            </title>
            <description>
<![CDATA[
Score 311 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24719680">thread link</a>) | @0x00000000
<br/>
October 8, 2020 | https://stdw.github.io/cm-sdr/ | <a href="https://web.archive.org/web/*/https://stdw.github.io/cm-sdr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
        <div id="title">
          
          
          <hr>
          <p><span>Project maintained by <a href="https://github.com/stdw">stdw</a></span>
          <span>Hosted on GitHub Pages — Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </p></div>

        

<p><img src="https://stdw.github.io/cm-sdr/img/modem.jpg" alt="cable modem"></p>

<h2 id="introduction">Introduction</h2>
<p>A few weeks ago I got curious about an old cable modem sitting in my closet,
a Motorola MB7220. Initially I was interested in what kind of hardware it had
and if it was running Linux. Some quick searching brought me to a thread on
a web forum where people were discussing the built in spectrum analyzer feature
used for diagnostics. Someone mentioned that they could see spikes
corresponding to FM radio stations. This sparked a thought: if a cable modem 
and a digital TV tuner dongle are fundamentally doing the same thing (receiving 
and demodulating QAM signals), could a modem be turned into an 
<a href="https://en.wikipedia.org/wiki/Software-defined_radio">SDR (software-defined radio)</a>
a la <a href="https://www.rtl-sdr.com/">RTL-SDR</a>?</p>

<p>Going into this project, I knew next to nothing about RF and had no idea if
this goal was even feasible at all for the hardware. I found 
<a href="http://www.hermeslite.com/">an SDR project</a> based on an Analog Devices 
cable modem chip, as well as a <a href="https://forums.qrz.com/index.php?threads/cable-modem-to-software-defined-radio-modification-projects.512433/">forum thread</a>
where someone else was wondering about the same thing a few years ago.</p>

<p>The last post in the thread from user VK4HAT states:</p>

<blockquote>
  <p>I say if you have the skills, time and desire, give it a go and see where you end up. If google shows nothing, then its likely not been tried. With so few firsts available in life, take those that present themselves and have a crack, even if failure is always an option.</p>
</blockquote>

<p>So that is exactly what I did.</p>

<h2 id="gaining-access">Gaining Access</h2>
<p>My first goal was to look for an access vector or a way to communicate with the
device. I knew that there wasn’t much to see on the web interface and telnet
was disabled, so I skipped ahead to opening it up.</p>

<p>After removing a few screws from the plastic housing to get access to the
board, my first thought was to look for <a href="https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter">UART</a> headers to take a peek at the serial console. 
After identifying two candidates consisting of four vias surrounded by a 
rectangle near the edge of the PCB, it was time to identify the pins. 
Using a multimeter, the ground pin can be easily identified by checking 
the continuity with one of the metal shields on board. The VCC pin can be 
identified by measuring the voltage of each pin when powering on the board. 
It should be a steady 3.3v, or in some cases 1.8v or 5v. This pin is not 
needed, but is still useful to identify the operating voltage and eliminate 
one candidate for the Tx and Rx pins.
While booting, the Tx pin will sit on average a little lower than the VCC pin
and drop much lower when a lot of data is being output. This leaves the last 
pin as Rx.</p>

<p>One of the UARTs identified earlier did not seem to be transmitting anything
while the other did. After soldering some wires to the active UART, I connected
the Tx to UART Rx GPIO pin on a Raspberry Pi, the Rx to the Pi’s Tx, and the 
ground to the ground pin. Note that this can only be done because both systems
are 3.3v. Had that not been the case, a USB TTL adapter with an adjustable 
voltage level could be used just as easily, and is probably a better idea most
of the time anyway.</p>

<p>There are a few reasons why the Raspberry Pi is not the best serial interface
such as if you need parity or other features, but in this case I had it on hand
and it works. The serial console of the Pi must also be disabled so that it can 
be freed up for other purposes. There is another reason I chose to use the 
Raspberry Pi which I will get to later.</p>

<p>Finally, to actually see the data I used the <code>cu</code> utility:<br>
<code>cu -l /dev/serial0 -s 115200</code><br>
The baud rate was a lucky guess, but 115200 is very common on such devices.
If the baud rate is wrong you will quickly know when you see a bunch of garbage
on the screen. A logic analyzer could be used to definitively find the baud 
rate and other parameters, but guessing is sometimes quicker and always 
cheaper.</p>

<p>After powering on the device, the terminal filled with output:</p>

<div><div><pre><code>pi@raspberrypi:~/modem $ cu -l /dev/serial0 -s 115200
Connected.
�
B3312inim S C 84(9 m
ose_VS 8
STesldlo rh 83 rs 10
STesldhi: _h 8, _s 13
Sync: 0 
MemSize:            128 M
Chip ID:     BCM3383D-B0

BootLoader Version: 2.4.0 fyl spiboot reduced DDR drive avs
Build Date: Nov 12 2015
Build Time: 14:31:43
SPI flash ID 0xef4016, size 4MB, block size 64KB, write buffer 256, flags 0x0
Cust key size 128

Signature/PID: 3383


Image 1 Program Header:
   Signature: 3383
     Control: 0005
   Major Rev: 0003
   Minor Rev: 0000
  Build Time: 2015/11/26 08:47:57 Z
 File Length: 1692841 bytes
Load Address: 80004000
    Filename: ecram_sto.bin
         HCS: e749
         CRC: 175b753f

Found image 1 at offset 20000

Enter '1', '2', or 'p' within 2 seconds or take default...


Performing CRC on Image 1...
CRC time = 282177012
Detected LZMA compressed image... decompressing... 
Target Address: 0x80004000
decompressSpace is 0x8000000
Elapsed time 736066500

Decompressed length: 8091524

Executing Image 1...


 eCos - hal_diag_init
Ecos memory map:
BLOCK    OWNER        MIPS      SIZE      MEM
Block 0: Owner: 0 - 0x00000000 0x07e00000 0x00000000
Block 0: Owner: 0 - 0 MB 126 MB 0 MB
Block 1: Owner: 3 - 0x07e00000 0x00200000 0x07e00000
Block 1: Owner: 3 - 126 MB 2 MB 126 MB
126MB (129024KB) remaining for eCos
Init device '/dev/BrcmTelnetIoDriver'
Init device '/dev/ttydiag'
Init tty channel: 807bb020
Init device '/dev/tty0'
Init tty channel: 807bb040
Init device '/dev/haldiag'
HAL/diag SERIAL init
Init device '/dev/ser0'
BCM 33XX SERIAL init - dev: b4e00500.2
Set output buffer - buf: 0x80852408 len: 4096
Set input buffer - buf: 0x80853408 len: 4096
BCM 33XX SERIAL config
Init device '/dev/ser1'
BCM 33XX SERIAL init - dev: b4e00520.3
Set output buffer - buf: 0x80854408 len: 4096
Set input buffer - buf: 0x80855408 len: 4096
BCM 33XX SERIAL config

Init device '/dev/ser2'
InitBoard: MIPS frequency 637200000

...

Reading Permanent settings from non-vol...
Checksum for permanent settings:  0xe9d88f65
Setting downstream calibration signature to '5.7.1mp1|die temperature:70.775degC'
Settings were read and verified.


Reading Dynamic settings from non-vol...
Checksum for dynamic settings:  0x6e4a329
Settings were read and verified.

Console input has been disabled in non-vol.
Console output has been disabled in non-vol!  Goodbye...
[00:00:00 01/01/1970] [Reset/Standby Switch Thread] BcmResetStandbySwitchThread::ProcessResetSwitchEvent:  (Reset/Standby Switch Thread) Reset switch released; resetting...
[00:00:00 01/01/1970] [Reset/Standby Switch Thread] BcmResetStandbySwitchThread::ProcessResetSwitchEvent:  (Reset/Standby Switch Thread) Cant Reset pfCmDocsisCtlThread==NULL...
</code></pre></div></div>

<p>This output contains a wealth of information. The device is 
running <a href="https://en.wikipedia.org/wiki/ECos">eCos</a> on a MIPS processor 
which is part of a Broadcom BCM3383 SoC. It turns out there are actually
two MIPS processors on this SoC although one of them is not used on this
modem, explaining the other UART. On some devices, the second processor
will run Linux for additional features.</p>

<p>Also, this seems like the end of the line for serial because shortly after 
booting the actual OS, it disables the serial console. Hitting “p” at the 
bootloader prompt does not lead to much except a way to download new OS 
images via tftp and a utility to read and write memory addresses. This could
be used to bypass the check, but a much greater understanding of the OS and
memory layout would be required.</p>

<h2 id="dumping-the-flash">Dumping the flash</h2>

<p>My goal now was to enable the serial console. Examination of the board reveals
a single <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface">SPI</a> flash
chip which likely contains the bootloader, OS, and configuration as it is the
only non-volatile storage visible on the board.</p>

<p>This is where the Raspberry Pi comes in handy once again. The GPIO header also
conveniently contains a SPI interface which can be used to read the data off
of the flash chip.</p>

<p>Searching the number on the chip, “winbond 25Q32JV”, yields the datasheet
containing the pinout. The important ones are VCC, Chip Select (CS), Clock
(CLK), Data Out (DO), Data In (DI), and ground.</p>

<p>One common issue with dumping a SPI chip on a board is that the chip requires
power, but this will also usually power the board and cause it to start booting
and using the chip. I chose to overcome this by heating the VCC pin with my
soldering iron and very carefully lifting it off the pad. This is a convenient,
but rather crude solution which may result in snapped off leads so use at your
own risk! I also soldered a jumper wire to the pad and another to the floating
leg so that I could easily connect and disconnect them and allow the device to
boot again.</p>

<p>Another note, on some boards the Chip Select pin is assumed to always be 
enabled so it is directly tied to VCC. This means when you power the CS 
pin, the board also starts booting. This can be solved in a similar way
to the VCC pin.</p>

<p>Now, wires can be soldered to the rest of the pins and the they can be
connected to the Raspberry Pi. The ground goes to ground (the UART ground
from earlier can also be used), the VCC to the Pi’s 3.3v pin. (Again, it is
critical to verify with the datasheet that this is a 3.3v chip because the Pi
only supports 3.3v). The DO pin is connected to the Pi’s SPI <code>MISO</code> (master in 
slave out) pin and DI to the <code>MOSI</code> pin (master out slave in). Lastly, the 
Clock is connected to the <code>SCLK</code> GPIO pin and the Chip Select to the <code>CE0</code> pin.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://stdw.github.io/cm-sdr/img/chip.jpg" alt="flash chip"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Not the best soldering job but it will work</em></td>
    </tr>
  </tbody>
</table>

<p>To actually read the chip, there is a fantastic tool called 
<a href="https://flashrom.org/Flashrom">flashrom</a> which supports an enormous number of
chips. <code>flashrom</code> is present in the repos of many distributions including that
of the Raspberry Pi OS (formerly known as Raspbian).</p>

<p>Luckily the W25Q32JV is supported, under the name “W25Q32.V”. A quick check on
the flashrom wiki shows the size and voltage match what is expected and that
the chip is fully supported.</p>

<p>Before proceeding, ensure that the SPI interface on the Pi is enabled by
using the <code>raspi-config</code> utility and checking under “Interfacing Options”.</p>

<p>At last we can read the chip. First verify that it is …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stdw.github.io/cm-sdr/">https://stdw.github.io/cm-sdr/</a></em></p>]]>
            </description>
            <link>https://stdw.github.io/cm-sdr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719680</guid>
            <pubDate>Thu, 08 Oct 2020 15:00:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Guide to Deep Learning and Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24719670">thread link</a>) | @NaeosPsy
<br/>
October 8, 2020 | https://serokell.io/blog/deep-learning-and-neural-network-guide | <a href="https://web.archive.org/web/*/https://serokell.io/blog/deep-learning-and-neural-network-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As a subset of artificial intelligence, deep learning lies at the heart of various innovations: self-driving cars, natural language processing, image recognition and so on. Companies that deliver DL solutions (such as Amazon, Tesla, Salesforce) are at the forefront of stock markets and attract impressive investments. According to <a href="https://www.statista.com/statistics/621468/worldwide-artificial-intelligence-startup-company-funding-by-year/">Statista</a>, the total funding of artificial intelligence startup companies worldwide in 2014–2019 is equal to more than $26 billion. This high interest can be explained by the amazing benefits of deep learning and its architectures — artificial neural networks.</p><p><img src="https://serokell.io/files/3s/3slpcvqe.1_(32)_(1).jpg" alt="AI startup funding graph"></p><h2 id="what-is-deep-learning%3F">What is deep learning?</h2><p><img src="https://serokell.io/files/yc/yctimg60.deviator-1_(1).jpg" alt="what is deep learning"></p><p>Deep learning is one of the subsets of machine learning that uses deep learning algorithms to implicitly come up with important conclusions based on input data.</p><p>Usually, deep learning is unsupervised or semi-supervised. Deep learning is based on <a href="https://en.wikipedia.org/wiki/Feature_learning#:~:text=In%20machine%20learning%2C%20feature%20learning,or%20classification%20from%20raw%20data.">representation learning</a>. Instead of using task-specific algorithms, it learns from representative examples. For example, if you want to build a model that recognizes cats by species, you need to prepare a database that includes a lot of different cat images.</p><p>The main architectures of deep learning are:</p><ul>
<li>Convolutional neural networks</li>
<li>Recurrent neural networks</li>
<li>Generative adversarial networks</li>
<li>Recursive neural networks</li>
</ul><p>We are going to talk about them more in detail later in this text.</p><h3 id="difference-between-machine-learning-and-deep-learning">Difference between machine learning and deep learning</h3><p>Machine learning attempts to extract new knowledge from a large set of pre-processed data loaded into the system. Programmers need to formulate the rules for the machine, and it learns based on them. Sometimes, a human might intervene to correct its errors.</p><p>However, deep learning is a bit different:</p><table>
  <tbody><tr>
   <th>Deep learning
   </th>
   <th>Machine learning
   </th>
  </tr>
  <tr>
   <td>large amounts of data
   </td>
   <td>small datasets as long as they are high-quality
   </td>
  </tr>
  <tr>
   <td>computation-heavy
   </td>
   <td>not always
   </td>
  </tr>
  <tr>
   <td>an draw accurate conclusions from raw data
   </td>
   <td>carefully pre-processed data
   </td>
  </tr>
  <tr>
   <td>take much longer to train
   </td>
   <td>can be trained in a reduced amount of time
   </td>
  </tr>
  <tr>
   <td>you can't know what are the particular features that the neurons  represent
   </td>
   <td>logic behind the machine’s decision is clear
   </td>
  </tr>
  <tr>
   <td>can be used in unexpected ways
   </td>
   <td>algorithm is built to solve a specific problem
   </td>
  </tr>
</tbody></table><h2 id="advantages-of-deep-learning">Advantages of deep learning</h2><p>Now that you know what the difference between DL and ML is, let us look at some advantages of deep learning.</p><ul>
<li>In 2015, a group of Google engineers was conducting research about <a href="https://ai.googleblog.com/2015/07/deepdream-code-example-for-visualizing.html">how NN carry out classification tasks</a>. By chance, they also noticed that neural networks can hallucinate and <a href="https://www.youtube.com/watch?v=uSUOdu_5MPc&amp;t=932s">produce rather interesting art</a>.</li>
<li>The ability to identify patterns and anomalies in large volumes of raw data enables deep learning to efficiently deliver accurate and reliable analysis results to professionals. For example, Amazon has more than <a href="https://www.digitalcommerce360.com/article/amazon-sales/">560 million items on the website and 300+ million users</a>. No human accountant or even a whole army of accountants would be able to track that many transactions without an AI tool.</li>
<li>Deep learning doesn’t rely on human expertise as much as traditional machine learning. DL allows us to make discoveries in data even when the developers are not sure what they are trying to find. For example, you want your algorithms to be able to <a href="https://www.digitalocean.com/community/tutorials/how-to-build-a-deep-learning-model-to-predict-employee-retention-using-keras-and-tensorflow">predict customer retention</a>, but you’re not sure which characteristics of a customer will enable the system to make this prediction.</li>
</ul><p><img src="https://serokell.io/files/b3/b37v6nzo.2_(24)_(1).jpg" alt="Deep learning advantages"></p><h2 id="problems-of-deep-learning">Problems of deep learning</h2><ul>
<li>Large amounts of quality data are resource-consuming to collect. For many years, the largest and best-prepared collection of samples was <a href="https://www.zdnet.com/article/worlds-largest-image-database-to-help-computers-learn-to-see/#:~:text=To%20develop%20a%20system%20that,holds%2014%20million%20labeled%20images.">ImageNet with 14 million different images</a> and more than 20,000 categories. It was founded in 2012, and only last year, <a href="https://neurohive.io/en/datasets/tencent-dataset/">Tencent released a database</a> that is larger and more versatile.</li>
<li>Another difficulty with deep learning technology is that it cannot provide reasons for its conclusions. Therefore, it is difficult to assess the performance of the model if you are not aware of what the output is supposed to be. Unlike in traditional machine learning, you will not be able to test the algorithm and find out why your system decided that, for example, it is a cat in the picture and not a dog.</li>
<li>It is very costly to build deep learning algorithms. It is impossible without qualified staff who are trained to work with sophisticated maths. Moreover, deep learning is a resource-intensive technology. It requires powerful GPUs and a lot of memory to train the models. A lot of memory is needed to store input data, weight parameters, and activation functions as an input propagates through the network. Sometimes deep learning algorithms become so power-hungry that researchers prefer to use <a href="https://serokell.io/blog/how-to-choose-ml-technique">other algorithms</a>, even sacrificing the accuracy of predictions.</li>
</ul><p>However, in many cases, deep learning cannot be substituted.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/0VH1Lim8gL8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe><h2 id="how-can-you-apply-dl-to-real-life-problems%3F">How can you apply DL to real-life problems?</h2><p><img src="https://serokell.io/files/66/66a4xqmg.4_(18)_(1).jpg" alt="Deep learning applications"></p><p>Today, deep learning is applied across different industries for various use cases:</p><ul>
<li><strong>Speech recognition.</strong> All major commercial speech recognition systems (like Microsoft Cortana, Alexa, Google assistant, Apple Siri) are based on deep learning-based.</li>
<li><strong>Pattern recognition.</strong> Pattern recognition systems are already able to give more accurate results than the human eye in <a href="https://www.bbc.com/news/health-50857759#:~:text=Artificial%20intelligence%20is%20more%20accurate,images%20from%20nearly%2029%2C000%20women.">medical diagnosis</a>.</li>
<li><strong>Natural language processing.</strong> Neural networks have been used to implement language models since the early 2000s. The invention of <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a> helped improve machine translation and language modeling.</li>
<li><strong>Discovery of new drugs.</strong> For example, the <a href="https://arxiv.org/abs/1510.02855">AtomNet neural network</a> has been used to predict new biomolecules that can potentially cure diseases such as Ebola and multiple sclerosis.</li>
<li><strong>Recommender systems.</strong> Today, deep learning is being used to study user preferences across many domains. <a href="https://www.netflix.com/">Netflix</a> is one of the brightest examples in this field.</li>
</ul><h2 id="what-are-artificial-neural-networks%3F">What are artificial neural networks?</h2><p><img src="https://serokell.io/files/vd/vd78l0x8.deviator-2_(1).jpg" alt="What are artificial neural networks"></p><p>“Artificial neural networks” and “deep learning” are often used interchangeably, which isn’t really correct. Not all neural networks are “deep”, meaning “with many hidden layers”, and not all deep learning architectures are neural networks. There are also <a href="https://en.wikipedia.org/wiki/Deep_belief_network#:~:text=In%20machine%20learning%2C%20a%20deep,between%20units%20within%20each%20layer.">deep belief networks</a>, for example.</p><p><img src="https://serokell.io/files/vk/vkpzrxrf.5_(12)_(1).jpg" alt="neural networks"></p><p>However, since neural networks are the most hyped algorithms right now and are, in fact, very useful for solving complex tasks, we are going to talk about them in this post.</p><h3 id="definition-of-an-ann">Definition of an ANN</h3><p>An artificial neural network is heavily inspired by the structure of a human brain. Simply put, an ANN represents a sequence of neurons connected by synapses. Those sequences are often organized into layers.</p><p>Having many (sometimes millions) of input neurons in the system, the machine learns to analyze and even memorize various information. Due to this structure, a neural network can process monstrous amounts of information very fast.</p><p>Here is a video for those who want to dive deeper into the technical details of how artificial neural networks work.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/njKP3FqW3Sk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe><p>Artificial neural networs are incredibly valuable not only to analyze incoming information but also to reproduce it from their memory.</p><h2 id="components-of-neural-networks">Components of Neural Networks</h2><p>Every neural network consists of neurons, synapses, weights, biases, and functions.</p><h3 id="neurons">Neurons</h3><p>A neuron or a node of a neural network is a computing unit that receives information, performs simple calculations with it, and passes it further.</p><p>All neurons in a net are divided into three groups:</p><ul>
<li>Input neurons that receive information from the outside world;</li>
<li>Hidden neurons that process that information;</li>
<li>Output neurons that produce a conclusion.</li>
</ul><p><img src="https://serokell.io/files/yt/ytl4jey2.6_(8)_(1).jpg" alt="ML architecture"></p><p>In a large neural network with many neurons and connections between them, neurons are organized in layers. An input layer receives information, n hidden layers (at least 3+) process it, and an output layer provides some result.</p><p>Each of the neurons inputs and outputs some data. If this is the first layer, input = output. In other cases, the information that the neurons have received from the previous layer is passed to input. Then, it uses an activation function to get a new output, which is passed to the next layer of neurons in the system.</p><p>Neurons only operate numbers in the range [0,1] or [-1,1]. In order to turn data into something that a neuron can work with, we need normalization. We talked about what it is in the <a href="https://serokell.io/blog/regression-analysis-overview">post about regression analysis</a>.</p><p>Wait, but how do neurons communicate? Through synapses.</p><h3 id="synapses-and-weights">Synapses and weights</h3><p>If we didn’t have synapses, we would be stuck with a bunch of inactive useless neurons. A synapse is a connection between two neurons. Every synapse has a weight. It is the weight that changes the input information while it is transmitted from one neuron to another. The neuron with the greater weight will be dominant in the next neuron. One can say that the <a href="https://en.wikipedia.org/wiki/Weighing_matrix">matrix of weights</a> is the brain of the whole neural system.</p><p><img src="https://serokell.io/files/b9/b92z8vod.7_(9)_(1).jpg" alt="Neuron weights"></p><p>It is thanks to these weights that the input information is processed and converted into a result. During the initialization (first launch of the NN), the weights are randomly assigned. Later on, they are optimized.</p><h3 id="bias">Bias</h3><p>A bias neuron allows for more variations of weights to be stored. Biases add richer representation of the input space to the model’s weights.</p><p>In the case of neural networks, a bias neuron is added to every layer. It plays a vital role by making it possible to move the activation function to the left or right on the graph.</p><p><img src="https://serokell.io/files/ey/eyarbo1y.8_(5)_(1).jpg" alt="bias neurons"></p><p>It is true that ANNs can work without bias neurons. However, they are almost always added and counted as an indispensable part of the overall model.</p><h2 id="how-anns-work">How ANNs work</h2><p>Every neuron processes input data to extract a feature. Let’s imagine that we have features x1, x2, x3, and three neurons, each of which is connected with all these features.</p><p>Each of the neurons has its own weights that are used to weight the features. During the training of the network, you need to select such weights for each of the neurons that the output provided by the whole network would be true-to-life.</p><p>To perform transformations and get an output, every neuron has an activation function. It allows us to get some new feature space. This combination of functions performs a transformation that is described by a common function F — this describes the formula behind the NN’s magic.</p><p><img src="https://serokell.io/files/ly/ly9z5sh4.9_(3)_(1).jpg" alt="ANN: activation function"></p><p>There are a lot of activation functions, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/deep-learning-and-neural-network-guide">https://serokell.io/blog/deep-learning-and-neural-network-guide</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/deep-learning-and-neural-network-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719670</guid>
            <pubDate>Thu, 08 Oct 2020 14:59:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Here's how Russia could track your every move – without even hacking your phone]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24719602">thread link</a>) | @geek_slop
<br/>
October 8, 2020 | https://www.geekslop.com/features/technology-articles/hacking-and-security-technology-articles/2020/if-you-have-this-popular-app-installed-on-your-phone-consider-this-heres-how-russia-could-track-your-every-move-without-even-hacking-your-phone | <a href="https://web.archive.org/web/*/https://www.geekslop.com/features/technology-articles/hacking-and-security-technology-articles/2020/if-you-have-this-popular-app-installed-on-your-phone-consider-this-heres-how-russia-could-track-your-every-move-without-even-hacking-your-phone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><img width="550" height="366" src="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141.png" alt="image thumb141" loading="lazy" srcset="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141.png 550w, https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141-416x277.png 416w, https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141-300x200.png 300w" sizes="(max-width: 550px) 100vw, 550px" data-attachment-id="13840" data-permalink="https://www.geekslop.com/news/technology-news/hacking-and-security/2015/interesting-geographic-attack-vector-from-a-russian-launched-cyber-counter-attack/attachment/russian-and-american-flags" data-orig-file="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141.png" data-orig-size="550,366" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Russian and American flags" data-image-description="" data-medium-file="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141-300x200.png" data-large-file="https://d9j7f8i6.rocketcdn.me/wp-content/uploads/2015/07/image_thumb141.png" title="If you have this popular app installed on your phone, consider this: Russia could track your every move - without even hacking your phone. 1"></p><p>What geek doesn’t like a good conspiracy theory? Well, I’ve got one for you – a follow-the-money chain that leads from the head of Russian state to an app that is installed on millions of personal phones – one that you probably use every day.</p>



<h2>The back-channel links between American media outlets and Russian propaganda</h2>



<p>Russia’s most used back-channel outlet to the Western World is Russia Today (RT or rt.com), a commonly known propaganda outlet for the Russian government. The RT media outlet is directly funded by the Russian federal tax budget and under the <em>Foreign Agents Registration Act</em>, is registered as a “foreign agent” with the <em>United States Department of Justice</em>. There’s no argument – RT is a propaganda machine for the Russian government.</p>



<p>In October 2020, the <a aria-label="Wall Street Journal noted how many Americans are unwittingly directed to RT (opens in a new tab)" rel="noreferrer noopener external" href="https://www.wsj.com/articles/how-russia-today-skirts-high-tech-blockade-to-reach-u-s-readers-11602078094?mod=hp_featst_pos3" target="_blank" data-wpel-link="external">Wall Street Journal noted how many Americans are unwittingly directed to RT</a> from right-leaning websites such as RealClearPolitics, The Blaze, 245WallSt, Newser, The Daily Caller, Newsmax, the National Review, and others. The Journal investigated the bizarre relationship and found that the outlets were a part of a distribution network known as <em>Mixi Media</em> – a company with a privately registered domain and no About page on their website. They also discovered that included in the Mixi Media family was another Russian state-backed outlet, Sputnik – and the that the owner and founder of Mixi Media is a man named Alex Baron. When they contacted Baron about the revelatory article they were going to publish, Mixi Media immediately began dropping partners from the network.</p>



<h2>Alex Baron and ties to the Russian government?</h2>



<p>Alex Baron is not a name known to many. According to WSJ, he is an associate of Russian private-equity magnate Victor Remsha. The Wall Street Journal also says Mixi “has other ties to Russia” and that there are some “technical connections between Mixi and properties owned by Remsha”. </p>



<p>Baron denies all ties with Remsha, his companies, and RT. However, he does not deny that he is the tech director of a piece of software found on millions of phones around the country – an app that in 2017 was scandalously found to be sending user location data to a third-party using WiFi tracking even when GPS location sharing was turned off. The app is one of the most popular and highly-rated apps on Andriod and iPhones – the weather app, AccuWeather.</p>



<h2>AccuWeather</h2>



<p>All it takes is a look at AccuWeather’s permissions to see how easily a foreign country could use an app to track a person. The AccuWeather app has access to and is allowed a terrifying degree of freedom on your smartphone device. As of October 8, 2020, the weather app was allowed:</p>



<h3>Storage</h3>



<ul><li>modify or delete the contents of your USB storage</li><li>read the contents of your USB storage</li></ul><h3>Wi-Fi connection information</h3>



<ul><li>view Wi-Fi connections (this is how they were able to track and send location data even when GPS was turned off)</li></ul><h3>Device ID &amp; call information</h3>



<ul><li>read phone status and identity</li></ul><h3>Location</h3>



<ul><li>precise location (GPS and network-based)</li><li>approximate location (network-based)</li></ul><h3>Microphone</h3>



<ul><li>record audio</li></ul><h3>Other</h3>



<ul><li>receive data from Internet</li><li>pair with Bluetooth devices, including microphones</li><li>read Google service configuration</li><li>draw over other apps, a permission that lets an app cover up warnings or change content of other apps</li><li>run at startup</li><li>connect and disconnect from Wi-Fi</li><li>prevent device from sleeping</li><li>access Bluetooth settings</li><li>disable your screen lock</li><li>control vibration</li><li>change system display settings</li><li>view network connections</li><li>and yes, full network access</li></ul><h2>Could Russia use AccuWeather to track the movements of Americans?</h2>



<p>It’s an indirect link from the Russian state-owned RT media outlet and the AccuWeather app but there is certainly an interesting chain of relationships that could be concerning to most people. Could Russia use an app like AccuWeather to track Americans movements? At this point, nobody knows. But I can tell you that right before I clicked “Publish” for this article, I uninstalled AccuWeather from my phone.</p>
		</div></div>]]>
            </description>
            <link>https://www.geekslop.com/features/technology-articles/hacking-and-security-technology-articles/2020/if-you-have-this-popular-app-installed-on-your-phone-consider-this-heres-how-russia-could-track-your-every-move-without-even-hacking-your-phone</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719602</guid>
            <pubDate>Thu, 08 Oct 2020 14:52:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Joy of Fixing Things]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24719143">thread link</a>) | @kioleanu
<br/>
October 8, 2020 | https://viorel.me/2020/2020-10-08-the-joy-of-fixing-things/ | <a href="https://web.archive.org/web/*/https://viorel.me/2020/2020-10-08-the-joy-of-fixing-things/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        Viorel
        <br>
        <span>on&nbsp;</span><time datetime="2020-10-08 12:00:18 +0000 UTC">October 8, 2020</time>
</p>
		


		

		

<p>As I’m getting older and grumpier, I find myself more and more attached to my stuff, so I’ve decided that I’ll do two things from now on: 1) try only buying stuff that will give me as many life years as possible and 2) repair as many of the items I already own</p>

<p>I was surprised how much satisfaction I get from repairing things and how much I can learn. Here’s the summary of what I did this week:</p>

<h3 id="my-wife-s-bike-chain">My wife’s bike chain</h3>

<p><em>Which I broke 6 months ago trying to get myself up a steep hill.</em></p>

<p>What I’ve learned:</p>

<ol>
<li>bike chains are consumables</li>
<li>their size depends on how many gears you have (they’re thicker for bikes with many gears)</li>
<li>you buy an approximate length chain, which you have to shorten yourself</li>
<li>there are special tools to shorten bike chains and all bike chains are shortenable<br></li>
<li>it’s really easy to change the chain (once you have the right tools)</li>
<li>you have to oil the chain after mounting it</li>
</ol>

<p>What I’ve had trouble with:</p>

<ol>
<li>I was mounting the chain wrong, which gave me the impression I had to shorten it more than I actually needed. I learned how to shorten and <em>lengthen</em> a bike chain. Tip to future me: when shortening a chain, don’t take the pin all the way out. It’s a pain to fit it back in the hole again. Another tip: when researching, try to find a tutorial on a bike that kinda looks like yours.</li>
</ol>

<h3 id="my-phone-s-battery">My phone’s battery</h3>

<p>I have an iPhone SE, first generation, which I absolutely love, mostly because of the size. The battery was slowly dying (OS showed about 80% capacity) and it meant I more or less can’t use the phone in cold weather anymore.</p>

<p>What I’ve had trouble with:</p>

<ol>
<li>The manual that came in the replacement kit was awful and it mixed the instructions for multiple iPhone models: 5, 5s and 5c, but SE wasn’t listed at all. I had to follow the instructions for 5s, but instead I followed those for 5. For the 5, the battery is glued completely differently</li>
<li>Removing the screen was not very easy as some edges were stuck to the body. Slow and steady did the job.</li>
<li>The battery is glued with two plastic stickers to the body and removing the battery was a real pain, because the instructions only said to find said stickers under the battery and pull them out. Unsurprinsingly I pulled them out wrong and it took an hour to remove the battery using a combination of a wedge tool and dental floss. I flossed the battery out by taking the dental floss between the battery and the body from top to bottom. I would have only used the wedge tool harder, but there was a good change of damaging the battery and I’ve seen how that works out.</li>
</ol>

<p>What I’ve learned:</p>

<ol>
<li>When pulling stuff out, apply the same pressure constantly and have patience. When taking the screen out, there was a good chance of it breaking if I pulled too hard. Applying a medium amount of pressure helped take the screen out slowly but steadily.</li>
<li>Don’t be afraid of jamming the flat tool to get the screen out</li>
<li>Always buy replacement kits that come with tools. It’s better to have too many screwdrivers that not enough screwdrivers.</li>
<li>Absolutely do not trust the instructions manual. Research the procedure from multiple sources before you even start working</li>
</ol>

<h3 id="the-family-external-hard-drive">The family external hard drive</h3>

<p>The 2TB Seagate Expansion drive gave up the ghost a couple of years ago and I was toying with an idea of getting an Western Digital MyCloud. My wife didn’t really agree pointing out that we bought the Seagate only 10 years ago and can’t I fix it? Turns out I can, the HDD was OK, but the bridge board was gone.</p>

<p>What I’ve had trouble with: nothing, the most problematic part was deciding which replacement case to buy</p>

<p>What I’ve learned:</p>

<ol>
<li>OK, I had no idea that there is an actual normal 3,5” HDD in there. There is an actual normal 3,5” HDD in there. You can take it out and put it in another casing. Or in a computer. The possibilities are endless.</li>
<li>You can buy another casing in which to plug the HDD</li>
<li>There are casings in which you can put an old laptop disk drive and then use it as an external drive. Wow, I find this amazing.</li>
<li>Splitting the broken piece of equipment in components helps you identify problems easier and fix them quicker. See what can be simply bought and replaced once it’s broken into pieces.</li>
<li>Dedicated forums are amazing and there’s dedicated forums for just about everything.</li>
</ol>

<h3 id="a-friend-s-laptop">A friend’s laptop</h3>

<p>A friend asked me if reinstalling Windows would bring his Sony Vaio back to life as a last attempt before throwing it away. The laptop took anywhere from 45 minutes to 2 hours to fully boot up and load one program. It initially came with Windows 8 and was updated to 10. I suggested upgrading the drive to a SSD and the RAM from 4 to 8 GB and then reinstall Windows.</p>

<p>I was pleasantly surprised by the Vaio. The drive and RAM had their own separate covers which you just unscrewed. Really easy and future-proof. After installing the SSD and memory board and installing Windows, it started working amazingly: load time in under one minute and absolutely no hiccups.</p>

<p>What I’ve had trouble with:</p>

<ol>
<li>I was mounting the memory board wrong, although I saw a tutorial on exactly how do it: place it a 45 degree angle and slide it in. “Slide” is the keyword here. I ended up jamming it. It worked, but it was risky. Redid one more time aftewards, and it went really smoothly.</li>
<li>I lost one of the drive screws inside the body. Took some (gentle) shaking to recover it. A magnetic screwdriver would have helped.</li>
</ol>

<p>What I’ve learned:</p>

<ol>
<li>If you have to apply too much pressure, you’re doing it wrong.</li>
<li>Do not underestimate what an SSD can do</li>
<li>SSDs are really cheap - 30EUR for a 256 GB one</li>
<li>Windows OEM licences are not affected by changing the disk and adding RAM.</li>
</ol>


		
	</div>

	
</div></div>]]>
            </description>
            <link>https://viorel.me/2020/2020-10-08-the-joy-of-fixing-things/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719143</guid>
            <pubDate>Thu, 08 Oct 2020 14:00:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn How Augmented Reality Can Boost Growth of E-Commerce]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24719006">thread link</a>) | @myurushkin
<br/>
October 8, 2020 | https://salesvision.ai/e-commerce-blog/how-augmented-reality-can-boost-growth-of-e-commerce/ | <a href="https://web.archive.org/web/*/https://salesvision.ai/e-commerce-blog/how-augmented-reality-can-boost-growth-of-e-commerce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
			<div>
				<p><strong>Augmented reality in e-commerce</strong> is a trending topic these days. The coronavirus pandemic has led to brick and mortar stores heading to the online marketplace. E-commerce technology solutions also gained in popularity. Apart from digital marketing and SEO for e-commerce, other technologies can also help with your online stores.</p>

<h2>What Is Augmented Reality and How Is It Used in Business?</h2>
<p>Augmented reality describes technologies that add a digital layer to the physical world. It enables computer-generated content to virtually interact with the real world. Famous examples include Snapchat filters and Pokémon GO.</p>
<p>AR is a broad concept, and its usage can be divided into four different types:</p>
<ol>
<li><b>Marker-based AR</b>: Marker-based AR involves image recognition of image content taken with a camera. Users use their camera to scan an object, and it can be transformed on the screen into an interactive model or widget. Snapchat filters belong in this category.</li>
<li><b>Markerless AR</b>: Markerless AI doesn’t use your camera for recognition. Instead, it generates content based on your location. The most famous example is Pokémon GO, where you needed to get to a specific place to find Pokémon. Often enough, they appear in some random places because there is no marker-based AR involved.</li>
</ol>
<p><img src="https://salesvision.ai/wp-content/uploads/2020/10/pokemon-go-ar.png" alt="Pokemon Go Augmented Reality" width="400" height="803"></p>
<p><i>Credits: </i><a href="https://www.npr.org/2016/07/08/485078495/gotta-catch-em-all-or-at-least-a-few-a-pokemon-neophyte-tries-pokemon-go"><i>Gotta Catch ‘Em All, Or At Least A Few: A Pokemon Neophyte Tries ‘Pokemon GO’</i></a><i> – NPR</i></p>
<ol>
<li><b>Superimposition-based AR</b>: It’s also based on object/image recognition, and it substitutes the original camera view with generated 3D content.</li>
<li><b>Projection AR</b>: This is the simplest type of augmented reality. It uses light that reflects off various surfaces. The best example is holograms often seen in science fiction movies.</li>
</ol>
<p>AR found its way into many areas. Augmented reality e-commerce technology is on the rise, so let’s dive into its uses.</p>

<h2>Current Uses of Augmented Reality in E-Commerce</h2>
<p>E-commerce technology often refers to digital marketing tools. Still, AR and data science in e-commerce started to take off. Let’s check out the current uses of augmented reality in e-commerce:</p>

<ul>
<li>
<h4><b>AR Filters for e-Commerce Apps<br>
</b></h4>
</li>
</ul>

<p>The first item on our list is the simplest one. Still, it’s a great idea to raise brand awareness and reach people on social media. For example,<a href="https://www.adweek.com/digital/ben-jerrys-created-a-facebook-ar-filter-that-challenges-you-to-catch-marshmallows-in-your-mouth/"> Ben &amp; Jerry’s launched an AR filter game on Facebook</a> to promote the new ice cream flavor. Sure, it takes a bit of work, but the result is fun, interactive, and a great thing to share with friends.</p>
<p><img src="https://salesvision.ai/wp-content/uploads/2020/10/ben-and-jerrys-ar-filter-game.png" alt="Ben and Jerrys AR Filter Game" width="890" height="500" srcset="https://salesvision.ai/wp-content/uploads/2020/10/ben-and-jerrys-ar-filter-game.png 890w, https://salesvision.ai/wp-content/uploads/2020/10/ben-and-jerrys-ar-filter-game-768x431.png 768w" sizes="(max-width: 890px) 100vw, 890px"></p>
<p><i>Credits: </i><a href="https://www.adweek.com/digital/ben-jerrys-created-a-facebook-ar-filter-that-challenges-you-to-catch-marshmallows-in-your-mouth/"><i>Ben &amp; Jerry’s Created a Facebook AR Filter That Challenges You to Catch Marshmallows in Your Mouth</i></a><i> – Adweek</i></p>


<ul>
<li>
<h4><b>Augmented Reality in Virtual Fitting Rooms</b></h4>
</li>
</ul>

<p>The lockdown has taken its toll on clothing stores, and many of them switched the emphasis to online retailing. The problem is that many customers are hesitant when it comes to online shopping for fashion items. It’s tough to see how it will fit them, and the process of returning the item is lengthy.</p>
<p>Virtual dressing rooms use 3D image generation for products in the store. This e-commerce technology takes the product image content and creates a 3D model of a product. It involves computer vision and AI in e-commerce. Customers can now see exactly how it will fit and feel more confident about the purchase.</p>


<ul>
<li>
<h4><b>Product Preview Placement</b></h4>
</li>
</ul>

<p>Product preview placement is similar to virtual dressing rooms. Instead of fashion items, users can check out how furniture, home appliances, and decorations will fit into their home. The application of this technology is more significant because it involves more expensive items.</p>
<p><img src="https://salesvision.ai/wp-content/uploads/2020/10/magnolia-augmented-reality-product.png" alt="Magnolia Augmented Reality Product" width="1600" height="900" srcset="https://salesvision.ai/wp-content/uploads/2020/10/magnolia-augmented-reality-product.png 1600w, https://salesvision.ai/wp-content/uploads/2020/10/magnolia-augmented-reality-product-768x432.png 768w, https://salesvision.ai/wp-content/uploads/2020/10/magnolia-augmented-reality-product-1536x864.png 1536w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<p><a href="https://www.shopify.com/enterprise/augmented-reality-ecommerce-magnolia-market">Magnolia Market partnered with Shopify</a> to let customers place the items from their catalog inside their homes to see how they fit.</p>

<ul>
<li>
<h4><b>Augmented Reality in Virtual e-Commerce Stores</b></h4>
</li>
</ul>

<p>Virtual stores are about taking the store to your e-customers. It’s the perfect example of innovative e-commerce technology. It uses 3D image generation to turn your bedroom into an interactive virtual store. With the help of computer vision and AI in e-commerce, customers can look at items from the comfort of their homes.</p>

<h2>The Future of Augmented Reality in E-Commerce</h2>
<p>The coronavirus pandemic has accelerated the development of e-commerce technology solutions. Augmented reality in e-commerce is still far from being the standard. The existing solutions are often clumsy, and they break the illusion.</p>
<p>AR goes to show the importance of data science in e-commerce. These solutions are impossible to implement without using AI in e-commerce applications. Computer vision and 3D image generations are the crucial aspects of building realistic AR experiences.</p>
<p>The future technologies will probably contain more of the following:</p>
<ul>
<li><b>Personalized shopping</b>: How about a virtual store full of items you viewed, shown interest in, or the ones recommended for you based on your past interests? It’s the next best thing with AR and AI in e-commerce.</li>
<li><b>Better e-commerce shopping experience</b>: AR is not just for looking at products. It can be used to display all relevant information right there on your screen. You won’t need to check different tabs and screens on your phone to see if there is a size L available.</li>
<li><b>Virtual assistants</b>: Humanoid robots are challenging to build, but you can feature them virtually as shopping assistants. They can talk about the store, products, or possible discounts for the user.</li>
<li></li>
</ul>
<h2>How AI Can Help Generate 3D Images for Augmented Reality Applications</h2>
<p>Talking about AR is all fun and games until the implementation turns out to be a nightmare. To effectively build AR visual content in e-commerce, you’ll need to perform 3D image generation on all products. The process is a painful one: each product needs to be photographed from all angles hundreds of times. Then&nbsp; the image content needs to go through editing before generating the 3D model. Imagine stores with thousands of clothing items; it would take days to take all needed photos.</p>
<p>This is where AI in e-commerce steps in as a significant e-commerce technology. 3D image generation powered by computer vision can form a 3D model out of image content. The difference is: there’s no need for hundreds of photos as one or two will do the trick.</p>
<p>The solution has countless benefits:</p>
<ul>
<li>Saving money on expensive photoshoots.</li>
<li>The time needed to form all 3D models is measured in hours, rather than in days.</li>
<li>No need for manual editing.</li>
<li>The same computer vision solution can be used for all products.</li>
</ul>
<p>3D image generation needed for embedding augmented reality in your store is an important step. If you’re considering opening your AR online store, <a href="https://salesvision.ai/contact-us/">contact SalesVision</a> to help you generate all required 3D models. We provide all the state-of-art applications of data science in e-commerce, and we can power your online store in a matter of hours!</p>

<h2>How COVID-19 Speeds AR Adoption in E-Commerce</h2>
<p>COVID-19 is a crucial factor in the acceleration of AR adoption. E-commerce technology development was already progressing rapidly before the pandemic, and it just exploded in recent times. The reasons are obvious:</p>
<ul>
<li>Constant lockdowns and epidemiologic measures prevent fashion stores from operating normally.</li>
<li>People spend more time than ever using their electronic gadgets.</li>
<li>Many people would rather shop online than cram with strangers in physical stores.</li>
</ul>
<p>Still, even after the pandemic is over, many customers will realize the convenience of online shopping. If you <a href="https://salesvision.ai/e-commerce-blog/how-to-start-your-online-clothing-store/">own an online store</a>, every new feature you add will remain relevant for a long time.</p>

<h2>Final Words</h2>
<p>There are many different types of augmented reality. Funnily enough, most of them can be used to improve customer experience in online stores. The core idea is to bring the store and your items to the customer. 2D image content doesn’t tell the full story about dimensions and how it will look on you or in your home.</p>
<p>The future will bring new developments. The leading retailers will create advanced stores that will appear more convenient than physical stores. Instead of having human workers in the store to ask many questions about the products, focus on it on your screen, and read everything there is to know.</p>
<p>The challenge behind AR is to generate the required models. However, SalesVision has got you covered on that one, and you’re just <a href="https://salesvision.ai/contact-us/">a message away</a> from obtaining your realistic 3D models.</p>
			</div>
		</div>
	</div></div>]]>
            </description>
            <link>https://salesvision.ai/e-commerce-blog/how-augmented-reality-can-boost-growth-of-e-commerce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24719006</guid>
            <pubDate>Thu, 08 Oct 2020 13:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A city with a thousand eyes: mass surveillance in Belgrade]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24718535">thread link</a>) | @milankragujevic
<br/>
October 8, 2020 | https://aboutintel.eu/mass-surveillance-serbia/ | <a href="https://web.archive.org/web/*/https://aboutintel.eu/mass-surveillance-serbia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre><strong><a href="https://aboutintel.eu/automated-video-surveillance">Discussion Prompt</a><a href="https://aboutintel.eu/predictive-policing">:</a> </strong>Should we ban the use of automated 
video-surveillance?

<a href="https://aboutintel.eu/automated-video-surveillance">See all contributions to this question.</a></pre>







<p><em>Modern video surveillance is a far cry from its clumsy predecessor. As technology has improved, and camera prices plummeted, surveillance en masse is likely coming to a city near you. Belgrade is one such city, experiencing the roll-out of thousands of cameras as part of a so-called “Safe Society” project. Installed without any public debate, nor a strong legal framework protecting digital and civil rights, concern by local civil society is high. Facial recognition in public spaces is one tool to fight crime, but residents must ask themselves, should this highly intrusive measure trump the privacy of all citizens</em>?</p>



<hr>



<p>Mass biometric surveillance can adversely affect a society — especially if in the case of Serbia, it is one with an already weak democratic tradition — and can cause serious violations of human rights. This is why it should be banned.</p>



<p>The digital age has brought about the idea that technology can exclusively be a force for good, helping us achieve nearly crime-free societies and peace among nations. Whether it’s preventing terrorist attacks or combating organised crime, one answer has been more surveillance of communications and the movements of citizens – most of whom are law-abiding. Now, entering the 2020s, the next targets of surveillance are our <em>faces</em>.&nbsp;</p>



<p><br><strong>Thousands of new eyes for Belgrade</strong></p>



<p>Citizens of the Serbian capital Belgrade learned in early 2019 that their city will be covered with a thousand<a href="https://www.sharefoundation.info/en/new-surveillance-cameras-in-belgrade-location-and-human-rights-impact-analysis-withheld/"> <span>cutting-edge surveillance cameras</span></a> in the following two years as part of the so-called “Safe Society” project. The project was unveiled without any prior public debate.<em> </em>What especially caught the public’s attention was the fact that these cameras — supplied by<a href="https://www.sharefoundation.info/en/huawei-knows-everything-about-cameras-in-belgrade-and-they-are-glad-to-share/"> <span>Chinese tech giant Huawei</span></a> — will have facial and vehicle license plate recognition capabilities. The news was declared by high-ranking officials in internal affairs, the Police Director of Serbia and the Minister of Interior. The latter is one of the key figures of the ruling party and a close associate of President Vučić, which gave the announcement particular ‘weight’ in public. Since then, a citizen initiative known as<a href="https://hiljade.kamera.rs/en/home/"> <span>“Thousands of Cameras” (“Hiljade kamera”)</span></a>, led by SHARE Foundation — a non-profit organisation dedicated to protecting digital rights, which I work for — has been actively challenging this surveillance system and demanding that such an intrusive technology be discussed in an open and inclusive setting before it is introduced.</p>



<p>Serbia does not have a long democratic tradition and features a <a href="https://www.hrw.org/world-report/2019/country-chapters/serbia/kosovo"><span>problematic human rights record</span></a> to this day. As a remnant of socialist Yugoslavia, which prioritised safety and security, privacy awareness is very low for most of the population. The country’s recent democratic backslide is also quite alarming. Earlier this year,<a href="https://freedomhouse.org/report/nations-transit/2020/dropping-democratic-facade"> <span>Freedom House</span></a> downgraded Serbia to a Transitional/Hybrid regime for the first time since 2003. On the<a href="https://rsf.org/en/serbia"> <span>World Press Freedom Index</span></a> for 2020, Serbia is ranked 93rd out of 180 countries – another 3 places down from the previous year. In its report, Reporters Without Borders <a href="https://rsf.org/en/serbia"><span>states</span></a> that “Serbia has become a country where it is often dangerous to be a journalist”. Data protection and privacy do not rest on a long political tradition. A data protection law has existed in Serbia for just over a decade and the Commissioner for Information of Public Importance and Personal Data Protection (the national data protection authority) was established only 16 years ago, at first as a freedom of information complaints body. Furthermore, video surveillance in Serbia — a country currently negotiating EU membership — has seen its fair share of controversy, with camera footage often being abused, leaked in the pro-government media, or the cameras ‘conveniently’ not working at key moments (i.e. when powerful individuals could have been compromised by the footage).&nbsp;</p>



<p>As the city administration’s infrastructure strategy is quite unpopular, the citizens of Belgrade, despite a general privacy lethargy, have paid attention to the new surveillance system; citizens and “Thousands of Cameras” activists<a href="https://hiljade.kamera.rs/map/"> <span>have mapped hundreds of locations</span></a> across Belgrade where cameras have been installed. This form of crowdsourcing provides more information about surveilled locations than the police itself has published. Photos of cameras from various Belgrade neighbourhoods are regularly posted on the<a href="https://twitter.com/hiljadekamera"> <span>“Thousands of Cameras” Twitter feed</span></a>. With this alarming spread of cameras, we have to ask what the deeper implications of such surveillance are? And can it cause or cement irreversible changes in a world of declining democratic values, particularly in a country like Serbia?</p>



<p><br><strong>The legal framework</strong></p>



<p>Serbia has modernised its data protection legal framework by adopting the new Law on Personal Data Protection (LPDP) in late 2018; its full application began in November 2019. Drafted from a confusing mix of translated GDPR regulations and the EU Law Enforcement Directive, the text of Serbia’s new LPDP was controversial from the start, but at least it provided a more modern approach to data protection. Among its main flaws however, is the fact that the new LPDP does not specifically regulate two important aspects of data processing: biometric data and video-surveillance. Despite this, the law’s general provisions and principles should still apply to any data processing, such as a massive video surveillance system across Belgrade.</p>



<p>Before deploying a public space surveillance system, the LPDP obliges the data controller to conduct a Data Protection Impact Assessment (DPIA) and ask for the Commissioner’s opinion. However the Ministry of Interior of Serbia, which is the implementing body for the “Safe Society” project, failed to comply with the LPDP. It issued two DPIAs, both of which did not satisfy the Commissioner, who refused to approve. Despite this, the cameras were installed anyway.&nbsp;</p>



<p>The latest information gathered from the second DPIA of the Ministry suggests that there will be<a href="https://www.sharefoundation.info/wp-content/uploads/Mini1000.png"> </a>more than 8000 different <a href="https://www.sharefoundation.info/wp-content/uploads/Mini1000.png"><span>cameras and other devices</span></a> in use, such as body cams, mobile cameras and vehicle-mounted cameras. Although facial recognition, i.e. automated detection of people’s faces from a video feed, is not yet rolled out by the Ministry, this feature is expected to be implemented by the end of the project. While little is known about the project’s timeline, this can be expected to be in the next two years.</p>



<p>Apart from the data protection issues related to facial recognition, we also need to ask whether these technologies are necessary and proportionate, particularly from the perspective of the European human rights framework and its underlying values. Is facial recognition in public spaces the only available measure that can be used to prevent serious crime and protect citizens? Can this highly intrusive measure trump the privacy of all citizens, effectively turning whole cities into mass surveillance zones?</p>



<p>All in all, the Belgrade surveillance camera system is of <a href="https://hiljade.kamera.rs/en/law-society/">dubious legality</a>, to say the least, because:&nbsp;</p>



<ol><li>the actual purpose of introducing this system has not been clearly defined;&nbsp;</li><li>it has not been confirmed that the use of this system is necessary for the operations of state bodies;&nbsp;</li><li>its positive influence on the reduction of criminal offences has been overrated and its use is not proportionate to the risks related to the rights and freedom of citizens;&nbsp;</li><li>there is no law to begin with that defines that the police have the right to use smart surveillance in public places; and&nbsp;</li><li>the Data Protection Impact Assessment (DPIA) of the Ministry of Interior does not meet formal and material conditions defined by the law and was not approved by the Commissioner.&nbsp;</li></ol>



<p><br><strong>Point of no return for human rights</strong></p>



<p>Automated biometric video-surveillance may be the pinnacle of today’s<a href="https://www.publicbooks.org/the-folly-of-technological-solutionism-an-interview-with-evgeny-morozov/"> <span>techno-solutionism</span></a> – trying to solve deep and complex social problems with often non-critical use of technology. Sadly, decision makers are usually blind to issues of ethical and legal nature, and far-reaching consequences, if a society sets public safety as its ultimate value. It is all the more troubling if they believe it can be achieved with technology such as mass video-surveillance. Once governments get a hold of such powerful technology, it might be impossible to completely remove it from their arsenal, even after successful legal challenges. In that regard, we can draw a parallel to blanket communications metadata retention — a highly controversial measure in terms of proportionality which is<a href="https://edri.org/eu-member-states-willing-to-retain-illegal-data-retention/"> <span>still alive and kicking in the EU</span></a>, despite two CJEU judgements against it.<sup>1 </sup>Not to mention lucrative infrastructure deals required to install a massive video surveillance network, possibly in every larger city. This is particularly worrisome for countries such as Serbia, which are currently experiencing democratic backslides.</p>



<p>In addition to privacy, other associated human rights and freedoms, such as freedom of expression and the rights to protest and peaceful gathering, would<a href="https://edri.org/facial-recognition-and-fundamental-rights-101/"> <span>also be affected</span></a> in areas covered with automated video-surveillance. Imagine a scenario where a government keeps a biometric database of all citizens who attended anti-government protests; the ways in which this could affect their work, families, social relationships, and other aspects of everyday life are vast. Facial recognition also<a href="https://www.washingtonpost.com/technology/2019/12/19/federal-study-confirms-racial-bias-many-facial-recognition-systems-casts-doubt-their-expanding-use/"> <span>discriminates against minorities</span></a>, further entrenching bias against disadvantaged communities and making them more vulnerable.</p>



<p>With its high risks and numerous adverse effects, especially once reaching a “point-of-no-return”, automated biometric video surveillance does not uphold the values of respect for human rights, equality and social justice of the EU and the Council of Europe. Therefore, banning automated video surveillance is the right step forward, especially when we take into account other worrying trends, such as <a href="https://www.laquadrature.net/en/2020/02/04/technopolice-resisting-the-total-surveillance-of-our-cities-and-of-our-lives/"><span>the total …</span></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aboutintel.eu/mass-surveillance-serbia/">https://aboutintel.eu/mass-surveillance-serbia/</a></em></p>]]>
            </description>
            <link>https://aboutintel.eu/mass-surveillance-serbia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24718535</guid>
            <pubDate>Thu, 08 Oct 2020 12:33:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Engineer Guide: Feature Store vs. Data Warehouse]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24718301">thread link</a>) | @nathaliaariza
<br/>
October 8, 2020 | https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; The feature store is a data warehouse of features for machine learning (ML). Architecturally, it differs from the traditional data warehouse in that it is a dual-database, with one database (row-oriented) serving features at low latency to online applications and the other database (column-oriented) storing large volumes of features, used by Data Scientists to create train/test datasets and by batch applications doing offline model scoring.</p><h2>Features Store: Data Warehouse Déjà Vu</h2><p>Data warehouses democratized access to Enterprise data by centralizing data in a single platform and then empowering business analysts with visual tools, such as Tableau and Power BI. No longer did they need to know what data resides where and how to query that data in that platform. They could derive historical insights into the business using BI tools.&nbsp;<br></p><p>Data scientists, in contrast, build predictive models to derive business insights. The feature store is the data warehouse for Data Science - it is a central vault for storing documented, curated, and access-controlled features that can be used across many different models. The feature store ingests data from the Enterprise’s many different sources after transforming, aggregating, and validating the data.&nbsp;<br></p><p>Feature pipelines need to be written to ensure that data reliably flows from existing sources and is available in a format ready to be consumed by ML training pipelines and models.</p><p>Most Data Scientists currently do not have a feature store. They spend most of their time looking for, cleaning, and featurizing data. Hence, the (very real) cliché that 80% of data science is data wrangling. Data Scientists without a feature store work in an era akin to how business analysts worked before the advent of data warehouses, with low individual and organizational productivity.</p><h2>The Data Warehouse is an input <br>to the Feature Store&nbsp;</h2><p>Both platforms are a central store of curated data used to generate insights into the data. Both platforms have pipelines (ETL and feature pipelines, respectively) to ingest data from one or more disparate sources (operational databases, data lakes, etc).</p><p>Both benefit from metadata catalogs to organize data sets and access control to share data with only authorized actors.&nbsp;</p><p>Both platforms can be designed to scale-out on commodity hardware and store large volumes of data, although typically a data warehouse stores only relevant to analysis (modern <a href="#">data lakehouses</a> are designed to store large volumes of data more cost efficiently).<em>‍</em></p><figure id="w-node-d225d8bb42d9-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f7eed8f6ff9277909bd9c6e_visual_blog5.jpg" loading="lazy" alt=""></p></figure><h2>Feature Store as a Dual Database</h2><p>The main architectural difference between a data warehouse and a feature store is that the data warehouse is typically a single columnar database, while the feature store is typically implemented as two databases:</p><ul role="list"><li>an <strong>offline feature store</strong> for serving large batches of features to (1) create train/test datasets and (2) batch applications scoring models using those batches of features, and</li><li>an <strong>online feature store</strong> for serving a single row of features (a <em>feature vector</em>) to be used as input features for an online model for an individual prediction.<br></li></ul><p><strong>The offline feature store</strong> is typically required to efficiently serve and store large amounts of feature data, <strong>while the online feature store</strong> is required to return feature vectors in very low latency (e.g., &lt; 10ms). Examples of databases used for the offline feature store are Apache Hive and BigQuery and examples of online feature stores include MySQL Cluster, Redis, and DynamoDB.&nbsp;</p><p>Note that if you want to reuse features in different train/test datasets for different models, your database or application will need to join features together. This is true for both the offline and online feature stores. If your feature store does not support joining features, that is, you do not reuse features across different models, you (or some system) will need to create a new ingestion pipeline for every new model you support in production.</p><figure id="w-node-fbcf667874fd-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f7eee044a3a1d737610fc25_visual_blog4.jpg" loading="lazy" alt=""></p></figure><h2>Detailed Comparison</h2><p>In the table below, we see an overview of the main architectural differences between feature stores and data warehouses.<strong> Data warehouses</strong> are used primarily by business analysts for interactive querying and for generating historical reports/dashboards on the business.<strong> Feature stores</strong> are used by both data scientists and by the online/batch applications, and they are fed data by feature pipelines, typically written in Python or Scala/Java.&nbsp;</p><p>Data scientists typically use Python programs to create train/test datasets by joining existing features in the feature store together and materializing the train/test datasets in a <a href="#">file format best suited to the framework</a> they are going to train their model in (e.g., TFRecord for TensorFlow, NPY for PyTorch). Data warehouses and SQL currently lack this capability to create train/test datasets in ML file formats.</p><figure id="w-node-3cbc549719ba-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f7ef334aaaf9d602868fc36_table_comparison_04.jpg" loading="lazy" alt=""></p></figure><h2>Feature Data should be Validated <br>before Ingestion</h2><p>The table also shows the differences in the types of data stored, as well as how the data is stored, validated, and queried. A data warehouse stores data in tables along with schemas for describing the type of data and constraints for columns. Similarly, the feature store stores typed data (typically in tables), but as features are typically stored as ready-to-consume numerical values or vectors (embeddings) or tensors, there is less need for a richer set of column types compared to a data warehouse.&nbsp; Foreign key constraints are typically not supported in feature stores, due to the difficulty in enforcing such constraints between online and offline stores.</p><p>As model training is very sensitive to bad data (null values, outliers cause numerical instability, missing values), feature data should be validated before ingestion. Data validation frameworks, such as <a href="#">Great Expectations</a> and <a href="#">Deequ</a>, have appeared to help implement feature pipelines that apply predicates (data validation rules) on all the features ingested into the feature store, ensuring high data quality in the feature store.&nbsp;</p><p>Domain specific languages (DSL) are sometimes used to define the feature transformations, aggregations, and data validation rules in feature pipelines, but general purpose languages (Python, Scala) are commonly used when non-trivial feature engineering is required.&nbsp;</p><h2>Using the feature store to create train/test data</h2><p>Data scientists are one of the main users of the feature store. They use a feature repository to perform exploratory data analysis (EDA) - searching/browsing for available features and inspecting feature values/schemas/statistics. Data Scientists mainly use Python to select features to create train/test datasets. This typically involves joining features together to create a&nbsp; train/test dataset in their file format of choice (.tfrecord, .csv, .npy, .petastorm, etc). Sometimes feature stores support a DSL (domain specific language) to create train/test datasets or other languages such as Scala/Java.&nbsp;</p><h2>Online feature store</h2><p>Online applications use the online feature store to retrieve feature values with low latency to build feature vectors that are sent to models for predictions. In contrast to higher latency data warehouses, feature stores may be required to return feature vectors in single millisecond latency - only really achievable in row-oriented or key-value stores.&nbsp;</p><p>The typical access pattern for retrieving features is a key-value lookup, but if features are to be reused in the online feature store, then joins are again required (either in the database or in the application). In some databases (such as <a href="#">MySQL Cluster</a>), a small number of joins can be performed at very low latency.<br></p><h2>Feature statistics to monitor for feature <br>drift and data drift</h2><p>Descriptive statistics (e.g., mean, standard deviation) for features are also useful when identifying data drift in online models. Your monitoring infrastructure can calculate statistics on live prediction traffic, and compare those statistics with the values in the feature store to <a href="#">identify data drift</a> for the live traffic, potentially required retraining of the model.</p><h2>Time-Travel&nbsp;</h2><p>Temporal databases support <em>time-travel</em>: the ability to query data as it was at a given point-in-time or data changes in a given time-interval. The “AS OF SYSTEM TIME” syntax was introduced to <a href="#">SQL 2011</a> to standardize point-in-time queries, while the “VERSIONS BETWEEN SYSTEM TIME ... AND ... “ syntax was introduced to identify the versioned changes to data in a time interval. Time-travel is supported in some data warehouses, but does not have universal support across all vendors.</p><p>For a feature store time-travel has several important uses: when creating train/test data (e.g., training data is data from the years 2010-2018, while test data is data from the range 2019-2020). Time-travel is also useful to make changes to a dataset (e.g., rollback a bad commit of data to the dataset) or to compare metadata (statistics) for features and how they change over time. We rarely require time-travel for features used in serving. Time-travel is also important when performing point-in-time joins, where we ensure that there is no data leakage from the future when we create train/test datasets from historical data.</p><h2>Feature Pipelines&nbsp;</h2><p>Data warehouses typically have timed triggers for running ETL jobs (or data pipelines) to ingest the latest data from operational databases, message queues, and data lakes. Similarly, feature pipelines can timed triggers to transform and aggregate the latest data from different sources before storing it in both the online and offline feature store for scoring by online and offline applications. However, additional pipelines can also feed features to the feature store.&nbsp;</p><p>Predictions made by models can be stored in the feature store along with the outcomes for those predictions. There can be long lags of even days or months or years before outcomes become available - e.g., a prediction on whether a loan will be repaid or not), but as they arrive new training data becomes available that can be used to trigger re-training of models.</p><figure id="w-node-74c5777df82a-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f7ef3219e6baa58c301c833_table_comparison_03.jpg" loading="lazy" alt=""></p></figure><h2>Conclusion</h2><p>Data …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse">https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/feature-store-vs-data-warehouse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24718301</guid>
            <pubDate>Thu, 08 Oct 2020 12:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taiwan's Bike-Sharing Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24717228">thread link</a>) | @eric_khun
<br/>
October 8, 2020 | https://erickhun.com/posts/taiwan-youbike-bike-sharing/ | <a href="https://web.archive.org/web/*/https://erickhun.com/posts/taiwan-youbike-bike-sharing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><a href="https://taipei.youbike.com.tw/home">YouBike</a> (or Ubike) is my first choice of transportation when it comes to moving around the city of Taipei. I largely prefer it over taking the subway, bus, or taxi. It is affordable, well maintained, comfortable, at waking distance reach from anywhere, and the cities have built great biking paths in the major cities.</p>
<p>The number of YouBike rides keeps increasing steadily since it was launched in 2012. There were 170 million rides since it was introduced in 2012, and <a href="https://taipei.youbike.com.tw/news/content?5ee1e4b61b994541c0690826">last month it reached  ~3 million rides</a> in Taipei:</p>
<p><img src="https://erickhun.com/img/ubike/youbike-monthly-rental.jpg" alt="Youbike usage statistics"></p>
<h2 id="a-high-quality-infrastructure">A high-quality infrastructure</h2>
<p>YouBikes are <a href="https://taipei.youbike.com.tw/station/map">everywhere</a> in Taipei and New Taipei City. As for October 2020, over <a href="https://gist.github.com/erickhun/f0d3e8f3c3c4f70dc521c2abb43bb8a0">42000 YouBikes are deployed</a>, with over 1000 stations. Stations <a href="https://taipei.youbike.com.tw/news/list?5cb582c1060db454916c643c">get added every few weeks</a>.</p>
<p>Since the first time I arrive in Taipei (2016), I am pleasantly surprised that I rarely got a broken bike. <a href="https://en.wikipedia.org/wiki/Giant_Bicycles">Giant</a> is actually the (local) company that provides them. The bikes feel durable, lightweight, and really well maintained. Each bike is bought by the city for around <a href="https://disp.cc/b/163-6PkZ">9200 TWD (~USD 300)</a>, and comes with a 7 years maintenance.</p>
<p>To make it really convenient, the city has organized each station  <a href="https://english.gov.taipei/News_Content.aspx?n=A11F01CFC9F58C83&amp;s=5888478293ADD1A8">from 200 to 600 meters</a> from each other. What makes you within 5 to 10 minutes walk from wherever you are in the city.</p>
<p><img src="https://i.imgur.com/F5HWa3v.jpg" alt=""></p>
<h2 id="data-driven-decisions">Data-driven decisions</h2>
<p>I’ve noticed that the stations are also rarely empty. From time to time, I’ve spotted some employees “reloading” or “deloading” stations that are full or empty. Who are they? Where do they take those bikes? I’ve discussed with <a href="https://twitter.com/TaipeiUrbanism">Alex Garcia</a> and <a href="https://www.linkedin.com/in/timcho-giser">Tim Cho</a>, two urbanism specialists of the city of Taipei.</p>
<p>1 or 2 employees are responsible for a given area to “unload” or “refill” the stations. But how do they decide if some station should be “refilled” or not? Is a single empty station enough to make an employee move to the station? Not necessarily. Most of the time, an area of few stations being almost empty will make it worthwhile to move. This is a “<a href="https://en.wikipedia.org/wiki/Cluster_analysis">cluster analysis</a>”. Alex mentioned me they also have “re-balancing” trucks equipped with an application with a smart algorithm telling them where which full stations to unload, and which empty ones need a refill.</p>
<p>To make their work easier, historical data are used to predict the flow-in &amp; flow out for each station. They know the patterns on which stations will be empty and which one will need a refill. Those stations often have a “buffer” of bikes nearby locked together in bulk. When the station is about to get empty, the employee responsible for this area will drive there and refill the empty station with the buffer of bikes already present.</p>
<p>To make the decisions to add new stations, <a href="https://www.linkedin.com/in/timcho-giser">Tim</a> explained they use <a href="https://en.wikipedia.org/wiki/Geographic_information_system">GIS spatial analysis</a>,  to realize uncovered area (population density, schools, presence of metro station, POIs, etc…) to make the decision to add or not a new YouBike station.</p>
<h3 id="open-data">Open data</h3>
<p>Taipei City (and <a href="https://data.gov.tw/">Taiwan in general</a>) makes an amazing job at <a href="https://data.taipei/">opening their data</a>. It provides <a href="https://tcgbusfs.blob.core.windows.net/blobyoubike/YouBikeTP.json">real time data</a> showing each Youbike station status. Any developer can offer their own application to help users to find bikes availability or making the service more useful. This open data is how <a href="https://gist.github.com/erickhun/f0d3e8f3c3c4f70dc521c2abb43bb8a0">I’ve calculated the number</a> of YouBikes in Taipei.</p>
<p><a href="https://twitter.com/jakubsvehla/status/1311345837952434176">Jakub told me</a> he used this open data to help him stop being late at class. He depended on the YouBike to go to NTUST but ended up always late because his nearest station was empty. He started recording the patterns/waves of bikes coming and leaving the stations to know the time to go to the station.</p>
<p><a href="http://bdon.org/about/">Brandon</a> created this really <a href="http://bdon.org/youbike-forecast/">interesting visual map</a> showing detailed usage of each station with cool animations. If you live in Taiwan, click on your station, and you’ll see when bikes are more likely to be available!</p>
<p><img src="https://erickhun.com/img/ubike/youbike-realtime.gif" alt=""></p>
<p>Google recently took advantage of it and made a really nice implementation when users are looking for directions in Google Maps. The app will <a href="https://twitter.com/eric_khun/status/1291567323510317057">show you nearest departure/arrival Youbike station</a> and its availability:</p>
<p><img src="https://erickhun.com/img/ubike/GoogleMaps-Youbike.jpg" alt=""></p>
<h2 id="an-universal-and-simple-payment-system">An universal and simple payment system</h2>
<p>One of my favorite this about Taiwan is probably the EasyCard payment system. With a single card, you can use it in the metro, convenient store, supermarkets, and YouBike. Probably the best thing is that you can use that card everywhere in Taiwan.</p>
<p>Banks with their debit/credit cards and phones (via NFC?) have the Easycard payment system integrated. All those following card/debit cards integrate the EasyCard payment chip. Any convenient store will sell you one of those cards, without any requirements.</p>
<p><img src="https://erickhun.com/img/ubike/easy_cards-back-front.jpg" alt="Easy Card solution integrated into every card payment"></p>
<p>A single chip to rule them all.</p>
<h2 id="the-right-pricing">The right pricing</h2>
<p>The Youbike rental system is a pay as you go model. It <a href="https://taipei.youbike.com.tw/use/rates?5cc2971d083e7b55e32b8172">costs</a>  <strong>5 NTD (usd0,17) the first 30 minutes</strong>, then 10NTD (usd0.35) per 30 minute. The city also encourages the usage of YoubBke by taking 5NTD on the first 30 minutes on them. To compare the rate with other cities in the world:</p>
<ul>
<li>Lyon (France) (<a href="https://velov.grandlyon.com/en/offers/groups/list#190">1usd/ 45 minute</a> per rental)</li>
<li>Paris is 1EUR / 30 minute (~ usd1,20)</li>
<li>Germany has a <a href="https://www.callabike.de/en">3euros per 30 minutes</a> rate (~ usd3,50)</li>
</ul>
<h2 id="impressive-dedicated-bike-paths-infrastructure">Impressive dedicated bike paths infrastructure</h2>
<p>Taiwan is famously known for being a paradise for Bike lovers, from the urban city bikers the <a href="https://youtu.be/Sxfd2xzlM6k">most courageous professional bikers</a>. Did you know that Taiwan had more than 4500km of dedicated bike path? The longest one measuring <a href="https://edition.cnn.com/travel/article/taiwan-cycle-tour/index.html">968km long</a>. Taipei alone has 500+ km of dedicated biking path. The city has spent a lot of effort into building a large and safe bike path. It is really pleasant to move around the city:</p>
<p><img src="https://i.imgur.com/5sv48SJ.jpg" alt=""></p>
<p>The riverside bike-path is <a href="https://www.travel.taipei/en/must-visit/riverside-bikeway">more than 100 kilometers</a> long! And they <a href="https://english.gov.taipei/News_Content.aspx?n=A11F01CFC9F58C83&amp;sms=DFFA119D1FD5602C&amp;s=C8487022F5E63064">are planning to extends those biking paths</a> to expand bicycle trails in the city soon.</p>
<h2 id="an-unified-bike-sharing-system-in-all-cities">An unified bike-sharing system in all cities</h2>
<p>Another great thing is that all the biggest cities in Taiwan (Taichung, New Tapei City, Kaoshuing) have YouBike. No matter <a href="https://www.economicshelp.org/blog/265/economics/are-monopolies-always-bad/">great or bad</a>, it makes the discovery of a new city frictionless. You don’t have to subscribe to other services and worry about getting back a deposit.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Taipei has made a great job of implementing an amazing infrastructure bike-sharing infrastructure. With open data, the incentive to use bikes, maintaining a low price, and keeping bikes in great shape. The steady increases in the number of rides in Taipei talks by itself, while <a href="https://www.icmrindia.org/casestudies/catalogue/Operations/V%C3%A9lib_%202.0-Case.htm">other countries see their usage decreasing</a> over years. They’re today transitioning to a second generation of <a href="https://english.gov.taipei/News_Content.aspx?n=A11F01CFC9F58C83&amp;s=5888478293ADD1A8">Youbike 2.0</a>, better, lighter, and with docks taking less space.</p>
<!-- Taiwan also recently stopped the ["dockless bikes" company Ofo to operate](https://www.gvm.com.tw/article/66450) -->
<h4 id="next-reads">Next reads:</h4>
<p>🤖 <a href="https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html">How to build a chat bot with Google’s Sentence Encoder Model and Google Spreadsheet as a database</a></p>
<!-- 🇹🇼 Living in Taiwan? I've recently built [a chat bot](https://m.me/thetaiwanbot) giving you currated recommendations in Taiwan! Where to find the best value cheese? Where is the best pizza? etc...  [Here the details on how it works](https://jonathanbgn.com/nlp/2020/09/29/chatbot-universal-sentence-encoder.html) -->
<!-- 🌏 Interested in living and working in Taiwan? Have you checked the [Gold Card program](https://taiwangoldcard.com/application-faq/)?  -->
<p>📚 <a href="https://erickhun.com/posts/why-you-should-have-a-side-project/">Why you should have a side project</a></p>
<p>🤸🏻‍♂️ <a href="https://erickhun.com/posts/traveling-and-working-out/">How to keep working out while travelling</a></p>




        <center>

            
            <a href="https://twitter.com/eric_khun" data-size="large" data-show-count="true">Follow @eric_khun</a>
            <br>
            <a href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ferickhun.com%2fposts%2ftaiwan-youbike-bike-sharing%2f&amp;s=fb" target="_blank" rel="noopener" aria-label="Facebook">
              
            </a>
  
            
            <a href="https://twitter.com/intent/tweet/?text=Taiwan%27s%20amazing%20bike-sharing%20system%20by%20@eric_khun%20&amp;url=https%3a%2f%2ferickhun.com%2fposts%2ftaiwan-youbike-bike-sharing%2f&amp;s=tw" target="_blank" rel="noopener" aria-label="Twitter">
              
            </a>
  
            
            <a href="https://erickhun.com/cdn-cgi/l/email-protection#09367a7c6b636c6a7d345d68607e68672c3b3e7a2c3b396864687360676e2c3b396b60626c247a61687b60676e2c3b397a707a7d6c64292f686479326b666d70345d68607e68672c3b3e7a2c3b396864687360676e2c3b396b60626c247a61687b60676e2c3b397a707a7d6c64292429617d7d797a2c3a682c3b6f2c3b6f6c7b606a62617c67276a66642c3b6f79667a7d7a2c3b6f7d68607e68672470667c6b60626c246b60626c247a61687b60676e2c3b6f2f7a346c64686065" target="_self" rel="noopener" aria-label="E-Mail">
              
            </a>
  
            
            <a href="https://reddit.com/submit/?url=https%3a%2f%2ferickhun.com%2fposts%2ftaiwan-youbike-bike-sharing%2f&amp;resubmit=true&amp;title=Taiwan%27s%20amazing%20bike-sharing%20system&amp;s=red" target="_blank" rel="noopener" aria-label="Reddit">
              
            </a>
  
            
            <a href="whatsapp://send?text=Taiwan%27s%20amazing%20bike-sharing%20system%20-%20https%3a%2f%2ferickhun.com%2fposts%2ftaiwan-youbike-bike-sharing%2f&amp;s=whatsapp" target="_blank" rel="noopener" aria-label="WhatsApp">
              
            </a>
    
          </center>
      </div></div>]]>
            </description>
            <link>https://erickhun.com/posts/taiwan-youbike-bike-sharing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24717228</guid>
            <pubDate>Thu, 08 Oct 2020 08:52:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Luca Concept Car: An Electric Vehicle Made from Plastic Waste]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24717157">thread link</a>) | @jacquesm
<br/>
October 8, 2020 | https://www.smalltechnews.com/archives/62931 | <a href="https://web.archive.org/web/*/https://www.smalltechnews.com/archives/62931">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.smalltechnews.com/archives/62931</link>
            <guid isPermaLink="false">hacker-news-small-sites-24717157</guid>
            <pubDate>Thu, 08 Oct 2020 08:37:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using a Piece of Paper as a Display Terminal – Ed vs. Vim]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24716218">thread link</a>) | @rhabarba
<br/>
October 7, 2020 | https://blog.robertelder.org/paper-display-terminal-ed-vim/ | <a href="https://web.archive.org/web/*/https://blog.robertelder.org/paper-display-terminal-ed-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>


<h5>2020-10-05 - By Robert Elder</h5>




<iframe src="https://www.youtube.com/embed/8vmOTvRXZ0E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This article will focus on discussing why the ancient text editor <a href="https://en.wikipedia.org/wiki/Ed_(text_editor)">'ed'</a> works the way it does.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Despite having its roots in the late 1960s, the 'ed' editor is still installed by default on most modern Linux distributions. &nbsp;Although there are few practical use cases for this editor today, it can still be meaningful to learn how 'ed' works since other Unix tools like vim, grep or sed have features that are significantly influenced from 'ed'.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If you try running the 'ed' command with or without a file argument, you'll see something that looks like this:</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_prompt-wait_811x349_q92.png" width="811" height="349"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If you're waiting for something to happen then you'll be waiting a long time. &nbsp;That's because 'ed' is waiting for you to do something! &nbsp;The 'ed' program doesn't work like other command-line text editors such as vim or nano. &nbsp;The luxury of being able to print the contents of the current file to the terminal is something that 'ed' takes very seriously. &nbsp;That's why you need to explicitly give 'ed' a command to tell it to do so!</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For example, if you want to print out an individual line in the file, you can just type the line number and press enter. &nbsp;If you want to append text, use the single-letter command 'a' on a line by itself to enter 'append' mode. &nbsp;Once you're done adding text, write a '.' character on a line by itself and press enter to stop adding text to the file. &nbsp;To review all the lines in the file, you can use the command '1,$p'. &nbsp;Finally, once you're done editing the file, you can use 'wq' to exit:</p>

<p><code><pre>1
Hello World.
a
Here is some more text.
.
1,$p
Hello World.
Here is some more text.
wq
</pre></code></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To make sense of why this editor is so hard to use, it make sense to think about the way in which people interacted with computers in the early days of computing. &nbsp;Around the time when 'ed' was created, it was still common for computers to print their output on <em>paper</em> instead of electronic screens! &nbsp;These early output devices were called <a href="https://en.wikipedia.org/wiki/Teleprinter">'teleprinters'</a>, often abbreviated as TTY. &nbsp;The term TTY is still used on most *nix systems to this day, and if you run this command, you can probably see some of the virtual TTY devices on your system:</p>

<p><code><pre><span>ls</span> /dev/tty*
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This ancient model of sending an infinite stream of characters (sent serially) to a 'terminal' or 'teleprinter' device that 'prints' or 'renders' them is still used today. &nbsp;It is even used by more modern terminal programs like vim or nano! &nbsp;You might not believe that vim works this way because it displays all kinds of information at the top and bottom of the terminal. &nbsp;Vim also lets you scroll up and down or open up screen splits etc. &nbsp;You can't possibly send the output of vim to a printer, right? &nbsp;Yes, you can and that's exactly what we're about to try.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The 'script' command lets you capture all output during a terminal session and save it to a file. &nbsp;This is a great way to log the output when you're running through a sequences of commands that you need to keep track of, but you can also use it to capture everything that gets output to the terminal during a vim session:</p>

<p><code><pre>script
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After running the 'script' command try opening a vim session. &nbsp;After doing a few things in vim, quit and then run the 'exit' command in the shell to exit the 'script' session to finish logging:</p>

<p><code><pre><span>exit</span>
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;All of the output from the terminal session is now saved in a file called 'typescript'. &nbsp;Here's an image of what some of the output in the script looks like:</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_vim-script-output_718x292_q92.png" width="718" height="292"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Many of these seemingly gibberish symbols are actually <a href="https://en.wikipedia.org/wiki/ANSI_escape_code">ANSI Escape codes</a>. &nbsp;These are the secret to how vim (and all other terminal applications) can use a serial output to print all sorts of interesting user interfaces. &nbsp;Most importantly, some of these escape sequences allow you to move the printing cursor around to arbitrary positions. &nbsp;That's how vim can keep some text pinned at the bottom or top of the terminal while also giving the illusion that you're scrolling 'up' or 'down' in the file. &nbsp;Some escape codes also control the foreground and background colours.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the old days, these escape codes were not actually processed by the CPU. &nbsp;The were instead interpreted by the 'terminal' monitor device itself. &nbsp;In other words, the oldest 'terminals' can be thought of as physically separate devices that received a serial stream of text, cursor movement instructions, and color changing instructions.  &nbsp;On a 'modern' computer, every 'terminal' window that you open is basically a software emulation of an ancient physical device that you can imagine to look like a small and bulky CRT monitor. &nbsp;Today, these escape codes are processed by the CPU of your laptop or desktop computer inside these software emulated 'terminals' in your graphical desktop environment.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;So, what's stopping us from trying to render the output of vim on a piece of paper to pretend that we're in the year 1969? &nbsp;Nothing! &nbsp;Here's is what the output of vim looks like when I try to render it using my laser printer:</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_vim-page_1920x1080_q30.jpeg" width="1920" height="1080"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The reason that this output doesn't look very useful is because my printer isn't expecting to be used as a display terminal for vim. &nbsp;It doesn't know how to deal with all the ANSI escape sequences and we end up with this weird looking mess.  &nbsp;Do you see the '?2004h' part near the start of the output? &nbsp;You can look that up and see that it's an ANSI escape sequence to 'Turn on bracketed paste mode'. &nbsp;It is an exercise left to the reader to look up the rest of the ANSI escape sequences shown on the page above.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Interestingly, my printer seemed to choke when I printed this and got stuck saying 'data remaining' until I printed a blank test page.</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_printer-stuck_1920x894_q50.jpeg" width="1920" height="894"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I didn't bother investigating, but I assume one of the control sequences confused the printer and made it think it was still waiting on data from the computer.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And here is what using ed would look like if you were only able to render its output on a piece of paper:</p>

<p><img src="https://blog.robertelder.org/images/paper-display-terminal-ed-vim_ed-page_1920x1080_q30.jpeg" width="1920" height="1080"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Since 'ed' doesn't print any ANSI escape sequences, my printer prints this with no problems!</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Based on the two experiences described above, which editor do you think you'd prefer if you had to print all the output on paper?</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If you decide to try and learn 'ed', you'll find that the man pages and the '-h' flag are not very helpful. &nbsp;Instead, you should check out the 'info' pages since that's where you'll find out all the details of different editor modes and single-letter commands are:</p>

<p><code><pre>info ed
</pre></code></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After you play around with 'ed' for a while, you'll realize that it acts almost like a command-line shell in itself. &nbsp;The only difference is that the environment in which you're working is a file instead of the user space of your operating system. &nbsp;Every little i/o operation on the file is implemented as a command that requires as little information as possible. &nbsp;This makes complete sense when you have to print everything to paper!</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Imagine working on a file with modern Vim where your output always goes to a printer. &nbsp;You now decide to open a log file to check what's on the last line and immediately, your printer starts churning a full page of material. &nbsp;Oops, you opened the wrong file. &nbsp;Try another file, and again, oops! &nbsp;Wrong file again! &nbsp;That's a lot of wasted paper. &nbsp;What is it with these millennials and their fancy text editors that just print every line automatically! &nbsp;I remember the good old days when the users had control over their systems, and programs wouldn't just do whatever they want without asking!</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In conclusion, the reason why the 'ed' command works the way it does was due to the higher resources constraints that existed at the time. &nbsp;Features like electronic display terminals and ANSI escape sequences were not in common enough use at the time when 'ed' was created, so there was no reason to consider using them. &nbsp;Instead, a shell-like command-line interface for editing files made way more sense.</p>




<table>
<tbody>
<tr>


	
		<td><a href="https://blog.robertelder.org/recording-660-fps-on-raspberry-pi-camera/"><img src="https://blog.robertelder.org/images/recording-660-fps-on-raspberry-pi-camera-thumb_250x150_q85.jpeg" alt="A Guide to Recording 660FPS Video On A $6 Raspberry Pi Camera" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/recording-660-fps-on-raspberry-pi-camera/"><strong>A Guide to Recording 660FPS Video On A $6 Raspberry Pi Camera</strong></a></p><p>Published 2019-08-01</p></div>
		</td>
	
	
	
	
	
	



	
	
	
	
		<td><a href="https://www.kickstarter.com/projects/2034896774/regular-expression-sticker-collection-and-video-guide?utm_source=blog&amp;utm_medium=link&amp;utm_campaign=k7&amp;utm_content=paper-display-terminal-ed-vim"><img src="https://blog.robertelder.org/images/k7_250x150_q85.png" alt="Regular Expression Laptop Stickers &amp; Video Guide" width="250" height="150"></a><div><p><a href="https://www.kickstarter.com/projects/2034896774/regular-expression-sticker-collection-and-video-guide?utm_source=blog&amp;utm_medium=link&amp;utm_campaign=k7&amp;utm_content=paper-display-terminal-ed-vim"><strong>Regular Expression Laptop Stickers &amp; Video Guide</strong></a></p></div>
		</td>
	
	
	



	
		<td><a href="https://blog.robertelder.org/don-libes-expect-unix-automation-tool/"><img src="https://blog.robertelder.org/images/automation-methods-thumb_250x150_q85.png" alt="Don Libes' Expect:  A Surprisingly Underappreciated Unix Automation Tool" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/don-libes-expect-unix-automation-tool/"><strong>Don Libes' Expect:  A Surprisingly Underappreciated Unix Automation Tool</strong></a></p><p>Published 2016-12-08</p></div>
		</td>
	
	
	
	
	
	



	
	
	
		<td><a href="https://twitter.com/RobertElderSoft">@RobertElderSoft On Twitter</a>
		</td>
	
	
	
	

</tr>
<tr>


	
		<td><a href="https://blog.robertelder.org/virtual-memory-with-256-bytes-of-ram/"><img src="https://blog.robertelder.org/images/256-bytes-virtual-memory-thumb_250x150_q85.png" alt="Virtual Memory With 256 Bytes of RAM - Interactive Demo" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/virtual-memory-with-256-bytes-of-ram/"><strong>Virtual Memory With 256 Bytes of RAM - Interactive Demo</strong></a></p><p>Published 2016-01-10</p></div>
		</td>
	
	
	
	
	
	



	
	
		<td><h2>Subscribe to Updates</h2><form method="post" action="https://api.robertelder.org/v1/message/">Email: </form><br><a href="https://www.robertelder.org/privacy-policy/">Privacy Policy</a>
		</td>
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/what-is-ssh/"><img src="https://blog.robertelder.org/images/what-is-ssh-thumb_250x150_q85.png" alt="What is SSH?  Linux Commands For Beginners" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/what-is-ssh/"><strong>What is SSH?  Linux Commands For Beginners</strong></a></p><p>Published 2017-04-30</p></div>
		</td>
	
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/installing-ubuntu-16-linux-ge62-6qd-apache-pro-msi-notebook/"><img src="https://blog.robertelder.org/images/msi-ge62-6qd-apache-pro_250x150_q85.jpeg" alt="Installing Ubuntu 16 Linux On A GE62 6QD Apache Pro MSI Notebook" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/installing-ubuntu-16-linux-ge62-6qd-apache-pro-msi-notebook/"><strong>Installing Ubuntu 16 Linux On A GE62 6QD Apache Pro MSI Notebook</strong></a></p><p>Published 2016-08-02</p></div>
		</td>
	
	
	
	
	
	

</tr>
<tr>


	
		<td><a href="https://blog.robertelder.org/data-science-linux-command-line/"><img src="https://blog.robertelder.org/images/data-science-linux-commands-thumb_250x150_q85.jpeg" alt="An Introduction To Data Science On The Linux Command Line" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/data-science-linux-command-line/"><strong>An Introduction To Data Science On The Linux Command Line</strong></a></p><p>Published 2019-10-16</p></div>
		</td>
	
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/robert-elder-software-linux-operating-system/"><img src="https://blog.robertelder.org/images/robert-elder-software-linux-operating-system-thumb_250x150_q85.png" alt="Introducing The Robert Elder Software Linux Operating System" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/robert-elder-software-linux-operating-system/"><strong>Introducing The Robert Elder Software Linux Operating System</strong></a></p><p>Published 2016-09-27</p></div>
		</td>
	
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/overlap-add-overlap-save/"><img src="https://blog.robertelder.org/images/overlap-add-overlap-save-thumb_250x150_q85.png" alt="Overlap Add, Overlap Save Visual Explanation" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/overlap-add-overlap-save/"><strong>Overlap Add, Overlap Save Visual Explanation</strong></a></p><p>Published 2018-02-10</p></div>
		</td>
	
	
	
	
	
	



	
		<td><a href="https://blog.robertelder.org/fast-meme-transform/"><img src="https://blog.robertelder.org/images/fast-meme-transform-thumb_250x150_q85.jpeg" alt="The Fast Meme Transform: Convert Audio Into Linux Commands" width="250" height="150"></a><div><p><a href="https://blog.robertelder.org/fast-meme-transform/"><strong>The Fast Meme Transform: Convert Audio Into Linux Commands</strong></a></p><p>Published 2018-02-10</p></div>
		</td>
	
	
	
	
	
	

</tr>
</tbody>
</table>


				</div>
			</div></div>]]>
            </description>
            <link>https://blog.robertelder.org/paper-display-terminal-ed-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24716218</guid>
            <pubDate>Thu, 08 Oct 2020 05:45:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NYU DS-GA 1008 – Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24715307">thread link</a>) | @eugenhotaj
<br/>
October 7, 2020 | https://atcold.github.io/pytorch-Deep-Learning/ | <a href="https://web.archive.org/web/*/https://atcold.github.io/pytorch-Deep-Learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <!-- Provide site root to javascript -->
    

    <!-- Work around some values being stored in localStorage wrapped in quotes -->
    

    <!-- Set the theme before any content is loaded, prevents flash -->
    

    <!-- Hide / unhide sidebar before it is displayed -->
    

    <nav id="sidebar" aria-label="Table of contents" aria-hidden="false">
        
        
    </nav>

    <div id="page-wrapper">
        <div class="page">
            

            <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
            

            <div id="content">
                <main>
                    <div class="page">
                      
                      <p><strong>DS-GA 1008 · SPRING 2020 · <a href="http://cds.nyu.edu/">NYU CENTER FOR DATA SCIENCE</a></strong></p>



<h2 id="description">Description</h2>

<p>This course concerns the latest techniques in deep learning and representation learning, focusing on supervised and unsupervised deep learning, embedding methods, metric learning, convolutional and recurrent nets, with applications to computer vision, natural language understanding, and speech recognition. The prerequisites include: <a href="https://cds.nyu.edu/academics/ms-curriculum/">DS-GA 1001 Intro to Data Science</a> or a graduate-level machine learning course.</p>

<h2 id="lectures">Lectures</h2>

<p><strong>Legend</strong>: 🖥 slides, 📓 Jupyter notebook, 🎥 YouTube video.</p>

<table>
<!-- =============================== HEADER ================================ -->
  <thead>
    <tr>
      <th>Week</th>
      <th>Format</th>
      <th>Title</th>
      <th>Resources</th>
    </tr>
  </thead>
  <tbody>
<!-- =============================== WEEK 1 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week01/01">①</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week01/01-1">History and motivation</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1Q7LtZyIS1f3TfeTGll3aDtWygh3GAfCb">🖥️</a>
        <a href="https://www.youtube.com/watch?v=0bMe_vCZo30">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week01/01-2">Evolution and DL</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week01/01-3">Neural nets (NN)</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/01-tensor_tutorial.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/02-space_stretching.ipynb">📓</a>
        <a href="https://www.youtube.com/watch?v=5_qrxVq1kvc">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 2 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week02/02">②</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week02/02-1">SGD and backprop</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1w2jV_BT2hWzfOKBR02x_rB4-dfVUI6SR">🖥️</a>
        <a href="https://www.youtube.com/watch?v=d9vdh3b787Y">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week02/02-2">Backprop in practice</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week02/02-3">NN training</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/01%20-%20Spiral%20classification.pdf">🖥</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/04-spiral_classification.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/05-regression.ipynb">📓</a>
        <a href="https://www.youtube.com/watch?v=WAn6lip5oWk">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 3 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week03/03">③</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week03/03-1">Parameter transformation</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=18UFaOGNKKKO5TYnSxr2b8dryI-PgZQmC">🖥️</a>
        <a href="https://youtu.be/FW5gFiJb-ig">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week03/03-2">CNN</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week03/03-3">Natural signals' properties</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/02%20-%20CNN.pdf">🖥</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/06-convnet.ipynb">📓</a>
        <a href="https://youtu.be/kwPWpVverkw">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 4 ================================ -->
    <tr>
      <td rowspan="1"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week04/04">④</a></td>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week04/04-1">1D convolutions</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/07-listening_to_kernels.ipynb">📓</a>
        <a href="https://youtu.be/OrBEon3VlQg">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 5 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week05/05">⑤</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week05/05-1">Optimisation I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1pwlGN6hDFfEYQqBqcMjWbe4yfBDTxsab">🖥️</a>
        <a href="https://youtu.be/--NZb480zlg">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week05/05-2">Optimisation II</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week05/05-3">CNN, autograd</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/03-autograd_tutorial.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/extra/b-custom_grads.ipynb">📓</a>
        <a href="https://youtu.be/eEzCZnOFU1w">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 6 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week06/06">⑥</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week06/06-1">CNN applications</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1opT7lV0IRYJegtZjuHsKhlsM5L7GpGL1">🖥️</a>
        <a href="https://drive.google.com/open?id=1sdeVBC3nuh5Zkm2sqzdScEicRvLc_v-F">🖥️</a>
        <a href="https://youtu.be/ycbMGyCPzvE">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week06/06-2">RNNs and attention</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week06/06-3">Training RNNs</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/08-seq_classification.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/09-echo_data.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/04%20-%20RNN.pdf">🖥️</a>
        <a href="https://youtu.be/8cAffg2jaT0">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 7 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week07/07">⑦</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-1">Energy-Based Models</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1z8Dz1YtkOEJpU-gh5RIjORs3GGqkYJQa">🖥️</a>
        <a href="https://youtu.be/tVwV14YkbYs">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-2">SSL, EBM</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-3">Autoencoders</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/10-autoencoder.ipynb">📓</a>
        <a href="https://youtu.be/bggWQ14DD9M">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 8 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week08/08">⑧</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week08/08-1">Contrastive methods</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1Zo_PyBEO6aNt0GV74kj8MQL7kfHdIHYO">🖥️</a>
        <a href="https://youtu.be/ZaVP2SY23nc">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week08/08-2">Regularised latent</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week08/08-3">Training VAEs</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/11-VAE.ipynb">📓</a>
        <a href="https://youtu.be/7Rb4s9wNOmc">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 9 ================================ -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week09/09">⑨</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week09/09-1">Sparsity</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=1wJRzhjSqlrSqEpX4Omagb_gdIkQ5f-6K">🖥️</a>
        <a href="https://youtu.be/Pgct8PKV7iw">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week09/09-2">World model, GANs</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week09/09-3">Training GANs</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/05%20-%20Generative%20models.pdf">🖥️</a>
        <a href="https://github.com/pytorch/examples/tree/master/dcgan">📓</a>
        <a href="https://youtu.be/xYc11zyZ26M">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 10 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week10/10">⑩</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week10/10-1">CV SSL I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/open?id=16lsnDN2HIBTcRucbVKY5B_U16c0tNQhR">🖥️</a>
        <a href="https://youtu.be/0KeR6i1_56g">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week10/10-2">CV SSL II</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week10/10-3">Predictive Control</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/09%20-%20Controller%20learning.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/14-truck_backer-upper.ipynb">📓</a>
        <a href="https://youtu.be/A3klBqEWR-I">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 11 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week11/11">⑪</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week11/11-1">Activations</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1AzFVLG7D4NK6ugh60f0cJQGYF5OL2sUB">🖥️</a>
        <a href="https://drive.google.com/file/d/1rkiZy0vjZqE2w7baVWvxwfAGae0Eh1Wm">🖥️</a>
        <a href="https://drive.google.com/file/d/1tryOlVAFmazLLZusD2-UfReFMkPk5hPk">🖥️</a>
        <a href="https://youtu.be/bj1fh3BvqSU">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week11/11-2">Losses</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week11/11-3">PPUU</a></td>
      <td>
        <a href="http://bit.ly/PPUU-slides">🖥️</a>
        <a href="http://bit.ly/PPUU-code">📓</a>
        <a href="https://youtu.be/VcrCr-KNBHc">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 12 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week12/12">⑫</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week12/12-1">DL for NLP I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/149m3wRavTp4DQZ6RJTej8KP8gv4jnkPW/">🖥️</a>
        <a href="https://youtu.be/6D4EWKJgNn0">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week12/12-2">DL for NLP II</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week12/12-3">Attention &amp; transformer</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/10%20-%20Attention%20%26%20transformer.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/15-transformer.ipynb">📓</a>
        <a href="https://youtu.be/f01J0Dri-6k">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 13 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week13/13">⑬</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week13/13-1">GCNs I</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1oq-nZE2bEiQjqBlmk5_N_rFC8LQY0jQr/">🖥️</a>
        <a href="https://youtu.be/Iiv9R6BjxHM">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week13/13-2">GCNs II</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week13/13-3">GCNs III</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/11%20-%20GCN.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/16-gated_GCN.ipynb">📓</a>
        <a href="https://youtu.be/2aKXWqkbpWg">🎥</a>
      </td>
    </tr>
<!-- =============================== WEEK 14 =============================== -->
    <tr>
      <td rowspan="3"><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14">⑭</a></td>
      <td rowspan="2">Lecture</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14-1">Structured Prediction</a></td>
      <td rowspan="2">
        <a href="https://drive.google.com/file/d/1qBu-2hYWaGYEXeX7kAU8O4S2RZ1hMjsk/">🖥️</a>
        <a href="https://youtu.be/gYayCG6YyO8">🎥</a>
      </td>
    </tr>
    <tr><td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14-2">Graphical methods</a></td></tr>
    <tr>
      <td rowspan="1">Practicum</td>
      <td><a href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14-3">Regularisation and Bayesian</a></td>
      <td>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/07%20-%20Regularisation.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/12-regularization.ipynb">📓</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/slides/08%20-%20Bayesian%20NN.pdf">🖥️</a>
        <a href="https://github.com/Atcold/pytorch-Deep-Learning/blob/master/13-bayesian_nn.ipynb">📓</a>
        <a href="https://youtu.be/DL7iew823c0">🎥</a>
      </td>
    </tr>
  </tbody>
</table>

<h2 id="people">People</h2>

<table>
  <thead>
    <tr>
      <th>Role</th>
      <th>Photo</th>
      <th>Contact</th>
      <th>About</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Instructor</td>
      <td><img src="https://atcold.github.io/pytorch-Deep-Learning/images/Yann.png" width="100" height="100"></td>
      <td><a href="https://twitter.com/ylecun">Yann LeCun</a><br>yann@cs.nyu.edu</td>
      <td>Silver Professor in CS at NYU<br>and Turing Award winner</td>
    </tr>
    <tr>
      <td>Instructor</td>
      <td><img src="https://avatars1.githubusercontent.com/u/2119355" width="100" height="100"></td>
      <td><a href="https://twitter.com/alfcnz">Alfredo Canziani</a><br>canziani@nyu.edu</td>
      <td>Asst. Prof. in CS at NYU</td>
    </tr>
    <tr>
      <td>Assistant</td>
      <td><img src="https://pbs.twimg.com/profile_images/1186879808845860864/czRv3g1G_400x400.jpg" width="100" height="100"></td>
      <td><a href="https://twitter.com/marikgoldstein">Mark Goldstein</a><br>goldstein@nyu.edu</td>
      <td>PhD student in CS at NYU</td>
    </tr>
    <tr>
      <td>Webmaster</td>
      <td><img src="https://pbs.twimg.com/profile_images/673997980370927616/vMXf545j_400x400.jpg" width="100" height="100"></td>
      <td><a href="https://twitter.com/ebetica">Zeming Lin</a><br>zl2799@nyu.edu</td>
      <td>PhD student in CS at NYU</td>
    </tr>
  </tbody>
</table>

<!--
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Serkan Karakulak <br>sk7685@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Raghav Jajodia <br>rj1408@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Priyank Pathak <br>pp1953@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Chiao-Hsun Wang <br>chw371@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Pedro Vidal<br>pmh314@nyu.edu|
|Grader|<img src="https://st3.depositphotos.com/13159112/17145/v/450/depositphotos_171453724-stock-illustration-default-avatar-profile-icon-grey.jpg" width="100" height="100">|Bixing Yan <br>by783@nyu.edu|
-->

<h2 id="disclaimer">Disclaimer</h2>

<p>All other texts found on this site are lecture notes taken by students of the New York University during lectures given by Yann Le Cun, Alfredo Canziani, Ishan Misra, Mike Lewis and Xavier Bresson.
Thus the texts in English were written by about 130 people, which has an impact on the homogeneity of the texts (some write in the past tense, others in the present tense; the abbreviations used are not always the same; some write short sentences, while others write sentences of up to 5 or 6 lines, etc.).
It is possible that there may be some omissions: typing errors, spelling mistakes, etc. If you notice any, we invite you to submit a PR on the <a href="https://github.com/Atcold/pytorch-Deep-Learning/pulls">GitHub directory of the site</a> specifying with an <code>[EN]</code> that it concerns the English translation.</p>

<p>Wishing you a deep reading !</p>

                    </div>
                </main>

                <nav aria-label="Page navigation">
                    <!-- Mobile navigation buttons -->
                    <a rel="prev" href="https://atcold.github.io/pytorch-Deep-Learning" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i></i>
                    </a>

                    <a rel="next" href="https://atcold.github.io/pytorch-Deep-Learning/en/about/" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>

                    
                </nav>
            </div>
        </div>

        <nav aria-label="Page navigation">
                <a href="https://atcold.github.io/pytorch-Deep-Learning" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                    <i></i>
                </a>

                <a href="https://atcold.github.io/pytorch-Deep-Learning/en/about/" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                    <i></i>
                </a>
        </nav>

    </div>

    
    
    

    

    

</div>]]>
            </description>
            <link>https://atcold.github.io/pytorch-Deep-Learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715307</guid>
            <pubDate>Thu, 08 Oct 2020 03:13:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New York City thinks up to half of restaurants will close permanently [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 135 (<a href="https://news.ycombinator.com/item?id=24715150">thread link</a>) | @bookofjoe
<br/>
October 7, 2020 | https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf | <a href="https://web.archive.org/web/*/https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715150</guid>
            <pubDate>Thu, 08 Oct 2020 02:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24715148">thread link</a>) | @zoozla
<br/>
October 7, 2020 | https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715148</guid>
            <pubDate>Thu, 08 Oct 2020 02:47:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recycling was a lie to sell more plastic, recycling industry veteran says]]>
            </title>
            <description>
<![CDATA[
Score 969 | Comments 407 (<a href="https://news.ycombinator.com/item?id=24714880">thread link</a>) | @vivekd
<br/>
October 7, 2020 | https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Less than 10 per cent of the plastics we’ve used have been recycled. A new documentary reveals why</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5755241.1602170985!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/157672506.jpg"></p></div><figcaption>trash on the beach<!-- --> <!-- -->(Getty Images)</figcaption></figure><p><span><p>Although our landfills and oceans are full of it, we are as dependent as ever on plastic. And since COVID-19, it's gotten worse.&nbsp;</p>  <p>Last year, Canada announced it was working on a ban of single-use plastics, which was initally&nbsp;<a href="https://www.cbc.ca/news/canada/toronto/single-use-plastics-covid-1.5683617">sidelined by the pandemic</a>. Recently, the government announced that <a href="https://www.cbc.ca/news/politics/single-use-plastics-1.5753327">many single-use plastics will be banned</a> by the end of 2021. At the same time, <a href="https://www.cbc.ca/news/canada/toronto/single-use-plastics-covid-1.5683617">CBC News reports</a> our single-use plastic use increased by 250 to 300 per cent as people tossed their personal protective equipment and stopped using reusable bags and containers over fears they would spread the virus.</p>  <p>What makes our lives convenient is also burying us. <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><strong><em>Plastic Wars</em></strong></a>, presented by <em>The Passionate Eye</em>, looks at the mounting crisis and how the industry has spent millions promoting recycling — just to sell more plastic.</p>  <h2>Less than 10% of the plastics we've used have been recycled</h2>  <p>Although activists sounded the alarm about plastic waste in the 1970s, the documentary claims from 1990 to 2010, plastic production more than doubled. We've been sorting our trash for decades, believing it would be recycled. But the truth is the vast majority of the plastic we use won't be. Over the last seven decades, <a href="https://www.oecd.org/environment/waste/policy-highlights-improving-plastics-management.pdf">less than 10 per cent of plastic waste has been recycled</a>.&nbsp;</p>  <p>That's because, says David Allaway, from the Oregon Department of Environmental Quality, the conversation has been almost exclusively about recycling and not reducing and reusing.</p>  <p><span><span><div><div role="button" tabindex="0" title="Plastic Wars: Recycling"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1002/935/PlasticWars_Recycling_2500kbps_620x350_1755680835594.jpg" alt=""></p></div></div></div><span>Even as the plastic crisis worsens, the demand for plastic grows and plastic production is rapidly expanding. One issue? Only focusing on recycling, and not reducing the amount of plastic that we use.<!-- --> <!-- -->1:06</span></span></span></p>  <h2>Recycling logo was used as a green marketing tool, says industry expert</h2>  <p>In the '80s, the industry was at the centre of an environmental backlash. Fearing an outright ban on plastics, manufacturers looked for ways to get ahead of the problem. They looked at recycling as a way to improve the image of their product and started labeling plastics with the now ubiquitous chasing-arrows symbol with a number inside.&nbsp;</p>  <p>According to Ronald Liesemer, an industry veteran who was tasked with overseeing the new initiative, "Making recycling work was a way to keep their products in the marketplace."&nbsp;</p>  <p>Most consumers might have assumed the symbol meant the product was recyclable. But according to experts in the film, there was no economically viable way to recycle most plastics, and they have ultimately ended up in a landfill. This included plastic films, bags and the wrapping around packaged goods, as well as containers like margarine tubs.<br> "Our own customers … they would flat out say, 'It says it's recyclable right on it,'" says Coy Smith, former board member of the National Recycling Coalition. "And I'd be like, 'I can tell you, I can't give this away. There's no one that would even take it if I paid them to take it.'" He believes manufacturers used the symbol as a green marketing tool.</p>  <p>"If the public thinks that recycling is working, then they're not going to be as concerned about the environment," says Larry Thomas, another top industry official interviewed in <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a>.</p>  <p>According to Lewis Freeman, a former vice-president with the Society of the Plastics Industry, many in the industry had doubts about recycling from the start. "There was never an enthusiastic belief that recycling was ultimately going to work in a significant way," he says.</p>  <p>Yet the plastic industry spent millions on ads selling plastics and recycling to consumers.</p>  <h2>Lots of our plastic was shipped to China, then Southeast Asia, for 'recycling'</h2>  <p>To solve the plastic waste problem, many recyclers started selling their product to China in the 1990s. According to recycling broker Sunil Bagaria, China took waste that North American recyclers couldn't use. "As long as it remotely resembled plastic, they wanted it," he says.</p>  <p>But they used the good stuff and disposed of the rest. And because of a growing plastic waste problem in that country, China finally stopped taking most imported plastic waste in 2018.</p>  <p>"We never asked the question, 'Are they doing it the right way? Are we damaging the environment more in the name of recycling?'" says Bagaria.</p>  <p>Now, Southeast Asian countries like Indonesia have picked up the plastic waste market. And although some North American plastics recyclers are following up to ensure their products are in fact being recycled, plastic waste is now a growing problem there, too.&nbsp;</p>  <p>In <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a>, local activist Yuyan Ismawati visits a rural community where locals scour through a huge field of plastic waste for items of value and burn the rest. This creates health problems for the residents in addition to destroying the surrounding environment. "We are struggling to clean up the modern debris and modern litter in Indonesia, the additional burden of waste from overseas — I don't know how we are going to handle it," says Ismawati. "Americans need to know that your waste ended up here."</p>  <h2>Production of plastics expected to triple by 2050</h2>  <p>In 2020, roughly 60 years after concerns about plastic waste were first raised, the focus is still on the consumer to recycle, says Allaway, and not on the environmental impact of the product and overproduction by the industry.</p>  <p><span><span><div><div role="button" tabindex="0" title="Plastic Wars: Full Impact"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1004/887/PlasticWars_FullImpact_2500kbps_620x350_1755684419745.jpg" alt=""></p></div></div></div><span>Consumers are constantly told that they should do their part to reduce plastic waste, but in reality, consumers have the lowest amount of leverage in reducing waste - it's plastic producers that should be reporting their full environmental impacts.<!-- --> <!-- -->1:56</span></span></span></p>  <p>According to <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a> the problem is only going to get worse. By 2050, it's estimated the global production of plastic will triple. As the oil and gas industry — which provides the source materials for plastics — &nbsp;faces a future of declining demand for fuel, it has turned to other markets.&nbsp;</p>  <p>The stakes are high, says Annie Leonard, executive director of Greenpeace USA. "This is their lifeline," she says. "They are going to double down on single-use plastic like we have never seen. So we're heading towards a real battle.... This is the big war."&nbsp;</p>  <p>Watch <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a> on <em>The Passionate Eye</em>.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618</link>
            <guid isPermaLink="false">hacker-news-small-sites-24714880</guid>
            <pubDate>Thu, 08 Oct 2020 02:01:04 GMT</pubDate>
        </item>
    </channel>
</rss>
